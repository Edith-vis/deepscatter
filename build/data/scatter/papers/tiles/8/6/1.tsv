id	title	keywords	abstract	entities	authors	year	journal	doi	fos	area	x	y	ix
8b4e62a0f35c429e5db331ee9bb098eead910e68	bad pixel correction method for locally analytic images: application to infrared spectroscopy	sensors;numerical analysis;staring arrays;algorithms;computer hardware;infrared spectroscopy;cameras	We describe a new bad pixel correction algorithm designed originally to correct two-dimensional images containing high-fidelity spectroscopic data. Our method can be used to correct images with significant rates of adjacent bad pixels or bad pixel clusters such as taken by infrared focal plane arrays. It is applicable to any image data that can be locally approximated by a second-degree polynomial. A filter performing the correction can be easily imple- mented in programmable hardware utilizing very little resources. The accuracy of the method is analyzed and its performance tested on real spectroscopic data. © 2013 SPIE and IS&T (DOI: 10.1117/1 .JEI.22.4.043020)	defective pixel	Piotr Skibinski;Czeslaw Radzewicz	2013	J. Electronic Imaging	10.1117/1.JEI.22.4.043020	infrared spectroscopy;computer vision;numerical analysis;computer science;sensor;algorithm;computer graphics (images)	Vision	61.39958778709887	-57.330262077066884	41861
cfabcd94560198f68236f50588231c4ddae08bf6	the research of image collection method for sediment online-detection	sediment concentration;image segmentation;online detection;image denoising;feature analysis	The water level and flow of middle and small rivers has been achieved online-monitoring. However, the sediment detection is still in the manual observation. We propose the sediment online-detection system of in flow-water based on image analysis. We capture the underwater images by special camera device, and then transmit images to monitoring centers through channel. Furthermore, we implement special video capture card to preprocess, segment, identify the hydrology image and calculate the sediment of sample. The characteristic of system is image segmentation algorithm based on a wavelet level Markov model, the multi-direction one-dimensional wavelet transformation microscopic image denoising algorithm. We build the preliminary model based on the feature analysis of image. The experiment shows that sediment detection system could get the sediment hydrological of middle and small rivers online and provides a theoretical basis for the sediment detection.	algorithm;image analysis;image segmentation;markov chain;markov model;noise reduction;pixel;preprocessor;tv tuner card;two-phase commit protocol;wavelet transform	Ying Xiao;Xuange Peng;Ming Leng;Bing Zhu	2010	JCP	10.4304/jcp.5.6.893-900	pattern recognition;computer vision;feature detection;computer science;image segmentation	Vision	73.94282271567621	-59.68949506972826	41884
82e5fd224a8c0b04bd53c39c0c41b612398d7e2e	inverse source problem for a host medium having pointlike inhomogeneities		The reconstruction of a source embedded within a multipath environment, which is created by inserting a grid of point scatterers in the scene, is addressed. In particular, the source Fourier spectrum is assumed known so that the focus here is on the reconstruction of the spatial support. As well documented, multipath can allow for resolution improvement. However, it also gives rise to artifacts when a backpropagation-like imaging is adopted. In this paper, we study in detail how resolution improvement and artifacts depend on the grid layout by employing a weighted backpropagation algorithm. More in detail, stationary phase arguments are used to predict the reconstruction leading order terms to which resolution improvement is linked. Moreover, it is shown that artifacts are mainly due to high-order terms and are dependent on the point scatterers’ arrangement. The nature of such artifacts is studied, and a simple way to mitigate their role (without resolution loss) is introduced; it consists in a suitable nonuniform grid arrangement with a “hole in the center.” Backpropagation is then compared with an inverse filtering imaging based on the truncated singular value decomposition (TSVD) of the radiation operator. It is shown that the TSVD is less prone to artifacts and can, in principle, allow for a higher resolution improvement. However, when model error (due to multiple scattering between the elements of the grid) and/or noise corrupt data, backpropagation performs definitely better. The theoretical findings are supported by an extensive numerical analysis. In particular, to keep the figures simple, we consider only 2-D cases.	algorithm;approximation algorithm;backpropagation;elegant degradation;embedded system;fourier analysis;image resolution;inverse filter;multipath propagation;numerical analysis;resolution (logic);sampling (signal processing);singular value decomposition;stationary process;while	Antonio Cuccaro;Raffaele Solimene	2018	IEEE Transactions on Geoscience and Remote Sensing	10.1109/TGRS.2018.2809913	algorithm;grid;multipath propagation;iterative reconstruction;computer vision;operator (computer programming);artificial intelligence;filter (signal processing);backpropagation;mathematics;singular value decomposition;image resolution	Vision	74.07750740934061	-68.89916506397189	41974
58b6f01e612c53c39a5db7f1867100ebdbc7889a	no-reference quality measure in brain mri images using binary operations, texture and set analysis		The authors propose a new application-specific, post-acquisition quality evaluation method for brain magnetic resonance imaging (MRI) images. The domain of a MRI slice is regarded as universal set. Four feature images; greyscale, local entropy, local contrast and local standard deviation are extracted from the slice and transformed into the binary domain. Each feature image is regarded as a set enclosed by the universal set. Four qualities attribute; lightness, contrast, sharpness and texture details are described by four different combinations of feature sets. In an ideal MRI slice, the four feature sets are identically equal. Degree of distortion in real MRI slice is quantified by fidelity between the sets that describe a quality attribute. Noise is the fifth quality attribute and is described by the slice Euler number region property. Total quality score is the weighted sum of the five quality scores. The authorsu0027 proposed method addresses current challenges in image quality evaluation. It is simple, easy-to-use and easy-to-understand. Incorporation of binary transformation in the proposed method reduces computational and operational complexity of the algorithm. They provide experimental results that demonstrate efficacy of their proposed method on good quality images and on common distortions in MRI images of the brain.	texture mapping	Michael Osadebey;Marius Pedersen;Douglas Arnold;Katrina Wendel-Mitoraj	2017	IET Image Processing	10.1049/iet-ipr.2016.0560	computer vision;pattern recognition;data mining	Vision	61.318013112417574	-64.69622088592362	42002
973d5b810b3e6d5d26f47036cbdfc52f5238a7b4	video chroma keying via global sampling and trimap propagation		Chroma keying is a widely used video editing technique, which finely separates the foreground objects from the background. Two major concerns are involved in chroma keying problems: alpha estimation and foreground color restoration. The alpha values reveal the opacity property of the foreground objects. The foreground color restoration removes the background color influence to the foreground appearance especially at transparent regions and objects’ boundaries. In this paper, the color range of the solid background is well analyzed to automatically separate foreground from background. Global sampling is utilized to robustly and reliably estimate the foreground color at boundaries and transparent regions. Furthermore, we propose to propagate the geometric shape of foreground boundaries between adjacent frames by using optical flow and thin plate splines interpolation. The trimap, which is an initial foreground/background/unknown segmentation of each frame can be automatically updated for each video frame by using our proposed propagation method. Compared to previous methods, our proposed matting method estimates high-quality alpha matte and reliable foreground color with least user interference.	algorithm;alpha compositing;chroma subsampling;circuit restoration;color;interference (communication);interpolation;key (cryptography);map;matte display;optical flow;sampling (signal processing);software propagation;thin plate spline;web colors	Chengcheng Hao;Wenyi Wang;Jiying Zhao	2015	Multimedia Systems	10.1007/s00530-015-0493-2	background subtraction	Vision	56.482126308208414	-59.36546781819132	42025
0137d18d09ed96f549044e61fa62f31c2cc0612a	image salt-pepper noise elimination by detecting edges and isolated noise points	impulse noise;pepper	This paper introduces segmentation based environment modeling method for constructing the real-time image-based view-rendering. The image (or environment map) is segmented according to the objects that form the environment and the depth value is set by the characteristics of the classified objects for the segmentation based modeling. This method can easily be implemented on an environment map and makes the environment modeling easier through extracting the depth value by the image segmentation. It becomes possible to develop an environment modeling system with a full-view through this method.	glossary of computer graphics;image segmentation;real-time clock;reflection mapping	João Rogério Caldas Pinto;Pedro Pina;Lourenço P. C. Bandeira;Luís Pimentel;Mário Ramalho	2004		10.1007/978-3-540-30125-7_22	gaussian noise;median filter;image noise;computer vision;dark-frame subtraction;telecommunications;impulse noise;computer science;noise floor;salt-and-pepper noise	Robotics	56.429473755683134	-61.42347908096503	42058
b3f201a1b97cc6895aa28c7a9bffb79c28c21289	slope stability assessment of the sarcheshmeh landslide, northeast iran, investigated using insar and gps observations	landslide;slope stability;gps;insar;displacement	The detection and monitoring of mass movement of susceptible slopes plays a key role in mitigating hazards and potential damage associated with creeping slopes and landslides. In this paper, we use observations from both Interferometric Synthetic Aperture Radar (InSAR) and Global Positioning System (GPS) to assess the slope stability of the Sarcheshmeh ancient landslide in the North Khorasan province of northeast Iran. InSAR observations were obtained by the time-series analysis of Envisat SAR images covering 2004–2006, whereas repeated GPS observations were conducted by campaign measurements during 2010–2012. Surface displacement maps of the Sarcheshmeh landslide obtained from InSAR and GPS are both indicative of slope stability. Hydrogeological analysis suggests that the multi-year drought and lower than average precipitation levels over the last decade might have contributed to the current dormancy of the Sarcheshmeh landslide.	aperture (software);displacement mapping;global positioning system;map;time series	Mehrdad Akbarimehr;Mahdi Motagh;Mahmud Haghshenas-Haghighi	2013	Remote Sensing	10.3390/rs5083681	slope stability;seismology;geomorphology;global positioning system;displacement;geology;landslide;interferometric synthetic aperture radar;geotechnical engineering;remote sensing	Mobile	82.49193761978562	-57.60595355509298	42080
f48a4ca1eea1409f6f9c4f37c665f949b424ab52	examination of classical detection schemes for targets in pareto distributed clutter: do classical cfar detectors exist, as in the gaussian case?	clutter transitions;pareto clutter;cfar;multiple targets;radar detection	The Pareto distribution has been validated as a new clutter intensity model for X-band high resolution maritime surveillance radar returns. Consequently, corresponding detection schemes have become of much interest. This paper examines the development of constant false alarm rate radar (CFAR) detectors operating in Pareto distributed clutter. Recent developments in the literature have shown that it is possible to produce CFAR detectors for this clutter model by transforming the Gaussian intensity CFAR detectors. This results in the preservation of the Gaussian threshold multiplier/probability of false alarm relationship. The cost of doing this is that the new CFAR process depends on the Pareto clutter scale parameter. This paper examines an alternative approach to Pareto CFAR development.		Graham Victor Weinberg	2015	Multidim. Syst. Sign. Process.	10.1007/s11045-013-0275-y	speech recognition;constant false alarm rate	ML	73.25732830217015	-64.23518277177551	42301
cf681f1f91fc46667a56af2f237c4b905759c27b	a pixel- and object-based image analysis framework for automatic well site extraction at regional scales using landsat data	disturbance mapping;geophysical image processing;vegetation mapping;remote sensing satellites earth feature extraction image segmentation accuracy image resolution;landsat 8 image;well site extraction;image segmentation;image resolution;landsat 8 image pixel based image analysis object based image analysis automatic well site extraction landsat 5 tm imagery oil exploration gas exploration alberta northwest territories canada geometric enhancement image segmentation;earth;oil exploration;well site extraction landsat 5 object based disturbance mapping;canada;accuracy;image enhancement;gas exploration;landsat 5 tm imagery;feature extraction;remote sensing;satellites;northwest territories;object based image analysis;landsat 5;alberta;geometric enhancement;vegetation mapping feature extraction geophysical image processing geophysical prospecting image enhancement image segmentation;automatic well site extraction;pixel based image analysis;object based;geophysical prospecting	Development associated with oil and gas exploration has expanded rapidly in Alberta and Northwest Territories, Canada. Such explorations result in landscape disturbances including forest cuts, seismic lines, well and waste sites. This paper describes a novel methodology for automatic extraction of well sites from Landsat-5 TM imagery. The method combines pixel-based and object-based image analyses and contains three major steps: geometric enhancement, segmentation, and well site extraction. For accuracy assessment, a small part of the image was used and the results were compared against visual counting of well sites visible in the pan-sharpened image of Landsat-8 of the same area. Results show correctness, completeness and quality factors of 87.3%, 96.2%, and 83.7%, respectively.	correctness (computer science);image analysis;object-based language;pixel;random forest;xml:tm	Bahram Salehi;William Jefferies;Paul Adlakha;Zhaohua Chen;Pradeep Bobby	2014	2014 IEEE Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2014.6946788	computer vision;image resolution;feature extraction;computer science;accuracy and precision;earth;image segmentation;physics;satellite;remote sensing	Visualization	77.1704123967986	-58.113270861676696	42318
1506a368d794e7ac8bc223e3035cceb6ab404044	non-linear dark current fixed pattern noise compensation for variable frame rate moving picture cameras		CMOS image sensors are used in most of the camera systems today. For achieving a high image quality it is essential to compensate for fixed pattern noise. Compensation can be carried out by subtracting an estimated noise value per pixel, either directly on the sensor or in the digital processing. Unfortunately these values are different for each camera and will vary for different exposure times, camera mode settings and temperature. This poses additional challenges for high-end moving picture camera systems. We present a new algorithm for improved fixed pattern noise compensation that extends the currently available linear models. Measurements of a real world camera system and a simulation are used to show the improvements with our algorithm. Significant improvement of the compensated fixed pattern noise over a wide exposure range is shown. This allows the operation of the camera system at a much wider range of frame rates and especially long exposures are now possible. Our algorithm can be implemented without increasing the required memory bandwidth which saves power, size and cost.	algorithm;cmos;computation;dark current (physics);digital data;fixed point (mathematics);fixed-pattern noise;image quality;image sensor;linear model;memory bandwidth;nonlinear system;pixel;quadratic equation;real-time clock;real-time computing;requirement;rounding;segmented regression;simulation;variable frame rate	Michael Schöberl;Cihan Senel;Siegfried Fößel;Hans Bloß;André Kaup	2009	2009 17th European Signal Processing Conference		median filter;image noise;computer vision;electronic engineering;real-time computing;dark-frame subtraction;image processing;computer science;digital image processing;image sensor format;image sensor;cmos sensor;camera interface	EDA	60.66962762981433	-57.45777068372434	42387
4f9e590abf7a62a8e0c1edfd391e7dfe303157cd	global ecmwf analysis data for estimating the water vapor content between two leo satellites through ndsa measurements		"""The normalized differential spectral attenuation (NDSA) approach was proposed years ago as an effective way to estimate the integrated water vapor (IWV) along a tropospheric propagation path between two low Earth orbit satellites. Two applications are possible: the retrieval of vertical profiles of WV if the sense of rotation is opposite and the retrieval of 2-D fields of WV over vertical tropospheric sections if the sense is the same. The method relies on the measurement of the so-called spectral sensitivity <inline-formula> <tex-math notation=""""LaTeX"""">$S$ </tex-math></inline-formula> at given frequencies, and on IWV-S relationships that convert <inline-formula> <tex-math notation=""""LaTeX"""">$S$ </tex-math></inline-formula> into an estimate of IWV along the radio link where <inline-formula> <tex-math notation=""""LaTeX"""">$S$ </tex-math></inline-formula> is measured. In this paper, we recompute the IWV-S relationships using synthetic atmospheres generated by means of European Centre for Medium-Range Weather Forecasts (ECMWF) analysis data instead of radiosonde profiles as done by ourselves in the past. Thanks to the uniform spatial distribution of the ECMWF data on a global Earth scale, we were able to validate the IWV-S relationships in the Ku/K band previously found through synthetic atmospheres generated by means of the aforementioned irregularly spaced radiosonde data, and to define the IWV-S relationships at 179 and 181 GHz that are exploitable in the upper troposphere. Since the ECMWF data also include information about the liquid water (LW) content, we then show that an additional <inline-formula> <tex-math notation=""""LaTeX"""">$S$ </tex-math></inline-formula> channel at 32 GHz can be exploited to detect and correct the bias induced by LW on IWV estimates made by applying the NDSA in the Ku/K band."""	ku band;limewire;liquid image;national digital information infrastructure and preservation program;software propagation;synthetic intelligence	Luca Facheris;Fabrizio Cuccoli	2018	IEEE Transactions on Geoscience and Remote Sensing	10.1109/TGRS.2017.2765204	earth's orbit;remote sensing;attenuation;troposphere;water vapor;mathematics;k band;tropospheric propagation;radiosonde;atmospheric sciences;microwave	ML	82.43026096811188	-64.59580184699433	42403
55fa8125ffb6ce0a153838d6a17795b7c5944416	software tools using csrbfs for processing scattered data	software tool;software libraries;retouching;computer graphics;scattered data interpolation;large data sets;surface reconstruction;scattered data;computer graphic;radial basis function;surface reconstruction and modification	A set of software tools that use compactly supported radial basis functions (CSRBFs) to process scattered data is proposed in this paper. To solve problems concerning the processing of scattered data in such applications as reconstruction of functionaly defined geometric objects, surface retouching, and shape modifications, we employ a specially designed C++ software library. Thanks to the efficient octree algorithm used in this study, the resulting matrix is a band-diagonal matrix that permits handling of large data sets in a reasonable time. The method, classes of the software library, time performance of the algorithm, and various examples of the use of the software tools are discussed.	algorithm;binary file;c++;cg (programming language);computational complexity theory;download;formal specification;library (computing);linux;list of microsoft windows versions;list of algorithms;octal;octree;radial (radio);radial basis function;server (computing);solver;sparse matrix;vrml	Nikita Kojekine;Ichiro Hagiwara;Vladimir V. Savchenko	2003	Computers & Graphics	10.1016/S0097-8493(02)00287-X	radial basis function;surface reconstruction;computer science;theoretical computer science;machine learning;data mining;computer graphics;computer graphics (images)	Visualization	70.17202699795082	-53.14321983365273	42418
64b86fce2034330148c14bb96a771bb873300638	quality adaptive least squares trained filters for video compression artifacts removal using a no-reference block visibility metric	g400 computer science;quality metric;adaptive filtering;quality improvement;video compression;visual quality;image enhancement;picture quality improvement;noise reduction;least square;compression artifacts removal;blocking artifact reduction;no reference quality metric;adaptive filter;blocking artifact;least squares filter;no reference	1047-3203/$ see front matter 2010 Elsevier Inc. A doi:10.1016/j.jvcir.2010.09.007 ⇑ Corresponding author. E-mail address: ling.shao@sheffield.ac.uk (L. Shao) Compression artifacts removal is a challenging problem because videos can be compressed at different qualities. In this paper, a least squares approach that is self-adaptive to the visual quality of the input sequence is proposed. For compression artifacts, the visual quality of an image is measured by a noreference block visibility metric. According to the blockiness visibility of an input image, an appropriate set of filter coefficients that are trained beforehand is selected for optimally removing coding artifacts and reconstructing object details. The performance of the proposed algorithm is evaluated on a variety of sequences compressed at different qualities in comparison to several other de-blocking techniques. The proposed method outperforms the others significantly both objectively and subjectively. 2010 Elsevier Inc. All rights reserved.	algorithm;blocking (computing);coefficient;compression artifact;least squares	Ling Shao;Jingnan Wang;Ihor O. Kirenko;Gerard de Haan	2011	J. Visual Communication and Image Representation	10.1016/j.jvcir.2010.09.007	adaptive filter;computer vision;quality management;computer science;theoretical computer science;computer graphics (images)	AI	60.6074164868905	-64.20906338674402	42605
fdf1ddbf3c01c95cc3376599c1e7ccd01581570a	structured light field generated by two projectors for high-speed three dimensional measurement	structured light filed;high speed three dimensional measurement;depth map		light field;structured light;video projector	Akihiro Obara;Xu Yang;Hiromasa Oku	2016	JRM	10.20965/jrm.2016.p0523	computer vision;optoelectronics;optics	Visualization	62.640217475031626	-56.239228975957424	42610
789df5f919c9a7733f1c13eca463b162ec4bd8f8	a simulator for gnss-r polarimetric observations over the ocean	polarization;gnss r;remote sensing gnss r bistatic radar polarization facet approach;facet approach;sea surface global positioning system remote sensing scattering wind speed surface waves;remote sensing;conference report;gnss r polarimetric observations physical optics cross polar scattered signal sea surface conditions wind speed scattering mechanisms polarization ratio kirchhoff approximation time evolving random 3 d sea surface delay doppler map zavorotny voronovich approach gnss l band signals facet based simulator remote sensing global navigation satellite systems reflectometry;bistatic radar;wind doppler radar oceanographic techniques radar polarimetry remote sensing by radar	Global Navigation Satellite Systems - Reflectometry (GNSS-R) represents an innovative tool for remote sensing. In this paper a facet-based simulator is presented to investigate the polarimetric characteristics of GNSS L-band signals reflected off sea surface. The aim of the proposed technique is to improve the classical simulation technique based on the Zavorotny-Voronovich (Z-V) approach. Therefore, the scattered power and the Delay-Doppler Map are obtained using a time-evolving random 3D sea surface and the Kirchhoff Approximation (KA) of the Physical Optics (PO) to describe the scattering mechanisms. Finally the polarization ratio (PR) between co- and cross-polar scattered signal is fully investigated against different sea surface conditions, i.e. wind speed.	approximation;kirchhoff's theorem;l band;polarimetry;polarization (waves);radio occultation;reflectometry;satellite navigation;simulation	Domenico Schiavulli;Ali Ghavidel;Adriano Camps;Maurizio Migliaccio	2014	2014 IEEE Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2014.6947312	geodesy;polarization;bistatic radar;optics;wave radar;physics;remote sensing	Embedded	82.79254178706529	-66.61772528802905	42642
304e0ce5cd39285d5d6fcb2076f2b540da30ebcd	combining landsat and alos data for land cover mapping		In this study, L-band ALOS PALSAR radar satellite image and Landsat TM optical satellite image were used to investigate the contribution of radar satellite image to optical satellite image for land cover mapping. Dual-polarimetric data of ALOS satellite and also normalized difference vegetation index (NDVl) generated from Landsat image were used for the analysis. In addition, different classification techniques were taken into consideration and forest dominated land cover maps were produced and the results were compared. Random Forest (RF), k-Nearest Neighbors (k-NN) and Support Vector Machines (SVM) approaches were applied as image classification techniques. While the best result among the methods is DVM, the data set in which combined data are used gives the best general accuracy result.	computer vision;k-nearest neighbors algorithm;l band;map;polarimetry;radar;radio frequency;random forest;support vector machine	Saygin Abdikan;Mustafa Ustuner;Fusun Balik Sanli;Gokhan Bilgin	2017	2017 25th Signal Processing and Communications Applications Conference (SIU)	10.1109/SIU.2017.7960379	computer science;computer vision;artificial intelligence;interferometric synthetic aperture radar;normalized difference vegetation index;random forest;radar;synthetic aperture radar;land cover;contextual image classification;lidar	ML	79.28572697927592	-58.486950908443845	42680
fb7f0429a483ff1fefff3e4748b1066bc5afb81e	three-dimensional imaging by self-reference digital holograms	image resolution;jordi three dimensional imaging digital holograms effective tool imaging three dimensional scenes self reference single channel digital holography fresnel incoherent correlation holography finch fourier incoherent single channel holography fisch joined object reference digital interferometer;stereo image processing holography light interferometers;optical imaging;image reconstruction;lenses;lenses holography optical imaging image reconstruction optical diffraction image resolution;optical diffraction;spatial light modulators holography optical microscopy;holography	Digital holography can serve as an effective tool for imaging three-dimensional scenes or objects, quickly and reliably. In this paper, recently developed methods of self-reference single channel digital holography are reviewed: Fresnel incoherent correlation holography (FINCH), Fourier incoherent single channel holography (FISCH), and the joined object reference digital interferometer (JORDI).	digital holography;self-reference	Roy Kelner;Joseph Rosen	2015	2015 IEEE 13th International Conference on Industrial Informatics (INDIN)	10.1109/INDIN.2015.7281831	computer vision;digital holographic microscopy;analytical chemistry;optics;physics	Robotics	62.969671845133846	-56.44825553127966	42780
6467a452008a3e01572dc14505ce555c8299b0be	fast image dehazing method based on linear transformation	filtering;transmission map dehazing linear transformation image restoration;scattering;image restoration;computational modeling;image color analysis;atmospheric modeling scattering filtering computational modeling image restoration image color analysis meteorology;atmospheric modeling;dehazing image restoration linear transformation transmission map;meteorology	Images captured in hazy or foggy weather conditions are seriously degraded by the scattering of atmospheric particles, which directly influences the performance of outdoor computer vision systems. In this paper, a fast algorithm for single image dehazing is proposed based on linear transformation by assuming that a linear relationship exists in the minimum channel between the hazy image and the haze-free image. First, the principle of linear transformation is analyzed. Accordingly, the method of estimating a medium transmission map is detailed and the weakening strategies are introduced to solve the problem of the brightest areas of distortion. To accurately estimate the atmospheric light, an additional channel method is proposed based on quad-tree subdivision. In this method, average grays and gradients in the region are employed as assessment criteria. Finally, the haze-free image is obtained using the atmospheric scattering model. Numerous experimental results show that this algorithm can clearly and naturally recover the image, especially at the edges of sudden changes in the depth of field. It can, thus, achieve a good effect for single image dehazing. Furthermore, the algorithmic time complexity is a linear function of the image size. This has obvious advantages in running time by guaranteeing a balance between the running speed and the processing effect.	algorithm;autostereogram;circuit restoration;computational complexity theory;computer vision;distortion;feature (computer vision);gaussian blur;gradient;image processing;image resolution;linear function;linear model;mathematical optimization;operation time;quadtree;real-time clock;requirement;subdivision surface;time complexity	Wencheng Wang;Xiaohui Yuan;Xiaojin Wu;Yunlong Liu	2017	IEEE Transactions on Multimedia	10.1109/TMM.2017.2652069	filter;image restoration;computer vision;atmospheric model;feature detection;scattering;computational model;computer graphics (images)	Vision	57.952539821049776	-59.95752213656796	42823
f5e67c04b4ebb746d58e27610dc9207d9c325104	three-dimensional aircraft isar imaging based on shipborne radar	chirp;chirp radar imaging imaging marine vehicles signal processing algorithms signal resolution;transforms aircraft error analysis marine radar monte carlo methods radar imaging radar receivers ships synthetic aperture radar;image quality function three dimensional aircraft isar imaging method shipborne radar inverse synthetic aperture radar radar hardware complexity target maneuvering movement multiple radar receiver uncontrollable target movement react relax adaptive chirplet transform monte carlo simulation partial derivative deduction error analysis time selecting method;marine vehicles;radar imaging;imaging;signal resolution;signal processing algorithms	A three-dimensional inverse synthetic aperture radar (ISAR) image can provide the target’s information in range, cross-range, and height directions. Because the existing three-dimensional ISAR imaging methods require changing the observing angle, they are highly dependent on radar hardware complexity or target maneuvering movement. In this paper, a new three-dimensional ISAR imaging method based on shipborne radar is proposed. Instead of utilizing multiple radar receivers or uncontrollable target movement, we take advantage of the ship’s known yaw, pitch, and roll rotations, and obtain different observing angles using a single receiver fixed on the ship. To extract the scatterers, a new algorithm called REACT that combines RELAX and adaptive chirplet transform is presented. Subsequently, the errors of the three-dimensional imaging method are analyzed by partial derivative deduction and Monte Carlo simulation. On the basis of the error analysis, a novel best imaging time selecting method based on image quality function that considers both accuracy and resolution is also put forward. Simulation results validate our theoretical analysis and show the effectiveness of our method.	algorithm;aperture (software);chirplet transform;error analysis (mathematics);image quality;linear programming relaxation;monte carlo method;natural deduction;radar;react;simulation;synthetic data;yaws	Yicheng Jiang;Sibo Sun;Yeshu Yuan;Tat Soon Yeo	2016	IEEE Transactions on Aerospace and Electronic Systems	10.1109/TAES.2016.150393	medical imaging;man-portable radar;computer vision;continuous-wave radar;electronic engineering;radar tracker;radar engineering details;synthetic aperture radar;radar lock-on;radar configurations and types;fire-control radar;radar horizon;bistatic radar;low probability of intercept radar;pulse-doppler radar;3d radar;radar imaging;inverse synthetic aperture radar;chirp;side looking airborne radar;radar;remote sensing	EDA	75.26629015623861	-67.35371286350708	42842
cc9e067a4e377e57170e4197d6d5ffb7aedbb187	objective quality assessment of multiply distorted images	human rating image distortion human judgment visual quality objective image quality assessment algorithm objective iqa algorithm human response visual distortion quality determinant features;multiple distortions image quality assessment subjective study;image processing	Subjective studies have been conducted in the past to obtain human judgments of visual quality on distorted images in order, among other things, to benchmark objective image quality assessment (IQA) algorithms. Existing subjective studies primarily have records of human ratings on images that were corrupted by only one of many possible distortions. However, the majority of images that are available for consumption are corrupted by multiple distortions. Towards broadening the corpora of records of human responses to visual distortions, we recently conducted a study on two types of multiply distorted images to obtain human judgments of the visual quality of such images. Further, we compared the performance of several existing objective image quality measures on the new database and analyze the effects of multiple distortions on commonly used quality-determinant features and on human ratings.	algorithm;benchmark (computing);distortion;image quality;text corpus	Dinesh Jayaraman;Anish Mittal;Anush K. Moorthy;Alan C. Bovik	2012	2012 Conference Record of the Forty Sixth Asilomar Conference on Signals, Systems and Computers (ASILOMAR)	10.1109/ACSSC.2012.6489321	psychology;subjective video quality;computer vision;multimedia;social psychology	AI	62.46275034000469	-64.07532183795372	42917
19f818c10dd42879a8f66c5a633c300bcdb9dd28	spatio-temporal tone mapping operator based on a retina model	video sequence tone mapping;tone mapping;color constancy;digital camera;local adaptation;temporal filtering;retina model;dynamic range;low dynamic range;high dynamic range;visual system;high dynamic range compression	From moonlight to bright sun shine, real world visu al scenes contain a very wide range of luminance; they are said to be High Dynami c Range (HDR). Our visual system is well adapted to explore and analyze such a variable visual content. It is now possible to acquire such HDR contents with digital c meras; however it is not possible to render them all on standard displays, w hich have only Low Dynamic Range (LDR) capabilities. This rendering usually ge nerates bad exposure or loss of information. It is necessary to develop locally ada ptive Tone Mapping Operators (TMO) to compress a HDR content to a LDR one and ke ep as much information as possible. The human retina is known to perform such a task to overcome the limited range of values which can be coded by neurons. The purpose of this paper is to present a TMO inspired from the retina properties. The presented biological model allows reliable dynamic range compression with natu ral color constancy properties. Moreover, its non-separable spatio-temporal filter enhances HDR video content processing with an added temporal constancy. Key works: High Dynamic Range compression, tone mapping, reti na model, color constancy, video sequence tone mapping.	ada;algorithm;color management;digital video;high dynamic range;high-dynamic-range imaging;human factors and ergonomics;information processing;ldraw;numerical aperture;tone mapping	Alexandre Benoit;David Alleysson;Jeanny Hérault;Patrick Le Callet	2009		10.1007/978-3-642-03265-3_2	computer vision;dynamic range;tone mapping;visual system;computer science;optics;color constancy;computer graphics (images)	Graphics	61.755080413307105	-61.424315621142384	42981
5f260138a4029127af03ac26c4ec2204acec190c	level set estimation from projection measurements: performance guarantees and fast computation	15a29;94a08;performance guarantees;15a60;projection measurements;68q17;compressive sensing;97m50;level set estimation	Estimation of the level set of a function (i.e., regions where the function exceeds some value) is an important problem with applications in digital elevation mapping, medical imaging, astronomy, etc. In many applications, the function of interest is not observed directly. Rather, it is acquired through (linear) projection measurements, such as tomographic projections, interferometric measurements, coded-aperture measurements, and random projections associated with compressed sensing. This paper describes a new methodology for rapid and accurate estimation of the level set from such projection measurements. The key defining characteristic of the proposed method, called the projective level set estimator, is its ability to estimate the level set from projection measurements without an intermediate reconstruction step. This leads to significantly faster computation relative to heuristic “plug-in” methods that first estimate the function, typically with an iterative algorithm, and then threshold the result. The paper also includes a rigorous theoretical analysis of the proposed method, which utilizes results from the literature on concentration of measure and characterizes the estimator’s performance in terms of geometry of the measurement operator and 1-norm of the discretized function.	adaptive sampling;algorithm;algorithmic efficiency;coded aperture;compressed sensing;computation;computational resource;discretization;heuristic;iterative method;medical imaging;parallel computing;plug-in (computing);region of interest;sampling (signal processing);simulation;sparse matrix;thresholding (image processing);tomographic reconstruction;tree (data structure);wavelet	Kalyani Krishnamurthy;Waheed Uz Zaman Bajwa;Rebecca M Willett	2013	SIAM J. Imaging Sciences	10.1137/120891927	computer vision;mathematical optimization;computer science;mathematics;geometry;compressed sensing;statistics	Vision	57.29680018940328	-74.53201791194783	43093
406968cf2edc2129b821c562698fef3fa9188eef	parallel algorithm based on a frequential decomposition for dynamic 3d computed tomography	image sampling;medical image processing parallel algorithms computerised tomography data compression image reconstruction image coding image sampling workstation clusters;image coding;parallel algorithm;computed tomography;data compression;downsampling techniques;parallel algorithms computed tomography fourier transforms image reconstruction surgery reconstruction algorithms attenuation content addressable storage filters sampling methods;speed up;filters;reconstruction algorithms;attenuation;tomographic reconstruction;dynamic 3d computed tomography;frequential decomposition;image reconstruction;medical image processing;fourier transforms;computerised tomography;attenuation function;surgery;pc cluster;component identification;pc clusters;parallel implementation;compression techniques;workstation clusters;downsampling techniques parallel algorithm frequential decomposition dynamic 3d computed tomography null component identification compression techniques speed up pc clusters tomographic reconstruction algorithm attenuation function;sampling methods;content addressable storage;tomographic reconstruction algorithm;parallel algorithms	We present a tomographic reconstruction algorithm based on a frequential decomposition of the data. We show that the frequential components of the attenuation function to be identified can be reconstructed from the frequential decomposition of the data. Moreover, down sampling techniques added to the identification of null components and coupled to compression techniques, speed up the reconstruction time up to six compare to the classical FBP. We identify the optimal number of frequential components. We show reconstructions from real data. A parallel implementation of our new algorithm is then proposed and evaluated on two small PC clusters.	ct scan;central processing unit;computer cluster;flow-based programming;message passing interface;parallel algorithm;sampling (signal processing);sequential algorithm;speedup;tomographic reconstruction;tomography	Thomas Rodet;Laurent Desbat;Pierre Grangeat	2003		10.1109/IPDPS.2003.1213091	computer vision;parallel computing;computer science;theoretical computer science;parallel algorithm;computed tomography;computer graphics (images)	ML	53.850270732388346	-79.23445136077028	43105
626b1e9533fef343c5d7e442b992049875a5e6e1	contrast enhancement in liquid crystal displays by adaptive modification of analog gamma reference voltages	dynamic gamma control;contraste;contrast enhancement;contrast enhanced;image numerique;tecnologia electronica telecomunicaciones;architecture systeme;liquid crystal display;implementation;liquid crystal displays;lcd;affichage ecran plat;qualite image;contrast;flat panel displays;image quality;imagen numerica;arquitectura sistema;calidad imagen;digital image;tecnologias;implementacion;grupo a;system architecture;affichage cristaux liquides	In this paper, I propose dynamic gamma control (DGC) as a new contrast enhancement technology for liquid crystal displays. Unlike conventional technologies involving the manipulation of digital image data, DGC modifies analog gamma reference voltages in accordance with the image data distribution. A digital gamma buffer (DGB) and a new system architecture were developed for DGC implementation. Experimental results show that DGC can increase the contrast ratio of 5 images twofold on average.	liquid-crystal display	Seung-Woo Lee	2007	IEICE Transactions	10.1093/ietele/e90-c.11.2083	computer vision;computer science;operating system;liquid-crystal display;systems architecture;computer graphics (images)	Visualization	63.03840906776092	-59.8357722064078	43113
06015eb27857150f6c3b7bf15ef1b7ae8d5d80bf	saliency-based change detection for aerial and remote sensing imageries		Change detection for aerial and remote sensing imageries is an important research topic with a wide range of applications in urban and environmental studies, emergency management, etc. It is a challenging problem due to various types of acquisition or environmental noises in the captured images. In this paper, we propose a saliency-based change detection technique that makes use of two-dimensional within-images and between-images co-occurrence histogram saliency. Our experimental results show that the proposed method can effectively detect true changes of semantic interest while suppressing false changes due to acquisition or environmental noises.	aerial photography;algorithm	Hui Li Tan;Shijian Lu	2017	2017 IEEE International Conference on Image Processing (ICIP)	10.1109/ICIP.2017.8296979	computer vision;synthetic aperture radar;salience (neuroscience);remote sensing;visualization;artificial intelligence;computer science;environmental studies;change detection	Robotics	74.79233511350608	-59.7524264318038	43119
07d45b5574812488ecff3223ad8789493e395d83	study on dynamic change of wetland of fujian based on rs and gis	georeference;reservoirs;dynamic change;vegetation mapping;environmental factors;digital elevation model wetland dynamic change gis ecosystems environment stabilization species preservation coastal province china landscape ecology remote sensing geographical information system fujian province wetlands etm data image preprocessing geometric correction georeference digital map radiometric correction image statistics image histograms arc info reservoirs ad 1990 to 2002 wetland landscape spatial distribution fractal theory fractal dimensional values jiulong river delta quanzhou coast dem;coastal province;image preprocessing;geometric correction;geographic information system;rivers;vegetation mapping ecology geographic information systems geomorphology hydrological techniques rivers terrain mapping;fujian province wetlands;arc info;environment stabilization;fractal dimensional values;image statistics;species preservation;digital elevation model;ecology;hydrologic measurements;image histograms;landscape ecology;geographical information system;geomorphology;gis;spatial distribution;ecosystems;jiulong river delta;geographic information systems;remote sensing;quanzhou coast;wetland landscape;ad 1990 to 2002;fractal theory;terrain mapping;dem;etm data;digital map;china;wetland dynamic change;hydrological techniques;radiometric correction;geographic information systems fractals ecosystems sea measurements environmental factors remote sensing information systems information analysis clouds radiometry;digital mapping	Wetland is one of the most important ecosystems and plays an important role in environment stabilization and species preserving. Fujian province is a coastal province of China possessing a considerable portion of wetland. In this paper, based on landscape ecology, remote sensing and geographical information system technologies, the dynamic change of wetlands in Fujian province of China is analyzed. ETM+ data of 1996 and 2002 that cover the study area were acquired. A wetland map of study area published in 1990 was also used. The images were preprocessed by geometric correction and geo-reference using the digital map, and were free of clouds. Then radiometric correction was done to make the image statistics and histograms from different time periods similar and comparable for the study area. Thus the wetlands in different times were identified by the images. The resultants were further analyzed jointly using ARC/INFO. The analysis result indicated that the wetlands in Fujian province mainly distributes around the bays along coast. In backland there were few wetlands except for some regions around a few reservoirs. The area of wetlands decreased greatly from 1990 to 2002, especially from 1990 to 1996. Since 1996 the decrease speed of wetland area had become slow. The result also indicated that the fragmentation of wetland landscape was evident in these years. The number and density of patch of wetlands had increased largely. The spatial distribution feature of wetland was studied by fractal theory. The fractal dimensional values were calculated respectively and they changed a lot. This means that the shape of wetland landscape had transformed. The wetlands around Jiulong river delta and Quanzhou coast were the main area where the area of wetland decreased evidently. In these areas, economic activities are the main reason for the decrease of wetland area such as the expansion of buildings, roads, farmland and so on	arcinfo;data pre-processing;ecosystem;fork (software development);fractal;geographic information system;landscape ecology;resultant;scene statistics;spatial reference system	Huide Liu;Dabing Yang	2004	IGARSS 2004. 2004 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2004.1369906	digital elevation model;geology;hydrology;geographic information system;remote sensing	Visualization	82.79844987238738	-55.95286958465691	43191
e9c52aff914180c6102efda8944979f5d62e2035	historical document image enhancement using background light intensity normalization	background light intensity normalization;algorithm adaptively;light source;color image;historical document image enhancement;adaptive linear function;historical document image;normalization algorithm;document paper;uneven background;new background light intensity;aged color;handwriting recognition;function approximation	"""This work presents a background light intensity normalization algorithm suitable for historical document images. The algorithm uses an adaptive linear function to approximate the uneven background due to the uneven surface of the document paper, aged color and light source of the cameras for image lifting. Our algorithm adaptively captures the background with a """"best fit"""" linear function and normalized with respect to the approximation. The technique works for both gray scale and color images with significant improvement in readability."""	approximation algorithm;color;curve fitting;experiment;grayscale;historical document;image editing;lifting scheme;linear approximation;linear function;pixel	Zhixin Shi;Venu Govindaraju	2004	Proceedings of the 17th International Conference on Pattern Recognition, 2004. ICPR 2004.	10.1109/ICPR.2004.1334167	color histogram;image texture;image restoration;computer vision;feature detection;speech recognition;image resolution;color image;image gradient;binary image;image processing;function approximation;computer science;machine learning;digital image processing;mathematics;handwriting recognition;image formation;computer graphics (images)	Vision	58.98412065179907	-62.38707759580151	43214
cf4aa9242e46cdf6a25a6350f9bc0f589090b3d3	optimal parameter estimation in heterogeneous clutter for high resolution polarimetric sar data	clutter;speckle;high resolution;polarimetry;normalized texture optimal parameter estimation heterogeneous clutter polarimetric sar synthetic aperture radar invariant random vector model polsar data clutter speckle normalized covariance matrix span estimator asymptotic distribution airborne polsar images;random variables;clutter covariance matrix maximum likelihood estimation speckle random variables parameter estimation;detection;maximum likelihood estimation;image texture;maximum likelihood estimate;estimation;synthetic aperture radar sar;covariance matrices;radar polarimetry;radar imaging;random variable;synthetic aperture radar sar detection estimation polarimetry;asymptotic distribution;radar clutter;multi spectral;parameter estimation;synthetic aperture radar covariance matrices image texture parameter estimation radar clutter radar imaging radar polarimetry speckle;covariance matrix;synthetic aperture radar	This paper presents a new estimation scheme for optimally deriving clutter parameters with high resolution POLSAR data. The heterogeneous clutter in POLSAR data was described by the Spherically Invariant Random Vectors model. Three parameters were introduced for the high resolution POLSAR data clutter: the span, the normalized texture and the speckle normalized covariance matrix. The asymptotic distribution of the novel span estimator is also investigated. The proposed method is tested with airborne POLSAR images provided by the ONERA RAMSES system.	airborne ranger;clutter;estimation theory;image resolution;onera;polarimetry	Gabriel Vasile;Frédéric Pascal;Jean Philippe Ovarlez;Pierre Formont;Michel Gay	2010	2010 IEEE International Geoscience and Remote Sensing Symposium	10.1109/LGRS.2011.2152363	random variable;computer vision;mathematics;maximum likelihood;optics;statistics;remote sensing	Robotics	72.55894751990111	-63.91382826866974	43230
92a75ee927122739b2d209c826f81d3dff68b900	improved high dynamic range image reproduction method	hdr image creation;image segmentation;multiple exposures;gradient method;segmentation;blending;high dynamic range imaging;image segmentation gradient methods;image processing method;image processing methods;dynamic range lighting image processing digital images cameras layout image edge detection laplace equations automotive engineering vehicles;gradient methods;gradient method high dynamic range image reproduction method hdr image creation image processing method digital image image segmentation;high dynamic range image reproduction method;digital image;high dynamic range;blending high dynamic range multiple exposures segmentation	High dynamic range (HDR) of illumination may cause serious distortions and other problems in viewing and further processing of digital images. This paper describes a new algorithm for HDR image creation based on merging images taken with different exposure time. There are many fields, in which HDR images can be used advantageously, with the help of them the accuracy, reliability and many other features of the certain image processing methods can be improved.	algorithm;alpha compositing;color space;distortion;high dynamic range;image processing;pixel	András Rövid;Takeshi Hashimoto;Péter Várlaki	2007	2007 4th International Symposium on Applied Computational Intelligence and Informatics	10.1109/SACI.2007.375511	computer vision;electronic engineering;computer science;gradient method;digital image processing;image segmentation;segmentation;digital image;computer graphics (images)	Graphics	57.98409205237792	-61.53469224675763	43265
b0a74e85c6e5d442122980961dda2088a169acbf	multi-sensor image fusion based on fourth order partial differential equations		In this paper, a new image fusion algorithm based on fourth order partial differential equations and principal component analysis is introduced. This is for the first time fourth order partial differential equations brought into the context of image fusion. The proposed algorithm is as follows: First, fourth order partial differential equations are applied on each source image to obtain approximation and detail images. Second, principal component analysis is applied on detail images to obtain optimal weights. Third, final detail image is obtained by fusing these detail images with help of optimal weights. Fourth, final approximation image is obtained by employing an average operation on approximation images. Finally, resultant fused image is calculated by combining the final approximation and detail images. Experiments are conducted on standard fusion datasets. Results are analyzed with help of petrovic metrics and further compared with traditional and recent fusion methods. Results justify that performance of the proposed method is superior to state-of-the-art fusion methods. Moreover, reasonable computational time, easy and effective implementation of the proposed method makes it suitable for real time applications.	algorithm;approximation;computation;image fusion;principal component analysis;real-time computing;resultant;software metric;time complexity	Durga Prasad Bavirisetti;Gang Xiao;Gang Liu	2017	2017 20th International Conference on Information Fusion (Fusion)	10.23919/ICIF.2017.8009719	scale space;numerical partial differential equations;computer vision;artificial intelligence;principal component analysis;multigrid method;partial differential equation;mathematical optimization;mathematics;image fusion	Vision	60.55327596963052	-67.7847732600861	43390
88de8e30c5a77c5a160dc31458dde59a4bf615b1	a novel framework for nonlocal vectorial total variation based on ℓ p, q, r -norms			aharonov–bohm effect	Joan Duran;Michael Möller;Catalina Sbert;Daniel Cremers	2014		10.1007/978-3-319-14612-6_11		EDA	54.40359242173865	-70.57286253353661	43394
83d9a2dd3c28ac7081daf7af441d78fa90fb28e1	a regular k-shrinkage thresholding operator for the removal of mixed gaussian-impulse noise		The removal of mixed Gaussian-impulse noise plays an important role in many areas, such as remote sensing. However, traditional methods may be unaware of promoting the degree of the sparsity adaptively after decomposing into low rank component and sparse component. In this paper, a new problem formulation with regular spectral k-support norm and regular k-support l1 norm is proposed. A unified framework is developed to capture the intrinsic sparsity structure of all two components. To address the resulting problem, an efficient minimization scheme within the framework of accelerated proximal gradient is proposed. This scheme is achieved by alternating regular k-shrinkage thresholding operator. Experimental comparison with the other state-ofthe-art methods demonstrates the efficacy of the proposed method.	circuit restoration;gaussian blur;impulse noise (audio);numerical analysis;proximal gradient methods for learning;sparse matrix;taxicab geometry;thresholding (image processing);unified framework	Han Pan;Zhongliang Jing;Lingfeng Qiao;Minzhe Li	2017	Applied Comp. Int. Soft Computing	10.1155/2017/2520301	operator (computer programming);mathematical optimization;computer science;thresholding;gaussian;impulse noise;shrinkage	AI	56.91131152255103	-71.18220057520902	43493
cec8d90eadda50325c7b4509ab1db0c4b2282e06	a new image mixed noise removal algorithm based on measuring of medium truth scale	distance ratio function;image restoration;noise measurement;noise removal;measuring of medium truth scale;image mixed noise	The medium mathematics system is another mathematical tool which deals with fuzzy and uncertain problem. According to the analysis of the features of the image mixed noise, this paper introduces a new image mixed noise removal algorithm based on measuring of medium truth scale. It uses the distance ratio function to detect the noise pixel and to restore the image. The experimental results demonstrate that the new image mixed noise removal algorithm can do better in smoothing mixed noise and preserving details than the classical ones do in subjective aspect and objective aspect, which will lead to its practicable and effective applications in mixed noise removal and image restoration.	algorithm	Ningning Zhou;Long Hong	2010		10.1007/978-3-642-13208-7_71	gradient noise;gaussian noise;median filter;image restoration;image noise;computer vision;dark-frame subtraction;value noise;computer science;noise measurement;machine learning;noise;mathematics;statistics;salt-and-pepper noise	Robotics	56.706373406782284	-65.80390004008352	43520
e7223a33926bf1a99b474f0e12e301ffcf4db5de	accurate multi-target surveillance system over wide areas		The article presents an accurate system for surveillance purposes of multiple targets in wide areas. The surveillance system is based on a GB-ROSAR (Ground-Based-Rotating Synthetic Aperture Radar). It is a fixed radar with the ability of obtaining images by synthesizing the radiating aperture by a circular movement of the antenna. The prototype makes use of FM-CW (Frequency-Modulated Continuous-Wave) signals, operating in millimeter wave bands. The system has been developed with low cost devices. The objective of this work is to show, through simulations and experimental results, the real possibilities of this type of systems in the setting of precise surveillance of several targets simultaneously over wide areas. This study contains the design and construction of the proposed surveillance system, the implemented signal processing, the obtained results and its interpretation, and the conclusions about this work.	fm broadcasting;gigabyte;modulation;performance;prototype;radar;signal processing;simulation;terrestrial television	Francisco-Javier Romero-Paisano;Félix Pérez-Martínez;Susan Martínez-Cordero;Jaime Calvo-Gallego	2017	2017 International Carnahan Conference on Security Technology (ICCST)	10.1109/CCST.2017.8167853	computer vision;real-time computing;radar imaging;artificial intelligence;radar;azimuth;aperture;extremely high frequency;synthetic aperture radar;computer science;signal processing;data acquisition	EDA	76.96953909993906	-65.58380861546313	43599
01e2bb7e563b5a5a276df4880241fd4d1467ef4f	multisensor super resolution using directionally-adaptive regularization for uav images	multisensor super resolution sr;biological patents;biomedical journals;text mining;europe pubmed central;image fusion;citation search;uav image enhancement;regularized image restoration;citation networks;research articles;abstracts;open access;life sciences;clinical guidelines;full text;rest apis;orcids;europe pmc;biomedical research;bioinformatics;literature search	In various unmanned aerial vehicle (UAV) imaging applications, the multisensor super-resolution (SR) technique has become a chronic problem and attracted increasing attention. Multisensor SR algorithms utilize multispectral low-resolution (LR) images to make a higher resolution (HR) image to improve the performance of the UAV imaging system. The primary objective of the paper is to develop a multisensor SR method based on the existing multispectral imaging framework instead of using additional sensors. In order to restore image details without noise amplification or unnatural post-processing artifacts, this paper presents an improved regularized SR algorithm by combining the directionally-adaptive constraints and multiscale non-local means (NLM) filter. As a result, the proposed method can overcome the physical limitation of multispectral sensors by estimating the color HR image from a set of multispectral LR images using intensity-hue-saturation (IHS) image fusion. Experimental results show that the proposed method provides better SR results than existing state-of-the-art SR methods in the sense of objective measures.	adaptive histogram equalization;aerial photography;algorithm;artifact (error);autostereogram;estimated;grayscale;image fusion;image sensor;iterative reconstruction;lr parser;magnetic resonance imaging;morphologic artifacts;multispectral image;national library of medicine (u.s.);netware loadable module;non-local means;oxygen saturation:mfr:pt:bld:qn:calculated from oxygen partial pressure;super-resolution imaging;unmanned aerial vehicle;video post-processing;sensor (device)	Wonseok Kang;Soohwan Yu;Seungyong Ko;Joonki Paik	2015		10.3390/s150512053	computer vision;text mining;computer science;bioinformatics;data mining;image fusion	Robotics	54.970000243538784	-76.01919606071672	43626
c1ad070107f05f4161976742388c4d7548e14d4b	sparse natural image statistics and their applications to colorization and compression	non linear sparse filter response distribution;natural image statistics;minimization;colour images;compressed sensing;image coding;data compression;qa mathematics;natural images;image statistics;sparse distributions;natural luminance;natural gray images;display non gaussian distributions;image data;l 1 optimisation;qa75 electronic computers computer science;image colorization;statistical analysis data compression image coding image colour analysis;statistical analysis;colorization;image color analysis image coding pixel optimization image reconstruction compressed sensing minimization;image color analysis;image colour analysis;compressive sensing;image reconstruction;pixel;l 1 optimisation natural images filter response sparse distributions colorization compressive sensing compression;optimization;compression;filter response;gaussian distribution;chromacity channels;image data image statistics statistical analysis natural luminance colour images display non gaussian distributions non linear sparse filter response distribution natural gray images image colorization chromacity channels	Statistical analysis of natural luminance and colour images have shown to display non-Gaussian distributions. We review a recent result on the non-linear sparse filter response distribution observed in [1], and illustrate its application to the problem of colorizing natural gray images. We further utilise elements of both image statistics and colorization for compression of the chromacity channels of image data.	data compression;nonlinear system;scene statistics;sparse matrix	Alexander Balinsky;Nassir Mohammad	2010	2010 IEEE International Conference on Image Processing	10.1109/ICIP.2010.5652168	computer vision;computer science;pattern recognition;mathematics;compressed sensing;statistics;computer graphics (images)	Robotics	60.048950762075144	-63.785401538710744	43666
c9901889da417cf5067f4c2ec69bd2379d444b23	a new shape-based method for object localization and characterization from scattered field data	inhomogeneous halfspace;background complex permittivities;regularized least squares;spline;demi espace;radar remote sensing;low order polynomial expansion;nonlinear inverse scattering algorithm;geologie militaire;image processing;cost function;half space;prospecting;methode electromagnetique;inverse scattering;localization;point location;geoelectric method;geometry;backscatter;spatial variation;scattering;localizacion;greedy type approach;analyse moindres carres;detection;buried object detection;difusion;indexing terms;b spline curve;polynomials;geophysical measurement technique;electromagnetic methods;spatial variations;algorithme;buried object detection geophysical techniques geophysical prospecting terrestrial electricity remote sensing by radar terrain mapping radar theory radar cross sections backscatter;mine detection;remote sensing by radar;radar scattering;least squares;object localization;military geology;ground penetrating radar;localisation;shape;greedy type approach geophysical measurement technique land surface terrain mapping prospecting exploration terrestrial electricity geoelectric method radar remote sensing buried object detection ground penetrating radar shape based method object localization characterization radar scattering backscatter geometric structure inhomogeneous halfspace nonlinear inverse scattering algorithm low dimensional parameterization low order polynomial expansion spatial variations background complex permittivities quadratic b spline curve;mines;variacion espacial;complex permittivity;characterization;exploration;quadratic b spline curve;variation spatiale;inverse problems polynomials permittivity spline cost function image processing numerical simulation scattering geometry shape;algorithms;field data;radar cross sections;land surface;terrain mapping;metodo electromagnetico;mine;radar theory;mina;terrestrial electricity;semiespacio;diffusion;geometric structure;low dimensional parameterization;geophysical techniques	The problem of characterizing the structure of an object buried in an inhomogeneous halfspace of unknown composition is considered. We develop a non-linear inverse scattering algorithm based on a low dimensional parameterization of the unknown object and the background. In particular, we use low order polynomials to represent the contrast in the real and imaginary parts of the object and background complex permittivities. The boundary separating the target from the unknown background is described using a periodic, quadratic B-spline curve whose control points can be individually manipulated. We determine the unknown control point locations and contrast expansion coe cients using a greedy-type approach to minimize a regularized least-squares cost function. The regularizer used here is designed to constrain the geometric structure of the boundary of the object and is closely related to snake methods employed in the image processing community. We demonstrate the performance of our approach via extensive numerical simulation involving 2D, TMz scattering geometries. This work was supported by an OSD MURI on Demining under Grant DAAG55-97-1-0013 and a CAREER Award from the National Science Foundation, MIP-9623721 1	b-spline;boundary representation;computer simulation;control point (mathematics);experiment;greedy algorithm;image formation;image processing;imaginary time;least squares;loss function;naruto shippuden: clash of ninja revolution 3;nonlinear system;object storage;open road tolling;parallel computing;polynomial;self-information;spline (mathematics)	Eric L. Miller;Misha Elena Kilmer;Carey M. Rappaport	2000	IEEE Trans. Geoscience and Remote Sensing	10.1109/36.851967	image processing;mathematics;geometry;diffusion;optics;physics;remote sensing	Robotics	71.12483854620027	-57.719622875739496	43685
084a6e8dfcbcf2c7a9b3969cdcd808a5a6f0ed82	image forgery localization via fine-grained analysis of cfa artifacts	tampering probability map cfa artifacts digital camera demosaicking forgery localization image forensics;image segmentation;computer forensics;interpolation forgery image color analysis forensics kernel classification algorithms digital cameras;2 2 image block image forgery localization fine grained analysis cfa artifacts forensic tool digital camera color filter array demosaicking algorithm new statistical model tampering probability;statistical analysis computer forensics filtering theory image colour analysis image segmentation;statistical analysis;image colour analysis;filtering theory	In this paper, a forensic tool able to discriminate between original and forged regions in an image captured by a digital camera is presented. We make the assumption that the image is acquired using a Color Filter Array, and that tampering removes the artifacts due to the demosaicking algorithm. The proposed method is based on a new feature measuring the presence of demosaicking artifacts at a local level, and on a new statistical model allowing to derive the tampering probability of each 2 × 2 image block without requiring to know a priori the position of the forged region. Experimental results on different cameras equipped with different demosaicking algorithms demonstrate both the validity of the theoretical model and the effectiveness of our scheme.	algorithm;charge-coupled device;color filter array;demosaicing;digital camera;digital image;display resolution;fingerprint;incidence matrix;jpeg;map;receiver operating characteristic;ringing artifacts;sensor;statistical model;super ccd;theory;thresholding (image processing)	Pasquale Ferrara;Tiziano Bianchi;Alessia De Rosa;Alessandro Piva	2012	IEEE Transactions on Information Forensics and Security	10.1109/TIFS.2012.2202227	computer vision;color image;computer science;mathematics;image segmentation;internet privacy;computer security;computer forensics;statistics;computer graphics (images)	Vision	54.73636889611676	-61.47028454199299	43750
fbcc662d62e2a9fe87418f8b4f0a25759108c02a	on designing efficient superresolution algorithms by regression models	super resolution;algorithms	A good superresolution (SR) algorithm obtains high-resolution (HR) images from the corresponding low-resolution (LR) ones and, moreover, makes the former look like they had been acquired with a sensor having the expected resolution or at least as “natural” as possible. In general, fast SR algorithms usually result in more ill artifacts in the enlarged image, while the well-performed ones usually have great complexity and take much more computing time. For this purpose, four efficient SR algorithms based on regression models are proposed. In the proposed SR algorithms, the difference of a natural HR image and an HR image obtained by fast interpolation is taken as the lost detail and is supposed to be composed of several different oriented details. By the self-similarity of the input LR image and its corresponding HR image, a regression model is established by the input LR image to decide the proper respective weights of these oriented details which is then used to reconstruct the lost detail of the natural HR image. As shown in the experimental results, the proposed SR algorithms not only perform well in both objective criteria and visual quality but also take less computing time than some well-performing algorithms. © 2013 SPIE and IS&T [DOI: 10.1117/1.JEI.22.3 .033002]	algorithm;fast fourier transform;high-resolution scheme;image resolution;interpolation;lr parser;peak signal-to-noise ratio;self-similarity;simulation;structural similarity;super-resolution imaging;whole earth 'lectronic link	Tse-Ming Kuo;Shen-Chuan Tai	2013	J. Electronic Imaging	10.1117/1.JEI.22.3.033002	computer vision;computer science;algorithm;superresolution	Vision	59.09719155422991	-65.52643524167621	43759
e5238abb6b17d13493e6d2c91e42f0ce8347a990	sparse recovery of hyperspectral signal from natural rgb images		Hyperspectral imaging is an important visual modality with growing interest and range of applications. The latter, however, is hindered by the fact that existing devices are limited in either spatial, spectral, and/or temporal resolution, while yet being both complicated and expensive. We present a low cost and fast method to recover high quality hyperspectral images directly from RGB. Our approach first leverages hyperspectral prior in order to create a sparse dictionary of hyperspectral signatures and their corresponding RGB projections. Describing novel RGB images via the latter then facilitates reconstruction of the hyperspectral image via the former. A novel, larger-than-ever database of hyperspectral images serves as a hyperspectral prior. This database further allows for evaluation of our methodology at an unprecedented scale, and is provided for the benefit of the research community. Our approach is fast, accurate, and provides high resolution hyperspectral cubes despite using RGB-only input.	compressed sensing;dictionary;display resolution;image resolution;modality (human–computer interaction);olap cube;sparse matrix;type signature	Boaz Arad;Ohad Ben-Shahar	2016		10.1007/978-3-319-46478-7_2	computer vision	Vision	60.45223292581501	-55.75169227661405	43822
c9f20c1d23cb0f2918d08dc7b4bf0f0a0320ad36	comments on picture thresholding using an iterative selection method	optimisation;image processing;optimizacion;iterative methods control systems signal design production facilities working environment noise cost function entropy automatic control manufacturing systems uncertainty;procesamiento imagen;picture processing;imagen nivel gris;traitement image;iterative methods;luminance picture processing iterative selection method picture thresholding bimodal histogram multiple gray level picture;image niveau gris;optimization;grey level image;algorithm design;conversion;picture processing iterative methods	T.W. Ridler and E.S. Calvard (ibid., vol.SMC-8, p.630-2, Aug. 1978) presented a method of picture thresholding that was further mathematically developed by H.J. Trussel (ibid., vol.SMC-9, p.311, 1979). The principle of this method is to evaluate the unique threshold T for any image with a bimodal histogram. The present paper reinterprets the procedure as an algorithm designed to optimize the conversion of a multiple gray-level picture to a bimodel picture while maintaining as closely as possible the average luminance of the picture. >	iterative method;selection (genetic algorithm);thresholding (image processing)	A. Magid;Stanley R. Rotman;Aryeh M. Weiss	1990	IEEE Trans. Systems, Man, and Cybernetics	10.1109/21.59988	algorithm design;computer vision;mathematical optimization;image processing;computer science;artificial intelligence;balanced histogram thresholding;mathematics;iterative method	EDA	55.3324717821984	-63.96803788273034	43845
1997f8d4c71b1355b7bb5868d4456563fda3665d	a comprehensive review of image enhancement techniques	point process;visual quality;image enhancement;pattern recognition;digital image	Principle objective of Image enhancement is to process an image so that result is more suitable than original image for specific application. Digital image enhancement techniques provide a multitude of choices for improving the visual quality of images. Appropriate choice of such techniques is greatly influenced by the imaging modality, task at hand and viewing conditions. This paper will provide an overview of underlying concepts, along with algorithms commonly used for image enhancement. The paper focuses on spatial domain techniques for image enhancement, with particular reference to point processing methods and histogram processing.	algorithm;digital image;image editing;modality (human–computer interaction)	Raman Maini;Himanshu Aggarwal	2010	CoRR		image quality;image warping;image restoration;computer vision;feature detection;image analysis;image processing;shadow and highlight enhancement;computer science;digital image processing;pattern recognition;point process;multimedia;automatic image annotation;top-hat transform;information retrieval;digital image;statistics	Vision	60.428855574269654	-63.174276770044465	43847
597afd0fb2e4e84dc27f50796c49b00e47a37134	dense disparity estimation from linear measurements	regularized energy minimization problem;image reconstruction correlation pixel image coding sensors optimization estimation;image sensors image coding image reconstruction image representation;image coding;random projections;sensors;disparity image representation;dense disparity estimation;disparity estimation;optimal estimation;image sensors;lts4;disparity image;correlation model estimation;linear operator;estimation;image compression;image acquisition;image representation;image reconstruction;pixel;optimization;energy minimization;vision sensor positioning;correlation;regularized energy minimization problem dense disparity estimation linear measurement correlation model estimation image pair vision sensor positioning disparity image representation image compression image acquisition image reconstruction linear operator;image pair;graph cuts;linear measurement	This paper proposes a methodology to estimate the correlation model between a pair of images that are given under the form of linear measurements. We consider an image pair whose common objects are relatively displaced due to the positioning of vision sensors. In such scenarios the correlation model that relates the displacement between the objects is effectively represented by a disparity image. We consider a framework where each image is directly acquired and compressed by projecting onto a random basis of lower dimension. Given the linear measurements computed from the images we propose to estimate the underlying correlation model directly in the compressed domain without reconstructing the images that is usually a costly solution. We first show that the correlated images can be efficiently related using a linear operator. Using this linear relationship between the images we derive the relationship between the corresponding measurements in the compressed domain. The underlying correlation model is then built by solving a regularized energy minimization problem. Experimental results show that the proposed scheme estimates an accurate correlation model between the images. Also we show by experiments that the proposed scheme performs competitively with the scheme that estimates the correlation model from the reconstructed images.	binocular disparity;displacement mapping;energy minimization;experiment;image sensor	Vijayaraghavan Thirumalai;Pascal Frossard	2011	2011 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	10.1109/ICASSP.2011.5946534	iterative reconstruction;optimal estimation;computer vision;mathematical optimization;estimation;cut;image compression;sensor;pattern recognition;image sensor;mathematics;linear map;energy minimization;correlation;pixel;statistics	Vision	55.489688121872476	-56.4089168625619	43884
8d8041e6cacf471a9e2fa45948deb5b3c46134ea	illumination effects on the differenced normalized burn ratio's optimality for assessing fire severity	landsat;terrains;europa;europa sur;c correction;change detection;landsat tm data;correccion topografica;grece;illumination;slopes;exposition;incendie;pouvoir reflecteur;europe sud;illumination effect;deplacement;correction topographique;thematic mapper;poder reflector;topographic correction;terrain;grecia;wildfires;time series;detection;feature space;forest;interior alaska;vegetation;forest fires;declive;landsat tm;topographic normalization;greece;reflectance;image acquisition;earth and environmental sciences;remote sensing;pixel;indexation;versant;normalized burn ratio;fire severity;optimization;satellite imagery;europe;southern europe;landsat thematic mapper;anisotropic reflectance;cloud cover;fires;wildfire;differenced normalized burn ratio;exhibits;index optimality;displacements;peloponnese;radiometric correction;fire behaviour	The influence of illumination effects on the optimality of the dNBR (differenced Normalized Burn Ratio) was evaluated for the case of the 2007 Peloponnese (Greece) wildfires using a pre/post-fire Landsat TM (Thematic Mapper) image couple. Well illuminated pixels (south and south-east facing slopes) exhibited more optimal displacements in the bi-spectral feature space than more shaded pixels (north and north-west exposed slopes). Moreover, pixels experiencing small image-to-image differences in illumination obtained a higher optimality than pixels with a relatively large difference in illumination. To correct for illumination effects, the c-correction method and a modified c-correction technique were applied. The resulting median dNBR optimality of uncorrected, c-corrected and modified c-correction data was respectively 0.58, 0.60 and 0.71 (differences significant for p<0.001). The original ccorrection method improved the optimality of badly illuminated pixels while deteriorating the optimality of well illuminated pixels. In contrast, the modified c-correction technique improved the optimality of all the pixels while retaining the prime characteristic of topographic correction techniques, i.e. detrending the illumination-reflectance relationship. For a minority of the data, for shaded pixels and/or pixels with a high image-to-image difference in illumination, the original c-correction outperformed the modified c-correction technique. In this study conducted in rugged terrain and with a bi-temporal image acquisition scheme that substantially deviated from the ideal anniversary date scheme the modified ccorrection technique resulted in a more reliable change detection.	feature vector;illumination (image);normalization (image processing);pixel;rugged computer;shading;topography	Sander Veraverbeke;Willem W. Verstraeten;Stefaan Lhermitte;Rudi Goossens	2010	Int. J. Applied Earth Observation and Geoinformation	10.1016/j.jag.2009.10.004	terrain;geography;geology;hydrology;mathematics;cartography;statistics;remote sensing	HCI	80.1399990222413	-57.776827725944784	43893
c1ae5bd27cea8bf4a48717b55e31ebed6c4532bf	frequency analysis and sheared reconstruction for rendering motion blur	moving object;light transport;anti aliasing;frequency analysis;reconstruction;spectrum;space time;sampling;specular reflection;first order;motion blur;filter;frequency domain	Motion blur is crucial for high-quality rendering, but is also very expensive. Our first contribution is a frequency analysis of motion-blurred scenes, including moving objects, specular reflections, and shadows. We show that motion induces a shear in the frequency domain, and that the spectrum of moving scenes can be approximated by a wedge. This allows us to compute adaptive space-time sampling rates, to accelerate rendering. For uniform velocities and standard axis-aligned reconstruction, we show that the product of spatial and temporal bandlimits or sampling rates is constant, independent of velocity. Our second contribution is a novel sheared reconstruction filter that is aligned to the first-order direction of motion and enables even lower sampling rates. We present a rendering algorithm that computes a sheared reconstruction filter per pixel, without any intermediate Fourier representation. This often permits synthesis of motion-blurred images with far fewer rendering samples than standard techniques require.	frequency analysis;gaussian blur	Kevin Egan;Yu-Ting Tseng;Nicolas Holzschuch;Frédo Durand;Ravi Ramamoorthi	2009	ACM Trans. Graph.	10.1145/1531326.1531399	spectrum;sampling;computer vision;specular reflection;filter;computer science;space time;first-order logic;mathematics;optics;frequency analysis;frequency domain;statistics;computer graphics (images)	Graphics	64.22760409998247	-53.653130412233374	43919
19892cf58d2462803a40aa59d9f1a0d95bc8c9fb	fuzzy weighted average filtering for mixture noises	gaussian noise;nonlinear filters;optimisation;fuzzy theory;fuzzy membership function;weighted averaging;impulse noise;nonlinear filter;signal denoising fuzzy set theory filtering theory nonlinear filters impulse noise gaussian noise optimisation;null;fuzzy set theory;gaussian noise acoustic noise fuzzy sets nonlinear filters filtering theory iterative algorithms pixel noise reduction attenuation morphology;mixture of gaussians;filtering theory;optimization fuzzy weighted average filtering mixture noise iteration method impulse noise suppression classic nonlinear filtering gaussian noise fuzzy theory weighted average filter;signal denoising	The classic nonlinear filter performs well in impulse noise suppression and edge preserving. However, the classic nonlinear filtering is not good at reducing the mixture of Gaussian noise and impulse noise. In this paper, we investigate the nonlinear filtering techniques to eliminate the mixture of impulse noise and Gaussian noise. Based on fuzzy theory, we present a weighted average filter by making use of the fuzzy membership functions to optimize the weights of the filter. Computational results, which have been obtained from experiments for noise attenuation, indicate that the new algorithm is promising.	algorithm;computation;experiment;fuzzy logic;impulse noise (audio);nonlinear system;zero suppression	Qing Xu;Liang Ma;Mingchu Li;Wei Wang;Jing Cai;Roberto Brunelli;Stefano Messelodi	2004	Third International Conference on Image and Graphics (ICIG'04)	10.1109/ICIG.2004.70	gradient noise;nonlinear filter;gaussian noise;median filter;computer vision;mathematical optimization;value noise;impulse noise;computer science;noise measurement;machine learning;mixture model;mathematics;fuzzy set;statistics;salt-and-pepper noise	Robotics	56.34303369738743	-65.98237289322813	44021
d5ec64aa56ff94d795961a504ea2128de4fd9b3b	image mosaic with relaxed motion	journal	We propose a novel method to stitch images with relatively large roll or pitch called relaxed motion, which defies most existing mosaic algorithms. Our approach adopts a multi-resolution strategy, which combines the merits of both feature-based and intensity-based methods. The main contribution is a robust motion estimation procedure which integrates an adaptive multi-scale block matching algorithm called TV-BMA, a low contrast filter and a RANSAC motion rectification to jointly refine motion and feature matches. Based on TV − L1 model, the proposed TV-BMA works on the coarsest layer to find a robust initial displacement field as the initial motion for source images. This motion estimation method can generate robust correspondences for further processing. In the subsequent camera calibration step, we also present two stable methods to estimate the camera matrix. To estimate the focal length, we combine the golden section search and the simplex method based on the angle invariance of feature vectors; to estimate the rotation matrix, we introduce a subspace trust region method, which matches features based on the rotation invariance. Extensive experiments show that our approach leads to improved accuracy and robustness for stitching images with relaxed motion.	ncsa mosaic	Xianyong Fang;Jiejie Zhu;Bin Luo	2012	Signal, Image and Video Processing	10.1007/s11760-010-0194-4	computer vision;mathematical optimization;simulation;quarter-pixel motion;computer science;motion estimation;mathematics;motion field	Vision	54.62901695179684	-57.473964575455085	44056
fe74cb1b9f4f53828a3de9931911462f66aec08a	array configuration optimization for rotating mirrored aperture synthesis (rmas)	brightness temperature;antenna arrays;sieving method array configuration optimization rotating mirrored aperture synthesis rmas high spatial resolution antenna array rotation;microwave radiometry;array configuration optimization rotating mirrored aperture synthesis rmas uniform spatial frequency sampling sieving method;image reconstruction;remote sensing;antenna arrays apertures image reconstruction brightness temperature remote sensing microwave radiometry;radiometry antenna arrays;apertures	Aperture synthesis with high spatial resolution would seriously increase the hardware requirements and system complexity. To reduce the system complexity, Rotating mirrored aperture synthesis (RMAS) that combines the antenna array rotation with mirrored aperture synthesis was proposed to reduce the number of antennas. In this paper, the sieving method is presented to optimize the array configuration for RMAS. The initial simulation results demonstrate the validity of the proposed method and the optimized array of RMAS can reconstruct the brightness temperature of the observed scene with fewer antennas.	mathematical optimization;requirement;simulation	Yufang Li;Qingxia Li;Rong Jin;Feng Li;Haofeng Dou;Hang Liu	2016	2016 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)	10.1109/IGARSS.2016.7729216	iterative reconstruction;aperture;brightness temperature;optics;physics;remote sensing	EDA	76.42898870629953	-66.88702432520282	44089
23f13954b76e1801911c37744a70a16d184d82f9	underwater image restoration using fusion and wavelet transform strategy		This paper describes a novel strategy to restore underwater images using fusion and wavelet Transform. Built on the fusion principles, our strategy derives the inputs and the weight measures only from the degraded version of the image. In order to overcome the limitations of the underwater medium we define two inputs that represent color corrected and contrast enhanced versions of the original underwater image/frame, but also four weight maps that aim to increase the visibility of the distant objects degraded due to the medium scattering and absorption. Our strategy is a single image approach that does not require specialized hardware or knowledge about the underwater conditions or scene structure. Our fusion framework with wavelet transform also supports temporal coherence between adjacent frames by performing an effective edge preserving noise reduction strategy. The enhanced images are characterized by reduced noise level, better exposedness of the dark regions, improved global contrast while the finest details and edges are enhanced significantly. In addition, the utility of our enhancing technique is proved for several challenging applications.	autostereogram;circuit restoration;coherence (physics);color;glossary of computer graphics;image restoration;map;noise (electronics);noise reduction;reduction strategy (lambda calculus);wavelet transform	Rashid Khan	2015	JCP		computer vision	Vision	57.99392101942801	-60.937067445725305	44108
97da640b511af9aa568fda5d3293e6ae1793e993	3d gravity interface inversion constrained by a few points and its gpu acceleration	parallel computing;interface inversion;gpu;speedup ratio;controlled points	We present a fast procedure for the interface inversion of density contrast on the platform of GPU. Firstly, based on the iterative method in spatial domain, we introduce soft constraints by some few control points, making the inversion results closer to reality. In this problem, we assume that the density contrast decays with depth according to a parabolic law. Secondly, in order to meet the interface inversion for a wide range large-scale gravity data, we develop GPU program of the 3D interface inversion of basement relief, and give the corresponding optimization strategies and the speedup tests for the calculation results. We demonstrate the applicability and efficacy of this technique by inverting gravity anomalies caused by a synthetic model of a density interface and a set of real field data. & 2015 Elsevier Ltd. All rights reserved.	graphics processing unit;hardware acceleration;iterative method;loop unrolling;mathematical optimization;parabolic antenna;program optimization;speedup;synthetic intelligence	Zhaoxi Chen;Xiaohong Meng;Sheng Zhang	2015	Computers & Geosciences	10.1016/j.cageo.2015.08.002	mathematical optimization;parallel computing;computer science;theoretical computer science	Graphics	71.31784491993359	-53.735607574096484	44166
33b43eed57ec8e7e9622dacca676710b21f32ee3	diagnostic quality of compressed medical images: objective and subjective evaluation	discrete wavelet transforms;discrete wavelet transform compressed medical images medical diagnostic ct scan images x ray images;x ray images;image coding;discrete wavelet transform;psnr;computed tomography;x ray imaging;clinical application;image coding biomedical imaging medical diagnostic imaging image reconstruction psnr computed tomography magnetic resonance imaging x ray imaging information retrieval image retrieval;information retrieval;medical diagnostic;telemedicine;discrete wavelet transform dwt;telemedicine medical image discrete wavelet transform dwt teleradiology;compressed medical images;biomedical imaging;ct scan images;ct scan;medical image;image compression;teleradiology;image reconstruction;medical image processing;magnetic resonance imaging;compression ratio;subjective evaluation;medical diagnostic computing;medical image processing discrete wavelet transforms image reconstruction medical diagnostic computing;medical diagnostic imaging;image retrieval	Without image compression, images data would become much larger and consequently retrieval of images will be slow, thus telemedicine would in many situations be impractical. But it is natural to raise the question of how much an image can be compressed and still preserve sufficient information for a given clinical application. Evaluation of the diagnostic quality of compressed medical image still remains an important issue. In this paper, three different medical image modalities have been compressed and decompressed using DWT for different compression ratios and evaluated using objective and subjective testing. The quality of the reconstructed images has been measured using objective measures such as MSE, MAE, SNR, and PSNR. Ten observers have been involved to carry out the subjective evaluation. Based on the quality of the reconstructed images, the PSNR obtained has been between 35.3 dB to 58.0 dB for CT scan images, 38.6 dB to 55.0 dB for MRI and 34.5 dB to 51 MB for X-ray images. For radiology applications, the compression ratio of 30:1 is acceptable for CT images, and a compression ratio of 40:1 is acceptable for MRI, and compression ratio of 20:1 is acceptable for X-ray images.	ct scan;data compression;decibel;discrete wavelet transform;image compression;mean squared error;peak signal-to-noise ratio;radiology	S. E. Ghrare;Mohd. Alauddin Mohd. Ali;Munira Ismail;K. Jumari	2008	2008 Second Asia International Conference on Modelling &#x00026; Simulation (AMS)	10.1109/AMS.2008.10	computer vision;radiology;computer science;medical physics	Vision	56.902057615977206	-79.71727372890903	44196
54746a78d38fc49acd9b47d33e246a6eb4c62be4	high resolution photography with an rgb-infrared camera	kernel;sensors cameras image color analysis image restoration crosstalk kernel lenses;image segmentation;image resolution;quadratic image regularizer high resolution photography rgb infrared camera rgb ir camera rgb infrared photography image formation model restoration problem channel deblurring channel separation pixel demosaicing;crosstalk;sensors;pixel demosaicing;image restoration;high resolution photography;colour photography;restoration problem;infrared imaging;image color analysis;infrared imaging colour photography image colour analysis image resolution image restoration image segmentation;image colour analysis;rgb ir camera;lenses;rgb infrared photography;rgb infrared camera;quadratic image regularizer;channel separation;channel deblurring;cameras;image formation model	A convenient solution to RGB-Infrared photography is to extend the basic RGB mosaic with a fourth filter type with high transmittance in the near-infrared band. Unfortunately, applying conventional demosaicing algorithms to RGB-IR sensors is not possible for two reasons. First, the RGB and near-infrared image are differently focused due to different refractive indices of each band. Second, manufacturing constraints introduce crosstalk between RGB and IR channels. In this paper we propose a novel image formation model for RGB-IR cameras that can be easily calibrated, and propose an efficient algorithm that jointly addresses three restoration problems - channel deblurring, channel separation and pixel demosaicing - using quadratic image regularizers. We also extend our algorithm to handle more general regularizers and pixel saturation. Experiments show that our method produces sharp, full-resolution images of pure RGB color and IR.	algorithm;circuit restoration;crosstalk;deblurring;demosaicing;experiment;graphics processing unit;image formation;multiplexing;pixel;run-time infrastructure (simulation);sensor	Huixuan Tang;Xiaopeng Zhang;Shaojie Zhuo;Feng Chen;Kiriakos N. Kutulakos;Liang Shen	2015	2015 IEEE International Conference on Computational Photography (ICCP)	10.1109/ICCPHOT.2015.7168367	computer vision;geography;optics;computer graphics (images)	Vision	59.581948714080006	-54.59819144742584	44234
58bd0411bce7df96c44aa3579136eff873b56ac5	multimodal classification of remote sensing images: a review and future directions	radar images remote sensing image image multimodal classification earth observation material identification material characterization space platforms airborne platforms heterogeneous image sources satellite sensors material classification multimodal image fusion signal processing machine learning sparse methods kernel based fusion markov modeling manifold alignment multiresolution fusion multispectral image classification multitemporal image fusion multidimensional interpolation optical images;multitemporal;sensors;fusion;image fusion;remote sensing spatial resolution sensors satellites image fusion synthetic aperture radar;classification;remote sensing classification fusion multiangular multimodal image analysis multisource multitemporal;remote sensing;satellites;multimodal image analysis;remote sensing geophysical image processing geophysical techniques image classification image fusion;multisource;multiangular;synthetic aperture radar;spatial resolution	Earth observation through remote sensing images allows the accurate characterization and identification of materials on the surface from space and airborne platforms. Multiple and heterogeneous image sources can be available for the same geographical region: multispectral, hyperspectral, radar, multitemporal, and multiangular images can today be acquired over a given scene. These sources can be combined/fused to improve classification of the materials on the surface. Even if this type of systems is generally accurate, the field is about to face new challenges: the upcoming constellations of satellite sensors will acquire large amounts of images of different spatial, spectral, angular, and temporal resolutions. In this scenario, multimodal image fusion stands out as the appropriate framework to address these problems. In this paper, we provide a taxonomical view of the field and review the current methodologies for multimodal classification of remote sensing images. We also highlight the most recent advances, which exploit synergies with machine learning and signal processing: sparse methods, kernel-based fusion, Markov modeling, and manifold alignment. Then, we illustrate the different approaches in seven challenging remote sensing applications: 1) multiresolution fusion for multispectral image classification; 2) image downscaling as a form of multitemporal image fusion and multidimensional interpolation among sensors of different spatial, spectral, and temporal resolutions; 3) multiangular image classification; 4) multisensor image fusion exploiting physically-based feature extractions; 5) multitemporal image classification of land covers in incomplete, inconsistent, and vague image sources; 6) spatiospectral multisensor fusion of optical and radar images for change detection; and 7) cross-sensor adaptation of classifiers. The adoption of these techniques in operational settings will help to monitor our planet from space in the very near future.	airborne ranger;angularjs;computer vision;downscaling;image fusion;interpolation;machine learning;manifold alignment;markov chain;multimodal interaction;multispectral image;radar;sensor;signal processing;sparse matrix;synergy;taxonomy (general);vagueness	Luis Gómez-Chova;Devis Tuia;Gustau Camps-Valls	2015	Proceedings of the IEEE	10.1109/JPROC.2015.2449668	computer vision;synthetic aperture radar;image resolution;fusion;biological classification;sensor;pattern recognition;image fusion;physics;satellite;remote sensing	Vision	75.72848639365317	-60.43682798853386	44489
02b278b9e51ebde36207a118765defd8b9eb78fa	confidence weighting for sensor fingerprinting	video signal processing image sensors;prnu estimation algorithm confidence weighting sensor fingerprinting photo response nonuniformity common source camera identification;performance test;video signal processing;confidence weighting;image sensors;estimation algorithm;photo response nonuniformity;common source camera identification;fingerprint recognition;noise reduction;pixel;sensor fingerprinting;fingerprint recognition videos testing sensor phenomena and characterization layout digital cameras forensics lenses image processing semiconductor device modeling;interviews;prnu estimation algorithm;high frequency;cameras;noise;videos	The use of photo-response non-uniformity (PRNU) has been proposed as the basis of a sensor fingerprint for common source camera identification. We perform tests of the PRNU-based fingerprint on a set of videos chosen to represent a wide range of potential inputs. Based on the results of these tests, we propose a confidence weighting scheme to address the problem of extracting a viable fingerprint from videos where high-frequency content (e.g. edges) persist at a given image location. We further show that the extended PRNU estimation algorithm with confidence weighting has improved performance on such problematic videos.	algorithm;antivirus software;circuit complexity;experiment;fingerprint (computing);noise reduction;sensor;test data;test set;tripod	Scott McCloskey	2008	2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops	10.1109/CVPRW.2008.4562986	computer vision;speech recognition;interview;computer science;noise;high frequency;pattern recognition;noise reduction;image sensor;fingerprint recognition;pixel	Vision	54.52831470209702	-61.32835333055425	44515
f608af904109e38cd32add4c3f18d5c7ea539225	tinting component extraction from gray-scale image for color estimation	image processing;characteristic;color image;computer vision;gray scale;luminance;estimate;statistical analysis	The authors havc bccn st.udying color cstimation of gray-scale imagc. The prohlcm of this study is defined as an ill-posed problem. bccausc a luminancc to arhitrary color is uniquely fixed but the Illminancr c.orrcsponds t.o plural color-values. In this papcr. tintingcomponcnt (m whit.c mixed valuc) cst,imat ion mct hod from gray-scale imcgc is proposcd based on st.atist ics. This mcthod acquires tainting valuc t,hat corresponds t,o input luminancc by using t,cndcncy of one color v c ~ t o r ' s pair of luminancc and t,int.ing valuc. In this nict.hod, a few of samplc imagc could bc estimate rcscnil~lancc under the situat,ion t,hat, appearance probability of any color valuc is equal. Thcn, this mrthod is cxpc.c.t.c,d t,hc cstimation with higher prccision hy making suita l ~ l c adjust,mcnt bascd on the charactcristics of input imagc.	grayscale;signal-to-noise ratio;transponder (aeronautics);well-posed problem	Shinya Koizumi;Takahiko Horiuchi	2002			pattern recognition;grayscale;computer vision;image processing;mathematics;artificial intelligence;color image;luminance	Vision	53.99731320928295	-60.863606346035034	44517
beb6bfa756d32f3a7f05899b6f694ae177f6643f	openglsl-based raycasting - comparison of execution durations of multi-pass vs. single-pass technique		Real time volume rendering of medical datasets using raycasting on graphics processing units (GPUs) is a common technique. Since more than 10 years there are two established approaches for realizing GPU ray casting: multi-pass (Kruger and Westermann, 2003) and single-pass (Röttger, et al., 2003). But the required parameters to choose the optimal raycasting technique for a given application are still unknown. To solve this issue both raycasting techniques were implemented for different raycasting types using OpenGLSL vertex and fragment shaders. The different techniques and types were compared regarding execution times. The results of this comparison show that there is no technique faster in general. The higher the computational load the more indicates the use of the multi-pass technique.	computation;computer graphics;graphics processing unit;ray casting;shader;volume rendering	Stefan Maas;Heinrich M. Overhoff	2015		10.5220/0005344703070310	data mining;parallel computing;computer science	Visualization	68.44973525045906	-52.5608869914958	44522
55573f31bafd6ee88f17cef4c283cf56b0a01860	quantifying bird migration by a high-resolution weather radar	tratamiento datos;aves;maps;traitement signal;teledetection;bird volume density bird migration high resolution weather radar bird detection bird count algorithm radar maps plan position indicator type spatial arrangement poisson distribution s band doppler weather radar alps;radar methods;high resolution;densite;radar maps;high resolution weather radar;mapa;indicateur;migration;meteorological radar;radar tracking;surveillance;indicators;data processing;bird detection;vertebrata;traitement donnee;radar target recognition biology radar applications radar signal processing;fauna pajaro;densidad;weather radar;biology;biologia;carte;faune oiseau;deteccion a distancia;chordata;spatial arrangement;algorithme;radar cross section;modelo;haute resolution;poisson distribution atmospheric techniques meteorological radar object detection;birds;bird count algorithm;tetrapoda;target recognition;radar antennas;remote sensing;radar imaging;doppler radar;alta resolucion;radar target recognition;radar applications;algorithms;radar detection;modele;atmospheric techniques;bird volume density;density;cumulant;s band doppler weather radar;plan position indicator type;algorithm design;models;bird migration;methode radar;radar signal processing;object detection;biologie;migracion;radar;poisson distribution;birds meteorological radar radar cross section radar antennas radar detection radar imaging radar applications radar tracking doppler radar surveillance;alps;algoritmo	We propose a bird detection and count algorithm designed to work with radar maps of plan-position-indicator type. The spatial arrangement of birds is modeled according to the Poisson distribution. It is possible to handle a nonuniform target distribution both on the vertical and horizontal planes. The method is applied to measurements carried out by an S-band Doppler weather radar located on the south side of the Alps. Quantitative estimates are given for the distribution of bird volume density with height, the cumulative density (integrated over height), and, finally, the daily migration traffic rate of nocturnal migrants over an area of about 2000 km2.	algorithm;clutter;cubic function;flocking (behavior);image resolution;map;pixel density;radar;signal processing	Roberto Nebuloni;Carlo Capsoni;Vittorio Vigorita	2008	IEEE Transactions on Geoscience and Remote Sensing	10.1109/TGRS.2008.916467	meteorology;algorithm design;radar tracker;image resolution;data processing;density;human migration;weather radar;mathematics;poisson distribution;radar imaging;radar cross-section;physics;radar;statistics;remote sensing;cumulant	Visualization	77.33308104371702	-61.7453780742459	44620
597b53db1f898f80be828a10a224fc60c1102cae	an adaptive window approach for image smoothing and structures preserving	statistical method;weighted sums;structure preservation;adaptive smoothing	A novel adaptive smoothing approach is proposed for image smoothing and discontinuities preservation. The method is based on a locally piecewise constant modeling of the image with an adaptive choice of a window around each pixel. The adaptive smoothing technique asso- ciates with each pixel the weighted sum of data points within the window. We describe a statistical method for choosing the optimal window size, in a manner that varies at each pixel, with an adaptive choice of weights for every pair of pixels in the window. We further investigate how the I-divergence could be used to stop the algorithm. It is worth noting the proposed technique is data-driven and fully adaptive. Simulation results show that our algorithm yields promising smoothing results on a variety of real images.	smoothing	Charles Kervrann	2004		10.1007/978-3-540-24672-5_11	exponential smoothing;mathematical optimization;machine learning;mathematics;statistics;smoothing	Vision	55.610141750647365	-66.5744557259664	44627
e4033eac53132256af6c1440d170dca355317e9c	sentinel-msi vnir and swir bands sensitivity analysis for soil salinity discrimination in an arid landscape		Depending on the band position on the electromagnetic spectrum, optical and electronic characteristics, sensors collect the reflected energy by the Earth’s surface and the atmosphere. Currently, the availability of the new generation of medium resolution, such as the Multi-Spectral Instrument (MSI) on board the Sentinel-2 satellite, offers new opportunities for long-term high-temporal frequency for Earth’s surfaces observation and monitoring. This paper focuses on the analysis and the comparison of the visible, the near-infrared (VNIR), and the shortwave infrared (SWIR) spectral bands of the MSI for soil salinity discrimination in an arid landscape. To achieve these, a field campaign was organized, and 160 soil samples were collected with various degrees of soil salinity, including non-saline soil samples. The bidirectional reflectance factor was measured above each soil sample in a goniometric laboratory using an ASD (Analytical Spectral Devices) spectroradiometer. In the laboratory work, pHs, electrical conductivity (EC-Lab), and the major soluble cations (Na+, K+, Ca2++, and Mg2+) and anions (CO32−, HCO3−, Cl−, and SO42−) were measured using extraction from a saturated soil paste, and the sodium adsorption ratio (SAR) was calculated using a standard procedure. These parameters, in addition to the field observations, were used to interpret and investigate the spectroradiometric measurements and their relevant transformations using the continuum removed reflectance spectrum (CRRS) and the first derivative (FD). Moreover, the acquired spectra over all the soil samples were resampled and convolved in the solar-reflective spectral bands using the Canadian Modified Herman transfer radiative code (CAM5S) and the relative spectral response profiles characterizing the Sentinel-MSI band filters. The statistical analyses conducted were based on the second-order polynomial regression (p u003c 0.05) between the measured EC-Lab and the reflectances in the MSI convolved spectral bands. The results obtained indicate the limitation of VNIR bands and the potential of SWIR domain for soil salinity classes’ discrimination. The CRRS and the FD analyses highlighted a serious spectral-signal confusion between the salt and the soil optical properties (i.e., color and brightness) in the VNIR bands. Likewise, the results stressed the independence of the SWIR domain vis-a-vis these soil artifacts and its capability to differentiate significantly among several soil salinity classes. Moreover, the statistical fit between each MSI individual spectral band and EC-Lab corroborates this trend, which revealed that only the SWIR bands were correlated significantly (R2 of 50% and 64%, for SWIR-1 and SWIR-2, respectively), while the R2 between the VNIR bands and EC-Lab remains less than 9%. According to the convergence of these four independent analysis methods, it is concluded that the Sentinel-MSI SWIR bands are excellent candidates for an integration in soil salinity modeling and monitoring at local, regional, and global scales.		Abderrazak Bannari;Ali El-Battay;Rachid Bannari;Hassan Rhinane	2018	Remote Sensing	10.3390/rs10060855	geology;remote sensing;vnir;spectral line;spectral bands;soil test;soil salinity;sodium adsorption ratio;polynomial regression;spectroradiometer	Mobile	82.82968748664094	-61.53787692138432	44673
61425139502c1ae76e19e88df2b72c2707a90e49	hclr: a hybrid clustering and low-rank regularization-based method for photon-limited image restoration		Abstract A photon-limited image can be represented as a pixel matrix limited by the relatively small number of collected photons. The image can also be seen as being contaminated by Poisson noise because the total number of photons follows the Poisson distribution. Through exploitation of the inherent properties of observation combined with application of a denoising method, an image can be significantly restored. In this paper, a hybrid clustering and low-rank regularization-based model (HCLR) is proposed based on the essential features of patch clustering and noise. An efficient Newton-type method is designed to optimize this biconvex problem. Experimental results demonstrate that HCLR achieves competitive denoising performance, especially for high noise levels, compared with state-of-the-art Poisson denoising algorithms.		Xiaolong Zhu;Xiangchu Feng;Weiwei Wang;Xi-xi Jia;Rui Zhang;Rui-qiang He;Chen Xu	2018	J. Visual Communication and Image Representation	10.1016/j.jvcir.2018.10.015	pixel;mathematics;image restoration;pattern recognition;artificial intelligence;shot noise;noise reduction;matrix (mathematics);small number;cluster analysis;poisson distribution	Vision	57.675616999003985	-71.06540645610018	44685
bd6780a48d6f374adb00235fe8e369b6c0a4269c	summary of terra and aqua modis on-orbit calibration and characterization results	aqua;nasa eos;thermal emissive bands;terra modis on orbit calibration;radiometric calibration;modis calibration temperature sensors ocean temperature signal to noise ratio sensor phenomena and characterization clouds stability nasa spatial resolution;calibration aerospace instrumentation artificial satellites;obc modis terra aqua sensor calibration;spectroradiometric calibration assembly;onboard calibrators;sensor;solar diffuser;reflective solar bands;spectroradiometric calibration assembly terra modis on orbit calibration aqua modis on orbit calibration nasa eos reflective solar bands thermal emissive bands onboard calibrators solar diffuser;artificial satellites;modis;obc;calibration;aqua modis on orbit calibration;aerospace instrumentation;terra;spatial resolution	Since launch the NASA EOS Terra MODIS has been in operation for more than seven years and the Aqua MODIS for nearly five years. Each MODIS has 20 reflective solar bands and 16 thermal emissive bands. It makes observations at three nadir spatial resolutions: 0.25 km, 0.5 km, and 1 km and is calibrated on- orbit by a set of on-board calibrators (OBC) that include a solar diffuser, a solar diffuser stability monitor, a blackbody, and a spectro-radiometric calibration assembly. This paper provides an overview of Terra and Aqua MODIS on-orbit calibration and characterization activities and results.	aqua;display resolution;eos;metric;on-board data handling	Xiaoxiong Xiong;Vince Salomonson;Brian Wenny;Xiaobo Xie;Nianzeng Che;Aisheng Wu;William Barnes	2007	2007 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2007.4423758	meteorology;calibration;image resolution;atmospheric sciences;sensor;physics;satellite;remote sensing	Embedded	81.75202720486308	-63.524394159749455	44740
a70af0f5e82acad7ebde36a3d4cc52689d1afc0f	shape and reflectance from two-bounce light transients	reflectance estimation two bounce light transients computer vision image based inference direct light transport single bounce light paths shape estimation;shape estimation transient analysis cameras photonics three dimensional displays time measurement;reflectivity computer vision	Computer vision and image-based inference have predominantly focused on extracting scene information by assuming that the camera measures direct light transport (i.e., single-bounce light paths). As a consequence, strong multi-bounce effects are treated typically as sources of noise and, in many scenarios, the presence of such effects can result in gross errors in the estimates of shape and reflectance. This paper provides the theoretical and algorithmic foundations for shape and reflectance estimation from two-bounce light transients, i.e., scenarios where photons from a light source interact with the scene exactly twice before reaching the sensor We derive sufficient conditions for exact recovery of shape and reflectance given lengths and intensities associated with two-bounce light paths. We also develop algorithms for recovery of shape and reflectance, and validate these on a range of simulated scenes.	algorithm;computer vision;image noise;transient (computer programming)	Chia-Yin Tsai;Ashok Veeraraghavan;Aswin C. Sankaranarayanan	2016	2016 IEEE International Conference on Computational Photography (ICCP)	10.1109/ICCPHOT.2016.7492882	computer vision;optoelectronics;optics;physics	Vision	55.24820082006847	-52.55114593583927	44889
7415fd081ca5e59dc6d1f9d3de9a7c1c4cdb2329	framework of applying independent component analysis after compressed sensing for electroencephalogram signals		This paper proposes a novel compressed sensing (CS) framework for electroencephalogram (EEG) signals with artifacts. A feature of this framework is the application of an independent component analysis (ICA) to remove the interference of artifacts after CS in a data processing unit. Therefore, we can remove the ICA processing block from the sensing unit. In the framework, we use a random sampling measurement matrix in CS to suppress the Gaussian of the compressed sensing data. Herein, the proposed framework is evaluated using raw EEG signals with a pseudo-model of an eye-blinking artifact. The comparison of normalized mean square error (NMSE) values are shown to quantitatively demonstrate the effectiveness of proposed framework.		Daisuke Kanemoto;Shun Katsumata;Masao Aihara;Makoto Ohki	2018	2018 IEEE Biomedical Circuits and Systems Conference (BioCAS)	10.1109/BIOCAS.2018.8584829	compressed sensing;independent component analysis;normalization (statistics);computer vision;electroencephalography;matrix (mathematics);data processing system;artificial intelligence;mean squared error;computer science	Robotics	64.88335384710292	-69.09940869942089	44948
55b6dd90a3d35fb786c056f240f82fe4dd998193	spatial-spectral-emissivity land-cover classification fusing visible and thermal infrared hyperspectral imagery		High-resolution visible remote sensing imagery and thermal infrared hyperspectral imagery are potential data sources for land-cover classification. In this paper, in order to make full use of these two types of imagery, a spatial-spectral-emissivity land-cover classification method based on the fusion of visible and thermal infrared hyperspectral imagery is proposed, namely, SSECRF (spatial-spectral-emissivity land-cover classification based on conditional random fields). A spectral-spatial feature set is constructed considering the spectral variability and spatial-contextual information, to extract features from the high-resolution visible image. The emissivity is retrieved from the thermal infrared hyperspectral image by the FLAASH-IR algorithm and firstly introduced in the fusion of the visible and thermal infrared hyperspectral imagery; also, the emissivity is utilized in SSECRF, which contributes to improving the identification of man-made objects, such as roads and roofs. To complete the land-cover classification, the spatial-spectral feature set and emissivity are integrated by constructing the SSECRF energy function, which relates labels to the spatial-spectral-emissivity features, to obtain an improved classification result. The classification map performs a good result in distinguishing some certain classes, such as roads and bare soil. Also, the experimental results show that the proposed SSECRF algorithm efficiently integrates the spatial, spectral, and emissivity information and performs better than the traditional methods using raw radiance from thermal infrared hyperspectral imagery data, with a kappa value of 0.9137.	algorithm;conditional random field;experiment;image resolution;mathematical optimization;smoothing;spatial variability;streaming simd extensions;unary operation	Yanfei Zhong;Tianyi Jia;Ji Zhao;Xinyu Wang;Shuying Jin	2017	Remote Sensing	10.3390/rs9090910	infrared;computer vision;geology;artificial intelligence;remote sensing;land cover;thermal;conditional random field;radiance;hyperspectral imaging;image fusion;emissivity	Visualization	76.01275259369888	-59.39812383640687	44982
bf6858dc9f3494b688be4f2a22499b87b73db901	statistical modeling and simulation of delay-doppler maps in the time-varying regime		The purpose of this paper is to extend the stationary stochastic model defined in [1] to a time evolving sea state and platform motion. The temporal analysis is carried out defining the time-varying model for the signal at the correlator output and its autocorrelation function (acf), following the work by You and Garrison [2, 3]. The temporal evolution of the signal has been integrated into the simulator developed by the Remote Sensing and Telecommunication Research Group of the University of Sannio in order to generate an arbitrary number of istantaneous correlated delay-Doppler maps. The acf function has been estimated by simulation runs and compared to known models, showing very good agreement for the signal scattered from the nominal specular point and from the other bins. The theoretical and estimated decorrelation times are about 4 ms in the nominal specular point. This result is coherent with other estimates obtained in airborne campaigns reported in [2], [4] and simulations reported in Garrison [3].	airborne ranger;autocorrelation;coherence (physics);decorrelation;map;simulation;stationary process	Stefano Principe;Tiziana Beltramonte;Maurizio di Bisceglie;Carmela Galdi	2017	2017 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)	10.1109/IGARSS.2017.8127907	computer vision;computer science;artificial intelligence;stochastic modelling;statistics;autocorrelation;doppler effect;sea state;decorrelation;gaussian process;specular reflection;statistical model	Robotics	73.27321369220337	-63.59164288774025	45044
ec38a315b5bb59b0d2643b228c637c24ea8c71db	incorporating incidence angle variation into sar image segmentation		We present a new approach for incorporating incidence angle derived synthetic aperture radar (SAR) brightness variation directly into SAR image analysis. This approach is unique in that the incidence angle dependency is modeled explicitly into the probability density function rather than an image-wide pre-processing ‘correction’. It can then be used for supervised and unsupervised image analysis, and is notably able to account for a different dependency rate for each class. This has potential benefits for wide-swath SAR imagery over flat areas and ocean, wide angled airborne and UAV based SAR data, connecting narrow-beam SAR images at different acquisition angles, as well as land-based analysis with local topographic terrain angles. An initial example demonstrates unsupervised image segmentation applied to sea ice mapping for meteorological services and climate science, and is compared to the same algorithm without the incidence angle modeling.	airborne ranger;algorithm;aperture (software);image analysis;image segmentation;incidence matrix;preprocessor;supervised learning;synthetic intelligence;topography;unmanned aerial vehicle	Anthony Paul Doulgeris;Anca Cristea	2018	IGARSS 2018 - 2018 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2018.8519043	computer vision;remote sensing;probability density function;sea ice;terrain;artificial intelligence;image segmentation;brightness;arctic;topographic map;synthetic aperture radar;computer science	Vision	76.33548458957084	-59.64248768295849	45060
266e5b82203ea9838413ea7de12d6bd068dab22f	piecewise-planar 3d reconstruction with edge and corner regularization	i 2 10 artificial intelligence vision and scene understanding 3d stereo scene analysis;i 5 4 pattern recognition applications computer vision;i 4 8 image processing and computer vision scene analysis range data;categories and subject descriptors according to acm ccs	This paper presents a method for the 3D reconstruction of a piecewise-planar surface from range images, typically laser scans with millions of points. The reconstructed surface is a watertight polygonal mesh that conforms to observations at a given scale in the visible planar parts of the scene, and that is plausible in hidden parts. We formulate surface reconstruction as a discrete optimization problem based on detected and hypothesized planes. One of our major contributions, besides a treatment of data anisotropy and novel surface hypotheses, is a regularization of the reconstructed surface w.r.t. the length of edges and the number of corners. Compared to classical area-based regularization, it better captures surface complexity and is therefore better suited for man-made environments, such as buildings. To handle the underlying higher-order potentials, that are problematic for MRF optimizers, we formulate minimization as a sparse mixed-integer linear programming problem and obtain an approximate solution using a simple relaxation. Experiments show that it is fast and reaches near-optimal solutions.	3d reconstruction;approximation algorithm;ct scan;discrete optimization;discretization;effective method;experiment;integer programming;lp-type problem;linear programming relaxation;manifold regularization;markov random field;mathematical optimization;matrix regularization;optimization problem;photogrammetry;polygon mesh;sampling (signal processing);sparse matrix;voxel	Alexandre Boulch;Martin de La Gorce;Renaud Marlet	2014	Comput. Graph. Forum	10.1111/cgf.12431	computer vision;artificial intelligence;machine learning;mathematics;geometry;algorithm;computer graphics (images)	Vision	56.55634156567727	-52.34678905713879	45117
66e5133a63d150c7dad7bb3d363761fc9b4c8dba	gamut clipping and mapping based on the coloroid system.		The paper presents novel techniques based on the Coloroid color system which hitherto has not been applied to gamut mapping. The introduced methods described are hue preserving and use three gravity centers in a huedependent way. Two of the gravity centers are shifted toward the direction of ‘negative saturation’, and can be used for regions of bright and dark colors, while a third gravity center is used for saturated colors. After a short survey of gamut mapping an introduction to the Coloroid describes concisely its features and formulas. Then a simple color clipping rule is presented applicable to any rendering applications. A gamut mapping method will be defined mapping from a generic input image to an RGB display. Other variations of the method describe RGB-CYMK transformation and also cross-media mapping for known input and output gamut boundaries. The introduced methods apply hue and chroma dependent lightness compression. They can be applied in realistic computer graphics and digital photography as well as in printing technologies. They are straightforward to implement and have low computational costs.	cathode ray tube;clipping (computer graphics);color management;computation;computer graphics;digital photography;experiment;gloss (annotation);input/output;jan dietz;list of 3d rendering software;printer (computing);printing;simulation;standard test image;time complexity	László Neumann;Attila Neumann	2004			computer vision;digital photography;rendering (computer graphics);rgb color model;lightness;coloroid;artificial intelligence;gamut;computer graphics;hue;computer science	Graphics	62.5369681704322	-53.731621456559566	45148
fe6a482dc4b8f338c37900a91d043f987eec2315	a local pixel distribution based self-adaptive median filter for removal of pepper and salt noise		As we know, for any image, the intensive function varies distinctly in the whole domain and fluctuates little in a small area or a special direction. We name this local pixel value distribution information as priori knowledge. After detecting the salt and pepper noise pixels, the self-adaptive median filter is use to find a suitable window containing more non-noise pixels. By applying the priori knowledge to these non-noise pixels, we deduce maximum likelihood value of the target pixel. Simulations with the restoring attention and peak signal-noise ratio are carried out to demonstrate that the proposed algorithm have superior performance to the existing classical methods.	adaptive filter;algorithm;computer simulation;information;median filter;noise (electronics);pixel;salt (cryptography);salt-and-pepper noise;sensor;signal-to-noise ratio	Xinxing Yuan;Peng Wen;Bo Fu;Min Zhang;XiuXiang Fan	2013		10.3182/20130902-3-CN-3020.00179	computer vision;machine learning;mathematics;bilateral filter;non-local means;salt-and-pepper noise	Vision	56.60248223039631	-65.78730297458692	45209
6ab8466a4fa9950fbb10fa0b6820be3d0536f47a	generalized histogram equalization based on local characteristics	contrast enhanced;transfer functions;histograms helium image enhancement transfer functions statistics dynamic range electronic mail image analysis density functional theory image quality;indexing terms;image enhancement;transfer function;proceedings paper;transfer functions image enhancement;image analysis;image enhancement generalized histogram equalization technique localized image analysis intensity transfer function;histogram equalization	Histogram equalization (HE) and its variations have been widely used in image enhancement. Even though these approaches may enhance image contrast in an effective and efficient way, they usually face some undesired drawbacks, like loss of image details, noise amplification and over-enhancement. In this paper, we propose a generalized histogram equalization technique based on localized image analysis. Starting from designing two measures f1 and f2 to measure local characteristics around each pixel, the global statistics of these two local measures are then recorded into an extended histogram. Based on this extended histogram, we develop a procedure to generate suitable intensity transfer functions for various applications, like contrast enhancement and shadow enhancement. Experimental results show that the proposed algorithm provides a flexible and efficient way for image enhancement.	algorithm;emoticon;histogram equalization;image analysis;image editing;pixel;shadow and highlight enhancement;transfer function	Tzu-Cheng Jen;Sheng-Jyh Wang	2006	2006 International Conference on Image Processing	10.1109/ICIP.2006.313030	computer vision;feature detection;image analysis;speech recognition;color normalization;shadow and highlight enhancement;computer science;histogram matching;balanced histogram thresholding;mathematics;transfer function;adaptive histogram equalization;histogram equalization;image histogram	Vision	56.32452351354609	-64.64426054595823	45216
045bf5717984b7fd44d7950c052c6cf58b06df75	model-based polsar decompositions: virtues and vices		Model-based polarimetric decompositions have long been applied to classify polarimetric SAR imagery. This long and successful history has, at times, been interrupted by nagging issues: polarimetric orientation angle effects, negative scattering powers, simplistic scattering models, etc. We test model-based polarimetric decomposition techniques for robustness to variations of the underlying in-scene scattering mechanisms. We determine the accuracy and robustness of the decomposition results using simulated data sets. The simulation inputs, e.g. volume scattering model, polarimetric signal-to-noise, simple multi-bounce models, etc., are known and thus provide “ground truth” for comparison to model-based decomposition results. We will illustrate our results by applying a select set of model-based decompositions to both simulated and actual PolSAR imagery.	ground truth;interrupt;polarimetry;robustness (computer science);signal-to-noise ratio;simulation	Thomas L. Ainsworth;Jong-Sen Lee;Yanting Wang	2018	IGARSS 2018 - 2018 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2018.8517630	computer vision;robustness (computer science);artificial intelligence;data set;data modeling;ground truth;scattering;solid modeling;computer science	Vision	73.66841472238163	-65.03910382179517	45322
830514e52d438523fe0a6914abdf7b9f2705c2de	very high resolution circular sar imaging at x band	object recognition;image resolution;training;very high resolution sar circular imagery;circular imaging;microwave imaging;circular imagery;remote sensing by radar;synthetic aperture radar radar imaging image resolution radar polarimetry aircraft training buildings;sar;target recognition;radar polarimetry;very high resolution;radar imaging;area monitoring onera ramses ng sar sensor circular imaging x band target recognition;x band;area monitoring;synthetic aperture radar microwave imaging object recognition remote sensing by radar;onera ramses ng sar sensor;buildings;aircraft;synthetic aperture radar	This paper presents a new acquisition capability of the ONERA RAMSES-NG SAR sensor consisting in circular imaging, and an associated experiment. Target recognition or area monitoring is tricky using classical SAR imaging because only a part of the object shape is visible. The backscattering is strongly dependant of the relative heading angle between the radar line of sight and the target. Then, circular imaging mode is very efficient to overcome this problem since 360° data are acquired in a single pass.	course (navigation);image resolution;onera	Xavier Dupuis;Philippe Martineau	2014	2014 IEEE Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2014.6946578	computer vision;synthetic aperture radar;image resolution;geology;x band;specific absorption rate;cognitive neuroscience of visual object recognition;optics;radar imaging;physics;remote sensing	Robotics	76.27697534470326	-63.61315796590509	45324
acbd9245943917b013573aaa5e0c2adc3485ae30	no-reference image quality assessment based on gradient histogram response		In view of the fact that objects with different natures usually respond differently to the same external stimulus, this paper proposes a no-reference image quality assessment based on gradient histogram response (GHR). GHR is the gradient histogram variation of an image object under a local transform. In the metric, through preprocessing, a test image is transformed to a noise image and a blur image, which are taken as two image objects. Each image object is exerted with a local transform as an object input, and its GHR as an object output is extracted in multiscale space. The two GHRs compose a global feature vector and are mapped to an image quality score. Experiments show that GHR outperforms state-of-the-art no-reference metrics statistically in the condition that test images are degraded by different types of distortions. Especially, the metric is feasible for the quality assessment of the images degraded by mixed distortions though the types of these images are not included in the training database. © 2015 Elsevier Ltd. All rights reserved.	distortion;experiment;feature vector;gaussian blur;gradient;image quality;preprocessor;standard test image	Tongfeng Sun;Shifei Ding;Wei Chen;Xinzheng Xu	2016	Computers & Electrical Engineering	10.1016/j.compeleceng.2015.11.007	image quality;image restoration;computer vision;feature detection;histogram matching;pattern recognition;mathematics;image histogram;computer graphics (images)	Vision	58.16966178803684	-62.69925897560582	45359
97e96a979126b171aedeb37b27341140a30f3f4a	a golden block self-generating scheme for continuous patterned wafer inspections	electrical capacitance tomography;filtering;golden block self generating scheme;defect free image;integrated circuit yield;image databases;building block;inspection electrical capacitance tomography read only memory image databases bridges filtering;image database;automatic optical inspection;bridges;inspection;image to image reference methods;structure representation;manufacturing data processing;image representation;feature extraction;continuous patterned wafer inspections;spectral estimation;parameter estimation;spectral analysis;manufacturing data processing automatic optical inspection image representation spectral analysis parameter estimation feature extraction integrated circuit yield;read only memory;image to image reference methods golden block self generating scheme continuous patterned wafer inspections defect detection periodic 2d wafer images spectral estimation structure representation pattern extraction defect free image pixel to pixel comparison self reference methods;pattern extraction;pixel to pixel comparison;self reference methods;defect detection;periodic 2d wafer images	This paper presents a novel technique for detecting possible defects in two-dimensional wafer images with repetitive patterns using prior knowledge. It has a learning ability that is able to create a golden block database from the wafer image itself, modify and refine its content when used in further inspections. The extracted building block is stored as a golden block for the detected pattern. When new wafer images with the same periodical pattern arrives, we do not have to re-calculate its periods and building block. A new building block can be derived directly from the existing golden block after eliminating alignment differences. If the newly derived building block has better quality than the stored golden block, then the golden block is replaced with the new building block. With the proposed algorithm, our implementation shows that a significant amount of processing time is saved. And the storage overhead of golden templates is also reduced significantly by storing golden blocks only.	algorithm;overhead (computing);sensor;software bug;wafer (electronics)	Steven Guan;Pin Xie	1999		10.1109/ICIAP.1999.797634	filter;computer vision;inspection;feature extraction;computer science;spectral density estimation;estimation theory;read-only memory;statistics	HPC	54.23271043678579	-59.95281007677683	45374
701d09ca40647d26cfe7cce95a1a25ca6ca539a5	high-resolution measurements of scattering in wheat canopies-implications for crop parameter retrieval	three dimensional imaging;vegetation mapping;teledetection;suelo cultivado;agricultural land;instruments;high resolution;medida en tierra;ble;instrumentation;scattering parameters crops spaceborne radar radar scattering soil radar measurements polarization biomass geoscience image retrieval;trigo;radar antenne synthetique;instrumentacion;polarization;angle incidence;biomasse;backscatter;imagerie;diffusion onde;cultivated soil;angulo incidente;3 to 6 cm shf geophysical measurement technique vegetation mapping agriculture crops wheat crop canopy radar remote sensing radar scattering backscatter layered structure incidence angle polarization double bounce volume scattering radar polarimetry crop parameter retrieval x band c band sar synthetic aperture radar three dimensional images;canopy vegetation;wavelength;sol cultive;attenuation;agricultura;dosel;deteccion a distancia;pluie;vegetation;polarizacion;vertical structure;remote sensing by radar;layered structure;occupation sol;haute resolution;imagery;backscatter modeling;vegetacion;synthetic aperture radar sar;radar polarimetry;field measurement;atenuacion;remote sensing;mesure au sol;wave scattering;alta resolucion;biomass;wheat;agriculture;radar cross sections;ground methods;canopee;imagineria;lluvia;longueur onde;polarisation;perturbation;biomasa;backscatter geophysical techniques agriculture vegetation mapping remote sensing by radar radar polarimetry synthetic aperture radar radar cross sections;angle of incidence;land cover;rainfall;geophysical techniques;radar synthese ouverture;synthetic aperture radar	Polarimetric Xand C-band measurements by the University of Sheffield ground-based synthetic aperture radar (GB-SAR) indoor system provide three-dimensional images of the scattering processes in wheat canopies, at resolutions of around a wavelength (3–6 cm). The scattering shows a pronounced layered structure, with strong returns from the soil and the flag leaves, and in some cases a second leaf layer. Differential attenuation at horizontal (H) and vertical (V) polarization, due to the predominantly vertical structure of the wheat stems, gives rise to marked effects. At both C and X bands, direct return from the canopy exceeds the soil return at large incidence angles for VV polarization, but is comparable to or less than the soil return in all other cases. At HV, the apparent ground return is probably due to a double-bounce mechanism, and volume scattering is never the dominant term. Direct sensing of the crop canopy is most effective at X band, VV, and large incidence angles, under which conditions the return is dominated by the flag leaf layer. Field measurements with the outdoor GB-SAR system suggest, however, that for sensitivity to biomass and reduced susceptibility to disturbances by rainfall, a two-channel C-band system operating at a medium range of incidence angles is preferred.	incidence matrix;motorola canopy;polarimetry;polarization (waves);synthetic data;verification and validation	Sarah C. M. Brown;Shaun Quegan;Keith Morrison;John C. Bennett;Geoff Cookmartin	2003	IEEE Trans. Geoscience and Remote Sensing	10.1109/TGRS.2003.814132	meteorology;polarization;hydrology;optics;physics;remote sensing	Mobile	82.90476613534675	-64.30210113272013	45389
9bfd6a5c91278338c98325189af6752255e1141c	minute feature analysis in speckled imagery	speckle;universal parametric statistical model minute feature analysis speckled imagery parameters estimation speckle noise ultrasound b synthetic aperture radar images;image processing;ultrasound;speckle noise;maximum likelihood estimation;small samples;statistical model;image analysis parameter estimation speckle lighting synthetic aperture sonar laser modes laser noise laser radar ultrasonic imaging failure analysis;parameter estimation speckle image processing maximum likelihood estimation;parameter estimation;feature analysis;linear equations;synthetic aperture radar	This paper tackles the problem of estimating the parameters of relevant distributions that describe speckled imagery. Speckle noise appears in data obtained with coherent illumination, as is the case of sonar, laser, ultrasound-B and synthetic aperture radar images. This noise is non-Gaussian and non-additive and, therefore, classical techniques of processing and analysis may fail. A universal parametric statistical model has been proposed for such data, and numerical issues arise when estimating its parameters. In particular, the usual techniques for optimization and for solving systems of non-linear equations often fail to converge and/or to produce acceptable results, specially when dealing with small samples. An alternated method is proposed and assessed, and it is shown to produce sensible results. As an application, real and simulated data are analyzed. We show that the discrimination of minute features in synthetic aperture radar images can be performed using the proposed procedure.	algorithm;coherence (physics);computation;converge;linear equation;mathematical optimization;nonlinear system;numerical analysis;parametric model;polarimetry;sonar (symantec);statistical model;subject indexing;synthetic data;synthetic intelligence;utility functions on indivisible goods	Alejandro César Frery;Francisco Cribari-Neto;Marcelo de O. Souza	2002		10.1109/SIBGRA.2002.1167165	speckle pattern;speckle noise;computer vision;geography;optics;inverse synthetic aperture radar;remote sensing	Vision	72.79877866943352	-65.98698833096941	45485
5999e62b4ec0cac04afd07b0c2dd9dba539f77f6	impulse noise removal from color images with hopfield neural network and improved vector median filter	vector median filter noise removal impulse noise color images hopfield neural network median filter;noise corruption;filtering;vector median filter;colored noise;median filter;color space;color;impulse noise;hopfield neural nets;hopfield neural network;false positive rate;color images;image edge detection;neural net work;image color analysis;image colour analysis;pixel;noise filtering;impulse noise pixel;colored noise color hopfield neural networks phase noise phase detection filters filtering algorithms performance evaluation impulse testing pixel;median filters hopfield neural nets image colour analysis image denoising impulse noise;impulse noise removal;image denoising;noise detection;noise corruption impulse noise removal color image hopfield neural network vector median filter noise detection impulse noise pixel noise filtering;real time application;noise removal;median filters;color image;noise	In this paper, a novel and effective method for impulse noise removal in corrupted color images is discussed. The new method consists of two phases. The first phase is a noise detection phase where a modified Hopfield neural network is used to detect impulse noise pixels. The second is a noise filtering phase where the disadvantage of taking vector median in a single color space is addressed and a new algorithm based on performing vector median first in RGB space and then in HSI space is presented. The results of simulations performed on a set of standard test images on a wide range of noise corruption show that the proposed method is capable of detecting all the impulse noise pixels with almost zero false positive rates and removes noise while retaining finer image details. It outperforms the standard procedures and is yet simple and suitable for real time applications.	algorithm;artificial neural network;color space;effective method;grayscale;hopfield network;horizontal situation indicator;impulse noise (audio);median filter;peak signal-to-noise ratio;pixel;real-time computing;sensor;simulation;standard operating procedure;standard test image	G. Phani Deepti;Maruti V. Borker;Jayanthi Sivaswamy	2008	2008 Sixth Indian Conference on Computer Vision, Graphics & Image Processing	10.1109/ICVGIP.2008.75	gradient noise;gaussian noise;median filter;image noise;computer vision;electronic engineering;dark-frame subtraction;value noise;noise measurement;machine learning;mathematics;salt-and-pepper noise	Vision	56.48023070149676	-65.42910050011041	45594
fb84c8bc5b4b3ce39ba2be89fe423189cc1a02ee	ers-2 scatterometer: mission performances and current reprocessing achievements	sea ice;c band;antenna measurement;instruments;radar measurements satellites spaceborne radar calibration instruments antenna measurements monitoring;antenna measurements;wind atmospheric boundary layer atmospheric techniques data analysis geophysical signal processing hydrological techniques microwave measurement moisture oceanographic techniques oceanography remote sensing by radar sea ice soil synthetic aperture radar;data processing;weather forecasting;data quality control;european remote sensing satellite;remote sensing by radar;data analysis;sea surface;wind wave;monitoring;geophysical signal processing;moisture;microwave measurement;satellites;soil water content;wind vector calibration c band european remote sensing satellite ers scatterometry;global climate observing system;data quality control activities ers 2 scatterometer mission performance data reprocessing european remote sensing satellite 2 satellite configuration on ground data processing algorithm instrument performance on ground data processor performance european space agency esa microwave instrument radar backscattering coefficient measurements synthetic aperture mode sar mode scatterometer mode wind mode wind wave mode sea surface wind vector estimation numerical weather forecast models meteorological weather forecast soil water content sea ice estec esrin european centre for medium range weather forecasts belgian royal military academy calibration zero gyro phase serco spa;european remote sensing satellite ers;atmospheric techniques;wind vector;soil;radar measurements;wind;oceanographic techniques;calibration;oceanography;hydrological techniques;scatterometry;european centre for medium range weather forecast;atmospheric boundary layer;spaceborne radar;synthetic aperture radar	This paper presents an overview of the evolution of the European Remote-sensing Satellite (ERS)-2 scatterometer mission during the last 16 years, highlighting the changes in both satellite configuration and on-ground data processing algorithm. Instrument and on-ground data processor performances and evolutions are analyzed and commented; finally, future developments are emphasized. ERS-2 was launched in 1995 by the European Space Agency (ESA). Since then, the active microwave instrument, which is one of the ERS-2 payloads, is providing radar backscattering coefficient measurements by using its three nominal operational acquisition mode: synthetic aperture mode (SAR mode), scatterometer mode (wind mode), and a special combination of the two over ocean where SAR and scatterometer mode are interleaved (wind/wave mode). The main applications for data acquired in scatterometer mode are related to the estimation of the wind vector over the sea surface. In that field, the ERS-2 scatterometer measurements give a very valuable contribution to the accuracy of the numerical weather forecast models, being assimilated in several meteorological weather forecast centers since the beginning of the mission. Other applications of the ERS-2 scatterometer data are over land to retrieve information about the soil water content and over the sea-ice. A constant monitoring of the scatterometer performances is carried out since the beginning of the mission by ESA engineering teams located in ESTEC and ESRIN and the instrument manufacture (Dornier at launch time), in collaboration with several European research institutions, as the European Centre for Medium-range Weather Forecasts for product geophysical validation, the Belgian Royal Military Academy for data processing and calibration during the zero-gyro phase, and industrial partners, as Serco SpA for the routine data quality control activities since the beginning of operational phase. Results show outstanding performances even after the failure of several hardware components that has been properly compensated on-ground with evolution of the processor, and many years of operation, which permits the creation of a homogeneous database of wind vectors for the last 16 years (20 years if the ERS-1 mission is considered), in accordance with Global Climate Observing System recommendations.	academy;algorithm;coefficient;data quality;esa;gyro;general comprehensive operating system;launch time;microwave;numerical analysis;numerical weather prediction;performance;revolution in military affairs;synthetic data	Raffaele Crapolicchio;Giovanna De Chiara;Anis Elyouncha;Pascal Lecomte;Xavier Neyt;Alessandra Paciucci;Marco Talone	2012	IEEE Transactions on Geoscience and Remote Sensing	10.1109/TGRS.2011.2179808	meteorology;wind wave;moisture;european remote-sensing satellite;calibration;synthetic aperture radar;c band;atmospheric sciences;weather forecasting;data processing;antenna measurement;data analysis;sea ice;physics;satellite;remote sensing;wind;planetary boundary layer	DB	80.15897125807993	-63.4728391049083	45621
50ab4481eda8e8e7a19dd0413fa7444a36e265c3	efficient 2d to 3d video conversion implemented on dsp	signal image and speech processing;quantum information technology spintronics	An efficient algorithm to generate three-dimensional (3D) video sequences is presented in this work. The algorithm is based on a disparity map computation and an anaglyph synthesis. The disparity map was first estimated by employing the wavelet atomic functions technique at several decomposition levels in processing a 2D video sequence. Then, we used an anaglyph synthesis to apply the disparity map in a 3D video sequence reconstruction. Compared with the other disparity map computation techniques such as optical flow, stereo matching, wavelets, etc., the proposed approach produces a better performance according to the commonly used metrics (structural similarity and quantity of bad pixels). The hardware implementation for the proposed algorithm and the other techniques are also presented to justify the possibility of real-time visualization for 3D color video sequences.	3d computer graphics;algorithm;anaglyph 3d;binocular disparity;computation;computer stereo vision;digital signal processor;optical flow;pixel;real-time locating system;structural similarity;wavelet	Eduardo Ramos-Diaz;Victor Kravchenko;Volodymyr I. Ponomaryov	2011	EURASIP J. Adv. Sig. Proc.	10.1186/1687-6180-2011-106	computer vision;computer science;theoretical computer science;computer graphics (images)	Vision	58.70364984065934	-58.441422697700006	45673
95e1b3d7a2742f520fe2ed0a0064eb059c47980f	outdoor photometric stereo	lighting light sources mirrors estimation surface treatment sparse matrices robustness;stereo image processing;lighting;complex real world illumination outdoor photometric stereo natural environmental illumination laboratory environment robust outdoor operation processing pipeline;stereo image processing lighting	We introduce a framework for outdoor photometric stereo utilizing natural environmental illumination. Our framework extends beyond existing photometric stereo methods intended for laboratory environments to encompass robust outdoor operation in the real world. In this paper, we motivate our framework, describe the components of its processing pipeline, and assess its performance in synthetic experiments as well as in natural experiments including objects in outdoor environments with complex real-world illuminations.	algorithm;data center;display resolution;experiment;ka band;lambertian reflectance;mathematical optimization;matrix regularization;normal (geometry);photometric stereo;structure from motion;synthetic intelligence;total variation denoising	Lap-Fai Yu;Sai Kit Yeung;Yu-Wing Tai;Demetri Terzopoulos;Tony F. Chan	2013	IEEE International Conference on Computational Photography (ICCP)	10.1109/ICCPhot.2013.6528306	computer vision;geography;optics;computer graphics (images)	Vision	59.155785460650115	-53.31776057123945	45675
2580a665c134cc437b0327267bce665bb24f7f6e	vessel classification features using spatial bayesian inference from historical ais data		Detections and classification of non-AIS-compliant vessels is an important ability for countries or institutions interested in MDA. SAR has been proven to be an effective method but there exists a trade-off between the area that can be imaged and the resolution of each image pixel. Large swath SAR images are a cost effective method of performing maritime surveillance but classification or identification from the images remains a challenge. An algorithm to predict the AIS class of a vessel using historical AIS data and SAR derived features is described in this paper. The novel algorithm calculates the class probability by taking historical AIS data into account using a Bayesian algorithm. Features extracted from SAR imagery are then used with the AIS historical data to provide a list of class probabilities that can enhance other course resolution classification algorithms or to flag vessels that do not conform to historical class behaviour.	algorithm;bayesian network;effective method;model-driven architecture;pixel;sensor;synapomorphy	R. G. V. Meyer;Colin P. Schwegmann;Waldo Kleynhans	2017	2017 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)	10.1109/IGARSS.2017.8127534	computer vision;artificial intelligence;computer science;feature extraction;statistical classification;bayesian statistics;image resolution;spatial analysis;effective method;synthetic aperture radar;bayesian inference	Vision	75.0188881877541	-60.34413838488159	45732
42d60f1cbdbcd9dc4c5a10267a9897e73a6f5b6a	field-inhomogeneity-corrected low-rank filtering of magnetic resonance spectroscopic imaging data	low rank filtering method field inhomogeneity corrected low rank filtering magnetic resonance spectroscopic imaging data signal noise ratio low rank approximation based denoising method mrsi data partial separability properties denoising performance;medical image processing biomedical mri filtering theory image denoising magnetic resonance spectroscopy;nonhomogeneous media noise reduction imaging in vivo image resolution signal to noise ratio nuclear magnetic resonance	Low signal-to-noise ratio has been a major problem in magnetic resonance spectroscopic imaging (MRSI). A low-rank approximation based denoising method has been recently proposed to address this problem by exploiting the partial separability properties of MRSI data. However, field inhomogeneity, an unavoidable complication in practice, can violate the partial separability assumption and thus degrade the denoising performance of the low-rank filtering method. This paper presents a field-inhomogeneity-corrected low-rank filtering method to achieve more robust denoising of practical MRSI data. In vivo experiment results have been used to demonstrate the effectiveness of the proposed method.	chlorhexadol;image resolution;linear separability;low-rank approximation;map;noise reduction;signal-to-noise ratio;video-in video-out;magnetic resonance spectroscopic imaging	Yan Liu;Chao Ma;Bryan A. Clifford;Fan Lam;Curtis L. Johnson;Zhi-Pei Liang	2014	2014 36th Annual International Conference of the IEEE Engineering in Medicine and Biology Society	10.1109/EMBC.2014.6945098	computer vision;mathematics;nuclear magnetic resonance	Robotics	57.19556128776533	-73.53157769775234	45822
d6c71c6f15997dede2a4a9d2780d8d5561e8f803	a noncentral and non-gaussian probability model for sar data		A general compound statistical model for coherent imaging is developed and tested on single-channel Synthetic Aperture Radar (SAR) data. In this formulation, coherent scattering is taken into consideration and the texture is modeled using an Inverse Gaussian distribution. Parameter estimation is conducted via an Expectation Maximization (EM) scheme. A Maximum a Posteriori (MAP) speckle filter based on this model is also implemented. The filter shows good smoothing capabilities and preserves details in the selected scene, showing promise for target-detection applications.		Anca Cristea;Anthony Paul Doulgeris;Torbjørn Eltoft	2017		10.1007/978-3-319-59129-2_14	mathematical optimization;artificial intelligence;pattern recognition;noncentral chi-squared distribution;maximum a posteriori estimation;smoothing;expectation–maximization algorithm;computer science;speckle pattern;estimation theory;inverse gaussian distribution;noncentral t-distribution	Vision	61.263970939492054	-70.98353631525457	45849
ec43f6b290f23ac3ff888439e8409254f38b9c32	compton scattering tomography: feature reconstruction and rotation-free modality		Compton scattering tomography (CST) is an emerging two-dimensional imaging concept exploiting the scattered radiation while a specimen is illuminated by a gamma source. In the last decade, the study of first-order scattered photons has led to model the measured flux by Radon transforms over circles. Such transforms were shown to be invertible due to their strong relation with the classical Radon transform, i.e., the line integrals. In this paper, we study the smoothness properties and the regularization issues for such transforms and then build suitable reconstruction methods based on the approximate inverse, which facilitates the extraction of features (for instance the contours). However, these previously derived models neglect physical factors such as the attenuation of the beam. This leads us to incorporate a weight in the forward transforms similarly to the attenuated Radon transform in single-photon emission computed tomography (SPECT). In this case, no analytical inversion of the corresponding weig...	tomography	Gaël Rigaud	2017	SIAM J. Imaging Sciences	10.1137/17M1120105	iterative reconstruction;compton scattering;mathematics;radon transform;mathematical analysis;emission computed tomography;attenuation;photon;radiation;tomography	Theory	59.607108774625296	-76.85904934477851	45902
ec47e27a857b6259fcec8e4608b6fb94ae9488e3	mountain crop monitoring with multitemporal sentinel-1 and sentinel-2 imagery		An analysis of radar signal sensitivity to crop and soil conditions was conducted using a time series of Sentinel-1 C-band dual-polarized (VH-VV) SAR images acquired from October 2014 to September 2016 for different crops (meadows, pasture, orchard, vineyards) located in mountain areas. Together with Sentinel-1 images, corresponding Sentinel-2 images and ground measurements were exploited. Preliminary results showed that the cross-polarized VH backscattering coefficients were useful for monitoring crop phenology. In particularly for meadows the VH signal is well correlated with NDVI derived from both Sentinel-2 images and from ground observations.	adobe swc file;algorithm;coefficient;meadow;orchard;polarization (waves);radar;simulation;time series;verification and validation	Claudia Notarnicola;Sarah Asam;A. Jacob;C. Marin;Mauro Rossi;L. Stendardi	2017	2017 9th International Workshop on the Analysis of Multitemporal Remote Sensing Images (MultiTemp)	10.1109/Multi-Temp.2017.8035225	normalized difference vegetation index;signal sensitivity;remote sensing;radar;synthetic aperture radar;crop;orchard;geography;phenology	Robotics	81.61388228643119	-61.03397439012501	45959
5f6648340110e54d56bb29ef9b15e8616094111d	an iterative method for shadow enhancement in high resolution sar images		The edges of shadows are blurred in Synthetic Aperture Radar (SAR) images due to the moving of the radar when data are collected. This phenomenon becomes obvious in High Resolution (HR) SAR images. In this work, an adaptive approach for shadow enhancements is proposed. The performance of the shadow enhancement has some relationship with the precision of the estimation of the height and this rule is used in this work. The Height-Variant Phase Compensation (HVPC) and golden section algorithm are employed. The adaptive method is built by iterative progress of calculating the quantities of pixels corresponding to the shadow region. This method provides an automatic way for shadow enhancements and it is suitable for objects mainly composed of flat-like structures. The experiments based on the Mini-SAR of a helicopter are implemented to test the validity of the approach. The work in this paper provides a way for shadow enhancement for HR SAR images and would be useful for SAR Automatic Target Recognition.	algorithm;aperture (software);automatic target recognition;experiment;image resolution;iterative method;pixel;radar;shadow and highlight enhancement;shadow volume	Yueting Zhang;Qi Liu;Jiayi Guo;Lei Liu;Zongxu Pan;Fangfang Li;Chibiao Ding;Bin Lei	2017	2017 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)	10.1109/IGARSS.2017.8127444	pixel;computer vision;remote sensing;iterative method;artificial intelligence;computer science;synthetic aperture radar;radar;information processing;automatic target recognition;phenomenon;shadow	Robotics	74.95540429446064	-65.05283613337086	46003
20c6d1eda0b325e6311abcb38b553191c2984648	digital staining for histopathology multispectral images by the combined application of spectral enhancement and spectral transformation	least squares approximations;organic compounds;least square method;hematoxylin and eosin;image color analysis;medical image processing;principal component analysis;multispectral images;principal component analysis least squares approximations medical image processing organic compounds;matrix converter;vectors image color analysis muscles pathology matrix converters training data imaging;masson s trichrome stained equivalent digital staining histopathology multispectral images spectral enhancement spectral transformation principal component vectors least square method hematoxylin eosin;algorithms fibrillar collagens humans image enhancement liver microscopy staining and labeling;principal component	In this paper we introduced a digital staining method for histopathology images captured with an n-band multispectral camera. The method consisted of two major processes: enhancement of the original spectral transmittance and the transformation of the enhanced transmittance to its target spectral configuration. Enhancement is accomplished by shifting the original transmittance with the scaled difference between the original transmittance and the transmittance estimated with m dominant principal component (PC) vectors;the m-PC vectors were determined from the transmittance samples of the background image. Transformation of the enhanced transmittance to the target spectral configuration was done using an nxn transformation matrix, which was derived by applying a least square method to the enhanced and target spectral training data samples of the different tissue components. Experimental results on the digital conversion of a hematoxylin and eosin (H&E) stained multispectral image to its Masson's trichrome stained (MT) equivalent shows the viability of the method.	enhancement description;eosine yellowish;hematoxylin and eosin stain method;histopathology;least-squares analysis;multispectral image;principal component analysis;staining method;transformation matrix	Pinky A. Bautista;Yukako Yagi	2011	2011 Annual International Conference of the IEEE Engineering in Medicine and Biology Society	10.1109/IEMBS.2011.6091976	computer vision;computer science;machine learning;optics;principal component analysis	Vision	65.25765795570929	-67.62481311664536	46052
a779ff10a95cb2dee5c69952f9ed74441b361d23	tv sparsifying mr image reconstruction in compressive sensing	compressed sensing;magnetic resonance image;image reconstruction;total variation	In this paper, we apply alternating minimization method to sparse image reconstruction in compressed sensing. This approach can exactly reconstruct the MR image from under-sampled k-space data, i.e., the partial Fourier data. The convergence analysis of the fast method is also given. Some MR images are employed to test in the numerical experiments, and the results demonstrate that our method is very efficient in MRI reconstruction.	compressed sensing;experiment;iterative reconstruction;numerical analysis;sparse matrix	Yonggui Zhu;Xiaolan Yang	2011	J. Signal and Information Processing	10.4236/jsip.2011.21007	computer vision;mathematical optimization;computer graphics (images)	ML	56.706743960074256	-74.09185009231062	46161
48c238a261dcfed1575a48057e97b434dd0ccfcd	generic 2d/3d smoothing via regional variation	three dimensional displays smoothing methods noise reduction noise image denoising image edge detection joining processes;mesh smoothing generic 2d 3d smoothing regional variation data samples maximum local variation 2d images 3d meshes smoothing filters image denoising image decomposition;two dimensional digital filters image denoising smoothing methods;image decomposition image smoothing mesh smoothing tone mapping adaptive filter	In this paper, we propose a method to measure the relationship between data samples, which is dependent on the possibility whether they are within a homogeneous region or not. By considering the regional variation, this possibility is formulated in terms of the maximum local variation along the shortest path connecting the samples. The metric is concretized in both 2D images and 3D meshes, and then integrated into smoothing filters. Benefited from our method, the improved filters tend to effectively preserve the structural component of data. Moreover, our method is implemented in various applications such as image denoising, image decomposition and mesh smoothing, which demonstrates better performance in comparison to the previous work.	noise reduction;shortest path problem;smoothing;structural element	Wenfei Jiang;Tao Luo;Fan Zhang;Jiang Tian;Pei Luo;Kangying Cai	2014	2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	10.1109/ICASSP.2014.6853656	edge-preserving smoothing;computer vision;mathematical optimization;pattern recognition;mathematics;laplacian smoothing;total variation denoising;non-local means;smoothing	Robotics	54.148871969952665	-69.49924337279222	46185
ad7b55f3ea0a07deec721157da9e9a45a2514ece	mangrove mapping and change detection using satellite imagery		Mangrove forests constitute an important coastal ecosystem, which provides valuable ecosystem services such as coastal erosion protection, water filtration and shelters for a wide variety of plants and animals. Remote sensing satellite imagery provides valuable information for mangrove mapping and monitoring. In this study, we use high resolution images from SPOT-5, Landsat-7 and Landsat-8 satellites to perform change detection on an area of interest that covers the mangrove forests at the Ramsar sites of Pulau Kukup, Tanjung Piai and Sungai Pulai in the southwestern part of Johor State of Malaysia. Land use/land cover maps and the mangrove change map are generated to identify the mangrove distribution and temporal variation between 2000 and 2016. A hierarchical object-based classification method was used to produce the land use/land cover map in 2000, 2005, 2013 and 2016. The WorldView2 data were also used for validation of the classification results. This study presented an approach for mangrove mapping and change detection analysis. The map provides an up to date information for the study area and can be used for future comparative study.	ecosystem services;image resolution;map;object-based language;water cooling	Ping Chen;Soo Chin Liew;Leong Keong Kwoh	2017	2017 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)	10.1109/IGARSS.2017.8128306	land use;remote sensing;ecosystem services;satellite imagery;land cover;mangrove;coastal erosion;computer science;change detection;ecosystem	Embedded	81.13254158752122	-57.173071729000924	46206
0973111dc4b0dd7f42fd227079f23e16b5811561	some considerations about the in-orbit calibration of spaceborne rotating fan beam radar scatterometer	amazon forest;rotating fan beam scatterometer;ocean surface vector wind;internal calibration precision;extended target rotating fan beam scatterometer ocean surface vector wind calibration;in orbit calibration;backscatter;external calibration accuracy;ocean surface vector wind measurement;extended target;ku band rfscat;receivers;remote sensing by radar;insertion loss;rotating fan beam radar scatterometer;antennas;wind atmospheric techniques calibration remote sensing by radar spaceborne radar;atmospheric techniques;calibration spaceborne radar radar measurements antennas backscatter insertion loss receivers;amazon forest in orbit calibration rotating fan beam radar scatterometer spaceborne scatterometer ocean surface vector wind measurement ku band rfscat internal calibration precision external calibration accuracy;radar measurements;wind;calibration;spaceborne radar;spaceborne scatterometer	Rotating fan-beam scatterometer (RFSCAT) is a new kind of spaceborne scatterometer for ocean surface vector wind (OSVW) measurement. In this paper, some consideration about the calibration of a Ku-band RFSCAT is presented. Both internal calibration and external calibration are described. Preliminary analyses about the internal calibration precision and external calibration accuracy are presented. Based on the method of Long, etal, external calibration method for RFSCAT is proposed. Some simulation results for the external calibration with natural extended targets, such as Amazon forest, are presented.	amazon simple storage service;coefficient;half-band filter;ku band;radar;radiation pattern;rotary woofer;simulation	Xiaolong Dong;Daozhi Liu;Jintai Zhu;Di Zhu;Wenming Lin	2011	2011 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2011.6049293	insertion loss;meteorology;calibration;hydrology;antenna;backscatter;physics;remote sensing;wind	Robotics	80.68672255284855	-65.1880081023292	46377
5f8a656ddcbba8a41dd0a7d3894004bc045f1df0	detecting the spread of invasive species in central chile with a sentinel-2 time-series		The presented work evaluates the potential of a Sentinel-2 time-series to detect Pinus radiata (Monterey Pine) invasions in endemic Nothofagus (Southern Beeches) forests in the Maule region, central Chile. Suitable cloud free images of the phenological cycle were selected from six Sentinel-2 scenes available for the years 2016. The scenes were unmixed using a non-negative least square (nnls) algorithm for different landcover components per pixel. The results were validated with a SVM classification of UAV-based hyperspectral mosaics acquired in March 2016. The results show that it is possible to map the coverage of the Pinus radiata class up to an accuracy of R2 ∼ 0.6 and RMSE of ∼ 10 %. Generally, a higher number of Sentinel-2 images increased the performance of the model, while there was no significant dependency on a specific acquisition date. However, the variability of the results is high, which indicates that a careful selection of multi-temporal endmembers is crucial to a successful unmixing of Pinus radiata.	algorithm;heart rate variability;pixel;sensor;time series;unmanned aerial vehicle	Michael Förster;Tobias Schmidt;Roman Wolf;Birgit Kleinschmit;Fabian Ewald Fassnacht;Julian Cabezas;Teja Kattenborn	2017	2017 9th International Workshop on the Analysis of Multitemporal Remote Sensing Images (MultiTemp)	10.1109/Multi-Temp.2017.8035216	nothofagus;vegetation;remote sensing;pinus radiata;invasive species;phenology;geography	Vision	81.05577076391404	-57.488292532641005	46395
132d9ee3ecb285abfd262641e1b4444b440f318e	discrete wavelet diffusion for image denoising	nonlinear diffusion;discrete wavelet transform;wavelet shrinkage;qa76 electronic computers computer science computer software;wavelet transform;image denoising;haar wavelet transform	Nonlinear diffusion, proposed by Perona and Malik, is a well­known method  for  image  denoising  with  edge  preserving  characteristics.  Recently, nonlinear  diffusion  has  been  shown  to  be  equivalent  to  iterative  wavelet shrinkage, but only for (1) Mallat­Zhong dyadic wavelet transform and (2) Haar wavelet  transform.  In  this  paper,  we  generalize  the  equivalence  of  nonlinear diffusion  to  non­linear  shrinkage  in  the  standard  discrete  wavelet  transform (DWT)  domain.  Two  of  the  major  advantages  of  the  standard  DWT  are  its simplicity (as compared to 1) and its potential to benefit from a greater range of orthogonal  and  biorthogonal  filters  (as  compared  to  both  1  and  2).  We  also extend the wavelet diffusion implementation to multiple scales. The qualitative and quantitative results shown for a variety of images contaminated with noise demonstrate the promise of the proposed standard wavelet diffusion.	discrete wavelet transform;dyadic transformation;haar wavelet;iterative method;noise reduction;nonlinear system;turing completeness	Kashif Rajpoot;Nasir M. Rajpoot;J. Alison Noble	2008		10.1007/978-3-540-69905-7_3	multiresolution analysis;wavelet;computer vision;constant q transform;mathematical optimization;mathematical analysis;s transform;harmonic wavelet transform;second-generation wavelet transform;continuous wavelet transform;computer science;cascade algorithm;mathematics;wavelet packet decomposition;stationary wavelet transform;discrete wavelet transform;fast wavelet transform;lifting scheme;wavelet transform	Vision	56.050946795314445	-68.72391889887487	46495
0bd58aa9365f82fdde8946b8b33c17a83c1e20b1	assessment of segmentation parameters for object-based land cover classification using color-infrared imagery				Ozgun Akcay;E. Ozgur Avsar;Melis Inalpulat;Levent Genç;Ahmet Cam	2018	ISPRS Int. J. Geo-Information	10.3390/ijgi7110424		ML	76.96266467871008	-59.795022071611584	46497
5a4e45c32cd7ef8c25c56a7e01ba7fc0bc1193f9	speed up of the edge-based inverse halftoning algorithm using a finite state machine model approach	full search;halftone image;finite state machine model;search method;inverse halftoning;left to right;image quality;lookup table;edges;speedup;finite state machine;sliding window	The recently published edge- and lookup table-based inverse halftoning (ELIH) algorithm has shown its quality and superiority when compared with the previous lookup table-based IH algorithm. This paper presents a new finite state machine model (FSMM)-based search method to speed up the existing ELIH algorithm significantly while preserving the same image quality as in the ELIH algorithm. From the observation that the sliding window for the ELIH algorithm moves from left to right one position; there are therefore one output column and one input column which are introduced at each step and thus a simple finite state machine can track the transitions from the current window movement to the next. This is faster than a full search in the lookup table. Under thirty typical testing images adopted from Mese's website, experimental results demonstrated that the proposed FSMM-based ELIH algorithm has an improvement in execution time of 20% to 80%, with a typical improvement of 50%, when compared to the ELIH algorithm.	algorithm;finite-state machine	Kuo-Liang Chung;Ping-Zen Chen;Ying-Lin Pan	2009	Computers & Mathematics with Applications	10.1016/j.camwa.2009.04.018	image quality;sliding window protocol;edge;mathematical optimization;lookup table;speedup;computer science;theoretical computer science;machine learning;finite-state machine;algorithm	ML	53.97484587088187	-63.9872920836167	46629
bf07d60ba6d6c6b8cabab72dfce06f203782df8f	manifold-learning-based feature extraction for classification of hyperspectral data: a review of advances in manifold learning	learning systems feature extraction hyperspectral imaging signal processing algorithms geometry laplace equations;geophysics computing;feature extraction;remote sensing;pattern classification;remote sensing feature extraction geophysics computing learning artificial intelligence pattern classification;learning artificial intelligence;large scale remote sensing data sets manifold learning based feature extraction hyperspectral data classification hyperspectral sensing geometric structures topological structures parameter tuning	Advances in hyperspectral sensing provide new capability for characterizing spectral signatures in a wide range of physical and biological systems, while inspiring new methods for extracting information from these data. HSI data often lie on sparse, nonlinear manifolds whose geometric and topological structures can be exploited via manifold-learning techniques. In this article, we focused on demonstrating the opportunities provided by manifold learning for classification of remotely sensed data. However, limitations and opportunities remain both for research and applications. Although these methods have been demonstrated to mitigate the impact of physical effects that affect electromagnetic energy traversing the atmosphere and reflecting from a target, nonlinearities are not always exhibited in the data, particularly at lower spatial resolutions, so users should always evaluate the inherent nonlinearity in the data. Manifold learning is data driven, and as such, results are strongly dependent on the characteristics of the data, and one method will not consistently provide the best results. Nonlinear manifold-learning methods require parameter tuning, although experimental results are typically stable over a range of values, and have higher computational overhead than linear methods, which is particularly relevant for large-scale remote sensing data sets. Opportunities for advancing manifold learning also exist for analysis of hyperspectral and multisource remotely sensed data. Manifolds are assumed to be inherently smooth, an assumption that some data sets may violate, and data often contain classes whose spectra are distinctly different, resulting in multiple manifolds or submanifolds that cannot be readily integrated with a single manifold representation. Developing appropriate characterizations that exploit the unique characteristics of these submanifolds for a particular data set is an open research problem for which hierarchical manifold structures appear to have merit. To date, most work in manifold learning has focused on feature extraction from single images, assuming stationarity across the scene. Research is also needed in joint exploitation of global and local embedding methods in dynamic, multitemporal environments and integration with semisupervised and active learning.	antivirus software;autostereogram;biological system;computation;feature extraction;horizontal situation indicator;nonlinear dimensionality reduction;nonlinear system;open research;overhead (computing);semi-supervised learning;sparse matrix;stationary process	Dalton Lunga;Saurabh Prasad;Melba M. Crawford;Okan K. Ersoy	2014	IEEE Signal Processing Magazine	10.1109/MSP.2013.2279894	computer vision;feature extraction;computer science;machine learning;pattern recognition	ML	69.25190171078793	-65.42323763153334	46714
579a91066de6c95611b4b7e47851d94eff6a3b0e	what does motion reveal about transparency?	image features;photogrammetry;object recognition;motion compensation;3d scene;model based approach;layout painting optical refraction optical control shape measurement computer science object detection graphics rendering computer graphics interpolation;scene features;transparent objects;computer vision;camera motion;environment matting;visual inspection;machine vision;feature extraction;feature position;scene features transparent objects refractive indices 3d scene environment matting camera motion computer vision graphics rendering visual inspection feature position photogrammetry image features;transparency;rendering computer graphics;graphics rendering;cameras computer vision rendering computer graphics motion compensation object recognition feature extraction transparency;cameras;refractive indices;numerical simulation	The perception of transparent objects from images is known to be a very hard problem in vision. Given a single image, it is difficult to even detect the presence of transparent objects in the scene. In this paper, we explore what can be said about transparent objects by a moving observer. We show how features that are imaged through a transparent object behave differently from those that are rigidly attached to the scene. We present a novel model-based approach to recover the shapes and the poses of transparent objects from known motion. The objects can be complex in that they may be composed of multiple layers with different refractive indices. We have conducted numerous simulations to verify the practical feasibility of our algorithm. We have applied it to real scenes that include transparent objects and recovered the shapes of the objects with high accuracy. 1 Why is Transparency Hard? The perception of transparency is a hard and important vision problem that has not received much attention. Transparent objects violate most of the fundamental assumptions made by vision algorithms. For instance, they cause the projection of a three-dimensional scene to the image plane to not be perspective. Furthermore, this projection can vary from one viewpoint to the next. As seen from Figure 1(a), a single view does not even determine with certainty whether the scene includes transparent objects within it, leave alone reveal the geometric properties of the transparent objects. The circular shape in Figure 1(a) may be a transparent sphere located in front of a painting, or it may be a part of the painting itself. This ambiguity arises from the fact that a transparent object does not have features of its own. It simply maps features that exist in its environment onto the image plane. This mapping is complex to say the least; even for a simple shape the mapping of a real feature to the image through a transparent object involves complex interactions between rays from the real feature, the surfaces of the transparent object, and the viewpoint of the observer. Several researchers have addressed issues related to transparency in vision and graphics. Zongker el al. [14] and Chuang et al. [3] presented a method called environment matting for capturing the optical behavior of transparent objects from known and controlled backgrounds for rendering ∗This work was supported by an NSF ITR Award IIS-00-85864 ”Interacting with the Visual World: Capturing, Understanding, and Predicting Appearance”. (a) (b) Figure 1: (a) A single view of a scene does not determine with certainty whether the scene includes transparent objects. The circular region in this image could be a transparent sphere placed in front of the painting or it could be a part of the painting itself. (b) This image is also of the scene in (a) but taken from a different viewpoint. The way in which the background changes (within the circular region as well as outside it) between (a) and (b) reveals that there is indeed a transparent sphere placed in front of the painting and compositing purposes. Wexler et al. [13] have extended this idea to obtain the environment matting model from uncontrolled backgrounds. Matusik et al. [8] use environment mattes obtained from multiple viewpoints to create novel views by interpolation. Note that these methods do not address the problem of explicit shape and pose estimation; in fact, they have been designed to avoid this problem. An interesting approach was proposed by Murase [9], where the shape of the surface of pool of water is recovered from the way it refracts the texture of the bottom of the pool. More recently, Saito et al. [12] proposed a very novel method for recovering the surface of a transparent object using polarized light. Hata et al. [5] used structured light and genetic algorithms to find the shapes of transparent objects such as paste drops. Other controlled methods, such as ones that use hologram laser lighting, have also been suggested [11, 2]. A similar problem, addressed in photogrammetry, arises when measuring objects through transparent multimedia, usually objects immersed in liquids [7]. In this paper, we explore what can be said about transparent objects by a moving observer. Figure 1(b) is another image of the scene in Figure 1(a), taken from a different viewpoint. The manner in which the background changes (within the circular region as well as outside it) with viewpoint confirms that there is indeed a transparent sphere placed in front of the painting. We show that it is possible to estimate the shapes of transparent objects immersed in an environment of unknown structure from a sequence of images taken during known camera motion. Our algorithm is a model-based Proceedings of the Ninth IEEE International Conference on Computer Vision (ICCV 2003) 2-Volume Set 0-7695-1950-4/03 $17.00 © 2003 IEEE one in that it assumes a parametric form for the shapes of the transparent objects, and estimates the shape parameters from the motion of features within the image of the object. Since the parametric model used is not restricted to any particular form, the algorithm can be used for a wide class of shapes. We have used simulations to extensively test the performance of algorithm. In addition, we have conducted several experiments with real objects. The objects we have used in our simulations and experiments have simple shapes. It is important to note, however, that the even for a very simple shape the underlying problem is hard as it involves highly non-linear interactions between light rays and the object surfaces. The most difficult case we have tried is the estimation of the shape parameters and the pose of a pipe filled with water; this is a very complex case as each light ray is subjected to four refractions through three media with different refractive indices. We view the results of this paper as an important initial step towards developing a general framework for the perception of transparency. 2 The Physics of Transparency Figure 2 shows a transparent object with refractive index μ2 immersed in a transparent medium with refractive index μ1, where μ1 < μ2. A ray of light that passes though the transparent object interacts with it at two interfaces, upon entrance and exit. At the first interface, a fraction of the ray is reflected and another fraction is refracted1. The angles (θ1, θ2) between the incident and the reflected rays relative to the normal N1 are equal, and the angles (θ1, θ3) of the incident and refracted rays relative to N1 are given by Snell’s law: μ1 sin θ1 = μ2 sin θ3. (1) The same relations hold for the second interface as well. For μ1 < μ2 there exists a value α = sin−1 μ1 μ2 which is called the critical angle. When φ1 > α a complete reflection of the ray occurs at the second interface (the ray does not pass through the interface), a condition known as total internal reflection. It is worth noting that the complete path of light from the source to the observer (including the incident ray, refracted ray at the first interface and the refracted ray at the second interface) is not restricted to lie on a plane. 3 Real and Virtual Features Classical vision algorithms, such as stereo and structure from motion, are based on the assumption that image features correspond to scene features that are rigidly attached 1As the ray passes through the object, some fraction of its energy may be absorbed as well. The exact fractions that are reflected, refracted and absorbed depend on the Fresnel coefficients [1] and the absorption coefficient of the object. These fractions are not important as long as the ray has sufficient energy left in it when it leaves the object at the second interface. By sufficient energy we mean that the scene point it represents produces a detectable brightness in the image. All we require in our approach is that at least some of features in the background can be detected in the image after they pass through the object. 3 1 1	autostereogram;coefficient;compositing;computer vision;emoticon;experiment;genetic algorithm;graphics;holography;ibm notes;iccv;image plane;interaction;interpolation;itakura–saito distance;map;nonlinear system;parametric model;paste;photogrammetry;polarization (waves);ray (optics);simulation;structure from motion;structured light;uncontrolled format string	Moshe Ben-Ezra;Shree K. Nayar	2003		10.1109/ICCV.2003.1238462	computer vision;machine vision;feature extraction;computer science;cognitive neuroscience of visual object recognition;multimedia;refractive index;transparency;motion compensation;feature;photogrammetry;computer graphics (images);visual inspection	Vision	60.04112271191176	-52.39473334918225	46720
ccc59d3bd1f32137c8e3fe591e85189dc2b29d75	underwater image super-resolution by descattering and fusion	databases;image resolution underwater imaging noise reduction databases image color analysis scattering resolution;resolution;image resolution;scattering;image fusion underwater imaging descattering super resolution;image resolution convex programming image colour analysis image fusion;image color analysis;underwater imaging;noise reduction;final hr image underwater image super resolution image fusion color distortion contrast distortion image preprocessing descattering algorithm high turbidity underwater image sr algorithm convex fusion rule	Underwater images are degraded due to scatters and absorption, resulting in low contrast and color distortion. In this paper, a novel self-similarity-based method for descattering and super resolution (SR) of underwater images is proposed. The traditional approach of preprocessing the image using a descattering algorithm, followed by application of an SR method, has the limitation that most of the high-frequency information is lost during descattering. Consequently, we propose a novel high turbidity underwater image SR algorithm. We first obtain a high resolution (HR) image of scattered and descattered images by using a self-similarity-based SR algorithm. Next, we apply a convex fusion rule for recovering the final HR image. The super-resolved images have a reasonable noise level after descattering and demonstrate visually more pleasing results than conventional approaches. Furthermore, numerical metrics demonstrate that the proposed algorithm shows a consistent improvement and that edges are significantly enhanced.	algorithm;distortion;image resolution;noise (electronics);numerical analysis;numerical method;preprocessor;self-similarity;super-resolution imaging	Huimin Lu;Yujie Li;Shota Nakashima;Hyoungseop Kim;Seiichi Serikawa	2017	IEEE Access	10.1109/ACCESS.2017.2648845	computer vision;resolution;image resolution;computer science;noise reduction;scattering;computer graphics (images)	Vision	58.10162902185226	-61.019916032080175	46826
65917cd596984f8813c4c3b0ffcb7a60f9957493	development of saliency-based seamless image compositing using hybrid blending (ssichb)		With the advancement in computer vision and graphics tools, digital compositing has become an integral part of the present computer-generated visual effects. However, factors such as inaccurate mask generation, intensive user interaction, and the creation of boundary seams due to colour or texture difference, make it hard to achieve quality composites. Poisson editing efficiently generates seamless composites but results in undesirable colour bleeding. Multi-resolution blending, in contrast, produces colour consistent composites; however often introduces blurry boundaries around the source object inserted. Motivated by these observations, the authors propose a colour consistent seamless compositing pipeline by integrating two new approaches. First, the authors use a visual attention algorithm based on the colour difference with increased edge weight using Gaussian filter bank (GFB) to ensure the least user interaction during mask generation. Second, the authors propose a hybrid framework by incorporating the goodness of the two different blending methods namely modified Poisson editing (MPE) and GFB-based multi-resolution blending to create colour consistent seamless composites. An extensive experiment has been carried out on challenging datasets to validate the proposed technique. Comparison with the state-of-the-art techniques shows the efficacy of the authors’ algorithm in generating colour consistent, seamless, and natural-looking composites for present image editing applications.	algorithm;alpha compositing;color bleeding (computer graphics);computer vision;computer-generated holography;filter bank;floor and ceiling functions;graphics;html5 in mobile devices;image editing;mask data preparation;seamless3d;visual effects	Achala Pandey;Umesh Chandra Pati	2017	IET Image Processing	10.1049/iet-ipr.2016.0754	computer vision;computer graphics (images)	Graphics	59.73689580103682	-61.07266928339594	46839
3307312b58882262fd26df043c450d64e4d5819f	the role of contrast in the perceived depth of monocular imagery	contrast sensitivity function;gaze contingent display;visual cues;natural vision;high dynamic range;binocular disparity	There are many visual cues that provide sensations of depth or distance in our observations of real-world 3D scenes as well as 2D images. In the latter case, these cues are monocular in that the images appear the same to both retinae and do not have binocular disparity that can be used to form depth judgments. Examples include perspective, relative sizes of objects, familiarity with sizes of objects, occlusion, contrast, brightness, color saturation, and haze. Contrast and brightness are of particular interest to us since they can be manipulated through a much greater range on high dynamic range displays than is possible on conventional displays.	binocular disparity;high dynamic range	Allan G. Rempel;Wolfgang Heidrich;Rafal Mantiuk	2011		10.1145/2077451.2077478	binocular disparity;computer vision;sensory cue;computer science	Vision	56.30591190364734	-53.34170253998575	46852
e558b0d57a96e629dee3cad75d6cd4227f7f2f1b	four-component scattering power decomposition algorithm with rotation of covariance matrix using alos-palsar polarimetric data	scattering power decomposition;radar polarimetry;polarimetric synthetic aperture radar polsar;covariance matrix rotation	The present study introduces the four-component scattering power decomposition (4-CSPD) algorithm with rotation of covariance matrix, and presents an experimental proof of the equivalence between the 4-CSPD algorithms based on rotation of covariance matrix and coherency matrix. From a theoretical point of view, the 4-CSPD algorithms with rotation of the two matrices are identical. Although it seems obvious, no experimental evidence has yet been presented. In this paper, using polarimetric synthetic aperture radar (POLSAR) data acquired by Phased Array L-band SAR (PALSAR) on board of Advanced Land Observing Satellite (ALOS), an experimental proof is presented to show that both algorithms indeed produce identical results.	algorithm;aperture (software);l band;oblique projection;phased array;polarimetry;polarization (waves);radar;randomness;synthetic data;turing completeness	Mitsunobu Sugimoto;Kazuo Ouchi;Yasuhiro Nakamura	2012	Remote Sensing	10.3390/rs4082199	optics;remote sensing	ML	78.67041869570397	-66.61346667504063	47077
6d6716d5accc0b37024ea490083a411bdd792528	synthetic image super resolution using featurematch	supercomputer education research centre;patchmatch;approximate nearest neighbour field;synthetic images;super resolution	In this paper, we propose a super resolution (SR) method for synthetic images using FeatureMatch. Existing state-of-the-art super resolution methods are learning based methods, where a pair of low-resolution and high-resolution dictionary pair are trained, and this trained pair is used to replace patches in low-resolution image with appropriate matching patches from the high-resolution dictionary. In this paper, we show that by using Approximate Nearest Neighbour Fields (ANNF), and a common source image, we can by-pass the learning phase, and use a single image for dictionary. Thus, reducing the dictionary from a collection obtained from hundreds of training images, to a single image. We show that by modifying the latest developments in ANNF computation, to suit super resolution, we can perform much faster and more accurate SR than existing techniques. To establish this claim we will compare our algorithm against various state-of-the-art algorithms, and show that we are able to achieve better and faster reconstruction without any training phase.	algorithm;autostereogram;computation;continuation;dictionary;image resolution;nearest neighbor search;peak signal-to-noise ratio;projection screen;real-time clock;strips;structural similarity;super-resolution imaging;synthetic data;synthetic intelligence	S. Avinash Ramakanth;R. Venkatesh Babu	2014	Multimedia Tools and Applications	10.1007/s11042-014-1925-2	computer vision;computer science;machine learning;superresolution;computer graphics (images)	Vision	56.26171232511966	-54.19708986444179	47108
3e77117e5ff402b504c624765fd75fa3a73d89d2	visibility of wavelet quantization noise	image sampling;transformation ondelette;wavelet analysis;quantization;female;errors;transformations mathematics;noise threshold;mathematics;cuantificacion;females;image coding;discrete wavelet transform;modele mathematique;image processing;image resolution;data compression;models theoretical;quantization noise;display devices;umbral deteccion;coding errors;nasa discipline space human factors;male;compresion senal;procesamiento imagen;modelo matematico;indexing terms;quantification;image processing computer assisted;traitement image;compression signal;noise measurement;color perception;image resolution wavelet transforms image coding data compression coding errors quantisation signal noise filtering theory energy level crossing adaptive signal processing image sampling;quantisation signal;detection threshold;wavelet transforms;data display;males;quantization discrete wavelet transforms frequency image coding noise level colored noise chromium displays spatial resolution lattices;adaptive signal processing;adults;visibility;adaptive quantization wavelet quantization noise visibility discrete wavelet transform spatial frequency spatial orientation image compression dwt quantization errors optimal compression uniform quantization coefficients dwt uniform quantization noise random amplitude basis functions dwt synthesis filter visual detection thresholds color channels display visual resolution mathematical model perceptually lossless quantization matrix visual threshold;image compression;mathematical models;support u s gov t non p h s;error cuantificuacion;adult color perception data display female humans image processing computer assisted male mathematics models theoretical visual perception;adult;signal compression;human;mathematical model;visual perception;seuil detection;transformacion ondita;nasa center arc;energy level crossing;erreur quantification;models;filtering theory;spatial frequency;wavelet transformation;bruit quantification;noise;quantization error	"""The discrete wavelet transform (DWT) decomposes an image into bands that vary in spatial frequency and orientation. It is widely used for image compression, measures of the visibility of DWT quantization errors are required to achieve optimal compression. Uniform quantization of a single band of coefficients results in an artifact that we call DWT uniform quantization noise; it is the sum of a lattice of random amplitude basis functions of the corresponding DWT synthesis filter. We measured visual detection thresholds for samples of DWT uniform quantization noise in Y, Cb, and Cr color channels. The spatial frequency of a wavelet is r2/sup -/spl lambda//, where r is the display visual resolution in pixels/degree, and /spl lambda/ is the wavelet level. Thresholds increase rapidly with wavelet spatial frequency. Thresholds also increase from Y to Cr to Cb, and with orientation from lowpass to horizontal/vertical to diagonal. We construct a mathematical model for DWT noise detection thresholds that is a function of level, orientation, and display visual resolution. This allows calculation of a """"perceptually lossless"""" quantization matrix for which all errors are in theory below the visual threshold. The model may also be used as the basis for adaptive quantization schemes."""	area striata structure;bands;basis function;channel (digital image);chromium;coefficient;discrete wavelet transform;hearing loss, high-frequency;image compression;lossless compression;low-pass filter;mathematical model;pixel;quantization (image processing);quantization (signal processing)	Andrew B. Watson;Gloria Y. Yang;Joshua A. Solomon;John D. Villasenor	1997	IEEE Transactions on Image Processing	10.1109/83.605413	computer vision;speech recognition;quantization;image processing;computer science;mathematics;quantization;algorithm;statistics	Vision	62.20566674142542	-62.16454115952493	47138
04309f0f99949d18d97d780a3534e05f61dd9b2b	reconstruction for spatially distributed single-pixel imaging based on pattern filtering		We propose an image sensing scheme using tiny spatially distributed sensor nodes in conjunction with compressive sampling. This scheme permits fast image acquisition due to simultaneous photographing at each node and size reduction of the sensor nodes due to a simple imaging architecture. Analysis suggests that reconstruction error occurs because different scenes are taken at each node. To address this issue, we introduce two filtering processes in the reconstruction: 1) a reduced-randomized filter; and 2) an unbiased filter. The reconstruction examples demonstrate that such filtering processes effectively reduce the error. The proposed method is potentially useful in forthcoming sensors based on ultrasmall-scale devices.	compressed sensing;pixel;randomized algorithm;sampling (signal processing);sensor	Tatsuya Nobunaga;Hiroya Tanaka;Yukihiro Tadokoro	2018	IEEE Signal Processing Letters	10.1109/LSP.2018.2816579	compressed sensing;artificial intelligence;iterative reconstruction;mathematics;pixel;pattern recognition;filter (signal processing);radio frequency;architecture	Vision	70.03022629520675	-70.35332599351626	47281
74a2d29b366baed416b538d928773d5cdc2030f6	total variation based wavelet domain filter for image denoising	gaussian noise;inverse wavelet transform;additive white gaussian noise;discrete wavelet transform;psnr;peak signal to noise ratio wavelet domain filter image denoising additive white gaussian noise single decomposed noisy image wavelet coefficients hl subband inverse wavelet transform;edge detection;wavelet domain filter;filters;awgn;wavelet transforms awgn edge detection filtering theory image denoising;noise measurement;peak signal to noise ratio gaussian noise total variation discrete wavelet transform;wavelet transforms;wavelet transform;image edge detection;peak signal to noise ratio;hl subband;additive white noise;total variation;image denoising;wiener filter;tv;wavelet domain;article;wiener filter tv image edge detection noise noise measurement psnr wavelet domain;single decomposed noisy image;wavelet coefficients;filtering theory;noise	In this paper the method total variation (TV) is applied on noisy image decomposed in wavelet domain for removal of additive white gaussian noise (AWGN). LL subband of a single decomposed noisy image is used to find the horizontal, vertical and diagonal edges. Using the pixel position of horizontal edges, the corresponding wavelet coefficients in HL subband is retained thresholding others to zero. Adopting the same procedure the vertical and diagonal details of LH and HH subband is retained. The method TV is applied to LL subband for one iteration only. Applying inverse wavelet transform on modified wavelet coefficients we get back the image with little noise. This little noise can be removed using TV filter with single iteration. The method performs well in terms of peak signal to noise ratio (PSNR) over many well known spatial and wavelet domain methods. The method also retains the edges and other detailed information very well.	additive white gaussian noise;coefficient;experiment;horseland;iteration;lh (complexity);ll parser;least mean squares filter;noise reduction;peak signal-to-noise ratio;pixel;thresholding (image processing);utility functions on indivisible goods;wavelet transform;wiener filter	Nilamani Bhoi;Sukadev Meher	2008	2008 First International Conference on Emerging Trends in Engineering and Technology	10.1109/ICETET.2008.6	mathematical optimization;electronic engineering;speech recognition;mathematics;wavelet packet decomposition;stationary wavelet transform	Robotics	56.22907931215457	-66.65957404681875	47330
3d4634f175c8386c34a4ac02da867d02a2856ade	coastal ship monitoring based on multiple compact high frequency surface wave radars		Recently, due to wide observable range as well as low power consumption, the usage of high frequency radars has been expanded to ship detection for both harbor management and national security. However, range and angular resolutions are typically low in high frequency radars due to environmental and physical constraints. Thus, a target location detected on a high frequency radar system is far away from its real position. To reduce the error of detection, a location estimation method is proposed based on multiple high frequency radars. With use of the Bayesian approach, a more accurate final location can be determined by posterior mean. For this work, both likelihood and prior probability are modelled. Effectiveness of the proposed method is shown through appropriate simulation that was conducted according to signal to clutter plus noise ratio. Results are shown to verify the proposed method improves both locating and detecting performances.	angularjs;clutter;location-based service;observable;performance;radar;sensor;simulation;surface wave	Sangwook Park;Chul Jin Cho;Younglo Lee;Andrew Da Costa;Sangho Lee;Hanseok Ko	2017	2017 IEEE International Conference on Multisensor Fusion and Integration for Intelligent Systems (MFI)	10.1109/MFI.2017.8170381	computer vision;artificial intelligence;mixture model;radar;computer science;prior probability;observable;clutter;surface wave;bayesian probability	Robotics	75.48735406980919	-64.41457727718134	47338
cb59673080840635b8b6cc6356f3c8e38df44bd7	parallelized matrix factorization for fast btf compression	matrix factorization;and texture g 4 mathematics of computing mathematical software parallel and vector implementations;categories and subject descriptors according to acm ccs i 3 7 computer graphics three dimensional graphics and realism color;shadowing;shading	Dimensionality reduction methods like Principal Component Analysis (PCA) have become commonplace for the compression of large datasets in computer graphics. One important application is the compression of Bidirectional Texture Functions (BTF). However, the use of such techniques has still many limitations that arise from the large size of the input data which results in impractically high compression times. In this paper, we address these shortcomings and present a method which allows for efficient parallelized computation of the PCA of a large BTF matrix. The matrix is first split into several blocks for which the PCA can be performed independently and thus in parallel. We scale the single subproblems in such a way, that they can be solved in-core using the EM-PCA algorithm. This allows us to perform the calculation on current GPUs exploiting their massive parallel computing power. The eigenspaces determined for the individual blocks are then merged to obtain the PCA of the whole dataset. This way nearly arbitrarily sized matrices can be processed considerably faster than by serial algorithms. Thus, BTFs with much higher spatial and angular resolution can be compressed in reasonable time.	angularjs;bidirectional texture function;cuda;central processing unit;computation;computer graphics;dimensionality reduction;expectation–maximization algorithm;graphics processing unit;linear algebra;load balancing (computing);out-of-core algorithm;parallel computing;principal component analysis;the matrix;time complexity	Roland Ruiters;Martin Rump;Reinhard Klein	2009		10.2312/EGPGV/EGPGV09/025-032	shading;parallel computing;computer science;theoretical computer science;operating system;matrix decomposition;algorithm;computer graphics (images)	HPC	69.89446929966093	-53.767232212134836	47425
eb5ce2327ba06a0f29a80c1301c07e1cbf2961da	a simple positional accuracy measure for linear features		In this paper we propose a simple technique for assessing the positional accuracy of digitized linear features. The approach relies on a comparison with a representation of higher accuracy, and estimates the percentage of the total length of the low accuracy representation that is within a speci® ed distance of the high accuracy representation. The approach deals successfully with three de® ciencies of other methods: it is statistically based; is relatively insensitive to extreme outliers; and does not require matching of points between representations. It can be implemented using standard functions and a standard scripting language in any raster or vector GIS. We present the results of a test using data from the Digital Chart of the World.	digital chart of the world;geographic information system;naruto shippuden: clash of ninja revolution 3;raster graphics;robustness (computer science);scripting language	Michael F. Goodchild;Gary J. Hunter	1997	International Journal of Geographical Information Science	10.1080/136588197242419	econometrics;data mining;mathematics;statistics	Vision	76.33098065738875	-55.07034347233332	47426
d0dc0d7d7438a5bbf68e0421ca8fbff17e40d670	a novel spectral similarity measure approach based on set operations and spectral polygon	wavelength measurement;information extraction;image classification;data mining;magnesium compounds;pixel;indexation;spectral information divergence;image analysis;spectral properties;magnesium compounds hyperspectral imaging image classification image analysis spectral analysis image retrieval data mining encoding pixel wavelength measurement;spectral analysis;hyperspectral imaging;correlation coefficient;encoding;similarity measure;coordinate system;image retrieval	-Based on the analysis to spectral curve in hyperspectral RS image, the concept of spectral polygon was proposed. After that, similarity measure of two sets based on set operations was discussed and some useful indexes for similarity and dissimilarity were designed. Finally a novel spectral similarity measure approach based on set operations and spectral polygon was proposed and experimented. In this new approach, the spectral curve or spectral vector was used to create a spectral polygon, and similarity measure between two spectral vectors was transformed to similarity measure between two polygon sets. In order to quantify the sets, area was computed and used to further processing and a rapid computing scheme was used. It proved that the new approach based on set operations and spectral polygon was effective to spectral similarity measure and can be used to hyperspectral RS image classification, retrieval and other processes. Spectral similarity measure in hyperspectral RS image is the basis of image classification, information extraction and other applications. Nowadays, some similarity measure methods including Euclidian distance, spectral angle, correlation coefficient, spectral information divergence (SID), encoding and matching and others are used in common, and each has its advantages and disadvantages. In order to improve the precision and efficiency of similarity measure, it is necessary to research and put forward some new methods. In this paper, a new approach based on set operation and spectral polygon will be proposed and experimented. I. SPECTRAL POLYGON IN HYPERSPECTRAL RS When one pixel is expressed by original spectral vector, this vector can be demonstrated by a spectral curve in the coordinate system with wavelength as horizontal axis and albedo as vertical axis in Figure (1). From Figure 1, we can know that a polygon can be formed by spectral curve, horizontal axis and two lines parallel vertical axis and crossing the first and last wavelength points. Here, this polygon is named as spectral polygon. Different ground objects or pixels in image have distinct spectral curves, and their spectral polygons are distinct, so some quantitative properties of spectral polygon can be used to describe the spectral properties of ground objects. II. SIMILARITY MEASURE BASED ON SET OPERATIONS It is known that similarity measure is the operation to compare the similarity of two sets and express it with a quantitative index in essence. Similarity of two sets can be analyzed by some set relationship and set operation. Suppose that A and B are two sets that will be compared, some new sets such as B AU , B AI , B A I , B AI , B A I can be generated by specific operation. For every set X, a function M(X) used to describe properties of X quantitatively can be defined so a set can be expressed by some quantitative indexes, and relationship between different sets can be analyzed by those indexes. Here, function M(X) is very important to the results and efficiency. For two definite sets A and B, B A I is an unlimited set generally, so ) ( B A M I is useless in practice and it isn’t adopted in further analysis. In addition, it can be known according to set theory that ) ( ) ( ) ( B A B A U B A B A I U I I U = and B AI , B A I 和 B AI are independent each other, so it can be drawn that ) ( B A M U = ) ( B A M I + ) ( B A M I + ) ( B A M I . Therefore, seven useful indexes can be used in further analysis . Those are: ) ( 1 B A M M I = (1) ) ( 2 B A M M I = (2) ) ( 3 B A M M I = (3) Figure 1 Spectral curve and Spectral polygon 4319 0-7803-9050-4/05/$20.00 ©2005 IEEE. 4319 ) ( ), ( ( 4 B M A M Min Min M = = (4) )) ( ), ( ( 5 B M A M Max Max M = = (5) ) ( ) ( 6 B M A M Sum M + = = (6) = 7 M ) ( B A M U = 3 2 1 M M M + + (7) According to Stephan Winter’s studies on region-based similarity and our analysis and experiments, the following indexes are effective to measure similarity between two sets : 7 1 1 / M M = μ . Its domain is [0,1]. When A is same to B, the result equals 1. 4 1 2 / M M = μ . Its domain is [0, 1]. When one polygon is within the other, the result is 1. 5 1 3 / M M = μ . Its domain is [0,1]. When A is same to B, the result equals 1. 6 1 4 / M M = μ . Its domain is [0,0.5]. When A is same to B, the result equals 0.5. And the following are useful to measure dissimilarity: 1 7 3 2 1 1 / ) ( μ − = + = M M M d 5 3 2 2 / ) ( M M M d + = 6 3 2 3 / ) ( M M M d + = It can be seen that the key factor to similarity is 1 M , or quantitative value of intersected set, and the key index to dissimilarity is 2 M and 3 M , so those indexes can be combined to define a new similarity measure index as follows: 3 2 1 1 1 1 M M M d s + = = μ (8) The bigger the index is, the more similar the two sets are. For two identical sets, this index is infinity because the denominator is zero. III. SPECTRAL SIMILARITY MEASURE BASED ON SET OPERATIONS AND SPECTRAL POLYGON Therefore, similarity measure of two spectral vectors is transformed into similarity measure of two spectral polygons, and area is selected to quantify properties of spectral polygon. That means area computation is selected as quantification function M(), and M1, M2, M3, M4, M5, M6 and M7 can be calculated. According to former discussions, M1, M2 and M3 are enough here. Although spectral polygon is irregular in shape, it is composed by N-1 trapezoids (N is the band number of hyperspectral RS image) and each trapezoid can be viewed as a sub spectral polygon. Each trapezoid is composed of the wavelength of two adjacent bands and their albedo, and its area is easy to compute by 2 / ) ( * ) ( 1 1 i i i i i S λ λ ρ ρ − + = + + (i=0,1, ... , N-2), and area of the spectral polygon can be calculated by ∑ = i S S . So the key is to compute area of every trapezoid. For two adjacent bands, the spatial relationships between two different spectral curves include four cases demonstrated in Figure 2. In the following, S (A) is the area of the trapezoid composed of the ith and (i+1)th band in spectral vector A, and S (B) is the area of corresponding polygon in spectral vector B. Case (I) is characterized by Ai < Bi and Ai+1 < Bi+1, so: M1 = S(A); M2 = O; M3 = S(B)-S(A). Case (II) is characterized by Ai < Bi and Ai+1 > Bi+1. In order to compute M1, M2 and M3, the intersected point of two lines should be computed at first. Suppose that the intersected point is (λ0,ρ0), so: M1 = (ρ0+ Ai) * (λ0 –λi) / 2 + (ρ0+ Bi+1) * (λi+1 –λ 0) / 2; M2 = (Ai+1 Bi+1) * (λi+1 –λ0) / 2; M3 = (Bi –Ai) * (λ0 –λi) / 2. Case (III) is characterized by Ai > Bi and Ai+1 > Bi+1, so: M1 = S(B); M2 = S(A) – S(B); M3 = O. λ ρ	ai-complete;artificial intelligence;coefficient;computation;computer vision;emoticon;euclidean distance;experiment;fuzzy set operations;information extraction;optic axis of a crystal;pixel;quantitative structure–activity relationship;reed–solomon error correction;set theory;similarity measure	Peijun Du;Yunhao Chen	2005	Proceedings. 2005 IEEE International Geoscience and Remote Sensing Symposium, 2005. IGARSS '05.	10.1109/IGARSS.2005.1525874	computer vision;contextual image classification;image analysis;image retrieval;computer science;hyperspectral imaging;coordinate system;pattern recognition;mathematics;information extraction;information retrieval;pixel;encoding;remote sensing	Vision	54.32657361971197	-62.205172004990224	47508
743d98ef35f34afb54ce29beac4fd5944522a4f0	natural calamity assessment by innovative methods		The earth is a dynamic entity that is undergoing changes all the time. However, sometimes the forces of nature cause great and drastic changes, and human beings and the effect can be disastrous. Though these disasters cannot be stopped, their damages can be minimized with proper management measures. To take up effective management and effective measures, there has to be efficient disaster assessment. Assessment is a vital component of the planning and implementation of the response to disasters. The phrase disaster assessment refers to the investigation and data collection activities carried out to conclude the outcome of disaster and area of disaster hit area. Here, we propose an algorithm that uses satellite images for assessing the disaster impact. The satellite images of flood affected region are collected from BHUVAN (ISRO), while data for fire affected region is collected from NASA associated official web source. We have compared our results with the government records to validate our proposed methodology. Accuracy is calculated and compared with conventional methods.	algorithm;bhuvan	Anish Kumar;Arpita Naganur;Nikhil Horakeri;K. Sumant;Shrinivas D. Desai	2017	2017 International Conference on Advances in Computing, Communications and Informatics (ICACCI)	10.1109/ICACCI.2017.8126049	data collection;control engineering;computer science;data mining;damages;data modeling;synthetic aperture radar;government	SE	81.96560422508973	-55.3986151912615	47511
8aac31783fafae833ce579e8e0d02008aa45e221	a particle swarm optimizer applied to soft morphological filters for periodic noise reduction	soft morphological filter;mathematical morphology;liverpool;least mean square;image processing;fourier transform;repository;particle swarm optimizer;noise reduction;spatial filtering;university;periodic noise	The removal of periodic noise is an important problem in image processing. To avoid using the time-consuming methods that require Fourier transform, a simple and efficient spatial filter based on soft mathematical morphology (MM) is proposed in this paper. The soft morphological filter (Soft MF) is optimized by an improved particle swarm optimizer with passive congregation (PSOPC) subject to the least mean square error criterion. The performance of this new filter and its comparison with other commonly used filters are also analyzed, which shows that it is more effective in reducing both periodic and non-periodic noise meanwhile preserving the details of the original image.	mathematical optimization;noise reduction;swarm	Tianyao Ji;Z. Lu;Q. Henry Wu	2007		10.1007/978-3-540-71805-5_40	median filter;mathematical optimization;electronic engineering;simulation;engineering	EDA	57.89177737654021	-67.4840551533179	47520
3090aa2f4d3adacc53d634c4576f94d39e93a49c	spatial and temporal distribution of multiple cropping indices in the north china plain using a long remote sensing data time series	glass lai;multiple cropping index;spatial and temporal changes;remote sensing;ncp	Multiple cropping provides China with a very important system of intensive cultivation, and can effectively enhance the efficiency of farmland use while improving regional food production and security. A multiple cropping index (MCI), which represents the intensity of multiple cropping and reflects the effects of climate change on agricultural production and cropping systems, often serves as a useful parameter. Therefore, monitoring the dynamic changes in the MCI of farmland over a large area using remote sensing data is essential. For this purpose, nearly 30 years of MCIs related to dry land in the North China Plain (NCP) were efficiently extracted from remotely sensed leaf area index (LAI) data from the Global LAnd Surface Satellite (GLASS). Next, the characteristics of the spatial-temporal change in MCI were analyzed. First, 2162 typical arable sample sites were selected based on a gridded spatial sampling strategy, and then the LAI information was extracted from the samples. Second, the Savizky-Golay filter was used to smooth the LAI time-series data of the samples, and then the MCIs of the samples were obtained using a second-order difference algorithm. Finally, the geo-statistical Kriging method was employed to map the spatial distribution of the MCIs and to obtain a time-series dataset of the MCIs of dry land over the NCP. The results showed that all of the MCIs in the NCP showed an increasing trend over the entire study period and increased most rapidly from 1982 to 2002. Spatially, MCIs decreased from south to north; also, high MCIs were mainly concentrated in the relatively flat areas. In addition, the partial spatial changes of MCIs had clear geographical characteristics, with the largest change in Henan Province.	avian crop;cns disorder;concentrate dosage form;decision making;experiment;extraction;geographic information system;hypothalamic area, lateral;kriging;land administration;largest;longest common subsequence problem;maximal set;multiple myeloma;national cancer program;population parameter;sampling (signal processing);scott continuity;silo (dataset);smoothing (statistical technique);spatial analysis;time series;algorithm;remote sensing;sensor (device)	Yan Zhao;Linyan Bai;Jianzhong Feng;Xiaosong Lin;Li Wang;Lijun Xu;Qiyun Ran;Kui Wang	2016		10.3390/s16040557	network control program;computer science;remote sensing	HCI	82.15571503534231	-56.73152160031914	47603
f93f4f809039791ab4e731e0fbd84b253a209359	aquatic vegetation indices assessment through radiative transfer modeling and linear mixture simulation	wavi;vegetation indices;radiative transfer models;sensitivity analysis;remote sensing;ndavi	Although spectral vegetation indices (VIs) have been widely used for remote sensing of vegetation in general, such indices have been traditionally targeted at terrestrial, more than aquatic, vegetation. This study introduces two new VIs specifically targeted at aquatic vegetation: NDAVI and WAVI and assesses their performance in capturing information about aquatic vegetation features by comparison with preexisting indices: NDVI, SAVI and EVI. The assessment methodology is based on: (i) theoretical radiative transfer modeling of vegetation canopy-backgrounds coupling, and (ii) spectral linear mixture simulation based on real-case endmembers. Two study areas, Lake Garda and Lakes of Mantua, in Northern Italy, and a multisensor dataset have been exploited for our study. Our results demonstrate the advantages of the new indices. In particular, NDAVI and WAVI sensitivity scores to LAI and LIDF parameters were generally higher than pre-existing indices’ ones. Radiative transfer modeling and real-case based linear mixture simulation showed a general positive, non-linear correlation of vegetation indices with increasing LAI and vegetation fractional cover (FC), more marked for NDVI and NDAVI. Moreover, NDAVI and WAVI show enhanced capabilities in separating terrestrial from aquatic vegetation response, compared to pre-existing indices, especially of NDVI. The new indices provide good performance in distinguishing aquatic from terrestrial vegetation: NDAVI over low density vegetation (LAI < 0.7–1.0, FC < 40–50%), and WAVI over medium-high density vegetation (LAI > 1.0, FC > 50%). Specific vegetation indices can therefore improve remote sensing egeta applications for aquatic v	aquatic ecosystem;motorola canopy;nonlinear system;simulation;terrestrial television	Paolo Villa;Alijafar Mousivand;Mariano Bresciani	2014	Int. J. Applied Earth Observation and Geoinformation	10.1016/j.jag.2014.01.017	enhanced vegetation index;geology;hydrology;ecology;sensitivity analysis;remote sensing	EDA	82.72674708719244	-58.46905784831483	47612
f47a60472e0801a4b7b40212a6da0ae8efa9e80f	2009 earthquakes in sumatra: the use of l-band interferometry in a sar-hostile environment	earthquake damage assessment;damage assessment;sumatra earthquakes;terrain factors;sar hostile environment;scanning tunnelling microscopy dynamic testing quantum cascade lasers rectangular waveguides;seismic geological phenomena;earthquakes coherence terrain factors orbits interferometry clouds cities and towns;ad 2009 09 30;seismic geological phenomena sumatra earthquakes l band interferometry sar hostile environment ad 2009 09 30 padang ad 2009 10 01 aftershock event seismic activity earthquake damage assessment;earthquakes;seismic activity;aftershock event;orbits;scanning tunnelling microscopy;clouds;padang;cities and towns;coherence;interferometry;quantum cascade lasers;ad 2009 10 01;dynamic testing;rectangular waveguides;l band interferometry	L-band interferometry is a useful tool to help the study of earthquakes and the assessment of the resultant damage in tropical regions. It can be used at different levels: using only the coherence or fully processing the differential interferogram.	l band;resultant	Emmanuel Christophe;Aik Song Chia;Tiangang Yin;Leong Keong Kwoh	2010	2010 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2010.5654173	seismology;coherence;geology;interferometry;dynamic testing;geotechnical engineering;physics;quantum mechanics;remote sensing	Embedded	80.19816535320221	-63.1824407272544	47634
cb3cf6e6488a1f2e120744c9082c6f3ccbbc9d80	multisource classification using icm and dempster-shafer theory	classification algorithm;image processing;iterated conditional mode;radar image classification;fuses;bayes methods;bayesian methods;image classification;laser radar;uncertainty handling;data fusion;radar image classification multisource classification icm dempster shafer theory bayesian decisions evidential reasoning markovian classification algorithm multiscale iterated conditional mode algorithm dempster shafer combination rule decision fusion multisource local spatial neighborhood noisy image classification data fusion remote sensing;indexing terms;multiscale iterated conditional mode algorithm;laser radar bayesian methods classification algorithms fuses pixel radar imaging optical sensors mathematical model remote sensing image processing;evidential reasoning;iterative methods;bayesian decisions;multisource local spatial neighborhood;remote sensing;radar imaging;pixel;dempster shafer theory;markovian classification algorithm;classification algorithms;decision fusion;mathematical model;dempster shafer;optical sensors;radar imaging image classification uncertainty handling markov processes bayes methods sensor fusion iterative methods;markov processes;noisy image classification;sensor fusion;dempster shafer combination rule;icm;multisource classification	We propose to use evidential reasoning in order to relax Bayesian decisions given by a Markovian classification algorithm (ICM). The Dempster–Shafer rule of combination enables us to fuse decisions in a local spatial neighborhood which we further extend to be multisource. This approach enables us to more directly fuse information. Application to the classification of very noisy images produces interesting results.	algorithm;iterated conditional modes	Samuel Foucher;Mickaël Germain;Jean-Marc Boucher;Goze B. Bénié	2002	IEEE Trans. Instrumentation and Measurement	10.1109/19.997824	computer vision;dempster–shafer theory;image processing;computer science;machine learning;pattern recognition;mathematics;sensor fusion;statistics	ML	71.42930766632152	-61.68246824228433	47767
871c68eb4327870ac2f9a7ae215c36fd99e5f3fd	on the effect of number and distribution of acquisitions in l-band sar tomography for forest structure estimation		Synthetic Aperture Radar Tomography techniques provide 3D information of the forest due to the ability of microwaves to penetrate through vegetation. Recent studies link the radar 3D information to forest 3D structure in order to translate the tomographic results to an ecological interpretation. However, due to the undersampled nature of tomographic acquisitions, the number and distribution of acquisitions can change the estimated 3D radar reflectivity and as a consequence the forest structure estimates. This paper explores the results for radar as well as for forest structure for different number and distribution of acquisitions in order to analyse the potential and limitations of the estimation of forest structure in future space borne scenarios where the number and distribution of acquisitions will be suboptimal. In this context, the paper analyses a tomographic campaign of 15 tracks acquired over Traunstein (Germany) in 2017 together with ground measurements and Lidar.	l band;microwave;radar;the forest;tomographic reconstruction;tomography	Victor Cazcarra-Bes;Marivi Tello;Matteo Pardini;Konstantinos P. Papathanassiou	2018	IGARSS 2018 - 2018 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2018.8519342	vegetation;computer vision;remote sensing;artificial intelligence;tomography;radar;synthetic aperture radar;lidar;l band;computer science;3d radar;microwave	Metrics	80.27325428967966	-62.81690847976149	47811
e789ec82599072a313c884c7b7b1c58dfe747111	modeling of target shadows for sar image classification	target classification;sar image classification;image segmentation;image resolution;hidden markov model;classification structure target shadows modeling sar image classification noncooperative target recognition synthetic aperture radar expectation maximization gaussian mixture distributions anisotropic smoothing posterior probabilities hidden markov model segmentation algorithm;image classification;image classification image segmentation hidden markov models target recognition synthetic aperture radar data mining radar scattering gaussian distribution anisotropic magnetoresistance smoothing methods;posterior probability;target shadows modeling;noncooperative target recognition;synthetic aperture radar expectation maximisation algorithm hidden markov models image classification image resolution image segmentation radar imaging radar target recognition;hidden markov models;expectation maximization;classification structure;target recognition;radar imaging;segmentation algorithm;sar image;radar target recognition;posterior probabilities;mixture of gaussians;gaussian mixture distributions;anisotropic smoothing;synthetic aperture radar;expectation maximisation algorithm	A recent thrust of non-cooperative target recognition (NCTR) using synthetic aperture radar (SAR) has been to complement the extraction of scattering centers by incorporating information contained in the target shadow. When classifying targets based on the shadow region alone, it is essential that an image be well clustered into its respective shadow, highlight, and background regions. To obtain the segmentation, the intensity and spatial location of a pixel are modeled as a mixture of Gaussian distributions. Expectation-maximization (EM) is used to obtain the corresponding distributions for the three regions within a given image. Anisotropic smoothing is applied to smooth the input image as well as the posterior probabilities. A representation of the shadow boundary is developed in conjunction with a Hidden Markov Model (HMM) ensemble to obtain target classification. A variety of targets from the MSTAR database are used to test the performance of both the segmentation algorithm and classification structure.	expectation–maximization algorithm;hidden markov model;markov chain;pixel;shadow mapping;smoothing;synthetic intelligence;thrust	Scott Papson;Ram M. Narayanan	2006	35th IEEE Applied Imagery and Pattern Recognition Workshop (AIPR'06)	10.1109/AIPR.2006.27	computer vision;geography;machine learning;pattern recognition	Vision	73.15997394244513	-61.69266068576773	47812
4e602db8346cb779a9446227c3b1ef81fea2bbdf	near real-time estimation of super-resolved depth and all-in-focus images from a plenoptic camera using graphics processing units	graphic processing unit;near real time	Depth range cameras are a promising solution for the 3DTV production chain. The generation of color images with their accompanying depth value simplifies the transmission bandwidth problem in 3DTV and yields a direct input for autostereoscopic displays. Recent developments in plenoptic video-cameras make it possible to introduce 3D cameras that operate similarly to traditional cameras. The use of plenoptic cameras for 3DTV has some benefits with respect to 3D capture systems based on dual stereo cameras since there is no need for geometric and color calibration or frame synchronization. This paper presents a method for simultaneously recovering depth and all-in-focus images from a plenoptic camera in near real time using graphics processing units (GPUs). Previous methods for 3D reconstruction using plenoptic images suffered from the drawback of low spatial resolution. A method that overcomes this deficiency is developed on parallel hardware to obtain near real-time 3D reconstruction with a final spatial resolution of 800×600 pixels. This resolution is suitable as an input to some autostereoscopic displays currently on the market and shows that real-time 3DTV based on plenoptic video-cameras is technologically feasible.	3d reconstruction;3d television;algorithm;angular defect;angularjs;autostereoscopy;cuda;color depth;color image;depth map;display resolution;encode;field-programmable gate array;glossary of computer graphics;graph bandwidth;graphics processing unit;image processing;opencl api;parallel computing;pixel;real-time clock;real-time computing;stereo camera;stereo cameras;stereoscopy;super-resolution imaging;synthetic data;synthetic intelligence	Jonas Philipp Lüke;Fernando Pérez Nava;José Gil Marichal-Hernández;José Manuel Rodríguez-Ramos;Fernando L. Rosa	2010	Int. J. Digital Multimedia Broadcasting	10.1155/2010/942037	computer vision;simulation;computer science;computer graphics (images)	Graphics	59.44518702982921	-55.787538088049565	47826
618612da1fd3cea7b284a097f8731053eb246c33	improving algebraic reconstruction techniques with nonlinear iterating algorithms	nonlinear iterating algorithms;simple self correlative algebraic reconstruction technique;algebraic reconstruction technique;current representative art;optical computerized tomography oct;mean square error methods algebra iterative methods;reconstruction;data mining;iterative algorithm;modified sart;subspace constraints;iterative reconstruction;optical computerized tomography oct iteration reconstruction algorithm;iterative methods;algorithm;accuracy;reconstructive effect;algebra;mean square error;image reconstruction;transforms;computerized tomography;mathematical model;mean square error methods;iteration;iterating program;non ideal bordered field;simultaneous art;reconstructive accuracy;iterating reconstruction technique algebraic reconstruction techniques nonlinear iterating algorithms simple self correlative algebraic reconstruction technique numerical simulation non ideal bordered field reconstructive effect current representative art simultaneous art modified sart reconstructive accuracy mean square error iterating program;iterating reconstruction technique;subspace constraints numerical simulation testing art;algebraic reconstruction techniques;numerical simulation	A new improvement, named Simple Self-correlative algebraic reconstruction technique (SSART), was brought forwards on algebraic reconstruction technique (ART). With numerical simulation, it was applied to reconstructing a Non-ideal-bordered field in order to test its reconstructive effect. For contrast, three current representative ARTs including basic algebraic reconstruction technique (ART), simultaneous ART (SART) and modified SART (MSART) were simulated. The calculated results and reconstructive accuracy were discussed with mean-square error (MSE). As the result, the reconstructive accuracy was improved much by SSART. It’s MSE decreased by 96.4% from that of ART at the level of 10-5 magnitude. SSART was considered a very superior reconstruction technique that had many advantages. Its iterating program was simple, reconstructive accuracy high, iterating process convergent persistently. It’s a superior iterating reconstruction technique to our knowledge.	algebraic reconstruction technique;algorithm;computer simulation;linear algebra;mean squared error	Zunying Li;Yizhong Song	2009	2009 Fifth International Conference on Natural Computation	10.1109/ICNC.2009.303	theoretical computer science;mathematics;geometry;algorithm	Visualization	57.25957382852354	-75.24706896270132	47929
cc365e1973b3775d2d619c321b6d337107d05e47	unsupervised classification using polarimetric decomposition and the complex wishart classifier	polarimetric synthetic aperture radar;analisis imagen;initial classification map;teledetection spatiale;electromagnetic scattering;radar remote sensing;bahia san francisco;baie san francisco;entropia;space remote sensing;image processing;neural networks;complex wishart classifier;north america;america del norte;amerique du nord;radar antenne synthetique;polarimetric target decomposition;training;polarization;terrain type;image classification;entropy alpha plane geophysical measurement technique land surface terrain mapping radar remote sensing radar imaging sar synthetic aperture radar unsupervised classification image classification polarimetric decomposition radar polarimetry polarization complex wishart classifier terrain type man made object polarimetric target decomposition maximum likelihood classifier complex wishart distribution covariance matrix initial classification map training iteration;californie;indexing terms;etats unis;classification;estados unidos;man made object;geophysical measurement technique;remote sensing by radar;radar scattering;teledeteccion espacial;california;sar;geophysical signal processing;radar polarimetry;radar imaging;complex wishart distribution;pixel;entropie;image classification geophysical techniques geophysical signal processing terrain mapping remote sensing by radar synthetic aperture radar radar imaging radar polarimetry;sar image;iteration;unsupervised classification;radar applications;image analysis;covariance matrix electromagnetic scattering synthetic aperture radar radar scattering radar imaging radar polarimetry image processing neural networks polarimetric synthetic aperture radar radar applications;polarimetric decomposition;land surface;entropy;terrain mapping;wishart distribution;analyse image;entropy alpha plane;clasificacion;maximum likelihood classifier;geophysical techniques;covariance matrix;san francisco bay;synthetic aperture radar	The authors propose a new method for unsupervised classification of terrain types and man-made objects using polarimetric synthetic aperture radar (SAR) data. This technique is a combination of the unsupervised classification based on polarimetric target decomposition, S.R. Cloude et al. (1997), and the maximum likelihood classifier based on the complex Wishart distribution for the polarimetric covariance matrix, J.S. Lee et al. (1994). The authors use Cloude and Pottier's method to initially classify the polarimetric SAR image. The initial classification map defines training sets for classification based on the Wishart distribution. The classified results are then used to define training sets for the next iteration. Significant improvement has been observed in iteration. The iteration ends when the number of pixels switching classes becomes smaller than a predetermined number or when other criteria are met. The authors observed that the class centers in the entropy-alpha plane are shifted by each iteration. The final class centers in the entropy-alpha plane are useful for class identification by the scattering mechanism associated with each zone. The advantages of this method are the automated classification, and the interpretation of each class based on scattering mechanism. The effectiveness of this algorithm is demonstrated using a JPL/AIRSAR polarimetric SAR image.	learning classifier system;polarimetry;unsupervised learning	Jong-Sen Lee;Mitchell R. Grunes;Thomas L. Ainsworth;Li-Jen Du;Dale L. Schuler;Shane Cloude	1999	IEEE Trans. Geoscience and Remote Sensing	10.1109/36.789621	computer vision;entropy;image analysis;image processing;physics;statistics;remote sensing	Mobile	72.1156816024195	-62.52641558377901	48002
5f8c80c9bc3ad96b10c6a79a62fa75de3eac4795	remote sensing of sun-induced chlorophyll fluorescence at different scales		In this contribution we present activities and selected results obtained in recent studies and campaigns conducted in the context of the FLuorescence EXplorer (FLEX) mission. FLEX is a candidate mission for the ESA 8th Earth Explorer and large efforts are currently dedicated to the development of an implementation scheme for an accurate mapping of fluorescence from the selected spaceborne sensor and mission configuration. Field and airborne data collected in different experimental campaigns, together with simulated data, have been used to demonstrate the feasibility of fluorescence retrievals and the potential of exploiting high spatial resolution fluorescence maps for a better understanding of the environment from space.	airborne ranger;esa;map	Roberto Colombo;Luis Alonso;Marco Celesti;Sergio Cogliati;Alexander Damm;Matthias Drusch;Luis Guanter;Tommaso Julitta;P. Kokkalis;Stefan Kraft;José F. Moreno;Cinzia Panigada;F. Pinto;Uwe Rascher;Micol Rossini;Anke Schickling;Dirk Schuettemeyer;Wout Verhoef;F. Zemek	2014	2014 6th Workshop on Hyperspectral Image and Signal Processing: Evolution in Remote Sensing (WHISPERS)	10.1109/WHISPERS.2014.8077542	remote sensing;flex;environmental science;chlorophyll fluorescence;image resolution	HCI	81.2922746832235	-61.826431174000774	48073
437bd5f6d7d658819efda5c94331a6e8973b64f7	combining single-image and multiview super-resolution for mixed-resolution image plus depth data	image resolution cameras data communication;interpolation;gain 0 53 db single image resolution multiview super resolution mixed resolution image cameras data transmission data storage free viewpoint television image quality occlusions single image super resolution;extrapolation;signal resolution;mixed resolution multiview super resolution;cameras signal resolution spatial resolution extrapolation interpolation;cameras;spatial resolution	In mixed-resolution multiview setups, a scene is captured from various viewpoints with cameras having different spatial resolutions. Compared to full-resolution systems, mixed-resolution setups allow for savings with respect to data transmission, storage, and costs. However, for applications like free viewpoint television, high-quality images are required for all available camera perspectives. Therefore, high-resolution cameras can be used to increase the image quality of a neighboring low-resolution view. Due to occlusions, some parts of the scene are invisible in the high-resolution reference views and thus cannot be directly synthesized from the neighboring perspectives. In this paper, we propose to integrate the idea of single-image super-resolution to better handle occluded areas and thus to improve the super-resolution quality for mixed-resolution multiview images. For a downsampling factor of 4, the proposed method achieves an average gain of 0.53 dB with respect to a comparable multiview super-resolution approach.	autostereogram;decimation (signal processing);free viewpoint television;image quality;image resolution;simulation;super-resolution imaging	Thomas Richter;Jürgen Seiler;Wolfgang Schnurrer;Michel Bätz;André Kaup	2015	2015 23rd European Signal Processing Conference (EUSIPCO)	10.1109/EUSIPCO.2015.7362702	computer vision;image resolution;optics;sub-pixel resolution;computer graphics (images)	Vision	60.342835735713535	-55.5869150275682	48094
1cd843b267dd519c3833533f55163f054857c5f7	efficient representation of zooming information in videos using multi resolution mosaics	camera motion;multi resolution	Video sequence often includes zoom camera motion. As a result the same scene is represented by frames at different resolutions. Present video mosaicing techniques construct mosaic images by mapping video frames onto a single resolution reference image plane. In such a mosaic the registration of zoomed frames requires diminishing in size to fit in the resolution of the final mosaic image. Consequently, extra details from video zoom are lost. To address this problem of handling variations in resolution we propose a novel idea of multi resolution mosaics. There are two contributions in this work; first a featureless registration method with a minimal weighted fusion procedure. Secondly, a multi resolution mosaic structure which captures zooming information in videos.		Asif Masood;Wajeeha Kanwal	2010		10.1007/978-3-642-14932-0_37	computer vision;computer science;multimedia;computer graphics (images)	AI	57.55891592787732	-54.16469068585714	48118
f4ce951d3d09b6b75cf6bbde40aa55c742386eb6	generalized non-local means filtering for image denoising	algorithms;image denoising;contamination;denoising	Non-local means (NLM) filtering has been shown to outperform alternative denoising methodologies under the model of additive white Gaussian noise contamination. Recently, several theoretical frameworks have been developed to extend this class of algorithms to more general types of noise statistics. However, many of these frameworks are specifically designed for a single noise contamination model, and are far from optimal across varying noise statistics. The NLM filtering techniques rely on the definition of a similarity measure, which quantifies the similarity of two neighbourhoods along with their respective centroids. The key to the unification of the NLM filter for different noise statistics lies in the definition of a universal similarity measure which is guaranteed to provide favourable performance irrespective of the statistics of the noise. Accordingly, the main contribution of this work is to provide a rigorous statistical framework to derive such a universal similarity measure, while highlighting some of its theoretical and practical favourable characteristics. Additionally, the closed form expressions of the proposed similarity measure are provided for a number of important noise scenarios and the practical utility of the proposed similarity measure is demonstrated through numerical experiments. © (2014) COPYRIGHT Society of Photo-Optical Instrumentation Engineers (SPIE). Downloading of the abstract is permitted for personal use only.	noise reduction;non-local means	Sudipto Dolui;Iván C. Salgado Patarroyo;Oleg V. Michailovich	2014		10.1117/12.2042396	machine learning;noise reduction;data mining;contamination	ML	64.75090530574386	-72.41467569803291	48144
291790c00cb2dda30f9078d2f46c22c69e68e8c6	using grace satellite gravimetry for assessing large-scale hydrologic extremes		Global assessment of the spatiotemporal variability in terrestrial total water storage anomalies (TWSA) in response to hydrologic extremes is critical for water resources management. Using TWSA derived from the gravity recovery and climate experiment (GRACE) satellites, this study systematically assessed the skill of the TWSA-climatology (TC) approach and breakpoint (BP) detection method for identifying large-scale hydrologic extremes. The TC approach calculates standardized anomalies by using the mean and standard deviation of the GRACE TWSA corresponding to each month. In the BP detection method, the empirical mode decomposition (EMD) is first applied to identify the mean return period of TWSA extremes, and then a statistical procedure is used to identify the actual occurrence times of abrupt changes (i.e., BPs) in TWSA. Both detection methods were demonstrated on basin-averaged TWSA time series for the world’s 35 largest river basins. A nonlinear event coincidence analysis measure was applied to cross-examine abrupt changes detected by these methods with those detected by the Standardized Precipitation Index (SPI). Results show that our EMD-assisted BP procedure is a promising tool for identifying hydrologic extremes using GRACE TWSA data. Abrupt changes detected by the BP method coincide well with those of the SPI anomalies and with documented hydrologic extreme events. Event timings obtained by the TC method were ambiguous for a number of river basins studied, probably because the GRACE data length is too short to derive long-term climatology at this time. The BP approach demonstrates a robust wet-dry anomaly detection capability, which will be important for applications with the upcoming GRACE Follow-On mission.	anomaly detection;breakpoint;collision detection;data assimilation;downscaling;grace murray hopper award;hilbert–huang transform;journal of applied meteorology and climatology;nonlinear system;onset (audio);rare events;sensor;spatial variability;spatiotemporal pattern;terrestrial television;time series	Alexander Y. Sun;Bridget R. Scanlon;Amir Aghakouchak;Zizhan Zhang	2017	Remote Sensing	10.3390/rs9121287	remote sensing;geology;anomaly detection;return period;climatology;standard deviation;gravimetry;drainage basin	ML	82.84467573447094	-57.60164133297818	48266
a82be9d0e69bba01ba66bccd4e0808d2c58c7259	feature aware 3d mesh compression using robust principal component analysis		In this paper, we present a progressive compression scheme that enables aggressive compression ratios, by successfully identifying and encoding sharp and small scale geometric features. The accurate identification of the features is achieved by exploiting the low rank property of the captured geometry and the sparsity of the features in the Laplacian domain, permeating benefits from robust principal component analysis. Due to the visual importance of the identified geometric features, the geometry coding process, is optimized for preserving the geometric features at extremely low bit rates. Extensive evaluation studies, carried out using a collection of scanned and synthetic 3D models, show that the proposed feature aware high pass quantization method achieves extremely high compression ratios, offering at the same time meaningful approximations of the given surfaces. Finally, a short discussion regarding the applicability of the proposed feature identification scheme to smooth completion and feature preserving surface denoising is also offered.	3d modeling;approximation;identification scheme;lossless compression;noise reduction;robust principal component analysis;sparse matrix;synthetic intelligence	Aris S. Lalos;Gerasimos Arvanitis;Aristotelis Spathis-Papadiotis;Konstantinos Moustakas	2018	2018 IEEE International Conference on Multimedia and Expo (ICME)	10.1109/ICME.2018.8486541	artificial intelligence;computer vision;robustness (computer science);quantization (signal processing);robust principal component analysis;identification scheme;pattern recognition;principal component analysis;low bit;polygon mesh;solid modeling;computer science	Vision	55.759546841588595	-56.66104598127459	48277
2534f1b53ef1feaae2f8867e0ded80b10926240d	utility assessment of a multispectral snapshot lwir imager	lwir imager utility assessment;lwir;measurement;technology development;multispectral snapshot lwir imager;optical filters;hyperspectral sensors;spectrum;materials;remote sensing applications;long wave infrared snapshot imager;arrays;optimal spectral channel width identification;band selection technique;optimal spectral channel number identification;color filter array lwir multispectral;infrared imaging;geophysical signal processing;image color analysis;remote sensing;color filter array;remote sensing geophysical equipment geophysical signal processing infrared imaging optical filters;optimal spectral channel width identification lwir imager utility assessment multispectral snapshot lwir imager long wave infrared snapshot imager remote sensing applications color filter array band selection technique optimal spectral channel number identification;multispectral;geophysical equipment;infrared;arrays measurement materials image color analysis hyperspectral sensors optical filters	The purpose of this study was to asses the utility of a Long Wave Infrared (LWIR) snapshot imager for remote sensing applications. The snapshot imager is made possible by the utilization of a color filter array that selectively allows different wavelengths of light to be collected on separate pixels of the focal plane in same fashion as a typical Bayer array in visible portion of the spectrum [1]. Recent technology developments have made this possible in the LWIR [2]. The primary focus of the study is to develop a band selection technique that is capable of identifying both the optimal number and width of the spectral channels. Once selected, the theoretical sensor performance is used to evaluate the usefulness in a typical remote sensing application.	bayer filter;color filter array;focal (programming language);image sensor;multispectral image;pixel;remote sensing application;snapshot (computer storage)	Jeffrey Mercier;Toby Townsend;Robert Sundberg	2010	2010 2nd Workshop on Hyperspectral Image and Signal Processing: Evolution in Remote Sensing	10.1109/WHISPERS.2010.5594956	computer vision;geography;optics;remote sensing	Mobile	77.28925396454089	-62.07867380350588	48286
1a5bffbe4beb6cad5a0b0ebb34c0bab7b8d44fc6	retrieving photosynthetic capacity parameter from leaf photochemical reflectance and chlorophyll fluorescence		Two dynamic vegetation optical indicators, namely chlorophyll fluorescence (ChIF) and photochemical reflectance index (PRI), have been proven valuable as estimators of terrestrial photosynthesis. Linking optical properties of vegetation to the underlying biochemical processes is a difficult task, however, key for the remote sensing of vegetation. We present a new method of retrieving leaf maximum carboxylation rate $(V_{\mathrm{c}\max})$: we combine the leaf radiative transfer model Fluspect to a biochemical routine, and use both $ChlF$ and green reflectance spectra simultaneously as an input. We test the method against various datasets, and discuss its applications, requirements and problems.	requirement;terrestrial television	Nastassia Vilfan;Christiaan van der Tol;Peiqi Yang;Wouter Verhoef	2018	IGARSS 2018 - 2018 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2018.8517912	atmospheric radiative transfer codes;photochemical reflectance index;vegetation;chlorophyll fluorescence;computer science;photochemistry;reflectivity;hyperspectral imaging;photosynthetic capacity;photosynthesis	Embedded	82.28759276074828	-58.7985415033841	48339
cb651696027a8f39ce1b0ff709ca73872ac19d33	regularization-based semi-blind image deconvolution using an improved function for pmmw images application		Image deconvolution is a method for reversing the distortion in an imaging system. It is widely used in removing blur and noise from a degraded image. This is an ill-posed inverse problem, and one should use regularization techniques to solve this problem. Regularization functions play an important role in ̄nding the desired solution. In this paper, a new function in wavelet domain is proposed, which is useful in blind deconvolution. In addition, a simple algorithm is used to obtain the restored image and unknown point spread function. The proposed approach is tested on three standard images and then compared with the previous methods using standard metrics. Real Passive Millimeter Wave (PMMW) images are also used to obtain the sharp deblurred images. Simulation results show that the proposed method can improve the quality of the restored image.	deconvolution	M. A. Mansoori;M. R. Mosavi;Mohammad-Hossein Bisjerdi	2018	Journal of Circuits, Systems, and Computers	10.1142/S0218126618501074	image restoration;well-posed problem;wavelet;deconvolution;point spread function;distortion;inverse problem;blind deconvolution;computer vision;artificial intelligence;mathematics	Vision	58.36673127584819	-67.02448219222005	48384
3b53e88a73eedc93aaeca540383a326370b64b20	fusion of tandem-x and cartosat-1 dems using tv-norm regularization and ann-predicted weights		This paper deals with TanDEM-X and Cartosat-1 DEM fusion over urban areas with support of weight maps predicted by an artificial neural network (ANN). Although the TanDEM-X DEM is a global elevation dataset of unprecedented accuracy (following HRTI-3 standard), its quality decreases over urban areas because of artifacts intrinsic to the SAR imaging geometry. DEM fusion techniques can be used to improve the TanDEM-X DEM in problematic areas. In this investigation, Cartosat-1 elevation data were fused with the TanDEM-X DEM by weighted averaging and total variation (TV)-based regularization, resorting to weight maps derived by a specifically trained ANN. The results show that the proposed fusion strategy can significantly improve the final DEM quality.	artificial neural network;glossary of computer graphics;map;tandem computers;usgs dem	Hossein Bagheri;Michael Schmitt;Xiao xiang Zhu	2017	2017 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)	10.1109/IGARSS.2017.8127720	artificial intelligence;fusion;artificial neural network;elevation;computer vision;computer science;lidar;regularization (mathematics)	Robotics	76.07677528210641	-59.784259132064726	48403
ec36903e9001b34bbce6a2087dcb5acbab36dc59	hazerd: an outdoor scene dataset and benchmark for single image dehazing		In this paper, a new dataset, HazeRD, is proposed for benchmarking dehazing algorithms under more realistic haze conditions. HazeRD contains fifteen real outdoor scenes, for each of which five different weather conditions are simulated. As opposed to prior datasets that made use of synthetically generated images or indoor images with unrealistic parameters for haze simulation, our outdoor dataset allows for more realistic simulation of haze with parameters that are physically realistic and justified by scattering theory. All images are of high resolution, typically six to eight megapixels. We test the performance of several state-of-the-art dehazing techniques on HazeRD. The results exhibit a significant difference among algorithms across the different datasets, reiterating the need for more realistic datasets such as ours and for more careful benchmarking of the methods.	algorithm;autostereogram;benchmark (computing);image resolution;pixel;scattering theory;simulation	Yanfu Zhang;Li Ding;Gaurav Sharma	2017	2017 IEEE International Conference on Image Processing (ICIP)	10.1109/ICIP.2017.8296874	haze;computer vision;benchmarking;artificial intelligence;visualization;scattering theory;benchmark (computing);computer science;atmospheric model;scattering	Vision	61.26450436586864	-52.68567059902943	48457
598f56600e8a8f26d86227613b7b2bf4151b59c4	weighting parameters to improve ihs transformation in data fusion of theos imagery		To efficiently fuse multi-spectral (MS) and panchromatic (PAN) images acquired from THEOS satellite, the authors offer proper parameters to improve IHS fusion technique based on its spectral responsivity. This concept was originally contributed by Tu et al., applied to IKONOS image fusion. Red and NIR bands of THEOS imagery with lower response were adjusted to be higher and close to the response of PAN band using those new proposed parameters. Indexes including the correlation coefficients (CCs), relative dimensionless global error in synthesis (ERGAS), and relative average spectral error (RASE) of the pan-sharpened and MS images were compared to quantitatively evaluate the quality of pansharpened images. The resulting indexes indicate that the quality of pan-sharpened images obtained from the study be obviously high. Indexes from images transformed by the method of Tu et al. were compared to the indexes obtained from the study as well. The comparison expresses that indexes resulted from the study are better than ones using the method of Tu et al. It can confirm that the fusion method based on the concept of adjustment on spectral responsivity of specific sensor is valid. The new approach provides a satisfactory result of image fusion, both visually and quantitatively.	coefficient;image fusion;theos	Satith Sangpradid;Sunya Sarapirome	2014	JDIM		responsivity;computer vision;panchromatic film;sensor fusion;artificial intelligence;image fusion;computer science;weighting	Robotics	65.44077185235386	-65.91570458170074	48486
7374eed7b14c74263a174d07cf99b207bb932b80	fuzzy directional (fd) filter for impulsive noise reduction in colour video sequences	spatio temporal filtering;directional processing;movement detection;video colour sequences;processing time;fuzzy logic;impulsive noise;noise estimator	This paper presents a novel Fuzzy Directional (FD) Filter for suppression of impulsive noise in colour video sequences. The proposed approach consists in the estimation of fuzzy levels to detect movement and noise presence in the neighbourhood frames, permitting to preserve the edges, fine details and chromaticity characteristics in colour images and video sequences. The new framework has been justified applying commonly used objective criteria, such as, Peak Signal to Noise Ratio (PSNR), Mean Absolute Error (MAE) and Normalized Colour Difference (NCD), as well subjective perception by human viewer showing better performance in comparison with known methods presented in the literature.	noise reduction	Alberto Rosales-Silva;Francisco J. Gallegos Funes;Volodymyr I. Ponomaryov	2012	J. Visual Communication and Image Representation	10.1016/j.jvcir.2011.09.007	fuzzy logic;computer vision;speech recognition;computer science;mathematics;salt-and-pepper noise	Vision	57.516689094063956	-63.6624478183227	48559
7b1d02a2c5173baaba36d07d9e49626748fc944f	lidars with narrow fov for daylight measurements	remote sensing by laser beam atmospheric optics atmospheric techniques;middle atmosphere daylight rayleigh lidar laser beam stabilization system bss;laser repetition rate daylight measurements daytime lidar operation middle atmosphere narrow field of view effective background reduction high transmission narrow band detection laser beam position receiving telescope optical axis high frequency disturbances beam stabilization system laser beam pulse to pulse stabilization single pulse data acquisition system laser divergence;laser beams measurement by laser beam laser radar temperature measurement telescopes laser stability mirrors	Daytime lidar operation in the middle atmosphere requires a narrow field of view (FOV) of the receiving telescope for effective background reduction and a high-transmission narrow-band detection. The laser beam position in the atmosphere relative to the optical axis of the receiving telescope is subject to high-frequency disturbances such as turbulence, vibration, and wind as well as comparable slow drift (thermal effects of the laser, stability of the building, etc.). We developed a beam stabilization system (BSS) that ensured a pulse-to-pulse stabilization of the laser beam with ~ 3 μrad remaining jitter, allowing ~ 60 μrad FOV. With BSS and single-pulse data acquisition system, the optimal alignment of the laser and telescope can be controlled, and information on the FOV and laser divergence in the far field can be derived. The capability of the BSS is to stabilize the laser against all internal and external disturbances below the repetition rate of the laser.	data acquisition;daylight;field of view in video games;format-preserving encryption;nyquist rate;optic axis of a crystal;piezoelectricity;real-time clock;turbulence	Ronald Eixmann;Michael Gerding;Josef Hoffner;Maren Kopp	2015	IEEE Transactions on Geoscience and Remote Sensing	10.1109/TGRS.2015.2401333	laser power scaling;laser linewidth;distributed feedback laser;ultrafast laser spectroscopy;laser beam quality;beam diameter;optoelectronics;laser doppler vibrometer;beam parameter product;optics;round-trip gain;far-infrared laser;physics;remote sensing	Robotics	80.95374736823346	-66.521496631543	48659
a6e5b9f2e098fd121d8ac3ad79b1bee8c908df5e	a bayesian mrf framework for labeling terrain using hyperspectral imaging	analisis imagen;hyperspectral image analysis;terrains;zona rural;teledetection;statistique;nonparametric density estimation;markov chain analysis;densite;probability;parametric statistics;north america;america del norte;amerique du nord;gaussian processes;district of columbia;dimension reduction;nongaussian statistics;bayesian inference;pixels values;methode monte carlo;nonparametric density estimate;terrain;bayesian methods;prior distribution;image classification;densidad;non gaussian statistics;zone rurale;etats unis;maximum likelihood estimation;classification;estados unidos;bayesian methods labeling hyperspectral imaging parametric statistics statistical analysis pixel image analysis probability laplace equations springs;deteccion a distancia;markov random field;a posteriori estimation;discriminant analysis;laplace equations;modelo;springs;statistical analysis;echantillon reference;spectral variation;generalized laplacian;markov chain monte carlo;geophysical signal processing;bayesian mrf framework;probability models;remote sensing;probability distribution;pixel;probabilidad;terrain labeling markov chain monte carlo markov random field mrf non gaussian statistics;markov random field mrf;analyse statistique;multidimensional signal processing;analyse spectrale;probabilite;hyperspectral data;rural area;statistics;markov random field bayesian mrf framework terrain labeling hyperspectral imaging nongaussian statistics pixels values standard gaussian models hyperspectral image analysis probability models terrain site classification nonparametric density estimate spectral variation generalized laplacian generalized bessel k form difference pixels random estimation a posteriori estimation markov chain monte carlo;difference pixels;generalized bessel k form;random estimation;image analysis;modele;standard gaussian models;analyse chaine markov;distrito de columbia;terrain mapping;markov processes;density;spectral analysis;hyperspectral imaging;probability model	Studies of hyperspectral images point to non-Gaussian statistics of pixels values, and consequently, standard Gaussian models may not perform well in hyperspectral image analysis. This paper presents novel probability models that capture non-Gaussian statistics of hyperspectral images, and uses them in automated classification of terrain sites. After the data are preprocessed using standard dimension-reduction tools, we use: 1) a nonparametric density estimate for capturing spectral variation at each site and 2) two parametric families-generalized Laplacian and Bessel K form-to capture non-Gaussian statistics of difference pixels. Assuming an Ising-type prior on site labels, favoring a smooth classification, we formulate a Markov random field-maximum a posteriori estimation problem and use a Markov chain to estimate site classifications. Results are presented from application of this framework to Washington, DC Mall and Indian Springs rural area datasets.	bessel filter;dimensionality reduction;estimation theory;image analysis;ising model;markov chain;markov random field;pixel;preprocessor	Robert Neher;Anuj Srivastava	2005	IEEE Transactions on Geoscience and Remote Sensing	10.1109/TGRS.2005.846865	econometrics;terrain;image analysis;pattern recognition;mathematics;rural area;statistics	Vision	71.63054482582099	-62.52275060281557	48689
2473f0a16967564c836ec06f65e08448ff57110c	a new approach for image quality assessment using svd	eigenvalues and eigenfunctions;image distortion;signal to noise ratio measurement;singular value decomposition;singular value decomposition algorithm;distortion measurement;image quality measure;eigenvalues;brightness;human visual system;mean square error;image reconstruction;largest eigenvalue;image quality;pixel by pixel difference;image quality assessment;image quality distortion measurement signal to noise ratio mean square error methods noise measurement pixel humans visual system singular value decomposition eigenvalues and eigenfunctions;image denoising;image distortion image quality assessment mean square error signal to noise ratio measurement pixel by pixel difference human visual system singular value decomposition algorithm eigenvalues image quality measure;signal to noise ratio;singular value decomposition image denoising;noise	The traditional mean square error (MSE) and signal to noise ratio (SNR) measurements are based on the pixel-by-pixel differences between the original and the distorted image. These quality values are not adapted with the human visual system (HVS). Also, they can not distinguish some different corruptions. In this paper, we use the singular value decomposition algorithm of each 8times8 blocks of image to calculate the ratio of the first and second largest eigenvalues to measure the distribution of brightness. So, we could measure the quality of an image and hence to determine the type of the relating distortion. The method is so simple that the simulation results easily arrange and show the best images in order.	approximation algorithm;distortion;human visual system model;image quality;mean squared error;pixel;signal-to-noise ratio;simulation;singular value decomposition	Farah Torkamani-Azar;Seyed Ali Amirshahi	2007	2007 9th International Symposium on Signal Processing and Its Applications	10.1109/ISSPA.2007.4555385	iterative reconstruction;image quality;computer vision;mathematical optimization;eigenvalues and eigenvectors;computer science;noise;mathematics;mean squared error;human visual system model;singular value decomposition;signal-to-noise ratio;brightness;statistics	Vision	57.87175334034736	-65.67668171701716	48763
3a1adde7d962c617df79cbeb3c89faff20bf1f8d	prism-based color separation for professional digital photography	digital camera;digital photography;image quality;digital image	In the field of silver-halide photography, color separation was explored about a century ago, using filter mosaics, dichroic mirrors, three-shot filtration, and other techniques, before the dominant technology of multi-layered color film emerged. In the field of digital photography, the same techniques are being explored now in conjuction with silicon sensor technology. The three-shot technique, and the related tri-linear scanning technique, can deliver excellent images, but are awkward to employ and unsuitable for subjects that move. The filter-mosaic aproach is currently dominant in the digital camera market, but its inevitable aliasing artifacts limit its applicability in the professional end of the business. The use of dichroic mirrors, embedded in prisms as in color-TV cameras, has been attempted by a few camera vendors, so far with limited success. The demand for better digital images, however, has provided a continuing incentive to work on making this three-sensor approach feasible. Several key problems must be solved to make a viable professional camera using this approach: first, sensors with high enough resolution and image quality must be made at a cost that allows three of them to be included in a product; second, a prism must be designed for good color reproduction fidelity and must be economically and precisely manufactured; third, the three sensors must be optically aligned to the prism in a way that avoids ghost reflections and other problems; and finally, a whole new camera system needs to be designed around such a three-channel sensor assembly. This paper recounts some of the ways in which these problems are addressed in the design of the recently introduced Foveon Studio Camera, and provides qualitative assessments of the resulting advantages in image quality and usability.	aliasing;camera phone;dichroism;digital camera;digital image;digital photography;embedded system;halide;image quality;reflection (computer graphics);sensor;triangular function;usability	Richard F. Lyon	2000			computer vision;computational photography;simulation;engineering;computer graphics (images)	HCI	62.4079024886219	-56.88351963672148	48772
55efb088c9bb60bf10478980271d2b3e65acd12c	prior image induced regularization method for electrical capacitance tomography				Pan Chu;Jing Lei;Qibin Liu	2019	IEEE Access	10.1109/ACCESS.2018.2886239	electrical capacitance tomography;computer science;electronic engineering;distributed computing;regularization (mathematics)	Vision	55.73624848339995	-73.8903677806298	48785
e011e1261818c6cf0e05e903ddd106a0c32e9c2e	two invariance properties on object color changes under daylights				Johji Tajima;Eiichi Niinomi	2006				Vision	63.81189613349827	-55.86420933108215	48802
a33a84c4fcb3816c543b97b7ca505d77806ef7f2	color quantization and optimization of luminance for digital mirror device–based projector	digital mirror device;quantization;mirrors;quantization signal switches mirrors image color analysis imaging cost function;optimisation brightness cmos image sensors image colour analysis image representation light emitting diodes light reflection mirrors optical projectors;cost function;color quantization cmos camera complementary metal oxide semiconductor camera led light emitting diode 24 binary image switching full color image representation binary image projection consumer electronics dmd digital mirror device based projector luminance optimization;quantization signal;imaging system digital mirror device projector quantization;imaging system;image color analysis;imaging;switches;projector	Projectors using digital mirror devices (DMDs) are widely used in consumer electronics. DMDs can switch between the ON and OFF states. Light is reflected by the DMDs, and a binary image is projected onto a screen. Full-color images can be represented by switching 24-binary images rapidly. To increase the frame rate, it is necessary to speed up the DMD switching. However, this is difficult because the switching time is limited by the mechanical constraints of the DMD. One solution is reducing the number of binary images to represent a full-color image. This paper proposes a framework for optimizing the color quantization and light-emitting diode (LED) luminance. The constructed system was evaluated by using a projector and complementary metal-oxide-semiconductor (CMOS) camera. The experimental results indicated that the proposed method improves the total luminance of a projected image approximately 122% compared to previous models and produces better image quality1.	active pixel sensor;binary image;cmos;color image;color quantization;digital signal processor;diode;experiment;image quality;light field;mathematical optimization;semiconductor;simulation;switching time;video projector	Gou Koutaki;Hiroshi Okajima;Nobutomo Matsunaga;Keiichi Uchimura	2016	IEEE Transactions on Consumer Electronics	10.1109/TCE.2016.7514668	medical imaging;computer vision;quantization;binary image;network switch;computer science	Vision	60.16370487781874	-59.416543700321256	48864
38600579817177884f3a5fe255dae22cdff28ba3	single-image tomography: 3d volumes from 2d x-rays		As many different 3D volumes could produce the same 2D x-ray image, inverting this process is challenging. We show that recent deep learning-based convolutional neural networks can solve this task. As the main challenge in learning is the sheer amount of data created when extending the 2D image into a 3D volume, we suggest firstly to learn a coarse, fixed-resolution volume which is then fused in a second step with the input x-ray into a high-resolution volume. To train and validate our approach we introduce a new dataset that comprises of close to half a million computer-simulated 2D x-ray images of 3D volumes scanned from 175 mammalian species. Applications of our approach include stereoscopic rendering of legacy x-ray images, re-rendering of x-rays including changes of illumination, view pose or geometry. Our evaluation includes comparison to previous tomography work, previous learning methods using our data, a user study and application to a set of real x-rays.	3d computer graphics;artificial neural network;computer simulation;convolutional neural network;deep learning;experiment;field (video);image resolution;light field;radiography;stereoscopy;synthetic intelligence;tomography;usability testing;video	Philipp Henzler;Volker Rasche;Timo Ropinski;Tobias Ritschel	2017	CoRR		convolutional neural network;computer vision;rendering (computer graphics);deep learning;tomography;stereoscopy;computer science;artificial intelligence	Vision	59.15171586253949	-52.76400598673158	48917
dd07618ebc641819bce54b9af6f70ee8e28fac4b	3d sparse coding based denoising of hyperspectral images	image denoising geophysical image processing hyperspectral imaging;image coding;image restoration;image coding three dimensional displays hyperspectral imaging dictionaries image restoration noise reduction;three dimensional displays;noise reduction;dictionaries;denoising hyperspectral images hsis 2d sparse coding 3d sparse coding spectral information;hyperspectral imaging;3d sparse coding based denoising rosis aviris sparse coefficients image noise hsi hyperspectral images	Hyperspectral images (HSIs) are often contaminated by noise, in order to remove the image noise efficiently and acquire excellent results. We propose a new denoising method based on 3D sparse coding. Firstly, to make full use of spectral information of hyperspectral data, we extract patches from HSIs and each patch contains the same area of different band. Secondly, we use aforementioned method to extract all patches and train these patches, the dictionary can be obtained, further calculate sparse coefficients. Finally, we can restore the HISs through the dictionary and the sparse coefficients. Experiments are implemented using the HSIs collected by AVIRIS and ROSIS. Results indicate that compared with common 2D sparse coding method, 3D sparse method can effectively improve the restoration performance for both subjective visual and objective evaluation criterion.	circuit restoration;coefficient;dictionary;image noise;neural coding;noise reduction;sparse approximation;sparse matrix	Di Wu;Ye Zhang;Yushi Chen	2015	2015 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)	10.1109/IGARSS.2015.7326476	image restoration;computer vision;computer science;hyperspectral imaging;machine learning;pattern recognition;noise reduction	Vision	67.57015583480346	-66.34558716292727	48926
df026fcf86881e1a4888108fcb0076fcdedf5a0f	adaptive bilateral filter considering local characteristics	bilateral filtering;image edge detection noise surface treatment noise reduction noise measurement surface texture conferences;gaussian processes;edge detection;surface texture;noise measurement;image texture;wavelet transforms;robust;adaptive;surface treatment;adaptive filters;image edge detection;noise reduction;details;wavelet transforms adaptive filters edge detection gaussian processes image denoising image texture;gaussian gradient;image denoising;bilateral filter;robust bilateral filter adaptive gaussian gradient details;wavelet denoising method adaptive bilateral filter local gaussian gradient information image processing edge regions texture regions;conferences;noise	In this paper, we propose a simple but effective adaptive bilateral filter considering local characteristics. The presented method exploits the local gaussian gradient information of the processing image and applies bilateral filter with changing the range filter parameter $\sigma_{r}$ adaptively. The proposed adaptive bilateral filter could preserve more details of the image compared with original bilateral filter in edge or texture regions. What is more, it is more robust to the noise. Also compared with the original bilateral filter and the state-of-art wavelet de-noising method, the proposed method also can effectively remove signal noise while preserving the original structure.	bilateral filter;gradient descent;image noise;noise (electronics);simulation;wavelet	Lin Sun;Oscar C. Au;Ruobing Zou;Wei Dai;Xing Wen;Sijin Li;Jiali Li	2011	2011 Sixth International Conference on Image and Graphics	10.1109/ICIG.2011.81	adaptive filter;edge-preserving smoothing;raised-cosine filter;computer vision;mathematical optimization;kernel adaptive filter;computer science;root-raised-cosine filter;pattern recognition;mathematics;filter design;top-hat filter;bilateral filter;m-derived filter	Vision	56.447470096496545	-66.38516738642727	48942
cf17c31bab0799ed028e14ca90dac8bc135e2a26	radiometric quality assessment of goes-16 abi l1b images			application binary interface	Zhipeng Wang;Xiangqian Wu;Haifeng Qian;Fangfang Yu;Robert Iacovazzi;Xi Shao;Vladimir Kondratovich;Hyelim Yoo	2018		10.1117/12.2322896	remote sensing;radiometric dating;geography	Vision	80.09722167850948	-60.84703697313567	48982
1bd9ceb1449152292cc39612102b7aa28a5e9a05	parameter tuning from pairwise preferences	parameter tuning	That most computer vision algorithms rely on parameters is a fact of life which cannot be avoided. For optimal algorithm performance, these parameters need to be tuned; generally speaking, this tuning is done manually or in some heuristic fashion. In this paper, we propose a new, general method for attacking the problem of parameter tuning, which is applicable to a wide variety of computer vision algorithms. Our method is semi-automatic: a user is given several pairs of outputs from a given vision algorithm, which have been generated by different parameter values; the user is then required to simply choose, for each pair, which output is preferred. Our method then finds the smoothest preference function which satisfies these user preferences. Using the theory of Reproducing Kernel Hilbert Spaces, we show how this problem can be reduced to a finite-dimensional convex optimization. We validate our parameter tuning scheme both on simulated data and on the problem of tuning the parameters of an image denoising algorithm.	algorithm;computer vision;convex optimization;edge detection;heuristic;hilbert space;mathematical optimization;noise reduction;semiconductor industry;smoothing;spaces;user (computing)	Pavel Kisilev;Daniel Freedman	2010		10.5244/C.24.4	mathematical optimization;computer science;theoretical computer science;machine learning;mathematics	Vision	57.87328724624811	-73.12974704456543	49060
3462386a3e1fccd0b8f701090150e40bde5fdbaf	a parallel scheme for large-scale polygon rasterization on cuda-enabled gpus			cuda;graphics processing unit;rasterisation	Chen Zhou;Zhenjie Chen;Yuzhe Pian;Ningchuan Xiao;Manchun Li	2017	Trans. GIS	10.1111/tgis.12213		HPC	68.19360562352749	-52.76039580727043	49066
ddb572acf970bfbaeb9abb5010409267702b10fd	data reduction of hyperspectral remote sensing data for crop stress detection using different band selection methods	fungal pathogens;decision support;bhattacharyya distance;crop stress detection sensor based decision support agricultural management fungal pathogen infections site specific fungicide applications spectral reflectance contiguous bands electromagnetic spectrum stress dependent shifting spectral wavelengths spectral information pathogen infected areas data reduction hyperspectral image data band selection techniques wheat bhattacharyya distance decision tree analysis aisa band selection hyperspectral remote sensing data;fungal infection;band selection;decision tree;remote sensing agriculture agrochemicals crops data reduction decision trees;stress detection aisa band selection bhattacharyya distance decision tree analysis;spectrum;hyperspectral sensors hyperspectral imaging remote sensing crops stress reflectivity testing pathogens sensor phenomena and characterization agriculture;remote sensing;spectral reflectance;stress detection;hyperspectral data;aisa;hyperspectral remote sensing;crops;agriculture;data reduction;decision trees;hyperspectral image;agrochemicals;decision tree analysis	The demand for sensor-based decision support in agriculture is rapidly growing which enhances precision of agricultural management. A fast and precise identification of fungal pathogen infections in crops is essential for the implementation of site-specific fungicide applications. Hyperspectral data collect spectral reflectance in contiguous bands over a broad range of the electromagnetic spectrum that allows examining stress-dependent shifting in certain spectral wavelengths caused by fungal infections. However, not all spectral information is needed for an accurate determination of pathogen infected areas. This study focuses on data reduction of hyperspectral image data for the identification of relevant and redundant information within the spectrum. By applying band selection techniques, different variants of fungal infected and vital wheat stands could be accurately differentiated and infected areas were localized.	decision support system	Thorsten Mewes;Jonas Franke;Gunter Menz	2009	2009 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2009.5418292	computer vision;decision support system;computer science;machine learning;decision tree;remote sensing	Embedded	80.80008540701965	-58.58289442464726	49100
dc8169c9ef85f77ca5877a810ed1adb01fcb598e	wavelet packet compression of medical images	image resolution;data compression;lossy compression;statistical significance;transform coding;picture archiving and communication system;wavelet packet;medical image;parameter selection;image compression;image representation;image quality;experimental measurement;biomedical application	The increasing need for efficient image storage and transmission in hospitals imposes heavy requirements on the design of picture archiving and communication systems. Thus new methods are needed for efficient image compression. Recent reviews of wavelets in biomedical applications showed that wavelets should be used with caution and that a particular solution should always be motivated by the problem itself. This study discovers the best design parameters for a data compression scheme applied to medical images of different imaging modalities. The proposed technique aims at reducing the transmission cost while preserving the diagnostic integrity. By selecting the wavelet packet’s filters, decomposition level and subbands that are better adapted to the frequency characteristics of the image, one may achieve better image representation in the sense of lower entropy or minimum distortion. Experimental results show that the selection of the best parameters has a dramatic effect on the data compression rate of medical images. Statistical significance tests were performed on the experimental measures to conduct the most suitable wavelet shape for each imaging modality. Image quality measures are used to evaluate the performance of different wavelet filters for different imaging modalities. Image resolution is found to have a remarkable effect on the compression rate.  2002 Elsevier Science (USA)	archive;biorthogonal wavelet;coefficient;data compression;distortion;emoticon;fingerprint;image compression;image quality;image resolution;lenna;medical imaging;modality (human–computer interaction);network packet;overhead (computing);packet switching;peak signal-to-noise ratio;picture archiving and communication system;requirement;screen burn-in;selection algorithm;wavelet packet decomposition;wavelet transform	Ahmed S. Tolba	2002	Digital Signal Processing	10.1006/dspr.2001.0401	data compression;image quality;lossy compression;computer vision;data compression ratio;transform coding;speech recognition;image resolution;image processing;transparency;image compression;computer science;theoretical computer science;digital image processing;mathematics;lossless compression;statistical significance;picture archiving and communication system;fractal compression;texture compression;statistics	Graphics	57.095655356166255	-79.74795057989725	49220
17a27d51eeee4e550aab39f94bca6fe444a22bc8	edge preserved image compression using extended shearlet transform	anisotropic property;extended shearlet transform;thresholding	Corresponding Author: Thayammal, S. Department of ECE Dhanalakshmi College of Engineering, Chennai-601 301, Tamil Nadu, India Email: tha_supa2003@yahoo.co.in Abstract: The motivation of the proposed compression method is to reduce the bit rate for image transmission or memory requirement for image storage while maintaining image quality. The edges are one of the prominent features in an image and they are essential for maintaining image quality. JPEG compression standards like JPEG98 and JPEG2000 produce visual artifacts in reconstructed image at low bit rate because, they didn’t tailored about the detailed information like edges. Hence second generation coding introduced to preserve edge information, in which approximation and detailed information are separately encoded, so that, it introduces additional computational time and complexity. A multi directional anisotropic shearlet transform provides an optimally efficient representation of images with edges whereas wavelet transform have limited capability in dealing with edge information in all directions. Here, multidirectional transform called extended shearlet transform is used to uncorrelate the input gray level values with edge preserving capabiltiy. Hard thresholding method is applied to transform coefficients and finally threshold output is encoded using Set Partitioning In Hierarchical Trees (SPIHT) technique. The comparative analysis is performed between Edge Preserved Wavelet Transform coding (EPWT) and the extended shearlet transform coding. Image quality is measured objectively using peak signal-to-noise ratio, Structural Similarity Index (SSIM) and subjectively, using perceived image quality. The simulation results show that, the extended shearlet based compression technique is more efficient than EPWT coding technique for wide range of geometrical features of the images. Quantitative analysis on standard test images show that the proposed technique outperforms the EPWT coding technique by 0.16 to 1.46 dB of PSNR with less computational time.	approximation;coefficient;data compression;decibel;discrete wavelet transform;electrical engineering;email;expanded memory;grayscale;image compression;image quality;iteration;jpeg 2000;multispectral image;peak signal-to-noise ratio;qualitative comparative analysis;second generation multiplex plus;set partitioning in hierarchical trees;shearlet;simulation;standard test image;structural similarity;thresholding (image processing);time complexity;transform coding;visual artifact	S. Thayammal;D. Selvathi	2015	JCS	10.3844/jcssp.2015.82.88	computer vision;theoretical computer science;pattern recognition;thresholding	Vision	60.72945975621827	-65.66006610150791	49268
0bcd2e5f6352c36d6bc9e8fd9980753bc3d04929	multidimensional image enhancement from a set of unregistered and differently exposed images	baja resolucion;interpolation;high resolution;accentuation image;surveillance;0130c;tiempo exposicion;low resolution;nccr mics;basse resolution;image multiple;digital camera;imagen multiple;qualite image;exposure time;high dynamic range imaging;multiple image;algorithme;digital cameras;image enhancement;haute resolution;response function;monitoring;ivrg;image quality;temps exposition;pixel;imaging;dynamic range;super resolution;formation image;response functions;algorithms;calidad imagen;high resolution imager;monitorage;superresolution;high dynamic range;monitoreo;4230v;superresolucion;cameras;high resolution methods;nccr mics cl1;fonction reponse	If multiple images of a scene are available instead of a single image, we can use the additional information conveyed by the set of images to generate a higher quality image. This can be done along multiple dimensions. Super-resolution algorithms use a set of shifted and rotated low resolution images to create a high resolution image. High dynamic range imaging techniques combine images with different exposure times to generate an image with a higher dynamic range. In this paper, we present a novel method to combine both techniques and construct a high resolution, high dynamic range image from a set of shifted images with varying exposure times. We first estimate the camera response function, and convert each of the input images to an exposure invariant space. Next, we estimate the motion between the input images. Finally, we reconstruct a high resolution, high dynamic range image using an interpolation from the non-uniformly sampled pixels. Applications of such an approach can be found in various domains, such as surveillance cameras, consumer digital cameras, etc.	algorithm;autostereogram;closed-circuit television;conditional random field;digital camera;frequency response;handheld game console;high dynamic range;high-dynamic-range imaging;image editing;image resolution;interpolation;pixel;range imaging;super-resolution imaging	Ali Ajdari Rad;Laurence Meylan;Patrick Vandewalle;Sabine Süsstrunk	2007		10.1117/12.704004	medical imaging;shift-and-add;computer vision;image resolution;image processing;digital image processing;optics;sub-pixel resolution;image formation;physics;superresolution;computer graphics (images)	Vision	61.66203984108952	-58.340239513835634	49286
1f82be03edfa4d90e97a047da8d85fe978a760d8	a hybrid segmentation and d-bar method for electrical impedance tomography	beltrami equation;scattering transform;edge preserving;35r30;electrical impedance tomography;d bar method	The regularized D-bar method for electrical impedance tomography (EIT) provides a rigorous mathematical approach for solving the full nonlinear inverse problem directly, i.e., without iterations. It is based on a low-pass filtering in the (nonlinear) frequency domain. However, the resulting D-bar reconstructions are inherently smoothed, leading to a loss of edge distinction. In this paper, a novel method that combines a D-bar approach with the edge-preserving nature of total variation (TV) regularization is presented. The method also includes a data-driven contrast adjustment technique guided by the key functions (CGO solutions) of the D-bar method. The new TV-enhanced D-bar method produces reconstructions with sharper edges and improved contrast. This is achieved by using the TV-induced edges to increase the truncation radius of the scattering data in the nonlinear frequency domain, thereby increasing the radius of the low-pass filter. The algorithm is tested on numerically simulated noisy EIT data and demonstrates significant improvements in edge preservation and contrast which can be highly valuable for absolute EIT imaging.	algorithm;characteristic impedance;electromagnetically induced transparency;iteration;list of astronomical catalogues;low-pass filter;nominal impedance;nonlinear system;numerical analysis;smoothing;tomography;truncation	S. J. Hamilton;Juan Manuel Reyes;Samuli Siltanen;Xiangrong Zhang	2016	SIAM J. Imaging Sciences	10.1137/15M1025992	mathematical optimization;mathematical analysis;electrical impedance tomography;beltrami equation;mathematics;geometry	Vision	55.739915515575895	-69.4895807049232	49293
48b733b5dfd62fe0eb7ccd74ed9ed216b0fcce66	the study of improved marker-controlled watershed crown segmentation algorithm	geophysical image processing;vegetation mapping;manuals;image recognition;mathematical morphology;theoretical model;forestry;image segmentation;populus;china improved marker controlled watershed crown segmentation algorithm tree detection crown delineation spatial resolution remotely sensed imagery forest management decisions sustainable forest management mathematical morphology quickbird satellite images populus 1 72 plantation nan gen village hai kou town anhui province;vegetation;remote sensing imagery;watershed transform;remote sensing;high spatial resolution remote sensing imagery;satellite image;high spatial resolution remote sensing imagery marker controlled watershed crown segmentation algorithm tree measuration;vegetation image segmentation spatial resolution manuals remote sensing algorithm design and analysis image recognition;tree measuration;marker controlled watershed crown segmentation algorithm;algorithm design;algorithm design and analysis;sustainable development;vegetation mapping forestry geophysical image processing image segmentation mathematical morphology remote sensing sustainable development;forest management;high spatial resolution;sustainable forest management;spatial resolution	Automated or semi automated tree detection and crown delineation using high spatial resolution remotely sensed imagery provides a potentially efficient means to acquire information needed for forest management decisions, sustainable forest management. The presented approach develops an improved mathematical morphology based marker-controlled watershed crown segmentation algorithm for crown segmentation. This method is be put on the Quick Bird satellite images in Populus I-72 plantation even stand at Nan Gen village Hai Kou town in Anhui Province of China. Segmentation using the watershed transform works better if you can identify or mark foreground objects and background locations. We analyze the theoretic model, applicability, precision, experiment condition, verification method, error analyse and limitation of this method. This algorithm does not take into account the classification and only gets the image segment for further analyzing. We overlap the segmentation result with original image by manually crown delineation. By visual appraise, this algorithm works well. Average tree numbers identification error is 36%. We discuss the improvement ways to get better results.	algorithm;crown group;image segmentation;mathematical morphology;nan;semiconductor industry;theory;watershed (image processing)	Guang Deng;Zengyuan Li	2011	2011 Seventh International Conference on Computational Intelligence and Security	10.1109/CIS.2011.353	algorithm design;computer vision;computer science;scale-space segmentation	Vision	76.79618084216192	-57.02187775643089	49298
7cea979dda1c56c239a7d22683730ffd67dc2368	lulc database updating from vhr images and lidar data using evidence theory	segmentation;pattern recognition;lidar	Urban growth and the development of urban plans make cities grow and substantially alter, in relatively short time periods, their land covers and land uses (LULC). To take control of this urban growth, it is important to create and update the LULC database. In this work, a method to automatically extract land covers from satellite VHR imagery and LIDAR data is presented. This method is based on the Dempster-Shafer evidence theory. The efficiency of this method is tested in three test sites in the Spanish city of Gijón. The provided results are compared with the SIOSE database in order to determine changes in the LULC.	database;decision problem;emoticon;rasterisation	Borja Rodríguez-Cuenca;María Concepcion Alonso;Agustin Tames-Noriega	2015			computer vision;pattern recognition;remote sensing	ML	78.91972579762295	-57.332946935954396	49376
7480ed0a25c3f0a2704005bb327b26a0c23a73f5	metal-dielectric object classification by polarization degree map	digital camera;image classification;polarisation computer vision image classification object detection;polarization filter metal dielectric object classification polarization degree map material classification object surfaces captured image data computer vision degree of polarization specular highlight spatial distribution digital camera;optical polarization dielectric materials optical reflection inorganic materials digital cameras digital filters fresnel reflection lighting histograms computer vision;computer vision;spatial distribution;object classification;polarisation;degree of polarization;object detection	Material classification of object surfaces from captured image data is an essential problem in computer vision. The present paper proposes a method for stably classifying the material of an object surface based on the distribution of the degree of polarization (DOP) around specular highlight on the surface. We show that the characteristic of spatial distribution for DOP is remarkably different in metal and dielectric substance. Based on the characteristic, an algorithm is presented for effectively classifying any object surface into two material categories from images captured by a digital camera with rotating a polarization filter. The feasibility of the proposed method is verified on experiments using a variety of object surfaces made of different materials.	algorithm;computer vision;concave function;degree of polarization;digital camera;experiment;polarization (waves);specular highlight	Shoji Tominaga;Tetsuya Yamamoto	2008	2008 19th International Conference on Pattern Recognition	10.1109/ICPR.2008.4761574	computer vision;contextual image classification;degree of polarization;computer science	Robotics	60.218395968973454	-52.85548042588361	49412
36b167d3f28e4ae9212a8127b353d5eaf9a58b85	object boundary based denoising for depth images		Economical RGB-D cameras such as Kinect can produce both RGB and depth (RGB-D) images in real-time. The accuracy of various RGB-D related applications suffers from depth image noise. This paper proposes a solution to the problem by estimating depth edges that correspond to the object boundaries and using them as priors in the hole filling process. This method exhibits quantitative and qualitative improvements over the current state-of-the-art methods.	noise reduction	Mayoore S. Jaiswal;Yu-Ying Wang;Ming-Ting Sun	2017		10.1007/978-3-319-59876-5_15	pattern recognition;artificial intelligence;computer science;computer vision;image noise;noise reduction;prior probability;edge detection;rgb color model	Robotics	56.69074962823759	-57.516266765759774	49469
8c649839db2250f077507ebb0199a7c733e24405	on the use of a multispectral markov random field model for texture analysis in multitemporal sar imagery	speckle;image segmentation;lattices;multispectral markov random field model;markov random fields;markov random field;image texture;grey level markov random field model;remote sensing by radar;texture analysis;noise models;multitemporal sar imagery;technology and engineering;geophysical signal processing;radar imaging;information processing;sar image;noise models multispectral markov random field model texture analysis multitemporal sar imagery multispectral extension grey level markov random field model synthetic aperture radar;image analysis;humans;image texture analysis;markov processes;multispectral extension;information analysis;noise synthetic aperture radar radar imaging geophysical signal processing markov processes image texture remote sensing by radar;noise;synthetic aperture radar;markov random fields synthetic aperture radar image texture analysis speckle image analysis information analysis lattices information processing humans image segmentation	In this paper we propose the use of the multispectral extension of the grey level Markov random field model for multitemporal texture analysis in Synthetic Aperture Radar (SAR) imagery. This extension is not a straightforward one, due to problems specific to the nature of these multitemporal SAR images. To circumvent these problems, as well as the computational burden, we propose another simple method for the calculation of the model parameters. These models are examined for their texture characterisation ability, as well as their behaviour under several noise models.	computation;grayscale;markov chain;markov random field;multispectral image	Gunther Heene	1999		10.1109/ISSPA.1999.815826	speckle pattern;image texture;computer vision;image analysis;synthetic aperture radar;information processing;computer science;noise;pattern recognition;lattice;image segmentation;markov process;data analysis;radar imaging	Vision	71.59623920977604	-61.96987524331466	49486
faff5a15508a73a95f9f64f040ce46f35f58373d	hisui vicarious calibration and cal/val activities	calibration satellites earth remote sensing atmospheric measurements lakes extraterrestrial measurements;hyperspectral imaging calibration geophysical image processing;terra aster hisui vicarious calibration cross calibration eo 1 hyperion eo 1 ali landsat 7 etm;meti hyperspectral imager suite hisui instrument vicarious calibration cross calibration cal val japanese next generation earth observation project japanese ministry of economy trade and industry	The Hyperspectral Imager Suite (HISUI) is the Japanese next-generation Earth observation project, and is being developed by Japanese Ministry of Economy, Trade, and Industry (METI). We conduct the vicarious calibration for HISUI instrument as the pre-launch activities in summer in the southern hemisphere. Recent our activities focus on vicarious calibration experiment over Lake Lefroy, which is a large salt lake in southern Western Australia. Cross-calibration for HISUI is also discussed. This paper shows both of vicarious calibration and cross-calibration for HISUI instrument.	cal;kaby lake;pretail;variable assembly language	Hirokazu Yamamoto;Kenta Obata;Toru Kouyama;Satoshi Tsuchida	2014	2014 IEEE Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2014.6947001	hydrology;remote sensing	Embedded	80.5172869487156	-61.5549218912992	49505
69aef0611d513f25c470ac2d13b5db346a5d9859	vhr geoeye-1 imagery reveals an ancient water landscape at the longcheng site, northern chaohu lake basin (china)	vhr remote sensing;segmentation;archaeological;classification;longcheng;geoeye 1	This study mainly focuses on revealing an ancient water landscape at the Longcheng site in the northern Chaohu Lake Basin using very highresolution (VHR) GeoEye-1 imagery. First, prior to classification, the GeoEye-1 image was processed following atmospheric and geometric correction. The supervised classification was carried out in order to show the land-cover situation in the Longcheng area. The overall classification accuracy was 89.98%, with a kappa coefficient of 0.87. The moat system around the city walls was discovered by using rule-based objectoriented segmentation of the postclassified image, and the other walls of ancient Longcheng were manually identified from the pansharpened VHR GeoEye-1 image. Finally, a map of the ancient water landscape containing the ancient city, wall and moat at the Longcheng site was produced. This paper demonstrates that VHR remote sensing has the ability to uncover an ancient water landscape and provide new insights for archaeological and paleoenvironmental studies. ARTICLE HISTORY Received 22 February 2016 Accepted 16 July 2016		Lei Luo;Xinyuan Wang;Jie Liu;Huadong Guo;Xin Zong;Wei Ji;Hui Cao	2017	Int. J. Digital Earth	10.1080/17538947.2016.1214983	geography;biological classification;segmentation;cartography;remote sensing	ML	79.99245404376951	-57.52949688092364	49549
b1a4720ed67f13ddb2d1b4913f2d260906e43dbb	frequency analysis of transient light transport with applications in bare sensor imaging	light transport;time of flight;frequency analysis;fourier analysis;lensless imaging	1. Fourier transform of time-resolved light field after propagation in free space (Eq.4 in the main text) 2. Convolution kernel and its properties: (Eq.5 in the main text) 3. From time-resolved to steady-state light field: (Sec.3 second to last paragraph in the main text) 4. Streak spectrum for Lambertian scenes: (Eq.7 in the main text) 5. Fourier transform of a streak image of a pulsed point source illuminating the scene: (Eq.8 in the main text)	convolution;frequency analysis;lambertian reflectance;light field;software propagation;steady state	Di Wu;Gordon Wetzstein;Christopher Barsi;Thomas Willwacher;Matthew O'Toole;Nikhil Naik;Qionghai Dai;Kiriakos N. Kutulakos;Ramesh Raskar	2012		10.1007/978-3-642-33718-5_39	time of flight;mathematics;fourier analysis;frequency analysis	Vision	63.93859786934401	-55.68739980585339	49788
9273f6ada829c501936a0cd540cc2396e7a89761	qualitative constraints for structure-from-motion	qualitative constraint	Existing computational models of structure-from-motion are all based on a quantitative analysis of variations in optical flow or feature point correspondences within the interiors of single objects. We present an alternative approach effective for objects rotating in depth. The method involves a set of qualitative constraints on shape and motion based on patterns of flow at surface boundaries. These constraints are used in the development of a simple approximation technique for recovering surface shape. The approach is based on large-magnitude effects that are likely to be easily extracted, even from noisy data. In addition, it explains a variety of phenomena described in the literature on human vision that cannot be accounted for by any existing computational model of structure-from-motion.	approximation;computational model;optical flow;signal-to-noise ratio;structure from motion	William B. Thompson;James S. Painter	1992	CVGIP: Image Understanding	10.1016/1049-9660(92)90086-I	computer vision;mathematical optimization;mathematics;geometry	Vision	53.85770893501962	-52.18452487790425	49878
e2d097fcdeab4642343cdec4e6deccfd2c47e1ac	localized image enhancement using depth map	image segmentation image color analysis image enhancement lighting heuristic algorithms biomedical imaging data structures;image segmentation;biomedical imaging;color information preservation localized image enhancement depth map medical purposes laminography spatial queue based data structure singular value decomposition svd;singular value decomposition data structures image colour analysis image enhancement;image enhancement;image color analysis;data structures;heuristic algorithms;lighting	The main objective of this paper is to propose a method for localized image enhancement. This method can be highly beneficial in medical purposes, like Laminography, or in enhancing images captured under non-uniform illumination. Along with a depth map, a spatial queue-based data structure is used to properly locate the area to be enhanced in the captured scene. There are automated techniques to detect areas where enhancement is required, but these methods suffer heavily with false detections, which, in turn, deteriorate the perceptual quality of the image. In the proposed algorithm, the area to be enhanced can be detected exactly with a minimum user intervention. After detecting, the area is enhanced using a singular value decomposition (SVD) based technique which preserves the color information of the scene and can enhance the scene in real time.	algorithm;data structure;depth map;image editing;sensor;singular value decomposition	Saumik Bhattacharya;Sumana Gupta;K. S. Venkatesh	2014	2014 IEEE International Symposium on Signal Processing and Information Technology (ISSPIT)	10.1109/ISSPIT.2014.7300587	medical imaging;image texture;image restoration;computer vision;feature detection;color image;data structure;binary image;image processing;computer science;machine learning;lighting;image segmentation;image-based lighting;computer graphics (images)	Vision	56.7046642352534	-60.411117123990266	49956
765555317b9912e53dbd2a50b8b21d5bfa1bd308	a cellular architecture for ray tracing		We propose in this paper a massively parallel machine dedicated to image synthesis by discrete ray tracing techniques. This machine is a four-stage pipeline, the last stage being a bidimensional cellular array with one cell per pixel. Two main phases describe its behaviour: • Loading into the cellular array of the objects of the scene to be displayed, after having been transformed into sets of planar polygons, and then into voxels. • Cellular ray tracing over the fully distributed scene. The first phase allows us to see this machine as a massively parallel (not realistic) rendering unit: at the end of the loading phase: objects are fully identified pixel per pixel in the cellular array. Then, we have only to display the computed visual features (by means of Gouraud or Phong-like incremental methods during the loading phase). The second phase increases the image quality by executing the ray tracing algorithm in a very special way, i.e., completely distributed all over the many cells of the array. In that phase, objects are seen as split into voxels into a virtual 3D memory space. The machine is an attempt to bring a dramatic answer to the problem of performance, taking into account not only the computational power required for image synthesis by using a massive parallelism, but also the realization costs by using very regular structures, which make it a VLS1-oriented architecture.	algorithm;cellular architecture;computation;dspace;gouraud shading;image quality;parallel computing;phong shading;pixel;ray tracing (graphics);rendering (computer graphics);voxel	Abdelghani Atamenia;Michel Mériaux;Eric Leprêtre;Samuel Degrande;Bruno Vidal	1990		10.2312/EGGH/EGGH90/085-091	computer vision;computer science;theoretical computer science;computer graphics (images)	ML	68.57132887554768	-53.14697731414175	50053
6e1d362a7b8bd54e3e98ba53dbd78f8c20521f86	dictionary learning-based inpainting on triangular meshes		The problem of inpainting consists of filling missing or damaged regions in images and videos in such a way that the filling pattern does not produce artifacts that deviate from the original data. In addition to restoring the missing data, the inpainting technique can also be used to remove undesired objects. In this work, we address the problem of inpainting on surfaces through a new method based on dictionary learning and sparse coding. Our method learns the dictionary through the subdivision of the mesh into patches and rebuilds the mesh via a method of reconstruction inspired by the Non-local Means method on the computed sparse codes. One of the advantages of our method is that it is capable of filling the missing regions and simultaneously removes noise and enhances important features of the mesh. Moreover, the inpainting result is globally coherent as the representation based on the dictionaries captures all the geometric information in the transformed domain. We present two variations of the method: a direct one, in which the model is reconstructed and restored directly from the representation in the transformed domain and a second one, adaptive, in which the missing regions are recreated iteratively through the successive propagation of the sparse code computed in the hole boundaries, which guides the local reconstructions. The second method produces better results for large regions because the sparse codes of the patches are adapted according to the sparse codes of the boundary patches. Finally, we present and analyze experimental results that demonstrate the performance of our method compared to the literature.	approximation algorithm;code;coherence (physics);data compression;dictionary;experiment;inpainting;machine learning;missing data;neural coding;non-local means;polygon mesh;software propagation;sparse matrix;subdivision surface;triangulated irregular network	Lizeth Joseline Fuentes Perez;Luciano Arnaldo Romero Calla;Anselmo Antunes Montenegro	2018	CoRR		mathematics;discrete mathematics;inpainting;missing data;neural coding;polygon mesh;pattern recognition;artificial intelligence	Vision	58.44568969779253	-55.63324371832612	50136
07b921be30f43cfe27bfe5ef1b5567910eeefac7	low cost robust blur estimator	optical transfer functions estimation image restoration image edge analysis;gaussian blur kernel robust blur estimator low pass filtering;gaussian processes;image restoration;costs robustness image edge detection kernel image restoration videos layout frequency domain analysis maximum likelihood estimation laboratories;estimation;low pass filters;optical transfer functions;low pass filters gaussian processes image restoration;image edge analysis	In this paper a novel local blur estimation method is presented. The focal blur process is usually modeled as a Gaussian low-pass filtering and then the problem of blur estimation is to identify the Gaussian blur kernel. In the proposed method, the blurred input image is first re-blurred by Gaussian blur kernels with different blur radii. Then the difference ratios between the multiple re-blurred images and the input image are used to determine the unknown blur radius. We show that the proposed method does not require edge detection preprocessing and can estimate a wide range of blur radius. Experimental results of the proposed method on both synthetic and natural images and a comparison with a state-of-the-art method are presented.	box blur;edge detection;focal (programming language);gaussian blur;low-pass filter;preprocessor;synthetic intelligence	Hao Hu;Gerard de Haan	2006	2006 International Conference on Image Processing	10.1109/ICIP.2006.312411	image restoration;computer vision;mathematical optimization;estimation;low-pass filter;gaussian blur;pattern recognition;gaussian process;mathematics;statistics	Vision	55.01008117874815	-65.56086312393192	50154
673ffb60270f06b45f02ab70c126437fc5344b5d	a novel wavelet image fusion algorithm based on chaotic neural network	weighted averaging;image fusion;energy method;energy function;wavelet transform;chaotic neural network;neural network	In this paper, Transiently Chaotic Neural Network (TCNN) is used in wavelet image fusion method. This paper adopts the weighted average strategy for the fusion of the wavelet transform coefficients. The TCNN outputs the weighting coefficient of every wavelet transform pixel when the energy function of the neural network has achieved the global minimum. At the same time, the average gradient value of the region around every wavelet transform pixel gets the global maximum according to the relationship between the average gradient and energy. The wavelet transform coefficients of the fused image are got by using the weighting coefficients. The advantage of the algorithm is that the weighting coefficient is obtained through the dynamic searching optimization of the average gradient. Experiments show that the average gradient values of the fusion images using the proposed method are greater than the results using the region energy method. The TCNN method improves the performance of the fusion image effectively.	algorithm;artificial neural network;image fusion;wavelet	Hong Zhang;Yan Cao;Yan-feng Sun;Lei Liu	2008		10.1007/978-3-540-69311-6_35	wavelet;mathematical optimization;second-generation wavelet transform;continuous wavelet transform;machine learning;pattern recognition;cascade algorithm;mathematics;wavelet packet decomposition;stationary wavelet transform;discrete wavelet transform;lifting scheme;wavelet transform	Robotics	58.61972512504831	-66.97065777185443	50187
0823bc9af3a0b47639ccd416541502e851714de7	online blind calibration of non-uniform photodetectors: application to endomicroscopy		We present an original method for the online blind calibration of non-uniform photodetectors. The disparity of the detectors may arise from both irregular spatial arrangement and distinct slowly time-varying photometric transfer functions. As natural images are mostly continuous, the signal collected by neighboring detectors is strongly correlated over time. The core idea of our method is to translate the calibration problem into relative pairwise calibrations between neighboring detectors followed by the regularized inversion of a system akin to gradient-based surface recovery. From our blind calibration procedure, we design an online blind calibration pipeline compatible with clinical practice. Online blind calibration is proved to be statistically better than standard offline calibration for reconstructing endomicroscopy sequences.	binocular disparity;calibration;detectors;endomicroscopy;gradient;image quality;online and offline;photometry;regression - mental defense mechanism;visually impaired persons;well-posed problem	Nicolas Savoire;Barbara André;Tom Vercauteren	2012	Medical image computing and computer-assisted intervention : MICCAI ... International Conference on Medical Image Computing and Computer-Assisted Intervention	10.1007/978-3-642-33454-2_79	pattern recognition;computer science;artificial intelligence;photometry (optics);calibration;computer vision;robust regression;transfer function;detector;total least squares;photodetector;pairwise comparison	Vision	61.770173401578944	-54.26211277254772	50204
caf1896d3252aa5d984bbf953295c94c2f2b787b	development and application of atmospheric infrared sounder ozone retrieval products for operational meteorology	north atlantic atmospheric infrared sounder ozone retrieval products operational meteorology national aeronautics and space administration short term prediction research and transition geostationary operational environmental satellite r series joint polar satellite system proving grounds transition unique ozone products opc forecasters ocean prediction center atmospheric infrared sounder ozone retrievals rgb air mass imagery airs version 6 level 2 ozone retrievals rapid cyclogenesis hurricane force winds;wind storms weather forecasting;wind forecasting;gases;weather forecasting cyclogenesis hyperspectral infrared meteorology ozone red green blue rgb air mass imagery remote sensing stratospheric air;satellites;terrestrial atmosphere;gases nasa wind forecasting terrestrial atmosphere satellites;nasa	The National Aeronautics and Space Administration Short-term Prediction Research and Transition (SPoRT) Center has worked closely with the Geostationary Operational Environmental Satellite-R series and the Joint Polar Satellite System Proving Grounds to develop and transition unique ozone products derived from Atmospheric Infrared Sounder (AIRS) ozone retrievals to the Ocean Prediction Center (OPC). These products were developed to aid identification of stratospheric air and enhance situational awareness of rapid cyclogenesis and hurricane-force wind events during which stratospheric air may play a key role. OPC forecasters have used the European Organisation for the Exploitation of Meteorological Satellites Meteosat Spinning Enhanced Visible and Infrared Imager red, green, blue (RGB) air mass imagery to identify regions of stratospheric air for their unique weather forecasting challenges; however, the qualitative nature of the new RGB product facilitated a need for quantitative products to enhance forecaster confidence in the RGB air mass imagery. To enhance forecaster interpretation and confidence in the RGB air mass imagery, SPoRT created the total column ozone and ozone anomaly products from hyperspectral infrared sounder ozone retrievals. AIRS Version 6 Level-2 ozone retrievals were utilized to create hourly ozone products over a northwest hemisphere domain. An example case study from February 24-27, 2014, shows the utility of the ozone products in enhancing interpretation of the RGB air mass imagery for anticipating rapid cyclogenesis and hurricane-force winds in the North Atlantic.	anomaly detection;image sensor;open platform communications	Emily B. Berndt;Bradley T. Zavodsky;Michael J. Folmer	2016	IEEE Transactions on Geoscience and Remote Sensing	10.1109/TGRS.2015.2471259	meteorology;astronomy;atmospheric sciences;physics;satellite;remote sensing	Visualization	81.21062170241665	-61.74463722007861	50313
bb6bfd6b191a1f520431c2bf641a99dcbf8d16b2	a cnn-based fusion method for feature extraction from sentinel data		Sensitivity to weather conditions, and specially to clouds, is a severe limiting factor to the use of optical remote sensing for Earth monitoring applications. A possible alternative is to benefit from weather-insensitive synthetic aperture radar (SAR) images. In many real-world applications, critical decisions are made based on some informative optical or radar features related to items such as water, vegetation or soil. Under cloudy conditions, however, optical-based features are not available, and they are commonly reconstructed through linear interpolation between data available at temporally-close time instants. In this work, we propose to estimate missing optical features through data fusion and deep-learning. Several sources of information are taken into account—optical sequences, SAR sequences, digital elevation model—so as to exploit both temporal and cross-sensor dependencies. Based on these data and a tiny cloud-free fraction of the target image, a compact convolutional neural network (CNN) is trained to perform the desired estimation. To validate the proposed approach, we focus on the estimation of the normalized difference vegetation index (NDVI), using coupled Sentinel-1 and Sentinel-2 time-series acquired over an agricultural region of Burkina Faso from May–November 2016. Several fusion schemes are considered, causal and non-causal, single-sensor or joint-sensor, corresponding to different operating conditions. Experimental results are very promising, showing a significant gain over baseline methods according to all performance indicators.	artificial neural network;baseline (configuration management);causal filter;convolutional neural network;deep learning;digital elevation model;feature extraction;information;linear interpolation;map;radar;synthetic data;time series	Giuseppe Scarpa;Massimiliano Gargiulo;Antonio Mazza;Raffaele Gaetano	2018	Remote Sensing	10.3390/rs10020236	artificial intelligence;limiting factor;normalized difference vegetation index;geology;elevation;convolutional neural network;computer vision;radar;feature extraction;sensor fusion;synthetic aperture radar	ML	75.41199180568735	-60.214254382727376	50317
26eb2d50ed805529bc2033c33af99cd80d8467e6	change detection of multitemporal sar data in urban areas combining feature-based and pixel-based techniques	extraction information;software;teledetection spatiale;zona urbana;errors;change detection;observation multitemporelle;erreur;space remote sensing;logiciel;radar antenne synthetique;geometry;zone urbaine;geometrie;detection;earthquake feature level change detection algorithm linear element extraction synthetic aperture radar multitemporal sar data urban areas feature based technique pixel based technique airborne sar data satellite sar data getty museum los angeles bam iran;algorithme;remote sensing by radar;teledeteccion espacial;urban areas;synthetic aperture radar sar;feature extraction;radar imaging;pixel;sar image;synthetic aperture radar sar change detection linear element extraction;synthetic aperture radar airborne radar feature extraction geophysical techniques radar imaging remote sensing by radar;urban area;algorithms;airborne radar;geometria;urban areas radar detection synthetic aperture radar change detection algorithms algorithm design and analysis pixel geometry satellites cities and towns earthquakes;error;radar ouverture synthetique;geophysical techniques;linear element extraction;los angeles;algoritmo;radar synthese ouverture;synthetic aperture radar	In this paper, the problem of change detection from synthetic aperture radar (SAR) images is addressed. Feature-level change-detection algorithms are still in their preliminary design stage. Indeed, while pixel-based approaches are already implemented into existing, commercial software, this is not the case for feature comparison approaches. Here, the authors propose a joint use of both approaches. The approach is based on the extraction and comparison of linear features from multiple SAR images, to confirm pixel-based changes. Though simple, the methodology proves to be effective, irrespectively of misregistration errors due to reprojection problems or difference in the sensor's viewing geometry, which are common in multitemporal SAR images. The procedure is validated through synthetic examples, but also two real change-detection situations, using airborne and satellite SAR data over the area of the Getty Museum, Los Angeles, as well as over an area around the city of Bam, Iran, stricken in 2003 by a serious earthquake	airborne ranger;algorithm;commercial software;getty thesaurus of geographic names;map projection;pixel;synthetic intelligence;virtual reality headset	Paolo Gamba;Fabio Dell'Acqua;Gianni Lisini	2006	IEEE Transactions on Geoscience and Remote Sensing	10.1109/TGRS.2006.879498	synthetic aperture radar;feature extraction;radar imaging;change detection;pixel;remote sensing	Vision	76.07983541149154	-59.909935276674815	50459
8a5d54d991ca47af970c0e279814516dd0e6c221	color appearance matching in hard-copy and soft-copy images in different office environments	hardcopies;matrices;colorimetry;color appearance	This paper describes a method for matching the color appearances of hard copies and soft copies in ordinary office environments where lighting conditions usually vary. To develop this method, we studied ways of easily calculating the colorimetric values of hard copies under an arbitrary illuminant. In this report, we converted the colorimetric values of hard copies taken under a reference illuminant to the colorimetric values taken under a viewing illuminant by using a 3-by-3 matrix. The conversion matrix CR under an arbitrary illuminant is calculated by using the following equation: CR equals IH X CRh + (1-IH) X CRl. Here, CRh represents a conversion matrix for a high color-rendering illuminant, and CRl represents a conversion matrix for a low color-rendering illuminant. IH is the coefficient that represents the mixture ratio of high and low color-rendering illuminants. We calculated the colorimetric values of a hard copy under an arbitrary illuminant by using the above method, performed a color adaptation correction, and displayed the soft copy on a monitor. The color appearance of the soft copy matched that of the hard copy well under various illuminants.© (1998) COPYRIGHT SPIE--The International Society for Optical Engineering. Downloading of the abstract is permitted for personal use only.		Yoshinobu Shiraiwa;Yumiko Hidaka;Toshiyuki Mizuno;Takashi Sasaki;Ken'ichi Ohta;Akihiro Usami	1998		10.1117/12.298275	computer vision;colorimetry;optics;standard illuminant;matrix;computer graphics (images)	ML	60.807823026861314	-59.78446602678419	50539
0c86ecd199b402108676a9b299d36225c8840912	novel 2-d mmse subpixel-based image down-sampling for matrix displays	image sampling;optimal solution;image resolution;least mean squares methods;image reconstruction model;apparent luminance resolution 2d mmse subpixel based image down sampling matrix displays image resolution chrominance distortion image reconstruction model;distortion measurement;least mean squares methods brightness distortion image reconstruction image sampling;manganese;brightness;distortion;image color analysis;image reconstruction;pixel;apparent luminance resolution;2d mmse;sampling methods;matrix displays;rendering computer graphics;subpixel based image down sampling;computer displays image resolution low pass filters image reconstruction rendering computer graphics personal digital assistants gold pixel distortion measurement glass;chrominance distortion	Subpixel-based down-sampling is a method that can potentially improve the apparent resolution of a down-scaled image by controlling individual subpixels rather than pixels. However, the increased luminance resolution often comes at the price of chrominance distortion. In this paper, we propose a new subpixel-based down-sampling scheme for which we design a two-dimensional image reconstruction model. Then, we formulate subpixel-based down-sampling as a MMSE problem and derive the optimal solution called MMSESD. To compare the performance of subpixel-based down-sampling methods, we propose novel objective measures for the apparent luminance resolution and chrominance distortion. Simulation results show that MMSE-SD can give sharper images compared with the conventional down-sampling methods, with little color fringing artifacts.	pixel;sampling (signal processing)	Lu Fang;Oscar C. Au	2010		10.1109/ICASSP.2010.5495307	computer vision;image resolution;distortion;telecommunications;computer science;manganese;mathematics;brightness;pixel;computer graphics (images)	Vision	60.196996926026394	-59.22307135584144	50674
55163f1e425ba967b1f8af155234ccf75a4bd8a6	ground-based interferometric radar for dynamic deformation monitoring of the ting kau bridge in hong kong	azimuth;bridges;monitoring;structural health monitoring ground based interferometric radar dynamic deformation monitoring ting kau bridge hong kong geoscience engineering geodesy man made structures buildings towers dams bridges real aperture radar system gamma portable radar interferometer gpri ii cable stayed bridge tsuen wan rotated azimuth scanning fixed azimuth scanning oscillation monitoring;radar antennas;bridges monitoring radar antennas radar imaging spaceborne radar azimuth;radar imaging;ting kau bridge dynamic deformation monitoring gamma portable radar interferometer structural health monitoring;radar interferometry condition monitoring deformation geophysical techniques mechanical variables measurement;spaceborne radar	Ground based interferometric radar (GBIR) is a revolutionary advanced measurement technique for geoscience and engineering geodesy. It is powerful for temporally and spatially dense measurements of highly dynamic target with sub-millimetric accuracy, especially in man-made structures, e.g. buildings, towers, dams and bridges. In this case study, we use a real aperture radar system, the Gamma Portable Radar Interferometer (GPRI-II), to perform near-real-time deformation monitoring of the deck (back side) of a cable-stayed bridge. As a test site, the Ting Kau Bridge at Tsuen Wan, Hong Kong, was continuously measured from two modes of observation, rotated azimuth scanning (RAS) and fixed azimuth scanning (FAS). The results reveal the wind-driven and vehicle-driven non-uniform oscillation of the bridge. The presented works demonstrate the ability of GPRI-II in bridge deformation or oscillation monitoring, which provide a new way for structural health monitoring of bridge.	radar;real-time clock;real-time computing;sandy bridge;temporal logic	Bochen Zhang;Xiaoli Ding;Mi Jiang;Bin Zhang;Songbo Wu;Hongyu Liang	2016	2016 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)	10.1109/IGARSS.2016.7730794	early-warning radar;radar engineering details;radar configurations and types;geodesy;3d radar;interferometric synthetic aperture radar;azimuth;geotechnical engineering;radar imaging;side looking airborne radar;physics;radar;remote sensing	Embedded	80.32106913100478	-64.06336417436071	50749
10fe6e65f8ef470c8f15ffe46ffa5a15ba613f1c	restorer: a visualization technique for handling missing data	data visualisation;image reconstruction;restorer;animation;grayscale;image restoration;interpolated data;luminance values;missing data;missing regions;pseudocoloring;scientific visualization;visualization technique	Pseudocoloring is a frequently used technique in scientific visualization for mapping a color to a data value. When using pseudocolor and animation to visualize data that contain missing regions displayed as black or transparent, the missing regions popping in and out can distract the viewer from the more relevant information. Filling these gaps with interpolated data could lead to a misinterpretation of the data. This paper presents a method for combining pseudocoloring and grayscale in the same colormap. Valid data are mapped to colors in the colormap. The luminance values of the colors bounding areas of missing data are used in interpolating over these regions. The missing data are mapped to the grayscale portion of the colormap. This approach has the advantages of eliminating distracting gaps caused by missing data and distinguishing between those areas that represent valid data and those areas that do not. This approach was inspired by a technique used in the restoration of paintings.	circuit restoration;color;grayscale;heat map;interpolation;missing data;scientific visualization	Ray Twiddy;John Cavallo;Shahram M. Shiri	1994			computer vision;computer science;mathematics;data visualization;grayscale;statistics;computer graphics (images)	Visualization	60.75644018240285	-56.10824186860023	50795
5090f0394dcc3db2996c26c06e412df0421bff9b	depth estimation using structured light flow — analysis of projected pattern flow on an object’s surface		Shape reconstruction techniques using structured light have been widely researched and developed due to their robustness, high precision, and density. Because the techniques are based on decoding a pattern to find correspondences, it implicitly requires that the projected patterns be clearly captured by an image sensor, i.e., to avoid defocus and motion blur of the projected pattern. Although intensive researches have been conducted for solving defocus blur, few researches for motion blur and only solution is to capture with extremely fast shutter speed. In this paper, unlike the previous approaches, we actively utilize motion blur, which we refer to as a light flow, to estimate depth. Analysis reveals that minimum two light flows, which are retrieved from two projected patterns on the object, are required for depth estimation. To retrieve two light flows at the same time, two sets of parallel line patterns are illuminated from two video projectors and the size of motion blur of each line is precisely measured. By analyzing the light flows, i.e. lengths of the blurs, scene depth information is estimated. In the experiments, 3D shapes of fast moving objects, which are inevitably captured with motion blur, are successfully reconstructed by our technique.	displacement mapping;experiment;gaussian blur;image sensor;motherboard;motion capture;movie projector;pixel;structured light;video projector	Ryo Furukawa;Ryusuke Sagawa;Hiroshi Kawasaki	2017	2017 IEEE International Conference on Computer Vision (ICCV)	10.1109/ICCV.2017.497	motion blur;computer vision;artificial intelligence;robustness (computer science);iterative reconstruction;structured light;shutter speed;image sensor;decoding methods;parallel;computer science;optics	Vision	56.70086143374654	-52.08267970487803	50829
a47d138fd6e3758cb7a8537250ff4dc5f8c93233	image super-resolution using multi-layer support vector regression	image superresolution learning based sr algorithms pixel space positions local characteristics smooth areas vertical edges horizontal edges pixel wise classification hr image high resolution image patches lr image low resolution image patches multilayer svr model source image reconstruction single layer svr model multilayer support vector regression;support vector machines image reconstruction image resolution learning artificial intelligence regression analysis;image resolution support vector machines image reconstruction training image edge detection signal resolution computational modeling;pixel wise classification super resolution sr support vector regression svr multilayer	Existing support vector regression (SVR) based image superresolution (SR) methods always utilize single layer SVR model to reconstruct source image, which are incapable of restoring the details and reduce the reconstruction quality. In this paper, we present a novel image SR approach, where a multi-layer SVR model is adopted to describe the relationship between the low resolution (LR) image patches and the corresponding high resolution (HR) ones. Besides, considering the diverse content in the image, we introduce pixel-wise classification to divide pixels into different classes, such as horizontal edges, vertical edges and smooth areas, which is more conductive to highlight the local characteristics of the image. Moreover, the input elements to each SVR model are weighted respectively according to their corresponding output pixel's space positions in the HR image. Experimental results show that, compared with several other learning-based SR algorithms, our method gains high-quality performance.	algorithm;image resolution;lr parser;layer (electronics);pixel;super-resolution imaging;support vector machine	Jie Xu;Cheng Deng;Xinbo Gao;Dacheng Tao;Xuelong Li	2014	2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	10.1109/ICASSP.2014.6854715	image texture;computer vision;feature detection;binary image;computer science;machine learning;pattern recognition;sub-pixel resolution	Vision	59.33561714041763	-66.08897777399643	50858
38d2c2d7cd77851269459ca0f76a9854f2c37a79	climate data records from meteosat first generation part i: simulation of accurate top-of-atmosphere spectral radiance over pseudo-invariant calibration sites for the retrieval of the in-flight visible spectral response				Yves M. Govaerts;Frank Rüthrich;Viju O. John;Ralf Quast	2018	Remote Sensing	10.3390/rs10121959		Mobile	82.00652659238932	-62.43467578964061	50885
346e7374d736e66bf1200ac32028ecf1dbdf0f9b	image processing for computer graphics	image processing;computer graphic	ion paradigm, 3, 8 for image, 107,108 achromatic line, 73 achromatic point, 73 ACM, 105 acuity angle of, 218 adaptive encoding, 136 adaptive filter, 29, 152 addition of signals, 29 additive color formation, 53, 54 Adelson, E., 184 Adobe Systems, 318 algebra of, 184 algorithm Floyd-Steinberg, 234 populosity, 126 algorithms digital halftone, 218 dithering, 311 aliasing, 191 and reconstruction, 210 error, 192 alpha channel, 255 discretization of, 256 alpha-channel compositing, 260 amplitude filter, 307 amplitude discretization, 298 analog signal, 16 analog-electronic image, 297 analytic sampling, 194 Anderson, C., 184 angle of visual acuity, 218 animation, 293 animation morphing, 294 Antunes, Andre, viii aperiodic, see non periodic approximation compression by, 138 area sampling, 28, 116, 193, 194 Arvo,James, 8 atlas color, 99 atop operator, 266 average quantization error, 219 background,252,308 band spectral, 180 bandlimited, 31 bandlimited signal, 191 bandpass filter, 31 bandstop filter, 31 Barnsley, Michael, 141 Barsky, Brian, 269 Bartlett filter, 164, 280 basis primary, 59 Shannon, 40,198,201 Bayer dithering, 231 Bayer, B., 244 Beatty,]. C., 318 Bergen,]., 184 BETACAM color system, 96 bilinear interpolation, 201, 281 binary operation, 146	adaptive filter;algorithm;aliasing;alpha compositing;analog signal;approximation;bandlimiting;bartlett's bisection theorem;bayer filter;bilinear filtering;brian;computer graphics;discretization;dither;floyd–steinberg dithering;image processing;interpolation;morphing;ordered dithering;programming paradigm;quantization (signal processing);sampling (signal processing);shannon (unit);utility functions on indivisible goods	Jonas Gomes;Luiz Velho	1997		10.1007/978-1-4757-2745-6	computer vision;image processing;computer science;digital image processing;real-time computer graphics;multimedia;computer graphics;computer graphics (images)	Graphics	64.94358661868856	-55.3559788151222	50990
04b7fd6a45d6ddd611a65b62cce674a63a35dd1d	fuzzification of a crisp near-real-time operational automatic spectral-rule-based decision-tree preliminary classifier of multisource multispectral remotely sensed images	crisp near real time operational automatic spectral rule fuzzification;decision tree classifier;stratified hierarchical context sensitive application dependent modules;remote sensing image;geophysical image processing;fuzzy rule based system;radiometric calibration;decision tree;image resolution;top down;earth;rule based;measurement system;system of systems;image classification;prior knowledge;remote sensing rs decision tree classifier fuzzy rule based system image classification prior knowledge radiometric calibration;fuzzy set theory;multisource multispectral remotely sensed images;radiometry;global earth observation system of systems;class specific feature extraction;radiometry calibration decision trees pixel earth remote sensing satellites;map information;first stage pixel based application independent top down preliminary classifier;feature extraction;global monitoring for the environment and security;remote sensing;satellites;pixel;automatic near real time per pixel multisource multiresolution;knowledge representation crisp near real time operational automatic spectral rule fuzzification decision tree preliminary classifier multisource multispectral remotely sensed images hierarchical hybrid remote sensing image understanding system architecture first stage pixel based application independent top down preliminary classifier stratified hierarchical context sensitive application dependent modules class specific feature extraction class specific feature classification automatic near real time per pixel multisource multiresolution application independent spectral rule based decision tree classifier global earth observation system of systems global monitoring for the environment and security map information;membership function;satellite remote sensing;cartography;earth observation;class specific feature classification;multispectral imagery;physical model;near real time;decision tree preliminary classifier;knowledge representation;decision trees;remote sensing rs	Proposed in recent literature, a novel two-stage stratified hierarchical hybrid remote-sensing image understanding system (RS-IUS) architecture comprises the following: 1) a first-stage pixel-based application-independent top-down (physical-model-driven and prior-knowledge-based) preliminary classifier and 2) a second-stage battery of stratified hierarchical context-sensitive application-dependent modules for class-specific feature extraction and classification. The first-stage preliminary classifier is implemented as an operational automatic near-real-time per-pixel multisource multiresolution application-independent spectral-rule-based decision-tree classifier (SRC). To the best of the author's knowledge, SRC provides the first operational example of an automatic multisensor multiresolution Earth-observation (EO) system of systems envisaged under ongoing international research programs such as the Global Earth Observation System of Systems (GEOSS) and the Global Monitoring for the Environment and Security (GMES). For the sake of simplicity, the original SRC formulation adopts crisp (hard) membership functions unsuitable for dealing with component cover classes of mixed pixels (class mixture). In this paper, the crisp (hierarchical) SRC first stage of a two-stage hybrid RS-IUS is replaced by a fuzzy (horizontal) SRC. In operational terms, a relative comparison of the fuzzy SRC against its crisp counterpart reveals that the former features the following: 1) the same degree of automation which cannot be surpassed, i.e., they are both “fully automatic”; 2) a superior map information/knowledge representation where component cover classes of mixed pixels are modeled; 3) the same robustness to changes in the input multispectral imagery acquired across time, space, and sensors; 4) a superior maintainability/scalability/reusability guaranteed by an internal horizontal (flat) modular structure independent of hierarchy; and 5) a computation time increased by 30% in a single-process single-thread implementation. This computation overload would reduce to zero in a single-process multithread implementation. In line with theory, the conclusion of this work is that the operational qualities of the fuzzy and crisp SRCs differ, but both SRCs are suitable for the development of operational automatic near-real-time multisensor satellite-based measurement systems such as those conceived as a visionary goal by the ongoing GEOSS and GMES research initiatives.	computation;computer vision;context-sensitive grammar;decision tree;feature extraction;fuzzy set;knowledge representation and reasoning;logic programming;model-driven engineering;multispectral image;pixel;real-time clock;real-time computing;sample rate conversion;scalability;sensor;system of measurement;system of systems;thread (computing);time complexity;top-down and bottom-up design	Andrea Baraldi	2011	IEEE Transactions on Geoscience and Remote Sensing	10.1109/TGRS.2010.2091137	rule-based system;knowledge representation and reasoning;computer vision;machine learning;decision tree;data mining;physics;remote sensing	Robotics	73.41234196268907	-59.73489416532113	51048
a75efc7a9e410a29e5c2e8f7b7243768f5ceae3a	an image quality metric based on biologically inspired feature model	saliency map;region of interest roi;structural similarity ssim;feature weighting;image quality assessment;biologically inspired feature model bifm	Objective image quality assessment (IQA) metrics have been widely applied to imaging systems to preserve and enhance the perceptual quality of images being processed and transmitted. In this paper, we present a novel IQA metric based on biologically inspired feature model (BIFM) and structural similarity index (SSIM). The SSIM index map is first generated through the well-known IQA metric SSIM between the reference image and the distorted image. Then, saliency map of the distorted image is extracted via BIF to define the most salient image locations. Finally, according to the saliency map, a feature weighting model is employed to define the different weights for the different samples in the SSIM index map. Experimental results confirm that the proposed IQA metric improves the performance over PSNR and SSIM under various distortion types in terms of different evaluation criteria.	distortion;feature model;image quality;nl-complete;numerical aperture;peak signal-to-noise ratio;sandy bridge;structural similarity;whole earth 'lectronic link	Cheng Deng;Jie Li;Yifan Zhang;Dongyu Huang;Lingling An	2011	Int. J. Image Graphics	10.1142/S0219467811004093	computer vision;machine learning;pattern recognition;mathematics	AI	61.41045421085584	-65.13923224672446	51134
574f893451c92647584f7f78798e334702032ff9	initial assessment of medium-baseline single-epoch rtk using gps/beidou/qzss	gnss;rtk		baseline (configuration management);beidou navigation satellite system;global positioning system;quasi-zenith satellite system;real time kinematic	Nobuaki Kubo;Hideki Yamada;Tomoji Takasu	2014	IEICE Transactions		computer science;gnss applications;real time kinematic	NLP	79.98651945671688	-65.33015459024188	51215
2d8e8ba0b8530c3b7e9f67617545232caebb0468	a bayesian framework for simultaneous matting and 3d reconstruction	bayesian framework;bayesian methods image reconstruction layout cameras pixel image segmentation reconstruction algorithms iterative algorithms large scale systems image sequences;shape from silhouette;large scale outdoor scene;global solution;simultaneous matting;image resolution;chroma keying;bayes methods;large scale;shape from silhouette bayesian framework simultaneous matting 3d scene reconstruction view synthesis large scale outdoor scene chroma keying;view synthesis;graph cut;image reconstruction;3d scene reconstruction;image resolution bayes methods image reconstruction;3d reconstruction	Conventional approaches to 3D scene reconstruction often treat matting and reconstruction as two separate problems, with matting a prerequisite to reconstruction. The problem with such an approach is that it requires taking irreversible decisions at the first stage, which may translate into reconstruction errors at the second stage. In this paper, we propose an approach which attempts to solve both problems jointly, thereby avoiding this limitation. A general Bayesian formulation for estimating opacity and depth with respect to a reference camera is developed. In addition, it is demonstrated that in the special case of binary opacity values (background/foreground) and discrete depth values, a global solution can be obtained via a single graph-cut computation. We demonstrate the application of the method to novel view synthesis in the case of a large-scale outdoor scene. An experimental comparison with a two-stage approach based on chroma-keying and shape-from-silhouette illustrates the advantages of the new method.	3d reconstruction;algorithm;computation;cut (graph theory);defense in depth (computing);expectation propagation;glossary of computer graphics;iterative method;key (cryptography);view synthesis	Jean-Yves Guillemaut;Adrian Hilton;Jonathan Starck;Joe Kilner;Oliver Grau	2007	Sixth International Conference on 3-D Digital Imaging and Modeling (3DIM 2007)	10.1109/3DIM.2007.3	3d reconstruction;iterative reconstruction;computer vision;image resolution;cut;computer science;pattern recognition;computer graphics (images)	Vision	53.8407156583525	-53.907697249117746	51222
eb829f8439cd4d99f95fb50204f90ccb4b7a5af5	feature importance analysis for local climate zone classification using a residual convolutional neural network with multi-source datasets		Global Local Climate Zone (LCZ) maps, indicating urban structures and land use, are crucial for Urban Heat Island (UHI) studies and also as starting points to better understand the spatio-temporal dynamics of cities worldwide. However, reliable LCZ maps are not available on a global scale, hindering scientific progress across a range of disciplines that study the functionality of sustainable cities. As a first step towards large-scale LCZ mapping, this paper tries to provide guidance about data/feature choice. To this end, we evaluate the spectral reflectance and spectral indices of the globally available Sentinel-2 and Landsat-8 imagery, as well as the Global Urban Footprint (GUF) dataset, the OpenStreetMap layers buildings and land use and the Visible Infrared Imager Radiometer Suite (VIIRS)-based Nighttime Light (NTL) data, regarding their relevance for discriminating different Local Climate Zones (LCZs). Using a Residual convolutional neural Network (ResNet), a systematic analysis of feature importance is performed with a manually-labeled dataset containing nine cities located in Europe. Based on the investigation of the data and feature choice, we propose a framework to fully exploit the available datasets. The results show that GUF, OSM and NTL can contribute to the classification accuracy of some LCZs with relatively few samples, and it is suggested that Landsat-8 and Sentinel-2 spectral reflectances should be jointly used, for example in a majority voting manner, as proven by the improvement from the proposed framework, for large-scale LCZ mapping.	apple maps;convolutional neural network;hardiness zone;image sensor;map;multi-source;ntl;openstreetmap;relevance	Chunping Qiu;Michael Schmitt;Lichao Mou;Pedram Ghamisi;Xiao xiang Zhu	2018	Remote Sensing	10.3390/rs10101572	residual;computer vision;convolutional neural network;geology;artificial intelligence;multi-source	Vision	80.24266871047146	-57.81328444702174	51324
822bedb87b323b8d469709187941ec1baa4ff1ac	on the use of image quality measures for image restoration	minimization;measurement;cost function;image restoration;indexes;image quality	Image quality measurements are valuable tools, crucial for most image processing applications, and used in particular to assess and compare the image restoration (IR) quality. The objective of this work is to investigate the potential of such measures when used as cost functions (integrated in the global criterion) to enhance the restoration performance. In this paper, the proposed approach uses the Structural SIMilarity (SSIM) index measure which is one of the most appropriate measures as it is inspired from the human visual system (HVS) and relatively simple to compute. For the composite criterion optimization, after initializing the algorithm by the alternating direction method of multipliers (ADMM), a gradient descent (GD) technique is used to minimize the global cost function. Finally, simulations are conducted to investigate the contexts in which such quality measures might lead to the desired IR improvement.	algorithm;augmented lagrangian method;circuit restoration;experiment;gradient descent;human visual system model;image processing;image quality;image restoration;loss function;mathematical optimization;simulation;structural similarity;undefined behavior	Fouad Boudjenouia;Karim Abed-Meraim;Aladine Chetouani;Rachid Jennane	2016	2016 Sixth International Conference on Image Processing Theory, Tools and Applications (IPTA)	10.1109/IPTA.2016.7821030	image quality;database index;image restoration;computer vision;mathematical optimization;simulation;computer science;measurement	Robotics	59.97570956581272	-65.33353368735344	51332
17cce2c92ad7d5deb959d5c81c6da365e14dfca8	results of a bistatic hf radar surface wave sea scatter experiment	oscr hf radar ocean coast current dynamics measurement technique hf radar bistatic radar radar remote sensing surface wave sea scatter experiment ocean wave radar scattering university of miami first order bragg line characteristics;radar remote sensing;current;antenna arrays;oscr hf radar;radar scattering hafnium surface waves sea surface transmitters radar antennas testing receiving antennas antenna arrays global positioning system;testing;first order bragg line characteristics;remote sensing by radar;radar scattering;sea surface;first order;surface wave;surface wave sea scatter experiment;university of miami;global positioning system;dynamics;radar antennas;transmitters;radar cross sections oceanographic techniques radar theory remote sensing by radar;ocean;doppler shift;radar cross sections;surface waves;antenna array;receiving antennas;radar theory;bistatic radar;ocean wave;measurement technique;coast;oceanographic techniques;hf radar;surface area;hafnium	We describe a set of HF radar sea scatter experiments that test a new digital receiver in both monostatic and bistatic modes. The University of Miami's OSCR HF radar system was used as a transmitter signal source, and sea echoes were received with both receive systems using different receive antenna arrays. Independent GPS time-coupled rubidium clocks were used to maintain site-pair coherence, and Bragg spectral purity was used as a measure. Expected first order Bragg line characteristics are first discussed that are based on a model (Trizna, 2000): predicted Bragg line NRCS and Doppler shift. With a monostatic transmitter and receive array and a single bistatic transmitter, two different aspects onto the same ocean surface area allows one to estimate current vectors.	radar;surface wave	Dennis Trizna;James Gordon	2002		10.1109/IGARSS.2002.1026294	meteorology;radar engineering details;geodesy;surface wave;passive radar;bistatic radar;physics;remote sensing	Robotics	81.13623016447706	-65.17597678237772	51363
d8172fe601c4b2f1ca4a12aeee4812223907007a	monitoring of carbon sink preservation activity for global warming countermeasure using a high-resolution satellite image	carbon sink forest;forestry;satellite image acquisition;monitoring global warming satellites cities and towns meteorology protocols image analysis clouds remote sensing image segmentation;image classification;papua new guinea carbon sink preservation activity global warming countermeasure high resolution satellite image satellite image acquisition land use classification object based image analysis carbon sink forest;remote sensing climate mitigation data acquisition forestry geophysical signal processing global warming image classification;papua new guinea;land use;carbon sink preservation activity;geophysical signal processing;remote sensing;object based image analysis;satellite image;climate mitigation;global warming countermeasure;land use classification;global warming;high resolution satellite images;data acquisition;carbon sink;high resolution satellite image	We represent the monitoring method of a carbon sink preservation activity for the global warming countermeasure using a high-resolution satellite image. We first investigate the satellite image availability and make a plan of a satellite image acquisition order. Next, we propose the land-use classification using the object-based image analysis to monitor carbon sink forest. Lastly, we apply the technique to the project site in Papua New Guinea.	image analysis;image resolution;object-based language	Naoko Kosaka;Yoshitaka Kuwata	2006	2006 IEEE International Symposium on Geoscience and Remote Sensing	10.1109/IGARSS.2006.181	meteorology;carbon sink;contextual image classification;land use;global warming;geology;data acquisition;physics;remote sensing	Embedded	80.89706762931146	-57.807909370097974	51433
c47a9a1d153c4b8e456a5dc50e96cbf949e04f2e	painting patches: reducing flicker in painterly re-rendering of video	non photorealistic rendering;flicker;stroke placement;video rendering;video ren dering;non photorealistic rendering painterly rendering stroke placement region clustering video rendering flicker;painterly rendering;region clustering	This paper presents a novel method for re-rendering video in a stroke-based painterly style. Previous methods typically place and adjust strokes on a frame by frame basis, guided by an analysis of motion vectors. Our method constructs painting patches which last for multiple frames, and paints them just once, compositing them after placing and clipping each one in each output frame. Painting patches are constructed by clustering pixels with similar motions, representing moving objects. This is done using a multi-frame window, to take account of objects which are present in consecutive frames, and which may occur a few frames apart with occlusion. The appearance of a given cluster across a sequence of frames is warped to a common reference to produce the painting patch; a global optimization of the warp is used to minimize distortion in the painting strokes. This approach outperforms prior algorithms in problem areas of the image, where flickering typically occurs, while producing comparable results elsewhere. In particular, stable strokes are produced at occlusion boundaries where objects emerge, and at image borders exposed by camera panning. A further advantage is consistent rendering of regions before and after brief occlusion, enhancing temporal stability of the output of discontiguous frames.	algorithm;cluster analysis;compositing;distortion;flicker (screen);global optimization;hidden surface determination;mathematical optimization;patch (computing);pixel	Song-Hai Zhang;Qiang Tong;Shi-Min Hu;Ralph R. Martin	2011	Science China Information Sciences	10.1007/s11432-011-4409-2	flicker;computer vision;3d rendering;rendering;computer science;non-photorealistic rendering;multimedia;real-time rendering;alternate frame rendering;computer graphics (images)	Vision	58.87528064917795	-54.83797831110303	51549
8502fc348d74e993a1f25d01f86228579022d9c0	3d pathfinding and collision avoidance using uneven search-space quantization and visual cone search		Pathfinding is a very popular area in computer game development. While two-dimensional (2D) pathfinding is widely applied in most of the popular game engines, little implementation of real three-dimensional (3D) pathfinding can be found. This research presents a dynamic search space optimization algorithm which can be applied to tessellate 3D search space unevenly, significantly reducing the total number of resulting nodes. The algorithm can be used with popular pathfinding algorithms in 3D game engines. Furthermore, a simplified standalone 3D pathfinding algorithm is proposed in this paper. The proposed algorithm relies on ray-casting or line vision to generate a feasible path during runtime without requiring division of the search space into a 3D grid. Both of the proposed algorithms are simulated on Unreal Engine to show innerworkings and resultant path comparison with A*. The advantages and shortcomings of the proposed algorithms are also discussed along with future directions. Keywords—3D, pathfinding, computer game, artificial intelligence, simulation.	airborne ranger;algorithm;artificial intelligence (video games);concave function;feedback;game engine;line-of-sight (missile);mathematical optimization;np-completeness;pc game;pathfinding;ray casting;resultant;simulation;unreal development kit;veritas cluster server;video game developer;video game development	Diptangshu Pandit	2017	CoRR		grid;collision;artificial intelligence;computer science;machine learning;quantization (signal processing);video game development;pathfinding	AI	66.59870167704057	-52.34403449882754	51558
03f729cf906f278e8ac38a3431d8de1f7654a5c5	a new filtering scheme for processing the chromatic signals of color images: definition and properties	image filtering;filtering signal processing color kernel nonlinear filters pixel image converters maximum likelihood detection equations additives;low pass filters image colour analysis;linear filtering;lowpass filtering filtering scheme chromatic signals processing color images cie chromaticity coordinates image filtering center of gravity law color mixture annoying hue shifts elimination linear filtering;image colour analysis;center of gravity;low pass filters;color image	This paper presents a new filtering scheme for processing the chromatic components of color images, expressed by the CIE U’ and U‘ chromaticity coordinates. The new scheme extends to image filtering the Center of Gravity Law of Color Mixture which describes the mixine of two colon within u’u’ chm~ ~ ~ ~ ~ ~~~~ ~ maticit? diagram. l h e most inl&sting propert) ofthe proposed filtering framework is the elimination of the annojing hue shifts along edges between bright and dark areas which would he inlroduced by the simnle linear filtering of the U‘ and v’ signals. Four examples of lowpass filtering repohed and discussed i i the paper which clearly demonstate this important feature.	colon classification;computability in europe;diagram;low-pass filter	Luca Lucchese;Sanjit K. Mitra	2002		10.1109/MMSP.2002.1203256	color histogram;computer vision;color image;low-pass filter;chromaticity;computer science;linear filter;mathematics;color balance;bilinear filtering;center of gravity;texture filtering;trilinear filtering	Vision	54.80375280268326	-65.5229233699257	51627
c6277bcb117686669635cd304dc3ecf536f66c13	virtual multi-offset reflection profiling with interferometric imaging for borehole radar	wave interferometric virtual source;cross hole;multi offset reflection;borehole radar	Interferometry is one of the most advanced signal-processing and imaging techniques. It is widely used in geophysical detection and remote sensing. Application of interferometric processing significantly improves the resolution in geophysical imaging. This paper reports the application of an interferometric imaging approach to cross-hole multi-offset transmission (CHMOT) borehole radar data to generate a virtual single-hole, multi-offset reflection (SHMOR) profile with the validation of a real SHMOR data set. In subsurface material property imaging, SHMOR is an effective technique for interface and fracture detection. However, borehole radar survey in SHMOR fashion is not practical for most cases. Transforming cross-hole transmission mode radar data to virtual single-hole, multi-offset reflection data using a wave interferometric virtual source (WIVS) approach was proposed previously but not fully validated with real SHMOR data. In this study, we compare WIVS-derived virtual SHMOR to real SHMOR profiles using data sets acquired in two boreholes (SIMA1 and SIMA2) drilled into crystalline igneous bedrocks. As the calibration and validation, the reflection from borehole SIMA2 (as the known object) is clearly imaged by both the real and WIVS-derived virtual SHMOR profiles in SIMA1. The diffractions and amplitude decay from sharp stratigraphic change also registered at both the real and WIVS-derived virtual SHMOR profiles. The results of this study demonstrate the potential of the WIVS approach to improve structural imaging in bedrocks for hydrogeological, geothermal, and petroleum reservoir development applications.	radar;reflection lines	Lanbo Liu	2017	Signal Processing	10.1016/j.sigpro.2016.06.028	geotechnical engineering	Embedded	79.49576008741236	-63.095151681681934	51801
56e8eb2cd6f5f8c424ef532f4b75403064834dc2	solving jigsaw puzzle with symbol matrixes	filtering;ssd sum of squared distance scoring;measurement;greedy algorithms;symbol matrixes;shape;image reconstruction greedy algorithms;image color analysis;image reconstruction;measurement image reconstruction filtering image color analysis shape greedy algorithms algorithm design and analysis;missing pieces ssd sum of squared distance scoring jigsaw puzzle symbol matrixes;jigsaw puzzle;missing pieces;crime scene reconstruction symbol matrix based jigsaw puzzle algorithm image reconstruction compatibility metric ssd sum of squared distance scoring greed algorithm artifact reconstruction biological information reconstruction;algorithm design and analysis	This paper presents a new symbol-matrix-based jigsaw-puzzle algorithm for image reconstruction. The proposed algorithm first calculates the compatibility metric using the SSD (Sum of Squared Distance Scoring) between adjacent pieces. Then the algorithm constructs a matrix to express the location relationship of pieces followed by constructing a symbol matrix to record the number and rotations of pieces. Finally, we use a greed algorithm to reconstruct the images. The proposed algorithm does not require any preset conditions and can reconstruct the images rapidly. The experimental results have shown that the proposed algorithm can accurately reconstruct the images with 28% speed-up in execution time. The results also show that it's very effective to reconstruct the puzzles with missing pieces, which is a useful feature for applications such as artifact reconstruction, biological information reconstruction and incomplete crime-scene reconstruction.	algorithm;iterative reconstruction;run time (program lifecycle phase);solid-state drive	Dai Cao;Li-Fang Chen;Yuan Liu	2016	2016 IEEE/ACIS 15th International Conference on Computer and Information Science (ICIS)	10.1109/ICIS.2016.7550797	iterative reconstruction;filter;algorithm design;greedy algorithm;shape;computer science;theoretical computer science;machine learning;data mining;algorithm;measurement;statistics	Vision	54.339111198300145	-59.56254376118021	51820
c26fb5224ccbff5a0f38f240967b4da957411c6a	effective color ink diffusion synthesis	previous work;new kubelka-munk equation;color shifting;effective color ink diffusion;color ink diffusion style;color ink diffusion synthesis;new overlapping equation;kubelka-munk equation;diffusion layer;new equation;detail missing;new algorithm;resultant image;reference image;image-based rendering algorithm;image colour analysis;image based rendering	"""Our previous work proposed a non-stroke, image-based rendering algorithm for automatically synthesizing a reference image with color ink diffusion style. However, our previous work also showed drawbacks of """"color shifting"""" and """"detail missing. """" In this paper, we present a new and effective color ink diffusion synthesis (ECIDS) algorithm. In particular, we propose a new Kubelka-Munk equation (SK-M) to properly mix pigment color. This new equation produces a resultant image that has a tone visually similar to the reference image. In addition, we present a new overlapping equation (NOL) to properly overlap deposit layer with diffusion layer. Thus, the resultant image can show more ink diffusion details than our previous work. Experimental results demonstrate that this new algorithm can effectively produce visually pleasing results better than our previous work."""	algorithm;pigment;resultant;ski combinator calculus	Ren-Jie Wang;Chung-Ming Wang	2007	Third International Conference on Intelligent Information Hiding and Multimedia Signal Processing (IIH-MSP 2007)	10.1109/IIH-MSP.2007.391	computer vision;image-based modeling and rendering;computer science;anisotropic diffusion;computer graphics (images)	Vision	58.24713651069971	-60.546827732495004	51840
047743e00759f99380f0d77da075d2c3bbea8e29	real-time rendering with compressed animated light fields		We propose an end-to-end solution for presenting movie quality animated graphics to the user while still allowing the sense of presence afforded by free viewpoint head motion. By transforming offline rendered movie content into a novel immersive representation, we display the content in real-time according to the tracked head pose. For each frame, we generate a set of cubemap images per frame (colors and depths) using a sparse set of of cameras placed in the vicinity of the potential viewer locations. The cameras are placed with an optimization process so that the rendered data maximise coverage with minimum redundancy, depending on the lighting environment complexity. We compress the colors and depths separately, introducing an integrated spatial and temporal scheme tailored to high performance on GPUs for Virtual Reality applications. We detail a real-time rendering algorithm using multi-view ray casting and view dependent decompression. Compression rates of 150:1 and greater are demonstrated with quantitative analysis of image reconstruction quality and performance.	algorithm;anomalous experiences;artifact (software development);codec;color;computer animation;cube mapping;data compression;end-to-end principle;feedback;gaussian blur;glossary of computer graphics;graphics processing unit;hardware acceleration;heuristic (computer science);image resolution;iterative reconstruction;light field;mathematical optimization;memory bandwidth;online and offline;pixel;pre-rendering;quadtree;ray casting;real-time clock;real-time transcription;redundancy (engineering);reflection (computer graphics);sparse language;sparse matrix;subdivision surface;texture compression;virtual reality	Babis Koniaris;Maggie Kosek;David Sinclair;Kenny Mitchell	2017		10.20380/GI2017.05	iterative reconstruction;artificial intelligence;ray casting;rendering (computer graphics);computer vision;immersion (virtual reality);computer graphics (images);real-time rendering;graphics;computer science;image-based modeling and rendering;cube mapping	Graphics	60.63153231707278	-54.00558818714188	51858
ca3f7fa6a695ff1c8a0936ce49906e71dd5915fd	real-time free viewpoint video from a range sensor and color cameras	image-based rendering;stereo;range data;sensor fusion;graphics processors	We propose a method for computing a depth map at interactive rates from a set of closely spaced calibrated video cameras and a Time-of-Flight (ToF) camera. The objective is to synthesize free viewpoint videos in real-time. All computations are performed on the graphics processing unit, leaving the CPU available for other tasks. Depth information is computed from color camera data in textured regions and from ToF data in textureless ones. The trade-off between these two sources is determined locally based on the reliability of the depth estimates obtained from the color images. For this purpose, a confidence measure taking into account the shape of the photo-consistency score as a function of depth is used. The final depth map is computed by minimizing a cost function. This approach offers a significant time savings relative to other methods that apply denoising to the photo-consistency score maps, obtained at every depth, and importantly, still obtains acceptable quality of the rendered image.	central processing unit;computation;computer graphics;depth map;expectation–maximization algorithm;graphics processing unit;ip camera;image-based modeling and rendering;interpolation;loss function;network switch;noise reduction;photo-consistency;real-time clock;time-of-flight camera	Stéphane Pelletier;Jeremy R. Cooperstock	2012	Machine Vision and Applications	10.1007/s00138-012-0428-2	computer vision;simulation;computer science;computer graphics (images)	Vision	58.415268227032186	-56.430447120121485	51874
90576ee67ceac0dadaa07c70a4f82e1f2e802a23	saliency-based endmember detection for hyperspectral imagery		This paper focuses on the spectral unmixing technique for analyzing hyperspectral image (HSI). In this paper, we first prove that the reconstruction errors and the abundance anomalies (AAs, abundances that are negative or greater than one) are effective in measuring the purity of pixels. Then, due to the continuity of the objects in the space, the endmembers are assumed to be located at some noticeable areas in residual and AA maps. A saliency-based endmember detection (SED) algorithm which aims at iteratively extracting endmembers from the residual and AA maps is proposed, where the visual attention mechanism is developed to understand and analyze the spatial pattern of endmembers. In addition, when searching for new endmembers, the spectral properties are also utilized to promote the robustness of the proposed method. The experimental results on both simulated data and real hyperspectral data illustrate the merits and viability of the proposed algorithm.	algorithm;horizontal situation indicator;map;pixel;pure function;scott continuity;spatiotemporal pattern	Xinyu Wang;Yanfei Zhong;Yao Xu;Liangpei Zhang;Yanyan Xu	2017	2017 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)	10.1109/IGARSS.2017.8127119	iterative reconstruction;pixel;endmember;residual;common spatial pattern;computer vision;artificial intelligence;robustness (computer science);computer science;hyperspectral imaging;sed	Vision	68.75947408220847	-65.91283453275852	51875
cc6f5196139a970592524f5d4dec8e3a22006e44	information processing approach to image quality	analisis escena;analyse scene;procesamiento informacion;algorithm performance;reproduccion color;data processing;hombre;qualite image;frequency response;reponse frequence;respuesta frecuencia;percepcion visual;resultado algoritmo;color reproduction;image quality;information processing;human;performance algorithme;perception visuelle;algorithms;visual perception;calidad imagen;traitement information;discriminacion;reproduction couleur;discrimination;homme;scene analysis	We present algorithms for predicting the quality of colour reproductions of natural scenes. The algorithms are based on a three-point concept for image quality: (1) images are carriers of visual information about the outside world and the objects located in it, (2) images are used by the visual and cognitive systems to reconstruct and interpret the outside world, and (3) the quality of an image is the degree of success with which this image can be used by the visual and cognitive systems.	algorithm;artificial intelligence;image quality;information processing	Ruud Janssen;Frans J. J. Blommaert	2000		10.1117/12.387211	image quality;computer vision;art;artificial intelligence;cartography	AI	62.85442453010975	-61.476398569915396	51891
1461069209c928ed7bc6ba55a1355f917fcfdd72	compensation of spectral mismatch to enhance wrgb demosaicking	spectral mismatch compensation wrgb cmos image sensor interpolation method wrgb color filter array wrgb demosaicking enhancement;demosaicking color filter array cmos image sensor spectral response white pixel;interpolation image colour analysis image enhancement image filtering image sensors;interpolation sensitivity image color analysis cmos integrated circuits signal to noise ratio semiconductor device modeling upper bound	The presence of spectral mismatch between the components of a WRGB color filter array severely affects the performance of demosaicking. This paper presents a novel method that compensates for the spectral mismatch and greatly enhances the accuracy of R, G, and B interpolation. The method is tested on a two-megapixel WRGB CMOS image sensor. The results show that the proposed method brings the performance of WRGB demosaicking to an unprecedented level competitive with that of the state-of-the-art Bayer demosaicking.	active pixel sensor;bayer filter;cmos;color filter array;demosaicing;image sensor;interpolation;spectral efficiency;stellar classification	Po-Hsun Su;Po-Chang Chen;Homer H. Chen	2015	2015 IEEE International Conference on Image Processing (ICIP)	10.1109/ICIP.2015.7350761	demosaicing;computer vision	Robotics	59.53758557219134	-58.90889294685698	51946
40eaa68205631317050414014e5841c93e6ac93e	proposed nrc portable target case for short-range triangulation-based 3d imaging systems characterization	3d imaging;stereoscopy;tolerancing;imaging system;optical properties;dimensional metrology;national research council	The National Research Council of Canada (NRC) is currently evaluating and designing artifacts and methods to completely characterize 3-D imaging systems. We have gathered a set of artifacts to form a low-cost portable case and provide a clearly-defined set of procedures for generating characteristic values using these artifacts. In its current version, this case is specifically designed for the characterization of short-range (standoff distance of 1 centimeter to 3 meters) triangulation-based 3-D imaging systems. The case is known as the “NRC Portable Target Case for Short-Range Triangulation-based 3-D Imaging Systems” (NRC-PTC). The artifacts in the case have been carefully chosen for their geometric, thermal, and optical properties. A set of characterization procedures are provided with these artifacts based on procedures either already in use or are based on knowledge acquired from various tests carried out by the NRC. Geometric dimensioning and tolerancing (GD&T), a well-known terminology in the industrial field, was used to define the set of tests. The following parameters of a system are characterized: dimensional properties, form properties, orientation properties, localization properties, profile properties, repeatability, intermediate precision, and reproducibility. A number of tests were performed in a special dimensional metrology laboratory to validate the capability of the NRC-PTC. The NRC-PTC will soon be subjected to reproducibility testing using an intercomparison evaluation to validate its use in different laboratories.	artifact (software development);characterization test;repeatability;stereoscopy	Benjamin Carrier;David K. MacKinnon;Luc Cournoyer;J.-Angelo Beraldin	2011		10.1117/12.871942	stereoscopy;simulation;telecommunications;computer science;optics;physics;quantum mechanics	Robotics	78.96314348974795	-71.812937506434	52044
52a94812033b0c158b9d81b5de8e87ccfaa4f4d3	multiscale semilocal interpolation with antialiasing	interpolation image edge detection size measurement iterative methods estimation noise reduction materials;interpolation;image resolution;semilocal antialiasing image interpolation iterative multiscale;edge detection;low resolution;image interpolation;size measurement;natural images;maximum likelihood estimation image resolution image texture interpolation iterative methods;maximum likelihood estimation;materials;visual quality;image texture;iterative methods;image generation;estimation;image edge detection;antialiasing;interpolation method;noise reduction;semilocal;total variation;high resolution imager;iteration method;subjective visual quality antialiasing low resolution images downsampling process image interpolation problem texture relevant lr pixels iterative multiscale semilocal interpolation method missing pixel estimation data fidelity term maximum a posteriori estimation bilateral total variation regularization term quantitative evaluation;quantitative evaluation;iterative multiscale	Aliasing is a common artifact in low-resolution (LR) images generated by a downsampling process. Recovering the original high-resolution image from its LR counterpart while at the same time removing the aliasing artifacts is a challenging image interpolation problem. Since a natural image normally contains redundant similar patches, the values of missing pixels can be available at texture-relevant LR pixels. Based on this, we propose an iterative multiscale semilocal interpolation method that can effectively address the aliasing problem. The proposed method estimates each missing pixel from a set of texture-relevant semilocal LR pixels with the texture similarity iteratively measured from a sequence of patches of varying sizes. Specifically, in each iteration, top texture-relevant LR pixels are used to construct a data fidelity term in a maximum a posteriori estimation, and a bilateral total variation is used as the regularization term. Experimental results compared with existing interpolation methods demonstrate that our method can not only substantially alleviate the aliasing problem but also produce better results across a wide range of scenes both in terms of quantitative evaluation and subjective visual quality.	alias;algorithm;aliasing;bilateral filter;cesarean section and delivery litter results domain;computation;decimation (signal processing);estimated;ground truth;http 404;image resolution;interpolation imputation technique;iteration;lr parser;large;morphologic artifacts;multiscale modeling;pixel;spatial anti-aliasing	Kai Guo;Xiaokang Yang;Hongyuan Zha;Weiyao Lin;Songyu Yu	2012	IEEE Transactions on Image Processing	10.1109/TIP.2011.2165290	computer vision;mathematical optimization;image resolution;computer science;mathematics;iterative method;statistics	Vision	57.17354773886533	-69.78770341690657	52117
a1dcec44ee1801af7ebcb4411b30d3c6668c1bbd	a method to analyze preferred mtf for printing medium including paper	printing;lcd;sharpness;simulation methods;mtf;granularity;image quality;modulation transfer function mtf	A method is proposed to analyze the preferred Modulation Transfer Function (MTF) of printing medium like paper for the image quality of printing. First, the spectral intensity distribution of printed image is simulated by changing the MTF of medium. Next, the simulated image is displayed on a high-precision LCD to reproduce the appearance of printed image. An observer rating evaluation experiment is carried out to the displayed image to discuss what the preferred MTF is. The appearance simulation of printed image was conducted on particular printing conditions: several contents, ink colors, a halftoning method and a print resolution (dpi). The experiments on different printing conditions can be conducted since our simulation method is flexible about changing conditions.		Masayuki Ukishima;Martti Mäkinen;Toshiya Nakaguchi;Norimichi Tsumura;Jussi Parkkinen;Yoichi Miyake	2009		10.1007/978-3-642-02230-2_62	image quality;computer vision;granularity;computer science;liquid-crystal display;computer graphics (images)	HCI	61.674422434023214	-61.17843746791219	52150
aa630c62ab73262f9f38f7665f75795180252bbc	generation and application of hyperspectral 3d plant models		Hyperspectral imaging sensors have been introduced for measuring the health status of plants. Recently, they have been also used for close-range sensing of plant canopies with a more complex architecture. The complex geometry of plants and their interaction with the illumination scenario severely affect the spectral information obtained. The combination of hyperspectral images and 3D point clouds are a promising approach to face this problem. Based on such hyperspectral 3D models the effects of plant geometry and sensor configuration can be quantified an modeled. Reflectance models can be used to remove or weaken the geometry-related effects in hyperspectral images and, therefore, have the potential potential to improve automated phenotyping significantly.		Jan Behmann;Anne-Katrin Mahlein;Stefan Paulus;Heiner Kuhlmann;Erich-Christian Oerke;Lutz Plümer	2014		10.1007/978-3-319-16220-1_9	computer science;point cloud;computer vision;artificial intelligence;architecture;complex geometry;reflectivity;hyperspectral imaging;sensor fusion	Vision	74.73413185813894	-56.68113311086729	52161
15ff15a78dcab1ed3cfd054a42ed99ce9c41aef8	using internal depth to aid stereoscopic image splicing detection		Splicing is a common image manipulation technique, where parts of multiple images are combined to create a new composite image. Commercial image editing software enables almost anyone to splice images and create fake photographs. This paper investigates how the relationship between object distance and internal depth can aid in detecting spliced stereoscopic images. An equation is derived for predicting the distance at which an object loses internal depth. Experiments with stereoscopic images indicate that the analysis of this depth information can assist in detecting image splicing.	distortion;experiment;graphics software;image editing;image scaling;sensor;splice (system call);stereoscopy	Mark-Anthony Fouche;Martin S. Olivier	2012		10.1007/978-3-642-33962-2_22	computer vision;computer science;multimedia;computer graphics (images)	Vision	63.519833967007564	-58.079787230187996	52189
3f8fb00d8c62d4bf8b0624fec74d92edca300624	adaptive doppler centroid estimation algorithm of airborne sar	energy balancing method;doppler centroid estimation;synthetic aperture radar sar;gaussian curve fitting	Successfully imaging of airborne SAR requires that Doppler centroid frequency be accurately estimated. Energy balancing method is a classical method to solve this problem, whereas its performance relies heavily on the homogeneity of the scene. In this paper, the spectra of prominent point targets are analyzed, and then an adaptive algorithm based on Gaussian curve fitting is proposed to eliminate the impact of prominent point targets in the scene. Random estimation error is further eliminated by using linear fitting of estimations from each range cell. The results of simulations and the imaging of raw data prove the veracity of this algorithm.	adaptive algorithm;airborne ranger;curve fitting;doppler effect;gaussian blur;institute of electronics, information and communication engineers;simulation;veracity	Jian Yang;Chang Liu;Yanfei Wang	2012	IEICE Electronic Express	10.1587/elex.9.1135	computer vision;geodesy;remote sensing	Robotics	75.6137440397731	-68.13980626923734	52214
c36a2dd99529cf96fadd53d74541c6825f363118	radiosity and hybrid methods	double patch method;residual image;radiosity method;separable reflectance;conjugated gradient method;convergence criteria;low resolution;photosimulation;conjugate gradient method;coupling method;mathematical analysis;global illumination;rendering equation;hybrid method;complete two pass method;ray tracing;southwell algorithm;distributed ray tracing;nondiffuse ambient term	We examine various solutions to the global illumination problem, based on an exact mathematical analysis of the rendering equation. In addition to introducing efficient radiosity algorithms, we present a uniform approach to reformulate all of the basic radiosity equations used so far. Using hybrid methods we are able to analyze possible combinations of the view-dependent ray-tracing method and of the low-resolution radiosity-based method, and to offer new algorithms.	algorithm;global illumination;radiosity (computer graphics);ray tracing (graphics);rendering equation	László Neumann;Attila Neumann	1995	ACM Trans. Graph.	10.1145/212332.212347	distributed ray tracing;ray tracing;mathematical optimization;radiosity;image resolution;computer science;rendering equation;mathematics;conjugate gradient method;optics;global illumination;computer graphics (images)	Graphics	57.052208244158884	-74.47660887834743	52227
14576a1e5cbc62bd900feca4196af82aa0f08a63	dependence of waterline mapping on radar frequency used for sar images in intertidal areas	radar frequency;intertidal flat;waterline intertidal flat radar frequency synthetic aperture radar sar;synthetic aperture radar images;radar signal;backscatter;global position system;intertidal areas;waterline detection;radar backscatter;remote sensing by radar;terrain mapping airborne radar backscatter global positioning system radar imaging remote sensing by radar synthetic aperture radar;sar images;waterline mapping;global positioning system;synthetic aperture radar sar;l band airborne sar;intertidal flat waterline mapping radar frequency sar images intertidal areas waterline detection synthetic aperture radar images l band airborne sar p band airborne sar global positioning system bragg waves radar signal radar backscatter;field measurement;radar imaging;sar image;radar imaging frequency synthetic aperture radar sea measurements spaceborne radar moon radar detection monitoring geophysics geoscience;airborne radar;p band airborne sar;terrain mapping;bragg waves;waterline;synthetic aperture radar	Waterline detection in the intertidal areas was investigated through synthetic aperture radar (SAR) images and field measurements. Two valuable facts were found in this letter: 1) A discrepancy of waterlines between L- and P-band airborne SAR images was discovered and investigated through precise global positioning system measurements and the theory of the SAR imaging mechanism. In the intertidal areas having low slopes, the Bragg waves resonant with the radar signal can reside in different depths depending on the radar frequency, with the result that the boundary between water and land can be mapped differently in the respective SAR images. 2) Intertidal areas covered with a water film present low radar backscatter in SAR images, which can cause mislocation of waterlines	airborne ranger;aperture (software);discrepancy function;global positioning system;ku band;mud;noise floor;radar;subsurface scattering;synthetic data	Duk-jin Kim;Wooil M. Moon;Sang-Eun Park;Ji-Eun Kim;Hyo-Sung Lee	2007	IEEE Geoscience and Remote Sensing Letters	10.1109/LGRS.2006.888843	waterline;meteorology;synthetic aperture radar;global positioning system;geodesy;radar imaging;backscatter;physics;remote sensing	Mobile	81.2014920564088	-65.25069067225186	52231
6b740fb3bf480c136293e38a3abefe7e45536cc8	surface area estimation of digitized planes using weighted local configurations	analisis imagen;minimum variance;coefficient of variation;image processing;digitizing;unbiased estimator;procesamiento imagen;numerisation;geometria discreta;traitement image;three dimensional;voxel;superficie curva;curved surface;efficient implementation;geometrie discrete;discrete geometry;analyse non convexe;numerizacion;surface courbe;image analysis;non convex analysis;parallel architecture;aire superficielle;area superficial;analyse image;surface area;variance;variancia;analisis no convexo	We describe a method for estimating surface area of three-dimensional binary objects. The method assigns a surface area weight to each 2 x 2 x 2 configuration of voxels. The total surface area is given by a summation of the local area contributions for a digital object. We derive optimal area weights, in order to get an unbiased estimate with minimum variance for randomly oriented planar surfaces. This gives a coefficient of variation (CV) of 1.40% for planar regions. To verify the results and to address the feasibility for area estimation of curved surfaces, the method is tested on convex and non-convex synthetic test objects of increasing size. The algorithm is appealingly simple and uses only a small local neighbourhood. This allows efficient implementations in hardware and/or in parallel architectures.		Joakim Lindblad	2003		10.1007/978-3-540-39966-7_33	discrete geometry;three-dimensional space;minimum-variance unbiased estimator;image analysis;topology;image processing;surface area;mathematics;geometry;variance;bias of an estimator;voxel;coefficient of variation;statistics	Vision	68.71988996826235	-55.42421370820057	52246
c97ae1ae6a8a1209909d9b7994b112534d40c106	accuracy of bathymetric assessment by locally analyzing radar ocean wave imagery (february 2008)	tratamiento datos;maps;traitement signal;teledetection;correlacion;errors;batimetria;radar methods;erreur;multibeam echosounder data bathymetric assessment radar ocean wave imagery x band radar image sequences sea surface waves spatial maps hydrographic parameters radar deduced bathymetry;measurement error;mapa;resolution spatiale;image sequence analysis;radar deduced bathymetry;direccion;spatial mapping;data processing;imagerie;traitement donnee;depth;problema inverso;carte;deteccion a distancia;error analysis;remote sensing by radar;accuracy;sea surface;imagery;precision;geophysical measurements;spatial correlation;inverse problem;condition monitoring;direction;spatial maps;geophysical signal processing;signal processing;oceanographic techniques image analysis radar imaging ocean waves dispersion sea surface image sequence analysis image sequences spatial resolution condition monitoring;remote sensing;sea surface waves;radar imaging;hydrographic parameters;bathymetric assessment;marine radar area measurement error analysis geophysical inverse problems geophysical measurements geophysical signal processing;marine radar;profundidad;weather condition;onde oceanique;area measurement;image analysis;x band radar image sequences;imagineria;error;geophysical inverse problems;profondeur;correlation;multibeam echosounder data;radar ocean wave imagery;dispersion;bathymetry;ocean wave;probleme inverse;oceanographic techniques;remote sensing by radar bathymetry image sequences marine radar ocean waves;methode radar;ocean waves;radar;bathymetrie;image sequences;spatial resolution	In this paper, the error source in assessing the bathymetry by a recently presented method, the dispersive surface classificator, is discussed. This method is based on the analysis of X-band radar image sequences of sea-surface waves to determine spatial maps of hydrographic parameters. To implement this objective, the radar-deduced bathymetry is validating by multibeam echosounder data. The accuracy of the method is high in homogeneous areas and reduced at the areas of bathymetric gradient and lower but comparable with multibeam echosounder data, under the assumption of the spatial resolution. The identification of systematic correlation of the absolute value of the error with the slope is significant and insignificant with the actual depth itself. The spatial correlation of the error illustrates that the direction of the wave field influences the neighboring grid cell in the same direction. The application of the method during crucial weather conditions is the main advantage and permits the accurate operational nearshore monitoring for several applications.	bathymetry;dispersive partial differential equation;gradient;map;radar;surface wave	Stylianos Flampouris;Friedwart Ziemer;Jörg Seemann	2008	IEEE Transactions on Geoscience and Remote Sensing	10.1109/TGRS.2008.919687	meteorology;wind wave;image analysis;data processing;geodesy;signal processing;mathematics;accuracy and precision;physics;statistics;remote sensing	Visualization	78.82960442358144	-64.14392712084502	52317
0507cb3da8c87c14afc318a86fd25a7a92cffc18	the colour preference control based on two-colour combinations	man;4230;color space;etude experimentale;0130c;observers;satisfiability;algorithme;observateur;pixel;perception visuelle;algorithms;visual perception;4266;espace chromatique;espacio cromatico;optimization model;homme	This paper proposes a framework of colour preference control to satisfy the consumer's colour related emotion. A colour harmony algorithm based on two-colour combinations is developed for displaying the images with several complementary colour pairs as the relationship of two-colour combination. The colours of pixels belonging to complementary colour areas in HSV colour space are shifted toward the target hue colours and there is no colour change for the other pixels. According to the developed technique, dynamic emotions by the proposed hue conversion can be improved and the controlled output image shows improved colour emotions in the preference of the human viewer. The psychophysical experiments are conducted to investigate the optimal model parameters to produce the most pleasant image to the users in the respect of colour emotions.© (2008) COPYRIGHT SPIE--The International Society for Optical Engineering. Downloading of the abstract is permitted for personal use only.		Ji Young Hong;Youngshin Kwak;Du-Sik Park;Chang-Yeong Kim	2008		10.1117/12.766022	computer vision;visual perception;artificial intelligence;color space;pixel;satisfiability	Robotics	62.13748484380838	-61.784813534090695	52400
7133fc9e480a103f6727348accabec302dcab3f8	a variational pansharpening approach based on reproducible kernel hilbert space and heaviside function		Pansharpening is an important application in remote sensing image processing. It can increase the spatial-resolution of a multispectral image by fusing it with a high spatial-resolution panchromatic image in the same scene, which brings great favor for subsequent processing such as recognition, detection, etc. In this paper, we propose a continuous modeling and sparse optimization based method for the fusion of a panchromatic image and a multispectral image. The proposed model is mainly based on reproducing kernel Hilbert space (RKHS) and approximated Heaviside function (AHF). In addition, we also propose a Toeplitz sparse term for representing the correlation of adjacent bands. The model is convex and solved by the alternating direction method of multipliers which guarantees the convergence of the proposed method. Extensive experiments on many real datasets collected by different sensors demonstrate the effectiveness of the proposed technique as compared with several state-of-the-art pansharpening approaches.	approximation algorithm;augmented lagrangian method;bands;convergence (action);convex function;experiment;hilbert space;image processing;kernel (operating system);mathematical optimization;multiresolution analysis;multispectral image;sparse approximation;sparse matrix;spectral density estimation;super-resolution imaging;toeplitz hash algorithm;variational inequality;variational principle;sensor (device)	Liang-Jian Deng;Gemine Vivone;Weihong Guo;Mauro Dalla Mura;Jocelyn Chanussot	2018	IEEE Transactions on Image Processing	10.1109/TIP.2018.2839531	mathematical optimization;kernel (linear algebra);hilbert space;pattern recognition;multispectral image;artificial intelligence;multiresolution analysis;computer science;distortion;reproducing kernel hilbert space;image resolution;heaviside step function	Vision	68.19952654183759	-66.93667198271181	52427
a49278b009ea9c1746b7f92beae1b2e8ed29733a	optical flow estimation using adaptive wavelet zeroing	adaptive optics image motion analysis wavelet coefficients optical noise testing image sequences apertures optical devices brightness equations;correlated noise;image motion analysis;optical noise;piecewise smooth;penalty parameter optical flow estimation adaptive wavelet zeroing motion fields real image sequences correlated noise wavelet coefficients l sub 1 regularisation sequence adaptive method;real image sequences;aperture problem;optical flow estimation;image restoration;testing;wavelet shrinkage;wavelet transforms;brightness;penalty parameter;l 1 regularisation;adaptive method;image sequence;wavelet transforms image sequences image restoration;motion fields;optical flow;adaptive wavelet zeroing;wavelet coefficients;apertures;adaptive optics;optical devices;image sequences;sequence adaptive method	Motionjelds of real image sequences are typically piecewise smooth with discontinuities at object boundaries. Further, because of the aperture problem, only the normal component of the optical flow can be observed. Direct application of wavelet shrinkage to the normal component flow may yield undesirable results due to the correlated noise affecting the wavelet coeficients. In this paper, we present a new technique for estimating optical flow based on L1 regularisation. The resulting flow estimate typically has many zero wavelet coeficients, but unlike wavelet shrinkage some of the remaining coeficients are allowed to “grow”. To highlight this difference, we have named our new technique wavelet zeroing. Additionally, we present a data-driven, sequence adaptive method for optimally choosing the penalty parameter.	cpu cache;optical flow;wavelet	Lydia Ng;Victor Solo	1999		10.1109/ICIP.1999.817211	wavelet;image restoration;aperture;computer vision;mathematical optimization;second-generation wavelet transform;motion perception;computer science;optical flow;cascade algorithm;mathematics;wavelet packet decomposition;software testing;stationary wavelet transform;discrete wavelet transform;adaptive optics;brightness;wavelet transform	Vision	54.29731348158533	-71.18262566480493	52439
b5b577a7a19abfc2c4fe2649e4fd124674c7194d	historical urban land use transformation in virtual geo-library	indonesia;urbanization;virtual geo library;gis;land use transformation	As countries become increasingly urbanized, understanding how urban areas are changing within the landscape becomes increasingly important. Urbanized areas are often the strongest indicators of human interaction with the environment, and understanding how urban areas develop through remotely sensed data allows for more sustainable practices. A Landsat satellite sensor which is a remote sensing platform, with its ability to analyze global data, rapidly present itself as being an invaluable tool for studying the growth of urban areas. In this study, we present the virtual geo-library as the geovisualization tools to provide the analytical studies of the urbanization process in Malang City, East Java, Indonesia, using images derived from Landsat sensor family (1989 to 2014). We provide a dynamic geovisualization through virtual geo-library, where users could understand and get valuable scientific information (e.g., urban area changes and land use transformation in higher land). This system is also equipped with the tools to enable users to create automatic cartographic maps and print the results out as a digital pdf format file.	cartography;geovisualization;java;map;portable document format	Fatwa Ramdani;Alfian Pratama Putra;Bayu Nursito Utomo	2015	ISPRS Int. J. Geo-Information	10.3390/ijgi4031500	geography;cartography;remote sensing	HCI	81.40670388010052	-56.00134810677262	52487
b4442589e99c4ebba7a7710a22026c8dd0a19992	coherence optimisation and its limitations for deformation monitoring in agricultural regions	coherence polinsar subsidence monitoring interferometry;l band data deformation monitoring agricultural regions differential interferometry techniques deformation measurements vegetation land surface evolution phase noise component underground mining environments surface deformation temporal decorrelation effects dinsar polinsar technique polarimetric radarsat 2 data alos palsar data optimisation multiple scattering mechanism approach c band radarsat 2 data scattering process random phase temporal baseline effects polinsar approach interferograms;phase noise;coherence optimization synthetic aperture radar interferometry phase noise decorrelation;vegetation geomorphology geophysical techniques optimisation radar interferometry;coherence;decorrelation;optimization;interferometry;synthetic aperture radar	Differential interferometry techniques are well known for their ability to provide cm to mm scale deformation measurements. However, in natural and agricultural areas, the presence of vegetation and the evolution of the land surface introduce a phase noise component which limits successful interferometric measurement. In underground mining environments, operational monitoring of surface deformation will be limited due to these temporal decorrelation effects. This paper aims to address the known limitations of traditional dInSAR in the presence of disturbances to reflected signals due to agricultural activities by testing the polInSAR technique for its ability to increase interferometric coherence and to detect surface movement in the areas of interest. Both fully polarimetric RADARSAT-2 and ALOS PALSAR data were subject to coherence optimisation using the Multiple Scattering Mechanism approach. For C-band RADARSAT-2 data, coherence optimisation resulted in a statistically significant increase in interferometric coherence. However, the spatial heterogeneity of the scattering process and how it changes over time caused random phase changes associated with temporal baseline effects and the evolution of the land surface. These effects could not be removed from C-band interferograms using the polInSAR approaches. Therefore, coherence optimization resulted in an increase in the random speckle in interferograms reducing the ability to derive high confidence interferometric measurements. On the other hand, coherence optimization on L-band data demonstrated an increase in the spatial homogeneity of the speckle noise indicating that coherence optimization on L-band data may be more successful in enhancing the ability to extract deformation measurements in dynamic agricultural regions.	baseline (configuration management);cache coherence;decorrelation;l band;mathematical optimization;phase noise;polarimetry	Jeanine Engelbrecht;Michael R. Inggs	2015	2015 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)	10.1109/IGARSS.2015.7326046	synthetic aperture radar;decorrelation;coherence;geodesy;interferometry;optics;phase noise;physics;quantum mechanics;remote sensing	Robotics	81.2204685358882	-61.61868594953331	52564
bcb6ac2e954b667acbd34efd6f5898e48bf1e643	image reconstruction from double random projection	image sampling;image coding;hyperspectral images;approximation algorithms;singular value decomposition;natural images;optimal low rank approximation;random matrix;matrix algebra;matrix decomposition approximation methods image reconstruction symmetric matrices vectors image coding approximation algorithms;symmetric matrices;approximation theory;random projection matrix;vectors;low rank matrix approximations;matrix decomposition;compressive sensing;image reconstruction;double random projection method;reconstruction error;approximation methods;random projection;compressible matrices;asymmetric distributions	We present double random projection methods for reconstruction of imaging data. The methods draw upon recent results in the random projection literature, particularly on low-rank matrix approximations, and the reconstruction algorithm has only two simple and noniterative steps, while the reconstruction error is close to the error of the optimal low-rank approximation by the truncated singular-value decomposition. We extend the often-required symmetric distributions of entries in a random-projection matrix to asymmetric distributions, which can be more easily implementable on imaging devices. Experimental results are provided on the subsampling of natural images and hyperspectral images, and on simulated compressible matrices. Comparisons with other random projection methods are also provided.	algorithm;chroma subsampling;iterative reconstruction;low-rank approximation;random projection;singular value decomposition	Qiang Zhang;Robert J. Plemmons	2014	IEEE Transactions on Image Processing	10.1109/TIP.2014.2316642	iterative reconstruction;mathematical optimization;combinatorics;discrete mathematics;random matrix;mathematics;matrix decomposition;compressed sensing;singular value decomposition;approximation algorithm;symmetric matrix;approximation theory	Vision	58.28548537716468	-73.42045425729245	52580
7c6396ef22eb604e6047daa7f670a4e607b870a1	modeling and simulation of polarimetric hyperspectral imaging process	geophysical image processing;analytical models;vegetation mapping;polarimetric spectral information;stokes vector;polarimetric integration polarimetric hyperspectral imaging process simulation polarimetric spectral information remote sensing applications crop growth monitoring water quality geology mapping information extraction classical fast canopy reflectance model vegetation canopy;information extraction;modeling and simulation;remote sensing crops geophysical image processing;biological system modeling;classical fast canopy reflectance model;imaging modeling;polarimetric information;water quality;remote sensing applications;polarimetric hyperspectral imaging process simulation;indexes;biological system modeling atmospheric modeling hyperspectral imaging vegetation mapping analytical models indexes;stokes vector image simulation imaging modeling polarimetric hyperspectral images polarimetric information;image simulation;polarimetric integration;reflection model;remote sensing;indexation;polarimetric hyperspectral images;geology mapping;crops;crop growth monitoring;atmospheric modeling;hyperspectral imaging;vegetation canopy;image modeling;hyperspectral image;analytical model	Polarimetric hyperspectral images can provide spectral, spatial, and polarimetric information of a scene, which are unique and comprehensive for remote sensing applications such as growth monitoring of crops, analysis of water quality, and geology mapping, etc. The researches on polarimetric hyperspectral imaging mechanism and on image characteristics are of great importance for further information extraction and utilization of the images. The purposes of this paper are to analyze the mechanism of polarimetric hyperspectral imaging and to model such a process. The outcome of the paper will help designers and users of a polarimetric hyperspectral imaging system to further understand the system and take full advantages of it. In this paper, a polarimetric hyperspectral imaging model is proposed, in which the influence of skylight on polarization is considered, and subpixel model, polarized reflectance models, and the classical fast canopy reflectance model are combined to model the vegetation canopy. Then, a simulated scene that includes a woodland area with low shrubbery and a road is obtained by using the imaging model. Experiments analyze and discuss the simulation condition and parameters of the imaging models, the uniqueness, and usefulness of the integration of polarimetric and spectral information.	information extraction;motorola canopy;pixel;polarimetry;polarization (waves);simulation	Junping Zhang;Jiawei Chen;Bin Zou;Ye Zhang	2012	IEEE Transactions on Geoscience and Remote Sensing	10.1109/TGRS.2011.2172618	full spectral imaging;crop;database index;computer vision;atmospheric model;hydrology;hyperspectral imaging;modeling and simulation;remote sensing application;information extraction;physics;stokes parameters;remote sensing	Vision	78.71180260195688	-61.299597734467476	52602
0d774cc0dd8e6517b22ee6afa927d62731946aad	opposite side ers-1 sar stereo mapping over rolling topography	geophysical signal processing feature extraction remote sensing by radar synthetic aperture radar radar imaging stereo image processing spaceborne radar topography earth;teledetection spatiale;linea costa;surfaces spaceborne radar synthetic aperture radar radar imaging feature extraction geometry lighting terrain mapping image analysis remote sensing;topography earth;systeme information geographique;space remote sensing;layover;features extraction;illumination;topographie;radar antenne synthetique;altimetrie;dem extractions opposite side ers 1 sar stereo mapping rolling topography radar stereo images illumination shadow layover foreshortening stereo viewing plotting features extraction planimetric accuracy altimetric accuracy lake shorelines;lago;altimetry;lakes;geometry;stereo viewing;altimetria;radar stereo images;cartographie;topography;altimetric accuracy;planimetric accuracy;ligne rivage;geographical information system;remote sensing by radar;canada;teledeteccion espacial;cartografia;lake shorelines;shadow;geophysical signal processing;feature extraction;opposite side ers 1 sar stereo mapping;remote sensing;radar imaging;stereo image processing;plotting;cartography;image analysis;surfaces;dem extractions;terrain mapping;lighting;lac;foreshortening;rolling topography;shorelines;sistema informacion geografica;topografia;satellite ers 1;spaceborne radar;synthetic aperture radar	Opposite-side radar stereo images have been considered unsuitable for stereo viewing due to illumination differences which limit the ability to identify the same features in the image pair. In some contexts, like a rolling topography (slope less than 10/spl deg/), the shadow, layover, and foreshortening effects, specific to radar images, will not be overwhelming with an opposite-side stereo pair. This paper reports on some issues of stereo viewing and plotting, as well as on quantitative results of mapping and features extraction from ascending and descending orbit ERS-1 SAR stereo images. Planimetric accuracy of 17 m and altimetric accuracy of 23.9 m have been achieved for lake shorelines and DEM extractions, respectively. Impacts of different parameters on the accuracy are also evaluated.	dillon's rolling western;topography	Thierry Toutin	1996	IEEE Trans. Geoscience and Remote Sensing	10.1109/36.485130	computer stereo vision;computer vision;image analysis;geodesy;topography;lighting;physics;remote sensing	Mobile	78.20877097106556	-63.096713259717916	52609
5aec39e5efdeaf573ae728956d09a7133052d732	color removal considering differences of colors and achromatic color preservation	color image	In this letter, a novel color removal method considering differences of colors in an input color image and achromatic color preservation is proposed. The achromatic color preservation is assigning lightness values to gray-levels concerning achromatic pixels for natural impression. The effectiveness and validity of the proposed method are verified by experiments.	color	Go Tanaka;Noriaki Suetake;Eiji Uchino	2013	IEICE Transactions		color histogram;computer vision;primary color;color model;lightness;color image;computer science;color balance;color space;pixel;achromatic lens;spectral color	Visualization	59.3667676225546	-61.74603484065869	52626
e59cf44c46f555e3bff4cc9c4f2af068e877330e	a 3d imaging technique for circular radar sensor networks based on radon transform	cgrt;3d imaging;simulation;complex valued generalised radon transform;crsn;circular radar sensor networks;cgrt clean;circular synthetic aperture radar;csar;reflection coefficient;position information	A three dimensional 3D imaging method which is a complex-valued generalised Radon transform CGRT-CLEAN algorithm for circular radar sensor networks CRSN is proposed in this paper. Based on the analysis of CRSN echo model, the echo of a scatterer in the range-azimuth domain can be modelled as a single cycle sinusoid. Inspired by the generalised Radon transform, this paper utilises the CGRT to estimate for scatterers' positions. Then, combining the CGRT with CLEAN technique, the parameters of a scatterer which include position information and reflection coefficient can be obtained. Thus, a 3D image of a target can also be reconstructed. Comparing with other algorithms, the outstanding characteristic of the proposed algorithm is that there is no need to analyse azimuth spectrum to achieve a 3D imaging. The performances of the CGRT-CLEAN method have been verified by simulations, and the results confirm the effectiveness of the proposed algorithm for processing CRSN data.	radar;stereoscopy	Biao Zhang;Yiming Pi	2013	IJSNet	10.1504/IJSNET.2013.055582	stereoscopy;simulation;computer science;reflection coefficient	Mobile	74.94592333774612	-68.5448430242469	52711
32900951cbc3006b5aadd9c119c28e9e24c2cb26	label propagation through edge-preserving filters	automatically generated sparse features label propagation edge preserving filters domain transform filter image structure global optimization;labeling transforms image edge detection interpolation optimization image color analysis three dimensional displays;interpolation edge detection feature extraction;sparse feature interpolation domain transform 2d to 3d conversion label propagation	In this paper we investigate methods for propagating automatically generated or user-defined labels through an image using edge-preserving filters. We focus on the domain transform filter as it has been used for propagation purposes in the past. The method we present addresses some of the numerical issues that arise with using the filter directly and also improve on the results by better respecting the underlying image structure during the label propagation. Finally we also demonstrate how a filter-based approach is preferable to using global optimization for interpolating automatically generated sparse features.	edge enhancement;global optimization;interpolation;mathematical optimization;numerical analysis;software propagation;sparse matrix	Richard Rzeszutek;Dimitrios Androutsos	2014	2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	10.1109/ICASSP.2014.6853666	demosaicing;computer vision;machine learning;pattern recognition;mathematics	Robotics	56.49695404749325	-69.96622257794016	52785
3a841414ab1e868d0089350f38d2101456373ea1	transputer based distributed cartographic image processing	image processing;distributed processing;computer architecture;computerised picture processing;cartography;transputers	Image processing requires large amounts of memory (main memory and mass storage) and important processing power. Digital signal processors (DSP) can increase processing speeds, but they don't provide any facilities for multiprocessing and for the management of mass storage devices. The present project requires the processing of large aerial photographs (20000×20000 pixels) for the automatic computation of terrain elevation. Currently, a CCD camera scans image parts of 512 by 480 pixels and transmits them to the image processing array. A processing array based on transputers was chosen for the parallelization of image processing operations. Such an architecture can easily be expanded if more processing power and storage capacity are required. The authors describe the message passing system ensuring communications between any processors of the network and several image processing algorithms running in a network which currently includes twenty transputers	image processing;transputer	B. Chardonnes;Roger D. Hersch;O. Kölbl	1990		10.1007/3-540-53065-7_112	parallel computing;analog image processing;computer hardware;image processing;computer science;digital image processing;computer graphics (images)	Robotics	69.02710174374089	-53.239974316730866	52806
2cf3a1e4c696c01b676df9d1bee2985f7f7543b0	enhancing perceived depth in images via artistic matting	tone reproduction;dynamic range;color appearance;categories and subject descriptors according to acm ccs i 3 7 computer graphics 2d graphics	We present a simple tutorial for the addition of artistic mattes to digital images for the purpose of enhancing the three-dimensional effect of the image. We show that artistic mattes add visual cues to an image enhancing the sense of depth in the image. We also report the results from two perception studies on matte color preferences and depth estimates in matted versus non-matted images.	digital image;matte display	Amy Ashurst Gooch;Bruce Gooch	2004		10.1145/1012551.1012590	computer vision;dynamic range;computer science;multimedia;computer graphics (images)	HCI	61.59309090749904	-60.87822013763256	52810
0fde7423ce0c613837ae016d48e7957c309ae01d	the interferometric data calibration for the airsar pacrim ii mission	calibrating;airborne synthetic aperture radar airsar;antenna measurements;data processing;radiofrequency interference;receivers;accuracy;global positioning system;radar antennas;error correction;differential global positioning system;propulsion;calibration error correction delay estimation radar antennas propulsion laboratories radiofrequency interference receivers global positioning system antenna measurements;accuracy analysis;interferometry;interferometric sar;calibration;delay estimation;inertial navigation system;synthetic aperture radar	This paper focuses on the crosstrack interferometric data calibration results and height accuracy analysis. We also present the key elements of the calibration technique for cross-track interferometric SAR data processed with the AIRSAR Integrated Processor.		Anhua Chu;Yunjin Kim;Jakob J. van Zyl;Yunling Lou;Bruce Chapman	2005	Proceedings. 2005 IEEE International Geoscience and Remote Sensing Symposium, 2005. IGARSS '05.	10.1109/IGARSS.2005.1526430	calibration;data processing;geodesy;physics;remote sensing	Embedded	79.99367841603927	-65.06079909435188	52869
dd5b2b6a840617840b84b1a148033743029457b5	autoencoder-driven weather clustering for source estimation during nuclear events		Emergency response applications for nuclear or radiological events can be significantly improved via deep feature learning due its ability to capture the inherent complexity of the data involved. In this paper we present a novel methodology for rapid source estimation during radiological releases based on deep feature extraction and weather clustering. Atmospheric dispersions are then calculated based on identified predominant weather patterns and are matched against simulated incidents indicated by radiation readings on the ground. We evaluate the accuracy of our methods over multiple years of weather reanalysis data in the European region. We juxtapose these results with deep classification convolution networks and discuss advantages and disadvantages. We find that deep autoencoder configurations can lead to accurate-enough origin estimation to complement existing systems, while allowing for rapid initial response.	algorithm;artificial neural network;atmospheric dispersion modeling;autoencoder;cluster analysis;convolution;data mining;deep learning;experiment;feature extraction;feature learning;image processing;machine learning;meteorological reanalysis;operational system;plume (fluid dynamics);prototype;quasiperiodicity;recurrent neural network;sensor	Iraklis A. Klampanos;Athanasios Davvetas;Spyros Andronopoulos;Charalambos Pappas;Andreas Ikonomopoulos;Vangelis Karkaletsis	2018	Environmental Modelling and Software	10.1016/j.envsoft.2018.01.014	management science;autoencoder;cluster analysis;feature extraction;radiation;computer science;artificial intelligence;feature learning;pattern recognition	ML	77.56306895253924	-59.401107894195555	52882
779c45a4030d8994aad2600ae1fa941a169125b3	single image super-resolution via internal gradient similarity	image super resolution;patch similarity;across scale;gradient similarity;self redundancy;optimization;image quality enhancement;gradient descent algorithm	Image super-resolution aims to reconstruct a high-resolution image from one or multiple low-resolution images which is an essential operation in a variety of applications. Due to the inherent ambiguity for superresolution, it is a challenging task to reconstruct clear, artifacts-free edges while still preserving rich and natural textures. In this paper, we propose a novel, straightforward, and effective single image superresolution method based on internal across-scale gradient similarity. The low-resolution gradients are first upsampled and then fed into an optimization framework to construct the final high-resolution output. The proposed approach is able to synthesize natural high-frequency texture details and maintain clean edges even under large scaling factors. Experimental results demonstrate that out method outperforms existing single image super-resolution techniques. We further evaluate the super-resolution performance when both internal statistics and external statistics are adopted. It is demonstrated that generally, internal statistics are sufficient for single image super-resolution.	autostereogram;image resolution;image scaling;mathematical optimization;stochastic gradient descent;super-resolution imaging;upsampling	Yang Xian;Yingli Tian	2016	J. Visual Communication and Image Representation	10.1016/j.jvcir.2015.11.015	gradient descent;computer vision;mathematical optimization;feature detection;computer science;machine learning;mathematics	Vision	59.02435444244924	-65.98013186060402	52915
47e6de670d304219f3edab66d24e6d7bfc9fb7b6	an optimal weighted averaging fusion strategy for thermal and visible images using dual tree discrete wavelet transform and self tunning particle swarm optimization		Image fusion plays a vital role in providing better visualization of image data. In this paper, we propose a new algorithm that optimally combines information from thermal images with a visual image of the same scene to create a single comprehensive fused image. In this work, an improved version of particle swarm optimization alogithm is proposed to optimally combine the thermal and visible images. The proposed algorithm is named self tunning particle swarm optimization (STPSO). Because of the importance of the fusion rule, a weighted averaging fusion rule is formulated that uses optimal weights resulting from STPSO for the fusion of both high frequency and low frequency coefficients obtained by applying Dual Tree Discrete Wavelet Transform (DT-DWT). The objective function in STPSO is formulated with the twin objectives of maximizing the Entropy and minimizing the Root Mean Square Error (RMSE), which differentiates our work from existing fusion techniques. The efficiency of our fusion algorithm is also evaluated by adding Gaussian white noise to the source images. The fusion results are compared with existing multi-resolution based fusion techniques, such as Laplacian Pyramid (LAP), Discrete Wavelet Transform (DWT) and Non Sub-Sampled Contourlet Transform (NSCT). The simulation results indicate that the proposed fusion framework results in better quality fused images when evaluated with subjective and objective metrics. Comparision of these results with those from PSO shows that our algorithm outperforms generic PSO.	airborne ranger;algorithm;coefficient;contourlet;discrete wavelet transform;distortion;dynamic range;image fusion;laplacian matrix;loss function;mathematical optimization;mean squared error;optimization problem;particle swarm optimization;resultant;simulation;spectral density;temporal logic;white noise	Madheswari Kanmani;Venkateswaran Narasimhan	2016	Multimedia Tools and Applications	10.1007/s11042-016-4030-x	computer vision;mathematical optimization;machine learning	Robotics	59.348016264266704	-66.69930733461946	52964
a5fda1315f23f5fdb747d6966cd526fe642d8ec6	sparse parallel mri based on accelerated operator splitting schemes		Recently, the sparsity which is implicit in MR images has been successfully exploited for fast MR imaging with incomplete acquisitions. In this paper, two novel algorithms are proposed to solve the sparse parallel MR imaging problem, which consists of l1 regularization and fidelity terms. The two algorithms combine forward-backward operator splitting and Barzilai-Borwein schemes. Theoretically, the presented algorithms overcome the nondifferentiable property in l1 regularization term. Meanwhile, they are able to treat a general matrix operator that may not be diagonalized by fast Fourier transform and to ensure that a well-conditioned optimization system of equations is simply solved. In addition, we build connections between the proposed algorithms and the state-of-the-art existing methods and prove their convergence with a constant stepsize in Appendix. Numerical results and comparisons with the advanced methods demonstrate the efficiency of proposed algorithms.	algorithm;condition number;elastic net regularization;fast fourier transform;list of operator splitting topics;mathematical optimization;mitral valve insufficiency;numerical method;partial;sparse matrix	Nian Cai;Weisi Xie;Zhenghang Su;Shanshan Wang;Dong Liang	2016		10.1155/2016/1724630	mathematical optimization;theoretical computer science;machine learning;mathematics;algorithm	ML	57.76530954364101	-73.98189772684	52976
35d231dad3b08f5fa7faaf893a2e7df865084ae9	urban footprint processor—fully automated processing chain generating settlement masks from global data of the tandem-x mission	geophysical image processing;landoberflache;texture;speckle;speckle time division multiplexing synthetic aperture radar spatial resolution backscatter urban areas remote sensing;urbanization;global mapping;synthetic aperture radar digital elevation models geophysical image processing geophysics computing image classification image texture program processors remote sensing by radar;georisiken und zivile sicherheit;backscatter;terrasar x add on for digital elevation measurement tandem x;image classification;image texture;remote sensing by radar;urban areas;geophysics computing;settlements pattern;remote sensing;digital elevation models;urbanization automation global mapping settlements pattern terrasar x add on for digital elevation measurement tandem x texture;time division multiplexing;program processors;synthetic aperture radar;spatial resolution;automation	The German TerraSAR-X add-on for Digital Elevation Measurement (TanDEM-X) mission (TDM) collects two global data sets of very high resolution (VHR) synthetic aperture radar (SAR) images between 2011 and 2013. Such imagery provides a unique information source for the identification of built-up areas in a so far unique spatial detail. This letter presents the novel implementation of a fully automated processing system for the delineation of human settlements worldwide based on the SAR data acquired in the context of the TDM. The proposed Urban Footprint Processor (UFP) includes three main processing stages dedicated to: i) the extraction of texture information suitable for highlighting regions characterized by highly structured and heterogeneous built-up areas; ii) the generation of a binary settlement layer (built-up, non-built-up) based on an unsupervised classification scheme accounting for both the original backscattering amplitude and the extracted texture; and iii) a final post-editing and mosaicking phase aimed at providing the final Urban Footprint (UF) product for arbitrary geographical regions. Experimental results assess the high potential of the TDM data and the proposed UFP to provide highly accurate geo-data for an improved global mapping of human settlements.	add-ons for firefox;aperture (software);comparison and contrast of classification schemes in linguistics and metadata;image resolution;image stitching;information source;postediting;synthetic data;toad data modeler;unsupervised learning	Thomas Esch;Mattia Marconcini;Andreas Felbier;Achim Roth;Wieke Heldens;Martin Huber;Max Schwinger;Hannes Taubenböck;Andreas Müller;Stefan W. Dech	2013	IEEE Geoscience and Remote Sensing Letters	10.1109/LGRS.2013.2272953	speckle pattern;image texture;computer vision;urbanization;contextual image classification;synthetic aperture radar;image resolution;digital elevation model;computer science;automation;texture;backscatter;physics;time-division multiplexing;remote sensing	Vision	76.9608360173681	-59.16811734924551	53000
a6b6e9073ee33dfc257d67fc441cdfb3b7abb896	walled ltsa array for rapid, high spatial resolution, and phase-sensitive imaging to visualize plastic landmines	mine exposif;maps;phased arrays spatial resolution high resolution imaging visualization plastics landmine detection frequency linear antenna arrays optical reflection antenna measurements;wideband reflection measurement;metal plates;texture;radar methods;experimental studies;size 28 mm;high speed scanning;antenna measurements;slot antenna arrays adaptive antenna arrays geophysical techniques geophysics computing ground penetrating radar landmine detection self organising feature maps;mapa;metals;high spatial resolution imaging;resolution spatiale;landmine detection;size 14 mm;structure enfouie;substrat;etude experimentale;low frequency;compact wideband antenna;textural features;plastique;linearly tapered slot antenna;frequence;suelo;attenuation;reflection images;detection;texture features;sol;carte;complex valued self organizing map;costo;plastics;complex amplitude texture;buried features;electrical switches;radar penetration sol;visualization;ground penetrating radar gpr;slot antenna arrays;soils;linearly tapered slot antenna ltsa;frecuencia;ground penetrating radar;plastic landmine;amplitud;plastic landmine visualization;geophysics computing;adaptive nonlinear visualization system;self organising feature maps;radar antennas;mines;slot antenna;atenuacion;textura;basse frequence;adaptive csom processing;phase sensitive imaging;self organized map;rapid imaging;amplitude;complex valued self organizing map csom;substrates;mine;frequency;plastic landmine complex valued self organizing map csom ground penetrating radar gpr linearly tapered slot antenna ltsa;mina;cost;visual system;high speed;glass epoxy substrates;reflection;methode radar;textures;frequency 8 ghz to 12 ghz;geophysical techniques;radar;walled ltsa array;cout;high spatial resolution;adaptive antenna arrays;spatial resolution	We propose a walled linearly tapered slot antenna (LTSA) array to visualize plastic landmines. Previously, we reported an adaptive nonlinear visualization system based on a complex-valued self-organizing map (CSOM) that deals with complex amplitude texture in reflection images at multiple frequencies. The system distinguishes landmines from clutter by paying attention to textural features obtained by high spatial resolution and wideband reflection measurement. Because the system employed a mechanical scan of a pair of horn antennas, the measurement required a long time. An array antenna can reduce the time. The antenna element to be used there should therefore be compact and wideband. This paper reports the design and fabrication of a walled LTSA array visualization system. The antenna element has a 14 times 28 mm aperture size, and works at the 8-12 GHz frequency band. Because the structure is a simple combination of glass epoxy substrates and metal plates, we can easily fabricate low-cost and lightweight arrays. Electrical switches realize a high-speed scanning of 12 times 12 = 144 elements in total. We also report the results of a visualization experiment, in which plastic landmines are clearly visualized with the array in combination with the adaptive CSOM processing. Detection of landmines at frequencies of 10 GHz is only likely to be possible for targets buried a few centimeter deep or where the soil attenuation is very low. This might be a severe limitation of applicability of the method, as in field conditions soil attenuations of 10 dB or considerably more are commonly encountered, requiring the radar to operate at frequencies below 2-3 GHz. The best solution may be a multisensor system comprising these complementary high- and low-frequency radars.	clutter;frequency band;local tangent space alignment;mock object;network switch;nonlinear system;organizing (structure);phasor;radar;self-organization;self-organizing map	Soichi Masuyama;Akira Hirose	2007	IEEE Transactions on Geoscience and Remote Sensing	10.1109/TGRS.2007.897418	optics;amplitude;physics;quantum mechanics;remote sensing	Visualization	78.35202928796	-68.05412046274526	53030
82ddc4e6c9a219b5721dcac35eb39ce795b16ca2	evaluation of different types of filters in magnetic resonance imaging using compressive sensing with pre-filtering		Magnetic resonance imaging (MRI) machines allow one to acquire medical images based on static and variable magnetic fields, in such a way as to reveal the interior of human organs. To acquire images with good quality, MRI machines often demand a high number of measurements, which often require long acquisition times. Therefore, an important topic of research consists of developing acquisition methods that reduce the number of measurements and, consequently, the time required to acquire an MRI image. In this work, we use compressive sensing techniques and pre-filtering strategies to reduce the number of MRI measurements. We empirically tested a large set of filter banks to determine which filter settings provide the best image quality. When compared with state-of-the-art filters and to the non-uniform Fourier transform reconstruction, we have been able to increase the quality of the generated images while reducing the required number of radial lines and, therefore, of acquisition samples.	bank (environment);compressed sensing;filter bank;image quality;magnetic resonance imaging;organ;radial (radio)	Jonathan A. Lima;Cristiano J. Miosso;Mylène C. Q. Farias;Ricardo von Borries	2018	2018 40th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)	10.1109/EMBC.2018.8513618	computer vision;electronic engineering;compressed sensing;fourier transform;iterative reconstruction;image quality;filter (signal processing);artificial intelligence;magnetic resonance imaging;computer science	Robotics	54.91745384116275	-78.92800007702724	53106
c1603edc94e621c46c4a109228f86081ae7aaf8e	effect of dem uncertainty on the positional accuracy of airborne imagery	geophysical image processing;analytical models;uncertainty digital elevation model dem error propagation geometric correction georeferencing geostatistics monte carlo simulation orthorectification;terrains;topography uncertainty propagation;calabre;orthorectification;europa;europa sur;errors;kernel;radar methods;airborne imagery atmospheric processing;erreur;geometric correction;geostatistique;topography earth;airborne imagery geometric processing;geoestadistica;information sources;uncertainty modeling;mountainous area;topographie;uncertainty;europe sud;uncertainty propagation;qualite;uncertainty monte carlo methods analytical models accuracy pixel kernel correlation;simulation;direccion;calabria;geostatistical uncertainty model;methode monte carlo;terrain;imagerie;off nadir viewing angles;italia;geostatistics;simulacion;correction;shuttle radar topography mission dem;digital elevation model;image geographic positioning;shuttle radar topography mission;topography;aircraft movements;corrections;error analysis;accuracy;modelo;positioning;aircraft changes;imagery;precision;uncertainties;digital elevation model dem;propagacion;error propagation;direction;italie;calabria italy;quality;topography earth digital elevation models error analysis geophysical image processing measurement errors monte carlo methods remote sensing;remote sensing;monte carlo method;pixel;airborne imagery positional accuracy;correccion;italy;digital elevation models;modele;imagineria;incertitude;error;correlation;europe;southern europe;variability;monte carlo;monte carlo simulation	The geometric and atmospheric processing of airborne imagery is a complex task that involves many correction steps. Geometric correction is particularly challenging because slight movements of the aircraft and small changes in topography can have a great impact on the geographic positioning of the processed imagery. This paper focused on how uncertainty in topography, represented by a digital elevation model (DEM), propagates through the geometric correction process. We used a Monte Carlo analysis, in which, first, a geostatistical uncertainty model of the DEM was developed to simulate a large number of DEM realizations. Next, geometric correction was run for each of the simulated DEMs. The analysis of the corrected images and their variability provided valuable information about the positional accuracy of the corrected image. The method was applied to a hyperspectral image of a mountainous area in Calabria, Italy, by using the Shuttle Radar Topography Mission-DEM as the topographic information source. We found out that the uncertainty varies greatly over the whole terrain and is substantial at large off-nadir viewing angles in the across-track direction. Also, positional uncertainty is larger in rugged terrains. We conclude that Monte Carlo uncertainty propagation analysis is a valuable technique in deriving quality layers that inform end users about the positional accuracy of airborne imagery, and we recommend that it is integrated in the operational processing steps of the Processing and Archiving Facilities.	airborne ranger;algorithm;digital elevation model;distortion;file archiver;information source;map;monte carlo method;pixel;propagation of uncertainty;rugged computer;shuttle radar topography mission;simulation;software propagation;spatial variability;viewing angle	Johan Beekhuizen;Gerard B. M. Heuvelink;Jan Biesemans;Ils Reusen	2011	IEEE Transactions on Geoscience and Remote Sensing	10.1109/TGRS.2010.2083672	topography;mathematics;statistics;remote sensing;monte carlo method;geostatistics	Visualization	78.72166581162105	-64.5057480022571	53107
9347e3ab184dc8e3d655a38d639ddb038c0553e9	evaluating a satellite-based seasonal evapotranspiration product and identifying its relationship with other satellite-derived products and crop yield: a case study for ethiopia	risk management;early warning;food security;crop yield;drought;evapotranspiration	Satellite-derived evapotranspiration anomalies and normalized difference vegetation index (NDVI) products from Moderate Resolution Imaging Spectroradiometer (MODIS) data are currently used for African agricultural drought monitoring and food security status assessment. In this study, a process to evaluate satellite-derived evapotranspiration (ETa) products with a geospatial statistical exploratory technique that uses NDVI, satellite-derived rainfall estimate (RFE), and crop yield data has been developed. The main goal of this study was to evaluate the ETa using the NDVI and RFE, and identify a relationship between the ETa and Ethiopia’s cereal crop (i.e., teff, sorghum, corn/maize, barley, and wheat) yields during the main rainy season. Since crop production is one of the main factors affecting food security, the evaluation of remote sensing-based seasonal ETa was done to identify the appropriateness of this tool as a proxy for monitoring vegetation condition in drought vulnerable and food insecure areas to support decision makers. The results of this study showed that the comparison between seasonal ETa and RFE produced strong correlation (R2 > 0.99) for all 41 crop growing zones in Ethiopia. The results of the spatial regression analyses of seasonal ETa and NDVI using Ordinary Least Squares and Geographically Weighted Regression showed relatively weak yearly spatial relationships (R2 < 0.7) for all cropping zones. However, for each individual crop zones, the correlation between NDVI and ETa ranged between 0.3 and 0.84 for about 44% of the cropping zones. Similarly, for each individual crop zones, the correlation (R2) between the seasonal ETa anomaly and de-trended cereal crop yield was between 0.4 and 0.82 for 76% (31 out of 41) of the crop growing zones. The preliminary results indicated that the ETa products have a good predictive potential for these 31 identified zones in Ethiopia. Decision makers may potentially use ETa products for monitoring cereal crop yields and early warning of food insecurity during drought years for these identified zones. © 2015 Z. Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).	anomaly detection;dvorak simplified keyboard;geographic names information system;geographic information system;guinness world records;heart rate variability;map;norm (social);norsk data;ordinary least squares;proxy server;spatial analysis;spatial variability;time series	Tsegaye Tadesse;Gabriel B. Senay;Getachew Berhan;Teshome Regassa;Shimelis Beyene	2015	Int. J. Applied Earth Observation and Geoinformation	10.1016/j.jag.2015.03.006	evapotranspiration;crop yield;geography;risk management;hydrology;warning system;agronomy;agroforestry;food security	AI	82.11267639900473	-56.426112987361975	53154
0264e9fd2d915e2fcb28e7c7da953852df65979b	assessment of the clouds and the earth's radiant energy system (ceres) flight model 5 (fm5) instrument performance and stability	mirrors;sensors;black bodies;attenuators;aluminum;bolometers;clouds;satellites;solar radiation;shortwaves;scanning;orbital dynamics;equipment and services;water;calibration;radiation	The Clouds and the Earth’s Radiant Energy System (CERES) scanning radiometer is designed to measure the solar radiation reflected by the Earth and thermal radiation emitted by the Earth. Four CERES instruments are supporting the EOS missions; two aboard the Terra spacecraft, launched in 1999 and two aboard the Aqua spacecraft, launched in 2002. A fifth instrument, Flight Model 5 (FM5), launched in October 2011 aboard the S-NPP satellite, began taking radiance measurements on January 27th, 2012. The CERES FM5 instrument uses three scanning thermistor bolometers to make broadband radiance measurements in the shortwave (0.3 – 5.0 micrometers), total (0.3 - <100 micrometers) and water vapor window (8 – 12 micrometer) regions. An internal calibration module (ICM) used for in-flight calibration is built into the CERES instrument package consisting of an anodized aluminum blackbody source for calibrating the total and window sensors, and a shortwave internal calibration source (SWICS) for the shortwave sensor. The ICM sources, along with a solar diffusor called the Mirror Attenuator Mosaic (MAM), are used to define shifts or drifts in the sensor response over the life of the mission. In addition, validation studies are conducted to assess the pointing accuracy of the instrument and understand any spectral changes that may occur with the sensors allowing for corrections to be made to the radiance calculations in later CERES data products. This paper summarizes the on-orbit behavior of the CERES FM5 instrument by outlining trends in the internal calibration data and discussing the various validation studies used to assess the performance and stability of the instrument. © (2014) COPYRIGHT Society of Photo-Optical Instrumentation Engineers (SPIE). Downloading of the abstract is permitted for personal use only.	radiant ai	Nathaniel P. Smith;Susan Thomas;Mohan Shankar;Z. Peter Szewczyk;Robert S. Wilson;Dale R. Walikainen;Janet L. Daniels;Phillip C. Hess;Kory J. Priestley	2014		10.1117/12.2061833	meteorology;radiation;water;calibration;bolometer;sensor;sunlight;attenuator;black body;orbital mechanics;optics;physics;satellite;quantum mechanics;remote sensing	Robotics	82.19117248984135	-62.945648109433584	53203
5a3b9490a52920bd3695a3669150db267d5f7572	status report on the terrasar-x mission	ad 2007 06 15;geoscience and remote sensing;radar remote sensing;instruments;image segmentation;deutsches fernerkundungsdatenzentrum;institut fur hochfrequenztechnik und radarsysteme;national remote sensing satellite;satelliten sar systeme;terrasar x;system potential terrasar x radar satellite launch and early orbit phase commissioning phase;commissioning phase;indexing terms;satisfiability;design for disassembly;germany;remote sensing by radar;earth scientific observation terrasar x mission status germany national remote sensing satellite german aerospace centre eads astrium gmbh satellite launch ad 2007 06 15 high quality radar data;orbits;satellite;remote sensing data;remote sensing;satellites;first nation;launch and early orbit phase;german aerospace centre;eads astrium gmbh;satellites instruments spaceborne radar remote sensing radar remote sensing synthetic aperture radar phased arrays image segmentation calibration design for disassembly;terrasar x mission status;private sector;umwelt und sicherheit;satellite launch;calibration;earth scientific observation;system potential;high quality radar data;remote sensing by radar geophysical techniques;geophysical techniques;radar;spaceborne radar;synthetic aperture radar;phased arrays	TerraSAR-X is Germany's first national remote sensing satellite being implemented in a public-private partner-ship between the German Aerospace Centre (DLR) and EADS Astrium GmbH. TerraSAR-X was launched on June 15th, 2007 and will supply high-quality radar data for purposes of scientific observation of the Earth for a period of at least five years. At the same time it is designed to satisfy the steadily growing demand of the private sector for remote sensing data in the commercial market [1].	dynamic language runtime	Stefan Buckreuss;Achim Roth	2008	IGARSS 2008 - 2008 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2008.4779007	meteorology;geodesy;physics;satellite;remote sensing	Embedded	80.01293060472831	-62.67974857792898	53209
80e7ac037693823523c8e19ce0c24e3e8c703373	spatio-temporal cellular automata-based filtering for image sequence denoising		This work describes a novel spatio-temporal cellular automata-based filtering algorithm (st-CAF) intended for performing image sequence denoising processes. The approach presents several advantages over more traditional single frame denoising techniques presented in the literature or even over their adaptation to sequences. Especially the fact that the cellular automaton used is able to contemplate information concerning the type of noise through the use of specific sequences to tune the algorithm, as well as temporal information by means of a spatio-temporal neighborhood when processing each pixel of the sequence. These two elements lead to significant improvements in the results with respect to simple spatial or temporal sets of neighbors.	algorithm;automata theory;cellular automaton;neighbourhood (graph theory);noise reduction;norm (social);peak signal-to-noise ratio;pixel;sap composite application framework;shot noise;synthetic data;synthetic intelligence	Blanca Maria Priego Torres;Abraham Prieto;Richard J. Duro;Jocelyn Chanussot	2017	2017 International Joint Conference on Neural Networks (IJCNN)	10.1109/IJCNN.2017.7966142	filter (signal processing);machine learning;genetic algorithm;artificial intelligence;pixel;computer science;theoretical computer science;cellular automaton;noise reduction	Vision	56.041311923673	-67.90395583422271	53316
5d48e282a1848eb167d337a2dae34cf7e9ec2cf6	phasepack user guide		"""""""Phase retrieval""""refers to the recovery of signals from the magnitudes (and not the phases) of linear measurements. While there has been a recent explosion in development of phase retrieval methods, the lack of a common interface has made it difficult to compare new methods against the current state-of-the-art. PhasePack is a software library that creates a common interface for a wide range of phase retrieval schemes. PhasePack also provides a test bed for phase retrieval methods using both synthetic data and publicly available empirical datasets."""	library (computing);phase retrieval;synthetic data;testbed;two-phase commit protocol	Rohan Chandra;Ziyuan Zhong;Justin Hontz;Val McCulloch;Christoph Studer;Tom Goldstein	2017	CoRR		theoretical computer science;computer science;phase retrieval;synthetic data;software	Web+IR	60.37871746749873	-75.88940693138188	53351
9afd08431fe3233935e28c1911ef43ae7ad14f7b	compressive spectral imaging via polar coded aperture	continuous rotation model compressed sensing image coding polar coded aperture circular viable filter;apertures imaging image coding weapons modulation sensors spatial resolution	A compressive spectral imager based on a polar coded aperture and a continuous variable circular bandpass filter is proposed for spinning munitions. As the imager rotates with the munition, compressive projections are sequentially captured with embedded spatial and spectral modulation. The polar coded aperture design is introduced, aiming at optimizing the sensing process. Both discrete and continuous rotation models of the proposed imager are derived and used to characterize the compressive imager. Computer simulations validate the computational models and the reconstruction algorithm.	algorithm;coded aperture;compressed sensing;computational model;data cube;embedded system;gaussian blur;image quality;image sensor;modulation;simulation	Chen Fu;Michael L. Don;Gonzalo R. Arce	2017	IEEE Transactions on Computational Imaging	10.1109/TCI.2016.2617740	computer vision;computer science;mathematics;optics;physics;remote sensing	Vision	67.75013114654577	-61.36710809220887	53371
39d5828554c82b1e9b5116b0be8e3a68ec700dd8	phase distortion correction for see-through-the-wall imaging radar	homeland security;approximate algorithm;plane waves;backscatter;electromagnetic wave propagation;spectrum;approximation theory;iterative methods;ground penetrating radar;law enforcement;radar imaging;phase distortion radar imaging frequency electromagnetic scattering reflection law enforcement terrorism electromagnetic propagation propagation delay phase estimation;nonlinear successive approximation algorithm phase distortion correction see through the wall sttw radar imaging surface penetrating radar radar propagation wavenumber migration direct backscatter signal dual phase approach nonparametric technique dual frequency approach surface reflection coefficient back wall coefficient iterative algorithm;radar imaging approximation theory backscatter electromagnetic wave propagation ground penetrating radar iterative methods;newton raphson;dual phase;reflection coefficient;synthetic aperture radar;electromagnetic waves	See through the wall (STTW) applications have become of high importance to law enforcement, homeland security and defense needs. In this work surface penetrating radar is simulated using basic physical principles of radar propagation. Wavenumber migration is employed to form 2D images of objects found behind a wall. It is shown that this technique cannot properly image with the wall present because of an unknown phase delay experienced by the electromagnetic waves as they pass through the wall. Two approaches are taken to estimate this phase by looking at the direct backscatter signal from the wall. The first is a dual phase approach, which uses a non-parametric technique to find the phase at every frequency. The second method is a dual frequency approach. The two frequencies are close enough together that the reflection coefficients are approximately equal. This approximation allows for more observations than unknown parameters. The surface reflection coefficient, back wall coefficient, and phase are simultaneously determined using an iterative, non-linear (Newton-Raphson) successive approximation algorithm. Comparisons are performed for a simple scenario of three point scatterers with and without phase correction.	approximation algorithm;group delay and phase delay;iterative method;newton's method;nonlinear system;phase distortion;radar;radio frequency;reflection coefficient;software propagation	Jay A. Marble;Alfred O. Hero	2006	2006 International Conference on Image Processing	10.1109/ICIP.2006.312854	homeland security;spectrum;electromagnetic radiation;linear phase;synthetic aperture radar;plane wave;ground-penetrating radar;wave propagation;reflection coefficient;iterative method;newton's method;radar imaging;backscatter;approximation theory	Robotics	77.90181200368836	-69.25976103481787	53378
b528180f58f7de53d61d6309cc065b61dd89738b	an efficient polyphase filter-based resampling method for unifying the prfs in sar data		Variable higher pulse repetition frequencies (PRFs) are increasingly being used to meet the stricter requirements and complexities of current airborne and spaceborne synthetic aperture radar (SAR) systems associated with higher resolution and wider area products. POLYPHASE, the proposed resampling scheme, downsamples and unifies variable PRFs within a single look complex SAR acquisition and across a repeat pass sequence of acquisitions down to an effective lower PRF. A sparsity condition of the received SAR data ensures that the uniformly resampled data approximate the spectral properties of a decimated densely sampled version of the received SAR data. While experiments conducted with both synthetically generated and real airborne SAR data show that POLYPHASE retains comparable performance with the state-of-the-art best linear unbiased interpolation scheme in image quality, a polyphase filter-based implementation of POLYPHASE offers significant computational savings for arbitrary (not necessarily periodic) input PRF variations, thus allowing fully on-board, in-place, and real-time implementation.	airborne ranger;aperture (software);approximation algorithm;decimation (signal processing);experiment;image quality;in-place algorithm;interpolation;on-board data handling;polyphase matrix;primitive recursive function;real-time transcription;requirement;sparse matrix;synthetic intelligence	Yoangel Torres;Kamal Premaratne;Falk Amelung;Shimon Wdowinski	2017	IEEE Transactions on Geoscience and Remote Sensing	10.1109/TGRS.2017.2713600	interpolation;radar imaging;mathematics;artificial intelligence;computer vision;polyphase system;inverse synthetic aperture radar;remote sensing;image quality;side looking airborne radar;synthetic aperture radar;pulse (signal processing)	Visualization	74.11715741622392	-66.77082454430607	53467
24f4b423e789713ab9909f83bb0da3ef97ea46fe	a novel building detection method using zy-3 multi-angle imagery over urban areas		This paper presents a new building indicator based on the multi-angle images, the angular difference feature (ADF), which characterizes angular properties from high-resolution ZY-3 multi-view images. The method for detecting buildings based on ADF consists of two main steps: ADF feature extraction and a post-processing step to refine the results by simultaneously incorporating the spectral and geometrical information. Experiments are conducted with three ZY-3 images acquired over Chinese cities. The proposed ADF achieves promising building detection performance over both highly dense urban areas and suburban areas, with an overall accuracy of better than 89% for all the three data sets.	angularjs;experiment;feature extraction;image resolution;sensor;video post-processing	Huijun Chen;Xin Huang;Jiayi Li;Jianya Gong;Chun Liu	2018	IGARSS 2018 - 2018 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2018.8518232	remote sensing;computer vision;feature extraction;artificial intelligence;data set;computer science	Vision	76.05769887587797	-59.150962544515124	53634
d1fae399ab8d8c48b261eda1e48e81692e7966de	earthen levee monitoring with synthetic aperture radar	earthen levees synthetic aperture radar levee screening;feature detection;classification algorithm;levee;rivers;neural nets;maximum likelihood;earthen levees;backscatter;image classification;geotechnical engineering;maximum likelihood estimation;image texture;wavelet transforms;radiometry;wavelet transforms airborne radar backscatter feature extraction floods geotechnical engineering image classification image texture maximum likelihood estimation neural nets radar imaging radar polarimetry radiometry spaceborne radar structural engineering computing synthetic aperture radar;structural engineering computing;radar polarimetry;feature extraction;remote sensing;radar imaging;mississippi river;flooding earthen levee monitoring multipolarized synthetic aperture radar earthen levee weak point screening l band airborne spaceborne radar x band spaceborne radar nasa uavsar platform german terrasar x platform feature detection classification algorithm radiometric method textural method radiometric features backscatter magnitude hh channel vv channel hv channel entropy anisotropy alpha angle grey level cooccurrence matrix wavelet feature maximum likelihood classifier artificial neural network lower mississippi river;levee screening;airborne radar;levee spaceborne radar rivers soil floods remote sensing;floods;soil;grey level co occurrence matrix;artificial neural network;spaceborne radar;synthetic aperture radar	The latest results are presented from an ongoing study of the use of multi-polarized Synthetic Aperture Radar as an aid in screening earthen levees for weak points. Both L-band airborne and X-band spaceborne radars are studied, using the NASA UAVSAR and the German TerraSAR-X platforms. Feature detection and classification algorithms tested for this application include both radiometric and textural methods. Radiometric features include both the simple backscatter magnitudes of the HH, VV, and HV channels as well as decompositions such as Entropy, Anisotropy, and Alpha angle. Textural methods include grey-level co-occurrence matrix and wavelet features. Classifiers tested include Maximum Likelihood and Artificial Neural Networks. The study area includes 240 km of levees along the lower Mississippi River. Results to date are encouraging but still very preliminary and in need of further validation and testing.	airborne ranger;algorithm;aperture (software);artificial neural network;co-occurrence matrix;document-term matrix;feature detection (computer vision);l band;levee breach;metric;radar;synthetic intelligence;verification and validation;wavelet	James Aanstoos;Khaled Hasan;Charles G. O'Hara;Saurabh Prasad;Lalitha Dabbiru;Majid Mahrooghy;Balakrishna Gokaraju;Rodrigo Nóbrega	2011	2011 IEEE Applied Imagery Pattern Recognition Workshop (AIPR)	10.1109/AIPR.2011.6176370	geography;hydrology;geotechnical engineering;remote sensing	Vision	78.24374751223807	-60.837262721238645	53647
04c78cdc5bfd570a062724c6548185aec12ab639	observing seasonal snow changes in the boreal forest area using active and passive microwave measurements	snow geophysical techniques microwave measurement;brightness temperature;microwave measurements;instruments;microwave observations;passive microwave;emission model;snow;snow cover;brightness temperature measurement;backscatter;backscatter temperature measurement;active measurement;snow cover property;snow cover property seasonal snow changes boreal forest area active microwave measurement passive microwave measurement full snow season dataset brightness temperature measurement backscatter temperature measurement microwave observations passive microwave instrument microwave observation;microwave radiometry;full snow season dataset;microwave observation;boreal forest area;seasonal snow changes;passive microwave snow emission model;seasonality;microwave measurement;boreal forest;active microwave measurement;passive microwave instrument;temperature measurement;snow temperature measurement microwave radiometry microwave measurements instruments microwave theory and techniques backscatter;passive microwave measurement;microwave theory and techniques;geophysical techniques	We present initial results from an experimental campaign aiming to acquire a comprehensive, full-snow season dataset of simultaneous backscatter and brightness temperature measurements of snow covered ground. The campaign is a part of Phase A activities in support of the proposed CoReH2O mission, aiming both to contribute to investigations on interpreting snow properties from active microwave observations, and to explore the possibilities for synergistic use of active measurements with existing passive microwave instruments. The campaign period covers the winter season of 2009-2010. Microwave observations are complemented by detailed in situ data of snow cover properties.	backscatter (email);microwave;synergy	Jouni Pulliainen;Juha Lemmetyinen;Anna Kontu;Ali Nadir Arslan;Andreas Wiesmann;Thomas Nagler;Helmut Rott;Malcolm Davidson;Dirk Schuettemeyer;Michael Kern	2010	2010 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2010.5653105	meteorology;snow;taiga;atmospheric sciences;temperature measurement;brightness temperature;backscatter;physics;quantum mechanics;seasonality;remote sensing	Embedded	82.14885024394589	-61.93459513169674	53734
bf435a1e9f5b9908245b8bf34a58b8352fe5a5b1	radarsat-2 and coastal applications: surface wind, waterline, and intertidal flat roughness	c band;wind geophysical techniques radar polarimetry remote sensing by radar synthetic aperture radar tides;polarimetrie;coastal waves;onde decimetrique;l band sar systems radarsat 2 intertidal flat roughness all weather earth observation satellite synthetic aperture radars c band imaging radars earth ecosystem monitoring maritime surveillance coastal zone problems coastal surface wind waterline mapping polarimetric sar data inversion coastal waves coastal currents wind speed estimation p band sar systems;observation par satellite;polarimetry;polarimetria;illumination;zona costera;observacion por satelite;l band sar systems;rugosidad;radar abertura sintetica;banda l;polarimetric sar;banda c;on board equipment;bande c;tidal flat;onde centimetrique;coastal zones;partial information;carta de datos;vitesse vent;bande l;polarimetric sar data inversion;remote sensing by radar;centimetric wave;c band imaging radars;tides;satellite observation;coastal zone;waterline mapping;monitoring;onda decimetrica;synthetic aperture radar sar;roughness;sea measurements rough surfaces surface roughness wind sea surface surface topography radar imaging radar polarimetry frequency artificial satellites;radar polarimetry;mappage;wind speed;field measurement;radar imaging;wind velocity;onda centimetrica;imaging;radarsat 2;coastal currents;waterline coastal zones intertidal flats polarimetric sar radarsat 2 sar surface wind synthetic aperture radar sar;coastal surface wind;rugosite;formation image;wind speed estimation;uhf wave;earth observation;mapping;imagerie radar;zone cotiere;formacion imagen;monitorage;intertidal flats;velocidad viento;earth ecosystem monitoring;equipo embarcado;monitoreo;coastal area;appareillage embarque;p band sar systems;nasa;eclairement;wind;data acquisition;radar ouverture synthetique;calibration;waterline;all weather earth observation satellite;maritime surveillance;synthetic aperture radars;geophysical techniques;coastal zone problems;sea measurements;alumbrado	RADARSAT-2 is a follow-up to RADARSAT-1 and is an all weather Earth observation satellite with fully polarimetric imaging capability. The synthetic aperture radars (SARs) onboard both RADARSATs are C-band imaging radars and they are well suited for Earth's ecosystem monitoring and maritime surveillance, because of the near polar orbit and their unique all weather imaging capability, independent of solar illumination. In this paper, RADARSAT-2 is first introduced and several applications of various modes of SAR data to coastal zone problems are discussed, including the coastal surface wind, waterline mapping, and polarimetric SAR data inversion for topographic and geological parameters of tidal flats. Coastal zones, the important interface between the land and the ocean, where a large proportion of the world's population inhabits, continuously change and evolve. The dynamic interaction of coastal winds, coupled with the coastal waves and currents, continuously erode rocks and land mass, and move and deposit various sediments on a continuous basis, along with the tides. Estimation of wind speeds and directions in coastal areas are empirically formulated and can further be improved with the available fully polarimetric data from RADARSAT-2. The water line mapping critically depends on the SAR frequency, or the wavelength of the SAR data used, and RADARSAT-2 SAR data using C-band should map waterlines more accurately than the longer wavelength L- or P-band SAR systems. The roughness parameters and partial information on the tidal flat compositions can be obtained from fully polarimetric SAR data. Some results obtained from NASA AIRSAR(2000) L-band data and RADARSAT-2(2008) C-band data do not fully agree with field measurements and further investigation is in progress. The inversion of polarimetric SAR data is a very complex problem and critically depends on the SAR signal frequency and model functions. RADARSAT-2 is an imaging radar, which is very flexible and powerful tool for potential coastal zone applications. Key RADARSAT-2 features and potential coastal zone application capabilities are also briefly reviewed.	ecosystem;l band;pet rock;polarimetry;radar;synthetic intelligence;topography	Wooil M. Moon;Gordon Staples;Duk-jin Kim;Sang-Eun Park;Kyung-Ae Park	2010	Proceedings of the IEEE	10.1109/JPROC.2010.2043331	wind speed;meteorology;medical imaging;geodesy;physics;remote sensing	Visualization	79.33123665026174	-63.387273529890486	53820
50d1a7d65b6c318fc2b1d4ac2e5bc5bd375aa3f9	advancing precipitation estimation and streamflow simulations in complex terrain with x-band dual-polarization radar observations			computer simulation;probability of precipitation	Marios N. Anagnostou;Efthymios I. Nikolopoulos;John Kalogiros;Emmanouil N. Anagnostou;Francesco Marra;Elisabeth Mair;Giacomo Bertoldi;Ulrike Tappeiner;Marco Borga	2018	Remote Sensing	10.3390/rs10081258	geology;remote sensing;weather radar;terrain;streamflow;precipitation;x band	Robotics	80.54317011578514	-60.85539086326419	53826
1f24e26767cd9a23e60f82def5fd1b7493047fdb	scene-aware video modeling and compression	quantization;occlusion detection;baseline compression performance;image coding;image segmentation;image formation;data compression;scene aware video modeling;video compression;data format;motion segmentation optical imaging image segmentation tracking redundancy image coding quantization;image texture;data formation process;video coding;motion segmentation;video representation video compression video modeling scene modeling;optical imaging;redundancy;texture structure partition;computational cost scene aware video modeling scene aware video compression data formation process image formation optical flow computation occlusion detection texture structure partition baseline compression performance;video representation;video modeling;computational cost;optical flow;scene aware video compression;scene modeling;optical flow computation;video coding data compression image texture object detection;tracking;object detection	"""We describe a video compression methodology that exploits the structure of the data formation process, whereby the """"source'' is the scene, and the ``channel'' includes scaling and occlusion phenomena that are critical elements of image formation. Thus our scheme involves occlusion detection, optical flow computation, texture/structure partition, and a notion of proper sampling. We show preliminary but promising results that exceed baseline compression performance, albeit at an increased computational cost."""	algorithmic efficiency;baseline (configuration management);compression artifact;computation;data compression;image formation;image scaling;optical flow;sampling (signal processing)	Georgios Georgiadis;Stefano Soatto	2012	2012 Data Compression Conference	10.1109/DCC.2012.23	data compression;computer vision;computer science;multimedia;computer graphics (images)	Vision	55.54853882265707	-56.65089383886506	53837
81eee275a12e31b3d924e49c5f24502aca3533c1	on denoising and compression of dna microarray images	microarray data;translation invariant;gene cluster;lossless compression;dna microarrays;context model;wavelet transform;image context modeling;image compression;mixture model;microarray image compression;cell cycle;microarray gene clustering;image denoising;dna microarray;microarray image denoising;image modeling;structural properties	We address the problems of noise and huge data sizes in microarray images. First, we propose a mixture model for describing the statistical and structural properties of microarray images. Then, based on the microarray image model, we present methods for denoising and for compressing microarray images. The denoising method is based on a variant of the translation-invariant wavelet transform. The compression method introduces the notion of approximate contexts (rather than traditional exact contexts) in modeling the symbol probabilities in a microarray image. This inexact context modeling approach is important in dealing with the noisy nature of microarray images. Using the proposed denoising and compression methods, we describe a near-lossless compression scheme suitable for microarray images. Results on both denoising and compression are included, which show the performance of the proposed methods. Further experiments using the results of the proposed near-lossless compression scheme in gene clustering using cell-cycle microarray data for S. cerevisiae showed a general improvement in the clustering performance, when compared with using the original data. This provides an indirect validation of the effectiveness of the proposed denoising method. 2006 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.	16-bit;approximation algorithm;cluster analysis;color depth;dna microarray;data compression;experiment;ibm notes;lossless compression;mixture model;noise reduction;pattern recognition;pixel;stationary wavelet transform	Donald A. Adjeroh;Yong Zhang;Rahul Parthe	2006	Pattern Recognition	10.1016/j.patcog.2006.02.019	dna microarray;computer science;bioinformatics;pattern recognition;data mining;mathematics	Vision	57.51156886511748	-68.48196076463793	53850
a61f2a2549a13a67aa98be18685b1d9b90d93a1d	detection of specularity using stereo in color and polarization space	cues specularity detection stereo images color histogram differencing polarization multiple views computer vision specular reflections;multiple views;computer vision;specular reflection;optical reflection optical polarization histograms image segmentation sensor fusion reflectivity machine vision dielectrics photometry light sources;direct method	We propose a specularity detection method based on a synergistic integration of color and polarization information from multiple views. The presence of specularity in images can cause many traditional computer vision processes to produce misleading results. Recent physics-based direction methods have provided much success in locating specularity; however no single cue reveals the full structure of specular reflections. Our method merges multiple-view color and polarization, two physically independent but highly effective cues, in a way that they mutually benefit from each other's strengths. In a fused color and polarization space, the proposed algorithm compares the distributions of sensor data from multiple views for detection of specular. We show that the efficacy of this new cue extends beyond that of the sum of its parts, and confirming experimental results are presented.	polarization (waves);specularity	Stephen Lin;Sang Wook Lee	1996		10.1109/ICPR.1996.546031	direct method;computer vision;specular reflection;computer science	Vision	59.265849226432756	-52.32085446531535	53951
dc8817d4580e61424e0fdf4b5bd37e2aee62ccb4	a regularization approach to joint blur identification and image restoration	minimisation;focusing;recursive estimation;space adaptive regularization method;image restoration autoregressive processes cost function minimization methods cameras recursive estimation maximum likelihood estimation gradient methods focusing measurement errors;algorithmic efficiency;image numerique;restauration image;image processing;methode plus grande pente;cost function;minimisation image restoration conjugate gradient methods adaptive signal processing;piecewise smooth;fonction etalement point;regularization method;simulacion numerica;steepest descent method;regularization approach;procesamiento imagen;blind image restoration;image restoration;minimization methods;conjugate gradient method;maximum likelihood estimation;funcion coste;traitement image;restoration error measure;restauracion imagen;photographically blurred images;minimizacion costo;a priori knowledge;adaptive signal processing;minimisation cout;blur identification;blur operator;cost minimization;autoregressive processes;imagen borrosa;scale problem;metodo gradiente conjugado;point spread function;blurred image;metodo mas grande inclinacion;simulation numerique;blur operator blur identification regularization approach blind image restoration point spread function space adaptive regularization method piecewise smoothness cost function restoration error measure hard constraints scale problem alternating minimization algorithmic efficiency steepest descent method conjugate gradient methods photographically blurred images numerically blurred images;imagen numerica;numerically blurred images;hard constraints;gradient methods;funcion distribucion punto;alternating minimization;fonction cout;digital image;image floue;methode gradient conjugue;conjugate gradient methods;piecewise smoothness;cameras;measurement errors;steepest descent;numerical simulation	The primary difficulty with blind image restoration, or joint blur identification and image restoration, is insufficient information. This calls for proper incorporation of a priori knowledge about the image and the point-spread function (PSF). A well-known space-adaptive regularization method for image restoration is extended to address this problem. This new method effectively utilizes, among others, the piecewise smoothness of both the image and the PSF. It attempts to minimize a cost function consisting of a restoration error measure and two regularization terms (one for the image and the other for the blur) subject to other hard constraints. A scale problem inherent to the cost function is identified, which, if not properly treated, may hinder the minimization/blind restoration process. Alternating minimization is proposed to solve this problem so that algorithmic efficiency as well as simplicity is significantly increased. Two implementations of alternating minimization based on steepest descent and conjugate gradient methods are presented. Good performance is observed with numerically and photographically blurred images, even though no stringent assumptions about the structure of the underlying blur operator is made.		Yu-Li You;Mostafa Kaveh	1996	IEEE transactions on image processing : a publication of the IEEE Signal Processing Society	10.1109/83.491316	gradient descent;adaptive filter;image restoration;computer vision;minimisation;mathematical optimization;a priori and a posteriori;image processing;computer science;method of steepest descent;point spread function;mathematics;geometry;conjugate gradient method;maximum likelihood;algorithmic efficiency;digital image;statistics;observational error	Vision	55.35362693550784	-72.958982962883	54083
37fc38a7f54468efb3b5776cbce4a3c486db4946	effect of raster resolution and polygon-conversion algorithm on landslide susceptibility mapping	vector to raster conversion;grid cell size;landslide susceptibility mapping;resampling;artificial neural network	The choice of the proper resolution in landslide susceptibility mapping is a worth considering issue. If, on the one hand, a coarse spatial resolution may describe the terrain morphologic properties with low accuracy, on the other hand, at very fine resolutions, some of the DEM-derived morphometric factors may hold an excess of details. Moreover, the landslide inventory maps are represented throughout geospatial vector data structure, therefore a conversion procedure vector-to-raster is required.#R##N##R##N#This work investigates the effects of raster resolution on the susceptibility mapping in conjunction with the use of different algorithms of vector-raster conversion. The Artificial Neural Network technique is used to carry out such analyses on two Sicilian basins. Seven resolutions and three conversion algorithms are investigated. Results indicate that the finest resolutions do not lead to the highest model performances, whereas the algorithm of conversion data may significantly affect the ANN training procedure at coarse resolutions.	algorithm	Elisa Arnone;Antonio Francipane;Antonino Scarbaci;Claudio Puglisi;Leonardo V. Noto	2016	Environmental Modelling and Software	10.1016/j.envsoft.2016.07.016	computer vision;resampling;computer science;machine learning;mathematics;artificial neural network	SE	80.04814969653344	-56.47395511251419	54116
6ee697485600a0a47e9595e1f274d500e091203d	clutter removal techniques for gpr images in structure inspection tasks	independent component analysis;inspection;principal component analysis;algorithms;water;radar	This document analyses the performance of subspace signal processing techniques applied to ground penetrating radar (GPR) images in order to reduce the amount of clutter and noise in the measured GPR image. Two methods considered in this work are Principal Component Analysis (PCA) and Independent Component Analysis (ICA). An approach to combine those two techniques to improve their effectiveness when applied to GPR data is proposed in this paper. The experiments performed to gather GPR data and evaluate proposed algorithms are also described. The aim of undertaken experiments is to replicate conditions found in water reservoirs where cracks and holes in the reservoir foundations and joints cause excessive water leakages and losses to water companies and the UK economy in general. Performance of implemented algorithms is discussed and compared to the results achieved by a highly skilled human - GPR image analyst.© (2012) COPYRIGHT Society of Photo-Optical Instrumentation Engineers (SPIE). Downloading of the abstract is permitted for personal use only.	clutter;kriging	Branislav Vuksanovic;Nurul Jihan Farhah Bostanudin	2012		10.1117/12.946100	computer vision;simulation;engineering;remote sensing	Vision	77.3028176033067	-60.653103010652636	54140
54bf326ab81458a5c64e3087d07dc57320014b2c	video retargeting based on stretchability-aware blocks scaling	video retargeting;image motion analysis;non stretchable block;image segmentation;static stretchability;dynamic stretchability;size measurement;computer vision;stretchable block;optical imaging;vectors;video signal processing feature extraction image colour analysis;image color analysis;stretched video size video retargeting stretchability aware blocks scaling gradient feature saliency feature color feature frame image dynamic stretchability measure analysis nonstretchable blocks stretchable blocks scaling factors;block scaling video retargeting static stretchability dynamic stretchability stretchable block non stretchable block;vectors image color analysis optical imaging image segmentation image motion analysis computer vision size measurement;block scaling	This paper proposes an efficient approach to retarget video based on stretch ability-aware block scaling. The static stretch ability of the frame image is first evaluated based on gradient, saliency and color features. Then the dynamic stretch ability of the frame image is determined through the mapping of blocks under the constraint of optical flow vectors. Based on the analysis of frame image dynamic stretch ability measures, the original frame image is partitioned into non-stretchable blocks and stretchable blocks, and their scaling factors are calculated based on their stretch ability measures and the stretched video size, in order to possibly preserve non-stretchable blocks and reasonably resize stretchable blocks. Finally, the stretched video is uniformly scaled to generate the target video. Experimental results on a variety of videos demonstrate that our approach achieves a reasonable retargeting performance compared to the state-of-the-art video retargeting approaches.	2.5d;color;gradient;image scaling;optical flow;retargeting	Huan Du;Zhi Liu;Zhiguo Yan;Yayun Jiang	2014	2014 10th International Conference on Semantics, Knowledge and Grids	10.1109/SKG.2014.9	computer vision;computer science;optical imaging;image segmentation;computer graphics (images)	Robotics	56.862402090297536	-61.50886319055652	54199
7204441181b74ece91f442291c74fc76e7542402	precision sar processing using chirp scaling	energy resolution;tratamiento datos;teledetection;interpolation;geophysics computing remote sensing remote sensing by radar synthetic aperture radar geophysical techniques;algorithm performance;chirp;fourier transform;chirp interpolation image quality signal processing energy resolution signal resolution synthetic aperture radar frequency domain analysis fourier transforms system testing;migration;radar antenne synthetique;frequency domain analysis;deutsches fernerkundungsdatenzentrum;interpolacion;simulacion numerica;data processing;traitement donnee;qualite image;geophysical measurement technique;wide swath;algorithme;algorithm;remote sensing by radar;geophysics computing;resultado algoritmo;sar image processing;cell migration;signal processing;image quality land surface remote sensing geophysical measurement technique radar imaging sar image processing chirp scaling chirp scaling algorithm range resolution cells migration synthetic aperture radar range cell migration correction;remote sensing;image quality;radar imaging;fourier transforms;simulation numerique;teledeteccion;analyse domaine frequence;performance algorithme;mathematical model;signal resolution;system testing;image analysis;range resolution cells;calidad imagen;chirp scaling algorithm;frequency domain;land surface remote sensing;chirp scaling;range cell migration correction;geophysical techniques;numerical simulation;algoritmo;synthetic aperture radar	Abstmct-A space-variant interpolation is required to compensate for the migration of signal energy through range resolution cells when processing synthetic aperture radar (SAR) data, using either the classical rangelDoppler (RID) algorithm or related frequency domain techniques. In general, interpolation requires significant computation time, and leads to loss of image quality, especially in the complex image. The new chirp scaling algorithm avoids interpolation, yet performs range cell migration correction accurately. The algorithm requires only complex multiplies and Fourier transforms to implement, is inherently phase preserving, and is suitable for wide-swath, largebeamwidth, and large-squint applications. This paper describes the chirp scaling algorithm, summarizes simulation results, presents imagery processed with the algorithm, and reviews quantitative measures of its performance. Based on quantitative comparison, the chirp scaling algorithm provides image quality equal to or better than the precision rangel Doppler processor. Over the range of parameters tested, image quality results approach the theoretical limit, as defined by the system bandwidth.	algorithm;cell (microprocessor);chirp;computation;image quality;image scaling;interpolation;simulation;synthetic data;time complexity	R. Keith Raney;Hartmut Runge;Richard Bamler;Ian G. Cumming;Frank H. Wong	1994	IEEE Trans. Geoscience and Remote Sensing	10.1109/36.298008	fourier transform;computer vision;image analysis;data processing;interpolation;signal processing;mathematics;frequency domain;remote sensing	Graphics	76.55931235905373	-67.83191202250818	54215
7c603500dc08faa90ff4fba3616b49f956d76f8a	snow particle automatic classification with texture operators	geophysical image processing;histograms;support vector machines atmospheric techniques geophysical image processing image texture meteorological radar neural nets rain snow;z r relation;image processing;support vector machines;neural nets;snow;meteorological radar;local binary pattern;indexing terms;classification;texture operators;image texture;imaging system;first order;shape;data structures;rain;volume measurement;atmospheric techniques;support vector machine;natural phenomena;automatic classification;image processing snow particle texture operators classification z r relation;data structure;snow particle automatic classification backscattered data meteorological radar snowfall rate calculation z r relation rainfall rate calculation snowflake types automatic snow particle classification imaging system svm technique knn technique texture operator techniques first order features cooccurence matrices run length codes grey tone difference matrix local binary patterns snow particle database image processing;snow particle;radar;snow support vector machines data structures histograms radar shape volume measurement	The backscattered data recorded by the meteorological radar is exploited for rainfall/snowfall rate calculation according to the Z-R relation. This relation is governed by parameters, which are influenced by the size and shape of the falling particles. The variety of snowflake types as well as the in class shape and size differences make this problem very difficult.	statistical classification;subatomic particle	Karolina Nurzynska;Mamoru Kubo;Ken-ichiro Muramoto	2011	2011 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2011.6049819	meteorology;support vector machine;computer vision;data structure;computer science;machine learning;remote sensing	Embedded	72.76079551866282	-59.72206361517568	54294
c0d2cd207f6532b165b4edefbd0c61908beceda7	image enhancement using calibrated lens simulations	measured data;nominal lens model;tolerances lens;lens model;simulated psf;image sharpness;additional measurement;psf measurement;lens point spread function;lens parameter;image enhancement;lens simulation	All lenses have optical aberrations which reduce image sharpness. These aberrations can be reduced by deconvolving an image using the lens point spread function (PSF). However, fully measuring a PSF is laborious and prohibitive. Alternatively, one can simulate the PSF if the lens model is known. However, due to manufacturing tolerances lenses differ subtly from their models, so often a simulated PSF is a poor match to measured data. We present an algorithm that uses a PSF measurement at a single depth to calibrate the nominal lens model to the measured PSF. The fitted model can then be used to compute the PSF for any desired setting of lens parameters for any scene depth, without additional measurements or calibration. The fitted model gives deconvolution results comparable to measurement but is much more compact and require hundreds of times fewer calibration images.	algorithm;computer simulation;deconvolution;image editing	Yichang Shih;Brian Guenter;Neel Joshi	2012		10.1007/978-3-642-33765-9_4	computer vision	Vision	61.13875765000116	-54.16796876490748	54367
90a817bc481a0f1717640ae009ca31d66cdb9322	optimised image autofocusing for polarimetric isar	signal to noise ratio focusing abstracts bandwidth;synthetic aperture radar focusing radar imaging radar polarimetry;polarisation information optimised image autofocusing polarimetric isar inverse synthetic aperture radar multichannel lsar image formation image autofocusing optimisation technique	The use of full polarisation enables multi-channel SAR processing for enhancing both imaging and classification capabilities. In the field of Inverse Synthetic Aperture Radar (ISAR) very little has been investigated, especially from the point of view of multi-channel ISAR image formation. In this paper, the authors want to define an optimised image autofocusing technique that exploits full polarisation information. Theory and simulation results will be provided in the paper.	aperture (software);goto;image formation;mac os x 10.4 tiger;polarimetry;signal-to-noise ratio;simulation;synthetic intelligence;xfig	Marco Martorella;Leonardo Cantini;Fabrizio Berizzi;Brett Haywood;Enzo Dalle Mese	2006	2006 14th European Signal Processing Conference		computer vision;geography;optics;radar imaging;inverse synthetic aperture radar;side looking airborne radar;remote sensing	Robotics	75.42434919324567	-65.75109101260645	54455
58c6339f058dc477c6177954d0c6b84f05928d01	a comparative analysis of a fixed thresholding vs. a classification tree approach for operational burn scar detection and mapping	landsat;fixed thresholding;maps;programa;europa;europa sur;spot xs;landsat 5 tm;decision tree classification;planeta tierra;comparative analysis;classification tree;decision tree;grece;mapa;accentuation image;resolution spatiale;frame structure;proyecto;incendie;europe sud;bâti;earth;europa del oeste;efficiency;performance;grecia;spot;wildfires;detection;france;classification;satelite;carte;costo;forest fires;accuracy;trees;image enhancement;risk eos;precision;eos;greece;echantillon reference;satellite;seasonality;remote sensing;satellites;francia;western europe;cost efficiency;programme;efficacite;arbre;satellite image;burn scar mapping;earth observation;satellite imagery;landsat 5;mapping;planete terre;monde;performances;mundo;europe;southern europe;projet;methodology;earth observing system;fires;projects;wildfire;cost;programs;clasificacion;standard samples;roca patron;global;europe ouest;cout;global monitoring for environment and security;spatial resolution	The scope of this paper is to demonstrate, evaluate and compare two burn scar mapping (BSM) approaches developed and applied operationally in the framework of the RISK-EOS service element project within the Global Monitoring for Environment and Security (GMES) program funded by ESA (http://www.risk-eos.com). The first method is the BSM_NOA, a fixed thresholding method using a set of specifically designed and combined image enhancements, whilst the second one is the BSM_ITF, a decision tree classification approach based on a wide range of biophysical parameters. The two methods were deployed and compared in the framework of operational mapping conditions set by RISK-EOS standards, based either on sets of unior multi-temporal satellite images acquired by Landsat 5 TM and SPOT 4 HRV. The evaluation of the performance of the two methods showed that either in unior multitemporal acquisition mode, the two methods reach high detection capability rates ranging from 80% to 91%. At the same time, the minimum burnt area detected was of 0.9–1.0 ha, despite the coarser spatial resolution of Landsat 5 TM sensor. Among the advantages of the satellite-based approaches compared to conventional burn scar mapping, are cost-efficiency, repeatability, flexibility, and high spatial and thematic accuracy from local to country level. Following the catastrophic fire season of 2007, burn scar maps were generated using BSM_NOA for the entirety of Greece and BSM_ITF for south France in the framework of the RISK-EOS/GMES Services Element project. 2009 Elsevier B.V. All rights reserved.	decision tree learning;eos;esa;heart rate variability;map;openbsm;qualitative comparative analysis;repeatability;thresholding (image processing);while	Charalambos Kontoes;Hervé Poilvé;Géraldine Florsch;Iphigenia Keramitsoglou;S. Paralikidis	2009	Int. J. Applied Earth Observation and Geoinformation	10.1016/j.jag.2009.04.001	astronomy;geography;physics;satellite;cartography;statistics;remote sensing	Robotics	79.80631761745649	-56.79537243254617	54466
12e525ef511bde86144a7de14ce8a8cc91d383bc	subjective quality of spatially asymmetric omnidirectional stereoscopic video for streaming adaptation		Asymmetric video coding is a well-studied area for bit rate reduction in stereoscopic video coding. Such video coding technique is possible because of the binocular fusion theory which states that the Human Visual System (HVS) is capable of fusing views from both the eyes. As a result, past literature has shown that the final perceived quality of different left and right quality images is closer the highest quality of the two views. In this paper, we investigate spatially asymmetric omnidirectional video in subjective experiments using a Head Mounted Display (HMD). We want to subjectively verify to what extent the binocular fusion theory applies in immersive media environments, and also assess to what degree reducing the omnidirectional video streaming bandwidth is feasible. We prove that (1) the HVS is capable of partial suppression of the low-quality view up to a certain resolution; (2) there is a bandwidth saving of 25% when 75% of the spatial resolution is used for one of the views, while ensuring a subjective visual quality with a DMOS of 4.7 points; (3) in case of bandwidth adaptation using asymmetric video, bit rate savings are in the range 25–50%.		Igor D. D. Curcio;Deepa Naik;Henri Toukomaa;Alireza Zare	2018		10.1007/978-3-030-04375-9_36	coding (social sciences);systems engineering;computer science;computer vision;stereoscopy;stereoscopic video coding;omnidirectional antenna;optical head-mounted display;bit rate reduction;human visual system model;bandwidth (signal processing);artificial intelligence	Vision	64.13981288535965	-63.08602498111991	54498
e79e5995eceeb45483d5c76234401fffe2f7003e	an adaptive-pca algorithm for reflectance estimation from color images	goodness of fit;estimation theory;adaptivity criterion;reconstruction process;principal component analysis estimation theory image colour analysis image reconstruction inverse problems;reflectivity;likelihood measurement;goodness of fit coefficient adaptive pca algorithm color images spectral reflectance estimation color camera outputs inverse problem reconstruction process pca adaptive adaptivity criterion likelihood measurement;reflectivity color cameras principal component analysis layout equations image reconstruction pixel optical surface waves optical filters;inverse problem;estimation;color images;image color analysis;image colour analysis;image reconstruction;principal component analysis;spectral reflectance;adaptive pca algorithm;mathematical model;color camera outputs;pca adaptive;goodness of fit coefficient;cameras;color image;spectral reflectance estimation;inverse problems	This paper deals with the problem of spectral reflectance estimation from color camera outputs. Because the reconstruction of such functions is an inverse problem, stabilizing the reconstruction process is highly desirable. One way to do this is to decompose reflectance function on a basis functions like PCA. The present work proposes an algorithm making PCA adaptive in reflectance estimation from a color camera output. We propose to adapt the PCA basis derivation by selecting, for each sample, the more relevant elements from the training set elements. The adaptivity criterion is achieved by a likelihood measurement. Finally, the spectral reflectance estimation results are evaluated with the commonly used goodness-of-fit coefficient (GFC) and ¿E color difference, and prove the reliability of the proposed methods.	algorithm;basis function;coefficient;key derivation function;principal component analysis;test set;triangular function;visual comparison	Alamin Mansouri;Tadeusz Sliwa;Jon Y. Hardeberg;Yvon Voisin	2008	2008 19th International Conference on Pattern Recognition	10.1109/ICPR.2008.4761120	computer vision;inverse problem;pattern recognition;mathematics;reflectivity;statistics	Vision	59.370414185781854	-70.9923867943478	54654
80b95aa6b19ddea25026519f7a3093ef13bb652f	bias correction for polarimetric phased-array radar with idealized aperture and patch antenna elements	scattering atmospheric measurements phased array radar par polarimetry remote sensing;correction matrix application polarimetric phased array radar patch antenna element idealized aperture element polarimetric parameters bias correction matrix beam direction array elements waveguide apertures waveguide patches correction matrices alternate transmission mode simultaneous reception mode simultaneous transmission mode;remote sensing by radar;radar polarimetry;remote sensing by radar microstrip antenna arrays radar polarimetry;apertures meteorology meteorological radar radar polarimetry arrays scattering;microstrip antenna arrays	Polarimetric phased-array radar (PPAR) creates biases in observed polarimetric parameters when the beam is pointed off broadside. Thus, a bias correction matrix needs to be applied for each beam direction. A bias correction matrix is developed for array elements consisting of either waveguide apertures or patches. Correction matrices are given for both the Alternate Transmission and Simultaneous Reception mode and the Simultaneous Transmission and Simultaneous Reception mode. The biases of polarimetric parameters measured with a PPAR without the application of a correction matrix are presented.	patch (computing);phased array;polarimetry	Lei Lei;Guifu Zhang;Richard Doviak	2013	IEEE Transactions on Geoscience and Remote Sensing	10.1109/TGRS.2012.2198070	phased array;continuous-wave radar;radar engineering details;bistatic radar;optics;radar imaging;side looking airborne radar;radar;remote sensing	Robotics	78.13152570894297	-66.81744976298423	54668
c236ae57eca7b57b0f7b25f24a688b962cb78e82	edge-based and efficient chromaticity spatio-spectral models for color constancy	chromaticity color constancy spatio spectral model edge detection;visual databases edge detection image colour analysis lighting transforms;color constancy;edge detection;image color analysis image edge detection computational modeling estimation databases reflectivity accuracy;chromaticity;image colour analysis;spatio spectral model;transforms;lighting;illuminant edge based color constancy method efficient chromaticity spatio spectral models real time computational color constancy applications transformation estimation execution time execution storage synthetic color image database color checker database human visual system edge detection;visual databases	Fast and accurate estimation of the transformation imposed by the illuminant to the colors of an image taken under that illuminant is of crucial importance in real-time computational color constancy applications. To this end, we present an edge based and an efficient chromaticity spatiospectral model which are modified versions of the spatiospectral method introduced by Chakrabarti et al [1]. As compared with the conventional color constancy methods, the spatio-spectral model improves the accuracy of estimation at the cost of increasing the execution time and storage dramatically. This increase makes the spatio-spectral model impractical and inappropriate for real-time applications. Our proposed methods aim at reducing the computational burden and required storage for the spatio-spectral modeling while retaining its accuracy of estimation. Evaluation of the performance of the proposed methods on a synthetic color image database and also the “Color Checker” database [2] are presented.	algorithm;color image;pixel;real-time clock;requirement;run time (program lifecycle phase);spectral method;synthetic data	Mehdi Rezagholizadeh;James J. Clark	2013	2013 International Conference on Computer and Robot Vision	10.1109/CRV.2013.46	color histogram;rgb color model;computer vision;edge detection;color normalization;color image;chromaticity;computer science;lighting;mathematics;color balance;color space;color constancy;computer graphics (images)	Vision	58.699597349534095	-61.64308561671055	54678
2070e59a89cc39f917a0484dbf1ca4d8684a1df7	detection of compound structures using a gaussian mixture model with spectral and spatial constraints	worldview 2 imaging gaussian mixture model spatial resolution constraint spectral resolution constraint remote sensing image images classification image detection heterogeneous compound structure detection gmm individual gaussian component model expectation maximization algorithm em algorithm constrained optimization gaussian object model spatial layout constraint region segmentation;image segmentation;compounds;layout;shape;vectors;optimization;mixture models expectation maximisation algorithm gaussian processes geophysical image processing image segmentation image sensors;spectral spatial classification constrained optimization context modeling expectation maximization em gaussian mixture model gmm object detection;compounds layout optimization shape vectors spatial resolution image segmentation;spatial resolution	Increasing spectral and spatial resolution of new-generation remotely sensed images necessitate the joint use of both types of information for detection and classification tasks. This paper describes a new approach for detecting heterogeneous compound structures such as different types of residential, agricultural, commercial, and industrial areas that are comprised of spatial arrangements of primitive objects such as buildings, roads, and trees. The proposed approach uses Gaussian mixture models (GMMs), in which the individual Gaussian components model the spectral and shape characteristics of the individual primitives and an associated layout model is used to model their spatial arrangements. We propose a novel expectation-maximization (EM) algorithm that solves the detection problem using constrained optimization. The input is an example structure of interest that is used to estimate a reference GMM and construct spectral and spatial constraints. Then, the EM algorithm fits a new GMM to the target image data so that the pixels with high likelihoods of being similar to the Gaussian object models while satisfying the spatial layout constraints are identified without any requirement for region segmentation. Experiments using WorldView-2 images show that the proposed method can detect high-level structures that cannot be modeled using traditional techniques.	automated planning and scheduling;constrained optimization;expectation–maximization algorithm;experiment;fits;google map maker;high- and low-level;mathematical optimization;mixture model;object detection;pixel;sensor;terms of service	Caglar Ari;Selim Aksoy	2014	IEEE Transactions on Geoscience and Remote Sensing	10.1109/TGRS.2014.2299540	layout;computer vision;image resolution;shape;machine learning;pattern recognition;mathematics;image segmentation	Vision	69.43975891573162	-64.57850985983521	54809
e1a47cc56b77490b534285af9223b1f454b31d03	subsurface deposits detection and shoreline feature interpretation of a vanished lop nur lake using multi-source sar data	synthetic aperture radar climatology lakes radar imaging radar polarimetry remote sensing by radar;multisource sar data tarim basin northwest china penetration capability moist saline materials synthetic aperture radar subsurface lacustrine deposit detection partially buried shorelines scattering mechanism interpretation polarimetric sar data multiple frequency sar data field investigation sample analysis vanished lop nur lake west lake ear feature optical remote sensing images closed shorelines drying up process east lop nur lake multiple sar data shrinking phases climate changes dry environment conditions wet environment conditions shoreline feature interpretation;lakes scattering synthetic aperture radar surface treatment remote sensing correlation backscatter;subsurface deposit lop nur sar polarimetric decomposition	Lop Nur, located at the east end of Tarim Basin, northwest China, is a huge vanished lake dried up before the 1970s. With the advantage of penetration capability and sensitivity to moist saline materials, synthetic aperture radar revealed the subsurface lacustrine deposits, delineated the partially buried shorelines and depicted a complete picture of Lop Nur Lake that leads to three important scientific findings in this study. Based on scattering mechanism interpretation of polarimetric and multiple frequency SAR data, field investigation and sample analysis, it is found that the total area of the vanished Lop Nur Lake is more than 10,300 km2, much larger than earlier reports. The relatively younger West Lake is superposed on the top of the lacustrine deposits of East Lake which makes the well known “Ear” feature of Lop Nur, so the west part of the shoreline is buried and not visible on optical remote sensing images. Therefore the Lop Nur Lake actually has nearly circular, closed shorelines. The drying-up process of East Lop Nur Lake went through six phases according to the shorelines interpreted from multiple SAR data. The shrinking phases of Lop Nur Lake indicate the climate changes between dry and wet environment conditions.	kaby lake;multi-source;polarimetry;salineos;synthetic data;whole earth 'lectronic link	Yun Shao;Huaze Gong;Zhihong Gao;Li Liu;Tingting Zhang;Lin Li;Longfei Wang	2014	2014 IEEE Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2014.6947512	geomorphology;geology;hydrology;remote sensing	Embedded	80.81467071808073	-61.83955203043872	54886
af729a01fc43b228ce2c26a941f6e306ce59e186	dubaisat-1: mission overview, development status and future applications	ad 2009 07;emirates institution for advanced science and technology;environment monitoring;multispectral band;optical remote sensing emirates institution for advanced science and technology eiast earth observation satellite program united arab emirates satrec initiative satellite manufacturing company south korea technology transfer program advanced satellites technology ad 2009 07 baikonur launch site dnepr rocket low earth orbit high resolution optical images panchromatic band multispectral band decision makers infrastructure development urban planning environment monitoring environment protection dubaisat 1 images geosciences remote sensing research earth observations national programs;science and technology;united arab emirates;high resolution;urban planning;image resolution;design engineering;design and development;remote sensing aerospace instrumentation geophysical equipment;job shop scheduling;dubaisat 1;satrec initiative;rockets;satellite manufacturing company;decision makers;high resolution optical images;environment protection;technology transfer program;mission operations;decision maker;panchromatic band;south korea;eiast;technology transfer;dnepr rocket;optical imaging;remote sensing;low earth orbit satellites;remote sensing research;earth observations;baikonur launch site;manufacturing;optical remote sensing dubaisat 1 earth observations national programs mission operations;dubaisat 1 images;artificial satellites;geosciences;earth observation;earth observation satellite program;optical sensors;infrastructure development;remote monitoring;geophysical equipment;low earth orbit;national programs;optical remote sensing;low earth orbit satellites remote monitoring artificial satellites manufacturing design engineering technology transfer job shop scheduling rockets image resolution optical sensors;aerospace instrumentation;advanced satellites technology	DubaiSat-1 is an initiative from Emirates Institution for Advanced Science and Technology (EIAST) to start the first Earth observation satellite program in the United Arab Emirates (UAE). The satellite was designed and developed by Satrec Initiative — a pioneer satellite manufacturing company in South Korea, with a strong participation from EIAST engineers. DubaiSat-1 is a catalyst project and part of an in-depth technology transfer program to convey advanced satellites technology to the UAE. The launch of the satellite is scheduled for July 2009 from Baikonur launch site onboard of Dnepr rocket. DubaiSat-1 will observe the Earth at a Low Earth Orbit (LEO) and generates high resolution optical images at 2.5m panchromatic (Pan) and 5m multispectral (MS) bands. These images will provide a variety of users and decision makers in the UAE with valuable tool for a wide range of applications including infrastructure development, urban planning as well as environment monitoring and protection. DubaiSat-1 images will be also used extensively to promote geosciences and remote sensing research in the region and support different scientific disciplines in private and academic sectors.	image resolution;multispectral image	Adnan Al Rais;Ali Al Suwaidi;Hosni Ghedira	2009	2009 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2009.5417697	meteorology;job shop scheduling;simulation;image resolution;urban planning;physics;remote sensing	Embedded	79.62700908634316	-61.976927518823445	54888
f25393ddf569f665ba37268065da90292d395046	a pilot study of video compression techniques for stereoscopic telepresence applications	pilot study;video compression	This paper focuses on evaluating and quantifying the effects of a novel foveated stereo video compression algorithm for visual telepresence applications. In a typical telepresence application, a user at the local site views real-time stereo video captured and transmitted from a telerobotic camera platform located at a remote site. The telerobotic camera platform tracks the user's head motion, producing the sensation of being present at the remote site. Three valuable factors were examined: foveation, disparity compression, and global motion compensation. The algorithm was analyzed by introducing the above-mentioned components separately. It was found that each component increased the compression rate significantly.	algorithm;binocular disparity;data compression;global motion compensation;real-time clock;stereoscopy;telerobotics	Stanley Fok;David W. L. Wang;Liya Ni;George H. Freeman	2009	PRESENCE: Teleoperators and Virtual Environments	10.1162/pres.18.2.139	video compression picture types;data compression;computer vision;simulation;computer science;motion compensation;computer graphics (images)	HCI	64.3828245837797	-62.92085795683959	54892
b0249b06eacc91070fe97d19c82f84c1cf6cc67a	panoramic video segmentation using color mixture models	moving object;image segmentation;data compression;video signal processing;video segmentation;fixed point;mixture model;image colour analysis;image segmentation cameras target tracking video sequences color image coding layout image reconstruction video compression bandwidth;on the fly;target tracking video signal processing image segmentation data compression image colour analysis image sequences;similarity search video segmentation color mixture models target tracking video sequences panoramic segment image compression;target tracking;similarity search;image sequences	Consider a color camera mounted at a fixed point and a target object to be tracked. We propose a method to replace the common ”blue screen” technique in performing segmentation of the object. The target object image in the video sequence is separated from the background through a segmentation process employing the color mixture model techniques. The background information is recovered through a similarity search with the panorama of the original background. The foreground segment can then be encoded by traditional compression while the scene background is represented as a panorama. Finally, the foreground object combines with the corresponding panoramic segment or any desired image on-the-fly to reconstruct the video frame. Our system can be used in low bandwidth applications as well as special demonstration in which the demonstrator can appear/disappear at any time he/she wishes.	experiment;fixed point (mathematics);mixture model;similarity search;streaming media;user-generated content	Siu-Hang Or;Kin Hong Wong;Kam-sum Lee;Tze-kin Lao	2000		10.1109/ICPR.2000.903566	video compression picture types;data compression;image texture;rgb color model;computer vision;color image;binary image;image processing;computer science;machine learning;segmentation-based object categorization;video tracking;mixture model;fixed point;multimedia;image segmentation;scale-space segmentation;statistics;multiview video coding;computer graphics (images)	Vision	58.043048413351535	-54.526148625774	55004
2ad4c904b3db090814be4cd06de769e0d8976a24	estimation of biophysical parameters from optical remote-sensing images with high-order residues	remote sensing image;neural nets remote sensing estimation theory support vector machines multilayer perceptrons;estimation theory;robust estimator;support vector machines;neural nets;parameter estimation biomedical optical imaging remote sensing support vector machines optical sensors robustness error correction multilayer perceptrons neural networks multi layer neural network;systematic error;multilayer perceptrons;multilayer perceptron;water quality;higher order;mlp neural network;remote sensing;support vector machine;residue exploitation biophysical parameter estimation optical remote sensing image high order residue robust estimation geographical area methodological issue systematic error approximated model proposed technique water quality parameter chlorophyll concentration data set regression method support vector machine svm multilayer perceptron mlp neural network;optical remote sensing;residual generation	Robust estimation of biophysical parameters in large geographical areas from remote sensing images represents an important methodological issue. A possible approach to this problem consists in modeling and correcting the systematic errors (residues) generated by an estimator trained to approximate the relationship between the remote sensing measurements and the biophysical parameter of interest. In this paper, we propose to extend this approach by capturing information from residues of higher order to refine further the approximated model. The proposed technique was applied to the problem of estimating water quality parameters with a particular focus on the estimation of the chlorophyll concentration. Two data sets and two regression methods (based on Support vector Machines (SVM) and Multilayer Perceptron (MLP) neural networks) were considered for the experimental phase. The obtained results point out that the exploitation of residues of order smaller or equal than two can improve the estimation accuracy while, above this order, overfitting problems may appear.	algorithmic efficiency;approximation algorithm;artificial neural network;computation;memory-level parallelism;multilayer perceptron;overfitting;support vector machine	Farid Melgani;Lorenzo Bruzzone	2004	IGARSS 2004. 2004 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2004.1368700	support vector machine;computer science;machine learning;pattern recognition;data mining;artificial neural network	Robotics	77.72216134054803	-58.49046234450927	55031
95becde2d0019f8f8f3be212eea4469634b9cbd7	an ontological system for interoperable spatial generalisation in biodiversity monitoring	natura 2000;nature conservation;generalisation;owl2;remote sensing;spatial reclassification	Semantic heterogeneity remains a barrier to data comparability and standardisation of results in different fields of spatial research. Because of its thematic complexity, differing acquisition methods and national nomenclatures, interoperability of biodiversity monitoring information is especially difficult. Since data collection methods and interpretation manuals broadly vary there is a need for automatised, objective methodologies for the generation of comparable data-sets. Ontology-based applications offer vast opportunities in data management and standardisation. This study examines two data-sets of protected heathlands in Germany and Belgium which are based on remote sensing image classification and semantically formalised in an OWL2 ontology. The proposed methodology uses semantic relations of the two data-sets, which are (semi-)automatically derived from remote sensing imagery, to generate objective and comparable information about the status of protected areas by utilising kernel-based spatial reclassification. This automatised method suggests a generalisation approach, which is able to generate delineation of Special Areas of Conservation (SAC) of the European biodiversity Natura 2000 network. Furthermore, it is able to transfer generalisation rules between areas surveyed with varying acquisition methods in different countries by taking into account automated inference of the underlying semantics. The generalisation results were compared with the manual delineation of terrestrial monitoring. For the different habitats in the two sites an accuracy of above 70% was detected. However, it has to be highlighted that the delineation of the ground-truth data inherits a high degree of uncertainty, which is discussed in this study. HighlightsKernel reclassification algorithm for creation of interoperable Natura 2000 habitats.Combination of spatial reclassification and ontology-based data handling.The results were compared with the manual delineation of terrestrial monitoring.For the different habitats in the two sites an accuracy of above 70% was detected.	interoperability	Simon Nieland;Niklas Moran;Birgit Kleinschmit;Michael Förster	2015	Computers & Geosciences	10.1016/j.cageo.2015.08.006	computer science;data mining;web ontology language;remote sensing	AI	79.95701271745776	-56.456409183585485	55099
c5af559ef9df20c06bb7f1a6f06d033630c2cc03	detection of occluded targets using thermal imaging spectroscopy	detectors;improvised explosive devices ied;buried object;change detection;improvised explosive device;multivariate statistical based method;buried object thermal hyperspectral change detection improvised explosive devices ied;thermal imaging spectroscopy;buried object detection;soil hyperspectral imaging covariance matrix detectors buried object detection aluminum;aluminum;statistical analysis;thermal imaging;automatic detection;infrared imaging;explosives;multivariate statistics;thermal hyperspectral;improvised explosive devices;occluded targets;temporal thermal hyperspectral scenes;statistical analysis explosives infrared imaging object detection;hyperspectral imaging;class conditional change detector occluded targets target detection thermal imaging spectroscopy automatic detection improvised explosive devices temporal thermal hyperspectral scenes multivariate statistical based method;soil;target detection;class conditional change detector;object detection;covariance matrix	Automatic detection of occluded targets from a sequence of images is an interesting area of research for defense related application. In this paper, change detection methods are investigated for the detection of buried improvised explosive devices (IED) using temporal thermal hyperspectral scenes. Specifically, the paper assesses the detection of buried small aluminium plates using the TELOPS Hyper-Cam sensor and by applying two change detection algorithms: multivariate statistical based method (Cross-Covariance (CC)) and class-conditional change detector (QCC). It was found that spectral based change detection is a good method for the detection of buried IED under disturbed soil. Moreover, the Cross-Covariance (CC)) and the class-conditional (QCC) change detector were able to detect changes using short temporal sequences as long temporal sequences pairs.	algorithm;cross-covariance	Michal Shimoni;Christiaan Perneel;J.-P. Gagnon	2010	2010 2nd Workshop on Hyperspectral Image and Signal Processing: Evolution in Remote Sensing	10.1109/WHISPERS.2010.5594934	materials science;computer vision;analytical chemistry;remote sensing	Vision	71.44507374129616	-63.92785333365272	55168
a8a69034b958349ad11d21b29abe993d6444f6cf	denoising of hyperspectral imagery using an intrinsic spectral representation model with spatial smoothness constraint	spatial smoothness constraint intrinsic spectral representation model spectral correlation linear spectral mixture model unsupervised feature extraction physical data generation process hsi spatial correlation effect noise variance heterogeneity effect noisy pixel nonnegative linear combination gaussian noise heterogeneous noise variances nonnegative coefficients endmembers simulated hyperspectral images real hyperspectral images hyperspectral imagery denoising;heterogeneous variances denoising hyperspectral imagery hsi intrinsic representation;image denoising feature extraction gaussian noise hyperspectral imaging;noise measurement;image reconstruction;noise reduction;noise reduction hyperspectral imaging noise measurement correlation signal to noise ratio image reconstruction;correlation;hyperspectral imaging;signal to noise ratio	Efficient denoising of hyperspectral imagery (HSI) relies on an representational model that is capable of capturing the spatial and spectral correlation in HSI. Recently, an intrinsic representation (IR) approach based on the linear spectral mixture model (LSMM) was proposed for unsupervised feature extraction. The IR model constitutes a sound representational model due to its ability to account for the physical data generation process of HSI, the spatial correlation effect, and the noise variance heterogeneity effect. In this paper, we explore the potential of IR for the denoising of HSI. A noisy pixel in HSI is expressed as a nonnegative linear combination of several endmembers, plus some Gaussian noise with heterogeneous noise variances. In order to perform denoising, the IR approach is used to adaptively estimate both the endmembers and the nonnegative coefficients (i.e., the abundances), which are finally used to reconstruct the clean image. The experiments on both simulated and real hyperspectral images demonstrate that the IR approach not only can resist the influence of noise, but also can preserve the image details.	coefficient;experiment;feature extraction;horizontal situation indicator;mixture model;noise reduction;pixel	Longshan Yang;Linlin Xu;Xiao Sun;Yuan Fang;Yujia Chen;Junhuan Peng	2016	2016 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)	10.1109/IGARSS.2016.7730112	iterative reconstruction;computer vision;computer science;noise measurement;hyperspectral imaging;machine learning;pattern recognition;noise reduction;mathematics;signal-to-noise ratio;correlation;physics;remote sensing	Vision	67.90323814374742	-66.67508762508436	55188
d351b64f0b178da7a9a69455fd2c9c84446db7f0	asymmetric depth estimation for multiview	multiple camera asymmetric depth estimation multiview depth map estimation algorithm low computational complexity n view plus n depth representation aggregation methodology permeability filtering two pass aggregation 2d support regions stereo matching asymmetric approach state of the art methods;filtering;image matching;estimation algorithm design and analysis computational efficiency stereo vision filtering cameras transform coding;transform coding;estimation algorithm;stereo matching;estimation;computational complexity;image representation;stereo image processing computational complexity filtering theory image matching image representation;stereo image processing;stereo vision;depth estimation;depth map;computational efficiency;algorithm design and analysis;filtering theory;cameras	A novel multi-view depth map estimation algorithm is proposed with low computational complexity and high accuracy, while meeting requirements of N-view plus N-depth representation. The algorithm exploits an aggregation methodology, namely permeability filtering (PF), through computationally efficient two-pass aggregation producing adaptively weighted and connected 2D support regions for each pixel. This aggregation approach is quite efficient compared to its alternatives in the literature. The advantage of being occlusion free in multiple viewpoints results with high quality maps compared to stereo matching. Moreover, the asymmetric approach further increases efficiency without any loss in the precision, in terms of mapped reliable center depth map to neighboring cameras in order to avoid redundant computation. Hence, the proposed algorithm is shown as to be a competitive alternative via simulations to some leading state-of-the-art methods by reduced number of computations and efficient support calculation for extracting high quality dense depth maps from multiple camera views.	algorithm;algorithmic efficiency;computation;computational complexity theory;computer stereo vision;depth map;display resolution;pixel;requirement;simulation	Cevahir Çigla;A. Aydin Alatan	2012	2012 20th Signal Processing and Communications Applications Conference (SIU)	10.1109/SIU.2012.6204482	filter;algorithm design;computer vision;mathematical optimization;estimation;transform coding;computer science;stereopsis;theoretical computer science;mathematics;computational complexity theory;statistics;depth map	Vision	55.534285587014004	-55.688783524862714	55203
4e6edc202b41e172b2f38de19f65f6a865b723c8	robust adaptive photon tracing using photon path visibility	density estimation;global illumination;markov chain monte carlo methods;ray tracing;adaptive sampling;monte carlo;photon mapping;markov chain	We present a new adaptive photon tracing algorithm which can handle illumination settings that are considered difficult for photon tracing approaches such as outdoor scenes, close-ups of a small part of an illuminated region, and illumination coming through a small gap. The key contribution in our algorithm is the use of visibility of photon path as the importance function which ensures that our sampling algorithm focuses on paths that are visible from the given viewpoint. Our sampling algorithm builds on two recent developments in Markov chain Monte Carlo methods: adaptive Markov chain sampling and replica exchange. Using these techniques, each photon path is adaptively mutated and it explores the sampling space efficiently without being stuck at a local peak of the importance function. We have implemented this sampling approach in the progressive photon mapping algorithm which provides visibility information in a natural way when a photon path contributes to a measurement point. We demonstrate that the final algorithm is strikingly simple, yet effective at sampling photons under lighting conditions that would be difficult for existing Monte Carlo ray tracing-based methods.	algorithm;illumination (image);jensen's inequality;light transport theory;markov chain monte carlo;monte carlo method;parallel tempering;photon mapping;ray tracing (graphics);sampling (signal processing)	Toshiya Hachisuka;Henrik Wann Jensen	2011	ACM Trans. Graph.	10.1145/2019627.2019633	ray tracing;computer vision;markov chain;mathematical optimization;density estimation;hybrid monte carlo;markov chain monte carlo;mathematics;rejection sampling;photon mapping;optics;global illumination;physics;statistics;monte carlo method;monte carlo method for photon transport	Graphics	63.93667549604921	-53.02792331535107	55339
23df9688c492d9e5b5b4327dabf3ee4a853f4f91	information-theoretic assessment of multi-dimensional signals	hyperspectral imagery;imaging spectrometer;medida informacion;noise estimation;capteur imagerie hyperspectral;imageria termica;acceso multiple;parametric model;analyse multivariable;sensor hiperespectral de formacion de imagenes;acces multiple;entropia;methode parametrique;multivariate analysis;data compression;information theoretic assessment;information transmission;metodo parametrico;mesure information;parametric method;informacion mutual;useful information;lossless compression;informacion util;hyperspectral imaging sensor;image bruitee;information content;imagen sonora;multi dimensional;information mutuelle;analisis regresion;thermal imaging;instrument aeroporte;information measure;infrared imaging;noise source;noisy image;source bruit;entropie;imaging;analyse correlation;airborne visible infrared imaging spectrometer aviris;parametric entropy modelling;hyperspectral data;lossless data compression;analyse regression;formation image;mutual information;analisis multivariable;imagerie thermique;generalised gaussian pdf;regression analysis;noise modelling;rapport signal bruit;spectral band;entropy;compression sans perte;relacion senal ruido;formacion imagen;compresion dato;transmision informacion;theorie information;fuente ruido;banda espectral;transmission information;bande spectrale;signal to noise ratio;multiple access;information theoretic;compresion sin perdida;multivariate regression;airborne instruments;information utile;information theory;compression donnee;analisis correlacion;correlation analysis;teoria informacion	"""This work focuses on estimating the information conveyed to a user by multi-dimensional digitised signals. The goal is establishing the extent to which an increase in radiometric resolution, or equivalently in signal-to-noise ratio (SNR), can increase the amount of information available to users. Lossless data compression is exploited to measure the """"useful"""" information content of the data. In fact, the bit-rate achieved by the reversible compression process takes into account both the contribution of the """"observation"""" noise, i.e. information regarded as statistical uncertainty, whose relevance is null to a user, and the intrinsic information of hypothetically noise-free samples. Once the parametric model of the noise, assumed to be possibly non-Gaussian, has been preliminarily estimated, the mutual information between noise-free signal and recorded noisy signal is easily estimated. However, it is desirable to know what is the amount of information that the digitised samples would convey if they were ideally recorded without observation noise. Therefore, an entropy model of the source is defined and such a model is inverted to yield an estimate of the information content of the noise-free source from the code rate and the noise model. Results are reported and discussed both on a simulated noisy image and on true hyperspectral data (220 spectral bands) recorded by the AVIRIS imaging spectrometer."""	theory	Bruno Aiazzi;Stefano Baronti;Leonardo Santurri;Massimo Selva;Luciano Alparone	2005	Signal Processing	10.1016/j.sigpro.2004.11.025	entropy;telecommunications;information theory;mathematics;lossless compression;statistics	ML	66.22323085782097	-62.47826213216443	55383
104f02c6231b46fa9c60d9d652d08dfc66bc6493	modeling fish-eye lenses	lenses spatial resolution retina humans visual system image sensors sensor phenomena and characterization psychology computer peripherals telecommunication computing;spatially varying resolution fish eye lenses human visual system variable resolution system foveal information;human visual system;lenses;high spatial resolution;spatial resolution	The human visual system can be characterized as a variable-resolution system: foveal information is processed at very high spatial resolution whereas peripheral information is processed at low spatial resolution. Various transforms have been proposed to model spatially varying resolution. Unfortunately, special sensors need to be designed to acquire images according to existing transforms. In this work, two models of fish-eye transform are presented. The validity of the transformations is demonstrated by fitting the alternative models to a real fish-eye lens.	human visual system model;peripheral;sensor	Anup Basu;Sergio Licardie	1993		10.1109/IROS.1993.583883	computer vision;image resolution;computer science;lens;optics;human visual system model;computer graphics (images)	Robotics	62.46965492017534	-58.67028751558949	55563
a98828180306c8d6bde37c8210a1fab045ec34ad	cast.fourier - an interactive method bank for generalized spectral techniques	interactive method	Without Abstract		Hermann Hellwagner	1989		10.1007/3-540-52215-8_31	computer science;multimedia;computer graphics (images)	Theory	64.4653895202232	-55.912040150995665	55634
66c021a6527579e8327431a1feccaeacbcca386b	an efficient directional weighted median switching filter for impulse noise removal in medical images		This paper proposes a new efficient directional weighted median filter for impulse noise removal in medical images. The proposed method consists of two phases: noise detection and noise filtering. In this method, detection is done by Directional Weighted Median (DWM) detection [1], and filtering is applied to only corrupted pixels in the noisy image. The noise detection stage is based on the differences between the current pixel and its neighbours aligned in the main four directions in the considered window. The weighted median filter is then applied on directional pixel values as well as on uncorrupted pixels in the selected window by giving appropriate weights for the better restoration of corrupted medical images. Extensive experimental analysis shows that the proposed technique can be used for medical images with different impulse type noises. Both quantitative and qualitative analysis shows the superiority of the proposed method over other filters.		Madhu S. Nair;J. Reji	2011		10.1007/978-3-642-22720-2_28	median filter;salt-and-pepper noise	Robotics	56.9034814799751	-66.44924778618295	55707
b5a6a52c8f33a7f90c89a15b7cacd73beaab3aa2	automating regional descriptive statistic computations for environmental modeling	computadora;tratamiento datos;computers;ecoulement cours eau;statistique;gauging;systeme information geographique;bassin versant;north america;america del norte;case studies;amerique du nord;ordinateur;raster;drainage divide;polygone;data processing;traitement donnee;etats unis;caroline du nord;estados unidos;united states geological survey;modelo;ligne partage eau;gis;estudio caso;geographic information systems;statistical computing;polygons;cuenca;streamflow;batch process;tennessee;etude cas;statistics;aforo;modele;models;jaugeage;environmental modeling;drainage basins;estadistica;north carolina;carolina del norte	A GIS toolset was developed to support the extraction of a variety of input variables for environmental models. The developed toolset allows the automated processing of large amounts of raster data over polygon data. A case study was performed in a region centered on eastern Tennessee and western North Carolina. Using the developed GIS toolset, topographic, geologic, and climatic characteristics for watersheds corresponding to 35 United States Geological Survey streamflow gauging sites were derived by processing approximately 1500 raster datasets. The developed GIS toolset greatly reduced the time and effort needed to process the GIS data, and provides a useful tool for a wide variety of environmental applications. The developed toolset is freely available for download, and a tutorial has been created. r 2006 Published by Elsevier Ltd.	computation;download;geographic information system;raster data;topography	Satoshi Hirabayashi;Charles Kroll	2007	Computers & Geosciences	10.1016/j.cageo.2006.06.013	data processing;geology;hydrology;computer science;polygon;mathematics;cartography;statistics	Visualization	77.38858296264908	-54.649765734169385	55774
c9f8142cefbb99351853d930dcc3903c1e20e9d7	high-order model and dynamic filtering for frame rate up-conversion		This paper proposes a novel frame rate up-conversion method through high-order model and dynamic filtering (HOMDF) for video pixels. Unlike the constant brightness and linear motion assumptions in traditional methods, the intensity and position of the video pixels are both modeled with high-order polynomials in terms of time. Then, the key problem of our method is to estimate the polynomial coefficients that represent the pixel’s intensity variation, velocity, and acceleration. We propose to solve it with two energy objectives: one minimizes the auto-regressive prediction error of intensity variation by its past samples, and the other minimizes video frame’s reconstruction error along the motion trajectory. To efficiently address the optimization problem for these coefficients, we propose the dynamic filtering solution inspired by video’s temporal coherence. The optimal estimation of these coefficients is reformulated into a dynamic fusion of the prior estimate from pixel’s temporal predecessor and the maximum likelihood estimate from current new observation. Finally, frame rate up-conversion is implemented using motion-compensated interpolation by pixel-wise intensity variation and motion trajectory. Benefited from the advanced model and dynamic filtering, the interpolated frame has much better visual quality. Extensive experiments on the natural and synthesized videos demonstrate the superiority of HOMDF over the state-of-the-art methods in both subjective and objective comparisons.	coefficient;coherence (physics);collision detection;experiment;frame (physical object);handling (psychology);inspiration function;interpolation imputation technique;mathematical optimization;maximum likelihood estimation;motion interpolation;optimization problem;part dosing unit;pixel;polynomial;velocity (software development);brightness;videocassette	Wenbo Bao;Xiaoyun Zhang;Li-hua Chen;Lianghui Ding;Zhiyong Gao	2018	IEEE Transactions on Image Processing	10.1109/TIP.2018.2825100	computer vision;artificial intelligence;filter (signal processing);pattern recognition;mathematics;frame rate	Vision	56.77424208713213	-58.41889294686169	55805
0d1ef39eeabefa4e4a85e2bdfc91316543bbff21	a generic tool for interactive complex image editing		Plenty of complex image editing techniques require certain per-pixel property or magnitude to be known, e.g., simulating depth of field effects requires a depth map. This work presents an efficient interaction paradigm that approximates any per-pixel magnitude from a few user strokes by propagating the sparse user input to each pixel of the image. The propagation scheme is based on a linear least-squares system of equations which represents local and neighboring restrictions over superpixels. After each user input, the system responds immediately, propagating the values and applying the corresponding filter. Our interaction paradigm is generic, enabling image editing applications to run at interactive rates by changing just the image processing algorithm, but keeping our proposed propagation scheme. We illustrate this through three interactive applications: depth of field simulation, dehazing and tone mapping.	algorithm;depth map;embedded system;filter (signal processing);hoc (programming language);image editing;image processing;interactivity;linear least squares (mathematics);linear system;mobile device;pixel;programming paradigm;requirement;simulation;software propagation;sparse matrix;system of linear equations;tone mapping;upwind scheme;video post-processing	Ana B. Cambra;Ana Cristina Murillo;Adolfo Muñoz	2017	The Visual Computer	10.1007/s00371-017-1422-5	system of linear equations;image processing;computer vision;artificial intelligence;computer science;magnitude (mathematics);tone mapping;depth of field;pixel;image editing;depth map	Graphics	66.28829402211923	-53.61886654739655	55877
40425c0750bfacdfc1bc337e1c534b2433282181	point cloud inpainting on graphs from non-local self-similarity		As 3D scanning devices and depth sensors advance, point clouds have attracted increasing attention as a format for 3D object representation, with applications in various fields such as tele-presence, navigation and heritage reconstruction. However, point clouds usually exhibit holes of missing data, mainly due to the limitation of acquisition techniques and complicated structure. Hence, we propose an efficient point cloud inpainting method, leveraging on graph signal processing and based on the observation of non-local self-similarity in point clouds. Specifically, we split a point cloud into fixed-size cubes as the processing unit, and globally search for the most similar cube to the target cube with holes inside. The similarity metric between two cubes is defined based on the direct component and the proposed anisotropic graph total variation of normals in each cube. We then formulate the hole-filling step as an optimization problem, based on the selected most similar cube and regularized by a graph-signal smoothness prior. Experimental results show that the proposed approach outperforms three competing methods significantly, both in objective and subjective quality.		Zeqing Fu;Wei Hu;Zongming Guo	2018	2018 25th IEEE International Conference on Image Processing (ICIP)	10.1109/ICIP.2018.8451550	computer vision;point cloud;inpainting;missing data;smoothness;signal processing;artificial intelligence;cube;self-similarity;computer science;optimization problem	Robotics	57.34368773051775	-56.39594160719284	55973
d70711188167ff4292e2ca018539da1be6726f95	robust image restoration matched with adaptive aperture formation in radar imaging systems with sparse antenna arrays	radar imaging antenna arrays frequency domain analysis image restoration;image restoration;radar imaging;spatial frequency domain adaptive aperture formation strategy radar imaging systems sparse antenna arrays robust adaptive image restoration principle image components;adaptive arrays;robustness;image restoration robustness aperture antennas radar imaging adaptive arrays;aperture antennas	The paper presents a complex approach to radar imaging system development. The approach consists of two main stages. The first stage is adaptive aperture formation and the second one is robust adaptive image restoration. The use of adaptive aperture formation strategy makes possible to estimate the principle image components in spatial frequency domain and increase the reliability of received data. The robust adaptive image restoration allows to compensate the blurring effect of sparse aperture in the presence of mixed noise (i.e. Gaussian and impulse). The efficiency of the proposed approach is investigated on numerous test examples.	aperture (software);circuit restoration;computer graphics;computer simulation;download;image formation;image processing;image restoration;iterative method;matrix regularization;nonlinear system;qualitative comparative analysis;radar;signal processing;sparse matrix	Ivan Prudyus;Sviatoslav Voloshynovskiy;Taras Holotyak	1998	9th European Signal Processing Conference (EUSIPCO 1998)		computer vision;electronic engineering;geography;radar imaging;inverse synthetic aperture radar;side looking airborne radar;remote sensing	Vision	72.51794923628876	-66.84800159050505	55978
de28ad07abf6bcc04c504d8de69443a185e25b8e	color rendering indices in global illumination methods	lumiere naturelle;radiation sources;man;color rendering;mise a jour;reproduccion color;color space;lamps;color difference;0130c;fatiga color;source rayonnement;4266s;multipoint method;skylights;actualizacion;etat actuel;global illumination;methode multipoint;evaluation subjective;metodo multipunto;colorimetrie;color reproduction;rendu couleur;state of the art;colorimetry;estado actual;espace chromatique;espacio cromatico;subjective evaluation;reproduction couleur;vision;human perception;updating;light sources;homme;evaluacion subjetiva	Human perception of material colors depends heavily on the nature of the light sources that are used for illumination. One and the same object can cause highly different color impressions when lit by a vapor lamp or by daylight, respectively. On the basis of state-of-the-art colorimetric methods, we present a modern ap- proach for the calculation of color-rendering indices (CRI), which were defined by the International Commission on Illumination (CIE) to characterize color reproduction properties of illuminants. We up- date the standard CIE method in three main points: first, we use the CIELAB color space; second, we apply a linearized Bradford trans- formation for chromatic adaptation; and finally, we evaluate color differences using the CIEDE2000 total color difference formula. Moreover, within a real-world scene, light incident on a measure- ment surface is composed of a direct and an indirect part. Neumann and Schanda (Proc. CGIV'06 Conf., Leeds, UK, pp. 283-286 (2006)) have shown for the cube model that diffuse interreflections can influence the CRI of a light source. We analyze how color- rendering indices vary in a real-world scene with mixed direct and indirect illumination and recommend the usage of a spectral render- ing engine instead of an RGB-based renderer for reasons of accu- racy of CRI calculations. © 2009 SPIE and	global illumination	David Geisler-Moroder;Arne Dür	2009		10.1117/12.805608	vision;icc profile;color model;color rendering index;colorimetry;color difference;color balance;optics;color space;perception;global illumination;standard illuminant	Graphics	62.921632678920346	-60.623624581188075	56018
cf054bf57bf251c15d83d53d5b7e8e06a5dbe88e	denoising of time-of-flight depth data via iteratively reweighted least squares minimization	minimisation;discontinuity preserving time of flight depth denoising method time of flight depth data denoising iteratively reweighted least squares minimization spatially varying noise;least mean squares methods;iterative methods;noise reduction noise cameras cost function three dimensional displays jacobian matrices robustness;minimisation image denoising iterative methods least mean squares methods;denoising time of flight depth;image denoising	Time-of-Flight depth data suffer from spatially varying noise, whose variance is inversely proportional to the squared amplitude of the received signal. On the other hand, preservation of genuine discontinuities of the scene is an important quality for a denoising method to have. This paper presents a noise-aware and discontinuity-preserving Time-of-Flight depth de-noising method. To incorporate different constraints from the two philosophies, we recast depth denoising into an iteratively reweighted least squares problem, in which the cost function is iteratively updated and minimized in a manner of preserving the discontinuities and rejecting outliers while denoising the depth data. The experiments show that the proposed method delivers better results with lower error than existing methods, irrespective of the amount of noise and discontinuities.	experiment;iteratively reweighted least squares;loss function;newton's method;noise reduction;reflections of signals on conducting lines	Ouk Choi;Byongmin Kang	2013	2013 IEEE International Conference on Image Processing	10.1109/ICIP.2013.6738222	iteratively reweighted least squares;minimisation;econometrics;mathematical optimization;mathematics;iterative method;statistics	Robotics	57.76831274440428	-72.35449566639211	56141
866e914d54ebf75e33975a613f3641dbf2712a02	image fusion based on visual salient features and the cross-contrast	image fusion;visual salient features;nonsubsampled contourlet transform;the cross contrast	Low frequency subband coefficients are selected based on visual salient features.Bandpass directional subband coefficients are selected by the cross-contrast.Three maps of visual salient features are constructed based on visual saliency. To extract and combine the features of the original images, a novel algorithm based on visual salient features and the cross-contrast is proposed in this paper. Original images were decomposed into low frequency subband coefficients and bandpass direction subband coefficients by using the nonsubsampled contourlet transform. Three maps of visual salient features are constructed based on visual salient features the local energy, the contrast and the gradient respectively, and low-frequency subband coefficients are got by utilizing these visual saliency maps. The cross-contrast is obtained by computing the ratio between the local gray mean of bandpass direction subband coefficients and the local gray mean of fused low-frequency subband coefficients. Bandpass direction subband coefficients is goted by the cross-contrast. Comparison experiments have been performed on different image sets, and experimental results demonstrate that the proposed method performs better in both subjective and objective qualities.	image fusion	Jianhua Adu;Shenghua Xie;Jianhong Gan	2016	J. Visual Communication and Image Representation	10.1016/j.jvcir.2016.06.026	computer vision;speech recognition;pattern recognition;image fusion	Vision	59.00462876094203	-67.07528549241985	56185
607cada7f24e28f9cf84bf75d815d5d4eddf82cf	digital computation of fractional fourier and linear canonical transforms and sparse image representation		Fast and accurate digital computation of the fractional Fourier transform (FRT) and linear canonical transforms (LCT) are of utmost importance in order to deploy them in real world applications and systems. The algorithms in O(NlogN) to obtain the samples of the transform from the samples of the input function are presented for several different types of FRTs and LCTs, both in 1D and 2D forms. To apply them in image processing we consider the problem of obtaining sparse transform domains for images. Sparse recovery tries to reconstruct images that are sparse in a linear transform domain, from an underdeter- mined measurement set. The success of sparse recovery relies on the knowledge of domains in which compressible representations of the image can be obtained. In this work, we consider two- and three-dimensional images, and investigate the effects of the fractional Fourier (FRT) and linear canonical transforms (LCT) in obtaining sparser transform domains. For 2D images, we investigate direct transforming versus several patching strategies. For the 3D case, we consider biomedical images, and compare several different strategies such as taking 2D slices and optimizing for each slice and direct 3D transforming.	algorithm;compressed sensing;computation;computer simulation;experiment;fractional fourier transform;image processing;linear canonical transformation;mathematical optimization;mined;mined-out;patch (computing);performance;sparse matrix	Aykut Koç;Haldun M. Özaktas;Burak Bartan;Erhan Gundogdu;Tolga Çukur	2017	2017 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)	10.1109/APSIPA.2017.8282011	image processing;fractional fourier transform;mathematical optimization;fourier transform;computation;sparse image;matrix decomposition;chirp;mathematics	Vision	60.14161169924516	-68.72633169526169	56216
e9f8e3cf0d7f11ad38d669e1791f6f0c1a13e0e9	a sparse nmf-su for seismic random noise attenuation	pattern clustering;signal denoising deconvolution fourier transforms geophysical signal processing geophysical techniques matrix decomposition pattern clustering random noise seismology;seismology;nonnegative matrix factorization nmf;noise attenuation noise measurement sparse matrices noise reduction matrix decomposition speech;spectral unmixing su intrinsic mode function imf nonnegative matrix factorization nmf seismic random noise;speech;attenuation;noise measurement;random noise;geophysical signal processing;matrix decomposition;noise reduction;fourier transforms;spectral unmixing su;deconvolution;intrinsic mode function imf;seismic random noise;f x filtering comparison sparse nmf su nonnegative matrix factorization sparse nmf spectral unmixing land seismic additive random noise attenuation noisy seismic signal decomposition intrinsic mode functions imf short time fourier transform spectrum stft spectrum mixing degree inverse stft k means clustering algorithm random noise suppression effective signal components time frequency peak filtering comparison;sparse matrices;geophysical techniques;noise;signal denoising	A novel method based on nonnegative matrix factorization (NMF) spectral unmixing is proposed for land seismic additive random noise attenuation. In the method, the noisy seismic signal is first decomposed into a collection of intrinsic mode functions (IMFs) instead of being directly processed. These IMFs can be considered as a new set of observations. In the short-time Fourier transform (STFT) spectrum of each IMF, the degree of mixing from the effective signal and the random noise is considerably reduced. Then, a sparse NMF is used to unmix the STFT spectrum of each IMF. We get the subsignals out of the separated subspectrums by the inverse STFT. Finally, the desired signal is reconstructed from the subsignals by K-means clustering algorithm. Experimental results of both synthetic and real seismic records show that the proposed method can significantly suppress random noise and preserve the effective signal components. Comparisons with time-frequency peak filtering and f-x filtering further verify its better performance.	algorithm;cluster analysis;k-means clustering;noise (electronics);non-negative matrix factorization;short-time fourier transform;sparse matrix;synthetic intelligence;utility functions on indivisible goods	Yanan Tian;Yue Li;Hongbo Lin;Haitao Ma	2013	IEEE Geoscience and Remote Sensing Letters	10.1109/LGRS.2012.2215835	attenuation;fourier transform;computer vision;speech recognition;sparse matrix;noise measurement;noise;deconvolution;speech;pattern recognition;noise reduction;mathematics;matrix decomposition	ML	70.09381347821984	-66.38586937706755	56304
dd0524432289ebdb4cdbd4ef57d63c4b7526b837	multi-modal non-line-of-sight passive imaging		We consider the non-line-of-sight (NLOS) imaging of an object using light reflected off a diffusive wall. The wall scatters incident light such that a lens is no longer useful to form an image. Instead, we exploit the four-dimensional spatial coherence function to reconstruct a two-dimensional projection of the obscured object. The approach is completely passive in the sense that no control over the light illuminating the object is assumed, and is compatible with the partially coherent fields ubiquitous in both indoor and outdoor environments. We formulate a multicriteria convex optimization problem for reconstruction, which fuses reflected field’s intensity and spatial coherence information at different scales. Our formulation leverages established optics models of light propagation and scattering and exploits the sparsity common to many images in different bases. We also develop an algorithm based on the Alternating Direction Method of Multipliers to efficiently solve the convex program proposed. A means for analyzing the null space of the measurement matrices is provided, as well as a means for weighing the contribution of individual measurements to the reconstruction. This work holds promise to advance passive imaging in challenging NLOS regimes in which the intensity does not necessarily retain distinguishable features, and provides a framework for multi-modal information fusion for efficient scene reconstruction.	algorithm;augmented lagrangian method;coherence (physics);convex optimization;kernel (linear algebra);line-of-sight (missile);mathematical optimization;modal logic;optimization problem;ray (optics);software propagation;sparse matrix	Andre Beckus;Alexandru Tamasan;George Atia	2018	CoRR		computer vision;artificial intelligence;kernel (linear algebra);ray;mathematics;coherence (signal processing);convex optimization;weighting;non-line-of-sight propagation;coherence (physics);matrix (mathematics)	Vision	65.86745019500418	-71.71663157556888	56366
5c73c31a7604178f5e70fb3de51ff49bbb8fd81f	camera identification for very low bit rate time varying quantization noise videos	eigenvalues and eigenfunctions;cameras videos noise vectors quantization signal bit rate eigenvalues and eigenfunctions;video coding cameras laplace equations principal component analysis quantisation signal;quantization signal;bit rate;vectors;camera identification photo response nonuniformity noise interclass separation linear discriminant analysis principal component analysis statistic moment vectors laplace distribution time varying overall noise pattern statistics very low bit rate time varying quantization noise videos;cameras;noise;videos	This paper addresses the camera identification based on very low bit rate videos with time varying overall noise pattern statistics. First, the overall noise pattern of each frame of the videos is resized to a column vector. It is found that the elements of the resized vectors approximately follow the Laplace distribution. Hence, the second, the fourth and the sixth order statistic moments of each resized vector are computed and these statistic moments form a new vector. The statistic moment vectors are different at different frames because the overall noise pattern statistics are time varying. Second, the principal component analysis is performed for reducing the total number of features for the camera identification. In particular, the statistic moment vector of each frame is projected to the most major component. The projected components of all the frames form a feature vector for each video. Third, the linear discriminant analysis is performed to minimize the intraclass separation and maximize the interclass separation. However, as many eigenvalues of the interclass separation matrix are close to zero, this optimization problem is severely ill-posed. To address this difficulty, this paper proposes to find the columns span the null spaces of the corresponding matrices. The feature vector of each video is projected to these columns and forms a new vector. It is found that these new vectors are pairwisely linear separable. Hence, a set of perceptrons can be employed for the camera identification. Computer numerical simulations show that our proposed method significantly outperforms the conventional method based on computing the correlation coefficients on the photo response nonuniformity noise (PRNU) and the conventional 1-nearest neighbor rule approach in terms of both the identification rate and the robustness performance.	coefficient;column (database);feature vector;kernel (linear algebra);linear discriminant analysis;mathematical optimization;numerical analysis;optimization problem;perceptron;principal component analysis;quantization (signal processing);simulation;well-posed problem	Zitong Yu;Lianshi Lin;Bingo Wing-Kuen Ling;Charlotte Yuk-Fan Ho;Chunmei Qing;Hailiang Xu;Weihang Dai;Yuming Liang;Jiameng Chen;Qingyun Dai	2014	2014 9th International Symposium on Communication Systems, Networks & Digital Sign (CSNDSP)	10.1109/CSNDSP.2014.6923826	computer vision;speech recognition;noise;mathematics;statistics	Vision	63.02562098625334	-74.612720506035	56468
1205ed0401cd6b00738d210f220eadaac6b3d18a	initial cram aerosol retrievals from calipso and supporting airborne hsrl measurements	remote sensing by laser beam;cram aerosol retrieval;weather climate change;constrained ratio aerosol model fit technique;cloudsat satellite;radar remote sensing;airborne high spectral resolution lidar data;calipso;information retrieval;climate change;earth;remote sensing by laser beam aerosols atmospheric techniques data acquisition optical radar;aqua satellite;aura satellite;cloud aerosol lidar and infrared pathfinder satellite observation;laser radar;earth atmosphere system;high spectral resolution lidar;aerosols satellites laser radar spaceborne radar context modeling information retrieval extraterrestrial measurements remote sensing radar remote sensing earth;parasol satellite;ad 2006 04 28;optical radar;airborne high spectral resolution lidar data cram aerosol retrieval calipso cloud aerosol lidar and infrared pathfinder satellite observation cloudsat satellite ad 2006 04 28 active remote sensing system radar spaceborne earth observation a train constellation aura satellite parasol satellite aqua satellite earth atmosphere system weather climate change constrained ratio aerosol model fit technique;cloud aerosol lidar and infrared pathfinder satellite observations;spaceborne earth observation;remote sensing;satellites;active sensing;scientific communication;earth observation;atmospheric techniques;model fitting;a train constellation;active remote sensing system;extraterrestrial measurements;context modeling;data acquisition;radar;level 1;spaceborne radar;aerosols	The successful launch of the Cloud-Aerosol Lidar and Infrared Pathfinder Satellite Observation (CALIPSO) and Cloud-Satellite (CloudSAT) satellites on April 28, 2006, placing two new active remote sensing systems (lidar and radar) in space, heralded a new era in spaceborne earth observations. Not only will they provide new information unique to active sensing satellites, but by positioning them in orbit with the A-Train constellation of satellites, joining the passive sensing satellites AURA, PARASOL and AQUA, this will enable myriad synergistic active-passive sensing opportunities. CALIPSO and CloudSAT have both successfully completed their payload checkouts and initial validations; some six months of data have already been collected and data are now beginning to be distributed to the scientific community (e.g., CALIPSO Level 1 and 2a data released on Dec. 8, 2006). Thus there are sufficient data, with more arriving daily, to fuel years of scientific studies addressing questions critical to more fully understanding the earth-atmosphere system and assessing weather-climate change issues. The Constrained Ratio Aerosol Model-fit (CRAM) technique for aerosol retrieval is examined in the context of CALIPSO data, and temporally/spatially coincident High Spectral Resolution Lidar (HSRL) data is studied with respect to its potential to provide external context to the retrievals and to verify aerosol models upon which the CRAM technique relies.	a-train;aura;airborne ranger;aqua;communications satellite;point of sale;synergy	John A. Reagan;Christopher McPherson;Chris Hostetler;Johnathan Hair;Richard Ferrare	2007	2007 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2007.4423979	earth observation;meteorology;lidar;atmospheric sciences;earth;context model;data acquisition;climate change;physics;radar;satellite;remote sensing	Embedded	81.41486052499309	-62.2933267031669	56476
678e771ffce151232591d8443dd5fcd6afa4a3a7	investigating lossy image coding using the plhaar transform	piecewise linear;general and miscellaneous mathematics computing and information science;mathematics;image coding;psnr;lossy image coding piecewise linear haar transform integer transform wavelet like transform lossy coding lossless coding thresholding transform coefficients image contrast entropy image reconstruction psnr;piecewise linear techniques;chaos;computer graphics;transformations;image coding haar transforms transform coding image reconstruction entropy;entropy image coding haar transforms transform coding image reconstruction;wavelet like transform;transform coding;bit rate;computer graphic;image contrast;wavelet transforms;data analysis;lossy coding;integer transform;piecewise linear haar transform;image reconstruction;dynamic range;lossless coding;lossy image coding;entropy;image coding wavelet transforms piecewise linear techniques computer graphics dynamic range chaos mathematics bit rate entropy image reconstruction;psnr lossy image coding piecewise linear haar transform integer transform wavelet like transform lossy coding lossless coding thresholding transform coefficients image contrast entropy image reconstruction;compression;haar transforms;thresholding transform coefficients	Summary form only given. We developed the piecewise-linear Haar (PLHaar) transform (Senecal, J.G. et al., Proc. 12th Pacific Conf. on Computer Graphics and Appl., p.371-80, 2004), an integer wavelet-like transform. PLHaar does not have dynamic range expansion, i.e., it is an n-bit to n-bit transform. To our knowledge, PLHaar is the only reversible n-bit to n-bit transform that is suitable for lossy and lossless coding. We are investigating PLHaar's use in lossy image coding. Preliminary results from thresholding transform coefficients show that PLHaar does not produce objectionable artifacts like previous n-bit to n-bit transforms, such as that of Honyang Chao et al. (CFH) (see Advances in Computational Mathematics, Lect. Notes In Pure and App. Math., vol.202, p.13-38, 1999). Also, at lower bitrates PLHaar images have increased contrast. For a given set of CFH and PLHaar coefficients with equal entropy, the PLHaar reconstruction is more appealing, although the PSNR may be lower.	chao (sonic);coefficient;computation;computational mathematics;computer graphics;dynamic range;haar wavelet;lossless compression;lossy compression;peak signal-to-noise ratio;pure;thresholding (image processing)	Joshua G. Senecal;Peter Lindstrom;Mark A. Duchaineau;Kenneth I. Joy	2005	Data Compression Conference	10.1109/DCC.2005.45	iterative reconstruction;transformation;computer vision;entropy;mathematical optimization;dynamic range;transform coding;piecewise linear function;peak signal-to-noise ratio;computer science;theoretical computer science;mathematics;data analysis;computer graphics;compression;statistics;wavelet transform	Vision	59.862316356694315	-64.05677821732293	56519
bd57364e93f05a74fa29c379087740f0ac7fe99b	influence of processing method, bit rate, and scene content on perceived and predicted image quality	modelizacion;bit;analisis escena;analyse scene;image processing;quality measurement;estudio comparativo;erreur quadratique moyenne;procesamiento imagen;hombre;qualite image;traitement image;modelisation;etude comparative;percepcion visual;mean square error;image quality;human;comparative study;estimacion parametro;perception visuelle;visual perception;calidad imagen;parameter estimation;error medio cuadratico;estimation parametre;modeling;homme;scene analysis	In this paper we evaluate two objective quality measures, the root-mean-square-error and a model based on the human visual system (HVS), on their ability to predict the perceived image quality for variations in bit-rate, processing method, and scene content. In theory quality metrics should be able to predict the perceived image quality independent of these variations. However, one can imagine that in practice this is not trivial to meet. But also subjects might have difficulties in making comparisons across processing methods or across scenes. In order to test whether subjects use separate quality scales for each identifiable scene and processing method or whether they use a single quality scale, we set up experiments in which the influence of bit-rate, processing method, and scene content was measured. In all experiments subjects were instructed to judge the quality difference between two simultaneously presented images.© (2000) COPYRIGHT SPIE--The International Society for Optical Engineering. Downloading of the abstract is permitted for personal use only.	image quality	Lydia Meesters;Jean-Bernard Martens	2000		10.1117/12.387186	computer vision;geography;artificial intelligence;cartography	Vision	62.75641661570835	-62.61431009246138	56618
d7f5b9bba04a954f465e9a0e34427c4311b97423	topography of sand covered bedrock using two-frequency airborne interferometric sar measurements	topography earth airborne radar geophysical prospecting radar interferometry remote sensing by radar rocks sand synthetic aperture radar terrain mapping;subsurface imaging topography sand covered bedrock two frequency airborne interferometric sar synthetic aperture radar oil field search insar processing iterative algorithm sand dunes;insar processing;sand dunes;topography earth;radar interferometry;sand;iterative algorithms;synthetic aperture radar interferometry frequency backscatter bandwidth receiving antennas surface topography signal design signal to noise ratio petroleum iterative algorithms;signal design;backscatter;interferometric synthetic aperture radar insar;topography;iterative algorithm;sand covered bedrock;surface topography;remote sensing by radar;petroleum;radar imaging;subsurface imaging;bandwidth;airborne radar;terrain mapping;oil field search;rocks;receiving antennas;synthetic aperture radar interferometry;signal to noise ratio;frequency;two frequency airborne interferometric sar;interferometric sar;sand dune;geophysical prospecting;subsurface imaging interferometric synthetic aperture radar insar terrain mapping radar imaging;synthetic aperture radar	This paper presents the application of Interferometric Synthetic Aperture Radar (InSAR) to estimate the height of the sand layer on top of the bedrock in deserts. This is anticipated to greatly increase the efficiency of oil field search and can have several applications for environmental and archaeological studies. The extension of InSAR processing to estimate the covered bedrock height through an iterative algorithm is introduced. The sensitivity of the proposed algorithm to system errors is investigated and its application to a common type of sand dunes is also presented.	airborne ranger;algorithm;aperture (software);iterative method;topography	Adel Elsherbini;Kamal Sarabandi	2009	2009 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2009.5418055	geomorphology;geology;hydrology;topography;sand dune stabilization;physics;remote sensing	Embedded	78.73066674464282	-65.14496316494949	56806
512a901da7a5fe3cad5fcbf745f4626284be44cf	speeding uplow rank matrix recovery for foreground separation in surveillance videos	speeding up low rank matrix recovery foreground extraction;videos surveillance image reconstruction noise image sequences robustness sparse matrices;surveillance;video surveillance feature extraction image reconstruction image sampling matrix algebra;foreground extraction low rank matrix recovery foreground separation video surveillance public safety public security target tracking activity recognition behavior prediction sampling strategy;speeding up low rank matrix recovery;image reconstruction;foreground extraction;robustness;sparse matrices;noise;videos;image sequences	Video surveillance currently is one of the most active research topics in public safety and security, in which foreground extraction is important and fundamental for further processing, such as target tracking, activity recognition, and behavior prediction. In this paper, by assuming the background is highly correlated across different frames, we propose to separate foregrounds via speeded up low rank matrix recovery. The proposed method first shrinks the scale of data to roughly catch outliers (foregrounds) of the background. Based on the outliers, we design a sampling strategy that selects a number of frames to construct the low rank model of background. According to the constructed background model, our method further recovers both the background and the foreground for the rest frames in a reconstruction manner. Experimental results on both simulated and real data demonstrate the clear advantage of our approach compared to the state of the arts, in terms of accuracy and efficiency.	activity recognition;sampling (signal processing)	Xiaojie Guo;Xiaochun Cao	2014	2014 IEEE International Conference on Multimedia and Expo (ICME)	10.1109/ICME.2014.6890207	iterative reconstruction;computer vision;background subtraction;sparse matrix;noise;machine learning;pattern recognition;mathematics;programming language;robustness	Vision	68.65551046001848	-67.52258214724549	56826
a5ebf8438d54bcb44037d30debd02d9bec7a5c2c	erratum to: a new class of wavelet-based metrics for image similarity assessment		In this paper, we propose a new class of image similarity metrics based on a wavelet decomposition. By suitably combining weighted contributions of the different dyadic frequency bands, we define a class of similarity measures and we prove it is a metric. Moreover, we discuss the theoretical relationship between the novel class of metrics and the well-known structural similarity index (SSIM) and its multiscale versions (MSSSIM and CWSSIM). By using standard benchmark indexes over a reference database in the literature (the TID2013 database), we test the efficiency of the newly defined metrics in performing similarity assessment. We compare the performance of our metric with other well-known indexes in the literature, such as SSIM, FPH, MSSSIM, CWSSIM and PSNR, to demonstrate its improvement over the current state of the art, which becomes more evident when the query image is the one identified by the worst level of degradation which is perceived by the human visual system, as coded by the standard mean opinion score stored in the database. The original version of this article was revised: The double vertical bars are inserted instead of single vertical bars in Equation 9. B Silvia Bertoluzza silvia.bertoluzza@imati.cnr.it Maria Grazia Albanesi mariagrazia.albanesi@unipv.it 1 Department of Electrical, Computer and Biomedical Engineering, University of Pavia, Via Ferrata 1, 27100 Pavia, Italy 2 CNR IMATI Enrico Magenes, via Ferrata 1, 27100 Pavia, Italy 3 ICH Humanitas, Milan, Italy	benchmark (computing);bibliographic database;dyadic transformation;elegant degradation;enrico clementi;frequency band;peak signal-to-noise ratio;structural similarity;symbolically isolated linguistically variable intelligence algorithms;wavelet;whole earth 'lectronic link	Maria Grazia Albanesi;Riccardo Amadeo;Silvia Bertoluzza;Giulia Maggi	2017	Journal of Mathematical Imaging and Vision	10.1007/s10851-017-0751-3	computer vision;wavelet;mathematics;machine learning;artificial intelligence	Vision	61.05419685433357	-65.56109170854546	56871
aa1c0857a681f365c60fe8371832e0c2f51edc68	sparse coding from a bayesian perspective	visual tracking computer vision sparse coding method nonconvexity discontinuity l 0 penalty l 1 penalty over penalization bayesian perspective objective function maximum a posteriori estimation reconstruction errors convergence property image super resolution;maximum a posteriori map;image coding;image resolution;bayes methods;object tracking bayes methods computer vision image coding image reconstruction image resolution maximum likelihood estimation;maximum likelihood estimation;computer vision;encoding dictionaries bayes methods vectors linear programming optimization estimation;bayesian;sparse coding bayesian compressive sensing cs computer vision maximum a posteriori map;image reconstruction;object tracking;compressive sensing cs;sparse coding	Sparse coding is a promising theme in computer vision. Most of the existing sparse coding methods are based on either <i>l</i><sub>0</sub> or <i>l</i><sub>1</sub> penalty, which often leads to unstable solution or biased estimation. This is because of the nonconvexity and discontinuity of the <i>l</i><sub>0</sub> penalty and the over-penalization on the true large coefficients of the <i>l</i><sub>1</sub> penalty. In this paper, sparse coding is interpreted from a novel Bayesian perspective, which results in a new objective function through maximum a posteriori estimation. The obtained solution of the objective function can generate more stable results than the <i>l</i><sub>0</sub> penalty and smaller reconstruction errors than the <i>l</i><sub>1</sub> penalty. In addition, the convergence property of the proposed algorithm for sparse coding is also established. The experiments on applications in single image super-resolution and visual tracking demonstrate that the proposed method is more effective than other state-of-the-art methods.	algorithm;autostereogram;coefficient;computer vision;control theory;convergence (action);experiment;loss function;neural coding;optimization problem;reflections of signals on conducting lines;small;sparse matrix;super-resolution imaging;unstable medical device problem;video tracking	Xiaoqiang Lu;Yulong Wang;Yuan Yuan	2013	IEEE Transactions on Neural Networks and Learning Systems	10.1109/TNNLS.2013.2245914	iterative reconstruction;computer vision;image resolution;bayesian probability;computer science;maximum a posteriori estimation;machine learning;video tracking;pattern recognition;mathematics;maximum likelihood;neural coding	Vision	57.634137148470224	-72.48362863837626	56916
7200a4f64729ad894967935bd8235d03fea64422	incomplete 3d for multiview representation and synthesis of video objects	video object;image tridimensionnelle;texture;three dimensional;sintesis imagen;image synthesis;codificacion;surface plane;senal video;signal video;textura;coding;video object plane;mpeg 4;video signal;synthese image;tridimensional image;plane surface;superficie plana;imagen tridimensional;verification model;codage	This paper introduces a new form of representation for three-dimensional video objects. We have developed a technique to extract disparity and texture data from video objects, that are captured simultaneously with multiple-camera configurations. As a result, we obtain the video object plane as an unwrapped surface of a 3D object, containing all texture data visible from any of the cameras. This texture surface can be encoded like any 2D video object plane, while the 3D information is contained in the associated disparity map. It is then possible to reconstruct different viewpoints from the texture surface by simple disparity-based projection. The merits of the technique are efficient multiview encoding of single video objects, and support for viewpoint adaptation functionality, which is desirable in mixing natural and synthetic images. We have performed experiments with the MPEG-4 video verification model, where the disparity map is encoded by use of the tools provided for grayscale alpha data encoding. Due to its simplicity, the technique is capable for applications with requirement for realtime viewpoint adaptation towards video objects.	3d film;multiview video coding	Jens-Rainer Ohm;Karsten Müller	1998		10.1007/3-540-64594-2_83	video compression picture types;three-dimensional space;computer vision;computer science;video tracking;multimedia;coding;texture;mpeg-4;statistics;multiview video coding;computer graphics (images)	Vision	60.942886960806504	-54.719197812644026	57002
48d4c78271864f3f3011f6d7381b4c1f707c77a4	a new approach of oil spill detection using time-resolved lif combined with parallel factors analysis for laser remote sensing	lasers;fluorescence;detection and identification technologies;oil spills;parafac;oil spill identification;time resolved fluorescence;laser remote sensing;factor analysis;remote sensing	In hope of developing a method for oil spill detection in laser remote sensing, a series of refined and crude oil samples were investigated using time-resolved fluorescence in conjunction with parallel factors analysis (PARAFAC). The time resolved emission spectra of those investigated samples were taken by a laser remote sensing system on a laboratory basis with a detection distance of 5 m. Based on the intensity-normalized spectra, both refined and crude oil samples were well classified without overlapping, by the approach of PARAFAC with four parallel factors. Principle component analysis (PCA) has also been operated as a comparison. It turned out that PCA operated well in classification of broad oil type categories, but with severe overlapping among the crude oil samples from different oil wells. Apart from the high correct identification rate, PARAFAC has also real-time capabilities, which is an obvious advantage especially in field applications. The obtained results suggested that the approach of time-resolved fluorescence combined with PARAFAC would be potentially applicable in oil spill field detection and identification.	categories;classification;fluorescence;low insertion force;petroleum pollution;principal component analysis;real-time clock;salicylic acid 20 mg/ml medicated liquid soap;sampling (signal processing);water wells	Deqing Liu;Xiaoning Luan;Jinjia Guo;Tingwei Cui;Jubai An;Ronger Zheng	2016		10.3390/s16091347	laser;fluorescence;engineering;analytical chemistry;environmental chemistry;optics;factor analysis;physics;time-resolved spectroscopy;remote sensing	Vision	78.18457551584973	-60.26635925601989	57109
bc8f0ea56764e8c54d79a4d1b0bda34f5c985fcc	a knowledge based approach for assessing debris cover dynamics and its linkages to glacier recession	vegetation mapping;glacier retreat debris cover glacier mapping;earth;remote sensing rocks knowledge based systems satellites vegetation mapping earth ice;remote sensing geophysical image processing glaciology image classification;remote sensing;satellites;debris cover dynamics glacier dynamics debris cover effect supraglacial debris cover ad 2014 lansat 8 operational land imager ad 1998 landsat thematic mapper ad 2003 aster ad 1999 landsat enhanced thematic mapper plus western himalayas upper indus basin glacier terrain hierarchical knowledge based classifier glacier recession;rocks;ice;knowledge based systems	This article focuses on the application of a hierarchical knowledge-based classifier (HKBC) to map the temporal changes in the debris cover together with other glacier terrain classes on a group of glaciers (16) located in Upper Indus Basin, Western Himalayas. The glacier terrain classes were mapped sequentially using HKBC on Landsat ETM+ 1999, ASTER 2003, Landsat TM 1998 and Lansat-8OLI 2014 images. A reduction of 16.1Km2 in the glaciated and ~ 9.1 Km of cumulative retreat had been accompanied by a secular increase in supraglacial debris cover by 13.57 Km2. This clearly suggests the profound influence of debris cover on glacier dynamics and linkages with shrinking of glaciers.	knowledge-based systems	Iram Ali;Aparna Shukla	2015	2015 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)	10.1109/IGARSS.2015.7326209	geomorphology;hydrology;knowledge-based systems;earth;physics;satellite;remote sensing	Robotics	81.56977804583998	-56.70905378847297	57254
994eb9eea028cceff482bcc14b9e342e39b5d4f6	spectral discrimination of vegetation classes in ice-free areas of antarctica	antarctica;field spectroscopy;classification;deschampsia antarctica;moss;hyperspectral imaging;lichen;species discrimination	Detailed monitoring of vegetation changes in ice-free areas of Antarctica is crucial to determine the effects of climate warming and increasing human presence in this vulnerable ecosystem. Remote sensing techniques are especially suitable in this distant and rough environment, with high spectral and spatial resolutions needed owing to the patchiness and similarity between vegetation elements. We analyze the reflectance spectra of the most representative vegetation elements in ice-free areas of Antarctica to assess the potential for discrimination. This research is aimed as a basis for future aircraft/satellite research for long-term vegetation monitoring. The study was conducted in the Barton Peninsula, King George Island. The reflectance of ground patches of different types of vegetation or bare ground (c. 0.25 m2, n = 30 patches per class) was recorded with a spectrophotometer measuring between 340 nm to 1025 nm at a resolution of 0.38 nm. We used Linear Discriminant Analysis (LDA) to classify the cover classes according to reflectance spectra, after reduction of the number of bands using Principal Component Analysis (PCA). The first five principal components explained an accumulated 99.4% of the total variance and were added to the discriminant function. The LDA classification resulted in c. 92% of cases correctly classified (a hit ratio 11.9 times greater than chance). The most important region for discrimination was the visible and near ultraviolet (UV), with the relative importance of spectral bands steeply decreasing in the Near Infra-Red (NIR) region. Our study shows the feasibility of discriminating among representative taxa of Antarctic vegetation using their spectral patterns in the near UV, visible and NIR. The results are encouraging for hyperspectral vegetation mapping in Antarctica, which could greatly facilitate monitoring vegetation changes in response to a changing environment, reducing the costs and environmental impacts of field surveys.	airborne ranger;baseline (configuration management);ecosystem;futures studies;height above ground level;hit (internet);image resolution;linear discriminant analysis;linear separability;principal component analysis;sensor;unmanned aerial vehicle	María Calvino-Cancela;Julio Martín-Herrero	2016	Remote Sensing	10.3390/rs8100856	meteorology;biological classification;hyperspectral imaging;lichen;ecology;remote sensing	HCI	81.65093343533393	-58.825576347590975	57481
2ce3342cb226b8e8583ab0d78770f0c023ce0926	use of multispectral aster images for mapping debris-covered glaciers within the glims project	image scanners;remote sensing glaciology ice image processing image scanners optical scanners;surface temperature;glacier surface temperature;italian alps;belvedere glacier;thermal band;image processing;energy balance modeling;optical scanners;multispectral terra aster image processing;glaciology;satellite borne optical scanner;glims project;field measurement;remote sensing;energy balance;debris covered black glacier mapping;satellite image;italy;global land ice monitoring from space;ice;satellites remote monitoring optical sensors fluctuations lakes civil engineering energy measurement ice surface land surface temperature temperature sensors;miage glacier;thermal band multispectral terra aster image processing debris covered black glacier mapping glims project global land ice monitoring from space satellite borne optical scanner belvedere glacier miage glacier italian alps italy energy balance modeling glacier surface temperature	The problem of mapping debris-covered glaciers using images derived from satellite-borne optical scanners is addressed in this paper. Results using also Terra-ASTER images on the Belvedere and Miage glaciers, both located in the Italian Alps, are presented. Field measurements and energy balance modeling indicate that for debris superimposed on ice, surface temperatures of some degrees colder than for pure, debris are to be expected in the morning. This fact is also confirmed by processing satellite images taking into account the thermal band. The results of black glacier detection can be useful for the project GLIMS (Global Land Ice Monitoring from Space) when debris-covered glaciers are to be mapped	image scanner;multispectral image	Roberto Ranzi;Giovanna Grossi;Laura Iacovelli;Stefan Taschner	2004	IGARSS 2004. 2004 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2004.1368616	geomorphology;glaciology;temperature;image processing;geology;hydrology;physics;remote sensing	Embedded	82.13017249623928	-61.696592876994785	57513
91da09846e7a3f19b542436fc07de0ae38633442	automatic detection of circular outlines in regional gravity and aeromagnetic data in the search for impact structure candidates	scandinavie;computadora;tratamiento datos;computers;europa;manuals;scandinavia;precambrien;feature detection;cratere impact;topographic maps;impact crater;noruega;carte topographique;ordinateur;champ potentiel;edge detection;search algorithm;direccion;gravity;data processing;traitement donnee;detection;potential field;topographic map;impact craters;algorithme;basamento;socle;precambrian;automatic detection;norway;direction;circularity;pixel;aeromagnetic;manual;algorithms;hough transform;manuel;norvege;europe;northern norway;norvege nord;finnmark;basement;noruega norte;plano topografico;algoritmo	A new automatic search algorithm based on circular data features has been applied to gravity and aeromagnetic regional data to detect impact structure candidates. Additionally, field investigations and laboratory analyses are needed to reach final conclusions. Compared to other Fennoscandian countries, the number of Norwegian impact structures is low such that the potential to find new ones should be high. This situation initiated the search for new impact structures in Finnmarksvidda (Northern Norway), an area of Precambrian basement rocks. Fresh impact craters are characterized by circular shapes, a pattern which also could be reflected in their geophysical potential fields. The presented algorithm calculates the amount of pixels in a given radius having a gradient direction towards a centre pixel. The algorithm differs from the commonly used circular Hough transform as it operates without an edge detection requirement. The algorithm detected a high number of features that were refined and reduced before field work by manual visual comparison to geologic and topographic maps. & 2010 Elsevier Ltd. All rights reserved.	edge detection;field research;gradient;hough transform;map;pixel;search algorithm;topography;visual comparison	Svein Olav Krøgli;Henning Dypvik	2010	Computers & Geosciences	10.1016/j.cageo.2009.07.010	topographic map;data processing;geology;computer science;impact crater;remote sensing	Vision	74.7766491650519	-57.76627050419799	57630
c4dad1305c634bd5f7e8d955c709f789cd5085ab	color persistent anisotropic diffusion of images	finite group;computer vision and robotics autonomous systems;perceptual image quality;partial differential equation;information science;color space;datorseende och robotik autonoma system;systemvetenskap;anisotropic diffusion;color image processing;color perception;local adaptation;euclidean geometry;diffusion process;non linear diffusion;color image	Techniques from the theory of partial differential equations are often used to design filter methods that are locally adapted to the image structure. These techniques are usually used in the investigation of gray-value images. The extension to color images is non-trivial, where the choice of an appropriate color space is crucial. The RGB color space is often used although it is known that the space of human color perception is best described in terms of non-euclidean geometry, which is fundamentally different from the structure of the RGB space. Instead of the standard RGB space, we use a simple color transformation based on the theory of finite groups. It is shown that this transformation reduces the color artifacts originating from the diffusion processes on RGB images. The developed algorithm is evaluated on a set of real-world images, and it is shown that our approach exhibits fewer color artifacts compared to state-of-the-art techniques. Also, our approach preserves details in the image for a larger number of iterations.	algorithm;anisotropic diffusion;color balance;color image;color space;color vision;composite artifact colors;image processing;iteration;nonlinear system;structural similarity	Freddie Åström;Michael Felsberg;Reiner Lenz	2011		10.1007/978-3-642-21227-7_25	color gradient;euclidean geometry;color histogram;computer vision;color quantization;hsl and hsv;3d lookup table;color image;information science;computer science;diffusion process;mathematics;geometry;color balance;color vision;color space;anisotropic diffusion;partial differential equation	Vision	55.1777474226965	-69.20255145573144	57648
8c537763bec9d703c8a94b64990d9be134c64d5d	evaluation of colour appearance models using transmissive media		 To predict colour appearance under a variety of viewing conditions like different luminance levels, backgrounds, light sources and surrounds  Used for achieving successful cross-media image reproduction  No. of models are developed by researchers e.g. Hunt94, CIECAM97s, CIECAM02 etc.  Relatively few experiments have been performed for testing these models Colour Appearance Model (CAM) X Y Z J, C, h etc Viewing conditions (X w Y w Z w , L w , Y b etc.) Project objectives  To collect new colour appearance data set for transmissive media under high luminance levels  To evaluate the performances of a number of existing colour appearance models by using the collected colour appearance data set  To test the ability of different colour appearance models to predict the colour appearance changes in varying luminance levels and background luminance factors	experiment;performance	Kiran Deshpande;Lindsay MacDonald	2006			computer science;computer vision;artificial intelligence	Vision	60.83056413963198	-61.615694195062034	57660
e17b6dea0659f9aeea2a268e1e214f965168642e	experimental low-terahertz radar image analysis for automotive terrain sensing	frequency 150 ghz experimental low terahertz radar image analysis automotive terrain sensing outdoor unstructured scenarios low thz single imaging radar sensor frequency modulated continuous wave radar on road scenario off road scenario fmcw radar stepped frequency radar frequency 30 ghz;azimuth;image resolution;roads;radar antennas;radar imaging;imaging;radar imaging roads radar antennas imaging azimuth image resolution;terahertz wave imaging cw radar fm radar millimetre wave imaging millimetre wave radar radar imaging road vehicle radar;low terahertz low thz imaging radar	In this letter, we report initial experimental results which provide the foundation for low-terahertz (low-THz) radar imagery for outdoor unstructured scenarios as expected in automotive sensing. The requirements and specifications for a low-THz single imaging radar sensor are briefly outlined. The imaging capabilities of frequency-modulated continuous-wave (FMCW) radar operating at 150 GHz are discussed. A comparison of experimental images of on-road and off- road scenarios made by a 150-GHz FMCW radar and a reference 30-GHz stepped-frequency radar is implemented, and their performance is analyzed.	autostereogram;feature detection (computer vision);feature detection (web development);feature extraction;frequency band;image analysis;image processing;modulation;radar;raw image format;requirement	Donya Jasteh;Edward G. Hoare;Mikhail Cherniakov;Marina Gashinova	2016	IEEE Geoscience and Remote Sensing Letters	10.1109/LGRS.2016.2518579	medical imaging;early-warning radar;man-portable radar;continuous-wave radar;space-based radar;radar engineering details;radar lock-on;image resolution;radar configurations and types;telecommunications;fire-control radar;radar horizon;bistatic radar;pulse-doppler radar;3d radar;azimuth;radar imaging;radar display;side looking airborne radar;physics;radar;remote sensing	Embedded	76.94976525527487	-65.33659432595316	57827
78bae2f10ba09166a05751c41f52386d0bcbf71a	hyper-spectral acquisition on historically accurate reconstructions of red organic lakes		Our cultural heritage is constituted by irreplacea bl artworks that must be known and preserved. Thei r study and documentation should be in principle carr ied out using non-invasive approaches. The technolo gical advances in spectroscopic imaging acquisition devic es made it possible to apply this methodology to su ch purpose. In this context, the present paper discusses a particu l ly challenging task within the conservation fiel d, which is the identification of red lake pigments in artworks, ap plying Vis-NIR hyper-spectral imaging spectroscopy. The latter was used to characterize and discriminate between h istorically accurate paint reconstructions of brazi lwood (vegetal) and cochineal (animal) lake pigments. The same pain ts were also analyzed with Fiber Optic Reflectance Spectroscopy to validate the data obtained with the imaging method. The requirements for a successful identification of these pigments are addressed, and future researc h is suggested in order to increase the usefulness of the technique’s application.	carr–benkler wager;documentation;passive optical network;requirement;tandy video information system	Tatiana Vitorino;Andrea Casini;Costanza Cucci;Maria João Melo;Marcello Picollo;Lorenzo Stefani	2014		10.1007/978-3-319-07998-1_29	artificial intelligence;computer vision;cochineal;brazilwood;computer science;imaging spectroscopy;cultural heritage;reflectivity	Robotics	71.79907517511187	-56.83080868307667	57957
5d87897135b6885629b71d9ae86e1c41e635f480	frequency and time domain measurements using cross well radar to develop testbeds for electromagnetic properties estimation	mesh plate dense nonaqueous phase liquid frequency domain measurement time domain measurement cross well radar electromagnetic property estimation reflection measurement transmission measurement bulk soil electromagnetic simulation helix antenna s parameter response air medium metal plate soilbed tank;sparameters measurements;helix antenna;electromagnetic wave propagation;soilbed;ground penetrating radar;soil electromagnetic wave propagation geophysical techniques ground penetrating radar helical antennas radar antennas;radar antennas;insertion loss;dnapl;cross well radar;soil;helix antenna dnapl electromagnetic wave propagation cross well radar sparameters measurements soilbed;helical antennas;geophysical techniques;time domain measurement;electromagnetic waves	This paper evaluates a technique to develop appropriate testbeds to take accurate reflection and transmission (s-parameters) measurements and provide accurate electromagnetic (EM) properties estimates of bulk soil using Cross Well Radar (CWR) technology. Frequency domain experimental measurements and electromagnetic simulations using helix antennas show inconsistencies in the s-parameters response, which suggests the use of time domain measurements of an air medium to verify the behavior of a medium with well-known EM properties. Time domain measurements results, and the inclusion of extended metal plates in the testbed confirm that energy was entering from top, bottom and edges of the soilbed tank, which was taken into account in the initial simplified analysis. Extended mesh plates reduces the amount of unwanted energy entering the soilbed tank, which lead to more accurate measurements and better estimates of the EM properties for bulk soil.	radar;scattering parameters;simulation;testbed	Jonathan Toro-Vazquez;Rafael A. Rodríguez-Solís;Ingrid Padilla	2011	2011 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2011.6049264	insertion loss;electromagnetic radiation;ground-penetrating radar;telecommunications;wave propagation;helical antenna;optics;physics;remote sensing	Embedded	82.90776252023677	-67.34948215298593	57976
6895350f9c3cac644bf0ad4eab57cb6ce901b59a	image completion with multi-image based on entropy reduction	sift;gist;image entropy;semantic matching;image completion;joint entropy	In this study, we present a new image completion method based on image entropy reduction. We complete the missing region with semantically matching images, which maximizes the reduction in the combined entropy of all regions in the image. We use labeled regions (high confidence regions) to complete the uncertain regions. By contrast, existing image completion methods focus on simple filling and ignore creative and semantic matching completion. Entropy reduction can yield higher accuracy of semantic image matching than existing image completion methods. We use Poisson blending and blending optimization (color handling) to complete the missing region with higher-quality results. The superiority of our method to existing image completion algorithms is validated. Experiments using an image database show that our method significantly improves the completion results.		Hao Wu;Zhenjiang Miao;Yi Wang;Jingyue Chen;Cong Ma;Tianyu Zhou	2015	Neurocomputing	10.1016/j.neucom.2014.12.088	computer vision;joint entropy;computer science;machine learning;pattern recognition;scale-invariant feature transform;mathematics;statistics	EDA	56.8784710642171	-60.776900455876785	57993
dfafb31393631966a6d66a0e12613e94dd21ac48	variational bayesian inference image restoration using a product of total variation-like image priors	variational approximation;belief networks;image features;image prior;bayesian inference;variational techniques;bayesian methods;variational bayesian;image restoration;imaging;variational bayesian inference;variational approximation variational bayesian inference image restoration total variation image prior;total variation;inference algorithms;approximation methods;tv;numerical experiment;variational techniques belief networks image restoration;image restoration bayesian methods approximation methods tv noise imaging inference algorithms;noise	In this paper a new image prior is introduced and used in image restoration. This prior is based on products of spatially weighted Total Variations (TV). These spatial weights provide this prior with the flexibility to better capture local image features than previous TV based priors. Bayesian inference is used for image restoration with this prior via the variational approximation. The proposed algorithm is fully automatic in the sense that all necessary parameters are estimated from the data. Numerical experiments are shown which demonstrate that image restoration based on this prior compares favorably with previous state-of-the-art restoration algorithms.	algorithm;approximation;calculus of variations;circuit restoration;experiment;image restoration;numerical linear algebra;variational principle	Giannis K. Chantas;Nikolas P. Galatsanos;Rafael Molina;Aggelos K. Katsaggelos	2010	2010 2nd International Workshop on Cognitive Information Processing	10.1109/CIP.2010.5604259	mathematical optimization;pattern recognition;mathematics;statistics	Vision	57.10655514021866	-71.3023795883012	58046
54a4eee5f715749222e642fcc7530190b51b92e4	microwave scattering behaviour analysis of typical targets with sar image	image analysis radar scattering polarization radar imaging spaceborne radar target recognition monitoring microwave measurements backscatter analytical models;targets;high resolution;sar microwave scattering typical targets;microwave scattering;typical targets;backscatter;scattering;vegetation backscatter electromagnetic wave scattering microwave propagation remote sensing synthetic aperture radar;microwaves;vegetation;electromagnetic wave scattering;sar;geology;remote sensing;sar image;radar target recognition;hj 1 c satellite microwave scattering behaviour synthetic aperture radar radarsat2 quadpolarimetric data mimics model michigan microwave canopy scattering model multiwave band full polarization backscattering simulation farmland forest x band sar image c band sar image target feature scattering properties;microwave propagation;synthetic aperture radar	As the high resolution radar satellite's has been successfully launched, its ability of the typical target's recognition monitor enhances a lot. This article mainly does analysis based on the RADARSAT2 quad-polarimetric data, compared scattering properties of typical target feature with two temporal full polarized data, and used the measured data to drive MIMICS (Michigan Microwave Canopy Scattering model) model and carry on the multi-wave band full polarization backscattering simulation about the farmland and forest. Then we carried on the comparison between X, C band SAR image gain's actual scattering value and simulation value in order to infer the typical target feature' scattering properties rule of S band. With anticipation of HJ-1-C satellite soon launched by China and then we can carrry on the comparison with the fact. Along with the full polarized data's development, the typical target feature's scattering properties analysis will be more perfect.	image resolution;microwave;motorola canopy;polarimetry;polarization (waves);radar;simulation	Xiaofang Li;Kun Li;Fengli Zhang;Yun Shao;Qulin Tan	2009	2009 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2009.5418196	meteorology;synthetic aperture radar;image resolution;microwave;specific absorption rate;optics;scattering;backscatter;physics;vegetation;remote sensing	Embedded	79.76525279502721	-63.791403614359275	58145
6cea84e17db631681ac13bfadb16db6b1668836d	lossy compression of high dynamic range images and video	ojo;compression algorithm;eye;color space;lossy compression;video compression;hombre;4266s;qualite image;information content;high dynamic range imaging;algorithme;lcds;computer programming;algorithm;codificacion;compression image;senal video;signal video;image compression;percepcion visual;display technology;transfer function;image quality;coding;human;dynamic range;perception visuelle;video signal;algorithms;visual perception;calidad imagen;high dynamic range;video;vision;oeil;codage;homme;algoritmo;compresion imagen	Most common image and video formats have been designed to work with existing output devices, like LCD or CRT monitors. As display technology makes progress, these formats no longer represent the data that new devices can display. Therefore a shift towards higher precision image and video formats is imminent. To overcome limitations of common image and video formats, such as JPEG, PNG or MPEG, we propose a novel color space, which can accommodate an extended dynamic range and guarantees the precision that is below the visibility threshold. The proposed color space, which is derived from contrast detection data, can represent the full range of luminance values and the complete color gamut that is visible to the human eye. We show that only minor changes are required to the existing encoding algorithms to accommodate the new color space and therefore greatly enhance information content of the visual data. We demonstrate this with two compression algorithms for High Dynamic Range (HDR) visual data: for static images and for video. We argue that the proposed HDR representation is a simple and universal way to encode visual data independent of the display or capture technology.	algorithm;cathode ray tube;color space;data compression;display device;encode;encoder;high dynamic range;high-dynamic-range rendering;human visual system model;jpeg;liquid-crystal display;lossy compression;moving picture experts group;output device;portable network graphics;self-information;video file format	Rafal Mantiuk;Karol Myszkowski;Hans-Peter Seidel	2006		10.1117/12.639140	data compression;computer vision;computer science;multimedia;computer graphics (images)	Graphics	62.27330325204262	-61.66260525007171	58184
a90edc200c8a57118995258430d1c91bfbc01aa9	quality assessment of stereoscopic images	signal image and speech processing;biometrics;quality assessment;pattern recognition;image processing and computer vision	Several metrics have been proposed in literature to assess the perceptual quality of two-dimensional images. However, no similar effort has been devoted to quality assessment of stereoscopic images. Therefore, in this paper, we review the different issues related to 3D visualization, and we propose a quality metric for the assessment of stereopairs using the fusion of 2D quality metrics and of the depth information. The proposed metric is evaluated using the SAMVIQ methodology for subjective assessment. Specifically, distortions deriving from coding are taken into account and the quality degradation of the stereopair is estimated by means of subjective tests.	distortion;elegant degradation;stereoscopy	Alexandre Benoit;Patrick Le Callet;Patrizio Campisi;Romain Cousseau	2008	EURASIP J. Image and Video Processing	10.1155/2008/659024	image quality;subjective video quality;computer vision;computer science;archaeology;pattern recognition;data mining;multimedia;biometrics	HCI	62.119338631785084	-63.975266258729434	58222
cfea9df87d5bee2f83d2feb54688ec029f4217a4	an improved mtfc restoration algorithm for remote sensing image	remote sensing image;mtfc;restoration;image restoration;satisfiability;adaptive algorithms;algorithm;modulation transfer function;image reconstruction;remote sensing;optimization;optimal algorithm	This paper proposes an improved modulation transfer function compensation restoration algorithm for remote sensing image based on inverse filtering, a traditional image restoration method. The improved algorithm is accomplished by optimizing the compensating curve shape and the compensating factor. The quality of resultant image is better than before and the quantitative results are satisfying. Moreover, the optimal algorithm is adaptive to various remote sensing images and it overcomes the limited adaptability of former work.	algorithm;circuit restoration;image restoration;inverse filter;modulation;resultant;transfer function	Yaqiong Chai;Zhongkui Feng;Dongkai Qi	2011		10.1145/1999320.1999353	computer vision;mathematical optimization;computer science;remote sensing	Vision	58.084759465146256	-65.24196276096016	58330
70e68d9a815920c8eb9bc6e25e83b2c8ed8a444a	large-scale color holographic display capable of steering view window	modulation three dimensional displays light sources laser beams image color analysis image reconstruction;spatial light modulators holographic displays object tracking;3d display holographic display computer holography color holography spatial light modulators;holographic stereogram steering view window pupil tracking technique optical fiber based large scale color holographic three dimensional display wide viewing angle display applications restrictive space bandwidth spatial light modulator motor control system;spatial light modulators;object tracking;holographic displays	We present optical fiber based large-scale color holographic three-dimensional display using a pupil tracking technique for wide viewing angle display applications. One of the limitations in implementing a large-scale holographic three-dimensional display is the restrictive space-bandwidth product of the spatial light modulator. In our proposed method, motor control system for steering optical fibers as a light guide and pupil tracking system are used to overcome the limitation of space-bandwidth product by steering the view window according to a position of the pupil of the observer. The proposed method employing the holographic stereogram in order to deliver two holographic patterns of different perspectives of a 3D scene to both eyes of the observer, which successfully provides both of the accommodation and binocular disparity.	binocular disparity;binocular vision;control system;holographic display;holographic principle;holography;modulation;optical fiber;spatial light modulator;stereoscopy;tracking system;viewing angle	Hyun-Eui Kim;Minsik Park;Byung Gyu Chae;Joonku Hahn;Hyun-Eui Kim;Cheong Hee Park;Kyungae Moon;Jinwoong Kim	2013	2013 International Conference on 3D Imaging	10.1109/IC3D.2013.6732083	computer vision;holographic interferometry;optics;holographic display;computer graphics (images)	Robotics	61.81397114924314	-55.61602098254507	58349
affee55f5185db0ab0f1837b19931c2ce520c1bb	consistent volumetric warping using floating boundaries for stereoscopic video retargeting	content aware media retargeting;stereo image processing shape optimization covariance matrices cameras spatiotemporal phenomena coherence;volumetric cropping consistent volumetric warping floating boundaries stereoscopic video retargeting content aware warping visually salient contents optimization technique dynamic frame cropping frame alignment unnatural object camera motions;mesh warping;optimization content aware media retargeting mesh warping cropping;shape;covariance matrices;stereo image processing;spatiotemporal phenomena;cropping;video signal processing image sensors stereo image processing;coherence;optimization;cameras	The key to content-aware warping and cropping is adapting data to fit displays with various aspect ratios while preserving visually salient contents. Most previous studies achieve this objective by cropping insignificant contents near frame boundaries and consistently resizing frames through an optimization technique with various preservation constraints and fixed boundary conditions. These strategies significantly improve retargeting quality. However, warping under fixed boundary conditions may bound/limit the preservation of visually salient contents. Moreover, dynamic frame cropping and frame alignment may result in unnatural object/camera motions. In this paper, a floating boundary with volumetric warping and object-aware cropping is proposed to address these problems. In the proposed scheme, visually salient objects in the space-time domain are deformed as rigidly and as consistently as possible using information from matched objects and content-aware boundary constraints. The content-aware boundary constraints can retain visually salient contents in a fixed region with a desired resolution and aspect ratio, called critical region, during warping. Volumetric cropping with the fixed critical region is then performed to adjust stereoscopic videos to the desired aspect ratios. The strategies of warping and cropping using floating boundaries and spatiotemporal constraints enable our method to consistently preserve the temporal motions and spatial shapes of visually salient volumetric objects in the left and right videos as much as possible, thus leading to good content-aware retargeting. In addition, by considering shape, motion, and disparity preservation, the proposed scheme can be applied to various media, including images, stereoscopic images, videos, and stereoscopic videos. Qualitative and quantitative analyses of stereoscopic videos with diverse camera and considerable motions demonstrate a clear superiority of the proposed method over related methods in terms of retargeting quality.	binocular disparity;case preservation;critical section;experiment;geo warping;mathematical optimization;retargeting;stereoscopy;volume	Shih-Syun Lin;Chao-Hung Lin;Yu-Hsuan Kuo;Tong-Yee Lee	2016	IEEE Transactions on Circuits and Systems for Video Technology	10.1109/TCSVT.2015.2409711	computer vision;coherence;shape;cropping;mathematics;multimedia;computer graphics (images)	Vision	58.979113975987225	-55.19265803028253	58358
ad7612f1a3bc17efa76e75513b758cff8ab5ba41	consistent calibration of virr reflective solar channels onboard fy-3a, fy-3b, and fy-3c using a multisite calibration method				Ling Wang;Xiuqing Hu;Lin Chen;Lingli He	2018	Remote Sensing	10.3390/rs10091336	computer vision;remote sensing;geology;calibration;artificial intelligence	Robotics	81.31653814934114	-63.355942956552596	58643
8ef16e5555a427eb083bed9a127d8bb25978ffd4	reconstruction by low cost software based on photogrammetry as a reverse engineering process		Among the various types of scanning that can be found on the market to perform a three-dimensional reconstruction, an alternative is highlighted due to its low cost and its ease of use, making it suitable for a great amount of applications. This is Image-based 3D Modeling and Rendering (IB3DMR), in which it is possible to generate a three-dimensional model from a set of 2D photographs. Among the existing commercial applications based on the IB3DMR, this communication has selected the Autodesk ReCap software, which is free and provides great features in terms of simplicity of operation, automation of the reconstruction process and possibility of exporting to other more complex applications. The use of this type of technologies based on photogrammetry is an alternative to the conventional reverse engineering processes, so a study with seven different pieces in terms of colour, geometry and texture has been performed for its assessment, obtaining three-dimensional reconstructions with very satisfactory results.	photogrammetry;reverse engineering	Dolores Parras;Francisco Cavas-Martínez;José Nieto;Francisco J. F. Cañavate;Daniel García Fernández-Pacheco	2018		10.1007/978-3-319-91581-4_11	rendering (computer graphics);3d reconstruction;image processing;photogrammetry;software;reverse engineering;computer vision;usability;3d modeling;computer science;artificial intelligence	SE	70.9719330791573	-55.94611397629069	58662
bb2ce697afeac20321502e359bdaa55a39b51630	image interpolation using adaptive fast b-spline filtering	filtering;spline;interpolation;image processing;computed tomography;adaptive zero order interpolation;image interpolation;directional edge information;image restoration;splines mathematics;moving average filter;image enhancement;moving average;adaptive filters;computational complexity;image reconstruction;image quality;statistics;adaptive fast b spline filtering;local image statistics;splines mathematics adaptive filters computational complexity image processing interpolation;b spline interpolation algorithm;magnification ratio;frequency;simplicity;spline interpolation;simplicity image interpolation adaptive fast b spline filtering b spline interpolation algorithm adaptive zero order interpolation directional edge information moving average filter local image statistics image quality magnification ratio;interpolation spline adaptive filters image restoration frequency filtering computed tomography statistics image reconstruction image enhancement	An adaptive version of a B-spline interpolation algorithm is proposed. Adaptivity is used in two different phases: (1) adaptive zero order interpolation is realized by considering directional edge information, and (2) adaptive length of the moving average filter in four directions is obtained by computing the local image statistics. The proposed algorithm exhibits significant improvements in image quality compared with the conventional B-spline type for algorithm, especially with high magnification ratio, such as four times or more. Another advantage of the proposed algorithm is its simplicity in both computation and implementations. >		Seong-Won Lee;Joonki Paik	1993		10.1109/ICASSP.1993.319776	demosaicing;computer vision;mathematical optimization;image processing;computer science;stairstep interpolation;mathematics;moving average;nearest-neighbor interpolation;multivariate interpolation;statistics;image scaling	Vision	56.03731236193632	-66.19313290499011	58778
ace1ade2b998675c5091a6dfbfd34a0e13635cd9	spatio-temporal photon density estimation using bilateral filtering	overblurring lighting detail;density estimation;local density;bilateral filtering;photon hit point;spatio-temporal domain andprovides control;bilateral filteringproves;spatio-temporal photon density estimation;traditionaldensity estimation technique;temporal domain;high-quality causticreconstruction;high-quality animation sequence;noise reduction;optical computing;noise;computer animation;image reconstruction;stochastic resonance;animation;filtering;global illumination;layout;lighting;ray tracing;surface reconstruction;level of detail;stochastic processes;photons	Photon tracing and density estimation are well established techniques in global illumination computation and rendering of high-quality animation sequences. Using traditional density estimation techniques it is difficult to remove stochastic noise inherent for photon-based methods while avoiding overblurring lighting details. In this paper we investigate the use of bilateral filtering for lighting reconstruction based on the local density of photon hit points. Bilateral filtering is applied in spatio-temporal domain and provides control over the level-of-details in reconstructed lighting. All changes of lighting below this level are treated as stochastic noise and are suppressed. Bilateral filtering proves to be efficient in preserving sharp features in lighting which is in particular important for high-quality caustic reconstruction. Also, flickering between subsequent animation frames is substantially reduced due to extending bilateral filtering into temporal domain	algorithm;autodesk 3ds max;bilateral filter;computation;computer graphics international;global illumination;plug-in (computing)	Markus Weber;Marco Milch;Karol Myszkowski;Kirill Dmitriev;Przemyslaw Rokita;Hans-Peter Seidel	2004	Proceedings Computer Graphics International, 2004.	10.1109/CGI.2004.1309200	iterative reconstruction;filter;layout;anime;stochastic process;ray tracing;computer vision;density estimation;surface reconstruction;computer science;noise;level of detail;photon;noise reduction;lighting;computer animation;optical computing;bilateral filter;global illumination;stochastic resonance;computer graphics (images)	Visualization	64.10446645631086	-52.43239824171807	58959
b5aad88bbfaca1a824f9620206ec01d90dd333bd	sparsity-driven despeckling for sar images	speckle;synthetic aperture radar jacobian matrices tv speckle image edge detection cost function;cost function;real world sar images sparsity driven despeckling speckle noise synthetic aperture radar images sar image processing tasks edge detection speckle reduction preprocessing step smoothing homogeneous regions sparsity driven total variation approach;image edge detection;total variation tv fractional norm l_ 0 norm l_ 1 norm speckle reduction synthetic aperture radar sar;tv;jacobian matrices;synthetic aperture radar geophysical image processing image segmentation;synthetic aperture radar	Speckle noise inherent in synthetic aperture radar (SAR) images seriously affects the result of various SAR image processing tasks such as edge detection and segmentation. Thus, speckle reduction is critical and is used as a preprocessing step for smoothing homogeneous regions while preserving features such as edges and point scatterers. Although state-of-the-art methods provide better despeckling compared with conventional methods, their resource consumption is higher. In this letter, a sparsity-driven total-variation (TV) approach employing l0-norm, fractional norm, or l1-norm to smooth homogeneous regions with minimal degradation in edges and point scatterers is proposed. Proposed method, sparsity-driven despeckling (SDD), is capable of using different norms controlled by a single parameter and provides better or similar despeckling compared with the state-of-the-art methods with shorter execution times. Despeckling performance and execution time of the SDD are shown using synthetic and real-world SAR images.	aperture (software);calculus of variations;edge detection;elegant degradation;image processing;loss function;noise reduction;numerical analysis;openmp;preprocessor;run time (program lifecycle phase);sensor;smoothing;sparse matrix;synthetic data;taxicab geometry	Caner Ozcan;Baha Sen;Fatih Nar	2016	IEEE Geoscience and Remote Sensing Letters	10.1109/LGRS.2015.2499445	speckle pattern;speckle noise;computer vision;synthetic aperture radar;geology;optics;inverse synthetic aperture radar;physics;remote sensing	Vision	71.31516629197066	-66.49903254572713	59035
b822cc9f02b4f834093259750f1c71f52f2ac78f	filter design based on the theory of the generalized morphological filter with omnidirectional structuring element	priority first strategy;region based image fusion;generalized morphology filter;high frequency detail;region priorities;image segmentation;non linear filtering;image processing;median filter;negative impulse noise;image resolution;non linear filter;close opening filter;size structure;impulse noise;image fusion;multiresolution image fusion;positive impulse noise;signal denoising filtering theory median filters;pixel based fusion methods;open closing filter;structuring element;filter design;simulation experiment;side effect;linear mapping methods;theoretical analysis;positive impulse noise filter design generalized morphological filter omnidirectional structuring element open closing filter close opening filter negative impulse noise;background subtraction;image fusion image segmentation discrete wavelet transforms image sensors sensor fusion space technology nonlinear distortion principal component analysis signal processing infrared image sensors;source images;filtering theory morphology image processing gaussian noise signal processing algorithms digital filters information filtering information filters image analysis adaptive filters;omnidirectional;fusion rule;high frequency detail non linear filter median filter generalized morphology filter omnidirectional structuring element;generalized morphological filter;image segmentation image fusion image resolution;multi resolution;omnidirectional structuring element;high frequency;pixel based fusion methods region based image fusion region priorities multiresolution image fusion source images background subtraction image segmentation priority first strategy linear mapping methods;filtering theory;median filters;signal denoising	The close-opening or open-closing filter based on the morphological filters with the same size structuring element cannot remove all the positive or negative impulse noise effectively. To improve the performance of these two kinds of filter, the generalized close- opening and open-closing filter based on the morphological filter with the different size structuring element are put forward. Based on the generalized morphological filter, this paper suggests a kind of designing project of the filter that applies a new structuring element to the generalized morphological filter. The theoretical analysis and the simulation experiments of the image processing indicate that this kind of filter can not only remove noise effectively but also keep the details of the image sufficiently.	closing (morphology);experiment;filter design;image processing;impulse noise (audio);mathematical morphology;simulation;structuring element	Xiangguang Zhang;Yun Liu;Chuanxu Wang	2007	Eighth ACIS International Conference on Software Engineering, Artificial Intelligence, Networking, and Parallel/Distributed Computing (SNPD 2007)	10.1109/SNPD.2007.443	median filter;omnidirectional antenna;computer vision;image resolution;background subtraction;image processing;impulse noise;computer science;high frequency;pattern recognition;image segmentation;filter design;image fusion;structuring element;side effect	Robotics	55.52564451107699	-66.73613106288904	59038
3dd559790bfb1b89329b83037a0044715644bc68	statistical characteristics of portal images and their influence in noise reduction		Portal imaging is used in radiotherapy to asses the correct positioning of the patient before applying the treatment. Given the high energy particles used in portal image formation, portal image is intrin- sically bound by low contrast and poor spatial resolution. The relevance of portal imaging in radiotherapy treatments and its common use justify efforts to improve its inherent low quality. The knowledge of the statistical properties of both image and noise is essential in order to develop suitable processing algorithms to clean the image. The aim of this paper is to show how the statistical characteristics of the portal images and noise images generated in one of the portal imaging systems most widely deployed, can be exploited to improve the quality of noisy portal images through efficient denoising methods. An ensemble of portal images is used to investigate their statistical characteristics. In the case of noise, a process of averaging and subtrac- tion of the mean is used to extract noise images. The distribution found for the noise is clearly Gaussian, in both the spatial and the wavelet domain. The curves for the noise show a parabolic shape in the semi-log graphs across the different scales, which translates into Gaussian character in the transformed domain. On the other hand, the probability density functions (pdf's) for portal images show large tails. Wavelet thresholding takes advantage of the different statistical fea- tures found for noise and signal. In the present work wavelet thresholding is compared to Wiener filtering, and the assesment of the denoised image is carried out by means of the peak signal to noise ratio PSNR and the structural similarity index SSMI. Thresholding the wavelet coefficients of the noisy image gives better denoising results for both figures of merit (PSNR and SSIM) than the Wiener filter in all the analysed cases. Furthermore, the differences be- tween the methods increase as the noise increases. abstract environment.	noise reduction	Antonio González-López;María Consuelo Bastida Jumilla;Jorge Larrey-Ruiz;Juan Morales-Sánchez	2013		10.1007/978-3-642-38637-4_40	gaussian noise;computer vision;simulation;speech recognition;noise measurement	HPC	55.902017409401715	-79.02406563952083	59053
7f040fbf24eded0c1dec8503131ed639f4be138a	scientific use of terrasar-x	artificial satellites;image sensors;remote sensing by radar;synthetic aperture radar;terrain mapping;ad 2006 04;ao;astrium gmbh;dlr;german radar satellite;scansar-mode;spotlight mode;stripmap mode;terrasar-x;announcement of opportunity;commercial exploitation rights;dual polarization imaging;high frequency x-band sar sensor;high resolution sar image;operational sar-system;quad polarization imaging;satellite tasking time;scientific application;scientific use;single polarization imaging;terrain mapping	"""TerraSAR-X is a new German radar satellite to be launched in April 2006. The expected lifetime is 5 years. It carries a high frequency X-band SAR sensor that can be operated in different modes and polarization. The Spotlight-, Stripmap- and ScanSAR-modes provide high resolution SAR images for detailed analysis as well as wide swath data whenever a larger coverage is required. Imaging is possible in single, dual and quad-polarization. TerraSAR-X is an operational SAR-system for scientific and commercial applications that equally shares the satellite tasking time. DLR is responsible for the scientific use while the Astrium GmbH has the exclusive commercial exploitation rights. The status """"scientific use"""" needs to be gained via a selection process. An announcement of opportunity (AO) is to be released one year before the launch. TerraSAR-X data can be provided for the costs of fulfilling the user request"""	dynamic language runtime;image resolution;polarization (waves);radar	Achim Roth	2004	IGARSS 2004. 2004 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2004.1370658	meteorology;polarization;physics;satellite;remote sensing	Embedded	79.74738574900584	-63.41676118159642	59062
b963253438ef2c05545bea368c4e835756662755	a pixel value restoration considerng line stucture for impulse noise removal	image restoration;median filter pixel value restoration impulse noise removal;median filters image denoising image restoration;image denoising;bridges noise;median filters	In this paper, a pixel value restoration method for images corrupted by impulse noise is proposed. For example, the median filter is a well-known solution for impulse noise removal. However, it cannot process well at line structures in images. We therefore propose an effective method in the view point of line structure restoration. The proposed method considers line structures in four angles. The key point of the method is to consider the two adjacent lines of the line which pass through the target pixel.	circuit restoration;color;effective method;emoticon;ibm thinkpad 310;impulse noise (audio);median filter;pixel	Yi Ru;Shi Bao;Go Tanaka	2013	2013 International Symposium on Intelligent Signal Processing and Communication Systems	10.1109/ISPACS.2013.6704566	median filter;image restoration;computer vision;electronic engineering;engineering;salt-and-pepper noise;computer graphics (images)	Robotics	56.49083939776848	-65.17081440891437	59098
458b64fcbcfbf45c1352a3bafa69b2018ad5ea27	image enhancement under data-dependent multiplicative gamma noise		An edge enhancement filter is proposed for denoising and enhancing images corrupted with data-dependent noise which is observed to follow a Gamma distribution. The filter is equipped with three terms designed to perform three different tasks. The first term is an anisotropic diffusion term which is derived from a locally adaptive p-laplacian functional. The second term is an enhancement term or a shock term which imparts a shock effect at the edge points making them sharp. The third term is a reactive term which is derived based on the maximum a posteriori (MAP) estimator and this term helps the diffusive term to perform aGamma distributive data-dependentmultiplicative noise removal from images. Andmoreover, this reactive term ensures that deviation of the restored image from the original one is minimum. This proposed filter is compared with the state-of-the-art restoration models proposed for data-dependent multiplicative noise.	anisotropic diffusion;circuit restoration;convex function;data dependency;edge enhancement;experiment;gaussian blur;image editing;multiplicative noise;noise reduction;nonlinear system	Jidesh Pacheeripadikkal;Bini Anattu	2014	Applied Comp. Int. Soft Computing	10.1155/2014/981932	speech recognition;machine learning	Vision	55.30027123067079	-69.79120278268749	59110
3ef1761e31ed05530b6b4aa18d5a26556d2af881	aks method: a new image compression by gradient haar wavelet		With the development of human communications the usage of Visual Communications has also increased. The advancement of image compression methods is one of the main reasons for the enhancement. This paper first presents the main modes of image compression methods such as JPEG and JPEG2000 without mathematical details. Also, the paper describes gradient Haar wavelet transforms in order to construct a preliminary image compression algorithm. Then, a new image compression (AKS) method is proposed based on the preliminary image compression algorithm that can improve standards of image compression. The AKS method is compared with original modes of JPEG and JPEG2000 by image quality measures such as MAE, PSNAR, and SSIM. The image quality and statistical results confirm that can boost image compression standards. It is suggested that the AKS method is used in a part or all of an image compression standard.	algorithm;gradient;haar wavelet;image compression;image quality;jpeg 2000;structural similarity;wavelet transform	Yaser Sadra	2017	CoRR		discrete wavelet transform	Vision	60.8105406211392	-65.86864426828778	59258
dc885a1fdf0fedcbf80dffba5da9a8c6ed2e6a1e	preliminary study of uas equipped with thermal camera for volcanic geothermal monitoring in taiwan	post-processed kinematic (ppk);thermal camera;unmanned aircraft system (uas);volcanic geothermal monitoring	Thermal infrared cameras sense the temperature information of sensed scenes. With the development of UASs (Unmanned Aircraft Systems), thermal infrared cameras can now be carried on a quadcopter UAV (Unmanned Aircraft Vehicle) to appropriately collect high-resolution thermal images for volcanic geothermal monitoring in a local area. Therefore, the quadcopter UAS used to acquire thermal images for volcanic geothermal monitoring has been developed in Taiwan as part of this study to overcome the difficult terrain with highly variable topography and extreme environmental conditions. An XM6 thermal infrared camera was employed in this thermal image collection system. The Trimble BD970 GNSS (Global Navigation Satellite System) OEM (Original Equipment Manufacturer) board was also carried on the quadcopter UAV to gather dual-frequency GNSS observations in order to determine the flying trajectory data by using the Post-Processed Kinematic (PPK) technique; this will be used to establish the position and orientation of collected thermal images with less ground control points (GCPs). The digital surface model (DSM) and thermal orthoimages were then produced from collected thermal images. Tests conducted in the Hsiaoyukeng area of Taiwan's Yangmingshan National Park show that the difference between produced DSM and airborne LIDAR (Light Detection and Ranging) data are about 37% between -1 m and 1 m, and 66% between -2 m and 2 m in the area surrounded by GCPs. As the accuracy of thermal orthoimages is about 1.78 m, it is deemed sufficient for volcanic geothermal monitoring. In addition, the thermal orthoimages show some phenomena not only more globally than do the traditional methods for volcanic geothermal monitoring, but they also show that the developed system can be further employed in Taiwan in the future.	aerial photography;airborne ranger;antenna device component;assisted gps;checking (action);circa;data logger;digital elevation model;dual;gjb2 wt allele;galileo (satellite navigation);global positioning system;gray platelet syndrome;hl7publishingsubsection <operations>;handheld game console;heart rupture, post-infarction;image resolution;norm (social);orthophoto;recorder device component;satellite navigation;topography;unmanned aerial vehicle;yaws	Shih-Hong Chio;Cheng-Horng Lin	2017		10.3390/s17071649	infrared;terrain;remote sensing;engineering;thermal;ranging;lidar;quadcopter;gnss applications;geothermal gradient	HCI	78.26318252945754	-56.18393249044083	59284
70d03a17ec38d9970917817e771e55aca19979be	sensor on-orbit calibration and characterization using spacecraft maneuvers	thermal emissive bands;bidirectional reflectance factor;sensor phenomena and characterization calibration space vehicles modis moon radiometry nasa bidirectional control sensor systems space technology;spacecraft maneuvers;sensor calibration;radiometric stability;space vehicles aerospace instrumentation calibration image sensors;image sensors;lunar observations;characterization spacecraft maneuver modis sensor calibration;sensor;lessons learned;maneuver;solar diffuser;reflective solar bands;characterization;modis;spacecraft design sensor on orbit calibration spacecraft maneuvers modis lunar observations reflective solar bands radiometric stability solar diffuser bidirectional reflectance factor sd screen vignetting function deep space observations thermal emissive bands;deep space observations;calibration;spacecraft;aerospace instrumentation;space vehicles;spacecraft design;sensor on orbit calibration;sd screen vignetting function	Sensor observations made during carefully scheduled spacecraft (S/C) maneuvers, such as pitch, yaw, and roll maneuvers, can be used to support its on-board calibrators (OBC) or to perform independent sensor calibration and characterization. Using MODIS as an example, this paper illustrates applications of various S/C maneuvers, including lunar observations via S/C roll maneuvers to track MODIS reflective solar bands (RSB) radiometric stability, solar observations via S/C yaw maneuvers to map its on-board solar diffuser (SD) bidirectional reflectance factor (BRF) and to derive the SD screen vignetting function, and deep space observations via S/C pitch maneuvers to characterize its thermal emissive bands (TEB) response versus scan angle (RVS). Experiences and lessons learned from these applications will provide valuable information and reference for future sensor as well as spacecraft design.	aqua;on-board data handling;sensor;spacecraft design;tebibyte;yaws	Xiaoxiong Xiong;Jim Butler;William Barnes;Bruce Guenther	2007	2007 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2007.4423289	calibration;geodesy;sensor;image sensor;spacecraft;optics;spacecraft design;physics;remote sensing	Embedded	81.76094657223787	-63.67599949679923	59293
3e7157479eef915e806046a135e23fda8e57b19a	preliminary results of satellite radar differential interferometry for the co-seismic deformation of the 12 may 2008 ms8.0 wenchuan earthquake	advanced land observing satellite;sar interferometry;co seismic deformation;sar;sichuan earthquake;alos palsar	1082-4006/08/14(01)-12$5.00 ©2008 The International Association of Chinese Professionals in Geographic Information Science (CPGIS) Abstract Satellite differential SAR interferometry has been widely accepted as a powerful tool to map co-, postand inter-seismic deformation since its successful application to the 1992 Landers Earthquake. As soon as the Ms8.0 Wenchuan Earthquake occurred on 12 May 2008 in the Sichuan Province of southwestern China, the Japan Aerospace Exploration Agency tasked its Advanced Land Observing Satellite (ALOS) to respond to the disaster by collecting images. This paper presents the preliminary DInSAR results of co-seismic deformation of the quake observed from two satellite paths of the onboard ALOS/PALSAR sensor with post-seismic images acquired on 19 and 24 May. Results from pixel offset analysis and difference of coherence will also be discussed. The radar mapping is still ongoing because the ruptured seismic fault is more than 300km in length. Each swath of the PALSAR fine beam covers only about a 75km segment of the fault, and it takes 46 days for ALOS to revisit the same site.	geographic information science;pixel;quake engine;radar	Linlin Ge;Kui Zhang;Alex Hayman Ng;Yusen Dong;Hsing-chung Chang;Chris Rizos	2008	Annals of GIS	10.1080/10824000809480634	seismology;geography;geodesy;specific absorption rate;remote sensing	Robotics	81.28123322030582	-60.90843852249129	59366
710785040570021b0a998341d2a6d6c7f990e48c	leaf marker spectra identification by hyperspectral image acquisition and vertex component analysis	biology computing;image processing;hyperspectral imaging pigments vectors indexes vegetation mapping cameras;matrix inversion;pigments biology computing hyperspectral imaging image processing matrix inversion;pigments;leaf marker spectra identification biological systems hyperspectral image processing hyperspectral image acquisition setup algebraic method vertex component analysis input spectra matrix inversion leaf image pigment repartition pigment concentration estimation reflectance index;hyperspectral imaging;spectrum remote sensing hyperspectral imaging linear algebra feature extraction	To monitor biological systems, aside destructive testing which have been developed in chemistry and chromatography, hyperspectral image acquisition and processing exhibit the great advantage of being non-destructive. In this paper, a hyperspectral image acquisition setup is proposed, to get detailed information on the reflectance of leaves. We aim at giving information about the repartition of pigments on a leaf, by proposing a hyperspectral image acquisition setup, and adapting an algebraic method, vertex component analysis, which selects, among a set of input spectra, the marker spectra which best yield all input spectra by linear combination. A matrix inversion yields the contribution of the marker spectra for any spectrum. We acquired the image of leaves and estimated pigment concentrations with the help of a reflectance index.	biological system;pigment	Julien Marot;Salah Bourennane	2013	European Workshop on Visual Information Processing (EUVIP)		full spectral imaging;computer vision;geography;chemical imaging;optics;remote sensing	Vision	70.75848320036839	-63.51810909478527	59402
0da970208593149dbeeb76c428e856c078b51382	prelaunch calibration of microwave humidity sounder on china's fy-3a meteorological satellite	meteorological instruments;second generation polar orbiting meteorological satellite;radiometric resolution;instruments;fy 3a;thermal vacuum t v test;microwave humidity sounder;china feng yun 3a meteorological satellite;thermal vacuum chamber;earth;data processing;atmospheric humidity;microwave radiometry;feng yun 3a fy 3a meteorological satellite;radiometry;calibration bias;microwave humidity sounder mwhs;remote sensing atmospheric humidity calibration meteorological instruments microwave measurement radiometry;prelaunch calibration;microwave measurement;remote sensing;thermal vacuum t v test calibration feng yun 3a fy 3a meteorological satellite microwave humidity sounder mwhs millimeter wave;receiver nonlinearity;millimeter wave;temperature measurement;microwave theory and techniques;calibration humidity meteorology satellite broadcasting testing payloads thermal conductivity atmospheric modeling microwave radiometry instruments;calibration;calibration bias prelaunch calibration china feng yun 3a meteorological satellite second generation polar orbiting meteorological satellite microwave humidity sounder thermal vacuum chamber fy 3a data processing radiometric resolution receiver nonlinearity	China's Feng Yun-3A (FY-3A) meteorological satellite is a second-generation polar-orbiting meteorological satellite launched in May 2008. The Microwave Humidity Sounder (MWHS) is the main payload, designed for atmospheric humidity sounding. Before the launch of MWHS, a series of experiments was conducted in a thermal/vacuum (T/V) chamber. This letter describes the MWHS T/V calibration, in which the flight model currently operating on FY-3A was tested. The calibration procedure and data-processing methods are presented. Calibration results, such as radiometric resolution, receiver nonlinearity, and calibration bias, were obtained. The results meet the specifications on bias and sensitivity of MWHS. Since the instrument temperatures will be approximately 10°C-20°C on orbit, the calibration errors of MWHS over the range of 100-300 K would be less than 0.3 K using the nonlinearity coefficients derived in the T/V test.	automatic sounding;coefficient;erewhon;experiment;metric;microwave;nonlinear system;parametric model	Zhenzhan Wang;Jing Li;Shengwei Zhang;Yun Li	2011	IEEE Geoscience and Remote Sensing Letters	10.1109/LGRS.2010.2050676	meteorology;calibration;radiometry;atmospheric sciences;data processing;temperature measurement;extremely high frequency;earth;physics;remote sensing	Robotics	82.02542868834868	-64.4631603270213	59433
37a5102fdadc2ce6d8afdeef7645f7f9f36a9b58	an interpolation-based data fusion scheme for enhancing the resolution of thermal image sequences	batch sharpening strategy interpolation based data fusion scheme thermal image sequences image resolution enhancement spatial resolution acquisition rate remotely sensed data fusion temporal resolution data sequence;spatial resolution silicon remote sensing bayes methods smoothing methods data integration;bayesian smoothing irrigation management thermal sharpening multitemporal analysis multisensor data fusion;remote sensing geophysical image processing image enhancement image fusion image resolution image sequences interpolation	In several human activities, such as agriculture and forest management, the monitoring of radiometric surface temperature is key. In particular both high spatial resolution and high acquisition rate are desirable but, due to the hardware limitations, these two characteristics are not met by the same sensor. The fusion of remotely sensed data acquired by sensors with different spatial and temporal resolution is a profitable choice to face this issue. When the real-time requirement is relaxed, the data sequence can be processed as a whole, allowing to improve the final result. Within this framework, we propose a novel batch sharpening strategy, relying on interpolation, data fusion and Bayesian smoothing techniques, and we assess its effectiveness on SEVIRI and MODIS thermal data.	image resolution;interpolation;real-time clock;sensor;smoothing	Paolo Addesso;Maurizio Longo;Rocco Restaino;Gemine Vivone;Antonino Maltese	2014	2014 IEEE Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2014.6947600	computer vision;pattern recognition;image fusion;sub-pixel resolution;remote sensing	Robotics	77.71329328313078	-56.72015653300499	59487
45a4f5c0fd5b653caedf8b3cf52f27354dcbb390	matting through variational inpainting	matting;natural images;geometric feature;variational inpainting	While current matting algorithms work very well for some natural images, their performance is questionable in the presence of sharp discontinuities in the foreground and background regions. To counter the above problem, we propose to use variational PDE based inpaintingtechniques within the matting problem, that are largely successful in inpainting geometric features into unknown regions.	algorithm;calculus of variations;ibm notes;inpainting;iteration;iterative method;solver;variational principle	Kangyu Ni;Sheshadri R. Thiruvenkadam;Tony F. Chan	2007			computer vision;pattern recognition;computer graphics (images)	Vision	54.99924517796657	-70.27097344651996	59508
84268f8ef0b987844541c272aed5484eb866465d	developing a computer vision method based on ahp and feature ranking for ores type detection	analytic hierarchy process;image processing;multi criteria decision making;artificial neural networks	Detection of size, shape and color of minerals are important for obtaining information about minerals. The output of mines is ores which vary in colors and shapes. The multiplicity of ores, large scale features and the importance of speeding up the mineral type detection process for intelligent systems, leads us to rely more on expert’s advice and rank the selected available features for type detection, according to their importance. In this paper, to separate different ores and gangue minerals, image processing and computer vision techniques with combination of multi criteria decision making (MCDM) approach are applied. Our method proposes a novel way which combines the image processing techniques and artificial neural nalytic hierarchy process mage processing rtificial neural networks networks, with analytic hierarchy process (AHP) approaches to detect different types of ores. By help of experts in feature ranking, the image processing techniques proved to be more effective and prompt. The final results show that the proposed method is more successful in type detection of minerals than the other image processing techniques for ores type detection. Our method is also applicable for real-time systems to estimate minerals at on-line ore sorting and classification stages. © 2016 Elsevier B.V. All rights reserved. 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 . Introduction In the science and engineering of geology, mineral particles are mportant elements for analysis to obtain quantitative informaion about particle size, shape and color from minerals [1]. With he development of technology, image processing methods are roved to be very useful in many disciplines as standard measureent and evaluation method. Fast taking of images, detection of olor and physical size over image, advantage of analysis in short ime made image processing methods superior over conventional nalysis methods [2]. Moreover, using machine learning and data ining methods, such as artificial neural networks proved to be ore effective for new intelligent systems performance which are sing image processing techniques [3]. In mining, the classificaion of the ores plays an important role, in equipment selection or excavation, for data analysis and planning for the rest of mining rocess [4]. The data extracted from mineral type detection systems Please cite this article in press as: M. Ebrahimi, et al., Developing a com type detection, Appl. Soft Comput. J. (2016), http://dx.doi.org/10.1016 re useful for understanding the local properties of the ore deposit hat determine the mine design. Knowing rock types is important n determining various process parameters such as grindability, ∗ Corresponding author. E-mail addresses: mo.ebrahimi@ut.ac.ir (M. Ebrahimi), m.abdolshah@ut.ac.ir M. Abdolshah), saeed.abdolshah@studenti.unipd.it (S. abdolshah). ttp://dx.doi.org/10.1016/j.asoc.2016.08.027 568-4946/© 2016 Elsevier B.V. All rights reserved. 57 58 59 60 slurry viscosity, and screening efficiency, among others [5]. Designing intelligent systems for type detection of the ores in the mines, not only will improve the mentioned factors, but it prevents from huge mineral waste. According to EU (European Union) in 2012, the total waste generated in the EU − 28 by all economic activities and households amounted to 2514 million tonnes; this was slightly higher than in 2010 and 2008 (2460 million tonnes and 2427 million tonnes) but lower than in 2004 (2565 million tonnes). Mine wastes require sensitive removal procedures to ensure the long-term stability of storage and disposal facilities, and also to prevent from air, water, and soil pollution [2]. The inappropriate or unsafe management of wastes at mining operations continues to serious environmental problems and has contributed to the negative public perception of the mining industry. Literature review shows that usually, rock classification or characterization is performed visually by geologists [6]. Nowadays, a more sophisticated method for ores identification and grading is done by collecting samples of ores to train an intelligent system for automatic type detection. There are other methods which are using the chemical analysis of ores to train the intelligent classifier systems for type detection. However because of the time needed for the chemical puter vision method based on AHP and feature ranking for ores /j.asoc.2016.08.027 analysis, it is not possible to perform it on-line [7]. Therefore, a faster sensing system is desirable to achieve on-line estimation of ores composition. This could be possible with a machine vision system since visual classification of rocks is carried out by humans. 61 62 63 64 ARTICLE IN PRESS G Model ASOC 3769 1–10 2 M. Ebrahimi et al. / Applied Soft Computing xxx (2016) xxx–xxx Table 1 Some applications of image processing and intelligent systems in mining engineering area. Paper Method Features Ranking No. types [1] Image processing and neural networks visual – 6 [8] Spatial frequency measurement and neural network chemical – 26 [9] Wavelet and curvelet transforms visual – 6 [10] Artificial neural network and support vector machines mixed – 2 [11] Wavelet texture analysis visual – – [12] Optimization and genetic algorithm visual – 7 [7] Textural analysis and image processing visual – – [3] textural analysis and pattern recognition chemical – 6 [13] Image and texture analysis visual – 4 T a t m t o ( s m b o m t e m r e a i d e i e o m d v t v m i a o e a a D i o r o f r p e c A b s m u 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93	alsa;algorithmic efficiency;analytical hierarchy;artificial intelligence;artificial neural network;co-occurrence matrix;color;computer vision;curvelet;genetic algorithm;image processing;machine learning;machine vision;online and offline;pattern recognition;real-time clock;real-time computing;soft computing;sorting;support vector machine;television;wavelet	Morteza Ebrahimi;Majid Abdolshah;Saeed Abdolshah	2016	Appl. Soft Comput.	10.1016/j.asoc.2016.08.027	analytic hierarchy process;image processing;computer science;artificial intelligence;machine learning;data mining;artificial neural network	AI	73.75457873448765	-57.77795368955955	59641
95249f6e5d5e1b25d307db6e82e224e09beb5775	learning to dodge a bullet: concyclic view morphing via deep learning		The bullet-time effect, presented in feature film “The Matrix”, has been widely adopted in feature films and TV commercials to create an amazing stopping-time illusion. Producing such visual effects, however, typically requires using a large number of cameras/images surrounding the subject. In this paper, we present a learning-based solution that is capable of producing the bullet-time effect from only a small set of images. Specifically, we present a view morphing framework that can synthesize smooth and realistic transitions along a circular view path using as few as three reference images. We apply a novel cyclic rectification technique to align the reference images onto a common circle and then feed the rectified results into a deep network to predict its motion field and per-pixel visibility for new view interpolation. Comprehensive experiments on synthetic and real data show that our new framework outperforms the state-of-the-art and provides an inexpensive and practical solution for producing the bullet-time effects.	align (company);background subtraction;deep learning;display resolution;experiment;image rectification;interpolation;lambertian reflectance;morphing;motion field;pixel;rendering (computer graphics);specular highlight;synthetic data;the matrix;visual effects	Shi Jin;Margo Rivera;Yu Ji;Jinwei Ye;Jingyi Yu	2018		10.1007/978-3-030-01264-9_14	rectification;machine learning;computer vision;interpolation;deep learning;artificial intelligence;motion field;image-based modeling and rendering;computer science;morphing;illusion	Vision	59.28289606745625	-52.68310463145421	59672
11cf62be21eea92ecca24070515734b66656099b	a method of spectral moment estimation	teledetection;electromagnetic scattering;radar methods;fading;direct routine;moment spectral;radar doppler;spectral moment estimation;testing;indexing terms;ionosphere;maximum likelihood estimation;power spectrum;electromagnetic propagation;deteccion a distancia;methode nouvelle;radar scattering;accuracy;precision;onde electromagnetique;propagacion;random process;remote sensing;doppler radar;random processes;electromagnetic scattering radar scattering spectral analysis maximum likelihood estimation testing electromagnetic propagation doppler radar parameter estimation fading ionosphere;new methods;ionospheric electromagnetic wave propagation;fading random processes ionospheric electromagnetic wave propagation radiowave propagation;accuracy analysis;radiowave propagation;multipath propagation;estimate;parameter estimation;signal fading;spectral analysis;metodo nuevo;high efficiency;method;methode radar;onda electromagnetica;ionosfera;propagation;radar;electromagnetic waves;multipath propagation ionosphere fading radiowave propagation power spectrum spectral moment estimation method random process direct routine estimate signal fading	The paper presents a new method that enables us to construct direct routines to estimate spectral moments of any orders. Accuracy analysis confirms high efficiency of the estimates. The feasibility of the method is tested for signal fading data acquired during observations of ionosphere multipath propagation.	multipath propagation;software propagation	Andrei A. Monakov;Donat V. Blagoveshchensky	1999	IEEE Trans. Geoscience and Remote Sensing	10.1109/36.752196	stochastic process;mathematics;accuracy and precision;optics;statistics;remote sensing	Mobile	80.0574512119654	-68.17564554980554	59737
6f7b8800a7dc95b457421cd064b709cb2536ba74	building extraction from lidar and aerial images and its accuracy evaluation	building boundary;geophysical image processing;evaluation system building extraction lidar accuracy evaluation building footprint extraction method building detection colour infrared aerial images;buildings laser radar accuracy data mining indexes shape image color analysis;remote sensing by laser beam;remote sensing by laser beam building geophysical image processing geophysical techniques object detection;building;building footprint;accuracy evaluation system;lidar accuracy evaluation system building footprint building boundary aerial imagery;aerial imagery;object detection;geophysical techniques;lidar	There are numerous building footprint extraction methods from various data sources and extraction strategies. However, the lack of a consistent standard to evaluate the accuracy of such methods impedes the comparison of different methods, as well as further exploration of new methods. In this study, a comprehensive evaluation system for building detection is proposed and implemented. In order to test its performance, four different building footprint extraction methods have been designed using LiDAR and Colour Infrared Aerial Images. The comparison of the proposed accuracy evaluation indices and the analysis of the results demonstrate that the designed evaluation system can provide a more complete assessment for building footprint detection.	aerial photography	Jinfei Wang;Chuiqing Zeng;Brad Lehrbass	2012	2012 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2012.6351636	lidar;computer vision;building;remote sensing	Robotics	76.17709241349078	-58.59548922703397	59760
425521dac120946882b17ae781770c705ed1915d	image carving with missing headers and missing fragments		Although some remarkable advancements have been made in image carving, even in the presence of fragmentation, existing methods are not effective when parts (fragments) of an image are missing. This paper addresses this problem and proposes a PRNU (Photo Response Non-Uniformity)-based image carving method. The proposed technique assumes that the underlying camera fingerprint (camera sensor noise) is available prior to the carving process. Given a large number of image fragments, the camera fingerprint is used to find the position of fragments in a to-be-carved image. Using all known-position-fragments, the number of to-be-carved images is then found. The known-position-fragments and the unknown-position-fragments are placed on these images using two different greedy algorithms. Experiment with 23040 fragments shows that the proposed scheme has a true positive rate of 94.2%.	fingerprint;fragmentation (computing);greedy algorithm;heuristic (computer science);image noise;image sensor;sensitivity and specificity;solid-state drive;synthetic intelligence;usb flash drive	Emre Durmus;Manoranjan Mohanty;Samet Taspinar;Erkam Uzun;Nasir D. Memon	2017	2017 IEEE Workshop on Information Forensics and Security (WIFS)	10.1109/WIFS.2017.8267665	computer vision;iterative reconstruction;transform coding;image sensor;carving;artificial intelligence;fragmentation (computing);computer science;greedy algorithm	Vision	56.83200412683179	-58.45525709316191	59807
c73a93af41a0cd97f3571f9cd4c6fa6ff65211cf	the radarsat constellation payload design	design process;disaster management;synthetic aperture radar artificial satellites geophysical techniques remote sensing by radar;canadian space agency;remote sensing by radar;ecosystem monitoring;sar data;artificial satellites;radarsat constellation payload design;c band data continuity;disaster management radarsat constellation payload design canadian space agency c band data continuity sar data maritime surveillance ecosystem monitoring;payloads satellites government ice surveillance ecosystems monitoring costs apertures image quality;maritime surveillance;geophysical techniques;synthetic aperture radar	The Canadian Space Agency completed the definition phase of the RADARSAT Constellation, a constellation of three satellites that will ensure C-band data continuity with RADARSAT-2. The first satellite is scheduled to enter in operation toward the end of the RADARSAT-2 mission, for a full implementation of the constellation in 2014-15. The RADARSAT Constellation is designed to improve significantly the availability of SAR data for main Canadian Government departments, the main applications areas being maritime surveillance, ecosystem monitoring and disaster management. An important constraint on the mission was to reduce significantly the cost of SAR data, which forced the use of new approaches in the payload design. The paper presents the initial payload design process and three techniques investigated to improve its performance.	eurion constellation;ecosystem;image quality;multi-user;scott continuity;systems design	Ralph Girard;Patrick Plourde;Guy Séguin	2007	2007 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2007.4423065	meteorology;synthetic aperture radar;design process;hydrology;physics;satellite;emergency management;remote sensing	Embedded	79.52529977026722	-61.96798952858685	59946
c0fb40d6581238c8033eab092f446adcff85bbf9	a novel angle algorithm of polarization sensor for navigation	cataglyphis polarization sensor desert ants direction information polarized light pattern sunlight scattering polarization sensitivity mechanisms compound eye bionic navigation sensor direction angle calculation normalization output curve angle output error;radio navigation;polarization vision angle algorithm navigation navigation sensor performance test;animals;electromagnetic scattering;polarization sensor;performance test;polarized light;bionic navigation sensor;direction angle calculation;direction information;desert ants;angle algorithm;navigation;optical polarization;polarized light pattern;angle output error;polarization vision;polarization sensitivity mechanisms;error correction;normalization output curve;output error;light polarisation;navigation sensor;optical sensors light polarisation navigation;optical sensors;satellite navigation systems radio navigation aircraft navigation optical polarization biosensors error correction animals educational technology electromagnetic scattering costs;educational technology;sunlight scattering;cataglyphis;compound eye;biosensors;satellite navigation systems;aircraft navigation	Navigation technology is an essential ability for the survival and development of animal and human. Desert ants Cataglyphis are able to explore their desert habitat for hundreds of meters while foraging and return back to their nest precisely and in a straight line. For deriving direction information, these animals use the pattern of polarized light in the sky, which arises due to scattering of sunlight in the atmosphere. The polarization sensitivity mechanisms of the ants' compound eye are analyzed. A novel bionic navigation sensor is constructed. The work principle of the sensor is discussed. A novel algorithm of the direction angle calculation is presented. The merits of the new algorithm are discussed in detail. The angle output experiment of the navigation sensor is performed under different light conditions. The normalization output curve is obtained, and the angle output error is given with our algorithm. The experiment result indicates that the new angle algorithm is feasible and effective.	algorithm;habitat;polarization (waves);sensor	Kaichun Zhao;Jinkui Chu;Tichang Wang;Qiang Zhang	2009	IEEE Transactions on Instrumentation and Measurement	10.1109/TIM.2009.2016299	computer vision;navigation;educational technology;error detection and correction;telecommunications;polarization;radio navigation;optics;physics;biosensor;remote sensing	Vision	82.62102643982807	-69.52690724259729	60030
19297c725a79c1ccd060d4bc2e15a0a6b9fe2e1f	ct image reconstruction from partial angular measurements via compressed sensing	image sampling;radiation dose;compressed sensing;image coding;psnr;computed tomography;wavelet transforms compressed sensing computerised tomography dosimetry image coding image reconstruction image sampling information theory iterative methods medical image processing;ct image reconstruction;dosimetry;wavelet transforms;iterative methods;radiation dose ct image reconstruction compressed sensing;image reconstruction;medical image processing;transforms;computerised tomography;filtered back projection method ct image reconstruction partial angular measurements computed tomograhpy radiation dose wavelet transform coefficient l 1 minimization image total variation minimization fbp compressed sensing iteration shannon nyquist sampling theorem;in vivo;image reconstruction computed tomography compressed sensing psnr transforms in vivo;information theory	Computed Tomograhpy (CT) is a technology that takes projection data along a trajectory and reconstructs an image of the objects. But it exposes patients to significant radiation. Therefore, lower radiation dose has been constantly pursued. The amount of radiation dose is a function of the number of projections. However, in traditional reconstruction algorithms, for example, filtered back projection (FBP) method, the number of projections must satisfy the Shannon/Nyquist sampling theorem so as to avoid streaking artifacts. In this paper, we apply compressed sensing for CT reconstruction. The algorithm minimizes the ℓ1 of the wavelet transform coefficient and total variation of the image. It employs FBP to calculate the intermediate results of derivative of the object function in each compressed sensing iteration. Our simulation experiments show that this method can reconstruct CT images from substantially fewer number of projections than the requirement of Shannon/Nyquist limit. Hence the associated radiation dose can be reduced without noticeable aliasing artifacts and streaking artifacts.	algorithm;aliasing;angularjs;ct scan;coefficient;compressed sensing;experiment;flow-based programming;iteration;iterative reconstruction;nyquist frequency;nyquist rate;nyquist–shannon sampling theorem;ringing artifacts;sampling (signal processing);shannon (unit);simulation;wavelet transform	Zangen Zhu;Khan A. Wahid;Paul Babyn	2012	2012 25th IEEE Canadian Conference on Electrical and Computer Engineering (CCECE)	10.1109/CCECE.2012.6334926	iterative reconstruction;dosimetry;computer vision;mathematical optimization;peak signal-to-noise ratio;information theory;absorbed dose;mathematics;iterative method;in vivo;compressed sensing;wavelet transform	Vision	55.38181752784027	-76.01012555924429	60262
10256f4ff4187ec54144948806a522e1f88d0ec2	the fusion of thaichote, x and c-band synthetic aperture radar imagery for estimating grain yield	geophysical image processing;water levels;synthetic aperture radar biomass optical sensors adaptive optics biomedical optical imaging optical imaging agriculture;forestry;optical vegetation indices thaichote sar image fusion x band sar image fusion c band sar image fusion synthetic aperture radar grain yield crop production monitoring global markets economic impact assessment agriculture cosmo skymed x band data radarsat 2 c band data thaichote optical imagery rice above ground biomass whole growing period central thailand ground based plots leaf area index water level plant density plant height radarsat 2 backscattering coefficient cosmo skymed backscattering coefficient x band hh backscatters;image fusion;vegetation geophysical image processing image fusion radar imaging remote sensing by radar synthetic aperture radar;vegetation;tracking radar;remote sensing by radar;geology;estimation;remote sensing;radar imaging;cultivation;biomass;backscattering;biomass thaichote cosmo skymed x band;international trade;synthetic aperture radar	The monitoring of crop production is an important component of the assessment of the economic impact on agriculture in global markets. This paper investigates the suitability of COSMOS-kyMed X-band and Radarsat-2 C-band data fused with THAICHOTE optical imagery to estimate above-ground biomass of rice over the whole growing period, and eventually yield, in irrigated areas of Central Thailand. Ground-based plots were measured in parallel with Synthetic Aperture Radar (SAR) derived variables such as plant density, height, water level, Leaf Area Index (LAI) and biomass. Biophysical characteristics of rice and COSMO-SkyMed as well as Radarsat-2 backscattering coefficients are analyzed. The resultant fusion technique is compared to national agricultural statistical data. Results show that X-band HH backscatters and Optical Vegetation Indices are a promising method to estimate rice yield.	aperture (software);cosmo-rs;coefficient;resultant;synthetic data;synthetic intelligence	Jiratiwan Kruasilp;Amornchai Prakobya;Chonticha Chitpaiboon;Bingfang Wu;Jihua Meng	2013	2013 IEEE International Geoscience and Remote Sensing Symposium - IGARSS	10.1109/IGARSS.2013.6723810	meteorology;estimation;synthetic aperture radar;geology;biomass;hydrology;image fusion;radar imaging;backscatter;physics;vegetation;remote sensing	Embedded	81.81833897021016	-60.03266518996926	60266
9da3818d4f8cfd226baff6647060186a17d3281e	accuracy optimization for high resolution object-based change detection: an example mapping regional urbanization with 1-m aerial imagery	high resolution imagery;accuracy assessment;land use land cover change;random forests;confusion matrix	The utility of land-cover change data is often derived from the intersection with other information, such as riparian buffers zones or other areas of conservation concern. In order to avoid error propagation, we wanted to optimize our change maps to have very low error rates. Our accuracy optimization methods doubled the number of total change locations mapped, and also increased the area of development related mapped change by 93%. The ratio of mapped to estimated change was increased from 76.3% to 86.6%. To achieve this, we used object-based change detection to assign a probability of change for each landscape unit derived from two dates of 1 m US National Agriculture Imagery Program data. We developed a rapid assessment tool to reduce analyst review time such that thousands of locations can be reviewed per day. We reviewed all change locations with probabilities above a series of thresholds to assess commission errors and the relative cost of decreasing acceptance thresholds. The resultant change maps had only change locations verified to be changed, thus eliminating commission error. This tool facilitated efficient development of large training sets in addition to greatly reducing the effort required to manually verify all predicted change locations. The efficiency gain allowed us to review locations with less than a 50% probability of change without inflating commission errors and, thus, increased our change detection rates while eliminating both commission errors and locations that would have been omission errors among the reviewed lower probability change locations. OPEN ACCESS Remote Sens. 2015, 7 12655	high-resolution scheme;map;mathematical optimization;object-based language;propagation of uncertainty;resultant;serialization;software propagation	Kenneth B. Pierce	2015	Remote Sensing	10.3390/rs71012654	random forest;confusion matrix;machine learning;remote sensing	AI	81.13165485301568	-56.39940161231552	60293
2e9465800abf92c40be4290790a234201b2af7cd	visualization using rational morphology and magnitude reduction ii	morphological filter;walsh transformation;background noise;satellite data;transformation hartley;feature detection;image processing;detection signal;transformacion walsh;non linear filter;localizacion objeto;edge detection;walsh transform;anomaly detection;signal detection;object location;transformacion hartley;procesamiento imagen;filtre morphologique;imagen nivel gris;traitement image;transformation orthogonale;deteccion contorno;detection and tracking algorithms;detection contour;transformacion ortogonal;visualization;deteccion senal;satellites;image niveau gris;hartley transformation;ruido fondo;transform theory;filtro no lineal;orthogonal transformation;earth observing system;bruit fond;grey level image;localisation objet;filtre non lineaire;object detection;transformation walsh	Morphological filters are investigated and employed for detecting and visualizing objects within an image. The techniques developed here will be employed on NASA's Earth Observing System (EOS) satellite data products for the purpose of anomaly detection. Previous efforts have shown the phase information in the spectral domain to be more significant than the magnitude information in representing the location of objects in an image. The magnitude information does provide some useful information for object location, but it is also sensitive to image illumination, blurring, and magnification variations, all of which influence the performance of object detection algorithms. Magnitude reduction techniques in the spectral domain can dramatically improve subsequent object detection methods by causing them to rely less on the magnitude and more on the phase information of the image. We propose three new improvements to our object enhancement and detection techniques. Our first method is an enhancement to our previous magnitude-reduction technique. Our second improvement is a modification of our Rational Morphological Filters in which we raise our resulting image to a power, thereby magnifying our feature detection capability. Third, we look at speed enhancement by utilizing Hartley and Walsh Transforms in place of classical Fourier techniques.© (1998) COPYRIGHT SPIE--The International Society for Optical Engineering. Downloading of the abstract is permitted for personal use only.	galaxy morphological classification	Robert G. Kogan;Sos S. Agaian;Karen Panetta	1998		10.1117/12.316419	computer vision;anomaly detection;visualization;edge detection;hadamard transform;image processing;transform theory;feature detection;background noise;physics;satellite;detection theory;computer graphics (images);orthogonal transformation	EDA	69.23703688272678	-62.936852034923184	60314
3ae540f09804cd7c040e9498537e3574086b6700	polarimetric, l-band, combined radiometer and short pulse scatterometer system	polarimetry;snow;l band radar measurements microwave radiometry remote sensing laboratories microwave measurements soil measurements surface soil vegetation snow;radiometry;microwave measurement;remote sensing;microwave emissive characteristics polarimetric system l band system short pulse scatterometer system short pulse scatterometer radiometer system remote sensing spatially coincident microwave active passive measurements soil vegetation snow surface water surface microwave reflective characteristics;polarimetry remote sensing soil radiometers radiometry snow microwave measurement geophysical techniques;soil;radiometers;passive measurement;geophysical techniques	In this paper L-band, polarimetric, combined, short pulse scatterometer-radiometer system is described, for short distance remote sensing application, under laboratory and field-control conditions. Developed system allows to carry out polarimetric (vv, vh, hit, hv), simultaneous and spatially coincident microwave active-passive measurements of observed surface (soil, soil vegetation, snow and water surface) microwave reflective and emissive characteristics at angles of incidence from the while of 0-80/spl deg/.	advanced spaceborne thermal emission and reflection radiometer;incidence matrix;l band;microwave;polarimetry;remote sensing application	Artashes Arakelyan;A. G. Goulyan;V. R. Karapetyan;R. M. Martirosyan;H. A. Pirumyan;Yu A. Saakyan;Astghik Hambaryan;Aleksander I. Smolin;Vanik Karyan;Vardan K. Hambaryan;Arsen Arakelyan	2004	IGARSS 2004. 2004 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2004.1369881	snow;polarimetry;radiometry;atmospheric sciences;hydrology;radiometer;microwave radiometer;optics;physics;remote sensing	Embedded	82.03309044181319	-63.70629551801406	60338
c5aff3b8bb18106c819f65c3b01379558d30049b	smoothing displacement field obtained via digital image correlation for robust strain calculation		A self-adaptive smoothing method is proposed to deal with the displacement field obtained via digital image cor- relation (DIC). This new smoothing method is based on penalized least squares regression technique, which can penalize the roughness of the displacement and realize displacement denoising. In this method, generalized cross validation (GCV) method and discrete cosine transform (DCT) are used to get penalized parameter and true displacement from the noisy displacement field separately. This method has advantages of easy implementation, little calculation requirement, complete automation and so on. Both simulation analyses and experimental results validate the effectiveness of this smoothing technology, which can improve the strain distribution differentiated by the smoothed displacement without any calculation increasement.	digital image;displacement mapping;smoothing	Huan Shen;Peize Zhang;Xiang Shen	2015	J. Comput. Meth. in Science and Engineering	10.3233/JCM-150537	econometrics;mathematical optimization;mathematics;statistics	Theory	57.925605627803314	-69.31868160611364	60377
ec8c4ea378cd3d21b240bcbdf6d1e485de6e257f	comparisons of precipitation measurements by the advanced microwave precipitation radiometer and multiparameter radar	hydrometeore;microwave radiation;microwave measurements radar imaging spaceborne radar microwave radiometry atmospheric measurements nasa airborne radar image resolution image sensors sensor systems;atmospheric precipitation;microwave measurements;microwave;sensor systems;processing;high resolution;atmospheric measurements;performance test;image processing;measurement;image resolution;north america;america del norte;amerique du nord;methode mesure;amerique;observation par avion;florida;estudio comparativo;radiation detectors;performance;advanced microwave precipitation radiometer;radiometric surveys;testing 580000 geosciences;floride;geophysical meteorological instrumentation 1990;metodo medida;image;radiation detector;microwave imaging;etats unis;image sensors;spectra;estados unidos;microwave radiometry;performance testing;aircraft observation;etude comparative;radiometry;remote sensing by radar;atmospheric precipitations;accuracy;across track scanning total power radiometer system;radiometre hyperfrequence balayage;remote sensing by radar atmospheric techniques radiometry rain remote sensing;precipitation;aerial monitoring;total power;monitoring;environmental sciences;imagen;radiometro hiperfrecuencia exploracion;precipitacion atmosferica;hidrometeoro;remote sensing;radar imaging;comparative study;geophysical surveys;geophysical survey;rain;geosciences;ad 1991;radiations;airborne radar;hydrometeor;environmental science;atmospheric techniques;microwave spectra;microwave scanner;measurement method;america;national center for atmospheric research;atmosphere;other instrumentation;nasa;precipitation atmospherique;across track scanning total power radiometer system technique rain rainfall atmosphere measurement remote sensing radiometry microwave ampr ad 1991 precipitation advanced microwave precipitation radiometer multiparameter radar;measuring instruments;observacion por avion;radiometers;rainfall;technique;electromagnetic radiation;radar;multiparameter radar	Multiparameter microwave radar measurements are based on dual-polarization and dual-frequency techniques and are well suited for microphysical inferences of complex precipitating clouds, since they depend upon the size, shape, composition, and orientation of a collection of discrete random scatterers. Passive microwave radiometer observations represent path integrated scattering and absorption phenomena of the same scatterers. The response of the upwelling brightness temperatures TB to the precipitation structure depends on the vertical distribution of the various hydrometeors and gases, and the surface features. As a result, combinations of both active and passive techniques contain great potential to markedly improve the longstanding issue of precipitation measurement from space. The NASA airborne Advanced Microwave Precipitation Radiometer (AMPR) and the National Center for Atmospheric Research (NCAR) CP-2 multiparameter radar were jointly operated during the 1991 Convection and Precipitation/Electrification experiment (CaPE) in central Florida. The AMPR is a four channel, high resolution, across-track scanning total power radiometer system using the identical multifrequency feedhorn as the widely utilized Special Sensor Microwave/Imager (SSM/I) satellite system. Surface and precipitation features are separable based on the TB behavior as a function of the AMPR channels. The radar observations are presented in a remapped format suitable for comparison with the multifrequency AMPR imagery. Striking resemblances are noted between the AMPR imagery and the radar reflectivity at successive heights, while vertical profiles of the CP-2 products along the nadir trace suggest a storm structure consistent with the viewed AMPR TB. Directly over the storm cores, the difference between the 37 and 85 GHz TB was noted to approach (and in some cases fall below) zero. Microwave radiative transfer computations show that this is theoretically possible for hail regions suspended aloft in the core of strong convective storms.	advanced spaceborne thermal emission and reflection radiometer;airborne ranger;computation;feed horn;image resolution;image sensor;interrupt storm;microwave;radar;terabyte	Jothiram Vivekanandan;F. Joseph Turk;Viswanathan N. Bringi	1993	IEEE Trans. Geoscience and Remote Sensing	10.1109/36.239909	meteorology;geophysical survey;precipitation;image resolution;image processing;microwave;hydrology;optics;particle detector;physics;quantum mechanics;remote sensing	HPC	82.38547353392572	-63.978026021746366	60384
d91a782473655e9c8bf44c6460d4286a55bf44a2	validation of the modis burned-area products across different biomes in south africa	landsat;vegetation mapping;savanna vegetation;estimation accuracy;omission and commission errors;southern africa;moderate resolution imaging spectroradiometer time series data;backup modis burned area product;earth;biomes;south african;thematic mapper;burned area product;time series;biomes moderate resolution imaging spectroradiometer time series data remote sensing south africa landsat 7 enhanced thematic mapper plus scenes savanna vegetation fire distribution mcd45a1 backup modis burned area product burned area detection estimation accuracy landsat 5 thematic mapper imagery validation sites size distribution;landsat 5 thematic mapper imagery;enhanced thematic mapper;size distribution;modis remote sensing satellites earth africa fires pixel;fire modis landsat burned area product omission and commission errors;mcd45a1;remote sensing;satellites;pixel;time series data;vegetation mapping remote sensing time series;south africa;modis;burned area detection;landsat 5;fire;fires;africa;vegetation type;fire distribution;validation sites;landsat 7 enhanced thematic mapper plus scenes	The Moderate Resolution Imaging Spectroradiometer (MODIS) time-series data afford the remote sensing community a unique opportunity to investigate the frequency and distribution of fires. Previous research that validated the MODIS burned area product (MCD45A1) in South Africa was only limited to two Landsat 7 Enhanced Thematic Mapper plus (ETM+) scenes in savanna vegetation, which is not adequate for robust assessment of fire distribution across diverse environments. In this study, validation of the MCD45A1 and the Backup MODIS burned area product (hereafter BMBAP) was extended over different South African vegetation types by quantifying their burned area detection and estimation accuracy using Landsat 5 Thematic Mapper (TM) imagery. Results from the four validation sites reveal that there are subtle differences in the accuracy of the two products. These differences could be influenced for example by, vegetation type, spectral characteristics, and size distribution of the burned areas. These results have significant implications for fire monitoring in Southern Africa.	backup;mapper;time series	Philemon L. Tsela;Paul van Helden;Philip Frost;Konrad J. Wessels;Sally Archibald	2010	2010 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2010.5650253	hydrology;time series;physics;statistics;remote sensing	Arch	82.70220662481512	-58.73740802137294	60452
b71d737d33d482ac8811bba5206b52ced97d3922	image quality evaluation using image quality ruler and graphical model	image quality graphical models correlation reliability estimation standards labeling;psychophysical experiment image print quality graphical model quality ruler machine learning;statistical analysis expectation maximisation algorithm image processing psychology;image quality evaluation psychophysical experiments human resources hidden variable estimation em method expectation maximization method image rating task quality score statistical model jnd unit just noticeable difference unit image quality ruler method subjective evaluation graphical model	Quantifying image quality through subjective evaluation is very critical to image quality evaluation. Using the image quality ruler method, an average score per stimulus can be easily obtained in the unit of Just Noticeable Differences (JNDs). However, it requires a large number of subjects, since pure averaging does not consider the different judging quality of different subjects. In this paper, we propose an image quality evaluation framework using the image quality ruler method with a statistical model. By incorporating this model, we consider the quality score, the expertise of the subjects, and the difficulty of image rating task as three hidden variables. Then we use expectation-maximization (EM) to estimate these hidden variables. From our experimental results, we show that our method provides reliable results without using a large number of subjects. Preliminary results also demonstrate that the estimates of the parameters can guide us to better distribute the valuable human resources used to conduct psychophysical experiments.	expectation–maximization algorithm;experiment;graphical model;hidden variable theory;image quality;standard test image;statistical model	Weibao Wang;Jan P. Allebach;Yandong Guo	2015	2015 IEEE International Conference on Image Processing (ICIP)	10.1109/ICIP.2015.7351203	image quality;subjective video quality;computer vision;computer science;pattern recognition;statistics	Robotics	62.80877103532646	-65.4597099042287	60518
9084d09ca7cf2892132b78d082c7281b28b9620a	focusing highly squinted azimuth variant bistatic sar	focusing;azimuth;focusing azimuth scaling function frequency modulation rate geometry property bulk secondary range compression linear range walk correction operation range compression geometry information aided extended azimuth nonlinear chirp scaling algorithm azimuth dependent range offset sar high resolution highly squinted azimuth variant bistatic synthetic aperture radar;frequency modulation;chirp;frequency domain analysis;azimuth frequency modulation frequency domain analysis focusing time domain analysis chirp;synthetic aperture radar focusing frequency modulation geometry;time domain analysis	Accurate focusing of high-resolution highly squinted azimuth variant bistatic synthetic aperture radar is a more challenge issue than its translational azimuth invariant bistatic counterpart due to the following two reasons: 1) higher order terms spatial variant feature in azimuth caused by removing relatively large range migration and 2) the azimuth-dependent range offset (RO) induced by inherent azimuth variant bistatic geometric configuration. In this paper, to solve those two issues, a geometry information-aided extended azimuth nonlinear chirp scaling algorithm to provide a better focus is proposed. First, the range compression containing two procedures, namely a linear range walk correction operation and a bulk secondary range compression, is utilized. Second, based on the geometry property of azimuth variant bistatic geometric configuration, the azimuth-dependent RO is obtained and then compensated to enhance focusing ability in the azimuth dimension. By evaluating the spatial variant characteristic of the frequency modulation (FM) rate and the higher order terms, a new azimuth scaling function is derived by adopting higher order approximation operation. With this new azimuth scaling function, not only the azimuth spatial variances of the higher order terms of FM rate and cubic phase terms are equalized, but also the azimuth-dependent RO is eliminated. Compared with existing azimuth nonlinear chirp scaling method, large azimuth depth of focusing can be realized without changing the overall imaging procedure. The experimental results with simulated data verify the effectiveness of the proposed algorithm.	algorithm;analysis of algorithms;approximation;chirp;coefficient;computational complexity theory;cubic function;fm broadcasting;geometric analysis;image resolution;image scaling;knowledge-based configuration;modulation;nonlinear system;perturbation theory;simulation;synthetic intelligence	Dong Li;Wei Wang;Hongqing Liu;Hai-lin Cao;Huan Lin	2016	IEEE Transactions on Aerospace and Electronic Systems	10.1109/TAES.2016.150491	frequency modulation;electronic engineering;telecommunications;computer science;azimuth;optics;chirp;frequency domain;physics;remote sensing	EDA	76.18439307520707	-67.76521536662028	60547
8ef34ca7c67e29c0fce67f64c5264477dfc559d8	vertical profile reconstruction with pol-insar data of a subpolar glacier	radar interferometry;radar scattering sea surface surface topography polarization tomography ice surface coherence particle measurements polynomials image reconstruction;glaciology;institut fur hochfrequenztechnik und radarsysteme;ice sheets;vertical profile;synthetic aperture radar glaciology ice image reconstruction radar interferometry radar polarimetry;norway vertical profile reconstruction pol insar data subpolar glacier accurate mapping wide coverage monitoring glaciers ice sheets climate change sea level rise polarimetric interferometric sar polarization coherence tomography e sar system austfonna ice cap svalbard;sea level rise;radar polarimetry;image reconstruction;global climate change;interferometric sar;sar technologie;ice;synthetic aperture radar	The last decade has seen an increasing demand for accurate mapping and wide-coverage monitoring of glaciers and ice sheets in order to measure and predict their response to global climate change and their contribution to sea level rise. This in turn requires a more complete understanding of their properties including topography, accumulation rates and vertical profiles. One promising new technique for vertical profile reconstruction using polarimetric interferometric SAR (Pol-InSAR) data is polarization coherence tomography (PCT) and for the first time, PCT is adapted here to a glacier scenario. The inversion algorithm to reconstruct vertical ice profiles is applied to both simulated data to assess its accuracy and sensitivity to input parameters, and to airborne Pol-InSAR data at L- and P-band and InSAR data at X-band collected using DLR's E-SAR system over the Austfonna ice cap in Svalbard, Norway.	airborne ranger;algorithm;dynamic language runtime;polarimetry;polarization (waves);tomography;topography;tree accumulation	Jayanti J. Sharma;Irena Hajnsek;Konstantinos P. Papathanassiou	2007	2007 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2007.4423006	iterative reconstruction;meteorology;synthetic aperture radar;glaciology;global warming;geology;hydrology;ice sheet;remote sensing	Arch	81.54691305777094	-61.67544521070716	60552
beff3e20f3931c42c082d5addaf20822b2bee72b	remote sensing image enhancement based on non-local means filter in nsct domain		In this paper, a novel remote sensing image enhancement technique based on a non-local means filter in a nonsubsampled contourlet transform (NSCT) domain is proposed. The overall flow of the approach can be divided into the following steps: Firstly, the image is decomposed into one low-frequency sub-band and several high-frequency sub-bands with NSCT. Secondly, contrast stretching is adopted to deal with the low-frequency sub-band coefficients, and the non-local means filter is applied to suppress the noise contained in the first high-frequency sub-band coefficients. Thirdly, the processed coefficients are reconstructed with the inverse NSCT transform. Finally, the unsharp filter is used to enhance the details of the image. The simulation results show that the proposed algorithm has better performance in remote sensing image enhancement than the existing approaches.	algorithm;bittorrent protocol encryption;coefficient;contourlet;image editing;non-local means;normalization (image processing);peak signal-to-noise ratio;simulation;unsharp masking	Liangliang Li;Yujuan Si;Zhenhong Jia	2017	Algorithms	10.3390/a10040116	mathematics;contourlet;normalization (image processing);remote sensing;non-local means;computer vision;artificial intelligence	EDA	57.91655258284962	-66.93177114064693	60624
1b280d74c31e9c8ff61a42fef81393cd24b32912	recovering fluid-type motions using navier-stokes potential flow	brightness constraint;partial differential equation;fluid type motion recovery;optical surface waves;navier stokes equations;fourier domain method;navier stokes;taylor expansion;optical flow fluid type motion recovery navier stokes potential flow wavefront surface brightness constraint partial differential equation dirichlet neumann operator 3d volumetric velocity potential 2d surface velocity potential taylor expansion fourier domain method taylor coefficients synthetic image;wavefront surface;potential flow;brightness;optical imaging;dynamics;partial differential equations;three dimensional displays;partial differential equations fourier analysis image sequences navier stokes equations;mathematical model;fourier analysis;optical flow;surface waves;efficient estimation;taylor coefficients;navier stokes potential flow;dirichlet neumann operator;brightness optical surface waves surface waves surface treatment image motion analysis clouds motion estimation partial differential equations taylor series robustness;2d surface velocity potential;3d volumetric velocity potential;synthetic image;image sequences	The classical optical flow assumes that a feature point maintains constant brightness across the frames. For fluid-type motions such as smoke or clouds, the constant brightness assumption does not hold, and accurately estimating the motion flow from their images is difficult. In this paper, we introduce a simple but effective Navier-Stokes (NS) potential flow model for recovering fluid-type motions. Our method treats the image as a wavefront surface and models the 3D potential flow beneath the surface. The gradient of the velocity potential describes the motion flow at every voxel. We first derive a general brightness constraint that explicitly models wavefront (brightness) variations in terms of the velocity potential. We then use a series of partial differential equations to separately model the dynamics of the potential flow. To solve for the potential flow, we use the Dirichlet-Neumann Operator (DNO) to simplify the 3D volumetric velocity potential to 2D surface velocity potential. We approximate the DNO via Taylor expansions and develop a Fourier domain method to efficiently estimate the Taylor coefficients. Finally we show how to use the DNO to recover the velocity potential from images as well as to propagate the wavefront (image) over time. Experimental results on both synthetic and real images show that our technique is robust and reliable.	approximation algorithm;coefficient;coherence (physics);gradient;ibm notes;internet information services;mathematical optimization;nsb/appstudio;navier–stokes equations;numerical analysis;optical flow;robustness (computer science);synthetic intelligence;turbulence;velocity (software development);voxel;wavefront technologies	Feng Li;Liwei Xu;Philippe Guyenne;Jingyi Yu	2010	2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition	10.1109/CVPR.2010.5539942	mathematical optimization;mathematical analysis;flow velocity;mathematics;geometry;partial differential equation	Vision	54.40274340389626	-71.25970198345688	60652
bf856688ded6b8e8b32f9370efcf26561d7b5232	a novel video dehazing method based on temporal visual coherence	video dehazing;motion estimation;temporal visual coherence;transmission map optimization	In this paper, we propose a novel video dehazing scheme which mainly consists of atmospheric light estimation, transmission map extraction and optimization by utilizing motion estimation. The key contribution of our scheme is the video temporal visual coherence improvement after video dehazing. We first extract the transmission map frame-by-frame by using dark channel prior model and then estimate motion vectors in original video without dehazing. The motion vectors are used to improve the temporal visual coherence on the transmission map sequence. To avoid blocking-artifacts, guided filter can also be used to refine the transmission map. Experimental results show that our model can achieve a good dehazing effect.	blocking (computing);mathematical optimization;mcgurk effect;motion estimation	Xinguang Xiang;Yang Cheng;Jinhui Tang	2015		10.1145/2808492.2808528	computer vision;geography;optics;computer graphics (images)	Vision	57.76474136108736	-58.45419574146027	60664
7dbb17f3ec470f408bf4807d50810f7e61332ed2	phase unwrapping correction with dual-baseline data for the tandem-x mission	sar signalverarbeitung;geophysical image processing;stereo radargrammetry phase unwrapping tandem x differential interferogram;dual baseline data operational dual baseline phase unwrapping algorithm tandem x mission single baseline phase unwrapping correction procedure tandem x acquisitions differential interferogram phase unwrapping errors stereoradargrammetric measurement phase unwrapping correction;accuracy coherence histograms standards reliability geometry error correction;stereo radargrammetry;tandem x;geophysical techniques geophysical image processing;differential interferogram;geophysical techniques;phase unwrapping	The operational dual-baseline phase unwrapping algorithm for the TanDEM-X mission is based on a combination of separate single-baseline phase unwrapping and a correction procedure of different levels of complexity. It benefits from all the information available from the two TanDEM-X acquisitions by computing a differential interferogram to obtain a more reliable unwrapped phase. This may still be prone to phase unwrapping errors, but these can be mitigated using a stereo-radargrammetric measurement. Hence, the resulting dual-baseline phase unwrapping algorithm outperforms a single-baseline one.	algorithm;baseline (configuration management);instantaneous phase	Thomas Fritz;Ulrich Balss;Richard Bamler;Michael Eineder	2012	2012 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2012.6352344	computer vision;optics;remote sensing	Embedded	75.3048322340509	-64.99698330940382	60696
a18082a451c64cb852faa44251f35a9fd74a4fa0	uncertainty representation using fuzzy-entropy approach: special application in remotely sensed high-resolution satellite images (rshrsis)		Abstract Remotely sensed high-resolution satellite images contain various information in context of changes. By analyzing this information very minutely, changes occurred in various atmospheric phenomena can be identified. Therefore, in this study, a novel change detection method is proposed using the fuzzy set theory. The proposed method represents the uncertain changes in the form of a fuzzy set using the corresponding degree of membership values. By using the fuzzy set operators, such as max and min functions, this study derives very useful information from the images. This study also proposes a new function to identify the boundary of uncertain changes. Further, this study is propagated to identify the similarity or dissimilarity between different images of the same event that contain various uncertain changes. To recognize the changes in a fine-grained level, this study introduces a way to represent the fuzzy information in a granular way. The utilization of the proposed method is shown by recognizing changes and retrieving information from the remotely sensed high-resolution satellite images. Various experimental results exhibit the robustness of the study.	image resolution	Pritpal Singh;Gaurav Dhiman	2018	Appl. Soft Comput.	10.1016/j.asoc.2018.07.038	artificial intelligence;machine learning;fuzzy logic;operator (computer programming);fuzzy set;robustness (computer science);mathematics;change detection	Robotics	74.00331306962595	-60.38889932835427	60709
b84c7589557925b65ebe7a2206d4566da01d5980	uncertainty in lidar derived canopy height models in three unique forest ecosystems		NEON conducts annual LiDAR flights over several ecologically unique sites within the continental United States. One of the products derived from the LiDAR acquisitions is a canopy height model (CHM), required to make inferences about vegetation structure and annual changes in growth. It is hypothesized that the flight acquisition parameters are sufficient to allow NEON's CHMs to detect inter-annual change in growth at the NEON forest plot scale. To test this hypothesis, a series of overlapping LiDAR flight lines were collected over a sample forest area at three unique ecosystems. The repeat data allowed empirical quantification of uncertainty in CHMs. When related to the growth rate of the dominant species, this allowed estimation of the time required to separate true change from CHM uncertainty and conclude growth had occurred. Results highlight that each forest eco-system displays unique sources of uncertainty, and that annual changes in NEON forest plots are generally achievable with the exception of plots with minimal canopy cover.	chemdraw;ecology;ecosystem;köppen climate classification;motorola canopy;neon	Tristan Goulden;Bridget Hass;Nathan Leisso	2017	2017 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)	10.1109/IGARSS.2017.8127592	canopy;remote sensing;vegetation;computer science;dominance (ecology);neon;forest plot;ecosystem;lidar;forest ecology	Arch	82.57997879484199	-57.56862987020932	60733
99250c089db433da67b04c149a7fb713591f43ba	blocking artifact reduction in compressed images based on edge-adaptive quadrangle meshes	quantization constraint set;280203;adaptive mesh;institute for integrated and intelligent systems;faculty of science environment engineering and technology;projection onto convex sets;journal article;blocking artifacts;smoothness constraint set;image postprocessing;image simulation;anti parallel;projections onto convex sets;pre2009 image processing;human perception;blocking artifact	During image deblocking, the preservation of visually significant edges in the image is important. Based on the observation that blocking artifact along edge direction is difficult for human perception, a number of existing techniques have proposed to filter the edge pixels with low weight or bypass them altogether to avoid blurring. However, the un-processed artifacts that are anti-parallel to the edge direction often fragment the edges and seriously degrade visual quality. In this paper, by considering the behavior of intensity evolution along and across edges, we propose a new POCS-based algorithm using a new smoothness constraint set. The new constraint set is realized indirectly by limiting the distance between the coded image and the image simulated using edge-adaptive quadrangle meshes. Experimental results indicated that our method compares favorably with several existing techniques. 2003 Elsevier Inc. All rights reserved. IDT: Image postprocessing; Adaptive mesh; Projections onto convex sets; Blocking artifacts; Smoothness constraint set; Quantization constraint set	algorithm;blocking (computing);convex set;deblocking filter;human visual system model;interrupt descriptor table;pixel;quadrangle (geography);spatial anti-aliasing	Xiangchao Gan;Alan Wee-Chung Liew;Hong Yan	2003	J. Visual Communication and Image Representation	10.1016/S1047-3203(03)00044-0	computer vision;mathematical optimization;theoretical computer science;mathematics;perception	Vision	57.88867113762621	-61.855281400847176	60805
699524a14cbd61b5e775816d43696739c69b82ff	regularized reconstruction of ultrasonic imaging and the regularization parameter choice		Ultrasound image reconstruction based on inverse problems has attracted attention to the ultrasonic imaging research community recently. Different from standard beamforming-based methods techniques, this new imaging method tries to solve a linear system g=Hf as a form of reconstructing the ultrasound image. In order to understand the behaviour of this imaging system, it is important to analyse the forward problem. In this paper, we analyse the effect of the noise in acquisition matrix using singular value decomposition. Also, the effect of regularization parameter in dealing with the noise is investigated in regularized. This analysis provides some interesting insights in the understanding of how the inverse reconstruction can be improve some aspects higher than beamforming.	beamforming;ccir system g;iterative reconstruction;linear system;matrix regularization;medical ultrasound;singular value decomposition	Leonardo G. S. Zanin;Fabio Kurt Schneider;Marcelo Victor Wüst Zibetti	2012			artificial intelligence;computer vision;computer science;mathematical optimization;regularization (mathematics);ultrasonic sensor	Vision	72.34595098937776	-69.32431475874657	60865
d2e6964c485cb5b07c95bb0c6e63f224612f746c	building damage assessment approach based on seismic spatial information grid	earthquake;earthquake disasters assessment;yushu earthquake;damage factors;qinghai province;vibrations;seismology;disaster loss assessment;space time distribution;hazards;attenuation;earthquakes;building damage assessment;earthquake thematic spatial information grid;china seismic spatial information grid natural disaster earthquake disasters assessment disaster risk gis based building damage assessment space time distribution damage factors ssig method spatial characteristics temporal characteristics seismic data earthquake thematic spatial information grid spatial information technology yushu earthquake qinghai province;spatial information grid;disaster loss assessment spatial information grid earthquake building damage assessment gis;fracture;temporal characteristics;gis;structural engineering computing;geographic information systems;vibrations buildings structures disasters earthquakes fracture geographic information systems seismology structural engineering computing;spatial information technology;natural disaster;ssig method;spatial characteristics;buildings attenuation hazards;seismic spatial information grid;buildings structures;china;disaster risk;buildings;seismic data;disasters;gis based building damage assessment	Earthquakes are a sudden natural disaster that seriously endangers the safety of people's lives and property. Rapid and accurate assessment of earthquake disasters, especially the building damage assessment, is an effective way to reduce the risk of disasters. Compared with traditional methods of GIS-based building damage assessment, which takes the entire stricken region as a whole assessment area, lacks in considering the uneven space-time distribution of damage factors, the seismic spatial information grid (SSIG) method fully considers the spatial and temporal characteristics of seismic data and can give a more accurate and detailed assessment results. SSIG is an earthquake thematic spatial information grid, which has integrated numerous kinds of spatial information technology. In this paper, SSIG has been introduced into building damage assessments. It describes the model and method of building damage assessment based on SSIG. The proposed method was exemplified after the Yushu earthquake in Qinghai province of China. The case application shows that the SSIG-based method can get more accurate assessment results than single GIS-based method.	earthquake network;geographic information system	Xiaohong Yang;Zhong Xie;Xiangang Luo;Zhanlong Chen	2015	2015 23rd International Conference on Geoinformatics	10.1109/GEOINFORMATICS.2015.7378552	seismology;geography;civil engineering;geotechnical engineering	EDA	81.37631835657452	-55.44892442467794	61059
2a0536f38fec9abf237f38857589570c11d2a62f	compressed beamforming with applications to ultrasound imaging	image sampling;finite element methods;array signal processing ultrasonic imaging receivers imaging finite element methods arrays approximation methods;xampling;array processing;compressed sensing cs;compressed sensing;medical signal detection;ultrasound;finite rate of innovation fri;ultrasonic imaging;ultrasonic transducers array signal processing compressed sensing image reconstruction image sampling medical signal detection patient treatment ultrasonic imaging;array signal processing;ultrasonic transducers;xampling compressed beamforming technique medical treatment ultrasound imaging systems ultrasound transducer elements image sampling methods power consumption cs techniques ultrasound signal detection sampling theory analog signal sampling snr nyquist rate multiple transducer elements;dynamic focus;xampling array processing beamforming compressed sensing cs dynamic focus finite rate of innovation fri matrix pencil ultrasound;receivers;arrays;image reconstruction;imaging;patient treatment;matrix pencil;approximation methods;beamforming	Recent developments in medical treatment put challenging demands on ultrasound imaging systems. These demands typically imply increasing the number of transducer elements involved in each imaging cycle. Confined to traditional sampling methods, the inevitable result is a significant growth in the amount of raw data that needs to be transmitted from the system front end, and then processed by the processing unit, effecting machinery size and power consumption. In this paper, we derive a scheme which reduces the amount of transmitted data, by applying Compressed Sensing (CS) techniques to analog ultrasound signals detected in the transducer elements. We follow the spirit of Xampling, which combines classic methods from sampling theory with recent developments in CS, aimed at sampling analog signals far below the Nyquist rate. Our scheme enhances SNR, by integrating low-rate samples extracted from multiple transducer elements. We refer to this process as “beamforming in the compressed domain”, or “compressed beamforming”.	analog signal;beamforming;compressed sensing;download;medical ultrasound;nyquist rate;sampling (signal processing);signal-to-noise ratio;transducer	Noam Wagner;Yonina C. Eldar;Arie Feuer;Zvi Friedman	2012	2012 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	10.1109/ICASSP.2012.6288705	iterative reconstruction;medical imaging;matrix pencil;finite element method;ultrasound;mathematics;compressed sensing;beamforming	Robotics	55.02949613800645	-79.77628921509145	61092
044292bd0706c4c31cb4d1c7a0939e306c3c9184	algorithm 890: sparco: a testing framework for sparse reconstruction	operador lineal;gnu public license;evaluation performance;compressed sensing;geophysics;performance evaluation;normalisation;evaluacion prestacion;geofisica;problema inverso;linear operator;inverse problem;image compression;imaging;logiciel libre;linear operators;normalizacion;sparse recovery;formation image;software libre;design;formacion imagen;experimentation;operateur lineaire;probleme inverse;standardization;geophysique;open source software	Sparco is a framework for testing and benchmarking algorithms for sparse reconstruction. It includes a large collection of sparse reconstruction problems drawn from the imaging, compressed sensing, and geophysics literature. Sparco is also a framework for implementing new test problems and can be used as a tool for reproducible research. Sparco is implemented entirely in Matlab, and is released as open-source software under the GNU Public License.	algorithm;compressed sensing;gnu;matlab;open-source software;sparse matrix	Ewout van den Berg;Michael P. Friedlander;Gilles Hennenfent;Felix J. Herrmann;Rayan Saab;Özgür Yilmaz	2009	ACM Trans. Math. Softw.	10.1145/1462173.1462178	medical imaging;design;simulation;image compression;computer science;inverse problem;theoretical computer science;mathematics;compressed sensing;standardization;algorithm	Graphics	58.689200900894605	-75.28678488389824	61254
c3b71dd87a8761f50c16f0af894986642b2c3431	mlp interpolation for digital image processing using wavelet transform	interpolation;digital image processing;image resolution;interpolation digital images wavelet transforms image resolution frequency signal resolution multilayer perceptrons pixel image reconstruction neural networks;multilayer perceptrons;low resolution;image classification;multilayer perceptron;wavelet transforms;image enhancement;wavelet transform;window edge classifier mlp interpolation digital image processing wavelet transform nonlinear interpolation image resolution enhancement multilayer perceptron subband filtering subimage signal estimation pixels low resolution image input signal wavelet subimage high resolution image vlsi techniques wavelet analysis synthesis;high resolution imager;filtering theory multilayer perceptrons interpolation image resolution image enhancement wavelet transforms image classification;filtering theory	In this paper, we present nonlinear interpolation sche mes for image resolution enhance ment. The Multilayer perceptron (MLP) interpolation sche mes based on the wavelet transform and subband filtering are proposed. B ecause esti mating each sub-image signal is more effective t han estimating the whole image signal, pixels in the low-resolution image are used as input signal of the MLP to esti mate all of the wavelet sub-i mage of the correspondin g high-resolution i mage. The image of increased resolution is finally produced by the synthesis procedure of wavelet transform. As compared with other popular methods, the results sho w that the i mprovement is remarkable. The detail si mulation results o f interpolated images and image sequences can be found in web page: http://www.cs.ccu.edu.tw/~hyl/wmi/.	digital image processing;han unification;image resolution;interpolation;memory-level parallelism;multilayer perceptron;nonlinear system;pixel;quad flat no-leads package;wavelet transform;web page	Yu-Len Huang;Ruey-Feng Chang	1999		10.1109/ICASSP.1999.757526	demosaicing;wavelet;computer vision;feature detection;harmonic wavelet transform;image resolution;second-generation wavelet transform;image processing;computer science;machine learning;digital image processing;pattern recognition;mathematics;wavelet packet decomposition;stationary wavelet transform;image fusion;discrete wavelet transform;sub-pixel resolution;top-hat transform;wavelet transform;image scaling	Robotics	56.05247461472818	-65.86361126929377	61321
22113028f867db03c7e264a59ef9560a8a46bd4c	lithological and mineralogical survey of the oyu tolgoi region, southeastern gobi, mongolia using aster reflectance and emissivity data	aster;tir;swir;brlo model;oyu tolgoi;matched filtering	The Oyu Tolgoi porphyry Cu–Au deposits, Southeastern Gobi, Mongolia, are estimated to be among the world’s largest reserves. Advanced Spaceborne Thermal Emission and Reflectance Radiometer (ASTER) reflectance and emissivity data were used to map distribution patterns of hydrothermal alteration and igneous rocks, and to locate areas with potential mineral deposit in the Oyu Tolgoi region. To obtain more accurate information for the detection and classification of minerals, pre-processing such as crosstalk correction and additional radiometric correction was performed. The shortwave infrared band ratio logical operator (SWIR-BRLO) models and matched filtering were used to map alteration zone and minerals in the Oyu Tolgoi region. These results were fairly consistent with mineralogical information of previous researches. In addition, we identified mineral potential areas with characteristics similar to the Oyu Tolgoi Cu–Au deposits. In particular, in the northwestern part of the OT North Pluton, an extensive area predicted to be an argillic zone was newly detected. ASTER Level 2B surface emissivity data was effectively used for lithological mapping of the Oyu Tolgoi region. The new thermal infrared band ratio logical operator (TIR-BRLO) models could detect areas showing emissivity features of quartzose and alkalic rocks. These results indicate that despite some limitations, ASTER data can provide basic information in the initial steps of ore deposit exploration, or when mapping the distribution of altered, quartzose and igneous rocks, especially in areas where direct field survey is difficult.	advanced spaceborne thermal emission and reflection radiometer;crosstalk;logical connective;preprocessor;qualcomm gobi	Young-Sun Son;Moon-Kyung Kang;Wang-Jung Yoon	2014	Int. J. Applied Earth Observation and Geoinformation	10.1016/j.jag.2013.07.004	biology;geology;mineralogy;aster;remote sensing	AI	80.87542172963072	-58.68812038269045	61325
33ce1e3597b4a2433c419f643d5ad424fe6f8200	rx anomaly detector with rectified background		An improved version of Reed–Xiaoli (RX) detector is proposed in this letter, which uses the benefits of median-mean line (MML) metric. The background data may be contaminated by anomalies. The anomalous outliers contributed in the estimate of background statistics decrease the differences between anomalous targets and background clutter. So, the performance of an RX detector is degraded. To deal with the negative effects of anomalous outliers, and to rectify the position of background data, the MML metric is used for providing more reliable background samples. Therefore, more stable background statistics (mean and covariance matrix) are estimated. The experimental results show the better performance of the proposed MML-RX method compared with some state-of-the-art anomaly detection methods with reasonable computation time.	anomaly detection;background subtraction;clutter;computation;pixel;rectifier;time complexity;uniform theory of diffraction	Maryam Imani	2017	IEEE Geoscience and Remote Sensing Letters	10.1109/LGRS.2017.2710618		Vision	71.16895843189164	-65.95104220631582	61385
0f1d6f814f7e47b94690bf9f1f3a9d739d5d2e14	mapping and monitoring urban growth on wetlands in humid tropical context using earth observation technology: case study of mangrove zones around douala in cameroon	interferometric land use technique;vegetation mapping;earth observation technology;craft activities;commercial activities;population growth rate;mangrove zones;topography earth;oceans;rivers;economic capital;earth;industrial economics;wetlands;laser radar;interferometric land use technique urban growth mapping urban growth monitoring wetlands earth observation technology mangrove zones douala cameroon commercial activities industrial activities transport activities fishing activities agricultural activities craft activities tourism industry atlantic ocean river wouri brackish humid environment radar processing;agricultural activities;brackish humid environment;river wouri;remote sensing by radar;cameroon;monitoring;land use;atlantic ocean;ecosystems;radar imaging;urban growth monitoring;environmental economics;cities and towns;monitoring earth radar imaging industrial economics laser radar optical interferometry environmental economics surfaces oceans rivers;coherence;earth observation;fishing activities;surfaces;douala;optical interferometry;transport activities;vegetation mapping remote sensing by radar topography earth;urban growth mapping;optical sensor;urban growth;radar processing;meteorology;surface area;tourism industry;industrial activities	Douala, the economic capital of Cameroon, is the hub of the Country in terms of Commercial, industrial, transport, fishing, agricultural, craft activities and the tourism industry. As typical of most tropical metropolis, Douala with 1.5 million inhabitants has a rapid annual population growth rate of more than 5 per cent. The spatial expansion of Douala has been greatly deterred and handicapped by its peninsular environment made up principally of a plane topography that is surrounded by the Atlantic Ocean, River Wouri and a Mangrove ecosystem. This Mangrove occupies a surface area of 2700 Km² along the Fringes of Littoral Cameroon, and typical of brackish humid environments. The main objective of this work was to show how the advance radar processing technique can enable important information to be extracted to characterize mangroves found in the west and south of Douala. This all-weather capability of radar waves is one of the main advantages of imaging radars compared to optical sensors. The Interferometric Land-Use (ILU) technique is useful for quickly assessing of the suitability of an interferometric pair for discrimination between different land use types around the Douala city.	ecosystem;radar;sensor;the hub (forum);topography;usb hub	Ngouanet Chrétien;Ojuku Tiafack;Dzalla Ngangue Guy Charly	2009	2009 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2009.5416900	earth observation;meteorology;lidar;land use;ecosystem;wetland;coherence;hydrology;interferometry;sensor;surface area;economic capital;earth;population growth;radar imaging;surface;tourism;physics;remote sensing	Embedded	80.091499864089	-59.234883761945376	61421
7d418650f54091177e878148637158a0bf87288e	optimal data acquisition in fmri using prolate spheroidal wave functions	prolate spheroidal wave function;fmri;rapid data acquisition;k space sampling;prolate spheroidal wave functions;data acquisition	Abstract#R##N##R##N#Functional magnetic resonance imaging (fMRI) is a technique that can be used to noninvasively study mental activity in a persons brain. fMRI has the potential to answer many interesting questions regarding the way the brain functions. Unfortunately, the drawback to fMRI studies, as they are traditionally performed, is that the temporal resolution is too low to effectively answer questions regarding what happens in an active region of the brain immediately following stimulation. Shepp and Zhang (2000) introduced a new method that could potentially lead to a significant increase in temporal resolution. Their method suggests a way to improve the time resolution in fMRI studies by sampling only a fraction of the points needed to recreate a full image. Instead of full image reconstruction, an optimal prolate spheroidal wave function filter is used to obtain a measurement over the total activity in a predefined region in the brain, B, at successive time points. The sampling region and filter are chosen in order to minimize the energy loss over the region of interest (ROI). The region they suggested to sample was chosen heuristically and corresponds to the scaled polar set of B. It was shown to be near optimal through extensive computer searches. In this article the optimal sampling region is found for the case when the ROI is circular or spherical and the sampling size is small. Based on this result, a new heuristic is introduced for other ROIs, which improves upon the results obtained using the polar set of B. © 2003 Wiley Periodicals, Inc. Int J Imaging Syst Technol 13, 126–132, 2003; Published online in Wiley Inter-Science (www.interscience.wiley.com). DOI 10.1002/ima.10051	data acquisition;prolate spheroidal wave function	Martin A. Lindquist	2003	Int. J. Imaging Systems and Technology	10.1002/ima.10051	speech recognition;computer science;artificial intelligence;data acquisition;statistics	Graphics	55.20258211852128	-79.23058956801263	61423
e25d4eacc83198687389da9c532ee9981e5d4edd	low ph detection in specim eagle-hawk using field spectra at s. domingos mine, se portugal: preliminary results	libraries;spectroscopy;pearson correlation matrix;geochemistry;minerals;pollution measurement;low ph detection method specim eagle hawk s domingos mine se portugal acid mine drainage system imaging spectroscopy data field spectral measurement method high correlation analysis standard spectral libraries spectral angle mapper ad 2007 asdfieldspecpro spectroradiometer calibration method volcanogenic massive sulphide deposits mineralogical assemblages;data analysis;ph;low ph mineralogical assemblages;minerals correlation spectroscopy atmospheric modeling libraries pollution measurement imaging;imaging;low ph mineralogical assemblages acid mine drainage pearson correlation matrix;acid mine drainage;radiometers calibration data analysis geochemistry geophysical techniques minerals ph;atmospheric modeling;correlation;calibration;radiometers;geophysical techniques	To detect the Acid Mine Drainage (AMD) in Imaging Spectroscopy (IS) data, field spectral measurements gathered contemporaneously were selected in function of their high correlation with relevant minerals of standard spectral libraries. Working as a spectra selector, the high correlation values at threshold ≥0.8 are inputted to a full pixel based classifier measuring the angle between spectra (Spectral Angle Mapper, SAM). This methodology is applied to SPECIM EAGLE-HAWK captured over old S. Domingos mine area in 2007. Field measurements were undertaken with an ASDFieldSpecPro spectroradiometer for calibration and on materials previously known as AMD indicators. The mining history dates back to pre-roman times, with an intensive exploitation of Volcanogenic Massive Sulphide deposits, leading to a significant environmental footprint. The isolation of mineralogical assemblages of pH<3 delineates the hot spots at threshold ≥ 0.8, mostly confined to acidic ponds and specific waste piles.	acid;library (computing);pixel	Lidia Quental;Antonio Jorge Sousa;Stuart Marsh	2011	2011 3rd Workshop on Hyperspectral Image and Signal Processing: Evolution in Remote Sensing (WHISPERS)	10.1109/WHISPERS.2011.6080860	mining engineering;geology;hydrology;mineralogy	ML	78.15561852916383	-60.55852029425793	61477
026b82cef7111ad3eab8e328faf39d14507f11ad	better faster noise with the gpu	interaction;computer vision	Filtered noise is a continuous, locally smooth function that is random in the sense that values more than a certain distance apart will be uncorrelated. We would also like it to be isotropic in a statistical sense so if we trace the function along a line its appearance doesn’t depend on the direction of the line. Perlin’s gradient noise has discernible axis aligned artifacts and the very nonrandom property that the value is zero at every point of the rectangular grid used to define the function. You can disguise these defects by adding noise values from non-aligned grids but then it is not so cheap.	apache axis;gradient noise;graphics processing unit;image noise;perlin noise;regular grid	Geoff Wyvill;Jeppe Revall Frisvad	2007		10.1145/1280720.1280915	computer vision;interaction;simulation;computer science;computer graphics (images)	ML	63.94598862218841	-54.2720269979015	61577
8c02d5cd80d933e495a59b6b9bad292a6ec7f557	landslide deformation analysis by coupling deformation time series from sar data with hydrological factors through data assimilation	corner reflectors;landslide;time series;triggering factors;pixel offset tracking;ensemble kalman filter;displacement;data assimilation	Time-series SAR/InSAR techniques have proven to be effective tools for measuring landslide movements over large regions. Prior studies of these techniques, however, have focused primarily on technical innovation and applications, leaving coupling analysis of slope displacements and trigging factors as an unexplored area of research. Linking potential landslide inducing factors such as hydrology to SAR/InSAR derived displacements is of crucial importance for understanding landslide deformation mechanisms and could support the development of early-warning systems for disaster mitigation and management. In this study, a sequential data assimilation method named the Ensemble Kalman filter (EnKF), is adopted to explore the response mechanisms of the Shuping landslide movement in relation to hydrological factors. Previous research on the Shuping landslide area shows that the reservoir water level and rainfall are the two main triggering factors in slope failures. To extract the time-series deformations for the Shuping landslide area, Pixel Offset Tracking (POT) technique with corner reflectors was adopted to process the TerraSAR-X StripMap (SM) and High-resolution Spotlight (HS) images. Considering that these triggering factors are the primary causes of displacement fluctuations in periodic displacement, time-series decomposition was carried out to extract the periodic displacement from the POT measurements. The correlations between the periodic displacement and the inducing factors were qualitatively estimated through a grey relational analysis. Based on this analysis, the EnKF method was adopted to explore the response relationships between the displacements and triggering factors. Preliminary results demonstrate the effectiveness of EnKF in studying deformation response mechanisms and understanding landslide development processes.	dbpedia;data assimilation;displacement mapping;ensemble kalman filter;grey relational analysis;histogram of oriented displacements;interaction;inverse kinematics;pixel;prognostic variable;seasonality;sommerfeld–kossel displacement law;synchronization (computer science);time series;time-scale calculus	Yanan Jiang;Mingsheng Liao;Zhiwei Zhou;Xuguo Shi;Lu Zhang;Timo Balz	2016	Remote Sensing	10.3390/rs8030179	ensemble kalman filter;data assimilation;displacement;hydrology;landslide;machine learning;time series;geotechnical engineering;statistics;remote sensing	HCI	82.17134799648483	-57.93628415097514	61636
6b4643cc2d426ffe47987e505a744d239104a88c	domain decomposition methods with graph cuts algorithms for total variation minimization	domain decomposition;total variation minimization;successive subspace correction;65k10;journal article;65n55;tv l 1 model;68u10;68r10;rof model;graph cuts	Recently, graph cuts algorithms have been used to solve variational image restoration problems, especially for noise removal and segmentation. Compared to time-marching PDE methods, graph cuts based methods are more efficient and able to obtain the global minimizer. However, for high resolution and large-scale images, the cost of both memory and computational time increases dramatically. In this paper, we combine the domain decomposition method and the graph cuts algorithm for solving the total variation minimizations with L (1) and L (2) fidelity term. Numerous numerical experiments on large-scale data demonstrate the proposed algorithm yield good results in terms of computational time and memory usage. Geometry of total variation regularized L-p-model Abstract: In this paper, the geometry and scale selection properties of the total variation (TV) regularized LP-model are rigorously analyzed. Some intrinsic features different from the	algorithm;circuit restoration;computation;cut (graph theory);domain decomposition methods;experiment;image resolution;image restoration;numerical analysis;time complexity;total variation diminishing;variational principle	Yuping Duan;Xue-Cheng Tai	2012	Adv. Comput. Math.	10.1007/s10444-011-9213-4	graph cuts in computer vision;mathematical optimization;combinatorics;cut;graph bandwidth;machine learning;mathematics;domain decomposition methods;tree decomposition	Vision	56.17947156252719	-71.2559950487346	61717
97dd228c6d17be92ac98810636f551783236bfd7	robust fringe projection profilometry via sparse representation	three dimensional displays image reconstruction solid modeling cameras robustness image coding;biological patents;biomedical journals;image coding;text mining;europe pubmed central;citation search;citation networks;sparse coding fringe projection profilometry 3d model reconstruction morphological component analysis mca dictionary learning;research articles;three dimensional displays;abstracts;image reconstruction;learning artificial intelligence image capture image classification image coding image reconstruction image representation image texture;open access;solid modeling;dictionaries;life sciences;clinical guidelines;robustness;sparse dictionary learning robust fringe projection profilometry sparse representation fpp algorithm phase unwrapping process embedded period order information sparse classification procedure modified morphological component analysis encoded fringe image texture patterns objects 3d model sparse coding techniques;full text;rest apis;cameras;orcids;europe pmc;biomedical research;bioinformatics;literature search	In this paper, a robust fringe projection profilometry (FPP) algorithm using the sparse dictionary learning and sparse coding techniques is proposed. When reconstructing the 3D model of objects, traditional FPP systems often fail to perform if the captured fringe images have a complex scene, such as having multiple and occluded objects. It introduces great difficulty to the phase unwrapping process of an FPP system that can result in serious distortion in the final reconstructed 3D model. For the proposed algorithm, it encodes the period order information, which is essential to phase unwrapping, into some texture patterns and embeds them to the projected fringe patterns. When the encoded fringe image is captured, a modified morphological component analysis and a sparse classification procedure are performed to decode and identify the embedded period order information. It is then used to assist the phase unwrapping process to deal with the different artifacts in the fringe images. Experimental results show that the proposed algorithm can significantly improve the robustness of an FPP system. It performs equally well no matter the fringe images have a simple or complex scene, or are affected due to the ambient lighting of the working environment.	20-methylcholanthrene;3d modeling;algorithm;appendix;approximation algorithm;augmented lagrangian method;bam 22p;circular convolution;computational technique;ddr2 wt allele;data compression;dictionary [publication type];discrete fourier transform;discrete subaortic stenosis;distortion;embedded system;embedding;entity name part qualifier - adopted;extraction;first-person (video games);fixed-priority pre-emptive scheduling;frame (linear algebra);immunostimulating conjugate (antigen);initial volume of distribution;instantaneous phase;iterative method;least squares;least-squares analysis;matlab;machine learning;manuscripts;maxima and minima;morphologic artifacts;neural coding;obstruction;pancreatic cholera;personal computers;personal computer;physical object;preparation;projection defense mechanism;projections and predictions;qr code;shading;soft error;sparse approximation;sparse dictionary learning;sparse matrix;structured-light 3d scanner;variable splitting;wavelet analysis;wavelet transform	B. Budianto;Daniel Pak-Kong Lun	2016	IEEE Transactions on Image Processing	10.1109/TIP.2016.2530313	iterative reconstruction;computer vision;text mining;computer science;machine learning;pattern recognition;solid modeling;robustness	Vision	55.61274801323459	-60.01668153465671	61720
65342cbf4881a132a03366fd12c2335c04d8cfc7	fractal image compression for efficient texture mapping	real time;texture mapping;computer graphic;image texture;image generation;level of detail;multi resolution;fractal image compression	Texture mapping has traditionally been used to add visual realism to computer graphics images. In the paper we propose an alternative technique for image texture handling. We use fractal image compression scheme to compress and decompress large and complex textures. We identify special properties of the method to apply in the very process of texture mapping. The main idea is to exploit high degree of local self-similarity in natural textures. The method allows for very high compression of complex textures, provides real-time decompression and perfectly suits Level of Detail. Properties of the method are compared to those of classical DCT and wavelet compression schemes.	computer graphics;data compression;discrete cosine transform;fractal compression;image compression;image texture;level of detail;real-time clock;self-similarity;texture mapping;wavelet transform	Jerzy Stachera;Slawomir Nikiel	2004			image texture;texture mapping;computer vision;adaptive scalable texture compression;displacement mapping;computer science;level of detail;alpha mapping;uvw mapping;multimedia;fractal transform;texture atlas;fractal compression;mipmap;texture compression;texture filtering;projective texture mapping;anisotropic filtering;computer graphics (images)	Graphics	65.4854933083949	-54.188139444284246	61729
5180baeb6335f3850c16d7e11d3babfcd4c5afb4	information-theoretic characterization and undersampling ratio determination for compressive radar imaging in a simulated environment	phase diagrams;rate distortion;clutter;gaussian mixtures;trans information;undersampling ratios;compressive sampling	Assuming sparsity or compressibility of the underlying signals, compressed sensing or compressive sampling (CS) exploits the informational efficiency of under-sampled measurements for increased efficiency yet acceptable accuracy in information gathering, transmission and processing, though it often incurs extra computational cost in signal reconstruction. Shannon information quantities and theorems, such as source rate-distortion, trans-information and rate distortion theorem concerning lossy data compression, provide a coherent framework, which is complementary to classic CS theory, for analyzing informational quantities and for determining the necessary number of measurements in CS. While there exists some information-theoretic research in the past on CS in general and compressive radar imaging in particular, systematic research is needed to handle issues related to scene description in cluttered environments and trans-information quantification in complex sparsity-clutter-sampling-noise settings. The novelty of this paper lies in furnishing a general strategy for information-theoretic analysis of scene compressibility, trans-information of radar echo data about the scene and the targets of interest, respectively, and limits to undersampling ratios necessary for scene reconstruction subject to distortion given sparsity-clutter-noise constraints. A computational experiment was performed to demonstrate informational analysis regarding the scene-sampling-reconstruction process and to generate phase transition diagrams showing relations between undersampling ratios and sparsity-clutter-noise-distortion constraints. The strategy proposed in this paper is valuable for information-theoretic analysis and undersampling theorem developments in compressive OPEN ACCESS Entropy 2015, 17 5172 radar imaging and other computational imaging applications.	algorithmic efficiency;approximation algorithm;clutter;coherence (physics);compressed sensing;computation;computer-generated holography;contingency (philosophy);data compression;diagram;distortion;graphics;information theory;interference (communication);lossy compression;performance evaluation;radar;rate–distortion theory;sampling (signal processing);self-information;sensor;shannon (unit);signal reconstruction;source-to-source compiler;sparse matrix;thrust;undersampling	Jingxiong Zhang;Ke Yang;Fengzhu Liu	2015	Entropy	10.3390/e17085171	computer vision;mathematics;clutter;thermodynamics;compressed sensing;phase diagram;physics;statistics	Vision	66.41977547467732	-71.34738259324476	61737
5fc5f12fd309f3af994c8a8fa5cb188870e6566c	rapid detection of new and expanding human settlements in the limpopo province of south africa using a spatio-temporal change detection method	change detection;settlements;time series;postprint article;hyper temporal;article;autocorrelation	Recent development has identified the benefits of using hyper-temporal satellite time series data for land cover change detection and classification in South Africa. In particular, the monitoring of human settlement expansion in the Limpopo province is of relevance as it is the one of the most pervasive forms of land-cover change in this province which covers an area of roughly 125 000km. In this paper, a spatio-temporal autocorrelation change detection (STACD) method is developed to improve the performance of a pixel based temporal Autocorrelation change detection (TACD) method previously proposed. The objective is to apply the algorithm to large areas to detect the conversion of natural vegetation to settlement which is then validated by an operator using additional data (such as high resolution imagery). Importantly, as the objective of the method is to indicate areas of potential change to operators for further analysis, a low false alarm rate is required while achieving an acceptable probability of detection. Results indicate that detection accuracies of 70% of new settlement instances are achievable at a false alarm rate of less than 1% with the STACD method, an improvement of up to 17% compared to the original TACD formulation.	algorithm;autocorrelation;google book search settlement agreement;image resolution;pervasive informatics;pixel;relevance;time series;trans atlantic consumer dialogue	Waldo Kleynhans;Brian P. Salmon;Konrad J. Wessels;J. Corné Olivier	2015	Int. J. Applied Earth Observation and Geoinformation	10.1016/j.jag.2015.04.009	human settlement;autocorrelation;geography;time series;mathematics;change detection;cartography;statistics;remote sensing	ML	81.63038137911116	-55.96911725730133	61757
d78d3511a61909206f79498a0593f53ee6ae719d	laser print quality: practically continuous addressability	printing;imprimante laser;nonimpact printing;antialiasage;lasers;4230;modulation duree impulsion;etude experimentale;0130c;localization;quality improvement;localizacion;pulse width modulated;positioning;haute resolution;localisation;antialiasing;pixel;resolution enhancement;laser printers;antimelladura;impression;imagen color;pulse width modulation;image couleur;high resolution methods;color image;positionnement;modulation	A novel method for resolution enhancement of Electro Photographic (EP) printers is presented. The proposed method is applicable for laser printers that have a partial-pixel exposure capability such as Pulse Width Modulation (PWM). By coupling partial exposure with anti-aliasing rendering, the proposed technology enables practically continuous addressability, namely, placement resolution. Using this technology we can show significant print quality improvement, such as the ability to render lines with arbitrary width and location. This would allow printing smooth line art at any angle with a relatively coarse pixel grid. The proposed method will thus provide better print quality compared to post process type resolution enhancement alternatives used today. The method has been tested theoretically using a Liquid EP (LEP) model, and experimentally confirmed.	aliasing;anti-aliasing;expectation propagation;experiment;liquid state machine;pixel;printing;pulse-width modulation	Mani Fischer;Doron Shaked;Gidi Amir;Craig Breen;Dror Kella	2008		10.1117/12.766351	computer vision;quality management;internationalization and localization;color image;laser;telecommunications;computer science;pulse-width modulation;optics;pixel;modulation	EDA	62.082196010803955	-59.03339941617451	61837
13d82bdb7104ba02553d11010b62aebafaef009e	error-amended sharp edge (ease) schemes for image interpolation	image zooming;interpolation;interpolation error theorem image zooming error amended sharp edge scheme ease scheme modified bilinear method;image resolution;interpolation image resolution;image interpolation;indexing terms;interpolation error theorem;interpolation method;interpolation mathematics kernel image resolution image sampling discrete transforms partial differential equations anisotropic magnetoresistance gray scale color;error amended sharp edge scheme;interpolation error theorem error amended sharp edge scheme image zooming interpolation	This article proposes a new interpolation method, called the error-amended sharp edge (EASE) scheme. EASE is a modified bilinear method which tries to amend the interpolation error in an edge-adaptive way by employing the interpolation error theorem. The resulting scheme has proved to result in zoomed images having sharper edges than bilinear, C1-bicubic, and C2-bicubic interpolation methods. EASE is similarly efficient as cubic interpolation methods and can be implemented with ease.	algorithmic efficiency;bilinear filtering;cubic hermite spline;linear interpolation	Youngjoon Cha;Seongjai Kim	2006	2006 International Conference on Image Processing	10.1109/ICIP.2006.312431	spline interpolation;demosaicing;interpolation;computer vision;mathematical optimization;discrete mathematics;bilinear interpolation;trigonometric interpolation;index term;image resolution;monotone cubic interpolation;interpolation;polynomial interpolation;computer science;stairstep interpolation;inverse quadratic interpolation;tricubic interpolation;bicubic interpolation;mathematics;geometry;linear interpolation;nearest-neighbor interpolation;multivariate interpolation;trilinear interpolation;image scaling	Robotics	58.306029919929834	-64.96840739461004	61864
5186e6f4a1033108e62501626fbe3e7907bc3c90	pixel classified colourisation method based on neighbourhood similarity priori		Colourisation is a kind of computer-aided technology which automatically adds colours to greyscale images. This paper presents a scribble-based colourisation method which treats the flat and edge pixels differently. First, we classify the pixels to flat or edge pixel categories using the neighbourhood similarity pixels searching algorithm. Then, we compute the weighted coefficients of the edge pixels by solving a constraint quadratic programming problem and compute the weighted coefficients of the flat pixels based on their luminance distances. Finally, we transmit the weighted coefficients to the chrominance images according to the joint correlation property between luminance and chrominance channels, and combine with the colours scribbled on by the user to compute all the unknown colours. The experimental results show that our method is effective especially on reducing colour bleeding in the boundary parts and can give better results when only a few colours are scribbled on.	pixel	Jie Chen;Zongliang Gan;Xiuchang Zhu;Zhongjing Wang	2018	IJHPCN	10.1504/IJHPCN.2018.10016379	grayscale;computer science;distributed computing;computer vision;pixel;chrominance;quadratic programming;neighbourhood (mathematics);search algorithm;luminance;artificial intelligence;communication channel	NLP	56.17245742736661	-63.935598535873496	62001
65e63f514bc02e20bf4e46b3ea775334002cdd05	a discrete/continuous minimization method in interferometric image processing	bayes estimation;estimation phase;valor absoluto;image processing;bayesian approach;absolute value;iterated conditional mode;interferometrie;procesamiento imagen;estimation a posteriori;gauss markov random field;image bruitee;traitement image;a posteriori estimation;imagen sonora;estimacion bayes;valeur absolue;first order;estimacion a posteriori;phase estimation;noisy image;map estimation;interferometry;interferometria;network programming;estimation bayes	The 2D absolute phase estimation problem, in interferometric applications, is to infer absolute phase (not simply modulo-2π) from incomplete, noisy, and modulo-2π image observations. This is known to be a hard problem as the observation mechanism is nonlinear. In this paper we adopt the Bayesian approach. The observation density is 2π-periodic and accounts for the observation noise; the a priori probability of the absolute phase is modeled by a first order noncausal Gauss Markov random field (GMRF) tailored to smooth absolute phase images. We propose an iterative scheme for the computation of the maximum a posteriori probability (MAP) estimate. Each iteration embodies a discrete optimization step (Z-step), implemented by network programming techniques, and an iterative conditional modes (ICM) step (π-step). Accordingly, we name the algorithm ZπM, where letter M stands for maximization. A set of experimental results, comparing the proposed algorithm with other techniques, illustrates the effectiveness of the proposed method.	computation;computer network programming;discrete optimization;expectation–maximization algorithm;image processing;iterated conditional modes;iteration;markov chain;markov random field;mathematical optimization;nonlinear system;quantum phase estimation algorithm	Jos&#x00E9; M. Bioucas-Dias;José M. N. Leitão	2001		10.1007/3-540-44745-8_25	computer vision;econometrics;mathematical optimization;absolute value;image processing;bayesian probability;computer science;interferometry;first-order logic;mathematics;programming language;computer network programming;statistics	Vision	54.69339355819018	-72.90647910326656	62008
111edaceef5afb078d025db01f5c756c312d081e	first delay doppler maps obtained with the microwave inteferometric reflectometer (mir)	global navigation satellite system relectometer gnss r;instruments;delay doppler map geophysical retrieval algorithm geros iss payload mir instrument beam steering antenna gps galileo satellite land observation ocean observation ignss r interferometric gnss reflectometer cgnss r conventional gnss reflectometer mir airborne instrument microwave inteferometric reflectometer;altimetry;remote sensing antennas global positioning system;delays doppler effect correlation global positioning system instruments satellites field programmable gate arrays;doppler effect;global positioning system;satellites;conference report;altimetry global navigation satellite system relectometer gnss r;correlation;field programmable gate arrays;delays	This work presents the first Delay Doppler Maps (DDMs) obtained with the Microwave Interferometric Reflectometer (MIR) airborne instrument. MIR is a GNSS Reflectometer (GNSS-R) which uses the conventional (cGNSS-R) and interferometric (iGNSS-R) techniques for ocean and land observation. It computes real-time sample-to-sample complex DDMs with averaging and alignment, of up to 4 simultaneous GPS/Galileo satellites at the L1/E1, and L5/E5a bands. Satellites are tracked with high directivity antennas with beam steering. The MIR instrument is designed to validate and compare both GNSS-R techniques with the new available signals, with special focus in the GEROS-ISS payload, and to contribute to the development of geophysical retrieval algorithms.	airborne ranger;algorithm;galileo (satellite navigation);global positioning system;microwave;real-time locating system;s-gps;satellite navigation;time-domain reflectometer	Daniel Pascual;Raul Onrubia Ibáñez;Jorge Querol;Alberto Alonso Arroyo;Hyuk Park;Adriano Camps	2016	2016 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)	10.1109/IGARSS.2016.7729514	meteorology;global positioning system;doppler effect;geodesy;altimeter;correlation;physics;satellite;field-programmable gate array;remote sensing	Embedded	79.9243779585867	-65.26186893012363	62053
c10745f4164848247cced706e7981051e985318f	the application of filtered transforms to the general classification problem	time varying;image processing;fourier transform;walsh transform;image classification;feature extraction fourier transform hadamard transform image classification image processing pattern recognition walsh transform;feature extraction;pattern recognition;hadamard transform;computer simulation;harmonic analysis	An image classification model based on nearest prototypes in filtered Fourier and Walsh transform domains is presented. A computer simulation of the model applied to handwritten English letters, Russian letters, numerals, and electromagnetic signals is also presented. Experiments to date fail to refute the working hypothesis that generalized harmonic analysis can be used to reliably classify alphabet characters, time-varying signals, and other images.	computer simulation;computer vision;experiment;hadamard transform	Joseph W. Carl;Charles F. Hall	1972	IEEE Transactions on Computers	10.1109/T-C.1972.223582	computer simulation;arithmetic;hough transform;discrete hartley transform;constant q transform;speech recognition;hartley transform;s transform;harmonic wavelet transform;hadamard transform;short-time fourier transform;continuous wavelet transform;image processing;computer science;fractional fourier transform;discrete fourier transform;harmonic analysis;pattern recognition;mathematics;discrete fourier transform;fourier analysis;top-hat transform	Vision	67.68395687900232	-58.55930916398828	62188
5550563a2397cb43f559e9abe5b8f7e35b59e018	land masking method for sar-based ship detection in coastal waters of many islands		This is a short summary of a published work on Synthetic Aperture Radar (SAR)-based land masking for ship detection after applying little modification in the original process [1]. The land masking in SAR images is commonly done by using either archived shoreline databases or an image segmentation which cannot appropriately masks all of the very small islets and exposed sea rocks in the coastal regions of Korean Peninsula. Therefore, in previous work coastline maps from Electronic Navigational Chart (ENC) were just used to retain the land objects from all extracted objects of KOMPSAT-5 images. In this study the method [1] is further improved by applying the ENC-based topography data at various depths which can also mask small sea rocks submerged just beneath the sea surface. Thus, this improved method of land masking could be useful for precise ship detection in SAR images, especially for the geographically complicated coastal regions with many small islets, exposed and submerged sea rocks like Korean Peninsula.	aperture (software);archive;database;image segmentation;map;norm (social);synthetic data;topography;unsharp masking	Chan-Su Yang;Ju-Han Park;Ahmed Harun-Al-Rashid	2018	IGARSS 2018 - 2018 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2018.8518147	computer vision;remote sensing;artificial intelligence;shore;image segmentation;peninsula;synthetic aperture radar;masking (art);electronic navigational chart;computer science	Vision	79.05116193476235	-58.59281673782306	62227
aac799300a3545f7a63ec35cc50a31ed8571f4c0	spatial co-registration of ultra-high resolution visible, multispectral and thermal images acquired with a micro-uav over antarctic moss beds	uav;image processing;co registration;bepress selected works;antarctica;thermal infrared;uav image co registration multispectral thermal infrared antarctica moss;image co registration;moss;multispectral;multi sensor	In recent times, the use of Unmanned Aerial Vehicles (UAVs) as tools for environmental remote sensing has become more commonplace. Compared to traditional airborne remote sensing, UAVs can provide finer spatial resolution data (up to 1 cm/pixel) and higher temporal resolution data. For the purposes of vegetation monitoring, the use of multiple sensors such as near infrared and thermal infrared cameras are of benefit. Collecting data with multiple sensors, however, requires an accurate spatial co-registration of the various UAV image datasets. In this study, we used an Oktokopter UAV to investigate the physiological state of Antarctic moss ecosystems using three sensors: (i) a visible camera (1 cm/pixel), (ii) a 6 band multispectral camera (3 cm/pixel), and (iii) a thermal infrared camera (10 cm/pixel). Imagery from each sensor was geo-referenced and mosaicked with a combination of commercially available software and our own algorithms based on the Scale Invariant Feature Transform (SIFT). The validation of the mosaic’s spatial co-registration revealed a mean root mean squared error (RMSE) of 1.78 pixels. A thematic map of moss health, derived from the multispectral mosaic using a Modified Triangular Vegetation Index (MTVI2), and an indicative map of moss surface temperature were then combined to demonstrate sufficient accuracy of our co-registration methodology for UAV-based monitoring of Antarctic moss beds. OPEN ACCESS Remote Sens. 2014, 6 4004	aerial photography;airborne ranger;algorithm;ecosystem;high-resolution scheme;mean squared error;multispectral image;pixel;sensor;thematic map;unmanned aerial vehicle	Darren Turner;Arko Lucieer;Zbynek Malenovský;Diana H. King;Sharon A. Robinson	2014	Remote Sensing	10.3390/rs6054003	multispectral image;computer vision;image processing;remote sensing	Mobile	78.79992090188478	-56.77126717169923	62345
f567f3a1ad2c841d7de3ad786998b2ef28433135	importance sampling of many lights with adaptive tree splitting		We present a technique to importance sample large collections of lights. A bounding volume hierarchy over all lights is traversed at each shading point using a single random number in a way that importance samples their predicted contribution. We further improve the performance of the algorithm by forcing splitting until the importance of a cluster is sufficiently representative of its contents.	algorithm;bounding volume hierarchy;importance sampling;random number generation;sampling (signal processing);shading	Alejandro Conty Estevez;Christopher D. Kulla	2017		10.1145/3084363.3085028	importance sampling;computer vision;computer graphics (images);artificial intelligence;shading;bounding volume hierarchy;computer science;ray tracing (graphics);forcing (mathematics)	ML	64.62086258840215	-52.42375748499748	62356
616b2bb7f8fd0a5d1ebd78228efeb5550cc986de	massive data input system for geographical origin identification system of vegetables using trace element compositions	agricultural products;chemical elements instruments agricultural products databases plasma measurements data mining intrusion detection soil computer science mass spectroscopy;trace element;closed system;compositional data;agricultural engineering;statistical testing;smirnov test massive data input system vegetable geographical origin identification system trace element composition agricultural chemist;radiofrequency identification;statistical testing agricultural engineering agricultural products radiofrequency identification	As co-research with agricultural chemists, we developed a vegetable geographical origin identification system using difference of trace element compositions of vegetables from cultivated districts. The system works well to identify geographical origin of vegetables in our previous works. However, there are some problems to gather trace element compositions data. Generally, measured trace element data contains outlying observations, and normally an experimenter removes these kinds of outlying observations. However, in case of massive data must be registered in short time, checking of measured data by hand is an obstruction to automatically registration. Therefore, in this paper, we describe about trial to introduce outlying observation detector using Smirnov test. Also, we describe about how to extract measured data in electronic form from measuring instruments such as ICP-MS which are normally closed system	closed system;robertson–seymour theorem;switch	Nobuyoshi Sato;Minoru Uehara;Koichiro Shimomura;Hirobumi Yamamoto;Ken'ichi Kamijo	2007	2007 International Symposium on Applications and the Internet Workshops	10.1109/SAINT-W.2007.63	statistical hypothesis testing;closed system;trace element	Security	78.61815049952143	-55.523614157915205	62401
0b76b43f5fdcf569ceff34be285d37e6a05aa22e	evolutionary design of evolvable hardware image filters using fuzzy noise models	image filter;cartesian genetic programming;evolvable hardware;salt and pepper noise;fuzzy sets	Image filtering, which removes or reduces noise from contaminated images, is an important task in image processing. This study deals with evolutionary design of image filters that can be implemented on evolvable hardware platforms using fuzzy noise models. Two fuzzy sets, similarity and divergence, are defined for classifying noise. Three filtering modules for pixels with various degrees of noise contamination are trained supervisedly by Cartesian genetic programming. The recovery of a noisy pixel is the fuzzy weighted sum of the output from the three filtering modules. Because each image filter is dedicated to a specific type of noise, it can produce a more accurate value for pixel recovery. With the proposed method, better accuracy of image filtering can be obtained. This paper evaluates and compares the performance of our proposed method with other ones.	composite image filter;continuous design;evolvable hardware;filter (signal processing);fitness function;fuzzy set;genetic programming;image processing;iteration;jung;parallel computing;pixel;vergence;weight function	Chih-Hung Wu;Chien-Jung Chen;Chin-Yuan Chiang	2014	J. Inf. Sci. Eng.		median filter;computer vision;computer science;theoretical computer science;machine learning;fuzzy set;composite image filter;salt-and-pepper noise	Vision	55.80261073846098	-65.17883919845954	62498
135a4ae6ad8b243b001f2b20faa179f81c4756d6	high quality depth estimation for multi-view video				Qiang Li	2012				Vision	57.111036872247475	-54.3510603561431	62570
55ac3559db26c9b7ee035d025391e55bb4a7084d	an ihs-based pan-sharpening method for spectral fidelity improvement using ripplet transform and compressed sensing	image fusion;intensity-hue-saturation transform;remote sensing;ripplet transform;sparse representation	Pan-sharpening aims at integrating spectral information from a multi-spectral (MS) image and spatial information from a panchromatic (PAN) image in a fused image with both high spectral and spatial resolutions. Numerous pan-sharpening methods are based on intensity-hue-saturation (IHS) transform, which may cause evident spectral distortion. To address this problem, an IHS-based pan-sharpening method using ripplet transform and compressed sensing is proposed. Firstly, the IHS transform is applied to the MS image to separate intensity components. Secondly, discrete ripplet transform (DRT) is implemented on the intensity component and the PAN image to obtain multi-scale sub-images. High-frequency sub-images are fused by a local variance algorithm and, for low-frequency sub-images, compressed sensing is introduced for the reconstruction of the intensity component so as to integrate the local information from both the intensity component and the PAN image. The specific fusion rule is defined by local difference. Finally, the inverse ripplet transform and inverse IHS transform are coupled to generate the pan-sharpened image. The proposed method is compared with five state-of-the-art pan-sharpening methods and also the Gram-Schmidt (GS) method through visual and quantitative analysis of WorldView-2, Pleiades and Triplesat datasets. The experimental results reveal that the proposed method achieves relatively higher spatial resolution and more desirable spectral fidelity.		Chen Yang;Qingming Zhan;Huimin Liu;Ruiqi Ma	2018		10.3390/s18113624	compressed sensing;engineering;electronic engineering;fidelity;sharpening	Vision	67.00077686268939	-66.29668528556311	62616
82b5947d815f6f572592208c25f9bdb7a1812275	land-cover monitoring using time-series hyperspectral data via fractional-order darwinian particle swarm optimization segmentation		This paper presents a new method for unsupervised detection of multiple changes using time-serires hyperspectral data. The proposed method is based on fractional-order Darwinian particle swarm optimization (FODPSO) segmentation. The proposed method is applied to monitor land-cover changes following the Fukushima Daiichi nuclear disaster using multitemporal Hyperion images. Experimental results indicate that the integration of segmentation and a time-series of hyperspectral images has great potential for unsupervised detection of multiple changes.	hyperion;mathematical optimization;particle swarm optimization;time series;unsupervised learning	Naoto Yokoya;Pedram Ghamisi	2016	2016 8th Workshop on Hyperspectral Image and Signal Processing: Evolution in Remote Sensing (WHISPERS)	10.1109/WHISPERS.2016.8071761	land cover;time series;scale-space segmentation;hyperspectral imaging;computer vision;segmentation;particle swarm optimization;pattern recognition;artificial intelligence;computer science	Robotics	73.82295744173877	-61.031658365817606	62746
01aa59c9d15a753102b998d00d859bacf56d8107	relighting of dynamic video	3d;multimedia application;indexing terms;face;specularity;relighting	We present a novel method to relight video sequences for multimedia applications given known surface shape and original illumination. The method preserves fine visual details. It requires single view video frames, approximate 3D shape and known illumination only, making it applicable for multimedia and studio production. The technique is demonstrated for relighting video sequences of faces. Index terms — relighting, face, 3D, specularity	3d computer graphics;approximation algorithm;color image;fits;frame (video);image resolution;light field;normal (geometry);specularity	Péter Csákány;Adrian Hilton	2006	Journal of Multimedia	10.4304/jmm.1.3.23-30	face;computer vision;index term;computer science;multimedia;3d computer graphics;computer graphics (images)	Vision	58.41958214675447	-53.82288401029004	62776
1ecef3559ed2af0a89ce444f04b442bc34568a58	optimal filtered backprojection for fast and accurate tomography reconstruction		Tomographic reconstruction is a method of reconstructing a high dimensional image with a series of its low dimensional projections, and the filtered backprojection is one of very popular analytical techniques for the reconstruction due to its computational efficiency and easy of implementation. The accuracy of the filtered backprojection method deteriorates when input data are noisy or input data are available for only a limited number of projection angles. For the case, some algebraic approaches perform better, but they are based on computationally slow iterations. We propose an improvement of the filtered backprojection method which is as fast as the existing filtered backprojection and is as accurate as the algebraic approaches under heavy observation noises and limited availability of projection data. The new approach optimizes the filter of the backprojection operator to minimize a regularized reconstruction error. We compare the new approach with the state-of-the-art in the filtered backprojection and algebraic approaches using four simulated datasets to show its competitive accuracy and computing speed.	autocorrelation;electron tomography;experiment;gaussian process;iteration;limited availability;linear algebra;mathematical optimization;optimization problem;pixel;spatial analysis;thresholding (image processing);tomographic reconstruction	Chen Mu;Chiwoo Park	2016	CoRR		computer vision;mathematical optimization;theoretical computer science;mathematics	Vision	57.51826509426633	-74.49658284836136	62839
93d5ed76a0a0cdb9a9b3751a3d4e4493b0ee67d0	optimization for blob-based image reconstruction with generalized kaiser–bessel basis functions		Generalized Kaiser–Bessel radial basis functions are frequently used in tomographic reconstructions, and the parameter selection can significantly impact both the qualitative and quantitative image characteristics. Currently, the blob parameters are simply selected based on the first-order approximation of a uniform object. To obtain optimal images, a detailed investigation and optimization of blob parameters is needed. In this paper, we aim at optimizing the parameters of the basis functions for optimal image representation and image reconstruction. We first represent the unknown radiotracer activity distribution as the coefficients of blob basis functions on a Bravais lattice from crystallography. We point out that the optimal sampling lattice is just the reciprocal of the lattice that achieves highest packing of equally sized spheres. Based on multidimensional sampling theorem and the Kepler conjecture (proven by Thomas C. Hales), we obtain that the body-centered cubic (BCC) and hexagonal close-packing lattices are optimal in terms of either reducing computational cost at similar image quality or improving image quality at the same computational cost. To optimize the blob parameters, we formulate two new image quality metrics—total harmonic distortion (THD) and minimum approximation error (MAE) based on the theory of approximation—to analytically characterize the blob representation errors of a nonzero uniform object and an arbitrary object, respectively. The MAE is formulated in terms of the power spectral density of an imaging object, and we use it for object-dependent blob parameter optimization. We validate the THD and MAE through numerical examples using homogeneous and heterogeneous objects, respectively. We also present 3-D blob-based image reconstructions using BCC lattice with different shape parameters to show the usefulness of the proposed optimization.	algorithmic efficiency;approximation algorithm;approximation error;bessel filter;bricx command center;coefficient;computation;cubic function;first-order predicate;image quality;iterative reconstruction;kepler;mathematical optimization;multidimensional sampling;numerical analysis;nyquist–shannon sampling theorem;order of approximation;radial (radio);radial basis function;sampling (signal processing);set packing;spectral density;tomographic reconstruction;total harmonic distortion	Yusheng Li	2018	IEEE Transactions on Computational Imaging	10.1109/TCI.2018.2796302	total harmonic distortion;kepler conjecture;mathematics;mathematical optimization;iterative reconstruction;basis function;image quality;bravais lattice;approximation error;multidimensional sampling	Vision	63.57293094246786	-69.6282874057414	62840
3501b48f90da62bcca1de5aeef3f34623e2df0e1	mangrove species identification: comparing worldview-2 with aerial photographs	mangrove species mapping;aerial photographs;object based image analysis;worldview 2;support vector machine	Remote sensing plays a critical role in mapping and monitoring mangroves. Aerial photographs and visual image interpretation techniques have historically been known to be the most common approach for mapping mangroves and species discrimination. However, with the availability of increased spectral resolution satellite imagery, and advances in digital image classification algorithms, there is now a potential to digitally classify mangroves to the species level. This study compares the accuracy of mangrove species maps derived from two different layer combinations of WorldView-2 images with those generated using high resolution aerial photographs captured by an UltraCamD camera over Rapid Creek coastal mangrove forest, Darwin, Australia. Mangrove and non-mangrove areas were discriminated using object-based image classification. Mangrove areas were then further classified into species using a support vector machine algorithm with best-fit parameters. Overall classification accuracy for the WorldView-2 data within the visible range was 89%. Kappa statistics provided a strong correlation between the classification and validation data. In contrast to this accuracy, the error matrix for the automated classification of aerial photographs indicated less promising results. In summary, it can be concluded that mangrove species mapping using a support vector machine algorithm is more successful with WorldView-2 data than with aerial photographs. OPEN ACCESS Remote Sens. 2014, 6 6065	aerial photography;algorithm;computer vision;curve fitting;darwin;digital image;image processing;image resolution;metric;map;object-based language;random forest;recommender system;support vector machine	Muditha K. Heenkenda;Karen E. Joyce;Stefan W. Maier;Renee Bartolo	2014	Remote Sensing	10.3390/rs6076064	support vector machine;computer vision;machine learning;remote sensing	Robotics	79.2044056278295	-56.95434003201884	62867
854f65a2935c3956f3eb73cc0dd3fa1d54aa4819	new decision-based trimmed median filter for high-density salt-and-pepper noise removal in images	single mode fibers;algorithms;denoising;radiometric corrections	A new switching-based trimmed median filter to remove high-density salt-and-pepper noise in digital images is proposed. Initially, a 3×3 sliding window is applied on each pixel in the noisy image. The minimum- and maximum-intensity values are trimmed, and the noisy pixels are detected based on the predefined threshold value. In the filtering stage, the noisy pixels are replaced by median value of uncorrupted pixels in the trimmed array. At very high noise density, if all the pixels in the sliding window are corrupted, then the proposed algorithm replaces noisy pixels by the midpoint of recently processed pixels. The experimental results for various test images show that the performance of the proposed algorithm is superior to the existing algorithms, namely SMF, WMF, CWMF, AMF, DBA, and MDBUTMF in terms of visual quality and edge preservation, even at noise levels as high as 95%.	median filter;salt-and-pepper noise	Vaithiyam Rengarajan Vijaykumar;Guru Santhanamari	2014	J. Electronic Imaging	10.1117/1.JEI.23.3.033011	computer vision;computer science;pattern recognition;noise reduction;algorithm;statistics	Robotics	56.88533081954409	-65.5275520888912	62891
51c2141087f6e279f613524b3ac42fc23db665fb	covariance estimation in terms of stokes parameters with application to vector sensor imaging	convergence;manifolds;stokes parameters;maximum likelihood estimation;acceleration;covariance matrices	Vector sensor imaging presents a challenging problem in covariance estimation when allowing arbitrarily polarized sources. We propose a Stokes parameter representation of the source covariance matrix which is both qualitatively and computationally convenient. Using this formulation, we adapt the proximal gradient and expectation maximization (EM) algorithms and apply them in multiple variants to the maximum likelihood and least squares problems. We also show how EM can be cast as gradient descent on the Riemannian manifold of positive definite matrices, enabling a new accelerated EM algorithm. Finally, we demonstrate the benefits of the proximal gradient approach through comparison of convergence results from simulated data.	expectation–maximization algorithm;gradient descent;least squares;proximal gradient methods for learning;stokes parameters	Ryan Volz;Mary Knapp;Frank D. Lind;Frank C. Robey	2016	2016 50th Asilomar Conference on Signals, Systems and Computers	10.1109/ACSSC.2016.7869593	estimation of covariance matrices;econometrics;mathematical optimization;covariance;mathematics;statistics;covariance function	ML	55.267131018439656	-74.51667698391842	62921
5d5780e00640548c65a02ff3cc7b5bec0915ea78	a reflectance model for radar shape from shading	empirical study;shape from shading;terrain analysis;large scale;reflection model;radar imaging;ground truth	This paper describes work aimed at developing a practical shape-from-shading process for terrain analysis from radar imagery. The paper commences by providing an analysis of the radar reflectance properties of terrain structures. By using ground truth elevation data, we provide an empirical study of the radar reflectance characteristics for large-scale terrain features. The main conclusion of this study are twofold. Firstly, we show that radar has a strong backscatter component. Secondly, we show that the radar noise has a tail which extends to large reflectance values. Based on these observations we develop a semi-empirical shape-from-shading algorithm. We illustrate the effectiveness of the algorithm in extracting surface orientation information from radar images of a mountainous area of terrain in North Wales.	algorithm;backscatter (email);ground truth;photometric stereo;radar;semiconductor industry;shading	Richard C. Wilson;Edwin R. Hancock	1999		10.5244/C.13.16	computer vision;photometric stereo;ground truth;computer science;radar horizon;radar imaging;empirical research	Robotics	76.3931873468205	-59.627745084824454	62997
7e1ff5d4ebbc53dbe21cbc7f6fab7eaf92e0504b	a method to create stable lighting and remove specular reflections for vision systems		A lighting system and method has been developed which has shown in testing to allow quality images to be obtained that are free from two particular problems, specular reflections on the subject, and light intensity variation. These problems both diminish the ability to compare objects for attributes such as colour variation, edges, contours, and many other features. The system developed eliminates specular reflection by using the cross-polarisation configuration, and reduced flickering due to fluctuations in the power supply to negligible levels by constructing a high-power DC source capable of providing sufficient 12 Volt power. These two improvements create an environment suitable for taking high-quality, noise free images at high shutter speeds for the purpose of assessing the quality of strawberries moving on a real-time production line.		Gilbert Eaton;Andrew Busch;Rudi Bartels;Yongsheng Gao	2017	2017 International Conference on Digital Image Computing: Techniques and Applications (DICTA)	10.1109/DICTA.2017.8227392	flicker;computer vision;artificial intelligence;computer science;shutter speed;specular reflection;surface wave	Robotics	60.743957326172705	-56.755266426170785	62999
0ec7d7774546a498c1c3749398ec54f013499cfe	detection of salient features in surface current maps from dopplerized x-band radar	eigenvalues and eigenfunctions;temporal varying bottom topography;radar data;experimental analysis;tensile stress;sea state images;real time monitoring;radar imaging optical radar;surface current maps;surface topography;sea surface doppler radar tensile stress surface topography eigenvalues and eigenfunctions image edge detection;sea surface;optical radar;image edge detection;coastal protection actions;spatial varying bottom topography;radar imaging;salient features;doppler radar;image processing methods;surface current;length scale;dopplerized x band radar;morphodynamic processes;coastal area;radar data salient features surface current maps dopplerized x band radar spatial varying bottom topography temporal varying bottom topography morphodynamic processes coastal protection actions image processing methods sea state images	Fig. 2 shows the maps of water depth and current magnitude. For consistency the finer bathymetry map was mapped onto the 15m ·15m grid of the RDCP analysis. The large bed dunes are clearly visible and position and orientation of the crests identified in most cases by the structure tensor method. Fig. 3. Digital terrain model with the current edges detected on an RDCP current map overlayed, demonstating the influence of bottom on the surface current (left). ADCP vertical current profile, showing hydrodynamic modulation (right). The current fields show a modulation in magnitude that obviously resembles the sea bed topology in the middle end eastern part (x > 600 m), although the algorithm did identify more salient structures here. This may be due to the fact that the two coherency thresholds for selecting the edges do not consistently mirror the fact that the edges are more pronounced in the digital terrain model than in the current map in the algorithm now implemented. The current modulation is most likely due to the flow continuity through the varying cross sections of the water column. This hdyrodynamic interaction of surface current with bottom topography was already indirectly observed in a modulation of the normalized radar cross section [6]. With the RDCP, however, this effect can be observed directly [7]. It shows up also in the vertical current component (s. Fig. 3). In the western part, the orientation of the current “edges” is nearly perpendicular to the bed dunes. A thorough topological analysis of bathymetry and current features is presently under investigation.	algorithm;bathymetry;cross section (geometry);digital elevation model;fractal dimension;map;modulation;radar;scott continuity;structure tensor;topography;xfig	Jörg Seemann;Marius Cysewski;Friedwart Ziemer;Martina Heineke;Rolf Riethmüller	2010	2010 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2010.5653778	meteorology;hydrology;stress;ocean current;radar imaging;length scale;physics;remote sensing;experimental analysis of behavior	Robotics	77.15345561179201	-62.69163853417926	63063
656d4a4238c3e50e04e8657510f832156bf0c0d1	target detection using pca and stochastic features	image processing;false alarm rate;linear discriminate analysis;signal processing;principal component analysis;infrared;target detection;electro optic	Automatic target detection (ATD) system which uses forward-looking infrared (FLIR) consists of two stages: image signal processing and clutter rejection. Images from electro-optical sensors are processed to express target well in signal processing stage. And true targets are well identified in clutter rejection stages. However, it is difficult to process target express well and to identify target from target candidates because they are obscure and there are many target-like objects. We propose new target detection algorithm using PCA and stochastic features. The proposed algorithm consists of two stages; image processing and clutter rejection. Image erosion, dilation and reconstruction is applied to eliminate multiple target candidates that are actually the same, single target and to remove small clutters in image processing stage. Linear Discriminant Analysis (LDA) using principal component analysis (PCA) and stochastic features is applied to clutter rejection. Several FLIR images are used to prove the performance of the proposed algorithm. The experimental results show that the proposed algorithm accurately detects targets with a low false alarm rate.	principal component analysis	Suk-Jong Kang;Hyeon-Deok Bae	2010		10.1007/978-3-642-17641-8_14	computer vision;speech recognition;pattern recognition	Vision	54.3118624526168	-63.31279909794262	63096
58f55fdc8293a77f87c8abe7a228b4b2e94fb62e	objectively optimised multisensor image fusion	discrete wavelet transforms;optimisation;optimised multisensor image fusion;image fusion discrete wavelet transforms displays robustness multiresolution analysis biomedical imaging biomedical engineering image reconstruction laplace equations image segmentation;image segmentation;image fusion;adaptive fusion optimised multisensor image fusion optimal fusion parameters multisensor dataset representative datasets fusion performance image fusion evaluation metrics fusion display;biomedical imaging;multisensor dataset;laplace equations;optimal fusion parameters;image fusion evaluation metrics;evaluation metric;adaptive fusion;biomedical engineering;adaptive fusion image fusion fusion optimisation;image reconstruction;displays;fusion display;robustness;representative datasets;multiresolution analysis;optimisation image fusion;fusion performance;fusion optimisation	A plethora of image fusion algorithms have been proposed recently, yet what are optimal fusion parameters that should be used for any multi-sensor dataset cannot be defined a priori. They could be learned by evaluating all available fusion strategies on large, representative datasets, but this is not practical and provides no guarantee that fusion performance will remain optimal should real input conditions differ from sample data. This paper proposes and examines the viability of a powerful framework for objectively optimal image fusion that explicitly optimises fusion performance for any set of input conditions. The idea is to integrate proven concepts used in objective image fusion evaluation metrics to optimally adapt the fusion process to the input conditions. Specific focus is on fusion for display, which has a broad appeal in a wide range of fusion applications as only metrics shown to be subjectively relevant are considered. The results show that the proposed framework achieves a considerable improvement in both the level and robustness of fusion performance for a wide array of multi-sensor images	algorithm;image fusion;iterative method;mathematical optimization;objective-c;pixel	Vladimir S. Petrovic;Timothy F. Cootes	2006	2006 9th International Conference on Information Fusion	10.1109/ICIF.2006.301683	computer vision;engineering;pattern recognition;data mining	Robotics	63.35214823537363	-66.73732165585474	63112
e4891e542d8393cf44d53b01bcb2c7cfbf78d7aa	acquisition and validation of spectral ground truth data for predictive rendering of rough surfaces			ground truth;rough set	O. Clausen;Ricardo Marroquim;A. Fuhrmann	2018	Comput. Graph. Forum	10.1111/cgf.13470	theoretical computer science;computer vision;rendering (computer graphics);computer science;artificial intelligence;ground truth	Robotics	73.0046109464188	-57.13686479938072	63133
50b63062b9d2a14b527c15fe55fe7d0dad5935ac	decision-level fusion of spatially scattered multi-modal data for nondestructive inspection of surface defects	scattered data;multi sensor data fusion;density estimation;registration errors;nondestructive testing;defect detection	This article focuses on the fusion of flaw indications from multi-sensor nondestructive materials testing. Because each testing method makes use of a different physical principle, a multi-method approach has the potential of effectively differentiating actual defect indications from the many false alarms, thus enhancing detection reliability. In this study, we propose a new technique for aggregating scattered two- or three-dimensional sensory data. Using a density-based approach, the proposed method explicitly addresses localization uncertainties such as registration errors. This feature marks one of the major of advantages of this approach over pixel-based image fusion techniques. We provide guidelines on how to set all the key parameters and demonstrate the technique's robustness. Finally, we apply our fusion approach to experimental data and demonstrate its capability to locate small defects by substantially reducing false alarms under conditions where no single-sensor method is adequate.	addresses (publication format);biological specimen;cdisc send biospecimens terminology;flaw hypothesis methodology;hepatitis b surface antigens;high- and low-level;image fusion;microsoft outlook for mac;modal logic;numerous;pixel;robustness (computer science);software bug;software inspection;registration - actclass	René Heideklang;Parisa Shokouhi	2016		10.3390/s16010105	computer vision;density estimation;nondestructive testing;computer science;engineering;data mining;forensic engineering;statistics	Visualization	57.72322683772127	-77.90221710234378	63143
f36715a431a4b3bfd09a916063b7f686e399deae	"""""""de-ghosting"""" artifact in scene-based nonuniformity correction of infrared image sequences"""	non uniformity correction;fixed pattern noise;focal plane array;infrared detectors;ghosting artifact	In this paper we present a new technique to improve the convergence and to reduce the ghosting artifacts based on constant statistics (CS) method. We propose to reduce ghosting artifacts and to speed up the convergence by using enhanced constant statistics method with the motion threshold. The key advantage of the method is based in its capacity for estimate detectors parameters, and then compensate for fixed-pattern noise in a frame by frame basics. The ability of the method to compensate for nonuniformity and reducing ghosting artifacts is demonstrated by employing video sequences of simulated and several infrared video sequences obtained using two infrared cameras.	rollover (key)	Anselmo Jara;Flavio Torres	2011		10.1007/978-3-642-25085-9_73	computer vision;computer science;computer graphics (images)	Vision	58.114445562421885	-59.556692917779245	63256
2aa54b3dbd16127f152d84aa978372ddde70a2c2	directly estimating endmembers for compressive hyperspectral images	measurement matrix;distributed compressive sensing;biological patents;biomedical journals;text mining;hyperspectral images;europe pubmed central;citation search;citation networks;research articles;abstracts;endmember estimation;open access;life sciences;clinical guidelines;full text;rest apis;orcids;europe pmc;biomedical research;bioinformatics;literature search	The large volume of hyperspectral images (HSI) generated creates huge challenges for transmission and storage, making data compression more and more important. Compressive Sensing (CS) is an effective data compression technology that shows that when a signal is sparse in some basis, only a small number of measurements are needed for exact signal recovery. Distributed CS (DCS) takes advantage of both intra- and inter- signal correlations to reduce the number of measurements needed for multichannel-signal recovery. HSI can be observed by the DCS framework to reduce the volume of data significantly. The traditional method for estimating endmembers (spectral information) first recovers the images from the compressive HSI and then estimates endmembers via the recovered images. The recovery step takes considerable time and introduces errors into the estimation step. In this paper, we propose a novel method, by designing a type of coherent measurement matrix, to estimate endmembers directly from the compressively observed HSI data via convex geometry (CG) approaches without recovering the images. Numerical simulations show that the proposed method outperforms the traditional method with better estimation speed and better (or comparable) accuracy in both noisy and noiseless cases.	3-d image;calcium-sensing receptor;coherence (physics);compressed sensing;computational fluid dynamics;data compression;detection theory;estimated;horizontal situation indicator;numerical linear algebra;simulation;sparse matrix;vertical talus	Hongwei Xu;Ning Fu;Liyan Qiao;Xiyuan Peng	2015		10.3390/s150409305	text mining;medical research;computer science;bioinformatics;data science;data mining;information retrieval;statistics	ML	69.4617410813495	-68.43086861859004	63291
e8253954603ff2e7ea71b5809170a0bef437afc5	investigating experienced quality factors in synthesized multi-view stereo images	inter view consistency quality factor visual comfort multi view generation lr image mismatch;stereo image processing;lr image mismatch synthesized multiview stereo images free viewpoint images stereoscopic viewing hole filling methods;visualization stereo image processing digital signal processing filling three dimensional displays q factor cameras	In this study, we investigated the quality factors in view synthesis that might lead to the visual discomfort and degradation of the overall viewing quality of the synthesized multi-view stereo or free viewpoint images. In particular, we focused on the investigation of the left and right (LR) image mismatch that might be one of the most important quality factors in the stereoscopic viewing. In order to measure how severely this factor influences the visual comfort and overall quality, we conducted a series of subjective assessment experiments on the visual comfort and viewing preference. In the subjective experiments, we compared the stereo view synthesis results of three different hole filling methods, because incorrectly filled holes could cause severe mismatches between the left- and right-view images. The subjective results revealed that the LR image mismatch could induce more visual discomfort and lower overall quality of stereoscopic images. Also, the results indicated that the visual comfort and overall quality were able to be improved by considering the inter-view consistency in multi-view stereo generation.	elegant degradation;experiment;lr parser;stereoscopy;view synthesis;viewing angle	Hak Gu Kim;Yong Ju Jung;Soo Sung Yoon;Yong Man Ro	2014	2014 19th International Conference on Digital Signal Processing	10.1109/ICDSP.2014.6900729	stereo cameras;stereo camera;computer vision;geography;image processing;digital image processing;multimedia;computer graphics (images)	Vision	63.46197400913171	-62.16423081311327	63332
50c81f0cee671b4d45bddedd0ad74eda8ec7cd92	bathymetric retrieval from hyperspectral imagery using manifold coordinate representations	coordonnee;hyperspectral imagery;tratamiento datos;focusing;lagune;lasers;teledetection;spectroscopy;optical image processing;laguna;radiative transfer model;manifold coordinate representation;batimetria;lagoons;radiative transfer;airborne lidar;image coding;image processing;rivers bathymetry geophysical signal processing geophysical techniques optical radar remote sensing by radar;rivers;north america;america del norte;amerique du nord;information retrieval;florida;bottom type;river channel;indian river lagoon;riviere indian;floride;data processing;imagerie;eau;spectrometrie;traitement donnee;laser radar;manifold learning;cartographie;layout;detection;scanning hydrographic operational airborne lidar survey beach zone;etats unis;estados unidos;canal;traitement image;isometric mapping algorithm;deteccion a distancia;portable hyperspectral imager for low light spectroscopy phills;algorithme;water bathymetry bottom type hyperspectral imagery isometric mapping manifold coordinates manifold learning nonlinear estimation optical data processing optical image processing remote sensing spectral analysis spectroscopy;remote sensing by radar;accuracy;modelo;apprentissage;imagery;cartografia;river channel bathymetry hyperspectral imagery manifold coordinate representation isometric mapping algorithm portable hyperspectral imager for low light spectroscopy phills hyperspectral camera indian river lagoon florida ad 2004 scanning hydrographic operational airborne lidar survey beach zone shoals;optical imaging;precision;playa;realite terrain;optical radar;geophysical signal processing;shoals;chenal;optical data processing;remote sensing;compresion;manifold coordinates;analyse spectrale;ad 2004;teledetection hyperspectrale;plage;coordinates;cartography;algorithms;lookup table;nonlinear estimation;realidad terreno;ground truth;satellite imagery;mapping;modele	In this paper, we examine the accuracy of manifold coordinate representations as a reduced representation of a hyperspectral imagery (HSI) lookup table (LUT) for bathymetry retrieval. We also explore on a more limited basis the potential for using these coordinates for modeling other in water properties. Manifold coordinates are chosen because they are a data-driven intrinsic set of coordinates, which naturally parameterize nonlinearities that are present in HSI of water scenes. The approach is based on the extraction of a reduced dimensionality representation in manifold coordinates of a sufficiently large representative set of HSI. The manifold coordinates are derived from a scalable version of the isometric mapping algorithm. In the present and in our earlier works, these coordinates were used to establish an interpolating LUT for bathymetric retrieval by associating the representative data with ground truth data, in this case from a Light Detection and Ranging (LIDAR) estimate in the representative area. While not the focus of the present paper, the compression of LUTs could also be applied, in principle, to LUTs generated by forward radiative transfer models, and some preliminary work in this regard confirms the potential utility for this application. In this paper, we analyze the approach using data acquired by the Portable Hyperspectral Imager for Low-Light Spectroscopy (PHILLS) hyperspectral camera over the Indian River Lagoon, Florida, in 2004. Within a few months of the PHILLS overflights, Scanning Hydrographic Operational Airborne LIDAR Survey LIDAR data were obtained for a portion of this study area, principally covering the beach zone and, in some instances, portions of contiguous river channels. Results demonstrate that significant compression of the LUTs is possible with little loss in retrieval accuracy.	algorithm;bathymetry;bottom type;data compression;ground truth;horizontal situation indicator;image sensor;interpolation;isometric projection;linear separability;lookup table;manifold regularization;pixel;scalability;spatial variability;test set;xfig	Charles M. Bachmann;Thomas L. Ainsworth;Robert A. Fusina;Marcos J. Montes;Jeffrey H. Bowles;Daniel Korwan;David B. Gillis	2009	IEEE Transactions on Geoscience and Remote Sensing	10.1109/TGRS.2008.2005732	meteorology;computer vision;data processing;spectroscopy;image processing;image retrieval;hyperspectral imaging;optics;physics;remote sensing	Vision	78.2473207815737	-62.74041274265428	63363
a15e0b9403067dc10db4b655a05cb01420c1c198	estimating rice production in the mekong delta, vietnam, utilizing time series of sentinel-1 sar data		Abstract Rice is the most important food crop in Asia and rice exports can significantly contribute to a countryu0027s GDP. Vietnam is the third largest exporter and fifth largest producer of rice, the majority of which is grown in the Mekong Delta. The cultivation of rice plants is important, not only in the context of food security, but also contributes to greenhouse gas emissions, provides man-made wetlands as an ecosystem, sustains smallholders in Asia and influences water resource planning and run-off water management. Rice growth can be monitored with Synthetic Aperture Radar (SAR) time series due to the agronomic flooding followed by rapid biomass increase affecting the backscatter signal. With the advent of Sentinel-1 a wealth of free and open SAR data is available to monitor rice on regional or larger scales and limited data availability should not be an issue from 2015 onwards. We used Sentinel-1 SAR time series to estimate rice production in the Mekong Delta, Vietnam, for three rice seasons centered on the year 2015. Rice production for each growing season was estimated by first classifying paddy rice area using superpixel segmentation and a phenology based decision tree, followed by yield estimation using random forest regression models trained on in situ yield data collected by surveying 357 rice farms. The estimated rice production for the three rice growing seasons 2015 correlates well with data at the district level collected from the province statistics offices with R 2 s of 0.93 for the Winter–Spring, 0.86 for the Summer–Autumn and 0.87 for the Autumn–Winter season.	time series	Kersten Clauss;Marco Ottinger;Patrick Leinenkugel;Claudia Kuenzer	2018	Int. J. Applied Earth Observation and Geoinformation	10.1016/j.jag.2018.07.022	food security;data availability;growing season;geography;delta;agroforestry;wetland;hydrology;crop;phenology;biomass	DB	82.75283077609016	-56.951068664227826	63364
742cdbbb2e748e5ac9874c9ca1a2443eba46d902	pareto boundary: a useful tool in the accuracy assessment of low spatial resolution thematic products	thematic maps;image resolution;multiresolution analysis pareto boundary low spatial resolution thematic products remote sensing temporal frequency continental thematic maps global thematic maps local scale mapping bidimensional space landsat 7 images;low resolution;accuracy assessment;pareto analysis remote sensing geophysical signal processing geophysical techniques image resolution multidimensional signal processing;spatial resolution image resolution satellites frequency production remote sensing image sensors multiresolution analysis error correction documentation;geophysical signal processing;remote sensing data;remote sensing;multidimensional signal processing;multiresolution analysis;quantitative evaluation;pareto analysis;geophysical techniques;spatial resolution	Low resolution remotely sensed data, providing consistent coverage of large areas with high temporal frequency, are increasingly used for the production of continental and global thematic maps. Nonetheless, current accuracy assessment methods relate mainly to local scale mapping investigations. In order to obtain a quantitative evaluation of the limitations due to the low spatial resolution of the data, we suggest to use the Pareto boundary. The Pareto boundary allows to determine the maximum user and producer's accuracy values that could he attained at the same time and to represent such a lower limit as a boundary in a bidimensional space. We apply the Pareto boundary to a dataset of Landsat 7 images, analysing how the spatial resolution of available medium and low resolution sensors limits the accuracy of the results.	image resolution;köppen climate classification;pareto efficiency;sensor;thematic map	Luigi Boschetti;Pietro Alessandro Brivio;Stéphane P. Flasse	2004	IGARSS 2004. 2004 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2004.1369940	computer vision;image resolution;computer science;data mining;remote sensing	Robotics	79.37905516316894	-58.85212343447067	63454
618d9855e9665baa94f85736188a4432d3297594	adaptive camera-based color mapping for mixed-reality applications	tone mapping;color matching;color;image color analysis cameras virtual reality color lighting rendering computer graphics visualization;virtual reality;computer graphic;global illumination;visualization;transfer function;image color analysis;mixed reality tone mapping color matching differential rendering;lighting;differential rendering;rendering computer graphics;mixed reality;cameras	We present a novel adaptive color mapping method for virtual objects in mixed-reality environments. In several mixed-reality applications, added virtual objects should be visually indistinguishable from real objects. Recent mixed-reality methods use global-illumination algorithms to approach this goal. However, simulating the light distribution is not enough for visually plausible images. Since the observing camera has its very own transfer function from real-world radiance values to RGB colors, virtual objects look artificial just because their rendered colors do not match with those of the camera. Our approach combines an on-line camera characterization method with a heuristic to map colors of virtual objects to colors as they would be seen by the observing camera. Previous tone-mapping functions were not designed for use in mixed-reality systems and thus did not take the camera-specific behavior into account. In contrast, our method takes the camera into account and thus can also handle changes of its parameters during runtime. The results show that virtual objects look visually more plausible than by just applying tone-mapping operators.	algorithm;coherence (physics);color mapping;fundamental fysiks group;heuristic;ismar;logo;mixed reality;online and offline;outsourcing;simulation;tone mapping;transfer function;visual computing	Martin Knecht;Christoph Traxler;Werner Purgathofer;Michael Wimmer	2011	2011 10th IEEE International Symposium on Mixed and Augmented Reality	10.1109/ISMAR.2011.6092382	computer vision;camera auto-calibration;tone mapping;visualization;computer science;lighting;virtual reality;mixed reality;multimedia;transfer function;global illumination;computer graphics (images)	Visualization	62.262467684078224	-52.08241521792604	63556
47b466d30da227c9ddf1030ed99aab095e39ac8d	radar maneuvering target motion estimation based on generalized radon-fourier transform	cramer rao low bound crlb;target tracking fourier transforms maximum likelihood estimation modulation motion estimation phase measurement polynomials radar cross sections radar tracking radon transforms;phase measurement;radon transforms;radar tracking;root mean square error rmse;motion estimation;maximum likelihood estimation;root mean square error rmse cramer rao low bound crlb generalized radon fourier transform grft maneuvering target parameter estimation polynomial phase signal pps;polynomials;phase measurement motion estimation radar measurements maximum likelihood estimation transforms motion measurement;fourier transforms;generalized radon fourier transform grft;transforms;crlb radar maneuvering target multivariate function motion parameter modulation coherent radar target echo radar target motion estimation maximum likelihood estimation mle phase measurement envelope only measurement signal to noise ratio snr generalized radon transform generalized fourier transform gft grt polynomial cramer rao low bound;polynomial phase signal pps;radar cross sections;parameter estimation;target tracking;motion measurement;radar measurements;maneuvering target;modulation	The slant range of a radar maneuvering target is usually modeled as a multivariate function in terms of its illumination time and multiple motion parameters. This multivariate range function includes the modulations on both the envelope and the phase of an echo of the coherent radar target and provides the foundation for radar target motion estimation. In this paper, the maximum likelihood estimators (MLE) are derived for motion estimation of a maneuvering target based on joint envelope and phase measurement, phase-only measurement and envelope-only measurement in case of high signal-to-noise ratio (SNR), respectively. It is shown that the proposed MLEs are to search the maximums of the outputs of the proposed generalized Radon-Fourier transform (GRFT), generalized Radon transform (GRT) and generalized Fourier transform (GFT), respectively. Furthermore, by approximating the slant range function by a high-order polynomial, the inherent accuracy limitations, i.e., the Cramer-Rao low bounds (CRLB), and some analysis are given for high order motion parameter estimations in different scenarios. Finally, some numerical experimental results are provided to demonstrate the effectiveness of the proposed methods.	approximation algorithm;bessel filter;coherence (physics);motion estimation;numerical analysis;parametric model;polynomial;radar;rewrite (programming);signal-to-noise ratio;utility functions on indivisible goods	Jia Xu;Xiang-Gen Xia;Shibao Peng;Ji Yu;Yingning Peng;Li-Chang Qian	2012	IEEE Transactions on Signal Processing	10.1109/TSP.2012.2217137	fourier transform;mathematical optimization;radar tracker;motion estimation;mathematics;maximum likelihood;estimation theory;statistics;polynomial;modulation	Vision	76.06606691021072	-68.65237657230242	63562
1aa858a767dd41d85928fe171a3e0d6ef0d2ac30	efficient gradient-domain compositing using an approximate curl-free wavelet projection		Gradient-domain compositing has been widely used to create a seamless composite with gradient close to a composite gradient field generated from one or more registered images. The key to this problem is to solve a Poisson equation, whose unknown variables can reach the size of the composite if no region of interest is drawn explicitly, thus making both the time and memory cost expensive in processing multi-megapixel images. In this paper, we propose an approximate projection method based on biorthogonal Multiresolution Analyses (MRA) to solve the Poisson equation. Unlike previous Poisson equation solvers which try to converge to the accurate solution with iterative algorithms, we use biorthogonal compactly supported curl-free wavelets as the fundamental bases to approximately project the composite gradient field onto a curl-free vector space. Then, the composite can be efficiently recovered by applying a fast inverse wavelet transform. Considering an n-pixel composite, our method only requires 2n of memory for all vector fields and is more efficient than state-of-the-art methods while achieving almost identical results. Specifically, experiments show that our method gains a 5x speedup over the streaming multigrid in certain cases.	8-bit;approximation algorithm;central processing unit;compositing;computer graphics;converge;core data;eurographics;experiment;gigapixel image;gradient;graphics processing unit;high dynamic range;image processing;iterative method;john d. wiley;multigrid method;multiresolution analysis;out-of-core algorithm;pixel;real-time web;region of interest;seamless3d;solver;speedup;wavelet transform;curl	Xiaohua Ren;Luan Lyu;Xiaowei He;Yanci Zhang;Enhua Wu	2017	Comput. Graph. Forum	10.1111/cgf.13286	theoretical computer science;artificial intelligence;compositing;computer science;computer vision;wavelet;computer graphics (images);real-time computer graphics;curl (mathematics);alpha compositing	Graphics	66.69457132388436	-53.59978542959127	63598
45fa00fc02fe692428736276d65bc8736538b229	novel survey on the color-image graying algorithm	information technology;handheld computers;conferences	Color-image graying operation is an important step for an image processing system. The gray image is the basis of subsequent image processing operations. This paper surveys the novel research achievements of the color-image graying algorithm, and discusses their two main classes, i.e., the weighting algorithm and the extreme algorithm. For the first class, we study three color-image graying algorithms, i.e., the Human Visual System (HVS) algorithm, the single component algorithm and the average algorithm. For the second class, we study two color-image graying algorithms, i.e., the maximum/minimum algorithm and the maximum/minimum-average algorithm. Finally, the algorithm comparison is made in terms of efficiency and fidelity. The experimental result and analyses show that the single component algorithm is the most efficient, and the HVS algorithm has the best visual effect.	british undergraduate degree classification;fidelity of quantum states;first-class function;human visual system model;image processing;selection algorithm;visual effects	Xiaoqiang Zhang;Xuesong Wang	2016	2016 IEEE International Conference on Computer and Information Technology (CIT)	10.1109/CIT.2016.32	simulation;weighted majority algorithm;computer science;fsa-red algorithm;dinic's algorithm;information technology;algorithm;population-based incremental learning;computer graphics (images)	Visualization	58.91714855202509	-63.64204964308351	63602
cafe0756f407297e6c7fd0c4311b3e401350b51b	adaptive neuro-fuzzy inference system for speckle noise reduction in sar images	image filtering;speckle;radar remote sensing;fuzzy neural nets;synthetic aperture radar images;anfis;fuzzy reasoning;psnr;training;speckle noise;sar images;synthetic aperture radar fuzzy neural nets fuzzy reasoning image denoising radar imaging speckle;radar imaging;sar image;adaptive systems speckle noise reduction radar imaging remote sensing radar remote sensing synthetic aperture radar image converters optical surface waves adaptive optics;anfis adaptive neuro fuzzy inference system speckle noise reduction sar images synthetic aperture radar images active radar image radar coherent images;image denoising;radar coherent images;active radar image;speckle noise reduction;adaptive neuro fuzzy inference system;radar;noise;synthetic aperture radar	An adaptive neuro-fuzzy inference system (ANFIS) based method is proposed for speckle noise reduction in synthetic aperture radar (SAR) images. Before using active RADAR (radio detection and ranging) and SAR imageries, the very first step is to reduce the effect of speckle noise. Reduction of speckle noise is one of the most important processes to increase the quality of radar coherent images. Filtering is the common method which is used to reduce the speckle noise. For this purpose, two ANFISs are trained and outputs of these systems are converted to one output through a mean calculator in this work. Performance of the proposed method is compared with performances of state-of-the-art methods in the literature for speckle noise reduction. Results are presented by filtered images and a table.	adaptive neuro fuzzy inference system;inference engine;neuro-fuzzy;noise reduction	Alper Bastürk;M. Emin Yüksel	2007		10.1109/ISSPA.2007.4555350	speckle noise;median filter;computer vision;adaptive neuro fuzzy inference system;computer science	EDA	66.76557494332361	-65.97985803581348	63609
70fea936643eba3803ab677800f4f8387db524ea	3d-spline reconstruction using shape from shading: spline from shading	shape from shading;perspective projection;boundary condition;3d spline;3d reconstruction	In this work, we propose an original method of resolution of the shape from shading problem, which is accurate and converges with a few iterations. It relies on two simple ideas. On the one hand, we propose to model the scene by a 3D-spline. The key advantage is that boundary conditions are no longer required to make the problem well-posed. On the other hand, we introduce the concept of “useful domain”, which allows us to widen the 3D-reconstruction to pixels whose greylevels are not in accordance with the assumptions of SFS. Our method is tailored to meet the two shape from shading formulations, corresponding to orthogonal projection and perspective projection. We can thus validate our method on both synthetic and real images.	3d projection;clustered file system;iteration;photometric stereo;pixel;resolution (logic);shading;spline (mathematics);synthetic intelligence;well-posed problem	Frédéric Courteille;Alain Crouzil;Jean-Denis Durou;Pierre Gurdjos	2008	Image Vision Comput.	10.1016/j.imavis.2007.02.004	3d reconstruction;computer vision;perspective;photometric stereo;boundary value problem;computer science;mathematics;geometry	Vision	56.30604928049459	-52.24532419811561	63640
dd7ddec8d5d56fdaaed03f236dd080f488a34021	a model based book dewarping method to handle 2d images captured by a digital camera	curved book page;2d document images;proposed book;digital camera;camera lens;book dewarping method;new model;flat page;warped book image;transform model;original rectangle region;cameras;transforms;original flat rectangle shape;book surface;warped region;book dewarping model;document image processing;flat rectangle shape	In this paper, we propose a book dewarping model which flattens a curved book page to its original flat rectangle shape. This model generalizes the model proposed by Cao to handle warped book images taken from different point of views instead of only from top of the book surface. In order to do so, we realize the impact of the angle between the camera lens and the book surface and take it into account in the transform model. Based on the new model, the rectification process includes two steps: 1) on the warped book image, find a region which is original a rectangle on a flat page; 2) map each pixel in warped region to a pixel in its original rectangle region. The experimental results demonstrate the effectiveness of our proposed book dewarping approach.	digital camera;image rectification;pixel	M. Wu;R. Li;B. Fu;Wenhui Li;Z. Xu	2007	Ninth International Conference on Document Analysis and Recognition (ICDAR 2007)	10.1109/ICDAR.2007.19	computer vision;computer science;multimedia;computer graphics (images)	Vision	59.29232168152908	-54.7445331338898	63710
362185020a777449acb4bcad5578996a84533674	a novel algorithm for image denoising based on unscented kalman filtering	ukf;two dimensional filtering;two dimensional non symmetric half plane;image denoising;unscented kalman filter	This paper presents a noise removal algorithm based on unscented Kalman filtering in order to improve image quality. We first analysed the characteristics of the background noise, and then discussed the unscented Kalman filter UKF. After that, one-dimensional unscented Kalman filtering, and two-dimensional non-symmetric half plane NSHP support image model based on two-dimensional unscented Kalman filtering are introduced. Experimental results show that as an adaptive method, the algorithm reduces the noise while retaining the image details, and two-dimensional NSHP model performs better than one-dimensional UKF algorithm. Therefore, UKF together with its two-dimensional NSHP implementation have efficacy for noise removal of images.	algorithm;kalman filter;noise reduction	Ruoqing Wang;Sufei Li;Ercan Engin Kuruoglu	2013	IJICT	10.1504/IJICT.2013.054944	kalman filter;computer vision;fast kalman filter;computer science;unscented transform;machine learning;extended kalman filter	Robotics	55.67383630214748	-67.20990969435984	63747
55d64fbdf91c4fea1a239c3c850d8569433943e6	image restoration: the wavelet-based approach	transformation ondelette;modelo markov oculto;restauration image;image processing;modele markov cache;hidden markov model;signal distortion;procesamiento imagen;image restoration;distorsion signal;traitement image;reduccion ruido;restauracion imagen;wavelet transform;noise reduction;expectation maximization algorithm;reduction bruit;algorithme em;algoritmo em;thresholding;rapport signal bruit;relacion senal ruido;transformacion ondita;methode domaine temps frequence;signal to noise ratio;em algorithm;metodo dominio tiempo frecuencia;wavelet transformation;time frequency domain method;distorsion senal	Wavelet-based techniques are suitable for recovering a signal corrupted by noise. The timeand frequency-localization capabilities of wavelets provide better noise reduction and less signal distortion than conventional filtering methods. The noise reduction technique used in this paper is based on the hidden Markov model (HMM) structure, which can efficiently shape the statistical characteristics of practical data. As confirmed by numerical results, the HMM based approach provides a significant performance improvement over competing methods.	circuit restoration;distortion;expectation–maximization algorithm;hidden markov model;image restoration;matlab;markov chain;nl (complexity);noise reduction;numerical analysis;numerical aperture;numerical method;peak signal-to-noise ratio;ski combinator calculus;wavelet;zero suppression	Tertulien Ndjountche;Rolf Unbehauen	2003	IJPRAI	10.1142/S0218001403002277	median filter;computer vision;speech recognition;expectation–maximization algorithm;image processing;computer science;noise measurement;mathematics;hidden markov model;statistics	HPC	54.150941590634446	-67.28484513617983	63756
2c8fad57cfb8843aec13e06e7dad53bc73145b67	simultaneous radar observations of tropical cyclones by space-based and ground-based radar	frequency 13 8 ghz;storms atmospheric precipitation atmospheric techniques doppler radar meteorological radar remote sensing by radar spaceborne radar;space based radar;atmospheric precipitation;precipitation radar;tropical rainfall measurement mission satellite;performance evaluation;frequency 13 8 ghz radar observation tropical cyclones space based radar ground based radar megha 2700 s band ground based doppler weather radar india storm detection precipitation characterization bay of bengal tropical rainfall measurement mission satellite precipitation radar ku band observation vertical structure ground based weather radars global precipitation measurement;meteorological radar;tropical cyclone;megha 2700;ground based radar;weather radar;bay of bengal;storm detection;global precipitation measurement;vertical structure;remote sensing by radar;ground validation;storms;tropical cyclones;pr;ku band observation;s band ground based doppler weather radar;satellites;ground based weather radars;inter comparison;doppler radar;trmm;area measurement;vertical profile of reflectivity;radar detection;atmospheric techniques;radar observation;long range;radar measurements;spaceborne radar tropical cyclones doppler radar meteorological radar radar measurements radar detection storms area measurement satellites performance evaluation;india;tropical rainfall measuring mission;validation studies;precipitation characterization;spaceborne radar;inter comparison trmm pr ground validation	Megha 2700, S-band ground-based Doppler weather radar (DWR) located on the east coast of India, is capable of providing long range detection and characterization precipitation and severe storm such as tropical cyclone over Bay of Bengal. The location of the radar is in coverage area of Tropical Rainfall Measurement Mission (TRMM) satellite. Precipitation radar (PR) operating at Ku-band (13.8 GHz) abroad the TRMM has capability of providing vertical structure of tropical cyclones. Although tropical cyclones can be frequently observed by PR, and their vertical structure can be studied, it is not so frequent that they are observed by most existing Ground based weather Radars (GR). The authors take this opportunity for performing inter- comparison between the two radars and inter-compare vertical profile of reflectivity (VPR) of tropical cyclone which were simultaneously observed by the Megha 2700 DWR and PR This work can be useful not only in cross-monitoring severe tropical cyclone activity in a long range over Bay of Bengal, but also as ground validation study of TRMM, and even to the future global space based precipitation mission such as Global Precipitation Measurement (GPM), which is planed to fly over the globe in the near future.	cyclone;direct web remoting;display resolution;graphical path method;ku band;radar	Direk Khajonrat;V. Chandrasekar;G. Viswanathan;Vikas Shellar	2007	2007 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2007.4423696	meteorology;atmospheric sciences;tropical cyclone;geology;central dense overcast;physics;tropical cyclone rainfall forecasting;remote sensing	Embedded	81.23760409614538	-63.169120026712	63781
4dfd9e67b3e8d53560544f07a8c932a88c759d16	variational image segmentation using boundary functions	metodo cuadrado menor;fonction frontiere;lp norm;partial differential equation;methode moindre carre;least squares approximations;image segmentation;image processing;least squares method;variational techniques;procesamiento imagen;segmentation;indexing terms;traitement image;objective function;approximation par fonction;least squares approximations image segmentation variational techniques partial differential equations;partial differential equations;least square;image segmentation least squares approximation particle measurements partial differential equations lakes military computing integral equations;real image problems variational image segmentation boundary functions general variational framework image approximation continuous line process edge boundaries variational theory approximation function objective functions mumford shah type functionals smoothness least squares approach total variation objective functional partial differential equation descent method synthetic image problems;total variation;approximation by function;aproximacion por funcion;segmentacion;boundary function	"""A general variational framework for image approximation and segmentation is introduced. By using a continuous """"line-process"""" to represent edge boundaries, it is possible to formulate a variational theory of image segmentation and approximation in which the boundary function has a simple explicit form in terms of the approximation function. At the same time, this variational framework is general enough to include the most commonly used objective functions. Application is made to Mumford-Shah type functionals as well as those considered by Geman and others. Employing arbitrary Lp norms to measure smoothness and approximation allows the user to alternate between a least squares approach and one based on total variation, depending on the needs of a particular image. Since the optimal boundary function that minimizes the associated objective functional for a given approximation function can be found explicitly, the objective functional can be expressed in a reduced form that depends only on the approximating function. From this a partial differential equation (PDE) descent method, aimed at minimizing the objective functional, is derived. The method is fast and produces excellent results as illustrated by a number of real and synthetic image problems."""	approximation;calculus of variations;image segmentation;least squares;reifenstein syndrome;synthetic intelligence;variational principle;waardenburg syndrome, type 4a;biologic segmentation	Gary A. Hewer;Charles S. Kenney;B. S. Manjunath	1998	IEEE transactions on image processing : a publication of the IEEE Signal Processing Society	10.1109/83.709660	computer vision;mathematical optimization;mathematical analysis;image processing;computer science;calculus;mathematics;least squares;partial differential equation	Vision	54.39820236845684	-73.05345966542193	63861
12fe67feb7868c536a5653bb34f448c51c067333	binary weighted averaging of an ensemble of coherently collected image frames	vision system;bayes estimation;remote sensing by laser beam;traitement signal;detection erreur;estimation theory;vision ordenador;deteccion error;speckle;coherently collected image frames;image processing;teoria ergodica;image resolution;resolution spatiale;motion compensation;resolucion espacial;systeme vision;laser range finding;weighted averaging;bayes methods;signal distortion;atmospheric seeing parameter coherently collected image frames bayesian estimation theory spatial resolution binary weighted motion compensated frame laser vision system remote laser radar imagery image resolution;lucky imaging;procesamiento imagen;imagineria optica;laser radar;distorsion signal;imagerie optique;laser radar laser theory laser noise radar imaging speckle bayesian methods estimation theory spatial resolution atmospheric modeling machine vision;qualite image;traitement image;motion compensated;computer vision;outlier detection;algorithme;registro imagen;algorithm;compensation mouvement;radar optico;estimacion bayes;resolucion imagen;remote laser radar imagery;optical imaging;telemetria laser;recalage image;optical radar;telemetrie laser;4279q;signal processing;laser vision system;image registration;image quality;imaging;ladar;theorie ergodique;methode moyenne;weighted averaging coherent imaging image registration ladar lidar lucky frame lucky imaging motion compensation outlier detection;coherent imaging;bayesian estimator;formation image;bayesian estimation theory;vision ordinateur;calidad imagen;rapport signal bruit;atmospheric techniques;relacion senal ruido;formacion imagen;error detection;binary weighted motion compensated frame;signal to noise ratio;remote sensing by laser beam atmospheric techniques bayes methods image resolution motion compensation optical radar;procesamiento senal;lucky frame	Recent interest in the collection of remote laser radar imagery has motivated novel systems that process temporally contiguous frames of collected imagery to produce an average image that reduces laser speckle, increases image SNR, decreases the deleterious effects of atmospheric distortion, and enhances image detail. This research seeks an algorithm based on Bayesian estimation theory to select those frames from an ensemble that increases spatial resolution compared to simple unweighted averaging of all frames. The resulting binary weighted motion-compensated frame average is compared to the unweighted average using simulated and experimental data collected from a fielded laser vision system. Image resolution is significantly enhanced as quantified by the estimation of the atmospheric seeing parameter through which the average image was formed	airborne ranger;algorithm;anomaly detection;arabic numeral 0;coherence (physics);distortion;estimation theory;frame (physical object);guided imagery;image resolution;loss function;naive bayes classifier;personnameuse - assigned;population parameter;signal-to-noise ratio;spatial frequency;vision;weight;likelihood ratio	A. MacDonald;Stephen C. Cain;Mark E. Oxley	2007	IEEE Transactions on Image Processing	10.1109/TIP.2007.891774	lidar;computer vision;image processing;computer science;signal processing	Vision	68.77334649815602	-62.91341511578808	63900
71b5816a142853a99bc4ccb1e706c0cde4201b7c	hazy image enhancement based on the full-saturation assumption	image processing;haze removal hazy image enhancement full saturation assumption hazy image quality visually pleasant haze free results fsa aesthetic photographic effect vivid color photo degraded saturation layer recovery depth image example based approach;educational institutions image enhancement abstracts;dehazing;image enhancement;image colour analysis;image enhancement image colour analysis;dehazing image processing image enhancement	In this paper, we present an algorithm that can successfully improve the quality of hazy images and offer visually-pleasant haze-free results with vivid colors. We propose the full-saturation assumption (FSA) based on the aesthetic photographic effect: photos of vivid colors are visually pleasant, and first recover the degraded saturation layer. The depth image is also obtained as a by-product. We then apply an example-based approach to avoid over-saturation. The proposed assumption can also serve as a criterion to evaluate the degree of haze removal. Results are shown on various images to demonstrate its competence.	algorithm;color;image editing	Yang Yang Xiang;Rajiv Ranjan Sahay;Mohan S. Kankanhalli	2013	2013 IEEE International Conference on Multimedia and Expo Workshops (ICMEW)	10.1109/ICMEW.2013.6618277	image restoration;computer vision;image processing;computer science;computer graphics (images)	Robotics	60.28015148722251	-60.78618685626361	63971
c7fe69f4b63d59606ca0999f92a339a8d73dda7c	patch-based residual networks for compressively sensed hyperspectral images restruction		Most traditional compressive sensing (CS) reconstruction methods suffer from the intensive computation caused by iterations. This paper aims at presenting a non-iterative algorithm to reconstruct hyperspectral images (HSI) from patch-based compressively sensed measurements. Our method contains two residual convolutional neural networks. One is reconstruction network for compressive sensing reconstruction and the other is deblocking network for removing the blocky effect, which is caused by patch-based sampling. The reconstruction network can efficiently reconstruct all the bands of HSI jointly, thus the spectral correlation is well preserved. In addition, the deblock performance is enhanced by combining more patches into a larger patch in the deblocking network. Experimental results verify that our method outperforms the state-of-the-art compressive sensing reconstruction methods with patch-based CS measurement.	algorithm;artificial neural network;compressed sensing;computation;convolutional neural network;deblocking filter;horizontal situation indicator;iteration;iterative method;patch (computing);sampling (signal processing)	Xiaowei Hu;Yang Xu;Zhihui Wei;Hongyi Liu;Ling Qian	2018	IGARSS 2018 - 2018 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2018.8518137	residual;iterative reconstruction;computer vision;deblocking filter;convolutional neural network;compressed sensing;artificial intelligence;hyperspectral imaging;computer science	Vision	58.09101974646399	-69.78729402120928	64038
d0a8ad15e0c2aa23bacdba8fa9aed51c3dcba8ad	normalized blind deconvolution		We introduce a family of novel approaches to single-image blind deconvolution, i.e., the problem of recovering a sharp image and a blur kernel from a single blurry input. This problem is highly ill-posed, because infinite (image, blur) pairs produce the same blurry image. Most research effort has been devoted to the design of priors for natural images and blur kernels, which can drastically prune the set of possible solutions. Unfortunately, these priors are usually not sufficient to favor the sharp solution. In this paper we address this issue by looking at a much less studied aspect: the relative scale ambiguity between the sharp image and the blur. Most prior work eliminates this ambiguity by fixing the L norm of the blur kernel. In principle, however, this choice is arbitrary. We show that a careful design of the blur normalization yields a blind deconvolution formulation with remarkable accuracy and robustness to noise. Specifically, we show that using the Frobenius norm to fix the scale ambiguity enables convex image priors, such as the total variation, to achieve state-of-the-art results on both synthetic and real datasets.	autostereogram;blind deconvolution;box blur;deblurring;experiment;gaussian blur;heuristic;iterative reconstruction;kernel (operating system);numerical analysis;synthetic intelligence;well-posed problem	Meiguang Jin;Stefan Roth;Paolo Favaro	2018		10.1007/978-3-030-01234-2_41	artificial intelligence;kernel (linear algebra);computer vision;prior probability;normalization (statistics);computer science;robustness (computer science);mathematical optimization;ambiguity;blind deconvolution;matrix norm	Vision	57.5148330707405	-72.92088023135285	64054
b46fd6800bc5dc5e2b487cece906694fb7c11609	performance evaluation of back-projection and range migration algorithms in foliage penetration radar imaging	image reconstruction radar imaging synthetic aperture radar;performance evaluation;seismic migration techniques back projection algorithm range migration algorithm foliage penetration radar imaging synthetic aperture radar fopen sar imaging image reconstruction computer aided tomography;performance comparison;medical image;image reconstruction;radar imaging;sar image;radar imaging synthetic aperture radar image reconstruction radar polarimetry fourier transforms equations biomedical engineering biomedical imaging tomography computational modeling;synthetic aperture radar	In this paper, two relatively novel synthetic aperture radar (SAR) imaging techniques, namely the back-projection algorithm and range migration algorithm, are discussed. The back-projection algorithm originates from the medical imaging reconstruction technique called computer-aided tomography whereas the range migration algorithm is derived from seismic migration techniques. In this paper, both the back-projection and range migration algorithms are applied to foliage penetration (FOPEN) SAR imaging and performance comparisons are made. The simulations and experimental data processing results show that both algorithms are suitable for FOPEN radar imaging and that theoretical performances can be achieved.	algorithm;medical imaging;penetration test;performance evaluation;simulation;synthetic data;tomography	Yibo Na;Hongbo Sun;Yee Hui Lee;Ling Chiat Tai;Hian Lim Chun	2004	2004 International Conference on Image Processing, 2004. ICIP '04.	10.1109/ICIP.2004.1418679	iterative reconstruction;computer vision;continuous-wave radar;radar engineering details;synthetic aperture radar;radar imaging;inverse synthetic aperture radar;side looking airborne radar	EDA	76.89794555246665	-67.86655004384532	64061
39d425f4661fe053e06937041f4163c1085d0ae9	orthorectification and digital elevation model (dem) generation using cartosat-1 satellite stereo pair in himalayan terrain	orthorectification;dem generation;himalaya;relief;mountain areas;terrain;digital elevation model;natural resources;stereo pair;remote sensing;satellite imagery;dem;global positioning systems;cartosat	High resolution data have high relief displacement in hilly terrains. Development of Digital Elevation model helps to assess bio resources more accurately in such terrains. While estimating bio resources in the Himalayan hilly terrain using multispectral LISS-III data of 23 m spatial resolution, the need for orthorectifcation of satellite data was necessary to correct for spatial distances due to high undulating slopes. Therefore, Cartosat stereo pair based Digital Elevation Model (DEM) was generated using the Rational Polynomial Coefficients (RPC) supplied along with the data products. By using the DEM orthorectification of LISS-III was created. In order to evaluate the positional accuracy of ortho rectified LISS-III Ground control points were selected using the Global Positioning System in differential GPS mode. As there is variation in the spatial distances and height over few points, the GCP corrected DEM was used for ortho rectifcation of Cartosat PAN and LISS-III data. This paper presents the procedure followed for ortho rectification and digital elevation model generation using Cartosat stereo pair data. The result of the study indicated high spatial resolution stereo images helped generation of three dimensional mountainous regions more accurately which helps in estimating the bio resources using multispectral LISS III data.	british informatics olympiad;coefficient;differential gps;digital elevation model;displacement mapping;games computers play;global positioning system;high-resolution scheme;image rectification;multispectral image;orthophoto;polyhedral terrain;polynomial;victor pan	Vivek Kumar Singh;Prashant Kumar Champati Ray;Ayyeum Perumal Thillai Jeyaseelan	2010	J. Geographic Information System	10.4236/jgis.2010.22013	digital elevation model;geography;geology;cartography;remote sensing	Robotics	79.28982379337948	-58.73379881337773	64106
7851d3c8ddad4ceeea790c8b0de1df3799c5da40	a fast iterative reconstruction method based on the selective total variation for sparse angular ct	convergence;computed tomography;tv image reconstruction convergence image edge detection imaging phantoms iterative methods computed tomography;iterative methods;imaging phantoms;image edge detection;image reconstruction;fast iterative parse angular ct low dose radiation image reconstruction selective total variation;tv;simulated shepp logan phantom fast iterative reconstruction method sparse angular ct sparse angular computer tomography high quality image reconstruction method low dose x rays total variation algorithm minimization edge detection convergence iterative shrinkage thresholding algorithm;variational techniques computerised tomography convergence of numerical methods edge detection image reconstruction iterative methods medical image processing phantoms	Sparse angular Computer Tomography (CT) is a rapidly developing imaging modality that reconstructs high-quality images from sparse data toward low-dose x-rays. The effectiveness of conventional total variation (TV) algorithm is limited by the over-smoothness on the edges and slow convergence. To mitigate this drawback, we proposed an improved fast iterative reconstruction method based on the minimization of selective image TV. The presented selective TV model is derived by linking the regularity metric to the local gradient of images, and selectively applies different degrees of regularization (the value of p) to background and potential signal locations for the purpose of preserving the edge details. In order to further speed up the convergence, we draws on a fast variant of The Iterative-Shrinkage-Thresholding Algorithm (ISTA), which uses a special linear combination of the two previous iterate results as the initial value of next iteration for more accurate correction. Experiments on simulated Shepp-Logan phantom are performed. The results demonstrated that the new method not only protected the edge of the image characteristics, but also significantly improved the convergence speed of the iterative reconstruction.	algorithm;angularjs;ct scan;embedded system;experiment;gradient;imaging phantom;iteration;iterative reconstruction;matrix regularization;modality (human–computer interaction);rate of convergence;shepp–logan phantom;sparse matrix;thresholding (image processing);tomography	Huijun Li;Shuxu Zhang;Kehong Yuan;Linjing Wang;Yingying Peng	2015	2015 8th International Conference on Biomedical Engineering and Informatics (BMEI)	10.1109/BMEI.2015.7401471	iterative reconstruction;computer vision;mathematical optimization;radiology;convergence;mathematics;iterative method;computed tomography;computer graphics (images)	Vision	55.76233143127099	-71.84696524556757	64238
ff9365c0f03aadf37a3b8cefdb51d1acb5230033	a type-2 fuzzy edge detector based speckle noise remover	speckle;image edge detection noise speckle boats conferences digital images;image edge detection;digital images;speckle noise type 2 fuzzy neural networks;conferences;noise;boats	The use of edge information for noise removal from digital images is of vital importance for preserving image details after filtering process. In this work, the edges in the speckled image are detected by employing a type-2 fuzzy edge detector and then the mean filter is used for removing speckle noise. Although the mean filter is effective for speckle noise removal, it also introduces undesirable blurrings, especially at the edges in the image. This can be a significant problem when the edge information is utilized for understanding and interpreting the image. The fuzzy edge detector can be highly efficient for detection of the edges correctly in the images with a minimum influence by the speckle noise. In the proposed filter, the mean filter window size is adjusted according to the edge information after detecting edges in the image. The window size in the vicinity of the edges is made smaller in comparison with the window size in the other areas to protect the edges. Experimental results demonstrate that the proposed method performs very well.	digital image;edge detection;sensor	Mehmet Ali Soyturk;Alper Bastürk;M. Emin Yüksel	2014	2014 22nd Signal Processing and Communications Applications Conference (SIU)	10.1109/SIU.2014.6830389	speckle pattern;speckle noise;median filter;image noise;computer vision;edge detection;computer science;noise;mathematics;digital image;salt-and-pepper noise	Vision	56.41274199173508	-64.20688626892283	64262
42fde41fe54246abbdeedb9676012e2f7d4c72e1	the discrimination of cloud using the data of calipso based on svm method				Jingbo Wang;Xiaoyi Li	2013		10.1007/978-3-642-45025-9_39	meteorology;atmospheric sciences;remote sensing	Robotics	79.04888330830602	-60.016491329054006	64299
262393e387fe3af0f190a510a1f79e42d5d6de4b	a rank-ordered marginal filter for deinterlacing	adaptive marginal filter;format conversion;image enhancement;image interpretation computer assisted;deinterlacing;algorithms;humans;rank ordered filter;telecommunications	This paper proposes a new interpolation filter for deinterlacing, which is achievedby enhancing the edge preserving ability of the conventional edge-based line average methods. This filter consists of three steps: pre-processing step, fuzzy metric-based weight assignation step, and rank-ordered marginal filter step. The proposed method is able to interpolate the missing lines without introducing annoying articles. Simulation results show that the images filtered with the proposed algorithm restrain less annoying pixels than the ones acquired by other methods.	algorithm;deinterlacing;fm broadcasting;fuzzy concept;iso 10303;interpolation imputation technique;marginal model;order (action);pixel;preprocessor;real-time computing;real-time transcription;simulation	Gwanggil Jeon;Marco Anisetti;SeokHoon Kang	2013		10.3390/s130303056	adaptive filter;computer vision;electronic engineering;kernel adaptive filter;telecommunications;computer science;root-raised-cosine filter;deinterlacing;control theory;filter design	Vision	57.17204239599891	-65.06151103057972	64327
929571ae0c216e023d430c65ded02ababa43d324	on visual ambiguities due to transparency in motion and stereo	optical flow	Transparency produces visual ambiguities in interpreting motion and stereo. Recent discovery of a general framework, principle of super-position, for building constraint equations of transparency makes it possible to analyze the mathematical properties of transparency perception. This paper theoretically examines multiple ambiguous interpretations in transparent optical flow and transparent stereo.		Masahiko Shizawa	1992		10.1007/3-540-55426-2_46	computer vision;geodesy;computer science;optical flow	Vision	55.89854254397211	-53.279902264952796	64329
084751199a690088f9d4aca0d602e171c9741117	patchmatch stereo - stereo matching with slanted support windows.		Common local stereo methods match support windows at integer-valued disparities. The implicit assumption that pixels within the support region have constant disparity does not hold for slanted surfaces and leads to a bias towards reconstructing frontoparallel surfaces. This work overcomes this bias by estimating an individual 3D plane at each pixel onto which the support region is projected. The major challenge of this approach is to find a pixel’s optimal 3D plane among all possible planes whose number is infinite. We show that an ideal algorithm to solve this problem is PatchMatch [1] that we extend to find an approximate nearest neighbor according to a plane. In addition to PatchMatch’s spatial propagation scheme, we propose (1) view propagation where planes are propagated among left and right views of the stereo pair and (2) temporal propagation where planes are propagated from preceding and consecutive frames of a video when doing temporal stereo. Adaptive support weights are used in matching cost aggregation to improve results at disparity borders. We also show that our slanted support windows can be used to compute a cost volume for global stereo methods, which allows for explicit treatment of occlusions and can handle large untextured regions. In the results we demonstrate that our method reconstructs highly slanted surfaces and achieves impressive disparity details with sub-pixel precision. In the Middlebury table, our method is currently top-performer among local methods and takes rank 2 among approximately 110 competitors if sub-pixel precision is considered.		Michael Bleyer;Christoph Rhemann;Carsten Rother	2011		10.5244/C.25.14	artificial intelligence;computer vision;computer science	Vision	66.50336456967176	-54.6074660214454	64404
aacde021243739eca25cad012eaa81287f539ac1	light field compressed sensing over a disparity-aware dictionary	light field perspective shifting compressed sensing sparse representation;compressed sensing;compressed sensing image coding image reconstruction image representation image sampling image sensors;dictionaries cameras image reconstruction spatial resolution apertures compressed sensing hardware;image reconstruction;dictionaries;light field compressed sensing disparity aware dictionary light field acquisition sensor resource spatial resolution angular resolution high resolution lf sampling high resolution lf reconstruction coded aperture camera perspective shifting lf dictionary sparse highly correlated lf representation subaperture scan normalized fluctuation scene disparity calculation scene disparity acquisition reconstruction quality computation efficiency;cameras;compressed sensing light field lf perspective shifting sparse representation;apertures;hardware;spatial resolution	Light field (LF) acquisition faces the challenge of extremely bulky data. Available hardware solutions usually compromise the sensor resource between spatial and angular resolutions. In this paper, a compressed sensing framework is proposed for the sampling and reconstruction of a high-resolution LF based on a coded aperture camera. First, an LF dictionary based on perspective shifting is proposed for the sparse representation of the highly correlated LF. Then, two separate methods, i.e., subaperture scan and normalized fluctuation, are proposed to acquire/calculate the scene disparity, which will be used during the LF reconstruction with the proposed disparity-aware dictionary. At last, a hardware implementation of the proposed LF acquisition/reconstruction scheme is carried out. Both quantitative and qualitative evaluation show that the proposed methods produce the state-of-the-art performance in both reconstruction quality and computation efficiency.	angularjs;binocular disparity;coded aperture;compressed sensing;computation;dictionary;image resolution;light field;performance;quantum fluctuation;sas;sampling (signal processing);sparse approximation;sparse matrix	Jie Chen;Lap-Pui Chau	2017	IEEE Transactions on Circuits and Systems for Video Technology	10.1109/TCSVT.2015.2513485	iterative reconstruction;aperture;computer vision;image resolution;computer science;machine learning;pattern recognition;compressed sensing	Vision	67.16302975432984	-61.80295874067607	64542
953594394357d1b7e7d61a4809945bb5d1cbf619	characterizing eye movements during temporal and global quality assessment of h.264 compressed video sequences	eye;quality measurement;video	Studies have shown that the deployment of visual attention is closely link to the assessment of image or video quality, though this link is not yet fully understood. The influence of rating temporal quality of compressed videos over the way an observer deploys his attention is investigated in this paper. We set-up a subjective experiment in which the eye movements of observers are recorded during three different tasks: a free-viewing task (FT), a global quality assessment task and a temporal quality assessment task. The FT acts as a reference to which we compare the eye movements during the two other tasks. As previously shown, observers assessing global quality gaze at locations dissimilar to those fixated during the FT. For temporal quality assessment, it seems that the fixated locations are closer to FT than the global quality assessment fixated locations. Our results suggest that the locations observers look at do not depend on the displayed video quality level. Quality however influences the way participants look at videos: the lower the quality, the longer they gaze at a precise location. The area fixated seems to be much smaller during the quality assessment tasks than during the FT for either perfect or poor quality level. The evolution over time of all indicators suggests that, during the first 1 or 2 seconds, the signal properties of the videos are the main attractors for the participants' eye movements. Instructions only seem to play a role afterwards on the deployment of the participants' visual attention.© (2012) COPYRIGHT Society of Photo-Optical Instrumentation Engineers (SPIE). Downloading of the abstract is permitted for personal use only.	data compression;h.264/mpeg-4 avc	Claire Mantel;Nathalie Guyader;Patricia Ladret;Gelu Ionescu;Thomas Kunlin	2012		10.1117/12.910122	computer vision;simulation;video;multimedia	AI	64.42028020073411	-63.14442422972383	64584
6d94388782e15ea2082edb589ea0f9700cfe8ef9	capability of integrated modis imagery and alos for oil palm, rubber and forest areas mapping in tropical forest regions	horticulture;forests;tropical climate;oil palm;rubber;tropical forests;spectrum analysis;moderate resolution imaging spectroradiometer;alos;photography;forest;oil palms;tropical regions;remote sensing;malaysia;forest plantations;modis;satellite imagery;mapping;accuracy mapping;systems integration;spacecraft;environmental monitoring	Various classification methods have been applied for low resolution of the entire Earth's surface from recorded satellite images, but insufficient study has determined which method, for which satellite data, is economically viable for tropical forest land use mapping. This study employed Iterative Self Organizing Data Analysis Techniques (ISODATA) and K-Means classification techniques to classified Moderate Resolution Imaging Spectroradiometer (MODIS) Surface Reflectance satellite image into forests, oil palm groves, rubber plantations, mixed horticulture, mixed oil palm and rubber and mixed forest and rubber. Even though frequent cloud cover has been a challenge for mapping tropical forests, our MODIS land use classification map found that 2008 ISODATA-1 performed well with overall accuracy of 94%, with the highest Producer's Accuracy of Forest with 86%, and were consistent with MODIS Land Cover 2008 (MOD12Q1), respectively. The MODIS land use classification was able to distinguish young oil palm groves from open areas, rubber and mature oil palm plantations, on the Advanced Land Observing Satellite (ALOS) map, whereas rubber was more easily distinguished from an open area than from mixed rubber and forest. This study provides insight on the potential for integrating regional databases and temporal MODIS data, in order to map land use in tropical forest regions.	classification;database;databases;forests;guided imagery;iterative method;k-means clustering;moderate resolution imaging spectroradiometer;phoenix dactylifera	Sheriza Mohd Razali;Arnaldo Marin;Ahmad Ainuddin Nuruddin;Helmi Zulhaidi Mohd Shafri;Hazandy Abdul Hamid	2014		10.3390/s140508259	forest;environmental monitoring;remote sensing	ML	80.89495202966951	-57.15286565071938	64586
17172e00c0d103aee88ba6a5f9ed0a406416b2a3	atmospheric humidity sounding using differential absorption radar near 183 ghz		A tunable G-band frequency-modulated continuous-wave radar system has been developed and used to perform differential absorption atmospheric humidity measurements for the first time. The radar’s transmitter uses high- power-handling GaAs Schottky diodes to generate between 15–23 dBm over a 10-GHz bandwidth near 183 GHz. By virtue of a high-isolation circular polarization duplexer, the monostatic radar’s receiver maintains a noise figure of about 7 dB even while the transmitter is on. With an antenna gain of 40 dB, high-SNR detection of light rain is achieved out to several hundred meters distance. Owing to the strong spectral dependence of the atmospheric absorption over the upper flank of the 183-GHz water absorption line, range-resolved measurements of absolute humidity can be obtained by ratioing the rain echoes over both range and frequency. Absorption measurements obtained are consistent with models of atmospheric millimeter-wave attenuation, and they demonstrate a new method for improving the accuracy of humidity measurements inside of clouds.	automatic sounding;circular polarization;dbm;diode;duplexer;modulation;noise figure;radar;schottky barrier;signal-to-noise ratio;transmitter	Ken B. Cooper;Raquel Rodriguez Monje;Luis Mill&#x00E1;n;Matthew Lebsock;Simone Tanelli;Jose V. Siles;Choonsup Lee;Andrew Brown	2018	IEEE Geoscience and Remote Sensing Letters	10.1109/LGRS.2017.2776078	mathematics;remote sensing;attenuation;bistatic radar;antenna gain;radar;noise figure;duplexer;chirp;optics;bandwidth (signal processing)	Mobile	80.9537564294513	-66.28010701737954	64605
c8be32bdc7661f92f0309f80ecc498669ffba23b	fast extraction of cutter engagement features by using the parallel processing function of a gpu		For an accurate analysis of the cutting force, the cutter engagement feature (CEF) representing the contact area between the cutter and workpiece must be extracted for each small feed motion of the cutter. In this paper, we propose a novel algorithm for accelerating the CEF computation by using the parallel processing capability of a graphics processing unit. In a milling simulation, the results of a prior cutting operation affect the subsequent CEF computations. This dependency on the cutting sequence can be ignored in a cutting operation along a linear trajectory. Based on this consideration, a new parallel CEF computation algorithm is developed. Our cutting simulation system using this algorithm can compute the CEF at 100,000 cutting positions in a few seconds.	algorithm;chromium embedded framework;computation;computer graphics;cutter expansive classification;cutting sequence;graphics processing unit;parallel computing;simulation	Masatomo Inui;Masayoshi Kobayashi;Nobuyuki Umezu	2017	2017 13th IEEE Conference on Automation Science and Engineering (CASE)	10.1109/COASE.2017.8256180	cutting sequence;graphics processing unit;contact area;computer vision;computation;parallel processing;trajectory;artificial intelligence;computer science	Robotics	69.05318874381351	-54.28218958387899	64619
ec7754cc2e87872b700b1703641144373a0be83c	a statistical approach to detect edges in sar images based on square successive difference of averages	geophysical image processing;image edge detection speckle detectors noise remote sensing gaussian distribution random variables;synthetic aperture radar geophysical image processing geophysical techniques radar imaging;synthetic aperture radar sar adaptive double thresholds edge detector edge thinning sar images square successive difference of averages ssdoa;synthetic aperture radar statistical approach real sar images average square successive difference statistical edge detector edge strength indicator constant false alarm rate postprocessing approach edge thinning adaptive double threshold processing edge detection results ratio of average operators;radar imaging;geophysical techniques;synthetic aperture radar	In this letter, a statistical edge detector based on the square successive difference of averages has been proposed and tested for SAR images. The operator employs the square successive of mean difference as the edge strength indicator for SAR images. It has been proved to be with constant false alarm rate and performs well in representation of many more region shapes. A postprocessing approach, including edge thinning and adaptive double-threshold processing, is proposed to refine the edge detection results. The performance of the proposed operator has been evaluated and compared with that of the Canny and ratio-of-average operators on simulated and real SAR images. The experimental results indicate that the operator achieves better performance in the detection rate and the localization accuracy, and the detected edges are more complete and longer than those by the other two operators.	canny edge detector;constant false alarm rate;edge detection;thinning	Xingyu Fu;Hongjian You;Kun Fu	2012	IEEE Geoscience and Remote Sensing Letters	10.1109/LGRS.2012.2190378	computer vision;synthetic aperture radar;geology;mathematics;canny edge detector;radar imaging;inverse synthetic aperture radar;remote sensing	Vision	72.22633962911624	-62.833030586785476	64638
4233d5bb6bc7e02e5c0ad58b660edb1446b76c4e	monitoring and correction methods for geomagnetic data influenced by artificial disturbances	artificial disturbance;geomagnetism;absolute observation;baseline value	Monitoring systems consisting of several magnetometers and cameras were installed to detect artificial magnetic disturbances at the Kakioka, Memambetsu, and Kanoya Magnetic Observatories in Japan. These systems calculate the magnetic dipole moment and source position of artificial magnetic disturbances as a routine matter. For sources of disturbance that are not magnetic dipole moments, each event must be tackled individually. For a non-dipole disturbance at Kanoya from 16 to 22 June 2011, the position and intensity of two lines of direct currents were calculated, and the baseline value affected by these currents was corrected appropriately.	baseline (configuration management);norm (social)	Shingo Nagamachi;Kenji Morinaga;Yoshitomo Ikoma;Mayumi Akutagawa;Takashi Moriyama;Takeshi Oowada;Tetsuo Tokumoto	2013	Data Science Journal	10.2481/dsj.G-034	earth's magnetic field	Robotics	78.21214921118953	-52.693958178223966	64678
81b9460d0f78cea1a06627ec53d6a5b503c1fd45	natural image noise level estimation based on local statistics for blind noise reduction		This study proposes an automatic noise estimation method based on local statistics for additive white Gaussian noise. Noise estimation is an important process in digital imaging systems. For example, the performance of an image denoising algorithm can be significantly degraded because of poor noise level estimation. Most of the literature on the subject tends to use the true noise level of a noisy image when suppressing noise artifacts. Moreover, even with the given true noise level, these denoising techniques still cannot attain the best result, particularly for images with complicated details. In this study, a patch-based estimation technique is used to estimate for noise level and applies it to the proposed blind image denoising algorithm. Our approach includes selecting low-rank sub-image with removing high-frequency components from the contaminated image. This selection is according to the gradients of patches with the same statistics. Consequently, we need to estimate the noise level from the selected patches using principal component analysis (PCA). For blind denoising applications, the proposed denoising algorithm integrates the undecimated wavelet-based denoising algorithms and PCA to develop the subjective and objective qualities of the observed image, which result from filtering processes. Experiment results depict that the suggested algorithm performs efficiently over a wide range of visual contents and noise conditions, as well as in additive noise. Associated with different conventional noise estimators, the proposed algorithm yields the best performance, higher-quality images, and faster running speed.	additive white gaussian noise;algorithm;digital image;digital imaging;experiment;image gradient;image noise;noise (electronics);noise reduction;noise shaping;peak signal-to-noise ratio;principal component analysis;semiconductor industry;thresholding (image processing);utility functions on indivisible goods;wavelet	Asem Khmag;Abd. Rahman Ramli;S. A. R. Al-Haddad;Noraziahtulhidayu Kamarudin	2017	The Visual Computer	10.1007/s00371-017-1362-0	image noise;computer science;value noise;salt-and-pepper noise;computer vision;statistics;noise measurement;gaussian noise;median filter;video denoising;gradient noise;pattern recognition;artificial intelligence	ML	57.9259278483591	-66.20538397393824	64689
2f62e445470e453cc79d1997173aac45375a1358	scale-change aware locally adaptive optical flow	training;computer vision;optical imaging;estimation;robustness;adaptive optics;data models	Optical flow is one of the key components in computer vision research area. Since the seminal work proposed by Horn and Schunck [1], numerous advanced algorithms have been proposed. Many state-of-the-art optical flow estimation algorithms optimize the data and regularization terms to solve ill-posed problems. However, despite their major advances over last decade, conventional optical flow methods utilize a single or fixed data terms without concerning scale changes in two consecutive frames of images. In this paper, we propose scale-change aware block matching data terms fused with locally adaptive models to establish dense correspondence between frames containing objects in different scales. We observed that taking scale variations into account in matching has a positive effect on optical flow accuracy.	algorithm;computer vision;iso 10303;mathematical optimization;online and offline;optical flow;preprocessor;real-time clock;well-posed problem	Euyoung Kim;Kyoung Mu Lee	2016	2016 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA)	10.1109/APSIPA.2016.7820725	computer vision;simulation;computer science;theoretical computer science	Vision	56.17655749958186	-56.68907623857907	64771
1cff489d55faabf0773f7d0dde24c7222b0529dc	color image enhancement technique using gamut mapping based on color space division	color space;color difference;image enhancement;human visual system;color reproduction;color image	This paper proposes a gamut mapping algorithm based on color space division for color reproduction of cross media. As each color device has a limited range of producible colors, the reproduced colors on a destination device are different from those of the original device. In order to reduce the color difference between those devices, the proposed method divides the whole gamut into parabolic shapes based on intersecting lightness by the “just noticeable difference” (JND) and the boundary of original gamut. By dividing the gamut with parabolic shapes and piecewise mapping of each region, it not only considers gamut characteristics but also provides for mapping uniformity. The lightness variations are more sensitive to the human visual system and by using lightness JND it can restrict lightness mapping variations that are unperceivable. As a result, the proposed algorithm is able to reproduce high quality color images using low-cost color devices.	algorithm;circuit complexity;color image;color management;color space;display resolution;image editing;output device;parabolic antenna;printing	Yang Ho Cho;Yun-Tae Kim;Ho-Keun Lee;Yeong-Ho Ha	2003		10.1117/12.474879	color histogram;false color;rgb color model;computer vision;icc profile;color model;color quantization;hsl and hsv;lightness;color depth;color image;geography;rgb color space;high color;color difference;color balance;optics;color space;computer graphics (images)	Robotics	60.02363421621949	-61.09039882149945	64773
f8ec90082873eeb423c73e7fe7aaef9fa5fc1f23	blind sharpness prediction based on image-based motion blur analysis	scene classification video sharpness assessment motion blur adaptive sharpness pooling region of interest;degradation;cameras discrete fourier transforms quality assessment degradation tracking distortion measurement;distortion measurement;quality assessment;sharpness measurements blind sharpness prediction image based motion blur analysis high bit rate video video contents focal blur compression distortion visual sharpness assessment vsa high resolution video scene classification sharpness estimation visual perception camera movements object movements spectral domain scene adaptive pooling;video signal processing cameras image classification image motion analysis image resolution image restoration;discrete fourier transforms;cameras;tracking	For high bit rate video, it is important to acquire the video contents with high resolution, the quality of which may be degraded due to the motion blur from the movement of an object(s) or the camera. However, conventional sharpness assessments are designed to find focal blur caused either by defocusing or by compression distortion targeted for low bit rates. To overcome this limitation, we present a no-reference framework of a visual sharpness assessment (VSA) for high-resolution video based on the motion and scene classification. In the proposed framework, the accuracy of the sharpness estimation can be improved via pooling weighted by the visual perception from the object and camera movements and by the strong influence from the region with the highest sharpness. Based on the motion blur characteristics, the variance and the contrast over the spectral domain are used to quantify the perceived sharpness. Moreover, for the VSA, we extract the highly influential sharper regions and emphasize them by utilizing the scene adaptive pooling. Based on the subjective results, we demonstrate that the VSA can measure the video sharpness more accurately than other sharpness measurements for high-resolution video.	algorithm;box blur;digital video;display resolution;distortion;elegant degradation;focal (programming language);gaussian blur;image resolution;visual basic[.net]	Taegeun Oh	2015	IEEE Transactions on Broadcasting	10.1109/TBC.2015.2395092	computer vision;degradation;computer science;tracking;multimedia;computer graphics (images)	Vision	63.77022502522366	-62.93174814848094	64836
a75f8e154307bc284aae7115278912bf8c85b57f	supervised and unsupervised landuse map generation from remotely sensed images using ant based systems	remote sensing image;image segmentation;ant colony;automatic generation;evaluation measure;clustering;remote sensing;landuse map;pattern classification;land cover mapping;aggregation pheromone	The landuse or land-cover map depicts the physical coverage of the Earth’s terrestrial surface according to its use. Landuse map generation from remotely sensed images is one of the challenging tasks of remote sensing technology. In this article, motivated from group forming behavior of real ants, we have proposed two novel ant based (one supervised and one unsupervised) algorithms to automatically generate landuse map from multispectral remotely sensed images. Here supervised landuse map generation is treated as	algorithm;multispectral image;supervised learning;terrestrial television	Anindya Halder;Ashish Ghosh;Susmita Ghosh	2011	Appl. Soft Comput.	10.1016/j.asoc.2011.02.030	computer vision;computer science;ant colony;machine learning;image segmentation;cluster analysis	Robotics	75.72159082595526	-58.39883684297852	64850
c8bfb7b5dbfc930ba4708fbba884ab732c2f34f5	viirs reflective solar bands on-orbit calibration using the moon	degradation;oceans;uncertainty;geometry;moon calibration degradation oceans geometry uncertainty radiometry;radiometry;remote sensing artificial satellites calibration lunar surface;moon;calibration viirs rsb sd sdsm;viirs reflective solar band lunar calibration viirs rsb calibration coefficient lunar surface short wavelength band solar diffuser degradation solar diffuser stability monitor solar diffuser panel lunar observation ad 2011 11 21 moon viirs rsb on orbit calibration visible infrared imager radiometer suite;calibration	The Visible Infrared Imager Radiometer Suite (VIIRS) has been on-orbit for more than three and half years. It has been scheduled to view the moon approximately monthly since its nadir door open on November 21, 2011. The scheduled lunar observations have been used to monitor the VIIRS reflective solar bands (RSB) on-orbit gain changes. The VIIRS RSB are primarily calibrated by an onboard Solar Diffuser (SD) panel and an accompanying Solar Diffuser Stability Monitor (SDSM). Due to non-uniformity of the SD degradation, the SD/SDSM calibration may have non-negligible errors, especially for the short wavelength bands. Since lunar surface is very stable, the Moon can be used to provide more reliable on-orbit long-term gain changes of the RSB. The RSB calibration coefficients derived from the lunar calibration are generally consistent with those derived from the SD/SDSM calibration, but clear differences in trend are seen, especially for the short wavelength bands.	circuit complexity;coefficient;elegant degradation;image sensor;moon	Junqiang Sun;Menghua Wang	2015	2015 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)	10.1109/IGARSS.2015.7326226	calibration;radiometry;degradation;uncertainty;atmospheric sciences;natural satellite;optics;physics;statistics;remote sensing	Embedded	82.45343137308781	-63.23973423199371	64970
4465b1151408a75a5107624bd125cd7f62fbe839	identification of swell zones in the ocean: a remote sensing approach	radar remote sensing;oceans;gravity;seasonal pattern ocean wave swell swell zone identification radar remote sensing measurement technique feasibility collocated wind speed significant wave height radar scatterometry spaceborne radar spatial pattern;swell;feasibility;physics;remote sensing by radar;collocated wind speed;feasibility study;spatial pattern;energy measurement;seasonal pattern;wind speed;remote sensing;satellites;oceans remote sensing sea measurements wind speed velocity measurement radar measurements energy measurement physics satellites gravity;spaceborne radar ocean waves oceanographic techniques remote sensing by radar;velocity measurement;radar scatterometry;radar measurements;ocean wave;measurement technique;oceanographic techniques;swell zone identification;ocean waves;sea measurements;spaceborne radar;significant wave height	This paper presents a feasibility study of using collocated wind speed and significant wave height measurements from simultaneous satellite scatterometer and altimeter to observe the spatial and seasonal pattern of dominant swell zones in the world's oceans.		Ge Chen;Jun Ma	2002		10.1109/IGARSS.2002.1025738	meteorology;wind wave;feasibility study;atmospheric sciences;physics;remote sensing	HCI	81.30826395526726	-63.749152843956054	65033
8f5854a0993627b51524055656950137cfae5278	plantation rows identification by means of image tiling and hough transform		In this work we address the problem of plantation rows identification on UAV imaged coffee crop fields. A fair number of approaches address the problem using the Hough Transform. However it assumes the plantation lines are straight which is hardly the case in Aerial images. We propose a tiling scheme which allows one to acceptably approximate the rows inside each tile to straight lines making it feasible to apply the Hough Transform. Experimental results compared to ground truths seems to indicate the proposed approach successfully approximate real plantation rows.	aerial photography;approximation algorithm;automatic parallelization;gigabyte;hough transform;image noise;microsoft windows;noise reduction;parallel computing;tessellation (computer graphics);tiling window manager;unmanned aerial vehicle	Guilherme Afonso Soares;Daniel Duarte Abdala;Mauricio Escarpinati	2018		10.5220/0006657704530459	row;computer vision;computer science;hough transform;artificial intelligence	Vision	65.67057058765236	-55.37274973345067	65052
77d134989ba7c27747ad9fb8eb5bc7f41b83226a	hypermix: an open source tool for hyperspectral imaging	open source tool hyperspectral imaging unmixing;graphics processing units geophysical image processing geophysical techniques;hyperspectral imaging graphics processing units estimation algorithm design and analysis;estimation;graphics processing units;hyperspectral imaging;algorithm design and analysis;hypermix gpu graphical processing unit complex processing graphical chains endmember abundances endmember signatures pure spectral signatures spectral unmixing chain remotely sensed hyperspectral images open source tool	Spectral unmixing has been a popular technique for analyzing remotely sensed hyperspectral images. The goal of unmixing is to find a collection of pure spectral signatures (called endmembers) that can explain each (possibly mixed) pixel of the scene as a combination of endmembers, weighted by their coverage fractions in the pixel or abundances. Over the last years, many algorithms have been presented to address the different parts of the spectral unmixing chain. These algorithms can be categorized in estimation of the number of end-members, identification of the endmember signatures, and estimation of the endmember's abundances on each pixel. This work presents a tool that integrates many efficient implementations of different methods in order to build more complex processing graphical chains. Also, the tool offers compatibility with the graphical processing unit (GPU), so that algorithms are automatically executed in parallel by the GPU (if available) in order to improve performance. The tool is available online from http://hypercomphypermix.blogspot.com.es and has been validated with both synthetic and real hyper-spectral scenes providing state-of-the-art unmixing results.	algorithm;antivirus software;categorization;graphical user interface;graphics processing unit;open-source software;pixel;stellar classification;synthetic intelligence;type signature	Luis-Ignacio Jimenez;Antonio J. Plaza	2015	2015 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)	10.1109/IGARSS.2015.7326127	algorithm design;computer vision;estimation;computer science;hyperspectral imaging;statistics;remote sensing;computer graphics (images)	Vision	70.17820931801158	-64.9744581131061	65358
9781f6cf17b57e47dcc7fb26d5c56389f324bec7	improving the visual comprehension of point sets	computer graphics;data reduction computer graphics;data reduction visual comprehension point sets 3d scanning systems depth cameras;data reduction;observers three dimensional displays image reconstruction approximation algorithms surface reconstruction noise	"""Point sets are the standard output of many 3D scanning systems and depth cameras. Presenting the set of points as is, might """"hide"""" the prominent features of the object from which the points are sampled. Our goal is to reduce the number of points in a point set, for improving the visual comprehension from a given viewpoint. This is done by controlling the density of the reduced point set, so as to create bright regions (low density) and dark regions (high density), producing an effect of shading. This data reduction is achieved by leveraging a limitation of a solution to the classical problem of determining visibility from a viewpoint. In addition, we introduce a new dual problem, for determining visibility of a point from infinity, and show how a limitation of its solution can be leveraged in a similar way."""	3d scanner;duality (optimization);list comprehension;sampling (signal processing);shading;standard streams	Sagi Katz;Ayellet Tal	2013	2013 IEEE Conference on Computer Vision and Pattern Recognition	10.1109/CVPR.2013.23	computer vision;data reduction;computer science;theoretical computer science;mathematics;computer graphics;computer graphics (images)	Vision	58.56684017644715	-52.58479554317432	65449
115b7a217c2e314d36c5c5ae31e73e9d7ceae336	color-image quality assessment: from metric to application		In digital imaging, evaluating the visual quality of images is a crucial requirement for most image-processing systems. For such an image quality assessment, mainly objective assessments are employed which automatically predict image quality by a computer algorithm. The vast majority of objective assessments are so-called image-difference metrics which predict the perceived difference between a distorted image and a reference. Due to the limited understanding of the human visual system, image quality assessment is not straightforward and still an open research field. The majority of image-difference metrics disregard color information which allows for faster computation. Even though their performance is sufficient for many applications, they are not able to correctly predict the quality for a variety of color distortions. Furthermore, many image-difference metrics do not account for viewing conditions which may have a large impact on the perceived image quality (e.g., a large display in an office compared with a small mobile device in the bright sunlight). The main goal of my research was the development of a new image-difference metric called improved Color-Image-Difference (iCID) which normalizes images to standard viewing conditions and extracts chromatic features. The new metric was then used as objective function to improve gamut mapping as well as tone mapping. Both methods represent essential transformations for the reproduction of color images. The performance of the proposed metric was verified by visual experiments as well as by comparisons with human judgments. The visual experiments reveal significant improvements over state-of-the-art gamut-mapping and tone-mapping transformations. For gamut-mapping distortions, iCID exhibits the significantly highest correlation to human judgments and for conventional distortions (e.g., noise, blur, and compression artifacts), iCID outperforms almost all state-of-the-art metrics.		Jens Preiss	2015				Vision	61.947715111580116	-63.51043653667817	65464
050d71e035db50a5696d84016098ef13ce492389	stereo matching in the presence of sub-pixel calibration errors	driver assistance example;calibration;image matching;stereo image matching;signal theory;sub-pixel calibration error;filter solution;cameras;filtering theory;robotics example;stereo image processing;parametric camera model;layout;ground truth;pixel;lenses;temperature;correlation;image reconstruction;glass	Stereo matching commonly requires rectified images that are computed from calibrated cameras. Since all underlying parametric camera models are only approximations, calibration and rectification will never be perfect. Additionally, it is very hard to keep the calibration perfectly stable in application scenarios with large temperature changes and vibrations. We show that even small calibration errors of a quarter of a pixel are severely amplified on certain structures. We discuss a robotics and a driver assistance example where sub-pixel calibration errors cause severe problems. We propose a filter solution based on signal theory that removes critical structures and makes stereo algorithms less sensitive to calibration errors. Our approach does not aim to correct decalibration, but rather to avoid amplifications and mismatches. Experiments on ten stereo pairs with ground truth and simulated decalibrations as well as images from robotics and driver assistance scenarios demonstrate the success and limitations of our solution that can be combined with any stereo method.	algorithm;approximation;background subtraction;bilateral filter;computer stereo vision;ground truth;image rectification;pixel;rectifier;robotics;second generation multiplex;signal processing;sobel operator	Heiko Hirschmüller;Stefan K. Gehrig	2009	2009 IEEE Conference on Computer Vision and Pattern Recognition	10.1109/CVPRW.2009.5206493	iterative reconstruction;layout;signalling theory;computer vision;calibration;simulation;temperature;ground truth;computer science;lens;glass;correlation;pixel;computer graphics (images)	Vision	59.166744337952295	-57.06486583142987	65587
10736ed3dde5e22eabcc11c07c015c5fd446b768	a matrix sampling-and-recovery approach for many-lights rendering	matrix sampling and recovery;many lights	Instead of computing on a large number of virtual point lights (VPLs), scalable many-lights rendering methods effectively simulate various illumination effects only using hundreds or thousands of representative VPLs. However, gathering illuminations from these representative VPLs, especially computing the visibility, is still a tedious and time-consuming task. In this paper, we propose a new matrix sampling-and-recovery scheme to efficiently gather illuminations by only sampling a small number of visibilities between representative VPLs and surface points. Our approach is based on the observation that the lighting matrix used in manylights rendering is of low-rank, so that it is possible to sparsely sample a small number of entries, and then numerically complete the entire matrix. We propose a three-step algorithm to explore this observation. First, we design a new VPL clustering algorithm to slice the rows and group the columns of the full lighting matrix into a number of reduced matrices, which are sampled and recovered individually. Second, we propose a novel prediction method that predicts visibility of matrix entries from sparsely and randomly sampled entries. Finally, we adapt the matrix separation technique to recover the entire reduced matrix and compute final shadings. Experimental results show that our method heavily reduces the required visibility sampling in the final gathering and achieves 3--7 times speedup compared with the state-of-the-art methods on test scenes.	algorithm;cluster analysis;column (database);numerical analysis;randomness;sampling (signal processing);scalability;simulation;speedup;the matrix;vpl research	Yuchi Huo;Rui Wang;Shihao Jin;Xinguo Liu;Hujun Bao	2015	ACM Trans. Graph.	10.1145/2816795.2818120	simulation;computer science;theoretical computer science;computer graphics (images)	Graphics	70.05999521936462	-53.93239953657905	65592
c1639357ad579e330fd82198fbabab37c7481530	distributed supercomputing for graphics applications: a case study on an implementation of the radiosity approach	radiosity approach;case study;graphics applications	Besides the ray tracing technique, the radiosity method is another major approach for global illumination modeling in the field of computer graphics. Since this method needs a huge amount of storage space (both memory and disk) and a long pre-computation cycle, it is not suitable to implement it on conventional workstations, so therefore that supercomputers are necessary for such kind of graphics applications.		José L. Encarnação;Geory Köberle;Ning Zhang	1989		10.1007/978-3-642-74844-8_2	computational science;parallel computing;computer science;computer graphics (images)	HPC	68.51095010514568	-52.21790869273071	65651
7f8cf3e9d7149f20b46407f3377bff6498a976aa	tof depth map super-resolution using compressive sensing	tof camera sampling model tof depth map super resolution time of flight depth map super resolution compressive sensing realtime depth information hd color cameras 3d reconstruction cs based depth map super resolution method low resolution depth map high resolution depth map reconstruction theory;compressed sensing;image resolution;image resolution cameras compressed sensing image reconstruction;time of flight camera;cameras image resolution sparse matrices image reconstruction vectors compressed sensing signal resolution;depth;vectors;compressive sensing;image reconstruction;signal resolution;super resolution;super resolution depth time of flight camera compressive sensing;sparse matrices;cameras	Although Time-of-Flight (TOF) camera can provide real-time depth information from a real scene, the resolution of depth map captured by TOF camera is rather limited compared to HD color cameras, and thus it cannot be directly used in 3D reconstruction. In order to handle this problem, this paper proposes a novel compressive sensing (CS) based depth map super-resolution method, which transforms a low resolution depth map to a high resolution depth map. Different from previous depth map SR methods, this algorithm uses a model-based CS as reconstruction theory, and this method also builds a TOF camera sampling model which is used in depth map SR. Experimental results show that the proposed method outperforms state-of-the-art methods for depth map super-resolution.	3d reconstruction;algorithm;compressed sensing;depth map;digital camera;image resolution;real-time clock;reconstruction conjecture;sampling (signal processing);super-resolution imaging;time-of-flight camera	Li-Wei Liu;Yang Li;Liang-Hao Wang;Dongxiao Li;Ming Zhang	2013	2013 Seventh International Conference on Image and Graphics	10.1109/ICIG.2013.33	computer vision;computer science;mathematics;compressed sensing;computer graphics (images)	Vision	57.7229725993007	-56.57714061724977	65672
2240d6484d6c9dd82e4a0b208608735319bdbdba	application of color transferring base on reinhard algorithm	painting;style of painting reinhard algorithm color transfer lαβ color space;color space;painting image colour analysis;image color analysis painting art argon algorithm design and analysis shape machine vision;image colour analysis;painting color transferring base reinhard algorithm color image analysis linear transformation	Transferring color between images is a method that borrows one image's color characteristics from another. The classic algorithm of color transferring named Reinhard was analyzed, and some methods which set different parameters to determine the linear transformation between two images were proposed. These new methods can generate different styles of painting of images. The experiments show that the proposed methods can generate convincing results with better performance. Transferring color applies to two images which are of strong similarity, it is worth further exploration on the art style of images.	algorithm;color;experiment	Dingying Tan;Pingping Chen;Huiling Liu;Xiufeng Liu	2011	Proceedings of 2011 International Conference on Electronic & Mechanical Engineering and Information Technology	10.1109/EMEIT.2011.6023080	color histogram;false color;rgb color model;computer vision;color model;color quantization;color normalization;color depth;color image;painting;computer science;color balance;color space;computer graphics (images)	Robotics	58.836178239665344	-63.048236841830196	65741
ce6d2d3a28308339af8a646a054b4f60fd124a41	optimized design of sun sensor and centroid algorithm for small satellite mission	sun arrays indexes calculators satellites photodiodes calibration;sunlight angular measurement artificial satellites attitude measurement calibration field programmable gate arrays photodetectors photodiodes sensor arrays sun;linear photodiode array attitude determination centroid algorithm digital sun sensor sun tracker;natural sunlight small satellite mission attitude determination system calibration 2 axis digital sun sensor linear photodiode array sun aspect angle determination centroid based technique fpga;centroid algorithm digital sun sensor;sun tracker;attitude determination;linear photodiode array	One of the most important components of attitude determination system for small satellite is sun sensor. In this paper design, development and calibration of 2-axis digital sun sensor using linear Photodiodes array is presented. Senor design comprises two linear arrays mounted orthogonally to provide Sun aspect angle in two axes. The Sun aspect angle is determined by the centroid based technique and implemented using FPGA. The proposed centroid algorithm is capable of obtaining the position of the centroid to an accuracy of sub pixel level which is desirable in such designs. A method of calibration using natural sun light is also presented. Commercial grade components were used which have resulted in development of low cost, light weight and power efficient sensor.	algorithm;field-programmable gate array;pixel	Bilal Ahmad Alvi;Naeem Abbas;Amber Israr;Muhammad Asif	2014	2014 4th International Conference on Wireless Communications, Vehicular Technology, Information Theory and Aerospace & Electronic Systems (VITAE)	10.1109/VITAE.2014.6934493	solar tracker;optics;physics;remote sensing	Robotics	80.30057855432192	-69.11388213144824	65865
59e27a0805ef1556e08562482fc10c0558f5cb8f	calibration of a superdarn radar antenna by means of a satellite beacon on a cubesat	hf antennas;antenna arrays;super dual auroral radar network hf beacon payload zacube 1 cubesat elevation resolving algorithm radio signal superdarn hf radar antenna beam pattern ionosphere polar regions calibration;remote sensing by radar;ionospheric techniques;spaceborne radar satellites arrays radar antennas ionosphere satellite broadcasting;polar ionosphere superdarn radar hf beacon;remote sensing by radar antenna arrays calibration hf antennas ionospheric techniques;calibration	This paper presents the context and potential outcomes of the HF Beacon payload on the ZACUBE-1 CubeSat jointly developed by the Satellite Engineering Program of F'SATI at the Cape Peninsula University of Technology (CPUT) in Bellville and the Space Science Directorate of the South African National Space Agency (SANSA Space Science) in Hermanus. The primary objective of the HF Beacon on ZACUBE-1 is to provide a continuous radio signal to determine the elevation resolving algorithm of the SuperDARN HF Radar antenna at SANAE in Antarctica. The signal will also be used to characterize the beam pattern of this and other HF Radar antennas in the SuperDARN network, and to characterize the ionosphere over the polar regions.	algorithm;radar;radiation pattern;radio wave	Pierre J. Cilliers;Doreen Agaba;Michael R. Inggs;Robert van Zyl	2013	2013 IEEE International Geoscience and Remote Sensing Symposium - IGARSS	10.1109/IGARSS.2013.6723017	early-warning radar;continuous-wave radar;radar engineering details;calibration;atmospheric sciences;geodesy;bistatic radar;3d radar;radar imaging;physics;radar;remote sensing	Embedded	80.87405934175212	-64.40755798584047	65909
ceaf42f0881512461c9d539da82aadd75840813d	from image to video, depth data reconstruction from a subset of samples: representations, algorithms, and sampling strategies	engineering;alternating direction method of multipliers;depth enhancement;dense depth estimation;and sampling strategies university of california;image and video processing;depth data reconstruction from a subset of samples representations;sparse reconstruction;algorithms;lee kang;san diego truong nguyen liu;engineering from image to video	Depth data acquisition has drawn considerable interest in recent years as a result of the rapid development of 3D technology. A large number of acquisition techniques are based on hardware devices, e.g., infra-red sensors, time-of-flight camera, and LiDAR, etc, whereas they have limited performance due to poor depth precision and low resolution. In some situations computational methods are preferred due to its flexibility and low cost. These computational techniques, typically known as depth estimation algorithms, estimate depth maps (in terms of disparities) from a pair of stereo images. However, existing computational techniques are sensitive to various factors such as noise, camera alignment, and illumination, resulting that a few samples are reliable. Therefore, dense depth data reconstruction from sparse samples is a significant technological challenge.In this thesis, we mainly consider the problem of dense depth data reconstruction from a subset of samples. We present computationally efficient methods to estimate dense depth maps from sparse measurements, and we further extend the work to dense depth video estimation. Working on single depth image, we have three main contributions: First, we provide empirical evidence that depth maps can be encoded much more sparsely than natural images by using common dictionaries such as wavelets and contourlets, and show that disparity maps can be sparsely represented by a combined wavelet and contourlet dictionary. Second, we propose a subgradient algorithm for dense depth image reconstruction, and propose an alternating direction methods of multipliers (ADMM) algorithm with a multi-scale warm start procedure to further speed up the convergence. Third, we propose a two-stage randomized sampling scheme to optimally choose the sampling locations, thus maximizing the reconstruction performance for a given sampling budget. Experimental results show that the proposed methods produce high quality dense depth estimates, and are robust to noisy measurements.For dealing with depth video sequences, a framework for depth video reconstruction from a subset of samples is proposed. By redefining classical dense depth estimation into two individual problems, sensing and synthesis, we propose a motion compensation assisted sampling (MCAS) scheme and a spatio-temporal depth reconstruction (STDR) algorithm for reconstructing depth video sequences from a subset of samples. Using the 3-dimensional extensible dictionary, 3D-DWT, and applying alternating direction method of multiplier technique, the proposed STDR algorithm possesses scability for temporal volume and efficiency for processing large scale depth data. Exploiting the temporal information and corresponding RGB images, the proposed MCAS scheme achieves an efficient 1-Stage sampling. Experimental results show that the proposed depth reconstruction framework outperforms the existing methods and is competitive comparing to our previous work on sampling single depth image, which requires a pilot signal in the 2-Stage sampling scheme. Finally, to estimate missing reliable depth samples from varying input sources, we present an inference approach using geometrical and color similarities. Applications for depth video super resolution from uniform-grid subsampled data and dense disparity video estimation from a subset of reliable samples are presented.		Lee-Kang Liu	2015			computer vision;mathematical optimization;computer science;theoretical computer science	Vision	59.58146448891922	-56.176664356610374	66009
46b91f73aec0e10168ed3e7e6e4437cab1d0d7a4	a zero-variance-based sampling scheme for monte carlo subsurface scattering	simulation;gravity;pre vis	Figure 1: Our Dwivedi-modified sampling is driven by adjoint importance solutions for semi-infinite, homogeneous medium with a flat boundary. Thus, its application to general curved geometry can lead to occasional high sample weights, or fireflies (see (e) around the nose) because the estimated importance of each path was not accurately predicted. We mitigate this problem by using MIS at each transition to combine classical sampling and the Dwivedi sampling. Note more fireflies near the nose and curved areas and their reduction as MIS mixes the classical and Dwivedi methods. Also note how the render time changes. While the use of the classical sampling is essential to avoid the fireflies for the curved regions, for flat regions like the cheek the pure Dwivedi walk is ideal and mixing in the classical sampling actually adds some noise. To get the best performance, the mixing weights could be driven by local curvature. (All images were rendered using 25 samples per pixel, uniform white illumination, a single-scattering albedo of 0.943 for all wavelengths, and index-matched smooth boundaries.)	index-matching material;monte carlo method;pixel;sampling (signal processing);semiconductor industry;subsurface scattering	Jaroslav Krivánek;Eugene d'Eon	2014		10.1145/2614106.2614138	gravity;computer science	ML	64.11992091641943	-53.73206304787323	66014
d18ca96bcdc87c4149eb29b19cf889a2b80dd78c	using independent component analysis and binocular combination for stereoscopic image quality assessment	image feature similarity;stereoscopic image quality assessment;local luminance consistency;independent component analysis;binocular combination	In this paper, a full reference stereoscopic image quality assessment (FR-SIQA) method is proposed based on independent component analysis (ICA) and binocular combination. Image features that reflect the responds of simple cells in the cortex are extracted by ICA-based algorithm. Both image feature similarity (IFS) and local luminance consistency (LLC) are calculated to measure the structure and brightness distortions, respectively. To simulate the binocular fusion properties, the energy of image features and the global relative luminance information are selected as the basic of binocular combination to fuse the right-left IFS and LLC into a final index. Experimental results demonstrate that the proposed algorithm achieves high consistency with subjective assessment on two public available 3D image quality assessment databases.	algorithm;binocular vision;database;distortion;feature (computer vision);image quality;independent computing architecture;independent component analysis;simulation;stereoscopy	Xianqiu Geng;Liquan Shen;Ping An;Zhi Liu	2016	2016 Visual Communications and Image Processing (VCIP)	10.1109/VCIP.2016.7805534	independent component analysis;computer vision;computer science;machine learning;pattern recognition;mathematics	Vision	61.531390492568725	-65.60117440085516	66028
6cf955d42d4a0ce61317ce4fe3a6b20fc65d9c34	the 2-looks tops mode: enhanced sensitivity to ground displacement in azimuth direction with burst-mode sar systems. demonstration with terrasar-x		The Terrain Observation by Progressive Scans (TOPS) SAR acquisition mode achieves wide coverage area by employing subapertures. This way multiple subswaths can be acquired. It overcomes the problems of scalloping and azimuth-varying ambiguities inherent to the ScanSAR mode by introducing a steering of the beam in the along-track direction. The drawback is that, due to the burst operation mode, the azimuth resolution is strongly worsened with respect to the conventional StripMap mode. This reduces the performance on the retrieval of the ground displacement in the azimuth direction. In this contribution we provide an update on the last developments with our proposed 2-looks TOPS mode. This mode has been devised to mitigate the degraded sensitivity on the retrieval of ground deformation azimuth shifts of 1-look TOPS acquisitions. We will present the last improvements to the mode as well as updated results with time-series of experimental TerraSAR-X data.	ct scan;displacement mapping;tops;time series	Nestor Yague-Martinez;Pau Prats;Steffen Wollstadt	2018	IGARSS 2018 - 2018 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2018.8518954	terrain;computer vision;remote sensing;artificial intelligence;burst mode (photography);azimuth;computer science;beam (structure);synthetic aperture radar;tops;mode (statistics)	Robotics	76.25371704148617	-67.22959879806254	66031
55b9b1aa8cf4afa6e78fc1a7f2873b7d000a0618	seagle: sparsity-driven image reconstruction under multiple scattering		Multiple scattering of an electromagnetic wave as it passes through an object is a fundamental problem that limits the performance of current imaging systems. In this paper, we describe a new technique—called Series Expansion with Accelerated Gradient Descent on the Lippmann–Schwinger Equation—for robust imaging under multiple scattering based on a combination of an iterative forward model and a total variation regularizer. The proposed method can account for multiple scattering, which makes it advantageous in applications where single scattering approximations are inaccurate. Specifically, the method relies on a series expansion of the scattered wave with an accelerated-gradient method. This expansion guarantees the convergence of the forward model even for strongly scattering objects. One of our key insights is that it is possible to obtain an explicit formula for computing the gradient of an iterative forward model with respect to the unknown object, thus enabling fast image reconstruction with the state-of-the-art fast iterative shrinkage/thresholding algorithm. The proposed method is validated on diffraction tomography, where complex electric field is captured at different illumination angles.	algorithm;approximation;ct scan;gradient descent;gradient method;iterative method;iterative reconstruction;series expansion;sparse matrix;thresholding (image processing);tomography	Hsiou-Yuan Liu;Dehong Liu;Hassan Mansour;Petros T. Boufounos;Laura Waller;Ulugbek S. Kamilov	2018	IEEE Transactions on Computational Imaging	10.1109/TCI.2017.2764461	iterative reconstruction;computer vision;mathematics;mathematical optimization;artificial intelligence;thresholding;permittivity;tomography;diffraction tomography;scattering;gradient descent;series expansion	Vision	56.930963317870784	-74.75992761818803	66104
09e90ade4175bcb11c51a24d0110004703f10db2	smos l1 processor prototype: from digital counts to brightness temperatures	software;brightness temperature;processing;remote sensing geophysical signal processing geophysical techniques microwave measurement radiometry;in orbit calibration;prototypes brightness temperature calibration software prototyping instruments software algorithms image reconstruction data processing earth computer architecture;data processing;function block;earth fixed grid;radiometry;processing units;fourier components;geophysical signal processing;smos operational chain;microwave measurement;algorithms smos l1 processing software;remote sensing;smos l1 processor;geolocation algorithm;miras data;digital counts;smos;algorithms;earth fixed grid smos l1 processor digital counts brightness temperature data processing smos operational chain processing units miras data in orbit calibration fourier components geolocation algorithm;reconstruction algorithm;geophysical techniques	L1 processing of SMOS data will transform MIRAS instrument raw outputs into geolocated Brightness Temperatures, providing observation angles and additional parameters for the L2 Processor. The objectives of the L1 processor prototype (L1PP) activities were the definition of the product types and contents, the definition of the data processing models and the implementation and validation of the baseline processing algorithms. The L1 prototype is intended to be used in studies on the feasibility of the algorithms as well as on the advantages/disadvantages of other relevant proposed algorithms before they are taken to the SMOS operational chain. This paper will begin by presenting a very high level description of the L1 processing strategy and functional blocks of the processor (called processing units). A brief definition of the three L1 products types (L1a, L1b and L1c) will be presented, together with data-driven approach selected for the processor. The main focus will be on three aspects of the processing: the practical approach taken for the calibration of MIRAS data, implementing the in-orbit calibration Plan; the reconstruction algorithms chosen and their implementation, converting Calibrated Visibilities into Brightness Temperature Fourier components; and the geolocation algorithm, computing brightness temperatures over an Earth fixed grid along with observation angles, pixel size and accuracy.	algorithm;baseline (configuration management);central processing unit;geolocation;graphical user interface;high-level programming language;microwave imaging radiometer with aperture synthesis;pixel;prototype;simulation	Antonio Gutierrez;José Barbosa;Nuno Almeida;Nuno Catarino;Jose Freitas;Marco Ventura;José Reis	2007	2007 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2007.4423631	computer vision;radiometry;data processing;computer science;processing;brightness temperature;optics;physics;quantum mechanics;remote sensing	Arch	78.32179512862605	-63.74090708305188	66111
a542a886502832374dcf055923872cc8ff812c96	evaluating sar polarization modes at l-band for forest classification purposes in eastern amazon, brazil	successional forest;eastern amazon;polarization modes;svm;secondary forest;alos palsar	Single, interferometric dual, and quad-polarization mode data were evaluated for the characterization and classification of seven land use classes in an area with shifting cultivation practices located in the Eastern Amazon (Brazil). The Advanced Land-Observing Satellite (ALOS) Phased Array L-band Synthetic Aperture Radar (PALSAR) data were acquired during a six month interval. A clear-sky Landsat-5/TM image acquired at the same period was used as additional ground reference and as ancillary input data in the classification scheme. We evaluated backscattering intensity, polarimetric features, interferometric coherence and texture parameters for classification purposes using support vector machines (SVM) and feature selection. Results showed that the forest classes were characterized by low temporal backscattering intensity variability, low coherence and high entropy. Quad polarization mode performed better than dual and single polarizations but overall accuracies remain low and were affected by precipitation events on the date and prior SAR date acquisition. Misclassifications were reduced by integrating Landsat data and an overall accuracy of 85% was attained. The integration of Landsat to both quad and dual polarization modes showed similarity at the 5% significance level. SVM was not affected by SAR dimensionality and feature selection technique reveals that co-polarized channels as well as SAR derived parameters such as Alpha-Entropy decomposition were important ranked features after Landsat’ near-infrared and green bands. We show that in absence of Landsat data, polarimetric features extracted from quad-polarization L-band increase classification accuracies when compared to single and dual polarization alone. We argue that the joint analysis of SAR and their derived parameters with optical data performs even better and thus encourage the further development of joint techniques under the Reducing Emissions from Deforestation and Degradation (REDD) mechanism.	l band;polarization (waves)	Veraldo Liesenberg;Richard Gloaguen	2013	Int. J. Applied Earth Observation and Geoinformation	10.1016/j.jag.2012.08.016	support vector machine;geography;computer science;machine learning;ecology;cartography;remote sensing;secondary forest	Logic	80.28499211905228	-57.98823078599783	66156
7900658061538a2fcc9647f6c5eb38d38c46411d	break ames room illusion: depth from general single images	small blur estimation;single image depth;out of focus;depth from defocus	Photos compress 3D visual data to 2D. However, it is still possible to infer depth information even without sophisticated object learning. We propose a solution based on small-scale defocus blur inherent in optical lens and tackle the estimation problem by proposing a non-parametric matching scheme for natural images. It incorporates a matching prior with our newly constructed edgelet dataset using a non-local scheme, and includes semantic depth order cues for physically based inference. Several applications are enabled on natural images, including geometry based rendering and editing.	2d computer graphics;autostereogram;gaussian blur;rendering (computer graphics)	Jianping Shi;Xin Tao;Li Xu;Jiaya Jia	2015	ACM Trans. Graph.	10.1145/2816795.2818136	computer vision;mathematics;optics;computer graphics (images)	Graphics	58.78662435906016	-52.41002288212671	66192
d7c3929529b9378d43785f2c97cb4830c4ec2039	stereo matching with space-constrained cost aggregation and segmentation-based disparity refinement	image segmentation;computer vision technology	Stereo matching is a fundamental topic in computer vision. Usually, stereo matching is mainly composed of four stages: cost computation, cost aggregation, disparity optimization and disparity refinement. In this paper, we propose a novel stereo matching method with space-constrained cost aggregation and segmentation-based disparity refinement. Stateof-the-art methods are used for cost aggregation and disparity optimization stages. Three technical contributions are given in this paper. First, applying space-constrained cross-region in cost aggregation stage; second, utilizing both color and disparity information in image segmentation; third, using image segmentation and occlusion region detection to aid disparity refinement. The performance of our platform ranks second in the Middlebury evaluation.	binocular disparity;computation;computer stereo vision;computer vision;image segmentation;mathematical optimization;refinement (computing)	Yi Peng;Ge Li;Ronggang Wang;Wenmin Wang	2015		10.1117/12.2083741	computer stereo vision;computer vision;simulation;computer science;image segmentation;scale-space segmentation;physics;computer graphics (images)	Vision	55.8556612222517	-56.178907957037765	66200
8c3eacc0918d8e0c06cc79d9c0e69260dd737140	shadow map filtering with gaussian shadow maps	shadow mapping;filtering;cumulative distribution function;anti aliasing;shadows;real time;gaussian;computer graphic;statistical analysis;real time application	"""Shadow mapping is a technique, widely used in computer graphics, for efficiently calculating shadows in real-time applications. However, shadows created with this technique can not be filtered as regular textures, causing severe aliasing. To solve this problem, several techniques based on statistical analysis, including variance shadow maps and exponential shadow maps, have been introduced by other authors in the past. However these techniques introduce different kinds of """"light leaking"""" artifacts, which are clearly visible in moderately complex scenes. In this paper we propose a new statistical filtering method which approximates the cumulative distribution function (CDF) of depths by a Gaussian CDF instead of bounding it with Chebyshev Inequality. This approximation significantly reduces """"light bleeding"""" artifacts, keeping the same performance and spatial cost as the original variance shadow maps."""	avt statistical filtering algorithm;aliasing;approximation;artifact (software development);computer graphics;map;real-time locating system;shadow copy;shadow mapping;texture mapping;time complexity	Jesús Gumbau;Mateu Sbert;László Szirmay-Kalos;Miguel Chover;Carlos González	2011		10.1145/2087756.2087766	filter;computer vision;shadow;cumulative distribution function;computer science;shadow mapping;gaussian;statistics;computer graphics (images)	Graphics	64.64154829419067	-53.407984608042355	66307
c7abc9e868a51540b1c11906a9b44485e0e54e4a	application of self-organizing feature map clustering and ordination to the analysis of subalpine meadows in north china	vegetation mapping;environmental factors;biology computing;vegetation environment relation mountain meadow quantitative analysis sofm artificial neural network;pattern clustering;wutai mountains;self organizing feature map clustering;subalpine meadows;biological system modeling;plant ecology;ecology;vegetation;mathematic branch discipline;self organizing feature map ordination;artificial neural networks;vegetation environment relation;self organising feature maps;north china;self organized feature map;quantitative analysis;sofm artificial neural network;vegetation biology computing botany ecology pattern clustering self organising feature maps;communities soil environmental factors vegetation mapping artificial neural networks biological system modeling vegetation;communities;mountain meadow;meadow vegetation self organizing feature map clustering subalpine meadows north china artificial neural network theory mathematic branch discipline plant ecology wutai mountains self organizing feature map ordination;artificial neural network theory;soil;botany;meadow vegetation;artificial neural network	Artificial neural network theory is a newer mathematic branch discipline. The SOFM clustering and ordination were just introduced to plant ecology recently. In this article, these two methods were applied to study subalpine meadows in the Wutai Mountains, North China. The results showed that SOFM clustering classified 78 quadrats into 8 community types, basically representing the associations of the high and cold meadows in the Wutai Mountains. This classification was meaningful in ecology. The SOFM ordination reflected ecological gradients obviously, indicating that altitude was the most important factor in affecting the growth and distribution of the meadow vegetation, and slope and aspect also had certain roles. SOFM clustering and ordination methods performed well in this application, and this study showed that the combination of these two methods was better in ecological analysis. The conservation of meadows in the Wutai Mountains needs further to strengthened.	artificial neural network;cluster analysis;ecology;gradient;meadow;network theory;organizing (structure);self-organizing map	Jin-Tun Zhang;Min Li	2010	2010 Sixth International Conference on Natural Computation	10.1109/ICNC.2010.5583714	geography;forestry;ecology	Robotics	82.72896653353696	-54.81901178919786	66384
ee2f052e16bda55a44ab86856195629ef4274a67	measurement of wind speed and direction using multifrequency hf radar	remote sensing by radar wind atmospheric boundary layer atmospheric techniques meteorological radar;meteorological radar;partial least square;data collection;velocity measurement wind speed hafnium radar measurements sea measurements sea surface wavelength measurement current measurement ocean waves resonance;remote sensing by radar;standard error of prediction;4 8 to 22 mhz north pacific united states usa california marine atmosphere measurement technique boundary layer surface layer wind speed wind direction ad 2000 summer santa cruz moss landing hf radar multifrequency radar radar remote sensing coastal monterey bay;wind speed;surface current;atmospheric techniques;ocean wave;wind;monterey bay;atmospheric boundary layer	HF radar has become an important tool for mapping surface currents in the coastal ocean. It is well known that HF radars are capable of measuring wind direction by using the relative strength of the echoes from the approaching and receding ocean waves at the Bragg resonant wavelengths. Here we examine the ability of multifrequency HF radar to measure wind speed as well as direction. In this study we use data collected over Monterey Bay, California in the late summer of 2000. At that time there were two buoys in the radar's observational area that were capable of measuring wind speed and direction one near the Bay mouth and one nearer the shore. We investigate the relationship between the wind speed and the near surface currents and Bragg line ratios as measured by two multifrequency HF radars near Santa Cruz and Moss Landing, California. These radars operated at 4.8, 6.8, 13.4 and 21.8 MHz, measuring currents at effective depths of 2.5, 1.8, 0.9 and 0.6 m respectively. The method of partial least squares is used with results for speed of a standard error of prediction (SEP) of /spl ap/ 1m/s, a bias of /spl ap/ 0.5 m/s and an R/sup 2/ of /spl ap/ 0.8. For direction the SEP /spl ap/ 40/spl deg/, the bias /spl ap/ 4/spl deg/ and R/sup 2/ of /spl ap/ 0.45. These preliminary results suggest that wind speed as well as direction can be estimated from multifrequency HF radar data.	helicon filter;radar	John F. Vesecky;Jessica A. Drake;Calvin C. Teague;Frank L. Ludwig;K W Davidson;J. D. Paduan	2002		10.1109/IGARSS.2002.1026293	wind speed;meteorology;wind wave;atmospheric sciences;geology;wind shear;ocean current;wave radar;physics;radar;remote sensing;wind;planetary boundary layer;data collection	HCI	82.61041097801024	-63.24570091951716	66392
f65ae8b5ebef7674b1c47f887697d316b5c4f78b	wavpy: a gnss-r open source software library for data analysis and simulation		Due to the launch of a number of dedicated GNSS-R satellite missions during the last years, there is a potential raise of research interest in this field. This paper presents an analysis and simulation tool for the GNSS-R community: wavpy. More than just a simple waveform simulator, this library provides a set of object-oriented classes dedicated to each of the different elements that characterize a GNSS-R scenario. Then, the user can focus on just a particular piece of analysis or, by exploiting their combined synergies, to perform a more comprehensive simulation exercise.	library (computing);open-source software;satellite navigation;simulation;synergy;waveform	Fran Fabra;Estel Cardellach;Weiqiang Li;Antonio Rius	2017	2017 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)	10.1109/IGARSS.2017.8127908	remote sensing;simulation;object-oriented modeling;global positioning system;software;satellite;computer science;gnss applications;waveform	Embedded	79.63964724162199	-64.34302243470857	66462
26ed199bc04dc84d698e7dd361f1953c6c22e8eb	remotely sensed image restoration using partial differential equations and watershed transformation	image segmentation;image restoration;partial differential equations;remote sensing;denoising;radiometric corrections	This paper proposes a novel approach for remotely sensed image restoration. The main goal of this study is to mitigate two most well-known types of noises from remote sensing images while their important details such as edges are preserved. To this end, a novel method based on partial differential equations is proposed. The parameters used in the proposed algorithm are adaptively set regarding the type of noise and the texture of noisy datasets. Moreover, we propose to apply a segmentation pre-processing step based on Watershed transformation to localize the denoising process. The performance of the restoration techniques is measured using PSNR criterion. For further assessment, we also feed the original/noisy/denoised images into SVM classifier and explore the results.	akaike information criterion;algorithm;circuit restoration;data structure;embedded system;image restoration;noise reduction;peak signal-to-noise ratio;performance;preprocessor;support vector machine;watershed (image processing)	Avishan Nazari;Amin Zehtabian;Marco Gribaudo;Hassan Ghassemian	2014		10.1117/12.2181817	image restoration;computer vision;geography;machine learning;remote sensing	Vision	57.42330518678048	-67.05420090022433	66576
2264eb6fe5ebff9dedf688e22afa588c14f1025b	landslide monitoring with spotlight terrasar-x data	geophysical image processing;azimuth;spotlight;terrain factors;vegetated areas;landslide;image resolution;variable dynamics;gb sar;man made structures;radar based remote sensing techniques;terrasar x;high resolution spotlight mode;persistent scatters;revisit time;remote sensing by radar;terrain mapping geomorphology geophysical image processing remote sensing by radar;doppler effect;geomorphology;monitoring;natural targets;spotlight terrasar x data;remote sensing;conference report;gb sar landslide dinsar spotlight terrasar x;spotlight terrasar x data radar based remote sensing techniques high mountain landslides vegetated areas coherent scatterers high resolution data persistent scatters natural targets man made structures high resolution spotlight mode x band carrier revisit time landslide trend variable dynamics landslide monitoring;landslide monitoring;landslide trend;dinsar;terrain mapping;high resolution data;high mountain landslides;terrain factors azimuth synthetic aperture radar monitoring doppler effect image resolution remote sensing;x band carrier;synthetic aperture radar;coherent scatterers	This paper aims to demonstrate that radar-based remote sensing techniques can be as effective as the conventional geotechnical ones for the detection and monitoring of well suited areas. Many of the high mountain landslides are vegetated areas that decorrelate faster at X-band. As in these scenarios the number of coherent scatterers is low and, in addition, the area of interest is usually small, the processing can be benefited of the usage of high-resolution data. This will maximize the chances of detecting persistent scatters coming from both natural targets and man-made structures. The high resolution Spotlight mode of TerraSAR-X is thus the perfect choice as it offers a fine resolution. On the other hand, its 11 days of revisit time and X-band carrier allows the monitoring of small variations in the landslide trend and deal with its variable dynamics.	coherence (physics);dbpedia;image resolution;radar;sensor	Rubén Iglésias;Daniel Monells;Giuseppe Centolanza;Jordi J. Mallorquí;Xavier Fàbregas;Albert Aguasca	2012	2012 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2012.6351300	synthetic aperture radar;image resolution;doppler effect;hydrology;landslide;azimuth;geotechnical engineering;physics;remote sensing	Arch	79.60834926619472	-64.1461629689911	66641
b085cc4ec61ca9816441483f8ca4579c8f5cc50c	gray-preserving color correction without exposure value information	presentation ligne appelante;traitement signal;optimisation;video techniques;video surveillance;4230;capteur image cmos;televigilancia;sensors;availability;etude experimentale;fotografia digital;presentation de la ligne apellante;0130c;identificacion de llamada entrante;4279p;photographie numerique;technique video;digital camera;optimization method;device independence;metodo optimizacion;cmos image sensors;digital cameras;digital photography;remote supervision;haute resolution;low power;matrices;telesurveillance;signal processing;camera phone;transformation lineaire;methode optimisation;reference data;cmos sensors;linear transformation;color correction;optimization;maquina fotografica;high resolution imager;imagen color;calling line identification presentation;disponibilite;image couleur;appareil photographique;cameras;high resolution methods;transformacion lineal;color image;camera	Digital cameras are widely used in many applications, such as digital still cameras, camcorders, camera phones, and video surveillance. Advances in large resolution CCD/CMOS sensors coupled with the availability of low-power image signal processors have led to the development of digital cameras with both high resolution image and short visual clip capabilities. The red, green, or blue color values obtained from a camera sensor are device-dependent. Thus there is a need to characterize these values in a device-independent fashion and provide a color correction. For simplicity, common methods presume a linear transformation to perform the color conversion. The problem translates to finding the transformation matrix and the offset vector. One well known approach uses a white-preserving constraint in the optimization. This approach requires that source data and reference data have the same exposure values. However, source data and reference data usually have different exposure values, and exposure information is either unavailable or inaccurate. We propose a new method that provides color conversion by linear transformation optimization with gray preservation. Our method allows for differing exposures between images from the target sensor and the color reference. Experiments show that images resulted from our method look more colorful than those from previous methods.© (2008) COPYRIGHT SPIE--The International Society for Optical Engineering. Downloading of the abstract is permitted for personal use only.		Jianping Zhou	2008		10.1117/12.760807	computer vision;availability;digital photography;color image;telecommunications;reference data;computer science;sensor;signal processing;linear map;camera phone;matrix;computer graphics (images)	HCI	61.55315984998144	-58.32911942876882	66677
6784e91f08dc00525bc351237471c4d74813f4d0	incoherent detection of man-made objects obscured by foliage in forest area		The paper introduces a new likelihood ratio test (LRT) for incoherent detection of man-made objects obscured by foliage in forest area. The test is performed to detect changes between a reference image and a surveillance image. The method is developed for change detection in high resolution Synthetic Aperture Radar (SAR). For simplicity and lack of more appropriate models, the new LRT is still based on simple and efficient models. If there is no man-made object, the statistical model for clutter and noise of two images will be a bivariate Rayleigh distribution. In contrary, a joint distribution of Rayleigh and uniform is used to model for target, clutter, and noise. The proposed LRT is evaluated using radar data acquired by CARABAS in northern Sweden. The probability of detection is up to 96% with much less than one false alarm per square kilometer.	algorithmic efficiency;aperture (software);bivariate data;clutter;computation;constant false alarm rate;image resolution;long-running transaction;preprocessor;radar;rayleigh–ritz method;space-time adaptive processing;statistical model	Mats I. Pettersson;Viet Thuy Vu;Natanael R. Gomes;Patrik B. G. Dammert;Hans Hellsten	2017	2017 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)	10.1109/IGARSS.2017.8127347	artificial intelligence;computer vision;joint probability distribution;computer science;radar;change detection;synthetic aperture radar;image resolution;clutter;likelihood-ratio test;rayleigh distribution	Vision	73.46478377478063	-64.57530504205549	66718
3c408db218093eed54982817b24c64e6caf6549a	high-resolution lidar-based depth mapping using bilateral filter	interpolation;laser radar;estimation;three dimensional displays;vehicles;cameras;spatial resolution	High resolution depth-maps, obtained by upsampling sparse range data from a 3D-LIDAR, find applications in many fields ranging from sensory perception to semantic segmentation and object detection. Upsampling is often based on combining data from a monocular camera to compensate the low-resolution of a LIDAR. This paper, on the other hand, introduces a novel framework to obtain dense depth-map solely from a single LIDAR point cloud; which is a research direction that has been barely explored. The formulation behind the proposed depth-mapping process relies on local spatial interpolation, using sliding-window (mask) technique, and on the Bilateral Filter (BF) where the variable of interest, the distance from the sensor, is considered in the interpolation problem. In particular, the BF is conveniently modified to perform depth-map upsampling such that the edges (foreground-background discontinuities) are better preserved by means of a proposed method which influences the range-based weighting term. Other methods for spatial upsampling are discussed, evaluated and compared in terms of different error measures. This paper also researches the role of the mask's size in the performance of the implemented methods. Quantitative and qualitative results from experiments on the KITTI Database, using LIDAR point clouds only, show very satisfactory performance of the approach introduced in this work.	bilateral filter;brainfuck;delaunay triangulation;experiment;foreground-background;high-resolution scheme;image resolution;investigative data warehouse;kriging;map;multivariate interpolation;object detection;outline of object recognition;point cloud;sparse matrix;upsampling	Cristiano Premebida;Luis Garrote;Alireza Asvadi;A. Pedro Ribeiro;Urbano Nunes	2016	2016 IEEE 19th International Conference on Intelligent Transportation Systems (ITSC)	10.1109/ITSC.2016.7795953	lidar;computer vision;estimation;image resolution;interpolation;statistics	Robotics	56.49531734988884	-56.98850922340699	66801
fe3999799be682988d916ef80e26b60d972ffc24	improvement on inverse distance weighted interpolation for ore reserve estimation	geological statistics;interpolation;irregular ellipsoid interpolation model;vein thin ore body;mining area;grade estimation model;visual simulation;ellipsoids;data mining;mining industry;interpolation ores estimation ellipsoids data mining three dimensional displays;inverse distance weighted method;estimation;ore reserve estimation;three dimensional displays;interpolation method;ores;inverse distance weighted interpolation;mining industry geophysical prospecting interpolation;mining area inverse distance weighted interpolation ore reserve estimation grade estimation model irregular ellipsoid interpolation model vein thin ore body geological statistics;estimation error;inverse distance weighted;irregular ellipsoid interpolation model geological statistics inverse distance weighted method interpolation;geophysical prospecting	In order to improve accuracy of estimation for ore reserves and average grade, it is important to select suitable interpolation method. Firstly, traditional inverse distance weighted method is analyzed and grade estimation model is improved. Specifically, irregular ellipsoid interpolation model is put forward, which is suitable for vein thin ore body or layerlike ore body, etc. The new model, based on regionalized variable theory of geological statistics, promotes the application of inverse distance weighted method by combining ore body occurrence elements with interpolation method Then, the method is applied in typical mining area, which verifies its effectiveness and feasibility. Contrast to traditional inverse distance weighted method and tessellation polygon method, its estimation error is smaller, which can provide data support for the construction of ore body model and 3dimension visualization simulation.	interpolation;regionalized variable theory;simulation	Zhongxue Li;Xin Li;Cuiping Li;Zhiguo Cao	2010	2010 Seventh International Conference on Fuzzy Systems and Knowledge Discovery	10.1109/FSKD.2010.5569390	mathematical optimization;estimation;inverse distance weighting;mining;interpolation;inverse quadratic interpolation;mathematics;ellipsoid;geometry;statistics	Robotics	75.82513760891882	-53.36644496422747	66810
c3c02f76b514bf08e6c8689675f531d173ef92fd	national bds augmentation service system (nbass) of china: progress and assessment		In this contribution, the processing strategies of real-time BeiDou System (BDS) precise orbits, clocks, and ionospheric corrections in the National BDS Augmentation Service System (NBASS) are briefly introduced. The Root Mean Square (RMS) of BDS predicted orbits are better than 10 cm in radial and cross-track components, and the accuracy of the BDS real-time clock is better than 0.5 ns for Inclined Geosynchronous Orbit (IGSO) and Mid Earth Orbit (MEO) satellites. The accuracy of BDS Geostationary Earth Orbit (GEO) orbits and clocks are worse than the IGSO and MEO satellites due to its poor geometry conditions. The real-time ionospheric correction is evaluated by cross-validation, and the average accuracy in the vertical direction is about 4 TECU. With these real-time corrections, the overall single and dual-frequency kinematic precise point positioning (PPP) performance in China are evaluated in terms of positioning accuracy at the 95% confidence level and convergence time. The BDS PPP positioning accuracy shows significant regional characteristics due to the geometry distribution of BDS satellites and the accuracy of ionospheric model in different regions. The BDS dual-frequency PPP positioning accuracy in high-latitude and western fringe region is about 0.5 m and 1.0 m in the horizontal and vertical component, respectively, while the horizontal accuracy is better than 0.2 m and the vertical accuracy is better than 0.3 m in the midlands. The convergence time of the BDS PPP is much longer than the GPS PPP and it needs more than 60 min to achieve the accuracy better than 10 cm in both horizontal and vertical directions for dual-frequency PPP. Similar with dual-frequency PPP, the positioning accuracy of the BDS single-frequency PPP in the fringe region is worse than other regions. The positioning in the midlands can achieve 0.5 m in horizontal component and 1.0 m in the vertical component. In addition, when GPS and BDS are combined, the positioning performance of both single-frequency and dual-frequency PPP can be greatly improved.	beidou navigation satellite system;cross-validation (statistics);geosynchronous orbit;global positioning system;maxima and minima;methods of computing square roots;point-to-point protocol;precise point positioning;radial (radio);real-time clock;single-frequency network	Chuang Shi;Fu Zheng;Yidong Lou;Shengfeng Gu;Weixing Zhang;Xiaolei Dai;Xianjie Li;Hailin Guo;Xiaopeng Gong	2017	Remote Sensing	10.3390/rs9080837	remote sensing;earth's orbit;geology;geodesy;global positioning system;vertical direction;geostationary orbit;horizontal and vertical;geosynchronous orbit;precise point positioning;root mean square	Mobile	82.79867540419957	-61.76759259143158	66841
d6ee1588b01c68752dcc62490c982e56a6dae22d	fast l1 smoothing splines with an application to kinect depth data	minimisation;splines mathematics discrete cosine transforms filtering theory functional analysis image reconstruction iterative methods minimisation smoothing methods;splines mathematics;iterative methods;grid data splines robust fitting split bregman;smoothing methods;splines mathematics robustness smoothing methods discrete cosine transforms noise optical imaging convergence;functional analysis;discrete cosine transforms;image reconstruction;range data smoothing fast l1 smoothing splines kinect depth data fitting term regularization term functional minimization l1 norm split bregman iteration dct based filter range data impainting;filtering theory	Splines are a popular and attractive way of smoothing noisy data. Computing splines involves minimizing a functional which is a linear combination of a fitting term and a regularization term. The former is classically computed using a (sometimes weighted) L2 norm while the latter ensures smoothness. In this work we propose to replace the L2 norm in the fitting term with an L1 norm, leading to automatic robustness to outliers. To solve the resulting minimization problem we propose an extremely simple and efficient numerical scheme based on split-Bregman iteration and a DCT-based filter. The algorithm is applied to the problem of smoothing and impainting range data, where high-quality results are obtained in short processing times.	algorithm;bregman divergence;discrete cosine transform;iteration;kinect;numerical analysis;signal-to-noise ratio;smoothing spline;spline (mathematics);taxicab geometry	Mariano Tepper;Guillermo Sapiro	2013	2013 IEEE International Conference on Image Processing	10.1109/ICIP.2013.6738104	iterative reconstruction;functional analysis;minimisation;econometrics;mathematical optimization;mathematics;iterative method;statistics;smoothing;box spline	Vision	56.80429975445876	-72.54885205444165	66858
06e90adc53d9787a5d761076ea53ec3d4f5d12e9	blind assessment of wavelet-compressed images based on subband statistics of natural scenes	subbands statistical;sufficient prediction monotonicity high spearman correlation coefficient sccs;blind image quality assessment;wavelet compressed image;natural scenes	This paper presents a no-reference image quality assessment metric that makes use of the wavelet subband statistics to evaluate the levels of distortions of wavelet-compressed images. The work is based on the fact that for distorted images the correlation coefficients of the adjacent scale subbands change proportionally with respect to the distortion of a compressed image. Subband similarity is used in this work to measure the correlations of the adjacent scale subbands of the same wavelet orientations. The higher the image quality is (i.e., less distortion), the greater the cosine similarity coefficient will be. Statistical analysis is applied to analyze the performance of the metric by evaluating the relationship between the human subjective assessment scores and the subband cosine similarities. Experimental results show that the proposed blind method for the quality assessment of wavelet-compressed images has sufficient prediction accuracy (high Pearson Correlation Coefficient, PCCs), sufficient prediction monotonicity (high Spearman Correlation Coefficient SCCs) and sufficient prediction consistency (low outlier ratios) and less running time. It is simple to calculate, has a clear physical meaning, and has a stable performance for the four image databases on which the method was tested. Blind Assessment of WaveletCompressed Images Based On Subband Statistics of Natural Scenes	coefficient;cosine similarity;database;distortion;image quality;time complexity;wavelet	Ying-Chun Guo;Gang Yan;Cui-Hong Xue;Yang Yu	2014	IJAPUC	10.4018/ijapuc.2014010103	computer vision;pattern recognition	AI	62.05837465009398	-64.94281473128952	66951
0e5e84374102bb965a04203d5c9964a9cfea4119	when patches match -- a statistical view on matching under illumination variation	elektroteknik och elektronik;electrical engineering electronic engineering information engineering;image matching affine transforms;matching scheme illumination variation image patches unknown affine photometric transformations fully symmetric matching measure measurement errors eigen system problem estimated mean value offset;vectors hidden markov models correlation lighting eigenvalues and eigenfunctions standards displacement measurement	We discuss matching measures (scores and residuals) for comparing image patches under unknown affine photometric (=intensity) transformations. In contrast to existing methods, we derive a fully symmetric matching measure which reflects the fact that both copies of the signal are affected by measurement errors ('noise'), not only one. As it turns out, this evolves into an Eigen system problem, however a simple direct solution for all entities of interest can be given. We strongly advocate for constraining the estimated gain ratio and the estimated mean value offset to realistic ranges, thus preventing the matching scheme from locking into unrealistic correspondences.	architecture design and assessment system;eigen (c++ library);entity;global illumination;illumination (image);lock (computer science);matching (graph theory);motion estimation;neural correlates of consciousness;phase correlation;utility functions on indivisible goods;whole earth 'lectronic link	Rudolf Mester;Christian Conrad	2014	2014 22nd International Conference on Pattern Recognition	10.1109/ICPR.2014.747	computer vision;mathematical optimization;mathematics;geometry;statistics	Vision	53.83194105653769	-55.667614135984785	66962
c2247dcaca19b5124f1c77abd8012601a7bc21d7	frame rate up-conversion based on motion-region segmentation	feature detection;vector filtering;k mean clustering;frame rate up conversion;motion region segmentation	The key problem of frame rate up-conversion (FRUC) is to obtain true motion vectors (MV), especially for the motion boundaries. In this paper, we propose a novel FRUC algorithm based on motion-region segmentation. According to region's temporal consistency, motion-regions are determined by a categorization of detected feature points' true MVs. Then, constrained by MV's spatial smoothness within a region, true motions are propagated to the entire frame. This motion-region segmentation based method achieves truthful motion vector field and preferable interpolated frames. Experiments show that comparing to the state-of-art methods, the proposed algorithm produces videos with better quality in terms of objective and subjective evaluation.	algorithm;categorization;cluster analysis;experiment;interpolation;software propagation	Wenbo Bao;Xiaoyun Zhang;Zhiyong Gao;Li Chen	2016	2016 Visual Communications and Image Processing (VCIP)	10.1109/VCIP.2016.7805437	computer vision;mathematical optimization;computer science;machine learning;pattern recognition;feature detection;mathematics;scale-space segmentation;k-means clustering	Vision	54.429918683030735	-59.0316550133351	66985
c72c96e1db93224f7aef9df4695df45adbbc4a97	a spatial variant approach for vergence control in complex scenes	vision system;high resolution;log polar transformation;log polar mapping;real time;disparity estimation;low resolution;vergence control;robot vision;stereo matching;binocular vision;multi resolution;image pyramid;normalized cross correlation	The flexibility in primate vision that utilizes active binocular vision is unparalleled even with modern fixed-stereo-based vision systems. However to follow the path of active binocular vision, the difficulty of attaining fixative capabilities is of primary concern. This paper presents a binocular vergence model that utilizes the retino-cortical log polar mapping in the primate vision system. Individual images of the binocular pair were converted to multi-resolution pyramids bearing a coarse-to-fine architecture (low resolution to high resolution) and disparity estimation on these pyramidal resolutions was performed using normalized cross correlation on the log polar images. The model was deployed on an actual binocular vergence system with independent pan-tilt controls for each camera and the system was able to robustly verge on objects even in cluttered environment with real time performance. This paper even presents the experimental results of the system functioning in unbalanced contrast exposures between the two cameras. The results proved favorable for real world robotic vision applications where noise is prevalent. The proposed vergence control model was also compared with a standard window based Cartesian stereo matching method and showed superior performance.	vergence	Xuejie Zhang;Alex Leng Phuan Tay	2011	Image Vision Comput.	10.1016/j.imavis.2010.08.005	computer stereo vision;binocular disparity;computer vision;image resolution;machine vision;computer science;computer graphics (images)	Vision	61.80641114441249	-55.669544248525575	67002
bc06133c10a1df657b0da418796575c6391ff6dd	development of a scale independent approach for landscape pattern metrics using fourier vector analysis of satellite images	image processing environmental factors fourier transform pattern recognition correlation;vegetation mapping;environmental factors;fractals;time scale;kernel;image processing;fourier transform;landscape pattern;statistical independence;land use change;image analysis pattern analysis satellites image edge detection earth image processing fractals kernel scalability least squares methods;fractal dimension;landscape change;satellite observation;monitoring;pixel;vegetation mapping fourier transforms image processing pattern recognition terrain mapping;fourier transforms;least square;pattern recognition;system analysis;satellite image;earth observation;least squares analysis land cover land use change lcluc mapping landscape change observation hydrologic function ecological function fractal dimension pattern metrics kernel operation vegetation fourier vector analysis earth observing satellite dominance contagion image processing;terrain mapping;correlation;soil;land cover;environmental factor	Mapping land-cover land-use change (LCLUC) over regional and continental scales and long time scales can be accomplished using class maps derived from Earth observing satellites. Observations of landscape change can be related to processes like hydrologic or ecological function by employing image processing tools that produce landscape pattern metrics such as dominance, fractal dimension, and contagion. These landscape pattern metrics arise from local kernel operations that detect edges and gradients in class maps, and suffer from a lack of statistical independence and scalability. This paper describes an approach to generating landscape pattern metrics based on a Fourier system analysis of the entire class map or any subset of the class map such as a watershed. Three metric improvements are made. First, correlations between the metrics are removed. Second, image sourced statistical independence is abated. Third, the proposed metrics become, in a least squares sense, optimally scalable.	fractal dimension;gradient;image processing;köppen climate classification;least squares;map;scalability;system analysis;watershed (image processing)	Alvin Spivey;Anthony Vodacek	2008	IGARSS 2008 - 2008 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2008.4779689	fourier transform;computer vision;image processing;remote sensing	Robotics	72.96034959304755	-61.443783762773876	67033
27ffae3ae2f3377ca317a732bab67b3f53a998e1	repairing and inpainting damaged images using diffusion tensor		The Removing or repairing the imperfections of a di gital images or videos is a very active and attractive fi eld of research belonging to the image inpainting techniqu e. This later has a wide range of applications, such as rem oving scratches in old photographic image, removing text and logos or creating cartoon and artistic effects. In this paper, we propose an efficient method to repair a damaged image based on a non linear diffusion tensor. The idea is to track perfectly the local geometry of the damaged image a nd allowing diffusion only in the isophotes curves dir ection. To illustrate the effective performance of our meth od, we present some experimental results on test and real photographic color images.	algorithm;comment (computer programming);contour line;gradient;inpainting	Faouzi Benzarti;Hamid Amiri	2012	CoRR		computer vision;mathematics;computer graphics (images)	Vision	55.933365701401215	-60.829239190873786	67095
cb2b95e7a53372b3ed6c53f8be6c5598577741a6	unsupervised nonlinear unmixing of hyperspectral images using sparsity constrained probabilistic latent semantic analysis		Unsupervised spectral unmixing (i.e., endmember extraction and abundance estimation) of nonlinear mixture is a very challenging subject in hyperspectral image analysis. In this paper, we present a new interpretation of the reflectance mixture by normalizing the absolute reflectance value into a unit L1 norm vector, such that the spectral reading can be treated as a probability distribution. The abundance can then be interpreted as the possibility that a spectral distribution belongs to an endmember distribution. Both endmember extraction and abundance estimation can be handled by the proposed sparsity constrained probabilistic latent semantic analysis (SC-pLSA). Experimental results using both synthetic and real data as compared to other unmixing algorithms show apparent advantage of the proposed method.	algorithm;image analysis;nonlinear system;probabilistic latent semantic analysis;sparse matrix;synthetic intelligence;t-norm;taxicab geometry;unsupervised learning	Wei Wang;Hairong Qi	2013	2013 5th Workshop on Hyperspectral Image and Signal Processing: Evolution in Remote Sensing (WHISPERS)	10.1109/WHISPERS.2013.8080751	probability distribution;endmember;probabilistic logic;nonlinear system;abundance estimation;artificial intelligence;spectral power distribution;machine learning;hyperspectral imaging;probabilistic latent semantic analysis;mathematics;pattern recognition	ML	69.41584304152352	-65.62696611256503	67130
9091ea4a531bac068b9fb7d7d899b4565a88d542	flash shadow detection and removal in stereo photography	histograms;3d perception flash shadow detection stereo photography 3d stereo image removal algorithm flash lighting flash shadow problem subjective rating shadow relighting;cameras photography histograms image color analysis detection algorithms lighting clustering algorithms;detection algorithms;computer graphics;flash positioning in stereo photography;photography;stereo image processing computer graphics photography;image color analysis;flash shadow in stereo photography;flash shadow detection and removal;flash positioning in stereo photography flash shadow detection and removal flash shadow in stereo photography 3d perception of flash shadow;stereo image processing;clustering algorithms;lighting;3d perception of flash shadow;cameras	Shadows created by flash when taking stereo images adversely affect 3D perception when stereo images are merged into 3D images. This paper presents a shadow detection and removal algorithm for stereo images taken under flash lighting. This is the first attempt at addressing the flash shadow problem in stereo photography. A quantitative measure is introduced to evaluate the effectiveness of shadow detection and a subjective rating is done to evaluate the effectiveness of shadow relighting or removal for 3D perception. It is shown that the developed solution outperforms the previous solutions designed for single images.	adobe flash;algorithm;autostereogram;nam;stereoscopy	Sang-Jae Nam;Nasser Kehtarnavaz	2012	IEEE Transactions on Consumer Electronics	10.1109/TCE.2012.6227414	stereo camera;computer vision;computer science;photography;lighting;histogram;cluster analysis;computer graphics;computer graphics (images)	Vision	57.46733809790206	-59.40826838912964	67138
9a33268e30f5151db8aa1be4d6b467a6b0ff59c6	an improved denoising method based on wavelet transform for processing bases sequence images		In this article, we present an improved images denoising method for base sequence images. It is based on the multiscale analysis of the images resulting from the a trous wavelet transform decomposition. We define a new thresholding function and use it to improve the denoising performance of the isotropic undecimated wavelet transform (IUWT). The proposed method selects the best suitable wavelet function based on IUWT. The advantages of the new thresholding function are that it is more robust than previous thresholding function, and the convergence of function is more efficient. The experimental results indicate that the proposed method can obtain higher signal-to-noise ratio (SNR) and mean squared error ratio (MSE) than conventional wavelet thres- holding denoising methods.	noise reduction;wavelet transform	Ke Yan;Jin-Xing Liu;Yong Xu	2015		10.1007/978-3-319-22180-9_35	wavelet;computer vision;mathematical optimization;harmonic wavelet transform;second-generation wavelet transform;continuous wavelet transform;pattern recognition;cascade algorithm;mathematics;wavelet packet decomposition;stationary wavelet transform;discrete wavelet transform;lifting scheme;wavelet transform	Robotics	57.53868336597142	-67.84483684153228	67261
fe0933c25d552028f602743eaacab5d26bb1aef9	disaster monitoring by fully polarimetric sar data acquired with alos-palsar	polarimetric decomposition disaster monitoring fully polarimetric sar data alos palsar scattering power decomposition image synthetic aperture radar color images red green blue color coding double bounce power volume scattering power surface scattering power color brightness time series data set four component scattering power decomposition advanced land observing satellite phased array type l band sar volcanic activity snow accumulation landslides tsunami effect earthquake;time series;remote sensing by radar;phased array radar;scattering power decomposition advanced land observing satellite phased array type l band synthetic aperture radar alos palsar disaster monitoring polarimetric synthetic aperture radar polsar radar polarimetry scattering matrix;image colour analysis;radar polarimetry;radar imaging;disaster management polarimetric synthetic aperture radar matrix decomposition synthetic aperture radar surface topography image color analysis radar image coding remote sensing;time series disasters image colour analysis phased array radar radar imaging radar polarimetry remote sensing by radar spaceborne radar synthetic aperture radar;disasters;spaceborne radar;synthetic aperture radar	This paper presents scattering power decomposition images of fully polarimetric synthetic aperture radar (SAR) data for disaster monitoring. Utilization of fully polarimetric data can derive full color images with red-green-blue color coding, red for the double-bounce power, green for the volume scattering power, and blue for the surface scattering power, for which each color brightness corresponds to the magnitude. Since disaster events cause the changes of each scattering power, it becomes straightforward for everyone to recognize the changes of the color in the polarimetric decomposed images provided time series data sets are made available. After applying the four-component scattering power decomposition to fully polarimetric image data sets acquired with the Advanced Land Observing Satellite (ALOS) Phased-Array-type L-band SAR (PALSAR), several images are presented for natural disaster monitoring of volcanic activity, snow accumulation, landslides, and tsunami effects caused by great earthquakes. It is seen in the polarimetric decomposition images that the surface scattering power becomes predominant in most disaster areas compared to those in normal situations.	color;l band;phased array;polarimetry;synthetic data;time series;tree accumulation	Yoshio Yamaguchi	2012	Proceedings of the IEEE	10.1109/JPROC.2012.2195469	early-warning radar;phased array;continuous-wave radar;space-based radar;disaster;radar engineering details;synthetic aperture radar;radar configurations and types;geodesy;bistatic radar;time series;3d radar;interferometric synthetic aperture radar;optics;radar imaging;inverse synthetic aperture radar;side looking airborne radar;physics;radar;remote sensing	Visualization	77.1902475490231	-62.72870101624172	67301
1d596392e699b36153e52d0bafcaf893572db134	hyperspectral target detection with sparseness constraint	geophysical image processing;sparse unmixing hyperspectral image target detection hybrid detectors;detectors hyperspectral imaging object detection matched filters materials;spectral analysis geophysical image processing geophysical techniques hyperspectral imaging object detection regression analysis;sparseness constrained linear unmixing hyperspectral target detection sparseness constraint hyperspectral imagery abundance fractions background endmember spectra dictionary incoherence sparse regression band selection;regression analysis;spectral analysis;hyperspectral imaging;object detection;geophysical techniques	A sparseness constrained approach is proposed for linear unmixing, and the results are used for hybrid detection of hyperspectral imagery. The sparseness constraint is imposed on the abundance fractions, resulting in better performance than the popular non-negative and fully constrained methods, particularly in the situations when background endmember spectra are not accurately acquired or estimated, which is very common in practical applications. To increase the dictionary incoherence required for sparse regression, the use of band selection is proposed to improve the performance of sparseness constrained linear unmixing, thereby enhancing the following detection performance.	dictionary;mixture model;neural coding;sensor;sparse matrix	Ben D Ma;Qian Du	2013	2013 IEEE International Geoscience and Remote Sensing Symposium - IGARSS	10.1109/IGARSS.2013.6721346	computer vision;geology;hyperspectral imaging;pattern recognition;physics;regression analysis;remote sensing	Vision	69.68108381452855	-65.81951208904725	67356
cbe3cf0c25530f74fd20bbe2a45a7c2db9fabefc	evaluation of time series distance functions in the task of detecting remote phenology patterns	near surface vegetation index time series distance function evaluation remote phenology pattern detection periodic natural phenomena pattern identification temporal data phenological change patterns time series knowledge extraction;vegetation geophysical techniques remote sensing;time series analysis accuracy image color analysis color correlation digital images educational institutions	Phenology is the study of periodic natural phenomena and their relationship to climate. Usually, phenology studies consider the identification of patterns on temporal data. In those studies, several phenological change patterns are often encoded in time series for analysis and knowledge extraction. In this paper, we evaluate the effectiveness of several time series similarity functions in the task of classifying time series related to phonological phenomena characterized by near-surface vegetation indices extracted from images. In addition, we performed a correlation analysis to identify potential candidates for combination.	sensor;time series	Jose C. Conti;Fabio A. Farial;Jurandy Almeida;Bruna Alberton;Leonor Patricia C. Morellato;Luiz Camolesi;Ricardo da Silva Torres	2014	2014 22nd International Conference on Pattern Recognition	10.1109/ICPR.2014.539	computer vision	SE	80.71754363029002	-54.90269734573392	67391
083d555af7b8e5539443054c5f6e255880d070fc	a new maximum likelihood generalized gamma cfar detector	order statistic;maximum likelihood detection gamma ray detection gamma ray detectors radar detection clutter maximum likelihood estimation parameter estimation equations testing statistical analysis;cell averaging;maximum likelihood;constant false alarm rate;generalized gamma model radar detection radar clutter cell averager ordered statistic optimized weibull maximum likelihood method generalized gamma cfar detector constant false alarm rate generalized gamma clutter generalized gamma distribution;maximum likelihood estimation radar detection radar clutter radar theory radar signal processing;maximum likelihood estimation;gamma distribution;radar detection;radar clutter;radar theory;radar signal processing	The Generalized Gamma Model has as special cases the Rayleigh, Weibull and Lognormal models. It also closely approximates the K-pdf model. Radar Clutter is often approximated in one of these forms. It is therefore quite useful to develop CFAR (Constant False Alarm Rate) detectors that perform well under this clutter model. In this paper, a Maximum Likelihood Generalized Gamma (MLGG) CFAR detector has been developed. This MLGG detector uses the Maximum Likelihood Equations, both locally and globally, in order to estimate the parameters of the Generalized Gamma clutter. These estimated parameters are then used to estimate the local mean of the detector. The mean of the local CFAR window is then taken as the first moment of the Generalized Gamma distribution evaluated with the estimated parameters. In the examples it is shown that in homogeneous Generalized Gamma clutter, with point targets, the MLGG detector outperforms our standard test detectors, Cell Averager, Ordered Statistic and Optimized Weibull.	constant false alarm rate	George Gigli;George A. Lampropoulos	2002		10.1109/IGARSS.2002.1027195	econometrics;pattern recognition;constant false alarm rate;mathematics;maximum likelihood;statistics	Robotics	72.76486366518299	-63.775006462917446	67417
66c2c968dd7aecd76e546cd0b79e4d3c0ce82f05	document image binarization using the camera device in mobile phones	mobile phone binarization camera image;mobile phone;mobile handsets document image processing cameras;mobile handsets;document image processing;nokia imaging phone document image binarization camera device mobile phones adaptive binarization method character structure;mobile handsets document image processing image recognition pixel economic forecasting digital cameras motion pictures character recognition brightness lenses;cameras	This paper proposes an adaptive binarization method for the document image binarization acquired by an imaging phone. The used algorithm determines the local thresholds with the information from the global trend as well as the local details. As a consequence, the proposed method is good not only for preserving the fine details of the character structure, but also for alleviating noise. The effectiveness of the proposed method is illustrated using the results obtained with a Nokia imaging phone.	algorithm;binary image;mobile phone	Adrian Burian;Markku Vehviläinen;Mejdi Trimeche;Jukka Saarinen	2005	IEEE International Conference on Image Processing 2005	10.1109/ICIP.2005.1530113	computer vision;multimedia;camera phone;computer graphics (images)	Robotics	59.64556627526973	-60.61148155384582	67418
0991446cc3906897351ad2913b7b89e617d0cd7e	hyperspectral image unmixing using a multiresolution sticky hdp	image sampling;geophysical image processing;recursive estimation;hidden markov tree;dirichlet distribution;image segmentation;image resolution;generic model;gibbs sampling;hidden markov model;bayesian inference;sticky hierarchical dirichlet process bayesian inference hidden markov trees hyperspectral unmixing image segmentation spatially constrained unmixing;traitement du signal et de l image;recursive estimation geophysical image processing image resolution image sampling markov processes;hyperspectral unmixing;markov random field;hidden markov trees;markov model;hidden markov models;posterior distribution;vectors;mixture model;traitement des images;signal processing;tree structure;sticky hierarchical dirichlet process;markov process;informatique;inference algorithms;standard mrf model hyperspectral image unmixing multiresolution sticky hdp joint bayesian endmember extraction linear unmixing generative model dirichlet distribution mixture model dd mixture model abundance sampling latent label process spatial prior adjacent pixels gibbs sampling framework posterior distributions tree structured sticky hierarchical dirichlet process tree structured shdp posterior endmember abundance distributions spatially constrained unmixing directed markov model scale recursive estimation algorithms standard markov random field model;markov processes;hierarchical dirichlet process;spatially constrained unmixing;hyperspectral imaging;hidden markov models signal processing algorithms hyperspectral imaging spatial resolution vectors markov processes inference algorithms;signal processing algorithms;hyperspectral image;spatial resolution	This paper is concerned with joint Bayesian endmember extraction and linear unmixing of hyperspectral images using a spatial prior on the abundance vectors. We propose a generative model for hyperspectral images in which the abundances are sampled from a Dirichlet distribution (DD) mixture model, whose parameters depend on a latent label process. The label process is then used to enforces a spatial prior which encourages adjacent pixels to have the same label. A Gibbs sampling framework is used to generate samples from the posterior distributions of the abundances and the parameters of the DD mixture model. The spatial prior that is used is a tree-structured sticky hierarchical Dirichlet process (SHDP) and, when used to determine the posterior endmember and abundance distributions, results in a new unmixing algorithm called spatially constrained unmixing (SCU). The directed Markov model facilitates the use of scale-recursive estimation algorithms, and is therefore more computationally efficient as compared to standard Markov random field (MRF) models. Furthermore, the proposed SCU algorithm estimates the number of regions in the image in an unsupervised fashion. The effectiveness of the proposed SCU algorithm is illustrated using synthetic and real data.	algorithm;algorithmic efficiency;generative model;gibbs sampling;hidden markov model;image resolution;markov chain;markov random field;mixture model;pixel;recursion;sampling (signal processing);signal-to-noise ratio;single compilation unit;sticky bit;synthetic intelligence;unsupervised learning	Roni Mittelman;Nicolas Dobigeon;Alfred O. Hero	2012	IEEE Transactions on Signal Processing	10.1109/TSP.2011.2180718	image resolution;computer science;machine learning;pattern recognition;mathematics;markov process;hidden markov model;statistics	ML	61.50871337380115	-72.15955864975845	67556
1050d1eb6e189fe8bde386697c31a6fbba947645	calibration of polarimetric palsar imagery affected by faraday rotation using polarization orientation	polarimetric synthetic aperture radar;contraste;polarimetrie;urban area faraday rotation phased array type l band synthetic aperture radar palsar polarimetric calibration polarization orientation po;spaceborne polarimetric synthetic aperture radar;polarization orientation po;zona urbana;polarimetric calibration;circular polarization;polarimetry;crosstalk;radar antenne synthetique;isolation;prospection;calibration method;faraday rotation;phased array;polarization;far east;zone urbaine;imagerie;correction;polarimetric palsar imagery calibration;orientation;cross polarization;satisfiability;delta modulation;noise robustness;polarization orientation;polarizacion;bande l;corrections;distortion;japan aerospace exploration agency;japon;imagery;isolement;calibration polarization crosstalk spaceborne radar polarimetric synthetic aperture radar synthetic aperture radar phase distortion l band delta modulation noise robustness;urban areas;faraday rotation correction;asie;phase distortion;radar polarimetry;bruit;distorsion;prospeccion;palsar;faraday effect;exploration;orientacion;correccion;urban area;extreme orient;crosstalk system;etalonnage;polarimetric system distortion model;rotacion;extremo oriente;imagineria;polarisation;crosstalk system spaceborne polarimetric synthetic aperture radar polarimetric palsar imagery calibration faraday rotation effect polarimetric system distortion model calibration method polarization orientation phased array type l band sar circular polarization based method distortion matrix calibrated data japan aerospace exploration agency faraday rotation correction;synthetic aperture radar calibration faraday effect geophysical techniques measurement standards radar polarimetry spaceborne radar;measurement standards;rotation;phased array type l band synthetic aperture radar palsar;radar ouverture synthetique;faraday rotation effect;distortion matrix calibrated data;calibration;japan;phased array type l band sar;geophysical techniques	For spaceborne polarimetric synthetic aperture radar (SAR), it is important to ensure the removal of both polarimetric system distortion and the effect of Faraday rotation. This paper proposes a new calibration method to derive the system distortion using polarization orientation (PO) induced in built-up areas and applies to Phased-Array-Type L-Band SAR (PALSAR) calibration. Faraday rotation is corrected by the circular-polarization-based method from the distortion matrix (DM)-calibrated data. The derived DMs do not coincide with those by the Japan Aerospace Exploration Agency (JAXA), but our calibration results compare well to JAXA's results in PO angles and calibrator's responses. The two results satisfy polarimetric calibration requirements, and the cross-polarized isolation improves by more than 5 dB after Faraday rotation correction following DM calibration-even in the case of small Faraday rotation (-2deg to -0.5deg). The proposed method is robust to noise and is useful when using an area of mixed polarimetric response for calibration. This method is also applicable to a large crosstalk system and the case of large Faraday rotation.	circular polarization;crosstalk;distortion;faraday cage;faraday effect;l band;phased array;polarimetry;polarization (waves);requirement;synthetic data	Hiroshi Kimura	2009	IEEE Transactions on Geoscience and Remote Sensing	10.1109/TGRS.2009.2028692	distortion;geodesy;polarization;optics;faraday effect;physics;remote sensing	Robotics	79.1012374238638	-65.48093874535978	67579
22288555b62b1f7bf12d8f376f128a3c40622993	an iterative adaptive approach for blood velocity estimation using ultrasound	adaptive estimation;biomedical ultrasonics;image sampling;iterative methods;medical image processing;b-mode images;doppler emissions;blood velocity estimation;blood velocity spectrum estimation;duplex mode transmissions;fast-time samples;field ii simulations;flexible transmission patterns;iterative data-adaptive spectral estimation technique;medical ultrasound scanners;slow-time sampling pattern;spectral artifacts;doppler effect;spectrogram;biomedical imaging;signal processing;estimation	This paper proposes a novel iterative data-adaptive spectral estimation technique for blood velocity estimation using medical ultrasound scanners. The technique makes no assumption on the sampling pattern of the slow-time or the fast-time samples, allowing for duplex mode transmissions where B-mode images are interleaved with the Doppler emissions. Furthermore, the technique is shown, using both simplified and more realistic Field II simulations, to outperform current state-of-the-art techniques, allowing for accurate estimation of the blood velocity spectrum using only 30% of the transmissions, thereby allowing for the examination of two separate vessel regions while retaining an adequate updating rate of the B-mode images. In addition, the proposed method also allows for more flexible transmission patterns, as well as exhibits fewer spectral artifacts as compared to earlier techniques.	artifact (error);duplex (telecommunications);iteration;iterative method;medical ultrasound;sampling (signal processing);simulation;spectral density estimation;velocity (software development)	Erik Gudmundson;Andreas Jakobsson;Jørgen Arendt Jensen;Petre Stoica	2010	2010 18th European Signal Processing Conference		computer vision;electronic engineering;engineering;analytical chemistry	Robotics	75.21534351733209	-67.99786547591411	67627
07deda960a5c1e4cde6d671fbc24c73fe0ed2def	fast image filter based on adaptive-weight and joint-histogram algorithm		Adaptive-weight operators are ubiquitous in numerous computer vision applications. The structure of general adaptive-weight models, however, are hard to accelerate with high speed to large or complex images. In this paper, the proposed adaptive-weight image filter algorithm is mainly on a new joint-histogram representation, median value searching, and a new data structure that contributes to fast data access. The effectiveness of these schemes is demonstrated on estimation of median position, which not only better preserves edges, but also reduces computation complexity from O(mnr 2) to O(mnr) using histogram, where m * n and r denote image size and radius of the mask window respectively. The results of our experiments demonstrate that our approach is effective to image filtering and image enhancement.	algorithm;composite image filter	Zhenhua Wang;Fuyuan Hu;Shaohui Si;Yajun Gu;Ze Li;Zhengtian Wu	2015		10.1007/978-3-319-23989-7_56	adaptive filter;multidelay block frequency domain adaptive filter;kernel adaptive filter;filter design	Vision	54.28485299772696	-64.52650402848596	67756
5fcce43e9a80122f4659bd28d4722f80ab440c7f	conveying visual information with spatial auditory patterns	sound recognition;auditory displays shape frequency auditory system brightness computer displays spatial resolution graphics image analysis vehicles;spatial surroundings;image recognition;reconocimiento imagen;brightness level;graphic percepts;image acoustique;acoustic image;image processing;sound localization;binary image;information channel;localization;2d binary images;slow raster scanning;auditory system;low resolution;procesamiento imagen;acoustic signal processing;imagen acustica;auditory imagery;localizacion;auditory displays;synthetic auditory images;reconocimiento sonido;traitement image;sound localization spatial auditory patterns visual information spatial surroundings auditory system low resolution patterns spatial resolution information channel 2d binary images auditory image slow raster scanning perceptual auditory surface brightness level level difference sound color contrast speed surface curvature graphic percepts synthetic auditory images experimental results;sintesis imagen;auditory image;image synthesis;brightness;speed;localisation;perceptual auditory surface;shape;sound color contrast;visual information;analyse performance;computer displays;reconnaissance image;performance analysis;reconnaissance son;surface curvature;audio signals;signal resolution;synthese image;level difference;image analysis;imagineria auditiva;spatial auditory patterns;vehicles;imagerie auditive;low resolution patterns;frequency;experimental results;hearing;signal resolution audio signals acoustic signal processing hearing image processing brightness;graphics;analisis eficacia;spatial resolution	"""Humans can perceive their spatial surroundings both by the visual and the auditory senses. Even though the auditory system has much lower spatial resolution, it can still serve as an alternative or supplementary information channel for the visual modality. In this paper, we investigate the feasibility of conveying elaborate visual information by auditory patterns. A system is developed which transforms two-dimensional binary images into \auditory images"""". Such images are based on slow raster-scanning of a perceptual auditory surface around the subject while emitting sounds that correspond to the brightness level of the images at each location. The parameters involved in such a system are quantitatively investigated with respect to their eeect on performance. These parameters include resolution, level diierence, sound color contrast, speed, surface curvature, etc. The graphic percepts of synthetic auditory images which correspond to simple shapes are also analyzed. The experimental results show that sound localization can be used to convey visual information quite successfully for simple shapes and low resolution patterns."""	binary image;humans;image resolution;modality (human–computer interaction);raster scan;resolution (logic);synthetic data	Zhiqian Wang;Jezekiel Ben-Arie	1996	IEEE Trans. Speech and Audio Processing	10.1109/89.544529	computer vision;image analysis;speech recognition;image resolution;acoustics;image processing;computer science;auditory scene analysis	Vision	63.534829831198344	-59.59381522162835	67757
8dad1cae02068ef89ed78dc7ae665379dcb0bf1a	micro aerial vehicles in disaster assessment operations - the example of cyprus 2011	nachrichtensysteme		aerial photography	Martin Frassl;Michael Lichtenstern;Michael Angermann;Giulio Gullotta	2012		10.1007/978-3-642-33161-9_68	mining engineering;geography;environmental protection;civil engineering	Vision	79.30318349015882	-60.20325713544019	67816
8ad7c5fd02d1cd00ad9202557e8c1a64d5234f1b	image fusion and 3-d surface reconstruction of microparts using complex valued wavelet transforms	wavelet transforms image fusion image reconstruction image resolution microscopy;high resolution;image resolution;real time control;depth of field;image fusion;microscopy;indexing terms;surface reconstruction;complex wavelet transform;microscopy image;wavelet transforms;microscopy image complex wavelet transforms image fusion;wavelet transform;image reconstruction;complex wavelet transforms;image resolution image fusion 3 d surface reconstruction wavelet transform microscopy imaging;image fusion surface waves surface reconstruction image reconstruction wavelet transforms reconstruction algorithms microscopy high resolution imaging image resolution focusing	"""Microscopy imaging can not achieve both high resolution and wide image space simultaneously. Image fusion and 3-D surface reconstruction is of fundamental importance to micromanipulation in providing high lever task understanding, task planning and real time control. Purpose of image fusion is to combine those images into one single image with an extended depth-of-field. Previously, real valued wavelet transforms based image fusion suffers from shift variance, poor directionality, and lack of phase information. One promising fusion method based on complex wavelet transforms to overcome these problems is proposed. Combined 2-D position data of """"in focus"""" pixels with a height map obtained from the proposed image fusion method, a 3-D surface reconstruction algorithm of microparts is developed. Experimental results validate performances of the proposed image fusion and 3-D surface reconstruction methods."""	algorithm;autostereogram;heightmap;image fusion;image resolution;performance;pixel;wavelet transform	Weibin Rong;Lining Sun;Wei Chen	2006	2006 International Conference on Image Processing	10.1109/ICIP.2006.312866	computer vision;image resolution;computer science;microscopy;mathematics;image fusion;wavelet transform;computer graphics (images)	Robotics	58.4611853582945	-59.50414022342503	67843
777a1c454281888511768e1a23fc5b8fdf2bb383	rotation-invariance can further improve state-of-the-art blind deconvolution techniques	cybernetics;constraint optimization;convolution;image reconstruction;linear programming;deconvolution;conferences	In many real-life situations, we need to reconstruct a blurred image in situations when no information about the blurring is available. This problem is known as the problem of blind deconvolution. There exist techniques for solving this problem, but these techniques are not rotation-invariant. Thus, the result of using this technique may change with rotation. So, if we rotate the image a little bit, the method, in general, leads to a different deconvolution result. Therefore, even when the original reconstruction is optimal, the reconstruction of a rotated image will be different and, thus, not optimal. To improve the quality of image decomposition, it is desirable to modify the current state-of-the art techniques by making them rotation-invariant. In this paper, we show how this can be done, and we show that this indeed improves the quality of blind deconvolution.	blind deconvolution;real life	Fernando Cervantes;Bryan Usevitch;Vladik Kreinovich	2016	2016 IEEE International Conference on Systems, Man, and Cybernetics (SMC)	10.1109/SMC.2016.7844614	iterative reconstruction;image restoration;computer vision;mathematical optimization;cybernetics;computer science;linear programming;deconvolution;machine learning;mathematics;blind deconvolution;convolution	Vision	58.99173109646396	-70.08836841068597	67864
1d8a4f1488e17be8e0e66bd28c593a7bad1657c5	reading recognition of digital display instrument based on bp neutral network	reading recognition;image preprocessing;instruments;image segmentation;neural nets;vertical tilt correction;instruments digital cameras lenses feature extraction image segmentation image recognition computer science computer displays digital control monitoring;training;character segmentation;display instrumentation;digital camera;backpropagation;digital instrumentation;digital cameras;digital display instrument reading recognition;bp neutral network;feature extraction;pixel;gray processing;grads sharp;character contraction digital display instrument reading recognition backpropagation neural network algorithm feature extraction digital camera image preprocessing gray processing grads sharp vertical tilt correction noise point removal character segmentation character unitary adjustment;backpropagation neural network algorithm;image denoising;reading recognition bp neutral network digital display instrument;neutral network;computerised instrumentation;noise point removal;character contraction;character recognition;neural nets backpropagation cameras computerised instrumentation digital instrumentation display instrumentation feature extraction image denoising image segmentation;cameras;character unitary adjustment;noise;digital display instrument	To recognize digital display instrumentpsilas reading, a BP neutral network is designed, an improved BP algorithm and 15-feature extraction method is proposed. The image of instrument plate is obtained by an digital camera and transmitted to PC firstly, then an image preprocessing is carried through. The image preprocessing includes gray processing, binarization, grads sharp, vertical tilt correction, noise point removal, character segmentation, character unitary adjustment, character contraction and feature extraction. Character features are extracted by 15-feature extraction method. Finally recognize the reading by the BP neutral network. The experiment result proves that the system can scan and recognize lots of instruments, the recognition is of high veracity and great efficienc.	algorithm;backpropagation;digital camera;display device;feature extraction;preprocessor;veracity	Zhiqiang Huang;Chengfu Wang	2008	2008 International Conference on Computer Science and Software Engineering	10.1109/CSSE.2008.778	computer vision;speech recognition;feature extraction;computer science;noise;neutral network;backpropagation;machine learning;image segmentation;artificial neural network;pixel;computer graphics (images)	Robotics	55.462379153544056	-60.87837130244673	67866
413b647b6d9ea884841e73b51152bd1c942d9962	survey of bathymetry and current fields by radar image series acquired by shore based x-band radar	water depth;morphodynamics;current field component coastal monitoring ground based radar morphodynamics water depth;component;coastal monitoring;error analysis;remote sensing by radar;spatial correlation;radar imaging;current field;ground based;remote sensing by radar bathymetry error analysis oceanographic techniques;bathymetry;oceanographic techniques;radar;radar imaging sea measurements image sequences dispersion sea surface radar antennas surface morphology sediments image analysis image sequence analysis;spatial correlation bathymetry current fields error source dispersive surface classificator	The error source in assessing the bathymetry by the Dispersive Surface Classificator method is discussed in this paper. The accuracy of the method is high in the deeper areas and is reduced behind the slopes. The identification of systematic correlation of the absolute value of the error with the slope was not possible. The spatial correlation of the error illustrates that the direction of the wave field influences the two neighboring cells in the same direction.	bathymetry;dispersive partial differential equation;radar	Stylianos Flampouris;Friedwart Ziemer;Jörg Seemann	2007	2007 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2007.4423619	spatial correlation;geodesy;geology;hydrology;bathymetry;component;radar imaging;radar;remote sensing	Embedded	79.11365221842621	-63.996617029589366	67916
0cfb03e9b1edf1407e52ee09bd70046f9c073c56	perceptually driven visibility optimization for categorical data visualization	optimisation;measurement;color design;user interface;image color analysis visualization data visualization optimization measurement retina;color optimization perceptually driven visibility optimization categorical data visualization technique categorical differences color perceptual qualities color palette utility coherent categorical structure color optimization algorithm class visibility metric visual search user preference;data visualisation;visualization;visibility;image color analysis;retina;data visualization;cartography;user interface color design visualization visibility;optimization;visibility cartography colour data visualisation optimisation;colour	Visualization techniques often use color to present categorical differences to a user. When selecting a color palette, the perceptual qualities of color need careful consideration. Large coherent groups visually suppress smaller groups and are often visually dominant in images. This paper introduces the concept of class visibility used to quantitatively measure the utility of a color palette to present coherent categorical structure to the user. We present a color optimization algorithm based on our class visibility metric to make categorical differences clearly visible to the user. We performed two user experiments on user preference and visual search to validate our visibility measure over a range of color palettes. The results indicate that visibility is a robust measure, and our color optimization can increase the effectiveness of categorical data visualizations.	algorithm;categorical variable;coherence (physics);color;data visualization;experiment;mathematical optimization;palette (computing);shadow volume;small	Sungkil Lee;Mike Sips;Hans-Peter Seidel	2013	IEEE Transactions on Visualization and Computer Graphics	10.1109/TVCG.2012.315	computer vision;visualization;visibility;computer science;multimedia;user interface;data visualization;measurement;statistics;computer graphics (images)	Visualization	61.25042806287147	-62.3531000117591	67984
47d52ed19303f3cae84a0be2da7d9968541eb9a3	super resolution volume rendering hardware	volume rendering;super resolution	"""The resolution obtained in volume rendering is greatly increased over known methods through the introduction of super resolution techniques which make it possible to enlarge the view of the dataset without the introduction of unnecessary positional, gradient and opacity errors. In this paper our """"Super Resolution"""" technique will be introduced along with a corresponding hardware design."""	computational complexity theory;display resolution;gradient;holomatix rendition;image resolution;nonlinear system;shading;super-resolution imaging;volume rendering;voxel	Marco Bosma;Jaap Smit;Jeroen Terwisscha van Scheltinga	1995		10.2312/EGGH/EGGH95/117-122	computer vision;optics;sub-pixel resolution;computer graphics (images)	Vision	65.89082237196475	-52.95339806846182	68018
b782143a08593ec444b93a36fc5f6d909395e214	a two-phase multiobjective sparse unmixing approach for hyperspectral data		With the sparse unmixing becoming increasingly popular recently, some advanced regularization algorithms have been proposed for settling this problem. However, they are limited by their “decision ahead of solution” attribute, i.e., the regularization parameters must be preset before the solution is obtained. In this paper, the sparse unmixing problem is first formulated as a two-phase multiobjective problem. The first phase simultaneously minimizes the unmixing residuals and the number of estimated endmembers for automatically finding the real active endmembers from the spectral library. A decomposition-based endmember selection algorithm considering the gene exchange in the population is specially designed for better and quicker search of the decision space. This algorithm can obtain a set of nondominated solutions for better decision of the active endmembers, which are important for the subsequent calculation of the abundance matrix. The second phase concurrently minimizes the unmixing residuals and the total variation term for estimating a preferable abundance matrix. A local search strategy based on the multiplicative update rule is designed in the evolution process for better approximation of the Pareto front. The experimental results on the synthetic as well as the real data reveal that the proposed framework has a better performance in finding the real active endmembers and estimating their corresponding abundances than some advanced regularization algorithms.	approximation;genetic operator;local search (optimization);mpls-tp;mathematical optimization;matrix regularization;multi-objective optimization;optimization problem;pareto efficiency;rate of convergence;selection algorithm;sparse matrix;synthetic data;two-phase locking	Xiangming Jiang;Maoguo Gong;Hao Li;Mingyang Zhang;Jun Li	2018	IEEE Transactions on Geoscience and Remote Sensing	10.1109/TGRS.2017.2751060	endmember;selection algorithm;mathematics;computer vision;artificial intelligence;local search (optimization);algorithm design;population;algorithm;multi-objective optimization;regularization (mathematics);hyperspectral imaging	ML	69.31098778879088	-66.96147357124534	68073
e95c735417f6545378fc281951763712e26b6554	an aerosol lidar model program used for the center for lidar and atmospheric sciences students lidar system	atmospheric science;remote sensing by laser beam;15 hz;continuum surelite ii nd yag pumped laser;optical transmitters;portable eyesafe 3d scanning aerosol lidar system;center for lidar and atmospheric sciences students;1 5 micron;backscatter;laser radar;yag nd;mathcad software;laser radar aerosols atmospheric modeling equations optical receivers optical transmitters backscatter optical scattering rayleigh scattering computer displays;atmospheric measuring apparatus;mathematical lidar model program;yal5o12 nd;yal5o12 nd center for lidar and atmospheric sciences students portable eyesafe 3d scanning aerosol lidar system hampton university class mathematical lidar model program mathcad software continuum surelite ii nd yag pumped laser 1 5 micron 85 mj 15 hz yag nd;optical scattering;optical radar;atmospheric measuring apparatus optical radar aerosols remote sensing by laser beam;hampton university;system design;85 mj;computer displays;class;atmospheric modeling;rayleigh scattering;optical receivers;aerosols	A portable, eyesafe, 3-D scanning aerosol lidar system designed and operated by the Hampton University Center for Lidar and Atmospheric Sciences Students (CLASS) is introduced. A mathematical lidar model program wrote using MathCAD software being developed and used by the student lidar team in CLASS is presented.		Langdon Williams;Wei Gong;Doyle Temple;Ali H. Omar;Jan Mangana	2002		10.1109/IGARSS.2002.1026522	meteorology;lidar;atmospheric model;light scattering;class;optics;rayleigh scattering;backscatter;physics;remote sensing;systems design	ML	82.07950936982753	-64.11748444342695	68120
753daf033c4c2b747858c01066ade76f3e6891d7	visible distortion predictors based on visual attention in color images	cortex transform;visible distortion;cvdp;inverse contrast;human visual system;visual attention	An image attention model and its application to image quality assessment are discussed in this paper. The attention model is based on rarity quantification, which is related to self-information to attract the attention in an image. It is relatively simpler than the others but results in taking more consideration of global contrasts between a pixel and the whole image. The visual attention model is used to develop a local distortion predictor, named color visual differences predictor (CVDP), in color images in order to effectively detect luminance and color distortions.	algorithm;distortion;entropy (information theory);image quality;indexed color;information theory;kerrison predictor;pixel;self-information;variable data printing;whole earth 'lectronic link	Sang-Gyu Cho;Jae-Jeong Hwang;Nae-Joung Kwak	2012	J. Inform. and Commun. Convergence Engineering	10.6109/jicce.2012.10.3.300	psychology;computer vision;optics;communication	Vision	61.72551520151604	-62.65992133806911	68121
432d53195d624fccf74989f552a670c7f8fe718b	post-processing of multiview images: depth scaling	multiview image post processing;probability density function;disparity;data mining;cameras pixel three dimensional displays testing layout information technology telecommunication computing telecommunication control performance evaluation acceleration;depth scaling method;visualization;monitoring;multiple camera;three dimensional displays;multiple camera multiview image post processing depth scaling method stereoscopic depth range;pixel;stereo image processing;multiview image;depth scaling;stereoscopic depth range;stereo image processing cameras;disparity depth scaling multiview image;3d display;cameras	The post processing of multiview images is one of new fields. Among them, a depth scaling is an important research. In this paper, we present a depth scaling method for multiview images that could provide an effective control of stereoscopic depth range. Unlike the previous works that change a camera configuration, our proposed method utilizes depth data in order to carry out the scaling of a depth range requested by users. In particular, our method can deal with multiview images captured by multiple cameras, and can be expanded from stereoscopic to multiview images. Our experimental results tested on automultiscopic 3D displays show that the perceived depth is appropriately scaled according to a user’s preferred depth. To prove this, DQCQS (Double Stimulus Continuous Quality Scale) subjective test is performed. The mean evaluation value of ten subjects is varied proportional to a scale factor.	2.5d;image scaling;multiscopy;norm (social);stereo display;stereoscopy;video post-processing	Manbae Kim	2009	2009 Sixth International Conference on Information Technology: New Generations	10.1109/ITNG.2009.110	computer vision;probability density function;visualization;stereo display;computer science;pixel;statistics;computer graphics (images)	Robotics	63.208783296698385	-63.14104553901426	68122
697044e20f7f18cdfb3d3b9b827bdadb54603118	a fast adaptive guided filtering algorithm for light field depth interpolation	image edge detection estimation cameras noise measurement optimization image texture lenses;conference paper;regression analysis adaptive filters cameras image texture;drntu engineering electrical and electronic engineering electronic circuits;coefficients regression fast adaptive guided filtering agf light field depth interpolation light field camera 4d information light rays scene depth information disparity depth maps false entries homogeneous regions image contour texture information disparity edges image texture	Light field camera provides 4D information of the light rays, from which the scene depth information can be inferred. The disparity/depth maps calculated from light field data are always noisy with missing and false entries in homogeneous regions or areas where view-dependant effects are present. In this paper we proposed an adaptive guided filtering (AGF) algorithm to get an optimized output disparity/depth map. A guidance image is used to provide the image contour and texture information, the filter is able to preserve the disparity edges, smooth the regions without influence of the image texture, and reject the data entries with low confidence during coefficients regression. Experiment shows AGF is much faster in implementation as compared to other variational or hierarchical based optimization algorithms, and produces competitive visual results.	algorithm;binocular disparity;coefficient;depth map;experiment;gnu common lisp;image texture;interpolation;light field;mathematical optimization;ray (optics);variational principle	Jie Chen;Lap-Pui Chau	2014	2014 IEEE International Symposium on Circuits and Systems (ISCAS)	10.1109/ISCAS.2014.6865626	image texture;computer vision;mathematics;texture compression;texture filtering;computer graphics (images)	Vision	57.22948608068665	-58.384077983675006	68172
38066f32764f476ea29d3e6e8516e2033cb276ff	remote sensing image fusion using statistical univariate finite mixture model in shearlet domain	image fusion;indexes;principal component analysis;remote sensing;transforms;mixture models;gaussian distribution	Remote sensing image fusion is a process that integrates the spatial detail of panchromatic (PAN) image and the spectral information of a low-resolution multispectral (MS) image and produces a fused image that contain both high spatial and spectral details. In this paper, a new remote sensing image fusion method is proposed based on Statistical Univariate Finite Mixture Model (UFMM) in Shearlet Domain. Foremost, the Shearlet sub-bands for PAN and MS image are achieved by Shearlet Transform (ST). Latter, a novel fusion strategy is designed for both low and high pass sub-bands. Finally, the fused image is achieved by Inverse Shearlet Transform (IST). By comparing with the well-known methods in terms of several quality evaluation indexes, the experimental results on QuickBird and IKONOS images show the superiority of our method.	coefficient;foremost;ibm http server;image fusion;informatics;mixture model;multispectral image;principal component analysis;shearlet;whole earth 'lectronic link	Biswajit Biswas;Abhishek Dey;Kashi Nath Dey	2015	2015 International Conference on Advances in Computing, Communications and Informatics (ICACCI)	10.1109/ICACCI.2015.7275940	normal distribution;database index;computer vision;computer science;pattern recognition;mixture model;mathematics;image fusion;statistics;remote sensing;principal component analysis	Robotics	65.92741734003631	-66.17635943658412	68180
d2c71d2991939703b2dcbe911a862e4dcc7634cf	a nation-wide system for landslide mapping and risk management in italy: the second not-ordinary plan of environmental remote sensing		Abstract Landslides are frequent events that may cause human casualties and injuries as well as damage to urban and man-made structures, with extensive loss of economic resources. For this reason, landslide mapping is a primary tool for hazard and risk assessment. Italian Ministry of Environment, thanks to great availability and functionality of Synthetic Aperture Radar (SAR) data promoted the Not-ordinary Plan of Environmental Remote Sensing (Piano Straordinario di Telerilevamento Ambientale, PST-A in Italian) in 2008, as to constitute a national database of active or potential instability phenomena affecting the Italian territory, based on the exploitation of interferometric products (ERS and ENVISAT). In this paper, the PST-A-3 is described. A procedure based on the integration of engineering-geological approaches and SAR interferometry data belonging to COSMO-SkyMed constellation (100 frames 40 × 40 km) has been here implemented over 7,400 km 2 of the Italian territory. First, landslides have been mapped by field geologists, defining type and state of activity. Simultaneously to field surveys, remote sensing data have been analyzed as to detect areas with considerable displacement registered by the satellite. Both products have been overlaid, also quantifying the coincidence between the events reported according to the two detection methodologies and subtracting those landslide not recordable by the satellite, finally obtaining an updated landslide inventory map with 4,522 newly detected phenomena. Therefore, PST-A-3 proves to be a valuable system for local authorities, in order to provide a contribution to risk management but also for the forecasting of landslide events, as testified by two case studies selected. Thanks to the PST-A experience, the use of such strategy to other countries could represent a valid contribution to land management at worldwide scale.	risk management	Diego Di Martire;M. Paci;P. Confuorto;S. Costabile;F. Guastaferro;A. Verta;Domenico Calcaterra	2017	Int. J. Applied Earth Observation and Geoinformation	10.1016/j.jag.2017.07.018	geography;risk management;christian ministry;hydrology;remote sensing;land management;synthetic aperture radar;instability;risk assessment;landslide	AI	81.53767445214761	-57.07170511925513	68182
1624b5efacb5029011e3b011103fe88ec528515a	line segment sampling with blue-noise properties	aliasing;blue noise;sampling;poisson disk sampling	Line segment sampling has recently been adopted in many rendering algorithms for better handling of a wide range of effects such as motion blur, defocus blur and scattering media. A question naturally raised is how to generate line segment samples with good properties that can effectively reduce variance and aliasing artifacts observed in the rendering results. This paper studies this problem and presents a frequency analysis of line segment sampling. The analysis shows that the frequency content of a line segment sample is equivalent to the weighted frequency content of a point sample. The weight introduces anisotropy that smoothly changes among point samples, line segment samples and line samples according to the lengths of the samples. Line segment sampling thus makes it possible to achieve a balance between noise (point sampling) and aliasing (line sampling) under the same sampling rate. Based on the analysis, we propose a line segment sampling scheme to preserve blue-noise properties of samples which can significantly reduce noise and aliasing artifacts in reconstruction results. We demonstrate that our sampling scheme improves the quality of depth-of-field rendering, motion blur rendering, and temporal light field reconstruction.	algorithm;aliasing;colors of noise;frequency analysis;gaussian blur;light field;nearest-neighbor interpolation;sampling (signal processing);smoothing	Xin Sun;Kun Zhou;Jie Guo;Guofu Xie;Jingui Pan;Wencheng Wang;Baining Guo	2013	ACM Trans. Graph.	10.1145/2461912.2462023	aliasing;coherent sampling;sampling;computer vision;temporal anti-aliasing;colors of noise;computer science;mathematics;optics;statistics;computer graphics (images)	Graphics	64.20146497394255	-53.644553318434305	68401
1281e320f43c143da1c2a208d0220744f9a28c1a	improved image capture using liveview images	object motion;liveview image;image capture;image processing;image resolution;liveview;object motion image capture liveview image digital camera;digital camera;noise reduction image capture liveview low light;aggregates noise pixel cameras noise reduction image resolution;aggregates;noise reduction;pixel;low light;image processing cameras;cameras;noise	Current digital cameras suffer from poor performance in lowlight situations. This paper addresses the problem of improving camera performance by using liveview images to augment a final capture. Attention is given to improving only the lowand mid-range frequency information in the final capture, corresponding to available information in the liveview images. Attention is also given to providing a solution with a small memory and computational footprint. It is shown that liveview images can be used to improve image capture, even in scenes containing significant object motion.	algorithm;computation;digital camera;gaussian blur;image resolution;memory footprint;sony ericsson liveview	Aaron Deever	2010	2010 IEEE International Conference on Image Processing	10.1109/ICIP.2010.5653870	computer vision;image resolution;image processing;computer science;noise;noise reduction;pixel;computer graphics (images)	Robotics	59.0054078211871	-57.354108185965366	68410
0df90f12d794d51f971c67470f8f5a0f6a5f6e63	evolvable hardware based gray-level image enhancement	histograms;evolved circuit evolvable hardware gray level image enhancement visual appearance evolved histogram stretching transformation;logic design;helium;reconfigurable architectures;evolved circuit;evolvable hardware;data mining;histogram stretching;brightness;integrated circuit design;image enhancement;hardware image enhancement histograms pixel helium brightness circuits equations nasa adaptive systems;reconfigurable architectures image colour analysis image enhancement integrated circuit design logic design;image enchancement;image colour analysis;evolved histogram stretching transformation;pixel;histogram stretching evolvable hardware image enchancement;gray level image enhancement;visual appearance;histogram equalization;hardware	A simple image enhancement technique based upon evolvable hardware is presented. Improving visual appearance is achieved by evolved histogram stretching transformation (evolved circuit). The performance is compared with the classical histogram equalization method using traditional measures of enhancement. Experimental results will be presented to show that the proposed technique offers better performance than the classical histogram equalization method.	evolvable hardware;histogram equalization;image editing	Jie Li	2009	2009 NASA/ESA Conference on Adaptive Hardware and Systems	10.1109/AHS.2009.12	computer vision;logic synthesis;computer science;histogram;adaptive histogram equalization;helium;visual appearance;histogram equalization;brightness;pixel;integrated circuit design;computer graphics (images)	EDA	55.3922710749624	-64.56230116950027	68436
5daa4a418f3c2252f61597591de59be09f7abb32	sar image enhancement for small target detection	radar resolution;interference suppression;image enhancement;performance improvement;speckle reduction sar image enhancement small target detection false alarm mitigation resolution background suppression multi look processing algorithm minimum variance algorithm multiple signal classification algorithm music algorithm;image enhancement object detection speckle australia image resolution signal resolution layout synthetic aperture radar multiple signal classification history;radar imaging;signal classification;sar image;interference suppression synthetic aperture radar image enhancement radar imaging radar resolution radar detection object detection signal classification;radar detection;target detection;object detection;synthetic aperture radar	This paper investigates the impact of SAR image enhancement on the performance of small target detection in SAR images. Three SAR image enhancement algorithms are evaluated on large SAR image data-sets. The evaluation results show that image enhancement can greatly improve the performance of false alarm mitigation, and that the level of performance improvement is correlated with the resolution and background suppression of the enhanced images. The higher the resolution and the level of background suppression, the higher the level of performance improvement.	algorithm;image editing;zero suppression	Jingxin Zhang;Jim Schroeder;Nicholas J. Redding	2003		10.1109/ICASSP.2003.1199508	computer vision;continuous-wave radar;synthetic aperture radar;radar imaging;inverse synthetic aperture radar	Vision	73.06246908023763	-65.30977644912288	68441
2e138e78fb2b80bdd2f650c0eec7bf5fb1287717	integrating quickbird multi-spectral satellite and field data: mapping bathymetry, seagrass cover, seagrass species and change in moreton bay, australia in 2004 and 2007	change detection;high resolution;remote sensing;field data;multi spectral;quickbird;bathymetry;seagrass	Shallow coastal ecosystems are the interface between the terrestrial and marine environment. The physical and biological composition and distribution of benthic habitats within these ecosystems determines their contribution to ecosystem services and biodiversity as well as their connections to neighbouring terrestrial and marine ecosystem processes. The capacity to accurately and consistently map and monitor these benthic habitats is critical to developing and implementing management applications. This paper presents a method for integrating field survey data and high spatial resolution, multi-spectral satellite image data to map bathymetry and seagrass in shallow coastal waters. Using Quickbird 2 satellite images from 2004 and 2007, acoustic field survey data were used to map bathymetry using a linear and ratio algorithm method; benthic survey field data were used to calibrate and validate classifications of seagrass percentage cover and seagrass species composition; and a change detection analysis of seagrass cover was performed. The bathymetry mapping showed that only the linear algorithm could effectively and accurately predict water depth; overall benthic map accuracies ranged from 57–95%; and the change detection produced a reliable change map and showed a net decrease in seagrass cover levels, but the majority of the study area showed no change in seagrass cover level. This study demonstrates that multiple spatial products (bathymetry, seagrass and change maps) can be produced from single satellite images and a concurrent field survey dataset. Moreover, the products were produced at higher spatial resolution and accuracy levels than previous studies in Moreton Bay. The methods are developed from OPEN ACCESS Remote Sens. 2011, 3 43 previous work in the study area and are continuing to be implemented, as well as being developed to be repeatable in similar shallow coastal water environments.	acoustic cryptanalysis;algorithm;bathymetry;ecosystem services;habitat;map;marine ecosystem;terrestrial television	Mitchell B. Lyons;Stuart R. Phinn;Chris M. Roelfsema	2011	Remote Sensing	10.3390/rs3010042	image resolution;oceanography;bathymetry;ecology;change detection;statistics;remote sensing	HCI	82.3585335042025	-58.4400881950528	68477
b03919e517bedffa2f47c129e54ce992617f80bd	a scalable probabilistic change detection algorithm for very high resolution (vhr) satellite imagery	satellite image processing;spatial data mining;probabilistic change detection;openmp	Detecting landscape changes using very high-resolution multispectral imagery demands an accurate and scalable algorithm that is robust to geometric and atmospheric errors. Existing pixel-based change detection approaches, however, have several drawbacks, which render them ineffective for VHR imagery analysis. A recent probabilistic change detection framework provides more accurate assessment of changes than traditional approaches by analyzing image patches than pixels. However, this patch (grid)-based approach produces coarse-resolution (patch size) changes. In this work we present a sliding window based approach that produces changes at the native image resolution. The increased computational demand of the sliding window based approach is addressed through thread-level parallelization on shared memory architectures. Our experimental evaluation showed a 91% performance improvement compared to its sequential counterpart on a sq. KM aerial image with varying window sizes on a 16-core (32 virtual threads) Intel Xeon processor.	aerial photography;algorithm;computation;computational complexity theory;computer;distributed memory;image resolution;intel core (microarchitecture);map;memory bandwidth;multi-core processor;multispectral image;parallel computing;patch (computing);pixel;scalability;scene statistics;sensor;shared memory;vii;window function	Seokyong Hong;Ranga Raju Vatsavai	2016	2016 IEEE International Congress on Big Data (BigData Congress)	10.1109/BigDataCongress.2016.42	computer vision;geography;remote sensing;computer graphics (images)	Visualization	68.82532963676	-58.84068105244777	68489
c3a616b166451e8698193710045f445e0500c530	a new method for change analysis of multi-temporal hyperspectral images	tensors hyperspectral imaging image representation matrix decomposition object detection;seasonal variation change analysis multi temporal hyperspectral images tensor factorization tf hyperspectral change detection multilinear algebra tensor based representation tensor based analysis spatial structure spectral structure temporal structure diurnal variation;radiometry monitoring matrix decomposition abstracts indexes object recognition;principal component analysis pca change detection hyperspectral imagery tensor factorization tf higher order orthogonal iteration hooi algorithm matrix factorization mf	In this paper, we propose a new method based on tensor factorization (TF) for hyperspectral change detection. The multilinear algebra is used to consider the whole data of multi-temporal images. The tensor-based representation and analysis has the advantage of keeping the spatial, spectral, and temporal structures in the original images. The preliminary result shows that this new method is capable of finding the foreground changes of interest in the presence of diurnal and seasonal variations.	algorithm;pixel;sensor	Qian Du	2012	2012 4th Workshop on Hyperspectral Image and Signal Processing (WHISPERS)	10.1109/WHISPERS.2012.6874223	computer vision;machine learning;pattern recognition;mathematics;multilinear subspace learning	Vision	69.13146880605792	-65.65792917524158	68673
3f85842b71da1dc951651475d962bd784c007f44	analysing variety of vegetation indices values using different methods for mapping oil palm closed-canopy composition in southern riau province, indonesia	closed canopy vegetation indices oil palm classification;geophysical image processing;vegetation mapping;closed canopy;oil palm;vegetation indices;classification;vegetation mapping geophysical image processing remote sensing;remote sensing;reflectance value vegetation index value characteristics oil palm closed canopy composition mapping southern riau province indonesia mature oil palm tree new planted tree brightness level tct algorithm young oil palm trees;vegetation mapping vegetation remote sensing satellites brightness reflectivity earth	This study discusses the vegetation indices values characteristics for mapping oil palm closed-canopy composition using six different methods. We found that vegetation indices value in every different technique could not distinguish between mature oil palm tree and new planted tree, except for the brightness level from TCT algorithm. The classification result shows better accuracy than using original bands, but the classification is still difficult to distinguish new planted and young oil palm trees due to the similar reflectance value.	algorithm;motorola canopy;the coroner's toolkit	Fatwa Ramdani	2012	2012 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2012.6352232	biological classification;geology;physics;remote sensing	Embedded	79.68533946870862	-57.70209414585905	68688
fe5ab09b9bc764418f0496825dd80146bd61a5e0	full-waveform lidar pixel analysis for low-growing vegetation mapping of coastal foredunes in western france		The monitoring of coastal sand dunes requires regular high-resolution aerial photography along hundreds of kilometers of coastal strips. Light detection and ranging (LiDAR) is now the most widely used method for detailed topographic and vegetation studies. The aim of this work is to show how the full-waveform shapes returned from single or multiple targets can carry information relating to low-vegetation cover and ground roughness of dunes. This work focuses on marram grass, widely involved in the development of mobile dunes. Low-growing plants often exhibit identical pigmentary composition and can only be distinguished by the height of their foliage, which modifies the shape of the LiDAR waveform around the main returns at the top of the foliage. We show that ray tracing of full LiDAR waveforms on the regular grid of pixels of hyperspectral images, acquired synchronously, can resolve the confusion between low-vegetation gradients and bare sand by analyzing the waveform damping induced by cumulating microdiffusion on foliage height, but also with glint effects on the surface roughness of compact materials. Analysis of successive shorelines of wet to dry sand, sand to pioneer couch grass, and couch grass to consolidating marram grass can thereby be conducted routinely.	pixel;waveform	Patrick Launeau;Manuel Giraud;Antoine Ba;Saïd Moussaoui;Marc Robin;Françoise Debaine;Dimitri Lague;Erwan Le Menn	2018	Remote Sensing	10.3390/rs10050669	vegetation;remote sensing;geology;surface roughness;shore;ranging;waveform;lidar;topographic map;sand dune stabilization	HCI	80.19189231559275	-61.75115454946613	68696
ce668e2e4726bf234bdef4df92f0fc83ac5995fd	noise-robust spatial preprocessing prior to endmember extraction from hyperspectral data	geophysical image processing;imaging spectrometer;remote sensing deconvolution geophysical image processing image classification radiometry;image classification;aviris noise robust spatial preprocessing endmember extraction remotely sensed hyperspectral images spatial homogeneity index spectral based classification spatial spectral unmixing approach comparison synthetic hyperspectral data real hyperspectral data airborne visible infrared imaging spectrometer;noise robustness;infra red;radiometry;indexes;hyperspectral imaging signal to noise ratio image reconstruction indexes;image reconstruction;remote sensing;indexation;hyperspectral data;deconvolution;spectral unmixing;hyperspectral imaging;signal to noise ratio;hyperspectral image	This paper develops a noise-robust spatial preprocessing module which can be used prior to spectral unmixing of remotely sensed hyperspectral images. The method first derives a spatial homogeneity index which is relatively insensitive to the noise present in the original hyperspectral data. Then, it fuses this index with a spectral-based classification, obtaining a set of pure regions which are used to guide the unmixing process. An experimental comparison of the proposed method with other spatial-spectral unmixing approaches is conducted using both synthetic and real hyperspectral data collected by the Airborne Visible Infra-Red Imaging Spectrometer (AVIRIS). Our experiments indicate that spectral unmixing can benefit from the proposed pre-processing approach, in particular, when the noise level present in the original hypespectral scene is relatively high.	experiment;noise (electronics);preprocessor;statistical classification;stellar classification;synthetic data	Gabriel Martín;Antonio J. Plaza;Maciel Zortea	2011	2011 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2011.6049435	iterative reconstruction;full spectral imaging;database index;computer vision;contextual image classification;radiometry;infrared;deconvolution;hyperspectral imaging;signal-to-noise ratio;imaging spectrometer;physics;remote sensing	Vision	70.6095290734421	-64.3102799590874	68709
c3068d3c72bef22959f94c29682150927607bfa0	an area time efficient field programmable mersenne twister uniform random number generator	infrared;reconfigurable computing	Reconfigurable computing offers an attractive solution to accelerating infrared scene simulations. In infrared scene simulations, the modeling of a number of atmospheric and optical phenomena like scintillation, refraction, blurring due to lens optics and photon noise may be implemented in parallel. All of these require simultaneous and continual generation of random numbers. Furthermore, random number generation is only a small component of all of these algorithms . Current software random number generators are too slow whilst current hardware random number generators are plagued by issues such correlations and are not area efficient. We describe a reconfigurable computing based uniform random number generator based on the mersenne twister algorithm that is area time efficient and that does not suffer from correlations.	algorithm;hardware random number generator;list of code lyoko episodes;mersenne twister;random number generation;reconfigurable computing;shot noise;simulation;while	Vinay Sriram;David A. Kearney	2006			lagged fibonacci generator;parallel computing;random number generation;hardware random number generator;theoretical computer science;reconfigurable computing;pseudorandom number generator;random seed;lavarand;mersenne twister;computer science	EDA	63.94991966354583	-53.224854211364715	68722
f7bfe80efab14e79134b790cb7d55c5c35316446	coupling potential of icesat/glas and srtm for the discrimination of forest landscape types in french guiana	systeme d information geographique;tropical forest;laser;guyane francaise;foret;french guiana;icesat glas;srtm dem;gestion durable;tres haute resolution spatiale;lidar;indice de vegetation	The Shuttle Radar Topography Mission (SRTM) has produced the most accurate near ly global elevation dataset to date. Over vegetated areas, the measured SRTM elevations are the result of a complex interaction between radar waves and tree crowns. In this study, waveforms acquired by the Geoscience Laser Altimeter System (GLAS) were combined with SRTM elevations to discriminat e the five forest landscape types (LTs) in French Guiana. Two differences were calculated: (1) penetration depth, defined as the GLAS highest elevati ons minus the SRTM elevations, and (2) the GLAS centroid elevations minus the SRTM elevations. The results show that these differences were similar for the five LTs, and they increased as a function of the GLAS canopy height and of the SRTM roughness index. Next, a Random Forest (RF) classifier was used to analyze the coupling potential of GLAS and SRTM in the discrimination of forest landscape types in French Guiana. The parameters used in the RF classification were the GLAS canopy height, the SRTM roughness index, the in : International Journal of Applied Earth Observation and Geoinformation, vol. 33, n° 1 , 2014	geographic information system;motorola canopy;radio frequency;random forest;shuttle radar topography mission;spectral centroid	Ibrahim Fayad;Nicolas Baghdadi;Valéry Gond;Jean-Stéphane Bailly;Nicolas Barbier;Mahmoud El Hajj;Frédéric Fabre	2014	Int. J. Applied Earth Observation and Geoinformation	10.1016/j.jag.2014.04.005	meteorology;lidar;laser;geography;hydrology;physics;remote sensing		80.79989310854793	-60.50169049148864	68745
9a2b39fb2b3d6c1bd262c40f8ca144cb57093610	seagull: seam-guided local alignment for parallax-tolerant image stitching		Image stitching with large parallax is a challenging problem. Global alignment usually introduces noticeable artifacts. A common strategy is to perform partial alignment to facilitate the search for a good seam for stitching. Different from existing approaches where the seam estimation process is performed sequentially after alignment, we explicitly use the estimated seam to guide the process of optimizing local alignment so that the seam quality gets improved over each iteration. Furthermore, a novel structure-preserving warping method is introduced to preserve salient curve and line structures during the warping. These measures substantially improve the effectiveness of our method in dealing with a wide range of challenging images with large parallax.	image stitching;parallax	Kaimo Lin;Nianjuan Jiang;Loong Fah Cheong;Minh N. Do;Jiangbo Lu	2016		10.1007/978-3-319-46487-9_23	smith–waterman algorithm;artificial intelligence;computer vision;parallax;computer science;image warping;image stitching	Vision	55.03293322971923	-57.95696687389354	68755
636b5caef1c824c1447e50ee16187216180e04c5	a multivariate gaussian mixture model of linear prediction error for colour texture segmentation		This paper presents an algorithm for parametric supervised colour texture segmentation using a novel image observation model. The proposed segmentation algorithm consists of two phases: In the first phase, we estimate an initial class label field of the image based on a 2D multichannel complex linear prediction model. Information of both luminance and chrominance spatial variation feature cues are used to characterize colour textures. Complex multichannel version of 2D Quarter Plane Autoregressive model is used to model these spatial variations of colour texture images in CIE L*a*b* colour space. Overall colour distribution of the image is estimated from the multichannel prediction error sequence of this Autoregressive model. Another significant contribution of this paper is the modelling of this multichannel error sequence using Multivariate Gaussian Mixture Model instead of a single Gaussian probability. Gaussian parameters are calculated through Expectation Maximization on a training dataset. In second phase of the algorithm, initial class label field obtained through the first stage is spatially regularized by ICM algorithm to have the final segmented image. Visual and quantitative results for different number of components of Multivariate Gaussian Mixture Model are presented and discussed.	autoregressive model;color space;computability in europe;expectation–maximization algorithm;iterated conditional modes;matrix regularization;mixture model;pixel	Imtnan-Ul-Haque Qazi;Fatima Ghazi;Olivier Alata;Jean-Christophe Burie;Christine Fernandez-Maloigne	2009	2009 17th European Signal Processing Conference		computer vision;machine learning;pattern recognition;mixture model;mathematics;image segmentation	Vision	61.251557920281705	-71.11296996350485	68772
20c8d20ad5b3e160846d8780e84f7fe4080eb71e	full-reference video quality assessment considering structural distortion and no-reference quality evaluation of mpeg video	image coding;data compression;video signal processing;structural distortion;mpeg video;video compression;video quality;perceived video quality assessment;video sequences;testing;distortion measurement;video quality experts group;wavelet transforms;quality estimation;quality assessment;quality assessment testing distortion measurement video compression mathematical model tv image coding video sequences wavelet transforms lifting equipment;parameter estimation video signal processing data compression;objective quality measurement techniques;quality evaluation;objective quality measurement techniques full reference quality assessment perceived video quality assessment video quality experts group test data set structural distortion no reference quality evaluation quality estimation mpeg video;mathematical model;full reference;lifting equipment;quality measures;tv;parameter estimation;full reference quality assessment;no reference quality evaluation;test data set;video quality assessment;no reference	There has been an increasing need recently to develop objective quality measurement techniques that can predict perceived video quality automatically. This paper introduces two video quality assessment models. The first one requires the original video as a reference and is a structural distortion measurement based approach, which is different from traditional error sensitivity based methods. Experiments on the video quality experts group (VQEG) test data set show that the new quality measure has higher correlation with subjective quality evaluation than the proposed methods in VQEG’s Phase I tests for full-reference video quality assessment. The second model is designed for quality estimation of compressed MPEG video stream without referring to the original video sequence. Preliminary experimental results show that it correlates well with our full-reference quality assessment model.	data compression;distortion;moving picture experts group;streaming media;test data	Ligang Lu;Zhou Wang;Alan C. Bovik;Jack Kouloheris	2002		10.1109/ICME.2002.1035718	data compression;subjective video quality;computer vision;simulation;computer science;video quality;multimedia;rate–distortion optimization;pevq;statistics	Vision	63.20440330985562	-64.17412163723509	68834
c4ca9ab15a347ce2011060a1a65e07534d76f04e	hyperspectral image denoising with a spatial–spectral view fusion strategy	total variation hyperspectral image denoising spatial view spectral view;geophysical image processing;q weighted fusion algorithm hyperspectral image denoising spatial spectral view fusion strategy noisy hyperspectral 3d cube hyperspectral total variation algorithm;image fusion;noise reduction hyperspectral imaging noise adaptation models measurement tv;image fusion geophysical image processing hyperspectral imaging image denoising;image denoising;hyperspectral imaging	In this paper, we propose a hyperspectral image denoising algorithm with a Spatial-spectral view fusion strategy. The idea is to denoise a noisy hyperspectral 3-D cube using the hyperspectral total variation algorithm, but applied to both the spatial and spectral views. A metric Q-weighted fusion algorithm is then adopted to merge the denoising results of the two views together, so that the denoising result is improved. A number of experiments illustrate that the proposed approach can produce a better denoising result than both the individual spatial and spectral view denoising results.	algorithm;experiment;matrix regularization;noise reduction;spectral method	Qiangqiang Yuan;Liangpei Zhang;Huanfeng Shen	2014	IEEE Transactions on Geoscience and Remote Sensing	10.1109/TGRS.2013.2259245	full spectral imaging;computer vision;hyperspectral imaging;pattern recognition;image fusion;non-local means;physics;remote sensing	Vision	67.84454949164898	-66.59706087008063	68911
b1461c6a3847916f5f9e02d6e0a0267e28bcce47	using spatial data analysis for delineating existing mangroves stands and siting suitable locations for mangroves plantation		Article history: Received 28 May 2016 Received in revised form 30 January 2017 Accepted 4 August 2017 Available online xxxx Mangroves protect shorelines from waves and floods, help prevent coastal erosion by stabilizing sediments with their tangled root systems, serve as valuable nursery areas for fish and invertebrates. In addition, mangroves can play an important role in protecting the land from future seawater rise. Small mangrove stands are distributed along the Red Sea coast in Egypt as small patches, rarely exceed few square kilometers. These stands have been rapidly destroyed in recent years due to the rapid development tourist activities and old running problem of over grazing and using the trees as fuel. The current research aimed at delineating the existing mangroves stands within the area between El Quseir – Marsa Alam and finding the most suitable locations to plant mangroves trees. Sharm ElBahari was found to be the healthiest mangroves stands in the area. By interpreting the satellite images and field survey the four environmental factors controlling the growing of mangroves: physical and chemical properties of seawater, soil properties and coastal geomorphology. These factors were measured at Sharm El-Bahari site and considered the best environmental boundaries suitable for mangroves growing in the study area. With these values in mind, the sites suitable for mangroves plantation were located where these environmental requirements were met. Six sites suitable for mangroves plantation were identified; these sites were ranked using Analytic Hierarchy Process (AHP). 2017 Elsevier B.V. All rights reserved.	el torito (cd-rom standard);geographic information system;mind;motorola canopy;requirement;spatial analysis	Hesham Abd-El Monsef;Mohamed A. A. Hassan;Salah Shata	2017	Computers and Electronics in Agriculture	10.1016/j.compag.2017.08.002	computer vision;artificial intelligence;spatial analysis;agroforestry;mangrove;overgrazing;engineering;coastal geography;shore;coastal erosion;ecology	HCI	82.67572448998634	-55.20745619849152	68941
567aab3f9834eaead9952a4ce69577a0150f2300	polarimetric 3-d imaging with airborne holographic sar tomography over glaciers	image resolution;synthetic aperture radar tomography image resolution radar imaging ice apertures;polarimetric synthetic aperture radar polsar cryosphere compressive sensing cs fast factorized back projection ffbp holographic sar tomography holosar;radar imaging;bedrock vertical profile polarimetric 3 d imaging reconstruction airborne holographic sar tomography mode glacier backscattering cryosphere biosphere holosar campaign l band dlr f sar sensor findel glacier monte rosa switzerland polarimetric analysis single circular flight arc pattern circular pattern vertical synthetic aperture circular synthetic aperture snow vertical profile ice sheet vertical profile;tomography;sar technologie;ice;apertures;synthetic aperture radar airborne radar glaciology hydrological techniques radar polarimetry;synthetic aperture radar	This paper presents an assessment of the backscattering of glaciers in the holographic SAR tomography (HoloSAR) mode. The motivation of HoloSAR in the cryosphere is mainly driven by recent investigations in the biosphere that have shown the capabilities of this mode to reconstruct volumes with 3-D imaging reconstructions over 360 ° at very high resolution. To that end, an HoloSAR campaign was conducted at L-band by the DLR's F-SAR sensor over the Findel glacier, Monte Rosa, Switzerland. The first part of this study shows a polarimetric analysis of the resulting images of a single circular flight, where the arc- and circular patterns of the 2-D images in the (x, y) plane already indicate wave penetration. The second part presents 3-D images obtained by the combination of the circular and vertical synthetic apertures, which enable an estimation of the vertical profile of snow, ice sheets and bedrock.	airborne ranger;bedrock (framework);biosphere;dynamic language runtime;holographic interference microscopy;holography;image resolution;l band;polarimetry;switzerland;synthetic data;tomography	Octavio Ponce;Pau Prats;Rolf Scheiber;Andreas Reigber;Irena Hajnsek;Alberto Moreira	2015	2015 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)	10.1109/IGARSS.2015.7327026	meteorology;early-warning radar;aperture;space-based radar;synthetic aperture radar;image resolution;hydrology;tomography;radar imaging;inverse synthetic aperture radar;side looking airborne radar;physics;remote sensing	Vision	80.10097152165739	-62.91943811230426	68964
f602919312a660135beb6f3cd21a0b66d14ae139	locally optimum detectors for deterministic signals in multiplicative noise	gaussian noise;detectors;optimisation;tail length;speckle;reflectivity;edge detection;laser;linear correlation detector;signal detection;performance;sar imagery system;additive noise;correlation methods;deterministic signals;noise distribution;multiplicative noise;imaging system;optical imaging;image edge detection;radar imaging;generalized gaussian density;edge detection radar detection optimisation gaussian distribution gamma distribution correlation methods radar imaging synthetic aperture radar gaussian noise;locally optimum detectors;generalized gaussian distribution;gamma distribution;coherent imaging systems;radar detection;detectors signal detection additive noise power system modeling radar detection speckle image edge detection reflectivity optical imaging laser modes;gaussian noise deterministic signals multiplicative noise locally optimum detectors coherent imaging systems sar imagery system laser multiplicative noise distribution generalized gaussian distribution gamma distribution generalized gaussian density performance linear correlation detector tail length noise distribution edge detection;multiplicative noise distribution;power system modeling;laser modes;gaussian distribution;synthetic aperture radar	This paper addresses the problem of detecting deterministic signals in multiplicative noise. The multiplicative noise model is appropriate for modelling coherent imaging systems such as SAR and LASER. Locally Optimum (LO) detectors are derived for any arbit,rary multiplicative noise distribution. The gamma and generalized Gaussian distributions are studied in detail. We also iintroduce an extension of the generalized Gaussian densky to include asymmetry. The performance of the LO detectors is studied and compared with that of the linear correlation detector. The paper gives insight into the influence of the tail length of the noise distribution on the detection power.	coherence (physics);gamma correction;multiplicative noise;sensor	Mounir Ghogho;Asoke K. Nandi;Bernard Garel	1998		10.1109/ICASSP.1998.681568	normal distribution;speckle pattern;gaussian noise;gamma distribution;detector;synthetic aperture radar;edge detection;laser;performance;computer science;multiplicative noise;optical imaging;mathematics;generalized normal distribution;reflectivity;radar imaging;statistics;detection theory	ML	72.56179181754793	-63.75033338487959	69040
680923924de8238758728fd6e133355c93edbd85	virtual reality using the concentric mosaic: construction, rendering and data compression	compression algorithm;interpolation;image motion analysis;image coding;image segmentation;image resolution;data compression;real time;virtual reality;image motion analysis virtual reality image segmentation image resolution rendering computer graphics interpolation image coding data compression image reconstruction;image reconstruction;virtual reality rendering computer graphics image storage cameras photometry layout solid modeling bandwidth transform coding compression algorithms;image quality;300 mhz virtual reality concentric mosaic vertical slit images data compression image based rendering camera circular region parallax lighting changes image reordering image interpolation high resolution images bandwidth storage mpeg like compression algorithm access patterns image redundancies real time reconstruction image quality pentium ii pc;high resolution imager;image based rendering;rendering computer graphics	This paper proposes a new image based rendering technique called concentric mosaic for virtual reality applications. It is constructed by capturing vertical slit images when a camera is moving around a set of concentric circles. Concentric mosaic allows the user to move freely in a circular region and observe significant parallax and lighting changes without recovering the geometric and photometric scene model. The rendering of concentric mosaic is very efficient, which amounts to reordering and interpolating of previously captured slit images in the concentric mosaic. Concentric mosaic typically consists of hundreds of high-resolution images, which consumes significant amount of storage and bandwidth for transmission. A MPEG-like compression algorithm is therefore proposed in this paper taking advantages of the access patterns and redundancies of the mosaic images. Experimental results show that real-time reconstruction of novel views with good image quality can be achieved in a Pentium I1 300 MHz PC.	algorithm;data compression;image quality;image resolution;interpolation;mpeg transport stream;moving picture experts group;ncsa mosaic;parallax;real-time clock;virtual reality	Harry Shum;King To Ng;Shing-Chow Chan	2000		10.1109/ICIP.2000.899536	data compression;computer vision;computer science;virtual reality;multimedia;statistics;computer graphics (images)	Graphics	60.58258777042152	-54.0999848422968	69050
fbd2134038cf0d67440752d88c21cbc29f6d664a	automated regularization parameter selection in multi-scale total variation models for image restoration	order statistics;order statistic;spatial dependence;primal dual method;fenchel duality;semismooth newton method;image restoration;total variation regularization;hierarchical decomposition;confidence interval;qualitative study;parameter selection;expectation maximization;total variation;variance estimation;local variance estimator;spatially dependent regularization parameter	Multi-scale total variation models for image restoration are introduced. The models utilize a spatially dependent regularization parameter in order to enhance image regions containing details while still sufficiently smoothing homogeneous features. The fully automated adjustment strategy of the regularization parameter is based on local variance estimators. For robustness reasons, the decision on the acceptance or rejection of a local parameter value relies on a confidence interval technique based on the expected maximal local variance estimate. In order to improve the performance of the initial algorithm a generalized hierarchical decomposition of the restored image is used. The corresponding subproblems are solved by a superlinearly convergent algorithm based on Fenchel-duality and inexact semismooth Newton techniques. The paper ends by a report on numerical tests, a qualitative study of the proposed adjustment scheme and a comparison with popular total variation based restoration methods.	algorithm;circuit restoration;fenchel's duality theorem;image restoration;matrix regularization;maximal set;newton;numerical analysis;rejection sampling;smoothing	Yiqiu Dong;Michael Hintermüller;M. Monserrat Rincon-Camacho	2010	Journal of Mathematical Imaging and Vision	10.1007/s10851-010-0248-9	econometrics;mathematical optimization;order statistic;mathematics;statistics	Vision	53.909153842583414	-72.38736058006099	69299
6b389bcee1f2407c4e503b1a3818e859c3019253	plasmaspheric electron content inferred from residuals between gnss-derived and topex/jason vertical tec data		The plasmasphere, which is located above the ionosphere, is a significant component of Earth’s atmosphere, and the plasmasphere electron content (PEC) distribution is determined by different physical mechanisms to those of the ionosphere electron content (IEC). However, the observation for the PEC is very limited. In this study, we introduced a methodology (called zero assumption method, which is based on the assumption that PEC can reach zero) to extract the PEC over TOPEX/JASON (T/J) and global navigation satellite system (GNSS) overlapping areas. Results show that the daily systematic bias (T/J vertical TEC > GNSS-derived vertical TEC) for both low (2009) and high (2011) solar activity condition is consistent, and the systematic bias for JASON2 and JASON1 is different. We suggest that systematic biases predominantly arise from the sea state bias (SSB), especially the tracker bias. After removing the systematic bias, we extracted reliable PEC inferred from differences between GNSS-derived vertical TEC and T/J vertical TEC data. Finally, the characteristics of the plasmaspheric component distribution for different local times, latitudes, and seasons were investigated.	bittorrent tracker;electron;satellite navigation;super smash bros.;total electron content	Lei Liu;Yibin Yao;Jian Kong;Lulu Shan	2018	Remote Sensing	10.3390/rs10040621	geology;geodesy;satellite system;remote sensing;latitude;sea state;atmosphere;tec;ionosphere;gnss applications;plasmasphere	HCI	80.98777522049318	-66.62094582259039	69488
bf17dd4a2d11641d23080e52122c77136dd9059f	using binocular feature combination for blind quality assessment of stereoscopic images	measurement;binocular quality prediction stereoscopic image blind quality assessment binocular feature combination 3d image quality assessment monocular feature encoding;quality assessment;vectors;three dimensional displays;feature extraction;stereo image processing three dimensional displays feature extraction vectors quality assessment measurement solid modeling;期刊论文;solid modeling;stereo image processing;support vector regression binocular feature combination blind image quality assessment stereoscopic image;stereo image processing feature extraction image coding	The quality assessment of 3D images is more challenging than its 2D counterparts, and little investigation has been dedicated to blind quality assessment of stereoscopic images. In this letter, we propose a novel blind quality assessment for stereoscopic images based on binocular feature combination. The prominent contribution of this work is that we simplify the process of binocular quality prediction as monocular feature encoding and binocular feature combination. Experimental results on two publicly available 3D image quality assessment databases demonstrate the promising performance of the proposed method.	binocular vision;database;image quality;stereoscopy	Feng Shao;Kemeng Li;Weisi Lin;Gangyi Jiang;Mei Yu	2015	IEEE Signal Processing Letters	10.1109/LSP.2015.2413946	image quality;computer vision;feature detection;feature extraction;computer science;machine learning;pattern recognition;mathematics;solid modeling;feature;measurement;statistics;computer graphics (images)	Vision	62.387117623492045	-65.12510070918975	69681
e52f1ce577a59a8ad199c149383d0cf6a0f82021	the potential of the controlled source electromagnetic method: a powerful tool for hydrocarbon exploration, appraisal, and reservoir characterization	reservoir characterization;electromagnetic measurements;seismology;hydrocarbon reservoirs;controllability;signal to noise ratio enhancement;seismology deconvolution geophysical signal processing hydrocarbon reservoirs;geophysical signal processing;csem method;deconvolution;geophysical signal processing electromagnetic measurements seismic measurements controllability;controlled source electromagnetic method;hydrocarbon exploration;seismic measurements;seismic method;signal to noise ratio enhancement controlled source electromagnetic method hydrocarbon exploration reservoir characterization seismic method csem method deconvolution	In this article, we show that the controlled source electromagnetic (CSEM) method is complementary to the seismic method.	anton (computer);anton chuvakin;apache axis;bandwidth (signal processing);characterization test;continuous signal;data acquisition;download;emoticon;iterative method;microsoft windows;noise reduction;offset (computer science);real-time clock;signal-to-noise ratio;software propagation;stacking;synthetic data;version control;wavelet;whole earth 'lectronic link	Anton Ziolkowski;David Wright	2012	IEEE Signal Processing Magazine	10.1109/MSP.2012.2192529	controllability;computer science;deconvolution;reservoir modeling	Visualization	77.87543408287786	-67.17007974254945	69712
fc48dcdda774452c47b65d27a0413748237e337e	medieval archaeology under the canopy with lidar. the (re)discovery of a medieval fortified settlement in southern italy		Despite the recognized effectiveness of LiDAR in penetrating forest canopies, its capability for archaeological prospection can be strongly limited in areas covered by dense vegetation for the detection of subtle remains scattered over morphologically complex areas. In these cases, an important contribution to improve the identification of topographic variations of archaeological interest is provided by LiDAR-derived models (LDMs) based on relief visualization techniques. In this paper, diverse LDMs were applied to the medieval site of Torre Cisterna to the north of Melfi (Southern Italy), selected for this study because it is located on a hilly area with complex topography and thick vegetation cover. These conditions are common in several places of the Apennines in Southern Italy and prevented investigations during the 20th century. Diverse LDMs were used to obtain maximum information and to compare the performance of both subjective (through visual inspections) and objective (through their automatic classification) methods. To improve the discrimination/extraction capability of archaeological micro-relief, noise filtering was applied to Digital Terrain Model (DTM) before obtaining the LDMs. The automatic procedure allowed us to extract the most significant and typical features of a fortified settlement, such as the city walls and a tower castle. Other small, subtle features attributable to possible buried buildings of a habitation area have been identified by visual inspection of LDMs. Field surveys and in-situ inspections were carried out to verify the archaeological points of interest, microtopographical features, and landforms observed from the DTM-derived models, most of them automatically extracted. As a whole, the investigations allowed (i) the rediscovery of a fortified settlement from the 11th century and (ii) the detection of an unknown urban area abandoned in the Middle Ages.	motorola canopy;software archaeology	Nicola Masini;Fabrizio Terenzio Gizzi;Marilisa Biscione;Vincenzo Fundone;Michele Sedile;Maria Sileo;Antonio Pecci;Biagio Lacovara;Rosa Lasaponara	2018	Remote Sensing		geology;medieval archaeology;cartography;remote sensing;vegetation;visual inspection;landform;lidar;topographic map;digital elevation model;urban area	HCI	79.48540228870142	-58.12809355081187	69716
6ea60012a7ab7a77b6a3cb1203173e26f43e8721	analysis of china grassland resource dynamic under different aridity based on gis and rs	grass;vegetation mapping;degradation;interpolation;tm images;irrigation;water resources;geometry;ad 2000;geomorphology;gis;degeneration;tm images ad 1995 ad 2000 geomorphology terrain mapping china land use agriculture geography remote sensing vegetation mapping grass grassland farming hydrology spatial distribution;land use;spatial distribution;rs;geographic information systems;grassland;remote sensing;ad 1995;grassland dynamic;hydrology;urban area;agriculture;image analysis;farming;analysis;terrain mapping;geographic information systems soil degradation irrigation remote sensing geometry interpolation water resources image analysis content addressable storage;aridity;china;content addressable storage;soil;hydrology geography vegetation mapping agriculture farming remote sensing;geography	This paper studies on dynamics of Chinese grassland resources during 1995 and 2000 under different aridity supported by GIS and RS based on TM images. We get the grassland dynamic coverage under MGE environment by contrasting 1995 and 2000 TM images. The results show there is an obvious zonal distribution under different aridity; grassland is changed to farmland in high cover grassland, especially at 4,5,6 degree which mainly distributes in west and north of China; grassland was replaced by urban areas at each aridity and grassland degradation. The change area between grassland changed into farmland and grassland is about same, but shifting into farmland shows the grassland decrease; a lot of grassland is changed into forest. With the aridity degree increasing, the degradation becomes serious, especially at 4,5 degree. But at I degree, the main change is that grassland changed to forest. The urban takes place of grassland in each aridity. But the mainly change is becoming farmland and grassland and grass resource having different degree degeneration. The main reason of grassland changing into farmland is population pressure; grassland degradation is caused by over graze etc.	gis and rs (university of pune);geographic information system	Yarong Zou;Zengxiang Zhang;Xiaoli Zhao;Quanbin Zhou;Bin Liu	2002		10.1109/IGARSS.2002.1026778	agriculture;image analysis;geology;soil science	HPC	82.86445269988744	-56.019550698194344	69825
05a7932a180a99cb453ac035de354edb10742e32	echo correlation analysis of targets with dominant scatterers in diversity mimo radar	analytical models;frequency diversity;spatial diversity;scattering;radar signal processing correlation methods electromagnetic wave scattering mimo radar;mimo radar;scattering correlation coefficient correlation mimo radar analytical models frequency diversity spatial diversity;correlation;correlation coefficient;spatial frequency diversity mimo radar target echo correlation analysis dominant scatterer model complex scattering intensity boundary scattering structure correlation coefficient;dominant scatterer mimo correlation coefficient	A huge limitation of the correlation analysis in existing scatterer model is that the former model, only consisting of uniformly distributed scatterers, ignores the variability of complex scattering intensity in real situation. In fact, each part of the target has a different scattering architecture. Moreover, the scattering intensity of pinnacle or boundary scattering structure is an order of magnitude larger than the normal scatterers. To solve this problem, this paper studies the correlation coefficient for scattering model which has several dominant scatterers in spatial-frequency diversity MIMO radar. And the positions of the dominant scatterers assumed to be variables to make an equivalent of different real targets. The proposed analysis enhances the authenticity of scattering model and can simulate the real model accurately. Simulation results show the effectiveness of the proposed approach.	coefficient;heart rate variability;mimo;simulation	Jieyi Liu;Linrang Zhang;Shanshan Zhao;Nan Liu;Juan Zhang	2016	2016 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)	10.1109/IGARSS.2016.7729177	antenna diversity;diversity scheme;optics;scattering;correlation;physics;remote sensing	Embedded	80.81489015560348	-68.64107585104432	69901
722052d7f81df5aa125872216c0c9698db459c56	today's image capturing needs: going beyond color management.				Chris Tuijn;Wim Cliquet	1997			color management;artificial intelligence;computer vision;computer science	Vision	62.655957971041836	-56.38651950979364	69914
dee80c3c5dc2e922a0d421332ba0d4b71cc7e079	optical design of high resolution and shared aperture electro-optical/infrared sensor for uav remote sensing applications	detectors;optical refraction;optical design optical imaging optical sensors optical refraction lenses detectors;infrared dual band imaging system visible light dual band imaging system compact structure suitable field of view high resolution coverage optical design unmanned aerial vehicle remote sensing applications target reconnaissance surveillance precision target location cost effective systems light weight systems visible band short wave infrared band band zemax software common refractive system dichroic beam splitter long wave infrared imaging system uncooled microbolometer focal plane array detector pixel size optical system design technical performance requirements compact size high resolution shared aperture electrooptical sensor optical design high resolution shared aperture infrared sensor optical design visible dual band imaging system;optical imaging;lenses;remote sensing autonomous aerial vehicles electro optical devices focal planes infrared detectors optical beam splitters optical design techniques optical sensors;optical sensors;optical design;lwir uav remote sensing optical design dual band	The increased requirement for visible light/infrared dual band imaging systems with compact structure, suitable field of view (FOV), high resolution coverage and without significantly complicates the optical design is increasing. Such systems are particularly desirable for unmanned aerial vehicle (UAV) remote sensing applications where increased levels of target reconnaissance, surveillance, precision target location and designation are required in cost-effective and light weight systems. Therefore, in this paper, a high resolution Electro-optical/infrared (EO/IR) sensor to simultaneously operate in the visible band and short wave infrared band (SWIR) band using ZEMAX software are presented. It has a common aperture using common refractive system and the spectrum is separated using a dichroic beam splitter. A long wave infrared (LWIR) imaging system based on uncooled microbolometer focal plane array (FPA) detector with pixel size equal to 17μm is presented. The results of the optical systems design indicated that our proposed approaches meet the technical performance requirements for high image performance and compact size. This system can be applied in UAV remote sensing applications.	aerial photography;demultiplexer (media file);dichroism;focal (programming language);field of view in video games;image resolution;microbolometer;pixel;requirement;staring array;systems design;unmanned aerial vehicle	Alaaeldin Mahmoud;Dong Xu;Lijun Xu	2016	2016 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)	10.1109/IGARSS.2016.7729754	detector;optoelectronics;optical imaging;lens;optical engineering;optics;physics;remote sensing	Embedded	78.91823913104092	-68.82145843374474	69956
df44746be177d833b85dd475c4bd8cc485c82528	optimized construction of icc profiles by lattice regression		We focus on a recently proposed regression framework termed lattice regression, as applied to the construction of multidimensional color management look-up tables from empirical measurements. The key idea of lattice regression is that the construction of a look-up table should take into account the interpolation function used in its final implementation. Lattice regression solves for the look-up table (LUT) that minimizes the error of interpolating the empirical measurements (training samples) and regularization is added to promote smoothness and enable extrapolation. The main contribution of this paper is the proposal and analysis of using the thin-plate regularizer for lattice regression to produce smooth and accurate color transformations. Experiments with a consumer inkjet and laser printer show that the proposed regularizer obtains similar accuracy to the previously-proposed (and more complicated) combination of Laplacian and globalbias regularizers, and that both can create significantly more accurate and smoother results than a state-of-the-art locally linear approach. Estimation for Color Transformations It is common to transform colors between colorspaces and devices by first characterizing the transformation with a look-up table (LUT), and then interpolating the LUT to transform new color values. The LUT can be specified in an International Color Consortium (ICC) profile, which is part of a standard color management workflow. In this paper we consider the estimation question of how to best specify a LUT to characterize a color transformation. Recently, we proposed a new approach called lattice regression for learning a LUT from sample pairs of input and output colors that takes into account that the LUT is interpolated at runtime [6, 7], but that preliminary work required a complicated regularizer in order to perform well in practice. In this paper, we show that similar results can be achieved using the more elegant thin-plate regularizer [8]. For simplicity, and because it is a common case, we refer throughout to the input color space as CIELAB and the output color space as RGB, but everything applies to transformations between any two colorspaces. We call the LUT defined over the input color space the lattice a, which has vertices {a1,a2, . . . ,am}, where each vertex ai ∈ CIELAB. Then the goal is to learn the output RGB color for each ai. We treat each of the output color planes separately so that the output color corresponding to vertex ai is the scalar color value bi ∈ [0,255]. Printing a calibration target results in data pairs {xi,yi}, where xi ∈ CIELAB, yi ∈ [0,255] and i = 1...n, where n is the number of color patches in the calibration target. The standard approach to learning a color transformation is to first fit a function to the data pairs {xi,yi} to produce an estimated function f̂ that maps CIELAB to [0,255]. Then, the estimated function f̂ is evaluated at the the vertices of the lattice. That is, the estimated output value for ai is b̂i = f̂ (ai). Mathematically, the estimated function f̂ is chosen to minimize the sum of some loss function, usually squared error as shown here: f̂ = arg min f∈F n ∑ i=1 ( f (xi)− yi), (1) where F is a set of allowed functions. For example, standard least-squares linear regression is (1) with F being the set of all linear functions f (x) = β T x+β0. Neural nets, decision trees, and support vector machine regression and other standard approaches to regression can be written as (1) for different choices of F , sometimes with a different loss function than squared error, and sometimes with additional regularization terms that are independent of the data but add a preference for smoother functions in the function class F . Many such regression methods have been compared for learning ICC profiles [1, 2, 11]. Bala’s experiments showed that the best accuracy was obtained with a local linear regression [2]. Roughly 20% improvement in median accuracy was achieved over local linear regression using the enclosing neighborhood definition and ridge regularization [9], and further accuracy improvements were shown if the ridge regularizer was replaced by a Tikhonov regularizer [10]. Another metric in the creation of ICC profiles is whether smooth images input to the LUT appear smooth after the LUT interpolation [14, 15]. Lattice Regression The problem with the standard approach described by (1) is that the LUT will be interpolated at run-time to actually estimate output color values for an image, and this interpolation step is not taken into account in fitting the function by (1). For example, if one used the LUT to estimate the appropriate RGB color for a training sample xi, the output of the lookup table is not f̂ (xi), rather it is the interpolation of xi from the vertex-output pairs {(ai, b̂i)} that surround xi. Thus, the error being minimized in (1) does not represent the true error produced by the LUT. Lattice regression takes into account the LUT interpolation, and directly chooses the m×1 vector of output values b such that the interpolated training CIELAB colors will be close to their corresponding RGB output values. A training point xi in CIELAB falls in a cell of the lattice with eight vertices; the jth vertex in the lattice is given a linear interpolation weight wi j ≥ 0, where wi j = 0 if a j is not a vertex of the cell containing xi, and otherwise wi j is set so that linear interpolation equations hold: ∑ j wi ja j = xi, and ∑ j wi j = 1 (see [6] for more on calculating linear interpolation weights). The LUT then interpolates the input CIELAB value xi as ŷi = ∑ j wi jb j. Lattice regression minimizes the post-interpolation error on the training data. That is, it chooses the m× 1 vector of output values b̂ that solve, b̂ = arg min b∈[0,255]m n ∑ i=1 (ŷi− yi) . = arg min b∈[0,255]m n ∑ i=1 (( ∑ j wi jb j ) − yi )2	artificial intelligence;artificial neural network;color management;color space;consortium;decision tree;emoticon;experiment;extrapolation;input/output;laser printing;least squares;linear function;linear interpolation;lookup table;loss function;map;maxima and minima;parameter (computer programming);printer (computing);run time (program lifecycle phase);support vector machine	Eric K. Garcia;Maya R. Gupta	2010			arg max;mathematical analysis;computer vision;artificial intelligence;local regression;linear interpolation;icc profile;interpolation;algorithm;rgb color model;linear regression;color space;mathematics	ML	65.56524708998357	-60.055737639964214	70061
36daf6b44cd8499a1321f714bb75d73b915d553a	clustered-dot color halftone watermarks using spatial frequency and color separability	printing;metodo separacion;filigranage numerique;protection information;digital watermarking;separation method;halftones;modulation phase continue;phase modulation;spatial frequencies;scanneur;spectrum;escaner;separability;scanner;scanners;separabilidad;proteccion informacion;information protection;frequence spatiale;filigrana digital;impression;continuous phase modulation;separabilite;methode separation;frecuencia espacial;impresion;spatial frequency;continuous phase modulated	A framework for clustered-dot color halftone watermarking is proposed. Watermark patterns are embedded in the color halftone on per-separation basis. For typical CMYK printing systems, common desktop RGB color scanners are unable to provide the individual colorant halftone separations, which confounds per-separation detection methods. Not only does the K colorant consistently appear in the scanner channels as it absorbs uniformly across the spectrum, but cross-couplings between CMY separations are also observed in the scanner color channels due to unwanted absorptions. We demonstrate that by exploiting spatial frequency and color separability of clustered-dot color halftones, estimates of the individual colorant halftone separations can be obtained from scanned RGB images. These estimates, though not perfect, allow per-separation detection to operate efficiently. The efficacy of this methodology is demonstrated using continuous phase modulation for the embedding of per-separation watermarks.	channel (digital image);desktop computer;embedded system;linear separability;modulation;printing;simulation	Basak Oztan;Gaurav Sharma	2010		10.1117/12.839293	color histogram;rgb color model;computer vision;color depth;telecommunications;rgb color space;high color;spatial frequency;optics;color space;physics	ML	54.05774191992684	-61.140927975208236	70076
33a0240b7257246d80ce6feb450a432ad66f5e85	bistatic border effects modelling in forest scattering	shadow mapping;vegetation mapping;electromagnetic scattering;bistatic coherent polarimetric model;radar remote sensing;radar interferometry;vegetation mapping electromagnetic wave scattering radar interferometry radar polarimetry remote sensing by radar;bistatic capability;interferometric capability;radiometry;remote sensing by radar;radar scattering;electromagnetic wave scattering;statistical distributions;radar polarimetry;forest scattering border effects bistatic coherent polarimetric model;character generation;sar image;bistatic border effects modelling;radar remote sensing bistatic border effects modelling forest scattering electromagnetic wave scattering shadowing effects coherent scattering model forest regions polarimetric capability interferometric capability bistatic capability;border effects;electromagnetic modeling;electromagnetic scattering radar scattering soil electromagnetic modeling shadow mapping radiometry radar polarimetry frequency character generation statistical distributions;forest scattering;border effect;coherent scattering model;frequency;soil;polarimetric capability;shadowing effects;forest regions;electromagnetic waves	Simulating forest scattering by electromagnetic waves has been proposed with both coherent and incoherent models. However, to our best knowledge, most models consider a description of the forest as infinite in the horizontal plane and layered vertically. Such description is relevant in most cases, but fail when border effects are present near the boundaries : the shadowing effects as well as the reinforcement ones, which are present in true SAR images, are absent in the synthetic images. The purpose of this study is to present a coherent scattering model taking into account forest regions of finite extent and benefit from its polarimetric, interferometric and bistatic capabilities to bring out interesting outlooks about border effect in the bistatic case.	coherence (physics);polarimetry;synthetic intelligence;the forest	Ludovic Villard;Pierre Borderies;Pascale Dubois-Fernandez;Jean-François Nouvel	2007	2007 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2007.4423314	meteorology;probability distribution;electromagnetic radiation;radiometry;frequency;shadow mapping;optics;physics;quantum mechanics;remote sensing	Vision	82.75348873132008	-66.28743040769747	70139
4c3f8ac75cb84c43d161e94a3bdb074d796f4dd6	scalable algorithms for large high-resolution terrain data	massive data;high resolution;gis;terrain modeling;lidar	In this paper we demonstrate that the technology required to perform typical GIS computations on very large high-resolution terrain models has matured enough to be ready for use by practitioners. We also demonstrate the impact that high-resolution data has on common problems. To our knowledge, some of the computations we present have never before been carried out by standard desktop computers on data sets of comparable size.	algorithm;computation;desktop computer;geographic information system;image resolution	Thomas Mølhave;Pankaj K. Agarwal;Lars Arge;Morten Revsbæk	2010		10.1145/1823854.1823878	simulation;geography;data mining;remote sensing	Visualization	72.06483203559142	-54.560311722322034	70169
498505a72657725d133f6ab360e115e36427bd57	observing shape from defocused images	image restoration;prior knowledge;three dimensional;surface geometry;shape;shape from focus;low level vision;shape from defocus	Accommodation cues are measurable properties of an image that are associated with a change in the geometry of the imaging device. To what extent can three-dimensional shape be reconstructed using accommodation cues alone? This question is fundamental to the problem of reconstructing shape from focus (SFF) and shape from defocus (SFD) for applications in inspection, microscopy, image restoration and visualization. We address it by studying the “observability” of accommodation cues in an analytical framework that reveals under what conditions shape can be reconstructed from defocused images. We do so in three steps: (1) we characterize the observability of any surface in the presence of a controlled radiance (“weak observability”), (2) we conjecture the existence of a radiance that allows distinguishing any two surfaces (“sufficient excitation”) and (3) we show that in the absence of any prior knowledge on the radiance, two surfaces can be distinguished up to the degree of resolution determined by the complexity of the radiance (“strong observability”). We formulate the problem of reconstructing the shape and radiance of a scene as the minimization of the information divergence between blurred images, and propose an algorithm that is provably convergent and guarantees that the solution is admissible, in the sense of corresponding to a positive radiance and imaging kernel.	algorithm;circuit restoration;image restoration	Paolo Favaro;Andrea Mennucci;Stefano Soatto	2003	International Journal of Computer Vision	10.1023/A:1022366408068	image restoration;three-dimensional space;computer vision;shape;mathematics;geometry	Vision	55.16812478243813	-52.504373331399	70238
f186aff35cf554ce0d558bb802c2ffd447792342	a novel noise-free pixels based impulse noise filtering	filtering;iterative process;genetic program;iterative methods filtering theory genetic algorithms image denoising impulse noise;impulse noise density noise free pixel impulse noise filtering iterative impulse noise removal iterative process genetic programming gp based estimator;image restoration impulse noise genetic programming estimation;impulse noise;image restoration;genetic programming;gp based estimator;noise measurement;pixel noise noise measurement image restoration filtering adaptive filters arrays;arrays;iterative methods;adaptive filters;estimation;pixel;noise free pixel;impulse noise density;genetic algorithms;image denoising;iterative impulse noise removal;impulse noise filtering;filtering theory;noise	Generally, impulse noise filtering schemes consider all pixels within a large neighborhood. However, the estimate from all pixels within the neighborhood may not be accurate. Moreover, large window may remove edges and fine details. In contrast to this approach, we propose iterative impulse noise removal scheme that emphasizes on few noise-free pixels within a small neighborhood. This iterative process continues until all noisy pixels are replaced with the estimated values. To estimate the optimal value of noisy pixel, we developed genetic programming (GP) based estimator using noise-free pixels. The estimator is constituent of useful local pixels information. Experimental results show that the proposed scheme is capable of removing impulse noise effectively while preserving the fine details. Especially, our approach has shown effectiveness against high impulse noise density.	genetic programming;impulse noise (audio);iterative method;optimization problem;pixel	Abdul Majid;M. Tariq Mahmood;Tae-Sun Choi	2010	2010 IEEE International Conference on Image Processing	10.1109/ICIP.2010.5651975	filter;adaptive filter;genetic programming;image restoration;computer vision;mathematical optimization;estimation;genetic algorithm;dark-frame subtraction;impulse noise;computer science;noise measurement;noise;iterative and incremental development;mathematics;iterative method;pixel;salt-and-pepper noise	Robotics	56.425217877803455	-65.8982029835974	70356
53c6b4a6ebf3dfcb3e6d68406b8762353bddc379	progressive scan conversion based on edge-dependent interpolation using fuzzy logic	fuzzy logic	De-interlacing algorithms realize the interlaced to progressive conversion required in many applications. The most cost efficient are intra-field techniques, which interpolate pixels of the same field. Some of these methods use the upper and lower line pixels. Among them, the ELA algorithm is widely employed since it reconstructs the edges of the de-interlaced image with more accuracy eliminating nondesired problems such as blurring and staircase effects. However, the ELA algorithm does not perform well when there are non clear edges or in presence of noise. In order to reduce these drawbacks, a new algorithm is presented in this paper. It is based on a simple fuzzy system which models heuristic rules to improve the ELA algorithm. Two enhancements of this new algorithm are also presented in this paper. Simulation results of video sequences prove the advantageous of the new algorithms.	algorithm;algorithmic efficiency;computation;cost efficiency;fuzzy control system;fuzzy logic;heuristic;interlaced video;interlacing (bitmaps);interpolation;pixel;progressive scan;simulation	Piedad Brox Jiménez;Iluminada Baturone;Santiago Sánchez-Solano	2005			fuzzy logic;fuzzy set operations;defuzzification;adaptive neuro fuzzy inference system;fuzzy associative matrix;computer vision;cost efficiency;artificial intelligence;fuzzy classification;fuzzy control system;computer science	Graphics	57.78934756473011	-64.86434416113802	70424
43dbd2cd93f9cf95f04137be2a5d55fc1298613f	relaxation labelling based land masking in sar images		In this paper, a relaxation labelling based land masking method is proposed for separating sea and land in SAR images. Land masking, also known as sea-land segmentation, is a part of ship detection system for SAR images to avoid detecting false alarms in the land. Relaxation labeling is an iterative method, which can separate foreground pixels from background ones using the neighborhood information of pixels in the image. When relaxation labelling converges, the segmented result is often unsatisfactory, since it tends to label more foreground pixels. To overcome this issue, a loss composed of the background probability distribution diversity and the gradient magnitude of the result is introduced to indicate when to stop the iteration. Experimental results on several Gaofen-3 SAR images demonstrate the effectiveness of the proposed method.	gradient;iteration;iterative method;lagrangian relaxation;linear programming relaxation;pixel;relaxation (approximation);relaxation labelling;sensor;unsharp masking	Zongxu Pan;Lei Liu;Bin Lei	2018	IGARSS 2018 - 2018 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2018.8518603	probability distribution;pixel;iterative method;computer vision;magnitude (mathematics);image segmentation;synthetic aperture radar;artificial intelligence;masking (art);relaxation labelling;computer science	Vision	55.61607638488816	-63.03571106547525	70459
0a454430c3937d36fcb0d08b51bc2191af5d75f8	depth enhancement considering just noticeable difference in depth	human visual system;just noticeable difference			Seung-Won Jung;Sung-Jea Ko	2012	IEICE Transactions		just-noticeable difference;computer vision;computer science;human visual system model	Visualization	62.09353456361081	-62.962588557291795	70577
27f2450fe3860cb75667ca087170bc71f949ac89	joint space-time interpolation for distorted linear and bistatic array geometries	radar aeroporte;grado libertad;evaluation performance;metodo estadistico;senal salida;clutter;interpolation;configuracion lineal;performance evaluation;output signal;degree of freedom;evaluacion prestacion;linear array;simulation;space time adaptive processing stap;matrice covariance;simulacion;statistical method;array signal processing;configuration lineaire;matriz covariancia;space time;matrix inversion;small samples;espacio tiempo;inversion matriz;carta de datos;linear antenna arrays;linear configuration;relacion senal interferencia ruido;signal to interference plus noise ratio;fouillis echo;antenne reseau lineaire;statistical analysis;rapport signal interference bruit;monostatic arrays;methode statistique;linear interpolation;covariance matrices;mappage;confusion eco;space time adaptive processing stap bistatic interpolation monostatic arrays;transformation lineaire;time adaptive processing stap bistatic interpolation monostatic arrays;linear transformation;inversion matrice;interpolation lineaire;bistatic;airborne radar;radar aerotransportado;mapping;statistical analysis space time adaptive processing interpolation array signal processing covariance matrices clutter airborne radar radar signal processing;freedom degree;radar signal processing;espace temps;airborne radar scenario joint space time interpolation technique distorted linear monostatic arrays linear bistatic array geometry space time adaptive processing clutter covariance matrix monostatic linear arrays arbitrary intersensor spacing signal to interference plus noise ratio;space 8211;transformacion lineal;interpolacion lineal;covariance matrix;signal sortie;degre liberte;space time adaptive processing;traitement adaptatif spatiotemporel;interpolation geometry clutter adaptive arrays covariance matrix training data doppler radar signal to noise ratio airborne radar frequency	"""This paper presents a new joint space-time interpolation technique (STINT) to improve the small sample support performance of space-time adaptive processing (STAP) with distorted linear monostatic arrays and linear bistatic array configurations. Brennan's rule for the space-time clutter covariance matrix rank is extended to monostatic linear arrays with arbitrary intersensor spacing, distorted linear arrays and bistatic geometries. It is shown that both distortion in the array geometry and bistatic operation increase the clutter rank and cause the space-time clutter covariance matrix to become range dependent. This results in lower output signal-to-interference-plus-noise ratio (SINR) for the same number of adaptive degrees of freedom and reduced available sample support. This motivates the development of the STINT technique aimed at compensating for the clutter rank inflation, while also making the clutter statistics appear more stationary across range. More specifically, a linear transformation is designed that maps the received clutter across space and time to that which would be received by a """"virtual"""" monostatic side-looking ULA. By mapping the data to form a reduced rank clutter covariance matrix, fewer snapshots are needed for a statistically stable matrix inversion as required in STAP, thereby improving the short observation time performance. Simulation results for a typical airborne radar scenario indicate up to 10-dB SINR improvement can be obtained using STINT with limited sample support."""	airborne ranger;charge-coupled device;clutter;distortion;gate array;interference (communication);interpolation;map;signal-to-interference-plus-noise ratio;simulation;space-time adaptive processing;stationary process;velocity (software development);whole earth 'lectronic link;zero suppression	Vijay Varadarajan;Jeffrey L. Krolik	2006	IEEE Transactions on Signal Processing	10.1109/TSP.2005.862941	covariance matrix;signal-to-interference-plus-noise ratio;telecommunications;interpolation;space-time adaptive processing;bistatic radar;space time;mathematics;clutter;linear map;degrees of freedom;linear interpolation;statistics	Visualization	76.16815225604944	-67.89381358972487	70741
227198e66716e3a5f4796b28043ddf28852482f0	robust sparse unmixing of hyperspectral data	libraries;matching pursuit algorithms;state of the art algorithm hyperspectral data sparse unmixing remote sensing image analysis su method linear mixing model nonlinear effect lmm traditional su algorithm norm loss function sparse unmixing method alternative direction multiplier method admm rsu problem hyperspectral su problem;robust sparse unmixing rsu hyperspectral data ℒ 2;hyperspectral imaging robustness signal to noise ratio libraries matching pursuit algorithms;robustness;hyperspectral imaging;signal to noise ratio;1 norm non linear effects outlier;remote sensing geophysical image processing hyperspectral imaging	Sparse unmixing (SU) of hyperspectral data has recently received particular attention for analyzing remote sensing images, which aims at finding the optimal subset of signatures to best model the mixed pixel in the scene. However, most SU methods are based on the commonly admitted linear mixing model (LMM), which ignores the possible nonlinear effects (i.e. nonlinearity), and the nonlinearity is merely treated as outlier. Besides, the traditional SU algorithms often adopt the ℒ2 norm loss function, which makes them sensitive to noises and outliers. In this paper, we propose a robust sparse unmixing (RSU) method with ℒ2,1 norm loss function, which is robust for noises and outliers. Then, the RSU can be solved by the alternative direction method of multipliers (ADMM). Finally, experiments on synthetic datasets demonstrate that the proposed RSU is efficient for solving the hyperspectral SU problem compared with state-of-the-art algorithms.	algorithm;experiment;loss function;nonlinear system;pixel;robustness (computer science);sparse matrix;synthetic intelligence;type signature	Yong Ma;Chang Li;Jiayi Ma	2016	2016 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)	10.1109/IGARSS.2016.7730618	computer vision;computer science;hyperspectral imaging;machine learning;pattern recognition;mathematics;signal-to-noise ratio;physics;robustness;remote sensing	Vision	68.93215240132703	-66.33642299751574	70786
9bdf070ac288ab5e340014efb5456f2c810b99d5	coastal mapping and change detection using high-resolution ikonos satellite imagery	change detection;human interaction;high resolution;shoreline change;digital elevation model;automatic generation;coastal zone;lake erie;satellite imagery;coastal area	Shoreline mapping and shoreline change detection are critical in many coastal zone applications. This paper presents results of the semi-automatic mapping of a coastal area of Lake Erie using 4-meter resolution multispectral (XS) and 1-meter resolution panchromatic (Pan) IKONOS Geo stereo images. An overview of the geometric processing of IKONOS imagery is presented. Then, the latest results of our IKONOS geopositioning accuracy improvement efforts are reported. Subsequently, methods and results of automatic generation of a Digital Elevation Model (DEM) and an orthoimage are outlined. Finally, a novel approach for the automatic extraction of a 3D shoreline from IKONOS images is described. Test results show that the proposed approach is capable of extracting shorelines from IKONOS images with little human interaction. The accuracies of the extracted shorelines from 4m XS and 1m Pan stereo images are estimated to be 8.5m and 2-3m, respectively.	digital elevation model;multispectral image;semiconductor industry;xs (perl)	Kaichang Di;Ruijin Ma;Jue Wang;Ron Li	2003			geography;cartography;remote sensing	Robotics	76.73431102852136	-57.8389096981429	70807
2a244f75fe7909f2cbc8b555e178613191912957	cache-aware sampling strategies for texture-based ray casting on gpu	scheduling benchmark testing cache storage graphics processing units image sampling image texture parallel processing rendering computer graphics resource allocation;casting;instruction sets graphics processing units rendering computer graphics benchmark testing casting algorithm design and analysis message systems;message systems;graphics processing units;microbenchmarking cache aware sampling strategies texture based ray casting memory intensive ray casting algorithm texture based volume rendering method blind computational resource mapping texture memory incoherent access pattern scheduling unit cuda texture cache hit rate sampling strategy computation to core mapping double buffer approach gpu operation parallel execution rendering performance warp marching algorithm;rendering computer graphics;algorithm design and analysis;benchmark testing;instruction sets	As a major component of volume rendering, the ray casting algorithm is memory-intensive. However, most existing texture-based volume rendering methods blindly map computational resources to texture memory and result in an incoherent access pattern, causing low cache hit rates in certain cases. The distance between samples taken by threads of the same scheduling unit (e.g. a warp of 32 threads in CUDA), of the GPU is a major factor that affects the texture cache hit rate. Based on this fact, we present a new sampling strategy, i.e. warp marching, which displays a novel computation-to-core mapping. In addition, a double buffer approach is introduced and special GPU operations are leveraged to improve the efficiency of parallel executions. To keep a roughly constant rendering performance when rotating the volume, we change our warp marching algorithm, so that samples can be taken along different directions of the volume. As a result, varying texture cache hit rates in different viewing directions are averaged out. Through a series of micro-benchmarking and real-life data experiments, we rigorously analyze our sampling strategies, and demonstrate significant performance enhancements over existing sampling methods.	algorithm;alpha compositing;cuda;cache (computing);computation;computational resource;distributed computing;experiment;fast marching method;glossary of computer graphics;graphics processing unit;hardware acceleration;marching cubes;marching squares;multiple buffering;out-of-core algorithm;point in polygon;ray casting;real life;sampling (signal processing);scheduling (computing);simulation;texture memory;volume rendering;workstation	Junpeng Wang;Fei Yang;Yong Cao	2014	2014 IEEE 4th Symposium on Large Data Analysis and Visualization (LDAV)	10.1109/LDAV.2014.7013200	parallel computing;computer hardware;rendering;computer science;texture mapping unit;real-time computer graphics;texture memory;alternate frame rendering;texture compression;volume rendering;software rendering;computer graphics (images)	Visualization	68.5889782661137	-52.77213175337764	70819
9675c78a20a03fe4936670d57456e0206cc954ca	towards detecting mowing of agricultural grasslands from multi-temporal cosmo-skymed data	radar remote sensing;vegetation agriculture noise radar interferometry spaceborne radar synthetic aperture radar;coherence biomass synthetic aperture radar remote sensing vegetation mapping decorrelation correlation;european level application monitoring agricultural grassland mowing detection multitemporal cosmo skymed data spaceborne repeat pass interferometric sar image applicability agricultural field mowing event detection one day repeat pass cosmo skymed acquisition agricultural grassland in situ measurement x band temporal interferometric coherence central estonia varying species composition varying species homogeneity temporal decorrelation grass height change grass wet biomass change nonlinear relationship one day temporal coherence noise level multitemporal interferometric sar image feasible technique	This work investigates applicability of spaceborne repeat-pass interferometric SAR images for detecting mowing events on agricultural fields. Four pairs of one-day repeat-pass COSMO-SkyMed acquisitions were analysed and compared to in situ measurements of 11 agricultural grasslands to study the potential of X-band temporal interferometric coherence for detecting mowing events. Field works covered 11 test plots in Central Estonia with varying species composition and homogeneity. Temporal decorrelation due to changes in the grass height and wet biomass was analysed. A nonlinear relationship was observed between the wet biomass and temporal coherence, as well as between the grass height and the temporal coherence. Our results show that one-day temporal coherence decreases as the grass height and the wet biomass increases, until reaching a noise level at 25 cm and 400 g, respectively. The current study shows that detecting mowing event from multitemporal interferometric SAR images is a feasible technique and could be used for monitoring applications on the European level.	cosmo-rs;coherence (physics);decorrelation;noise (electronics);nonlinear system;sensor	Karlis Zalite;Kaupo Voormansik;Jaan Praks;Oleg Antropov;Mart Noorma	2014	2014 IEEE Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2014.6947638	meteorology;hydrology;remote sensing	SE	82.02253680788081	-60.66795942221925	70845
851a93481a08c831d152b85d4aedc2eebdda45fc	parallel fixed-point digital differential analyser with antialiasing. pfddaa		This paper introduces a quick, efficient and simple algorithm for drawing straight lines with antialiasing on discrete devices like printers or CRTs. It is based on the DDA algorithm. It uses 32 bits fixed-point arithmetic. This is a pipelined, parallelized and scalable SIMD version. It may be hardware implemented. It is suitable for MMX or Streaming SIMD Pentium1 III instructions. The algorithm allows drawing true colour lines using a brush 3 pixels high and 1 pixel wide in parallel. The computing cost is very low and only integer arithmetic is used. This algorithm takes into account that the real width of the line remains constant always and it does not depend on its slope. Given that the total radiation emitted by a line is proportional to its real surface, total emitted light also increases with its slope.	32-bit;algorithm;cathode ray tube;differential analyser;fixed-point arithmetic;integer (computer science);mmx (instruction set);parallel computing;pipeline (computing);pixel;simd;scalability;spatial anti-aliasing	Ramón Mollá Vayá;Roberto Vivó	2000	Scalable Computing: Practice and Experience		parallel computing;mmx;pentium;pixel;computer hardware;fixed point;radiation;simple algorithm;computer science;simd;digital differential analyzer (graphics algorithm)	Vision	67.73050809266545	-52.16351242398788	70852
9f3c050a96e4a260466a10d142e0fbade4f74c7f	experimental ophthalmic multimodal imaging system for iris and retina	optical system;optical filters;biometrics;iris recognition;optical imaging;retina;optical sensors;biomedical optical imaging;iris	This paper deals with the design of optical system for simultaneous iris and retina acquirement of a human eye. This unique combination in one particular apparatus can be used for medical (ophthalmology) as well as for biometric purposes. Scanning in one cycle could significantly save the work time in comparison with separate scanning of each part of the eye particularly. Only one camera is used in the device.	biometrics;image scanner;multimodal interaction	Josef Hajek;Martin Drahanský;Radim Kolár	2014	2014 IIAI 3rd International Conference on Advanced Applied Informatics	10.1109/IIAI-AAI.2014.140	computer vision;ophthalmology;engineering;optics	Robotics	64.01926932448517	-57.23549440354921	70927
e8828ce789c36dbf28c15eb7665091550853f4fb	in-orbit calibration of the tandem-x system	geometric accuracy;antenna measurement;tdx satellite;antenna measurements;tdx satellite in orbit calibration tandem x system tsx satellite tandem x mission digital elevation model global scale dem acquisition bistatic satellite constellation nominal terrasar x operation bistatic tandem x mission monostotic terrasar x mission;dem acquisition;bistatic satellite constellation;tandem x mission;monostotic terrasar x mission;in orbit calibration;geophysical equipment calibration digital elevation models;nominal terrasar x operation;tandem x;satelliten sar systeme;terrasar x;digital elevation model;global scale;geometric accuracy tandem x terrasar x calibration antenna model radiometric accuracy;satellite broadcasting;calibration accuracy satellites satellite broadcasting radiometry antenna measurements antennas;radiometry;accuracy;tandem x system;tsx satellite;satellites;antennas;radiometric accuracy;digital elevation models;bistatic tandem x mission;geophysical equipment;antenna model;calibration	In addition to the first satellite TSX already in-flight since 2007 [1], the second satellite TDX of the TanDEM-X system could be successfully launched in 2010 [2]. The primary object of the TanDEM-X mission is to generate a highly accurate digital elevation model (DEM) with never achieved accuracy on global scale. But in addition to this DEM acquisition based on a bistatic satellite constellation, nominal TerraSAR-X operation shall be available anymore, i.e. the bistatic TanDEM-X mission and the monostatic TerraSAR-X mission have to be operated in parallel with both satellites. Consequently the second satellite TDX had to achieve the same accuracy and performance as those of the first satellite TSX. Based on a short overview of the different calibration procedures the paper discusses the calibration results achieved for the whole TanDEM-X system, successfully in-flight since June 2010.	digital elevation model	Marco Schwerdt;Jaime Hueso Gonzalez;Markus Bachmann;Dirk Schrank;Björn Döring;Nuria Tous-Ramon;John Mohan Walter Antony	2011	2011 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2011.6049699	meteorology;digital elevation model;geodesy;physics;remote sensing	Embedded	79.79277052143922	-64.64901132204102	70932
21ff84706c30aa33a207053039236799f0ad4aa6	quadratic optimization based small scale details extraction	quadratic programming;image processing problems;high dynamic range images;image processing;quadratic programming feature extraction image denoising image enhancement;ash equations optimization image processing noise reduction dynamic range graphics;image enhancement;multilight image enhancement;feature extraction;noise reduction;single input image quadratic optimization small scale detail extraction image processing problems high dynamic range images nonflash image denoising multilight image enhancement;ash;dynamic range;quadratic optimization;small scale detail extraction;optimization;single input image;image denoising;graphics;nonflash image denoising	In many image processing problems, it is required to extract small scale details from an image or a set of images. In this paper, we introduce a new framework for extracting small scale details from a single input image or a set of input images. We then show how to apply the framework to address several important problems in the field of image processing including tone mapping of high dynamic range images, de-noising of a non-flash image with a pair of non-flash and flash images, as well as details enhancement via multi-light images and a single input image. Experimental results show that the proposed framework outperforms existing methods.	high dynamic range;high-dynamic-range imaging;high-dynamic-range rendering;image processing;mathematical optimization;optimization problem;quadratic programming;tone mapping;unified framework	Zhengguo Li;Jinghong Zheng;Chuohao Yeo;Susanto Rahardja	2011	2011 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	10.1109/ICASSP.2011.5946652	computer vision;mathematical optimization;dynamic range;image processing;feature extraction;computer science;graphics;machine learning;digital image processing;noise reduction;quadratic programming;top-hat transform	Robotics	59.2011210140202	-64.11356192605037	70943
2874790ba2198f0b712b3700e290c326468a3b32	reconstructing textureless objects - image enhancement for 3d reconstruction of weakly-textured surfaces		Photogrammetric techniques for 3D reconstruction of weakly-textured surfaces are challenging. This paper proposes a new method to enhance image-based 3D reconstruction of weakly-textured surfaces. The idea behind it is to enhance the contrast of images, especially in weakly-textured regions, before feeding them to the reconstruction pipeline. Images contrast is enhanced using a recently proposed approach for noise reduction. The dynamic range of the generated denoised-images has to be squeezed to the limited 8-bit range that is used by the standard 3D reconstruction techniques. Dynamic range squeezing is a very critical process and can lead to information losses, since many levels in the original range will no longer be available in the limited target range. To this end, this paper proposes a new tone-mapping approach that is based on Contrast Limited Adaptive Histogram Equalization (CLAHE). It amplifies the local contrast adaptively to effectively use the limited target range. At the same time, it uses a limit to prevent local noise from being amplified. Using our approach leads to a significant improvement of up to 400% in the completeness of the 3D reconstruction.	3d reconstruction;8-bit;adaptive histogram equalization;color space;dynamic range;experiment;feature detection (computer vision);feature detection (web development);graphics pipeline;image editing;image noise;image processing;noise reduction;photogrammetry;precision and recall;texture mapping;tone mapping;zero suppression	Nader H. Aldeeb;Olaf Hellwich	2018		10.5220/0006628805720580	3d reconstruction;computer vision;computer science;artificial intelligence	Vision	57.813918091941034	-60.78549395958146	70944
18e38d9a4eee6e6f0623c00f2abf33f841262e9b	constraint matrix factorization for space variant psfs field restoration		Context: in large-scale spatial surveys, the Point Spread Function (PSF) varies across the instrument field of view (FOV). Local measurements of the PSFs are given by the isolated stars images. Yet, these estimates may not be directly usable for post-processings because of the observational noise and potentially the aliasing. Aims: given a set of aliased and noisy stars images from a telescope, we want to estimate well-resolved and noise-free PSFs at the observed stars positions, in particular, exploiting the spatial correlation of the PSFs across the FOV. Contributions: we introduce RCA (Resolved Components Analysis) which is a noise-robust dimension reduction and super-resolution method based on matrixfactorization. We propose an original way of using the PSFs spatial correlation in the restoration process through sparsity. The introduced formalism can be applied to correlated data sets with respect to any euclidean parametric space. Results: we tested our method on simulated monochromatic PSFs of Euclid telescope (launch planned for 2020). The proposed method outperforms existing PSFs restoration and dimension reduction methods. We show that a coupled sparsity constraint on individual PSFs and their spatial distribution yields a significant improvement on both the restored PSFs shapes and the PSFs subspace identification, in presence of aliasing. Perspectives: RCA can be naturally extended to account for the wavelength dependency of the PSFs.	aliasing (computing);approximation algorithm;circuit restoration;coefficient;convolution;dimensionality reduction;eigen (c++ library);euclid;field of view in video games;formal system;image restoration;monochrome;ne (complexity);polynomial greatest common divisor;sparse matrix;super-resolution imaging;television;the matrix	Fred Maurice Ngolè Mboula;Jean-Luc Starck;Koryo Okumura;Jérôme Amiaux;P. Hudelot	2016	CoRR	10.1088/0266-5611/32/12/124001	mathematical optimization;mathematics;geometry;optics;statistics	ML	70.63718945360014	-69.15030473345944	70964
45bece4d17dd1c82bb98e6c0660debcfb1bb9001	active tracking and cloning of facial expressions using spatio-temporal information	face expression analysis and synthesis;motion tracking;temporal information;optical flow;facial expression	This paper presents a new method to analyze and synthesize facial expressions, in which a spatio-temporal gradient based method (i.e., optical flow) is exploited to estimate the movement of facial feature points. We proposed a method (called motion correlation) to improve the conventional block correlation method for obtaining motion vectors. The tracking of facial expressions under an active camera is addressed. With the motion vectors estimated, a facial expression can be cloned by adjusting the existing 3-D facial model, or synthesized by using different facial models. The experimental results demonstrate that the approach proposed is feasible for applications such as low bit rate video coding and face animation.	data compression;gradient;optical flow	Lijun Yin;Anup Basu;Matt T. Yourst	2003	International Journal on Artificial Intelligence Tools	10.1142/S0218213003001241	computer vision;computer science;optical flow;facial expression;computer graphics (images)	Vision	56.76922937738935	-55.28573626536735	71092
9e0425720e5d6a3c773f8c884182d25cefb48a97	a characteristics of ionosphere d-region using tweek radio atmospherics at malaysia	time 10 day ionosphere d region tweek radio atmospherics malaysia ukm station fundamental cut off frequency tweek spectrograms night time d region ionospheric reflection height night time d region equivalent electron density propagation distance vlf waves lightning discharges receiving station elf vlf signals;d region ionosphere tweek radio atmospherics very low frequency vlf lightning discharge;radiowave propagation electromagnetic wave reflection ionospheric electromagnetic wave propagation;lightning discharge;electromagnetic wave reflection;ground penetrating radar geophysical measurement techniques ionosphere cutoff frequency reflection harmonic analysis atmospheric waves;d region ionosphere;ionospheric electromagnetic wave propagation;very low frequency vlf;radiowave propagation;tweek radio atmospherics	This paper presents an observation of tweek radio atmospherics received at Malaysia (UKM station) from 21st to 25th October 2010 and 1st to 5th November 2010 from 12:00:00 UT to 00:00:00 UT (Universal Time); 08:00 pm to 08:00 am. Fundamental cut-off frequency (fcm) will be extracted from tweeks spectrograms to measure the night-time D-region ionospheric reflection height (h), night-time D-region equivalent electron density (ne) and propagation distance (d) traveled by VLF waves from the causative lightning discharges to the receiving station. Analysis of 10 days sample that involves 2518 tweeks demonstrates that these ELF/VLF signals travel considerable distances up to 7500 km from the causative lightning discharges. The estimated ionosphere reflection height varies from 85 km to 92 km and the estimated equivalent electron density at the reflection height varies from 22 el/cm3 to 24 el/cm3.	diffuse reflection;electron;geforce 7 series;ne (complexity);software propagation;spectrogram	Norsuzila Ya'acob;Mahamod Ismail;Azita Laily Yusof;Mohd. Tarmizi Ali;Mazriza Osman	2012	2012 18th Asia-Pacific Conference on Communications (APCC)	10.1109/APCC.2012.6388181	meteorology;atmospheric sciences;geography;remote sensing	Vision	82.09461909389563	-66.30998966447278	71110
a7baa7f56280b76e3edec6e02e0c72c30566f793	wavelet priors for multiframe image restoration	traitement optique information;restauration image;image processing;0705p;probability density function;low resolution;wavelet priors;natural images;image restoration;prior knowledge;iterative algorithm;traitement image;markov random field;algorithme;iterative methods;multiframe image restoration;optical information processing;optimal regularization parameters;methode iterative;generalized gaussian;algorithms;calidad imagen;superresolution;4230v;wavelets;radiometric corrections	It is known that the distributions of wavelet coefficients of natural images at different scales and orientations can be approximated by generalized Gaussian probability density functions. We exploit this prior knowledge within a novel statistical framework for multi-frame image restoration based on the maximum a-posteriori (MAP) algorithm. We describe an iterative algorithm for obtaining a high-fidelity object estimate from multiple warped, blurred, and noisy low-resolution images. We compare our new method with several other techniques including linear restoration, and restoration using Markov Random Field (MRF) object priors. We will discuss the performances of the algorithms.© (2007) COPYRIGHT SPIE--The International Society for Optical Engineering. Downloading of the abstract is permitted for personal use only.	circuit restoration;image restoration;wavelet	Premchandra Shankar;Mark A. Neifeld	2007		10.1117/12.720939	computer vision;image processing;pattern recognition;iterative method	Vision	55.423935150487424	-72.53851563414713	71147
10c8feb1f9ce00c8444115e857e2f505b35fa150	ego-motion estimate corruption due to violations of the range flow constraint		Visual odometry methods are increasingly being used to estimate a vehicle's ego-motion from range data due to the decreasing cost of range sensors and the impressive speed and accuracy of visual odometry techniques. Dense geometry-based visual odometry methods are fundamentally based on the range flow constraint equation, an equation which depends on the temporal and spatial derivatives of range images. However, these derivatives are calculated with the fundamental assumption that the range flow is magnitude-limited. When scaling this method for faster vehicles, this assumption could be violated, invaliding the range flow constraint equation and thus corrupting the resulting ego-motion estimates. This paper derives the sensor, motion, environment, and sampling frequency conditions that would mathematically violate the range flow constraint. This information is useful for defining the operational limits of dense geometry-based visual odometry methods.		Chris D. Monaco;Sean N. Brennan	2018	2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)	10.1109/IROS.2018.8594131	computer vision;artificial intelligence;optical imaging;adaptive optics;scaling;flow (psychology);sampling (signal processing);constraint algorithm;visual odometry;computer science	Robotics	54.95932907623637	-52.320399486764046	71174
a9696234cd7dfad000125436dda828cdeb5cec14	compression efficiency of high dynamic range and wide color gamut pixel’s representation	standards;image color analysis;encoding;dynamic range;transfer functions	Ultra-high definition (UHD) is currently being deployed in video distribution pipelines for improved quality of experience. This new recommendation not only improves spatial and temporal resolution, but also the quality and accuracy of pixels using wide color gamut (WCG) and high dynamic range (HDR) technologies. Indeed, HDR video technology aims at conveying the full range of perceptible shadow and highlight details with enough different tonal levels to prevent loss of visual information, while WCG increases the amount of visible color that can be represented. However, these technologies require different standard digital pixel representations than the ones currently employed in high definition (HD) television. While the impact of increasing spatial and temporal resolution (i.e., increase of resolution and frame rate) on compression efficiency has already been assessed, it is not clear how new pixel representations would affect the compression performance. In this paper, we discuss the differences between HD color pixel representation and the newly standardized representations developed to meet the requirements introduced by WCG and HDR. Moreover we explain why existing HD pixel representations are sub-efficient for encoding HDR and WCG pixels. We also perform a statistical analysis of pixel distribution in real images to explain how pixel’s representation influences compression efficiency. Results show that by tailoring a pixel representation upon the range of luminance and color values accessible in content and displays, bandwidth savings can be achieved while increasing the quality of delivered content. We conclude this paper by discussing the shortcomings of the color pixel representation recommended for the UHD television standards and provide guidelines to create a more efficient one.	baseband;broadcast television systems;codec;color space;emergence;graphics pipeline;high dynamic range;high-dynamic-range rendering;high-dynamic-range video;pixel;requirement;software deployment;transfer function;world community grid	Ronan Boitard;Mahsa T. Pourazad;Panos Nasiopoulos	2018	IEEE Transactions on Broadcasting	10.1109/TBC.2017.2781120	electronic engineering;dynamic range;real image;pixel;high dynamic range;frame rate;computer vision;computer science;temporal resolution;gamut;shadow;artificial intelligence	Graphics	63.65451457754058	-62.39825092398998	71267
1a494ab86d99aeea8df5047132adbdc0f90eddd6	medical image fusion with parameter-adaptive pulse coupled neural network in nonsubsampled shearlet transform domain		As an effective way to integrate the information contained in multiple medical images with different modalities, medical image fusion has emerged as a powerful technique in various clinical applications such as disease diagnosis and treatment planning. In this paper, a new multimodal medical image fusion method in nonsubsampled shearlet transform (NSST) domain is proposed. In the proposed method, the NSST decomposition is first performed on the source images to obtain their multiscale and multidirection representations. The high-frequency bands are fused by a parameter-adaptive pulse-coupled neural network (PA-PCNN) model, in which all the PCNN parameters can be adaptively estimated by the input band. The low-frequency bands are merged by a novel strategy that simultaneously addresses two crucial issues in medical image fusion, namely, energy preservation and detail extraction. Finally, the fused image is reconstructed by performing inverse NSST on the fused high-frequency and low-frequency bands. The effectiveness of the proposed method is verified by four different categories of medical image fusion problems [computed tomography (CT) and magnetic resonance (MR), MR-T1 and MR-T2, MR and positron emission tomography, and MR and single-photon emission CT] with more than 80 pairs of source images in total. Experimental results demonstrate that the proposed method can obtain more competitive performance in comparison to nine representative medical image fusion methods, leading to state-of-the-art results on both visual quality and objective assessment.		Ming Yin;Xiaoning Liu;Yu Liu;Xun Chen	2019	IEEE Transactions on Instrumentation and Measurement	10.1109/TIM.2018.2838778	positron emission tomography;computer vision;computed tomography;artificial neural network;electronic engineering;pulse (signal processing);mathematics;radiation treatment planning;shearlet;artificial intelligence;image fusion	Vision	58.87194732002048	-67.6901673682646	71281
e963c3a31b22e166eaa3a94b19c2e93efec3a59f	on edge gradient approximations	edge detection	The effect of imposing some desirable properties on the masks of differential-type operators is studied. It is shown that in a 3 x 3 window there are only two free parameters to specify. It is also shown that under the assumption of these properties a widely used differential-type edge detection method is equivalent to an appropriate template-matching method and viceversa.	approximation;edge detection;gradient	J. Föglein	1983	Pattern Recognition Letters	10.1016/0167-8655(83)90082-X	computer vision;mathematical optimization;combinatorics;discrete mathematics;edge detection;computer science;mathematics	Vision	54.314644390246926	-69.40511512102617	71521
86151148a797e8966064a54e02f39532dd8c9de0	compressive sensing for high resolution differential sar tomography - the sl1mmer algorithm	systematic tomographic imaging;sar signalverarbeitung;parametric method differential sar tomography sl1mmer algorithm synthetic aperture principle 4d imaging meter resolution space borne sar system terrasar x systematic tomographic imaging urban infrastructure tomographic system formulation differential tomographic inversion 2d compressive sensing nonparametric method;nonparametric method;minimization;tomography radar imaging spaceborne radar synthetic aperture radar;high resolution;compressed sensing;image resolution;sl1mmer;parametric method;nonlinear motion;synthetic aperture principle;terrasar x;differential tomographic inversion;4d imaging;tomographic system formulation;terrasar x differential sar tomography nonlinear motion compressive sensing sl1mmer super resolution;sl1mmer algorithm;estimation;seasonality;tomography image resolution image reconstruction estimation robustness minimization compressed sensing;compressive sensing;image reconstruction;radar imaging;differential sar tomography;super resolution;non parametric method;robustness;meter resolution space borne sar system;tomography;spaceborne radar;urban infrastructure;synthetic aperture radar;2d compressive sensing	Differential SAR tomography extends the synthetic aperture principle into the elevation and time directions for 4-D imaging. With modern meter-resolution space-borne SAR systems like TerraSAR-X (TS-X), systematic tomographic imaging of urban infrastructure and its deformations becomes feasible. We demonstrate the potential of TS-X data for this purpose and introduce several novel concepts. Since building deformation in general is nonlinear, e.g. due to thermal dilation, we start from a tomographic system formulation that is general enough to allow for the inclusion of motion models (linear, periodic, etc.). By appropriate warping of the time axis we map the motion model function to become linear and lead to a peak in the spectral domain. For the differential tomographic inversion itself we propose a 2-D compressive sensing (CS) based approach—“SL1MMER”. We demonstrate the super-resolution power and the robustness of SL1MMER both with simulated and with real data. We also show that it provides an attractive compromise between parametric and non-parametric methods. A full reconstruction of a building complex and its seasonal deformation from a stack of TS-X spotlight data is finally presented.	algorithm;apache axis;compressed sensing;dbpedia;dilation (morphology);image resolution;nonlinear system;super-resolution imaging;synthetic data;tomography	Xiaoxiang Zhu;Richard Bamler	2010	2010 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2010.5654021	computer vision;image resolution;computer science;tomography;optics;compressed sensing;statistics;remote sensing	Vision	76.08513593357773	-65.01189559407044	71528
43f5c23fef0b8fbb5e35c8804dc579c976e0fa2e	application of the ici principle to window size adaptive median filtering	traitement signal;evaluation performance;reconstruccion senal;performance evaluation;median filter;denoizing;adaptive filtering;filtrado adaptable;evaluacion prestacion;simulation;estimation non parametrique;adaptive window median filter;simulacion;detection;reduccion ruido;non parametric estimation;intersection of confidence intervals;signal processing;noise reduction;filtro mediano;reduction bruit;signal reconstruction;filtrage adaptatif;estimacion no parametrica;reconstruction signal;procesamiento senal;filtre median	We describe a novel approach to solve a problem of varying window size selection for median filtering a noisy signal. The approach is based on the intersection of confidence interval rule. This rule gives the adaptive varying window size and enables the algorithm to be spatially adaptive in such a way that its quality is close to that which one could achieve if the smoothness of the estimated signal is known in advance. A multiwindow estimate combining left and right windowed median estimates is developed.	ici (programming language);median filter	Vladimir Katkovnik;Karen O. Egiazarian;Jaakko Astola	2003	Signal Processing	10.1016/S0165-1684(02)00387-0	adaptive filter;signal reconstruction;median filter;computer vision;econometrics;computer science;machine learning;signal processing;noise reduction;mathematics;statistics	Arch	54.0017848079437	-66.80472246368606	71562
1821c674842cb97c983650c3a7e5e821f172222b	a generalized vector-valued total variation algorithm	color tv signal processing algorithms colored noise gaussian noise noise reduction gray scale iterative algorithms gold laboratories;computational performance generalized vector valued total variation generalized vector valued tv functional deconvolution denoising vector valued images gaussian noise salt and pepper noise iteratively reweighted norm scalar images grayscale images;gaussian noise;scalars;image processing;color;performance;color image processing;image denoising deconvolution gaussian noise;vector valued total variation;image color analysis;noise reduction;deconvolution;algorithms;total variation;image denoising;tv;color image processing vector valued total variation;99;signal to noise ratio;pepper;images;color image	We propose a simple but flexible method for solving the generalized vector-valued TV (VTV) functional, which includes both the ¿2-VTV and ¿1-VTV regularizations as special cases, to address the problems of deconvolution and denoising of vector-valued (e.g. color) images with Gaussian or salt-and-pepper noise. This algorithm is the vectorial extension of the Iteratively Reweighted Norm (IRN) algorithm [1] originally developed for scalar (grayscale) images. This method offers competitive computational performance for denoising and deconvolving vector-valued images corrupted with Gaussian (¿2-VTV case) and salt-and-pepper noise (¿1-VTV case).	algorithm;deconvolution;grayscale;noise reduction;salt-and-pepper noise	Paul Rodríguez;Brendt Wohlberg	2009	2009 16th IEEE International Conference on Image Processing (ICIP)	10.1109/ICIP.2009.5413587	gaussian noise;computer vision;mathematical optimization;color image;performance;image processing;computer science;deconvolution;noise reduction;mathematics;signal-to-noise ratio;total variation;statistics	Robotics	55.8902674125165	-72.55732705017515	71692
20ec7bc4f1e97144f825a21bc136583244118378	texture image segmentation based on wavelet-domain hidden markov models	discrete wavelet transforms;model parameters;expectation maximization algorithms;discrete wavelet transform;image segmentation;image processing;hidden markov model;segmentation accuracy;image texture;wavelet transform;geophysical measurements;hidden markov models;expectation maximization;geophysical signal processing;remote sensing;remote sensing discrete wavelet transforms geophysical signal processing geophysical techniques hidden markov models image segmentation image texture;segmentation accuracy texture image segmentation hidden markov models 2d discrete wavelet transform image processing image analysis wavelet coefficients gaussian distribution model parameters expectation maximization algorithms;image analysis;image texture analysis;texture image segmentation;image segmentation hidden markov models discrete wavelet transforms wavelet coefficients wavelet analysis production image analysis image processing parameter estimation wavelet transforms;2d discrete wavelet transform;em algorithm;gaussian distribution;wavelet coefficients;geophysical techniques	Many approaches have been used to segment texture-based image, but can't have one's wish fulfilled. People unremittingly try to find high quality, more effective method. The 2D discrete wavelet transform, as a powerful and effective approach, have got preferable production in image analyzing and image processing. However routine method focuses on the assumption that the wavelet coefficients are independent and jointly Gaussian. In fact, most real-world images are not always Gaussian distributed, there are underlying relationships and rules among these wavelet coefficients on both the same scale and the inter-scale. In this paper, we first reveal the dependencies among these coefficients through the wavelet-domain HMM's, then estimate the model parameters using the expectation maximization (EM) algorithms. The classification can be first realized through maximum likely method in each band, and then combine with the classification results of the three sub-bands from the 2D wavelet transform and also integrate the classification results of different scale. These approaches offer improved segmentation accuracy	coefficient;discrete wavelet transform;display resolution;effective method;expectation–maximization algorithm;hidden markov model;image processing;image segmentation;markov chain	Ling Peng;Zhongming Zhao;Jianglin Ma	2004	IGARSS 2004. 2004 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2004.1369958	computer vision;expectation–maximization algorithm;computer science;machine learning;pattern recognition;mathematics;stationary wavelet transform;hidden markov model	Vision	60.82008192276655	-70.20617179375294	71778
2422028e6092eea7e5a900d0bfb7b78ad55c7222	classifying land cover from satellite images using time series analytics		The Earth’s surface is continuously observed by satellites, leading to large multi-spectral image data sets of increasing spatial resolution and temporal density. One important application of satellite data is the mapping of land cover and land use changes such as urbanization, deforestation, and desertification. This information should be obtained automatically, with high accuracy, and at the pixel level, which implies the need to classify millions of pixels even when only small regions are studied. Balancing runtime and accuracy for this task becomes even more challenging with the recent availability of multiple time points per pixel, created by periodically performed satellite scans. In this paper we describe a novel approach to classify land cover from series of multi-spectral satellite images based on multivariate time series analytics. The main advantage of our method is that it inherently models the periodic changes (seasons, agriculture etc.) underlying many types of land covers and that it is comparably robust to noise. Compared to a classical feature-based classifier, our new method shows a slightly superior overall accuracy, with an increase of up to 20% in accuracy for rare land cover classes, though at the cost of notably increased runtime. The highest accuracy is achieved by combining both approaches.	experiment;f1 score;feature extraction;harsh realm;image noise;köppen climate classification;machine learning;multispectral image;pixel;point of view (computer hardware company);random forest;time series	Patrick Schäfer;Dirk Pflugmacher;Patrick Hostert;Ulf Leser	2018			remote sensing;geography;land cover;satellite;analytics	ML	78.22185749708001	-58.581098557192355	71819
b00f1fbb388ad988fb33c0f328fa72715c1d883f	polarimetric sar change detection with the complex hotelling–lawley trace statistic	vdp matematikk og naturvitenskap 400 geofag 450;detectors;synthetic aperture radar sar change detection complex wishart distribution fisher snedecor fs distribution hotelling lawley trace hlt statistic likelihood ratio test lrt statistic polarimetry;change detection;polarimetry;polarimetric sar change detection false alarm rate regulated change detector fisher snedecor distribution hlt statistic approximation complex kind hlt statistic distribution scaled complex wishart distribution multilook complex covariance matrix data polarimetric radar image unsupervised change detection test statistic complex hotelling lawley trace statistic;fisher snedecor distribution;journal article;tidsskriftartikkel;computational modeling;peer reviewed;covariance matrices synthetic aperture radar detectors optical sensors computational modeling object oriented modeling estimation;estimation;synthetic aperture radar approximation theory covariance matrices radar detection radar imaging radar polarimetry statistical distributions;covariance matrices;complex wishart distribution;optical sensors;hotelling lawley trace statistic;object oriented modeling;likelihood ratio test statistic;synthetic aperture radar	In this paper, we propose a new test statistic for unsupervised change detection in polarimetric radar images. We work with multilook complex covariance matrix data, whose underlying model is assumed to be the scaled complex Wishart distribution. We use the complex-kind Hotelling-Lawley trace (HLT) statistic for measuring the similarity of two covariance matrices. The distribution of the HLT statistic is approximated by a Fisher-Snedecor distribution, which is used to define the significance level of a false alarm rate regulated change detector. Experiments on simulated and real PolSAR data sets demonstrate that the proposed change detection method gives detection rates and error rates that are comparable with the generalized likelihood ratio test.	approximation algorithm;polarimetry;unsupervised learning	Vahid Akbari;Stian Normann Anfinsen;Anthony Paul Doulgeris;Torbjørn Eltoft;Sebastiano B. Serpico	2016	IEEE Transactions on Geoscience and Remote Sensing	10.1109/TGRS.2016.2532320	econometrics;estimation;detector;peer review;synthetic aperture radar;polarimetry;pattern recognition;mathematics;computational model;change detection;physics;statistics	ML	72.37932988647718	-63.79166244208399	71824
2eeee8bc9480b70cbac03ee5b67a953101578328	system for developing photon mapping algorithms		This paper presents several algorithms for high-performance rendering engines. In the first part we describe the development of global illumination methods with particular emphasis on photon mapping. Secondly, we present methods used by the rendering system design and consider the possibility of further developing these methods.	algorithm;photon mapping	Krzysztof Guzek;Piotr Napieralski	2012		10.1007/978-3-642-27446-6_7	photon mapping;rendering (computer graphics);algorithm;global illumination;computer science	HCI	67.05903741360277	-52.20505302673548	71934
f6847d8e755cd2744b2cc059558f530711599fc0	grids at 4300 meters over the sea level: argo on euchinagrid				Cristian Stanescu;Federico Ruggieri;Y. Q. Guo;L. Wang;X. M. Zhang	2007	Bio-Algorithms and Med-Systems		meteorology;metre;argo;geology;sea level	NLP	79.80674856721163	-60.487987171172925	71960
0677faa76deac6e21f884f49881be372d345176d	reduced-reference image quality assessment by structural similarity estimation	natural image statistics;image deblurring;image restoration;distortion measurement;regression analysis feature extraction image restoration;receivers;nonlinear distortion;structural similarity divisive normalization transform image deblurring image repairing natural image statistics reduced reference image quality assessment rr iqa;image repairing;estimation;feature extraction;image quality;transforms;distortion measurement feature extraction nonlinear distortion transforms image quality receivers estimation;regression analysis;image deblurring reduced reference image quality assessment automatic image quality evaluations rr iqa method structural similarity index estimation ssim estimation full reference image quality measure fr image quality measure perceptual image quality statistical feature extraction multiscale multiorientation divisive normalization transform fr ssim measure image distortion regression by discretization method subject rated databases rr ssim method rr features;reduced reference image quality assessment rr iqa;divisive normalization transform;structural similarity	Reduced-reference image quality assessment (RR-IQA) provides a practical solution for automatic image quality evaluations in various applications where only partial information about the original reference image is accessible. In this paper, we propose an RR-IQA method by estimating the structural similarity index (SSIM), which is a widely used full-reference (FR) image quality measure shown to be a good indicator of perceptual image quality. Specifically, we extract statistical features from a multiscale multiorientation divisive normalization transform and develop a distortion measure by following the philosophy in the construction of SSIM. We find an interesting linear relationship between the FR SSIM measure and our RR estimate when the image distortion type is fixed. A regression-by-discretization method is then applied to normalize our measure across image distortion types. We use six publicly available subject-rated databases to test the proposed RR-SSIM method, which shows strong correlations with both SSIM and subjective quality evaluations. Finally, we introduce the novel idea of partially repairing an image using RR features and use deblurring as an example to demonstrate its application.	approximation algorithm;database;deblurring;discretization;distortion;do not track;dysembryoplastic neuroepithelial tumor;estimated;evaluation;exhibits as topic;image quality;matching;normalize;rapid refresh;rating (action);round-robin scheduling;structural similarity;uncompressed video;wound healing	Abdul Rehman;Zhou Wang	2012	IEEE Transactions on Image Processing	10.1109/TIP.2012.2197011	image quality;image restoration;computer vision;nonlinear distortion;estimation;speech recognition;feature extraction;computer science;structural similarity;pattern recognition;mathematics;regression analysis;statistics	Vision	62.43338290006506	-65.40624695438459	71989
88a0216c766b00db10205d552354334f78f143fe	frost heave estimation of marshy soil by alos palsar interferometry and geodetic leveling, case study from the baikal lake region	soil moisture dinsar of layered surface geodetic leveling seasonal thawing freezing;moisture;water quality estimation theory geodesy lakes radar interferometry;satellites;soil moisture;interferometry;radar interferometry frost heave estimation marshy soil alos palsar interferometry geodetic level baikal lake region vertical ground displacement estimation differential radar interferometry selenga river ad 2008 to 2011 seasonal deformation interferometric measurement upper soil moisture content geodetic measurement moisture content;moisture synthetic aperture radar soil moisture interferometry satellites;synthetic aperture radar	Estimation of vertical ground displacements due to seasonal periods of freezing and thawing was carried out on the Selenga River mouth using differential radar interferometry. The results of seasonal radar interferometry measurements for 2008-2010 have been compared with the survey data for 2011, under the assumption that the seasonal deformation is comparable for different years and lie within the limits of geodetic leveling error. The difference between the interferometric and geodetic measurements is below 1 cm in winter months, whereas in summer, as the upper soils moisture content varies, the difference reaches 2-2.7 cm. It has been concluded that the moisture content and its profile should be taken into consideration in summer or when choosing the radar interferometry in winter.	geodetic datum;radar	Tumen N. Chimitdorzhiev;Pavel N. Dagurov;Michail Bykov;Aleksey V. Dmitriev;Irina Kirbizhekova	2016	2016 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)	10.1109/IGARSS.2016.7730378	moisture;geomorphology;synthetic aperture radar;water content;geology;hydrology;interferometry;physics;satellite;remote sensing	Embedded	82.5676633817895	-61.065003568788114	72034
8feaef131ad650a2e760437f9b089e4c585a1e2b	image reconstruction using divergent beams distributed over limited angle	tomography image reconstruction divergent beams divergent geometry anisotropic properties divergent projections parallel projections extended entropy;image reconstruction geometry entropy geometrical optics image converters nondestructive testing interpolation anisotropic magnetoresistance tomography atomic measurements;data distribution;image reconstruction;entropy;tomography;tomography image reconstruction entropy	We present a new image reconstruction technique from acquisition data in divergent geometry distributed over a limited angle. In many practical situations, it is not possible to obtain the data distributed over the whole 360/spl deg/. For example, when the test object presents anisotropic properties, i.e., when it is extremely sensible to the radiation coming from some specific direction. Physical constraints can also obstruct the acquisition of data in all angles. The proposed technique solves this problem by allowing image reconstruction from data distributed over a limited angle. This technique first converts the divergent projections distributed over a limited angle into parallel projections homogeneously distributed over the whole contour of the test object. Then, an algorithm based on extended entropy reconstructs the image.	iterative reconstruction	Harold Ivan Angulo Bustos;Hae Yong Kim;Ricardo T. Lopes	2002		10.1109/ICIP.2002.1039983	iterative reconstruction;computer vision;entropy;mathematics;geometry;tomography	Vision	71.96302947743871	-67.442985427896	72039
ddd8349ce3c37cfe5fd97066196e3455b5878465	estimation of agricultural and biophysical parameters of rice fields in vietnam using x-band dual-polarization sar	vegetation mapping crops geophysical image processing radar imaging radar polarimetry remote sensing by radar synthetic aperture radar time series;backscatter biomass synthetic aperture radar monitoring agriculture production satellites;mekong delta rice monitoring x band synthetic aperture radar;vv polarisation time series x band synthetic aperture radar data rice fields mekong delta vietnam dual polarisation images cosmo skymed constellation rice season ad 2013 ad 2014 backscatter parameters biophysical parameters sowing date plant biomass vegetative stage agricultural parameters x band dual polarization sar hh polarisation	In this study, we use time-series of X-band Synthetic Aperture Radar (SAR) data to monitor rice fields in the Mekong Delta, Vietnam. Ten dual-polarisation (HH&VV) images of the COSMO-SkyMed constellation are used in the third rice season of 2013, and 3 images in the first season of 2014. In 2013, the season-long comparison of backscatter and biophysical parameters measured in 40 fields allowed us to develop methods to map rice fields at both seasons and to derive the sowing date and the plant biomass at the vegetative stage in 2013.	aperture (software);cosmo-rs;persistent vegetative state;synthetic data;time series	Alexandre Bouvet;Thuy Le Toan;Nguyen Lam-Dao	2014	2014 IEEE Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2014.6946723	meteorology;hydrology;remote sensing	Embedded	81.9020802991458	-60.27398672999123	72056
3e48fd8d60a694383919123d302c1f9edac134ad	generation of dem by radargrammetric techniques	radar resolution digital elevation models geophysical image processing image matching image resolution radar imaging;geophysical image processing;dem generation;azimuth;image resolution;mountainous area;radar signal;image matching;geometry;elevation terrain;radar resolution;digital elevation model;sir c shuttle mission;epipolar geometry;radargrammetric processing;image reconstruction;signal processing;very high resolution;pyramidal scheme;radar imaging;pixel;sir c shuttle mission dem signal processing radar signal image resolution radar image elevation terrain digital elevation model mountainous area radargrammetric processing image matching epipolar geometry pyramidal scheme;digital elevation models;pixel radar imaging image matching azimuth geometry image reconstruction;radar image;dem	Thanks to the signal processing applied to radar signal [1], radar systems can provide images with a very high resolution. With regard to these properties, one can estimate that radar images are used to get elevation terrain considering the basic characteristics of a radar image. This paper examines one way to produce DEM (Digital Elevation Models) from a mountainous area (the French Alps). So, we organize the discussion in three parts. First, we present the basic operations that the radargrammetric processing requires to be performed. So we deal with the different steps to obtain a DEM. Secondly, we expose two classical image matching improvements: the epipolar geometry and the pyramidal scheme. At the end, we present the results of DEM generation from a SIRC shuttle mission image pair and the way to improve these results.	digital elevation model;epipolar geometry;image registration;image resolution;radar;signal processing	Franck Fayard;Stephane Meric;Eric Pottier	2010	2010 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2010.5654111	computer vision;digital elevation model;geology;signal processing;physics;remote sensing;computer graphics (images)	Robotics	75.64421884170031	-65.53613427266367	72063
64aff1550a304d89a62b33eee55918ec887d1883	a family of nonlinear filters with data dependent coefficients	image sampling;preservation contour;pulse response;nonlinear filters;evaluation performance;nonlinear filters finite impulse response filter working environment noise gaussian noise signal processing smoothing methods information filtering information filters signal processing algorithms face;performance evaluation;image processing;non linear filter;signal sampling;evaluacion prestacion;ruido;nonlinear filter;respuesta impulsion;noise suppression;suppression bruit;digital filtering;supresion;data dependence;reponse impulsion;bruit;filtrado numerico;filtro no lineal;image sampling nonlinear filters noise filtering theory image processing;weight function;filtering theory;filtrage numerique;filtre non lineaire;noise;linear smoothers nonlinear filters data dependent coefficients signal samples rank order dependent weighting function performance noise suppression impulse rejection edge preservation averager;suppression	A new family of data dependent nonlinear filters (DDNI.) is presented. Coefficients are computed locally and the absolute distance between signal samples is used to determine a rank order dependent weighting function. The new filters have very good performance regarding noise suppression and impulse rejection and at the same time provide better edge preservation than the averager and other linear smoothers.	coefficient;nonlinear system;rejection sampling;smoothing;weight function;zero suppression	George Economou;Spiros Fotopoulos;M. Vemis	1995	IEEE Trans. Signal Processing	10.1109/78.365317	nonlinear filter;computer vision;weight function;speech recognition;digital filter;image processing;computer science;noise;control theory;mathematics;statistics	ML	54.98514811563226	-66.46673381187695	72091
98b7b2086e1f2291bd92b7659516411a82fdb1e3	cultural heritage sites in danger - towards automatic damage detection from space	change detection;photogrammetrie und bildanalyse;cultural heritage;georisiken und zivile sicherheit;texture analysis	The intentional damage to local Cultural Heritage sites carried out in recent months by the Islamic State have received wide coverage from the media worldwide. Earth Observation data provide important information to assess this damage in such non-accessible areas, and automated image processing techniques will be needed to speed up the analysis if a fast response is desired. This paper shows the first results of applying fast and robust change detection techniques to sensitive areas, based on the extraction of textural information and robust differences of brightness values related to preand post-disaster satellite images. A map highlighting potentially damaged buildings is derived, which could help experts at timely assessing the damages to the Cultural Heritage sites of interest. Encouraging results are obtained for two archaeological sites in Syria and Iraq.		Daniele Cerra;Simon Plank;Vasiliki Lysandrou;Jiaojiao Tian	2016	Remote Sensing	10.3390/rs8090781	cultural heritage;change detection;statistics;remote sensing	HCI	80.99244957012347	-56.11795061818887	72108
5f0b87d12b3583371f3dcd836449c35b2aa84848	optimal orthogonal basis and image assimilation: motion modeling	reduced model;galerkin method;numerical analysis data assimilation galerkin method image sequences motion estimation;motion estimation;computational cost optimal orthogonal basis image assimilation numerical computation motion estimation image data galerkin projection physical model euler equations optical flow equations data assimilation method synthetic data interest of model reduction;galerkin projection;numerical analysis;vectors mathematical model equations motion estimation numerical models data assimilation boundary conditions;satellite image;data assimilation;satellite image data assimilation galerkin projection motion estimation reduced model;image sequences	This paper describes modeling and numerical computation of orthogonal bases, which are used to describe images and motion fields. Motion estimation from image data is then studied on subspaces spanned by these bases. A reduced model is obtained as the Galerkin projection on these subspaces of a physical model, based on Euler and optical flow equations. A data assimilation method is studied, which assimilates coefficients of image data in the reduced model in order to estimate motion coefficients. The approach is first quantified on synthetic data: it demonstrates the interest of model reduction as a compromise between results quality and computational cost. Results obtained on real data are then displayed so as to illustrate the method.	algorithmic efficiency;coefficient;computation;data assimilation;database;euler;galerkin method;motion estimation;numerical analysis;optical flow;synthetic data	Etienne G. Huot;Giuseppe Papari;Isabelle Herlin	2013	2013 IEEE International Conference on Computer Vision	10.1109/ICCV.2013.416	computer vision;mathematical optimization;mathematical analysis;data assimilation;numerical analysis;computer science;motion estimation;galerkin method;mathematics;geometry	Vision	67.41911474683792	-70.54515047429187	72143
2aeeb5595c5f510232d25e23e17b1c3fea42cfb9	detecting digital image forgeries using sensor pattern noise	filigranage numerique;protection information;digital watermarking;filtering;compresion con perdida;filtrage;image numerique;spread spectrum;detecteur image;data integrity;image processing;sensors;espectro ensanchado;lossy compression;integrite donnee;filtrado;procesamiento imagen;digital imaging;estimacion a priori;traitement image;a priori estimation;spectre etale;proteccion informacion;information protection;filigrana digital;imaging;imagen numerica;estimation a priori;formation image;algorithms;correlation detection;detector imagen;optical sensors;formacion imagen;digital image;detection correlation;deteccion correlacion;image sensor;cameras;compression degradante	We present a new approach to detection of forgeries in digital images under the assumption that either the camera that took the image is available or other images taken by that camera are available. Our method is based on detecting the presence of the camera pattern noise, which is a unique stochastic characteristic of imaging sensors, in individual regions in the image. The forged region is determined as the one that lacks the pattern noise. The presence of the noise is established using correlation as in detection of spread spectrum watermarks. We proposed two approaches. In the first one, the user selects an area for integrity verification. The second method attempts to automatically determine the forged area without assuming any a priori knowledge. The methods are tested both on examples of real forgeries and on non-forged images. We also investigate how further image processing applied to the forged image, such as lossy compression or filtering, influences our ability to verify image integrity.	digital image;image processing;lossy compression;sensor	Jan Lukás;Jessica J. Fridrich;Miroslav Goljan	2006		10.1117/12.640109	lossy compression;filter;image noise;computer vision;telecommunications;image processing;digital watermarking;sensor;electrical engineering;image sensor;data integrity;digital imaging;spread spectrum;information protection policy;digital image	Vision	54.28574498715249	-61.282415011446226	72296
5e9849fbf7386eb77b8dc9233b8c3ce595915f80	surface clutter and echo location analysis for the interpretation of sharad data from mars	mars;clutter;topography earth geophysical techniques;optical surface waves;shallow radar sharad cluttergram incoherent radar simulation mars reconnaissance orbiter mro planetary radar;surface topography clutter surface waves mars radar clutter optical surface waves;surface topography;surface clutter orbital parameter radar model radar wavelength surface topography cross track long wavelength surface slope orbital sounders broad beam pattern orbital radar sounding subsurface echoes time delay cross track surface echoes mars reconnaissance orbiter shallow radar sharad data echo location analysis;radar clutter;surface waves	This letter presents a suite of analysis techniques designed to support the interpretation of data from the Shallow Radar on Mars Reconnaissance Orbiter. Cross-track surface echoes (“clutter”) with a time delay similar to potential subsurface echoes are known to present a major challenge to orbital radar sounding; furthermore, we demonstrate that the broad beam pattern of orbital sounders combined with cross-track long-wavelength surface slopes can result in first-received echoes arising from locations significantly distant from the nadir point, further hindering interpretation. Combining known surface topography (of lower resolution than the radar wavelength) with an appropriate radar model and orbital parameters, we can simultaneously address both of these challenges. Our technique has been applied to a variety of scientific targets on Mars with success and is recommended as a standard practice.	algorithm;automatic sounding;broadcast delay;clutter;map;molecular orbital;planetary data system;radar;radiation pattern;reflection (computer graphics);simulation;technical standard;topography	Prateek Choudhary;John W. Holt;Scott D. Kempf	2016	IEEE Geoscience and Remote Sensing Letters	10.1109/LGRS.2016.2581799	geophysics;early-warning radar;continuous-wave radar;space-based radar;mars exploration program;radar engineering details;synthetic aperture radar;marsis;geodesy;surface wave;radar horizon;bistatic radar;envelope;pulse-doppler radar;clutter;3d radar;radar imaging;radar astronomy;physics;radar;remote sensing	Visualization	80.22727952400105	-65.20990092050943	72332
5a434e31fb6de6176d49e41460dfede35fcc4f0d	bathymetry and water quality measurement of shallow waters using hyperion: serçin lake	bathymetry hyperspectral remote sensing water quality;hyperspectral imaging water signal processing conferences;signal processing;hyperspectral imaging;water;conferences	Hyperspectral images are very useful in estimating dense bathymetry of shallow waters cost-effectively. In this study, work on Lake Serçin using Hyperion images is summarized. Firstly, outlier pixels are determined by using median filtering on vertical profiles to handle the radiometric calibration problem that manifests itself as vertical stripes and their effect is removed. Remaining effect is suppressed using horizontal smoothing on the profile. Following the removal of radiometric and atmospheric effects, the depth and chlorophyll A are estimated using visible bands.	bathymetry;hyperion;kaby lake;median filter;pixel;smoothing;stripes	Ayfer Ozdemir;Ugur M. Leloglu	2014	2014 22nd Signal Processing and Communications Applications Conference (SIU)	10.1109/SIU.2014.6830656	water;computer science;hyperspectral imaging;signal processing	Robotics	77.481782436697	-62.232004848828474	72409
73a7e6a9fe673f6db0431a0224e06587703ffbc8	a bandelet-based inpainting technique for clouds removal from remotely sensed images	remote sensing image;image structures;teledetection;topology;flow;aerial image processing remotely sensed images photo editing inpainting technique areas reconstruction cloud shadows bandelet transform multiscale geometrical grouping geometric flow curves image structures cloud contaminated zone removal missing data;restauration image;image processing;ecoulement;time measurement;earth;ondelette;pollution measurement;geometric flow curves;topologie;geometry;imagerie;geometrie;remote sensing geophysical techniques geophysics computing image restoration;photo editing;image restoration;filling;traitement image;deteccion a distancia;information geometry;topologia;aerial image;inpainting technique;nube;imagery;cloud contaminated zone removal;geophysics computing;wavelets image reconstruction image restoration;image reconstruction;clouds;remote sensing;multiscale geometrical grouping;geometria;imagineria;cloud shadows;missing data;nuage;aerial image processing;remotely sensed images;bandelet transform;wavelets;wavelet;reconstitution image;areas reconstruction;geophysical techniques;geometric flow;clouds image reconstruction pollution measurement remote sensing time measurement filling information geometry topology image restoration earth	It is well known that removing cloud-contaminated portions of a remotely sensed image and then filling in the missing data represent an important photo editing cumbersome task. In this paper, an efficient inpainting technique for the reconstruction of areas obscured by clouds or cloud shadows in remotely sensed images is presented. This technique is based on the Bandelet transform and the multiscale geometrical grouping. It consists of two steps. In the first step, the curves of geometric flow of different zones of the image are determined by using the Bandelet transform with multiscale grouping. This step allows an efficient representation of the multiscale geometry of the image's structures. Having well represented this geometry, the information inside the cloud-contaminated zone is synthesized by propagating the geometrical flow curves inside that zone. This step is accomplished by minimizing a functional whose role is to reconstruct the missing or cloud contaminated zone independently of the size and topology of the inpainting domain. The proposed technique is illustrated with some examples on processing aerial images. The obtained results are compared with those obtained by other clouds removal techniques.	aerial photography;bandelet (computer science);cloud computing;inpainting;missing data	Aldo Maalouf;Philippe Carré;Bertrand Augereau;Christine Fernandez-Maloigne	2009	IEEE Transactions on Geoscience and Remote Sensing	10.1109/TGRS.2008.2010454	wavelet;computer vision;image processing;mathematics;statistics;remote sensing;computer graphics (images)	Vision	69.62621655161654	-62.33624850073599	72430
e2c09f29ac989a40a7cf8a24b44db7281a188758	non-lambertian model-based facial shape recovery from single image under unknown general illumination	image irradiance equation;reflectance modeling statistical shape recovery image irradiance equation hemi spherical harmonics;skin reflectance;shape from shading;complex illumination conditions;reflectivity;spherical harmonic;skin;harmonic projection images;shape recovery;frequency space based image representation;shape recognition;3d facial shape;lambertian reflectance model;albedo models;statistical shape recovery;nonlambertian model based facial shape recovery;computational modeling;shape harmonic analysis lighting mathematical model skin computational modeling humans;face recognition;visual perception face recognition image representation lighting reflectivity regression analysis shape recognition;depth perception;shape;reflectance modeling;image representation;reflection model;regression like algorithm;mathematical model;minimization process nonlambertian model based facial shape recovery unknown general illumination depth perception 2d image projection shape from shading sfs 3d facial shape nonrealistic assumption lambertian reflectance model albedo models frequency space based image representation image irradiance equation harmonic projection images human skin types complex illumination conditions skin reflectance torrance sparrow model harmonic basis noniterative approach regression like algorithm;human skin;visual perception;regression analysis;harmonic basis;humans;lighting;sfs;hemi spherical harmonics;unknown general illumination;torrance sparrow model;nonrealistic assumption;minimization process;human skin types;noniterative approach;2d image projection;harmonic analysis	Through depth perception, humans have the ability to determine distances based on a single 2D image projected on their retina, where shape-from-shading (SFS) provides a mean to mimic such a phenomenon. The goal of this paper is to recover 3D facial shape from a single image of unknown general illumination, while relaxing the non-realistic assumption of Lambert Ian reflectance. Prior shape, albedo and reflectance models from real data, which are metric in nature, are incorporated into the shape recovery framework. Adopting a frequency-space based representation of the image irradiance equation, we propose an appearance model, termed as Harmonic Projection Images, which accounts explicitly for different human skin types as well as complex illumination conditions. Assuming skin reflectance obeys Torrance-Sparrow model, we prove analytically that it can be represented by at most 5th order harmonic basis whose closed form is provided. The recovery framework is a non-iterative approach which incorporates regression-like algorithm in the minimization process. Our experiments on synthetic and real images illustrate the robustness of our appearance model vis-a-vis illumination variation.	algorithm;autostereogram;clustered file system;depth perception;experiment;iterative method;lambertian reflectance;oren–nayar reflectance model;photometric stereo;quintic function;shading;synthetic intelligence	Shireen Y. Elhabian;Eslam A. Mostafa;Ham M. Rara;Aly A. Farag	2012	2012 Ninth Conference on Computer and Robot Vision	10.1109/CRV.2012.40	facial recognition system;computer vision;photometric stereo;visual perception;depth perception;shape;computer science;harmonic analysis;mathematical model;lighting;mathematics;reflectivity;skin;computational model;regression analysis;statistics;spherical harmonics;computer graphics (images)	Vision	54.51611605233285	-52.932508638201526	72485
f15941e6a6a0e19349885a471700d802db015795	legibility of perceptually-tuned grayscale fonts	image recognition;gray scale bars character generation liquid crystal displays filtering frequency bismuth psychology marine vehicles shape;digital typography;image recognition character recognition character sets;subjective preferences perceptually tuned grayscale fonts legibility character outline descriptions thin character parts well contrasted bars character shape parts bilevel display fonts reading speed typography font size italic string search task;character sets;character recognition	Perceptually-tuned grayscale fonts are generated from character outline descriptions by applying to them a set of modifications specifically conceived for strengthening thin character parts, obtaining well-contrasted bars and preserving important relationships between character shape parts. The present study aims at comparing the legibility of perceptually-tuned grayscale and bilevel display fonts at small and very small sizes ( 6, 8 and 10 pt). The study confirms the results of previous studies indicating that reading speed is to a large extent independent of the typography (bilevel or grayscale) and the font size. However, perceptually-tuned grayscale characters perform better than bilevel characters for an italic string search task in a meaningless text. Regarding the subjective preferences of the test subjects, perceptually-tuned grayscale fonts at 8 and 10 point sizes received a superior rating than bilevel fonts at the same sizes. 1. PERCEPTUALLY TUNED GRAYSCALE FONTS In order to improve the display of text on limited resolution computer displays, researchers have tried to trade-off the lack of spatial resolution for an increased number of intensity levels [1, 2, 3]. Especially with respect to typographic text display on resolution limited CRT and LCD display devices, it has been shown that using grayscale makes font dependent character features visible which disappear when displaying text with bilevel characters. Though they can more accurately render font differences, grayscale characters generated by filtering and resampling high-resolution bilevel master characters nevertheless look rather fuzzy.	cathode ray tube;computer monitor;grayscale;image resolution;string searching algorithm;text display	J. Kevin O'Regan;Nicole Bismuth;Roger D. Hersch;Alexandros Pappas	1996		10.1109/ICIP.1996.559552	computer vision;character encoding;computer science;computer graphics (images)	HCI	61.34144563554261	-60.431558188844825	72489
839ceee424297acd807bc116a0fd500a23a77cdc	interreflections in computer vision: a survey and an introduction to spectral infinite-bounce model	interreflection;mutual illumination;inverse problem;computer vision	Interreflections are observed on concave objects or when multiple objects are located closely. In a vision system, interreflections can largely affect color values captured by the camera. Due to this fact, modeling interreflections is important for many vision applications. In this paper, we consider the problem of treating and modeling interreflections in the domain of computer vision. First, a survey of existing approaches in the state of the art is given. These approaches are detailed, discussed and compared. Most of the state of the art models take into consideration only two bounces of light between surface elements. We, afterward, introduce a new interreflection model based on radiometric definitions. This model is the first one that takes into consideration an infinite number of light bounces between surface elements while providing image RGB values as a result. The accuracy of our model is studied by comparing it to real camera outputs. Thanks to our new model, the importance of using infinite bounces of light while studying interreflection, instead of only two bounces, is demonstrated.	bounce message;computer vision;concave function;webcam	Rada Deeb;Damien Muselet;Mathieu Hébert;Alain Trémeau	2017	Journal of Mathematical Imaging and Vision	10.1007/s10851-017-0781-x	artificial intelligence;computer vision;mathematics;mathematical optimization;inverse problem;rgb color model;machine vision	Vision	58.9501756817925	-52.17035435949896	72501
c492ae030435584f3a8996e7595a6f14ac092306	color measurements with a consumer digital camera using spectral estimation techniques	minimisation;printing;consumidor;minimization;linear estimation;image processing;time measurement;gestion production;consommateur;facteur reflexion;chronometrie;materials engineering;estimacion lineal;procesamiento imagen;digital camera;minimizacion;linear constraint;traitement image;production management;estimation lineaire;engineering and technology;teknik och teknologier;production control;reflectance;consumer;gestion produccion;cronometria;analyse spectrale;impression;analisis espectral;materialteknik;spectral estimation;spectral analysis;impresion;coeficiente reflexion	The use of spectrophotometers for color measurements on printed substrates is widely spread among paper producers as well as within the printing industry. Spectrophotometer measurements are precise, but timeconsuming procedures and faster methods are desirable. The rapid development of digital cameras has opened the possibility to use consumer digital cameras as substitutes for spectrophotometers for certain applications such as production control. Two methods for estimating the reflectance properties of objects from camera RGB measurements using linear estimation techniques combined with linear and non-linear constraints are presented. In the experiments, we have investigated if these techniques can be used to measure the reflectance properties of flat objects such as printed pages of paper. Reflectances were converted to CIELAB color values, and the minimization of color errors were evaluated with CIE color difference formulas. Our experiments show that a consumer digital camera can be used as a fast and inexpensive alternative to spectrophotometers for color measurements on printed substrates.	computability in europe;digital camera;estimation theory;experiment;nonlinear system;printing;spectral density estimation	Martin Solli;Mattias Andersson;Reiner Lenz;Björn Kruse	2005		10.1007/11499145_12	minimisation;consumer;telecommunications;image processing;computer science;mathematics;spectral density estimation;reflectivity;statistics;time	HCI	61.774510260715864	-58.45927936897393	72532
8d03ec6f47abd70fd1236220d11d27324b6042fe	"""correction to """"a coarse-to-fine matching algorithm for flir and optical satellite images registration"""""""	optical imaging;target recognition;remote sensing;image registration;satellites;satellite image;optical sensors;optical sensor;optical imaging satellite navigation systems image registration optical imaging geometrical optics algorithm design and analysis;algorithm design and analysis;adaptive optics;satellite navigation systems;geometrical optics	In the above titled paper (ibid., vol. 9, no. 4, pp.599-603, Jul. 2012), formulas (10) and (12) are incorrect. Their correct forms are presented here.	algorithm	Zhiguo Qu;Ping Wang;Yinghui Gao;Zhenkang Shen	2012	IEEE Geosci. Remote Sensing Lett.	10.1109/LGRS.2012.2196891	geometrical optics;algorithm design;computer vision;sensor;image registration;optical imaging;optics;adaptive optics;physics;satellite;remote sensing	Vision	75.01891365752913	-62.82045473592294	72596
31df39a27bf55aef49769177df39b6acd025561f	sar traffic monitoring using time-frequency analysis for detection and parameter estimation	condition monitoring time frequency analysis parameter estimation chirp modulation signal detection data mining matched filters fourier transforms frequency modulation road vehicles;azimuth;radarkonzepte;frequency modulation;history;fractional fourier transform;linear frequency modulation;moving target signal detection;road traffic;ground moving target indicator;synthetic aperture radar fourier transforms geophysical signal processing geophysical techniques remote sensing by radar road traffic signal detection;signal detection;institut fur hochfrequenztechnik und radarsysteme;moving target signal extraction;moving road vehicles synthetic aperture radar sar traffic monitoring time frequency analysis ground moving target indication gmti algorithm cell migration correction moving target signal detection moving target signal extraction along track velocity estimation matched filter banks fractional fourier transform linear frequency modulated signals;gmti algorithm;data mining;remote sensing by radar;along track velocity estimation;doppler effect;a priori knowledge;estimation;condition monitoring;geophysical signal processing;linear frequency modulated signals;cell migration;ground moving target indication;fourier transforms;cell migration correction;motion parameter estimation;matched filters;chirp modulation;fractional fourier transform moving target indication mti motion parameter estimation synthetic aperture radar;parameter estimation;velocity estimation;traffic monitoring;matched filter;moving road vehicles;time frequency analysis;sar traffic monitoring;geophysical techniques;moving target indication mti;matched filter banks;road vehicles;synthetic aperture radar	In the paper a ground moving target indication (GMTI) algorithm operating on preprocessed range-compressed SAR data is presented. For preprocessing range cell migration correction for stationary targets in most practical cases is sufficient. Moving target signal detection and extraction, adaptive range cell migration correction, position and across as well as along-track velocity estimation is then performed without a priori knowledge by using matched filter banks and the fractional Fourier transform. The proposed algorithm is able to cope with multi-component linear frequency modulated signals as they arise in real traffic scenarios containing a number of moving road vehicles.	algorithm;detection theory;estimation theory;filter bank;fractional fourier transform;frequency analysis;matched filter;modulation;moving target indication;preprocessor;stationary process;velocity (software development)	Stefan V. Baumgartner;Gerhard Krieger	2008	IGARSS 2008 - 2008 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2008.4778918	telecommunications;matched filter;physics;remote sensing	Robotics	75.47242332759903	-66.41088934124865	72628
29afde1a6e751af403694d00d4cd9bbfd83327a9	motion-compensated frame interpolation using patch-based sparseland model	motion compensated frame interpolation;predictive search;maximum a posteriori estimation;sparseland model;optical flow	Using patch-based sparseland model, we design a novel Motion-Compensated Frame Interpolation (MCFI) method. Optical-flow estimation is first adopted to generate a reliable Motion Vector Field (MVF) from the previous frame to the following frame. Then we use patch-based bidirectional motion estimation to generate a smooth Motion Vector Felid (MVF). In the last step, we extract patches from reference frames along the motion trajectories, and perform Principle Component Analysis (PCA) to generate dictionaries that code the patches with various local structures. The sparseland model becomes the prior knowledge of the intermediate frame to fuse into the Motion Compensated Interpolation (MCI) by maximum a posteriori (MAP) criterion. By iterative numerical computing, we solve this sparseland-prior reconstruction model, and acquire a sparsity-preferred interpolated frame. Experimental results show that our method outperforms the existing algorithms in both objective and subjective picture qualities, but it also introduces a high computational complexity in the meantime.	algorithm;computational complexity theory;dictionary;iterative method;k-means clustering;motion interpolation;nos;numerical analysis;numerical method;optical flow;real-time clock;real-time computing;sparse matrix	Ran Li;Hongbing Liu;Zhenghui Liu;Yanling Li;Zhangjie Fu	2017	Sig. Proc.: Image Comm.	10.1016/j.image.2017.02.010	inter frame;residual frame;computer vision;mathematical optimization;simulation;computer science;maximum a posteriori estimation;optical flow;mathematics	Vision	57.09448675801459	-70.10803009494664	72629
8b68cf0eba248a223a4e348fd880a2e7d58f4cd4	joint sar image compression and coherent change detection	compression synthetic aperture radar change detection;image coding;quantization signal;synthetic aperture radar data compression geophysical image processing geophysical techniques radar imaging;charge coupled devices;block adaptive quantization method sar image compression coherent change detection synthetic aperture radar foot prints sar imagery image resolution image precision sar change detection systems unmanned aerial vehicles sar data compression sar ccd performance model based compression method sar data distribution decompressed sar pair;radar imaging;synthetic aperture radar image coding charge coupled devices data models correlation quantization signal radar imaging;correlation;data models;synthetic aperture radar	Fine details revealed by synthetic aperture radar (SAR) coherent change detection (CCD), such as foot prints, require SAR imagery with both high resolution and precision. These large data requirements are at odds with the low bandwidths often available for SAR change detection systems such as those that utilize small unmanned aerial vehicles (UAVs). Here we investigate the interplay between SAR data compression and SAR CCD performance. As the data are compressed further, the ability to detect changes decreases. However, there is redundant information contained in SAR imagery that is not necessary for change detection, and removing it makes SAR compression possible. In this paper, we introduce a new model-based compression method that leverages the known distribution of SAR data for a compact storage, while improving change detection performance. We show experimentally that the CCD using the decompressed SAR pair after our proposed method not only yields significant improvement in change detection over the CCD using the decompressed SAR after block adaptive quantization (BAQ) method, but also over the CCD using the original SAR data. Experimental results are presented to show the effectiveness and robustness of the proposed algorithm for SAR compression and change detection.	aerial photography;algorithm;aperture (software);charge-coupled device;coherence (physics);data compression;experiment;image compression;image resolution;quantization (signal processing);requirement;synthetic data;unmanned aerial vehicle	Miriam Cha;Myra Nam;Kelly Geyer	2014	2014 IEEE Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2014.6946343	data modeling;computer vision;synthetic aperture radar;geology;radar imaging;inverse synthetic aperture radar;correlation;remote sensing	Robotics	67.991899516576	-62.520741728683326	72651
44be90f66092a7928f967ca6a00c6dd4bd41eceb	efficient autofocus for 3-d sar sparse imaging based on joint criterion optimization		This paper presents an efficient sparse autofocusing algorithm for 3-D SAR imaging based on joint criterion optimization. Exploiting by the least square (LS) regularization sparse recovery technique, an autofocus model combined with minimum mean square error criterion and maximum sharpness criterion, is constructed for 3-D SAR sparse image formation via linear measurement expression. Moreover, the adaptive weighted factor for phase error estimation is derived. Then, a joint iterative estimated method is introduced to efficiency estimate the phase errors. Numerical simulation and experimental results are provided to demonstrate the effectiveness of the proposed algorithm with different types of phase error.	algorithm;compressed sensing;computer simulation;image formation;iterative method;mathematical optimization;mean squared error;sparse matrix	Shunjun Wei;Min Yan;Bokun Tian;Lin Pu;Xiaoling Zhang;Jun Shi	2018	IGARSS 2018 - 2018 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2018.8518028	autofocus;computer vision;radar imaging;sparse image;synthetic aperture radar;computer simulation;artificial intelligence;minimum mean square error;least squares;solid modeling;computer science	Vision	58.1223466809562	-74.32180934726533	72664
e4ac687c62553fd476f25227a5161a13330e1267	robust, efficient depth reconstruction with hierarchical confidence-based matching	image reconstruction optimization robustness mobile handsets three dimensional displays pipelines;depth recovery depth reconstruction multiview stereo stereo matching confidence map;three dimensional displays;image reconstruction;pipelines;mobile handsets;robustness;optimization	In recent years, taking photos and capturing videos with mobile devices have become increasingly popular. Emerging applications based on the depth reconstruction technique have been developed, such as Google lens blur. However, depth reconstruction is difficult due to occlusions, non-diffuse surfaces, repetitive patterns, and textureless surfaces, and it has become more difficult due to the unstable image quality and uncontrolled scene condition in the mobile setting. In this paper, we present a novel hierarchical framework with multi-view confidence-based matching for robust, efficient depth reconstruction in uncontrolled scenes. Particularly, the proposed framework combines local cost aggregation with global cost optimization in a complementary manner that increases efficiency and accuracy. A depth map is efficiently obtained in a coarse-to-fine manner by using an image pyramid. Moreover, confidence maps are computed to robustly fuse multi-view matching cues, and to constrain the stereo matching on a finer scale. The proposed framework has been evaluated with challenging indoor and outdoor scenes, and has achieved robust and efficient depth reconstruction.	computer stereo vision;control theory;depth map;evaluation;fuse device component;gaussian blur;ground truth;image quality;matching;mathematical optimization;mobile device;numerous;obstruction;pyramid (image processing);uncontrolled format string;unstable medical device problem	Li Jian Sun;Ke Chen;Mingli Song;Dacheng Tao;Gang Chen;Chun Chen	2017	IEEE Transactions on Image Processing	10.1109/TIP.2017.2687101	iterative reconstruction;computer vision;simulation;computer science;pipeline transport;robustness;computer graphics (images)	Vision	56.337979566111606	-56.310305532475	72706
ecf53127ff8fc051b74181018f750e589f666712	development of a method for remote sensing of land-cover change 1980-2000 in the usfs north central region using heterogeneous usgs luda and noaa avhrr 1 km data	land cover classification;time series;remote sensing;usa heterogeneous usgs luda data noaa avhrr data national land cover classification ad 1980 to 2000 remote sensing method forest urban areas agricultural areas usfs north central region land cover change napp photographs luda protocols avhrr isodata classification nri land cover statistical data idrisl illinois indiana iowa michigan minnesota missouri wisconsin;satellite imagery;terrain mapping;remote sensing spatial resolution satellites belts us department of agriculture road transportation protocols image processing lakes rail transportation;land cover change;land cover	A 1980 national land-cover classification (USGS LUDA aggregated to 1 km) was combined with 2000 satellite imagery (AVHRR NDVI time series) to derive land-cover change information for forest, urban, and agriculture categories in southeast Michigan, part of the USFS North Central Region. To derive useful land-cover change data using a heterogeneous dataset, we (a) interpreted a sample of NAPP photographs from 2000 following 1980 LUDA protocols and used this interpreted land-cover for calibrating a 2000 AVHRR ISODATA classification, and (b) used NRI land-cover statistical data to develop relationships between 1980 NRI and 1980 LUDA proportions for the three classes to develop expected proportions in each class for 2000 AVHRR. We further constrained this by using the NRI predicted proportions with an allocation procedure in IDRISI. Results showed that these approaches we adopted in order to produce comparable classifications improved on AVHRR ISODATA classifications alone.		Kathleen M. Bergen;Daniel G. Brown;James R. Rutherford;Eric J. Gustafson	2002		10.1109/IGARSS.2002.1025891	meteorology;hydrology;time series;statistics;remote sensing	Robotics	81.58231780249139	-57.39377400353752	72822
2b1668e3ba21bd8021ff0c2eeb78b7d2d82a14b4	a new approach of blind image restoration	iterative algorithm blind image restoration blurring image acquisition systems deblur methods point spread function blurred images gaussian blur noise reduction preprocessing edge detection;edge detection image restoration optical transfer function noise;optical transfer function;edge detection;image restoration;iterative algorithm;image acquisition;point spread function;image restoration noise reduction iterative algorithms image edge detection educational institutions computer science image databases degradation low frequency noise image reconstruction;noise	Blurring is inevitable in many image acquisiiion sysiems. Blind image restoration is one of deblur methods, and because it does not need a priori point spread function (PSF), it becomes more and more popular. In ihis paper, a novel method of blind image restoration is presented which can be applied to various kinds of images. The method has no limiiation on blurred images, and does not need any extra database supports. Gaussian Blur is assumed to be able to present every other blur, and by successfully dealing with Gaussian Blur, our method can be suitable io deal with other blur methods. In order to reduce the noise, a pre-processing step is introduced. With edge deiection, point spread function can be reconstmcted automatically. Then an iteraiive algorithm is used to restore the image. Experimental resulis show the good performance of this method.	algorithm;circuit restoration;gaussian blur;image restoration;preprocessor	Cheng Jin;Chun Chen;Jiajun Bu	2003		10.1109/ICSMC.2003.1243823	image restoration;image noise;computer vision;feature detection;edge detection;image gradient;image processing;computer science;noise;gaussian blur;point spread function;optical transfer function;mathematics;iterative method;computer graphics (images)	Vision	56.95329937991609	-65.45110276356381	73009
2ac933b54a11e29330a49d70bed988f7835e03a0	a study on camera-detector system for traffic control in korea	coreano;microwave;base donnee;measurement accuracy;integration information;road traffic;data collection;gestion trafic;hyperfrequence;conceptual analysis;database;base dato;traffic control;traffic management;satisfiability;analisis conceptual;korean;captador medida;information integration;measurement sensor;autoroute;capteur mesure;trafic routier;coreen;precision mesure;autopista;integracion informacion;hiperfrecuencia;gestion trafico;radio wave;trafico carretera;information system;precision medida;analyse conceptuelle;freeway;systeme information;onda radio;onde radioelectrique;sistema informacion	Actual detectors of traffic information in Korea adopt the loop detector system. The evaluation of alternative detector of the above system such as camera or microwave detector has been limited to the situation for uninterrupted flow instead of interrupted one. However, recently the installation of camera-detectors tends to be rapidly increased in freeways. In the case of camera detector, it appears to satisfy the requirement of measurement accuracy of traffic variables such as occupancy, traffic amount and speed in the interval unit of 5 or 15 min of uninterrupted flow situation. This study is to understand the traffic information data collection level required in the sophistication of future Korean traffic control in focusing on city map and freeways and to analyze and evaluate the loop detector as alternative for camera detector.		Chang-Hee Kwon;Hong-Jin Park	2004		10.1007/978-3-540-30466-1_52	simulation;telecommunications;microwave;computer science;information integration;radio wave;database;information system;korean;statistics;data collection	Robotics	74.56219063386781	-55.25196289012185	73042
9d1db5ac0c8c5dd88ecb203da5985f17442d306a	hierarchical super-resolution approach for expanding image with high magnification	hierarchical super resolution;interpolation;video surveillance;image processing;image resolution;sr;high resolution images;visual communication;image resolution computational complexity image reconstruction;low resolution;super resolution image reconstruction;strontium;high magnification image;medical image;estimation;computational complexity;image reconstruction;medical imaging;pixel;high magnification super resolution sr optical flow multi frame;super resolution;high magnification;optical flow;super resolution image reconstruction hierarchical super resolution high magnification image visual communication image processing high resolution images video surveillance medical imaging computational complexity;high resolution imager;image resolution strontium image reconstruction cameras security pixel visual communication image processing video surveillance biomedical imaging;proposals;multi frame	Recently, with the development of visual communication and image processing, there is a high demand for High-Resolution images such as video surveillance, medical imaging, and so on. Therefore, the Super-Resolution technology that produces a high-resolution image from a set of shifted, blurred, and decimated versions is actively researched. However, most previously published techniques perform well only for small magnifications but get worse either in computational complexity or ringing artifacts for large magnifications. In this paper, we propose a Hierarchical algorithm for high-magnification Super-Resolution image reconstruction. The proposed algorithm magnifies the low-resolution image in multiple steps. Experiment results show that the new approach is more efficient and can provide much better reconstruction quality in comparison with the reconstruction result in one step.	algorithm;closed-circuit television;computational complexity theory;decimation (signal processing);image processing;image resolution;iterative reconstruction;medical imaging;ringing artifacts;super-resolution imaging	Motonori Ohashi;Xian-Hua Han;Yen-Wei Chen	2009	2009 Fifth International Conference on Natural Computation	10.1109/ICNC.2009.658	computer vision;image processing;computer science;optics;computer graphics (images)	Vision	58.7437689139172	-58.64937611561168	73061
2cba05a020f6a58f629abf70ce9462d49af7925f	estimation of skew angle in text-image analysis byslide: subspace-based line detection	reseau capteur;text;image processing;sensor array processing;procesamiento imagen;text analysis;texte;traitement image;analyse;line fitting;red sensores;sensor array;skew detection;ocr;analysis;texto;analisis	A new signal processing method is developed for estimating the skew angle in text document images. Detection of the skew angle is an important step in text processing tasks such as optical character recognition (OCR) and computerized filing. Based on a recently introduced multiline-fitting algorithm, the proposed method reformulates the skew detection problem into a special parameter-estimation framework such that a signal structure similar to the one in the field of sensor array processing is obtained. In this framework, straight lines in an image are modeled as wavefronts of propagating planar waves. Certain measurements are defined in this virtual propagation environment such that the large amount of coherency that exists between the locations of the pixels on parallel lines is exploited to enhance a subspace in the space spanned by the measurements. The well-studied techniques of sensor array processing (e.g., the ESPRIT algorithm) are then exploited to produce a closed form and high-resolution estimate for the skew angle.	algorithm;array processing;edge detection;estimation theory;image analysis;image resolution;optical character recognition;pixel;signal processing;software propagation;whole earth 'lectronic link	Hamid K. Aghajan;Babak Hossein Khalaj;Thomas Kailath	1994	Machine Vision and Applications	10.1007/BF01213417	computer vision;speech recognition;image processing;computer science;analysis	Robotics	64.73127483065113	-71.15021170022878	73082
2f68bea54c1deb64d0eeb63e63d78d71e08864f5	ice cover determination of the volga and the don river reservoirs on the base of jason-2 sattelite observations	rivers hydrological techniques ice remote sensing reservoirs;frequency 5 ghz to 37 ghz ice cover determination volga reservoirs don river reservoirs altimetry jason 1 2 satellite data geophysical data record freshwater inland water bodies dual frequency radar altimeters three channel microwave radiometers;reservoirs satellites satellite broadcasting ice brightness temperature backscatter	This work aims to development of a simple method for distinction between open water and ice cover on the base of geophysical data record (GDR) of altimetry satellite Jason-2 for large and middle-sized freshwater inland water bodies. The method is applied for six reservoirs at the Volga and Don Rivers. It was shown earlier [1, 2] that the retracking of the Jason-1, 2 satellite data allow us to determine with sufficient accuracy the water level variations either for the large Rybinsk reservoir, or for the middle-sized Volga reservoirs (the Gorky reservoir and others). Ice and snow conditions of inland waters are of interest since they influence the life and economic activity of people and are significant indicators of climate changes. Satellite methods of ice-snow cover observations have certain advantages, connected with the global coverage, instantaneous observations of large water areas and relatively low cost. However, the use of satellite methods for inland waters is often limited by their spatial resolution comparable to or greater than the size of water reservoirs. Satellites carrying instruments of high spatial resolution often have large repeat periods (ICESat), either the data quality strongly depend on weather conditions (Landsat). In this regard, the use of Jason -1, 2 satellites, equipped with a dual-frequency (13.6 GHz and 5 GHz) radar altimeters and three-channel (18, 21 and 37 GHz) microwave radiometers is of great interest, because the footprint diameter of their altimeters in Ku-band is about 10 Km and the repeat period of observations is ten days, that make them suitable for observations of large and medium-sized inland waters.	data quality;don woods (programmer);jason;ku band;microwave;radar;row (database)	Galina Rybushkina;Yuliya I. Troitskaya;Irina Soustova	2014	2014 IEEE Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2014.6946378	meteorology;sea ice thickness;hydrology;remote sensing	Mobile	82.41701055949682	-58.786246654390474	73105
91d6075d64d87046b1245874e6a61736cecf467c	modified clipped histogram equalization for contrast enhancement	contrast enhancement;histograms dynamic range color heuristic algorithms noise brightness consumer electronics;consumer electronics;image enhancement consumer electronics;image enhancement;histogram equalization contrast enhancement dynamic range;dynamic range;consumer electronics clipped histogram equalization contrast enhancement che visual quality improvement dark regions bright regions automatic dynamic image range detection;histogram equalization	Histogram equalization (HE) based methodologies are popular and effective ways to improve image contrast and visual quality, but standard HE is not directly applied on consumer electronics. This paper proposes a modified Clipped Histogram Equalization (CHE) for contrast enhancement based on the fundamental of histogram modification. It improves the visual quality by enhancing details both in dark and bright regions through automatically detecting the dynamic range of the image. Experimental results show that the proposed algorithm outperforms state-of-the-art HE based algorithms in improving contrast and giving a visually-pleasing result while avoiding over-enhancement and noise amplification. Its high efficiency makes the proposed method practical for applications on consumer electronic.	adaptive histogram equalization;algorithm;clipped tag;dynamic range;grayscale;matlab;real-time clock;real-time computing;sensor	Yuecheng Li;Hong Zhang	2012	2012 13th International Conference on Parallel and Distributed Computing, Applications and Technologies	10.1109/PDCAT.2012.97	computer vision;dynamic range;color normalization;shadow and highlight enhancement;computer science;histogram matching;adaptive histogram equalization;histogram equalization;image histogram;computer graphics (images)	EDA	57.11557742947864	-64.045069092267	73112
61ecd405d72b84f7e470e6394c8dc9bde84cb8f9	resolving scaling ambiguities with the ℓ1/ℓ2 norm in a blind deconvolution problem with feedback	kernel;seismology deconvolution feedback geophysical signal processing geophysical techniques numerical analysis;convolution;earth;deconvolution convolution kernel sea measurements conferences earth;numerical experiments blind deconvolution problems seismic applications feedback mechanism free surface plagued blind deconvolution l 1 constraints l 2 constraint scaling ambiguity lifting approaches sparse signal;deconvolution;conferences;method of multipliers blind deconvolution l1 l2 norm lifting;sea measurements	Compared to more mundane blind deconvolution problems, blind deconvolution in seismic applications involves a feedback mechanism related to the free surface. The presence of this feedback mechanism gives us an unique opportunity to remove ambiguities that have plagued blind deconvolution for a long time. While beneficial, this feedback by itself is insufficient to remove the ambiguities even with ℓ1 constraints. However, when paired with an ℓ1/ℓ2 constraint the feedback allows us to resolve the scaling ambiguity under relatively mild assumptions. Inspired by lifting approaches, we propose to split the sparse signal into positive and negative components and apply an ℓ1/ℓ2 constraint to the difference, thereby obtaining a constraint that is easy to implement. Numerical experiments demonstrate robustness to the initialization as well as to noise in the data.	blind deconvolution;experiment;feedback;lifting scheme;list of code lyoko episodes;sparse matrix	Ernie Esser;Tim T. Y. Lin;Felix J. Herrmann;Rongrong Wang	2015	2015 IEEE 6th International Workshop on Computational Advances in Multi-Sensor Adaptive Processing (CAMSAP)	10.1109/CAMSAP.2015.7383812	mathematical optimization;deconvolution;machine learning;mathematics;blind deconvolution;statistics;wiener deconvolution	Vision	57.523626489474964	-72.53022634268078	73120
a4d38cb65523646aac7961353635599c229db452	motion compensation processing of airborne sar data	focusing;azimuth;sensor path irregularity airborne sar data motion compensation processing airborne sensor sensor trajectory segments;wavenumber domain sar motion compensation;motion compensation focusing history global positioning system image segmentation antenna arrays chirp image sensors azimuth navigation;high resolution;airborne sar data;image segmentation;history;chirp;motion compensation;antenna arrays;synthetic aperture radar airborne radar motion compensation remote sensing by radar;image sensors;motion compensated;remote sensing by radar;navigation;doppler effect;sar;trajectory;global positioning system;wavenumber domain;antennas;airborne radar;sensor trajectory segments;sensor path irregularity;motion compensation processing;airborne sensor;synthetic aperture radar	This paper presents a motion compensation algorithm to focus high resolution SAR data taken from an airborne sensor. The basic idea is to fragment the sensor trajectory into smaller segments that can be modelled as linear or quadratic. The synthetic antenna is then considered as an array of smaller subarrays. The algorithm can easily adapt and trade efficiency for sensor path irregularity. In fact the algorithm is more efficient if the segments are longer. Experimental results with real airborne data confirm the correctness of the approach.	airborne ranger;algorithm;array data structure;correctness (computer science);image resolution;motion compensation;quadratic function;synthetic data	Pietro Guccione;Ciro Cafforio	2008	IGARSS 2008 - 2008 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2008.4779560	computer vision;navigation;synthetic aperture radar;image resolution;global positioning system;doppler effect;geodesy;specific absorption rate;trajectory;antenna;image sensor;azimuth;image segmentation;motion compensation;chirp;physics;remote sensing	Embedded	77.76302052974027	-65.43379622497307	73200
3f195ac3e5b87fbacb8c01ed7ebc7e076073a647	transform amplitude sharpening: a new method of image enhancement	integral transformations;processing;general and miscellaneous mathematics computing and information science;image processing;fourier transform;frequency analysis;transformations 990200 mathematics computers;method of image;digital frequency analysis;mathematical logic;image enhancement;integral transforms;image generation;fourier transformation;algorithms;frequency domain;logical process;two dimensional calculations	"""A new frequency-domain based technique is proposed. In the proposed method, the magnitude of the Fourier transform of the image is modified using a noval amplitude change function with the phase kept invariant. The inverse transform of the new 2D transform results in an enhanced image. The amplitude change function used is the Tukey's twicing function (Exploratory Data Analysis, Addison-Wesley, Reading, MA, 1977). In many applications, multiple use of the twicing function is shown to yield better results. The proposed method is somewhat similar to the alpha-rooting method but does not suffer from certain objectionable artifacts associated with the latter and also exhibits less degradation due to noise. A postprocessing of the enhanced image generated using the proposed transform amplitude method via histogram modification has been found to improve the picture quality. A number of image enhancement examples are included illustrating the effectiveness of the proposed method. ~"""" 1987 Academic Prcss, Inc."""	elegant degradation;image editing;image quality	Sanjit K. Mitra;Tian-Hu Yu	1987	Computer Vision, Graphics, and Image Processing	10.1016/S0734-189X(87)80115-9	fourier transform;s transform;short-time fourier transform;continuous wavelet transform;image processing;computer science;theoretical computer science;mathematics;top-hat transform;algorithm	Vision	59.804559776280705	-66.17676282252924	73226
eeae0c1e136c573cd683d31a13e6c2431f0d0394	ratio-detector-based feature extraction for very high resolution sar image patch indexing	image segmentation;photogrammetrie und bildanalyse;image classification;synthetic aperture radar feature extraction indexing histograms detectors remote sensing image edge detection;high resolution terrasar x patches feature extraction very high resolution sar image patch indexing synthetic aperture radar local content description image segmentation pixel level classification high level semantic description sar image interpretation ratio edge detector vhr sar image content characterization bag of word model weber local descriptor sar image database;feature extraction;radar imaging;weber local descriptor wld bag of words bow feature extraction ratio detector sar image indexing synthetic aperture radar sar;synthetic aperture radar feature extraction image classification image segmentation radar imaging;synthetic aperture radar	With the advent of very high resolution (VHR) synthetic aperture radar (SAR) images, local content description is becoming a critical issue for indexing. Conventional SAR image analysis techniques, like segmentation and pixel-level classification, are likely to fail as high-level semantic description should be considered for better discrimination. Therefore, we propose to use image-patch-based analysis method for SAR image interpretation. Inspired by ratio edge detector, in this letter, a new feature extraction method represented by the mean ratios in different directions is proposed for VHR SAR image content characterization. Based on the mean ratio, two simple yet powerful and robust features are proposed for SAR image patch indexing. One is the bag-of-word model using not only the basic statistics, i.e., local mean and variance, but also the mean ratios in different directions. The second one is an adaptation of the Weber local descriptor to SAR images by substituting the gradient with the ratio of mean differences in vertical and horizontal directions. To evaluate the proposed features, image patch indexing based on active learning using a SAR image database consisting of high-resolution TerraSAR-X patches is performed. Comparison with the state-of-the-art features, particularly texture features, has shown improved performance for SAR image categorization.	aperture (software);categorization;edge detection;feature extraction;gradient;high- and low-level;image analysis;image resolution;patch (computing);pixel;synthetic data	Shiyong Cui;Corneliu Octavian Dumitru;Mihai Datcu	2013	IEEE Geoscience and Remote Sensing Letters	10.1109/LGRS.2012.2235406	image texture;computer vision;contextual image classification;feature detection;synthetic aperture radar;feature extraction;computer science;pattern recognition;image segmentation;radar imaging;inverse synthetic aperture radar;remote sensing	Vision	72.2881309812115	-61.7076332354918	73275
359650d31662737db76c7984c572835e0517ea6c	vicarious calibration of ccd on cbers02b using gongger test site	charge coupled image sensors;ad 2007 09 19;cbers02b satellite;sensor calibration;radiative transfer;atmospheric measurements;radiative transfer code;onboard calibrator;gongger test site;sensors;test site;cbers02b ccd;earth;ad 2007 10 12;dunhuang test site;testing;charge coupled devices;ccd image sensors;surface reflectance;vicarious calibration;ccd calibration;reflectance based method;field measurement;gongger;remote sensing;satellites;gongger test site cbers02b ccd vicarious calibration reflectance based method;artificial satellites;geophysical equipment;top of atmosphere;calibration charge coupled devices testing remote sensing satellites earth charge coupled image sensors spatial resolution atmospheric measurements extraterrestrial measurements;extraterrestrial measurements;radiative transfer artificial satellites calibration ccd image sensors geophysical equipment;calibration;dunhuang test site ccd calibration cbers02b satellite gongger test site ad 2007 09 19 onboard calibrator ad 2007 10 12 surface reflectance radiative transfer code;spatial resolution	CBERS02B with three payloads onboard was successfully launched on September 19, 2007 in order to ensure the continuity of CBERS series and CCD is one of three payloads. Calibration of CCD is a precursor for its quantitative application because there isn't onboard calibrator for CCD. A comprehensive vicarious calibration and validation campaign of CCD was performed at Gongger test site on October 12, 2007. The reflectance-based calibration method was used in this campaign with the ground measurements of the surface reflectance and atmospheric characteristics. Then 6S, a radiative transfer code, was used to compute the top-of-atmosphere(TOA) radiance at the sensor. Calibration result was obtained for CCD showing that some change brought to the CCD after launch, especially band 1 and band 2. The in-situ field measurement at the Dunhuang test site was collected validating that the calibration result was good expect for band 4.	charge-coupled device;scott continuity	Hui Gong;Tao Yu;Guoliang Tian;Xingfa Gu;Hailiang Gao;Xiaoying Li;David L. B. Jupp;Yi Qin	2009	2009 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2009.5417788	optics;physics;satellite;remote sensing	Robotics	81.97198100083567	-63.79280184804763	73277
43862edc2409c82996c5087f96d495ccf89f36e6	an iterative haze optimized transformation for automatic cloud/haze detection of landsat imagery	earth remote sensing satellites clouds land surface indexes multivariate regression;haze contamination iterative haze optimized transformation automatic cloud haze detection landsat imagery haze optimized transformation land surface information bright surfaces top of atmosphere;landsat imagery haze detection haze optimized transformation hot haze thickness iterative hot ihot;remote sensing by radar atmospheric optics	Most previous haze/cloud detection methods for Landsat imagery, e.g., haze optimized transformation (HOT), cannot adequately suppress land surface information and, in particular, often overestimate haze thickness over bright surfaces. This paper proposes an iterative HOT (IHOT) for improving haze detection with the help of a corresponding clear image. With an iterative procedure of regressions among HOT, the reflectance difference at the top of atmosphere (TOA) between hazy and clear images, and TOA reflectances of hazy and clear images, the land surface information can be removed, and the iterative HOT (IHOT) result is derived to spatially characterize the haze contamination in the Landsat images. A group of Landsat images that were acquired in different landscapes and seasons were used to test IHOT. Visual comparisons indicate that IHOT performed better than previous haze detection methods for images that were acquired in diverse landscapes and also performed robustly for hazy images that were acquired at different seasons when using the same reference clear image. Additionally, two indirect quantitative validations were used to illustrate that IHOT can provide the best transformation for accurately determining haze information. Therefore, it is expected that the proposed IHOT method will be used for automatic cloud/haze detection for large numbers of Landsat images if data sets of clear Landsat imagery are available.	iterative method;thickness (graph theory);time of arrival	Shuli Chen;Xuehong Chen;Jin Chen;Pengfei Jia;Xin Cao;Canyou Liu	2016	IEEE Transactions on Geoscience and Remote Sensing	10.1109/TGRS.2015.2504369	meteorology;atmospheric sciences;remote sensing	Vision	76.09661470011856	-62.393297089023996	73280
f64e43075b0ba1485d94f4b89faab97b48b6280b	the determination of cloud altitudes using sciamachy onboard envisat	radiative transfer;remote sensing atmospheric techniques height measurement clouds;onboard measurement cloud altitudes determination sciamachy onboard envisat semianalytical cloud retrieval algorithm top of atmosphere reflectance oxygen a band geometrical thickness cloud top height space;clouds pollution measurement reflectivity satellites information retrieval physics atmospheric measurements spatial resolution instruments absorption;height measurement;clouds;remote sensing;atmospheric techniques;top of atmosphere;cloud top height;cloud profiling radar	This letter shows first results for the application of a recently developed semianalytical cloud retrieval algorithm for the determination of cloud top heights from space. The technique is based on the measurements of the top-of-atmosphere reflectance in the oxygen A-band. The depth of the band depends on the cloud top height and its geometrical thickness. The data obtained are compared to ground-based measurements of the cloud top height using a cloud-profiling radar.		Alexander A. Kokhanovsky;Vladimir V. Rozanov;Wolfgang von Hoyningen-Huene;Heinrich Bovensmann;John P. Burrows;Henk Klein Baltink	2004	IEEE Geoscience and Remote Sensing Letters	10.1109/LGRS.2004.830123	meteorology;radiative transfer;atmospheric sciences;cloud top;physics;remote sensing	Embedded	82.86146167999817	-63.53337653196812	73407
573905544cf1c979f316eecb2e8675c732c994a6	mri reconstruction based on three regularizations: total variation and two wavelets	split bregman;compressed sensing;three regularizations;mri	This paper proposes an efficient algorithm for magnetic resonance imaging (MRI) reconstruction based on compressed sensing (CS) to further improve the accuracy of the reconstructed image and simultaneously take into account the reconstruction speed. The proposed algorithm makes full use of prior knowledge of the sparsity of the MR image in different transform domains. It uses the total variation (TV), the orthogonal Haar wavelet, and the orthogonal Daubechies20 wavelet as regularizations, on top the split Bregman iteration algorithm. Experimental results show that when the sample ratio is 20%, SNR is 30 dB, the RI plit Bregman hree regularizations average reconstruction PSNR of the proposed algorithm is 41.09 dB. The proposed method is compared to nonlinear conjugate gradients combined with the backtracking line-search method, split Bregman algorithm based on TV regularization method and split Bregman algorithm based on TV + orthogonal Haar wavelet regularizations method, and the average reconstruction peak signal to noise ratio (PSNR) increases 3.71 dB, 3.44 dB and 1.14 dB, respectively. © 2016 Elsevier Ltd. All rights reserved.	algorithm;backtracking line search;bregman divergence;compressed sensing;conjugate gradient method;haar wavelet;iteration;iterative method;nonlinear system;peak signal-to-noise ratio;rs-232;resonance;sparse matrix	Li-xin Song;Jian-guang Zhang;Qian Wang	2016	Biomed. Signal Proc. and Control	10.1016/j.bspc.2016.06.003	mathematical optimization;mathematical analysis;computer science;magnetic resonance imaging;calculus;mathematics;compressed sensing	Robotics	56.39783665119215	-71.3437688780747	73559
328b575b13ada50e4a445601b0a84d1f5dbb30af	compressive sensing for image fusion - with application to pan-sharpening	spatial resolution image reconstruction dictionaries remote sensing compressed sensing image fusion;sar signalverarbeitung;geophysical image processing;pan sharpening;high resolution;compressed sensing;image resolution;image resolution geophysical image processing geophysical techniques image fusion;image fusion;spectral distortion geoeye satellite quick bird satellite ikonos satellite high spatial resolution panchromatic channel multispectral channels low spatial resolution spectral channel high resolution multispectral image pan sharpening method sparse image fusion lr multispectral image patches hr multispectral image patches panchromatic image sparsefi algorithm;sparse coefficients estimation compressive sensing pan sharpening dictionary training;compressive sensing;image reconstruction;remote sensing;multispectral images;dictionaries;sparse coefficients estimation;earth observation;sparse representation;dictionary training;geophysical techniques;spectral resolution;high spatial resolution;spatial resolution	Data provided by most optic earth observation satellites such as IKONOS, Quick Bird and GeoEye are composed of a panchromatic channel of high spatial resolution (HR) and several multispectral channels at a lower spatial resolution (LR). The fusion of a HR panchromatic and the corresponding LR spectral channels is called “pan-sharpening”. It aims at obtaining a high resolution multispectral image. In this paper, we propose a new sophisticated pan-sharpening method named Sparse Fusion of Images (SparseFI, pronounced as sparsify). SparseFI is based on the compressive sensing theory and explore the sparse representation of HR/LR multispectral image patches in the dictionaries pairs co-trained from the panchromatic image and its corresponding down-sampled version. Compared to other methods it “learns” from, i.e. adapts itself to, the data and has better performance than existing methods. Due to the fact that the SparseFI algorithm does not assume any model of the panchromatic image and thanks to the super-resolution capability and robustness of compressive sensing, it gives higher spatial and spectral resolution with less spectral distortion compared to the conventional methods.	algorithm;compressed sensing;dictionary;distortion;image fusion;image resolution;lr parser;multispectral image;sparse approximation;sparse matrix;super-resolution imaging	Xiaoxiang Zhu;Xuan Wang;Richard Bamler	2011	2011 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2011.6049794	computer vision;image resolution;computer science;image fusion;physics;remote sensing	Robotics	67.86681621955333	-66.04894870513303	73580
c42750275d72cc6a59026e23006baa536215e62e	multimodal medical image fusion framework based on simplified pcnn in nonsubsampled contourlet transform domain	multimodal image fusion;期刊论文;nonsubsampled contourlet transform nsct;non subsampled contourlet transform nsct;multimodal image fusions;spiking cortical model scm;medical image fusion;simplified pcnn;cortical models	In this paper, we present a new medical image fusion algorithm based on nonsubsampled contourlet transform (NSCT) and spiking cortical model (SCM). The flexible multi-resolution, anisotropy, and directional expansion characteristics of NSCT are associated with global coupling and pulse synchronization features of SCM. Considering the human visual system characteristics, two different fusion rules are used to fuse the low and high frequency sub-bands respectively. Firstly, maximum selection rule (MSR) is used to fuse low frequency coefficients. Secondly, spatial frequency (SF) is applied to motivate SCM network rather than using coefficients value directly, and then the time matrix of SCM is set as criteria to select coefficients of high frequency subband. The effectiveness of the proposed algorithm is achieved by the comparison with existing fusion methods.	algorithm;coefficient;contourlet;image fusion;multimodal interaction;pulse-coupled networks;selection rule	Nianyi Wang;Yide Ma;Kun Zhan;Min Yuan	2013	Journal of Multimedia	10.4304/jmm.8.3.270-276	computer vision;speech recognition;pattern recognition	Visualization	59.47733118964965	-67.1682370130338	73644
3d1e013740c27fbcc893f203454dbf54a0e6ca20	surveying noctural cuttlefish camouflage behaviour using an auv	autonomous underwater vehicle;animals;high resolution stereo imaging system;image resolution;underwater vehicles;noctural cuttlefish camouflage behaviour;data collection;temperature sensors;ecological interest noctural cuttlefish camouflage behaviour autonomous underwater vehicle high resolution stereo imaging system data collection auv sirius post cruise analysis;mobile robots;ecology;navigation;shallow water;imaging system;robot vision;ecological interest;stereo image processing;simultaneous localization and mapping;underwater vehicles ecology mobile robots robot vision stereo image processing;vehicles;remotely operated vehicles animals australia cameras laboratories underwater vehicles filters image color analysis global positioning system image analysis;south australia;auv sirius;post cruise analysis	This paper describes a recent study in which an Autonomous Underwater Vehicle (AUV) with a high resolution stereo-imaging system was used to document nocturnal camouflage behaviour in cuttlefish at a well known spawning site in Whyalla, South Australia. The AUV's ability to fly at low altitude during day and night while closely following a desired survey pattern provided improved data collection compared to divers and previous work with a small ROV. Over the course of the week long expedition, the AUV Sirius was deployed on 38 dives at three sites in the survey area and collected tens of thousands of stereo images. Of these, nearly a thousand were seen to contain cuttlefish during post cruise analysis, with a large proportion showing evidence of camouflage. The distribution of images containing cuttlefish suggest that the animal concentrations were substantially higher closer in to shore in shallow waters, where the flat rocky substrate occurs; females lay their eggs on the underside of these rocks. Results demonstrate the strengths of using an AUV for surveying near-shore benthic habitats of ecological interest, with a particular emphasis on the ability to operate during both day and night time operations.	day and night (cellular automaton);habitat;image resolution;sirius systems technology;substrate (electronics);the australian	Stefan B. Williams;Oscar Pizarro;Martin J. How;Duncan Mercer;George Powell;N. Justin Marshall;Roger T Hanlon	2009	2009 IEEE International Conference on Robotics and Automation	10.1109/ROBOT.2009.5152868	mobile robot;computer vision;navigation;image resolution;computer science;waves and shallow water;artificial intelligence;remote sensing;data collection;simultaneous localization and mapping	Robotics	78.88381279415607	-53.70664822700147	73669
38f84c67235d17ea9a85136dacf57c14b5b3f5b0	scalable algorithms for locally low-rank matrix modeling		We consider the problem of modeling data matrices with locally low rank (LLR) structure, a generalization of the popular low rank structure widely used in a variety of real world application domains ranging from medical imaging to recommendation systems. While LLR modeling has been found to be promising in real world application domains, limited progress has been made on the design of scalable algorithms for such structures. In this paper, we consider a convex relaxation of LLR structure, and propose an efficient algorithm based on dual projected gradient descent (D-PGD) for computing the proximal operator. While the original problem is non-smooth, so that primal (sub)gradient algorithms will be slow, we show that the proposed D-PGD algorithm has geometrical convergence rate. We present several practical ways to further speed up the computations, including acceleration and approximate SVD computations. With experiments on both synthetic and real data from MRI (magnetic resonance imaging) denoising, we illustrate the superior performance of the proposed D-PGD algorithm compared to several baselines.	approximation algorithm;computation;experiment;gradient descent;linear programming relaxation;low-rank approximation;lucas–lehmer–riesel test;medical imaging;missing data;noise reduction;proximal operator;rate of convergence;recommender system;resonance;scalability;singular value decomposition;synthetic intelligence	Qilong Gu;Joshua Trzasko;Arindam Banerjee	2017	2017 IEEE International Conference on Data Mining (ICDM)	10.1109/ICDM.2017.23	machine learning;artificial intelligence;rate of convergence;computer science;low-rank approximation;algorithm design;approximation algorithm;algorithm;matrix (mathematics);singular value decomposition;ranging;gradient descent	ML	56.720417858342806	-73.35923154202557	73761
885124e57205164cd927659e37220f20410ff03d	a new remote sensing filter radiometer employing a fabry-perot etalon and a ccd camera for column measurements of methane in the earth atmosphere	calibrating;methane;absorption;wavelength 1 636 mum to 1 646 mum remote sensing filter radiometer fabry perot etalon ccd camera earth atmosphere portable remote sensing system methane precision column measurements nasa gsfc air gapped fabry perot filter xs 1 7 320 camera unit xenics infrared solutions uncooled ingaas detector array custom software graphical user basic interface x control trace gases system calibration;instrumentation;fabry perot interferometers;measurement;atmospheric composition;signal to noise ratios;air pollution measurement;fabry perot instrumentation measurement metrology remote sensing atmospheric composition optical instruments absorption interferometry;remote sensing air pollution measurement atmospheric measuring apparatus calibration ccd image sensors fabry perot interferometers;imaging techniques;metrology;atmospheric measuring apparatus;ccd image sensors;infrared radiation;optical fibers;remote sensing;bandpass filters;fabry perot;sun;instruments atmospheric measurements optical fiber sensors calibration arrays cameras radiometry;interferometry;ccd cameras;etalons;calibration;radiometers;optical instruments;earth atmosphere	A portable remote sensing system for precision column measurements of methane has been developed, built and tested at NASA GSFC. The sensor covers the spectral range from 1.636 μm to 1.646 μm, employs an air-gapped Fabry-Perot filter and a CCD camera and has a potential to operate from a variety of platforms. The detector is an XS-1.7-320 camera unit from Xenics Infrared solutions 1which combines an uncooled InGaAs detector array working up to 1.7 μm. Custom software was developed in addition to the graphical user basic interface X-Control provided by the company to help save and process the data. The technique and setup can be used to measure other trace gases in the atmosphere with minimal changes of the etalon and the prefilter. In this paper we describe the calibration of the system using several different approaches.	charge-coupled device;graphical user interface	Elena M. Georgieva;Wen Huang;William S. Heaps	2012	2012 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2012.6350999	calibration;optics;physics;remote sensing	Robotics	81.71388848662014	-64.48758863497447	73773
87ac9f7790e0013b6dc26e78c4312a7618567530	color image enhancement method based on weighted image guided filtering		A novel color image enhancement method is proposed based on Retinex to enhance color images under non-uniform illumination or poor visibility conditions. Different from the conventional Retinex algorithms, the Weighted Guided Image Filter is used as a surround function instead of the Gaussian filter to estimate the background illumination, which can overcome the drawbacks of local blur and halo artifact that may appear by Gaussian filter. To avoid color distortion, the image is converted to the HSI color model, and only the intensity channel is enhanced. Then a linear color restoration algorithm is adopted to convert the enhanced intensity image back to the RGB color model, which ensures the hue is constant and undistorted. Experimental results show that the proposed method is effective to enhance both color and gray images with low exposure and non-uniform illumination, resulting in better visual quality than traditional method. At the same time, the objective evaluation indicators are also superior to the conventional methods. In addition, the efficiency of the proposed method is also improved thanks to the linear color restoration algorithm.		Qi Mu;Y. Wei;Zhanli Li	2018	CoRR			Vision	58.14687513170768	-61.911531011391865	73774
b9de1ecc328e2afa158f904553db08578902da61	a large width sar image registration method based on the compelex correlation function	azimuth;interpolation;correlation synthetic aperture radar image registration interpolation interference tomography azimuth;interference;synthetic aperture radar large width sar image registration method complex correlation function method interferometirc sar tomographic sar complex correlation function interpolation slave image master image alos data processing;complex correlation functions large width sar image registration;tomography correlation theory image registration interpolation radar imaging radar interferometry synthetic aperture radar;image registration;correlation;tomography;synthetic aperture radar	SAR complex image registration is one of the key steps of the interferometirc SAR and tomographic SAR. The complex correlation function based method is an common registration method. Generally in the application, the adopted SAR complex image is large width, however, the complex correlation functions of registration accuracy can only be guaranteed the high precision of a small scale registration in an image. This paper puts forward a complex correlation function based method of large width SAR image. First of all, we take a large width SAR image into blocks, and obtain registered offsets according to the complex correlation functions of every block. And then we advocate ten times interpolation for the master image and the slave image. With the master image as reference, we resample for the slave image according to registered offsets of each block. Finally, we present the detailed steps of registration method. We use The ALOS data for real data processing, and the processing results demonstrate the effective method.	effective method;image registration;interpolation	Zhichun Zhang;Hui Liu;Su Wang;Zhizhe Li;Jianjiang Wu	2016	2016 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)	10.1109/IGARSS.2016.7730692	computer vision;synthetic aperture radar;interpolation;image registration;interference;azimuth;tomography;optics;inverse synthetic aperture radar;correlation;physics;remote sensing	Vision	76.37654467741989	-67.53410847301036	73995
2136a2db9ec0bdf891a077aaa2a7c928855fcb23	superpixel based depth map generation for stereoscopic video conversion	depth map;2d to 3d conversion		depth map;stereoscopy	Jie Feng;Xiangyu Lin;Hanjie Ma;Jie Hu	2014	IEICE Transactions		computer vision;computer science;2d to 3d conversion;depth map	Vision	57.675212611643445	-54.86093637455396	74031
a4be5045b949fb5c80dde71b8054887f07ed7739	modeling of soil weathering on hillslopes: coping with nonlinearity and coupled processes using a data-driven approach			nonlinear system	Fabio Iwashita	2011			coping (psychology);weathering;geomorphology;soil science;geology	Vision	79.54332161740645	-60.07869559822779	74093
339cd90260d8ada8126db948f347757b66a42990	speckle reduction of sar images in the bandlet domain	discrete wavelet transforms;wavelets synthetic aperture radar image denoising bandlets adaptive thresholding;speckle;adaptive thresholding;psnr;synthetic aperture radar image;piecewise smooth;glaciology;speckle noise;additive noise;multiscale representation;linear functionals;multiplicative noise;bandlets;wavelet transforms;image enhancement;wavelet transform;speckle discrete wavelet transforms synthetic aperture radar optical scattering noise reduction radar scattering psnr optical noise filters wavelet coefficients;sar image;transforms;weather condition;wavelet transforms glaciology image enhancement speckle synthetic aperture radar;orthogonal transformation;denoising;multiresolution analysis;wavelets;iceland speckle reduction synthetic aperture radar sar images bandlet transformation multiplicative speckle noise scattering phenomenon adaptive sigmoid thresholding undecimated discrete wavelet transform lena image image visual fidelity peak signal to noise ratio standard wavelet transform image enhancement image reduction glacier kotlujokull;noise;synthetic aperture radar	Synthetic Aperture Radar (SAR) images are inherently affected by multiplicative speckle noise, which is due to the coherent nature of the scattering phenomenon. This paper deals with the speckle reduction using the bandlet transform combined with the adaptive sigmoid thresholding. The operation needs to provide multiscale transform. We use the Undecimated Discrete Wavelet Transform (UDWT) and apply the bandlet transform on each resulting scale. Numerical tests applied on Lena image contaminated with multiplicative noise show that our method provides improvement both in terms of image visual fidelity and in terms of Peak Signal-to-Noise Ratio (PSNR). Comparisons are made with the standard wavelet transform and the shift invariant discrete time wavelet transform.	coherence (physics);discrete wavelet transform;lenna;multiplicative noise;numerical method;peak signal-to-noise ratio;sigmoid function;thresholding (image processing)	Johannes R. Sveinsson;Zohra Semar;Jon Atli Benediktsson	2008	IGARSS 2008 - 2008 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2008.4779561	computer vision;glaciology;s transform;harmonic wavelet transform;second-generation wavelet transform;continuous wavelet transform;mathematics;wavelet packet decomposition;stationary wavelet transform;optics;discrete wavelet transform;physics;remote sensing;wavelet transform	Vision	57.32208312057281	-67.71142008779297	74094
6dd1c2a556c161965dbde55ae958c80c426c4689	interpolating probability values or fuzzy set values for uncertain spatiotemporal objects	spatio temporal uncertainty;interpolation;uncertain systems;probability;computational geometry;fuzzy set theory;uncertain systems computational geometry fuzzy set theory interpolation probability spatiotemporal phenomena;interpolation artifacts probability values interpolation fuzzy set values interpolation uncertain spatiotemporal object tetrahedralization consistent interpolation;spatiotemporal phenomena;tetrahedralization;interpolation spatiotemporal phenomena uncertainty shape spatial databases filling spatial indexes;tetrahedralization interpolation spatio temporal uncertainty	This paper looks at ways of quickly interpolating probability values or fuzzy set values for uncertain spatiotemporal objects that may change continuously over time. The paper starts with presenting a way to compute a tetrahedralization of an uncertain spatiotemporal object and using that to compute consistent interpolations. This approach also turns out to be able to create fairly good interpolations of the shape of the spatiotemporal object without needing an extra algorithm for this purpose. However, a naïve use of any tetrahedralization turns out to create interpolation artifacts in those objects that become significantly more or less uncertain with time. The paper then presents a way to overcome this issue at the cost of more processing.	algorithm;fuzzy set;interpolation	Erlend Tøssebro	2012	2012 Eighth International Conference on Signal Image Technology and Internet Based Systems	10.1109/SITIS.2012.79	mathematical optimization;discrete mathematics;bilinear interpolation;computational geometry;interpolation;probability;mathematics;fuzzy set;nearest-neighbor interpolation;multivariate interpolation;statistics	Robotics	66.63770594351327	-54.67196693830361	74152
082e1a8ed61227770d5c2b823c3d09edaadc4bc2	remotely sensed surface characteristics of three deserts in the alxa plateau, inner mongolia, china		The differences of surface characteristics are very important for sand dune stabilization, sand dune migration, sand transport and dust storm outburst which have been the focus of many researches interest. In this study, a new method for surface characteristic assessment on a regional scale was developed using a Decision Tree approach based on combination the TCA and DI with the TGSI derived from MODIS MCD43A4 data. The results showed that the integration of their advantages of TCA, DI and TGSI could better assess the surface characteristics of the desert. In 2015, there were obvious differences on surface characteristics among the Badain Jardan Desert, Tengger Desert and Ulan Buh Desert.	advanced telecommunications computing architecture;decision tree;gallium3d;union list of artist names	Qingsheng Liu;Gaohuan Liu;Chong Huang;Yunjie Zhang;Yushan Guo	2017	2017 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)	10.1109/IGARSS.2017.8126892	dust storm;geomorphology;remote sensing;computer science;china;sand dune stabilization;plateau	Visualization	82.27558290773457	-55.06852621214352	74167
49cd901e3155ed47be64452fd3f7e5b6b4b69408	fast and efficient haze removal	filtering;filtering method haze removal maximum filter transmission estimation transmission refinement process;consumer electronics;channel estimation;integrated circuits estimation channel estimation filtering conferences consumer electronics computational complexity;image processing filtering theory;estimation;computational complexity;integrated circuits;conferences	This paper presents a fast and efficient method to remove the haze from a single image. The proposed method employs the maximum filter to reduce the artifacts arising in the transmission estimation, which can simplify the transmission refinement process without sacrificing the quality of the results.	autostereogram;refinement (computing)	Won-Tae Kim;Hyun-Woo Bae;Tae-Hwan Kim	2015	2015 IEEE International Conference on Consumer Electronics (ICCE)	10.1109/ICCE.2015.7066445	filter;computer vision;estimation;electronic engineering;simulation;computer science;computational complexity theory;statistics	Robotics	58.9636909150079	-59.235300674670306	74358
f13847ae839203f3d75e2098c7ff96bbebb4894a	monitoring structural damages in big industrial plants with uav images	corrosion monitoring industrial plants inspection unmanned aerial vehicles feature extraction transforms;unmanned aerial vehicles uav aerial inspection damage monitoring industrial plants scale invariant features transform sift;structural engineering computing autonomous aerial vehicles computerised monitoring condition monitoring corrosion geophysical image processing image segmentation industrial plants;unmanned aerial vehicles structural damages monitoring industrial plants aerial images corrosion unmanned aerial vehicle image acquisition geometric transformation automatic thresholding technique damage growth estimation	The monitoring of possible damages on industrial plants from aerial images represents a challenging task. In this work, we present a methodology to monitor the changes due to corrosion damages on industrial plants by using Unmanned Aerial Vehicle (UAV) images. First, a couple of images acquired at two different times is considered and aligned to each other through a geometric transformation. Then, the possible changes are highlighted in both images by exploiting a simple automatic thresholding technique based on the assumption that damages have usually different aspects with respect to the surrounding structures. At the end, the images are compared to obtain an estimation of the damage growth. The methodology has been tested on extremely high resolution images obtained with different acquisition conditions. The achieved results demonstrate the precision of the method and suggest the possible use of such a technique in practical applications.	aerial photography;image resolution;thresholding (image processing);unmanned aerial vehicle	Thomas Moranduzzo;Farid Melgani	2014	2014 IEEE Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2014.6947606	computer vision;remote sensing	Robotics	75.21196529617409	-58.140157028650954	74436
0a2be73931f861caae73ddc01847f3c5d7630244	a fuzzy topology for computing the interior, boundary, and exterior of spatial objects quantitatively in gis	computadora;tratamiento datos;computers;topology;systeme information geographique;hongkong;ordinateur;logique floue;topologie;far east;data processing;traitement donnee;fotografia aerea;topologia;vegetation;fuzzy logic;modelo;photographie aerienne;asie;vegetacion;geographic information systems;closure operator;interior operator;aerial photograph;extreme orient;modele;extremo oriente;hong kong;topological relations;models;aerial photography;topological relation;asia	There have been many research developments on the conceptual description of topological relations between spatial objects. In order to practically implement these conceptual topological relations in a computer environment, we need to calculate the values of the topological relations. One of the theoretical bases for doing this is a computational fuzzy topology, which is the research focus of this study. Here, we present a development of computational fuzzy topology, which is based on the interior operator and closure operator. These operators are further defined as a coherent fuzzy topology—the complement of the open set is the closed set and vice versa; where the open set and closed set are defined by interior and closure operators—two level cuts. The elementary components of fuzzy topology for spatial objects—interior, boundary and exterior—are thus computed based on the computational fuzzy topology. An example of calculating the interior, boundary, and exterior of Mikania micrantha based on the aerial photographs of the Hong Kong countryside is provided in order to demonstrate the application of the theoretical development. Practically, the developed computational fuzzy topology is applicable for computing the values of fuzzy topological relations, such as defined conceptually by the 9-intersection model. r 2007 Elsevier Ltd. All rights reserved.	aerial photography;coherence (physics);computation;fuzzy mathematics;geographic information system	Wenzhong Shi;Kimfung Liu	2007	Computers & Geosciences	10.1016/j.cageo.2006.10.013	closed set;fuzzy logic;far east;computational topology;topology;interior;subspace topology;product topology;computer science;fuzzy number;mathematics;geometry;weak topology;extension topology;particular point topology;topological space;closure;initial topology;fuzzy set operations;general topology;boundary;vegetation;aerial photography;closure operator	Vision	73.209824830596	-55.651523604538376	74453
a79527ad791dedec10e79de7b54015aae012d96d	volume rendering of pool fire data	chemical engineering computing rendering computer graphics fires radiative transfer data visualisation ray tracing health hazards fuel;data visualization techniques volume rendering pool fire data ignited puddle liquid fuel burning hazard control spilled fuels case study radiative transfer imaging tools irradiation efficient ray casting radiometrically accurate line integrations;ignited puddle;radiative transfer;chemical engineering computing;irradiation efficient ray casting;optical surface waves;volume rendering;optical filters;pool fires;fuel;fires data visualization fuels optical surface waves computational modeling radiometry probes casting optical filters atmosphere;imaging tools;probes;spilled fuels;radiometry;data visualisation;visualization;computational modeling;pool fire data;casting;visualization technique;fuels;radiometrically accurate line integrations;data visualization;radiative simulation;ray tracing;burning;hazard control;liquid fuel;rendering computer graphics;health hazards;fires;atmosphere;data visualization techniques;ray casting	In a pool fire, an ignited puddle or pool of liquid fuel burns in the atmosphere. Understanding pool fires is important to devising methods to control the hazards resulting from spilled fuels. In this case study, we consider techniques for visualizing the data measured in pool fires and for computing the radiative transfer from pool fires. We used basic tools to image fire data and to compute irradiation-efficient ray casting and radiometrically accurate line integrations. Visualization techniques help answer a number of questions about pool fires. >	volume rendering	Holly E. Rushmeier;Anthony Hamins;Mun-Young Choi	1995	IEEE Computer Graphics and Applications	10.1109/38.391493	radiative transfer;ray tracing;casting;simulation;radiometry;visualization;computer science;ray casting;optical filter;atmosphere;computational model;volume rendering;data visualization;statistics;combustion;computer graphics (images)	Visualization	74.48234305299212	-52.103328986328265	74458
3f3e6381fdcde967fdd7ffe541df4e84b232f1dd	supervised classification of radarsat-2 polarimetric data for different land features		The pixel percentage belonging to the user defined area that are assigned to cluster in a confusion matrix for RADARSAT-2 over Vancouver area has been analysed for classification. In this study, supervised Wishart and Support Vector Machine (SVM) classifiers over RADARSAT-2 (RS2) fine quadpol mode Single Look Complex (SLC) product data is computed and compared. In comparison with conventional single channel or dual channel polarization, RADARSAT-2 is fully polarimetric, making it to offer better land feature contrast for classification operation.	confusion matrix;machine learning;multi-channel memory architecture;multi-level cell;pixel;polarimetry;polarization (waves);support vector machine	Abhishek Maity	2016	CoRR		pattern recognition;data mining	ML	79.01268991713015	-58.26413949916095	74481
9a09bac653a122cb89df672154819a7e0b8b77be	image denoising by multiple compressed sensing reconstructions	noise reduction image reconstruction noise tv compressed sensing signal processing algorithms biology;compressed sensing;medical image processing compressed sensing image denoising image reconstruction;biology;fourier transform bioimaging compressed sensing denoising total variation;image reconstruction;noise reduction;tv;signal processing algorithms;synthetic image image denoising multiple compressed sensing reconstructions bioimaging low sampling rate high quality denoised images total variation sparsity constraints;noise	In this paper, compressed sensing (CS) is investigated as a denoising tool in bioimaging. Multiple reconstructions at low sampling rates are combined to generate high quality denoised images using total-variation spar-sity constraints. The validity of the proposed method is first assessed on a synthetic image with a known ground truth and then applied to real biological images.	compressed sensing;display resolution;ground truth;noise reduction;sampling (signal processing);synthetic intelligence	William Meiniel;Yoann Le Montagner;Elsa D. Angelini;Jean-Christophe Olivo-Marin	2015	2015 IEEE 12th International Symposium on Biomedical Imaging (ISBI)	10.1109/ISBI.2015.7164096	iterative reconstruction;computer vision;mathematical optimization;computer science;noise;pattern recognition;noise reduction;mathematics;compressed sensing;non-local means	Vision	53.853252186898196	-76.95594192633838	74519
cbe6d3a39440f7f0f5186339a2cdb7a5e7607ab1	automatic ship detection in sar satellite images: performance assessment	detectors;histograms;azimuth;clutter;synthetic aperture radar marine radar radar imaging ships spaceborne radar;maritime environment sar satellite images automatic ship detection performance assessment satellite borne synthetic aperture radar data fp7 nereids project;marine vehicles;articles in periodicals and books;sar ship detection maritime surveillance maritime security satellite imaging;marine vehicles detectors synthetic aperture radar azimuth benchmark testing clutter histograms;benchmark testing;synthetic aperture radar	This paper presents the benchmarking of four ship detection systems based on satellite borne Synthetic Aperture Radar data. This research, carried out within the framework of the FP7 NEREIDS project, provides a detailed performance assessment of the four detectors, not only in terms of detection accuracy, but also showing how they can cope with challenging situations typical of the maritime environment. Despite the good results, the conclusions are that none of the detection systems behave well in all of the conditions. Nevertheless, merging all the different ship detection reports would increase the performances.	numerical aperture;performance;sensor;synthetic data	Mattia Stasolla;Carlos Santamaria;Jordi J. Mallorquí;Gerard Margarit;Nick Walker	2015	2015 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)	10.1109/IGARSS.2015.7326311	meteorology;early-warning radar;radar masint;man-portable radar;benchmark;detector;continuous-wave radar;space-based radar;radar engineering details;synthetic aperture radar;radar lock-on;geodesy;computer science;fire-control radar;bistatic radar;an/apy-10;histogram;clutter;3d radar;azimuth;radar imaging;inverse synthetic aperture radar;side looking airborne radar;automatic radar plotting aid;physics;radar;remote sensing	Embedded	74.57779979755456	-63.66566024050724	74573
035d4905c7c51632ae8e943dde7ee7a04e3782b3	maximum a posteriori super resolution based on simultaneous non-stationary restoration, interpolation and fast registration	dft domain maximum a posteriori framework super resolution problem high resolution images reconstruction simultaneous nonstationary restoration low resolution degraded observations hierarchical nonstationary edge adaptive prior discrete fourier transform domain;abstracts;maximum likelihood estimation discrete fourier transforms image registration image resolution image restoration interpolation	In this paper we propose a maximum a posteriori (MAP) framework for the super resolution problem, i.e. reconstructing high-resolution images from shifted, low-resolution degraded observations. In this framework the restoration, interpolation and registration subtasks of this problem are preformed simultaneously. The main novelties of this work are the use of a new hierarchical non-stationary edge adaptive prior for the super resolution problem, and an efficient implementation of this methodology in the discrete Fourier transform (DFT) domain. We present examples with real data that demonstrate the advantages of this methodology.	circuit restoration;discrete fourier transform;image resolution;interpolation;stationary process;super-resolution imaging	Giannis K. Chantas;Nikolas P. Galatsanos;Nathan A. Woods	2006	2006 14th European Signal Processing Conference		computer vision;mathematical optimization;mathematics;statistics	Vision	57.71511820246367	-69.88527920042496	74598
6c46b0ede9354ed453db9f5041511076f9c97ee7	update calibration results of prism and avnir-2 onboard alos ‘daichi’	prism;alos;calibration alos daichi prism avnir 2;daichi;avnir 2;radiometers calibration geophysical equipment;calibration accuracy satellites satellite broadcasting modis;geophysical equipment;radiometric accuracy calibration result update prism calibration avnir 2 calibration advanced land observing satellite ad 2006 01 ad 2011 04 22 low load mode ad 2011 05 12 archived data prism nadir looking radiometer;calibration;radiometers	The Advanced Land Observing Satellite (ALOS, nicknamed `Daichi') was launched on January 2006, and has operated very well. However, its operation moved to the low load mode (LLM) since April 22, 2011, and was subsequently followed by an official termination on May 12, 2011. Notwithstanding, approx. 6,500,000 scenes of archived data covering the entire globe are available to users. Therefore the calibration result is still important information for users. This paper describes calibration results of two optical instruments called PRISM and AVNIR-2 onboard ALOS are summarized during whole mission period. The previous result has been published in 2009, which was explained an overview of calibration and validation plan, and their results at that time. As the updated calibration results, we confirmed 6.1 m (root mean square error, RMSE) for PRISM nadir-looking radiometer and 21.9 m (RMSE) for AVNIR-2 0 deg. pointing of absolute geometric accuracies, and no significant degradation on radiometric accuracy.	approximation;archive;elegant degradation;mean squared error;prism (surveillance program);surround sound	Takeo Tadono;Masanobu Shimada;Junichi Takaku;Hiroshi Murakami	2012	2012 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2012.6352481	meteorology;calibration;geodesy;radiometer;prism;physics;remote sensing	Robotics	82.34858545433406	-63.13948640164082	74601
4ff49e55de972f0ce7ed6488cb25b68638a0893c	supervised image classification by contextual adaboost based on posteriors in neighborhoods	teledetection;optimisation;geophysics;probability;bayes rule;image segmentation;modele mathematique;bayes methods;electrical and electronic engineering;supervised classification;imagerie;image classification;geochemistry and petrology;markov random field image classification contextual adaboost machine learning technique land cover contextual classifiers posterior probability log posteriors classification functions noniterative maximization artificial multispectral images bayes rule image segmentation;posterior probability;modelo matematico;segmentation;classification;deteccion a distancia;markov random field;posterior probability bayes rule image segmentation machine learning markov random field mrf;occupation sol;apprentissage;imagery;machine learning;mathematical models;geophysical signal processing;remote sensing;multispectral images;pixel;probabilidad;markov random field mrf;probabilite;imagineria;markov processes;geophysical techniques image classification image segmentation learning artificial intelligence geophysical signal processing bayes methods markov processes optimisation remote sensing;computers in earth sciences;learning artificial intelligence;land cover;clasificacion;image classification machine learning voting probability markov random fields pattern recognition mathematics multispectral imaging iterative methods image segmentation;convex combination;geophysical techniques	AdaBoost, a machine learning technique, is employed for supervised classification of land-cover categories of geostatistical data. We introduce contextual classifiers based on neighboring pixels. First, posterior probabilities are calculated at all pixels. Then, averages of the log posteriors are calculated in different neighborhoods and are then used as contextual classification functions. Weights for the classification functions can be determined by minimizing the empirical risk with multiclass. Finally, a convex combination of classification functions is obtained. The classification is performed by a noniterative maximization procedure. The proposed method is applied to artificial multispectral images and benchmark datasets. The performance of the proposed method is excellent and is similar to the Markov-random-field-based classifier, which requires an iterative maximization procedure.	adaboost;benchmark (computing);coefficient;computer vision;contextual image classification;directed graph;emoticon;expectation–maximization algorithm;isotropic position;iterative method;loss function;machine learning;markov chain;markov random field;multispectral image;pixel;statistical model;support vector machine;test data;time complexity	Ryuei Nishii;Shinto Eguchi	2005	IEEE Transactions on Geoscience and Remote Sensing	10.1109/TGRS.2005.848693	multispectral image;computer vision;contextual image classification;convex combination;biological classification;machine learning;linear classifier;multiclass classification;pattern recognition;probability;mathematical model;mathematics;image segmentation;markov process;posterior probability;bayes' theorem;segmentation;pixel;statistics	ML	71.51693281264637	-62.24228291707513	74662
3d36c07539e7e20e9b86252ceda86e2604d34037	improved processing of the casie sar data	geophysical image processing;sea ice;casie sar data processing;backprojection image processing casie sar data processing ad 2009 nasa characterization of arctic sea ice experiment casie09 lfm cw sar nasa sierra unmanned aerial system uas motion compensation casie sensors sar image focus sar calibration motion data time alignment microasar data processing;chirp;motion compensation;backprojection image processing;ad 2009;nasa characterization of arctic sea ice experiment;lfm cw sar;global position system;microasar data processing;remotely operated vehicles;casie sensors;arctic;remote sensing by radar;accuracy;nasa sierra unmanned aerial system;global positioning system;synthetic aperture radar calibration geophysical image processing motion compensation oceanographic techniques radar imaging remote sensing by radar remotely operated vehicles sea ice;radar imaging;global positioning system delay graphics processing unit sea ice chirp arctic accuracy;motion data time alignment;graphic processing unit;graphics processing unit;uas;sar calibration;sar image focus;oceanographic techniques;calibration;casie09;synthetic aperture radar	In the summer 2009 NASA Characterization of Arctic Sea Ice Experiment (CASIE09), the microASAR, a small LFMCW SAR, was operated on the NASA Sierra unmanned aerial system (UAS). An overview of the microASAR and its role in CASIE09 are described in [1, 2]. While the limitations in the motion measurements stored with the microASAR data during the CASIE09 mission originally precluded full motion compensation, motion data collected for other CASIE sensors can be employed to improve the SAR image focus and calibration. This paper describes the methodology developed to time-align this motion data and applies this data along with other algorithm improvements to the processing of the microASAR data. This paper also presents a concise description of the backprojection image processing used.	aerial photography;algorithm;align (company);image processing;motion compensation;sensor;usb attached scsi;unmanned aerial vehicle	Craig Stringham;David G. Long	2011	2011 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2011.6049325	remotely operated underwater vehicle;meteorology;computer vision;calibration;synthetic aperture radar;arctic;global positioning system;geology;accuracy and precision;radar imaging;motion compensation;chirp;sea ice;physics;remote sensing	Robotics	78.66503524840122	-64.2699618438432	74895
5dd5833d97948ba20c9010e6f0fde3a2e4c34779	orthogonal subspace projection (osp) revisited: a comprehensive study and analysis	gaussian noise;proyeccion;d;teledetection;filtering;filtrage;osp anomaly detector ospad;gaussian maximum likelihood;modele mathematique;orthogonal subspace projection osp;exploitation;maximum likelihood;gaussian processes;linear spectral mixture analysis;signal detection;maximum vraisemblance;constrained energy minimization cem;detecteur;detectors maximum likelihood detection hyperspectral imaging signal analysis signal processing object detection filters spectral analysis gaussian noise maximum likelihood estimation;image classification;revision;depth;modelo matematico;analyse moindres carres;detection;maximum likelihood estimation;classification;deteccion a distancia;osp model;target constrained interference minimized filter orthogonal subspace projection hyperspectral data exploitation signal processing target detection target classification linear spectral mixture analysis gaussian noise gaussian maximum likelihood detector gaussian maximum likelihood estimator constrained energy minimization linear discriminant analysis osp anomaly detector signal detection signal parameter estimation;least squares;classifier;rx detector rxd;multidimensional signal processing geophysical signal processing remote sensing geophysical techniques image classification object detection maximum likelihood estimation signal detection gaussian processes;mathematical models;geophysical signal processing;target constrained interference minimized filter tcimf;signal processing;projection;remote sensing;bruit;least square;multidimensional signal processing;likelihood ratio test;u model;hyperspectral data;profundidad;design rationale;profondeur;orthogonal subspace projection;linear discriminant analysis;target detection;signal parameter estimation;clasificacion	The orthogonal subspace projection (OSP) approach has received considerable interest in hyperspectral data exploitation recently. It has been shown to be a versatile technique for a wide range of applications. Unfortunately, insights into its design rationale have not been investigated and have yet to be explored. This work conducts a comprehensive study and analysis on the OSP from several signal processing perspectives and further discusses in depth how to effectively operate the OSP using different levels of a priori target knowledge for target detection and classification. Additionally, it looks into various assumptions made in the OSP and analyzes filters with different forms, some of which turn out to be well-known and popular target detectors and classifiers. It also shows how the OSP is related to the well-known least-squares-based linear spectral mixture analysis and how the OSP takes advantage of Gaussian noise to arrive at the Gaussian maximum-likelihood detector/estimator and likelihood ratio test. Extensive experiments are also included in this paper to simulate various scenarios to illustrate the utility of the OSP operating under various assumptions and different degrees of target knowledge.	anomaly detection;computer simulation;design rationale;detection theory;estimation theory;experiment;least squares;linear discriminant analysis;sensor;signal processing;simulation;statistical classification;white noise;whole earth 'lectronic link	Chein-I Chang	2005	IEEE Transactions on Geoscience and Remote Sensing	10.1109/TGRS.2004.839543	machine learning;signal processing;pattern recognition;mathematics;maximum likelihood;linear discriminant analysis;least squares;statistics	ML	71.19187027184299	-64.70890023579706	75088
78766dced3d13c77923fc72d71a28992ee91f26c	study on algorithm for panoramic image basing on high sensitivity and high resolution panoramic surveillance camera	histograms;surveillance adaptive signal processing ccd image sensors computational complexity computer vision digital arithmetic distortion edge detection field programmable gate arrays hardware description languages image enhancement interpolation;interpolation;dynamic panoramic image processing panoramic image basing high sensitivity panoramic surveillance camera high resolution panoramic surveillance camera single panoramic annular lens optical system ccd sensors 360 panoramic night vision image processing hardware platform unwrapped algorithm correcting algorithm coordinate rotation digital computer cordic bilinear interpolation algorithm dynamic panoramic annular image processing night vision image enhancement algorithm adaptive piecewise linear gray transformation laplacian of gaussian edge detection log edge annular panoramic image rectangular image aplgt algorithm image histogram contrast enhancement vhdl fpga panoramic image algorithm unwrapped correction distortion correction computation complexity;image processing;surveillance;edge detection;hardware description languages;heuristic algorithms lenses image processing interpolation field programmable gate arrays night vision histograms;ccd image sensors;computer vision;distortion;image enhancement;adaptive signal processing;night vision;computational complexity;heuristic algorithms;lenses;digital arithmetic;field programmable gate arrays	A single panoramic annular lens optical system and high-sensitivity, high-resolution CCD sensors form the basis of a 360° panoramic night vision image processing hardware platform. The unwrapped and correcting algorithm based on Coordinate Rotation Digital Computer (CORDIC) and bilinear interpolation algorithm was presented in this paper, with the purpose of processing dynamic panoramic annular image. The night vision image enhancement algorithm, based on adaptive piecewise linear gray transformation (APLGT) and Laplacian of Gaussian (LOG) edge detection, were given. An original annular panoramic image captured by panoramic annular lens (PAL) can be unwrapped and corrected to conventional rectangular image without distortion, which is much more coincident with people's vision. APLGT algorithm can be adaptively truncate the image histogram on both ends to obtain a smaller dynamic range so as to enhance the contrast of the night vision image. LOG algorithm can be propitious to find and detect dim small targets in night vision circumstance. The algorithm for panoramic image processing is modeled by VHDL and implemented in FPGA. The experimental results show that the proposed panoramic image algorithm for unwrapped and distortion correction has the lower computation complexity and the architecture for dynamic panoramic image processing has lower hardware cost and power consumption.	algorithm;bilinear filtering;blob detection;cordic;charge-coupled device;closed-circuit television;computation;distortion;dynamic range;edge detection;field-programmable gate array;image editing;image histogram;image processing;image resolution;interpolation;pal;piecewise linear continuation;sensor;truncation;vhdl;word lens	Zhenhai Zhang;Kejie Li	2013	2013 10th IEEE International Conference on Advanced Video and Signal Based Surveillance	10.1109/AVSS.2013.6636666	adaptive filter;computer vision;edge detection;distortion;image processing;interpolation;computer science;histogram;lens;mathematics;hardware description language;computational complexity theory;field-programmable gate array;computer graphics (images)	Robotics	54.74373521470194	-60.511778530863374	75133
dbf2ad0027419ded94547f6084b869dc25457d9b	dlsla 3-d sar imaging algorithm for off-grid targets based on pseudo-polar formatting and atomic norm minimization	3 d imaging;atomic norm minimization bdlsla 3 d sar sparse recovery off grid targets pseudo pfa 3 d imaging;pseudo pfa;sparse recovery;off grid targets;bdlsla 3 d sar;atomic norm minimization	This paper concerns the imaging problem for downward looking sparse linear array three-dimensional synthetic aperture radar (DLSLA 3-D SAR) under the circumstance of sparse and non-uniform cross-track dimensional virtual phase centers configuration. Since the 3-D imaging scene behaves typical sparsity in a certain domain, sparse recovery approaches hold the potential to achieve a better reconstruction performance. However, most of the existing compressive sensing (CS) algorithms assume the scatterers located on the pre-discretized grids, which is often violated by the off-grid effect. By contrast, atomic norm minimization (ANM) deals with sparse recovery problem directly on continuous space instead of discrete grids. This paper firstly analyzes the off-grid effect in DLSLA 3-D SAR sparse image reconstruction, and then introduces an imaging method applied to off-gird targets reconstruction which combines 3-D pseudo-polar formatting algorithm (pseudo-PFA) with ANM. With the proposed method, wave propagation and along-track image reconstruction are operated with pseudo-PFA, then the cross-track reconstruction is implemented with semidefinite programming (SDP) based on the ANM model. The proposed method holds the advantage of avoiding the off-grid effect and managing to locate the off-grid targets to accurate locations in different imaging scenes. The performance of the proposed method is verified and evaluated by the 3-D image reconstruction of different scenes, i.e., point targets and distributed scene. 下视稀疏线性阵列三维合成孔径雷达(DLSLA 3-D SAR)常常由于跨航向的稀疏阵列安装条件受限等因素出现等效相位中心缺失和非均匀分布的情况,造成跨航向稀疏非均匀采样。对于具有稀疏性的3-D SAR成像场景,压缩感知(CS)方法能够在稀疏非均匀采样情况下获得良好的重构效果。然而,大多数CS算法都是基于离散假设,即假设散射点准确位于离散网格上;当真实散射点与离散网格不重合时,CS算法的重构效果将会受到网格偏离现象(off-grid effect)的影响。与离散的CS算法不同,原子范数最小化方法(ANM)直接在连续域上对稀疏信号进行恢复,不受网格偏离现象的影响。本文首先分析了DLSLA 3-D SAR跨航向稀疏重构时存在的网格偏离现象,然后提出了伪极坐标变换与原子范数最小化结合的成像算法。该算法首先通过距离压缩对波传播方向成像,然后对航迹向和跨航向进行伪极坐标变换,并通过傅里叶变换实现航迹向成像,然后在跨航向利用原子范数最小化方法进行成像。本文提出的方法能够在不同的成像场景中避免网格偏离现象、获得精确的成像结果。不同成像场景(点目标和分布式目标场景)的仿真实验成像结果验证了本文算法的有效性。	academy;compressed sensing;discretization;experiment;image resolution;iterative reconstruction;mathematical optimization;prime-factor fft algorithm;reconstruction filter;semidefinite programming;signal reconstruction;software propagation;sparse matrix;synthetic intelligence;volumetric display;wavelet	Qian Bao;Kuoye Han;Xueming Peng;Wen Hong;B. Dongdong Zhang;Weixian Tan	2015	Science China Information Sciences	10.1007/s11432-015-5477-5	computer vision;mathematical optimization;computer science;machine learning	Vision	72.40368525416874	-68.14613208953497	75159
8843d6384bb20721d11022d042fd7b0232ff50ec	phase mismatch calibration of the multichannel sar based on azimuth cross correlation	synthetic aperture radar calibration frequency domain analysis geophysical techniques radar antennas receiving antennas remote sensing by radar;real data processing phase mismatch calibration multichannel sar system azimuth cross correlation multiple azimuth channel synthetic aperture radar systems minimum antenna area channel phase imbalance range sampling time error image quality calibration method frequency domain cross correlation function;frequency domain analysis;remote sensing by radar;synthetic aperture radar azimuth calibration apertures delay effects correlation doppler effect;radar antennas;synthetic aperture radar sar channel imbalance cross correlation multiple azimuth channel mac;receiving antennas;calibration;geophysical techniques;synthetic aperture radar	Multiple-azimuth-channel (MAC) synthetic aperture radar (SAR) systems can overcome the minimum-antenna-area constraint. However, channel phase imbalance and range sampling time error can degrade the quality of the final image. To deal with these two problems, a calibration method based on the azimuth cross correlation is presented in this letter. The proposed method applies the azimuth cross-correlation operation after transforming the received signals of each channel into range frequency domain, where the phase of the cross-correlation function is linear with the range frequency. We obtain the range sampling time error by testing this line's slope, and then the phase mismatch can be derived. Simulation experiments and real data processing results validate the proposed method.	aperture (software);cross-correlation;doppler echocardiography;doppler effect;download;experiment;regular expression;sampling (signal processing);simulation;synthetic data	Jin Feng;Canguan Gao;Yi Zhang;Robert Wang	2013	IEEE Geoscience and Remote Sensing Letters	10.1109/LGRS.2012.2227107	continuous-wave radar;radar engineering details;calibration;synthetic aperture radar;geology;bistatic radar;pulse-doppler radar;optics;radar imaging;inverse synthetic aperture radar;side looking airborne radar;frequency domain;physics;radar;remote sensing	Embedded	76.22327220537748	-66.92004024510987	75307
e70899ff1c03c3d1c1385f069378a48e96135f37	a public database of simulated multidimensional sar data for techniques validation	databases;public sar database;tomography database management systems geophysical techniques geophysics computing information services radar polarimetry remote sensing by radar synthetic aperture radar;multi baseline polarimetric sar interferometry public sar database simulated multidimensional sar data sar techniques validation techniques validation benchmark sar simulator urban structures sar tomography multitemporal analysis multifrequency analysis;sar tomography;frequency analysis;image databases;simulated multidimensional sar data;sensors;database management systems;geometry;multifrequency analysis;scattering;urban structure;sar simulator;sar techniques validation;testing;aerospace simulation;information services;multidimensional database;remote sensing by radar;radar cross section;sar interferometry;geophysics computing;multi baseline polarimetric sar interferometry;data testing set;radar polarimetry;remote sensing;techniques validation benchmark;urban scattering;urban structures;multidimensional systems testing interferometry tomography aerospace simulation radar cross section geometry image databases predictive models numerical simulation;multitemporal analysis;predictive models;data testing set urban scattering multidimensional techniques;interferometry;atmospheric modeling;numerical models;user interaction;tomography;multidimensional systems;geophysical techniques;multidimensional techniques;numerical simulation;synthetic aperture radar	This paper presents a new benchmark for techniques validation based on a multidimensional database of simulated data. By exploiting a SAR simulator of complex targets, series of numerical simulations may be run for specific sets of observation conditions and the results made public. Targets are in principle focused on urban structures, despite any other type of man-made targets may be considered. User interaction has allowed to fix the range of values for some design parameters according to the experience gained with real data. Multi-baseline polarimetric SAR interferometry and SAR tomography are the techniques for which this benchmark has been initially conceived, despite other research areas may also benefit, as multi-temporal or multi-frequency analysis. With the resulting amount of images, an adequate testing set can become available for multidimensional methods, which validation with real imagery is difficult.	baseline (configuration management);benchmark (computing);computer simulation;frequency analysis;numerical analysis;online analytical processing;polarimetry;tomography	Gerard Margarit;Jordi J. Mallorquí;Irene Corney;Carlos López-Martínez	2008	IGARSS 2008 - 2008 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2008.4779064	computer vision;atmospheric model;synthetic aperture radar;multidimensional systems;interferometry;sensor;data mining;predictive modelling;software testing;tomography;frequency analysis;scattering;radar cross-section;information system;physics;remote sensing	Visualization	78.84704760681814	-63.77284350843333	75346
b9c2c9179c1de4695d06c81919b5212b890109f4	measurements of the propagation parameters of tree canopies at mmw frequencies	propagation parameters;volume backscattering coefficient;extincion;vegetation mapping;teledetection;tree canopy;forests;clutter;radar methods;radar remote sensing;35 ghz;forestry;millimeter wave propagation;dynamique;extinction;millimeter wave measurements;frequence;volume;mm wave;millimetre wave;backscatter;95 ghz;diffusion onde;millimeter wave radar;attenuation;layout;95 ghz ehf mm wave geophysical measurement technique land surface land use terrain mapping millimetre wave radar scattering backscatter vegetation mapping forest propagation parameters tree canopy radar remote sensing grazing incidence attenuation backscatter response extinction volume backscattering coefficient 35 ghz;forest;deteccion a distancia;retrodiffusion;geophysical measurement technique;vegetation;dinamica;algorithme;foret;remote sensing by radar;radar scattering;trees;volumen;frecuencia;propagacion;vegetacion;land use;onde;dynamics;backscatter extinction coefficients layout radar detection millimeter wave measurements millimeter wave propagation millimeter wave technology millimeter wave radar radar scattering attenuation;atenuacion;remote sensing;extinction coefficients;detection algorithm;wave scattering;dynamic range;arbre;backscatter geophysical techniques terrain mapping vegetation mapping forestry remote sensing by radar radar cross sections;algorithms;radar cross sections;grazing incidence;radar detection;land surface;canopee;ehf;terrain mapping;millimeter wave;millimeter wave technology;bosque;frequency;backscattering;waves;methode radar;propagation;geophysical techniques;radar;backscatter response;algoritmo;attenuation measurements	The presence of trees in a given scene can hamper detection of nearby targets by millimeter-wave radars especially at near grazing incidence. Proper characterization of scattering and attenuation in tree canopies is important for optimal detection algorithms. In this paper, a new technique for determining the extinction and volume backscattering coefficients in tree canopies using the measured radar backscatter response is proposed and verified experimentally. The technique, which can be applied to already available wideband radar backscatter data, is used to compute the extinction and volume backscattering coefficients of different tree canopies under various physical conditions. The dynamic range of these coefficients are presented and results at 35 GHz are compared with results at 95 GHz. Prepared through collaborative participation in the Advanced Sensors Consortium sponsored by the U.S. Army Research Laboratory under the Federated Laboratory Program, Cooperative Agreement DAAL01-96-2-0001. 1	algorithm;coefficient;consortium;decibel;dynamic range;experiment;incidence matrix;propagation constant;radar;sensor;verification and validation	Adib Y. Nashashibi;Fawwaz T. Ulaby;Panayiotis Frantzis;Roger D. De Roo	2002	IEEE Trans. Geoscience and Remote Sensing	10.1109/36.992787	meteorology;forest;extremely high frequency;optics;backscatter;physics;remote sensing	Visualization	82.00506002323432	-64.59735903464394	75371
2b1aaa1b7da1e28654c70efd0f37ffae717b8a2a	improved ground moving target indication method in heterogeneous environment with polarization-aided adaptive processing	synthetic aperture radar sar adaptive target detection ground moving target indication gmti radar polarimetry;clutter;training;covariance matrices;image color analysis;object detection adaptive filters matrix inversion;covariance matrices training clutter synthetic aperture radar signal processing algorithms image color analysis;generalized inner product algorithm adaptive ground moving target indication heterogeneous environment polarization aided adaptive processing sample matrix inversion secondary data training data adaptive filter polarization aided gmti method polarization space 2d wishart classifier;signal processing algorithms;synthetic aperture radar	Adaptive ground moving target indication (GMTI) algorithms based on the sample matrix inversion require the availability of a secondary data (training data) set to determine the adaptive filter. A polarization-aided GMTI method is devised in this letter for selecting this training data, which could improve the detection performance in heterogeneous environments. In particular, improved classification results are first obtained with the proposed polarization-space 2-D Wishart classifier, which are then employed in a generalized inner product algorithm to select the secondary data. The proposed scheme is able to provide a better choice of secondary data, resulting in considerable improvement in detection performance. Numerical results are provided to show the effectiveness of the proposed method.	adaptive filter;algorithm;iterative method;landweber iteration;moving target indication;numerical method;polarization (waves)	Wentao Du;Zhiwei Yang;Guisheng Liao	2016	IEEE Geoscience and Remote Sensing Letters	10.1109/LGRS.2016.2606458	stationary target indication;computer vision;synthetic aperture radar;geology;space-time adaptive processing;clutter;physics;remote sensing	Visualization	71.37940385731771	-66.0607227061374	75375
bb5b0df96d26dc055856689768210bb06265b967	designing anaglyphs with minimal ghosting and retinal rivalry	color reproduction anaglyph ghosting retinal rivalry;mathematical analysis;image colour analysis;image color analysis retina rendering computer graphics equations stereo image processing glass lenses;mathematical analysis filtering theory image colour analysis;filtering theory;color reproduction anaglyphs minimal ghosting retinal rivalry three dimensional image viewing colored display image filtering colored lenses anaglyph image designing mathematical analysis	The anaglyph is a widely overlooked method of viewing three-dimensional images on any colored display. This is done by selectively filtering the image through colored lenses. Despite the simplicity of this system, the approach to designing anaglyph images remained largely empirical until a recent mathematical analysis by Eric Dubois. While the methods shown in the said work create good anaglyphs, they still exhibit a large amount of retinal rivalry which makes anaglyphs uncomfortable to view. This paper tackles modifications to the said approach to tackle several anaglyph issues, namely ghosting, retinal rivalry, and color reproduction, simultaneously. Subjective testing showed an improvement in viewer acceptance of images designed using the proposed method.	anaglyph 3d;rollover (key);eric	Cecille Adrianne Ochotorena;Carlo Noel Ochotorena;Edwin Sybingco	2013	2013 IEEE International Conference on Acoustics, Speech and Signal Processing	10.1109/ICASSP.2013.6638011	computer vision;mathematics;computer graphics (images)	Robotics	60.34120070827864	-58.90485018546004	75385
ba1030063f22194ef48b3ef8ec93030d12f241f8	can saliency map models predict human egocentric visual attention	account visual motion;human egocentric visual attention;high visual saliency;conventional visual saliency model;egocentric vision;human visual attention;human visual system;visual saliency map;visual motion;visual saliency model;conventional saliency map model	The validity of using conventional saliency map models to predict human attention was investigated for video captured with an egocentric camera. Since conventional visual saliency models do not take into account visual motion caused by camera motion, high visual saliency may be erroneously assigned to regions that are not actually visually salient. To evaluate the validity of using saliency map models for egocentric vision, an experiment was carried out to examine the correlation between visual saliency maps and measured gaze points for egocentric vision. The results show that conventional saliency map models can predict visually salient regions better than chance for egocentric vision and that the accuracy decreases significantly with an increase in visual motion induced by egomotion, which is presumably compensated for in the human visual system. This latter finding indicates that a visual saliency model is needed that can better predict human visual attention from egocentric videos.	experiment;map;motion compensation;visual odometry	Kentaro Yamada;Yusuke Sugano;Takahiro Okabe;Yoichi Sato;Akihiro Sugimoto;Kazuo Hiraki	2010		10.1007/978-3-642-22822-3_42	computer vision;computer graphics (images)	Vision	63.654636375878624	-62.0508591710919	75409
ad3982a16bdc905d0d9cf8c1e51ba09888d01317	k-means based spatial aggregation for hyperspectral compression	computers;image coding;data compression;redundancy;image coding clustering algorithms data compression hyperspectral imaging decorrelation redundancy computers;pattern clustering computational complexity data compression geophysical image processing hyperspectral imaging image coding;aviris imagery k means based spatial aggregation compression ratio hyperspectral data compression klt jpeg2000 based compression k means clustering algorithm computational complexity samlc spatially aggregated multilevel clustering hyperion imagery;clustering algorithms;decorrelation;hyperspectral imaging;segmentation compression hyperspectral jpeg 2000 klt aggregation	Summary form only given. We investigate a method to improve the compression ratio for hyperspectral data compression by use of a pre-processing step that gathers together correlated pixels before the transform is applied in a KLT-JPEG2000 based compression. Using a k-means clustering algorithm, the pixels can be grouped together before the application of the transform. Some similar methods have been studied, but k-means has been avoided due to its computational complexity. We call our proposed method SAMLC (Spatially Aggregated Multilevel Clustering). The simulation results show that in the case of lossy modes of compression, the proposed algorithm outperforms KLT+JPEG2000 and basic multilevel clustering for Hyperion imagery and some AVIRIS imagery. In lossless mode, Hyperion, AVIRIS, and AIRS data was tested but the proposed algorithm performed nearly the same as the competing algorithms across the 10 images tested. Overall, the proposed SAMLC algorithm is designed for lossy-to-lossless compression and performed best in lossy mode with Hyperion data.	algorithm;cluster analysis;computational complexity theory;computer cluster;data compression;hyperion;jpeg 2000;k-means clustering;lossless compression;lossy compression;pixel;preprocessor;simulation	Jason McNeely;Greg Geiger	2014	2014 Data Compression Conference	10.1109/DCC.2014.15	data compression;lossy compression;computer vision;decorrelation;computer science;hyperspectral imaging;pattern recognition;lossless compression;cluster analysis;redundancy;texture compression	Robotics	68.62649986886575	-63.87058734396685	75416
7690bc98b4cf03e9897227f37f9d790a271ccb81	feature-based multiexposure image-sequence fusion with guided filter and image alignment	quality measurement;convolution;image fusion;high dynamic range imaging;distortion;cameras	Multiexposure fusion images have a higher dynamic range and reveal more details than a single captured image of a real-world scene. A clear and intuitive feature-based fusion technique for multiexposure image sequences is conceptually proposed. The main idea of the proposed method is to combine three image features [phase congruency (PC), local contrast, and color saturation] to obtain weight maps of the images. Then, the weight maps are further refined using a guided filter which can improve their accuracy. The final fusion result is constructed using the weighted sum of the source image sequence. In addition, for multiexposure image-sequence fusion involving dynamic scenes containing moving objects, ghost artifacts can easily occur if fusion is directly performed. Therefore, an image-alignment method is first used to adjust the input images to correspond to a reference image, after which fusion is performed. Experimental results demonstrate that the proposed method has a superior performance compared to the existing methods.		Liang Xu;Junping Du;Zhenhong Zhang	2015	J. Electronic Imaging	10.1117/1.JEI.24.1.013022	computer vision;distortion;telecommunications;computer science;pattern recognition;convolution;image fusion;computer graphics (images)	Vision	56.78851522952568	-58.95238290045826	75505
a7985d90d6e0e9d42f5f7579575fd1e659b5a0ec	adaptive vector quantization for raw sar data	azimuth;spaceborne sar data;block adaptive quantization;block gain adaptive vector quantization;image coding;data compression;lbg algorithm;gaussian distributed data;radar scattering;block adaptive quantization raw sar data spaceborne sar data adaptive vector quantization data compression gaussian distributed data block gain adaptive vector quantization lbg algorithm codebook simulated images real images bgavq algorithm synthetic aperture radar;adaptive vector quantization;vector quantization;bgavq algorithm;radar antennas;codebook;radar imaging;signal resolution;compression ratio;raw sar data;vector quantizer;vector quantization data compression azimuth algorithm design and analysis image coding;gaussian distribution spaceborne radar synthetic aperture radar vector quantisation radar imaging image coding;vector quantisation;real images;rayleigh scattering;algorithm design and analysis;gaussian distribution;spaceborne radar;simulated images;synthetic aperture radar	'I This paper proposes an adaptive vector quantization scheme designed for spaceborne raw SAR data compression. This approach is based on the fact that spaceborne raw data are Gaussian distributed, independent, and quite stationary over an interval (in both azimuth and range) which depends on SAR system parameters. The Block Gain Adaptive Vector Quantization (BGAVQ) is a generalization of the Block Adaptive Quantization (BAQ) algorithm to vectors. It operates as a set of optimum vector quantizers (designed by the LBG algorithm) with different gain settings. The adaptation is particularly efficient since, for a fixed compression ratio, the same codebook is used for any spaceborne SAR data. Results on simulated and real images, for data rate of 1.5 to 2 bit/sample, have confirmed the expected performance of the BGAVQ algorithm. INTRODUCTION CNES AEROSPATIALE Traitement Bord Espace et Dkfense 18 av Edouard Belin 31055 Toulouse 100 bd du midi BP 99 06322 Cannes la Bocca (France) (France) To preserve the system design, data compression techniques can be employed. Until now, a technique called Block Adaptive Quantization (BAQ), and a similar one referred to as Block Floating Point Quantization (BFPQ), have been selected for on-board raw data compression [2,3]. Nevertheless, other data compression techniques have been considered [4,5,6]. Several studies conclude that Vector Quantization (VQ) of raw data exhibits good performance [5,6,7]. This paper proposes a new approach for spaceborne raw SAR data compression; it consists in a vector quantizer which adapts to the changing level of the signal. Section I presents the SAR data features which are the basis for the BAQ design given in section 11. Section I11 briefly describes the VQ. The proposed raw data compression technique is explained in section IV. With this adaptive VQ, we will establish that only one optimum codebook is used for any raw data. Results achieved on two different data sets are presented in section V. I. RAW DATA FEATURES According to signal processing, the backscattered real and imaginary parts show particular statistics. We propose here a brief reminder; for more details, we suggest the reader to refer to [2,31, Each radar pulse illuminates a delimited surface area which consists of many scattering points. The echo sk of a scatter is viewed as a complex number: This paper deals with strip mapping mode SAR. The SAR usually raw data, is supposed signal is viewed as a (complex) random variable whose to be collected from a high resolution spaceborne SAR. known method for improving the resolution of radar imaging systems without increasing the physical antenna size [ 1,2]. The high resolution is achieved by processing a sequence of radar returns from a moving transmitter to simulate a very long antenna array. The net effect is that the SAR Synthetic Aperture Radar (SAR) is a system is capable of achieving a resolution independent of sk = akeJpk the sensor altitude. However, image generation requires substantial computation. Therefore, given the current technology, raw data on-board storage and downlink transmission will be considered. The high data rate of future SAR systems is often incompatible with the available communication channels or recorder storage. Thus, a reduction of raw data rate is necessary. where ak represents the amplitude and $k the phase related to the path distance. It is obvious that ak and & are independent. Since range varies rapidly from scatter to scatter with respect to the wavelength of the transmitted signal, we can assume that the phases @k are uniformly distributed between [-n: , n], and are independent. 251 1 0-7803-2431 4/95 $4.00	aperture (software);codebook;computation;data compression;data rate units;delimiter;espace;glossary of computer graphics;image resolution;imaginary time;linde–buzo–gray algorithm;linear algebra;location-based game;midi;on-board data handling;quantization (signal processing);radar;signal processing;simulation;stationary process;systems design;telecommunications link;transmitter;uncompressed video;vector quantization	Dimitri Lebedeff;Pierre Mathieu;Michel Barlaud;Catherine Lambert-Nebout;Pascale Bellemain	1995		10.1109/ICASSP.1995.480059	normal distribution;data compression;algorithm design;computer vision;synthetic aperture radar;computer science;codebook;compression ratio;mathematics;azimuth;rayleigh scattering;linde–buzo–gray algorithm;radar imaging;real image;vector quantization;statistics	Robotics	77.9634856342721	-66.60670528867905	75512
2ecd52b4844219d30bf3f4baba21ce7bf83af27a	low-cost imaging photometer and calibration method for road tunnel lighting	cameras estimation lighting calibration charge coupled devices measurement uncertainty optical imaging;lighting control;optical variables measurement;veiling luminance estimation;tunnel entrance;low cost commercial grade camera;calibration method;optimum luminance level estimation;measurement uncertainty;image sensors;charge coupled devices;tunnels;brightness;low cost commercial grade camera low cost imaging photometer calibration method road tunnel lighting camera based measuring instrument veiling luminance estimation optimum luminance level estimation tunnel entrance driver safety;camera based measuring instrument;optical imaging;road transportation calibration image sensors lighting control lighting optical variables measurement photometry;estimation;photometry;photometers;tunnels brightness calibration cameras image sensors lighting photometers;low cost imaging photometer;driver safety;charged couple device;lighting;road transportation;reference standard;calibration;image sensor;cameras;road tunnel lighting	A camera-based measuring instrument for road tunnels lighting is proposed. The system is aimed at estimating the veiling luminance as it will be perceived by a driver approaching the tunnel, thus allowing the estimation of the optimum luminance level of tunnel entrances, hence increasing the driver's safety. The proposed measuring instrument and the relative calibration method are based on a low-cost commercial grade camera and a reference standard, respectively.	technical standard	Stefano Cattini;Luigi Rovati	2012	IEEE Transactions on Instrumentation and Measurement	10.1109/TIM.2011.2180966	computer vision;image sensor;optics;physics;remote sensing	Visualization	61.637683310948766	-57.767144675987446	75611
dd360474673f72ca14712193a86e37c1cb1f43e3	a kernel regression approach to cloud and shadow detection in multitemporal images	spain kernel regression approach multitemporal images earth observation satellites surface monitoring cloud shadow detection method cloud screening detection method landsat 5 tm time series albacete;remote sensing kernel satellites time series analysis earth clouds feature extraction;remote sensing geophysical image processing geophysical techniques land cover	Earth observation satellites will provide in the next years time series with enough revisit time allowing a better surface monitoring. In this work, we propose a cloud screening and a cloud shadow detection method based on detecting abrupt changes in the temporal domain. It is considered that the time series follows smooth variations and abrupt changes in certain spectral features will be mainly due to the presence of clouds or cloud shadows. The method is based on linear and nonlinear regression analysis; in particular we focus on the regularized least squares and kernel regression methods. Experiments are carried out using Landsat 5 TM time series acquired over Albacete (Spain), and comparative results with the Fmask approach [1] show the potential of exploiting the temporal domain.	cloud computing;least squares;nonlinear system;rejection sampling;sensor;time series	Julia Amorós-López;Emma Izquierdo-Verdiguier;Luis Gómez-Chova;Jordi Muñoz-Marí;Gustavo Camps-Valls	2013	MultiTemp 2013: 7th International Workshop on the Analysis of Multi-temporal Remote Sensing Images	10.1109/Multi-Temp.2013.6866014	meteorology;geography;hydrology;remote sensing	Vision	76.74816491522418	-61.14467075527143	75615
9f89fafd763e33b5fd0bb2906df3947a98f62781	entropy estimation and multiscale processing in meteorological satellite images	image recognition;chaotic information;meteorological radar;chaos;image classification;data mining;maximal information;entropy estimation;multiscale processing;atmospheric flow;infrared imaging;feature extraction;clouds;satellites;infrared satellite images;multiscale characterization;satellite image;entropy meteorology satellites chaos digital images atmospheric modeling infrared imaging clouds data mining feature extraction;entropy;digital image;atmospheric modeling;meteorological radar image recognition image classification;infrared;point of view;meteorological satellite images;maximal information entropy estimation multiscale processing meteorological satellite images multiscale characterization turbulence chaotic information digital images infrared satellite images atmospheric flow;digital images;meteorology;turbulence	A new model for the multiscale characterization of turbulence and chaotic information in digital images is presented. The model is applied to infrared satellite images for the determination of specific areas inside the clouds. These images are difficult to manipulate however due to their intrinsically chaotic character, consequence of the extreme turbulent regime of the atmospheric flow. In this paper we briefly review some known techniques for processing such data and we will justify the necessity of multiscale methods to extract the relevant features. In the theory presented herein, one main attribute is determined for every image: the Most Singular Manifold (MSM, of fractal nature), characterizing the sharpest changes in graylevel values. We will see that the most important set (from the statistical point of view) is that which both contains the sharpest transitions (MSM) and maximizes the local entropy. For that reason, images can be reconstructed to a good quality from the value of the gradient over that set of maximal information. The results are interpreted according to their relevance for determining meteorological features.	digital image;entropy estimation;fractal;gradient;markov switching multifractal;maximal set;point of view (computer hardware company);relevance;turbulence	Jacopo Grazzini;Antonio Turiel;Hussein M. Yahia	2002		10.1109/ICPR.2002.1048103	computer vision;computer science;digital image	Graphics	72.98631798661988	-59.55419535038903	75622
6b24e247e085a9e533cfc095dadae97fea464518	evaluating the quality of light fields computed from hand-held camera images	optimization technique;light field;camera motion;image sequence;experimental evaluation;camera calibration;image based rendering;structure from motion	Given an image sequence recorded by a hand-held camera we examine the computation of a light field without any further input data. Using structure-from-motion algorithms and optimization techniques camera motion and a 3-D reconstruction of the scene are established. The light field is completed by computing local depth information for each input image. During experimental evaluation a special focus is set on the effects of falsely estimated intrinsic parameters as well as different depth representations on the quality of the resulting light fields.	algorithm;binocular disparity;camera resectioning;computation;experiment;image quality;information theory;light field;linear programming;mathematical optimization;mobile device;nonlinear programming;nonlinear system;signal-to-noise ratio;structure from motion;variational principle	Heinrich Niemann;Ingo Scholz	2005	Pattern Recognition Letters	10.1016/j.patrec.2004.10.025	stereo camera;computer vision;camera auto-calibration;camera matrix;structure from motion;camera resectioning;image-based modeling and rendering;computer science;light field;motion field;camera interface;pinhole camera model;image-based lighting;computer graphics (images)	Vision	54.91263625289441	-52.6437826668645	75730
3c78b04855af7f86442353d9af18e54e40eff873	3d underwater scene reconstruction through descattering and colour correction	colour distortion;deep sea imaging;colour correction;image reconstruction;descattering;3d images;ocean observation;underwater scene reconstruction;3d reconstruction;inherent optical properties	This paper describes a novel method for ocean scene 3D reconstruction. While light is travelling through water, light rays are distorted depending on the wavelength. That is, absorption, scattering and colour distortion are three major distortion issues for underwater optical imaging. Scattering is caused by large suspended particles, as in turbid water that contains abundant particles, which causes the degradation of the captured image. Colour distortion corresponds to the varying degrees of attenuation encountered by light travelling in water at different wavelengths, causing ambient underwater environments to be dominated by a bluish tone. Our key contributions proposed here include a novel deep-sea imaging model to compensate for the attenuation discrepancy along the propagation path and an effective underwater scene 3D reconstruction method. The recovered 3D images are characterised by a reduced noise level, better exposure of the dark regions, and improved global contrast where the finest details and edges are enhanced significantly.		Huimin Lu;Yujie Li;Seiichi Serikawa;Xin Li;Jian-Ru Lin;Kuan-Ching Li	2016	IJCSE	10.1504/IJCSE.2016.076950	3d reconstruction;iterative reconstruction;computer vision;computer science	Vision	57.78650429966359	-59.60695882546179	75754
23aa2aae87084a38fafa35a1d82550d15168e4eb	imaging mechanism of moving object detection with bionic compound eye	ommatidium projected imaging;eye;compounds;image resolution;unmanned aerial vehicle;biological system modeling;data processing;biomedical imaging;bionic compound eye;remotely operated vehicles;imaging mechanism;biocybernetics;projected imaging;single len data acquisition;remote sensing data;compounds object detection biomedical imaging biological system modeling image resolution equations;remote sensing;moving object detection;unmanned aerial vehicle imaging mechanism moving object detection bionic compound eye single len data acquisition ommatidium projected imaging real remote sensing data;remotely operated vehicles aircraft biocybernetics data acquisition eye object detection remote sensing;data acquisition;real remote sensing data;object detection;projected imaging moving object detection bionic compound eye;aircraft	Normal moving object detection method, based on single lens data acquisition, has some limits, such as small view field, slow data processing et al. Insect's compound eye has unique advantage on moving object detection. In this paper a moving object detection method with bionic compound eye is proposed, including its imaging principle, especially in ommatidium projected imaging. We also simulate the process of compound eye imaging with real remote sensing data from unmanned aerial vehicle. This research provides theoretical basis for further study on moving object detection with bionic compound eye.	aerial photography;data acquisition;object detection;simulation;unmanned aerial vehicle	Huabo Sun;Huijie Tong;Rui Liang;Yunfei Lu;Lei Yan	2010	2010 18th International Conference on Geoinformatics	10.1109/GEOINFORMATICS.2010.5567534	computer vision;simulation;geography;remote sensing	Robotics	76.03470608168487	-63.394884711823124	75758
681ee1cfe18ba6138e04dfb9391153926eff9675	bamboo classification using worldview-2 imagery of giant panda habitat in a large shaded area in wolong, sichuan province, china	bamboo mapping;geostatistics;classification;worldview 2;object based analysis	This study explores the ability of WorldView-2 (WV-2) imagery for bamboo mapping in a mountainous region in Sichuan Province, China. A large area of this place is covered by shadows in the image, and only a few sampled points derived were useful. In order to identify bamboos based on sparse training data, the sample size was expanded according to the reflectance of multispectral bands selected using the principal component analysis (PCA). Then, class separability based on the training data was calculated using a feature space optimization method to select the features for classification. Four regular object-based classification methods were applied based on both sets of training data. The results show that the k-nearest neighbor (k-NN) method produced the greatest accuracy. A geostatistically-weighted k-NN classifier, accounting for the spatial correlation between classes, was then applied to further increase the accuracy. It achieved 82.65% and 93.10% of the producer's and user's accuracies respectively for the bamboo class. The canopy densities were estimated to explain the result. This study demonstrates that the WV-2 image can be used to identify small patches of understory bamboos given limited known samples, and the resulting bamboo distribution facilitates the assessments of the habitats of giant pandas.	bamboo;bands;class;effective method;feature vector;guided imagery;habitat;k-nearest neighbors algorithm;linear separability;mathematical optimization;motorola canopy;multispectral image;object-based language;principal component analysis;prostheses, dental, fixed, crown, total, temporary;shading;single linkage cluster analysis;sparse matrix;state or province of birth:location:point in time:^patient:nominal;statistical classification;density;pandas	Yunwei Tang;Linhai Jing;Hui Li;Qingjie Liu;Qi Yan;Xiuxia Li	2016		10.3390/s16111957	biological classification;statistics;remote sensing;geostatistics	ML	79.32879291964707	-57.49614664878645	75818
33cf5e83d3c2f76bdabf9aa48dd6305c38f6c152	detection of defects in carbon-fiber composites using computer-vision-based processing of microwave maps		In this paper, a method for analyzing data gathered by a non-destructive inspecting approach of carbon-fiber composites is presented. In the process of composite probing a map of measurements is obtained. Upon the measurements an analysis can be performed in order to decide if the composite under examination is defective or not. The map is composed of a set of separate probes, which may be viewed as a set of pixels and, therefore, whole map can be perceived as an image. For this reason, image-based processing has been applied to examine the maps. The proposed method allows to detect suspicious regions with different, user-defined sensitivity.	computer vision;map;microwave	Bartlomiej Zielinski;Marcin Iwanowski;Bartlomiej Salski;Szymon Reszewicz	2014		10.1007/978-3-319-10662-5_30	materials science;ceramic materials	Robotics	65.84114049679724	-58.68596822272315	75998
997a6479c549df3afb6114c828d1f61f364765c8	versatile compression of multidimensional spectral data for space instruments				Björn Fiethe	2012				Theory	69.62095625989494	-60.98511225877132	76001
be45cdebc66e1129286d21ee240a2b62111fdf87	hybrid vector filters based on marginal ordering for impulsive noise suppression in color images	color image;impulse noise;adaptive median filter;vector median filter	To attenuate impulsive noise in color images, a hybrid basic vector filter and its switching extensions are introduced in this paper. By utilizing reliable components provided by the marginal filter and retaining the inherent correlation between multi-channels, the new method selects the vector, which has minimal distance to the output of the marginal median filter. Based on this scheme, some well-known switching filters are easily modified to improve their noise suppression capability. The experiments demonstrate that the proposed filtering approach is more effective to suppress multichannel impulsive noise in color images, and its computation is more efficient than state-of-the-art basic vector filters. Moreover, extended experiments indicate that the noise suppression capability of several well-known switching vector filters can also be improved by adopting this basic scheme as an alternative approach at the replacement stage.		Ling Zhong;Muhammad Talal Ibrahim;Yun Zhang;Ling Guan	2017	Signal Processing Systems	10.1007/s11265-016-1208-4	salt-and-pepper noise;filter (signal processing);hybrid vector;computation;color image;median filter;computer science;impulse noise;correlation;control theory	ML	56.63977506067745	-66.00161776580536	76028
ae88a46c74fa43b7dec909c379514fd76835dec7	data embedding in text for a copier system	copy tracking data embedding copier system predominantly text pages watermarking data hiding schemes noisy image regions text segmentation data embedding system boundary detection uncertainties text region based embedding approach print level layer;data hiding;graphics optical noise color watermarking data encapsulation humans visual system frequency position measurement size measurement;high spatial frequency;document image processing copy protection security of data;optical character recognition;copy protection;data embedding;natural images;satisfiability;human visual system;document image processing;error rate;boundary detection;security of data;text segmentation;color image	In this paper, we present a scheme for embedding data in copies (color or monochrome) of predominantly text pages that may also contain color images or graphics. Embedding data imperceptibly in documents or images is a key ingredient of watermarking and data hiding schemes. It is comparatively easy to hide a signal in natural images since the human visual system is less sensitive to signals embedded in noisy image regions containing high spatial frequencies. In other instances, e.g., simple graphics or monochrome text documents, additional constraints need to be satisfied to embed signals imperceptibly. Data may be embedded imperceptibly in printed text by altering some measurable property of a font such as position of a character or font size. This scheme however, is not very useful for embedding data in copies of text pages, as that would require accurate text segmentation and possibly optical character recognition, both of which would deteriorate the error rate performance of the data-embedding system considerably. Similarly, other schemes that alter pixels on text boundaries have poor performance due to boundarydetection uncertainties introduced by scanner noise, sampling and blurring. The scheme presented in this paper ameliorates the above problems by using a textregion based embedding approach. Since the bulk of documents reproduced today contain black on white text, this data-embedding scheme can form a print-level layer in applications such as copy tracking and annotation.	algorithm;append;digital watermarking;embedded system;graphics;light-on-dark color scheme;monochrome;optical character recognition;photocopier;pixel;printing;requirement;robustness (computer science);sampling (signal processing);text segmentation	Anoop K. Bhattacharjya;Hakan Ancin	1999		10.1109/ICIP.1999.822893	text segmentation;computer vision;color image;word error rate;computer science;theoretical computer science;human visual system model;optical character recognition;information hiding;information retrieval;satisfiability	Graphics	61.12588122844007	-59.73205141197392	76043
48507b940f02fbcea1ee8f16fd7ae447c0129d1f	outline reconstruction for radar forward-looking imaging based on total variation functional deconvloution methodxs		It is great significant to achieve clear outline reconstruction for radar forward-looking imaging. In this paper, we apply the total variation (TV) function as the regularization term operator to obtain the forward-looking imaging with clear outline. Firstly, we establish the deconvolution model, by which the forward-looking super-resolution imaging problem is converted into inverse problem. Then, taking the TV function as regularization constraint term, we construct the objective function to solve the inverse problem. Finally, we obtain the minimum of the objective function, by which we can achieve radar forward-looking super-resolution imaging with clear outline. Simulations verify effectiveness of the proposed method in reconstructing the outline of targets.	computer simulation;deconvolution;loss function;optimization problem;radar;super-resolution imaging	Yang Wu;Yin Zhang;Yongchao Zhang;Yulin Huang;Jianyu Yang	2018	IGARSS 2018 - 2018 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2018.8519584	operator (computer programming);radar imaging;computer vision;iterative reconstruction;radar;deconvolution;inverse problem;artificial intelligence;regularization (mathematics);computer science;image resolution	Robotics	56.910482106916255	-72.90452734881572	76045
6d751779f89cc739d93f7208ab79ebc0cf7cd376	colour constancy for scenes with varying illumination	colour constancy	We present an algorithm which uses information from both surface reflectance and illumination variation to solve for colour constancy. Most colour constancy algorithms assume that the illumination across a scene is constant, but this is very often not valid for real images. The method presented in this work identifies and removes the illumination variation, and in addition uses the variation to constrain the solution. The constraint is applied conjunctively to constraints found from surface reflectances. Thus the algorithm can provide good colour constancy when there is sufficient variation in surface reflectances, or sufficient illumination variation, or a combination of both. We present the results of running the algorithm on several real scenes, and the results are very encouraging.	algorithm	Kobus Barnard;Graham D. Finlayson;Brian V. Funt	1996		10.1007/3-540-61123-1_123	computer science	Vision	53.9142330107325	-55.62862141496775	76048
284688acb9514856b668b0e36a67d1cbf8ed82c8	practical super-resolution from dynamic video sequences	elliptic equations;image resolution;weighted averaging;image alignment;image matching;low resolution;motion estimation;computer vision image sequences video coding image resolution motion estimation image matching image reconstruction elliptic equations iterative methods;computer vision;iterative methods;video coding;point spread function;image reconstruction;super resolution;optical flow;high resolution imager;ibp dynamic video sequence image superresolution high resolution image reconstruction super resolve frame object occlusion scene change image quality image alignment correctness image frame optical flow motion estimation image matching elliptical weighted average ewa filter spatially variant point spread function psf acquisition system iterative backward projection;video sequences spatial resolution image resolution optical filters image reconstruction layout robustness image motion analysis motion estimation degradation;image sequences	This paper introduces a practical approach for superresolution, the process of reconstructing a high-resolution image from the low-resolution input ones. The emphasis of our work is to super-resolve frames from dynamic video sequences which may contain significant object occlusion or scene changes. As the quality of super-resolved images highly relies on the correctness of image alignment between consecutive frames, we employ the robust optical flow method to accurately estimate motion between the image pair. An efficient and reliable scheme is designed to detect and discard incorrect matchings which may degrade the output quality. We also introduce the usage of elliptical weighted average (EWA) filter to model the spatiallyvariant point spread function (PSF) of acquisition system in order to improve accuracy of the model. A number of complex and dynamic video sequences are tested to demonstrate the applicability and reliability of our algorithm.	algorithm;correctness (computer science);image resolution;matching (graph theory);optical flow;super-resolution imaging	Zhongding Jiang;Tien-Tsin Wong;Hujun Bao	2003		10.1109/CVPR.2003.1211515	computer vision;image resolution;computer science;theoretical computer science;mathematics;computer graphics (images)	Vision	55.47972832705887	-55.137114850763176	76114
e45be4419eea182137325b17694212c39d9bc484	total variation image restoration using hyper-laplacian prior with overlapping group sparsity	image restoration;total variation;iterative optimization alternating direction method of multiplier;sparse prior	Image restoration is a highly ill-posed problem and requires to be regularized. Many common image priors aim to make full use of natural image prior information. Total variation (TV) regularize prior has good performance of preserving edges but also has drawbacks in arising In this paper, we propose a total variation based image restoration method using hyper-Laplacian prior for image gradient and the overlapping group sparsity prior for sparser image representation constraint. We adopt the alternating direction method of multipliers (ADMM) method to optimize the object function of the proposed model and discuss the parameter selection criterion in the complex formulation. Finally, we carry out experiments on various degrade images and compare our method with several classical state-of-the-art methods. Experimental results show that our method has good performance in convergence and suppressing staircase artifacts, which makes a good balance between alleviating staircase effects and preserving image details. & 2015 Elsevier B.V. All rights reserved.	augmented lagrangian method;circuit restoration;experiment;image gradient;image restoration;laplacian matrix;mathematical optimization;numerical analysis;sparse approximation;sparse matrix;well-posed problem	Mingzhu Shi;Tingting Han;Shuaiqi Liu	2016	Signal Processing	10.1016/j.sigpro.2015.11.022	image restoration;computer vision;mathematical optimization;computer science;machine learning;mathematics;total variation	Vision	56.90856347221939	-71.0046442257005	76115
5df42e48cd803b6b521a3ae8621df2ef1740786a	an evaluation of ecotope classification using superresolution images derived from chris/proba data	remote sensing image;geometric correction;image processing;image resolution;moisture content;manual registration process ecotope classification superresolution image compact high resolution imaging spectrometer chris proba data image reconstruction regularization approach visual interpretation tree based ensemble classifier random forest land cover classification ecotope mapping space borne image kalmthout site belgium europe;image restoration;heating;image resolution spatial resolution strontium remote sensing layout image restoration interpolation image reconstruction classification tree analysis hyperspectral sensors;ecotope classification;strontium;vegetation;accuracy;random forest superresolution chris proba ecotope classification;machine vision;image reconstruction;remote sensing;random forest;hyperspectral data;satellite image;chris proba;vegetation image reconstruction terrain mapping;total variation;terrain mapping;superresolution;spatial resolution	This paper discusses the application of superresolution (SR) image reconstruction on multi-angle Chris/Proba images. The goal is to increase the spatial resolution of Chris/Proba images, with 18 bands from 0.4-1.0 mum in the hope to obtain a better ecotope classification. The SR approach chosen for this study is Total Variation, an iterative method which models the relationship between the desired high resolution image and the low resolution images, with the following components: a subsampling factor, a point spread function, an estimated rotation and shift, and a regularization term. This regularization approach is fast in implementation and flexible in handling noise. Efficient gradient descent methods can be used to find the desired high resolution image. The spatial resolution of the original image is improved from 25 m to 12 m using Total Variation. Subjective assessment through visual interpretation shows substantial improvement in detail. A tree-based ensemble classifier Random Forest is used for the classification of 18 ecotopes. Overall accuracy shows a 10% increase with the SR derived Chris/Proba images, compared with a classification based on the original imagery. Our results demonstrate that SR methods can improve spatial detail of multi-angle images, and subsequently classification accuracy.	chroma subsampling;ensemble learning;gradient descent;image resolution;iterative method;iterative reconstruction;matrix regularization;random forest;super-resolution imaging	Jonathan Cheung-Wai Chan;Jianglin Ma;Pieter Kempeneers;Frank Canters;Jeroen Vanden Borre;Desiré Paelinckx	2008	IGARSS 2008 - 2008 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2008.4779348	computer vision;image resolution;machine vision;image processing;computer science;remote sensing	Vision	68.07310930636869	-65.52564295937673	76135
7c3becbd11f6b17f742702a4651ef7414d23bf21	perceptually adapted mpeg video encoding	modelizacion;moving object;psicofisica;constant bit rate;quality measurement;implementation;spatial frequencies;mpeg video;motion adaptation;technique video;hombre;consumer electronics;contrast sensitivity;analyse multiresolution;tecnica video;qualite image;local adaptation;modelisation;computer programming;ejecucion;distortion;codificacion;quality assessment;percepcion visual;human visual system;frequence spatiale;image quality;coding;human;psychophysique;perception visuelle;video technique;not significant;visual perception;calidad imagen;video;frecuencia espacial;multi resolution;multiresolution analysis;modeling;radiometric corrections;spatial frequency;analisis multiresolucion;codage;homme;psychophysics	In picture quality assessment, the amount of distortion perceived by a human observer differs from one region to another according to its particular local content. This subjective perception can be explained/predicted by considering some simple psychovisual properties (masking) of the Human Visual System (HVS). We have implemented a HVS model based on a pyramid decomposition for extracting the spatial frequencies, associated with a multi-resolution motion representation. Then the visibility of the decoded errors is computed by exploiting the Kelly's contrast sensitivity spatio-velocity model. The resulting data is called a 'Quality-map.' Special attention has been paid to temporal/moving effects since, in the case of video sequences, motion strongly influences the subjective quality assessment. The quality of the motion information is thus preponderant. In the second part, two possible uses of these psychovisual properties for improving MPEG video encoding performances are depicted: (1) The pre-processing of the pictures to remove non-visible information using a motion adapted filtering. This process is efficient in term of bits saved and degradation is not significant especially on consumer electronic TV sets. (2) A perceptual quantizer based on a local adaptation scheme in order to obtain Quality-maps as uniform as possible (homogeneous perceived distortion), at constant bit-rate. Further improvements have been considered, especially when the viewer is tracking a moving object in the scene.© (2000) COPYRIGHT SPIE--The International Society for Optical Engineering. Downloading of the abstract is permitted for personal use only.	data compression;moving picture experts group	Philippe Bordes;Philippe Guillotel	2000		10.1117/12.387153	computer vision;geography;multimedia;computer graphics (images)	Vision	62.73863806251077	-62.432149896622704	76145
93e8ed56f90ce3a229b50e45660f3ae339c9f076	adaptive sparse modeling and shifted-poisson likelihood based approach for low-dosect image reconstruction		Recent research in computed tomographic imaging has focused on developing techniques that enable reduction of the X-ray radiation dose without loss of quality of the reconstructed images or volumes. While penalized weighted-least squares (PWLS) approaches have been popular for CT image reconstruction, their performance degrades for very low dose levels due to the inaccuracy of the underlying WLS statistical model. We propose a new formulation for low-dose CT image reconstruction based on a shifted-Poisson model based likelihood function and a data-adaptive regularizer using the sparsifying transform model for images. The sparsifying transform is pre-learned from a dataset of patches extracted from CT images. The nonconvex cost function of the proposed penalized-likelihood reconstruction with sparsifying transforms regularizer (PL-ST) is optimized by alternating between a sparse coding step and an image update step. The image update step deploys a series of convex quadratic majorizers that are optimized using a relaxed linearized augmented Lagrangian method with ordered-subsets, reducing the number of (expensive) forward and backward projection operations. Numerical experiments show that for low dose levels, the proposed data-driven PL-ST approach outperforms prior methods employing a nonadaptive edge-preserving regularizer. PL-ST also outperforms prior PWLS-ST approach at very low X-ray doses.	augmented lagrangian method;ct scan;experiment;iterative reconstruction;least squares;loss function;neural coding;numerical method;sparse matrix;statistical model	Siqi Ye;Saiprasad Ravishankar;Yong Long;Jeffrey A. Fessler	2017	2017 IEEE 27th International Workshop on Machine Learning for Signal Processing (MLSP)	10.1109/MLSP.2017.8168124	artificial intelligence;iterative reconstruction;pattern recognition;radiation;tomographic reconstruction;computer science;likelihood function;poisson distribution;statistical model;neural coding;augmented lagrangian method	Vision	56.02320487262003	-74.53778126131631	76154
b9c4f71ca41cdfd43f96c32d72619f34315fb780	hot pixel removal within colour filter array demosaicking using modified bilateral filters	median based detail preserving filter hot pixel removal image sensor digital camera colour artifact problem colour filter array interpolation process cfa demosaicking colour image modified bilateral filter;interpolation;image color analysis interpolation image edge detection filtering algorithms equations arrays patents;optical filters;image sensors;image colour analysis;optical filters cameras image colour analysis image sensors interpolation;cameras	Hot pixels are defective pixels in image sensors produced in the manufacturing process. The amount of these hot pixels is likely to be higher for higher resolution digital cameras, and this may increase with usage. These defective pixels are impulsive in nature and will cause severe colour artifact problems in the colour filter array (CFA) interpolation process for demosaicking of a full colour image. In our proposed method, novel modified bilateral filters are developed to exclude these defective pixels from interfering with the demosaicking process. Once the missing colour pixels are populated, a median based detail-preserving filter is then applied to remove hot pixels from the original sensor data. From our experimental results, it has been shown that our proposed method is able to exclude hot pixels within the demosaicking process in order to minimise colour artifacts. These results have visually and quantitatively confirmed that the proposed method outperforms other existing techniques.	bilateral filter;color filter array;color image;defective pixel;demosaicing;digital camera;gabor filter;image sensor;interpolation;population	Sharmil Randhawa;J. S. Jimmy Li	2013	2013 28th International Conference on Image and Vision Computing New Zealand (IVCNZ 2013)	10.1109/IVCNZ.2013.6727012	demosaicing;computer vision;interpolation;image sensor;optical filter;mathematics;bilateral filter;non-local means;computer graphics (images)	Robotics	58.90274349791181	-59.97461367991751	76182
24492601236f7016f3a9b6a4a8723d4a342957cd	application of genetic programming to edge detector design	programmable logic devices;detectors;genetic program;programmable logic device;genetic programming applications;image processing;transfer functions;edge detection;programmable logic device genetic programming applications image edge detector digital transfer function found function;genetic programming;transfer functions edge detection genetic algorithms programmable logic devices;digital transfer function;current measurement;stochastic processes;image edge detection;transfer function;pixel;image edge detector;logic functions;genetic algorithms;found function;genetic programming detectors image edge detection transfer functions pixel logic functions stochastic processes programmable logic devices image processing current measurement;image edge analysis	The new approach to edge detection is presented in this paper. The proposed method uses genetic programming (GP) to search for digital transfer function of image edge detector. The found function can be easily implemented to any programmable logic device (PLD) that allows to build a fast system of image processing	edge detection;genetic programming;image analysis;image processing;logic gate;pixel;programmable logic device;sensor;test set;transfer function	Tomasz Golonek;Damian Grzechca;Jerzy Rutkowski	2006	2006 IEEE International Symposium on Circuits and Systems	10.1109/ISCAS.2006.1693675	computer vision;electronic engineering;image processing;computer science;theoretical computer science;programmable logic device;transfer function	Arch	55.08514459541334	-64.67708972955315	76289
ecde594335538dd2ed82633f1445d19561e21459	on-orbit calibration of the “meteor-m” microwave imager/sounder	radiative transfer equation;brightness temperature;microwave measurements;radiometry radiative transfer;radiative transfer;mtvza gy;amsr e;ocean temperature;horizontal polarization;microwave imaging;spatial structure;microwave radiometry ocean temperature microwave measurements microwave imaging sea surface sea measurements temperature measurement;microwave radiometry;meteorology remote sensing microwave radiometry sea surface;amsr e on orbit calibration meteor m microwave imager meteor m microwave sounder multichannel microwave radiometer mtvza gy microwave radiative transfer equation brightness temperature vertical polarization horizontal polarization physical geographical region spatial structure marine weather system;meteor m microwave imager;radiometry;sea surface;numerical integration;microwave radiative transfer equation;on orbit calibration;remote sensing;physical geographical region;marine weather system;vertical polarization;temperature measurement;meteor m microwave sounder;multichannel microwave radiometer;microwave radiometer;meteorology;sea measurements	Multichannel microwave radiometer MTVZA-GY onboard of meteorological satellite Meteor-M N 1 performs carries out measurements of outgoing radiation of the atmosphere-underlying system. Both internal and external calibrations of the measured radiation as well as the results of numerical integration of microwave radiative transfer equation are used to derive brightness temperatures TBs at vertical (V) and horizontal (H) polarizations at MTVZA-GY frequencies. Radiosonde data for TBs modeling and comparison with the measured values were selected for various physical-geographical regions. The spatial structures of the marine weather systems measured by MTVZA-GY and AMSR-E were mainly similar. Their differences were due to the differences in the incidence angle: 55° for AMSR-E and 65° for MTVZA-GY.	image sensor;incidence matrix;meteor;microwave;numerical analysis;numerical integration	Igor V. Cherny;Leonid M. Mitnik;Maia L. Mitnik;Alexandr B. Uspensky;Andrey M. Streltsov	2010	2010 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2010.5651139	meteorology;radiative transfer;atmospheric sciences;polarization;microwave radiometer;optics;physics;remote sensing	Embedded	81.82980571835591	-64.07056270583321	76352
2a5dd5f6747ad691159f84ab686ff461ec77a4b2	less is more: coded computational photography	computer vision	Computational photography combines plentiful computing, digital sensors, modern optics, actuators, and smart lights to escape the limitations of traditional cameras, enables novel imaging applications and simplifies many computer vision tasks. However, a majority of current Computational Photography methods involve taking multiple sequential photos by changing scene parameters and fusing the photos to create a richer representation. The goal of Coded Computational Photography is to modify the optics, illumination or sensors at the time of capture so that the scene properties are encoded in a single (or a few) photographs. We describe several applications of coding exposure, aperture, illumination and sensing and describe emerging techniques to recover scene parameters from coded photographs.	computation;computational photography;computer vision;sensor	Ramesh Raskar	2007		10.1007/978-3-540-76386-4_1	computer vision;computational photography;computer science;computational photography;multimedia;computer graphics (images)	Graphics	62.01163449543372	-56.27984461799261	76404
bc8e92de6d4a4f0646c4b4847643d7e7e7625d67	sithon: an airborne fire detection system compliant with operational tactical requirements	health research;uk clinical guidelines;biological patents;airborne imaging system;europe pubmed central;thermal infrared uncooled camera;citation search;wildland fires;global positioning system gps;uk phd theses thesis;life sciences;uk research reports;medical journals;europe pmc;biomedical research;inertial navigation system ins;bioinformatics	In response to the urging need of fire managers for timely information on fire location and extent, the SITHON system was developed. SITHON is a fully digital thermal imaging system, integrating INS/GPS and a digital camera, designed to provide timely positioned and projected thermal images and video data streams rapidly integrated in the GIS operated by Crisis Control Centres. This article presents in detail the hardware and software components of SITHON, and demonstrates the first encouraging results of test flights over the Sithonia Peninsula in Northern Greece. It is envisaged that the SITHON system will be soon operated onboard various airborne platforms including fire brigade airplanes and helicopters as well as on UAV platforms owned and operated by the Greek Air Forces.	airborne ranger;compliance behavior;component-based software engineering;digital camera;geographic information systems;geographic information system;global positioning system;imaging system;projections and predictions;requirement;sithon;unmanned aerial vehicle	Charalambos Kontoes;Iphigenia Keramitsoglou;Nicolaos Sifakis;Pavlos Konstantinidis	2009		10.3390/s90201204	embedded system;medical research;simulation;telecommunications;bioinformatics;engineering;electrical engineering;nanotechnology;remote sensing	Graphics	78.54064399706495	-56.39966872500976	76421
f006bd65b120a6ec0dbe4c67452820a5af5187d9	image quality assessment using foveated wavelet error sensitivity and isotropic contrast	foveation spatial error sensitivity model;image coding;data compression;standard deviation;isotropic contrast;evaluation method;image compression image quality assessment foveated wavelet error sensitivity isotropic contrast image quality evaluation method foveation spatial error sensitivity model wavelet coefficients jpeg compressed images jpeg 2000 compressed images;jpeg compressed images;image quality evaluation method;wavelet transforms;contrast;wavelet transform;wavelet transforms data compression image coding;image compression;foveation;jpeg 2000 compressed images;image quality;image quality frequency humans image coding wavelet domain transform coding wavelet transforms retina testing image processing;image quality assessment;error sensitivity;subjective evaluation;foveated wavelet error sensitivity;wavelet coefficients;contrast image quality assessment wavelet transform foveation error sensitivity	In this paper, we propose a new image quality evaluation method, which is based on foveation spatial error sensitivity model and wavelet error sensitivity model. The image quality is measured by isotropic contrast and the standard deviation of the errors of the wavelet coefficients in subbands with the weighting factors that are determined by two models. Experiments on a test database comprising JPEG and JPEG 2000 compressed images have shown that the proposed metric can achieve very good correlation with subjective evaluation.	coefficient;image quality;jpeg 2000;sensitivity and specificity;wavelet	Susu Yao;Weisi Lin;Ee Ping Ong;Zhongkang Lu;Mei Hwan Loke;Zhengguo Li	2007	2007 IEEE International Symposium on Circuits and Systems	10.1109/ISCAS.2007.377959	computer vision;speech recognition;mathematics;statistics;wavelet transform;computer graphics (images)	Vision	62.074955731876244	-63.47158853991508	76560
e7fb38491c440879691345777885767f505c2e17	similarity criterion for sar tomography over dense urban area		Starting from a stack of co-registered SAR images in interferometric configuration, SAR tomography performs a reconstruction of the reflectivity of scatterers in 3-D. Several scatterers observed within the same resolution cell of each SAR image can be separated by jointly unmixing the SAR complex amplitude observed throughout the stack. To achieve a reliable tomographic reconstruction, it is necessary to estimate locally the SAR covariance matrix by performing some spatial averaging. This necessary averaging step introduces some resolution loss and can bias the tomographic reconstruction by mistakenly including the response of scatterers located within the averaging area but outside the resolution cell of interest. This paper addresses the problem of identifying pixels corresponding to similar tomographic content, i.e., pixels that can be safely averaged prior to tomographic reconstruction. We derive a similarity criterion adapted to SAR tomography and compare its performance with existing criteria on a stack of Spotlight TerraSAR-X images.	dbpedia;phasor;pixel;tomographic reconstruction;tomography	Clement Rambour;Loïc Denis;Florence Tupin;Jean-Marie Nicolas;Hélène Oriot;Laurent Ferro-Famil;Charles-Alban Deledalle	2017	2017 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)	10.1109/IGARSS.2017.8127315	computer vision;remote sensing;artificial intelligence;pixel;synthetic aperture radar;tomography;covariance matrix;amplitude;tomographic reconstruction;computer science;speckle pattern;image resolution	Vision	74.00397981089473	-65.92354962736506	76590
c5806ed097d719126a2dc0b93a268632f0d0f3bd	ground deformation monitoring in the ranafjord area of norway by means of the permanent scatterers technique	stress;norsar;radar remote sensing;information retrieval;synthetic aperture radar norway tectonics faulting geodesy crustal deformation geophysical measurement technique ground deformation monitoring ranafjord permanent scatterers method norsar differential sar interferometry radar remote sensing dinsar insar sar;tectonics;testing;ground deformation monitoring;synthetic aperture radar tectonics tectonics faulting faulting geodesy geodesy geophysical techniques remote sensing by radar;layout;earthquakes;surface topography;monitoring radar scattering earthquakes interferometry layout testing information retrieval synthetic aperture radar surface topography stress;geophysical measurement technique;remote sensing by radar;radar scattering;sar interferometry;permanent scatterers method;sar;monitoring;norway;insar;permanent scatterer;differential sar interferometry;interferometry;dinsar;ranafjord;faulting;crustal deformation;continental margin;geophysical techniques;geodesy;synthetic aperture radar	Although Norway is situated along a passive continental margin, it is not devoid of tectonic activity. Several studies have documented significant movements along faults within the last 10-12 ka. Most of such movements probably occurred shortly after deglaciation, when rates of crustal rebound were very high. Nonetheless, current seismicity along the Norwegian coast suggests that crustal deformation is still taking place. Ranafjord, in northern Norway, is a region with higher than average seismic activity. A six-station seismic network installed by NORSAR detected numerous earthquake swarms in the area. In order to retrieve further crustal deformation data relative to Ranafjord it was decided to use differential SAR interferometry (DInSAR). The application of conventional DInSAR is extremely challenging because the expected deformation rates are low (a few mm/yr) and over long time spans phase coherence is not preserved on large portions of the area to be investigated. The Permanent Scatterers (PS) technique overcomes these drawbacks by exploiting long series of ERS data. At Permanent Scatterers, i.e. individual phase stable point-wise radar targets, displacement data can be retrieved with millimetric: accuracy. The PS grid can be seen as a high spatial density natural geodetic network. Thirty-seven ERS scenes covering the time span 1992-2000 were involved in a Permanent Scatterers (PS) analysis.		John F. Dehls;Marco Basilico;Carlo Colesanti	2002		10.1109/IGARSS.2002.1024988	layout;seismology;synthetic aperture radar;geodesy;continental margin;geology;interferometry;stress;tectonics;physics;remote sensing	EDA	79.58713876385295	-62.86147030683682	76639
cd9f9bd15b5b928da659550eec17800c69e34a2b	investigation of smap fusion algorithms with airborne active and passive l-band microwave remote sensing	microwave radiometry soil moisture l band radar soil measurements microwave measurement;radarkonzepte;juser;publikationsdatenbank;websearch;smap fusion algorithm single source soil moisture products regression parameters radar vegetation index radar backscatter soil moisture retrieval active microwave backscatter passive microwave brightness temperature active sensor backscatter data passive sensor data active passive fusion technique land cover type ad 2013 f sar active l band system polarimetric l band multibeam radiometer passive l band system germany rur catchment airborne instrument soil moisture mapping radiometer instrument l band radar freeze thaw state global soil moisture measurement soil moisture active passive mission nasa smap mission passive l band microwave remote sensing airborne active l band microwave remote sensing;microwave radiometry;microwave measurement;airborne radar hydrology moisture radar polarimetry radiometry remote sensing by radar soil synthetic aperture radar;soil moisture;soil moisture active passive fusion l band microwave radar radiometer soil moisture active passive smap;publications database;active passive fusion l band microwave radar radiometer soil moisture active passive smap soil moisture;soil measurements;single source soil moisture products regression parameters radar vegetation index radar backscatter soil moisture retrieval active microwave backscatter passive microwave brightness temperature active sensor backscatter data passive sensor data active passive fusion technique land cover type ad 2013 f sar active l band system polarimetric l band multibeam radiometer passive l band system germany rur catchment airborne instrument soil moisture mapping radiometer instrument l band radar freeze thaw state global soil moisture measurement soil moisture active passive mission nasa smap mission passive l band microwave remote sensing airborne active l band microwave remote sensing smap fusion algorithm	The objective of the NASA Soil Moisture Active Passive (SMAP) mission is to provide global measurements of soil moisture and freeze/thaw states. SMAP integrates L-band radar and radiometer instruments as a single observation system combining the respective strengths of active and passive remote sensing for enhanced soil moisture mapping. Airborne instruments are a key part of the SMAP validation program. Here, we present an airborne campaign in the Rur catchment, Germany, in which the passive L-band system Polarimetric L-band Multi-beam Radiometer and the active L-band system F-SAR of DLR were flown simultaneously on six dates in 2013. The flights covered the full heterogeneity of the area under investigation, i.e., the main land cover types and all experimental monitoring sites. Here, we used the obtained data sets as a test bed for the analysis of three active-passive fusion techniques: 1) estimation of soil moisture by passive sensor data and subsequent disaggregation by active sensor backscatter data; 2) disaggregation of passive microwave brightness temperature by active microwave backscatter and subsequent inversion to soil moisture; and 3) fusion of two single-source soil moisture products from radar and radiometer. Results indicate that the regression parameters β are dependent on the radar vegetation index. The best performance was obtained by the fusion of radiometer brightness temperatures and radar backscatter, which was able to reach the same accuracy as single-source coarse-scale radiometer soil moisture retrieval but on a higher spatial resolution.	airborne ranger;algorithm;common platform;dynamic language runtime;l band;microsoft outlook for mac;microwave;passive optical network;pixel;polarimetry;radar;second level address translation;sensor;system f;testbed;time series	Carsten Montzka;Thomas Jagdhuber;Ralf Horn;Heye R. Bogena;Irena Hajnsek;Andreas Reigber;Harry Vereecken	2016	IEEE Transactions on Geoscience and Remote Sensing	10.1109/TGRS.2016.2529659	meteorology;l band;water content;hydrology;electrical engineering;radar;remote sensing	Mobile	81.7078687780743	-63.33179734791435	76664
833d2ac1f3d7d40371a7e5703931c47b9c9266b1	a robust framework for eigenspace image reconstruction	eigenvalues and eigenfunctions;pixel level;estimation theory;optimisation;least squares approximations;image resolution;least squares estimation techniques;basis image space;two step algorithm;optimal method;computer vision;sparse projected coefficients;eigenspace image reconstruction;frame level;signal processing problems;principal components analysis;soft threshold estimation;image reconstruction;signal processing;principal component analysis;robustness image reconstruction principal component analysis computer vision signal processing least squares approximation signal processing algorithms pixel optimization methods computational efficiency;robust m estimation;soft threshold estimation eigenspace image reconstruction principal components analysis computer vision signal processing problems least squares estimation techniques two step algorithm frame level pixel level lasso optimization method sparse projected coefficients basis image space robust m estimation intra sample outliers;least squares estimate;principal component analysis eigenvalues and eigenfunctions estimation theory image reconstruction image resolution least squares approximations optimisation;large scale problem;lasso optimization method;intra sample outliers;principal component	"""Principal components analysis (PCA) is proved to be a useful tool for many computer vision and signal processing problems. One drawback of traditional PCA is that they are based on least squares estimation techniques and hence fail to account for """"outliers"""" which commonly occurs in realistic training sets. To make PCA more robust to real-world problems such as image reconstruction addressed in this paper, we develop a two-step algorithm that can eliminate the outliers on both frame level and pixel level through the LASSO and RPCA separately. With LASSO optimization method, we may obtain sparse projected coefficients of the original image into the basis image space. According to the sparsity of these coefficients, sample outliers can be recognized automatically. Then, with the use of robust M-estimation, the influence of intra-sample outliers may be overwhelmed to great extent. Additionally, due to orthogonality of the principal components, the soft-threshold estimation can be applied to the LASSO to alleviate the computational costs, hence make our robust PCA method more applicable to large-scale problems. An experiment on object image reconstruction is used to illustrate the advantage of our proposed technique over standard PCA"""	algorithm;coefficient;computer vision;iterative reconstruction;lasso;least squares;mathematical optimization;pixel;principal component analysis;signal processing;sparse matrix	Xiao-Tong Yuan;HongWen Zhu;ShuTang Yang	2005	2005 Seventh IEEE Workshops on Applications of Computer Vision (WACV/MOTION'05) - Volume 1	10.1109/ACVMOT.2005.12	computer vision;mathematical optimization;computer science;machine learning;signal processing;pattern recognition;mathematics;statistics;principal component analysis	Vision	59.62996729684542	-69.10373214934359	76721
5b2cf6da10abd8676f13b5065907d449c04ef9e6	small baseline stereovision	numerical elevation model nem;finite resolution;digital elevation model;satisfiability;discrete correlation;digital elevation model dem;shannon sampling;stereo;block matching	This paper presents a study of small baseline stereovision. It is generally admitted that because of the finite resolution of images, getting a good precision in depth from stereovision demands a large angle between the views. In this paper, we show that under simple and feasible hypotheses, small baseline stereovision can be rehabilitated and even favoured. The main hypothesis is that the images should be band limited, in order to achieve sub-pixel precisions in the matching process. This assumption is not satisfied for common stereo pairs. Yet, this becomes realistic for recent spatial or aerian acquisition devices. In this context, block-matching methods, which had become somewhat obsolete for large baseline stereovision, regain their relevance. A multi-scale algorithm dedicated to small baseline stereovision is described along with experiments on small angle stereo pairs at the end of the paper.	aerial photography;bandlimiting;baseline (configuration management);coefficient;computer vision;domain generation algorithm;experiment;jean;langrisser schwarz;linear algebra;metric;multi-touch;order of approximation;pixel;relevance;social inequality;stereopsis;stereoscopy	Julie Delon;Bernard Rougé	2007	Journal of Mathematical Imaging and Vision	10.1007/s10851-007-0001-1	computer vision;simulation;digital elevation model;mathematics;geometry;stereophonic sound;satisfiability	Vision	66.74099248215893	-55.294766717853975	76730
2c34cedb3f000ef619ad037207c7a253c12db5a1	introducing total curvature for image processing	minimisation;radon transforms;integral equation;image segmentation;image processing;radon transforms computational geometry image processing minimisation;approximation method;computational geometry;minimization algorithm total curvature image processing menger melnikov curvature radon measure convex relaxation convex set;tv minimization approximation methods integral equations noise reduction image segmentation;noise reduction;total variation;generalized inverse;inproceedings;convex set;convex relaxation;mean curvature;radon measure;support function	We introduce the novel continuous regularizer total curvature (TC) for images u: Ω → ℝ. It is defined as the Menger-Melnikov curvature of the Radon measure |Du|, which can be understood as a measure theoretic formulation of curvature mathematically related to mean curvature. The functional is not convex, therefore we define a convex relaxation which yields a close approximation. Similar to the total variation, the relaxation can be written as the support functional of a convex set, which means that there are stable and efficient minimization algorithms available when it is used as a regularizer in image processing problems. Our current implementation can handle general inverse problems, inpainting and segmentation. We demonstrate in experiments and comparisons how the regularizer performs in practice.	algorithm;approximation;convex optimization;convex set;experiment;image processing;inpainting;linear programming relaxation;menger sponge;theory	Bastian Goldlücke;Daniel Cremers	2011	2011 International Conference on Computer Vision	10.1109/ICCV.2011.6126378	support function;computer vision;minimisation;mathematical optimization;topology;generalized inverse;image processing;computational geometry;radon measure;mean curvature;noise reduction;mathematics;geometry;convex set;image segmentation;total variation;integral equation	Vision	54.55723643728798	-72.55586610849377	76775
0b830bdacf578f6e1750420683a345e7af3c5b26	feature selection for classification of hyperspectral data by svm	support vector machines;hughes phenomenon;dimensionality reduction analysis;reduction;hyperspectral sensors;statistical significance;stockage donnee;infrared spectra;classification;costo;hyperspectral imaging support vector machines support vector machine classification hyperspectral sensors educational institutions memory computational efficiency space technology infrared sensors infrared spectra;support vector machines geophysics computing;accuracy;data storage;precision;geophysics computing;remote sensing data;hyperspectral sensor data sets;computational processing costs support vector machines svm dimensionality reduction analysis hyperspectral sensor data sets feature selection analysis hughes phenomenon hyperspectral data data storage;hyperspectral data;support vector machines svm;almacenamiento datos;support vector machine classification;svm;feature selection;space technology;support vector machine;feature selection analysis;hyperspectral imaging;classification accuracy;computational processing costs;computational efficiency;cost;dimensional reduction;clasificacion;infrared sensors;support vector machines svm classification accuracy feature selection hughes phenomenon hyperspectral data;memory;cout	Support vector machines (SVM) are attractive for the classification of remotely sensed data with some claims that the method is insensitive to the dimensionality of the data and, therefore, does not require a dimensionality-reduction analysis in preprocessing. Here, a series of classification analyses with two hyperspectral sensor data sets reveals that the accuracy of a classification by an SVM does vary as a function of the number of features used. Critically, it is shown that the accuracy of a classification may decline significantly (at 0.05 level of statistical significance) with the addition of features, particularly if a small training sample is used. This highlights a dependence of the accuracy of classification by an SVM on the dimensionality of the data and, therefore, the potential value of undertaking a feature-selection analysis prior to classification. Additionally, it is demonstrated that, even when a large training sample is available, feature selection may still be useful. For example, the accuracy derived from the use of a small number of features may be noninferior (at 0.05 level of significance) to that derived from the use of a larger feature set providing potential advantages in relation to issues such as data storage and computational processing costs. Feature selection may, therefore, be a valuable analysis to include in preprocessing operations for classification by an SVM.	computer data storage;design of experiments;dimensionality reduction;dynamic language runtime;feature selection;multispectral image;pal;preprocessor;support vector machine;test set	Mahesh Pal;Giles M. Foody	2010	IEEE Transactions on Geoscience and Remote Sensing	10.1109/TGRS.2009.2039484	support vector machine;computer science;machine learning;linear classifier;pattern recognition;data mining;feature selection	ML	79.43198487347888	-55.567889468834245	76947
71c94209516ec32cffa33ecf0374f3b0caea2a33	hyperspectral image analysis using multifractal attributes	hyperspectral remote sensors;traitement du signal et de l image;intelligence artificielle;vision par ordinateur et reconnaissance de formes;traitement des images;synthese d image et realite virtuelle	The increasing spatial resolution of hyperspectral remote sensors requires the development of new processing methods capable of combining both spectral and spatial information. In this article, we focus on the spatial component and propose the use of novel multifractal attributes, which extract spatial information in terms of the fluctuations of the local regularity of image amplitudes. The novelty of the proposed approach is twofold. First, unlike previous attempts, we study attributes that efficiently summarize multifractal information in a few parameters. Second, we make use of the most recent developments in multifractal analysis: wavelet leader multifractal formalism, the current theoretical and practical benchmark in multifractal analysis, and a novel Bayesian estimation procedure for one of the central multifractal parameters. Attributes provided by these state-of-the-art multifractal analysis procedures are studied on two sets of hyperspectral images. The experiments suggest that multifractal analysis can provide relevant spatial/textural attributes which can in turn be employed in tasks such as classification or segmentation.	benchmark (computing);experiment;image analysis;memory segmentation;multifractal system;semantics (computer science);sensor;statistical classification;wavelet	Sébastien Combrexelle;Herwig Wendt;Jean-Yves Tourneret;Stephen McLaughlin;Patrice Abry	2015	2015 7th Workshop on Hyperspectral Image and Signal Processing: Evolution in Remote Sensing (WHISPERS)	10.1109/WHISPERS.2015.8075453	computer vision;geography;artificial intelligence;cartography	Vision	72.13425956976153	-61.47419823167563	76962
000b53742baa258b8f203393cfda3f2f91dddcea	system design of cloud profiling radar for earthcare	active sensor;cpr;remote sensing by radar clouds doppler radar meteorological radar;earthcare;millimeter wave doppler radar;design and development;meteorological radar;climate model;earth;millimeter wave radar;earth radiation budget;clouds european space agency japanese space agency earthcare cpr system design earth clouds aerosols and radiation explorer satellite cloud profiling radar millimeter wave doppler radar;three dimensional;satellite broadcasting;vertical structure;remote sensing by radar;european space agency;doppler effect;optical imaging;doppler radar cloud profiling radar earthcare cpr;radar antennas;system design;clouds;satellites;doppler radar;earth clouds aerosols and radiation explorer satellite;earthcare cpr system design;communications technology;space technology;japanese space agency;global warming;clouds spaceborne radar doppler radar satellite broadcasting earth aerosols radar antennas millimeter wave radar space technology communications technology;meteorology;cloud profiling radar;radar;spaceborne radar;aerosols	European and Japanese space agencies plan to launch a satellite called EarthCARE (Earth Clouds, Aerosols and Radiation Explorer). The Cloud Profiling Radar (CPR), which will be the first millimeter-wave Doppler radar in space, is installed on this satellite as a main sensor to observe clouds. This paper describes the outline of the system design of EarthCARE CPR.	radar;systems design	Hirotaka Nakatsuka;Kazuyuki Okada;Hiroaki Horie;Toshiyoshi Kimura;Yukie Iida;Masahiro Kojima;Kenji Sato;Yuichi Ohno;Nobuhiro Takahashi;Hiroshi Kumagai	2008	IGARSS 2008 - 2008 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2008.4780035	meteorology;three-dimensional space;information and communications technology;atmospheric sciences;doppler effect;global warming;optical imaging;earth;space technology;physics;radar;satellite;remote sensing;climate model;systems design	Embedded	80.37998781063087	-63.062920134231874	77005
c1ceb73d6fe314e37fe671bd95f5ac67f8fe9c9f	arc recognition on irregular isothetic grids and its application to reconstruction of noisy digital contours	digital circle;irregular isothetic grid;arc recognition	In the present paper, we introduced an arc recognition technique suitable for irregular isothetic object. It is based on the digital inter-pixel (DIP) circle model, a pixel-based representation of the Kovalevsky’s circle. The adaptation to irregular image structurations allows us to apply DIP models for circle recognition in noisy digital contours. More precisely, the noise detector from Kerautret and Lachaud (2009) provides a multi-scale representation of the input contour with boxes of various size. We convert them into an irregular isothetic object and, thanks to the DIP model, reduce the recognition of arcs of circles in this object to a simple problem of point separation.	digital geometry;pixel;synthetic data;time complexity	Jean-Luc Toutant;Antoine Vacavant;Bertrand Kerautret	2013		10.1007/978-3-642-37067-0_23	computer vision;mathematics;computer graphics (images)	Vision	65.33533741469572	-53.834812665023236	77026
7f0cc5a5977bfa7a27d26b7c8499b21e00c60e61	implementation of total variation regularization algorithm on cell processor	image motion analysis;pipeline processing hdtv image processing minimization broadband communication programming;image processing;motion pictures;regularization method;cell processor;microprocessor chips high definition television image motion analysis iterative methods;total variation regularization;iterative methods;total variation;software design;hdtv total variation regularization algorithm cell processor tv regularization method image processing applications iterative calculations motion pictures programming techniques optimum software design high definition television;high definition television;microprocessor chips	The total variation (TV) regularization method is very effective and attractive for various image processing applications. The problem with the TV approach is the long computational time resulting from iterative calculations, which has been considered to be a major hurdle for its application to motion pictures. In this study, we have implemented the TV algorithm on the CELL processor by using various special programming techniques and an optimum software design.	algorithm;cell (microprocessor);computation;image processing;iterative method;software design;time complexity;total variation denoising;total variation diminishing	A. Tsutsui;Yasuhiro Sakuta;Tomio Goto;Masaru Sakurai;R. Sakai	2012	2012 IEEE International Conference on Consumer Electronics (ICCE)	10.1109/ICCE.2012.6161990	computer vision;electronic engineering;image processing;computer science;software design;theoretical computer science;iterative method;total variation	Robotics	59.26882807266229	-74.8756123149848	77055
92b88a75e74d95176692fcba88efff1bb17508a3	interference cancellation for high-frequency surface wave radar	cochannel radio frequency interference;high frequency surface wave radar;onde surface;high frequency surface wave radar hfswr;clutter;radar methods;interferences;lightning impulsive noise;marine radar array signal processing geophysical techniques interference suppression;foudre;interference cancellation adaptive beamforming high frequency surface wave radar hfswr;impulse noise;performance;frequence;array signal processing;ionospheric clutter;interference;ionosphere;radiofrequency interference;time domain analysis;interference suppression;rayo;haute frequence;sea surface;frecuencia;surface wave;radio frequency interference;bruit;noise cancellation;radiating source;lightning;marine radar;evaluation;performances;interference cancellation surface waves radar radiofrequency interference clutter hafnium time domain analysis sea surface noise cancellation lightning;onda superficie;surface waves;hfswr;experimental evaluation;environmental interference;frequency;adaptive beamforming;high frequency;methode radar;interference cancellation;geophysical techniques;hfswr interference cancellation environmental interference noise cochannel radio frequency interference radiating source ionospheric clutter lightning impulsive noise adaptive beamforming schemes high frequency surface wave radar;onde radar;radar;adaptive beamforming schemes;noise;onde radioelectrique;hafnium	The performance of high-frequency surface wave radar (HFSWR) is known to suffer from external environmental interference and noise, such as cochannel radio-frequency interference from other radiating source, ionospheric clutter, lightning impulsive noise, etc. This paper experimentally evaluates the interference cancellation performance of various adaptive beamforming schemes with respect to the aforementioned three types of interferences in an attempt to find the most promising adaptive cancellation scheme in practical HFSWR environment.	adaptive beamformer;beamforming;clutter;experiment;interference (communication);performance;radar;radio frequency;statistical interference;surface wave	Xingjie Guo;Hongbo Sun;Tat Soon Yeo	2008	IEEE Transactions on Geoscience and Remote Sensing	10.1109/TGRS.2008.916482	single antenna interference cancellation;acoustics;performance;telecommunications;surface wave;physics	Visualization	76.76390784684514	-67.1854300962333	77067
70bee9d022527f77b86b7f47cf3b26fc8144fcff	interferometric data fusion for topographic profile reconstruction	topographic profile reconstruction sensitivity;phase measurement;change detection;topography earth;radar interferometry;digital elevation model interferometric data fusion topographic profile reconstruction ground surface change detection differential sar interferometry;data fusion;interferometric data fusion;digital elevation model;surface reconstruction;surface topography;remote sensing by radar;accuracy;sar interferometry;ground surface change detection;mean square error;phase estimation;pixel;interferometry digital elevation models surface reconstruction surface topography radar detection phase estimation phase measurement radar measurements coherence mean square error methods;mean square error methods;coherence;decorrelation;digital elevation models;radar detection;differential sar interferometry;interferometry;topographic profile reconstruction;interferometric data fusion sar interferometry topographic profile reconstruction sensitivity;sensor fusion;radar measurements;radar;topography earth digital elevation models radar interferometry remote sensing by radar sensor fusion synthetic aperture radar;synthetic aperture radar	Topographic profile reconstruction and ground surface change detection are actually being measured by SAR and differential SAR interferometry. The deal is how topography is estimated from interferometry especially the relative sensitivity of measured radar phase to topography and changes in topography. The objective of this paper is to combine several DEM (Digital Elevation Model) resulting from different interferometric processing by taking into account the coherence information in order to improve the topographic profile accuracy. For that purpose different conjunctive operators are used in data fusion processing. The resulted digital elevation models are evaluated using Mean Square Error (MSE) according to a local reference DEM.	digital elevation model;mean squared error;topography	Ferdaous Chaabane	2008	IGARSS 2008 - 2008 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2008.4779843	digital elevation model;geodesy;computer science;sensor fusion;optics;physics;remote sensing	Embedded	77.99990876484003	-65.35489743448369	77108
c340d2bb1c90d905eee7d415787671d7ddd40e26	supervised som based atr method with circular polarization basis of full polarimetric data	polarimetric sar;automatic target recognition atr;synthetic aperture radar sar;target area extraction;circular polarization basis	Satellite-borne or aircraft-borne synthetic aperture radar (SAR) is useful for high resolution imaging analysis for terrain surface monitoring or surveillance, particularly in optically harsh environments. For surveillance application, there are various approaches for automatic target recognition (ATR) of SAR images aiming at monitoring unidentified ships or aircraft. In addition, various types of analyses for full polarimetric data have been developed recently because it can provide significant information to identify structure of targets, such as vegetation, urban, sea surface areas. ATR generally consists of two processes, one is target feature extraction including target area determination, and the other is classification. In this paper, we propose novel methods for these two processes that suit full polarimetric exploitation. As the target area extraction method, we introduce a peak signal-to noise ratio (PSNR) based synthesis with full polarimetric SAR images. As the classification method, the circular polarization basis conversion is adopted to improve the robustness especially to variation of target rotation angles. Experiments on a 1/100 scale model of X-band SAR, demonstrate that our proposed method significantly improves the accuracy of target area extraction and classification, even in noisy or target rotating situations. key words: synthetic aperture radar (SAR), polarimetric SAR, automatic target recognition (ATR), target area extraction, circular polarization basis	aperture (software);automatic target recognition;circular polarization;feature extraction;image resolution;peak signal-to-noise ratio;polarimetry;synthetic data	Shouhei Ohno;Shouhei Kidera;Tetsuo Kirimoto	2015	IEICE Transactions	10.1587/transcom.E98.B.2520	computer vision	Vision	75.73576783383629	-58.899048607140514	77167
8a64f910291819b968a7f48a3cc5027ce3ef0f88	stochastic modeling of time series radar interferometry	radar interferometry;stochastic processes remote sensing by radar geophysical signal processing synthetic aperture radar radar theory radiowave interferometry radar signal processing time series;time series;remote sensing by radar;stochastic processes;stochastic processes radar interferometry synthetic aperture radar interferometry parameter estimation surfaces image resolution space technology testing phase estimation state estimation;error propagation;geophysical signal processing;deformation estimation stochastic modeling time series radar interferometry insar evaluation phase ambiguity resolution deterministic problem error propagation probability distribution topography estimation;probability distribution;ambiguity resolution;radiowave interferometry;stochastic model;radar theory;radar signal processing;synthetic aperture radar	Quality description and evaluation of InSAR results is hampered by the fact that the model to derive parameters from the observations is usually underdetermined. Only using strong, often rather qualitative, assumptions it is possible to reach unique solutions. One of the most prominent assumptions is that phase ambiguity resolution can be treated as a deterministic problem. In this study, a model formulation is presented that captures the majority of the assumptions in a mathematical sense, allowing for adjustment, testing procedures and formal error propagation. The influence of stochastic ambiguity resolution to the probability distribution of the estimated parameters is shown.	estimation theory;markov chain;modal logic;multimodal interaction;propagation of uncertainty;radar;software propagation;stochastic modelling (insurance);time series	Ramon F. Hanssen	2004	IGARSS 2004. 2004 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2004.1369832	probability distribution;stochastic process;synthetic aperture radar;stochastic modelling;propagation of uncertainty;time series;optics;statistics;remote sensing	Embedded	73.82533155804363	-65.99370046964191	77254
6bc4790e8940d41c274e2314485a17dc530a359a	estimation of croplands using indicator kriging and fuzzy classification	supervised classification;sugarcane;geostatistics;remote sensing;artigo;citrus	The knowledge of the land use is important for the agricultural economy and for defining the deployment of new crops. Thus, a tool for the mapping and quantification of crops is necessary. The development of a tool is possible with the use of remote-sensing images and efficient algorithm classifiers. The objective of this study was to verify the accuracies of indicator kriging and fuzzy classification as supervised classifiers in identifying sugarcane and citrus crops, which are more cultivated in São Paulo, Brazil. The investigated area was located on the border of the municipalities of São Manuel and Botucatu, São Paulo State, Brazil. We used digital images from satellite IRS-P6 (ResourceSat-1; path/row 329/94, January 29, 2011) with a spatial resolution of 23.5 m. In the pre-processing phase, images were prepared for classification using several techniques, such as enhancement, geometric rectification and registration and reduction of dimensionality. In the process of image classification for citrus and sugarcane areas, two methods of classification were utilized, namely indicator kriging (IK) and fuzzy classification, and compared to the visual classification, which was assumed to reflect the reality on the ground (citrus, sugarcane, native vegetation, forest regeneration, soil and water). The classifications were made based on bands 2, 3, 4 and 5 and were evaluated using the kappa index. From the results of the classification of the pictures used for the discrimination and quantification of areas cultivated with citrus and sugarcane, the following conclusions can be drawn: the multispectral bands showed spatial dependence for both citrus and sugarcane, whereas a comparison of the maps revealed that the IK classifier confused citrus with areas of vegetation, and the fuzzy classifier confused citrus with forest regeneration; the IK classifier overestimated the areas of sugarcane crops, whereas the fuzzy classifier underestimated these areas. Based on the kappa index, band 2 (0.52–0.59 lm) better represented the citrus and sugarcane areas, whereas band 5 (1.55–1.70 lm) had the worst classification for both the IK and fuzzy algorithms. Citrus crop were best identified using the fuzzy classifier, and the sugarcane crop was best identified using the	algorithm;computer vision;digital image;formal concept analysis;fuzzy classification;image rectification;image registration;kriging;map;multispectral image;p6 (microarchitecture);preprocessor;software deployment;supervised learning	Alessandra Fagioli da Silva;Ana Paula Barbosa;Célia Regina Lopes Zimback;Paulo Milton Barbosa Landim;Amílcar Soares	2015	Computers and Electronics in Agriculture	10.1016/j.compag.2014.11.020	agronomy;remote sensing;geostatistics	ML	79.6374287439765	-57.61035759430929	77274
24ff6df6bbe33f53439d281d1a64425544183781	extraction of building's geometric axis line from lidar data for disaster management	building extraction;airborne laser scanning;disaster management airborne laser scanning building s geometric axis line inclined building ransac;building geometric axis line;disaster management;radar signal processing disasters optical radar;inclined building;laser radar;ransac;earthquakes;data mining;building s geometric axis line;buildings laser radar earthquakes three dimensional displays clouds data mining algorithm design and analysis;damage analysis;optical radar;three dimensional displays;clouds;lidar data;natural disaster;damage analysis building geometric axis line lidar data disaster management;algorithm design and analysis;radar signal processing;buildings;disasters	Fast and reliable building damage analysis is crucial for survivors rescue and disaster management when a destructive natural disaster occurs which helps to limit life losses. For this purpose, a method was developed in this paper to extract building's geometric axis line from aerial LiDAR data which helps to do further building damage analysis like to identify inclined buildings. To extract building's geometric axis line, several steps were carried out such as segmentation of buildings, extraction of roof facets, fitting of mean roof plane and getting main roof. The aerial LiDAR data was captured over the area of Port-au-Prince, Haiti which contains numerous of inclined buildings. The results demonstrate the feasibility and effectiveness of the proposed approach to identify inclined building for damage management.	aerial photography;apache axis;image segmentation;prince	Yonglin Shen;Zhi Wang;Lixin Wu	2010	2010 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2010.5654178	lidar;algorithm design;computer vision;disaster;ransac;natural disaster;computer science;machine learning;emergency management;remote sensing	Robotics	75.11196846710551	-58.59486132793045	77276
6fd8520c21001ac9ba1c9748e3dfc00e7f6aa845	optimal parameter updating for optical diffusion imaging	optical imaging;inverse problems;absorption;approximation algorithms;nonlinear optics;image reconstruction;iterative methods;optical scattering;convergence;frechet derivative;born approximation	Because optical diffusion imaging is a highly nonlinear inverse problem, iterative inversion algorithms based on the Born approximation have usually been employed as reconstruction technique, but convergence is slow, especially for high contrast parameter distributions. We show here that the slow convergence of the conventional algorithms is due to the linear integral operator derived by the Born approximation not being the optimal Fre'chet derivative. W e derive the optimal Fre'chet derivative operator with respect to the spatially varying absorption and scattering coeficients in integral form, and then develop a new iterative inversion algorithm.	algorithm;approximation;gene expression programming;iterative method;nonlinear system	Jong Chul Ye;Kevin J. Webb;Rick P. Millane;Thomas J. Downar	1998			absorption;iterative reconstruction;nonlinear optics;born approximation;fréchet derivative;mathematical optimization;mathematical analysis;convergence;inverse problem;calculus;optical imaging;mathematics;iterative method;light scattering;approximation algorithm	Vision	56.99156123774255	-74.77580427573866	77289
9817c194f1340cbf4382fd442bc8e1c4860956bb	nonlinear filtering in the wavelet transform domain	gaussian noise;image features;nonlinear filters;pattern clustering;image processing;psnr nonlinear filtering wavelet transform domain wavelet coefficient local neighboring coefficients similarity measure noise classification edge classification statistical characteristics noise characteristics clustering technique neighboring coefficients additive white gaussian noise outlier type noise image features image denoising awgn;nonlinear filter;image classification;filtering wavelet domain wavelet transforms wavelet coefficients gaussian noise signal processing algorithms image denoising noise reduction signal to noise ratio noise measurement;wavelet transforms;expected value;wavelet transform;statistical analysis;pattern clustering nonlinear filters filtering theory gaussian noise image processing wavelet transforms image classification statistical analysis;image denoising;filtering theory	A new approach for image denoising in the wavelet transform domain is proposed. In this approach we attempt to replace each wavelet coefficient by its expected value. For that we will use local neighboring coefficients to provide a measure of similarity, noise and edge classification. The approach uses the statistical characteristics of neighboring coefficients as well as the noise characteristics. A clustering technique will be used to determine the degree of belonging of neighboring coeflcients and coefficient under consideration. Experimental results will show that this technique yields comparable results in removing gaussian type noise. Results will show that the approach yields far better results than other existing technique in removing both gaussian and outlier type noise without disturbing important image features.	cluster analysis;coefficient;image noise;noise reduction;wavelet transform	Yousef M. Hawwar;Ali M. Reza	2000		10.1109/ICIP.2000.899346	gaussian noise;computer vision;image processing;computer science;machine learning;pattern recognition;mathematics;stationary wavelet transform;statistics;wavelet transform	AI	56.1273763238342	-66.22570216985285	77296
2fef49c00fa88784d02b2b7ecaf4f4c929bf04d8	objective quality assessment for image retargeting based on perceptual distortion and information loss	image processing;quality evaluation image retargeting sift flow quality assessment;geometry;measurement abstracts image analysis correlation databases;image processing distortion geometry;distortion;subjective assessments objective quality assessment display screens content aware image retargeting algorithms objective metric visual quality assessment perceptual geometric distortion information loss sift flow variation visual saliency map human perception metric assessments	Image retargeting techniques aim to obtain retargeted images with different sizes or aspect ratios for various display screens. Various content-aware image retargeting algorithms have been proposed recently. However, there is still no accurate objective metric for visual quality assessment of retargeted images. In this paper, we propose a novel objective metric for assessing visual quality of retargeted images based on perceptual geometric distortion and information loss. The proposed metric measures the geometric distortion of retargeted images by SIFT flow variation. Furthermore, a visual saliency map is derived to characterize human perception of the geometric distortion. On the other hand, the information loss in a retargeted image, which is calculated based on the saliency map, is integrated into the proposed metric. A user study is conducted to evaluate the performance of the proposed metric. Experimental results show the consistency between the objective assessments from the proposed metric and subjective assessments.	algorithm;distortion;experiment;retargeting;scale-invariant feature transform;seam carving;usability testing	Chih-Chung Hsu;Chia-Wen Lin;Yuming Fang;Weisi Lin	2013	2013 Visual Communications and Image Processing (VCIP)	10.1109/VCIP.2013.6706443	computer vision;distortion;telecommunications;image processing;computer science;machine learning;pattern recognition;mathematics	AI	62.06285430054988	-63.782117116616796	77329
232649c6b514563a9285bdd322a36041de825279	sirf: simultaneous satellite image registration and fusion in a unified framework	image fusion distortion image registration remote sensing distortion measurement spatial resolution;terrain mapping geophysical image processing image fusion image registration image resolution iterative methods least squares approximations mathematics computing optimisation;pan sharpening;image fusion;distortion measurement;distortion;joint fusion;remote sensing;image registration;group sparsity;dynamic gradient sparsity;joint fusion image fusion pan sharpening image registration dynamic gradient sparsity group sparsity;future research simultaneous satellite image registration sirf high resolution panchromatic image low resolution multispectral image geographical location convex optimization problem linear least squares fitting combination dynamic gradient sparsity regularizer spectral information ms image image edges linear computational complexity dynamic gradient sparsity property image iteration state of the art image fusion methods spectral qualities spatial qualities high quality products matlab implementation coarsely registered real world ikonos data sets;spatial resolution	In this paper, we propose a novel method for image fusion with a high-resolution panchromatic image and a low-resolution multispectral (Ms) image at the same geographical location. The fusion is formulated as a convex optimization problem which minimizes a linear combination of a least-squares fitting term and a dynamic gradient sparsity regularizer. The former is to preserve accurate spectral information of the Ms image, while the latter is to keep sharp edges of the high-resolution panchromatic image. We further propose to simultaneously register the two images during the fusing process, which is naturally achieved by virtue of the dynamic gradient sparsity property. An efficient algorithm is then devised to solve the optimization problem, accomplishing a linear computational complexity in the size of the output image in each iteration. We compare our method against six state-of-the-art image fusion methods on Ms image data sets from four satellites. Extensive experimental results demonstrate that the proposed method substantially outperforms the others in terms of both spatial and spectral qualities. We also show that our method can provide high-quality products from coarsely registered real-world IKONOS data sets. Finally, a MATLAB implementation is provided to facilitate future research.	algorithm;assumed;bands;computational complexity theory;convex optimization;drug vehicle;existential quantification;experiment;feature extraction;gradient;image editing;image fusion;image registration;image resolution;iteration;joints;least squares;location (geography);matlab;mathematical optimization;multispectral image;optimization problem;physical object;puromycin aminonucleoside;satellite viruses;sparse matrix;statistical classification;stemming;unified framework;variational principle;registration - actclass	Chen Chen;Yeqing Li;Wei Liu;Junzhou Huang	2015	IEEE Transactions on Image Processing	10.1109/TIP.2015.2456415	image warping;image texture;image restoration;computer vision;mathematical optimization;feature detection;image resolution;distortion;image gradient;binary image;image processing;computer science;image registration;digital image processing;image fusion	Vision	68.74398546698168	-66.53076034519253	77331
45196b551434071140f6528ffeec3c94b5e74968	microarray image denoising using a two-stage multiresolution technique	dna;gene expression profile;image resolution;multiresolution transform;two stage multiresolution technique;dna microarrays;heavy tail;molecular biophysics biomedical optical imaging dna genetics image denoising image resolution medical image processing;genetics;multiplicative noise;gene expression profiles;medical image processing;molecular biophysics;multiresolution transform microarray image denoising two stage multiresolution technique dna microarrays gene expression profiles;image denoising;biomedical optical imaging;dna microarray;microarray image denoising;noise removal;image denoising image resolution additive noise noise measurement gene expression biomedical measurements signal resolution computer science biology biotechnology	DNA microarrays have demonstrated an excellent potential in correlating specific gene expression profiles to specific conditions. However, they are affected by inherent noise. This paper presents a two-stage approach for noise removal that processes the additive and the multiplicative noise component. The proposed approach first decomposes the signal by a multiresolution transform and then accounts for both the multiscale correlation of the subband decompositions and their heavy-tailed statistics. Real microarray images have been processed by the proposed method and its improved performance is shown through quantitative measures and qualitative visual evaluation.	dna microarray;dynamic range;image noise;imaging technology;multiplicative noise;noise reduction;throughput;utility functions on indivisible goods	Hara Stefanou;Thanasis Margaritis;Dimitris Kafetzopoulos;Kostas Marias;Panagiotis Tsakalides	2007	2007 IEEE International Conference on Bioinformatics and Biomedicine (BIBM 2007)	10.1109/BIBM.2007.47	biology;computer vision;dna microarray;bioinformatics;genetics;molecular biophysics	Visualization	53.843953163883064	-77.4577513504053	77360
3d82de4e1371833d69cc9b4fedf1de895ffe5ae8	automatic color correction: region-based approach and performance evaluation using full reference metrics	image segmentation;distortion;video;cameras	This article proposes a solution to automatic color correction between two images/videos based on region correspondences. It starts with image segmentation by marker-controlled watershed transformation, which is faster and produces more uniform regions with better adherence to object boundaries than the segmentation in previous color correction approaches. Then, regions between two images are matched using point feature correspondences which are invariant to geometric transformation and illumination change. Finally, the color distorted image is corrected using the color statistics of corresponding regions and the color transfer functions weighted by influence masks. We demonstrate the experimental results using several data sets and evaluate the color correction by different measures of image similarity.	algorithm;color mapping;image quality;image segmentation;outline of television broadcasting;performance evaluation;streaming media;watershed (image processing)	Sang Ly;Serge Beucher;Michel Bilodeau;Stelian Persa;Klaas Damstra;Robert Pot;Jan Van Rooy	2015	J. Electronic Imaging	10.1117/1.JEI.24.6.061207	demosaicing;color histogram;computer vision;icc profile;color quantization;hsl and hsv;video;color normalization;color depth;color image;distortion;image gradient;binary image;computer science;mathematics;color balance;image segmentation;computer graphics (images)	Vision	58.28799894118568	-61.65135758502212	77376
d00b3aa86f0d8104a3f17ce3122379828868d85c	mini-uav borne hyperspectral remote sensing: a review		In recent years, the science of hyperspectral remote sensing has huge development in virtue of the integration of low-cost lightweight hyperspectral sensors and unmanned aerial vehicles (UAVs). As an alternative of manned aircraft, UAV has some unique advantages enabling the researchers acquire the hyperspectral images of their interest area flexibly and promptly. This review focuses on the recent developments of UAV borne hyperspectral remote sensing system, and gives an overview of the corresponding platforms, sensors, data acquisition, processing and current applications. Future challenges and research directions for UAV borne hyperspectral data are also addressed.	data acquisition;sensor;television antenna;unmanned aerial vehicle	Yanfei Zhong;Xinyu Wang;Yao Xu;Tianyi Jia;Song Cui;Ailong Ma;Liangpei Zhang	2017	2017 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)	10.1109/IGARSS.2017.8128354	artificial intelligence;computer science;computer vision;remote sensing;data acquisition;hyperspectral imaging	Embedded	77.65487060314459	-61.09241103762366	77442
8bc4ad9024f04166e305b52145339ea60a0224fb	a new quantization method for 3-d seismic visualization	bilateral filtering;quantization;histogram based quantization algorithm;edge preserving filter;3d seismic data visualization;geological structure;geology data visualization large scale systems filters clustering algorithms data engineering dynamic range frequency vector quantization acoustic noise;high dynamic range data;data visualisation;large scale;geophysics computing;geology;seismic waves;filtering algorithms;seismic visualization;seismic visualization quantization bilateral filter;data visualization;high quality visualization;histogram based quantization algorithm 3d seismic data visualization high dynamic range data high quality visualization geological structure edge preserving filter bilateral filter;low dynamic range;bilateral filter;seismic waves data visualisation geophysics computing;high dynamic range;rendering computer graphics;high frequency;algorithm design and analysis;noise	The seismic data is a kind of high dynamic range data, which is very difficult to realize high-quality visualization. In this paper, we present a new method to scale the high-dynamic-range seismic data for visualization, which can quantize the high-dynamic-range data into the low-dynamic-range data, while preserving the high frequency characteristics of the geological structure. We divide the seismic data into two parts, the large-scale geological structure part and the small-scale geological structure part. The large-scale part is obtained using an edge-preserving filter called bilateral filter. Then the small-scale part and the processed large-scale part are merged into a new seismic data. Finally, the new generated data is scaled by the histogram-based quantization algorithm to a low-dynamic-range data. In this paper, we discuss and implement our quantization algorithm, and give the results.	algorithm;bilateral filter;high dynamic range;high-dynamic-range rendering;quantization (signal processing)	Gang Hua;Hai Lin;Jinguang Sun	2009	2009 11th IEEE International Conference on Computer-Aided Design and Computer Graphics	10.1109/CADCG.2009.5246858	computer vision;computer science;theoretical computer science;bilateral filter;data visualization;computer graphics (images)	Visualization	69.33046042049186	-56.27488006311218	77459
4eef12fd81e08e0bd9ba972b4c06ced88124b287	cultural heritage management using analysis of satellite images and advanced gis techniques at east luxor, egypt and kangavar, iran (a comparison case study)		Nowadays; the new technology like remote sensing techniques play an important role in cultural heritage management. Urban and agriculture crawling have become a universal problem in the developing countries like Egypt and Iran. This study deals with the spatial characterization over three times 1963, 1984 and 2017 of the buildup and vegetation indices around two important areas; east Luxor (Egypt) and Kangavar (Iran). For the both of investigated sites, environmental changes will detect using satellite Images indices in Thematic Mapper (TM) imagery and Sentinel 2 2016 available for free charge from the USGS Earth Explorer. The past and current urban and agricultural areas have been extracted by using consolidated remote sensing and GIS techniques. Analyses and quantification of the spatial dimension of the urban expansion show for both of the study sites in a significant percentage. As a whole, outputs from our investigations will clearly highlight of the environmental monitoring, and detect the changes between the indices of the both areas to observe and quantify urban and land use changes from a global view down to a local scale to protect the archaeological areas.	geographic information system	Abdelaziz Elfadaly;Rosa Lasaponara;Beniamino Murgante;Mohamad Molaei Qelichi	2017		10.1007/978-3-319-62401-3_12	cultural heritage management;computer network;land use;comparison case;computer science;vegetation;environmental resource management;environmental monitoring;agriculture;satellite;thematic mapper	SE	81.41730251649358	-57.27631185377322	77521
eaa3d91ce979858f408f580370bebc1cbdcdeee5	a bayesian transformation model for wavelet shrinkage	transformation ondelette;bayes estimation;image restoration random noise bayes methods wavelet transforms parameter estimation image processing statistical distributions markov processes image denoising;analisis imagen;mcmc computation;speckle;chaine markov;cadena markov;metodo monte carlo;transformation model;image processing;shrinkage estimation;bayes methods;speckle noise;ruido;markov random fields;procesamiento imagen;methode monte carlo;bayesian methods additive noise contamination image processing synthetic aperture radar wavelet coefficients probability distribution markov random fields monte carlo methods computational modeling;image restoration;indexing terms;product model;traitement image;wavelet shrinkage;markov random field;image restoration bayesian transformation model wavelet shrinkage estimators additive normal noise bayesian estimators power transformations image processing widespread additive model sar imagery mixture priors wavelet coefficients markov random field priors signal denoising;additive model;wavelet transforms;random noise;estimacion bayes;statistical distributions;markov chain monte carlo;bayesian computation;monte carlo method;bruit;linear model;power transformer;image analysis;transformation models;image denoising;transformacion ondita;markov processes;stochastic model;parameter estimation;analyse image;modelo estocastico;hierarchical models;modele stochastique;hierarchical model;wavelet transformation;diagrama mancha;noise;estimation bayes;markov chain;synthetic aperture radar	Wavelet shrinkage estimators, in general, make the additive normal noise assumption and disregard the nonlinear nature of contamination. We develop Bayesian wavelet shrinkage estimators (based on the power transformations in the linear model) to accommodate a broad class of noise models in image processing applications. We intend to admit, under one roof, the widespread additive model, the product models common in imaging (such as in synthetic aperture radar (SAR) imagery), as well as noise that may exist amid these two extremes. Tactful prior elicitation in this model, such as the simultaneous assignment of mixture priors for wavelet coefficients and the transformation, imparts flexibility and ample insight into the underlying structure. The model permits estimation with unknown noise structure for reasonably unimodal and well-behaved (on the tails) distributions, wherein it can outperform common shrinkage estimators. Extensions with multiple transformations and Markov random field priors are also considered for adaptation to local variations in contamination. Modern Markov chain Monte Carlo (MCMC) Bayesian computation has been used for simulations and several examples are reported in the paper.	acclimatization;additive model;assignment (computer science);coefficient;computation;image processing;license;linear model;markov chain monte carlo;markov random field;monte carlo method;nonlinear system;simulation;synthetic data;tail;tails;utility functions on indivisible goods;wavelet;cell transformation	Shubhankar Ray;Bani K. Mallick	2003	IEEE transactions on image processing : a publication of the IEEE Signal Processing Society	10.1109/TIP.2003.819306	speckle pattern;probability distribution;speckle noise;image restoration;econometrics;markov chain;image analysis;synthetic aperture radar;index term;markov chain monte carlo;image processing;noise;stochastic modelling;linear model;pattern recognition;mathematics;markov process;additive model;estimation theory;transformer;hierarchical database model;statistics;monte carlo method;wavelet transform	Vision	61.72677281706812	-70.26621548376174	77524
a766dce016a7154776ba8bcd137ecce42d7a876e	on the detection and quantification of rfi in l1a signals provided by smos	brightness temperature;l1a signals smos mission european space agency project global monitoring soil moisture ocean salinity radiometric l band observations radio frequency interferences radiometer measurements aperture synthesis;soil hydrological techniques hydrology oceanographic techniques radiometry;data collection;aperture synthesis;microwave radiometry;radiometry;pollution measurement spline extraterrestrial measurements radiometry temperature measurement sea measurements brightness temperature;radio frequency interference;hydrology;radio frequency interference rfi aperture synthesis microwave radiometry;temperature measurement;soil;oceanographic techniques;hydrological techniques;soil moisture and ocean salinity	The SMOS mission is a European Space Agency project aimed at global monitoring of surface Soil Moisture and Ocean Salinity from radiometric L-band observations. This paper is concerned with the contamination of the data collected by SMOS by radio-frequency interferences (RFIs) which degrade the performance of the mission. RFI events are evidenced on both reference radiometer measurements and interferometric ones. It is explained why well-known standard RFI detection methods cannot be used. A specific method for the SMOS mission is presented and illustrated with data acquired during the commissioning phase.	l band;radio frequency	Eric Anterrieu	2011	IEEE Transactions on Geoscience and Remote Sensing	10.1109/TGRS.2011.2136350	meteorology;electromagnetic interference;radiometry;temperature measurement;hydrology;aperture synthesis;brightness temperature;physics;quantum mechanics;remote sensing;data collection	Visualization	81.27292724556604	-65.27768460981146	77610
e7bf2cd7f7546e12d4b7ed6a312c10193d2deade	impact of information buffering on a flexible cloud gaming system		Cloud gaming will make high quality gaming more accessible to everyone. It not only relieves users of the constant need to upgrade their hardware, but also makes it possible to enjoy high quality gaming on a variety of devices. Although cloud gaming alleviates some of the hardware constraints associated with end user devices, it does come at a cost - an array of performance issues such as increased bandwidth usage, degradation in visual quality, and higher interactive latency. In previous work, we proposed a flexible cloud gaming system that utilizes different combinations of local and remote resources that trades off different performance requirements. A 3D image warping technique is used to help reduce or even eliminate interactive latency by making use of the most recently received residual frame. However, due to occlusion effect and insufficient sampling, some of the pixels will not get the residual information needed to recover their original values. In this paper, we address this issue by applying 3D image warping to multiple recently received and buffered residual frames. Our experimental results show that the impact on visual quality can be positive or negative depending on factors such as interactive latency and base Level of Detail (LOD) models used on the client side.	client-side;cloud gaming;computation;display resolution;elegant degradation;image warping;level of detail;mathematical optimization;pixel;requirement;residual frame;sampling (signal processing)	De-Yu Chen;Magda El Zarki	2017	2017 15th Annual Workshop on Network and Systems Support for Games (NetGames)	10.1109/NetGames.2017.7991543	distributed computing;latency (engineering);simulation;end user;residual frame;real-time computing;image warping;computer science;level of detail;upgrade;server;cloud gaming	HCI	62.14595187540094	-54.513267570251365	77624
364d687f263c99fc0fa9129456b542009889e4cb	a fusion scheme for joint retrieval of urban height map and classification from high-resolution interferometric sar images	maps;teledetection;image filtering;filtering;object recognition;zona urbana;filtrage;town and country planning;urban areas classification height map markovian fusion synthetic aperture radar sar interferometry;scene architecture;high resolution;topography earth;mapa;image resolution;coherence images;information extraction;radar imaging sensors;radar antenne synthetique;efficiency;image fusion;digital surface model;low resolution;zone urbaine;interferometrie;modele numerique terrain;optical imaging sensors;image classification;srtm;contextual information;height map;spot;correction;urban 3d monitoring;shuttle radar topography mission;classification;carte;deteccion a distancia;digital terrain models;digital terrain model;corrections;town and country planning digital elevation models geophysical signal processing height measurement image classification image fusion radar imaging remote sensing by radar synthetic aperture radar topography earth;height measurement;remote sensing by radar;interferogram images;accuracy;sar interferometry;haute resolution;urban areas;precision;amplitud;dsm computation;realite terrain;amplitude images;geophysical signal processing;spot hrs;markovian framework;remote sensing;surface model;height mapping;radar imaging;sar image;edificio;earth 3d surface models;alta resolucion;efficacite;correccion;urban area;realidad terreno;digital elevation models;ground truth;interferometry;amplitude;object classification;interferometric sar images;global image classification;interferometria;interferometric sar;image retrieval image resolution radar imaging optical interferometry surface topography optical sensors urban areas synthetic aperture radar earth remote sensing;radar image resolution	The retrieval of 3-D surface models of the Earth is a major issue of remote sensing. Some nice results have already been obtained at medium resolution with optical and radar imaging sensors. For instance, missions such as the Shuttle Radar Topography Mission (SRTM) or the SPOT HRS have provided accurate digital terrain models. The computation of a digital surface model (DSM) over urban areas is the new challenging issue. Since the recent improvements in radar image resolution, synthetic aperture radar (SAR) interferometry, which had already proved its efficiency at low resolution, has provided an accurate tool for urban 3-D monitoring. However, the complexity of urban areas and high-resolution SAR images prevents the straightforward computation of an accurate DSM. In this paper, an original high-level processing chain is proposed to solve this problem, and some results on real data are discussed. The processing chain includes three main steps, namely: (1) information extraction; (2) fusion; and (3) correction. Our main contribution addresses the merging step, where we aim at retrieving both a classification and a DSM while imposing minimal constraint on the building shapes. The joint derivation of height and class enables the introduction of more contextual information. As a consequence, more flexibility toward scene architecture is possible. First, the initial images (interferogram, amplitude, and coherence images) are converted into higher-level information mapping with different approaches (filtering, object recognition, or global classification). Second, these new images are merged into a Markovian framework to jointly retrieve an improved classification and a height map. Third, DSM and classification are improved by computing layover and shadow from the estimated DSM. Comparison between shadow/layover and classification allows some corrections. This paper mainly addresses the second step, while the two others are briefly explained and referred to already published papers. The results obtained on real images are compared to ground truth and indicate a very good accuracy in spite of limited image resolution. The major limit of DSM computation remains the initial spatial and altimetric resolutions that need to be made more precise	aperture (software);computation;digital elevation model;digital geometry;ground truth;heightmap;high- and low-level;image resolution;information extraction;outline of object recognition;sensor;shuttle radar topography mission;synthetic intelligence	Celine Tison;Florence Tupin;Henri Maître	2007	IEEE Transactions on Geoscience and Remote Sensing	10.1109/TGRS.2006.887006	computer vision;image resolution;information extraction;physics;remote sensing	Vision	76.02492607702233	-59.81228915327282	77668
c639c03c7d79bfb643360aaed801fdaf44307f6e	large-eddy simulations of pedestrian-level ventilation for assessing a satellite-based approach to urban geometry generation		Abstract Realistic digital elevations of urban areas are required in urban studies but are not always available. There is a need to extract urban information from satellite images that can be used for, but not limited to, studies of the urban wind environment. This study evaluates urban geometries, including building heights and building footprints, extracted from various satellite images by large-eddy simulations for air ventilation assessment (AVA). The result shows that building heights extracted from TerraSAR-X synthetic aperture radar (SAR) images and the fused results of SAR and WorldView-2 optical (stereo) images are suitable for AVA. Better performance in representing tall buildings, rather than low buildings, is found to be more important for AVA purposes. Moreover, the performance of building geometries retrieved from fused satellite images with and without real building footprints is comparable, which suggests that building footprints extracted from stereo images are reliable.	simulation	Weiwen Wang;Yong Xu;Edward Ng	2018	Graphical Models	10.1016/j.gmod.2017.06.003	large eddy simulation;computer vision;ventilation (architecture);synthetic aperture radar;satellite;urban studies;mathematics;artificial intelligence	HCI	76.91235451984697	-59.31300155874134	77704
88f4acd2e2d699d416bc75934e86a3851527b22a	a stereo matching data cost robust to blurring	quantization;blurred stereo matching data cost;image matching;disparity;blurred;objective function;optimization problem;focus;stereo matching;pixel;stereo image processing;disparity blurring robust stereo matching focus data cost;stereo vision;matched filters;pixel robustness cameras stereo vision quantization robot vision systems matched filters;robustness;stereo image processing image matching;blurring robust;data cost;robot vision systems;cameras	Most modern stereo matching algorithms involve solving an optimization problem where the objective function includes a data cost term and a smoothness term. The data cost term measures how well corresponding pixels match between the left and right images. In this paper a new stereo matching data cost is proposed which is robust to variations in blurring between the images caused by camera focus. In our method, each image is blurred once with a large filter. By comparing the original and blurred versions of each image we obtain a range of possible values each pixel could take on for different levels of blurring. Based on this range we construct a blur robust data cost for comparing pixels between two images. Experimental results show our proposed method greatly improves stereo matching accuracy when the left and right images in a stereo pair are focused differently.	algorithm;box blur;computer stereo vision;filter (signal processing);gaussian blur;mathematical optimization;optimization problem;pixel	Colin Doutre;Panos Nasiopoulos	2010	2010 IEEE International Conference on Image Processing	10.1109/ICIP.2010.5653884	optimization problem;computer vision;quantization;computer science;stereopsis;mathematics;matched filter;pixel;robustness;focus;computer graphics (images)	Robotics	57.50941248618526	-58.11936669795469	77793
ce768c998d6e653429ec6be659c465304a41ece7	building a hyperspectral library and its incorporation into sparse unmixing for mineral identification		The objective of the SOLSA project (EU-H2020) is to develop an analytical expert system for on-line-on-mine-real-time mineralogical and geochemical analyses on sonic drill cores. As one aspect of the system, this paper presents the building of the hyperspectral library and its incorporation into sparse unmixing techniques for mineral identification. Twenty seven spectra representing 14 minerals have been collected for the library. Three sparse unmixing techniques have been investigated and evaluated using simulated data generated from our hyperspectral library, and real hyperspectral data acquired from a serpentinized harzburgite sample. Among the three techniques, the collaborative sparse unmixing by variable splitting and augmented Lagrangian (CLSUnSAL) method provided the best accurate results on the simulated data. In addition, the results of the CLSUnSAL method show high correlation with that of the QEMSCAN® analysis on the harzburgite hyperspectral data.	augmented lagrangian method;expert system;online and offline;real-time locating system;simulation;sparse matrix;variable splitting	Thanh Bui;Beate Orberger;Simon B. Blancher;Ali Mohammad-Djafari;Henry Pilliere;Anne Salaun;Xavier Bourrat;Nicolas Maubec;Thomas Lefévre;Celine Rodriguez;Antanas Vaitkus;Saulius Grazulis;Cedric Duee;Dominique Harang;Thomas Wallmach;Yassine El Mendili;Daniel Chateigner;Mike Buxton;Monique Le Guen	2018	IGARSS 2018 - 2018 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2018.8519131	computer vision;artificial intelligence;sparse matrix;hyperspectral imaging;augmented lagrangian method;computer science	Embedded	69.59671923563447	-66.08223139754317	77829
204b25a00ff0efe1119cf0339fbc04436c63e37a	averaged stokes vector based polarimetric sar data interpretation	stokes vector data interpretation polarimetric sar polsar;alos palsar data polarimetric sar data interpretation method synthetic aperture radar averaged stokes vector extracted discriminator physical interpretation layers low coherence target layer man made target layer low backscattering target layer advanced land observing satellite phased array type l band sar;synthetic aperture radar object detection radar polarimetry remote sensing by radar;vectors apertures scattering erbium matrix decomposition synthetic aperture radar image color analysis	In this paper, we propose a new polarimetric synthetic aperture radar (SAR) data interpretation method based on a locally averaged Stokes vector. We first propose a method to extract discriminators from all three components of the averaged Stokes vector. Based on the extracted discriminators, we build four physical interpretation layers with ascending priorities, i.e., the basic structure layer, the low-coherence targets layer, the man-made targets layer, and the low-backscattering targets layer. An intuitive final image can be generated by simply stacking the four layers in the priority order. We test the performance of the proposed method over Advanced Land Observing Satellite Phased Array type L-band SAR (ALOS-PALSAR) data. Experimental results show that the proposed method has high interpretation performance, particularly for skew-aligned or randomly distributed buildings and isolated man-made targets such as bridges.	aperture (software);focus stacking;l band;phased array;polarimetry;randomness;stokes parameters;synthetic data	Fang Shang;Akira Hirose	2015	IEEE Transactions on Geoscience and Remote Sensing	10.1109/TGRS.2015.2401043	early-warning radar;continuous-wave radar;synthetic aperture radar;geodesy;interferometric synthetic aperture radar;optics;radar imaging;inverse synthetic aperture radar;side looking airborne radar;remote sensing	EDA	72.92268256412855	-62.92046642612091	77923
48e49306613130e8bb57fdfd1698900a8c77ac51	using spot 5 high spatial resolution image to detect vegetation patches at gudong oil field	geophysical image processing;vegetation mapping;vegetation mapping geophysical image processing;mathematical morphology;vegetation patch;vegetation community patch;gudong oil field;spatial structure;china vegetation community patch vegetation function structure researches spot 5 high spatial resolution fusion image mathematical morphology circle object ellipse object spatial structure models gudong oil field;structure researches;detecting spot 5 vegetation patch gudong oil filed;spot 5;morphology;circle object;shape;spatial structure models;spot 5 high spatial resolution fusion image;remote sensing;satellites;vegetation function;vegetation mapping communities remote sensing spatial resolution shape morphology satellites;detecting;communities;china;ellipse object;gudong oil filed;high spatial resolution;spatial resolution	Numbers and areas and locations of vegetation community patch are the important parameters for vegetation function and structure researches. In this paper, vegetation community patches are extracted using SPOT 5 high spatial resolution fusion image based on mathematical morphology. Firstly, vegetation is extracted according to the scatter plot between B3 and B2. Then vegetation community patches are detected based on the criterion of circle and ellipse object. And the centers of the patches are located. Finally, two types of the spatial structure models of vegetation communities are outlined. The experiments at Gudong oil field show that the algorithms for extracting circle and ellipse object based on mathematical morphology are simple and effective for detecting vegetation community patch.	algorithm;experiment;mathematical morphology;object-based language;sensor;unofficial patch	Qingsheng Liu;Gaohuan Liu;Chong Huang;Chuanjie Xie	2011	2011 Seventh International Conference on Natural Computation	10.1109/ICNC.2011.6022600	geography;ecology;remote sensing	Robotics	76.31415041954884	-58.182953808058016	77942
e83ebed49722ea29807d63040550b7d53ba9d10d	multiple radar time series similarity matching algorithm	similarity modal;sbmdtsm algorithm;spatial data;distance measure;time measurement;meteorological radar;multiple time series;internal structure;modal algrothm;euclidean distance;time series;matrix algebra;distance measurement;time series analysis;three dimension time series;modal algrothm multiple radar time series similarity matching euclidean distance spatial position three dimension time series radar sequence distance measurement;radar distance measurement matrix algebra modal analysis;radar sequence;multiple radar time series similarity matching;radar measurements radar applications time measurement meteorological radar software algorithms shape measurement computer science education systems engineering education educational institutions geoscience;modal analysis;sbmdtsm algorithm meteorological radar multiple time series distance measure similarity modal;radar measurements;similarity measure;algorithm design and analysis;radar;matching method;spatial position	The paper provide a new algorithm for multiple radar time series similarity matcing. The main difficulty for multiple radar time series similarity matching lies in huge data amount and too many factors will be considered. So, the previous algorithm on this area has existance of false dismissals and false alarms. The traditional methods mostly based on Euclidean distance and pay little attention to the influence of amplitude change, frequency persistence and internal structure of sequence. The matching method held out in the paper firstly devided the radar spatial data into certatin segments based on its' spatial position. Then, the mutidemession time series in each data segments can maped to a time interval with certain length. The step can transform multiple radar time series to three-demession time series and greatly reduce the complexity of algorithm. In order to improve the accuracy of the method, some weighted factor with consideration of amplitude change, frequency persistence and internal structure of radar sequence is carried out to define an accuracy distance measure for two sequences. With the predefined distance measure, a multiple radar time series similarity measure modal and an algrothm for similarity matching is discussed in detail. At the end of the paper, the method in the paper is applied in actually radar observed data and proved its better performance.	algorithm;euclidean distance;modal logic;persistence (computer science);radar;similarity measure;time series	Xuejun Chen;Jijun Li;Xiaoyun Chen	2008	2008 International Conference on Computer Science and Software Engineering	10.1109/CSSE.2008.1145	speech recognition;machine learning;time series;mathematics;statistics	DB	76.54739356205393	-69.04049254410337	77961
c1318f3cb939774c3a0fde4426c624c32d480486	4d light field superpixel and segmentation		Superpixel segmentation of 2D image has been widely used in many computer vision tasks. However, limited to the Gaussian imaging principle, there is not a thorough segmentation solution to the ambiguity in defocus and occlusion boundary areas. In this paper, we consider the essential element of image pixel, i.e., rays in the light space and propose light field superpixel (LFSP) segmentation to eliminate the ambiguity. The LFSP is first defined mathematically and then a refocus-invariant metric named LFSP self-similarity is proposed to evaluate the segmentation performance. By building a clique system containing 80 neighbors in light field, a robust refocus-invariant LFSP segmentation algorithm is developed. Experimental results on both synthetic and real light field datasets demonstrate the advantages over the state-of-the-arts in terms of traditional evaluation metrics. Additionally the LFSP self-similarity evaluation under different light field refocus levels shows the refocus-invariance of the proposed algorithm.	algorithm;angularjs;apple maps;binocular disparity;computer vision;lambertian reflectance;light field;pixel;self-similarity;synthetic intelligence	Hao Zhu;Qi Zhang;Qing Wang	2017	2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)	10.1109/CVPR.2017.710	computer vision;pattern recognition;pixel;computer science;ambiguity;artificial intelligence;image segmentation;scale-space segmentation;light field;segmentation-based object categorization;segmentation	Vision	55.95224930131832	-57.475039094172146	78055
838144786392be7573b6dbeb003f926ff8507ac0	a robust method for the extraction of instantaneous attributes from seismic data	hilbert transforms;hilbert transform instantaneous attributes extraction seismic data wavelet domain generalized morse wavelets;wavelet analysis wavelet transforms noise estimation noise measurement wavelet domain;seismology;instantaneous attributes;wavelet transforms;hilbert transform;the gmws;geophysical signal processing;feature extraction;wavelet transforms feature extraction geophysical signal processing hilbert transforms seismology;cwt;the gmws instantaneous attributes hilbert transform cwt	In this paper, a robust method for the extraction of instantaneous attributes is proposed in wavelet domain. A new class of analytic wavelets, the Generalized Morse Wavelets (GMWs), which have some desirable properties, are applied during the procedure of the proposed method. Compared to the conventional method based on Hilbert transform (HT), the new method is proved to yield higher precision and better anti-noise performance. Experimental results on synthetic signals and real seismic data show the validity of the method.	hilbert transform;synthetic intelligence;wavelet	Ping Wang;Jinghuai Gao	2012	2012 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2012.6350370	wavelet;mathematical optimization;mathematical analysis;harmonic wavelet transform;hundredweight;hilbert transform;second-generation wavelet transform;continuous wavelet transform;feature extraction;hilbert–huang transform;pattern recognition;mathematics;wavelet packet decomposition;stationary wavelet transform;discrete wavelet transform;lifting scheme;hilbert spectral analysis;wavelet transform	Robotics	65.88364875549738	-68.64852474990481	78062
ae262718dde485fd625bd63f19d5f55f41da6ab6	objective quality measures comparison of impaired 3d video sequences from the uc3d database	video databases correlation theory image sequences image texture quality of service;three dimensional displays quality assessment correlation video recording video sequences visualization databases;3d video sequences objective quality measures subjective scores correlation;dmos score objective quality measure impaired 3d video sequences uc3d database correlation analysis video quality measure image quality measure subjective score computation 3d texture depth video sequences university of coimbra 3d quality metrics depth information ssim psnr view synthesis	In this study we analyze the correlation between different image and video quality measures and corresponding subjective scores computed on 20 3D texture+depth video sequences from the University of Coimbra 3D (UC3D) video database. Quality metrics were tested on (degraded) depth information and synthesized views. The results show that in the case of measures based on depth information, the best correlation is achieved by SSIM. For the case of measures computed on the synthesized view, the highest correlation is obtained when using PSNR. Overall results show that quality measures computed on the synthesized view correlate better with subjective (DMOS) scores than measures based on the depth information.	information theory;peak signal-to-noise ratio;structural similarity	Emil Dumic;Sonja Grgic;Luís Alberto da Silva Cruz;Pedro A. Amado Assunção	2014	2014 3DTV-Conference: The True Vision - Capture, Transmission and Display of 3D Video (3DTV-CON)	10.1109/3DTV.2014.6874728	subjective video quality;computer vision;computer science;video quality;data mining;multimedia;pevq	Vision	62.96180596104971	-63.980930568141105	78079
24812b6a5c17b55be9dc416cffac3f552e7b3ba5	interactive point spread function simulation with diffraction and interference effects		Interactive simulation of point spread functions is an invaluable tool for evaluating optical designs. We present an interactive method for simulating the point spread function for designs that require diffraction and interference effects. These effects occure when the design contains apertures whose size approaches the wavelength of light, typically in the form of gratings or masks. Traditional ray-based techniques are not suitable here, whereas wave-based methods are not immediately amenable to an efficient implementation due to their complexity. We propose a method based on the Wigner Distribution function. This function models wave optics at gratings, but does so in a ray-based framework. This enables us to simulate diffraction and interference effects efficiently, even for multiple gratings. The resulting computation is in the order of a fraction of a second, thereby enabling the user to interactively manipulate the optical configuration or the projection plane. The proposed method can be scaled down in precision in order to achieve real-time performance.	computation;data compression;interactive media;interactivity;interference (communication);monte carlo method;projection plane;real-time clock;sampling (signal processing);simulation;surround sound;tom;variable shadowing;wigner distribution function;wigner quasiprobability distribution	Tom Cuypers;Tom Mertens;Philippe Bekaert;Se Baek Oh;Ramesh Raskar	2011			human–computer interaction;point spread function;electronic engineering;interference (wave propagation);diffraction;computer science	Graphics	62.96557415299649	-52.93978716988492	78099
e7b1bc98b8a0f19b9319baa088539d579df7dcaa	multi-look in glrt-based detection of single and double persistent scatterers		Persistent scatterer (PS) interferometry and more recently synthetic aperture radar tomography have shown to be powerful tools in urban scenarios for providing 3-D point clouds in the reconstruction of buildings as well as in the monitoring of their possible slow temporal deformations. The detection of PSs represents a fundamental aspect, which in the literature has been mainly addressed at full resolution (single-look detection), thus considering only the scatterer coherence properties along the different acquisitions. In this paper, we investigate the benefits offered by the usage of multiple observation looks. Multi-look generalized likelihood ratio test detection schemes are derived and analyzed in terms of detection performances. The analysis shows that even a slight multi-look can provide a dramatic improvement on the detection capability both on simulated and real data, especially in the areas characterized by a low signal-to-noise ratio and in the presence of a limited number of acquisitions.	cache coherence;coherence (physics);data model;exptime;expectation–maximization algorithm;long-running transaction;performance;pixel;point cloud;principal component analysis;sensor;signal-to-noise ratio;simulation;synthetic intelligence;tomography	Antonio Pauciullo;Diego Reale;Walter Franz&#x00E9;;Gianfranco Fornaro	2018	IEEE Transactions on Geoscience and Remote Sensing	10.1109/TGRS.2018.2809538	computer vision;point cloud;artificial intelligence;tomography;mathematics;likelihood-ratio test;synthetic aperture radar;detector;image resolution;interferometry;coherence (physics)	Vision	73.92437995730451	-65.16326124434593	78115
2d73656287957a1a88d69f23ca04ecbec634dce5	salt and pepper noise removal in surveillance video based on low-rank matrix recovery	multimedia computing noise cancellation signal denoising sparse matrices video signal processing video surveillance	This paper proposes a new algorithm based on low-rank matrix recovery to remove salt & pepper noise from surveillance video. Unlike single image denoising techniques, noise removal from video sequences aims to utilize both temporal and spatial information. By grouping neighboring frames based on similarities of the whole images in the temporal domain, we formulate the problem of removing salt & pepper noise from a video tracking sequence as a low-rank matrix recovery problem. The resulting nuclear norm and L1-norm related minimization problems can be efficiently solved by many recently developed methods. To determine the low-rank matrix, we use an averaging method based on other similar images. Our method can not only remove noise but also preserve edges and details. The performance of our proposed approach compares favorably to that of existing algorithms and gives better PSNR and SSIM results.	algorithm;autostereogram;closed-circuit television;experiment;image noise;noise reduction;peak signal-to-noise ratio;salt (cryptography);salt-and-pepper noise;structural similarity;taxicab geometry;video denoising;video tracking	Yongxia Zhang;Yi Liu;Xuemei Li;Caiming Zhang	2015	Computational Visual Media	10.1007/s41095-015-0005-5	computer vision;simulation;speech recognition;computer science;video denoising	Vision	57.616052277953244	-71.07142066019317	78137
813a2222bf7f1febb32eba1847703c6926fe57f7	estimation of multiple fiber orientations using nonconvex regularized spherical deconvolution		In diffusion magnetic resonance imaging, the fiber tractography generally desires the estimation of intravoxel multiple fiber orientations (MFOs) with high accuracy and reliability. In general, spherical deconvolution (SD) based methods have many advantages for MFOs estimation. However, these methods are lowly immune to noise. To cope with this problem, regularization techniques were introduced in SD-based methods to reduce noise artifacts. But, the regularizers were often defined as a convex function to make the model resolving simpler, which limits their effect of regularization. In this work, we introduce a nonconvex regularizer in the Richardson-Lucy based SD framework for estimating MFOs. The results on synthetic phantom and physical phantom images demonstrate that the proposed method is superior to existing SD-based methods in terms of mean angular errors, edge preservation and computation time.	angularjs;computation;convex function;deconvolution;dreamwidth;image noise;imaging phantom;matrix regularization;rl (complexity);resonance;richardson number;secure digital;synthetic data;synthetic intelligence;time complexity;voxel	Chunyu Chu;Zi-Xiang Kuai;Yue Min Zhu	2017	2017 10th International Congress on Image and Signal Processing, BioMedical Engineering and Informatics (CISP-BMEI)	10.1109/CISP-BMEI.2017.8302190	computer vision;artificial intelligence;imaging phantom;deconvolution;regularization (mathematics);stress (mechanics);computer science;convex function;image resolution;tractography;signal-to-noise ratio	Vision	56.76655344592067	-73.77776088745284	78153
397bc0052162fc9aba6f5dd584884a82265a72aa	hyperspectral image spatial super-resolution via 3d full convolutional neural network		Hyperspectral images are well-known for their fine spectral resolution to discriminate different materials. However, their spatial resolution is relatively low due to the trade-off in imaging sensor technologies, resulting in limitations in their applications. Inspired by recent achievements in convolutional neural network (CNN) based super-resolution (SR) for natural images, a novel three-dimensional full CNN (3D-FCNN) is constructed for spatial SR of hyperspectral images in this paper. Specifically, 3D convolution is used to exploit both the spatial context of neighboring pixels and spectral correlation of neighboring bands, such that spectral distortion when directly applying traditional CNN based SR algorithms to hyperspectral images in band-wise manners is alleviated. Furthermore, a sensor-specific mode is designed for the proposed 3D-FCNN such that none of the samples from the target scene are required for training. Fine-tuning by a small number of training samples from the target scene can further improve the performance of such a sensor-specific method. Extensive experimental results on four benchmark datasets from two well-known hyperspectral sensors, namely hyperspectral digital imagery collection experiment (HYDICE) and reflective optics system imaging spectrometer (ROSIS) sensors, demonstrate that our proposed 3D-FCNN outperforms several existing SR methods by ensuring higher quality both in reconstruction and spectral fidelity.	algorithm;artificial neural network;benchmark (computing);convolution;convolutional neural network;distortion;end-to-end principle;horizontal situation indicator;image sensor;pixel;super-resolution imaging	Shaohui Mei;Xin Yuan;Jingyu Ji;Yifan Zhang;Shuai Wan;Qian Du	2017	Remote Sensing	10.3390/rs9111139	artificial intelligence;geology;computer vision;convolutional neural network;remote sensing;image sensor;deep learning;full spectral imaging;small number;hyperspectral imaging;imaging spectrometer;image resolution	Vision	67.86666490410381	-65.37560130711847	78182
134cc2094465096ee777dd6e2c74597df9735323	wood variety recognition on mobile devices		The traditional method of identifying wood species involves manual browsing through digital wooden veneer catalogues and making a subjective judgement. This is labour intensive, and concentration problems can lead to errors. Additionally, gradual changes and changing shades due to variable light conditions are difficult for humans to detect. As an alternative, we aimed to develop an application to identify wood species using a smartphone camera, which returns the resulting species name and a corresponding high quality database wood specimen image. This computer-aided wood identification system retrieves a wood template from a digital wood database, selecting that which most closely resembles the query sample.	biological specimen;display resolution;smartphone	Pavel Vácha;Michal Haindl	2013	ERCIM News		computer engineering;computer security;mobile device;computer science	HCI	70.81880834341929	-55.9530104017946	78211
7941c752c23823abac1d7b2e179e4837f3f50698	hierarchical pixel clustering for image segmentation		The paper focuses on the domain of image segmentation by optimal approximations that minimally differ from the image of N pixels in the standard deviation  or total squared error 2  N E  . Although related approaches, namely Otsu methods [1, 2], K-means method [3] and Mumford-Shah model [4–7] have a long history, the opportunities of minimizing of the total squared error E are far from being exhausted, especially, in the task of multiple optimization for each number of pixel clusters or, in particular, connected image segments. In this task Otsu's multi-thresholding [2] provides an accurate but incomplete solution for clustering of pixels. Mumford-Shah model [4–7] provides a complete sequence of image partitions into each number of segments, but minimizing effect is poor. K-means method for image segmentation is too heuristic to provide any of mentioned two requirements, but it can be advanced for application in conjunction with Otsu method and Mumford-Shah model [8]. To solve the task of multiple optimization without any difficulties we use a special data structure of Sleator-Tarjan dynamic trees [9] that essentially optimizes the computing, but does not affect the obvious meaning of algorithms. Therefore, to avoid the cumbersome details of implementation, here we address rather to motivation of solutions and do not dwell on the software that supports the fast generation, storing in the available RAM and effective transformations of pixel clusters in a computer memory. To substantiate the study of segmentation results without appealing to the subsequent detection of a priori specified objects, we have calculated the optimal and nearly optimal approximations for the simplest examples of real images [10]. These proved important for the formulation of the problem caused by two challenges.	algorithm;approximation;cluster analysis;computer memory;data structure;experiment;handy board;heuristic;image segmentation;k-means clustering;link/cut tree;mathematical optimization;otsu's method;pixel;random-access memory;requirement;thresholding (image processing)	Mikhail V. Kharinov	2014	CoRR		computer vision;mathematical optimization;range segmentation;morphological gradient;segmentation-based object categorization;pattern recognition;mathematics;image segmentation;pixel connectivity;scale-space segmentation	ML	65.73165308956717	-55.34695834087558	78228
853f5af8d5d0f83751be37702e0a6af6841b044a	simple imaging system to measure velocity and improve the quality of fertilizer spreading in agriculture	image processing;particles;imaging system;image acquisition;hough transforms;agriculture;imaging systems	The management of mineral fertilization using centrifugal spreaders requires the development of spread pattern characterization devices to improve the quality of fertilizer spreading. In order to predict the spread pattern deposition using a ballistic flight model, several parameters need to be determined and especially the velocity of the granules when they leave the spinning disc. This paper demonstrates that a motion blurred image acquired in the vicinity of the disc with a low cost imaging system can provide the three dimensional components of the outlet velocity of the particles. A binary image is first obtained using a recursive linear filter. Then an original method based on the Hough transform is developed to identify the particle trajectories and to measure their horizontal outlet angles, not only in the case of horizontal motion but also in the case of three dimensional motion. The method combines a geometric approach and mechanical knowledge derived from spreading analysis. The outlet velocities are deduced from the outlet angle measurements using kinematic relationships. Experimental results provide first validations for the technique.	angularjs;binary image;centrifugal governor;computation;concave function;geometric analysis;heat spreader;hough transform;lagrangian and eulerian specification of the flow field;on-board data handling;physical vapor deposition;recursion;sensor;time complexity;uncontrolled format string;velocity (software development)	Sylvain Villette;Frédéric Cointault;Emmanuel Piron;Bernard Chopinet;Michel Paindavoine	2008	J. Electronic Imaging	10.1117/1.2956835	computer vision;agriculture;image processing;computer science	Robotics	72.6160913358802	-57.74320218280671	78367
6de831d0e8115d8f9be3a925e24582eeb73ae3c7	ink relocation for color halftones		In this section we formulate the color design criterion in more concrete terms. To this end we analyze it in a special case of rendering large patches of arbitrary solid colors. Given a color in the RGB cube, it may be rendered using the 8 basic colors located at the vertices of the R G B cube. Actually, any particular color may be rendered using no more than 4 colors (in a linear color space, any colorquadruple whose convex hull contains the desired color will do). The issue raised in this section is: Suppose we want to print a patch of solid color, what halftones should we use? This question has been raised before (see for example [3], [4], [5], and [7]), though mainly as an example of how bad things can be (e.g. specifying halftones that are not appropriate for some colors). The following criterion gives this question a full answer. Consider the basic rationale of halftoning: When presented with high frequency patterns, the human visual system ÒappliesÓ a low-pass filter and perceives only their average. Current inkjet printing resolution can still be resolved by the human visual system, thus still higher resolutions might have to be achieved. Relevant to the problem at hand is the fact that the human visual system is more sensitive to changes in brightness than to changes in the chrominance, which average at much lower frequencies. Thus we arrive at the following formulation of the third criterion:	color space;convex hull;design rationale;eisenstein's criterion;human visual system model;low-pass filter;printing;relocation (computing)	Doron Shaked;Nur Arad;Andrew Fitzhugh;Irwin Sobel	1998			visual arts;computer vision;art;computer graphics (images)	Robotics	61.34184843070274	-59.84989618700246	78384
ebf06f67c2edd2f1ff312b7d11345f783aa74f9c	speckle reduction of sar images in the curvelet domain	speckle reduction;discrete wavelet transforms;speckle;radar remote sensing;computed tomography;subband images;chaos;additive noise;threshold;transforms geophysical signal processing geophysical techniques terrain mapping speckle remote sensing by radar synthetic aperture radar radar imaging;curvelet domain;geophysical measurement technique;hard thresholding;wavelet transforms;remote sensing by radar;threshold geophysical measurement technique land surface terrain mapping radar remote sensing radar imaging speckle reduction sar synthetic aperture radar curvelet domain curvelet transform sar images subband images thresholding subband image coefficients hard thresholding soft thresholding denoising;sar;sar images;curvelet transform;geophysical signal processing;noise reduction;radar imaging;sar image;transforms;speckle noise reduction wavelet transforms discrete wavelet transforms continuous wavelet transforms computed tomography additive noise wavelet coefficients wavelet domain chaos;soft thresholding;land surface;thresholding;terrain mapping;denoising;wavelet domain;subband image coefficients;wavelet coefficients;geophysical techniques;continuous wavelet transforms;synthetic aperture radar	Curvelet transform (CT), proposed by E. Candes et al. (1999), is used for speckle reduction of SAR images. The CT is useful for speckle reduction through its subband images and the speckle reduction is obtained by thresholding the subband-image coefficients of the digitized SAR images. Two thresholding methods are used; hard thresholding and soft thresholding. The denoising method shows great promise for speckle removal and hence provides good detection performance for SAR based recognition.	curvelet	Magnus Orn Ulfarsson;Johannes R. Sveinsson;Jon Atli Benediktsson	2002		10.1109/IGARSS.2002.1025025	speckle noise;computer vision;computer science;noise reduction;thresholding;optics;computed tomography;remote sensing	Vision	66.19111198672078	-65.56042901101448	78401
9a05050a19505949bf0ccdee76f4396cfa51f760	smos brightness temperature measurements and end-to-end calibration	brightness temperature;antenna measurement;antenna measurements;aperture synthesis;microwave imaging;temperature measurement calibration microwave imaging radiometers remote sensing;system performance;receivers;radiometry;remote sensing;conference report;interferometer;calibration temperature measurement extraterrestrial measurements radiometry brightness temperature receivers antenna measurements;smos;radiometer;radiometric accuracy smos brightness temperature measurement soil moisture and ocean salinity european space agency esa miras microwave imaging radiometer aperture synthesis complex multistep calibration procedure pre flight ground testing commissioning phase activity radiometric sensitivity;temperature measurement;extraterrestrial measurements;calibration;radiometers;soil moisture and ocean salinity;calibration remote sensing smos radiometer interferometer	SMOS is the acronym for the Soil Moisture and Ocean Salinity mission by the European Space Agency (ESA) [1]. Its single payload, the Microwave Imaging Radiometer using Aperture Synthesis (MIRAS), was launched in November 2009. After a six months Commissioning Phase SMOS entered in operational mode in May 2010. Since then SMOS has been delivering a large amount of data to successfully produce the first relevant scientific results. In order to provide accurate measurements, MIRAS requires a complex multi-step calibration procedure that was successfully tested both during pre-flight ground tests and Commissioning Phase activities. Additionally, an assessment of SMOS system performance in terms of short and long term stability, radiometric sensitivity and radiometric accuracy was also produced. In this context, this work is devoted to provide a high level overview of MIRAS calibration scheme by focusing on the rationale behind it. 1	design rationale;esa;end-to-end principle;high-level programming language;microwave imaging radiometer with aperture synthesis	Francesc Torres;Ignasi Corbella;Nuria Duffo;Manuel Martín-Neira	2011	2011 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2011.6049974	meteorology;hydrology;radiometer;computer performance;optics;physics;remote sensing	Embedded	81.06401994710419	-64.13262484179333	78487
815a21e536f71e4894277eaa94146fe1cc6cf9d1	hyperspectral unmixing using secant function optimization		In this paper a new spectral unmixing method for hyperspectral images is introduced. In this method, the unmixing problem is modeled as an optimization problem and the objective function is selected based on the secant function. The secant error between the original hyperspectral images, and the multiplication of endmember and abundance fraction matrices is minimized. In fact, it is found that the secant function can efficiently reduce the spectral distortion. The proposed algorithm is applied to synthetic and real datasets and compared with some state-of-the-art unmixing algorithms. The obtained results show that the proposed method successfully estimates the abundance fraction maps.	algorithm;distortion;map;mathematical optimization;optimization problem;secant method;synthetic intelligence	Elnaz Sharifi;Azam Karami	2018	IGARSS 2018 - 2018 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2018.8517508	endmember;computer vision;matrix (mathematics);multiplication;hyperspectral imaging;artificial intelligence;mathematical optimization;distortion;linear programming;computer science;optimization problem	Vision	69.18416468439001	-66.70414742199996	78548
8e370a58ed207f92a3df300d81f8d113ef93d166	maintaining data records: practical decisions required for data set prioritization, preservation, and access	distributed active archive center;nasa distributed active archive centers;scientific maturity;level of service;satellite data;preservation maturity;data records maintenance;satellite based remote sensing;information retrieval;data set prioritization;societal impact;resource management;data management;level of service categorization;records management;data preservation;remote sensing data;remote sensing;satellites;science communication;national snow and ice data center;data access;distributed databases;nasa satellites earth observing system resource management data systems environmental management councils production documentation calibration;production;councils;data systems;book reviews;scientific information systems information retrieval records management remote sensing;satellite data management;communities;maturity index;earth observing system;nasa;environmental management;nasa earth observing system;meteorology;cost management;level of service categorization data records maintenance data set prioritization data preservation data access nasa earth observing system satellite based remote sensing nasa distributed active archive centers national snow and ice data center maturity index scientific maturity preservation maturity societal impact;calibration;ice;data archive prioritization satellite data management;scientific information systems;documentation;data archive;data archive prioritization	The NASA Earth Observing System (EOS) has collected an unprecedented volume of satellite-based remote sensing data. The current suite of sensors is maturing and the data sets derived from these sensors are slowly being integrated into science research programs. As NASA moves on to new missions and other funding priorities, it is likely that the funding to maintain these data in a highly interactive data system will decrease. The challenge to the NASA Distributed Active Archive Centers (DAAC) in general and to the National Snow and Ice Data Center (NSIDC) DAAC in particular is to prioritize holdings, delegating lower priority data sets to lower cost management systems and perhaps lower levels of service. In order to address these data prioritization requirements, the NSIDC DAAC is experimenting with data maturity and levels of service scaling systems, thus permitting discussion of data set importance to our users in a more quantitative and less subjective manner. The Maturity Index (MI) is divided into three categories: scientific maturity, preservation maturity, and societal impact. In both the MI and Level of Service (LOS) categorizations, attempts are made convert descriptive categories into ordinal scales, with a resultant score for each data set. If this system proves successful, it could offer data managers a mechanism to assess data set value and defend high value data sets to the science community and federal funding agencies.	archive;capability maturity model;categorization;data center;data system;eos;experiment;image scaling;level of measurement;requirement;resultant;sensor	Ronald L. S. Weaver;Walter N. Meier;Ruth E. Duerr	2008	IGARSS 2008 - 2008 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2008.4779423	meteorology;data access;science communication;calibration;data management;documentation;computer science;resource management;data mining;database;national snow and ice data center;level of service;physics;remote sensing	HPC	80.9691787001958	-60.37655083038805	78561
f210305df38dae39bb73d0796f0cde92c3315d96	a stratospheric balloon gnss-r experiment: the 3cat-2 project in dlr/snsb bexus	gnss ro;stratospheric balloon gnss r experiment international space station geros iss radio occultation global navigation satellite systems reflectometry pycaro esa earth reflected gnss signals european space agency bexus programme rexus programme spacecraft development stratospheric flights spatiotemporal evolution mesoscale phenomena earth environment cubesat concept gnss reflectometry barcelonatech remote sensing laboratory snsb bexus dlr bexus 3 cat 2 project;cubesat;gnss r;gnss ro cubesat ocean altimetry biomass soil moisture gnss r;ocean altimetry;global positioning system satellites oceans reflectometry radar measurements spaceborne radar altimetry;biomass;soil moisture;stratosphere atmospheric techniques balloons reflectometry remote sensing satellite navigation spatiotemporal phenomena;conference lecture	Universitat Politècnica de Catalunya (UPC) - BarcelonaTech Remote Sensing Laboratory focus on the development of breakthrough concepts. The 3Cat-2 mission is on the synergy of GNSS reflectometry and the CubeSat concept. Scientifically valuable mission data will improve our understanding on the Earth's environment. In particular, ocean currents need further investigation because of the spatio-temporal evolution of the mesoscale phenomena. The spacecraft development work includes two stratospheric flights in the frame of the REXUS/BEXUS programme coordinated by the European Space Agency (ESA). Coherent and incoherent scattering of Earth-reflected GNSS signals as sensed by the P(Y) & C/A ReflectOmeter (PYCARO) payload will be evaluated using the main state-of-the art Global Navigation Satellite Systems Reflectometry (GNSS-R) methodologies. Future spaceborne activities could take advantage of it, including the GNSS REflectometry, Radio Occultation and Scatterometry on-board International Space Station (GEROS-ISS) experiment.	assembly language;coherent;dynamic language runtime;esa;fm broadcasting;gnss reflectometry;galileo (satellite navigation);on-board data handling;radio occultation;satellite navigation;synergy;time-domain reflectometer;universal product code	Hugo Carreno-Luengo;Adriano Camps;Jorge Querol;Giuseppe Forte;Raul Onrubia Ibáñez;Raul Diez	2014	2014 IEEE Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2014.6947268	meteorology;atmospheric sciences;water content;biomass;remote sensing	Robotics	80.02264554574225	-64.21646225428894	78592
ad8a8e24adac4090f7842d1fc4296a5a95f2f209	improved detection and tracking of dynamic signals by bayes-markov techniques	probability density;cross correlation;meteorological radar;radar tracking;bayesian methods;computational modeling;doppler radar;computer simulation radar tracking bayesian methods computational modeling signal to noise ratio motion detection target tracking doppler radar meteorological radar sonar;target tracking;signal to noise ratio;computer simulation;motion detection;sonar	A recursive Bayesian technique is developed which computes the a posteriori probability density of the location of a dynamic signal in successive sets of low signal-to-noise ratio data. This serves to enhance the detection and tracking of signals which may be undetectable in an individual data frame and, because of unknown target motion between data frames, it may not generally be possible by conventional techniques to integrate the successive data for signal-to-noise enhancement. Computer simulation examples are presented to demonstrate the performance of the Bayesian-Markov technique on simulated low SNR range-doppler amplitude data obtained in a pulse-doppler radar system and on simulated cross-ambiguity surface data obtained by cross correlating the data received at two spatially separated sonar arrays.	markov chain	Amin G. Jaffer;Ryan L. Stoutenborough;William B. Green	1983		10.1109/ICASSP.1983.1172104	computer simulation;computer vision;continuous-wave radar;pulse compression;probability density function;radar tracker;radar engineering details;radar lock-on;bayesian probability;space-time adaptive processing;computer science;bistatic radar;cross-correlation;low probability of intercept radar;pulse-doppler radar;mathematics;radar imaging;signal-to-noise ratio;computational model;sonar;statistics	DB	74.07409892386904	-67.70882806893147	78623
28c45fe95e4a8d3fb74693bddd2f297efb94436f	the go4 model in near-nadir microwave scattering from the sea surface	sea surface surface waves approximation methods optical surface waves radar scattering wind speed;total sea surface mss go4 model near nadir microwave scattering filtered mean square slope geometrical optics model diffraction correction effective mean square curvature surface wavenumber spectrum function radar frequency physical optics model frequency bands incidence bands classical sea spectrum model nongaussian effects relative radar cross sections;remote sensing geometrical optics ocean waves oceanographic techniques;optical surface waves;scattering;sea surface;wind speed;near nadir;slope;ocean radar sensing;curvature;approximation methods;surface waves;slope curvature geometrical optics near nadir ocean radar sensing;radar;geometrical optics	We introduce a practical and accurate model, referred to as “GO4,” to describe near-nadir microwave scattering from the sea surface, and at the same time, we address the issue of the filtered mean square slope (mss) conventionally used in the geometrical optics model. GO4 is a simple correction of this last model, taking into account the diffraction correction induced by the rough surface through what we call an effective mean square curvature (msc). We evaluate the effective msc as a function of the surface wavenumber spectrum and the radar frequency and show that GO4 reaches the same accuracy as the physical optics model in a wide range of incidence and frequency bands with the sole knowledge of the mss and msc parameters. The key point is that the mss entering in GO4 is not the filtered but the total slope. We provide estimation of the effective msc on the basis of classical sea spectrum models. We also evaluate the effective msc from near-nadir satellite data in various bands and show that it is consistent with model predictions. Non-Gaussian effects are discussed and shown to be incorporated in the effective msc. We give some applications of the method, namely, the estimation of the total sea surface mss and the recalibration of relative radar cross sections.	cross section (geometry);frequency band;gaussian blur;heuristic;incidence matrix;ka band;ku band;mean squared error;microwave;radar;spectral method	Olivier Boisot;Frédéric Nouguier;Bertrand Chapron;Charles-Antoine Guérin	2015	IEEE Transactions on Geoscience and Remote Sensing	10.1109/TGRS.2015.2424714	wind speed;meteorology;geometrical optics;geodesy;surface wave;curvature;optics;scattering;physics;radar;slope;remote sensing	Visualization	82.45186870288929	-66.78829624494459	78668
962201ccdcb6854fdccf1a3596d709458452998d	an adaptive filter for aeromagnetic compensation based on wavelet multiresolution analysis	aeromagnetic compensation proposed adaptive filter effectiveness aircraft maneuver frequency characteristics linear equation system mallat algorithms preprocessing step data filtering coefficient estimating methods tolles lawson model wavelet multiresolution analysis;aircraft mathematical model interference multiresolution analysis frequency domain analysis adaptation models;frequency domain analysis;interference;wavelet multiresolution analysis adaptive filtering aeromagnetic compensation multicolinearity;mathematical model;magnetometers geophysical techniques interface magnetism;adaptation models;multiresolution analysis;aircraft	In aeromagnetic compensation, the multicolinearity of the Tolles-Lawson model is one of the main factors limiting the performance of the coefficient-estimating methods. Aside from the intrinsic characteristic of the Tolles-Lawson model, data filtering as a preprocessing step in estimating the coefficients has a significant impact on the multicolinearity. To solve this problem, an adaptive filter based on wavelet multiresolution analysis is proposed. By modifying the wavelet decomposition results of the Mallat algorithms and reconstructing the signal, the adaptive filter can be used to establish a system of linear equations not only by capturing the frequency characteristics of the aircraft maneuvers as is usual but also by having a weakened multicolinearity. Simulation results illustrate the effectiveness of the proposed adaptive filter.	adaptive filter;algorithm;bandlimiting;coefficient;data pre-processing;interference (communication);linear equation;multiresolution analysis;preprocessor;simulation;system of linear equations;wavelet	Zhenjia Dou;Qi Han;Xiamu Niu;Xiang Peng;Hong Guo	2016	IEEE Geoscience and Remote Sensing Letters	10.1109/LGRS.2016.2565685	multiresolution analysis;mathematical optimization;mathematical model;mathematics;interference;frequency domain;physics	Visualization	74.51229851572947	-69.68894495089953	78679
a12c991cfd8c5c0270a2c24929e581bd749fbbf3	high-resolution maps of bathymetry and benthic habitats in shallow-water environments using multispectral remote sensing imagery	atmospheric modeling sea measurements satellites sea surface satellite broadcasting sensors atmospheric measurements;atmospheric measurements;sensors;support vector machines albedo atmospheric radiation bathymetry geophysical image processing radiative transfer remote sensing seafloor phenomena seawater solar radiation;satellite broadcasting;sea surface;worldview 2 wv2 atmospheric model bathymetry mapping benthic habitat mapping high resolution multispectral imagery physical and image processing techniques sunglint;satellites;albedo atmospheric radiation bathymetry geophysical image processing radiative transfer remote sensing seafloor phenomena seawater solar radiation support vector machines;atmospheric model bathymetry mapping benthic habitat mapping high resolution multispectral imagery physical and image processing techniques sunglint worldview 2 wv2;atmospheric modeling;sea measurements	Coastlines, shoals, and reefs are some of the most dynamic and constantly changing regions of the globe. The emergence of high-resolution satellites with new spectral channels, such as the WorldView-2, increases the amount of data available, thereby improving the determination of coastal management parameters. Water-leaving radiance is very difficult to determine accurately, since it is often small compared to the reflected radiance from other sources such as atmospheric and water surface scattering. Hence, the atmospheric correction has proven to be a very important step in the processing of high-resolution images for coastal applications. On the other hand, specular reflection of solar radiation on nonflat water surfaces is a serious confounding factor for bathymetry and for obtaining the seafloor albedo with high precision in shallow-water environments. This paper describes, at first, an optimal atmospheric correction model, as well as an improved algorithm for sunglint removal based on combined physical and image processing techniques. Then, using the corrected multispectral data, an efficient multichannel physics-based algorithm has been implemented, which is capable of solving through optimization the radiative transfer model of seawater for bathymetry retrieval, unmixing the water intrinsic optical properties, depth, and seafloor albedo contributions. Finally, for the mapping of benthic features, a supervised classification methodology has been implemented, combining seafloor-type normalized indexes and support vector machine techniques. Results of atmospheric correction, remote bathymetry, and benthic habitat mapping of shallow-water environments have been validated with in situ data and available bionomic profiles providing excellent accuracy.	algorithm;bathymetry;emergence;habitat;image processing;image resolution;machine learning;mathematical optimization;multispectral image;supervised learning;support vector machine	Francisco Eugenio-Gonzalez;Javier Marcello;Javier Martín Abasolo	2015	IEEE Transactions on Geoscience and Remote Sensing	10.1109/TGRS.2014.2377300	meteorology;atmospheric model;astronomy;hydrology;sensor;physics;satellite;remote sensing	Visualization	80.36945525142119	-59.639683645015374	78705
6d69b20423e972229fbad79a85b4b248199ef389	automatic co-registration of multi-temporal landsat-8/oli and sentinel-2a/msi images		This study aims at addressing misregistration issues between Landsat-8/OLI and Sentinel-2A/MSI at 30 m resolution using a phase correlation approach and multiple transformation functions. Phase correlation proved to be a robust approach that allowed us to identify hundreds and thousands of control points on images acquired more than 100 days apart. Overall, misregistration of up to 1.6 pixels at 30 m resolution between Landsat-8 and Sentinel-2A images were observed. The Random Forest regression used for constructing the mapping function showed best results, yielding an average RMSE error of 0.07 pixels at 30 m resolution for multiple tiles and multiple conditions.	phase correlation;pixel;random forest	Serhiy Skakun;Jean-Claude Roger;Eric F. Vermote;Christopher Justice;Jeffrey G. Masek	2017	2017 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)	10.1109/IGARSS.2017.8128191	artificial intelligence;computer vision;satellite imagery;remote sensing;pixel;computer science;phase correlation;random forest;mean squared error	Vision	76.16092151664913	-60.62100312966876	78729
079163e7d59d80a2177d1cc305a284ea3ff2d7b7	deformation monitoring and analysis of the geological environment of pudong international airport with persistent scatterer sar interferometry	geological environment;shanghai pudong international airport;deformation;terrasar x satellite images	Many coastal cities have undertaken reclamation projects to satisfy the land demands of rapid urbanization. However, the foundations of reclaimed land are susceptible to settlement and can have undesirable environmental impacts that could adversely affect these dense, populated areas. In the case of international airports built on reclaimed areas especially, regional-scale deformation must be monitored to ensure operational security for public safety. Persistent Scatterer SAR Interferometry (PSI) technology has proven to be an effective tool to detect ground deformation in urban areas. However, it is still a challenge to apply PSI to effectively monitor settlement at airports built on newly developed coastal reclamation areas because of the scarcity of identifiable targets. Moreover, additional issues arise as the complicated deformation patterns associated with the underlying geological conditions make it difficult to interpret InSAR-derived results. In this study, a time-series analysis of a high-resolution TerraSAR-X satellite image stack acquired from September 2011 to October 2012 was performed by employing a modified PSI technique to retrieve the mean deformation velocity and time series of surface deformation at Pudong International Airport. Qualitative evaluation of spatial distribution and temporal evolution of deformation was conducted by joint analyses of deformation measurements and local geological data. Detailed analysis of various driving forces for deformation patterns confirmed that the results of deformation monitoring obtained by PSI are reliable and consistent with that of local geological surveys. Since the factors responsible for the subsidence within the airport are still at play, ongoing and routine deformation monitoring is warranted.	google book search settlement agreement;image resolution;operations security;population;time series;velocity (software development)	Yanan Jiang;Mingsheng Liao;Hanmei Wang;Lu Zhang;Timo Balz	2016	Remote Sensing	10.3390/rs8121021	geotechnical engineering;deformation;physics;remote sensing	Visualization	81.88731237889401	-57.430363974843154	78749
17b4f58e796a572268dd0a4c2ca0a1ea167b70c5	binarization of noisy microscopy images through signal reconstruction using iterative detection network	binarization;iterative detection network;image processing;particle detection noisy microscopy image image binarization signal reconstruction iterative detection network image acquisition process point spread function image blur image noise maximum a posteriori probability criterion noise suppression property deconvolution property;microscopy optical microscopy cameras noise measurement signal to noise ratio iterative decoding;iterative detection network binarization microscopy images image processing image reconstruction;image reconstruction;object detection deconvolution image denoising image reconstruction image restoration iterative methods maximum likelihood estimation;microscopy images	We propose a novel binarization method based on a signal reconstruction using an iterative detection network. The algorithm simulates the whole image acquisition process taking into account a point spread function of the imaging system and its noise characteristics. The negative influence of image blur and noise is effectively suppressed by iterative detection network based on the criterion of maximum a posteriori probability. The proposed method was successfully applied to noisy microscopy images. Experiments show that the proposed method due to the noise suppression and deconvolution properties provides for noisy images significantly better results compared to common thresholding techniques. Binarized images obtained by the proposed method can be particularly useful for particle detection and analysis of cell samples.	algorithm;binary image;deconvolution;experiment;gaussian blur;iterative method;particle filter;signal reconstruction;thresholding (image processing);zero suppression	Tomás Lukes;Daniel Kehrt;Karel Fliegel;Milos Klima	2014	2014 IEEE International Conference on Image Processing (ICIP)	10.1109/ICIP.2014.7025802	iterative reconstruction;image restoration;image noise;computer vision;feature detection;image processing;computer science;machine learning;pattern recognition;mathematics	Vision	56.19796217929392	-66.79382441412302	78783
3acb06f513542cc34d2289fcf7b68845303f80a4	efficient optimization of inpainting scheme and line scratch detection for old film restoration	computational complexity;video quality;mse;mean square error;inpainting	Old films usually have typical damages from dirt, scratch, and scribbling. These damages make an image degradation of vertical line scratches or blotches in frames. This paper proposes an efficient line scratch detection technique and efficient inpainting method based on MSE (mean square error) to fill the identified line scratch areas. Previous line scratch detection algorithms can only detect full column line scratches; however, we found that partial line scratch should also be identified for better film restoration. We identify line scratches using block-by-block inspection; thereby we can detect partial line scratches. After identifying the line scratches, we use a modified inpainting scheme, which uses MSE measure to compute gradient vector of the inpainting regions. In our experiment with old Korean films, we show that our scheme gives better video quality with much reduced computational complexity.	circuit restoration;inpainting	Seong-Whan Kim;Ki-Hong Ko	2006		10.1007/11801603_66	image quality;image restoration;computer vision;film;edge detection;color image;computer science;video quality;gradient;korean;inpainting;computer graphics (images)	Vision	57.35167613028768	-60.47931797233781	78829
594832db46f82145745d579e7909c4fd57ca291b	an automatic method for unequal and omni-directional anisotropic diffusion filtering of video sequences	teleconferencing;video signal processing;videoconferencing face skin identification video sequence anisotropic diffusion filtering omnidirectional diffusion filtering unequal diffusion filtering automatic foreground background discrimination human face color characteristics skin color characteristics visual quality skin tone variations lighting variations;low complexity;anisotropic magnetoresistance filtering video sequences skin decoding humans face encoding robustness calibration;anisotropic diffusion;visual quality;face recognition;image colour analysis;teleconferencing video signal processing face recognition image colour analysis;foreground background	In this paper, we propose a method for automatic, unequal and omni-directional anisotropic diffusion filtering of video sequences. Our method, which consists of automatic foreground/background discrimination using the color characteristics of the human face and skin, unequal filtering of the determined regions and then composition of the filtered regions into the final frames, is applied prior to encoding the video sequences. In addition to yielding higher visual quality of the decoded sequences than that of the decoded sequences with equal filtering over the entire frame, our method is robust with respect to skin tone and lighting variations, has low complexity and requires no calibration. We illustrate the main advantages of our method using videoconferencing sequences.	anisotropic diffusion;code;color	Adriana Dumitras;James O. Normile	2004	2004 IEEE International Conference on Acoustics, Speech, and Signal Processing	10.1109/ICASSP.2004.1326545	facial recognition system;computer vision;speech recognition;teleconference;computer science;foreground-background;multimedia;anisotropic diffusion	Vision	56.58811630535195	-62.464321739768145	78906
068fa7f05423a16f7f787ed85107f18ea44da221	an adaptive patch-based reconstruction scheme for view synthesis by disparity estimation using optical flow	image reconstruction optical imaging image edge detection estimation adaptive optics rendering computer graphics cameras;optical flow view synthesis image based rendering view interpolation	Due to the rapid growth of technology and the dropping cost of cameras, multiview imaging applications have attracted many researchers in recent years. Free viewpoint and 3D Televisions are among these interesting applications. One of the problems that should be solved to realize such applications is rendering. In this paper, we propose an optical flow-assisted adaptive patch-based view synthesis algorithm. This patch-based scheme reduces the size and number of holes during reconstruction. The size of patch is determined in response to edge information for better reconstruction, especially near the boundaries. In the first stage of the algorithm, disparity is obtained using optical flow estimation. Then, a reconstructed version of the left and right views is generated using our adaptive patch-based algorithm. The mismatches between each view and its reconstructed version are obtained in the mismatch detection steps. This stage results in two masks as outputs, which help with the refinement of disparities and the selection of the best patches for final synthesis. Finally, the remaining holes are filled using our simple hole-filling scheme and the refined disparities. The objective and subjective performances of the proposed algorithm are compared with recent methods. The results show that the proposed algorithm achieves an improvement of 2.14 dB on average.	3d television;algorithm;binocular disparity;canny edge detector;decibel;edge detection;electron hole;experiment;optical flow;patch (computing);peak signal-to-noise ratio;performance;refinement (computing);rendering (computer graphics);space-filling tree;variable shadowing;version 7 unix;view synthesis	Hoda Rezaee Kaviani;Shahram Shirani	2018	IEEE Transactions on Circuits and Systems for Video Technology	10.1109/TCSVT.2017.2682887	computer science;view synthesis;optical imaging;rendering (computer graphics);computer vision;artificial intelligence;iterative reconstruction;image-based modeling and rendering;adaptive optics;left and right;optical flow	Vision	58.49054373267516	-59.33789635402147	78952
3073ada421eca96edfe2b556a27d715fb8cfca1d	three-dimensional synthetic aperture radar imaging of a fir tree: first results	three dimensional imaging;etude laboratoire;diffusiometrie;vegetation mapping;polarimetrie;electromagnetic scattering;isar;radar remote sensing;radar polarimetry geophysical measurement technique forestry forest vegetation mapping fir tree radar remote sensing radar imaging synthetic aperture radar three dimensional imaging sar single tree wideband radar two dimensional aperture isar;wideband radar;forestry;performance evaluation;three dimensional models;modelo 3 dimensiones;radar imageur synthese ouverture;radar antenne synthetique;single tree;modele 3 dimensions;polarization;imagerie;aperture synthesis;indexing terms;forest;three dimensional;retrodiffusion;geophysical measurement technique;fir tree;laboratory studies;polarizacion;remote sensing by radar;radar polarimetry radar measurements synthetic aperture radar electromagnetic scattering inverse synthetic aperture radar laboratories performance evaluation radar imaging frequency radar scattering;radar scattering;trees;imagery;sar;onde electromagnetique;radar polarimetry;radar imaging;inverse synthetic aperture radar;radar polarimetry geophysical techniques vegetation mapping forestry remote sensing by radar synthetic aperture radar radar imaging;syn thetic aperture radar;arbre;imagineria;two dimensional aperture;polarisation;frequency;backscattering;radar measurements;onda electromagnetica;validation and verification;geophysical techniques;high spatial resolution;synthetic aperture radar;electromagnetic waves	A three-dimensional (3-D) inverse synthetic aperture radar (ISAR) imaging experiment on a fir tree is described. Radar measurements on single trees under laboratory conditions can be performed in the scatterometric, with no aperture synthesis, and in the imaging (SAR) mode. Imaging an entire tree requires the use of a wideband radar and a two-dimensional (2-D) aperture which may be synthetic or real. A 3-D ISAR image can be obtained by processing coherently the backscattered fields as a function of the frequency and two rotation angles about axes which are mutually orthogonal. With such a system, and by conveniently processing the acquired data, the major scatterers and their positions within the tree volume can be identified with a high spatial resolution. The obtained 2-D and 3-D polarimetric ISAR images show that this new technique can be used to support the understanding of the interaction of electromagnetic waves with natural targets and provide the basis for the validation and verification of existing models.	3d computer graphics;aperture (software);polarimetry;radar;synthetic data;verification and validation	Joaquim Fortuny-Guasch;Alois J. Sieber	1999	IEEE Trans. Geoscience and Remote Sensing	10.1109/36.752219	synthetic aperture radar;astronomy;polarization;hydrology;optics;radar imaging;inverse synthetic aperture radar;side looking airborne radar;physics;quantum mechanics;remote sensing	Visualization	79.24910510316943	-65.77199987270858	79026
82d289ca308e5a338d11dafc9fc326ebef7a0213	improvement of digital terrain model interpolation using sfs techniques with single satellite imagery	photogrammetry;teledetection spatiale;shape from shading;space remote sensing;image processing;traitement image stereoscopique;image databank;procesamiento imagen;fotogrametria;traitement image;digital terrain model;high resolution satellite imagery;reconstruction image;teledeteccion espacial;specification donnee;reconstruccion imagen;image reconstruction;remote sensing;banco imagen;stereo image processing;banque image;especificacion datos;satellite imagery;photogrammetrie;data specification	The technique of stereo measurements is mainly applied to extract Digital Terrain Model (DIM) height data from stereo images in photogrammetry and remote sensing. Tremendous amounts of local and global DTM data with different specifications are now available. However, there are numerous geoscience and engineering applications which need denser DTM grid data than available. Advanced space technology has provided much single (if not stereo) high-resolution satellite imageries almost worldwide. In cases where only monocular images are available, reconstruction of the object surfaces becomes more difficult. Shape from Shading (SFS) is one of the methods to derive the geometric information about the objects from the analysis of the monocular images. This paper discusses the use of SFS methods with single high resolution satellite imagery to density regular grids of heights. Three different methodologies are explained and implemented with both simulated and real data. Very encouraging results are obtained and briefly discussed.	clustered file system;digital elevation model;interpolation	Mohammad A. Rajabi;J. A. Rod Blais	2002		10.1007/3-540-47789-6_17	iterative reconstruction;computer vision;photometric stereo;digital elevation model;image processing;computer science;photogrammetry;computer graphics (images)	Vision	75.8177667189347	-60.04557434250305	79059
2a767e0856bb650f5f1e7b007adcbfe57660c4bd	estimating fluid optical flow	continuity equation;spatial coherence;motion estimation;fluid mechanics;computer vision;image sequence;image motion analysis biomedical optical imaging equations image analysis optical distortion spatial coherence brightness image sequences fluid flow image sequence analysis;optical flow;meteorological images fluid optical flow fluid motion estimation continuity equation div curl type smoothness term;meteorology;meteorology motion estimation image sequences computer vision;image sequences	In this paper, we address the problem of fluid motion estimation in image sequences. For such motions, standard optical flow methods, based on intensity conservation and spatial coherence of motion field, are not suitable. This is due to the highly deformable nature of fluid medium. For all applications where fluid motions are to be recovered from images, it is then important to have specific techniques. We investigate such dedicated models which include an original observation constraint, based on the continuity equation from fluid mechanics, and a new div-curl-type smoothness term. Our method is validated on synthetic and real meteo-	coherence (physics);motion estimation;motion field;optical flow;scott continuity;span and div;synthetic intelligence;curl	Thomas Corpetti;Étienne Mémin;Patrick Pérez	2000		10.1109/ICPR.2000.903722	computer vision;computer science;continuity equation;motion estimation;optical flow;mathematics;geometry;motion field;fluid mechanics	Vision	55.933863907546474	-55.69854958233645	79078
69bb23205685de2fc80f7438ee7d379151233ea5	a regularized iterative image restoration algorithm	least squares approximations;spatial adaptivity deterministic information convergence image quality regularized iterative image restoration algorithm set theoretic approach statistical information undistorted image noise constrained least squares algorithm;picture processing;image restoration iterative algorithms degradation ellipsoids visual system additive noise iterative methods least squares methods humans layout;image restoration;set theory;iterative algorithm;iterative methods;set theory iterative methods least squares approximations picture processing;constrained least square;human visual system;visual system	This paper introduces a regularized iterative image restoration algorithm. The development of the algorithm is based on a set theoretic approach to regularization. Deterministic andlor statistical information about the undistorted image and statistical information about the noise are directly incorporated into the iterative procedure. The restored image is the center of an ellipsoid bounding the intersection of two ellipsoids. The proposed algorithm, which has the constrained least squares algorithm as a special case, is also extended into an adaptive iterative restoration algorithm. The spatial adaptivity is introduced to incorporate properties of the human visual system. Convergence of the proposed iterative algorithms is established. For the experimental results which are shown, the adaptively restored images have better quality than the nonadaptively restored ones based on visual observations and on an objective criterion of merit which accounts for the noise masking property of the visual system.	algorithm;circuit restoration;ellipsoid method;image restoration;iteration;iterative method;linear least squares (mathematics);matrix regularization;set theory	Aggelos K. Katsaggelos;Jan Biemond;Ronald W. Schafer;Russell M. Mersereau	1991	IEEE Trans. Signal Processing	10.1109/78.80914	iterative reconstruction;computer vision;mathematical optimization;non-linear iterative partial least squares;theoretical computer science;machine learning;mathematics;iterative method;iterative proportional fitting	Vision	58.15337338656232	-71.13342815948975	79130
be0593e77cdffc5e78c6d5da13632f2fbfde886b	characterization of integrating sphere homogeneity with an uncalibrated imaging spectrometer	experimentelle verfahren	The radiometric calibration of imaging spectrometers is usually performed using integrating spheres as light sources. Their homogeneities are usually defined for the entrance aperture. As airborne hyperspectral sensors are focused on infinity, the calibration of such sensors is done in a way which is not well defined. In this paper, a method is shown which allows the characterization of integrating spheres with a radiometrically uncalibrated hyperspectral sensor. The sphere is characterized in the same way as it is used for the calibration of hyperspectral sensors. This allows the determination of the relative uncertainty of radiometric measurements due to inhomogeneities. Also, the relative radiometric response of the sensor can be derived at the same time. The method is demonstrated exemplarily with a HySpex VNIR-1600, an airborne imaging spectrometer system from Norsk Elektro Optikks A/S (NEO).	airborne ranger;approximation error;elektro;metric;sensor	Andreas Baumgartner	2013	2013 5th Workshop on Hyperspectral Image and Signal Processing: Evolution in Remote Sensing (WHISPERS)	10.1109/WHISPERS.2013.8080735	geography;analytical chemistry;optics;remote sensing	Vision	82.35877948835308	-64.7355738730558	79154
0f96757a179dbf6d487213056bc799c3096f97ea	indusion: fusion of multispectral and panchromatic images using the induction scaling technique	pan sharpening;interpolation;discrete wavelet transform;fusion;image fusion;low resolution;q4 index;scaling;smoothing methods;induction;geophysical signal processing;intensity modulation;scaling fusion induction indusion pan sharpening q4 index;remote sensing;indexation;smoothing filter based intensity modulation;spatial resolution discrete wavelet transforms interpolation image resolution intensity modulation satellites filters induction generators fusion power generation;satellite image;quickbird satellite images indusion image fusion multispectral images panchromatic images induction scaling technique smoothing filter based intensity modulation bicubic interpolation;high frequency;indusion;smoothing methods geophysical signal processing image fusion intensity modulation interpolation remote sensing	The fusion of multispectral (MS) and panchromatic (PAN) images is a useful technique for enhancing the spatial quality of low-resolution MS images. Liu recently proposed the smoothing-filter-based intensity modulation (SFIM) fusion technique. This technique upscales MS images using bicubic interpolation and introduces high-frequency information of the PAN image into the MS images. However, this fusion technique is plagued by blurred edges if the upscaled MS images are not accurately coregistered with the PAN image. In the first part of this letter, we propose the use of the Induction scaling technique instead of bicubic interpolation to obtain sharper, better correlated, and hence better coregistered upscaled images. In the second part, we propose a new fusion technique derived from induction, which is named ldquoIndusion.rdquo In this method, the high-frequency content of the PAN image is extracted using a pair of upscaling and downscaling filters. It is then added to an upscaled MS image. Finally, a comparison of SFIM (with both bicubic interpolation and induction scaling) is presented along with the fusion results obtained by IHS, discrete wavelet transform, and the proposed Indusion techniques using Quickbird satellite images.	bicubic interpolation;discrete wavelet transform;downscaling;image registration;image scaling;list of code lyoko episodes;mathematical induction;modulation;multispectral image;smoothing	Muhammad Murtaza Khan;Jocelyn Chanussot;Laurent Condat;Annick Montanvert	2008	IEEE Geoscience and Remote Sensing Letters	10.1109/LGRS.2007.909934	computer vision;image resolution;fusion;interpolation;scaling;computer science;intensity modulation;high frequency;mathematics;optics;image fusion;discrete wavelet transform;physics;remote sensing	Robotics	66.50427277575146	-65.59276414200313	79183
3d97ecd857ce3e25c02bc5f440b39297c44950ca	color-accurate underwater imaging using perceptual adaptive illumination	underwater imaging;accurate colors;adaptive illumination;color rendering index	Capturing color in water is challenging due to the heavy non-uniform attenuation of light in water across the visible spectrum, which results in dramatic hue shifts toward blue. Yet observing color in water is important for monitoring and surveillance as well as marine biology studies related to species identification, individual and group behavior, and ecosystem health and activity monitoring. Underwater robots are equipped with motor control for large scale transects but they lack sensors that enable capturing color-accurate underwater images. We present a method for color-accurate imaging in water called perceptual adaptive illumination. This method dynamically mixes the illumination of an object in a distance-dependent way using a controllable multi-color light source. The color mix compensates correctly for color loss and results in an image whose color composition is equivalent to rendering the object in air. Experiments were conducted with a color palette in the pool and at three different coral reefs sites, and with an underwater robot collecting image data with the new sensor.	color;experiment;global illumination;habitat;illumination (image);image plane;palette (computing);rendering (computer graphics);robot;sensor	Iuliu Vasilescu;Carrick Detweiler;Daniela Rus	2010	Auton. Robots	10.15607/RSS.2010.VI.003	computer vision;acoustics;optics	Robotics	65.8298408831914	-56.953025228560165	79213
203a9c780189ceb386131024dfcbefa9547d6966	image characteristic oriented tone mapping for high dynamic range images	dynamic range histograms quantization visualization graphics algorithm design and analysis image coding;tone mapping;histograms;image characteristic oriented tone mapping;quantization;adverse mapping;tone mapping algorithm;contrast ratio;high dynamic range images;image coding;image resolution;tone reproduction curve;visual quality;high dynamic range imaging;distortion;visualization;contrast ratio tone mapping high dynamic range low dynamic range;image resolution distortion;visual quality image characteristic oriented tone mapping high dynamic range images tone mapping algorithm low dynamic range images adaptive mapping adverse mapping tone reproduction curve;dynamic range;low dynamic range;low dynamic range images;high dynamic range;algorithm design and analysis;graphics;adaptive mapping	This paper presents a novel and efficient tone mapping algorithm for converting high dynamic range (HDR) images back to low dynamic range (LDR) images for displaying purpose because of the limited contrast ratio of common displays and printers. As the ratio between the maximum and minimum values of common HDR images is always very large and also the population usually deflects to one side, for convenient processing, most researchers first take the logarithm on the luminance layer or use another adaptive mapping to shorter the range of the distribution in their tone mapping methods. However, these mappings have already distorted the original imagespsila characteristics. In this paper, there is no such adverse mapping applied on the luminance layer in the proposed tone mapping algorithm. The paper does produce a tone reproduction curve to convert HDR images to LDR images. Adaptive techniques are also manipulated to provide better visual quality. The whole process is automatic and no parameter is required for manual input. The result will be a superior visual quality tone mapped LDR image with original HDR imagepsilas characteristics.	algorithm;contrast ratio;high dynamic range;high-dynamic-range imaging;high-dynamic-range rendering;ldraw;maxima and minima;tone mapping	Chun-Hung Liu;Oscar C. Au;Peter Hon-Wah Wong;Man Cheung Kung	2008	2008 IEEE International Conference on Multimedia and Expo	10.1109/ICME.2008.4607639	algorithm design;computer vision;dynamic range;tone mapping;visualization;image resolution;distortion;quantization;computer science;graphics;histogram;contrast ratio;computer graphics (images)	Visualization	60.73437592076292	-61.445062438419995	79237
949a1bcd8ad0457154e0a96504246704c4d677db	a generic level 1 simulator for spaceborne gnss-r missions and application to geros-iss ocean reflectometry		"""In the past decade Global Navigation Satellites System Reflectometry (GNSS-R) has emerged as a new technique for earth remote sensing for various applications, such as ocean altimetry and sea state monitoring. After the success of the GNSS-R demonstrator payloads aboard the UK-DMC or TDS-1 satellites; at present, there are several missions planned to carry GNSS reflectometers. The GNSS rEflectometry, Radio Occultation, and Scatterometry onboard International Space Station (GEROS-ISS) is an innovative ISS experiment exploiting GNSS-R technique to measure key parameters of ocean, land, and ice surfaces. For GEROS-ISS mission, the European Space Agency (ESA) supported the study of GNSS-R assessment of requirements and consolidation of retrieval algorithms (GARCA). For this, it was required to accurately simulate the GEROS-ISS measurements including the whole range of parameters affecting the observation conditions and the instrument, which is called GEROS-SIM. To meet these requirements, the PAU/PARIS end-to-end performance simulator (P<inline-formula><tex-math notation=""""LaTeX"""">$^{2}$</tex-math></inline-formula>EPS) previously developed by UPC BarcelonaTech was used as the baseline building blocks for the level 1 (L1) processor of GEROS-SIM. P<inline-formula> <tex-math notation=""""LaTeX"""">$^{2}$</tex-math></inline-formula>EPS is a flexible tool, and is capable of systematically simulating the GNSS-R observations for spaceborne GNSS-R missions. Thanks to the completeness and flexibility, the instrument-to-L1 data module of GEROS-SIM could be implemented by proper modification and update of P<inline-formula> <tex-math notation=""""LaTeX"""">$^{2}$</tex-math></inline-formula>EPS. The developed GEROS-SIM was verified and validated in the GARCA study as comparing to the TDS-1 measurements. This paper presents the design, implementation, and results of the GEROS-SIM L1 module in a generic way to be applied to GNSS-R instruments."""	airborne ranger;altimeter device component;antenna device component;basal ganglia diseases;baseline (configuration management);esa;end-to-end principle;fifty nine;gnss reflectometry;generic drugs;global positioning system;instrument - device;interface device component;light-harvesting protein complexes;lung consolidation;population parameter;radio occultation;religious missions;requirement;sim2 gene;satellite viruses;satellite navigation;semiconductor consolidation;simulation;simulators;subscriber identity module;universal product code;usability;algorithm;level 1;phosphatidylinositol 3'-kinase-associated serine kinase	Hyuk Park;Adriano Camps;Daniel Pascual;Yujin Kang;Raul Onrubia;Jorge Querol;Alberto Alonso-Arroyo	2017	IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing	10.1109/JSTARS.2017.2720625	remote sensing;radio occultation;satellite navigation;international space station;mathematics;simulation;sea state;reflectometry;gnss reflectometry;altimeter;gnss applications	Embedded	80.79131978624038	-63.58060994703073	79275
72eefc164b96ebdc110488323e8e56c967db1852	data quality inspection of watermarked gis vector map	digital watermarking;geographical information copyright protection;watermarking;geographic information;watermarking error analysis geographic information systems;watermark embedding algorithm data quality inspection watermarked gis vector map digital watermarking geographical information copyright protection polygon closure data topology error analysis visual analysis coding;polygon closure;data quality inspection;digital watermark;watermark embedding algorithm;topology inspection gis vector map watermark data quality inspection error analysis visual analysis;inspection;topology inspection;copyright protection;error analysis;accuracy;visualization;watermarking inspection geographic information systems error analysis accuracy visualization signal to noise ratio;geographic information systems;data topology;visual analysis;coding;watermark;watermarked gis vector map;vector data;data quality;signal to noise ratio;gis vector map	In recent years, digital watermarking is playing an increasingly important role in the geographical information copyright protection. According to the characteristics of GIS vector data, the watermark embedding algorithms should at least meet the following demands: no significant loss in data accuracy, no obvious reduction in data quality and no significant change in visual observation. In this paper, the quality of watermarked GIS vector data is inspected through polygon closure, data topology, error analysis and visual analysis. And the above functions are achieved by coding. Through experiments we can find that this method can inspect the quality of watermarked GIS vector data well, so that it can provide basis for judging whether the watermark embedding algorithm is good.	algorithm;computer programming;data quality;digital watermarking;error analysis (mathematics);experiment;galaxy morphological classification;geographic information system;planimetrics;requirement;vector map	Li Huang;Wei Zhou;Rui Jiang;Anbo Li	2010	2010 18th International Conference on Geoinformatics	10.1109/GEOINFORMATICS.2010.5567694	computer vision;computer science;data mining;computer security	DB	75.96685038582623	-56.28660358771588	79282
643a098771dae7ee086e9778a76b2f0be77b4c52	pupil configuration for extended source imaging with optical interferometry: a computational geometry approach	light interferometry;fourier domain;astronomical telescopes;optical transfer function;spatial frequencies;computational geometry methods;computational geometry;incoherent light;optical imaging optical interferometry computational geometry instruments adaptive optics autocorrelation frequency telescopes transfer functions mirrors;pupil configuration;optical instrument;extended source imaging;pupil segment;fourier domain pupil configuration extended source imaging optical interferometry computational geometry methods interferometry based observation instruments optical transfer function optical instrument incoherent light input pupil pupil segment pupil geometries isotropic otf support spatial frequencies;fourier analysis;input pupil;optical interferometry;isotropic otf support;pupil geometries;optical transfer function astronomical telescopes computational geometry fourier analysis light interferometry;spatial frequency;interferometry based observation instruments	The input pupil of interferometry-based observation instruments is necessarily segmented. Since the optical transfer function (OTF) of any optical instrument observing in incoherent light is the auto-correlation of its input pupil, it follows that any combination of size and position of each pupil segment have an impact on the OTF behavior and therefore on the quality of the output image. The goal of this study is to propose computational geometry methods allowing to find pupil geometries leading to an isotropic OTF support with a controlled redundancy of viewed spatial frequencies in the Fourier domain	autocorrelation;coherence (physics);computation;computational geometry;transfer function	Trung Nguyen;Jean-Daniel Boissonnat;Philippe Blanc;Frédéric Falzon;Eric Thomas	2006	2006 IEEE International Conference on Acoustics Speech and Signal Processing Proceedings	10.1109/ICASSP.2006.1660462	computer vision;computational geometry;pupil function;spatial frequency	Robotics	79.22357695293458	-68.47073708649418	79324
11f9a771eeb39c8c220ee11cec108a5be86ff0e7	anomaly-based hyperspectral image compression	discrete wavelet transforms;rate distortion;dwt;image coding;image compression process;discrete wavelet transform;personal communication networks;lossy compression;compression algorithms;anomaly detection;post compression anomaly detection;aa algorithm lossy compression algorithm hyperspectral image principal component analysis pca jpeg2000 anomaly removal model image compression process anomalous pixel preservation post compression anomaly detection discrete wavelet transform dwt rate distortion performance anomaly adjusted algorithm;anomaly adjusted algorithm;transform coding;remote sensing discrete wavelet transforms geophysical techniques principal component analysis;anomaly removal model;lossy compression algorithm;anomalous pixel preservation;image reconstruction;principal component analysis;aa algorithm;remote sensing;pixel;rate distortion performance;hyperspectral imaging image coding principal component analysis discrete wavelet transforms compression algorithms transform coding pixel rate distortion decorrelation personal communication networks;jpeg2000;decorrelation;hyperspectral imaging;signal to noise ratio;hyperspectral image;pca;geophysical techniques	We propose a new lossy compression algorithm for hyperspectral images, which is based on spectral principal component analysis (PCA), followed by JPEG2000 (JP2K). The approach employs an anomaly-removal model in the compression process to preserve anomalous pixels. Results on two different hyperspectral image scenes show that the new algorithm not only provides good post-compression anomaly-detection performance but also improves rate-distortion performance.	algorithm;anomaly detection;distortion;image compression;jpeg 2000;lossy compression;pixel;principal component analysis	Qian Du;Wei Zhu;James E. Fowler	2008	IGARSS 2008 - 2008 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2008.4779159	color cell compression;computer vision;anomaly detection;image compression;computer science;machine learning;pattern recognition;mathematics;remote sensing;principal component analysis	Vision	68.4880292060808	-63.89318417465922	79354
c237bdb04453234fb09e00df9654cc668e16b900	automatic ship photo interpretation by the method of moments	method of moments;high resolution;low resolution;linear regression;comparison with human;high contrast imaging;rotation invariance;ship images;method of moment;automatic photo interpretation comparison with human invariant moments linear regression method of moments ship images;automatic photo interpretation;invariant moments	The results of a study undertaken to determine the feasibility of automatic interpretation of ship photographs using the spatial moments of the image as features to characterize the image are reported. The photo interpretation consisted of estimating the location, orientation, dimensions, and heading of the ship. The study used simulated ship images in which the outline of the ship was randomly filled with black and white cells to give a low-resolution high-contrast image of the ship such as might be obtained by a high-resolution radar. The estimates were made using polynomials of invariant moments formed by transformations of the original spatial moments, e. g., density-invariant moments, central moments, rotation-invariant moments, etc. The transformations to invariant moments were chosen using physical reasoning. The best moments for the polynomials were chosen using linear regression. The performance of the method of moments on these low-resolution images was found to be comparable to that of a human photointerpreter and to certain heuristic techniques that would be more difficult to implement than the method of moments.	course (navigation);heuristic;image moment;image resolution;polynomial;radar;randomness;windows photo gallery	Fred W. Smith;Margaret H. Wright	1971	IEEE Transactions on Computers	10.1109/T-C.1971.223408	velocity moments;computer vision;simulation;image resolution;method of moments;computer science;mathematics;statistics	Visualization	69.31124275072355	-57.92563907522198	79473
cd54b729ffb602dc9356fed6e04d4c3570ccbbea	image sensor characterization in a photographic context.	image sensor	"""The new Kodak KAI-11000CM image sensor, a 35-mm format, 11-Megapixel interline CCD, has been characterized in terms of its performance in photography applications. Traditional sensor performance parameters are summarized in addition to photographic image quality parameters. A photographic evaluation of the sensor, including measurements of signal-to-noise ratio and color fidelity, is described. Finally, a comparison of sharpness is drawn between the KAI-11000CM image sensor and the Kodak Professional DCS 760 digital camera in the context of a large 30"""" x 40"""" poster."""	charge-coupled device;digital camera;image quality;image sensor;interlaced video;signal-to-noise ratio	Sean C. Kelly;Gloria G. Putnam;Richard B. Wheeler;Shen Yun Wang;William Davis;Ed Nelson;Doug Carpenter	2003			computer vision;image sensor;remote sensing	Mobile	62.86833599852795	-57.897585724349305	79636
a90c8724c05dcd71ebb55ee8e17416db6635f2ec	theoretical application of overlapped subaperture algorithm for quasi-forward-looking parameter-adjusting spotlight sar imaging		This letter theoretically extends and applies the overlapped subaperture algorithm (OSA) for the challenging spotlight synthetic aperture radar (SAR) imaging in a quasi-forward-looking (QFL) geometry. A parameter-adjusting framework, in which the radar parameters relate closely to the geometry, is employed to mitigate the spatial signal coupling. By innovatively fitting the phase error induced by the planar wavefront assumption directly to the wavenumbers, both the linear and quadratic phase errors, which determine the geometrical distortion and the defocusing effects, respectively, can be accurately expressed and then corrected. When compared with the parameter-adjusting polar format algorithm proposed by the authors in previous work, the OSA is superior in contributing to an expanded imaging swath. The validity of the OSA methodology is demonstrated by the simulation of a Ka-band SAR working in the QFL diving mode with an extreme 85° squint angle.	algorithm;cubic hermite spline;cubic function;dbpedia;distortion;information diving;interpolation;ka band;linear phase;loose coupling;picasa web albums;predictive failure analysis;simulation;synthetic data	Yan Wang;Jian Yang;Jingwen Li	2017	IEEE Geoscience and Remote Sensing Letters	10.1109/LGRS.2016.2619861	computer vision	EDA	76.00882215746677	-67.67836377174392	79674
e132301be589e8d57fdd6f8f3fa690208b5bc1d7	effective mapping of urban areas using envisat asar, sentinel-1a, and hj-1-c data	speckle;image resolution;density based spatial clustering of applications with noise dbscan synthetic aperture radar sar urban area mapping;data mining;urban areas;remote sensing;clustering algorithms;urban areas synthetic aperture radar clustering algorithms speckle data mining image resolution remote sensing;synthetic aperture radar	This letter presents a methodology for urban area mapping with density-based spatial clustering of applications with noise (DBSCAN) using the Advanced Synthetic Aperture Radar (ASAR), Sentinel-1A, and HuanJing-1C data. Urban areas have a diversity of shapes, including circles, squares, strips, and other irregular shapes, and the DBSCAN clustering algorithm is suitable for identifying clusters of arbitrary shapes. Exploiting DBSCAN to extract urban areas is a key aspect of this method, and improvements via the incorporation of synthetic aperture radar data preprocessing and postprocessing also play important roles in optimizing the extractions. Different test site sizes were chosen to demonstrate the effectiveness and feasibility of the proposed method, and the validation results showed that the method is efficient and accurately extracts urban areas ranging from small towns to super metropolitan areas.	algorithm;aperture (software);cluster analysis;computation;dbscan;data pre-processing;experiment;preprocessor;region growing;strips;sensor;synthetic intelligence;towns	Shengxiu Zhou;Yunkai Deng;Robert Wang;Ning Li;Qi Si	2017	IEEE Geoscience and Remote Sensing Letters	10.1109/LGRS.2017.2686419	speckle pattern;computer vision;synthetic aperture radar;image resolution;computer science;cluster analysis;physics;remote sensing	Visualization	75.79069692107421	-58.972689318466124	79681
1bded46d5ead0d024c5c3dab1b12db128372752e	image structural information assessment	computational techniques;information content;image information assessment;computer imaging;image analysis;shape description;information theory	Many image information assessment techniques have been proposed in the past. Most of them are based on the image histogram. When the histogram of an image is derived, the structural component of the image is generally ignored. The information assessed using the histogram is thus independent of the image spatial attributes. In this investigation an original computational technique for the assessment of the structural information content of an image is described. The developed technique produces as output an information measure which is proportional to the image geometrical attributes such as the size, the shape complexity, etc. The technique is normalised and tested on a series of artificial images. The results obtained are analysed to show how the normalised information is related to the image geometrical attributes. The results obtained are also confirmed when English character images are considered. Finally, conclusions will be drawn in terms of the suitability of the technique for applications in computer imaging problems.		Ahmed Ghali;Mohammad F. Daemi;M. Mansour	1998	Pattern Recognition Letters	10.1016/S0167-8655(98)00024-5	image quality;image warping;image texture;computer vision;feature detection;image analysis;self-information;image processing;information theory;computer science;digital image processing;data mining;mathematics;information retrieval;statistics;image histogram	Vision	61.40818539868071	-64.42448375980426	79716
0539ae4dd46eaf74512b58ec4d39b0e73df9164c	an adaptive parallel algorithm for display of csg objects	parallel algorithm;performance estimation;constructive solid geometry;parallel architecture	This paper presents a parallel algorithm for the direct display of solid objects represented by Constructive Solid Geometry. The algorithm overcomes many of the limitations of previous approaches by using an adaptive technique that ensures a high degree of parallelism. Performance estimates have been obtained by simulation, and a parallel architecture is proposed.	constructive solid geometry;parallel algorithm	David T. Morris;Peter M. Dew	1986		10.1007/3-540-16811-7_172	parallel computing;computer science;theoretical computer science;parallel algorithm;constructive solid geometry;computer graphics (images)	HCI	68.48407821548885	-52.90086331286368	79768
bee882ef3a8dab8a28512723055d674fe4516596	efficient numerical schemes for chan-vese active contour models in image segmentation		In this paper, we introduce multi-symplectic Lagrangian variational integrators for solving Chan-Vese active contour models in image segmentation. Energy functionals are discretized firstly, and numerical schemes are derived from discrete Euler-Lagrange equations based on discrete variational principle. Lagrangian variational integrators preserve native differential structure-multi-symplecticity, that makes the numerical methods have a satisfied behavior. Experiments are performed on the benchmark images from literature. We further evaluated the methods in a segmentation database containing 1023 images. It shows that the proposed numerical schemes attain relatively faster convergence rates and better segmentation accuracy. Comparisons with the standard explicit Euler method of the original Chan-Vese model and other fast numerical optimization methods show that the proposed methods have better stability, higher accuracy, and are more robust when dealing with a large number of pictures. This study provides an example for further research to improve the performance of other existing image segmentation methods based on active contour models.	active contour model;augmented lagrangian method;benchmark (computing);calculus of variations;chan's algorithm;circuit restoration;compressed sensing;computation;discretization;euler method;euler–lagrange equation;experiment;image processing;image restoration;image segmentation;iteration;mathematical optimization;numerical method;scheme;standard test image;symplectic integrator;theory;time complexity;truncation;variational principle	Jiuzhen Liang;Min Li;Cuicui Liao	2017	Multimedia Tools and Applications	10.1007/s11042-017-5232-6	computer vision;artificial intelligence;computer science;pattern recognition;numerical analysis;discretization;variational integrator;scale-space segmentation;active contour model;euler method;mathematical optimization;image segmentation;segmentation-based object categorization	Vision	55.26377234357053	-70.68506516611707	79795
866a2cea4f5863ba0c8c58973b9c3a6606a01a4b	the active temperature, ozone and moisture microwave spectrometer (atomms), a new global climate sensor	active probing;atmospheric absorption;global climate sensor remote sensing system university of arizona atomms gps radio occultation microwave limb sounder atmospheric absorption satellite to satellite occultation nsf aircraft time nasa high altitude aircraft to aircraft occultations meteorology microwave spectroscopy;atomic measurements;microwave spectroscopy atmospheric measurements meteorology remote sensing;microwave limb sounder;atmospheric measurements;atomic clocks;remote sensing geophysical equipment meteorology;aircraft time;gps radio occultation;satellite to satellite occultation;global climate sensor;remote sensing;microwave spectroscopy;high altitude;university of arizona;radio occultation;high altitude aircraft to aircraft occultations;atomic measurements atmospheric measurements atomic clocks atmospheric modeling aircraft extraterrestrial measurements meteorology;geophysical equipment;atmospheric modeling;remote sensing system;extraterrestrial measurements;nasa;meteorology;ozone;nsf;atomms;aircraft	We are developing a new remote sensing system at the University of Arizona called the Active Temperature, Ozone and Moisture Microwave Spectrometer (ATOMMS). ATOMMS combines many of the best features of GPS Radio Occultation (RO) and the Microwave Limb Sounder (MLS) by actively probing cm to sub-mm wavelength atmospheric absorption features via satellite-to-satellite occultation. ATOMMS will provide an unprecedented combination of features for monitoring climate from orbit. With funding from NSF and aircraft time from NASA, we will demonstrate the ATOMMS concept via high altitude aircraft-to-aircraft occultations in 2011. Here we summarize the ATOMMS concept and demonstration project and provide early test results from the instrument indicative of ATOMMS capabilities and performance.	global positioning system;ibm notes;microwave;radio occultation;sensor web	Emil R. Kursinski;Angel Otarola;Dale Ward;Abram Young;Sarmad Albanna;Christopher Groppi;Robert Stickney;Michael Stovern;Brian Wheelwright;Brian Duffy;Michael Schein;Katherine Sammler;Rod Frehlich;Willy Bertiger;Herb Pickett;David Rind;Martin Ross	2010	2010 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2010.5653877	meteorology;atomic clock;effects of high altitude on humans;ozone;atmospheric model;atmospheric sciences;physics;rotational spectroscopy;remote sensing	Robotics	81.64313694009516	-63.44770855584267	79827
f39daecf8cfc7f5bed5a5dfcc3b34276fc6a74a2	calibration and test of a hyperspectral imaging prototype for intra-operative surgical assistance	tunable filters;software;interfaces;tissues;reflectivity;near infrared;lenses;computing systems;diagnostics;imaging spectroscopy;liquid crystals;hyperspectral imaging;spectral calibration;scanning;data acquisition;calibration;cameras;imaging systems	A significant recent breakthrough in medical imaging is the development of a new non-invasive modality based on multispectral and hyperspectral imaging that can be easily integrated in the operating room. This technology consists of collecting series of images at wavelength intervals of only few nanometers and in which single pixels have spectral information content relevant to the scene under observation. Before becoming of practical interest for the clinician, such system should meet important requirements. Firstly, it should enable real reflectance measurements and high quality images to dispose of valuable physical data after spatial and spectral calibration. Secondly, quick band pass scanning and a smart interface are needed for intra-operative mode. Finally, experimentation is required to develop expert knowledge for hyperspectral image interpretation and result display on RGB screens, to assist the surgeon with tissue detection and diagnostic capabilities during an intervention. This paper is focused mainly on the two first specifications of this methodology applied to a liquid crystal tunable filter (LCTF) based visible and near infrared spectral imaging system. The system consists of an illumination unit and a spectral imager that includes a monochrome camera, two LCTFs and a fixed focal lens. It also involves a computer with the data acquisition software. The system can capture hyperspectral images in the spectral range of 400 – 1100 nm. Results of preclinical experiments indicated that anatomical tissues can be distinguished especially in near infrared bands. This promises a great capability of hyperspectral imaging to bring efficient assistance for surgeons.	data acquisition;display resolution;experiment;focal (programming language);image resolution;image sensor;medical imaging;modality (human–computer interaction);monochrome;multispectral image;pixel;prototype;requirement;self-information	Dorra Nouri;Yves Lucas;Sylvie Treuillet	2013		10.1117/12.2006620	full spectral imaging;near-infrared spectroscopy;computer vision;calibration;imaging spectroscopy;liquid crystal;hyperspectral imaging;interface;lens;reflectivity;optics;data acquisition;physics;remote sensing	Robotics	64.05411082164972	-57.42390039219573	79857
62738130c2cd430f8d3495f499c92c24a0c64546	a ka-band backscatter model function and an algorithm for measurement of the wind vector over the sea surface	meteorological radar;backscatter;airborne radar wind atmospheric techniques atmospheric boundary layer meteorological radar microwave measurement fm radar cw radar backscatter;indexing terms;backscatter sea measurements sea surface radar measurements spaceborne radar airborne radar velocity measurement wind speed surface waves rough surfaces;algorithm;sea surface;cw radar;frequency modulated;microwave measurement;wind speed;wind direction ka band backscatter model function wind vector measurement wind speed measurement sea surface frequency modulated radar demonstrator system continuous wave radar demonstrator system scatterometer mode operation wind vector retrieval;airborne radar;atmospheric techniques;ka band backscatter model;sea wind retrieval algorithm frequency modulated continous wave fm cw radar ka band backscatter model;fm radar;frequency modulated continous wave fm cw radar;wind;radar;atmospheric boundary layer;sea wind retrieval	A Ka-band backscatter model and an algorithm for measurement of the wind speed and direction over the sea surface by a frequency-modulated continous-wave radar demonstrator system operated in scatterometer mode have been developed. To evaluate the proposed algorithm, a simulation of the wind vector retrieval has been performed.	airborne ranger;algorithm;fm broadcasting;ka band;modulation;radar;simulation	Alexey Nekrasov;Peter Hoogeboom	2005	IEEE Geoscience and Remote Sensing Letters	10.1109/LGRS.2004.840613	wind speed;meteorology;index term;atmospheric sciences;backscatter;physics;radar;remote sensing;wind;planetary boundary layer	Mobile	80.57379937919252	-65.4961719740721	79868
87937ea823aaefe7aefe91ae3ca68a047c245887	whittle maximum likelihood estimator for isotropic fractional brownian images	exact stein method whittle maximum likelihood estimator isotropic fractional brownian images fractional brownian motion fbm stochastic fractal process wmle;whittle estimator;image synthesis;indexes;2d fractional brownian motion;periodic embedding;ash;indexes ash;periodic embedding 2d fractional brownian motion whittle estimator image synthesis;stochastic processes brownian motion image processing maximum likelihood estimation	Fractional Brownian motion (fBm) of H parameter is a stochastic fractal process that can be used to create virtual landscapes or to model 2D physical phenomenon. In this communication, we explore the Whittle maximum likelihood estimator (WMLE) to assess the H parameter of isotropic fBm images. We have compared a 1D estimator assessed from the lines increments of the image, to a 2D estimator of the 2D increments of the image. These 2 estimators were tested on 2D fBm generated using the exact Stein method. Results are of high quality. The mean H values are very close to the true ones for both estimators. The standard deviations of the 2D estimates are 2 times smaller than in 1D and should be preferred for practical application as for example texture analysis.	brownian motion;display resolution;fractal	Rachid Harba;Gerard Jacquet;Carlos Wilches;Martha Zequera Diaz;Luis Vilcahuaman	2014	2014 IEEE International Symposium on Signal Processing and Information Technology (ISSPIT)	10.1109/ISSPIT.2014.7300626	database index;mathematical optimization;computer science;calculus;mathematics;fractional brownian motion;statistics	Robotics	61.65786625629111	-69.3484952900067	79912
0c039b318834f2815c5566455269c591087d4436	multi-temporal images classification with evidential fusion of manifold alignment		Multi-temporal remote sensing images classification have attracted more and more attention in the last decade because of a wide range of applications of multi-temporal images in long-term environmental monitoring and land cover change detection and increasing multi-temporal data available. At present, most papers investigated two temporal remote-sensing images classification. In fact, there is lots of distinctive information to be unexploited between two or more temporal images which can enhance classification effect and improve ability of detecting change area. In this paper, we present an evidential fusion framework of manifold alignment to combine more than two multi-temporal remote sensing images. Embedding of multi-groups two temporal images pairs after MA can be intergraded based a layered structure of D-S theory. The proposed method was evaluated using five Landsat 8 images. Results confirmed that the proposed algorithm performed better than those with only two temporal images.	algorithm;manifold alignment;sensor	Meiling Zhang;Tianzhu Liu;Guoming Gao;Yanfeng Gu	2017	2017 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)	10.1109/IGARSS.2017.8127078	manifold alignment;computer vision;artificial intelligence;computer science;change detection;fusion	Vision	74.88345028115367	-59.78776170750449	80003
16794066a9b3aff2b82b599f14f669c52041ad07	video color conceptualization using optimization		Color conceptualization aims to propagate “color concepts” from a library of natural color images to the input image by changing the main color. However, the existing method may lead to spatial discontinuities in images because of the absence of a spatial consistency constraint. In this paper, to solve this problem, we present a novel method to force neighboring pixels with similar intensities to have similar color. Using this constraint, the color conceptualization is formalized as an optimization problem with a quadratic cost function. Moreover, we further expand two-dimensional (still image) color conceptualization to three-dimensional (video), and use the information of neighboring pixels in both space and time to improve the consistency between neighboring frames. The performance of our proposed method is demonstrated for a variety of images and video sequences.	color;conceptualization (information science);image;loss function;mathematical optimization;optimization problem;pixel	Xiaochun Cao;Yujie Zhang;Xiaojie Guo;Yiu-ming Cheung	2013	Science China Information Sciences	10.1007/s11432-013-4934-2	color histogram;computer vision;color quantization;color normalization;color depth;artificial intelligence;mathematics;computer graphics (images)	AI	57.41431075904907	-56.07622420319302	80007
d33421e7c31b409d508da96f1243cb09d18f6958	influence and dependent parameters of terrain undulation to bistatic sar imaging	analytical models;history;sar imaging;3d imaging;radar polarimetry transmitters history analytical models image analysis virtual reality laboratories microwave imaging microwave technology testing;bistatic sar imaging;virtual reality;synthetic aperture radar radar imaging remote sensing by radar;microwave technology;microwave imaging;testing;receivers;remote sensing by radar;doppler effect;terrain undulation;three dimensional displays;radar polarimetry;3d imaging bistatic sar sar imaging;radar imaging;imaging;sar image;transmitters;angular velocity;image analysis;doppler history;3d imaging terrain undulation bistatic sar imaging doppler history;bistatic sar;synthetic aperture radar	As the Doppler history depends both on the transmit range and the receive range in bistatic SAR, those targets, who have the same bistatic range but different locations, will have different doppler history. So the unknown terrain undulation will cause defocusing in bistatic SAR imaging. This paper firstly analyzes which parameters in bistatic configuration affect the defocusing severely, and then shows the simulation results to testify the analysis. Besides, it points out the 3D imaging ability (though very weak) of bistatic SAR based on the defocusing phenomena. And Finally the 3D imaging results are also exhibited.	3d reconstruction;digital history;simulation;stereoscopy;undulation of the geoid	Xiaolan Qiu;Donghui Hu;Chibiao Ding;Daojing Li	2008	IGARSS 2008 - 2008 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2008.4779573	stereoscopy;transmitter;image analysis;synthetic aperture radar;doppler effect;geodesy;angular velocity;virtual reality;software testing;optics;radar imaging;physics;remote sensing	Embedded	79.79560686529342	-66.7048231322801	80039
3c2074d6da01101acae249ac038987b29dd753f9	a similarity metric for edge images	experimental tests;similarity metric;assignment problem;matching problem;weighted matching in bipartite graphs;performance evaluation;edge detection;image matching;image matching edge detection;assignment problem edge images optimal matching edge detection image similarity performance evaluation pixel correspondence metric weighted matching in bipartite graphs;image edge detection pixel image segmentation distortion measurement signal to noise ratio psnr algorithm design and analysis image analysis performance analysis optimal matching;pixel correspondence metric;image similarity	The performance of several discrepancy measures for the comparison of edge images is analyzed and a novel similarity metric aimed at overcoming their problems is proposed. The algorithm finds an optimal matching of the pixels between the images and estimates the error produced by this matching. The resulting Pixel Correspondence Metric (PCM) can take into account edge strength as well as the displacement of edge pixel positions in the estimation of similarity. A series of experimental tests shows the new metric to be a robust and effective tool in the comparison of edge images when a small localization error of the detected edges is allowed.	algorithm;approximation;binary file;conceptual schema;discrepancy function;displacement mapping;edge detection;map;optimal matching;peak signal-to-noise ratio;performance evaluation;pixel;video content analysis	Miguel Segui Prieto;Alastair R. Allen	2003	IEEE Trans. Pattern Anal. Mach. Intell.	10.1109/TPAMI.2003.1233900	computer vision;mathematical optimization;template matching;edge detection;computer science;morphological gradient;pattern recognition;mathematics;assignment problem;canny edge detector	Vision	55.62192554661569	-61.41362961503933	80101
0076dbc26989b05a924ac027cc0a3468aae83cc5	psychophysical assessment of perceived interest in natural images: the roi-d database	databases;image segmentation;image processing;databases image quality visualization observers image segmentation brushes humans;signalbehandling;natural images;observers;image processing research community psychophysical assessment perceived interest roi d database natural image content region of interest photographic images image quality databases;visualization;research and development;signal processing;region of interest;image quality;humans;visual databases image processing research and development;telekommunikation;telecommunications;visual databases;brushes	We introduce a novel region-of-interest (ROI) database for natural image content, the ROI-D database. The database consists of ROI maps created from manual selections obtained in a psychophysical experiment with 20 participants. The presented stimuli were 42 photographic images taken from 3 publicly available image quality databases. In addition to the ROI selections, dominance ratings were recorded that provide further insight into the interest of the selected ROI in relation to the background. In this paper, the experiment is described, the resulting ROI database is analysed, and possible applications of the database are discussed. The ROI-D database is made freely available to the image processing research community.	database;image processing;image quality;map;region of interest	Ulrich Engelke;Hans-Jürgen Zepernick	2011	2011 Visual Communications and Image Processing (VCIP)	10.1109/VCIP.2011.6115973	image quality;computer vision;visualization;image processing;computer science;signal processing;data mining;multimedia;image segmentation;region of interest	Vision	62.33165856414186	-63.864520691005545	80113
226fda137ef2bca6e01f2586a7b172eb21fa5f9d	salient edge and region aware image retargeting	seam carving;saliency detection;higher order statistics;cartoon texture decomposition;image retargeting	The purpose of image retargeting is to automatically adapt a given image to fit the size of various displays without introducing severe visual distortions. The seam carving method can effectively achieve this task and it needs to define image importance to detect the salient context of images. In this paper we present a new image importance map and a new seam criterion for image retargeting. We first decompose an image into a cartoon and a texture part. The higher order statistics (HOS) on the cartoon part provide reliable salient edges. We construct a salient object window and a distance dependent weight to modify the HOS. The weighted HOS effectively protects salient objects from distortion by seam carving. We also propose a new seam criterion which tends to spread seam uniformly in nonsallient regions and helps to preserve large scale geometric structures. We call our method salient edge and region aware image retargeting (SERAR). We evaluate our method visually, and compare the results with related methods. Our method performs well in retargeting images with cluttered backgrounds and in preserving large scale structures. & 2014 Elsevier B.V. All rights reserved.	algorithm;distortion;edge detection;kelly criterion;retargeting;seam carving;thumbnail;window function	Weiwei Wang;Dong Zhai;Tao Li;Xiangchu Feng	2014	Sig. Proc.: Image Comm.	10.1016/j.image.2014.08.001	seam carving;computer vision;computer science;machine learning;mathematics;computer graphics (images)	Vision	57.12865282114187	-61.862155170775814	80115
d6b9a12a171a4cf702e9d510888a3ee0e5a174b2	landslide detection and monitoring with insar technique over upper reaches of jinsha river, china	reservoirs;hydroelectric power generation;terrain factors;rivers;geologic measurements;geology;monitoring;jinpingzi landslide insar technique jinsha river china small baseline subsets;terrain factors monitoring rivers hydroelectric power generation reservoirs geology geologic measurements;landslide detection and monitoring wudongde hydropower station insar;synthetic aperture radar geomorphology geophysical techniques	Three InSAR products and DEM data are involved to detect the potential landslides over Wudongde Hydropower Station Section, Jinsha River. More than ten known and unknown landslides are successfully detected. Meanwhile, Small Baseline Subsets (SBAS) InSAR technique is applied to calculate the time-series deformation of the Jinpingzi landslide. Then, in-situ georobot measurements are used for point-wise comparison. The precision in slide direction is 1.8 cm by comparing with in-situ georobot measurements. At last, the Erpingcun landslide is taken as an example to calculate the vertical and horizontal deformation components by fusing the ascending and descending line-of-sight results.	gnss augmentation;line-of-sight (missile);time series	Chaoying Zhao;Ya Kang;Qin Zhang;Wu Zhu;Bin Li	2016	2016 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)	10.1109/IGARSS.2016.7729744	geomorphology;geology;hydrology;geotechnical engineering;reservoir	Embedded	82.11410696887184	-60.15209269021351	80137
7f369e615a29392fa40469a86993e824ccb89aa6	cost-based closed-contour representations	sensors;digital filtering;algorithms	bstract. This paper presents an efficient technique for linking dge points in order to generate a closed-contour representation. It s based on the consecutive use of global and local schemes. In oth cases it is assumed that the original intensity image, as well as ts corresponding edge map, are given as inputs to the algorithm. he global scheme computes an initial representation by connecting dge points minimizing a global measure based on spatial informaion (3D space). It relies on the use of graph theory and exploits the dge points’ distribution through the given edge map, as well as heir corresponding intensity values. At the same time spurious edge oints are removed by a morphological filter. The local scheme fially generates closed contours, linking open boundaries, by using local cost function that takes into account both spatial and topoogical information. Experimental results with different images, toether with comparisons with a previous technique, are resented. © 2007 SPIE and IS&T. DOI: 10.1117/1.2731799	algorithm;central processing unit;curve fitting;edge enhancement;graph theory;interpolation;loss function;mathematical morphology;minimum spanning tree;openclipart;piecewise linear continuation;polygon mesh;procedural generation;signal-to-noise ratio;systems engineering laboratories	Angel Domingo Sappa;Boris Xavier Vintimilla	2007	J. Electronic Imaging	10.1117/1.2731799	computer vision;mathematical optimization;combinatorics;digital filter;computer science;sensor;mathematics;geometry;algorithm	Vision	53.92443952826469	-57.99492441547794	80153
95a8be54d358e14f0a9a09b3d09108c74aa5275f	real-time computational camera system for high-sensitivity imaging by using combined long/short exposure	video;cameras;imaging systems	In this study, we realize high-resolution (4K-format), small-size (1.43 x 1.43 μm pixel pitch size with a single imager) and high-sensitivity (four times higher sensitivity as compared to conventional imagers) video camera system. Our proposed system is the real time computational camera system that combined long exposure green pixels with short exposure red / blue pixels. We demonstrate that our proposed camera system is effective even in conditions of low illumination.	4k resolution;autostereogram;dot pitch;image resolution;image sensor;pixel;real-time clock;real-time operating system;virtual camera system	Satoshi Sato;Yusuke Okada;Takeo Azuma	2012		10.1117/12.907631	computer vision;camera auto-calibration;camera resectioning;simulation;video;three-ccd camera;computer graphics (images)	Vision	61.504678645873575	-56.53187980406032	80192
87c8b3dae4448f030ae71000379a19f227f0500d	radarsat-1 and -2 government calibration activities	ad 1996;history;antenna measurements;government calibration activities;government;calibration measurements eleven year image quality measurement sar radiometry ad 1996 radarsat 1 mission radarsat 2 mission government calibration activities;radarsat 2 mission;satellite broadcasting;radiometry;remote sensing by radar;sar;radarsat 1 mission;quality;eleven year image quality measurement;image quality;government calibration image quality sea measurements remote monitoring space technology history radiometry satellite broadcasting antenna measurements;radarsat;space technology;remote monitoring;synthetic aperture radar calibration geophysical techniques radiometry remote sensing by radar;calibration measurements;calibration;geophysical techniques;radiometry radarsat sar calibration quality;sea measurements;synthetic aperture radar	This paper examines the calibration activities assumed by the Canadian government within the RADARSAT program, from RADARSAT-1 commissioning in 1996 to the current period, more than one year into the RADARSAT-2 mission. Concepts, operations and results of the RADARSAT-1 calibration plan are reviewed, including the eleven-year image quality measurement history. Government calibration monitoring activities and results for RADARSAT-2 are also presented, indicating that image quality and calibration measurements are better that the specifications.	image quality	Stéphane Côté;Stephanie Muir;Satish Srivastava;Tom Lukowski;Robert K. Hawkins	2009	2009 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2009.5418241	image quality;calibration;synthetic aperture radar;radiometry;geodesy;hydrology;space technology;physics;government;remote sensing	Embedded	80.39499849733559	-63.05737706181316	80213
4c24073b161a046a4609c6138cc4ab9923b4c35e	an em-based hybrid fourier-wavelet image deconvolution algorithm	optimisation;signal to noise ratio em based hybrid fourier wavelet image deconvolution algorithm blurred image restoration expectation maximization based approach wavelet domain sparsity property gaussian scale mixture heavy tailed statistical distribution;image restoration deconvolution gsm wavelet domain noise bayes methods wavelet transforms;image restoration;blur restoration image deconvolution gaussian scale mixture;optimisation image restoration	Blurred image restoration is a longstanding and critical research problem. We addressed this problem using Expectation Maximization (EM) based approach in wavelet domain. The sparsity property of wavelet coefficients is modeled using the class of Gaussian Scale Mixture (GSM), which represents the heavy-tailed statistical distribution, suitable for natural images. The underlying original image and noise parameters are estimated by alternating EM iterations based on available and hidden data sets, where regularization is introduced using an intermediate variable. Although similar formulations have been proposed before but the resulting optimization problems have been computationally demanding, where our formulation is simple to implement and converge in few iterations. Simulation results are presented to demonstrate the quality of our method both visually and in terms of signal to noise ratio improvement.	circuit restoration;coefficient;converge;deconvolution;expectation–maximization algorithm;image restoration;iteration;mathematical optimization;quantum decoherence;signal-to-noise ratio;simulation;sparse matrix;wavelet	Muhammad Hanif;Abd-Krim Karim Seghouane	2013	2013 IEEE International Conference on Image Processing	10.1109/ICIP.2013.6738122	image restoration;computer vision;mathematical optimization;computer science;pattern recognition;mathematics;statistics	Robotics	60.32878472359545	-71.59656879250707	80335
099fbf0ff9dafe6be7d99dc67b4456cf47c09cd6	high-speed transition patterns for video projection, 3d reconstruction, and copyright protection	change detection;structured light;void pantograph;3d reconstruction	This paper presents a camera-projector system which allows for 3D reconstruction and copyright protection. Our approach relies on video-embedded binary patterns whose proportion of black and white at each pixel correspond to the original grayscale value. When projected at a sufficiently high frame rate, these binary patterns are seamless to the observer and look as if a normal video was projected. These patterns have been designed to encode pixel position based on a collection of on-off/ off-on transitions. When the camera is properly adjusted, these temporal transitions can be detected with a change detection method and converted into a 3D surface. However, when filmed by an uncalibrated camera, these transitions are not only unreadable, they induce spatial parasitic patterns in the recorded video. Our method is motivated by two families of applications. First, all applications for which a creative visual work needs to be pre-warped according to a 3D model to prevent geometric distortion when displayed on a dynamic scene. Typical examples include augmented reality and plays involving artistic staging. Second, all applications for which a multimedia copyrighted document (e.g. a movie projected in a theater) shall not be copied integrally with a hand-held digital video camera. The interference between the on-off/off-on transitions and the acquisition rate of most consumer-grade cameras creates disturbing visual artifacts. The system can even be adjusted to make sure a ‘VOID’ pattern appears in the recorded video. In this paper, we present how video frames are encoded and decoded and how the detection (and the nondetection) of temporal transitions allows for 3D reconstruction and copyright protection at the same time. Experimental results reveal that our system computes dense 3D maps at a rate of 11.25 fps and with an accuracy of approximately 71/2 pixel, i.e. 56 microns when in focus and using a standoff distance of 75 cm. Crown Copyright & 2014 Published by Elsevier Ltd. All rights reserved.	3d modeling;3d reconstruction;artifact (software development);augmented reality;crown group;digital camera;digital micromirror device;digital video;disk staging;distortion;encode;embedded system;grayscale;interference (communication);maximal set;mobile device;mobile phone;on-off keying;pattern recognition;pixel;preprocessor;prototype;pyramid (geometry);seamless3d;software development kit;streaming media;traffic enforcement camera;video projector;visual artifact;void pantograph	Jonathan Boisvert;Marc-Antoine Drouin;Pierre-Marc Jodoin	2015	Pattern Recognition	10.1016/j.patcog.2014.06.001	3d reconstruction;computer vision;simulation;structured light;computer science;change detection;statistics;computer graphics (images)	Vision	60.97233148970675	-56.33149821723618	80337
0be6a88061cac1a4cb7fa97ac8d7c0e6ec51d960	reduced reference image quality assessment based on contourlet domain and natural image statistics	histograms;natural image statistics;guassian transform reduced reference image quality assessment natural image statistics contourlet transform hidden markov model gaussian scale mixtures marginal histogram guassian distribution;image coding;image processing;gaussian processes;hidden markov model;reduced reference image quality assessment;transform coding;guassian transform;transforms gaussian distribution gaussian processes hidden markov models image processing;gaussian scale mixture;human subjects;nonlinear distortion;hidden markov models;feature extraction;marginal histogram;image quality;transforms;image quality assessment;image quality statistics data mining hidden markov models feature extraction gaussian distribution testing wavelet domain graphics information science;contourlet transform;guassian distribution;gaussian scale mixtures;reduced reference;gaussian distribution	Reduced-reference (RR) image quality assessment metrics (IQA) evaluate the quality of images by extracting a parameter set from the original reference image and using this set in place of the actual reference image. In this paper, we propose a novel RR-IQA metric based on Contourlet transform. By combining Contourlet transform with a version of the hidden Markov model--Gaussian scale mixtures (GSM), the marginal distributions of neighbor coefficients in the Contourlet domain are modeled. With Contourlet transform as a pre-processing, the marginal histogram of coefficients in each subband can be well fitted by Guassian distribution after divisive normalization transforming. The standard derivation of the fitted Guassian transform and fitted error will be extracted as feature parameters. Experiments show that the proposed metric has good consistency with human subjective perception.	coefficient;contourlet;experiment;hidden markov model;image quality;marginal model;markov chain;preprocessor;round-robin scheduling;scene statistics	Xu Wang;Gangyi Jiang;Mei Yu	2009	2009 Fifth International Conference on Image and Graphics	10.1109/ICIG.2009.44	normal distribution;image quality;computer vision;nonlinear distortion;contourlet;transform coding;feature extraction;computer science;pattern recognition;gaussian process;histogram;mathematics;hidden markov model;statistics	Vision	61.80804616788468	-66.03568289719887	80356
4f8545c5ca5012ac9211f1207b22e8dad4a73368	object-based spatial classification of forest vegetation with ikonos imagery	forest type classification;dissertation;object based image analysis;grey level co occurrence matrix;segmentation quality;ikonos;spatial autocorrelation	Object-based image analysis (OBIA) is employed to classify forest types, including deciduous, evergreen and mixed forests, in a U.S. National Park unit using very high spatial resolution (VHR) IKONOS satellite imagery. This research investigates the effect of scale on segmentation quality and object-based forest type classification. Average local variance and spatial autocorrelation analyses are utilized to determine the quality of segmentation. This research also examines the effect of grey-level co-occurrence matrix (GLCM) texture measures on forest classification results. The comparison of a manual interpretation revealed that three distinct levels of segmentation quality were yielded depending on scale: over-, optimaland under-segmentation. Oversegmentation produced larger number and smaller size of image objects (or segments) than those of manually interpreted forest stands. Under-segmentation generated the smaller number of image objects with larger average size compared with manual interpretation. On the other hand, optimal segmentation with a scale (i.e., scale parameter) of 18 generated similar image objects much resembling manually interpreted forest stands in number and average size. Based on visual assessment, image segments were similar to manually interpreted forest stands in terms of location, shape, number and average size. Statistical analyses supported these results. A graph of average local variance against segmentation scale also indicated an optimal scale of 18. According to spatial autocorrelation analysis, this research found that overand under-segmentations were related to positive autocorrelation, while optimal segmentations achieved lower, or even negative, Moran’s I values. This research discovered that optimal segmentations achieved higher accuracy of forest type classification than overand under-segmentation. In particular, a scale of 19 produced the highest overall classification accuracies when using only spectral bands (79 % in overall accuracy and 0.65 in Kappa). The research found that the incorporation of individual texture measures did not improve OBIA forest classification at scale 19. Instead, the use of multiple texture measures enhanced OBIA forest type classification accuracies to 83 % in overall accuracy and 0.71 in Kappa by disentangling classification confusions. OBIA with multiple GLCM texture measures are expected to be a useful approach to automatically classify forest types. In addition, OBIA will play a role in closely coupling remote sensing and GIS with its ability to create a GIS database to be utilized for further GIS analyses. INDEX WORDS: Object-based image analysis, IKONOS, Segmentation quality, Spatial autocorrelation, Forest type classification, Grey-level co-occurrence matrix texture OBJECT-BASED SPATIAL CLASSIFICATION OF FOREST VEGETATION WITH	autocorrelation;co-occurrence matrix;document-term matrix;geographic information system;image analysis;object-based language;random forest;spatial analysis	Minho Kim	2009			computer vision;geography;cartography;remote sensing	Vision	78.59045751675878	-57.51563538176792	80432
9990403c905193d1d0756d70f21d86a322e9ef32	topographic mapping using radar interferometry: processing techniques	microwave interferometers;topography earth cartography geophysical techniques remote sensing by radar;geological surveys;nonlinear optics;topography earth;radar interferometry;radar maps;measurement;motion compensation;terrain;radar resolution;laser radar;testing;digital elevation model;topography;topographic map;three dimensional;reference point;ultraviolet sources;motion compensated;remote sensing by radar;sar;three dimensional target location algorithm;phase ambiguity;processing algorithm;relief maps;nasa jpl topsar;cartography;height maps;airborne radar;digital elevation models;mapping;computer aided mapping;land surface;topographic radar mapper;optical interferometry;terrain sar land surface cartography measurement technique topography mapping radar interferometry processing algorithm nasa jpl topsar topographic radar mapper motion compensation three dimensional target location algorithm phase ambiguity height maps;radar interferometry laser radar nasa motion compensation testing ultraviolet sources aircraft digital elevation models nonlinear optics optical interferometry;nasa;technique;geophysical techniques;aircraft;synthetic aperture radar	In the summer of 1991 the NASA DC-8 airborne synthetic aperture radar (SAR) system acquired data with the radar configured in a C-band across-track interferometer mode. The data were processed to generate rectified topographic maps. A new processing scheme was developed featuring motion compensation, absolute phase retrieval, and three-dimensional location. The new processor has been tested using data which were acquired with extreme aircraft motion so that performance could be evaluated under adverse conditions. The topographic maps generated by the radar were compared to Digital Elevation Models (DEM’s) derived using conventional optical stereo techniques. In one region we measured rms elevation deviations which were less than the specified DEM accuracy, and in the region covered by the more accurate DEM we found errors varying from 2.2 m rms in relatively flat terrain up to 5.0 m in mountainous areas. The rms difference between radar and DEM elevations over the 6.5 km by 22 km area covered by the more accurate DEM was 3.6 m.	airborne ranger;aperture (software);digital elevation model;google summer of code;map;motion compensation;phase retrieval;radar;rectifier;synthetic data;topography	Søren Nørvang Madsen;Howard A. Zebker;Jan M. Martin	1993	IEEE Trans. Geoscience and Remote Sensing	10.1109/36.210464	computer vision;digital elevation model;geodesy;topography;physics;remote sensing	Graphics	79.06510339067286	-64.3511136524911	80535
8f99b4a422cdc4c86945fb38b54a5cfd8d47adc4	light-field image superresolution using a combined deep cnn based on epi		Light-field cameras can capture spatial and angular information of light with a single exposure, but they suffer from low spatial resolution that limits their performance in practical use. Superresolution (SR) methods have been used to improve spatial resolution of light-field images, but most of them do not take full advantages of the particular structure of the light field. In this letter, we present an SR method to obtain light-field images with high quality and geometric consistency via a combined deep convolutional neural networks (CNNs) framework. The spatial resolution of subaperture images is enhanced separately by a single-image superresolution deep CNN. Then, an epipolar plane image enhancement deep CNN is proposed to restore the geometric consistency of these images. Experimental results show that our method achieves the state-of-the-art performance on both quantitative and qualitative evaluations.	angularjs;artificial neural network;autostereogram;convolutional neural network;display resolution;epipolar geometry;image editing;light field;super-resolution imaging	Yan Yuan;Ziqi Cao;Lijuan Su	2018	IEEE Signal Processing Letters	10.1109/LSP.2018.2856619	mathematics;artificial intelligence;convolutional neural network;feature extraction;pattern recognition;convolution;superresolution;epipolar geometry;light field;qualitative evaluations;image resolution	Vision	56.811034534027996	-57.27216354765435	80563
bd973f6ee4a79b66e1a257e181f1dbb42a2fb318	multipeak aniostropic microfacet model for iridescent surfaces	iridescent surface;microfacet distribution;rendering	In this paper, we propose an efficient iridescent rendering method. The iridescent colors on a surface is caused by the different reflection paths of rays with different wavelengths. In microfacet-based rendering model, the dominant reflection path of an incident light ray is statistically described by the microfacet-distribution function (MDF) of the surface. Therefore, the iridescent colors on the surface can be produced by applying different MDFs to different light wave channels. However, it is unnatural for a surface to have significantly different reflection properties in accordance with the light waves. Taking those into account, the proposed method employs identical and anisotropic microfacet distribution function(MDF) for each light wave channel, and rotates the identical anisotropic MDF of each channel with its own angle to produce iridescent reflection. The method also employs multi-peak MDF for the simulation of diffraction effects, and can be successfully applied to iridecent surface such as CD-ROM and mother-of-pearl (nacre) furniture. The experimental results demonstrate that the method enables interactive applications such as games or virtual reality softwares to plausibly express various cases of iridescent surfaces.	anisotropic diffusion;cd-rom;channel (communications);color;interference (communication);ray (optics);real-time computer graphics;simulation;specular highlight;virtual reality	Young Min Kang;Do-Hoon Lee;Hwan-Gue Cho	2014	Multimedia Tools and Applications	10.1007/s11042-014-2092-1	rendering;computer science;computer graphics (images)	Graphics	62.39621518778832	-52.1417740139871	80586
4f8c07edd5969db0fcc3def418e2d4a9167be5bb	high-quality image interpolation via local autoregressive and nonlocal 3-d sparse regularization	numerical stability;interpolation;image resolution;interpolation adaptation models solid modeling numerical models vectors computational modeling psnr;iterative methods;local nonlocal modeling image interpolation local autoregressive model adaptive 3 d sparse model;autoregressive processes;visual perception autoregressive processes image resolution interpolation iterative methods numerical stability solid modelling;visual perception;visual perception high quality image interpolation local autoregressive regularization nonlocal 3d sparse regularization image interpolation algorithm local autoregressive model ar model nonlocal adaptive 3d sparse model regularized constraints regularization framework local ar regularization interpolation coefficients rough structural similarity low resolution images lr images high resolution images hr images interpolated hr image numerical stability split bregman based iterative algorithm performance improvements objective quality;solid modelling	In this paper, we propose a novel image interpolation algorithm, which is formulated via combining both the local autoregressive (AR) model and the nonlocal adaptive 3-D sparse model as regularized constraints under the regularization framework. Estimating the high-resolution image by the local AR regularization is different from these conventional AR models, which weighted calculates the interpolation coefficients without considering the rough structural similarity between the low-resolution (LR) and high-resolution (HR) images. Then the nonlocal adaptive 3-D sparse model is formulated to regularize the interpolated HR image, which provides a way to modify these pixels with the problem of numerical stability caused by AR model. In addition, a new Split-Bregman based iterative algorithm is developed to solve the above optimization problem iteratively. Experiment results demonstrate that the proposed algorithm achieves significant performance improvements over the traditional algorithms in terms of both objective quality and visual perception.	algorithm;autoregressive model;bregman divergence;coefficient;high-resolution scheme;image resolution;interpolation;iterative method;lr parser;manifold regularization;mathematical optimization;matrix regularization;nonlocal lagrangian;numerical analysis;numerical stability;optimization problem;pixel;quantum nonlocality;sparse matrix;structural similarity	Xinwei Gao;Jian Zhang;Feng Jiang;Xiaopeng Fan;Siwei Ma;Debin Zhao	2012	2012 Visual Communications and Image Processing	10.1109/VCIP.2012.6410749	computer vision;mathematical optimization;image resolution;visual perception;interpolation;stairstep interpolation;machine learning;mathematics;iterative method;nearest-neighbor interpolation;multivariate interpolation;numerical stability;algorithm	Vision	56.67318654547418	-70.54338020453459	80592
a7252afc847c1f85f138d0979d0e40a6c652c502	associations among image assessments as cost functions in linear decomposition: mse, ssim, and correlation coefficient		The traditional methods of image assessment, such as mean squared error (MSE), signal-to-noise ratio (SNR), and Peak signal-to-noise ratio (PSNR), are all based on the absolute error of images. Pearson’s inner-product correlation coefficient (PCC) is also usually used to measure the similarity between images. Structural similarity (SSIM) index is another important measurement which has been shown to be more effective in the human vision system (HVS). Although there are many essential differences among these image assessments, some important associations among them as cost functions in linear decomposition are discussed in this paper. Firstly, the selected bases from a basis set for a target vector are the same in the linear decomposition schemes with different cost functions MSE, SSIM, and PCC. Moreover, for a target vector, the ratio of the corresponding affine parameters in the MSE-based linear decomposition scheme and the SSIM-based scheme is a constant, which is just the value of PCC between the target vector and its estimated vector.	approximation error;basis (linear algebra);basis set (chemistry);coefficient;computer data storage;human visual system model;mean squared error;neural coding;peak signal-to-noise ratio;portable c compiler;proof-carrying code;scheme;singular value decomposition;sparse matrix;structural similarity	Jianji Wang;Nanning Zheng;Badong Chen;José Carlos Príncipe	2017	CoRR		artificial intelligence;basis set;pattern recognition;structural similarity;statistics;affine transformation;correlation coefficient;approximation error;mean squared error;mathematics	Vision	61.638586741437344	-66.12625260885473	80634
258981a9ddcd765a9119bb83e254938a82d384cc	efficient auto-refocusing for light field camera		Abstract Computer vision tasks prefer the images focused at the related objects for a better performance, which requests a Auto-ReFocusing (ARF) function for using light field cameras. However, the current ARF schemes are time-consuming in practice, because they commonly need to render an image sequence for finding the optimally refocused frame. This paper presents an efficient ARF solution for light-field cameras based on modeling the refocusing point spread function (R-PSF). The R-PSF holds a simple linear relationship between refocusing depth and defocus blurriness. Such a linear relationship enables to determine the two candidates of the optimally refocused frame from only one initial refocused image. Because our method only involves three times of refocusing rendering for finding the optimally refocused frame, it is much more efficient than the current “rendering and selection” solutions which need to render a large number of refocused images.	light field	Chi Zhang;Guangqi Hou;Zhaoxiang Zhang;Zhenan Sun;Tieniu Tan	2018	Pattern Recognition	10.1016/j.patcog.2018.03.020	rendering (computer graphics);machine learning;point spread function;light field;artificial intelligence;computer vision;mathematics;light-field camera	Vision	58.124128766691584	-54.58355227717213	80650
4ea2d84c6f67050d274bd5f6bee5c372c57ae032	the reconnection of contour lines from scanned color images of topographical maps based on gpu implementation	graphics processing units image color analysis color lead image segmentation earth remote sensing;open source computer vision opencv compute unified device architecture cuda contour lines graphics processing unit gpu	This paper presents a method for the reconnection of contour lines from scanned color images of topographical maps based on graphics processing unit (GPU) implementation. The extraction of contour lines, which are shown with brown color on USGS maps, is a difficult process due to aliasing and false colors induced by the scanning process and due to closely spaced and intersecting/overlapping features inherent to the map. First, an effective method is presented for contour line reconnection from scanned topographical maps based on CPU. This method considers both the distance and direction between the two broken points of the contour lines. It gets better performance and has high connection rate, but the time complexity of the algorithm is nonlinear with the increasing size of topographical map. Second, the advantage of the massively parallel computing capability of GPU with the compute unified device architecture is taken to improve the algorithm. Finally, a better performance has been achieved based on the open source computer vision library. The experimental results show that the GPU implementation with loop-based patterns achieves a speedup of 1360 $\times$ and the identical result compared with the implementation on CPU.	algorithm;aliasing;cpu (central processing unit of computer system);cuda;central processing unit;color;computation (action);computer graphics;computer vision;contour line;effective method;graphics processing unit;map;nonlinear system;open-source software;parallel computing;scanning;speedup;time complexity;topography	Jianfeng Song;Panfeng Wang;Qiguang Miao;Ruyi Liu;Bormin Huang	2017	IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing	10.1109/JSTARS.2016.2580903	computer vision;color quantization;color image;computer hardware;computer science;real-time computer graphics;general-purpose computing on graphics processing units;physics;computer graphics (images)	Visualization	57.69282153085846	-59.65030570855685	80668
3ad689741a3105b864c057089dcea0d09254b5c0	implementation of the land, atmosphere near real-time capability for eos (lance)	satellite sensor;geophysical image processing;homeland security;forecasting;satellite instruments;microwave limb sounder;imaging spectrometers;natural hazard monitoring;real time systems modis earth observing system nasa ocean temperature;image resolution;atmospheric infrared sounder;advanced microwave scanning radiometer earth observing system;ocean temperature;prototypes;moderate resolution imaging spectroradiometer;aqua satellite;radiometry geophysical image processing image resolution;aura satellite;hazards;satellite applications real time systems;terra satellite;satellite applications;numerical weather forecasting;modis radiometry;radiometry;satellite observation;advanced microwave scanning radiometer;natural hazard;earth observing system eos;microwave sounding;microwave landing systems;satellite sensor land near real time capability atmosphere near real time capability numerical weather prediction numerical weather forecasting natural hazard monitoring disaster relief agriculture homeland security real time system moderate resolution imaging spectroradiometer atmospheric infrared sounder advanced microwave scanning radiometer earth observing system microwave limb sounder ozone monitoring instrument terra satellite aqua satellite aura satellite;modis;agriculture;real time system;ozone monitoring instrument;disaster relief;near real time;infrared;earth observing system;security;nasa;real time operation;atmosphere near real time capability;land near real time capability;disasters;real time systems;numerical weather prediction	The past decade has seen a rapid increase in availability and usage of near real-time data from satellite sensors. Applications have demonstrated the utility of timely data in a number of areas ranging from numerical weather prediction and forecasting, to monitoring of natural hazards, disaster relief, agriculture and homeland security. As applications mature, the need to transition from prototypes to operational capabilities presents an opportunity to improve current near real-time systems and inform future capabilities. This paper presents NASA's effort to implement a near real-time capability for land and atmosphere data acquired by the Moderate Resolution Imaging Spectroradiometer (MODIS), Atmospheric Infrared Sounder (AIRS), Advanced Microwave Scanning Radiometer - Earth Observing System (AMSR-E), Microwave Limb Sounder (MLS) and Ozone Monitoring Instrument (OMI) instruments on the Terra, Aqua, and Aura satellites.	aqua;eos;microwave;numerical analysis;numerical weather prediction;real-time clock;real-time computing;real-time data;real-time transcription;sensor	Karen Michael;Kevin Murphy;Dawn Lowe;Edward J. Masuoka;Bruce Vollmer;Curt Tilmes;Michael Teague;Gang Ye;Martha Maiden;H. Michael Goodman;Christopher Justice	2010	2010 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2010.5650534	natural hazard;meteorology;homeland security;agriculture;real-time operating system;radiometry;image resolution;atmospheric sciences;infrared;forecasting;computer science;information security;numerical weather prediction;physics;remote sensing	Embedded	80.2946334379938	-61.530745143377615	80682
fa60521dabd2b64137392b4885e4d989f4b86430	physics-based generative adversarial models for image restoration and beyond		We present an algorithm to directly solve numerous image restoration problems (e.g., image deblurring, image dehazing, image deraining, etc.). These problems are highly ill-posed, and the common assumptions for existing methods are usually based on heuristic image priors. In this paper, we find that these problems can be solved by generative models with adversarial learning. However, the basic formulation of generative adversarial networks (GANs) does not generate realistic images, and some structures of the estimated images are usually not preserved well. Motivated by an interesting observation that the estimated results should be consistent with the observed inputs under the physics models, we propose a physics model constrained learning algorithm so that it can guide the estimation of the specific task in the conventional GAN framework. The proposed algorithm is trained in an end-to-end fashion and can be applied to a variety of image restoration and related low-level vision problems. Extensive experiments demonstrate that our method performs favorably against the state-of-the-art algorithms.	algorithm;circuit restoration;deblurring;end-to-end principle;experiment;generative adversarial networks;generative model;heuristic;high- and low-level;image restoration;physics engine;well-posed problem	Jinshan Pan;Yang Liu;Jiangxin Dong;Jiawei Zhang;Jimmy S. J. Ren;Jinhui Tang;Yu-Wing Tai;Ming-Hsuan Yang	2018	CoRR		artificial intelligence;pattern recognition;image restoration;machine learning;generative grammar;adversarial system;prior probability;computer science;deblurring;heuristic	Vision	54.911336158201145	-53.84497977685586	80709
0e89995cc7fc1d28b0fa35e5aa07e0fc32ababca	sar image despeckling method using bivariate shrinkage based on dual-tree complex wavelet	geophysical image processing;synthetic aperture radar geophysical image processing geophysical techniques radar imaging;synthetic aperture radar sar;radar imaging;synthetic aperture radar wavelet coefficients noise noise reduction filtering;homogeneous regions sar image despeckling method bivariate shrinkage dual tree complex wavelet speckle suppression method dual tree complex wavelet nongaussian bivariate distribution model complex wavelet coefficients shrinkage function state of the art techniques visual effect look equivalent number;bivariate shrinkage;dual tree complex wavelet;despeckling;dual tree complex wavelet synthetic aperture radar sar despeckling bivariate shrinkage;geophysical techniques;synthetic aperture radar	In this paper, we propose a speckle suppression method for SAR image based on dual-tree complex wavelet. Non-Gaussian bivariate distribution model is proposed by considering the correlation of the real and imaginary parts of complex wavelet coefficients. Based on this model, the shrinkage function of real and imaginary parts of complex coefficients is obtained with the help of maximum a posteriori estimate. Compared with the state-of-the-art techniques through the visual effect and the equivalent number of looks (ENL), experimental results demonstrate that the proposed algorithm obtains good performance in smoothing speckles of homogeneous regions and preserving edges and details effectively.	algorithm;bivariate data;coefficient;imaginary time;noise reduction;smoothing;visual effects;wavelet;zero suppression	Shuang Wang;Jiao Zhou;Jun Li;Biao Hou	2012	2012 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2012.6351087	computer vision;synthetic aperture radar;geology;wavelet packet decomposition;radar imaging;statistics;remote sensing	Robotics	70.48533755892608	-66.3498176184293	80801
7c06b4d496a5b948c0f5fcd59ee4778c2580f32f	moving-target tracking in single-channel wide-beam sar	nonlinear filters;radar tracking;kalman filters;target tracking kalman filters nonlinear filters object detection object tracking radar detection radar imaging radar tracking statistics synthetic aperture radar;tracking filters kalman filtering synthetic aperture radar sar tracking;radar imaging space moving target tracking single channel wide beam sar synthetic aperture radar large antenna beamwidth subaperture sar processing image statistics multitarget unscented kalman filtering moving object detection moving object tracking;radar imaging;object tracking;statistics;radar detection;target tracking;object detection;radar tracking azimuth target tracking doppler effect synthetic aperture radar kalman filters;synthetic aperture radar	A novel method for moving-target tracking using single-channel synthetic aperture radar (SAR) with a large antenna beamwidth is introduced and evaluated using a field experiment and real SAR data. The presented approach is based on subaperture SAR processing, image statistics, and multitarget unscented Kalman filtering. The method is capable of robustly detecting and tracking moving objects over time, providing information not only about the existence of moving targets but also about their trajectories in the image space while illuminated by the radar beam. We have successfully applied the method on an experimental data set using miniature SAR to accurately characterize the movement of vehicles on a highway section in the radar image space.	algorithm;computer;doppler echocardiography;doppler effect;experiment;ground truth;image processing;kalman filter;microsoft outlook for mac;radar;real-time computing;scene statistics;sensor;supercomputer;switzerland;synthetic data;velocity (software development);video post-processing	Daniel Henke;Christophe Magnard;Max Frioud;David Small;Erich Meier;Michael E. Schaepman	2012	IEEE Transactions on Geoscience and Remote Sensing	10.1109/TGRS.2012.2191561	kalman filter;computer vision;continuous-wave radar;radar tracker;radar engineering details;synthetic aperture radar;radar lock-on;fire-control radar;bistatic radar;low probability of intercept radar;video tracking;pulse-doppler radar;3d radar;optics;radar imaging;inverse synthetic aperture radar;side looking airborne radar;remote sensing	Visualization	76.1915659503704	-65.89729581001968	80810
4ffea9c67584eb10b6af2223d6cbfc84a85e9945	aerosols and air quality	jalisco metropolitan area of guadalajara terrestrial remote sensing instrument sunlight aerosol optical thickness solar intensity natural aerosols industrial area urban area air quality indicators ministry of environment for sustainable development;environmental factors;atmosphere photometry environmental factors air pollution;sunlight;atmospheric optics;photometry;air pollution;remote sensing;aerosols urban areas atmospheric measurements terrestrial atmosphere area measurement green products particle measurements;sunlight aerosols air pollution atmospheric optics remote sensing;atmosphere;aerosols	This report presents an analysis that gives an answer about the relation between air quality in the Metropolitan Area of Guadalajara and the aerosols. The data were obtained from a terrestrial remote sensing instrument which provide the maximum voltage of sunlight received. This voltage is needed to calculate the aerosols optical thickness (AOT). The instrument has two channels that measure aerosols depending on its wavelength. The AOT is needed to calculate the solar intensity received after the interaction with the natural aerosols and aerosols generated by industrial and urban areas and its relation with the air quality indicators proportionated from ministry of environment for sustainable development of Jalisco.	terrestrial television;thickness (graph theory)	Carolina Rojas Lafarga;Toatzin Padilla Arias	2012	2012 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2012.6350345	meteorology;atmospheric sciences;photometry;sunlight;atmosphere;optics;atmospheric optics;physics;remote sensing;air pollution	Robotics	82.73201921457023	-62.49468361222279	80910
1b073e4d73affdfb77997bec7db2939a7ca99bc2	study of gnss loss of lock characteristics under ionosphere scintillation with gnss data at weipa (australia) during solar maximum phase	gnss signals;ionosphere scintillation;loss of lock;solar maximum;temporal and spatial characteristics	One of the adverse impacts of scintillation on GNSS signals is the loss of lock status, which can lead to GNSS geometry and visibility reductions that compromise the accuracy and integrity of navigation performance. In this paper the loss of lock based on ionosphere scintillation in this solar maximum phase has been well investigated with respect to both temporal and spatial behaviors, based on GNSS observatory data collected at Weipa (Australia; geographic: 12.45° S, 130.95° E; geomagnetic: 21.79° S, 214.41° E) from 2011 to 2015. Experiments demonstrate that the percentage of occurrence of loss of lock events under ionosphere scintillation is closely related with solar activity and seasonal shifts. Loss of lock behaviors under ionosphere scintillation related to elevation and azimuth angles are statistically analyzed, with some distinct characteristics found. The influences of daytime scintillation and geomagnetic storms on loss of lock have also been discussed in details. The proposed work is valuable for a deeper understanding of theoretical mechanisms of-loss of lock under ionosphere scintillation in global regions, and provides a reference for GNSS applications in certain regions at Australian low latitudes.	behavior;gnss applications;gamma camera;interrupt storm;minimum phase;satellite navigation;sensorineural hearing loss (disorder)	Yang Liu;Lianjie Fu;Jinling Wang;Chunxi Zhang	2017		10.3390/s17102205	elevation;engineering;geomagnetic storm;earth's magnetic field;scintillation;solar maximum;atmospheric sciences;gnss applications;ionosphere;compromise	AI	81.86200692338544	-66.02619376917856	80957
b52488f4e3892a67595315cf2ffc4a5b9c3fa59f	jaxa high-resolution land use/land cover map for central vietnam in 2007 and 2017		Robust remote monitoring of land cover changes is essential for a range of studies such as climate modeling, ecosystems, and environmental protection. However, since each satellite data has its own effective features, it is difficult to obtain high accuracy land cover products derived from a single satellite’s data, perhaps because of cloud cover, suboptimal acquisition schedules, and the restriction of data accessibility. In this study, we integrated Landsat 5, 7, and 8, Sentinel-2, Advanced Land Observing Satellite Advanced Visual, and Near Infrared Radiometer type 2 (ALOS/AVNIR-2), ALOS Phased Array L-band Synthetic Aperture Radar (PALSAR) Mosaic, ALOS-2/PALSAR-2 Mosaic, Shuttle Radar Topography Mission (SRTM), and ancillary data, using kernel density estimation to map and analyze land use/cover change (LUCC) over Central Vietnam from 2007 to 2017. The region was classified into nine categories, i.e., water, urban, rice paddy, upland crops, grassland, orchard, forest, mangrove, and bare land by an automatic model which was trained and tested by 98,000 reference data collected from field surveys and visual interpretations. Results were the 2007 and 2017 classified maps with the same spatial resolutions of 10 m and the overall accuracies of 90.5% and 90.6%, respectively. They indicated that Central Vietnam experienced an extensive change in land cover (33 ± 18% of the total area) during the study period. Gross gains in forests (2680 km2) and water bodies (570 km2) were primarily from conversion of orchards, paddy fields, and crops. Total losses in bare land (495 km2) and paddy (485 km2) were largely to due transformation to croplands and urban & other infrastructure lands. In addition, the results demonstrated that using global land cover products for specific applications is impaired because of uncertainties and inconsistencies. These findings are essential for the development of resource management strategy and environmental studies.	accessibility;climate model;confusion matrix;cover system;data acquisition;download;ecosystem;erosion (morphology);global change;hoa;image resolution;java desktop system;kernel density estimation;l band;map;matthews correlation coefficient;nsa product types;orchard;phased array;population;preprocessor;sensor;shuttle radar topography mission	Phan Cao Duong;Ta Hoang Trung;Kenlo Nishida Nasahara;Takeo Tadono	2018	Remote Sensing	10.3390/rs10091406	land use;geology;remote sensing;land cover	ML	80.991624804565	-56.98361986903015	80999
c93dd2be2676aded3970acde7cd3afa00e3a9ba1	object tracking extensions for accurate recovery of rainfall maps using microwave sensor network	kalman filters;atmospheric techniques;geophysical signal processing;microwave detectors;object tracking;rain;signal reconstruction;cmn;kalman filter;rsl;coherency algorithm;instantaneous rainfall map reconstruction;low temporal resolution;object tracking algorithms;object tracking extensions;rain field temporal property;rain measurements;rainfall map recovery;received signal level measurements;sequential instantaneous rainfall maps;sparse network;spatio-temporal reconstruction;estimation;microwave network;object tracking;rainfall mapping;reconstruction	Recently, diverse methods have been proposed for faithful reconstruction of instantaneous rainfall maps by using received signal level (RSL) measurements from commercial microwave network (CMN), especially in dense networks. The main lacking of these methods is that the temporal properties of the rain field had not been considered, hence their accuracy might be limited. This paper presents a novel method for accurate spatio-temporal reconstruction of rainfall maps, derived from CMN, by using an extension to object tracking algorithms. An efficient coherency algorithm is used, which relates between sequential instantaneous rainfall maps. Then by using Kalman filter, the observed rain maps are predicted and corrected. When comparing the estimates to actual rain measurements, the performance improvement of the rainfall mapping is manifested, even when dealing with a rather sparse network, and low temporal resolution of the measurements. The method proposed here is not restricted to the application of accurate rainfall mapping.	algorithm;kalman filter;map;microwave;signal-to-noise ratio;sparse matrix	Yoav Liberman	2014	2014 22nd European Signal Processing Conference (EUSIPCO)		computer vision;electronic engineering;geography;remote sensing	Robotics	76.91155350391246	-64.44552432145174	81046
a3fdd5cb8a354d7caa3acd93472c3ee43f33fa7b	adaptive image sampling using deep learning and its application on x-ray fluorescence image reconstruction		This paper presents an adaptive image sampling algorithm based on Deep Learning (DL). The adaptive sampling mask generation network is jointly trained with an image inpainting network. The sampling rate is controlled in the mask generation network, and a binarization strategy is investigated to make the sampling mask binary. Besides the image sampling and reconstruction application, we show that the proposed adaptive sampling algorithm is able to speed up raster scan processes such as the X-Ray fluorescence (XRF) image scanning process. Recently XRF laboratory-based systems have evolved to lightweight and portable instruments thanks to technological advancements in both X-Ray generation and detection. However, the scanning time of an XRF image is usually long due to the long exposures requires (e.g., $100 \mu s-1ms$ per point). We propose an XRF image inpainting approach to address the issue of long scanning time, thus speeding up the scanning process while still maintaining the possibility to reconstruct a high quality XRF image. The proposed adaptive image sampling algorithm is applied to the RGB image of the scanning target to generate the sampling mask. The XRF scanner is then driven according to the sampling mask to scan a subset of the total image pixels. Finally, we inpaint the scanned XRF image by fusing the RGB image to reconstruct the full scan XRF image. The experiments show that the proposed adaptive sampling algorithm is able to effectively sample the image and achieve a better reconstruction accuracy than that of the existing methods.		Qiqin Dai;Henry Chopp;Emeline Pouyet;Oliver Cossairt;Marc Walton;Aggelos K. Katsaggelos	2018	CoRR			Vision	58.912803840784896	-58.54838672019319	81070
54580b68d4a75dcdcb202a2fc554becf3bba2e6c	using images combined with dem in classifying forest vegetations	vegetation mapping;object recognition;forestry;image resolution;image classification;spectrum;digital elevation model;china dem forest vegetation classification image resolution forest vegetation recognition forest vegetations conifer forest broadleaf forest mixed forest spectral characteristic changbai mountains image spectral information vegetation type cover digital elevation model elevation information object recognition object classification;geophysical signal processing;terrain mapping;spectral analysis;image resolution forestry vegetation mapping terrain mapping geophysical signal processing object recognition spectral analysis image classification;vegetation mapping remote sensing image resolution image recognition digital elevation models infrared imaging image analysis information analysis geographic information systems geography;vegetation type	More and more different resolution images are used in the process of forests vegetations classifying and recognizing. Most classifying methods, including supervising and non-supervising methods, are based on spectral information and work well in forest vegetations recognizing. But some forest vegetations such as conifer, broadleaf and mixed forest are not distinguished clearly by using these methods just because these vegetations have similar spectral characteristic. In this paper, TM image of Changbai Mountains was obtained and spectral information of the image is analyzed. At the same time, the vegetation types covering the Changbai Mountains are acquired by investigating the region in person. On the other hand, DEM (digital elevation model) is employed as an important criterion in classifying forest vegetations basing on spectral character in this article. The classified results are better than those calculated by original classifying methods. At last, the results are verified by data surveyed on the spot. The results illustrate that DEM is an important factor in classifying forest vegetations distributed by the elevation. Spectrum combined with elevation information is very useful for object recognizing and classifying. Images and DEM have widely practical application and should be used in more research fields.	digital elevation model	Jiangtao Li;Yanmin Shuai;Qijiang Zhu	2004	IGARSS 2004. 2004 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2004.1369762	spectrum;contextual image classification;image resolution;digital elevation model;hydrology;cognitive neuroscience of visual object recognition;physics;remote sensing	Robotics	77.21470158346469	-59.08868640990791	81208
f9c321d5270c1c343e2856e40b6c323475d1df1b	joint nonnegative matrix factorization for hyperspectral and multispectral remote sensing data fusion		This paper presents a new fusion approach producing unobservable fused remote sensing data with high spatial and spectral resolutions. This approach, related to linear spectral unmixing (LSU) techniques, introduces joint nonnegative matrix factorization (JNMF) for combining observable low spatial resolution hyperspectral and high spatial resolution multispectral data. JNMF is applied to synthetic but realistic data generated from real airborne hyperspectral data. Spectral and spatial qualities of fused data are evaluated by frequently used criteria. Experimental results show the low computational cost of the proposed approach, and the good spectral and spatial fidelities of the fused data. Our method also outperforms the recently proposed coupled nonnegative matrix factorization (CNMF) method.	airborne ranger;algorithmic efficiency;computation;computational complexity theory;data model;multispectral image;non-negative matrix factorization;observable;performance;polynomial;synthetic intelligence	Moussa Sofiane Karoui;Yannick Deville;Sarah Kreri	2013	2013 5th Workshop on Hyperspectral Image and Signal Processing: Evolution in Remote Sensing (WHISPERS)	10.1109/WHISPERS.2013.8080718	multispectral image;iterative reconstruction;computer vision;hyperspectral imaging;full spectral imaging;sensor fusion;multispectral pattern recognition;mathematics;artificial intelligence;image resolution;non-negative matrix factorization	AI	68.13819672842979	-66.71088808386801	81278
5a181a7c15c5865411f74ee27c2fe06e3ac34ddb	research on imaging detection based on digital reflection device	detectors;mirrors;pixel imaging imaging detection digital reflection device picture information pixel imaging technique array imaging multispectral imaging dynamic imaging;image coding;imaging;moving object image detection micro mirror spatial resolution;imaging image coding mirrors spatial resolution detectors reflection;reflection;object detection;spatial resolution	In this paper, we apply the pixel imaging to generate images for catching picture information. Pixel imaging technique has great advantages over the array imaging in the cost area. It has been found out that multi-spectral imaging with high resolution can be acquired when compared with traditional methods. In the part of dynamic imaging, some technical issues are discussed for the use of the pixel imaging with digital reflection devices.	dynamic imaging;image resolution;multispectral image;pixel	Xin Wang	2015	2015 International Conference on Intelligent Information Hiding and Multimedia Signal Processing (IIH-MSP)	10.1109/IIH-MSP.2015.31	medical imaging;computer vision;detector;reflection;image resolution;computer science;imaging science;image sensor;point spread function;spectral imaging;imaging spectrometer;computer graphics (images)	Robotics	63.461392686545686	-57.366008523487785	81347
d21dc1f544613409ccdfb12c8c494bbd804e67aa	on the use of a joint spatial-frequency representation for the fusion of multi-focus images	articulo;image fusion;image enhancement;multi focus;evaluation measure;wigner distribution;pseudo wigner distribution;difference set;space frequency;spatial frequency;multi focus image enhancement	This paper shows practical examples of the application of a new image fusion paradigm for achieving a 2-D all in-focus image starting from a set of multi-focus images of a 3-D real object. The goal consists in providing an enhanced 2-D image showing the object entirely in focus. The fusion procedure shown here is based on the use of a focusing pixel-level measure. Such measure is defined in the space-frequency domain through a 1-D pseudo-Wigner distribution. The method is illustrated with different sets of images. Evaluation measures applied to artificially blurred cut and pasted regions have shown that the present scheme can provide equally or even better performance than other alternative image fusion algorithms.		Salvador Gabarda;Gabriel Cristóbal	2005	Pattern Recognition Letters	10.1016/j.patrec.2005.06.003	image restoration;computer vision;discrete mathematics;image processing;wigner distribution function;mathematics;geometry;spatial frequency;image fusion;difference set	Vision	61.150329386372746	-65.9401940314819	81356
0fdfee5d114b098ac60a03b506340424e6524892	detection of wind farm using the relative phase of compact polarimetry sar	the relative phase;ocean compact polarimetry sar the relative phase target detection;wind turbines;wind turbines oceanographic regions radar polarimetry synthetic aperture radar wind;oceanographic regions;wakes wind farm detection relative phase compact polarimetry sar automatic ocean surveillance compact linear polarization high sea state conditions north sea cl pol sar wind turbines quad polarization radarsat 2 images;compact polarimetry sar;radar polarimetry;ocean;target detection;wind;synthetic aperture radar oceans wind turbines marine vehicles wind farms remote sensing surveillance;synthetic aperture radar	This paper discusses the potential for automatic ocean surveillance using compact linear polarization (CL-pol) SAR, with large area coverage, including high sea state conditions. Here, the target is a wind farm in the North Sea. The relative phase derived from CL-pol SAR is employed for detection of the wind turbines, apart from the wind turbines' wakes, based on fine mode quad-polarization (quad-pol) RADARSAT-2 (RS-2) images. The relative phase of CL-pol measurements improves the contrast between the wind turbines and their wakes, because its sign is opposite for these two entities. Therefore, the relative phase of CL-pol SAR provides new light on the problem of operational auto-detection of man-made targets, under high sea state conditions, over large areas.	entity;linear polarization;polarimetry;polarization (waves)	Haiyan Li;William Perrie	2012	2012 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2012.6351859	wind power;meteorology;synthetic aperture radar;atmospheric sciences;geology;physics;remote sensing;wind	Embedded	79.76293959294537	-62.53794661415391	81373
54964bdc70885fee107e021327da2ce8be724f28	the long-term vicarious and cross calibration plan for hyper-spectral imager suite (hisui)	quality assurance;cross calibration;radiometric calibration;sensors;calibration radiometry sensors hyperspectral imaging satellites satellite broadcasting;hisui;hisui hyperspectral multispectral vicarious calibration cross calibration;hyper spectral;multispectral sensors long term vicarious cross calibration plan hyper spectral imager suite multispectral remote sensing earth observation project vnir swir region spatial resolution multispectral imager spectral bands in flight radiometric calibration;satellite broadcasting;radiometry;vicarious calibration;remote sensing infrared imaging;infrared imaging;remote sensing;multispectral images;satellites;next generation;earth observation;multispectral;hyperspectral imaging;hyperspectral image;high frequency;calibration;hyperspectral;spatial resolution	The hyperspectral and multispectral remote sensing mission named HISUI is the Japanese next-generation Earth observation project that will be onboard ALOS-3. HISUI will be composed of hyperspectral imager (185 spectral bands in VNIR-SWIR region with 30 m spatial resolution) and multispectral imager (4 spectral bands in VNIR region with 5 m spatial resolution). To expand use of Earth observation data from HISUI, quality assurance and control of data products is indispensable, therefore, the long-term radiometric calibration has a crucial role. The objective of this research is to establish the techniques and develop the plans for conducting the in-flight radiometric calibration of HISUI with high frequency, reliability, and stability, based on the traditional in-flight radiometric calibration for multispectral sensors.	image sensor;multispectral image	Akihide Kamei;Kazuki Nakamura;Tetsushi Tachikawa;Hirokazu Yamamoto;Ryosuke Nakamura;Satoshi Tsuchida	2011	2011 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2011.6049305	multispectral image;quality assurance;computer vision;hyperspectral imaging;optics;physics;remote sensing	Robotics	80.13454096843927	-62.777371304714094	81378
7da7678882d06a1f93636f58fe89635da5b1dd0c	enhancenet: single image super-resolution through automated texture synthesis		Single image super-resolution is the task of inferring a high-resolution image from a single low-resolution input. Traditionally, the performance of algorithms for this task is measured using pixel-wise reconstruction measures such as peak signal-to-noise ratio (PSNR) which have been shown to correlate poorly with the human perception of image quality. As a result, algorithms minimizing these metrics tend to produce over-smoothed images that lack highfrequency textures and do not look natural despite yielding high PSNR values.,,We propose a novel application of automated texture synthesis in combination with a perceptual loss focusing on creating realistic textures rather than optimizing for a pixelaccurate reproduction of ground truth images during training. By using feed-forward fully convolutional neural networks in an adversarial training setting, we achieve a significant boost in image quality at high magnification ratios. Extensive experiments on a number of datasets show the effectiveness of our approach, yielding state-of-the-art results in both quantitative and qualitative benchmarks.	algorithm;artificial neural network;benchmark (computing);convolutional neural network;experiment;ground truth;image quality;image resolution;peak signal-to-noise ratio;pixel;smoothing;super-resolution imaging;texture synthesis	Mehdi S. M. Sajjadi;Bernhard Schölkopf;Michael Hirsch	2017	2017 IEEE International Conference on Computer Vision (ICCV)	10.1109/ICCV.2017.481	magnification;machine learning;convolutional neural network;artificial intelligence;computer vision;superresolution;image quality;ground truth;computer science;pattern recognition;texture synthesis;image resolution	Vision	62.93815220965868	-65.2315921193362	81404
12a77055d95d3b49f6c4db307a9f7809cf9321b7	preferred color reproduction based on personal histogram transformation	skin color face beautification video processing;computational performance evaluation;histograms;skin color face beautification video processing facial impression histogram transformation;facial impression;performance evaluation;video signal processing;video signal processing image colour analysis video communication;facial color beautification method;real time;user study;skin;video processing;image restoration;user preferences;data mining;personal histogram transformation;histograms face detection image converters skin color humans cameras laboratories shape lighting control;color distribution;skin color;histogram transformation;streaming media;image color analysis;image colour analysis;color reproduction;facial impression histogram transformation;eye luminance;eye luminance color reproduction personal histogram transformation facial color beautification method video communication face detection color distribution computational performance evaluation real time video processing performance;light environment;real time video processing performance;face;face beautification;face detection;video communication	"""We propose a facial color beautification method for video communication. The video-captured face often disappoints us, especially the subjects themselves, because the lighting environment is often poor. Inadequate lighting makes the face look depressed or tired. The best solution is illuminating the face directly with good light, but it is not always possible to realize the perfect environment in everyday situations. Our solution is to retouch the captured video. Our method identifies the distribution of skin color and the eye luminance of a detected face, and converts the color distribution of the entire image by histogram transformation. This method provides three strong points, which are 1) converting video in real-time, 2) beautifying the facial color even if it is captured under inadequate light, and 3) creating a variety of face """"styles"""" by controlling the transformation parameters. We conduct a computational performance evaluation, which shows that our method provides real-time video processing performance. Moreover, we also conduct a user study to reveal the diversity of user preferences and the method's effectiveness in terms of impression improvement. The user study indicates that our method is effective even though user preferences vary widely."""	computation;performance evaluation;real-time clock;real-time locating system;usability testing;user (computing);video processing	Kenji Hara;Atsuhiko Maeda;Hirohito Inagaki;Minoru Kobayashi;Masanobu Abe	2009	IEEE Transactions on Consumer Electronics	10.1109/TCE.2009.5174466	face;image restoration;computer vision;face detection;computer science;histogram;multimedia;video processing;skin;computer graphics (images)	Vision	60.012128418168494	-61.00002519014734	81420
78cd7003b6febea4f0ee13da4c36f76c11f7bfa3	anisotropic interpolation of sparse images	tangent spaces image flow anisotropic interpolation orientation selection;stochastic processes image reconstruction image resolution interpolation sparse matrices;interpolation parallel processing mathematical model image reconstruction anisotropic magnetoresistance estimation convergence;super resolution problem anisotropic interpolation sparse discontinuous field data points image flows stochastic tangent space local stochastic measure angular orientation score function aosf sts local orientation encoding sparse image interpolation reconstruction problems;orientation selection;tangent spaces;image flow;anisotropic interpolation	This paper addresses the problem of interpolating over a sparse, discontinuous field of data points. As data become sparse, interpolation becomes problematic as the connectivity between points is less apparent. Cues such as provided by image flows become difficult to discern as most algorithms for computing flow start to break down in the vicinity of discontinuities, often characteristic of sparse images. The main contribution of this paper is a new algorithm for computing flow, based on a representation we call the Stochastic Tangent Space (STS). It is an aggregate of a local stochastic measure called the Angular Orientation Score Function (AOSF), which encodes local orientation and is robust to discontinuities. We present algorithms for computing the AOSF and STS, and as a proof-of-concept, some preliminary results on sparse image interpolation. These results suggest that the algorithms can generalize well to other challenging reconstruction problems such as super resolution.	aggregate data;algorithm;computer vision;data point;file spanning;grayscale;interpolation;iterative reconstruction;pixel;sampling (signal processing);sparse matrix;structural similarity;super-resolution imaging	Amir Abbas Haji Abolhassani;Roussos G. Dimitrakopoulos;Frank P. Ferrie	2016	2016 13th Conference on Computer and Robot Vision (CRV)	10.1109/CRV.2016.41	spline interpolation;tangent space;computer vision;mathematical optimization;bilinear interpolation;interpolation;stairstep interpolation;sparse approximation;bicubic interpolation;mathematics;geometry;nearest-neighbor interpolation;multivariate interpolation;trilinear interpolation;image scaling	Vision	54.90769173772516	-56.97779025993332	81440
f1a43db9dacee05e095af7181b47b89e586db172	reconstruction capabilities of down-looking airborne gprs: the single frequency case		This paper addresses the problem of imaging shallow buried targets via ground penetrating radar surveys carried out by an airborne platform. The radar system is monostatic and collects scattered field data at a single frequency in down-looking mode and along parallel lines. The data are processed by means of an image formation algorithm based on a microwave tomographic approach valid under Born and start–stop approximations. The goal of the present study is to derive analytical results for the spatial resolution depending on the measurement configuration parameters. The achieved results highlight the peculiar features of the imaging configuration providing useful indications for setting a proper acquisition strategy. Numerical results based on synthetic data are shown to support the analysis of resolution limits.	airborne ranger;algorithm;approximation;image formation;microwave;numerical method;radar;resolution (logic);synthetic data;tomography	Gianluca Gennarelli;Ilaria Catapano;Francesco Soldovieri	2017	IEEE Transactions on Computational Imaging	10.1109/TCI.2017.2669865	computer vision;artificial intelligence;mathematics;radar imaging;radar engineering details;bistatic radar;continuous-wave radar;radar lock-on;man-portable radar;side looking airborne radar;fire-control radar	Robotics	79.24334886690573	-66.21618780238211	81564
2809c911258bf054983cdaad32dd3a28c3240a63	time-based retrieval of soft maps for environmental change detection	glaciar;remote sensing image;maps;time based retrieval;archivos;europa;thematic maps;medio ambiente;change detection;mapa;spatial data;deteccion;information retrieval;query formulation;formulacion pregunta;cartographie;detection;environmental research;classification;formulation question;carte;climate modification;cartografia;glacier;recherche information;environment;archives;alpes;cartography;modificacion clima;environnement;modification climat;recuperacion informacion;europe;environmental change;archives of soft maps;data structure;models;alps	This contribution aims to shortly describe a data structure for creating and managing archives of thematic maps derived by classifying remotely sensed images by soft techniques (soft maps). Unlike traditional models for managing spatial data, the main key feature for query formulation is time, thus improving the investigation on changes occurred in time ranges. The data structure originally extends time-based models to soft maps, thus promoting a retrieval by changes approach also in the monitoring of phenomena for which hard classifications are not sufficiently accurate nor complete.The data structure has been implemented in a system, which is also described, available today in a Windows version. It has been applied to the monitoring of variations of Alpine glaciers.	map	Paola Carrara;Giuseppe Fresta;Anna Rampini	2003	Inf. Process. Manage.	10.1016/S0306-4573(02)00055-9	environmental change;data structure;biological classification;computer science;spatial analysis;glacier;natural environment;change detection;thematic map;statistics	AI	81.47316975225587	-54.080712009759765	81594
cdd76fac9351f6d04487535171282088a552ac01	estimation of the vertical gradient of the atmospheric refractivity from weather radar data using square trihedral corner reflector returns	polarimetric weather radar atmospheric refractivity trihedral corner reflector;phase measurement;backscattered signal level atmospheric refractivity estimation weather radar data square trihedral corner reflector atmospheric refractivity variation radar phase measurement stationary ground based target vertical gradient variation;atmospheric measurements;meteorological radar;refractive index atmospheric measurements meteorology meteorological radar phase measurement radar measurements;remote sensing by radar atmospheric optics meteorological radar refractive index;refractive index;radar measurements;meteorology	The aim of this paper is to characterize the atmospheric refractivity variations from radar phase measurements corresponding to responses from different stationary ground-based targets. Phase variations due to the different heights of the targets and the vertical gradient variation of the refractivity are considered. Square trihedral corner reflectors have been used as test targets to remove the uncertainty about the specific position of the targets and enhance the level of the backscattered signal.	gradient;radar;stationary process	Ruben Nocelo Lopez;Veronica Santalla del Rio	2015	2015 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)	10.1109/IGARSS.2015.7326921	meteorology;radar engineering details;atmospheric sciences;radar horizon;weather radar;refractive index;physics;radar;remote sensing	EDA	81.35731732385658	-65.60141951829169	81631
bbfaafff2e3f42cc07cbaedf054f9372327feefb	the big data processing of hf sky-wave radar sea echo for detection of sea moving targets		A﻿high-frequency﻿(HF)﻿sky-wave﻿radar﻿always﻿monitoring﻿large﻿area﻿of﻿sea﻿surface,﻿for﻿detecting﻿ sea﻿surface﻿moving﻿objects,﻿there﻿must﻿be﻿big﻿data﻿waiting﻿to﻿be﻿processed.﻿A﻿set﻿of﻿data﻿processing﻿ methods﻿were﻿proposed,﻿the﻿successful﻿implementation﻿of﻿HF﻿sky-wave﻿radar﻿on﻿the﻿sea﻿moving﻿ target﻿detection.﻿By﻿setting﻿the﻿HF﻿sky-wave﻿radar﻿parameters,﻿after﻿the﻿initial﻿data﻿processing,﻿the﻿ gotten﻿HF﻿sky-wave﻿radar﻿data﻿were﻿saved.﻿Then﻿a﻿new﻿HF﻿sky-wave﻿radar﻿data﻿processing﻿method﻿ was﻿provided,﻿this﻿method﻿was﻿the﻿so-called﻿three-step﻿detection﻿method﻿(TSTM)﻿which﻿based﻿on﻿ the﻿constant﻿false﻿alarm﻿rate﻿(CFAR)﻿technique.﻿By﻿using﻿TSTM,﻿setting﻿the﻿decision﻿threshold﻿G,﻿ with﻿false﻿alarms﻿being﻿ruled﻿out,﻿a﻿moving﻿target﻿was﻿detected﻿out﻿at﻿last,﻿its﻿speed﻿was﻿calculated.﻿ The﻿results﻿also﻿proved﻿that﻿TSTM﻿could﻿effectively﻿reduce﻿the﻿sea﻿clutter,﻿and﻿greatly﻿lessen﻿the﻿ echo-broadening﻿and﻿double-image﻿caused﻿by﻿ionosphere﻿contamination. KEyWoRDS Big Data, Detection Threshold, HF Sky-Wave Radar, Range-Gate, Target Detection		Qianzhao Lei;Zhensen Wu;Lixin Guo;Junmei Fan;Senlin Geng	2017	IJITWE	10.4018/IJITWE.2017100104	remote sensing;computer science;data mining;radar;skywave;big data;early-warning radar	ML	79.01996029345399	-60.43124088575117	81716
55b897824b15d7b7d0ede8cf9cec4878a1f72550	generating sharp panoramas from motion-blurred videos	sharp panoramas;kernel;video signal processing;joint global motion estimation;motion estimation;image restoration;video signal processing image restoration motion estimation;motion blur;multi frame deblurring sharp panoramas motion blurred videos joint global motion estimation;pixel;duty cycle;motion blurred videos;deconvolution;approximation methods;multi frame deblurring;global motion estimation;cameras;videos cameras kernel motion estimation tracking image sequences layout piecewise linear techniques piecewise linear approximation deconvolution;noise;videos	In this paper, we show how to generate a sharp panorama from a set of motion-blurred video frames. Our technique is based on joint global motion estimation and multi-frame deblurring. It also automatically computes the duty cycle of the video, namely the percentage of time between frames that is actually exposure time. The duty cycle is necessary for allowing the blur kernels to be accurately extracted and then removed. We demonstrate our technique on a number of videos.	deblurring;duty cycle;motion estimation	Yunpeng Li;Sing Bing Kang;Neel Joshi;Steven M. Seitz;Daniel P. Huttenlocher	2010	2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition	10.1109/CVPR.2010.5539938	image restoration;computer vision;kernel;computer science;noise;deconvolution;motion estimation;mathematics;multimedia;duty cycle;pixel;computer graphics (images)	Vision	57.29096891548025	-55.665171847986635	81839
fdb0f4df9a47b9a2a5eebb43c60562c0fac36772	noise analysis for diffraction enhanced imaging	x-ray diffraction;diagnostic radiography;image enhancement;image reconstruction;maximum likelihood estimation;medical image processing;poisson noise;x-ray imaging method;x-ray sources;absorption images;covariance;diffraction enhanced imaging;image-estimation problem;maximum-likelihood solution;noise analysis;reconstruction methods;refraction images;signal-to-noise ratio;wide-angle scatter;optical imaging;maximum likelihood;x ray diffraction;image analysis;light scattering;signal to noise ratio	Herein we present a quantitative noise analysis of diffraction enhanced imaging (DEI), an X-ray imaging method that produces absorption and refraction images, with inherent immunity to wide-angle scatter. DEI produces remarkable images, but requires an X-ray source of very high power; therefore, it has principally been confined to synchrotron studies. Clinical systems currently under development using conventional X-ray sources will be photon-limited. Therefore, it is important that the noise properties of DEI be understood. Herein, we show that the original formulation of DEI, given by Chapman, et al, is the maximum-likelihood solution of the image-estimation problem for the case of Poisson noise. We derive the mean, covariance and signal-to-noise ratio of the images produced by this method, which sheds light on the effect of system parameters on the computed images. We will use these results in future work to derive reconstruction methods that are more optimal in the presence of noise than the original DEI formulation.	radiography;signal-to-noise ratio;x-ray (amazon kindle)	Miles N. Wernick;Jovan G. Brankov;Alejandro Saiz-Herranz	2004	2004 2nd IEEE International Symposium on Biomedical Imaging: Nano to Macro (IEEE Cat No. 04EX821)		image analysis;mathematics;maximum likelihood;optics;physics;statistics	Vision	53.972516151324974	-78.04569952525448	81961
c764cc3ce8b42b456fd9e73a072eb920fd13bf04	adaptive linear spectral mixture analysis	analytical models;adaptation models data models mathematical model image restoration predictive models analytical models fuses;fuses;image restoration;mathematical model;predictive models;neyman pearson detection theory adaptive linear spectral mixture analysis alsma adaptive linear mixing model almm spectral signatures recursive lsma rlsma virtual dimensionality;spectral analysis;adaptation models;virtual dimensionality vd adaptive linear mixing model almm adaptive linear spectral mixture analysis alsma fully constrained least squares fcls linear mixing model lmm linear spectral unmixing lsu recursive linear spectral mixture analysis rlsma;data models	This paper presents a theory of adaptive linear spectral mixture analysis (ALSMA), which can implement LSMA using an adaptive linear mixing model (ALMM) that adjusts and varies with spectral signatures adaptively. In doing so, a recursive LSMA (RLSMA) is developed for ALSMA to allow LSMA to update spectral signature by spectral signature without reprocessing LSMA and also to fuse LSMA results obtained by ALMM using different sets of spectral signatures. To form ALMM, the concept of RLSMA-specified virtual dimensionality is further proposed for ALSMA, which not only can find spectral signatures recursively by RLSMA to adjust ALMM but also can automatically determine the number of spectral signatures via Neyman-Pearson detection theory.	algorithm;antivirus software;computer data storage;detection theory;dynamical system;emoticon;field-programmable gate array;kleene's recursion theorem;parallel computing;recursion;time series;type signature	Chein-I Chang	2017	IEEE Transactions on Geoscience and Remote Sensing	10.1109/TGRS.2016.2620494	fuse;image restoration;data modeling;computer vision;econometrics;machine learning;mathematical model;mathematics;predictive modelling;statistics	Vision	68.10616009681962	-67.89468134983915	82029
a6bb7f77d9a85e53350387a70b7fa76723b24a20	a nonlinear pde-based method for sparse deconvolution	partial differential equation;sparse deconvolution;optimal transportation;65m;continuity equation;iterative regularization;nonlinear pde;mathematical analysis;numerical analysis;35k;fluid dynamics;convolution operator;l1 minimization;numerical experiment;ell_1 minimization;iteration method;transport equation;68w;optimization model	In this paper, we introduce a new nonlinear evolution partial differential equation for sparse deconvolution problems. The proposed PDE has the form of continuity equation that arises in various research areas, e.g. fluid dynamics and optimal transportation, and thus has some interesting physical and geometric interpretations. The underlying optimization model that we consider is the standard l1 minimization with linear equality constraints, i.e. minu{‖u‖1 : Au = f} with A being an under-sampled convolution operator. We show that our PDE preserves the l1 norm while lowering the residual ‖Au − f‖2. More importantly the solution of the PDE becomes sparser asymptotically, which is illustrated numerically. Therefore, it can be treated as a natural and helpful plug-in to some algorithms for l1 minimization problems, e.g. Bregman iterative methods introduced for sparse reconstruction problems in [1]. Numerical experiments show great improvements in terms of both convergence speed and reconstruction quality.	algorithm;bregman divergence;convolution;deconvolution;experiment;iterative method;linear equation;mathematical optimization;navier–stokes equations;nonlinear system;numerical analysis;numerical method;plug-in (computing);sampling (signal processing);scott continuity;sparse matrix;taxicab geometry;thresholding (image processing)	Yu Mao;Bin Dong;Stanley Osher	2010	Multiscale Modeling & Simulation	10.1137/090769399	mathematical optimization;mathematical analysis;numerical analysis;convection–diffusion equation;calculus;continuity equation;mathematics;iterative method;convolution;partial differential equation;physics;quantum mechanics;fluid dynamics	Vision	56.06645729350743	-71.9050372360601	82049
4d4c731a3bb1e7f4fc56a0ae155272805cf9de8e	a population density grid for spain	downscaling;land cover and use information system siose;articulo;corine land cover;population density;dasymetric mapping;siose	This article describes a high-resolution land cover data set for Spain and its application to dasymetric population mapping at census tract level. Eventually, this vector layer is transformed into a grid format. The work parallels the effort of the Joint Research Centre JRC of the European Commission, in collaboration with Eurostat and the European Environment Agency EEA, in building a population density grid for the whole of Europe, combining CORINE Land Cover with population data per commune. We solve many of the problems due to the low resolution of CORINE Land Cover, which are especially visible with Spanish data. An accuracy assessment is carried out from a simple aggregation of georeferenced point population data for the region of Madrid. The bottom-up grid constructed in this way is compared to our top-down grid. We show a great improvement over what has been reported from commune data and CORINE Land Cover, but the improvements seem to come entirely from the higher resolution data sets and not from the statistical modeling in the downscaling exercise. This highlights the importance of providing the research community with more detailed land cover data sets, as well as more detailed population data. The dasymetric grid is available free of charge from the authors upon request.		Francisco J. Goerlich;Isidro Cantarino	2013	International Journal of Geographical Information Science	10.1080/13658816.2013.799283	geography;dasymetric map;downscaling;population density;cartography;remote sensing	HPC	79.27971860356087	-56.781263182687304	82067
19726bcf434d517d2aee7e860df5c34ceeda18e3	motion-extended array synthesis—part ii: experimental validation	imaging prototypes apertures arrays aerospace electronics microwave antenna arrays;synthetic aperture imaging motion extended array synthesis mxas virtual array multistage experimental validation outdoor vehicle based prototype system highly controlled indoor free space prototype system key imaging principles consumer off the shelf components;prototypes;microwave antenna arrays;arrays;synthetic aperture imaging aperture synthesis microwave imaging;imaging;aerospace electronics;synthetic aperture radar geophysical image processing radar imaging remote sensing by radar;apertures	The theory and method for motion-extended array synthesis (MXAS) are described by Kendra. The concept describes how MXAS, for a one- or two-dimensional synthetic array, is realized specifically without recourse to a reference waveform. The essential idea is that the relative motion between (a minimum of) two collection platforms with different velocity vectors can be exploited to create a virtual array, with the size of the virtual array being equivalent to the space swept out by the relative motion of the collectors. This paper describes a multistage experimental validation for MXAS, progressing from a “closed” (nonfree space) RF-domain test bed, to a highly controlled indoor free-space prototype system, and finally to an outdoor, vehicle-based prototype system. Key imaging principles validated include resolution performance relative to theoretical prediction; capability across a range of scenarios, including extreme near field, multipath, and ultralow power; retention of array degrees of freedom for steering nulls; and satisfaction of system requirements for synchronization and precision using consumer off-the-shelf components.	array processing;multipath propagation;multistage amplifier;near field communication;prototype;radio frequency;requirement;synthetic intelligence;system requirements;testbed;triune continuum paradigm;vector processor;velocity (software development);waveform	John R. Kendra;Andrew L. Ashworth;Thomas E. Merryman;Aref Fouladi;Nathan E. Crow	2017	IEEE Transactions on Geoscience and Remote Sensing	10.1109/TGRS.2016.2635655	medical imaging;aperture;prototype;optics;radar imaging;inverse synthetic aperture radar;side looking airborne radar;physics;remote sensing	Visualization	80.13901207735671	-69.08234995432674	82144
1d2c253de598481eb372494f867098ea962cd37b	liver segmentation and 3d modeling based on multilayer spiral ct image		The 3D reconstruction can facilitate the diagnosis of liver disease by making the target easier to identify and revealing the volume and shape much better than 2D imaging. In this paper, in order to realize 3D reconstruction of liver parenchyma, a series of pretreatments are carried out, including windowing conversion, filtering and liver parenchyma extraction. Furthermore, three kinds of modeling methods were researched to reconstruct the liver parenchyma containing surface rending, volume rendering and point rendering. The MC (marching cubes) algorithm based on 3D region growth is proposed to overcome the existence of a large number of voids and long modeling time for the contours of traditional MC algorithms. Simulation results of the three modeling methods show different advantages and disadvantages. The surface rendering can intuitively image on the liver surface modeling, but it cannot reflect the inside information of the liver. The volume rendering can reflect the internal information of the liver, but it requires a higher computer performance. The point rendering modeling speed is quickly compared to the surface rendering and the volume rendering, whereas the modeling effect is rough. Therefore, we can draw a conclusion that different modeling methods should be selected for different requirements.	3d modeling;ct scan;spiral computed tomography	Yanhua Liang;Yongxiong Sun	2017		10.1007/978-3-319-70093-9_75	volume rendering;rendering (computer graphics);3d reconstruction;artificial intelligence;computer performance;filter (signal processing);pattern recognition;computer science;3d modeling;segmentation;marching cubes	Vision	56.228927318066376	-77.66865661837024	82167
22e6e929fd8570434bbdf753c8d8edfe4e417504	decision feedback equalisation for document input	data transmission;image processing;binary image;low pass filter;decision feedback equaliser;dynamic threshold;image enhancement;digital image;inter symbol interference	Obtaining digital images from binary scenes (for example text on paper) and subsequent thresholding does not necessarily lead to high quality binary images. In the imaging process. the binary scene is low-pass filtered and tiny details are therefore smeared. This low-pass filtering is necessary for the subsequent sampling to get a discrete image. In this paper, we bomw from the t h o ry of data transmission, where a similar smearing process occurs: inter symbol interference (ISI) [Qu85]. We have tried to use the theory of decision feedback equalisation @FE) in order to improve the quality of detail of binary images from binary scenes. It will be shown that DFE can be used to obtain a binary image with the same quality of a surface which is 2 to 3 times as large as when straightforward thresholding is used. The method will be compared with dynamic thresholding [Be861 and iterative constrained deblurring [BL90]. Another application of DFE in images is in image enhancement	adder (electronics);algorithmic efficiency;binary image;circa;circuit restoration;computation;deblurring;digital image;display resolution;entry point;finite impulse response;image editing;information sciences institute;interference (communication);iterative method;low-pass filter;pixel;propagation of uncertainty;quantization (signal processing);sampling (signal processing);software propagation;thresholding (image processing)	John Bernsen	1990			computer vision;electronic engineering;binary image;computer science;control theory	Vision	57.22649613581169	-64.84217472333054	82186
2317badcfc3391861346b9c232447a3aac8aa169	an edge-based registration method for locating defects on pcb films		To increase flaw detection rate and decrease false alarm rate, this paper proposed an edge-based image comparison method to detect flaws on PCB films. The detection procedures can be best described as follows: First, histogram equalization is applied to the original image to resolve the problems caused by the variances in illumination. Second, the spatial relationship between test image and golden image is obtained using image registration. Third, transform golden image to register with tested image using spatial coordinate transformation. Finally, subtract golden image from test image to show candidate defects on the result image. The experiment results show that it takes 0.123 second on average for the developed film inspection system to inspect a 780 X 582 image.	flaw hypothesis methodology;histogram equalization;image registration;standard test image	Yih-Chih Chiou;Yu-Kang Zhang	2006			computer science	Vision	55.49906003079795	-59.95506351649892	82244
db7fa33b45846b9ad0322ea310f5c555b697ded7	travel time tomography with adaptive dictionaries		We develop a two-dimensional travel time tomography method, which regularizes the inversion by modeling groups of slowness pixels from discrete slowness maps, called patches, as sparse linear combinations of atoms from a dictionary. We propose to use dictionary learning during the inversion to adapt dictionaries to specific slowness maps. This patch regularization, called the local model, is integrated into the overall slowness map, called the global model. The local model considers small-scale variations using a sparsity constraint, and the global model considers larger-scale features constrained using $\ell _2$ regularization. This strategy in a locally sparse travel time tomography (LST) approach enables simultaneous modeling of smooth and discontinuous slowness features. This is in contrast to conventional tomography methods, which constrain models to be exclusively smooth or discontinuous. We develop a maximum a posteriori formulation for LST and exploit the sparsity of slowness patches using dictionary learning. The LST approach compares favorably with smoothness and total variation regularization methods on densely, but irregularly sampled synthetic slowness maps.	dictionary;machine learning;map;matrix regularization;pixel;sparse matrix;synthetic intelligence;tomography;total variation denoising	Michael J. Bianco;Peter Gerstoft	2018	IEEE Transactions on Computational Imaging	10.1109/TCI.2018.2862644	mathematical optimization;mathematics;slowness;total variation denoising;maximum a posteriori estimation;smoothness;tomography;pixel;linear combination;regularization (mathematics)	Vision	67.15402619048837	-67.52699657606487	82401
27d864dc2708a2804cac20606a8195c5313eed5c	a tensor decomposition-based anomaly detection algorithm for hyperspectral image	tensile stress detection algorithms matrix decomposition detectors hyperspectral imaging computational modeling;tucker decomposition anomaly detection hyperspectral imagery hsi tensor representation;cfar test tensor decomposition based anomaly detection algorithm hyperspectral imagery spectral signature spectral anomaly hsi tensor representation spectral information factor matrix tucker decomposition gaussian noise;tensors gaussian noise hyperspectral imaging remote sensing signal processing	Anomalies usually refer to targets with a spot of pixels (even subpixels) that stand out from their neighboring background clutter pixels in hyperspectral imagery (HSI). Compared to backgrounds, anomalies have two main characteristics. One is the spectral anomaly, i.e., their spectral signatures are different from those associated to their surrounding backgrounds; another is the spatial anomaly, i.e., anomalies occur as few pixels (even subpixels) embedded in the local homogeneous backgrounds. However, most of the existing anomaly detection algorithms for HSI only employed the spectral anomaly. If the two characteristics are exploited in a detection method simultaneously, better performance may be achieved. The third-order (two modes for space and one mode for spectra) tensor representation of HSI has been proved to be an effective tool to describe the spatial and spectral information equivalently; therefore, tensor representation is convenient for exhibiting the two characteristics of anomalies simultaneously. In this paper, a new anomaly detection method based on tensor decomposition is proposed and divided into three steps. Three factor matrices and a core tensor are first estimated from the third-order tensor that is constructed from the HSI data cube by using the Tucker decomposition, and their major and minor principal components (PCs) are more likely to correspond to the spectral signatures of the backgrounds and the anomalies, respectively. In the second step, a reconstruction-error-based method is presented to find the first largest PCs along each mode to eliminate the spectral signatures of the backgrounds as much as possible, and thus, the remaining data may be modeled as the spectral signatures of the anomalies with a Gaussian noise. Finally, a CFAR test is implemented to detect the anomalies from the remaining data. Experiments with simulated, synthetic, and real HSI data sets reveal that the proposed method outperforms those spectral-anomaly-based methods with better detection probability and less false alarm rate.	algorithm;anomaly detection;antivirus software;clutter;constant false alarm rate;data cube;electronic signature;embedded system;experiment;horizontal situation indicator;pixel;sensor;synthetic intelligence;tucker decomposition;type signature	Xing Zhang;Gongjian Wen;Wei Dai	2016	IEEE Transactions on Geoscience and Remote Sensing	10.1109/TGRS.2016.2572400	full spectral imaging;computer vision;machine learning;pattern recognition;mathematics	Vision	70.4283968922447	-66.2147411491976	82534
7427a7b3c1948e732ceb0d8e21af97e45b25a668	prediction of s-npp viirs dnb gains and dark offsets				Chengbo Sun;Thomas Schwarting;Hongda Chen;Kwo-Fu Chiang;Xiaoxiong Xiong	2017		10.1117/12.2274118	remote sensing;geography	NLP	79.25289429199488	-60.27973633291609	82563
50f54775bb79a2e445fe7cd79a15c3d80b58a567	novel edge preserve and depth image recovery method in rgb-d camera systems	tensors computational complexity edge detection image colour analysis optimisation;tensile stress;noise measurement;edge preservation method computation complexity object depth boundary rgb image edge tensor total generalized variation optimization anisotropic diffusion edge tensor edge detection noisy boundary depth map rgb d camera systems depth image recovery method;image edge detection;three dimensional displays;anisotropic magnetoresistance;total generalized variation rgb d camera depth recovery anisotropic diffusion tensor;image edge detection tensile stress cameras anisotropic magnetoresistance three dimensional displays noise measurement optimization;optimization;cameras	We propose a new edge preserve and depth image recovery method in RGB-D camera systems that gives a sharp and accurate object shape from a noisy boundary depth map. The edges of an input depth image are detected and the noisy pixels around them are removed from the depth image. An anisotropic diffusion edge tensor of an input RGB image is computed. Missing depth pixels are then recovered using the total generalized variation optimization with guidance of the RGB-image edge tensor. Thus, accurate object depth boundary can be obtained and well aligned with the object edges in RGB images. The missing or invalid depth pixels in the large hole areas and the thin object can also be recovered. Experimental results show the improvement in edge preserve and depth image recovery with the expense on computation complexity when compared with previous works.	anisotropic diffusion;computation;depth map;image processing;mathematical optimization;pixel	Pongsak Lasang;Sheng Mei Shen;Wuttipong Kumwilaisak	2014	2014 IEEE Fourth International Conference on Consumer Electronics Berlin (ICCE-Berlin)	10.1109/ICCE-Berlin.2014.7034303	computer vision;mathematics;geometry;optics	Robotics	56.01515360971403	-56.58466288355631	82710
09a727b4166389f943a4fdbe9b5f33cd365641d6	hyperspectral imaging and analysis for sparse reconstruction and recognition	forensic document analysis;band selection;multispectral image;face recognition;sparse pca;palmprint recognition;spectral imaging;hyperspectral image	Hyperspectral imaging, also known as imaging spectroscopy, captures a data cube of a scene in two spatial and one spectral dimension. Hyperspectral image analysis refers to the operations which lead to quantitative and qualitative characterization of a hyperspectral image. This thesis contributes to hyperspectral imaging and analysis methods at multiple levels. In a tunable filter based hyperspectral imaging system, the recovery of spectral reflectance is a challenging task due to limiting filter transmission, illumination bias and band misalignment. This thesis proposes a hyperspectral imaging technique which adaptively recovers spectral reflectance from raw hyperspectral images captured by automatic exposure adjustment. A spectrally invariant self similarity feature is presented for cross spectral hyperspectral band alignment. Extensive experiments on an in-house developed multi-illuminant hyperspectral image database show a significant reduction in the mean recovery error. The huge spectral dimension of hyperspectral images is a bottleneck for efficient and accurate hyperspectral image analysis. This thesis proposes spectral dimensionality reduction techniques from the perspective of spectral only, and spatio-spectral information preservation. The proposed Joint Sparse PCA selects bands from spectral only data where pixels have no spatial relationship. The joint sparsity constraint is introduced in the PCA regression formulation for band selection. Application to clustering of ink spectral responses is demonstrated for forensic document analysis. Experiments on an in-house developed writing ink hyperspectral image database prove that a higher ink mismatch detection accuracy can be achieved using relatively fewer bands by the proposed band selection method. Joint Group Sparse PCA is proposed for band selection from spatio-spectral data where pixels are spatially related. The additional group sparsity takes the spatial context into account for band selection. Application to compressed hyperspectral imaging is demonstrated where a test hyperspectral image cube can be reconstructed by sensing only a sparse selection of bands. Experiments on four hyperspectral image datasets including an in-house developed face database verify that the lowest reconstruction error and the highest recognition accuracy is achieved by the proposed compressed sensing technique. An application of the proposed band selection is also presented in an end-to-end framework of hyperspectral palmprint recognition. An efficient representation and binary encoding technique is proposed for selected bands of hyperspectral palmprint which outperforms state-of-the-art in terms of equal error rates on three databases. Acknowledgements I begin by thanking Almighty Allah for making me achieve this milestone. I cannot be more thankful in this world than to my parents, grandparents, siblings and relatives who wished and prayed for my success. I also thank my lovely wife who was a great motivation for me to finish my PhD (and get married!). I am indebted to the unconditional support of my supervisors Dr. Ajmal Mian and Dr. Faisal Shafait, through all times, highs and lows. Without their presence, this dream could not be realized. They trained me to undertake research, provided feedback at regular intervals and navigated me through the course of PhD. I am also grateful to Dr. Yiqun Hu for his co-supervision in the first two years of PhD. I owe a huge thanks to Prof. Robyn Owens who provided an insightful directive on my research, crucial to shape the thesis towards the end. I also thank Dr. Arif Mahmood who reviewed one of my important research contribution. I am grateful to all the anonymous peers who reviewed my numerous submissions to conferences and journals. I am enormously appreciative of the reviewers of this thesis whose timely feedback resulted in great improvement to the final version of this thesis. One of the most important aspect of this thesis was hyperspectral datasets collection. I thank my supervisors for motivating and encouraging me to collect these datasets. I am extremely thankful to Muhammad Uzair for his support in collection of the hyperspectral face dataset. I thank all the participants, who volunteered for research data collection. I am also grateful to the graduate research coordinator and the head of school for their valuable support as mentors. I thank the administration and support staff at the school who deserve due recognition of their efforts. I acknowledge the contribution of the external research groups and universities for making their spectral datasets publicly available for research. They are: Carnegie Mellon University (hyperspectral face data), Hong Kong Polytechnic University (multispectral palm data, hyperspectral palm data and hyperspectral face data), Chinese Academy of Sciences Institute of Automation (multispectral palm data), Columbia University (multispectral image data), Harvard University (hyperspectral image data) and Simon Fraser University (hyperspectral illuminant data). In the end, I would thankfully acknowledge all funding institutions, without whom quality research is inconceivable. This research was sponsored by The Australian Research Council (ARC Grant DP110102399 and DP0881813) and The University of Western Australia (IPRS and UWA Grant 00609 10300067).	automation;binary file;cluster analysis;compressed sensing;data cube;database;dimensionality reduction;directive (programming);end-to-end principle;experiment;fingerprint;holographic principle;image analysis;institute of automation, chinese academy of sciences;multispectral image;my baby (series);pixel;self-similarity;sparse pca;sparse matrix;spectral method;the australian	Zohaib Khan	2014	CoRR		facial recognition system;full spectral imaging;multispectral image;computer vision;sparse pca;computer science;pattern recognition;spectral imaging	Vision	66.54778966975395	-67.1846959147417	82809
3f5bb1533f2d248926cfcae16d89b426d8ae0b3c	image compression via colorization using semi-regular color samples	image sampling;psnr semiregular color samples colorization based image compression sparsely sampling color points jpeg extreme gray scale values;image coding;data compression;image coding transform coding image color analysis psnr gray scale google;image sampling data compression image coding image colour analysis;image compression;image colour analysis	Summary form only given. We improves colorization-based image compression by sparsely sampling color points on a semi-regular grid and compressing them using JPEG. We generate variations of sampling locations based on extreme gray-scale values to to further improve PSNR.	grayscale;image compression;jpeg;peak signal-to-noise ratio;regular grid;sampling (signal processing);semiconductor industry	Changuang Zhang;Hui Fang	2013	2013 Data Compression Conference	10.1109/DCC.2013.112	data compression;image texture;color cell compression;computer vision;color image;image gradient;binary image;image compression;computer science;jpeg;mathematics;multimedia;algorithm;standard test image;computer graphics (images)	Robotics	59.75247046558762	-63.50643705157234	82810
f7bc2a491bc3091f3d0bb9cd8dcf7f86b0491024	a dwt-based deblocking technique based on edge detection and zero masking for reducing blocking effect	dwt;edge detection;jpeg;blocking artifact	To reduce blocking artifacts and enhance visual quality, a simple and efficient DWT-based technique is proposed for post-processing of block-based encoded images. Basically, the technique proposed in this paper removes the blocking artifacts that appear in smooth blocks within the DWT frequency domain. From the experimental results, we see that the proposed technique can easily and effectively remove the blocking artifacts as well as enhance the visual quality of an image. In addition, compared with some other current deblocking methods, the deblocked images created by using the proposed technique have higher PSNR.	deblocking filter;discrete wavelet transform;edge detection	Chwei-Shyong Tsai;Chin-Chen Chang	2003	Fundam. Inform.		computer vision;real-time computing;edge detection;computer science;jpeg;computer graphics (images)	EDA	57.6403180682212	-63.49322193217649	82828
013c15919a55641c532c321ae2f524935bea01ae	an efficient parallel algorithm for multi-scale analysis of connected components in gigapixel images	differential attribute profile;csl model;giga pixel images;spatial signature;connected filters;image decomposition	Differential Morphological Profiles (DMPs) and their generalized Differential Attribute Profiles (DAPs) are spatial signatures used in the classification of earth observation data. The Characteristic-Salience-Leveling (CSL) is a model allowing the compression and storage of the multi-scale information contained in the DMPs and DAPs into raster data layers, used for further analytic purposes. Computing DMPs or DAPs is often constrained by the size of the input data and scene complexity. Addressing very high resolution remote sensing gigascale images, this paper presents a new concurrent algorithm based on the Max-Tree structure that allows the efficient computation of CSL. The algorithm extends the “one-pass” method for computation of DAPs, and delivers an attribute zone segmentation of the underlying trees. The DAP vector field and the set of multi-scale characteristics are computed separately and in a similar fashion to concurrent attribute filters. Experiments on test images of 3.48 to 3.96 Gpixel showed an average computational speed of 59.85 Mpixel per second, or 3.59 Gpixel per minute on a single 2U rack server with 64 opteron cores. The new algorithms could be extended to morphological keypoint detectors capable of handling gigascale images.	32-bit;64-bit computing;bottleneck (engineering);color depth;computation;computational complexity theory;concurrent algorithm;declaration (computer programming);distributed computing;distributed memory;electronic signature;gigapixel image;grayscale;icl distributed array processor;image resolution;input/output;parallel algorithm;parallel computing;pixel;raster data;raster graphics;seamless3d;sensor;server (computing);shared memory;tree structure	Michael H. F. Wilkinson;Martino Pesaresi;Georgios K. Ouzounis	2016	ISPRS Int. J. Geo-Information	10.3390/ijgi5030022	computer vision;computer science;theoretical computer science;data mining	Visualization	68.09108162541308	-53.52910163097755	82869
8bf35b33c13fb7179ecd2371c09f3787dc9f7055	aggressive region growing for speckle reduction in ultrasound images	speckle;median filter;adaptive filtering;regional growth;speckle noise;ultrasound imaging;arithmetic mean;region growing;adaptive filter	In this paper, a post-processing adaptive smoothing technique for speckle reduction is proposed. This method employs an aggressive region growing filtering (ARGF) technique, which grows a maximal-sized homogeneous region about each image pixel and then applies one of two filters to produce the output pixel values. Homogeneous regions are processed with a modified arithmetic mean filter, and regions cent aining resolvable edges are processed with a simple median filter. The performance of the ARGF technique is compared to two other methods. Results of processed images show that the method proposed reduces speckle noise and preserves edge details effectively.	adaptive filter;algorithm;computation;imaging phantom;mean squared error;median filter;nonlinear system;norm (social);pixel;region growing;signal-to-noise ratio	Ruming Yin;Patrick J. Flynn;Shira L. Broschat	2003	Pattern Recognition Letters	10.1016/S0167-8655(02)00174-5	adaptive filter;speckle noise;median filter;computer vision;computer science;machine learning;mathematics;salt-and-pepper noise	Vision	55.82439737079259	-67.02150835975061	82931
c0f78929b9fc139dbd4f1efb3e0e014ac31db3e2	improvement of adaptive-model based decomposition with polarization orientation compensation	geophysical image processing;general volume component polariemtric radar adaptive model based decomposition;vegetation mapping;polariemtric radar;p band airsar image adaptive model based decomposition polarization orientation compensation polarimetric sar decomposition scattering mechanism vegetated terrain vegetation orientation angle isolation topographic polarization orientation compensation tpoc germany;adaptive model based decomposition;radar polarimetry;radar imaging;vegetation mapping geophysical image processing radar imaging radar polarimetry synthetic aperture radar;general volume component;synthetic aperture radar	Polarimetric SAR decomposition has been used extensively because of its capability to identify the strength of each scattering mechanism from polarimetric SAR data. To achieve higher accuracy, one should take into account not only variation of vegetated terrain but also topography under vegetation. In this paper, we firstly isolate vegetation orientation angle from generalized volume scattering component, and then modify a conventional adaptive model-based decomposition by carefully introducing a concept of topographic polarization orientation compensation (TPOC). Finally, experimental validation is conducted by using P-band AIRSAR image of Black Forest in Germany.	polarimetry;polarization (waves);topography	Motofumi Arii;Jakob J. van Zyl;Yunjin Kim	2012	2012 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2012.6351628	computer vision;synthetic aperture radar;geology;optics;radar imaging;inverse synthetic aperture radar;remote sensing	Robotics	78.72859518352416	-62.68513499065192	83241
5b2918359c4e317f4d7891839ba13275dc446374	use of remote sensing and topographic slope in evaluating seismic site-conditions in damascus region	seismology digital elevation models geophysical techniques remote sensing;surface topography;remote sensing wald allen method seismic array microzonation maps amplification factors predominant period subsequent map products slope angle velocity model aster advanced spaceborne thermal emission reflection radiometer topographic slope angle digital elevation model damascus region seismic site conditions;urban areas;estimation;remote sensing;satellites;digital elevation models;damascus topographic slope amplification miscrozonation shear velocity;soil;estimation remote sensing digital elevation models surface topography urban areas soil satellites	The paper discusses the use of remote sensing, digital elevation model and topographic slope angle in evaluating the seismic site-conditions in Damascus region. Thirty meter pixel resolution DEM, derived from the Advanced Spaceborne Thermal Emission Reflection Radiometer (ASTER), was the basis for the slope angle-velocity model and subsequent map products. The predominant period (T0), amplification factors (Fa and Fv) and microzonation maps have produced for Damascus region. The estimated results have been compared with the earlier results. The estimated results using proposed new approach have shown a good agreement to seismic array results. Suggested slope angle-velocity relationship shows a better estimation of site-conditions and microzonation maps compared to the Wald-Allen method.	advanced spaceborne thermal emission and reflection radiometer;digital elevation model;map;pixel;topography;velocity (software development)	Raed Ali Ahmad;Ramesh P. Singh	2016	2016 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)	10.1109/IGARSS.2016.7730509	estimation;digital elevation model;geology;hydrology;physics;satellite;remote sensing	Embedded	82.40358993449516	-61.27366610556659	83300
a959feeef0fcf3229275fdb45ad92ea1fd233979	evaluation of a real-time direct volume rendering system	real time;hardware architecture;ray tracing;user requirements;direct volume rendering;real time rendering;ray casting;volume data	Abstract   The results of evaluating VIRIM, that can be considered as the first real-time direct volume rendering system for ray-casting and volume ray-tracing, is described in this paper. Emphasis is laid on experiences concerning the hardware architecture used with respect to the anticipated application area in medicine. The issues are the flexibility of VIRIM, the restriction to two gradient components only, the duplication of the volume data sets on different modules, the size of the volume data set, the gray-value segmentation tool, and the support of algorithmic improvements like space-leaping, early ray-termination and others. It turned out that flexibility gives the main benefits since it allows easy response to different demands during integration into clinical routines. Given this flexibility the application areas of real-time rendering systems increase dramatically: most of the user requirements focus now not on visualization but on general volume data processing. The most serious bottleneck of VIRIM is the limited volume memory that is integrated in the first prototype. The gray-value segmentation tool turned out to be very valuable. It is highly useful if original,  i.e.  unsegmented data have to be dealt with, and if pre-segmented data have to be investigated. All other benefits and architectural shortcomings are not critical for the application areas of VIRIM,  i.e.  operation simulation and control in head surgery.	real-time clock;rendering (computer graphics);volume rendering	M. De Boer;Jürgen Hesser;A. Gröpl;Thomas Günther;Christoph Poliwoda;Christof Reinhart;Reinhard Männer	1997	Computers & Graphics	10.1016/S0097-8493(96)00082-9	ray tracing;simulation;rendering;computer science;user requirements document;operating system;ray casting;hardware architecture;computer graphics (images)	Visualization	70.1438472704703	-52.350123730136175	83367
fc230412d45ab8372f7c1c961e4969838f6f85b0	evaluation on radiometric capability of chinese optical satellite sensors	virr;radiometric capability;radiometric stability;ccd;mersi;radiometric accuracy;reflective bands	The radiometric capability of on-orbit sensors should be updated on time due to changes induced by space environmental factors and instrument aging. Some sensors, such as Moderate Resolution Imaging Spectroradiometer (MODIS), have onboard calibrators, which enable real-time calibration. However, most Chinese remote sensing satellite sensors lack onboard calibrators. Their radiometric calibrations have been updated once a year based on a vicarious calibration procedure, which has affected the applications of the data. Therefore, a full evaluation of the sensors' radiometric capabilities is essential before quantitative applications can be made. In this study, a comprehensive procedure for evaluating the radiometric capability of several Chinese optical satellite sensors is proposed. In this procedure, long-term radiometric stability and radiometric accuracy are the two major indicators for radiometric evaluation. The radiometric temporal stability is analyzed by the tendency of long-term top-of-atmosphere (TOA) reflectance variation; the radiometric accuracy is determined by comparison with the TOA reflectance from MODIS after spectrally matching. Three Chinese sensors including the Charge-Coupled Device (CCD) camera onboard Huan Jing 1 satellite (HJ-1), as well as the Visible and Infrared Radiometer (VIRR) and Medium-Resolution Spectral Imager (MERSI) onboard the Feng Yun 3 satellite (FY-3) are evaluated in reflective bands based on this procedure. The results are reasonable, and thus can provide reliable reference for the sensors' application, and as such will promote the development of Chinese satellite data.	bands;binary prefix;calibration;calibrator device component;charge-coupled device;elegant degradation;grammatical framework;imager device component;instrument - device;instrument amplifier;jing;kuso;matching;metric;moderate resolution imaging spectroradiometer;numerous;pei-yuan wei;perineuronal satellite cell;real-time clock;satellite communications;satellite viruses;schisandra chinensis;time of arrival;time series;toshiba satellite;trichosanthis;zyweb;sensor (device)	Aixia Yang;Bo Zhong;Shanlong Wu;Qinhuo Liu	2017		10.3390/s17010204	meteorology;optics;charge-coupled device;physics;remote sensing	Mobile	82.09516830168121	-58.975646621177916	83386
22c21727a705318ab5ad7e98a88deb2b5c4be05b	evaluation of multi-resolution satellite sensors for assessing water quality and bottom depth of lake garda	remote sensing reflectance;biological patents;aquatic optics;biomedical journals;text mining;fieldwork activities;europe pubmed central;citation search;citation networks;lake garda;research articles;abstracts;open access;life sciences;clinical guidelines;satellite remote sensing;full text;rest apis;orcids;europe pmc;biomedical research;bioinformatics;literature search	In this study we evaluate the capabilities of three satellite sensors for assessing water composition and bottom depth in Lake Garda, Italy. A consistent physics-based processing chain was applied to Moderate Resolution Imaging Spectroradiometer (MODIS), Landsat-8 Operational Land Imager (OLI) and RapidEye. Images gathered on 10 June 2014 were corrected for the atmospheric effects with the 6SV code. The computed remote sensing reflectance (Rrs) from MODIS and OLI were converted into water quality parameters by adopting a spectral inversion procedure based on a bio-optical model calibrated with optical properties of the lake. The same spectral inversion procedure was applied to RapidEye and to OLI data to map bottom depth. In situ measurements of Rrs and of concentrations of water quality parameters collected in five locations were used to evaluate the models. The bottom depth maps from OLI and RapidEye showed similar gradients up to 7 m (r = 0.72). The results indicate that: (1) the spatial and radiometric resolutions of OLI enabled mapping water constituents and bottom properties; (2) MODIS was appropriate for assessing water quality in the pelagic areas at a coarser spatial resolution; and (3) RapidEye had the capability to retrieve bottom depth at high spatial resolution. Future work should evaluate the performance of the three sensors in different bio-optical conditions.	british informatics olympiad;d&c yellow no. 10, aluminum lake;gradient;image sensor;imager device component;management audit;map;moderate resolution imaging spectroradiometer;sensor (device)	Claudia Giardino;Mariano Bresciani;Ilaria Cazzaniga;Karin Schenk;Patrizia Rieger;Federica Braga;Erica Matta;Vittorio E. Brando	2014		10.3390/s141224116	text mining;medical research;computer science;bioinformatics;remote sensing	Robotics	81.1113230806237	-60.055243246333795	83403
a35dc67ca613e8c765724c846a2b44d96cc9c4ab	algorithmic principles of remote ppg	skin cameras color light sources mathematical model algorithm design and analysis image color analysis;colors biomedical monitoring photoplethysmography remote sensing	This paper introduces a mathematical model that incorporates the pertinent optical and physiological properties of skin reflections with the objective to increase our understanding of the algorithmic principles behind remote photoplethysmography (rPPG). The model is used to explain the different choices that were made in existing rPPG methods for pulse extraction. The understanding that comes from the model can be used to design robust or application-specific rPPG solutions. We illustrate this by designing an alternative rPPG method, where a projection plane orthogonal to the skin tone is used for pulse extraction. A large benchmark on the various discussed rPPG methods shows that their relative merits can indeed be understood from the proposed model.	algorithm;amiga reflections;benchmark (computing);choice behavior;distortion;execution;mathematical model;mathematics;memory, remote;photoplethysmography;point of sale;projection plane;relevance;skin pigmentation;solutions	Wenjin Wang;Albertus C. den Brinker;Sander Stuijk;Gerard de Haan	2017	IEEE Transactions on Biomedical Engineering	10.1109/TBME.2016.2609282	artificial intelligence;computer vision;electronic engineering;computer science;algorithm design;blood volume determination;projection plane	Visualization	67.06910027914815	-73.72878458104712	83473
f99773a18b63a194672301456898d779895fe146	impulse noise removal from color images using adaptive neuro-fuzzy impulse detector	impulse noise;neuro fuzzy;color image		neuro-fuzzy	Umesh Ghanekar;Awadhesh Kumar Singh;Rajoo Pandey	2010		10.1007/978-3-642-14834-7_35	computer vision;color image;impulse noise;computer science;neuro-fuzzy;machine learning	Vision	55.947232516064375	-65.17478635510486	83621
c25bc0a466524e1d1fcc7bb61873d34848f7b5b2	an approach for unsupervised change detection in multitemporal vhr images acquired by different multispectral sensors		This paper proposes an approach for the detection of changes in multitemporal Very High Resolution (VHR) optical images acquired by different multispectral sensors. The proposed approach, which is inspired by a recent framework developed to support the design of change-detection systems for single-sensor VHR remote sensing images, addresses and integrates in the general approach a strategy to effectively deal with multisensor information, i.e., to perform change detection between VHR images acquired by different multispectral sensors on two dates. This is achieved by the definition of procedures for the homogenization of radiometric, spectral and geometric image properties. These procedures map images into a common feature space where the information acquired by different multispectral sensors becomes comparable across time. Although the approach is general, here we optimize it for the detection of changes in vegetation and urban areas by employing features based on linear transformations (Tasseled Caps and Orthogonal Equations), which are shown to be effective for representing the multisensor information in a homogeneous physical way irrespectively of the considered sensor. Experiments on multitemporal images acquired by different VHR satellite systems (i.e., QuickBird, WorldView-2 and GeoEye-1) confirm the effectiveness of the proposed approach.	automatic system recovery;dataflow;feature vector;metric;multispectral image;sensor;time of arrival	Yady Tatiana Solano Correa;Francesca Bovolo;Lorenzo Bruzzone	2018	Remote Sensing	10.3390/rs10040533	computer vision;remote sensing;multispectral image;homogeneous;geology;feature vector;artificial intelligence;change detection	AI	74.55631144058918	-60.449915043780145	83628
cc4f45ad249fa08e938433d97d1ee0ece550ff10	a patch-based non-local means denoising method using hierarchical searching		Non-local means (NLM) is a powerful denoising algorithm that can protect texture effectively. However, the computational complexity of this method is so high that it is difficult to be widely applied in real-time systems. In this paper, we propose a fast NLM denoising algorithm which can product comparable or better result with less computation time than the traditional NLM methods. Some experimental results are provided to demonstrate the superiority of the proposed method.	noise reduction;non-local means	Zhi Dou;Yubing Han;Weixing Sheng;Xiaofeng Ma	2015		10.1007/978-3-662-47791-5_9	pattern recognition	Robotics	57.173680446694625	-68.20734744326552	83674
4ff3449d98261abe30411157b0292496a3e68a9f	pseudo-multiple-exposure-based tone fusion with local region adjustment	detectors;piecewise linear approximation;image fusion display instrumentation image enhancement;dynamic range brightness educational institutions videos piecewise linear approximation detectors;dynamic range independent image quality assessment method pseudo multiple exposure based tone fusion local region adjustment display devices ldr images region based enhancement hdr image generation exposure dependent s curve;tone mapping contrast enhancement high dynamic range hdr inverse tone mapping local region enhancement low dynamic range ldr multiple core system;brightness;dynamic range;videos	New generations of display technologies provide a significantly improved dynamic range compared to conventional display devices. Inverse tone mapping methods have been proposed to convert low dynamic range (LDR) images to HDR ones, and several of them require multiple exposure LDR images of the same scene as inputs. However, the vast majority of LDR images and videos available have only one single exposure. In this paper, we propose a region-based enhancement of the pseudo-exposures to generate an HDR image. First, we present an exposure dependent curve to convert one LDR image to the pseudo-multiple-exposures. Only certain regions of the pseudo-exposures contain noticeable detail information. We propose a region-based enhancement on the pseudo-exposures to boost details in the most distinct region. Thereby the region-enhanced pseudo-exposures are fused into an HDR image. The fused image thus enhances details in the bright region of the dark image and the dark region of the bright image. Compared with other inverse tone mapped methods, our method generates lower total contrast error measured under the dynamic range independent image quality assessment method in [1].	display device;dynamic range;high-dynamic-range rendering;image quality;ldraw;tone mapping	Tsun-Hsien Wang;Cheng-Wen Chiu;Wei-Chen Wu;Jen-Wen Wang;Chun-Yi Lin;Ching-Te Chiu;Jing-Jia Liou	2015	IEEE Transactions on Multimedia	10.1109/TMM.2015.2403612	computer vision;detector;dynamic range;tone mapping;simulation;computer science;brightness;computer graphics (images)	Visualization	60.444730428866926	-61.371450199295865	83848
2cc1f6e41b5d1fdd5884d7652ba1813261b19ffd	on the choice of regularisation parameter in image restoration	noise estimation;image restoration	This paper considers the application of the method of regularisation within the context of the restoration of degraded two-dimensional images. In particular, several recipes for choosing an appropriate degree of regularisation are described and their performance compared with reference to test-images. Some of these methods require the availability of a data-based noise-estimator; a neighbourhood noise estimator is proposed and its performance is discussed.	circuit restoration;image restoration	J. W. Kay	1988		10.1007/3-540-19036-8_59	image restoration;computer vision;computer science	Vision	54.73434389136391	-67.25730118706586	83994
56ba9bb59f06fee8e90c047d43fecb06a6630e25	light diffusion in multi-layered translucent materials	light transport;construccion arquitectura tecnologia ambiental;computacion informatica;layered material;grupo de excelencia;diffusion approximation;layered materials;global illumination;diffusion theory;ciencias basicas y experimentales;multiple scattering;reflection models;reflection model;human skin;rough surface;subsurface scattering;tecnologias;bssrdf;realistic image synthesis	This paper introduces a shading model for light diffusion in multi-layered translucent materials. Previous work on diffusion in translucent materials has assumed smooth semi-infinite homogeneous materials and solved for the scattering of light using a dipole diffusion approximation. This approximation breaks down in the case of thin translucent slabs and multi-layered materials. We present a new efficient technique based on multiple dipoles to account for diffusion in thin slabs. We enhance this multipole theory to account for mismatching indices of refraction at the top and bottom of of translucent slabs, and to model the effects of rough surfaces. To model multiple layers, we extend this single slab theory by convolving the diffusion profiles of the individual slabs. We account for multiple scattering between slabs by using a variant of Kubelka-Munk theory in frequency space. Our results demonstrate diffusion of light in thin slabs and multi-layered materials such as paint, paper, and human skin.		Craig Donner;Henrik Wann Jensen	2005	ACM Trans. Graph.	10.1145/1073204.1073308	subsurface scattering;computer science;optics;global illumination;computer graphics (images)	Graphics	62.17060253107318	-52.08694318929216	84025
30b532af6126cc4037a7d94be84b6593b9a893d3	using spatially varying pixels exposures and bayer-covered photosensors for high dynamic range imaging	wide dynamic range;image processing;indexing terms;high dynamic range imaging;red green and blue;response function;image reconstruction;quantitative analysis;digital image	The method of a linear high dynamic range imaging using solid-state photosensors with Bayer colour filters array is provided in this paper. Using information from neighbour pixels, it is possible to reconstruct linear images with wide dynamic range from the oversaturated images. Bayer colour filters array is considered as an array of neutral filters in a quasimonochromatic light. If the camera’s response function to the desirable light source is known then one can calculate correction coefficients to reconstruct oversaturated images. Reconstructed images are linearized in order to provide a linear high dynamic range images for optical-digital imaging systems. The calibration procedure for obtaining the camera’s response function to the desired light source is described. Experimental results of the reconstruction of the images from the oversaturated images are presented for red, green, and blue quasimonochromatic light sources. Quantitative analysis of the accuracy of the reconstructed images is provided.	algorithm;bayer filter;coefficient;decibel;digital imaging;edge detection;elegant degradation;frequency response;high dynamic range;high-dynamic-range imaging;monochrome;numerical analysis;pixel;programming paradigm;range imaging;wavefront coding	Mikhail V. Konnik	2008	CoRR		iterative reconstruction;computer vision;index term;image processing;computer science;quantitative analysis;digital image;computer graphics (images)	Vision	60.77242906973828	-58.8123041778086	84143
5f1dd54cd0e0932069eaf485cb266438e9dac80d	sar estimation of river surface currents: a sub-aperture analysis approach	motion analysis;azimuth;single look complex;image formation;rivers;geometry;high resolution imaging;radar scattering;radar imaging;sar image;rivers azimuth geometry motion analysis time frequency analysis image analysis high resolution imaging synthetic aperture radar radar imaging radar scattering;image analysis;surface current;time frequency analysis;synthetic aperture radar	We present an alternative approach to the problem of estimating river currents employing single-phase center SAR systems. We use sub-aperture processing of the original singlelook complex SAR imagery to produce a series of image frames. The frame-to-frame displacement of the river surface signature provides a unique means to estimate river currents. We plan to present data from the NRL research X-band SAR system. Keywords-Sub-aperture processing; SAR; target motion; river currents	displacement mapping;estimated;frame (physical object);guided imagery;psychologic displacement	Thomas Ainsworth;Mark A. Sletten;Robert Jansen;J.-S. Lee	2006	2006 IEEE International Symposium on Geoscience and Remote Sensing	10.1109/IGARSS.2006.621	early-warning radar;computer vision;continuous-wave radar;radar engineering details;image analysis;synthetic aperture radar;time–frequency analysis;geodesy;geology;radar horizon;bistatic radar;pulse-doppler radar;interferometric synthetic aperture radar;azimuth;ocean current;radar imaging;inverse synthetic aperture radar;image formation;side looking airborne radar;physics;radar;remote sensing	Vision	76.77641005801222	-65.21278819585814	84152
0ce862b6b70059af0c12c75f8959d59577f6dacc	free viewpoint video synthesis using multi-view depth and color cameras	free viewpoint video;depth camera;ftv;video signal processing;ftv free viewpoint video depth camera up sampling noise reduction;up sampling;video signal processing cameras;noise reduction;cameras image color analysis noise color image segmentation three dimensional displays calibration;cameras;depth map enhnacement free viewpoint video synthesis multiview depth camera color camera viewpoint video generation full pipeline processing	In this paper, we propose an approach for generating free viewpoint videos based on multiple depth and color cameras to resolve issues encountered with traditional color cameras techniques. Our system is based on consumer products such as Kinect that does not provide satisfying quality in terms of resolution and noise. Our contribution is then to propose a full pipeline for enhancing the depth maps and finally improving the quality of the novel viewpoint generated.	depth map;kinect	Kazuki Matsumoto;Chiyoung Song;François de Sorbier;Hideo Saito	2013	IVMSP 2013	10.1109/IVMSPW.2013.6611922	rgb color model;computer vision;multimedia;video processing;three-ccd camera;multiview video coding;computer graphics (images)	Vision	57.73672487627744	-55.08381078744339	84165
9411bbd2b8656ff370ee40fb36a3e257019e9f96	an ℓ1-tv algorithm for deconvolution with salt and pepper noise	minimisation;mumford shah functional;processing;efficient algorithm;acoustics;data;impulse noise;performance;variational techniques;computations;signals;speech;image restoration;salt and pepper noise;total variation regularization;indexing terms;variations;iterative methods;functional imaging;variational approach;deconvolution signal processing algorithms noise reduction iterative algorithms tv image restoration vectors digital signal processing inverse problems mathematical model;image reconstruction;noise reduction;variational techniques deconvolution image denoising iterative methods minimisation;total variation image restoration deconvolution impulse noise;deconvolution;algorithms;formulations;total variation;generalized inverse;alternative variational approach;image denoising;minimisation lscr 1 tv algorithm image deconvolution salt and pepper noise total variation regularization data fidelity image denoising iteratively reweighted norm algorithm alternative variational approach mumford shah regularization;data fidelity;signal processing algorithms;pepper;image deconvolution;images;iteratively reweighted norm algorithm;lscr 1 tv algorithm;noise;functionals;boats;mumford shah regularization	There has recently been considerable interest in applying Total Variation regularization with an ℓ1 data fidelity term to the denoising of images subject to salt and pepper noise, but the extension of this formulation to more general problems, such as deconvolution, has received little attention. We consider this problem, comparing the performance of ℓ1-TV deconvolution, computed via our Iteratively Reweighted Norm algorithm, with an alternative variational approach based on Mumford-Shah regularization. The ℓ1-TV deconvolution method is found to have a significant advantage in reconstruction quality, with comparable computational cost.	algorithm;algorithmic efficiency;computation;deconvolution;elastic net regularization;noise reduction;salt (cryptography);salt-and-pepper noise;total variation denoising;variational principle	Brendt Wohlberg;Paul Rodríguez	2009	2009 IEEE International Conference on Acoustics, Speech and Signal Processing	10.1109/ICASSP.2009.4959819	iterative reconstruction;image restoration;computer vision;minimisation;mathematical optimization;index term;generalized inverse;performance;impulse noise;computer science;noise;deconvolution;speech;processing;machine learning;functional imaging;computation;noise reduction;formulation;mathematics;blind deconvolution;iterative method;total variation;salt-and-pepper noise;data;wiener deconvolution	Vision	56.207167764356846	-72.74968450885635	84170
0568051a83056feeafbc79956d19f20a3271eb84	mapping indicators of riparian vegetation health using ikonos and landsat-7 etm+ image data in australian tropical savannas	vegetation mapping;image resolution;vegetation mapping satellites remote sensing australia remote monitoring spatial resolution floods temperature control water pollution distortion measurement;riparian zone;vegetation mapping geophysical signal processing image resolution image texture;spatial resolution imagery;vegetation indices;riparian vegetation;mapping indicators;mapping properties;adjacent grass;riparian zones;image texture;australian tropical savannas;landsat 7 etm;queensland;geophysical signal processing;ikonos image data;remote sensing;health indicator;environmental health;riparian zone width;species composition;tree crown;riparian environmental health indicators;tree crown riparian vegetation health australian tropical savannas remote sensing keelbottom creek queensland image texture riparian zone width adjacent grass canopies spatial resolution imagery mapping properties riparian environmental health indicators mapping indicators landsat 7 etm ikonos image data;image texture analysis;keelbottom creek;canopies;canopy cover;ikonos;spatial resolution;riparian vegetation health	Government agencies responsible for riparian environments are assessing the utility of remote sensing for mapping and monitoring environmental health indicators. The objective of this work was to evaluate IKONOS and Landsat-7 ETM+ imagery for mapping riparian vegetation health indicators in tropical savannas for a section of Keelbottom Creek, Queensland, Australia. Vegetation indices and image texture from IKONOS data were used for estimating percentage canopy cover (r2=0.86). Pan-sharpened IKONOS data were used to map riparian species composition (overall accuracy=55%) and riparian zone width (accuracy within 4 m). Tree crowns could not be automatically delineated due to the lack of contrast between canopies and adjacent grass cover. The ETM+ imagery was suited for mapping the extent of riparian zones. Results presented demonstrate the capabilities of high and moderate spatial resolution imagery for mapping properties of riparian zones, which may be used as riparian environmental health indicators	image texture;motorola canopy;portable c compiler	Kasper Johansen;Stuart R. Phinn	2004	IGARSS 2004. 2004 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2004.1370611	geology;hydrology;computer science;remote sensing;riparian zone	Robotics	81.09498288447136	-58.09919707560869	84187
53992879fca86faa4ac8d42b76a475c0ab540f29	soil moisture retrieval over grassland using x-band sar data	irrigation;cosmo skymed;terrasar x;cosmo skymed grassland soil moisture irrigation terrasar x;medium incidence angle grassland soil moisture retrieval x band sar data x band radar signal sensitivity irrigated grassland soil condition radar time image series terrasar x image cosmo skymed image high temporal frequency ad 2013 small agricultural region south eastern france satellite data acquisition ground measurement grassland growing cycle soil characteristic evolution monitoring vegetation characteristic evolution monitoring higher soil moisture sensitivity soil moisture biomass hh polarization hv polarization x band radar wave penetration depth dense vegetation high vegetation flooded area image higher detection potential vegetation height gravity irrigation track soil moisture variation sar x band image high spatial resolution;grassland;soil moisture vegetation mapping synthetic aperture radar irrigation sensitivity;soil moisture;vegetation data acquisition floods irrigation soil synthetic aperture radar time series	The objective of this study was to analyze the sensitivity of radar signal in X-band to irrigated grassland soil conditions. Time series of radar (TerraSAR-X and Cosmo-SkyMed) images were acquired at a high temporal frequency in 2013 over a small agricultural region in South Eastern France. Simultaneously to satellite data acquisitions, ground measurements were conducted during several growing cycles of the grassland in order to monitor evolution in soil and vegetation characteristics. Results show that radar signal is clearly dependent on the soil moisture with a higher sensitivity to soil moisture for biomass lower than 1 kg/m2. HH and HV polarizations showed almost similar sensitivity to soil moisture. The penetration depth of the radar wave in X-band was high even for dense and high vegetation: flooded areas were clearly visible on the images with higher detection potential in HH polarization than in HV polarization even for vegetation heights reaching 1 m. These results showed that it is possible to track gravity irrigation and soil moisture variation from SAR X-band images acquired at high spatial resolution and medium incidence angle.	cosmo solvation model;cosmo-rs;incidence matrix;polarization (waves);radar;time series	Mohammad El-Hajj;Nicolas Baghdadi;Gilles Belaud;Mehrez Zribi;Bruno Cheviron;Dominique Courault;François Charron	2014	2014 IEEE Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2014.6947271	water content;geology;hydrology;soil science;irrigation;remote sensing	Embedded	82.0464118496846	-60.647407399678684	84193
7c4e56ead65e3d9357b8b384d187daa2da7c1dfc	reduction of poisson noise in coded exposure photography		Coded exposure photography (CEP), originally proposed by Raskar et al., has been known as one of the promising techniques for motion deblurring. In this area, much efforts have been made for designing a fluttered shutter sequence to shape the spectrum of a uniformly motion-blurred image into an invertible one. Since the duty cycle of the fluttered shutters proposed thus far is generally low, the number of photons entering into an image sensor is reduced, which leads to a large Poisson noise in a low lighting condition. In the existing design techniques for the fluttered shutter, an increase of the duty cycle leads to a failure in the motion deblurring due to the singularities in the Fourier domain. To overcome the difficulty’ this paper proposes a new motion deblurring framework using a higher duty-cycle fluttered shutter and a compressed sensing technique. The experimental results given in this paper demonstrate that the proposed technique is advantageous over a conventional one, in particular in a low lighting condition.		Chihiro Tsutake;Toshiyuki Yoshida	2018	2018 25th IEEE International Conference on Image Processing (ICIP)	10.1109/ICIP.2018.8451407	fourier transform;computer vision;exposure;shot noise;compressed sensing;shutter;duty cycle;image sensor;deblurring;computer science;artificial intelligence	Robotics	63.81051177117632	-54.39960737349555	84194
aed8fddc73c20f178ab17afb78476c49a3310b6b	first demonstration of airborne sar with nonlinear fm chirp waveforms	synthetic aperture radar airborne radar chirp modulation fm radar matched filters radar interference;azimuth;frequency modulation;chirp;rma airborne sar synthetic aperture radar system impulse response multiplicative noise nlfm chirp waveform nonlinear frequency modulation chirp waveform power spectral density radar matched filter output signal to noise ratio modified range migration algorithm;shape;synthetic aperture radar sar nonlinear frequency modulation nlfm chirp range migration algorithm rma sidelobe reduction signal to noise ratio snr;signal to noise ratio;time frequency analysis;synthetic aperture radar chirp frequency modulation time frequency analysis azimuth shape signal to noise ratio;synthetic aperture radar	For synthetic aperture radar (SAR), a system impulse response with low sidelobes is very important because sidelobes may interfere with the nearby scatterers and contribute to multiplicative noise. It is well known that a nonlinear frequency-modulation (NLFM) chirp waveform can shape the signal's power spectral density and provide a radar matched filter output with lower sidelobes without loss of the signal-to-noise ratio when compared with the linear frequency-modulation chirp. These advantages make the NLFM waveform to be a promising candidate to improve the imaging quality for SAR. However, so far, to our knowledge, there is no real application of NLFM waveforms for SAR. This letter, for the first time, demonstrates the airborne SAR experiment using an NLFM waveform. In the underlying experiment, the construction of the NLFM signal is investigated and a modified range migration algorithm (RMA) is developed to adapt it for focusing the NLFM SAR data. Both simulation and experimental results exhibit the promising power of the NLFM chirp and show the accuracy of the proposed modified RMA.	airborne ranger;algorithm;chirp;curve fitting;fm broadcasting;matched filter;modulation;multiplicative noise;nonlinear system;polynomial;revolution in military affairs;signal-to-noise ratio;simulation;spectral density;synthetic data;waveform	Wei Wang;Robert Wang;Zhimin Zhang;Yunkai Deng;Ning Li;Lili Hou;Zhihuo Xu	2016	IEEE Geoscience and Remote Sensing Letters	10.1109/LGRS.2015.2508102	frequency modulation;synthetic aperture radar;time–frequency analysis;shape;azimuth;optics;inverse synthetic aperture radar;signal-to-noise ratio;chirp;side looking airborne radar;physics;remote sensing	Vision	76.12694473673808	-67.23570578885294	84243
556e98b646a65535ae192b14800f624704ae09e5	a novel inpainting-based layered depth video for 3dtv	mvd representation inpainting based layered depth video 3dtv ldv 3d video data representation mvv system three dimensional television video plus depth sequence multiview video plus depth representation;three dimensional displays pixel cameras stereo vision image color analysis streaming media tv;three dimensional television;mvv system;video plus depth sequence;layered depth video;three dimensional;3d video data representation;inpainting;streaming media;video communication three dimensional television;three dimensional displays;image color analysis;pixel;3dtv dibr inpainting layered depth video;stereo vision;mvd representation;3dtv;ldv;tv;video communication;dibr;inpainting based layered depth video;cameras;multiview video plus depth representation;base layer	Layered Depth Video (LDV) is recognized as a promising 3D video data representation for supporting advanced 3D video services required in Multiview Video (MVV) systems such as Three-Dimensional Television (3DTV). This representation consists of one full or central view in the form of a video-plus-depth sequence as the main layer, and additional enhancement layers including residual texture and depth data that represent side views. LDV is thus both a derivative of and an alternative to Multiview Video-plus-Depth (MVD) representation by only transmit one full view with associated residual data over the channel. There is a risk, however, of residual data information rapidly increasing as the distance between the center view and side views increases. This occurs when parts of the central view are not visible in the side views, leaving blank spots called disocclusions. These disocclusions may grow larger, which increases the amount of residual data that needs to be sent with the main layer. In this paper, we address the residual layer generation problem. We propose an inpainting-based LDV generation method to reduce the amount of residual data to send by retrieving the missing pixels from the main layer. In the proposed method, we take into account the depth information by distinguishing between foreground and background parts of the scene, at low complexity, during the texture and structure propagation stage of the inpainting process. Experimental results demonstrated the effectiveness of the proposed method.	3d computer graphics;3d television;algorithm;coherence (physics);computation;data (computing);depth map;digital video;futures studies;information theory;inpainting;pixel;preprocessor;software propagation	Ismaël Daribo;Hideo Saito	2011	IEEE Transactions on Broadcasting	10.1109/TBC.2011.2125110	three-dimensional space;computer vision;computer science;stereopsis;multimedia;pixel;inpainting;computer graphics (images)	Vision	57.16594016801675	-55.10670911057842	84293
f5cb146b32dbe144569edadd89b89f1b58589aca	single image dehazing with white balance correction and image decomposition	single ima;color fidelity;image resolution;imaging model;dehazing;会议论文;imaging device;auto white balance;color temperatures;illumination images;dark channel priors;computer vision;imaging process;image enhancement;image resolution computer vision image colour analysis image enhancement;high quality;image colour analysis;ill posed natures;benchmark datasets;image color analysis lighting mathematical model equations estimation helium imaging;image decomposition;exposure adjustment;color distortions;color fidelity single image dehazing white balance correction image decomposition awb autowhite balance color temperature color distortion reflex lightness image ambience illumination image dark channel prior based algorithm haze free image	Single image dehazing has been a challenging problem due to its ill-posed nature. While most of the existing single image based dehazing algorithms address this issue by introducing certain assumptions and priors into the haze imaging model, the imaging process of imaging devices has been seldom taken into account, such as white balance and metering. In general, consumer photos are taken with AWB (Auto White Balance). Hence, color temperature in a foggy scenario may not be correctly detected, which results in color distortion; and the whole scene looks brighter, which leads to under-exposure during the imaging process. In this paper, we propose to handle these two issues by applying white balance correction and decomposing an image into two component images, reflex lightness image and ambience illumination image. We devise an improved dark channel prior based algorithm to dehaze the reflex lightness image and the exposure adjustment is estimated from the ambience illumination image. Finally, a high quality haze- free image is produced by refining the brightness of the preliminarily dehazed image with the estimated exposure adjustment. Experimental results with a benchmark dataset demonstrate that our approach outperforms the state-of-the-art, in terms of contrast and color fidelity.	algorithm;autostereogram;benchmark (computing);color balance;display resolution;distortion;well-posed problem	Renjie He;Zhiyong Wang;Hao Xiong;David Dagan Feng	2012	2012 International Conference on Digital Image Computing Techniques and Applications (DICTA)	10.1109/DICTA.2012.6411690	image restoration;computer vision;image resolution;computer science;color balance;computer graphics (images)	Vision	57.602418813526874	-58.65287441221954	84379
3d32c8e7e1dd2b1f551ae7b46a0f203508e2db63	exploiting shading cues in kinect ir images for geometry refinement	refinement kinect ir infrared;cameras lighting geometry three dimensional displays light sources mathematical model estimation;conference;refinement;kinect;ir;infrared;geometry refinement shading cues exploitation kinect ir image capture kinect fusion kinect ir camera image filtering natural indoor illumination near light ir shading model surface normal albedo lighting direction light source surface points multiview information surface details estimation 3d mesh model;mesh generation cameras image capture image fusion information filtering infrared imaging	In this paper, we propose a method to refine geometry of 3D meshes from the Kinect fusion by exploiting shading cues captured from the infrared (IR) camera of Kinect. A major benefit of using the Kinect IR camera instead of a RGB camera is that the IR images captured by Kinect are narrow band images which filtered out most undesired ambient light that makes our system robust to natural indoor illumination. We define a near light IR shading model which describes the captured intensity as a function of surface normals, albedo, lighting direction, and distance between a light source and surface points. To resolve ambiguity in our model between normals and distance, we utilize an initial 3D mesh from the Kinect fusion and multi-view information to reliably estimate surface details that were not reconstructed by the Kinect fusion. Our approach directly operates on a 3D mesh model for geometry refinement. The effectiveness of our approach is demonstrated through several challenging real-world examples.	adaptive mesh refinement;bidirectional reflectance distribution function;displacement mapping;display resolution;illumination (image);kinect;lambertian reflectance;list of common shading algorithms;mathematical optimization;microsoft research;normal (geometry);refinement (computing);specular highlight;vertex normal	Gyeongmin Choe;Jaesik Park;Yu-Wing Tai;In-So Kweon	2014	2014 IEEE Conference on Computer Vision and Pattern Recognition	10.1109/CVPR.2014.501	computer vision;infrared;computer science;refinement;computer graphics (images)	Vision	59.19868167535656	-53.479052336191096	84385
53e0fe2c9d7d30d74d2f36b0346e25c55d08e168	vao++: practical volumetric ambient occlusion for games		Ambient occlusion is one of the commonly used methods to increase visual fidelity in real-time rendering applications. We propose several extensions of the recently introduced volumetric ambient occlusion method. These extensions improve the properties of the methods with a particular focus on the quality vs performance tradeoff and wide applicability in contemporary games. We describe the implementation of the proposed algorithm and its extensions. We implemented the method as a camera effect within the Unity game engine. The results show that our implementation compares favorably with the standard ambient occlusion in Unity both in terms of quality and speed.		Jakub Boksanský;Adam Pospísil;Jirí Bittner	2017		10.2312/sre.20171192	rendering (computer graphics);fidelity;ambient occlusion;computer graphics (images);computer vision;computer science;artificial intelligence	HCI	65.04054893808949	-52.138408339284595	84429
e1d1e4a29379520fc5014e52b178f61ae1dab94c	"""remote sensing and geology """"surveying the geosphere"""""""				Konstantinos G. Nikolakopoulos	2015	Earth Science Informatics	10.1007/s12145-015-0226-2	geomorphology;geology;soil science;physical geography	HCI	79.80422134187921	-60.175376657104415	84455
82a98846489bf2aa244f06bbcc89f5a7c9a3ec77	adaptive deblocking algorithm based on image characteristics for low bit-rate video	low pass filter;low bit rate video;video coding;deblocking filter;mpeg 4 video;motion compensated prediction;blocking artifact;post processing	Reconstructed images in low bit-rate video coding often have visually annoying artifacts, such as blocking artifacts and corner outliers, usually due to block-based quantization and motion-compensated prediction. In this paper, we propose an adaptive deblocking algorithm based on local image characteristics. We remove ringing artifacts using a simple low-pass filter in the preprocessing. Among four filtering modes, an appropriate filter is selected adaptively, removing noticeable blocking artifacts in flat areas, while preserving details without blurring in highly complex areas. The proposed filter contains a non-symmetric filter a corner outlier removal filter. Simulation results show the effectiveness of the proposed deblocking algorithm in objective and subjective quality compared with those of the MPEG-4 deblocking filter.	algorithm;deblocking filter	Jongho Kim;Minseok Choi;Jechang Jeong	2007		10.1007/978-3-540-74260-9_66	computer vision;real-time computing;low-pass filter;computer science;deblocking filter;root-raised-cosine filter;filter;video post-processing;computer graphics (images)	Vision	57.65696437548365	-63.37175402061701	84517
a82b4b2ad1bd56cc9629bbfdd22ab0633510eb44	image quality assessment based on multi-scale representation of structure	difference of gaussian;image quality assessment;information content weighting;full reference	This paper presents an image quality assessment algorithm using representation of image structures in scale space. It is based on the finding that difference-of-Gaussian (DoG) can capture the structures of an image with flexibility and it is sensitive to image degradations. A set of DoG signals are first computed to represent the image structures at different octaves and scales. A coarse quality score is calculated by comparing the DoG signals between the reference image and test image at each octave and scale. Information content weighting is then incorporated to generate the final quality score. Experimental results on five singly-distorted databases and the Laboratory for Image and Video Engineering (LIVE) multiply-distorted database show the effectiveness of the proposed method.	image quality	Jiansheng Qian;Dong Wu;Leida Li;Deqiang Cheng;Xuesong Wang	2014	Digital Signal Processing	10.1016/j.dsp.2014.06.009	image quality;image texture;computer vision;feature detection;image processing;computer science;difference of gaussians;gaussian blur;data mining;information retrieval;standard test image	Graphics	61.41623201157481	-65.30743561390564	84540
d78faf20691d16b6e1d98687d843dfccb5ad9572	impact of non-local filtering on 3d reconstruction from tomographic sar data		In this paper, we introduce two spatially adaptive covariance filtering methods and evaluate their effect on scatterer separation and height estimation from tomographic SAR. The first one was previously introduced for polarimetric data and uses pixel similarities based on Riemannian distances between covariance matrices. The second one is a new method extending the previous one to patch-based similarities. We show the importance of spatial adaptivity in covariance estimation by comparing the 3D reconstructions obtained with our nonlocal filters and the boxcar filter. Our experiments on simulated and L-band experimental data show the ability of the non-local filters to improve the height estimation and scatterer separation in layover areas thanks to their smoothing and edge preserving properties.	3d reconstruction;aharonov–bohm effect;experiment;l band;pixel;polarimetry;smoothing	Olivier D'Hondt;Carlos López-Martínez;Stéphane Guillaso;Olaf Hellwich	2017	2017 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)	10.1109/IGARSS.2017.8127495	experimental data;computer vision;filter (signal processing);3d reconstruction;iterative reconstruction;artificial intelligence;computer science;estimation of covariance matrices;smoothing;tomography;covariance	Vision	67.62543287501228	-66.81897830324816	84553
5754934974db9060eed1f264427b328f853f9c04	on the gray-scale inverse hough transform	line detection;gray scale hough transform;hough transform	This paper proposes a gray-scale inverse Hough transform (GIHT) algorithm which is combined with a modified gray-scale Hough transform (GHT). Given only the data of the Hough transform (HT) space and the dimensions of the image, the GIHT algorithm reconstructs correctly the original gray-scale image. As a first application, the GIHT is used for line detection and filtering according to conditions associated with the polar parameters, the size and the gray-scale values of the lines. The main advantage of the GIHT is the determination of the image lines exactly as they appear, i.e. pixel by pixel and with the correct gray-scale values. To avoid the quantization effects in the accumulator array of the GHT space, inversion conditions are defined which are associated only with the image size. The GIHT algorithm consists of two phases, which are the collection of gray-scale information stored in the accumulator array and the extraction of the final image according to the filtering conditions. Experimental results confirm the efficiency of the proposed method. q 2000 Elsevier Science B.V. All rights reserved.	accumulator (computing);algorithm;binary image;edge detection;grayscale;hough transform;image resolution;parity (physics);pixel	Anastasios L. Kesidis;Nikos Papamarkos	2000	Image Vision Comput.	10.1016/S0262-8856(99)00067-0	arithmetic;hough transform;computer vision;computer science;scale-invariant feature transform;mathematics;computer graphics (images)	Vision	55.33553518459829	-62.4625650643214	84579
536fd779c89b9fd3e3f6cf4438ac537c007136a2	mapping urban areas by performing systematic correction for dmsp/ols nighttime lights time series in china from 1992 to 2008	geophysical image processing;time series geophysical image processing light sources remote sensing;information extraction;urban areas satellites remote sensing systematics data mining cities and towns earth;information extraction dmsp ols nighttime lights china urban areas;time series;data mining;remote sensing;satellite remote sensing;urban area;urban expansion urban area mapping dmsp ols nighttime lights time series china ad 1992 to 2008 stable lights data defense meteorological satellite program operational line scan system urban area extraction;digital number;light sources;spatial resolution;urban expansion	The stable lights data in the Version 4 Nighttime Lights Time Series Dataset gained by the Defense Meteorological Satellite Program's Operational Line-scan System can't be used to map urban areas directly because the data has no on-board calibration and many unstable lights are also included in the data. So the systematic correction was performed before the urban areas extraction according to the characteristic of stable lights data in China from 1992 to 2008 with the 1 km spatial resolution. It was found that, with systematic correction, the stable lights data could be strictly comparable from one year to the next, in which the remarkable differences of digital number values and the unstable lights were removed effectively. Besides, the urban areas extracted from the stable lights data could be used to describe the real process of urban expansion in China from 1992 to 2008.	control theory;on-board data handling;ordinary least squares;time series	Zhifeng Liu;Chunyang He;Yang Yang	2011	2011 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2011.6049485	image resolution;computer science;time series;information extraction;remote sensing	Robotics	81.22304582890075	-60.219310464855155	84582
205b5a491a82c36f81dfcd41b64e7127d083cfdd	augmented lagrangian based reconstruction of non-uniformly sub-nyquist sampled mri data	transform;shearlet;compressed sensing;cell size;fourier transform;thresholding algorithm;augmented lagrangian method;augmented lagrangian methods;conjugate gradient;mr imaging;linear inverse problems;mri reconstruction;technology and engineering;image quality;resolution enhancement;non uniform fourier transform;design;optimal algorithm;augmented lagrangian;signal recovery	MRI has recently been identified as a promising application for compressed-sensing-like regularization because of its potential to speed up the acquisition while maintaining the image quality. Thereby non-uniform k-space trajectories, such as random or spiral trajectories, are becoming more and more important, because they are well suited to be used within the compressed-sensing (CS) acquisition framework. In this paper, we propose a new reconstruction technique for non-uniformly sub-Nyquist sampled k-space data. Several parts make up this technique, such as the non-uniform Fourier transform (NUFT), the discrete shearlet transform and a augmented Lagrangian based optimization algorithm. Because MRI images are real-valued, we introduce a new imaginary value suppressing prior, which attenuates imaginary components of MRI images during reconstruction, resulting in a better overall image quality. Further, a preconditioning based on the Voronoi cell size of each NUFT data point speeds up the conjugate gradient optimization used as part of the optimization algorithm. The resulting algorithm converges in a relatively small number of iterations and guarantees solutions that fully comply to the imposed constraints. The results show that the algorithm is applicable not only to sub-Nyquist sampled k-space reconstruction, but also to MR image fusion and/or resolution enhancement. & 2011 Elsevier B.V. All rights reserved.	algorithm;augmented lagrangian method;cs games;cs-cipher;cell (microprocessor);chroma subsampling;compressed sensing;conjugate gradient method;data point;experiment;image fusion;image quality;imaginary time;iteration;mathematical optimization;preconditioner;shearlet;speedup;spiral model;voronoi diagram	Jan Aelterman;Hiêp Quang Luong;Bart Goossens;Aleksandra Pizurica;Wilfried Philips	2011	Signal Processing	10.1016/j.sigpro.2011.04.033	computer vision;mathematical optimization;augmented lagrangian method;mathematics;geometry	Vision	56.57561939528891	-73.69705616955451	84680
cfc46dfc4fe31e94183ef992ae63731b2af069b8	geometric integration of heterogeneous models for multisatellite image positioning	geophysical image processing;least squares approximations;geometric correction;mathematical model equations satellites ray tracing accuracy space vehicles systematics;geometric integration;least squares approximations geophysical image processing;rational function model rfm;rational function model;direct georeferencing;least squares collocation lsc;ray tracing;least squares collocation geometric integration heterogeneous model multisatellite image positioning geometrical consistency georeferencing rational function model collocation based block adjustment collocation aided block adjustment cbba method caba method;mathematical model;direct georeferencing dg;rational function model rfm direct georeferencing dg least squares collocation lsc;article;least squares collocation;space vehicles	With the wider availability of more and more images acquired from various satellites, the integration of different orientation models for different sensors has become an important task in order to maintain geometrical consistency. This study combines two heterogeneous geometric correction models, namely, direct georeferencing and the rational function model for multisatellite image positioning. Two types of adjustment models, collocation-based block adjustment (CBBA) and collocation-aided block adjustment (CABA), are proposed to reach the goal. The former is based on the concept that the adjustment is first performed on individual images, and then, all images are integrated. Discrepancies are compensated for by least squares collocation (LSC). The latter method entails simultaneous adjustment of the two heterogeneous models followed by LSC. Experimental results indicate that the proposed method can significantly improve the geometric accuracy as well as reduce geometric discrepancies between images. We also demonstrate that CABA is slightly better than CBBA.	collocation;function model;geometric integrator;global positioning system;least squares;multiresolution analysis;polynomial and rational function modeling;sensor	Liang-Chien Chen;Wen-Chi Chang;Tee-Ann Teo	2012	IEEE Transactions on Geoscience and Remote Sensing	10.1109/TGRS.2011.2176739	ray tracing;econometrics;mathematical optimization;mathematical model;mathematics;statistics	Robotics	75.91559099791125	-59.639474949044946	84692
6b215f037fa65802dfef82c7d01cda41f0db7a7e	effect of high frame rates on 3d video quality of experience	conferences consumer electronics;high frame rates effect mos values mean opinion score values quality of experience 3d video quality;three dimensional television quality of experience stereo image processing;three dimensional television;quality of experience;stereo image processing	In this paper, we study the effect of 3D videos with increased frame rates on the viewers' quality of experience. We performed a series of subjective tests to seek the subjects' preferences among videos of the same scene at four different frame rates: 24, 30, 48, and 60 frames per second (fps). Results revealed that subjects clearly prefer higher frame rates. In particular, Mean Opinion Score (MOS) values associated with the 60 fps 3D videos were 55% greater than MOS values of the 24 fps 3D videos.	3d film;jumbo frame	Amin Banitalebi-Dehkordi;Mahsa T. Pourazad;Panos Nasiopoulos	2014	2014 IEEE International Conference on Consumer Electronics (ICCE)	10.1109/ICCE.2014.6776065	subjective video quality;computer vision;computer science;multimedia;computer graphics (images)	Visualization	63.65571206718429	-62.832431098146	84710
6862734b103e74219dffe3f5e8dde8f5fb4a91b7	wavelet image restoration and regularization parameters selection	akaike information criterion;bepress selected works;degree of freedom;regularization method;wavelet image restoration lasso aic;image restoration;aic;wavelet transforms;aic wavelet image restoration lasso;parameter selection;image deblurring wavelet image restoration regularization parameters selection scale dependent 1 penalized regularization method akaike information criterion;image restoration wavelet domain wavelet transforms inverse problems noise reduction bayesian methods computer science mathematics testing fast fourier transforms;lasso;wavelet;scale dependence;wavelet transforms image restoration	For the restoration of an image based on its noisy distorted observations, we propose wavelet domain restoration by scale-dependent L1 penalized regularization method (WaveRSL1). The data adaptive choice of the regularization parameters is based on the Akaike Information Criterion (AIC) and the degrees of freedom (df) is estimated by the number of nonzero elements in the solution. Experiments on some commonly used testing images illustrate that the proposed method possesses good empirical properties.	akaike information criterion;circuit restoration;image restoration;matrix regularization;wavelet	Leming Qu	2009	2009 Fourth International Conference on Frontier of Computer Science and Technology	10.1109/FCST.2009.18	mathematical optimization;akaike information criterion;pattern recognition;statistics	Robotics	60.19896001497026	-70.26120389326022	84716
29583ff4f39dd1f05a46e8debd4d5a764814a212	super-resolution reconstruction of multi-polarization sar images based on projections onto convex sets algorithm		Resolution is one of the important indices to measure the quality of SAR images. Super-resolution reconstruction is a widely adopted resolution enhancement method. Many algorithms have been developed for the super-resolution reconstruction. Among these algorithms, this paper applies projections onto convex sets algorithm to SAR image reconstruction processing. The POCS can efficiently obtain high-resolution SAR images with enhanced details. However, the POCS requires many low-resolution SAR images of the same area to gain a better result, usually 10 to 20 images. Such requirement is very difficult to achieve when only single-polarization mode is included. In this paper, we propose a novel method that utilizes all the polarimetric images of the same original SAR data for the algorithm. Thus, the number of the available images is increased exponentially. The experiment results have demonstrated the effectiveness of our proposed method: The reconstructed high-resolution SAR image based on multi-polarimetric information is more detailed and clearer than that based on single-polarization information.	algorithm;convex set;image resolution;iterative reconstruction;polarimetry;polarization (waves);super-resolution imaging	Jin Huang;Bo Gao;Yunping Chen;Ling Tong	2018	IGARSS 2018 - 2018 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2018.8518557	iterative reconstruction;computer vision;polarimetry;artificial intelligence;algorithm;superresolution;synthetic aperture radar;projections onto convex sets;computer science;polarization (waves);image resolution	Vision	67.96369611133159	-65.69719798716879	84816
0df5bda313fe7839feb411265b18056777b6c6a4	depth interpolation from surface boundary perceived with binocular viewing	binocular viewing;picture processing;disparity;perceived surface;visual perception picture processing;3d surface;visual stimulus;visual stimulus 3d surface ambiguity attention depth binocular viewing disparity displayed surface boundary mathematical model perceived surface surface interpolation;mathematical model;ambiguity;visual perception;surface interpolation;attention depth;displayed surface boundary	In the perception of a 3D surface with binocular viewing, a 3D surface can be perceived even in the area where there is no visual stimulus to give the disparity. Concerning this phenomenon, the possibility of surface interpolation from its boundary has arisen. The perceived surface can be not only a plane, but also a curve. If the displayed surface boundary includes ambiguity, which means that there exist a number of surfaces having exactly the same boundary, the surface can be perceived differently according to the attention depth of observation. In order to get a better understanding of these phenomena, a simple mathematical model has been developed	binocular vision;interpolation	M. Idesawa	1990		10.1109/IJCNN.1990.137763	computer vision;visual perception;mathematical model;mathematics;statistics	Vision	56.212813321357366	-52.79595096666058	84829
22a2120067aceea30ab06a096ad9253bd0bdf1b6	an adaptive image denoising model based on nonlocal diffusion tensor	eigenvalues and eigenfunctions;tensile stress;psnr;gaussian processes;edge detection;structure tensor;anisotropic diffusion equation;wavelet transforms edge detection gaussian processes image denoising image texture nonlinear equations partial differential equations tensors;image texture;wavelet transforms;image edge detection;partial differential equations;pde based image processing adaptive image denoising model nonlocal diffusion tensor weickert anisotropic diffusion equation method fidelity term coefficient linear gaussian function edge directions gaussian kernel nonlinear wavelet threshold texture preservation edge enhancing diffusion method coherence enhancing diffusion method partial differential equation;anisotropic magnetoresistance;mathematical model tensile stress equations image edge detection eigenvalues and eigenfunctions anisotropic magnetoresistance psnr;mathematical model;anisotropic diffusion equation nonlocal diffusion tensor structure tensor wavelet threshold;nonlinear equations;image denoising;wavelet threshold;nonlocal diffusion tensor;tensors	When denoising with the method of Weickert's anisotropic diffusion equation, the textures and details will be compromised. A fidelity term is added into Weickert's equation. The coefficient of fidelity term will vary adaptively with the instant image, which makes that the diffusion term and the fidelity term come to a better compromise. Otherwise, when deciding the edge directions, because of the strong smoothness of linear Gaussian function, a few other edge directions hiding in the main direction will be lost. To preserve these detailed edge directions, Gaussian kernel is substituted for nonlinear wavelet threshold. In addition, in order to preserving the textures and details as much as possible, a nonlocal diffusion tensor was introduced and the two eigenvalues are reset by combining the two methods: edge enhancing diffusion and coherence enhancing diffusion. Experiments show that the new model has obvious effect in preserving textures and details.	aharonov–bohm effect;anisotropic diffusion;coefficient;experiment;noise reduction;nonlinear system;texture mapping;wavelet	Sun Xiao-li;Xu Chen;Li Min	2012	2012 Eighth International Conference on Computational Intelligence and Security	10.1109/CIS.2012.70	magnetoresistance;image texture;computer vision;mathematical optimization;mathematical analysis;edge detection;tensor;peak signal-to-noise ratio;nonlinear system;computer science;mathematical model;gaussian process;mathematics;geometry;stress;structure tensor;partial differential equation;wavelet transform	Vision	55.97263012720685	-69.07896952584176	84865
621988d81958fd27e19156fa395eb40cf97c3934	error diffusion with vivid color enhancement and noise reduction	printing;high resolution;halftones;inkjet technology;noise reduction;diffusion process;denoising;pepper;diffusion	A novel error diffusion technique with vivid color enhancement and noise reduction has been developed to achieve high quality, high resolution color ink jet printing. Conventional error diffusion produces halftones with worm-like and salt-and-pepper-like noises. Each halftoned pixel may be one of the 8 colors: RGBCMYKW. Depending on the printing device characteristics (including printer dot size, registration, resolution, ink, and media), color interference between the 8 possible colors may occur. This color interference produces visible salt-and-pepper noise. In order to remove the noise, we classify the 8 colors into three clusters. Each cluster contains a set of harmonic colors. We exclude non-harmonic color halftones to be mixed. Any smooth color area in an input image uses a cluster (i.e., a set of colors) to make the halftone color more vivid and to minimize the non-harmonic color interference. In the error diffusion processing, inter-frame information between RGB plans are used to enforce the color cluster rules to achieve no salt-and-pepper noise and more vivid color halftones. Experimental results are provided to show the effectiveness of the technique.© (1996) COPYRIGHT SPIE--The International Society for Optical Engineering. Downloading of the abstract is permitted for personal use only.	error diffusion;noise reduction	Joseph Shu	1996		10.1117/12.238744	color histogram;rgb color model;computer vision;color filter array;color quantization;color depth;color image;engineering;high color;color balance;optics;color space;dither;computer graphics (images)	EDA	58.54956618215126	-60.93779706189914	84889
bf6fcd6bcff144c3bd882d53bbde6e6f1e6b4b54	preparation of multi-stage remote sensing for monitoring sea ice in the okhotsk sea with alos sensors	verification;sea ice;data set;radar remote sensing;spaceborne radar ocean sea ice measurement technique satellite remote sensing arctic north pacific okhotsk sea alos algorithm data set verification optical method radar remote sensing sar synthetic aperture radar;remote monitoring sea ice helicopters ice thickness thickness measurement digital cameras remote sensing satellites sea measurements airplanes;alos;okhotsk sea;oceanographic regions;arctic;digital cameras;algorithm;spaceborne radar oceanographic regions sea ice sea ice oceanographic techniques remote sensing remote sensing by radar synthetic aperture radar;remote sensing by radar;sar;north pacific;airplanes;remote sensing data;remote sensing;satellites;optical method;ocean;satellite remote sensing;remote monitoring;sea ice concentration;measurement technique;ice thickness;oceanographic techniques;helicopters;thickness measurement;sea measurements;spaceborne radar;synthetic aperture radar	In order to develop and/or improve algorithms of extracting various sea ice parameters, such as sea ice concentration, sea ice thickness, and sea ice types from ALOS data, it is necessary to prepare certain data set for verification. This paper describes about the preparation of multi-stage remote sensing for obtaining a series of remotely sensed data of sea ice in the Okhotsk Sea.		K Cho;Masashige Nakayama;Haruhisa Shimoda;Seiho Uratsuka;H. Enomoto;Yoshiaki Honda	2002		10.1109/IGARSS.2002.1025053	meteorology;sea ice thickness;verification;synthetic aperture radar;arctic;oceanography;geology;specific absorption rate;sea ice concentration;sea ice;data set;physics;satellite;remote sensing;rmon	Mobile	79.70681893909484	-62.08956059791951	85011
ad129b1be9fb64e05aa5733a35e75265f147c89b	a display method allocating sar image and ati phase map to value and saturation, respectively	azimuth;clutter;synthetic aperture radar airborne radar colour displays radar imaging;radar tracking;saturation sar ati display;image color analysis;synthetic aperture radar azimuth image color analysis radar tracking interferometry clutter radar imaging;radar imaging;airborne sar data display method synthetic aperture radar sar image ati phase map color display track interferometry;interferometry;synthetic aperture radar	Synthetic Aperture Radar (SAR) can take a fine radar image without relation to sunshine condition, so it is important to propose the display method that fulfills a user's demand. SAR provides some information with high-level process. To confirm both SAR image and the results of the high-level process simultaneously, the color display is effective. However, conventional method has the restriction of color combination. In this context, we proposed the display method focusing the saturation. The proposed method superimposed the phase map of along track interferometry, which is one of the high-level processes, on SAR image with good visibility. In this paper, we discuss the effect of the proposed display method, explain its formularization, and demonstrate the effect by airborne SAR data.	airborne ranger;aperture (software);color;high- and low-level;radar	Tomoya Yamaoka;Teruyuki Hara	2016	2016 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)	10.1109/IGARSS.2016.7730704	early-warning radar;computer vision;continuous-wave radar;radar tracker;radar engineering details;synthetic aperture radar;radar lock-on;interferometry;fire-control radar;radar horizon;bistatic radar;low probability of intercept radar;pulse-doppler radar;clutter;3d radar;interferometric synthetic aperture radar;azimuth;optics;radar imaging;inverse synthetic aperture radar;radar display;side looking airborne radar;physics;remote sensing	Visualization	76.07049292636641	-64.79333067285005	85014
1c491ffaf25c8ce3da8077e0becc947947e3afc4	hyperspectral image compression employing a model of anomalous pixels	discrete wavelet transforms;anomalous pixels model;rate distortion;image coding;discrete wavelet transform;data compression;spectral karhunen loeve transform;karhunen loeve transforms data compression geophysical techniques image coding;hyperspectral images;wavelet anomaly detection discrete wavelet transform dwt hyperspectral data jpeg 2000 karhunen loeve transform klt lossy compression reed xiaoli rx algorithm;lossy compression;compression algorithms;anomaly detection;karhunen loeve transform klt;discrete wavelet transform dwt;anomaly detection performance;karhunen loeve transforms;lossy compression algorithm;infrared imaging;hyperspectral imaging image coding pixel compression algorithms karhunen loeve transforms transform coding infrared imaging infrared spectra spectroscopy layout;anomaly detection performance anomalous pixels model lossy compression algorithm hyperspectral images spectral karhunen loeve transform spatial jpeg 2000 airborne visible infrared imaging spectrometer rate distortion performance;reed xiaoli rx algorithm;hyperspectral data;rate distortion performance;jpeg 2000;airborne visible infrared imaging spectrometer;hyperspectral imaging;spatial jpeg 2000;karhunen loeve transform;hyperspectral image;wavelet;geophysical techniques	We propose a new lossy compression algorithm for hyperspectral images, which is based on the spectral Karhunen-Loeve transform, followed by spatial JPEG 2000, which employs a model of anomalous pixels during the compression process. Results on Airborne Visible/Infrared Imaging Spectrometer scenes show that the new algorithm provides better rate-distortion performance, as well as improved anomaly detection performance, with respect to the state of the art.	algorithm;anomaly detection;distortion;image analysis;image compression;jpeg 2000;lossy compression;pixel	Barbara Penna;Tammam Tillo;Enrico Magli;Gabriella Olmo	2007	IEEE Geoscience and Remote Sensing Letters	10.1109/LGRS.2007.903976	data compression;computer vision;anomaly detection;speech recognition;computer science;mathematics;statistics;computer graphics (images)	Vision	68.66923250657973	-63.85822577054811	85041
cb072f54ac0747ca3c88e9dcaa0336302eade9ac	combined efficiency of rpc and dem accuracy on georeferencing accuracy of orthoimage: case study with pléiades panchromatic mono image	photogrammetry;accuracy remote sensing mathematical model satellites sensors geospatial analysis image sensors;zonguldak test field figure condition georeferencing pleiades rational function model rfm undulating topography;remote sensing digital elevation models photogrammetry;remote sensing;rational function model rpc accuracy dem accuracy orthoimage georeferencing accuracy pleiades panchromatic mono image orthoimage generation remote sensing photogrammetry height information density height information accuracy rational polynomial coefficients digital elevation models figure condition method auxiliary data ikonos satellite image quickbird satellite image orbview 3 satellite image zonguldak test site turkey;digital elevation models	Generation of orthoimages in remote sensing and photogrammetry is a common and sometimes mandatory issue. The desired georeferencing accuracy of the orthoimage depends on two main factors: accuracy of transformation parameters and density and accuracy of height information. The objective of this letter is to estimate the combined efficiency of accuracies of refined rational polynomial coefficients and digital elevation models on georeferencing accuracy of the orthoimage utilizing the figure condition method (FCM). In this letter, details of the method, the characteristics of the evaluated Pléiades panchromatic mono image and auxiliary data, and also the test site are presented. The findings were compared with other results from high-resolution satellite images such as those from IKONOS, QuickBird, and OrbView-3. It is observed that the FCM might be preferred to estimate the overall georeferencing accuracy of an orthoimage, reaching ± 0.3-2.7-pixel accuracy range. The Pléiades panchromatic mono image presents almost equal accuracy as the compared images. The research was carried out on the Zonguldak (Turkey) test site which has mountainous and extremely undulating topography.	coefficient;digital elevation model;fuzzy cognitive map;image resolution;photogrammetry;polynomial;topography	Huseyin Topan;Murat Oruc;Talha Taskanat;Ali Cam	2014	IEEE Geoscience and Remote Sensing Letters	10.1109/LGRS.2013.2288360	computer vision;digital elevation model;geology;photogrammetry;remote sensing	HCI	78.86369783036312	-58.77895398649069	85064
1dbc7949db11ddb536355c54cfece1aabcf46b82	high resolution dsm generation from alos prism - archiving and mosaicking	remote sensing instrument;geophysical image processing;software;vegetation mapping;topographic data analysis;remote sensing geophysical image processing geophysical techniques image matching image resolution;high resolution;stereo image matching algorithm;image resolution;advanced land observing satellite;image matching;prism alos digital surface model geometric calibration;prism;prism stereoscopic observation data;alos;digital surface model;surface topography;mosaicking analysis;accuracy;geometric calibration;remote sensing;satellites;digital surface model data;mosaicking analysis high resolution dsm generation process advanced land observing satellite topographic data analysis digital surface model data prism stereoscopic observation data stereo image matching algorithm;satellite remote sensing;tiles;tiles software accuracy satellites remote sensing vegetation mapping surface topography;geophysical techniques;high resolution dsm generation process	Panchromatic Remote-sensing Instrument for Stereo Mapping (PRISM) carried by Advanced Land Observing Satellite (ALOS) was designed to generate worldwide topographic data with its high resolution and stereoscopic observation. According to this aim, we developed the software of generating Digital Surface Model (DSM) data. Following the accumulations of PRISM stereoscopic observation data during over five year operations, the capabilities of the matching-algorithm for stereo images, as well as the characteristics of processed DSMs, were widely validated. This paper reports on the latest validation results, archiving status, and the mosaicking results of the DSM.	algorithm;archive;digital elevation model;file archiver;image resolution;image stitching;prism (surveillance program);stereoscopy;topography	Junichi Takaku;Takeo Tadono	2011	2011 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2011.6050191	computer vision;image resolution;computer science;physics;remote sensing;computer graphics (images)	Robotics	79.80792917827749	-61.10719829588881	85105
57ff36ce80cd6fc53478c05385ec181fa8ab5647	image stabilization based on fusing the visual information in differently exposed images	image fusion;natural images;image restoration;indexing terms;exposure time;simulation experiment;edge preserving image image stabilization visual information fusion image motion blur degradation exposed images illumination condition exposure time maximum a posteriori estimation;motion blur;image stabilization;degradation cameras image restoration layout deconvolution image sensors lighting manufacturing motion measurement optical sensors;map estimation;image restoration image fusion;image deconvolution image stabilization motion blur image restoration exposure time;image deconvolution	The objective of image stabilization is to prevent or remove the motion blur degradation from images. We introduce a new approach to image stabilization based on combining information available in two differently exposed images of the same scene. In addition to the image normally captured by the system, with an exposure time determined by the illumination conditions, a very shortly exposed image is also acquired. The difference between the exposure times of the two images determines differences in their degradations which are exploited in order to recover the original image of the scene. We formulate the problem as a maximum a posteriori (MAP) estimation based on the degradation models of the two observed images, as well as by imposing an edge-preserving image prior. The proposed method is demonstrated through a series of simulation experiments, and visual examples on natural images.	elegant degradation;experiment;gaussian blur;simulation	Marius Tico;Markku Vehviläinen	2007	2007 IEEE International Conference on Image Processing	10.1109/ICIP.2007.4378905	image quality;image warping;image texture;image restoration;computer vision;feature detection;index term;image resolution;image gradient;binary image;image processing;computer science;gaussian blur;time delay and integration;shutter speed;image fusion;image formation;image-based lighting;image stabilization;computer graphics (images)	Vision	57.06627214482572	-58.17621687303416	85176
70d427fde3d504ddb1eac73752cb949543ace67f	exploiting galileo ionospheric disturbance flags to boost nequick	satellite navigation ionospheric disturbances;receivers computational modeling mathematical model global positioning system satellites delays europe;receivers;computational modeling;nequick g galileo ionospheric disturbance flag european commission satellite navigation system gnss receiver european gnss open service signal in space interface control document issue 1 1 galileo ionospheric correction calculation;global positioning system;satellites;articles in periodicals and books;mathematical model;europe;delays	The European Commission has recently released the official document describing the particular ionospheric model developed for the Galileo satellite navigation system. Such publication allows GNSS receiver manufacturers starting the implementation of the specific algorithm targeted for their Galileo related products in order to be compliant with the Galileo system. According to the European GNSS (Galileo) Open Service Signal In Space Interface Control Document, Issue 1.1, among the parameters that are broadcast in the Galileo navigation message, one can find five Ionospheric Disturbance Flags for Regions 1 to 5 (SF1, SF2, SF3, SF4 and SF5 respectively). Nevertheless, in the current version of the model presented in the Galileo-Iono document, the Ionospheric Disturbance flags are not used within the Galileo ionospheric correction calculation. In this work, a potential approach to account for this information is being investigated. This approach includes the update of the Galileo ionospheric correction model, NeQuick-G, by specifying the use of these flags. Hence a customized version of the NeQuick-G model has been developed and tested.	algorithm;computation;galileo (satellite navigation);interface control document;iteration;satellite navigation;single-frequency network;synergy;total electron content	Angela Aragon-Angel;Joaquim Fortuny-Guasch	2016	2016 International Conference on Localization and GNSS (ICL-GNSS)	10.1109/ICL-GNSS.2016.7533856	satellite navigation;geography;geodesy;telecommunications;gnss applications;remote sensing	Robotics	80.0054195834962	-65.15914299954942	85214
568baa22e82335fd8625df258525a38eec57f6ec	construction and application of characteristic bands of typical land cover based on spectrum-photometric method	geophysical image processing;reservoirs;photogrammetry;vegetation mapping;shaanxi province;normalized difference water index;object oriented methods;error matrix;decision tree;vegetation index;rivers;information extraction;dry land;band operation method;object oriented classification;high resolution imagery;spot5 xs imagery;accuracy assessment;spot5 satellite imagery;spectrum photometric method high spatial resolution spot5 satellite imagery texture information color texture statistical classification technology spot5 xs imagery multispectral bands land cover remote sensing data automated information extraction band information taibai mountain shaanxi province china evergreen coniferous forest deciduous broad leaved forest uncovered rock riverbed dry land residential area band operation method normalized difference water index normalized difference soil index adjusted normalized difference vegetation index texture bands object oriented classification approach decision trees error matrix accuracy assessment overall classification accuracy overall kappa statistics spatial information spectral analysis;spectrum;photometric methods;vegetation mapping decision trees geophysical image processing object oriented methods photogrammetry remote sensing spectral analysis terrain mapping;color texture;texture features;data mining;normalized difference soil index;statistical classification technology;deciduous broad leaved forest;accuracy;indexes;near infrared;spot5;coniferous forest;object oriented classification approach spectral analysis spectrum photometric method spot5 construction of characteristic band;residential area;normalized difference vegetation index;overall classification accuracy;remote sensing data;remote sensing;evergreen coniferous forest;indexation;taibai mountain;spectrum photometric method;adjusted normalized difference vegetation index;overall kappa statistics;multispectral bands;satellite imagery;texture information;terrain mapping;band information	With high spatial resolution, SPOT5 satellite imagery contains rich texture information, such as geometry and color texture which embodies the details of object surfaces by changing the hue or brightness. However, traditional statistical classification technology based on the spectrum of pixels couldn't make full use of the texture information of SPOT5 satellite imagery because SPOT5-XS imagery only includes four multispectral bands, i.e. green(G) with wavelengths ranging from 0.50 to 0.59 microns, red(R) 0.61 to 0.68, near infrared (NIR) 0.78 to 0.89 and shortwave infrared (SWIR) 0.15 to 1.75. If only these four bands are applied to identify land cover by using remote sensing data, it will often bring some problems, such as the divisibility among various land cover types reduced and the automated information extraction more difficult, which mainly results in the lack of band information and complexity of spectrum. By using SPOT5 imagery covering Taibai Mountain in Shaanxi Province, China, we analyzed spectrum characteristic, relations among bands and texture feature of typical land cover types including evergreen coniferous forest, deciduous broad-leaved forest, uncovered rock riverbed, dry land, residential area, etc. Based on these results, many characteristic bands were built through Band Operation method and merged into the original SPOT5-XS imagery, which includes Normalized Difference Water Index (NDWI), Normalized Difference Vegetation Index (NDVI), Normalized Difference soil Index (NDSI), Difference Vegetation Index (DVI), Adjusted Normalized Difference Vegetation Index (ANDVI), Sum of Vegetation Index (SVI) and two texture bands. Object-oriented classification approach was then applied to the new generated imagery based on decision trees and Error Matrix for accuracy assessment. Experimental results show that the Overall Classification Accuracy (OCA) is 92.22% and Overall Kappa Statistics (Kappa) 89.43%. The classification accuracy of evergreen coniferous forest, deciduous broad-leaved forest and dry land is 95.20%, 94.04% and 93.10%, respectively. These results indicated that the object-oriented method based on the new constructed spectrum features could take advantage of spatial information of high resolution imagery, improve the divisibility among various land cover types and make the information extraction more easily and the high classification accuracy obtained. In particularly, with the texture feature bands, the objects with similar spectrum could be well identified.	decision tree;digital visual interface;image resolution;information extraction;multispectral image;pixel;quantum well infrared photodetector;statistical classification	Wenfang Lin;Quanfang Wang;Shuping Zha;Jiayong Li	2010	2010 18th International Conference on Geoinformatics	10.1109/GEOINFORMATICS.2010.5567712	geography;hydrology;cartography;remote sensing	Visualization	79.39032380777377	-57.69445612863741	85267
313d87988230c88dd6536ffca1ae1fb662aabfdc	an interactive image mining tool handling gigapixel images	geophysical image processing;disaster;image information mining;complexity theory;image segmentation;image resolution;support vector machines;information extraction;vhr images;training;training accuracy support vector machines complexity theory image segmentation feature extraction remote sensing;detection;data mining;vhr;accuracy;detection image information mining vhr images;information extraction interactive image mining tool handling gigapixel images very high resolution vhr humanitarian situations submetric panchromatic image disaster earth surface;earth surface;feature extraction;very high resolution;remote sensing;interactive image mining tool handling gigapixel images;humanitarian situations;submetric panchromatic image;public administration data mining disasters geophysical image processing image resolution image retrieval;disasters;image retrieval;public administration	Very High Resolution (VHR) satellite images are products which are very useful for assessing humanitarian situations following a disaster or a crisis. When disaster or conflict hits, generally several square kilometers on Earth surface are involved. Having a high resolution and an extended surface, the scenes, from which the information is extracted, become huge in the number of pixels. Built-up structures are the first visible objects from these images which give information about the situation. In this paper, an interactive image mining paradigm is presented for detecting structures of interest in gigapixel images. The proposed approach is tested for refugee tents detection in submetric panchromatic image.	gigapixel image;image resolution;pixel;programming paradigm;sensor	Lionel Gueguen;Martino Pesaresi;Pierre Soille	2011	2011 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2011.6049373	computer vision;disaster;image retrieval;computer science;machine learning;data mining;information extraction;remote sensing	Vision	76.45856345785592	-58.770560036014565	85308
3e18d08c430ab93d403f9e08e99a78cb38130e0b	long-term monitoring of the flooding regime and hydroperiod of doñana marshes with landsat time series (1974-2014)	classification tree;articulo;hydroperiod;marsh;flood mask;normalization;landsat time series;inundation mapping	This paper presents a semi-automatic procedure to discriminate seasonally flooded areas in the shallow temporary marshes of Doñana National Park (SW Spain) by using a radiommetrically normalized long time series of Landsat MSS, TM, and ETM+ images (1974–2014). Extensive field campaigns for ground truth data retrieval were carried out simultaneous to Landsat overpasses. Ground truth was used as training and testing areas to check the performance of the method. Simple thresholds on TM and ETM band 5 (1.55–1.75 μm) worked significantly better than other empirical modeling techniques and supervised classification methods to delineate flooded areas at Doñana marshes. A classification tree was applied to band 5 reflectance values to classify flooded versus non-flooded pixels for every scene. Inter-scene cross-validation identified the most accurate threshold on band 5 reflectance ($ < 0.186) to classify flooded areas (Kappa = 0.65). A joint TM-MSS acquisition was used to find the MSS band 4 (0.8 a 1.1 μm) threshold. The TM flooded area was identical to the results from MSS 4 band threshold $ < 0.10 despite spectral and spatial resolution differences. Band slicing was retrospectively applied to the complete time series of MSS and TM images. About 391 flood masks were used to reconstruct historical spatial and temporal patterns of Doñana marshes flooding, including hydroperiod. Hydroperiod historical trends were used as a baseline to understand Doñana’s flooding regime, test hydrodynamic models, and give an assessment of relevant management and restoration decisions. The historical trends in the hydroperiod of Doñana marshes show two opposite spatial patterns. While the north-western part of the marsh is increasing its hydroperiod, the southwestern part shows a steady decline. Anomalies in each flooding cycle allowed us to assess recent management decisions and monitor their hydrological effects.	baseline (configuration management);circuit restoration;classification chart;cross-validation (statistics);data retrieval;direct method in the calculus of variations;ground truth;host protected area;pixel;semiconductor industry;shattered world;spatial variability;supervised learning;time series;topography	Ricardo Díaz-Delgado;David Aragonés;Isabel Afán;Javier Bustamante	2016	Remote Sensing	10.3390/rs8090775	marsh;decision tree learning;hydrology;machine learning;normalization;ecology;remote sensing	ML	82.51627597068172	-57.43129161472698	85357
b138d2998234caf09e3cc0ee57c33e24d5a81f37	a sensor-based approach to linear blur identification for real-time video enhancement	adaptive image sensor motion blur super resolution blur identification;video signal processing image enhancement image restoration image sensors motion estimation;video signal processing;real time;motion estimation;image restoration;image sensors;strontium;image enhancement;motion blur;blur identification;point spread function;image reconstruction;strontium motion estimation image sensors image reconstruction image resolution spatial resolution educational institutions degradation linearity polynomials;pixel;super resolution reconstruction quality realtime video enhancement linear blur identification super resolution methods point spread function adaptive image sensor;super resolution;image sensor;adaptive image sensor;real time systems;spatial resolution	Super-resolution (SR) methods are largely affected by the accurate evaluation of the Point Spread Function (PSF) that is related to the input frames. When the frames are degraded by heavy motion blur, the PSFs are highly non-isotropic, which further complicates their estimation. The ill-posed nature of blur identification is usually addressed using the assumption of linear and uniform motion. However, in real-life systems, this may deviate significantly from the actual motion blur. To resolve the above, this work proposes combining a scheme that validates the initial motion assumption with the real-time reconfiguration property of an adaptive image sensor. If the linearity and uniformity assumption is invalid for a given motion region, the sensor is locally reconfigured to larger pixels that produce higher frame-rate samples with reduced blur. Once the appropriate configuration that gives rise to a valid motion assumption is applied, highly accurate PSFs are estimated, resulting to an improved SR reconstruction quality.	box blur;circuit complexity;gaussian blur;image sensor;pixel;real life;real-time clock;super-resolution imaging;well-posed problem	Maria E. Angelopoulou;Christos-Savvas Bouganis;Peter Y. K. Cheung	2009	2009 16th IEEE International Conference on Image Processing (ICIP)	10.1109/ICIP.2009.5414162	computer vision;computer science;motion estimation;image sensor;computer graphics (images)	Vision	55.61157663989485	-54.929973375660516	85361
021e658896a9b2dd50721ef59d89d737ddcee1df	filter design for gray image by down-sample and up-sample	matrices	Aims: Designing of a filter which can separate out the target from background in a given image. Methods: The original gray image is down-sampled by rejecting every alternate pixel values between two columns and two rows. A 3-step down-sampling was done to avoid major information loss. A 3-step up-sampling was done by replicating the lower row and the right column from the down-sampled data matrix to obtain the original size of the matrix. The image matrix thus obtained was subtracted from the original image. Results: The iterative down-sampling and up-sampling matrix gives the background information. Subtraction from original image obtains the target. Thus filters the background.	column (database);filter (signal processing);filter design;iterative method;pixel;sampling (signal processing);the matrix	Mousumi Gupta	2012		10.1117/12.946640	computer vision;artificial intelligence;mathematics;computer graphics (images)	Vision	56.40932752996317	-62.93503356001786	85424
53b32ef0481ce80670828805a5664b1c3b2a680c	new snr estimate for the wiener filter to image restoration	image restoration;it value;arithmetic mean;wiener filter;signal to noise ratio;minimum mean square error	Image restoration is an estimation process that attempts to recover an ideal high quality image from a given degraded version. The Wiener filter method derived from the minimum mean square error criterion is widely used in image restoration to restore degraded images. In this method the constant (Gamma) , which is an a priori representation of the signal to noise ratio for the complete image plane, is unknown and its value is supplied by the user and adjusted by the trial and error approach. In this paper a new estimation process of (Gamma) is proposed. First of all, a second image is constructed from the given degraded image (referred to as the first image) using the Lagrangeu0027s interpolation technique. The Lagrangeu0027s interpolation technique used here is actually a modified version of the original approach. Secondly, an expression for (Gamma) [i, j], which is an a priori representation of the signal to noise ratio at pixel [i, j], is obtained using both the first and the second images and their auto correlations. However the Wiener filter only needs (Gamma) for the complete image plane. Therefore an arithmetic mean of a selected set of (Gamma) [i, j] values is calculated. This arithmetic mean is then used as (Gamma) in the Wiener filter to restore the first image.© (1994) COPYRIGHT SPIE--The International Society for Optical Engineering. Downloading of the abstract is permitted for personal use only.	circuit restoration;image restoration;signal-to-noise ratio;wiener filter	Shan Suthaharan	1994	J. Electronic Imaging	10.1117/12.183756	minimum mean square error;image restoration;computer vision;arithmetic mean;computer science;control theory;wiener filter;signal-to-noise ratio;non-local means;statistics;wiener deconvolution	Vision	58.02755221852764	-65.74777976121224	85431
e5dd11d2e0b35a84baca1fd5866809f8a74e4226	real-time motion blur using extruded triangles	real-time rendering;motion blur;visibility;shading	Several algorithms have been introduced to render motion blur in real time by solving the visibility problem in the spatial-temporal domains. However, some algorithms render at interactive frame rates but have artifacts or noise. Therefore, we propose a new algorithm that renders real-time motion blur using extruded triangles. Our method uses two triangles in the previous frame and the current frame to make an extruded triangle then send it to rasterization. By using the standard rasterization, visibility determination is performed efficiently. To solve the occlusion between extruded triangles for a given pixel, we introduce a combination solution using a sorting in front-to-back order and bitwise operations in the spatial-temporal dimensions. This solution ensures that only non-occluded extruded triangles are shaded. We further improve performance of our algorithm using a coverage map.	algorithm;bitwise operation;box blur;gaussian blur;graphics processing unit;hidden surface determination;interpolation;linked list;pixel;rasterisation;real-time clock;rendering (computer graphics);shading;sorting;texture mapping;visibility (geometry)	MinhPhuoc Hong;Kyoungsu Oh	2017	Multimedia Tools and Applications	10.1007/s11042-017-4949-6	computer vision;coverage map;pixel;computer science;motion blur;artificial intelligence;frame rate;real-time rendering;bitwise operation;sorting;shading	Graphics	65.37082836999274	-52.61286518862207	85505
9c8a37c31af11ec3cd59f4cfcd4562516305cd0e	an a-contrario approach for unsupervised change detection in radar images	ckld;geophysical image processing;detectors;change detection;synthetic aperture radar images;earth;kullback leibler divergence;multiscale series;laser radar;volcanology geophysical image processing radar imaging synthetic aperture radar;radar images;congo;congo a contrario approach unsupervised change detection synthetic aperture radar images multiscale approach multiscale series cumulant based kullback leibler divergence ckld nyiragongo volcanic eruption ad 2002 01;volcanology;radar images change detection kullback leibler divergence multiscale;multiscale approach;radar imaging;sar image;statistics;area measurement;a priori information;robustness;radar detection;unsupervised change detection;cumulant based kullback leibler divergence;radar detection radar imaging synthetic aperture radar detectors statistics robustness laser radar telecommunications area measurement earth;cumulant;multiscale;volcanic eruption;ad 2002 01;nyiragongo volcanic eruption;telecommunications;synthetic aperture radar;a contrario approach	This paper presents a new approach for unsupervised change detection in pairs of Synthetic Aperture Radar (SAR) images. As changes to detect can have various sizes and intensities which are a priori unknown in most applications, we propose a multiscale approach without considering any a priori information. Using multiscale series of a cumulant-based Kullback-Leibler divergence (CKLD) measure computed between two dates, changes are characterized as areas where the CKLD values vary a lot when the scale varies. In a probabilistic a-contrario framework, a measure of meaningfulness of such an evolution through scale is derived, leading to a criterion free of parameter. Results are presented using a pair of SAR images acquired before and after the volcanic eruption of the Nyiragongo in January 2002 (Congo), showing the robustness of the method with respect to the number of false alarms.	aperture (software);kullback–leibler divergence;radar;unsupervised learning	Amandine Robin;Grégoire Mercier;Sebastiano B. Serpico	2009	2009 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2009.5417327	computer vision;geology;radar imaging;physics;statistics;remote sensing;volcanology	Embedded	74.0545479238117	-63.63961652221405	85560
6ef90b0f44d2bca33e896b580f3bb5f4c57e832d	laweco: active region detection in non-uniformly sampled data using laplacian-weighted covariance	kernel;graph signal processing;activity detection;insar data laweco active region detection nonuniformly sampled data laplacian weighted covariance event detection signal processing techniques graph theoretic framework active region localization active region characterization graph neighborhood connectivity scale space formulation interferometric synthetic aperture radar;laplacian;multiscale analysis;synthetic aperture radar covariance analysis graph theory radar signal processing signal detection;covariance;event detection;laplace equations;time series analysis;covariance matrices;spectral analysis;activity detection graph signal processing laplacian covariance multiscale analysis;kernel laplace equations covariance matrices time series analysis event detection spectral analysis	Event detection in sparse, non-uniformly sampled multidimensional data eludes traditional signal processing techniques. We propose a method that, within the graph-theoretic framework, successfully addresses the task of localizing and characterizing active regions by leveraging the coherent behavior detection capabilities of the covariance matrix together with the natural definition of graph neighborhood connectivity provided by the Laplacian. We further extend this framework using scale space formulation to detect the extent of active region. Our method exhibits significant improvement in detecting active regions compared to other similar state-of-the art techniques. The method is demonstrated on interferometric synthetic aperture radar (InSAR) data that is both sparse and non-uniformly sampled. Comparison with three widely used event detection methods reveals the efficacy and efficiency of the Laplacian-weighted covariance technique.	aperture (software);coherence (physics);computation;graph theory;parallel computing;robustness (computer science);scale space;sensor;signal processing;singular value decomposition;sparse matrix;synthetic data	Tamal Batabyal;Andrea Vaccari;Scott T. Acton	2016	2016 IEEE Southwest Symposium on Image Analysis and Interpretation (SSIAI)	10.1109/SSIAI.2016.7459192	estimation of covariance matrices;laplace operator;kernel;covariance;machine learning;time series;pattern recognition;mathematics;statistics	Vision	70.2597776555827	-66.65041124562023	85587
9fe9126bf3ede3096467830d40ea7ddb4520916e	radiometric and geometric scarab-megha-tropiques ground calibration comparison with first in orbit calibration	remote sensing albedo atmospheric measuring apparatus atmospheric radiation calibration radiometry;atmospheric radiation;albedo;collimator test radiometric calibration geometric scarab megha tropiques ground calibration in orbit calibration scarab 3 instrument indian french megha tropiques mission earth radiation budget cnes spectral band shortwave channel solar flux total channel total flux infrared earth radiance albedo earth long wave radiance radiometric accuracy integrating sphere black body calibration vacuum test;atmospheric measuring apparatus;radiometry;calibration radiation budget satellite observations remote sensing;satellite observations;radiation budget;remote sensing;calibration temperature measurement thermal stability instruments extraterrestrial measurements collimators gain measurement;calibration	The Scarab-3 instrument, part of the Indian-French Megha-Tropiques mission [1], has been launched in october 2011. It is a radiometer dedicated to earth radiation budget. CNES is prime of the development of this instrument. Last year, CNES conducted the final integration of the instrument and the radiometric/geometric calibrations. Two main spectral bands are measured by this instrument: A shortwave (SW) channel dedicated to solar fluxes and a Total (T) channel for (total) fluxes combining the infra-red earth radiance and the albedo. The earth long wave (LW) radiance is computed by subtracting the SW channel to the Total channel. Thus is defined a 3rd (virtual) LW channel. To obtain a good radiometric accuracy, intensive tests have been conducted using integrating sphere, black body calibration, vacuum tests and collimator test. After a brief sum up of the instrument, the results of the calibration will be presented and compared with the first in orbit calibration.	limewire;metric;shattered world;webscarab	Alain Rosak;Thierry Trémas;Nadia Karouche;Laurene Gillot;Olivier Simonella	2012	2012 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2012.6352332	meteorology;calibration;radiometry;optics;physics;albedo;remote sensing	Robotics	81.9833160035381	-63.6824320547382	85622
2ecdf31b67ac997a8099d5509b2dd4c6e1938633	a hybrid denoising algorithm based on shearlet transform method and yaroslavsky’s filter	image denoising;shearlet transform;yaroslavsky’s filter;kernel smoothing;minimax bounds	In this paper, we have proposed a hybrid denoising algorithm based on combining of the shearlet transform method, as a pre-processing step, with the Yaroslavsky’s filter, as a kernel smoother, on a wide class of images with various properties such as thin features and textures. In the other word, proposed algorithm is a two-step algorithm, where in the first step the image is filtered by shearlet transform method and in the second step the weighted Yaroslavsky’s filter is applied on result of first step. The weight coefficients of the Yaroslavsky’s filter are achieved by pixel similarities in the denoised image from the first step. The theoretical results are confirmed via simulations for 2D images corrupted by additive white Gaussian noise. Experimental results illustrate that proposed hybrid method has good effect on suppressing the pseudo-Gibbs and shearlet-like artifacts can obtain better performance in terms of mean square error (MSE), peak signal to noise ratio (PSNR) and structural similarity (SSIM) index rather than existing state-of-the-art methods.	additive white gaussian noise;algorithm;artifact (error);coefficient;digital image processing;experiment;matlab;mean squared error;noise reduction;numerical analysis;numerical method;peak signal-to-noise ratio;pixel;preprocessor;shearlet;simulation;structural similarity;utility functions on indivisible goods	Reza Abazari;Mehrdad Lakestani	2018	Multimedia Tools and Applications	10.1007/s11042-018-5648-7	computer vision;pixel;structural similarity;computer science;noise reduction;additive white gaussian noise;artificial intelligence;algorithm;kernel smoother;pattern recognition;peak signal-to-noise ratio;shearlet;mean squared error	Vision	57.23134652489405	-67.76688579668406	85633
7c8f0fd2fc6e05cb5653459ccfc2061145139d6d	multi-view object segmentation. (segmentation multi-vues d'objet)				Abdelaziz Djelouah	2015				Vision	56.89327948249898	-54.429260348129205	85691
c5b2365964b4e49ec79e116f77854356eaf834ba	contextual filtering in curvelet domain for fluoroscopic sequences	image quality;denoising;wavelets;x rays	X-ray exposure during image guided interventions can be important for the patient as well as for the medical staff. Therefore dose reduction is a major concern. Nevertheless, decreasing the dose per image affects significantly the image quality. As a matter of fact, this tends to increase the noise and reduce the contrast. Hence, we propose a new and efficient method to reduce the noise in low dose fluoroscopic sequences. Many studies in that domain have been proposed implementing either multi-scale approaches using wavelet with its derivatives or using filters in the direct space. Our work is based on a spatio-temporal denoising filter using the curvelet transform. Indeed, this sparse transform represents well smooth images with edges and can be applied to fluoroscopic images in order to achieve robust denoising performances. Therefore, we propose to combine a temporal recursive filter with a spatial curvelet filter. Our work is focused on the use of the statistical dependencies between the curvelet coefficients in order to optimize the threshold function. Determining the correlation among coefficients allows to detect which coefficients represent the relevant signal. Thus, our method allows to diminish or even to erase curvelet-like artefacts. The performances and robustness of the proposed method are assessed both on synthetic and real low dose sequences (ie: 20 nGy/frame).	coefficient;curvelet;image noise;image quality;multi-scale approaches;noise reduction;performance;recursion;recursive filter;sparse matrix;synthetic intelligence;wavelet	Carole Amiot;Jérémie Pescatore;Jocelyn Chanussot;Michel Desvignes	2013		10.1117/12.2006795	image quality;wavelet;computer vision;simulation;noise reduction	Vision	54.817802849469395	-75.89788651884966	85698
0f3137962768e10c6732f47c65c175f3baaf1a6c	a full reference stereoscopic video quality assessment metric		We propose a full reference stereo video quality assessment algorithm for assessing the perceptual quality of natural stereo videos. We exploit the separable representation of motion and binocular disparity in the visual cortex and develop a four stage algorithm to measure the quality of a stereoscopic video called FLOSIM3D. First, we compute the temporal features by utilizing an existing 2D VQA metric which measures the temporal annoyance based on patch level statistics such as mean, variance and minimum eigen value and pools them with a frame categorization based non-linear pooling strategy. Second, a structure based 2D Image Quality Assessment (IQA) metric is used to compute the spatial quality of the frames. Next, the loss in depth cues is measured using a structure based metric. Finally, the features for each of the stereo views are pooled to obtain the final stereo video quality score. We demonstrate the state-of-the-art performance of the proposed metric on IRCCYN dataset involving H.264, JP2K compression artifacts.	algorithm;binocular disparity;binocular vision;categorization;compression artifact;depth perception;eigen (c++ library);h.264/mpeg-4 avc;image quality;jpeg 2000;nonlinear system;stereoscopy	Balasubramanyam Appina;K. Manasa;Sumohana S. Channappayya	2017	2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	10.1109/ICASSP.2017.7952509	subjective video quality;video quality	Vision	63.06273843464473	-64.02479120628982	85781
2e38e60a1d32e9a54634c1bb3ce932e86fb60b44	imaging of a shallow subsurface objects: an experimental investigation	traitement signal;teledetection;3 5 ghz geophysics remote sensing measurement technique location forward looking microwave imaging military system buried mine geoelectric terrestrial electricity mine detection shallow subsurface objects bistatic signal processing s band system isolated target;deteccion blanco;instruments;geophysics;instrumentation;image processing;measurement;capa subsuperficial;helium;military system;instrumentacion;procesamiento imagen;picture processing;imagerie;microwave imaging;location;traitement image;deteccion a distancia;signal processing frequency image processing bistatic radar ground penetrating radar radar imaging radar cross section dielectrics system testing;buried mine;buried features;detection cible;algorithme;mine detection;remote sensing by radar;radar cross section;subsurface layer;imagery;ground penetrating radar;couche subsuperficielle;mines;military systems;signal processing;remote sensing;radar imaging;terrestrial electricity geophysical techniques military systems picture processing remote sensing by radar;caractere morphologique enfoui;caracter morfologico oculto;system testing;algorithms;bistatic;imagineria;radar biestatico;geoelectric;mine;forward looking;dielectrics;3 5 ghz;wave propagation;frequency;mina;bistatic radar;terrestrial electricity;procesamiento senal;target detection;shallow subsurface objects;s band system;technique;geophysical techniques;isolated target;algoritmo;radar bistatique	In this work, the principles of a bistatic (forwardlooking) system equipped with the capability for location and imaging of isolated shallow, subsurface objects is presented. Simple signal processing tools are developed, which are subsequently employed on experimental data obtained using an S-band system (3.5 GHz) on several objects of interest observed under ideal test-bed conditions. The results of signalhmage processing using measured data are presented that attest to the success in identifying isolated target signatures under these ideal conditions, and also indicate further need for sophisticated signal/image processing based on improved wave propagation models.	antivirus software;image processing;signal processing;software propagation;subsurface scattering;testbed	Tayfun Ozdemir;Sumit Roy;Raymond S. Berkowitz	1992	IEEE Trans. Geoscience and Remote Sensing	10.1109/36.142925	image processing;hydrology;bistatic radar;signal processing;physics;remote sensing		81.02893536965115	-67.53593300592574	85933
73b58f3132dde557b82290befe0e809b6014e312	comparison of two water vapor retrieval algorithms for hj1a hyperspectral imagery	hyperspectral imagery;water vapor;hj 1a;absorption;water absorption;absorption atmospheric modeling modis atmospheric measurements accuracy hyperspectral imaging aerosols;radiometric calibration;atmospheric measurements;hj 1a hyperspectral columnar water vapor content;systematic error;water atmospheric humidity atmospheric optics atmospheric techniques radiometers remote sensing;atmospheric humidity;columnar water vapor content;accuracy;atmospheric optics;remote sensing;modis;h 2 o water vapor retrieval algorithm hj1a hyperspectral imagery environment and disaster monitoring microsatellite constellation hyperspectral imager hypespectral imagery weak water absorption band continuum interpolated band ratio atmospheric precorrected differential absorption cibr algorithm modis product radiometric calibration wavelength 820 nm;atmospheric techniques;atmospheric modeling;hyperspectral imaging;hyperspectral image;water;hyperspectral;radiometers;spectral resolution;aerosols	HJ-1A is one member of the Environment and Disaster Monitoring Microsatellite Constellation, which carries a HyperSpectral Imager (HSI) with the spectral resolution about 5nm from 450nm to 950nm. Retrieving columnar water vapor content is essential to the quantitative applications of hypespectral imagery. The ideal best band (940nm) for water vapor retrieval has lower signal-tonoise( S/N) value. In this paper, we choose another weak water absorption band (820nm) to retrieval the columnar water vapor content. Two common water vapor retrieval algorithms, called the Continuum Interpolated Band Ratio (CIBR) and the Atmospheric Precorrected Differential Absorption (APDA), are implemented and compared with each other. Simulation results show that these two algorithms have less difference in the accuracy of water vapor retrieval because the weak water vapor absorption effect in 820nm. The water vapor contents derived from HJ-1A HSI by CIBR algorithm are compared with MODIS products and a systematic error may exist in the radiometric calibration of HSI.	algorithm;horizontal situation indicator;image sensor;interpolation;nanophotonic coherent imager;simulation	Hao Zhang;Zhengchao Chen;Bing Zhang;Dailiang Peng	2011	2011 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2011.6049570	meteorology;atmospheric sciences;hyperspectral imaging;physics;remote sensing	Vision	82.37449120840532	-61.948859087851396	85975
fb05295844828c5c3620c8ff395c755109a8edb7	modeling large-area influence in digital halftoning for electrophotographic printers	printing;halftones;electrophotography;modeling	Digital halftoning provides a mechanism for rendering continuous-tone images on devices such as printers. With electrophotography, the deposition of toner within the area of a given printer addressable pixel is strongly influenced by the halftone values of the immediately neighboring pixels. To account for these effects, it is necessary to embed a printer model in the halftoning algorithm. In our previous work, we used an efficient strategy to account for the impact of a 5×5 neighborhood of pixels on the central pixel absorptance. Now we examine the potential influence of a much larger neighborhood (45×45) of the digital halftone image on the measured value of a printed pixel at the center of that neighborhood. The experiment shows that the extended model yields a significant improvement in the accuracy of the prediction of the pixel values of the printed and measured halftone image.	algorithm;physical vapor deposition;pixel;printed circuit board;printer (computing);printing;toner	Yanling Ju;Dhruv Saxena;Tamar Kashti;Dror Kella;Doron Shaked;Mani Fischer;Robert Ulichney;Jan P. Allebach	2012		10.1117/12.912769	computer vision;systems modeling;multimedia;error diffusion;physics;xerography;computer graphics (images)	HCI	63.98523108020598	-59.09680953076206	85984
d35e4d8d09fd3b053103aed4f260cdde7ff4eab0	on huynen's decomposition of a kennaugh matrix	decomposition;target extraction radar polarimetry scattering matrix huynen decomposition kennaugh matrix;matrix decomposition radar scattering symmetric matrices polarization scattering parameters radar polarimetry acoustic reflection radar theory educational programs;s matrix theory;scattering matrices;remote sensing by radar;radar polarimetry;remote sensing;radar imaging;scattering matrix;scattering matrix decomposition kennaugh matrix radar polarimetry;kennaugh matrix;huynen decomposition;s matrix theory radar polarimetry remote sensing by radar;target extraction	For some special case, Huynen's decomposition cannot be used to extract a desired target from an average Kennaugh matrix. In this paper, the authors modify Huynen's method for overcoming its disadvantage, based on a simple transform of a Kennaugh matrix. Using an example, the effectiveness of the modified method is validated		Jian Yang;Yingning Peng;Yoshio Yamaguchi;Hiroyoshi Yamada	2006	IEEE Geoscience and Remote Sensing Letters	10.1109/LGRS.2006.873229	s-matrix;optics;decomposition;radar imaging;physics;remote sensing	Robotics	73.4238536112583	-66.73020759860032	85994
34b5b5b4f9739e274391515675b13f9b12370990	a fast rendering method for a scene with participating media of anisotropic scattering property	image sampling;participating media;probability;probability density;spherical harmonic;probability density function;brightness;global illumination;netcommons;ray tracing;layout anisotropic magnetoresistance rendering computer graphics light scattering particle scattering equations image sampling monte carlo methods computer graphics lighting;probability rendering computer graphics image sampling ray tracing brightness lighting;cms;lighting;maple;spherical harmonic fast rendering method participating media anisotropic scattering property global illumination rendering ray marching method high quality image computational time image sampling probability density function radiance distribution 3d space grid structure;importance sampling;rendering computer graphics	"""This paper presents an efficient technique for global illumination rendering of a scene with participating media. The rendering handling participating media is performed by ray marching method, which requires sampling along each view direction. The step size of the ray marching must be taken short to generate a high quality image and thus leads to very long computational time. One possible method to improve the computational cost is to exploit importance sampling. In this paper, we propose a method to determine the step size based on the importance sampling technique. For efficient sampling, the probability density function which is """"close"""" to the radiance distribution is required. In our method, 3D space is divided into a set of uniform grids. The radiance distribution is approximated using the grid structure. To deal with the participating media which has anisotropic scattering property, we use spherical harmonics to represent directional dependence of radiance distribution. Using this grid-based representation, fast calculation of good approximation of desirable probability density is made possible. Using this probability, high quality image can be rendered with fewer number of sampling compared to the conventional methods."""	algorithmic efficiency;approximation algorithm;coefficient;display resolution;expect;experiment;global illumination;image quality;importance sampling;legendre polynomials;polynomial;rendering (computer graphics);sampling (signal processing);subsurface scattering;time complexity;volume ray casting;voxel	Yusuke Tokuyoshi;Minoru Maruyama	2005	International 2005 Computer Graphics	10.1109/CGI.2005.1500423	computer vision;probability density function;computer science;mathematics;statistics;computer graphics (images)	Visualization	64.33894791928708	-53.19253013264202	86028
d281307b2fce1a6b064b78536e5ec04e3ef36217	an advanced fpga-based processor and controller for the next-generation precipitation radar	field programmable gate array;pr 2;atmospheric precipitation;new technology;precipitation radar;radar remote sensing;on board processor;next generation precipitation radar;process capability;meteorological radar;ctu;high performance digital processing;prototypes;adaptive control;precipitation meteorology;programmable control;controller;adaptive timing controller;radar equipment;onboard data processing;dwell time;atmospheric measuring apparatus;on board processing;remote sensing by radar;precipitation radar fpga on board processing control;geophysical signal processing;36 ghz;controllers;adaptive arrays;process control;next generation;shf;rain;pulse compression;pulse compression processor;instrument;36 ghz shf ehf radar remote sensing atmosphere instrument radar equipment advanced fpga based processor controller next generation precipitation radar meteorological radar pr 2 high performance digital processing field programmable gate arrays pulse compression processor adaptive timing controller on board processing spaceborne radar on board processor adaptive scanning control and timing unit ctu 14 ghz;advanced fpga based processor;radar signal processing rain atmospheric precipitation atmospheric techniques meteorological radar atmospheric measuring apparatus remote sensing by radar spaceborne radar geophysical signal processing;atmospheric techniques;ehf;field programmable gate arrays;atmosphere;adaptive scanning control and timing unit;nasa;high performance;14 ghz;radar signal processing;process control spaceborne radar field programmable gate arrays programmable control adaptive control timing prototypes nasa rain adaptive arrays;spaceborne radar;timing	With the success of the Precipitation Radar on the Tropical Rainfall Measuring Mission (TRMM), a new class of spaceborne precipitation radars are being developed for the TRMM follow-on missions, such as the Global Precipitation Mission. The Next-Generation Precipitation Radar (PR-2) prototyped by NASA/ JPL will depend heavily on high-performance digital processing to collect meaningful rain echo data. Using field-programmable gate arrays (FPGAs), we have developed for the PR-2 a compact, radiation tolerant data processor and adaptive timing controller that will permit full on-board processing capabilities from a 14 and 36 GHz spaceborne radar. Several enabling technologies are included in the PR-2 processor for sensitive rain rate detection (0.5 mm/hr), high range resolution (250 m) and wide swath coverage (500 km). To reduce sea surface clutter, a complex, 20 x lo9 op/s pulse compression filter with a range sidelobe performance of -60 dB is designed into each data processor FPGA. Fading noise within each echo is also reduced by 4.5 dB, using wideband chirp radar and range averaging techniques. Alongside the processor core, a novel control and timing unit (CTU) FPGA allows the PR-2 to use its own “quick-scan” data to electronically steer the radar beam to only those areas which contain precipitation, and to ignore areas that are precipitation-free. The transmit/receive timing solution generated by the CTU is 90% efficient and yields an order-of-magnitude increase in the number of independent looks for each rain bin. In the summer of 2001, the processor core was successfully tested in our airborne prototype of the PR-2 which was deployed during the 4th Convection and Moisture Experiment (CAMEX-4). The first 14 and 36 GHz rain echo data sets collected in CAMEX-4 demonstrate the PR-2’s high spatial resolution and sensitivity over a range of rain rates. Presently, new versions of the data processor and CTU firmware are being developed to realize features of the spaceborne PR-2, like the adaptive scanning method and echo averaging. The research described in this paper was carried out by the Jet Propulsion Laboratory, California Institute of Technology, under contract with the National Aeronautics and Space Administration. *Preferred topic area: Advanced Passive and Active Sensors, oral session (F.02)		Andrew C. Berkun;Mark A. Fischman;Eastwood Im	2002		10.1109/IGARSS.2002.1025684	adaptive control;process control;physics;field-programmable gate array;remote sensing	HPC	78.86654340523457	-64.03569936958313	86046
2d909f07b8d2cc875b25fb5db78bf5bc9098e33c	robust super resolution of compressed video		This paper presents a robust algorithm to recover high-frequency information from compressed low-resolution (LR) video sequences. Previous super-resolution (SR) approaches have succeeded in resolution enhancement when the motion in the LR sequence is simple. However, when the motion is complex, new artifacts will be introduced in the SR processing. To solve this problem, we develop a robust Bayesian SR algorithm with two steps. We first isolate the frames individually to get their corresponding initial SR solutions within the Bayesian framework. Secondly, with a robust cost function to reject outliers and noise, final SR images are achieved with multiple LR frames. In the mean time, we impose the constraint that the distribution of high-resolution (HR) image gradient should be equal to one of the corresponding decompressed LR images to sharpen the edges of the results. As a result of these steps, we are able to produce high-quality deblurred results, which show a suppressing of high-frequency artifacts and less ringing artifacts, with a higher peak signal-to-noise ratio (PSNR).	algorithm;artifact (software development);bayesian network;data compression;high-resolution scheme;image gradient;image resolution;iteratively reweighted least squares;lr parser;loss function;peak signal-to-noise ratio;ringing artifacts;super-resolution imaging	Xiaohong Zhang;Min Tang;Ruofeng Tong	2011	The Visual Computer	10.1007/s00371-011-0666-8	computer vision;speech recognition;mathematics;computer graphics (images)	Vision	56.331413391475216	-59.44037807813874	86049
aaf79c91f0e27c1339267a02fdb07e9bd087d17f	enhancing space situational awareness using passive radar from space based emitters of opportunity	global positioning system trajectory receivers space debris arrays radar tracking signal to noise ratio;radar tracking;receivers;arrays;space debris;trajectory;global positioning system;space users space situational awareness enhancement passive radar emitters of opportunity space debris debris trajectories telescopes prediction accuracy update frequency performance budget global navigation satellites;space situational awareness space debris gnss gps bistatic radar;signal to noise ratio;telescopes passive radar satellite navigation space debris	Space debris is a growing hazard to space users. Debris trajectories must be accurately predicted to maintain safe space access. Accurate predictions are premised on precise knowledge of the current trajectory, and a detailed understanding of disturbances that affect the future trajectory. Both tasks are facilitated by accurate and timely tracking of debris. It is possible to track space debris using radar and telescopes, yet both are expensive and result in unacceptable trajectory projections due to limitations on both accuracy and update frequency. In this paper we consider the performance budget necessary to augment debris tracking by passive radar, initially using Global Navigation Satellites as emitters of opportunity.	hazard (computer architecture);matched filter;parallel computing;process gain;radar;resultant;software deployment;staring array	Craig R. Benson	2014	2014 Military Communications and Information Systems Conference (MilCIS)	10.1109/MilCIS.2014.7002727	simulation;radar lock-on;geography;geodesy;remote sensing	HCI	77.83809567272843	-65.74439077663995	86056
0fcb1938fa94a92c3f4450bfdb76b8349fca751e	fusion of pixel and object-based features for weed mapping using unmanned aerial vehicle imagery		The developments in the use of unmanned aerial vehicles (UAVs) and advanced imaging sensors provide new opportunities for ultra-high resolution (e.g., less than a 10 cm ground sampling distance (GSD)) crop field monitoring and mapping in precision agriculture applications. In this study, we developed a strategy for interand intra-row weed detection in early season maize fields from aerial visual imagery. More specifically, the Hough transform algorithm (HT) was applied to the orthomosaicked images for inter-row weed detection. A semi-automatic Object-Based Image Analysis (OBIA) procedure was developed with Random Forests (RF) combined with feature selection techniques to classify soil, weeds and maize. Furthermore, the two binary weed masks generated from HT and OBIA were fused for accurate binary weed image. The developed RF classifier was evaluated by 5-fold cross validation, and it obtained an overall accuracy of 0.945, and Kappa value of 0.912. Finally, the relationship of detected weeds and their ground truth densities was quantified by a fitted linear model with a coefficient of determination of 0.895 and a root mean square error of 0.026. Besides, the importance of input features was evaluated, and it was found that the ratio of vegetation length and width was the most significant feature for the classification model. Overall, our approach can yield a satisfactory weed map, and we expect that the obtained accurate and timely weed map from UAV imagery will be applicable to realize site-specific weed management (SSWM) in early season crop fields for reducing spraying non-selective herbicides	aerial photography;algorithm;binary image;coefficient of determination;cross-validation (statistics);feature selection;ground sample distance;ground truth;hough transform;image analysis;image resolution;linear model;machine learning;mean squared error;object-based language;pixel;radio frequency;random forest;sampling (signal processing);semiconductor industry;sensor;unmanned aerial vehicle	Junfeng Gao;Wenzi Liao;David Nuyttens;Peter Lootens;Jürgen Vangeyte;Aleksandra Pizurica;Yong Jun He;Jan G. Pieters	2018	Int. J. Applied Earth Observation and Geoinformation	10.1016/j.jag.2017.12.012	cross-validation;geography;remote sensing;precision agriculture;computer vision;weed;ground sample distance;random forest;ground truth;feature selection;hough transform;artificial intelligence	Vision	78.67533194252911	-56.74672392336602	86153
ba976bf17dff19db6e006d608740e6c47f696873	moiré-free color halftoning using hexagonal geometry and spot functions	halftones	Hexagons are widely observed as a packing or tiling geometry in nature, yet they appear to have been avoided in conventional halftone tiling. A goal of the present study is to understand the potential barriers that have prevented their use and present new halftone geometry options that overcome the issues while offering several potential benefits. While conventional halftone geometries often include the fourth screen (e.g., yellow) in a suboptimal manner, the hexagonal geometry presented here can include a clustered-dot fourth screen moiré-free. Hexagonal screens can appear to have smoother texture. Due to differences in packing geometry and touch point geometry, hexagons have the potential to possess different tone reproduction characteristics, which may be favorable for somemarking processes. We also present a parametrically controlled hexagonal halftone spot function that allows for optimization of dot touch points and provides compact growth. The controllable touch points can prevent a tone reproduction discontinuity, while the compact growth throughout the gray range ensures maximum stability. Additionally, we present a three-colorant dot-off-dot halftone configuration using hexagonal geometry. Examples are provided. © 2012 SPIE and IS&T. [DOI: 10.1117/1.JEI.21.1.013017]	approximation;cell (microprocessor);color;frequency band;item unique identification;jan dietz;mathematical optimization;monochrome;pixel;printing;reflections of signals on conducting lines;set packing;texture mapping;tiling window manager	Shen-Ge Wang;Robert P. Loce	2012	J. Electronic Imaging	10.1117/1.JEI.21.1.013017	computer vision;computer science;mathematics	Graphics	60.46898897753598	-60.23612784866587	86166
68e6e0c609c0e0657ab504176611c0d2622696ee	a landslide monitoring technique based on dual-receiver and phase difference measurements	terrain factors receivers monitoring arrays phase measurement synthetic aperture radar geophysical measurements;radio transceivers demodulation geomorphology geophysical signal processing geophysical techniques;geomorphology;demodulation;geophysical signal processing;remote monitoring detection algorithm displacement measurement geophysical measurement system land surface;landslide movement landslide monitoring technique dual receiver measurement phase difference measurement landslide detection technique transmitter array signal transmission phase difference change dual receiver system critical area landslide signal demodulation ambiguity route;radio transceivers;geophysical techniques	A new landslide detection technique that installs a transmitter (Tx) array at the area of interest to transmit signals to two receivers is presented. It detects the phase difference change, due to the Tx displacement, at the dual-receiver system to monitor near real time of small but critical area landslide in centimeter range. The dual-receiver system, apart at a small distance, demodulates the receiving signals independently but coherently. An ambiguity route, which corresponds to a landslide's movement without change on phase difference, is defined and must be avoided. No field test was tried, but three simulated examples are given to illustrate the technique.	and-or-invert;ambiguity function;diagram;displacement mapping;real-time computing;sensor;transmitter	Bu-Chin Wang	2013	IEEE Geoscience and Remote Sensing Letters	10.1109/LGRS.2012.2236298	hydrology;geotechnical engineering;demodulation;remote sensing	EDA	79.53225707381687	-66.26214998375592	86170
89942f3b78ec21937f3ec25ce8c609a7a38d598d	influence of the smooth region on the structural similarity index	the structural similarity ssim index;visual quality;weighting function;image quality metric;spatial pooling;indexation;image quality assessment;weight function;structural similarity	The Structural Similarity (SSIM) Index is a very popular image quality assessment algorithm due to its good performance and simple calculation. This paper analyzes the influence of the smooth region on the performance of SSIM. It was found out that SSIM tends to depend on the quality of the smooth region to assess the quality of the whole image. From analysis by means of the SSIM quality map, we found out that SSIM overestimated the importance of the smooth region to visual quality. So in this paper we proposed a new weighting function as the spatial pooling method. The resultant weighted-SSIM outperforms the classic SSIM by a considerable amount.	algorithm;image quality;resultant;software quality;structural similarity;weight function	Songnan Li;King Ngi Ngan	2009		10.1007/978-3-642-10467-1_74	weight function;data mining;information retrieval;statistics	Vision	62.227211724467246	-64.39780735705222	86173
a87f3e346963fdf15bda49b1874955d9a3458d5f	the time-reversal technique for sar focusing of buried targets : theoretical improvements and practical limitations	tutorials synthetic aperture radar ground penetrating radar airborne imaging surface treatment radar imaging;synthetic aperture radar ground penetrating radar radar imaging remote sensing by radar soil;surface treatment;ground penetrating radar;buried targets time reversal based airborne ground penetrating radar tr agpr time reversal synthetic aperture radar sar trsar focusing soil imaging;tutorials;radar imaging;airborne imaging;synthetic aperture radar	This tutorial-style article presents the novel concept of time-reversal-based airborne ground penetrating radar (TR-AGPR) and its application for soil imaging and gives a brief description of the time-reversal synthetic aperture radar SAR (TRSAR) focusing algorithm. The intent of this article is to answer the question as to whether the time-reversal based algorithm is a feasible technique for SAR focusing of a buried target (structure).	airborne ranger;algorithm;dhrystone;t-symmetry	Robert Kedzierawski;Jean-Marc Le Caillec;Witold Czarnecki	2014	IEEE Signal Processing Magazine	10.1109/MSP.2014.2311165	early-warning radar;continuous-wave radar;space-based radar;radar engineering details;synthetic aperture radar;radar lock-on;ground-penetrating radar;radar configurations and types;bistatic radar;3d radar;interferometric synthetic aperture radar;radar imaging;inverse synthetic aperture radar;side looking airborne radar	Visualization	79.70259252267758	-65.08630412118652	86188
8c42f797a441ef8542cec4510510de2f71a5e441	sparse and low rank hyperspectral unmixing		In this paper, hyperspectral data is modeled as a combination of a sparse component, a low rank component and noise. The low rank component is a product of the endmembers and the abundances in an image, and the sparse component is composed of outliers and structured noise. Outliers and structured noise in this context are, e.g. band specific noise, vertical or horizontal artifacts or saturated pixels. Sparse and low rank matrix decomposition (SLR) is a method that has recently been developed for estimating those components. Here, an algorithm based on l1 SLR is developed using sparse blind hyperspectral unmixing and soft thresholding. The number of endmembers and the sparsity parameters are selected using the extended Bayesian information criterion (EBIC). The proposed algorithm is evaluated using a real remote sensing hyperspectral image.	algorithm;artifact (software development);bayesian information criterion;image noise;pixel;sparse matrix;thresholding (image processing)	Jakob Sigurdsson;Magnus Orn Ulfarsson;Johannes R. Sveinsson	2017	2017 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)	10.1109/IGARSS.2017.8126936	computer vision;pixel;artificial intelligence;outlier;low-rank approximation;sparse matrix;computer science;hyperspectral imaging;thresholding;bayesian information criterion;matrix decomposition	Robotics	67.86737543143731	-66.58255638000607	86223
40a7153a3d9236cefcf5b595038702b1db90791e	image registration using autolandmark	goodness of fit;image registration extraterrestrial measurements satellites clouds layout image databases image edge detection monitoring space vehicles fuzzy logic;quality metric;landmark measurements;atmospheric measurements;weather forecasting atmospheric techniques clouds fuzzy logic geophysical signal processing image matching image registration storms terrain mapping;image matching;real time;weather forecasting;landmark shoreline;cloudy pixels;fuzzy logic;cloud detection process;automated image registration;storms;cloud mask;geophysical signal processing;clouds;image registration;correlation algorithm;cloudy scenes;atmospheric techniques;terrain mapping;automatic image registration technique;autolandmark;digital map;shoreline extraction;geostationary operational environmental satellite;replacement product monitor;cloud mask autolandmark automatic image registration technique real time landmark registration correlation algorithm landmark shoreline shoreline extraction digital map cloud detection process cloudy pixels cloudy scenes quality metric image matching replacement product monitor geostationary operational environmental satellite goes imagery goes spacecraft ground system landmark measurements fuzzy logic;goes spacecraft ground system;real time landmark registration;digital mapping;goes imagery	AutoLandmark is a fully automated image registration technique capable of performing real time landmark registration. It's based on a correlation algorithm used to match the shoreline of a measured landmark to the corresponding shoreline extracted from a digital map. A cloud detection process implemented in AutoLandmark identifies cloudy pixels to avoid erroneous measurements from cloudy scenes. The validity of a measurement obtained with Autolandmark is determined by a quality metric (QM) which is calculated using several factors including the goodness-of-fit of the matching algorithm, scene cloudiness, and scene contrast. AutoLandmark is implemented in the Replacement Product Monitor (RPM) for landmark registration of the Geostationary Operational Environmental Satellite (GOES) imagery with subpixel accuracy. The RPM is part of the GOES Spacecraft Ground System and has been operational since 2001, producing more than a thousand daily landmark measurements	algorithm;bertrand (programming language);carr–benkler wager;distortion;gshhg;generic mapping tools;image registration;image resolution;intel mcs-48;larry l. peterson;pixel;vector graphics	Houria Madani;James L. Carr;Cathya Schoeser	2004	IGARSS 2004. 2004 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2004.1369945	fuzzy logic;meteorology;computer vision;digital mapping;weather forecasting;computer science;image registration;geostationary operational environmental satellite;goodness of fit;storm;physics;remote sensing;computer graphics (images)	Robotics	77.08257932581752	-60.914137007295864	86300
493e56d16abb76b54262155a658cde9d79cc7fa5	lightweight linear broadband antennas enabling small uav wing systems and space flight nanosat concept	space flight;interferometric radiometer;dielectric backing structure;microwave measurements;antenna arrays;doppler beam synthesis linear broadband antennas uav wing systems radstar interferometric radiometer digital beam forming scatterometer earth surface backscatter nasa p 3 commercial off the shelf design materials remote sensing soil moisture unmanned aerial vehicles dielectric backing structure nano satellite mission l band imaging scatterometer small business innovative research active passive hydrology mission;unmanned aerial vehicle;small business innovative research;uav wing systems;remotely operated vehicles;broadband antennas unmanned aerial vehicles spaceborne radar l band radiometry radar measurements nasa dielectric materials prototypes radar antennas;cross polarization;l band imaging scatterometer;hydrologic measurements;moisture measurement;hydrological equipment;radstar;radiometry;remote sensing by radar;nano satellite mission;soil airborne radar antenna arrays broadband antennas hydrological equipment hydrological techniques microwave measurement moisture measurement radiometers radiometry radiowave interferometry remote sensing by radar remotely operated vehicles;rapid prototyping;commercial off the shelf;microwave measurement;remote sensing;radar imaging;instrument development;low mass;active passive hydrology mission;soil moisture;radiowave interferometry;broadband antennas;airborne radar;emission measure;earth surface backscatter;antenna array;linear broadband antennas;doppler beam synthesis;soil;radio interferometry;digital beam forming;unmanned aerial vehicles;radiometers;commercial off the shelf design materials;hydrological techniques;nasa p 3;aspect ratio;digital beam forming scatterometer	The RadSTAR initiative merges an interferometric radiometer with a digital beam forming scatterometer, providing Earth surface backscatter and emission measurements. Heretofore these instrument developments have been designed for low flying brown platforms such as the NASA P-3. Commercial-off-the-shelf design materials can be used to inexpensively build antennas that approximate free-space permittivity, enabling remote sensing of soil moisture levels locally using small Unmanned Aerial Vehicles (UAVs). A foam/free-space sandwich can be used to minimize the weight of the dielectric backing structure. This technique enables rapid prototyping with space-grade materials. A low-mass 3-element antenna array of this design is already baselined for a University nano-satellite mission. A light-weighted version of the L-band Imaging Scatterometer (US) radar electronics is being developed for a Small Business Innovative Research (SBIR) program. This lightweight wing antenna has a large potential payoff to NASA. For example, it may enable an active/passive hydrology mission using a fleet of low cost small UAVs. A mesh ground plane can further reduce the overall mass and stowability of the very large antennas required for spaceborne observations at L-Band. The cross track scan success criterion was met at L-Band frequencies for radar and radiometry. That is, we designed and prototyped a wideband antenna patch tunable in this range and additional work is being earned out to improve the cross polarization isolation. Making the present broadband design into arrays will be limited to one dimension due to array spacing and the aspect ratio of the patch elements. A fore and aft Doppler beam synthesis and the US cross-track beam forming concept will be considered for potential application to surface hydrology measurements using these arrays	aerial photography;approximation algorithm;beamforming;gnu nano;l band;nasa/ipac extragalactic database;polarization (waves);radar;rapid prototyping;unmanned aerial vehicle	Lawrence Hilliard;James Mead;Rafael F. Rincon;Peter H. Hildebrand	2004	IGARSS 2004. 2004 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2004.1370484	remotely operated underwater vehicle;meteorology;aspect ratio;radiometry;cross-polarized wave generation;water content;spaceflight;radiometer;optics;radar imaging;antenna array;physics;remote sensing	Robotics	80.66960459041655	-63.76093943958966	86347
1bafdbdd852d86a627ae5013547fbfad87a79a4b	terrasar-x data for high-precision land subsidence monitoring: a case study in the historical centre of hanoi, vietnam	land subsidence;terrasar x;heritage culture assets;historical centre of hanoi;small baseline interferometry;synthetic aperture radar	In this study, subsidence patterns in the Historical Centre of Hanoi, Vietnam are mapped using the Interferometric Synthetic Aperture Radar (InSAR) technique, with particular emphasis on the stability of ancient monuments, historical buildings and archaeological sectors. Due to the small and scattered characteristics of these structures, not only is a comprehensive coverage of radar targets needed, but also the details of a single building or monument. We took advantage of the high-resolution TerraSAR-X imagery with the aid of oversampling implementation on the Small Baseline (SB) InSAR approach to reveal the subsidence patterns. A total of 6.29 million radar targets were obtained, maintaining the average density of 217,012 points/km2. Our results suggest that image oversampling not only increased the number of measurement points 4.4 times more than the standard processing chain, but also removed some of the noisiest points. The observed subsidence patterns are mostly related to adjacent groundwater extraction and construction activities, with maximum subsiding rate reaching  ́18.1 mm/year for the study period April 2012 to November 2013. Generally, heritage assets and monuments in the Citadel, the Old Quarter and French Quarter remain in a steady state, whereas those located along the Red River and in southern Hanoi are subject to subsidence.	aperture (software);baseline (configuration management);decorrelation;image resolution;level of detail;oversampling;pixel density;radar;real-time clock;real-time computing;sandy bridge;sensor;steady state;synthetic data;velocity (software development)	Tuan S. Le;Chung-Pai Chang;Xuan T. Nguyen;Akano Yhokha	2016	Remote Sensing	10.3390/rs8040338	subsidence;synthetic aperture radar;remote sensing	HCI	81.13573142865815	-60.70287605897897	86432
3152a528728f40a65dea19db7e60a035c364c411	considerations for derivation and use of soil moisture data from active microwave satellites at high latitudes	vegetation mapping;active microwave;synthetic aperture radar hydrology moisture remote sensing by radar soil;snow;backscatter;scansar mode soil moisture data active microwave satellites carbon exchange permafrost freezing thawing landscape heterogeneity envisat asar;wide swath;arctic;remote sensing by radar;scatterometer soil moisture arctic active microwave sar;landscape heterogeneity;sar;scatterometer;monitoring;moisture;soil moisture backscatter radar measurements monitoring satellites snow vegetation mapping;satellites;soil moisture;hydrology;soil;radar measurements;semi arid region;synthetic aperture radar	Soil moisture is an import parameter for high latitude research focusing on carbon exchange and permafrost issues. This paper reviews requirements, constrains and possibilities of satellite derived soil moisture data for high latitude applications. Major points are freezing and thawing, and landscape heterogeneity. Special focus is on data derived from ENVISAT ASAR. The different ScanSAR modes (wide swath and global monitoring mode) can be used to address various issues. Sensitivity over tundra at this wavelength is similar to semi-arid regions in mediterranean and subtropic climates.	microwave;requirement;semiconductor industry	Annett Bartsch;Daniel Sabel;Wolfgang Wagner;Sang-Eun Park	2011	2011 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2011.6049882	moisture;snow;synthetic aperture radar;arctic;water content;geology;hydrology;specific absorption rate;soil science;backscatter;physics;satellite;remote sensing	Embedded	82.48987483479637	-61.565432192688604	86440
758ed1f5c971239b6f9fe8958bef1b84014345fe	a fuzzy-based impulse noise detection and cancellation for real-time processing in video receivers	fuzzy based algorithm;nonlinear filters;video receivers;circuit noise;fuzzy based average threshold filter;video signal processing;filter architecture;real time;impulse noise;information filtering;low computational complexity;real time processing;real time hardware design;fuzzy based impulse noise cancellation;fuzzy based impulse noise detection;indexing terms;receivers;fuzzy logic;computational modeling;noise cancellation nonlinear filters computational complexity hardware image quality circuit noise computational modeling information filtering information filters fuzzy logic;fuzzy;video equipment;computational complexity;image quality;noise filtering;noise cancellation;real time hardware design fuzzy based impulse noise detection fuzzy based impulse noise cancellation real time processing video receivers fuzzy based algorithm images real time applications filter architecture fuzzy based average threshold filter noise filtering low computational complexity;hardware design;real time applications;image denoising;video equipment impulse noise image denoising fuzzy logic filtering theory real time systems computational complexity nonlinear filters video signal processing receivers;noise detection;information filters;real time application;noise filter;filtering theory;images;hardware;real time systems	In this paper, a simple fuzzy-based algorithm to remove the impulse noise from images is proposed. To achieve real-time applications, the proposed filter architecture, which combines fuzzy noise detection and noise filtering, is also designed. With low computational complexity, simulation results show that the proposed filters effectively remove the impulse noise.	algorithm;computational complexity theory;impulse noise (audio);real-time clock;simulation	Chung-Bin Wu;Bin-Da Liu;Jar-Ferr Yang	2003	IEEE Trans. Instrumentation and Measurement	10.1109/TIM.2003.814677	fuzzy logic;median filter;image noise;computer vision;electronic engineering;computer science;noise measurement;theoretical computer science;noise	EDA	57.007824377755625	-64.52761287144246	86542
e876623d7876f13117cc783ed423b03e7728785f	parallel processing of intersections for ray-tracing in application-specific processors and gpgpus	cuda;application specific;gpgpu;ray tracing;parallel architecture;asip	The ray tracing rendering algorithm can produce high-fidelity images of 3-D scenes, including shadow effects, as well as reflections and transparencies. This is currently done at a processing speed of 30 frames per second. Therefore, current implementations of the algorithm are not yet suitable for interactive real-time rendering, which is required in games and virtual reality based applications. Nonetheless, the algorithm allows for massive parallelization of its computations, which is a strong reason of further improvements. Also, we present a parallel architecture for ray tracing based on a uniform spatial subdivision of the scene that exploits an embedded computation of ray-triangle intersections. This approach allows for a significant acceleration of intersection computations, as well as a reduction of the total number of the required intersections checks. Furthermore, it allows for these checks to be performed in parallel and in advance for each ray. In this paper we discuss and analyze an ASIP-based implementation using FPGAs and a GPGPU-based parallel implementation of the proposed architecture, both running different 3-D scenes. The performance of both implementations are reported and compared. Furthermore, a second GPU has been included in the GPGPU-based implementation, running the same parallel architecture. Thus, primary rays are split among both GPUs for parallel execution and their performance are also presented and compared.	central processing unit;general-purpose computing on graphics processing units;ray tracing (graphics)	Alexandre Solon Nery;Nadia Nedjah;Felipe Maia Galvão França;Lech Józwiak	2013	Microprocessors and Microsystems - Embedded Hardware Design	10.1016/j.micpro.2012.06.006	embedded system;ray tracing;parallel computing;real-time computing;computer science;operating system;general-purpose computing on graphics processing units;computer graphics (images)	EDA	67.56328801236478	-52.21169344273303	86561
01e26bcc9bb9f29b55ae62cd965afa990889ee4e	the fifedom (frequent image frames enhanced digital orthorectified mapping) camera for automatic mapping of tree species and structures	tree structural properties;vegetation mapping;frames per second;tree species;fifedom camera;spatial distributions;digital camera;image sensors;frequent image frames enhanced digital ortho rectified mapping;bi directional reflectance signatures;near infrared;spatial distribution;vegetation mapping image sensors;remote sensing;tree structure;forest canopy;cost effectiveness;digital cameras lenses remote monitoring calibration hyperspectral imaging target tracking remote sensing layout tree data structures collimators;remote sensing method;forest canopies;near infrared band;forest management frequent image frames enhanced digital ortho rectified mapping fifedom camera remote sensing method spatial distributions tree species tree structural properties forest monitoring near infrared band bi directional reflectance signatures forest canopies;forest monitoring;forest management	The FIFEDOM (Frequent Image Frames Enhanced Digital Ortho- rectified Mapping) camera was designed to provide a cost-effective remote sensing method for the accurate acquisition bidirectional surface signatures, which for forest scenes is expected to yield information related to spatial distributions of individual tree species and tree structure with application in forest monitoring and management. Compared with existing regular digital cameras, the FIFEDOM camera has several unique features: (1) it can collect image data not only in the visible bands (550 nm and 670 nm), but also in the near-infrared band (800 nm); (2) it has a frame rate of up to 3 frames per second with a frame size of 3500 x 2300; and (3) it has a wide angular field view with 150 degrees along track and 78.8 degrees across track. Its high frame rate and wide angular field view allow it to obtain a sequence of images that over-sample ground target areas. The multi-angle database and bi-directional reflectance signatures of forest canopies can be generated from the over-sampled image data, which can be used to estimate metrics of tree structural properties.	angularjs;digital camera;orthophoto;tree structure;type signature	K. Frank Zhang;Baoxin Hu;John R. Miller;Lawrence Gray	2006	2006 IEEE International Symposium on Geoscience and Remote Sensing	10.1109/IGARSS.2006.283	near-infrared spectroscopy;tree canopy;computer vision;cost-effectiveness analysis;forest management;image sensor;tree structure;optics;frame rate;physics;remote sensing	Vision	78.77298831446693	-59.7056163670291	86594
eade2ffce4313b3e87b836e0ef4b19e5da04cc1a	a ground moving target detection approach based on shadow feature with multichannel high-resolution synthetic aperture radar	azimuth;clutter;synthetic aperture radar feature extraction clutter object detection azimuth signal to noise ratio;ground moving target detection approach detection algorithms multifeature fusion shadow detection method shadow aided method geometric relationships interferometric phase gmti ground moving target indication target signal to noise ratio multichannel high resolution synthetic aperture radar shadow feature;synthetic aperture radar geophysical techniques;feature extraction;synthetic aperture radar sar ground moving target indication gmti shadow feature;signal to noise ratio;object detection;synthetic aperture radar	With the observation distance of the radar increasing, the multichannel high-resolution synthetic aperture radar system may suffer from the reduction of the target signal-to-noise ratio, which leads to degradation in the detection performance for ground moving target indication (GMTI). Fortunately, the shadow feature, apart from the amplitude and interferometric phase of a moving target, may be available to improve the performance for target detection. In this letter, according to the geometric relationships between the moving object and its shadow in position and size, a shadow-aided method for GMTI is proposed. In addition, an efficient shadow detection method based on multifeature fusion is discussed to improve the shadow detection performance. Finally, numerical simulation results show that the shadow-aided method has a better detection performance, compared with the traditional detection algorithms.	algorithm;computer simulation;elegant degradation;experiment;image resolution;moving target indication;numerical analysis;radar;signal-to-noise ratio;synthetic data;theory	Huajian Xu;Zhiwei Yang;Guozhong Chen;Guisheng Liao;Min Tian	2016	IEEE Geoscience and Remote Sensing Letters	10.1109/LGRS.2016.2597159	stationary target indication;computer vision;synthetic aperture radar;moving target indication;feature extraction;computer science;radar horizon;pulse-doppler radar;clutter;azimuth;optics;radar imaging;inverse synthetic aperture radar;signal-to-noise ratio;side looking airborne radar;physics;remote sensing	Robotics	75.04125067751947	-66.2228493762801	86619
53045adafc5418e1ffc0e6b2e420816839a2a944	a method for measuring the incremental information contributed from non-stationary spatio-temporal data to be fused	spatio temporal estimation feature extraction bayesian networks information theory hydrology;belief networks;bayesian network;rivers;bayesian methods;spatio temporal estimation;spatio temporal bayesian network incremental information nonstationary spatio temporal data hydrologic problems stream discharge sensor fusion computational cost;spatio temporal data;bayesian methods fault location fluid flow measurement gain measurement electric variables measurement hydrologic measurements surface discharges sea measurements data engineering hydrological techniques;geophysical signal processing;feature extraction;remote sensing;spatiotemporal phenomena belief networks feature extraction geophysical signal processing hydrological techniques remote sensing rivers sensor fusion;spatiotemporal phenomena;rain;hydrology;partial discharges;sensor fusion;information gain;discharges;hydrological techniques;information theory;fault diagnosis;bayesian networks;fault location	Complex hydrologic problems, such as estimating stream discharge (flow), require the utilization (fusion) of multiple sets of measurements (features). Due to the computational cost of incorporating all available features, it is desirable to use a reduced set of the most informative ones. A method is presented for determining the information gain of different feature subsets in a Bayesian network. The method is applied to the problem of estimating flow in a Spatio-Temporal Bayesian Network (STBN), under the constraint that the features retain their original physical meaning.	algorithmic efficiency;bayesian network;computation;discharger;information gain in decision trees;kullback–leibler divergence;stationary process	Carolyn Krekeler;Karthik Nagarajan;K. Clint Slatton	2008	IGARSS 2008 - 2008 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2008.4778977	bayesian average;information theory;computer science;machine learning;pattern recognition;bayesian network;data mining	Robotics	73.02808904826459	-61.14767800732425	86634
314637f111e392695f7c956bd3e82009afdebe7d	fast local and global illuminations through a simd z-buffer	image processing;efficiency;local illumination;calculateur simd;traitement image;algorithme parallele;paralelismo masivo;global illumination;simd computer;simd parallelism;radiosity;hidden part removal;parallelisme massif;tampon z;massive parallelism;z buffer;parallel algorithms	The z-buffer is a well-known hidden-part removal technique commonly used by local illumination algorithms. Some global illumination approaches use this technique too, in order to approximate energy exchanges. In this paper we propose a massively parallel implementation of the z-buffer on the MP-1 machine. Efficiency is achieved by precisely studying the different stages of the algorithm, and by taking care in correctly using the SIMD control of the architecture. Local illumination models are then applied to the z-buffer algorithm, by using Gouraud and Phong's interpolations. Finally, the parallel z-buffer is used in a massively parallel radiosity algorithm. The results obtained allow to provide quickly illuminated images by decreasing dramatically the computation time required for global illumination.	simd;z-buffering	C. Renaud	1997	IJPRAI	10.1142/S0218001497000500	parallel computing;radiosity;image processing;computer science;theoretical computer science;z-buffering;parallel algorithm;efficiency;global illumination;computer graphics (images)	Vision	67.98806939351539	-54.54861310815861	86691
8501dfdbe5b8e8b281be39d3ba976e4fc2ce716d	inverse synthetic aperture radar phase adjustment and cross-range scaling based on sparsity		Abstract Due to inherent sparsity of ISAR images, compressive sensing theory has been used to obtain a high resolution image. However, before applying sparse recovery methods, the phase error due to the translational motion of target is compensated by autofocusing algorithms and the target rotation rate is estimated by cross-range scaling methods. In this paper, a comprehensive matrix model for a uniformly rotating target that includes the phase error and chirp-rate of the target is derived. Then by using sparsity and minimum entropy criterion, the estimation of residual phase error and the rotation rate is refined. In order to reduce the computational load, we simplify the model and by an iterative method based on adaptive dictionary, the phase error and chirp-rate are estimated separately. Actually, by exploiting a two-dimensional (2D) optimization method and the Nelder–Mead algorithm the phase adjustment is performed and the chirp-rate is estimated by solving a 1D optimization method for dominant range cells of the target. Finally, both simulation and practical data have been used to verify the validity of the proposed approach.	algorithm;chirp;computation;dictionary;emoticon;image scaling;iterative method;mathematical optimization;nelder–mead method;remote database access;simulation;sparse matrix;synthetic intelligence	Hamidreza Hashempour;Mohammad Ali Masnadi-Shirazi	2017	Digital Signal Processing	10.1016/j.dsp.2017.05.004	mathematical optimization;compressed sensing;mathematics;residual;iterative method;inverse synthetic aperture radar;scaling;matrix (mathematics)	Robotics	58.55006650891448	-74.21030577026497	86723
35342a786d355d6250a96f24c3b05e089f128658	remote sensing of coastal upwelling in the south-eastern baltic sea: statistical properties and implications for the coastal environment		A detailed study of wind-induced coastal upwelling (CU) in the south-eastern Baltic Sea is presented based on an analysis of multi-mission satellite data. Analysis of moderate resolution imaging spectroradiometer (MODIS) sea surface temperature (SST) maps acquired between April and September of 2000–2015 allowed for the identification of 69 CU events. The Ekman-based upwelling index (UI) was applied to evaluate the effectiveness of the satellite measurements for upwelling detection. It was found that satellite data enable the identification of 87% of UI-based upwelling events during May–August, hence, serving as an effective tool for CU detection in the Baltic Sea under relatively cloud-free summer conditions. It was also shown that upwelling-induced SST drops, and its spatial properties are larger than previously registered. During extreme upwelling events, an SST drop might reach 14 ◦C, covering a total area of nearly 16,000 km2. The evolution of an upwelling front during such intensive events is accompanied by the generation of transverse filaments extending up to 70 km offshore. An analysis of the satellite optical data shows a clear decline in the chlorophyll-a concentration in the coastal zone and in the shallow Curonian Lagoon, where it drops down by an order of magnitude. It was also shown that a cold upwelling front alters the stratification in the atmospheric boundary layer, leading to a sudden drop of air temperature and near-surface winds.	chlorophyll;environmental wind;large;moderate resolution imaging spectroradiometer;numerous;registration;sixty nine;square kilometer;stratification;tip (unix utility);transverse wave;unique identifier;user interface;wildlife corridor	Toma Dabuleviciene;Igor E. Kozlov;Diana Vaičiūtė;Inga Dailidiene	2018	Remote Sensing	10.3390/rs10111752			82.78092231217596	-58.10692163936262	86746
80b78d9c4cf518e147eec8896948c88ee67d2170	determination of the snpp viirs solar diffuser brdf degradation factor over wavelengths longer than 1μm	diffusers;sensors;bidirectional reflectance transmission function;physical oceanography;infrared imaging;short wave infrared radiation;satellites;orbital dynamics;calibration	To radiometrically calibrate its reflective solar bands, the Visible Infrared Imaging Radiometer Suite (VIIRS) aboard the Suomi National Polar-orbiting Partnership (SNPP) satellite observes a sunlit onboard solar diffuser (SD). Once on orbit, the bidirectional reflectance distribution function (BRDF) of the SD degrades over time. The degradation factor is determined by an onboard solar diffuser stability monitor (SDSM). However, the central wavelengths (414 to 929 nm) of the SDSM detectors do not cover the VIIRS short wave infrared (SWIR) bands which have central wavelengths from 1238 to 2257 nm. Although it is known that at wavelengths longer than 1 m the SD BRDF degrades at a much slower rate, the degradation at some of the SWIR bands’ central wavelengths may still be non-negligible as Ocean Color products often require a radiometric calibration stability of at least 0.1%. To access the SD BRDF degradation factor in the SWIR bands wavelength region, we investigate a phenomenological model and apply the model to determine the degradation factor in the SWIR bands wavelength region.	bidirectional reflectance distribution function;elegant degradation;phenomenological model;sensor;simple network paging protocol	Ning Lei;Xiaoxiong Xiong	2015		10.1117/12.2186633	meteorology;calibration;physical oceanography;sensor;orbital mechanics;optics;physics;satellite;remote sensing	Vision	82.68031931219798	-63.19081035194772	86828
a33fa4e7542ebc74e5b932be29fad050822e5ba4	a novel fuzzy filter for impulse noise removal	construction process;ncku 成功大學 成大 圖書館 機構典藏;fuzzy number;impulse noise;mean square error;dissertations and theses journal referred papers conference papers nsc reserach report patent nckur ir ncku institutional repostiory 博碩士論文 期刊論文 國科會研究報告 專利 成大機構典藏;decision process;subjective evaluation;knowledge base	In this paper, we propose a novel Neural Fuzzy Filter (NFF) to remove impulse noise from highly corrupted images. The proposed filter consists of a fuzzy number construction process, a neural fuzzy filtering process and an image knowledge base. First, the fuzzy number construction process will receive sample images or the noise-free image, then construct an image knowledge base for the neural fuzzy filtering process. Second, the neural fuzzy filtering process contains of a neural fuzzy mechanism, a fuzzy mean process, and a fuzzy decision process to perform the task of impulse noise removing. By the experimental results, NFF achieves better performance than the state-of-theart filters based on the criteria of Mean-Square-Error (MSE). On the subjective evaluation of those filtered images, NFF also results in a higher quality of global restoration.	circuit restoration;fuzzy number;impulse noise (audio);knowledge base;mean squared error	Chang-Shing Lee;Shu-Mei Guo;Chin-Yuan Hsu	2004		10.1007/978-3-540-28648-6_59	knowledge base;impulse noise;computer science;artificial intelligence;fuzzy number;mean squared error;operations research	AI	55.908705492456136	-65.3850741695803	86976
412647ea52bf16523126695b13afaecd16cf16cc	synthetic aperture radar observations of interannual ocean-atmosphere coupling over the somali current		The covariability of wind stress and sea surface temperature is observed at high resolution over the Western Arabian Sea. Synthetic aperture radar data were acquired over the Somali Current in 2016 and 2017 during the summer monsoon season. The Somali Current, the Southern Gyre and the Great Whirl were all observed at the time of these acquisitions. Wind stress curl derived from the synthetic aperture radar data show the effects of the cold upwelled coastal water and the Somali Current on the wind stress. Significant organized large eddies are also observed east of the Somali Current.	image resolution;numerical aperture;synthetic data;synthetic intelligence;curl	Michael J. Caruso;Hans Graber	2018	IGARSS 2018 - 2018 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2018.8517828	ocean gyre;remote sensing;climatology;wind stress;sea surface temperature;synthetic aperture radar;somali;monsoon;eddy;atmosphere;computer science	Visualization	82.66234516490256	-60.32980200022907	87006
95ba6569773f6428389f0e1259553c509bec33b1	litemaker: interactive luminaire development using progressive photon tracing and multi-resolution upsampling			upsampling	Katharina Krösl;Christian Luksch;Michael Schwärzler;Michael Wimmer	2017		10.2312/vmv.20171253	computer science;photon;artificial intelligence;upsampling;computer vision;computer graphics (images);image processing;ray tracing (graphics);computing methodologies;distributed ray tracing;tracing;beam tracing	HCI	65.83483305360716	-52.97698904082763	87061
47dc9cc167535ebf0917c783df1c3023a9c69643	depth from motion using critical point filters with unconstraint camera motion	camera motion estimation 2d to 3d video conversion depth map critical point filters;video signal processing;image matching;conference;motion estimation;iterative methods;image compression;feature extraction;pixels;initial depth map estimation depth from motion critical point filters unconstraint camera motion depth estimation 2d conversion 3d conversion monoscopic video image matching pixel level motion field extraction pseudo motion vectors camera moving model estimation robust ransac algorithm;video signal processing cameras feature extraction image matching iterative methods motion estimation;cameras	Depth estimation is a crucial step for 2D/3D conversion from monoscopic video. In this paper, a novel method for depth estimation from motion with camera motion is proposed. In the proposed method, image matching using critical point filters is applied to extract the pixel-level motion field for each frame. As camera motion can bring pseudo motion vectors by image matching, and thus leading to depth ambiguity. To solve this problem, we propose to estimate the camera moving model using robust RANSAC algorithm. Then, the initial depth map is estimated by using the motion vectors without camera motion. Finally, the depth values of the pixels at the edges of moving objects are refined using a post filter based on homogeneous points. Experimental results show that the proposed method achieves considerable performances on depth map in presence of camera motion.	algorithm;critical point (network science);depth map;glossary of computer graphics;image registration;motion field;performance;pixel;post-hartree–fock;random sample consensus	Yixiong Zhang;Binyou Deng;Jun Tang	2013	2013 IEEE International Conference on Image Processing	10.1109/ICIP.2013.6738461	computer vision;camera auto-calibration;match moving;structure from motion;feature extraction;image compression;quarter-pixel motion;computer science;motion interpolation;motion estimation;mathematics;block-matching algorithm;iterative method;motion field;motion compensation;pixel;computer graphics (images)	Vision	55.627172921373344	-55.162418601260384	87066
28d1ad19cfd2ab8ed8b74a20d89b30c87cdb498c	precise estimation of flight path for airborne sar motion compensation	los displacement synthetic aperture radar trajectory deviation;navigation data flight path precise estimation airborne sar motion compensation synthetic aperture radar airborne sar systems reference flight path line of sight displacement;synthetic aperture radar remote sensing by radar;estimation synthetic aperture radar electronics packaging trajectory navigation motion compensation azimuth	Airborne synthetic aperture radar (SAR) systems are very sensible to deviations of the aircraft to the reference flight path. The trajectory errors can be divided into along-azimuth errors and the line-of-sight (LOS) displacement, while the latter one is the main source of motion errors. The LOS displacement can be obtained from the navigation data in which an ideal flight path should be assumed first. However, the accuracy of the assumed nominal trajectory is limited especially in high resolution SAR systems. To improve the precision of the estimation of LOS displacement, we present a novel method to acquire a precise flight path in the imaging intervals. This method can estimate trajectory deviation precisely by making full use of the navigation data.	airborne ranger;aperture (software);displacement mapping;image resolution;line-of-sight (missile);motion compensation;synthetic data	Jincheng Li;Pengbo Wang;Chunsheng Li;Jie Chen;Wei Yang	2014	2014 IEEE Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2014.6946626	early-warning radar;man-portable radar;computer vision;continuous-wave radar;space-based radar;synthetic aperture radar;radar lock-on;radar configurations and types;geodesy;fire-control radar;bistatic radar;3d radar;interferometric synthetic aperture radar;radar imaging;inverse synthetic aperture radar;side looking airborne radar;radar;remote sensing	Robotics	78.4960452464836	-65.34221794468765	87246
be45e7a7b0e29fe96a0cbfb726e402d36ab3d9f5	image warping for 3-d reconstruction: robustness and efficiency	parameter estimation;image warping	Abstract: Many problems in medical imaging are stated in terms of parameterestimation. Given a proper parametric function local or globaloptimization procedures are applied to compute the best fit betweenthe chosen model and observed measurements. The mathematical formalizationof the tackled problem decides on the success of the finalalgorithm. We introduce a framework for practitioners which is usefulfor the definition of parameter estimation problems. The discussion ofthese techniques is...	image warping	Joachim Hornegger;Carlo Tomasi	2001			image restoration;robustness (computer science);image warping;computer vision;estimation theory;artificial intelligence;computer science	Vision	55.775103508228035	-75.07609757268635	87267
8b979a11e88d07f51f5240f6d34ccb037f87f338	multiscale versus multiresolution analysis for multisensor image fusion	image fusion;image resolution;wavelet transforms;multiresolution analysis;multiscale decomposition;multisensor image fusion method;quantitative evaluation;redundant wavelet transform;wavelet coefficients	In this paper, We propose a multisensor image fusion method based on the multiscale decomposition. In this representation, the redundant wavelet transform is performed on input images to emphasise the dominant details present at each scale. A fusion rule is applied between wavelet coefficients in order to produce a fused image. Two different fusion rules are used in the wavelet domain. A quantitative evaluation shows the superiority of our approach over the existing multiresolution method.	coefficient;image fusion;multiresolution analysis;stationary wavelet transform	Youcef Chibani;Amrane Houacine	1998	9th European Signal Processing Conference (EUSIPCO 1998)		multiresolution analysis;wavelet;computer vision;speech recognition;second-generation wavelet transform;continuous wavelet transform;pattern recognition;cascade algorithm;mathematics;wavelet packet decomposition;stationary wavelet transform;image fusion;discrete wavelet transform;fast wavelet transform;wavelet transform	Robotics	59.38620703650223	-67.27635580528477	87383
491d6ae8579d572601afafddb8a901e16ed0521f	reduction of the non-uniform illumination using nonlocal variational models for document image analysis		Abstract In this paper, we investigate two new reflectance and illumination decomposition models based on a nonlocal partial differential equation (PDE) applied to text images. Taking into consideration the higher regularity level of the illumination compared to the reflectance, we propose a nonlocal PDE which deals with repetitive structures and textures that characterize the text image much better compared to the classical local PDEs. The aim of this approach is to use the repetitive features of the reflectance to efficiently extract it from the non-uniform illumination. This idea is motivated by extending the range of application of the nonlocal operators to such a problem. Numerical experiments on both grayscale and color text images show the performance and strength of the proposed nonlocal PDE.	calculus of variations;image analysis;nonlocal lagrangian	Bárbara Tauffner;Mohammed El Rhabi;Abdelilah Hakim;Amine Laghrib	2018	J. Franklin Institute	10.1016/j.jfranklin.2018.08.012	grayscale;operator (computer programming);mathematical optimization;partial differential equation;reflectivity;mathematics	Vision	55.20627322095972	-70.239128059466	87407
d8e885bb9780fc586319f28e7ddcd54c99e4b7c5	comparative study on required bit depth of gamma quantization for digital cinema using contrast and color difference sensitivities	color difference;human visual system	A specification for digital cinema systems which deal with movies digitally from production to delivery and projection on the screens is recommended by DCI (Digital Cinema Initiative), and systems based on this specification have been developed and installed in theaters. The parameters of the systems that play an important role in determining image quality include image resolution, quantization bit depth, color space, gamma characteristics, and data compression methods. This paper comparatively discusses a relation between required bit depth and gamma quantization using both of a human visual system for grayscale images and a color difference model for color images. The required bit depth obtained from a contrast sensitivity function against grayscale images monotonically decreases as the gamma value increases, while it has a minimum value when the gamma is 2.9 to 3.0 from CIE 1976 L*a*b* color difference model. It is also shown that the bit depth derived from the contrast sensitivity function is one bit greater than that derived from the L*a*b* color difference model at the gamma value of 2.9.	cinema 4d;color depth;color space;computability in europe;data compression;digitally controlled impedance;gamma correction;grayscale;image quality;image resolution	Junji Suzuki;Isao Furukawa	2013	IEICE Transactions		rgb color model;computer vision;color depth;computer science;color difference;mathematics;human visual system model;computer graphics (images)	Graphics	61.95485943062482	-62.13759524084421	87418
1b830d73ce3f35c4af8d6e8cf6934201a6dd63f4	towards on-line digital doubles	local pixel gradient information;image motion analysis;high resolution;image segmentation;high density;real time;lossless image compression;camera color conversions;psi_visics;plane sweep algorithm online digital doubles modular system real time 3d body scanning high resolution shape foreground background segmentation visual hull representation 3d reconstruction depth estimation multiview stereo plane sweep approach infrared illumination local pixel gradient information camera color conversions depth range computation visual hull generation lossless image compression network transfer;real time 3d body scanning;depth range computation;real time systems image motion analysis image reconstruction image segmentation;color real time systems humans shape robustness lighting pipelines cameras image converters image segmentation;3d scanning;image reconstruction;foreground background segmentation;human body;modular system;visual hull generation;network transfer;visual hull;multi view stereo;online digital doubles;infrared illumination;multiview stereo plane sweep approach;infrared;depth estimation;plane sweep algorithm;3d reconstruction;foreground background;high resolution shape;real time systems;visual hull representation	We present a modular system for real-time 3D-scanning of human bodies under motion. The high-resolution shape and colour appearance is captured by several scanning units positioned around the object of interest. Each of these units performs a foreground-background segmentation and computes a valid depth-range for the spatially neighbouring units. Multiple depth-ranges are combined in a visual hull representation, which limits the search-range for the 3D-reconstruction. Depth-estimation is based on a hierarchical multi-view-stereo plane sweep approach. Robustness and accuracy is increased by incorporating imperceptible infrared illumination as well as adding local pixel gradient information. All parts of the processing pipeline, involving camera color conversions, segmentation, depth-range computation, visual-hull generation, lossless image compression, network transfer of the infrared and colour images, and the plane sweep algorithm, are implemented on the GPU and highly optimized for speed, allowing scanning times of less than 40 ms per frame. Experimental results demonstrate the applicability of our system to the creation of high-density on-line digital doubles.	3d film;3d scanner;computation;depth perception;foreground-background;gradient descent;graphics hardware;graphics processing unit;image compression;image resolution;image scanner;lossless compression;online and offline;pixel;real-time clock;real-time transcription;sweep line algorithm;type system;virtual actor;visual hull	Andreas Griesser;Nico Cornelis;Luc Van Gool	2006	Third International Symposium on 3D Data Processing, Visualization, and Transmission (3DPVT'06)	10.1109/3DPVT.2006.140	computer vision;mathematics;optics;computer graphics (images)	Graphics	58.35991264288607	-54.040364127622034	87525
16a3a6711d1a9f81c2d932ce814b1edea23481d8	effects of speed difference on accelerating target imagery signatures for broadside sar		Recent analyses have showed that moving target smears in synthetic aperture radar (SAR) imagery are not constrained to have the shapes of simple parabolas but instead can have a wide variety of two-dimensional (2D) shapes, including self-crossing signatures. The current study investigates the properties of the central smear contour under the conditions of varying the target speed difference for targets which transition from lower to higher speed. This investigation reveals that these theoretical predictions of the signature contour shapes yield excellent agreement with the SAR image formation imagery results applied to simulated radar data.	antivirus software;aperture (software);contour line;image formation;radar;smear campaign;synthetic intelligence;type signature	David A. Garren	2017	2017 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)	10.1109/IGARSS.2017.8127469	radar imaging;remote sensing;computer vision;artificial intelligence;computer science;parabola;radar;synthetic aperture radar;trajectory;image formation	Visualization	76.32150722487425	-65.31732268189903	87626
e7e082d6d27733b9d3fff745ac174b53bbf28247	opportunities of snow property extraction based on single and multi pass sar interferometry: tandem-x	synthetic aperture radar hydrological techniques radar interferometry radar polarimetry remote sensing by radar snow;radar interferometry;random volume over ground model;snow;pol insar;polinsar;polarimetric sar;tandem x sar acquisitions;tandem x;snow property extraction;snow volume estimation;remote sensing by radar;penetration depth;snow interferometry coherence synthetic aperture radar atmospheric modeling spaceborne radar;radar polarimetry;forest height determination;single pass sar interferometry;x band microwaves;insar;terrasar x acquisitions;rvog;tandem x sar acquisitions snow property extraction single pass sar interferometry multipass sar interferometry radar interferometry radar polarimetry polinsar snow volume estimation random volume over ground model rvog forest height determination l band radar penetration depth x band microwaves polarimetric sar terrasar x acquisitions;coherence;multipass sar interferometry;snow tandem x insar pol insar;interferometry;l band radar;atmospheric modeling;hydrological techniques;spaceborne radar;synthetic aperture radar	The combination of interferometry and polarimetry (PolInSAR) is a promising candidate for estimating the snow volume using the Random Volume over Ground model (RVoG). The model was originally developed for forest height determination using L-band [1]. The adaption of the RVoG model to snow is not straight forward due to the thin volume of snow and the highly varying penetration depth of X-band microwaves. In this paper we show parameter ranges and recommendation where the RVoG model might work, together with results of interferometry (InSAR) and polarimetric SAR (Pol-InSAR) using TerraSAR-X and TanDEM-X SAR acquisitions.	l band;microwave;polarimetry;tandem computers	Silvan Leinss;Irena Hajnsek	2012	2012 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2012.6351616	meteorology;l band;atmospheric model;snow;synthetic aperture radar;penetration depth;coherence;hydrology;interferometry;interferometric synthetic aperture radar;optics;physics;remote sensing	Robotics	81.65367757513587	-62.66917027708639	87628
33c1f243516e582825058e9cb5cc7d9ed7997949	testing general relativity using galileo satellite signals	phase measurement;clocks;earth;orbits;satellites;extraterrestrial measurements;delays	The two Galileo satellites launched in 2014 (E14 and E18) were injected in orbits with a significant eccentricity. Both the gravitational potential at the location of the satellites and their velocity thus change as a function of time. Since the Galileo satellites carry very stable clocks, these can potentially be used to set new bounds to the level of agreement between measurements of the clocks' frequency shifts and their prediction by the theory of relativity. This paper presents some initial results obtained by processing available data from Galileo satellite E18.	12-hour clock;distance (graph theory);galileo (satellite navigation);hoc (programming language);numerical relativity;redshift;velocity (software development)	Gabriele Giorgi;Martin Lülf;Christoph Günther;Sven Herrmann;Daniela Kunst;Felix Finke;Claus Lämmerzahl	2016	2016 24th European Signal Processing Conference (EUSIPCO)	10.1109/EUSIPCO.2016.7760410	astrobiology;geodesy;astrophysics;physics	Robotics	81.34403454287265	-66.11211664943201	87680
0f41e4a4e1ba34e6f07b8b6acd27537a033e4f98	nonuniform image representation in area-of-interest systems	image sampling;filtering;filtrage;image numerique;projection operator;image processing;non uniform distribution;distribucion no uniforme;fourier transforms image representation image sampling low pass filters filtering theory;aliasing;random sampling;filtrado;information density;procesamiento imagen;distribution non uniforme;low pass filter;sampling distribution;nonuniform sampling;traitement image;data distribution;area of interest;area of interest systems;low pass filtering operations;nonuniform image representation;pyramidal representation;optical imaging;nonuniformly sampled images;image representation;retina;muestreo aleatorio;fourier transforms;imaging;imagen numerica;distribution echantillonnage;aliasing effects;irregular random sampling;image representation image sampling nonuniform sampling fourier transforms retina filtering humans visual system jacobian matrices optical imaging;nonuniformly distributed data;echantillonnage non uniforme;formation image;sequential projections;low pass filters;humans;position varying projection operators;formacion imagen;digital image;fourier like domain;aliasing effects nonuniform image representation area of interest systems nonuniformly distributed data area of interest imaging information density nonuniform sampling position varying projection operators low pass filtering operations fourier like domain sequential projections pyramidal representation nonuniformly sampled images irregular random sampling;jacobian matrices;distribucion muestreo;echantillonnage aleatoire;visual system;filtering theory;area of interest imaging;repliegue espectro;repliement spectre	"""This paper is concerned with image representation by data distributed nonuniformly and in particular with a representation scheme suitable for """"area-of-interest"""" imaging. The class of signals under consideration, whose information density varies with position, can be represented according to a nonuniform sampling scheme. Position-varying projection operators are presented as simple low-pass filtering operations in a Fourier-like domain. Sequential projections are used for pyramidal representation of nonuniformly sampled images. It is shown that irregular random sampling, prevents, under certain mild restrictions, aliasing effects."""	aliasing;hl7publishingsubsection <operations>;information design;low-pass filter;nonuniform sampling;petrosal sinus sampling;projections and predictions;sampling (signal processing);sampling - surgical action	Natan Peterfreund;Yehoshua Y. Zeevi	1995	IEEE transactions on image processing : a publication of the IEEE Signal Processing Society	10.1109/83.413165	computer vision;mathematical optimization;discrete mathematics;low-pass filter;image processing;computer science;mathematics	Visualization	63.195668218269866	-68.11003166440936	87682
b0fa27ec62e1fa50cdf2f6866b5f043e02d716af	intrinsic image decomposition using structure-texture separation and surface normals		While intrinsic image decomposition has been studied extensively during the past a few decades, it is still a challenging problem. This is partly because commonly used constraints on shading and reflectance are often too restrictive to capture an important property of natural images, i.e., rich textures. In this paper, we propose a novel image model for handling textures in intrinsic image decomposition, which enables us to produce high quality results even with simple constraints. We also propose a novel constraint based on surface normals obtained from an RGB-D image. Assuming Lambertian surfaces, we formulate the constraint based on a locally linear embedding framework to promote local and global consistency on the shading layer. We demonstrate that combining the novel texture-aware image model and the novel surface normal based constraint can produce superior results to existing approaches.	arc diagram;computer vision;display resolution;experiment;graphics;lambertian reflectance;nonlinear dimensionality reduction;normal (geometry);procedural texture;reflection (computer graphics);shading;texture mapping	Junho Jeon;Sunghyun Cho;Xin Tong;Seungyong Lee	2014		10.1007/978-3-319-10584-0_15	computer vision;mathematical optimization;mathematics;geometry	Vision	58.154331642980424	-52.2288627069153	87697
09622e50460d8e7eef3f42c7ab15bf9e4a27f3f2	a fast iterative algorithm for implementation of pixel purity index	geophysical techniques geophysical signal processing feature extraction remote sensing iterative methods;virtual dimensionality vd automatic target generation process atgp endmember extraction algorithm eea endmember pixel fast iterative pixel purity index fippi pixel purity index ppi;pixel purity index;iterative algorithm;iterative algorithms hyperspectral imaging indexes pixel image analysis humans hyperspectral sensors computer science availability visualization;iterative methods;geophysical signal processing;feature extraction;remote sensing;hyperspectral image;fast iterative pixel purity index iterative algorithm hyperspectral image analysis environment for visualizing images software envi software virtual dimensionality unsupervised algorithm automatic target generation process endmember extraction algorithm endmember pixel;geophysical techniques	The pixel purity index (PPI) has been widely used in hyperspectral image analysis for endmember extraction due to its publicity and availability in the Environment for Visualizing Images (ENVI) software. Unfortunately, its detailed implementation has never been made available in the literature. This paper investigates the PPI based on limited published results and proposes a fast iterative algorithm to implement the PPI, referred to as fast iterative PPI (FIPPI). It improves the PPI in several aspects. Instead of using randomly generated vectors as initial endmembers, the FIPPI produces an appropriate initial set of endmembers to speed up its process. Additionally, it estimates the number of endmembers required to be generated by a recently developed concept, virtual dimensionality (VD) which is one of the most crucial issues in the implementation of PPI. Furthermore, it is an iterative algorithm, where an iterative rule is developed to improve each of the iterations until it reaches a final set of endmembers. Most importantly, it is an unsupervised algorithm as opposed to the PPI, which requires human intervention to manually select a final set of endmembers. The experiments show that both the FIPPI and the PPI produce very close results, but the FIPPI converges very rapidly with significant savings in computation.	algorithm;computation;experiment;image analysis;iteration;pixel density;procedural generation;pure function;speedup;terminate (software);visual inspection	Chein-I Chang;Antonio J. Plaza	2006	IEEE Geoscience and Remote Sensing Letters	10.1109/LGRS.2005.856701	computer vision;computer science;machine learning;data mining;mathematics;iterative method;remote sensing	Robotics	69.96040739474486	-65.05228102368133	87699
f4f0f57ea6302d5945916ce79c84b004cc1248eb	psi analyses of land subsidence due to economic development near the city of hangzhou, china	ers 1 2 sar images;groundwater exploitation;geophysical image processing;economic indicators geology rivers industries cities and towns biological system modeling;land subsidence ps insar china urbanization;urbanization;rivers;overseas funded enterprises psi analyses land subsidence economic development spatial patterns temporal patterns ers 1 2 sar images groundwater exploitation xiaoshan economic and technological development zone state level development zone;ps insar;temporal patterns;technological development;biological system modeling;industries;land subsidence;state level development zone;overseas funded enterprises;geology;radar imaging;spatial patterns;synthetic aperture radar economics geophysical image processing groundwater radar imaging;temporal pattern;sar image;cities and towns;xiaoshan economic and technological development zone;groundwater;economic development;economics;china;psi analyses;high speed;economic indicators;synthetic aperture radar	In this work we mapped the spatial and temporal patterns of the land subsidence near the city of Hangzhou, China by PSI analysis with 49 scenes of ERS-1/2 SAR images acquired from 1992 to 2006 to detect and retrieve the subsidence due to economic development. The main reason of land subsidence in Hangzhou is groundwater exploitation, which is necessary for the rapid economic development, especially in China. Xiaoshan Economic and Technological Development Zone was approved as a state-level development zone by the State Council in May, 1993. Since then the zone has been suffering land subsidence. There have been more than 300 overseas-funded enterprises with investors from 26 countries and regions by the year 2006. The development of this area can be divided into three periods according to its pace: construction period (1993-1996), stable increase period (1996-2001) and high-speed period (2001-2006).	land administration	Dapeng Yan;Daqing Ge;Jin Yang;Ling Zhang;Yan Wang;Xiaofang Guo	2010	2010 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2010.5651399	urbanization;synthetic aperture radar;groundwater;spatial ecology;geology;hydrology;radar imaging;china;groundwater-related subsidence;remote sensing	Embedded	82.4367242326078	-56.57848123046429	87759
8175057b18ac416f9f3a9f313358f6baa9204c8f	focusing of sar with curved trajectory based on improved hyperbolic range equation		For a synthetic aperture radar (SAR) system with curved trajectory, which is different from the conventional SAR, the downward velocity and the acceleration result in highly complicated range history, making it hard to achieve a focused target response. The traditional SAR imaging algorithms are not accurate enough to compensate the phase errors introduced from the highly complicated range history. In this letter, considering the impact of complex range history, an improved hyperbolic range equation is proposed to access the 2-D spectrum for curved trajectory SAR imaging. Based on the derived spectrum, frequency-domain imaging algorithm can be performed to focus targets. By analyzing the phase error and comparing with other current range models, the proposed range model is proved to be precise enough to deal with the complex motion model happened in curved trajectory SAR imaging. Simulation experiments are implemented to evaluate the imaging performance of the proposed approach.	algorithm;aperture (software);experiment;simulation;synthetic intelligence;velocity (software development)	Yi Liao;Song Zhou;Lei Yang	2018	IEEE Geoscience and Remote Sensing Letters	10.1109/LGRS.2018.2794471	range of a projectile;azimuth;acceleration;artificial intelligence;mathematics;computer vision;algorithm design;synthetic aperture radar;target response;trajectory	Robotics	76.03235404276323	-67.39766044679081	87794
202de712ce2ddd24d21f44553bd48fdd71c82424	network optimization and design in group-wise registration of terrain corrected satellite images			mathematical optimization	Luigi Barazzetti	2018	MASA	10.3233/MAS-180439	terrain;satellite;computer vision;artificial intelligence;computer science	Robotics	77.19928412752787	-60.020042503369126	87957
d7e2ff8ae1a69166213f9ed1759399cef4211d3c	sar image stacking for the exploitation of long-term coherent targets	sar image stacking;synthetic aperture radar images;radarkonzepte;coherent temporal filtering;institut fur hochfrequenztechnik und radarsysteme;indexing terms;covariance matrix sar image stacking long term coherent targets synthetic aperture radar images coherent temporal filtering signal to noise ratio terrasar x data long term interferograms;temporal filtering;long term coherent targets;estimation;stacking;terrasar x data;covariance matrices;radar imaging;sar image;coherence;synthetic aperture radar covariance matrices filtering theory radar imaging;decorrelation;interferometry;synthetic aperture radar interferometry;signal to noise ratio;coherence interferometry decorrelation estimation noise stacking synthetic aperture radar;filtering theory;long term interferograms;noise;covariance matrix;synthetic aperture radar	This letter shows that in a repeat-pass data set of synthetic aperture radar (SAR) images, a long-term coherent component, when present, can be recovered by coherent temporal filtering of the SAR images and can successively form interferograms with higher signal-to-noise ratio. The validity of the idea is confirmed through simulations and one example with real TerraSAR-X data. The theoretical necessity of using long-term interferograms is also discussed and linked to autoregressive processes, starting from the observation that the optimal weighting is given by the inverse of the covariance matrix.	autoregressive model;coherent;signal-to-noise ratio;simulation;stacking;synthetic data	Francesco De Zan;Paco L&#x00F3;pez-Dekker	2011	IEEE Geoscience and Remote Sensing Letters	10.1109/LGRS.2010.2089494	computer vision;covariance matrix;estimation;synthetic aperture radar;index term;decorrelation;coherence;interferometry;noise;stacking;optics;radar imaging;signal-to-noise ratio;physics;statistics;remote sensing	Vision	74.8833039294233	-66.33167282528885	87984
8cb9eced43c2958b3185feadb55ea6f38c5dee6e	a joint motion-image inpainting method for error concealment in video coding	image inpainting error concealment markov random field motion inpainting;image motion analysis;error concealment;conference_paper;image restoration;indexing terms;visual quality;markov random field;video coding;motion inpainting;video coding image motion analysis image restoration markov processes spatiotemporal phenomena;frame restoration spatial temporal error concealment video coding joint motion image inpainting adaptive markov random field mrf based diffusion visual quality;spatiotemporal phenomena;image inpainting;markov processes;video coding motion estimation markov random fields image restoration robustness video compression image storage asia image coding digital images	In this paper, we propose a new method for spatial-temporal error concealment in video coding using joint motion-image inpainting. The proposed method combines motion inpainting and adaptive Markov random field (MRF) based diffusion as robust motion inpainting. Image inpainting is employed to refine the result. With robust motion inpainting, effective compromise between temporal and spatial method is achieved for each point in the missing marcroblock (MB), which provides satisfactory visual quality of the restored frame with complex motion in video.	data compression;error concealment;inpainting;markov chain;markov random field	Liyong Chen;Shing-Chow Chan;Harry Shum	2006	2006 International Conference on Image Processing	10.1109/ICIP.2006.312808	image restoration;computer vision;index term;computer science;pattern recognition;mathematics;markov process;statistics;computer graphics (images)	Vision	55.372998557393096	-56.48724598703943	88038
96f13d2d0d911fa177888b20ff02ddab7547899f	adaptive homogeneity-directed demosaicing algorithm	interpolation;image segmentation;digital camera;image sensors;iterative methods;red green and blue;image colour analysis;image reconstruction;interpolation image sensors digital cameras digital filters pixel image reconstruction color iterative algorithms filter bank digital images;filtering theory image sensors image colour analysis image reconstruction iterative methods interpolation image segmentation;cost effectiveness;digital images digital camera image sensor demosaicing algorithm color images sensor data directional interpolation approach misguidance color artifacts interpolation color artifacts aliasing metric neighborhood modeling filterbank techniques nonlinear iterative procedure;filtering theory;color image	A cost-effective digital camera uses a single-image sensor, applying alternating patterns of red, green, and blue color filters to each pixel location. A way to reconstruct a full three-color representation of color images by estimating the missing pixel components in each color plane is called a demosaicing algorithm. This paper presents three inherent problems often associated with demosaicing algorithms that incorporate two-dimensional (2-D) directional interpolation: misguidance color artifacts, interpolation color artifacts, and aliasing. The level of misguidance color artifacts present in two images can be compared using metric neighborhood modeling. The proposed demosaicing algorithm estimates missing pixels by interpolating in the direction with fewer color artifacts. The aliasing problem is addressed by applying filterbank techniques to 2-D directional interpolation. The interpolation artifacts are reduced using a nonlinear iterative procedure. Experimental results using digital images confirm the effectiveness of this approach.	algorithm;aliasing;autostereogram;composite artifact colors;demosaicing;digital camera;digital image;estimated;filter bank;image sensor;interpolation imputation technique;iterative method;morphologic artifacts;nonlinear system;pixel;ringing artifacts	Keigo Hirakawa;Thomas W. Parks	2003	IEEE Transactions on Image Processing	10.1109/ICIP.2003.1247333	iterative reconstruction;demosaicing;color histogram;rgb color model;computer vision;mathematical optimization;cost-effectiveness analysis;image resolution;color image;binary image;interpolation;bayer filter;computer science;stairstep interpolation;image sensor;mathematics;iterative method;image segmentation;image scaling;computer graphics (images)	Vision	58.73104153375703	-59.94825139453599	88061
61d8ca01eb1491856f74dad412e9eeec034a0380	digital orthophotography: mapping with pictures	high resolution;topography earth;geographic information system;geographic information;environmental impact assessment;photography;infrastructure assessment digital orthophotography mapping rasterized aerial photograph rectification camera lens aircraft position distortion elevation topographical features aerial photographs aerial maps geographic sectors geographical information systems planimetric maps topographic maps vegetation management timber management environmental impact assessments;terrain mapping geometry information analysis earth rendering computer graphics image analysis digital cameras lenses aircraft digital images;geographic information systems;aerial photograph;cartography;digital image;geographic information systems photography cartography topography earth	Aerial photographs and maps would seem a natural combination to record and analyze geographical information: maps provide geometric information and photographs add realistic, timely detail. But cameras record images on a flat plane, whereas the earth is curved and its terrain takes on many varied shapes-all of which distort the image geometry and render it invalid for mapping and geographic analysis. Digital orthophotographs solve this problem. A digital orthophoto starts with a rasterized (scanned) aerial photograph; a process called rectification (described below) removes distortions arising from the camera lens, the aircraft's position, and elevation and other topographical features. This transforms aerial photos into high-resolution digital images that correctly represent the geometry of an area and its terrain. These images can be used as standard true-scale representations of geographic sectors-a function already served by analog orthophotos, which must be painstakingly scanned and rectified in small strips or patches. Their fully digital format makes digital orthophotos useful as base maps in geographical information systems (GIS) used for creating and revising topographic and planimetric maps, vegetation and timber management, environmental impact assessments, and infrastructure assessment.	orthophoto	Anne C. Lear	1997	IEEE Computer Graphics and Applications	10.1109/38.610196	computer vision;image resolution;computer science;photography;geographic information system;digital image;environmental impact assessment;computer graphics (images)	Visualization	75.74463550409095	-55.55139530368469	88145
3a2253c5cd2787ae9c8cafea72dd2a50d7d4289d	validation of quikscat radiometer rain rates using the trmm microwave radiometer	brightness temperature;microwave measurements;oceans;antenna measurements;trmm microwave imager;validation atmosphere meteorology remote sensing quikscat radiometer rain rate qrad level 2b algorithm tmi satellite remote sensing trmm microwave radiometer measurement technique microwave radiometry;pollution measurement;trmm microwave radiometer;backscatter;qrad;tmi;microwave radiometry;rain rate;satellite broadcasting;algorithm;radiometry;quikscat radiometer;microwave radiometry rain sea measurements pollution measurement radar measurements oceans antenna measurements backscatter microwave measurements satellite broadcasting;level 2b;geophysical signal processing;remote sensing;field of view;rain;satellite remote sensing;validation;geophysical signal processing rain radiometry atmospheric techniques remote sensing;emission measure;atmospheric techniques;microwave radiometer;quality control;atmosphere;radar measurements;measurement technique;meteorology;tropical rainfall measuring mission;sea measurements	The primary mission of the SeaWinds scatterometer on the QuikSCAT satellite is to infer surface wind vector from ocean backscatter measurements. Occasionally the backscatter measurements are contaminated by the presence of rain; therefore a reliable method of identifying rain is needed. Fortunately, the SeaWinds scatterometer simultaneously obtains active (scattering) and passive (emission) measurements of the ocean; thus, the QuikSCAT Radiometer (QRad) measured brightness temperatures can be used to infer rain rate within the scatterometer antenna field-of-view. This paper describes a new QuikSCAT Level-2B science product of rain rate over oceans. The principal use of this product for quality control purposes to provide a quantitative rain flag associated with QuikSCAT wind vector cells. The QRad rain rate algorithm is described and the characteristics of the rain rates product are presented. This product has been validated by near-simultaneous comparisons with rain rate measurements from the Tropical Rainfall Measuring Mission (TRMM) Microwave Imager (TMI). An example of QuikSCAT retrieved winds in the presence of rain is presented with collocated QRad rain measurements. Results demonstrate that the QRad rain rate product provides a reliable, quantitative wind vector quality flag.	advanced spaceborne thermal emission and reflection radiometer;algorithm;backscatter (email);microwave	W. Linwood Jones;Khalil Ahmad;Jun-Dong Park;Takis Kasparis;Josko Zec	2002		10.1109/IGARSS.2002.1026264	meteorology;quality control;radiometry;atmospheric sciences;field of view;atmosphere;microwave radiometer;brightness temperature;optics;backscatter;physics;remote sensing	Metrics	82.14149102706547	-63.959175921166484	88171
8c11f907813fc1b605211138f12a2abe80eb11ca	detection of building and infrastructure instabilities by automatic spatiotemporal analysis of satellite sar interferometry measurements				Mao Zhu;Xiaoli Wan;Bigang Fei;Zhuping Qiao;Chunqing Ge;Federico Minati;Francesco Vecchioli;Jiping Li;Mario Costantini	2018	Remote Sensing	10.3390/rs10111816		Mobile	79.25233270249103	-60.13698965212647	88188
8f01767f4ea66ca66aac6c9204fb7d21dd643854	parallel adaptive sparsity-constrained nmf algorithm for hyperspectral unmixing	kernel;gpu hyperspectral unmixing nonnegative matrix factorization nmf l 1 2 regularization half thresholding algorithm;parallel architectures concurrency computers data handling graphics processing units hyperspectral imaging image segmentation matrix decomposition parallel algorithms;computer architecture;graphics processing units kernel hyperspectral imaging instruction sets computer architecture parallel processing;graphics processing units;synthetic data parallel adaptive sparsity constrained nmf algorithm hyperspectral unmixing sparsity constrained nonnegative matrix factorization optimization parallel l 1 2 sparsity constrained nmf unmixing method graphics processing units compute unified device architecture multiplicative update rule parallelization endmember extraction half thresholding update rule adaptive regularization parameter abundance estimation concurrent kernel computation power hyperspectral data;hyperspectral imaging;parallel processing;instruction sets	Sparsity-constrained Nonnegative matrix factorization (NMF) has been proved to be an effective method for hyperspectral unmixing. However, the optimization procedure of sparsity-constrained NMF is computational demanding, which may limit its application in time-constrained conditions. In this paper, a parallel L1/2 sparsity-constrained NMF unmixing method on Graphics Processing Units (GPUs) is proposed, and implemented using the Compute Unified Device Architecture (CUDA). It mainly involves the parallelization of multiplicative update rule for endmembers extraction and half thresholding update rule with adaptive regularization parameter strategy for abundance estimation. In particular, the concurrent kernel computation power of modern GPUs is employed to overlap the separated subtasks. The experiment results on the synthetic and real hyperspectral data demonstrate the effectiveness of our implementation.	algorithm;cuda;computation;effective method;graphics processing unit;mathematical optimization;non-negative matrix factorization;parallel computing;sparse matrix;synthetic intelligence;thresholding (image processing)	Wenhong Wang;Yuntao Qian	2016	2016 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)	10.1109/IGARSS.2016.7730603	parallel processing;kernel;computer science;theoretical computer science;hyperspectral imaging;machine learning;instruction set;pattern recognition;remote sensing	HPC	69.17131666170795	-66.11854109857721	88194
7ff138279104e9aefd5cec173e2da1577184eba8	satellite observations of surface air pressure using active microwave remote sensing technique for severe weather forecast improvements		Currently there is a tremendous gap in observations of global air pressure fields although many satellite remote sensing techniques have been developed in measuring certain atmospheric variables such as temperature and moisture in last few decades. Air pressure is the key variable for the Earth's dynamic fields. This study explores the potential of global surface air pressure measurements using a satellite active microwave sensing technique, namely the Differential-absorption BArometric Radar (DiBAR), to improve weather forecasts, particularly severe weather such as typhoon predictions. The research team at NASA Langley has developed a prototype instrument and demonstrated its performance through ground and airborne experiments. Spacebome capability of this measurement approach will significantly improve typhoon and severe weather forecasts.	airborne ranger;experiment;microwave;prototype;radar;typhoon	Bing Lin;Qilong Min;Steve Harrah;Yongxiang Hu;Roland Lawrence	2018	IGARSS 2018 - 2018 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2018.8519463	remote sensing;severe weather;atmospheric pressure;tropical cyclone;pressure measurement;sea surface temperature;radar;computer science;typhoon;microwave	Robotics	82.08015933037402	-61.98930745695689	88208
ac3cac24ebc94568769a8de92b31f1723900fba4	tomographic image reconstruction using dictionary priors		We describe and examine a framework for tomographic image reconstruction where prior knowledge about the solution is available in the form of training images. We first construct a dictionary that contains prototype elements from these images. Then by using the dictionary as a prior to regularize the inverse problem, and looking for a solution with a sparse representation in the dictionary, we formulate the reconstruction problem in a convex optimization framework. Our computational experiments clarify the choice and interplay of the model parameters and the regularization parameters, and they show that in few-projection settings we are able to produce better images with more structural features than the total variation approach.	computation;convex optimization;dictionary;experiment;iterative reconstruction;mathematical optimization;matrix regularization;prototype;reconstruction conjecture;sparse approximation;sparse matrix	Sara Soltani;Martin S. Andersen;Per Christian Hansen	2015	CoRR		computer vision;k-svd;machine learning;pattern recognition;mathematics	Vision	56.34470774831882	-73.13594101614157	88321
e7edcec32a71c18d01163a979addc9c6850268ef	on restoration of degraded cinematic sequences by means of digital image processing	mathematical morphology;human interaction;morfologia matematica;digital image processing;image processing;cultural heritage;restoration;procesamiento imagen;spectrum;traitement image;tratamiento numerico;world war ii;restauration;digital processing;traitement numerique;morphologie mathematique;restauracion	There are thousands of old black and white movies that are the cultural heritage of nations. These films are quite often seriously degraded. This is a problem of significant importance especially in Poland, where most of cinematic heritage was damaged during and after World War II. There is a wide spectrum of defects of different kinds and various complexity, which is a serious challenge for image processing scientists. In this paper a systematic methodology for solving these difficult problems is proposed. It contains an analysis of most common defects and introduces their taxonomy. The most important part of the work is devoted to the detection and removal of degradations. For this purpose different tools of image processing are applied, especially based on mathematical morphology. Considering the diversity and complexity of the defects one can easily observe that there is no uniform methodology that could be successfully applied to all degradation types. Unfortunately it does not seem to be possible to detect and remove all of them completely automatically. Therefore the whole system for semi-automatic treatment (with limited human interaction) is proposed.		Slawomir Skoneczny;Marcin Iwanowski	2001		10.1007/3-540-44692-3_51	spectrum;computer vision;interpersonal relationship;mathematical morphology;image processing;computer science;cultural heritage;artificial intelligence;digital image processing;world war ii	Graphics	63.973423520553865	-58.47578902714617	88386
21632f1f1a65df7fdc0189174aa5bf4d9221d7ea	evolutionary design of morphology-based homomorphic filter for feature enhancement of medical images	morphological filter;homomorphic filter;medical image enhancement	In this paper, a new morphology-based homomorphic filtering technique is presented to enhance features in medical images. The homomorphic filtering is performed based on the morphological sub-bands, in which an image is morphologically decomposed. An evolutionary design is carried to find an optimal gain and structuring element of each sub-band. As a search algorithm, Differential Evolution scheme is utilized. Simulations show that the proposed filter improves the contrast of the interest feature in medical images.	computer simulation;continuous design;differential evolution;galaxy morphological classification;homomorphic filtering;mathematical morphology;medical imaging;search algorithm;structuring element	Hee-Soo Hwang;Jinsung Oh	2009	Int. J. Fuzzy Logic and Intelligent Systems	10.5391/IJFIS.2009.9.3.172	computer vision;computer science;machine learning;pattern recognition	Vision	58.29050752595222	-67.32398815939432	88434
e50e962c105abdbd6e6ab43150a51fe91d03ed8b	application to multispectral images of a blind identification system for blur, additive, multiplicative and impulse noises	noise imaging abstracts laplace equations image segmentation classification algorithms sociology;impulse noise hyperspectral imaging image restoration;casi airborne hyperspectral imaging sensor multispectral images blind identification system impulse noises multiplicative noises additive noises blur noises preponderant degradation identification defocusing blur	We address the problem of the identification of the preponderant degradation affecting an image, in the context of blind, processing where the identification has to be made from the observed image. Considering that the main difficulty for any pre-processing treatment is to find the good balance between the two contradictory aspects of preserving the fine details and removing the degradation effects, the estimation from the observed image of the degradation characteristics is crucial to choose the algorithms and the order in which to apply them. The degradations considered here involve a defocusing blur and a noise or a combinations of both. The noise can be additive, multiplicative or impulse. The system presented here is tested on images obtained from the CASI airborne hyperspectral imaging sensor.	airborne ranger;algorithm;circuit restoration;dirac delta function;elegant degradation;emoticon;gaussian blur;image sensor;impulse noise (audio);john d. wiley;matrix multiplication;multispectral image;preprocessor;utility functions on indivisible goods	Marie-Paule Carton-Vandecandelaere;Benoit Vozel;Luc Klaine;Kacem Chehdi	2002	2002 11th European Signal Processing Conference		computer vision;geography;optics;remote sensing	Vision	68.37581222891644	-66.30537900217227	88438
5e04c944d71651c2227769e5c65f91fd0505029f	new methodologies in the design of a general purpose fuzzy expert system: applications with ai based precipitation retrieval designed for satellite microwave measurements	new methodology;general purpose;precipitation retrieval;fuzzy expert system;satellite microwave measurement		expert system;microwave	Kyung-Whan Oh	1988			simulation;engineering;remote sensing;computer engineering	AI	79.52248913242418	-60.72186280811803	88524
97264e72ea9d400c87d0356f3b14b9887e4db606	real-time fpga implementation of linear blending vision reconstruction algorithm using a spherical light field camera	light field camera;real time;geometry;fpga;fpga light field camera real time;computer vision;image reconstruction;field programmable gate arrays;cameras field programmable gate arrays interpolation image reconstruction observers real time systems arrays;hardware architecture real time fpga implementation linear blending vision reconstruction algorithm spherical light field camera polydioptricsystem imager spherical geometry focal plane omnidirectional camera light information virtual observer reconstructed vision quality ordinary stitching technique pixel gridding scheme rectangular displaying panoptic system;cameras;image reconstruction cameras computer vision field programmable gate arrays geometry	A custom spherical light-field camera used as a polydioptricsystem where imagers are distributed over a spherical geometry, each having its own vision of the surrounding and distinct focal plane. The spherical light-field camera is also an omnidirectional camera which records light information fro many direction around its center. A novel linear blending technique is presented for vision reconstruction of a virtual observer located inside the spherical geometry of this camera. This blending technique improves the output quality of the reconstructed vision with respect to the ordinary stitching technique. A novel pixel gridding scheme is presented for rectangular displaying of the reconstructed vision induced from the spherical light field camera. This gridding technique preserve the correct size of objects when mapped on the spherical geometry of the Panoptic system. A hardware architecture based on FPGAs with the real-time implementation of the linear blending algorithm and the new pixel gridding scheme of the spherical light-field camera are presented along with imaging results.	algorithm;alpha compositing;focal (programming language);field-programmable gate array;image stitching;light field;omnidirectional camera;pixel;real-time clock;real-time transcription	Hossein Afshari;Abdulkadir Akin;Vladan Popovic;Alexandre Schmid;Yusuf Leblebici	2012	2012 IEEE Workshop on Signal Processing Systems	10.1109/SiPS.2012.49	embedded system;computer vision;camera auto-calibration;camera resectioning;computer science;field-programmable gate array;computer graphics (images)	Vision	62.21050091135626	-55.390840643831226	88594
172e42ada54a1fa2c3c770060e261a8ac5b5f66b	fully automatic dark-spot detection from sar imagery with the combination of nonadaptive weibull multiplicative model and pulse-coupled neural networks	geophysical image processing;settore ing inf 02 campi elettromagnetici;image segmentation;neural nets;remote sensing by radar;automatic dark spot detection pcnn technique envisat images ers2 images subimage segmentation synthetic aperture radar imagery oil spill detection pulse coupled neural networks nonadaptive weibull multiplicative model sar imagery;neurons synthetic aperture radar joining processes feature extraction neural networks speckle image segmentation;synthetic aperture radar geophysical image processing image segmentation neural nets remote sensing by radar;weibull multiplicative model dark spot detection oil spill detection pulse coupled neural networks sar image processing synthetic aperture radar sar;synthetic aperture radar	Dark-spot detection is a critical step in oil-spill detection. In this paper, a novel approach for automated dark-spot detection using synthetic aperture radar imagery is presented. A new approach from the combination of Weibull multiplicative model (WMM) and pulse-coupled neural network (PCNN) techniques is proposed to differentiate between the dark spots and the background. First, the filter created based on WMM is applied to each subimage. Second, the subimage is segmented by PCNN techniques. As the last step, a very simple filtering process is used to eliminate the false targets. The proposed approach was tested on 60 Envisat and ERS2 images which contained dark spots. The same parameters were used in all tests. For the overall data set, an average accuracy of 93.66% was obtained. The average computational time for dark-spot detection with a 512 × 512 image is about 7 s using IDL software, which is the fastest one in this field at present. Our experimental results demonstrate that the proposed approach is very fast, robust, and effective. The proposed approach can be applied on any kind of synthetic aperture radar imagery.	artificial neural network;computation;dark web;fastest;pulse-coupled networks;robustness (computer science);synthetic intelligence;time complexity	Alireza Taravat;Daniele Latini;Fabio Del Frate	2014	IEEE Transactions on Geoscience and Remote Sensing	10.1109/TGRS.2013.2261076	computer vision;synthetic aperture radar;machine learning;image segmentation;radar imaging;inverse synthetic aperture radar;artificial neural network;remote sensing	Vision	74.08969430561272	-61.13220024964555	88636
58baf7bbf3b3ad72d767149f73791a32b678c602	evaluating spaceborne passive microwave snow water equivalent retrievals across the canadian northern boreal - tundra ecotone	in situ measurements;special sensor microwave;passive microwave;atmospheric measurements;ad 1978;snow;spaceborne passive microwave snow water equivalent retrievals;special sensor imager;meteorological service of canada algorithm suite;lakes;ssi;snow measurements;msc;western canada;snow pack properties;snow time series analysis information retrieval image sampling hydrologic measurements image sensors microwave sensors image retrieval meteorology microwave measurements;microwave imaging;500 km spaceborne passive microwave snow water equivalent retrievals canadian northern boreal forest tundra ecotone time series analysis spaceborne passive microwave data record ad 1978 interannually consistent zone microwave swe retrievals northern boreal forest western canada hydrological implication climatological implication snow measurements northern manitoba ad 2003 11 ad 2004 03 special sensor microwave special sensor imager ssm ssi meteorological service of canada algorithm suite in situ measurements snow pack properties surface water frozen lakes tundra specific swe retrieval algorithm msc;frozen lakes;in situ measurement;interannually consistent zone;northern boreal forest;hydrologic measurements;water atmospheric techniques climatology hydrological techniques lakes microwave imaging remote sensing by radar snow spaceborne radar;remote sensing by radar;500 km;time series analysis;surface water;hydrological implication;remote sensing;radar imaging;boreal forest;tundra specific swe retrieval algorithm;ad 2004 03;canadian northern boreal forest;snow water equivalent;atmospheric techniques;microwave swe retrievals;ad 2003 11;climatological implication;ssm;meteorology;water;northern manitoba;climatology;hydrological techniques;spaceborne radar;tundra ecotone;spaceborne passive microwave data record	Time series analysis of the spaceborne passive microwave data record (1978-present) has identified an interannually consistent zone of high snow water equivalent (SWE) retrievals across the northern boreal forest of Western Canada. Because of potentially significant hydrological and climatological implications, and the sparse conventional observing network across this region, a dedicated field sampling campaign was conducted to verify the existence of this pattern. Snow measurements were made along an approximately 500 km transect across Northern Manitoba, Canada, during late November 2003 and early March 2004. Both snow surveys revealed strong agreement between Special Sensor Microwave/Imager (SSM/I) derived passive microwave SWE retrievals (using the Meteorological Service of Canada algorithm suite) and in situ measurements across the northern boreal forest: a gradient of increasing SWE between Thompson and Gillam was evident, as was a well defined zone of high SWE values to the north and east of Gillam. Further to the north, SSM/I derived SWE retrievals over the open tundra were anomalously low. These findings suggest that development of a tundra-specific SWE retrieval algorithm is necessary, given the unique snow pack properties, and high fraction of surface water (frozen lakes)	algorithm;gradient;image sensor;microwave;row (database);sampling (signal processing);snow;sparse matrix;time series	Chris Derksen;Anne E. Walker	2004	IGARSS 2004. 2004 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2004.1370644	meteorology;water;snow;surface water;taiga;geology;hydrology;time series;radar imaging;physics;remote sensing	Visualization	82.14385327833044	-61.289379360583894	88638
6fc1ece070b5e92a3c59dba08441c3c067977a67	imagine all the plants: evaluation of a light-field camera for on-site crop growth monitoring	canopy measurements;plant phenology;light field lf vision;crop growth monitoring;precision agriculture;on site observation	The desire to obtain a better understanding of ecosystems and process dynamics in nature accentuates the need for observing these processes in higher temporal and spatial resolutions. Linked to this, the measurement of changes in the external structure and phytomorphology of plants is of particular interest. In the fields of environmental research and agriculture, an inexpensive and field-applicable on-site imaging technique to derive three-dimensional information about plants and vegetation would represent a considerable improvement upon existing monitoring strategies. This is particularly true for the monitoring of plant growth dynamics, due to the often cited lack of morphological information. To this end, an innovative low-cost light-field camera, the Lytro LF (Light-Field), was evaluated in a long-term field experiment. The experiment showed that the camera is suitable for monitoring plant growth dynamics and plant traits while being immune to ambient conditions. This represents a decisive contribution for a variety of monitoring and modeling applications, as well as for the validation of remote sensing data. This strongly confirms and endorses the assumption that the light-field camera presented in this study has the potential to be a light-weight and easy to use measurement tool for on-site environmental monitoring and remote sensing purposes.	ecosystem;light field	Robert Schima;Hannes Mollenhauer;Görres Grenzdörffer;Ines Merbach;Angela Lausch;Peter Dietrich;Jan Bumberger	2016	Remote Sensing	10.3390/rs8100823	simulation;precision agriculture;ecology;remote sensing	HCI	79.69734329730895	-54.31050748234934	88707
e1a8f75532875b9a9dad2e92f7d7dc5f68a64145	space-time interpolation of oceanic fronts	ocean atlantique;geophysical signal processing oceanographic techniques remote sensing infrared imaging interpolation image processing;teledetection spatiale;satellite data;minimax problem;interpolation;feature detection;surface temperature;north atlantic;space remote sensing;front oceanique;image processing;problema minimax;interpolacion;sampling frequency;space time;gulf stream;motion compensated;probleme minimax;algorithme;optimization problem;algorithm;reconstruction image;oceano atlantico;teledeteccion espacial;atlantic ocean;reconstruccion imagen;infrared imaging;geophysical signal processing;image reconstruction;remote sensing;frente termico;oceanic front;interpolation image reconstruction ocean temperature smoothing methods infrared imaging satellites clouds image sampling frequency motion estimation;frente oceanico;ocean atlantique nord;oceanographic techniques;motion compensated interpolation algorithm ocean dynamics current composite infrared image thermal structure sst satellite remote sensing measurement technique ir radiometry space time interpolation oceanic front temperature front avhrr sampling frequency frontal position observations meandering meander contour reconstruction space time smoothing point feature detection matching scheme image processing;oceano atlantico norte;adaptive estimation;front thermique;thermal front;algoritmo	Oceanic temperature fronts observed through composite infrared images from the AVHRR satellite data are fragmented due mostly to cloud occlusion. The sampling frequency of such frontal position observations tends to be insufficiently high to resolve dynamics of the meandering features associated with the frontal contour, so that contour reconstruction using a standard space-time smoothing often leads to introduction of spurious features. Augmenting space–time smoothing with a simple point–feature detection/matching scheme, however, can dramatically improve the reconstruction product. This paper presents such a motion-compensated interpolation algorithm, for reconstruction of open contours evolving in time given fragmented position data. The reconstruction task is formulated as an optimization problem, and a time-sequential solution which adaptively estimates feature motion is provided. The resulting algorithm reliably interpolates position measurements of the surface temperature fronts associated with the highly convoluted portions of strong ocean currents such as the Gulf Stream and Kuroshio.	algorithm;contour line;feature detection (computer vision);feature detection (web development);gulf of execution;interpolation;mathematical optimization;optimization problem;sampling (signal processing);smoothing	Toshio Mike Chin;Arthur J. Mariano	1997	IEEE Trans. Geoscience and Remote Sensing	10.1109/36.581994	meteorology;image processing;interpolation;mathematics;optics;remote sensing	Vision	74.63726156828719	-62.912448436738906	88710
acd55fa49f886d28a22266d3e1f7dd8c884a41c3	images registration based on mutual information and nonsubsampled contourlet transform	nonsubsampled contourlet transform;registration;mutual information	Aiming at the problem that how to improve the accuracy of image registration, this paper presents an approach for image registration based on mutual information and non-subsampled contourlet transform. First of all, the reference image and the floating image are decomposed with nonsubsampled contourlet transform. Secondly, register approximate component of the floating image from the highest level to the lowest level based mutual information. Finally, the new image is obtained. Experimental results on remote sensing images demonstrate that the presented method can improve the accuracy.	approximation algorithm;contourlet;image registration;mutual information	Dandan Tian;Xianbin Wen;Haixia Xu;Ming Lei	2011		10.1007/978-3-642-23887-1_38	computer vision;contourlet;speech recognition;pattern recognition;mutual information;statistics	Vision	58.975813954357676	-67.32249052502796	88825
2958d110ec5669c5b21f44754a3992b5eb50f15f	importance sampling via load-balanced facility location	approximate algorithm;high dynamic range imaging;computer graphic;3d environment;facility location problem;linear program;load balance;low density;uncapacitated facility location problem;importance sampling;facility location	In this paper, we consider the problem of “importance sampling” from a high dynamic range image, motivated by a computer graphics problem called image-based lighting . Image-based lighting is a method to light a scene by using real-world images as part of a 3D environment. Intuitively, the sampling problem reduces to finding representative points from the image such that they have higher density in regions of high intensity (or energy) and low density in regions of low intensity (or energy). We formulate this task as a facility location problem where the facility costs are a function of the demand served. In particular, we aim to encourage load balance amongst the facilities by using V-shaped facility costs that achieve a minimum at the “ideal” level of demand. We call this the load-balanced facility location problem, and it is a generalization of the uncapacitated facility location problem with uniform facility costs. We develop a primal-dual approximation algorithm for this problem, and analyze its approximation ratio using dual fitting and factorrevealing linear programs. We also give some experimental results from applying our algorithm to instances derived from real high dynamic range images.	approximation algorithm;computer graphics;facility location problem;high dynamic range;high-dynamic-range imaging;image-based lighting;importance sampling;linear programming;load balancing (computing);load/store architecture;range imaging;sampling (signal processing)	Aaron Archer;Shankar Krishnan	2008		10.1007/978-3-540-68891-4_22	mathematical optimization;simulation;linear programming;facility location problem;mathematics;1-center problem	Theory	60.375250940729536	-54.57118060655267	88920
cac91e2738090cc22822d751c4b66f6d3fc4221d	image perforation: automatically accelerating image pipelines by intelligently skipping samples	image filters;compilers;optimizations	Image pipelines arise frequently in modern computational photography systems and consist of multiple processing stages where each stage produces an intermediate image that serves as input to a future stage. Inspired by recent work on loop perforation [Sidiroglou-Douskos et al. 2011], this article introduces image perforation, a new optimization technique that allows us to automatically explore the space of performance-accuracy tradeoffs within an image pipeline. Image perforation works by transforming loops over the image at each pipeline stage into coarser loops that effectively “skip” certain samples. These missing samples are reconstructed for later stages using a number of different interpolation strategies that are relatively inexpensive to perform compared to the original cost of computing the sample. We describe a genetic algorithm for automatically exploring the resulting combinatoric search space of which loops to perforate, in what manner, by how much, and using which reconstruction method. We also present a prototype language that implements image perforation along with several other domain-specific optimizations and show results for a number of different image pipelines and inputs. For these cases, image perforation achieves speedups of 2 × --10 × with acceptable loss in visual quality and significantly outperforms loop perforation.	computational photography;genetic algorithm;interpolation;loop perforation;mathematical optimization;pipeline (computing);prototype	Li-ming Lou;Paul Nguyen;Jason Lawrence;Connelly Barnes	2016	ACM Trans. Graph.	10.1145/2904903	mathematical optimization;compiler;feature detection;computer science;theoretical computer science;algorithm;computer graphics (images)	Graphics	67.15016501916958	-53.45280592757037	88936
7e24380c7e654aec6cf1acb4b695435ef1e199af	new faults detection by multi-temporal insar over greater houston, texas		Growth faults are common and continue to evolve throughout the unconsolidated sediments of Greater Houston region. Property damages due to faulting have become more evident during the past few years. The constant damages and the rapid rate of the fault movements portray the necessity of further study of the faults over this area. Locating the active faults is crucial for protecting people and infrastructures from severe damages. However, the mechanism of a majority of geo-hazards caused by faulting is still unclear, and many relatively small faults or fissures are still unrecognized. This paper aims to position and monitor the faults activity in Greater Houston region using an improved MTI technique. The improved MTI method, with maximized usable signal and correlation, has ability to identify and monitor the active faults by a detailed monitoring of differential vertical displacements. Not only those previously known faults position but also the new fault traces that have not been recognized or mapped by other methods are imaged.	moving target indication;tracing (software)	Feifei Qu;Zhong Lu;Jin-Woo Kim	2017	2017 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)	10.1109/IGARSS.2017.8126896	remote sensing;fault (geology);growth fault;interferometric synthetic aperture radar;computer science;active fault	Arch	82.24047616969686	-57.156795542952246	89021
27e16c8436d37d78ab10b51c89145a5767076edc	temporal scale of sea surface temperature fronts revealed by microwave observations	microwave remote sensing;ocean temperature;edge detection;impulse noise;temperature sensors;stationary ocean currents sea surface temperature microwave observations sst data advanced microwave scanning radiometer earth observing system global sst fronts entropy based edge detection method impulsive noises sst groups e folding scales;sea surface temperature sst;microwave radiometry;sea surface temperature sst front detection microwave remote sensing;statistical evaluation;front detection;sea surface;sea surface temperature;advanced microwave scanning radiometer;temporal scale;remote sensing;ocean temperature microwave theory and techniques microwave radiometry sea surface temperature sensors correlation;remote sensing ocean temperature ocean waves oceanographic techniques;correlation;microwave theory and techniques;earth observing system;oceanographic techniques;ocean waves	Sea surface temperature (SST) data for three years from the Advanced Microwave Scanning Radiometer for the Earth Observing System are used to statistically evaluate the temporal scales of the global SST fronts (SSTFs). Using the entropy-based edge detection method which is very resistant to impulsive noises, temporal autocorrelation of the dissimilarities of two SST groups across the SSTF is calculated in 10-km-gridded map. In general, the derived temporal scales, defined as e-folding scales in this study, range from 10 to 40 days. Long temporal scales of up to 100 days are found in areas where the stationary ocean currents maintain the frontal structures.	advanced spaceborne thermal emission and reflection radiometer;autocorrelation;data structure;edge detection;microwave;shortest seek first;stationary process	Koh Hosoda;Hiroshi Kawamura;Kuo-Wei Lan;Teruhisa Shimada;Futoki Sakaida	2012	IEEE Geoscience and Remote Sensing Letters	10.1109/LGRS.2011.2158512	meteorology;sea surface temperature;geology;climatology;remote sensing	Visualization	81.60758342400001	-61.157087087848964	89101
280171f83f70e7728344f0d09c9dc4c3ae208d9a	2d and 3d vegetation resource parameters assessment using marked point processes	satellite images;3d images vegetation resource parameter assessment marked point processes aerial images satellite images natural resource management forest resources biodiversity ecological sustainability stochastic geometry ellipses ellipsoids tree position geometric features energy minimization problem feature extraction 2d images;high resolution;forestry;vegetation resource parameter assessment;2d images;forest resources;energy minimization problem;ellipsoids;vegetation environmental science computing feature extraction forestry stereo image processing stochastic processes;geometric feature;environmental science computing;vegetation;aerial image;natural resource management;national forest inventory;marked point process;stochastic processes;marked point processes;feature extraction;ellipses;ecological sustainability;stereo image processing;aerial images;satellite image;tree position;energy minimization;geometric features;3d images;biodiversity;data mining vegetation mapping image resolution satellites resource management biodiversity humans stochastic processes geometry biological system modeling;stochastic geometry	High resolution aerial and satellite images of forests have a key role to play in natural resource management. As they enable to study forests at the scale of trees, it is now possible to get a more accurate evaluation of the forest resources, from which can be deduced information on biodiversity and ecological sustainability. In that prospect, automatic algorithms are needed to give a further exploitation of the data and to assist human operators. In this paper, we present a stochastic geometry approach to extract 2D and 3D parameters of the trees, by modelling the stands as some realizations of a marked point process of ellipses or ellipsoids, whose points are the positions of the trees and marks their geometric features. This approach gives also the number of stems, their position, and their size. It is an energy minimization problem, where the energy embeds a regularization term (prior density), which introduces some interactions between the objects, and a data term, which links the objects to the features to be extracted. Results are shown on aerial images provided by the French National Forest Inventory (IFN)	aerial photography;algorithmic trading;approximation algorithm;energy minimization;interaction;matrix regularization;point process;the forest	Guillaume Perrin;Xavier Descombes;Josiane Zerubia	2006	18th International Conference on Pattern Recognition (ICPR'06)	10.1109/ICPR.2006.20	computer vision;biodiversity;image resolution;feature extraction;natural resource management;ellipsoid;energy minimization;sustainability;ellipse;vegetation;stochastic geometry	Robotics	72.91322413726151	-60.8198872770383	89145
274b623c6ed1798a75f461dcb12bfde7070c0c99	edge directed prediction for lossless compression of natural images	least squares approximations data compression image coding computational complexity probability;least squares approximations;complexity edge directed prediction lossless compression natural images local statistics probability modeling image sources recursive least square based predictive modeling covariance matrix local causal neighborhood mmse optimal predictor local covariance estimate rls based adaptation context based prediction schemes;image coding;probability;data compression;lossless image compression;lossless compression;natural images;indexing terms;computational complexity;least square;image coding covariance matrix statistics predictive models arithmetic probability least squares methods performance loss decorrelation gaussian processes	This paper sheds light on the recent least-square (LS)-based adaptive prediction schemes for lossless compression of natural images. Our analysis shows that the superiority of the LS-based adaptation is due to its edge-directed property, which enables the predictor to adapt reasonably well from smooth regions to edge areas. Recognizing that LS-based adaptation improves the prediction mainly around the edge areas, we propose a novel approach to reduce its computational complexity with negligible performance sacrifice. The lossless image coder built upon the new prediction scheme has achieved noticeably better performance than the state-of-the-art coder CALIC with moderately increased computational complexity.	computational complexity theory;kerrison predictor;least squares;lossless compression	Xin Li;Michael T. Orchard	1999		10.1109/ICIP.1999.819519	data compression;lossy compression;computer science;machine learning;pattern recognition;mathematics;lossless compression;statistics	Vision	61.41440142884783	-70.49416707933865	89201
8b2e5732dd4cef89d3109d59817208b65da93622	stripmap mode test of x-band autosar prototype using measurement instruments	azimuth;synthetic aperture radar modulation power amplifiers radar signal processing radar transmitters road vehicle radar;chirp;image resolution;spotlight mode sar radar railsar autosar stripmap mode;prototypes;synthetic aperture radar prototypes azimuth chirp cameras image resolution;cameras;x band automobile synthetic aperture radar stripmap mode test x band autosar prototype measurement instrument power amplifier signal demodulator arbitrary waveform generator chirp generation vector signal generator commercial off the shelf device signal processing cots device;synthetic aperture radar	We introduce the stripmap mode test of X-band Automobile Synthetic Aperture Radar(AutoSAR) prototype in this paper. We design and develop a power amplifier, a signal demodulator, and use Matlab for post-processing. The transmitter of this prototype, however composes measurement instruments, an Arbitrary Waveform Generator(N8241A, Keysight) for chirp generation and a Vector Signal Generator(E8267D, Keysight) for modulation. Moreover, the Commercial-Off-The-Shelf(COTS) device is used for signal processing and recording in this test. The resolutions of the prototype finally are 0.41m range, 0.14m azimuth.	aperture (software);audio power amplifier;chirp;matlab;modulation;prototype;signal processing;transmitter;video post-processing;waveform	Hyeon-Cheol Lee;Eun Su Kang;Sang Burm Ryu;Sang-Gyu Lee;Sang-Soon Yong;Chul Ho Jung	2015	2015 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)	10.1109/IGARSS.2015.7326137	continuous-wave radar;radar engineering details;synthetic aperture radar;radar lock-on;image resolution;telecommunications;fire-control radar;bistatic radar;pulse-doppler radar;prototype;azimuth;radar imaging;inverse synthetic aperture radar;chirp;side looking airborne radar;physics;radar;remote sensing	Embedded	77.7095565962432	-66.58010903293047	89221
6da1c746595173a76afe87f3fa1c25b193a5b0db	terrasar-x products and product performance update	production performance;phased arrays polarization image resolution satellite broadcasting instruments antenna arrays object detection image segmentation layout radiometry;image resolution;neustrelitz terrasar x eads astrium phased array antenna scansar ground moving target detection quad polarization dlr ground segment;information content;remote sensing by radar;process parameters;radar antennas;phased array antenna;artificial satellites;synthetic aperture radar artificial satellites geophysical equipment radar antennas remote sensing by radar spaceborne radar;geophysical equipment;target detection;spaceborne radar;synthetic aperture radar	TerraSAR-X is a German satellite to be launched towards end of the year 2006. The SAR instrument built by EADS/Astrium has a multipolarized active phased array antenna and is programmable in wide ranges. This allows to operate imaging modes such as e.g. stripmap, spotlight, ScanSAR and dual-polarization modes. By further dividing the antenna in halves with different position or different polarization, experimental modes for ground moving target detection (GMT) or Quad-Polarization are possible. As a consequence of the various sensor capabilities the tree of SAR products offered by the DLR Ground Segment contains many different variants of polarization, resolution and scene size. Even more product variants are caused by different processing parameters selectable by the user. Some product performance parameters, such as the radiometric accuracy as a function of geometric resolution or the image resolution as a function of incidence angle depend on both, sensor settings (PRF, pulse duration) and on processing parameters (bandwidth, weighting, multi-looking). The processing parameters for the products have been designed by DLR in a way so that valuable products with maximum information content are offered to the user. In order to generate the specified products, the TerraSAR Multi Mode SAR Processor TMSP has been designed by DLR. This processor will be operated at the DLR payload ground segment in Neustrelitz for commercial and scientific customers. The processor will also be operated at additional direct access partner stations of Infoterra GmbH, who will serve private and public customers.	dbpedia;dynamic language runtime;image resolution;incidence matrix;phased array;polarization (waves);primitive recursive function;pulse duration;random access;self-information	Helko Breit;Michael Eineder;Thomas Fritz;Birgit Schättler;Martin Huber;Josef Mittermayer	2006	2006 IEEE International Symposium on Geoscience and Remote Sensing	10.1109/IGARSS.2006.496	early-warning radar;phased array;radar engineering details;synthetic aperture radar;image resolution;self-information;telecommunications;fire-control radar;radar imaging;inverse synthetic aperture radar;side looking airborne radar;physics;radar;satellite;remote sensing	Robotics	79.88589721768888	-63.8416567622024	89262
a000b716388819be391cb9d4572a7edfe8f0b1d1	distributed compressed sensing-based pan-sharpening with hybrid dictionary	pan sharpening;image fusion;joint sparsity model jsm;distributed compressed sensing dcs;low resolution multispectral lrms image;high resolution panchromatic hrp image	Spectral correlation between each band of multispectral (MS) image is an important characteristic. In this paper, a novel pan-sharpening method inspired by distributed compressed sensing (DCS) theory is presented, which considers the correlation characteristic among the MS bands as prior information in the restoration model. Two basic image formation models reflecting the relationships of the low-resolution multispectral (LRMS) image and the high-resolution panchromatic (HRP) image to the unknown high-resolution multispectral (HRMS) image are constructed. In order to exactly recover the HRMS image from the measurements, a joint sparsity model (JSM) is employed to solve the ill-posed inverse problem. The basic assumption of JSM is that each HRMS spectral band shares a sparse common component and a sparse innovation component. The choice of dictionaries that are used to sparsely represent the common and innovation components is very important. The common component can be sparsely coded by a dictionary, which is learned from the source HRP image patches. Each innovation component can be sparsely represented by a hybrid dictionary, which is composed of discrete cosine transform (DCT) bases, Gabor bases, wavelet 'db1' bases, ridgelet bases and the learned dictionary atoms. By solving the l 1 -norm optimization problem, the unknown HRMS image can be estimated. The proposed method and the state-of-the-art methods are performed on simulated and real remote sensing images. Experimental results demonstrate that the proposed pan-sharpening method shows better performance than other well-known methods in terms of quantitative assessment and visual analysis. We propose a pan-sharpening method based on DCS theory.We model pan-sharpening into an image restoration problem.Joint sparsity prior is used in the method.A hybrid dictionary is constructed in the proposed method.Experiments prove the effectiveness of the proposed method.	compressed sensing;dictionary	Wenqing Wang;Licheng Jiao;Shuyuan Yang;Kaixuan Rong	2015	Neurocomputing	10.1016/j.neucom.2014.11.054	computer vision;speech recognition;machine learning;image fusion	ECom	67.58350497165044	-66.58392178008825	89268
78b4eb43f55b8621bd49835296ea7e5138675451	spatio-temporal video contrast enhancement	2d target histogram;video signal processing image enhancement;spatio temporal video contrast enhancement algorithm;two dimensional target histogram;spatio temporal video contrast enhancement algorithm real time contrast enhancement applications 2d input histogram backward neighbouring video frames forward neighbouring video frames 2d target histogram two dimensional target histogram neighbouring pixels grey level differences spatial information temporal information;temporal information;neighbouring pixels;2d input histogram;grey level differences;backward neighbouring video frames;spatial information;forward neighbouring video frames;real time contrast enhancement applications	A video contrast enhancement algorithm which automatically enhances the contrast of a video using spatial and temporal information is proposed. The algorithm is based on the observation that the contrast in a video frame can be improved by increasing the grey-level differences between each pixel of the video frame and its neighbouring pixels. Furthermore, such an improvement should be smooth in between consecutive video frames so that continuum of contrast improvement is achieved. A two-dimensional (2D) histogram of a video frame is constructed using mutual relationship between each pixel and its neighbouring pixels. For each video frame, a 2D target histogram is computed by considering 2D histogram of the video frame, 2D uniformly distributed histogram, and the 2D histograms of forward and backward neighbouring video frames. The contrast enhancement of the video frame is achieved by mapping the diagonal elements of the 2D input histogram to the diagonal elements of the 2D target histogram. The proposed algorithm is easy to implement and is thus suitable for real-time contrast enhancement applications.	algorithm;apache continuum;frame (video);pixel;real-time clock	Turgay Çelik	2013	IET Image Processing	10.1049/iet-ipr.2012.0687	reference frame;computer vision;histogram matching;mathematics;spatial analysis;block-matching algorithm;multimedia;adaptive histogram equalization;motion compensation;statistics;image histogram;computer graphics (images)	Vision	56.81740057170213	-59.200660583881984	89364
a23fe80bba63413d6d150d6b35738cd51892a5dc	microwave imaging under oblique illumination	inverse scattering problem;microwave imaging;oblique incidence;som	Microwave imaging based on inverse scattering problem has been attracting many interests in the microwave society. Among some major technical challenges, the ill-posed, multi-dimensional inversion algorithm and the complicated measurement setup are critical ones that prevent it from practical applications. In this paper, we experimentally investigate the performance of the subspace-based optimization method (SOM) for two-dimensional objects when it was applied to a setup designed for oblique incidence. Analytical, simulation, and experimental results show that, for 2D objects, neglecting the cross-polarization scattering will not cause a notable loss of information. Our method can be potentially used in practical imaging applications for 2D-like objects, such as human limbs.	algorithm;experiment;gene expression programming;hearing loss, high-frequency;incidence matrix;limb structure;mathematical optimization;microwave;numerous;oblique projection;physical object;polarization (waves);preparation;simulation;well-posed problem;interest	Qingyang Meng;Kuiwen Xu;Fazhong Shen;Bin Zhang;Dexin Ye;Jiangtao Huangfu;Changzhi Li;Lixin Ran	2016		10.3390/s16071046	simulation;inverse scattering problem;optics;physics;remote sensing	EDA	72.35053142082859	-69.87843584986578	89440
58f9fdec94f7cb778c57d84c287d751ea6a7bdcc	the effect of dictionary learning algorithms on super-resolution hyperspectral reconstruction	dictionary learning hyperspectral super resolution sparse respresentation;dictionaries spatial resolution hyperspectral imaging signal resolution signal processing algorithms;generalized simultaneous orthogonal matching pursuit online dictionary learning algorithm super resolution hyperspectral image reconstruction sparse representation based algorithm k svd algorithm odl algorithm g somp singular value decomposition;dictionaries;signal resolution;super resolution;dictionary learning;sparse respresentation;hyperspectral imaging;signal processing algorithms;time frequency analysis hyperspectral imaging image reconstruction image representation image resolution iterative methods singular value decomposition;hyperspectral;spatial resolution	The spatial resolutions of hyperspectral images are generally lower due to imaging hardware limitations. Super-resolution algorithms can be applied to obtain higher resolutions. Many algorithms exist to achieve super-resolution hyperspectral images from low resolution images acquired in different wavelengths. One of the popular algorithms is sparse representation-based algorithms that employ dictionary learning methods. In this study, a comparative framework is developed to investigate which dictionary learning algorithm leads to better super-resolution images. In order to achieve that, K-SVD and ODL dictionary learning algorithms are employed for comparison. A sparse representation-based algorithm G-SOMP+ is used for hyperspectral super-resolution reconstruction. The experimental results show that ODL algorithm outperforms K-SVD in terms of both reconstruction quality and processing times.	algorithm;dictionary;image resolution;k-svd;machine learning;singular value decomposition;sparse approximation;sparse matrix;super-resolution imaging	Murat Simsek;Ediz Polat	2015	2015 XXV International Conference on Information, Communication and Automation Technologies (ICAT)	10.1109/ICAT.2015.7340509	computer vision;k-svd;computer science;machine learning;pattern recognition	Vision	68.76077271194015	-66.17801875292614	89458
89050172aafec9f13a4682b66815de416ba6466f	curvature regularization for resolution-independent images	regularization;curvature;elastica	A resolution-independent image models the true intensity function underlying a standard image of discrete pixels. Previous work on resolution-independent images demonstrated their efficacy, primarily by employing regularizers that penalize discontinuity. This paper extends the approach by permitting the curvature of resolution-independent images to be regularized. The main theoretical contribution is a generalization of the well-known elastica energy for regularizing curvature. Experiments demonstrate that (i) incorporating curvature improves the quality of resolution-independent images, and (ii) the resulting images compare favorably with another state-of-the-art curvature regularization technique.	analysis of algorithms;computation;experiment;manifold regularization;matrix regularization;mesh generation;piecewise linear continuation;pixel;point process;reflections of signals on conducting lines;triangle mesh;whole earth 'lectronic link	John MacCormick;Andrew W. Fitzgibbon	2013		10.1007/978-3-642-40395-8_13	regularization;mathematical analysis;topology;computer science;mathematics;geometry;curvature	Vision	54.70316829311413	-71.26896567038477	89479
0401848c0a0208d52fec4079c187ebbc65f19a68	multidimensional extension of singular spectrum analysis based on filtering interpretation	singular spectrum analysis;adaptive eigenfilter decomposition;multidimensional data	Singular spectrum analysis is a nonparametric spectral decomposition of a time series. The singular spectrum analysis can be viewed as the two-step filtering with the complete set of eigenfilter adaptively constructed from the original time series. Based on this viewpoint, we present a flexible and quite simple algorithm for the singular spectrum analysis which can be applied to the multidimensional data series with arbitrary dimension. We have carried out the decomposition of two-dimensional image data, and the optimally constructed filters are found to be the smoothing or the edge enhancement filters of various type. We have also examined a simple example for the decomposition of 3D data.	algorithm;circuit restoration;edge enhancement;filter bank;image restoration;schematic;smoothing;spectral density;time series	Kenji Kume;Naoko Nose-Togawa	2014	Advances in Adaptive Data Analysis	10.1142/S1793536914500058	mathematical optimization;mathematical analysis;discrete mathematics;mathematics;singular spectrum analysis	Vision	55.39080976685177	-68.51754438778815	89534
2a8ef671250f7d0fa71f36c7111a623fac54cd0c	efficient dense reconstruction using geometry and image consistency constraints	engineering;optimisation graphics processing units image reconstruction interpolation;image reconstruction cameras three dimensional displays interpolation feature extraction reconstruction algorithms shape;densification method efficient dense reconstruction geometry constraint image consistency constraint depth value interpolation 2d image space superpixel region interpolated value optimization image consistency analysis depth values per pixel turntable dataset dinosaur dataset gpu;dense reconstruction;gpu reconstruction	We introduce a method for creating very dense reconstructions of datasets, particularly turn-table varieties. The method takes in initial reconstructions (of any origin) and makes them denser by interpolating depth values in two-dimensional image space within a superpixel region and then optimizing the interpolated value via image consistency analysis across neighboring images in the dataset. One of the core assumptions in this method is that depth values per pixel will vary gradually along a gradient for a given object. As such, turntable datasets, such as the dinosaur dataset, are particularly easy for our method. Our method modernizes some existing techniques and parallelizes them on a GPU, which produces results faster than other densification methods.		Mikhail M. Shashkov;Jason Mak;Shawn Recker;Connie S. Nguyen;John D. Owens;Kenneth I. Joy	2015	2015 IEEE Applied Imagery Pattern Recognition Workshop (AIPR)	10.1109/AIPR.2015.7444539	computer vision;mathematical optimization;mathematics;computer graphics (images)	Vision	66.25138139334179	-54.67716349803909	89622
651b71e0b6f6a95e6353793f063472ca336e0d49	nonconvex demixing from bilinear measurements		We consider the problem of demixing a sequence of source signals from the sum of bilinear measurements. It is a generalized mathematical model of blind demixing with deconvolution, which has wide applications in communication, image processing and dictionary learning, etc. However, state-of-art algorithms for blind demixing either fail to scale to large problem sizes or require proper regularization with tedious algorithmic parameters for optimality guarantees. To address the limitations of exiting methods, we propose a provable nonconvex demixing procedure via Wirtinger flow, much like vanilla gradient descent, to harness the benefits of regularization free, fast convergence rate, and optimality guarantees. This is achieved by exploiting the benign geometry of blind demixing, thereby revealing that Wirtinger flow enforces the iterates in the region of strong convexity and qualified level of smoothness.	algorithm;bilinear filtering;bilinear transform;convex function;deconvolution;dictionary;gradient descent;image processing;machine learning;mathematical model;provable security;rate of convergence	Jialin Dong;Yuanming Shi	2018	2018 IEEE International Symposium on Information Theory (ISIT)	10.1109/ISIT.2018.8437562	discrete mathematics;rate of convergence;iterated function;deconvolution;smoothness;computer science;gradient descent;bilinear interpolation;regularization (mathematics);convexity	ML	56.065693899052775	-72.60942710386375	89636
88ecaf5885a412beab14b236228e2d9d08378968	super-resolution with adaptive pixel weighting scheme and its application to super-resolved free-viewpoint image synthesis	free viewpoint image synthesis;minimization;adaptive pixel weighting robust super resolution free viewpoint image synthesis;image resolution;cost function;image resolution image reconstruction image registration;robust super resolution;adaptive pixel weighting;image reconstruction;image registration;robustness;image reconstruction image resolution cameras robustness minimization cost function;hr image adaptive pixel weighting scheme super resolved free viewpoint image synthesis reconstruction based super resolution high resolution image low resolution image registration registration error input pixels robust super resolution regularization term;cameras	The objective of reconstruction-based super-resolution is to construct a high-resolution image from a sequence of low-resolution images. The super-resolution processing requires precise registration of low-resolution images and the registration error degrades the resulting high-resolution image. In order to handle inaccuracies in registration, the robust super-resolution methods have been proposed. We propose an adaptive pixel weighting method which uses pixel weighting variables for the input pixels. The proposed method is the extension of the conventional pixel selection type robust super-resolution. We define the cost function which includes the regularization term for the weighting variables and the cost function is minimized against the weighting variables and the resulting HR image simultaneously. We confirmed the effectiveness of the proposed method with super-resolved free-viewpoint image synthesis.	image quality;image resolution;iteration;loss function;mathematical optimization;pixel;rendering (computer graphics);super-resolution imaging;viewpoint	Koichi Hamada;Ryo Nakashima;Keita Takahashi;Takeshi Naemura	2013	2013 International Conference on Signal-Image Technology & Internet-Based Systems	10.1109/SITIS.2013.123	iterative reconstruction;image restoration;computer vision;mathematical optimization;feature detection;image resolution;binary image;image processing;computer science;image registration;mathematics;pixel connectivity;sub-pixel resolution;robustness;computer graphics (images)	Vision	57.533260702358085	-58.35614519702863	89695
e53a49861218e907f72b5165d7b11fb60e220682	individual differences in image-quality estimations: estimation rules and viewing strategies	individual differences;subjective image quality estimation;image quality attributes;eye movements	Subjective image-quality estimation with high-quality images is often a preference-estimation task. Preferences are subjective, and individual differences exist. Individual differences are also seen in the eye movements of people. A task's subjectivity can result from people using different rules as a basis for their estimation. Using two studies, we investigated whether different preference-estimation rules are related to individual differences in viewing behaviour by examining the process of preference estimation of high-quality images. The estimation rules were measured from free subjective reports on important quality-related attributes (Study 1) and from estimations of the attributes’ importance in preference estimation (Study 2). The free reports showed that the observers used both feature-based image-quality attributes (e.g., sharpness, illumination) and abstract attributes, which include an interpretation of the image features (e.g., atmosphere and naturalness). In addition, the observers were classified into three viewing-strategy groups differing in fixation durations in both studies. These groups also used different estimation rules. In both studies, the group with medium-length fixations differed in their estimation rules from the other groups. In Study 1, the observers in this group used more abstract attributes than those in the other groups; in Study 2, they considered atmosphere to be a more important image feature. The study shows that individual differences in a quality-estimation task are related to both estimation rules and viewing strategies, and that the difference is related to the level of abstraction of the estimations.	basis (linear algebra);feature (computer vision);list of system quality attributes;motion estimation;property (philosophy);software quality assurance	Jenni Radun;Mikko Nuutinen;Tuomas Leisti;Jukka Häkkinen	2016	TAP	10.1145/2890504	differential psychology;psychology;computer vision;optics;communication;social psychology;eye movement	HCI	63.087388090049004	-62.5926014393189	89702
263b4f0050861122cf81f04410a3b64f90830d0e	image deblur with regularized backward heat diffusion	partial differential equation;frequency analysis;gaussian processes;image deblurring;image restoration;low pass filter;inverse problem;blind deblurring method image blurring regularized backward heat diffusion gaussian kernel partial differential equation low pass filtering wiener filter;partial differential equations;partial differential equations gaussian processes image restoration;gaussian kernel;kernel image restoration heating noise deconvolution cutoff frequency;wiener filter;frequency analysis image deblur partial differential equation pde inverse problems regularization	Image blurring with Gaussian kernel can also be modeled as an heat diffusion partial differential equation (PDE), therefore, image deblur is an inverse problem of PDE. In this paper, we proposed a novel image deblur method: regularized backward heat diffusion (RBHD) PDE, based on inverse problem and PDE theories. We have derived the concrete regularization forms: low-pass filtering or adding high order derivative terms, provided several kinds of RBHD PDE, and analyzed the relationship between the optimal cut-off frequency and the estimated forward diffusion time. Compared to the traditional energy based methods, e.g. Wiener filter, our method is more flexible and extensible, and the experiments shows that RBHD PDE achieves much better results both with and without the exact kernel width, and is more suitable as an experimental blind deblurring method for Gaussian blurry image.	deblurring;experiment;low-pass filter;matrix regularization;theory;wiener filter	Liang Wang;Siwei Luo;Zhe Wang	2010	2010 IEEE International Conference on Image Processing	10.1109/ICIP.2010.5651365	mathematical optimization;mathematical analysis;mathematics;anisotropic diffusion;partial differential equation;statistics	Robotics	56.0133807571616	-69.13847883141064	89761
9d05b5c55bb6aac5c2c4cfbabd988802bbcd6434	statistical comparison and combination of gps, glonass, and multi-gnss multipath reflectometry applied to snow depth retrieval	snow depth;reflectometry;snow global positioning system signal to noise ratio satellites satellite broadcasting time series analysis sea measurements;signal to noise ratio snr;global navigation satellite system gnss glonass gps multipath reflectometry signal to noise ratio snr snow depth;global navigation satellite system gnss;gps;multipath;glonass	Global navigation satellite system (GNSS) multipath reflectometry (MR) has emerged as a new technique that uses signals of opportunity broadcast by GNSS satellites and tracked by ground-based receivers to retrieve environmental variables such as snow depth. The technique is based on the simultaneous reception of direct or line-of-sight (LOS) transmissions and corresponding coherent surface reflections (non-LOS). Until recently, snow depth retrieval algorithms only used legacy and modernized GPS signals. Using multiple GNSS constellations for reflectometry would improve GNSS-MR applications by providing more observations from more satellites and independent signals (carrier frequencies and code modulations). We assess GPS and GLONASS for combined multi-GNSS-MR using simulations as well as field measurements. Synthetic observations for different signals indicated a lack of detectable interfrequency and intercode biases in GNSS-MR snow depth retrievals. Received signals from a GNSS station continuously operating in France for a two-winter period are used for experimental snow depth retrieval. We perform an internal validation of various GNSS signals against the proven GPS-L2-C signal, which was validated externally against in situ snow depth in previous studies. GLONASS observations required a more complex handling to account for topography because of its particular ground track repeatability. Signal intercomparison show an average correlation of 0.922 between different GPS snow depths and GPS-L2-CL, while GLONASS snow depth retrievals have an average correlation that exceeds 0.981. In terms of precision and accuracy, legacy GPS signals are worse, while GLONASS signals and modernized GPS signals are of comparable quality. Finally, we show how an optimal multi-GNSS combined daily snow depth time series can be formed employing variance factors with a ~59%–90% precision improvement compared to individual signal snow depth retrievals, resulting in snow depth retrieval with uncertainty of 1.3 cm. The developed combination strategy can also be applied for the European Galileo and the Chines BeiDou navigation systems.	algorithm;beidou navigation satellite system;carrier wave;coherence (physics);glonass;gps block iiia;gps signals;galileo (satellite navigation);geodetic datum;global positioning system;incidence matrix;line-of-sight (missile);multipath propagation;reflection (computer graphics);reflectometry;repeatability;satellite navigation;signal-to-noise ratio;simulation;time complexity;time series;topography	Sajad Tabibi;Felipe Geremia-Nievinski;Tonie van Dam	2017	IEEE Transactions on Geoscience and Remote Sensing	10.1109/TGRS.2017.2679899	meteorology;multipath propagation;glonass;satellite navigation;global positioning system;geodesy;gnss applications;physics;remote sensing	Mobile	80.04502164038038	-65.24877502688229	89818
06858c9ef807ca15502cc13afa7393930682cccc	the ers-1 central africa mosaic: a new perspective in radar remote sensing for the global monitoring of vegetation	vegetation mapping;european commission;zaire;teledetection spatiale;information structure;radar methods;global monitoring;tropical forest;radar remote sensing;central africa mosaic project;high resolution;spaceborne radar geophysical techniques forestry forestry vegetation mapping vegetation mapping remote sensing by radar synthetic aperture radar;forestry;space remote sensing;radar antenne synthetique;ers 1;africa spaceborne radar synthetic aperture radar condition monitoring radar remote sensing remote monitoring vegetation mapping layout satellite ground stations ecosystems;satellite methods;tropical rain forest;low resolution;cartographie;layout;indexing terms;satellite ground stations;geophysical measurement technique;vegetation;hot spot;radiometry;remote sensing by radar;teledeteccion espacial;haute resolution;central africa;cartografia;sar;condition monitoring;vegetacion;ecosystems;remote sensing;alta resolucion;methode satellite;satellite remote sensing;cartography;radiometrie;remote monitoring;desforestacion;camp geophysical measurement technique satellite remote sensing spaceborne radar sar radar remote sensing synthetic aperture radar forestry africa vegetation mapping tropical forest ers 1 global monitoring central africa mosaic project;multiresolution analysis;afrique centrale;africa;methode radar;satellite ers 1;camp;space application;geophysical techniques;radar;spaceborne radar;deforestation;afrique;satelite artificial;synthetic aperture radar	"""The Central Africa Mosaic Project (CAMP) is an attempt to bring spaceborne synthetic aperture radar (SAR) remote sensing into an entirely new perspective for tropical forest monitoring, this goal represents a drastic change in the use of radar data, as it brings high-resolution SAR from the role of gap-filler and local hot spot analysis to the role of global mapping at a semicontinental scale. CAMP consists of more than 400 ERS-1 SAR scenes, which were acquired on demand and in a short time frame (two months) over the entire Central Africa region by the ESA Libreville ground station and correlated by the German processing and archiving faculty (PAF) at DLR. The work was carried out in the monitoring of the tropical vegetation unit (MTV) of the European Commission space applications institute (SAI), Ispra, Italy, and within the R/D activity of the Tropical Ecosystem Environment Monitoring by satellites (TREES) project, this paper will give an overview of the CAMP project, the general setting is first established through the motivation and the rationale, as seen in the context of the TREES objectives, the main underlying concepts and the major innovative aspects of the CAMP machine, such as multiresolution pyramidal information structure and processing on demand, are highlighted, the focus is then shifted onto some radar science aspects and engineering issues of the processing chain, such as the statistical characterization of the baseline low-resolution products, and radiometry-related problems, preliminary thematic results based on visual interpretation are finally reported, at this stage of the project, it can already be concluded that the material provided by the ERS-1 Central Africa Mosaic constitutes a unique source of data on vegetation distribution at a continental scale, the most celebrated """"all-weather"""" characteristic of active microwave sensing has taken its full meaning in the present case since a whole equatorial region has been covered on demand and in a minimum amount of time, and since a significant level of information on forest conditions has rapidly been extracted, this places the ERS-1 SAR approach firmly in a central position in the set of instruments to be further exploited for tropical forest monitoring."""	radar	Gianfranco De Grandi;Jean-Paul Malingreau;Marc Leysen	1999	IEEE Trans. Geoscience and Remote Sensing	10.1109/36.763296	meteorology;image resolution;hydrology;physics;remote sensing	Mobile	80.00165422727028	-61.21847350023666	89865
64ded2751aa5032c33a690252d873ecd4e0bb961	image texture classification using wavelet based curve fitting and probabilistic neural network	wavelet packet transform;curve fitting;image texture;singular value decomposition;signal to noise ratio;singular value;probabilistic neural network	This article describes a new approach for image texture classification based on curve fitting of wavelet domain singular values and probabilistic neural networks. Image textures are wavelet packet transformed and singular value decomposition is then employed on subband coefficient matrices after introducing non-linearity. Lower singular values are truncated based on energy distribution to effectively classify textures in the presence of noise. The selected singular values are fitted to the exponential curve. The model parameters are estimated using population-sample analogues method and the parameters are used for performing classification. A modified form of probabilistic neural network (PNN) called weighted PNN (WPNN) is employed for performing the classification. Compared to probabilistic neural network, WPNN includes weighting factors between pattern layer and summation layer of the PNN. Performance of the approach is compared with model based and feature based methods in terms of signal to noise ratio and classification rate. Experimental results prove that the proposed approach gives better classification rate under noisy environment. © 2007 Wiley Periodicals, Inc. Int J Imaging Syst Technol, 17, 266–275, 2007	artificial neural network;curve fitting;image texture;probabilistic neural network;wavelet	Srinivasan Ramakrishnan;Srinivasan Selvan	2007	Int. J. Imaging Systems and Technology	10.1002/ima.20122	image texture;computer vision;probabilistic neural network;machine learning;pattern recognition;mathematics;wavelet packet decomposition;singular value decomposition;signal-to-noise ratio;singular value;statistics;curve fitting	Robotics	57.92317519606438	-67.90988649538862	89881
f1d7ed5566e002c4454d1e1eb666adc86ed82ce2	a new high resolution depth map estimation system using stereo vision and kinect depth sensing	high resolution;kinect;depth estimation system;stereo vision;article	Depth map estimation is an active and long standing problem in image/video processing and computer vision. Conventional depth estimation algorithms which rely on stereo/multi-view vision or depth sensing devices alone are limited by complicated scenes or imperfections of the depth sensing devices. On the other hand, the depth maps obtained from the stereo/multi-view vision and depth sensing devices are de facto complementary to each other. This motivates us to develop in this paper a new system for high resolution and high quality depth estimation by joint fusion of stereo and Kinect data. We modeled the observations using Markov random field (MRF) and formulated the fusion problem as a maximum a posteriori probability (MAP) estimation problem. The reliability and the probability density functions for describing the observations from the two devices are also derived. The MAP problem is solved using a multiscale belief propagation (BP) algorithm. To suppress possible estimation noise, the depth map estimated is further refined by color image guided depth matting and a 2D polynomial regression (LPR)-based filtering. Experimental results and numerical comparisons show that our system can provide high quality and high resolution depth maps, thanks to the complementary strengths of both stereo vision and Kinect depth sensors.	algorithm;backpropagation;belief propagation;color image;computer vision;depth map;display resolution;image resolution;kinect;markov chain;markov random field;multiscale modeling;numerical analysis;polynomial;resultant;sensor;software propagation;stereopsis;video processing	Xueying Zhang;Chong Wang;Shing-Chow Chan	2015	Signal Processing Systems	10.1007/s11265-013-0821-8	computer stereo vision;stereo cameras;computer vision;image resolution;computer science;stereopsis;natural user interface;computer graphics (images)	Vision	56.955991122370094	-57.463441823971635	89927
238e1485f7deef02c05dd0a9ec1e16635e81255d	recalibration and validation of the smap l-band radiometer		The Soil Moisture Active Passive (SMAP) mission was launched on 31st January 2015 in a 6 AM/6 PM sun-synchronous orbit at 685 km altitude to measure soil moisture and free/thaw globally [1]. The passive instrument of SMAP is a fully polarimetric L-band radiometer (1.4GHz) operating with a bandwidth of 24MHz. The radiometer uses a combination of noise-diodes and Dicke-loads for internal calibration with a design similar to that used by the Aquarius or Jason series radiometers [3]. The SMAP digital backend back-end enables implementation of advanced Radio Frequency Interference (RFI) detection and mitigation algorithms for corrupted L-band measurements [6]. The radiometer uncalibrated raw counts are converted to Level 1B antenna temperatures and brightness temperature (TB) values [2]. These TB values are used with other ancillary data to retrieve soil-moisture products on a 40km global grid. The error requirement for the SMAP radiometer is 1.3K and calibration drift is less than 0.4 K/month to measure soil-moisture with volumetric fraction uncertainty of less than 0.04 m3/m3.	advanced spaceborne thermal emission and reflection radiometer;algorithm;diode;interference (communication);jason;l band;noise generator;polarimetry;radio frequency;terabyte	Jinzheng Peng;Sidharth Misra;Jeffrey R. Piepmeier;Emmanuel P. Dinnat;Thomas Meissner;David M. Le Vine;Rajat Bindlish;Giovanni De Amici;Priscilla N. Mohammed;Simon H. Yueh	2017	2017 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)	10.1109/IGARSS.2017.8127511	calibration;remote sensing;radiometer;brightness temperature;computer science;ancillary data;polarimetry;electromagnetic interference;meteorology;microwave;l band	Visualization	81.91443372767645	-64.00635733519086	89989
1d2efd0395faa356f15000c5dc67a6fafe854246	rerendering landscape photographs	relighting;depth estimation	We present a practical approach for realistic rerendering of landscape photographs. We extract a view dependent depth map from single input landscape images by examining global and local pixel color distributions and demonstrate applications of depth dependent rendering such as novel viewpoints, digital refocusing and dehazing. We also present a simple approach to relight the input landscape photograph under novel sky illumination. Here, we assume diffuse reflectance and relight landscapes by estimating the irradiance due the sky in the input photograph. Finally, we also take into account specular reflections on water surfaces which are common in landscape photography and demonstrate a semiautomatic process for relighting scenes with still water.	depth map;lambertian reflectance;pixel;reflection (computer graphics)	Pu Wang;Diana Bicazan;Abhijeet Ghosh	2014		10.1145/2668904.2668942	computer vision;geography;optics;computer graphics (images)	Graphics	60.95652010988912	-52.424017226769756	89993
a38649767fe16ba825f02d7278fcc3a003e7ef63	space-borne and ground-based insar data integration: the åknes test site	ground based radar;journal article;rockslide monitoring;satellite interferometry;radar data integration	This work concerns a proposal of the integration of InSAR (Interferometric Synthetic Aperture Radar) data acquired by ground-based (GB) and satellite platforms. The selected test site is the Åknes rockslide, which affects the western Norwegian coast. The availability of GB-InSAR and satellite InSAR data and the accessibility of a wide literature make the landslide suitable for testing the proposed procedure. The first step consists of the organization of a geodatabase, performed in the GIS environment, containing all of the available data. The second step concerns the analysis of satellite and GB-InSAR data, separately. Two datasets, acquired by RADARSAT-2 (related to a period between October 2008 and August 2013) and by a combination of TerraSAR-X and TanDEM-X (acquired between July 2010 and October 2012), both of them in ascending orbit, processed applying SBAS (Small BAseline Subset) method, are available. GB-InSAR data related to five different campaigns of measurements, referred to the summer seasons of 2006, 2008, 2009, 2010 and 2012, are available, as well. The third step relies on data integration, performed firstly from a qualitative point of view and later from a semi-quantitative point of view. The results of the proposed procedure have been validated by comparing them to GPS (Global Positioning System) data. The proposed procedure allowed us to better define landslide sectors in terms of different ranges of displacements. From a qualitative point of view, stable and unstable areas have been distinguished. In the sector concerning movement, two different sectors have been defined thanks to the results of the semi-quantitative integration step: the first sector, concerning displacement values higher than 10 mm, and the 2nd sector, where the displacements did not exceed a 10-mm value of displacement in the analyzed period.	accessibility;algorithm;boot sector;control theory;disk sector;displacement mapping;gnss augmentation;geographic information system;global positioning system;map;point of view (computer hardware company);semiconductor industry;spatial database;time series;unavailability	Federica Bardi;Federico Raspini;Andrea Ciampalini;Lene Juel Kristensen;Line Rouyet;Tom Rune Lauknes;Regula Frauenfelder;Nicola Casagli	2016	Remote Sensing	10.3390/rs8030237	meteorology;geodesy;remote sensing	DB	82.18136230660765	-59.76624600498619	90020
44875303fb613d29b150f5341dc98579561a8125	how does image content affect the added value of visual attention in objective image quality assessment?	visual attention eye tracking image quality assessment objective metric saliency map;image processing;observers image content visual attention objective image quality assessment natural scene saliency nss eye tracking data objective metric performance perceived image quality prediction;image quality image processing observers quality assessment	Our previous research has demonstrated that adding natural scene saliency (NSS) obtained from eye-tracking data may improve an objective metric's performance in predicting perceived image quality. In this letter, we further investigate the image content dependency of this improvement. Results show that the variation in saliency between observers highly depends on image content, and that this variation predicts the extent to which a certain image may profit from adding saliency in the objective image quality assessment.	eye tracking;image quality	Hantao Liu;Ulrich Engelke;Junle Wang;Patrick Le Callet;Ingrid Heynderickx	2013	IEEE Signal Processing Letters	10.1109/LSP.2013.2243725	image quality;computer vision;image processing;computer science;multimedia;computer graphics (images)	Vision	62.859392293743845	-63.11522230232393	90024
6ca3af73fdc0e6c8711ed9f142aa64407e2705da	status of gnss reflectometry related receiver developments and feasibility studies within the german indonesian tsunami early warning system	satellite navigation systems reflectometry tsunami alarm systems low earth orbit satellites global positioning system radar measurements spaceborne radar space technology satellite broadcasting;uhf radio propagation oceanographic equipment oceanographic techniques receivers reflectometry remote sensing satellite navigation tsunami;cold start time to first fix;reflectometry;time 5 ms;tsunami;frequency 200 hz gnss reflectometry gors space receiver development gors space receiver feasibility study german indonesian tsunami early warning system gitews multifrequency gnss global navigation satellite system gnss occultation reflectometry scatterometry tsunami detection small low earth orbit satellites small leo satellites reflectometry measurements scatterometry measurements radiooccultation measurements high precision navigation applications gnss receiver firmware gfz dlr javad cold start time to first fix optimal tracking loop parameters channel slaving reflected signal monitoring in phase accumulation quadrature phase accumulation civil l2c signal tracking time 5 ms;small low earth orbit satellites;gors space receiver feasibility study;reflected signal monitoring;tsunami detection;time to first fix;radiooccultation measurements;javad;german indonesian tsunami early warning system;frequency 200 hz;small leo satellites;spectrum;gnss occultation reflectometry scatterometry;noise measurement;receivers;satellite broadcasting;gitews;channel slaving;feasibility study;high precision navigation applications;commercial off the shelf;gors space receiver development;global positioning system;remote sensing;low earth orbit satellites;civil l2c signal tracking;satellite navigation;quadrature phase accumulation;raumflugbetrieb und astronautentraining;gfz;radio occultation;in phase accumulation;multifrequency gnss;space technology;optimal tracking loop parameters;uhf radio propagation;low earth orbit;reflectometry measurements;gnss reflectometry;alarm systems;gnss receiver firmware	In the frame of the German Indonesian Tsunami Early Warning System (GITEWS) project a multi-frequency Global Navigation Satellite System (GNSS) Occultation & Reflectometry & Scatterometry (GORS) space receiver is developed. It is based on commercial off-the-shelf (COTS) GNSS receiver technology, as the core instrument for a future tsunami detection constellation of small low Earth orbit (LEO) satellites. For use in reflectometry, scatterometry and radio-occultation measurements as well as high-precision navigation applications, specific adaptations of the GNSS receiver firmware are desirable, which require a close interaction between scientists and the receiver manufacturer. Within the GITEWS project GFZ has set up a team consisting of GFZ, DLR and JAVAD GNSS (JAVAD) to adapt and extend their new generation GNSS receivers for advanced scientific space applications. Specific adaptations address the improvement of the cold start time-to-first-fix, the selection of optimal tracking loop parameters and channel slaving for monitoring of reflected signals. Besides pseudorange, phase and signal-to-noise measurements, the modified receiver allows output of in-phase (I) and quadrature-phase (Q) accumulations at 5 msec intervals (200 Hz). As a major step forward compared to current space receivers, the new receiver supports tracking of the civil L2C signal of the GPS constellation. An overview of the current status is given and first results are discussed. Within GITEWS the feasibility of a tsunami detection mission is studied, including the constellation mission design, the options for operating the system and the ways to develop an end-to-end system for the quick response to tsunami events. In parallel simulation studies of the GNSS signals reflected to a LEO satellite are carried out. This will be realised by a Zavorotny and Voronovich scattering model with a two-scale model approach using an Elfouhaily sea wave spectrum. An overview of the current activities is given and first results are discussed.	cold start;dynamic language runtime;end system;end-to-end encryption;firmware;gnss reflectometry;gps signals;galileo (satellite navigation);global positioning system;government operational research service;in-phase and quadrature components;pseudorange;radio occultation;satellite navigation;signal-to-noise ratio;simulation;spectral density;time to first fix	Achim Helm;Ralf Stosius;Georg Beyerle;Oliver Montenbruck;Markus Rothacher	2007	2007 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2007.4424005	meteorology;spectrum;feasibility study;satellite navigation;time to first fix;global positioning system;geodesy;noise measurement;space technology;physics;remote sensing	Mobile	79.60653295745917	-65.83190224254214	90030
12a856e85e0347b2c9b095f2f9b3a3b7e2010bfd	motion compensation on range doppler algorithm for airborne sar		This paper studies the single step Motion compensation (MOCO) algorithm and its effectiveness in eliminating the defocusing effects on Synthetic Aperture Radar (SAR) images. The deviation of the airborne platform from the ideal trajectory results in the distortion of the SAR data thereby defocusing the SAR images and degrading resolution. MOCO algorithms are used to correct for these platform deviations resulting in the improved focusing of degraded SAR images. This paper proposes a single step MOCO algorithm wherein SAR raw data is processed using Range-Doppler algorithm (RDA) and phase compensation is applied prior to azimuth compression. The single step MOCO algorithm proposed simplifies the ease of implementation making it more suitable for real-time SAR implementations. Effectiveness of the algorithm was validated using simulated data.		Aditi Moudgalya;Peter Joseph Basil Morris;C. V. Giriraja	2018	2018 International Conference on Advances in Computing, Communications and Informatics (ICACCI)	10.1109/ICACCI.2018.8554378	raw data;radar imaging;computer science;azimuth;doppler effect;synthetic aperture radar;distortion;motion compensation;algorithm;image resolution	Robotics	75.19978383814762	-66.72469866628066	90039
daf2b3c91f9c2380ef9a937bba44672119e3d7c6	edge-based image compression with homogeneous diffusion	partial differential equation;laplace equation;lossy compression;image compression;contour coding;partial differential equations pdes;diffusion process;steady state	It is well-known that edges contain semantically important image information. In this paper we present a lossy compression method for cartoon-like images that exploits information at image edges. These edges are extracted with the Marr–Hildreth operator followed by hysteresis thresholding. Their locations are stored in a lossless way using JBIG. Moreover, we encode the grey or colour values at both sides of each edge by applying quantisation, subsampling and PAQ coding. In the decoding step, information outside these encoded data is recovered by solving the Laplace equation, i.e. we inpaint with the steady state of a homogeneous diffusion process. Our experiments show that the suggested method outperforms the widely-used JPEG standard and can even beat the advanced JPEG2000 standard for cartoon-like images.	algorithm;anna-brita stenström;chroma subsampling;codec;encode;experiment;hysteresis;image compression;inpaint;inpainting;iterative reconstruction;jbig;jpeg 2000;lossless compression;lossy compression;paq;quantization (physics);real-time clock;real-time computing;steady state;thresholding (image processing)	Markus Mainberger;Joachim Weickert	2009		10.1007/978-3-642-03767-2_58	data compression;lossy compression;computer vision;mathematical optimization;discrete mathematics;image compression;diffusion process;mathematics;lossless compression;steady state;partial differential equation;statistics;laplace's equation	Vision	56.22259794766766	-68.2596815978653	90042
bb4476be4bf57bb49b86687f845028d8d509dd87	analyzing the effect of lossy compression on particle traces in turbulent vector fields		We shed light on the accuracy of particle trajectories in turbulent vector fields when lossy data compression is used. So far, data compression has been considered rather hesitantly due to supposed accuracy issues. Motivated by the observation that particle traces are always afflicted with inaccuracy, we quantitatively analyze the additional inaccuracies caused by lossy compression. In some experiments we confirm that the compression has only minor impact on the accuracy of the trajectories. Even though our experiments are not generally valid, they indicate that a more thorough analysis of the error in particle integration due to compression is necessary, and that in some cases lossy compression is valid and can significantly reduce performance limitations due to memory and communication bandwidth.	data compression;desktop computer;digital footprint;experiment;graphics processing unit;interpolation;lossy compression;out-of-core algorithm;requirement;throughput;tracing (software);turbulence;velocity (software development)	Marc Treib;Kai Bürger;Jun Wu;Rüdiger Westermann	2015		10.5220/0005307202790288	lossy compression;vector field;computational physics;data mining;particle;computer science;turbulence	Mobile	67.10855812993609	-53.74049073294296	90118
9fdeae1edc6325a27b61125be4c2dc1784aab652	forward and inverse solution for the mems deformable mirrors in adaptive optics	mirrors;optical variables control actuators adaptive optics astronomical telescopes inverse problems matrix algebra micromirrors micro optomechanical devices navier stokes equations;actuators;force;mirrors force noise inverse problems micromechanical devices adaptive optics actuators;micromechanical devices;matrix inversion inverse solution forward solution mems deformable mirrors adaptive optics mirror layer force actuators navier solution tikhonov regularization technique;adaptive optics;noise;inverse problems	Adaptive optics is used in modern telescope to compensate the wavefront aberrations introduced by the Earth's atmosphere. A continuous facesheet MEMS deformable mirror owing to its advantages is gaining popularity in the area of adaptive optics. The mirror layer is influenced by a matrix of force actuators each applying a point force for generating a desired shape. For small deformations this layer is treated as a thin plate undergoing linear displacement. The resulting shape of deformed mirror due to the applied forces can be given by superposition of the independent Navier solution. In an adaptive optics system desired shape of mirror is known beforehand from the measured light wavefront and inverse problem is solved to obtain the force to be applied. We present the Tikhonov regularization technique for obtaining the inverse solution and compare it with the solution obtained using matrix inversion. The inverse solution obtained by regularization technique is stable even in presence of significant noise in the wavefront measurements.	displacement mapping;matrix regularization;microelectromechanical systems;quantum superposition;well-posed problem	T. S. Kumar;Ravi N. Banavar	2015	2015 10th Asian Control Conference (ASCC)	10.1109/ASCC.2015.7244630	classical mechanics;control theory;optics;adaptive optics;deformable mirror;physics	Vision	72.14138674757318	-70.14808143226054	90128
41dfd14182c9bc754c8624fdbed8f60426b14a2e	learning based prior for analyzer-based phase contrast image reconstruction	absorption;support vector machines;gaussian process analyzer based phase contrast imaging phase sensitive imaging multiple image radiography prior estimation bayesian reconstruction machine learning relevance vector machine;bayes methods;training;image reconstruction support vector machines imaging estimation absorption bayes methods training;estimation;image reconstruction;abi system detector learning based prior distribution analyzer based phase contrast image reconstruction maximum a posteriori method machine learning scheme relevance vector machine x ray deflection x ray absorption x ray refraction ultrasmall angle scatter quasimonochromatic beam highly collimated beam extremely low photon count;imaging;photon counting diagnostic radiography image reconstruction learning artificial intelligence maximum likelihood estimation medical image processing	Maximum a posteriori (MAP) method for image reconstruction is subjected to an appropriate selection of the prior distribution. In this paper, we introduce a new approach to estimate the prior distribution using a machine learning scheme based on Relevance Vector Machine (RVM). The RVM prior is applied to the Analyzer-based Imaging (ABI) reconstruction problem. ABI is a technique capable of measuring very subtle X-ray deflection and scatter phenomena when passing through an imaged object producing three parametric images (Absorption, Refraction and ultra-small angle scatter USAXS). The need of a quasi-monochromatic and highly collimated beam causes an extremely low photon count in the ABI systems detector, which leads to noisy reconstructions. Here we demonstrate the use of RVM priors to improve the resulting ABI images.	application binary interface;iterative reconstruction;machine learning;monochrome;reconstruction conjecture;relevance vector machine;x-ray (amazon kindle)	Oriol Caudevilla;Jovan G. Brankov	2015	2015 IEEE 12th International Symposium on Biomedical Imaging (ISBI)	10.1109/ISBI.2015.7164189	absorption;iterative reconstruction;medical imaging;support vector machine;computer vision;estimation;radiology;medicine;computer science;pattern recognition;mathematics;optics	Vision	53.920814294839346	-76.71502335322894	90138
830a5710d4ef3f85f4a240e3cf08d572dd4a82ef	a new nonlinear integral transform relating ocean wave spectra to phase image spectra of an along-track interferometric synthetic aperture radar	nonlinear integral transform;teledetection;phase image spectrum;along track interferometric synthetic aperture radar;radar remote sensing;linear transfer function;normalized radar cross section;mapping integral;ocean wave spectrum;radar imageur synthese ouverture;radar antenne synthetique;transfer functions;phase modulation;transformations;interferometrie;transformacion;spectrum;indexing terms;deteccion a distancia;remote sensing by radar;radar cross section;radar scattering;sea surface;integral transforms;sar;surface wave;current measurement;transfer function;remote sensing;ocean wave spectra;transforms;insar;onde oceanique;linear transfer function ocean wave sea surface radar remote sensing measurement technique nonlinear integral transform ocean wave spectra phase image spectra along track interferometric synthetic aperture radar insar sar at insar mapping integral velocity bunching phase image spectrum ocean wave spectrum;phase image spectra;surface current;interferometry;surface waves;transformation;transforms ocean waves oceanographic techniques remote sensing by radar synthetic aperture radar;synthetic aperture radar interferometry;interferometria;ocean wave;measurement technique;oceanographic techniques;at insar;ocean waves;velocity bunching;sea measurements;synthetic aperture radar;ocean waves surface waves sea surface synthetic aperture radar interferometry current measurement sea measurements radar scattering phase modulation radar cross section transfer functions	The along-track interferometric synthetic aperture radar (AT-INSAR) has the potential to measure ocean surface currents and ocean surface waves. The authors have derived a new nonlinear integral transform that relates the ocean wave spectrum to the AT-INSAR phase image spectrum. This integral transform is obtained from an approximation of the mapping integral that includes the radial component of the velocity of the scatter elements and velocity bunching. However, it neglects the modulation of the normalized radar cross section by the long ocean waves, which has a small effect on the AT-INSAR phase. Under the assumption that the imaging is only weakly nonlinear, the nonlinear integral transform can be further simplified. In this case, the relationship between the AT-INSAR phase image spectrum and the ocean wave spectrum can be described by a linear transfer function.	nonlinear system;synthetic data	Mingquan Bao;Werner Alpers;Claus Brüning	1999	IEEE Trans. Geoscience and Remote Sensing	10.1109/36.739088	wind wave;geodesy;surface wave;transfer function;optics;physics;remote sensing	EDA	79.86612766433079	-67.36459491401315	90159
3a3b5d2e7cae35f4da6d753ab395dc09354464f5	color lens shade compensation achieved by linear regression of piece-wise bilinear spline functions	lagrangien;current sensor;capteur image cmos;spatial dependence;capteur image;vignetting;sensors;fotografia digital;0130c;capteur courant;linear regression;4279p;photographie numerique;image sensors;0768;cmos image sensors;digital photography;constrained least square;cmyk color model;color filter array;pixel;spline function;lenses;regresion lineal;cmos sensors;sensor corriente;lagrangiano;etalonnage;0707d;lagrangian;calibration;regression lineaire;image sensor	The pixel densities of current CMOS sensors increase and bring new challenges for image sensor designers. Todays sensor modules with miniature lenses often exhibit a considerable amount of color lens shading. This shading is spatial-variant and can be easily identified when capturing a flat textureless Lambertian surface and inspecting the light fall-off and hue change from the image center towards the borders. In this paper we discuss lens shade compensation using spatially dependent gains for each of the four color channel in the Bayer color filter array. We determine reference compensation functions in off-line calibration and efficiently parameterize each function with a bilinear spline which we fit to the reference function using constrained least-squares and Lagrangian conditions ensuring continuity between the piece-wise bilinear functions. For each spline function we optimize a rectilinear grid on which the spline knots are aligned by minimizing the square errors between reference and approximated compensation function. Our evaluations provide quantitative results with real image data using three recent CMOS sensor modules.	algorithmic efficiency;approximation algorithm;bayer filter;bilinear filtering;cmos;channel (digital image);color filter array;image plane;image sensor;lambertian reflectance;least squares;online and offline;pixel density;polynomial;regular grid;scott continuity;shading;signal processing;spline (mathematics);texture mapping	Touraj Tajbakhsh	2010		10.1117/12.840951	computer vision;image sensor;optics;physics	Vision	61.62530182919906	-58.27205138566736	90214
c330acd2e6990190be042aabf13de8b3c9f22b59	multiple directional viewing projection display based on the incident-angle-independent, diffusion-angle-quantizing technology	multiple directional viewing projection display;display devices;optical projectors display devices lenses;quantized diffusion angle screen qda screen;incident angle independent;optical projectors;multiple different image capability multiple directional viewing projection display incident angle independent quantized diffusion angle screen multiple directional viewing projection display system double side lenticular lens multiple projector;lenses;multiple directional viewing lenses;double side lenticular lens;double side lenticular lens multiple directional viewing projection display incident angle independent quantized diffusion angle screen qda screen;multiple directional viewing	We have devised an incident-angle-independent, quantized-diffusion-angle screen and have realized a multiple directional viewing projection display system using double-side lenticular lens. Our display system has advantages of easy alignment for multiple projectors, and capability of multiple different images simultaneously according to viewing angle at any distance from the screen.	lenticular printing;movie projector;video projector;viewing angle	Tohru Kawakami;Baku Katagiri;Takahiro Ishinabe;Tatsuo Uchida	2011	2011 IEEE Industry Applications Society Annual Meeting	10.1109/IAS.2011.6074379	computer vision;optics;computer graphics (images)	Visualization	61.973948606020144	-55.9592985274536	90242
78b4d0a6b3d267433ec595621caa4df353ad1aed	multiresolution image fusion based on wavelet transform by using a novel technique for selection coefficients	coefficients;image fusion;variance;wavelet transform	Today, image fusion as one kind of information integrated technology has played an important role in many fields. This paper presents a novel wavelet based technique for image fusion, which is developed by taking into account the physical meaning of the wavelet coefficients. The images to be fused are firstly decomposed into high frequency and low frequency bands by wavelet transform. Then, by considering the physical meaning of the coefficients, a new selection strategy that treats the coefficients in different ways is proposed. This strategy selects the coefficients of high frequency bands with a variance based scheme, while selects the coefficients of low frequency band with an edge based scheme. Finally, the fused image is constructed by an inverse wavelet transform performing on the combined coefficients from all frequency bands. The proposed method is validated and compared with some existing fusion methods. Experimental results can clearly indicate the superiority of the proposed method through visual inspection and objective fusion performance measurements.	coefficient;frequency band;image fusion;pixel;resultant;visual inspection;wavelet transform	Yong Yang	2011	Journal of Multimedia	10.4304/jmm.6.1.91-98	wavelet;computer vision;speech recognition;second-generation wavelet transform;continuous wavelet transform;artificial intelligence;wavelet packet decomposition;stationary wavelet transform;discrete wavelet transform;lifting scheme;wavelet transform	Robotics	59.60767383003605	-66.98468596641895	90264
278e961dd2a6e560dd07a09d0e4601c349e2dd81	complexity-aware algorithm architecture for real-time enhancement of local anomalies in hyperspectral images	hyperspectral imagery;anomaly enhancement;anomaly detection;real time processing;rx algorithm	Anomaly detection (AD) from remotely sensed multi-hyperspectral images is a powerful tool in many applications, such as strategic surveillance and search and rescue operations. In a typical operational scenario, an airborne hyperspectral sensor searches a wide area to identify regions that may contain potential targets. These regions typically cue higher spatial-resolution sensors to provide target recognition and identification. While this procedure is mostly automated, an on-board operator is generally assigned to examine in real time the AD output and select the regions of interest to be sent for cueing. Real-time enhancement of local anomalies in images of the over flown scene can be presented to the operator to facilitate the decision-making process. Within this framework, one of the ultimate research interests is undoubtedly the design of complexity-aware AD algorithm architectures capable of assuring real-time or nearly real-time in-flight processing and prompt decision making. Among the different AD algorithms developed, this work focuses on those AD algorithms aimed at detecting small rare objects that are anomalous with respect to their local background. One of such algorithms, called RX algorithm, is based on a local Gaussian assumption for background and locally estimates its parameters from each pixel local neighborhood. RX has been recognized to be the benchmark AD algorithm for detecting local anomalies in multi-hyperspectral images. RX decision rule has been employed to develop computationally efficient algorithms tested in real-time operating systems. These algorithms rely upon a recursive block-based parameter estimation procedure that makes their processing and, in turn, their detection performance differ from those of original RX. In this paper, a complexity-aware algorithm architecture fully adaptable to real-time processing is presented that allows the computational load to be reduced with respect to original RX, while strictly following its original formulation and thus assuring the same detection performance. An experimental study is presented that analyzes in detail the complexity reduction, in terms of number of elementary operations, offered by the proposed architecture with respect to original RX. A real hyperspectral image of a scene with deployed targets has been employed to perform a case-study analysis of the complexity reduction to be experienced in different operational scenarios. The real data are also adopted to illustrate a possible strategy for on-board line-by-line enhanced visualization of anomalies for decision support.	airborne ranger;algorithmic efficiency;anomaly detection;benchmark (computing);best, worst and average case;computation;computational complexity theory;data acquisition;decision support system;estimation theory;experiment;genetic algorithm;live event support;merge sort;multiprocessing;numerical analysis;on-board data handling;parallel computing;pixel;pixel aspect ratio;real-time clock;real-time operating system;recursion;reduction (complexity);region of interest;sensor	Nicola Acito;Stefania Matteoli;Marco Diani;Giovanni Corsini	2011	Journal of Real-Time Image Processing	10.1007/s11554-011-0205-x	embedded system;computer vision;anomaly detection;real-time computing;simulation;computer science;artificial intelligence;hyperspectral imaging;data mining	ML	69.9862370127763	-61.41310521335868	90406
89628736bf35262a859dcb401cec9c4e29a0b475	nonnegative-matrix-factorization-based hyperspectral unmixing with partially known endmembers	libraries;remote sensing geophysical image processing geophysical techniques hyperspectral imaging;hyperspectral imaging libraries dictionaries estimation linear programming;partially known endmembers hyperspectral unmixing nonnegative matrix factorization nmf;estimation;dictionaries;linear programming;hyperspectral imaging;image data nonnegative matrix factorization based hyperspectral unmixing remote sensing imagery endmember signatures spectral signature optimization process	Hyperspectral unmixing is an important technique for estimating fractions of various materials from remote sensing imagery. Most unmixing methods make the assumption that no prior knowledge of endmembers is available before the estimation. This is, however, not true for some unmixing tasks for which part of the endmember signatures may be known in advance. In this paper, we address the hyperspectral unmixing problem with partially known endmembers. We extend nonnegative-matrix-factorization-based unmixing algorithms to incorporate prior information into their models. The proposed approach uses the spectral signature of known endmembers as a constraint, among others, in the unmixing model, and propagates the knowledge by an optimization process which minimizes the difference between the image data and the prior knowledge. Results on both synthetic and real data have validated the effectiveness of the proposed method and have shown that it has outperformed several state-of-the-art methods that use or do not use prior knowledge of endmembers.	algorithm;baseline (configuration management);dictionary;experiment;mathematical optimization;non-negative matrix factorization;sparse matrix;synthetic intelligence;type signature	Lei Tong;Jun Zhou;Yuntao Qian;Xiao Bai;Yongsheng Gao	2016	IEEE Transactions on Geoscience and Remote Sensing	10.1109/TGRS.2016.2586110	computer vision;estimation;linear programming;hyperspectral imaging;pattern recognition;mathematics;statistics;remote sensing	Vision	69.31271236116933	-66.22782934156604	90433
7440e17afd626acc96cf87b4aa635e18f99432e6	improving high-pass fusion method using wavelets		In an appropriate image fusion method, spatial information of the panchromatic image is injected into the multispectral images such that the spectral information is not distorted. The high-pass modulation method is a successful method in image fusion. However, the main drawback of this method is that this technique uses the boxcar filter to extract the high frequency information of the panchromatic image. Using the boxcar filter introduces the ringing effect into the fused image. To cope with this problem, we use the wavelet transform instead of boxcar filters. Then, the results of the proposed method and those of other methods such as, Brovey, IHS, and PCA ones are compared. Experiments show the superiority of the proposed method in terms of correlation coefficient and mutual information.	coefficient;experiment;image fusion;modulation;multispectral image;mutual information;principal component analysis;ringing artifacts;wavelet transform	Hamid Reza Shahdoosti	2017	CoRR		multispectral image;pattern recognition;artificial intelligence;wavelet;computer science;wavelet transform;pulse shaping;panchromatic film;mutual information;high-pass filter;image fusion	Robotics	59.23019312817734	-67.27247692422948	90442
df7ae740de7b5bc46f910a9e31e72727cb02883c	image processing applications for geologic mapping	landsat;geologic maps;teledetection;satellite data;lineament;aerial survey;processing;geological map;image processing;landsat satellites;imagerie;aerial surveying;cartographie;traitement image;satellites 580203 geophysics geophysical survey methods 1980 1989;algorithme;algorithm;algorritmo;imagery;geology;digital systems;remote sensing;exploration;geosciences;cartography;algorithms;lithology;lineaments;mapping;geologic deposits;erts landsat;carte geologique;structure analysis	The use of satellite data, particularly Landsat images, for geologic mapping provides the geologist with a powerful tool. The digital format of these data permits applications of image processing to extract or enhance information useful for mapping purposes. Examples are presented of lithologic classification using texture measures, automatic lineament detection and structural analysis, and use of registered multisource satellite data. In each case, the additional mapping information provided relative to the particular treatment is evaluated. The goal is to provide the geologist with a range of processing techniques adapted to specific mapping problems.	image processing	Michael Abrams;Annick Blusson;Véronique Carrère;Phu Thien Nguyen;Yves Rabu	1985	IBM Journal of Research and Development	10.1147/rd.292.0177	geologic map;image processing;computer science;lineament;remote sensing	HPC	75.97030177922768	-57.513442042924346	90515
200f662432bd2667ff63bfca315a492826e8c713	metric to evaluate the texture visibility of halftone patterns	iterative method;visibilite;desviacion tipica;visibilidad;contrast sensitivity function;halftones;analisis textura;color space;imagen medio tinte;standard deviation;image demi teinte;luminance;quality factor;senal crominancia;half tone image;metric;contrast sensitivity;experimental result;metodo iterativo;texture analysis;visibility;chrominance signal;methode iterative;ecart type;resultado experimental;seuil contraste;signal chrominance;metrico;espace chromatique;espacio cromatico;resultat experimental;vision;analyse texture;limite contraste;contrast threshold;metrique;luminancia	Halftones are intended to produce the illusion of continuous images from binary output states, so the visibility of undesired halftone textures is an essential quality factor of halftone patterns. We propose a metric to predict the visibility of color halftone textures. The metric utilizes the human visual threshold function and contrast sensitivity functions (CSF) of luminance and chrominance. The threshold is related to the average background luminance level by de Vries-Rose law (square root law). An iterative approach was used to determine the distance in which the visual error just exceeds the visual threshold. This distance is the metric that predicts the critical distance that a human observer can just discriminate the textures. To verify the metric, the texture visibility was determined experimentally by a psychological experiment. The halftone stimuli were presented on an SGI monitor. Starting from an initial distance, where the halftone images appeared as continuous color patches, the subject walked toward the monitor and found the distance where he or she could just discriminate the spatial changes caused by the textures. Then the distances determined by the experiment and those predicted by the metric were compared. A good correlation was achieved. The results show that the metric is able to predict the visibility over a wide range of texture characteristics.	experiment;iterative method;texture mapping	Muge Wang;Kevin J. Parker	2001		10.1117/12.429486	vision;computer vision;metric;visibility;iterative method;luminance;optics;color space;standard deviation;q factor;physics;computer graphics (images)	Vision	62.48633374156741	-61.88250449350601	90536
c3a995abc4824a04411cf8ef347bb9e93ce17070	a novel insar phase denoising method via nonlocal wavelet shrinkage	filtering;wavelet shrinkage interferometric sar phase filtering nonlocal;phase noise filtering nonlocal wavelet shrinkage interferometric synthetic aperture radar double l1 norm restrictions local sparsity constraints nonlocal sparsity constraints shrinkage operators group blocks insar phase image denoising tasks root mean square error;noise measurement;wavelet transforms;filtering wavelet transforms noise measurement noise reduction coherence dictionaries;wavelet transforms filtering theory image denoising mean square error methods radar imaging radar interferometry synthetic aperture radar;noise reduction;dictionaries;coherence	In this paper, an interferometric synthetic aperture radar phase denoising method which utilizes both local sparsity of wavelet coefficients and nonlocal similarity of grouped blocks, has been proposed. The derived nonlocal wavelet shrinkage use double L1 norm restrictions, which enforce local and nonlocal sparsity constraints by efficient shrinkage operators. This method can take advantage of the coefficients of nonlocal similarity between group blocks for wavelet shrinkage, and improve the accuracy of filtering result. Experimental results in InSAR phase image denoising tasks with simulation and actual noise data show that the proposed method outperforms the state of the art with lower root-mean-square error and less noisy fringes, making it possible to effectively filtering phase noise with superior performance.	aharonov–bohm effect;coefficient;noise reduction;nonlocal lagrangian;phase noise;quantum nonlocality;simulation;sparse matrix;synthetic data;t-norm;taxicab geometry;wavelet	Dongsheng Fang;Xiaolei Lv;Bin Lei	2016	2016 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)	10.1109/IGARSS.2016.7730680	filter;computer vision;mathematical optimization;coherence;computer science;noise measurement;noise reduction;mathematics;physics;statistics;wavelet transform	EDA	68.13098508919663	-66.50595842476169	90652
39cb9970befb22d3cf7fd020dad170027762e7e5	digital image forensics using multi-resolution histograms	digital image;multi resolution	INTRODUCTION With the development of digital image processing technology, and wide spread use of digital image processing software, such as Photoshop, the modification of digital images has become much easier for people without professional knowledge. This makes our lives more colorful; however, a new problem is introduced. Is a digital image's authenticity trustworthy? How do we check the digital image's authenticity? Therefore, using digital image forensics to check a digital image's authenticity has become a significant research focus. We will review the current digital image forensics technology first. ABSTRACT In this paper, the authors investigate the prospect of using multi-resolution histograms (MRH) in conjunction with digital image forensics, particularly in the detection of two kinds of copy-move manipulations , i.e., cloning and splicing. To the best of the authors' knowledge, this is the first work that uses the same feature in both cloning and splicing forensics. The experimental results show the simplicity and efficiency of using MRH for the purpose of clone detection and splicing detection.	adobe photoshop;authentication;computer forensics;digital image processing;duplicate code	Jin Liu;Hefei Ling;Fuhao Zou;WeiQi Yan;Zhengding Lu	2010	IJDCF	10.4018/jdcf.2010100103	image analysis;image resolution;color image;binary image;computer science;digital image processing;digital imaging;sub-pixel resolution;image formation;digital image;standard test image	Graphics	63.73804661693613	-58.27250090189801	90665
36c43e1f26d364a2d67bd586580498e261226585	a system for estimating optics blur psfs from test chart images	software;photographic lenses;optics;diffraction;point spread functions;lenses;deconvolution;cameras;apertures	Camera lenses suffer from aberrations that can cause noticeable blur in captured images, especially when large apertures are used. With very small apertures, images become less sharp due to diffraction. The blur that is due to camera optics can be removed by deconvolution if the PSFs that accurately characterize this blur are available. In this paper we describe a new system developed by us that allows estimating optics blur PSFs in an efficient manner. It consists of a new test chart with black square tiles containing small white random circle pattern and software for fully automatic processing of captured images of this chart. It can process a high resolution image of the chart and produce PSF estimates for a dense set of field position covering the entire image frame within a couple of minutes. The system has been tested with several different lenses and the estimated PSFs have been successfully used for removing optics blur from a variety of different images. © (2015) COPYRIGHT Society of Photo-Optical Instrumentation Engineers (SPIE). Downloading of the abstract is permitted for personal use only.	gaussian blur	Radka Tezaur;Tetsuji Kamata;Li Hong;Stephen S. Slonaker	2015		10.1117/12.2081458	aperture;computer vision;deconvolution;lens;optics;diffraction;physics;computer graphics (images)	Vision	61.35010249790976	-57.28198306269338	90684
0765628f4df0532785df57c81dedc743751d1934	a gpu sub-pixel algorithm for autostereoscopic virtual reality	autostereoscopic display;paper;visual acuity;autostereo combiner;glsl;computer graphics;autostereoscopic virtual reality;varrier;real time;virtual reality rendering computer graphics stereo image processing;head tracking;virtual reality;varrier subpixel algorithm autostereoscopic virtual reality immersive virtual reality autostereo rendering autostereo combiner graphics processing units;subpixel algorithm;virtual reality computer displays rendering computer graphics interleaved codes computer graphics three dimensional displays strips eyes visualization laboratories;parallax barrier;interleaved codes;large scale;visualization;eyes;interactive application;three dimensional displays;graphics processing units;nvidia geforce 7900 gtx;stereo image processing;immersive virtual reality;computer displays;nvidia;graphic processing unit;opengl;strips;computer science;parallax barrier autostereoscopic display 3d display virtual reality varrier;rendering computer graphics;autostereo rendering;high performance;3d graphics and realism;3d display;nvidia quadro fx 3000	Autostereoscopic displays enable unencumbered immersive virtual reality, but at a significant computational expense. This expense impacts the feasibility of autostereo displays in high-performance real-time interactive applications. A new autostereo rendering algorithm named autostereo combiner addresses this problem using the programmable vertex and fragment pipelines of modern graphics processing units (GPUs). This algorithm is applied to the Varrier, a large-scale, head-tracked, parallax barrier autostereo virtual reality platform. In this capacity, the Combiner algorithm has shown performance gains of 4x over traditional parallax barrier rendering algorithms. It has enabled high-performance rendering at sub-pixel scales, affording a 2x increase in resolution and showing a 1.4x improvement in visual acuity	algorithm;analysis of algorithms;autostereoscopy;computer graphics;graphics processing unit;immersion (virtual reality);parallax barrier;pipeline (computing);pixel;power dividers and directional couplers;real-time clock;virtual reality;visual basic[.net]	Robert Kooima;Tom Peterka;Javier Girado;Jinghua Ge;Dan Sandin;Thomas A. DeFanti	2007	2007 IEEE Virtual Reality Conference	10.1109/VR.2007.352473	parallax barrier;computer vision;strips;visualization;stereo display;computer science;artificial intelligence;virtual reality;multimedia;computer graphics;immersion;computer graphics (images)	Visualization	67.31739100009293	-52.41112274543335	90687
2ee233810fde3c26aae0bd4afecf98aa218df28c	a lagrange multiplier-based regularization algorithm for image super-resolution		In this article, we propose a Lagrange multiplier-based model for the regularization problem encountered in the image super-resolution. By establishing the equivalent relationship between the regularization model and the Lagrange multiplier-based model, we provide another version of the physical meaning of the regularization parameter. The nonlinearly monotonic relationship between the regularization parameter and the Lagrange multiplier is proved by contradiction. To solve the regularization parameters, a two-phase iterative method based on the Lagrange multiplier-based model is presented. Furthermore, we apply the propagation filtering method to smoothen the super-resolution image. A QR code image super-resolution is employed to validate the effectiveness of the proposed method.		Bai Li;Lixin Miao;Canrong Zhang;Wenming Yang	2018	2018 IEEE International Conference on Industrial Engineering and Engineering Management (IEEM)	10.1109/IEEM.2018.8607450		Robotics	56.59129515069501	-71.58489401884803	90711
68a119e0d1187f2309f65bd7b185b7962593b74d	mineral mapping and applications of imaging spectroscopy	imaging spectrometer;planetary surfaces;spectroscopy;spectroscopy astrochemistry astronomical spectra geochemistry minerals planetary surfaces remote sensing;geochemistry;minerals;spatial mapping;astrochemistry;astronomical spectra;remote sensing;multispectral images;absorption features mineral mapping imaging spectroscopy astronomy chemistry absorption detection emission detection chemical bonds species abundance remote spectroscopic measurements earth planets multispectral imaging experiments point spectrometers;imaging spectroscopy;minerals spectroscopy extraterrestrial measurements high resolution imaging absorption chemical analysis earth planets spatial resolution image resolution;spectral resolution	Spectroscopy is a tool that has been used for decades to identify, understand, and quantify solid, liquid, or gaseous materials, especially in the laboratory. In disciplines ranging from astronomy to chemistry, spectroscopic measurements are used to detect absorption and emission features due to specific chemical bonds, and detailed analyses are used to determine the abundance and physical state of the detected absorbing/emitting species. Spectroscopic measurements have a long history in the study of the Earth and planets. Up to the 1990s remote spectroscopic measurements of Earth and planets were dominated by multispectral imaging experiments that collect high-quality images in a few, usually broad, spectral bands or with point spectrometers that obtained good spectral resolution but at only a few spatial positions. However, a new generation of sensors is now available that combines imaging with spectroscopy to create the new discipline of imaging spectroscopy. Imaging spectrometers acquire data with enough spectral range, resolution, and sampling at every pixel in a raster image so that individual absorption features can be identified and spatially mapped (Goetz et al., 1985).	experiment;multispectral image;pixel;raster graphics;sampling (signal processing);sensor;word lists by frequency	Roger N. Clark;Joseph W. Boardman;Jack Mustard;Fred A. Kruse;Cindy Ong;Carle M. Pieters;Gregg Alan Swayze	2006	2006 IEEE International Symposium on Geoscience and Remote Sensing	10.1109/IGARSS.2006.514	astrochemistry;multispectral image;imaging spectroscopy;spectroscopy;hyperspectral imaging;chemical imaging;mineralogy;spectral imaging;imaging spectrometer;spectral resolution;physics;remote sensing	Embedded	79.85307866421437	-61.47220731031837	90714
b724b69ddc5685235a88df3e767df3b3c755a3bb	multiobjective sparse unmixing approach with noise removal		"""In sparse hyperspectral unmixing, regularization methods inevitably suffer from the """"decision ahead of solution"""" issue concerning the regularization parameter, which is not conducive to practical applications. To settle this issue, a two-phase multiobjective sparse unmixing (Tp-MoSU) approach has been proposed recently. However, Tp-MoSU has limited performance on high noise data and uses little spatial-contextual information in estimating abundances. To address the first problem, a tri-objective optimization model is established for each of the two phases to model mixed additive noise automatically. To address the second problem, a dual spatial exploiting objective is specially designed in the second phase to exploit similarity among adjacent pixels, which can improve the quality of estimated abundances. In addition, the memetic based evolutionary algorithms are elaborately modified for each of the two phases for better convergence. The experimental results on several representative data sets demonstrate that the proposed method performs better than Tp-MoSU in both of the two phases and completely better than some advanced regularization algorithms in abundance estimation under mixed additive noise."""	additive white gaussian noise;evolutionary algorithm;mpls-tp;mathematical optimization;matrix regularization;memetics;pixel;sparse matrix;triangular function;two-phase locking;utility functions on indivisible goods	Xiangming Jiang;Maoguo Gong;Tao Zhan;Zedong Tang	2018		10.1145/3205455.3205544	mathematical optimization;computer science;evolutionary algorithm;abundance estimation;regularization (mathematics);data set;convergence (routing)	AI	69.28679204381486	-66.92004323721348	90740
7619035aa233e87004429fe6f72318a91ee989fb	coherent detection of swerling 0 targets in sea-ice weibull-distributed clutter using neural networks	sea ice;detectors;clutter;neyman pearson detector coherent detection sea ice weibull distributed clutter neural networks synthetic data supervised training;neural networks;neural nets;sea ice weibull distributed clutter;neyman pearson detector;coherent detection;remote sensing artificial intelligence clutter reduction detection neural networks nns radar;detection;neyman pearson;artificial intelligent;statistical properties;weibull distribution;remote sensing by radar;radar cross section;weibull distribution clutter learning artificial intelligence neural nets remote sensing by radar sea ice;radar antennas;clutter detectors neural networks radar cross section radar antennas artificial intelligence remote sensing;signal processing;remote sensing;clutter reduction;artificial intelligence;neural networks nns;synthetic data;learning artificial intelligence;supervised training;radar;neural network	The detection of Swerling 0 targets in movement in sea-ice Weibull-distributed clutter by neural networks (NNs) is presented in this paper. Synthetic data generated for typical sea-ice Weibull parameters reported in the literature are used. Due to the capability of NNs for learning the statistical properties of the clutter and target signals during a supervised training, high clutter reduction rates are achieved, reverting on high detection performances. The proposed NN-based detector is compared with a reference detector proposed in the literature that approximates the Neyman-Pearson (NP) detector. The results presented in the paper allow empirically demonstrating how the NN-based detector outperforms the detector taken as reference in all the cases under study. It is achieved not only in performance but also in robustness with respect to changes in sea-ice Weibull-distributed clutter conditions. Moreover, the computational cost of the NN-based detector is very low, involving high signal processing speed.	algorithmic efficiency;clutter;computation;dead sea scrolls;neural networks;pearson–anson effect;performance;signal processing;supervised learning;synthetic data	Raul Vicen-Bueno;Manuel Rosa-Zurera;Mar&#x00ED;a-Pilar Jarabo-Amores;David de la Mata-Moya	2010	IEEE Transactions on Instrumentation and Measurement	10.1109/TIM.2010.2047579	weibull distribution;detector;speech recognition;computer science;engineering;electrical engineering;machine learning;carrier recovery;clutter;radar cross-section;sea ice;artificial neural network;radar;remote sensing;synthetic data	Vision	74.9985218062264	-61.587654476599894	90769
67ed71c205deaf461b559fdc8af671b74538a7c7	tomographic reconstruction methods for decomposing directional components		Decomposition of tomographic reconstructions has many different practical application. We propose two new reconstruction methods that combines the task of tomographic reconstruction with object decomposition. We demonstrate these reconstruction methods in the context of decomposing directional objects into various directional components. Furthermore we propose a method for estimating the main direction in a directional object, directly from the measured computed tomography data. We demonstrate all the proposed methods on simulated and real samples to show their practical applicability. The numerical tests show that decomposition and reconstruction can combined to achieve a highly useful fibre-crack decomposition.	ct scan;hybrid fibre-coaxial;imaging phantom;numerical analysis;tomographic reconstruction;tomography;variational principle	Rasmus Dalgas Kongskov;Yiqiu Dong	2017	CoRR		mathematical optimization;mathematics;tomographic reconstruction;computer vision;artificial intelligence;computed tomography technique	Vision	56.92103557768306	-74.49269516510432	90801
02f4459ec2e6ae5d529eabedb80ee4e6c84fbbc9	dynamic phenomena in the coastal waters of the north-eastern black sea retrieved from satellite data	seawater;remote sensing satellite;noaa avhrr;satellite data;coastal waters;eddy currents;instruments;vortices;ocean temperature;information retrieval;nontidal internal waves;coastal water circulation;oceanographic regions;eddy current;infrared image sensors remote sensing synthetic aperture radar sea surface eddy currents;radiometry;remote sensing by radar;sea surface;envisat asar;coastal zone;vortex structures coastal waters northeastern black sea remote sensing satellite ers 2 sar envisat asar terra modis aqua modis noaa avhrr coastal water circulation nontidal internal waves sea eddy structure;infrared imaging;internal waves;terra modis;remote sensing;satellites;radar imaging;spirals;vortices ocean temperature ocean waves oceanographic regions oceanographic techniques radiometry remote sensing remote sensing by radar seawater;modis;optical sensors;surface waves;infrared image sensors;aqua modis;ers 2 sar;sea measurements information retrieval satellites radar imaging spaceborne radar modis optical sensors spirals remote sensing instruments;oceanographic techniques;northeastern black sea;ocean waves;sea eddy structure;radar;sea measurements;vortex structures;spaceborne radar;synthetic aperture radar	Our paper discusses satellite observations data for the north-eastern Black Sea. Our study is based on remote sensing satellite data obtained by ERS-2 SAR, Envisat ASAR, Terra and Aqua MODIS, and NOAA AVHRR instruments. The data from different sensors was analyzed jointly to investigate coastal water circulation and in particular the occurrence, evolution and drift of vortical structures. One result of our investigation included a discovery of surface manifestations of non-tidal internal waves generated in the vicinities of sea eddy structures. Another finding was a seasonal variability of vortex structures in the coastal zone.	aqua;dead sea scrolls;sensor;spatial variability;vortex	Marina Mityagina;Olga Lavrova	2008	IGARSS 2008 - 2008 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2008.4778999	meteorology;atmospheric sciences;eddy current;physics;remote sensing	Embedded	81.50164198371155	-62.151756035378924	90843
c55f74e51af6ae75114d6195fa913a1417a1cc0f	the topographic change of turtle mountain island with multi-temporal airborne lidar data	topography earth geomorphology remote sensing by laser beam;geomorphometry terrain change lidar;taiwan geomorphology topographic change turtle mountain island multitemporal airborne lidar data topographic data lidar systems coastal erosion topographic datasets ad 2005 ad 2011 active volcano island shadow relief maps;laser radar sea measurements sea surface surface topography educational institutions laser modes	To obtain a big area of high-resolution topographic data in a short time using the LiDAR systems are nowadays largely used for quantitative analyses and modelling in geology, coastal erosion, and geomorphology. In this study, two topographic datasets taken in 2005 and 2011 in Turtle island, an active volcano island in Taiwan, are used to plot shadow relief maps firstly. Then the change analysis in the coastal area is performed. The change analysis results show that a fault feature occurred in the northern slope surface of Turtle island, and the coastal cliff avalanche tends to magnify at the turtle head. Moreover, the geomorphometric feature of accelerating erosion can also be clearly identified. It is concluded that geomorphometric features reflecting active processes can be clearly recognized using the detailed multi-temporal LIDAR data.	airborne ranger;erosion (morphology);image resolution;map;topography;turtle (robot)	Kuan-Tsung Chang;Feng-Chi Yu;Yi Changc;Jin-King Liu;Hui-Peng Chene	2014	2014 IEEE Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2014.6947448	geomorphology;hydrology;remote sensing	Embedded	82.50519056168375	-56.82999851126223	90918
b86bc4c7c7c9c93cd9ffe0c02a7aad6074a0f2f5	spatially adaptive threshold for image denoisng based on nonsubsampled contourlet transform	image segmentation;psnr context modeling nsct spatially adaptive coefficient characteristics;edge detection;frequency domain analysis;wavelet transforms edge detection frequency domain analysis image denoising image segmentation;wavelet transforms;psnr image denoising nonsubsampled contourlet transform wavelet transform frequency domain transform transform coefficients edge information noise information image quality context modeling based spatially adaptive threshold neighboring coefficients coefficient characteristics;noise noise reduction image edge detection context wavelet transforms filter banks;image denoising	In recent years, the threshold for removing noise based on wavelet transform has been very widely used because of its effectiveness and simplicity. Thus, there has been threshold based on a variety of frequency-domain transform. During the process of denoising, due to the differentiation of transform coefficients generated by noise and edge information, a good threshold for denoising can make a significant impact on the image quality. In currently existing threshold, spatially adaptive threshold based on Context-Modeling is proposed because of having considered neighboring coefficients so that it can adjust to coefficient characteristics. In this paper the improved spatially adaptive threshold method is applied to the nonsubsampled contourlet transform. Experimental results show that the method yields superior image quality and higher PSNR.	coefficient;contourlet;image quality;noise reduction;peak signal-to-noise ratio;wavelet transform	Xiangda Sun;Junping Du;Yipeng Zhou	2012	2012 3rd IEEE International Conference on Network Infrastructure and Digital Content	10.1109/ICNIDC.2012.6418799	wavelet;computer vision;contourlet;speech recognition;s transform;harmonic wavelet transform;second-generation wavelet transform;continuous wavelet transform;pattern recognition;mathematics;stationary wavelet transform;discrete wavelet transform;top-hat transform;wavelet transform	Vision	57.55400588756914	-66.83956692998265	90921
28c0c2471a8c9ba38901a8133b8fab33fb0d29b8	some approaches to quantization for distributed estimation with data association	distributed estimation;traitement signal;quantization;rate distortion;cuantificacion;quantization performance evaluation measurement uncertainty bandwidth target tracking rate distortion signal processing proposals computer architecture source coding;signal estimation;distributed processing;simulation;simulacion;data fusion;quantification;sensor fusion quantisation signal parameter estimation;data association;quantisation signal;data fusion from multiple sources;signal processing;fusion donnee;analyse performance;estimacion senal;performance analysis;distributed signal processing distributed estimation data association censoring strategy uniform quantization data fusion;parameter estimation;sensor fusion;distributed signal processing data association data fusion from multiple sources;fusion datos;procesamiento senal;estimation signal;traitement reparti;distributed signal processing;tratamiento repartido;analisis eficacia	"""Quantization for estimation is explored for the case that it must be performed jointly with data association, that is, the case in which measurements are of uncertain origin. Data association requires some sort of gating of distributed observations, and a censoring strategy is proposed. Several quantization philosophies are explored, specifically, uniform quantization, uniform quantization with measurement exchangeability incorporated (the """"type"""" method), and uniform quantization of sorted measurements. The second scheme uses less bandwidth than the third, but it is shown, perhaps surprisingly, that the third preserves more information that may be useful for estimation, and a simple procedure for optimal fused estimation based on this third scheme is given. Interestingly, when compared in terms of rate-distortion curve, the schemes two and three perform similarly; their censored versions offer further improvement in performances due to the uncertain-origin property of the measurements."""	censoring (statistics);correspondence problem;distortion;performance;quantization (image processing);quantization (signal processing)	Stefano Maranò;Vincenzo Matta;Peter Willett	2005	IEEE Transactions on Signal Processing	10.1109/TSP.2004.842160	computer vision;quantization;computer science;machine learning;signal processing;pattern recognition;sensor fusion;vector quantization;statistics	Vision	63.31754272402889	-68.04897186665566	90925
965954d35008f2940d3f2e6046051d12f34afe7b	land-cover change detection using local feature descriptors extracted from spectral indices		An effective monitoring and analysis of ecosystems requires developing new tools and knowledge. In this paper, we propose an approach for detecting land-cover changes using satellite Image Time Series. This approach represents each image by spectral indices and then extracts local features of these representations. Next, a clustering technique (e.g., k-means) is applied to the extracted features, where the resulting clusters are assumed to refer to land-cover classes. The land-cover change is then obtained by counting the number of times an assigned class to each point changes along the time series. For our experiments, we use a collection of Landsat-5 images captured every second month from October 2009 to August 2010 over the protected area of the Doñana National Park in southwestern Spain, which is the largest sanctuary for migratory birds in western Europe. Results demonstrate that the proposed approach can detect the occurring changes in the main land-cover categories along the assessed time series.	cluster analysis;ecosystem;experiment;feature vector;k-means clustering;sensor;time series	Daniela Espinoza;Reza Bahmanyar;Ricardo Díaz-Delgado;Javier Bustamante;Mihai Datcu	2017	2017 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)	10.1109/IGARSS.2017.8127358	time series;national park;remote sensing;land cover;cluster analysis;feature extraction;change detection;satellite image time series;protected area;geography	Vision	80.29934339267707	-55.58257763937916	90929
4f2cc8c46e629d74981c260c853c0ee9b0dbf5fd	towards a multidimensional visualization of environmental soft sensors predictions	soft sensors;environmental factors;multidimensional visualization;sensor systems;homogeneous communication paradigm;long period;environmental soft sensors predictions;sensors computerised monitoring data visualisation environmental factors;3d navigation;sensors;color;cultural heritage;temperature sensors;monument surface;multidimensional data;chemical analysis;cultural heritage data visualization glyph color soft sensors environmental data;multidimensional visualization techniques;environmental parameter;shape variation;invasive process;data visualisation;degradation process;shape;condition monitoring;monitoring;glyph;visual support;image color analysis;temperature measurement sensors image color analysis temperature sensors monitoring data visualization shape;environmental data;data visualization;councils;visual support environmental soft sensors predictions chemical measurements monument surface invasive process degradation process multidimensional visualization techniques shape variation homogeneous communication paradigm 3d navigable model;chemical measurements;temperature measurement;computerised monitoring;3d navigable model;object oriented modeling;intelligent sensors;multidimensional systems;cultural differences;chemical sensors	Soft sensors have been successfully applied to simulate physical and chemical measurements in specific locations of a monument. They allowed monitoring the quality conditions of the monument surface for long periods of time. This is a not invasive process that provides a huge set of multidimensional data. They have been analyzed by the Cultural Heritage experts to find physical or chemical critical condition which could generate some degradation process. Here we propose several multidimensional visualization techniques to represent the predictions of environmental parameters, given by several soft sensors, in a comprehensive and compact way. Visualization tools using both shape variation (glyph) and color are developed to realize an homogeneous communication paradigm. Moreover, each tool uses a 3D navigable model of the monument as visual support.	case preservation;circuit restoration;color;elegant degradation;glyph;programming paradigm;sensor;simulation;vtk	Umberto Maniscalco;Patrizia Ciarlini;Rossella Cossu	2008	2008 International Conference on Complex, Intelligent and Software Intensive Systems	10.1109/CISIS.2008.111	computer vision;simulation;engineering;remote sensing	Visualization	80.4369625775196	-53.96408770919568	90988
4c7aa9c5f1f29eca445ab2c788ced8ba0ca333ed	efficient normal estimation using variable-size operator		Shading an object is to simulate the behaviour of light incident on its surfaces. It is necessary to calculate normal vectors on the surfaces of the object for shading it. Since objects do not contain surface inclination in voxel-based representation, a normal vector for each voxel must be estimated from the relative position of its neighbouring voxels that have the same data value. The previously devised methods that use fixed-size gradient operators can estimate normal vectors accurately only in a limited area and may cause some errors and artefacts. In this paper we propose an efficient normal estimation method using an extended central difference operator whose size can vary according to the arrangement of surface-comprising voxels. This method calculates normals more accurately than the previous methods and its computation time is shorter than that of methods that guarantee the same image quality. In order to show the improvement, we compare the quality of resulting images and processing time by implementing the newly proposed method and the previous methods and then applying them to some volume data. Copyright ? 1999 John Wiley & Sons, Ltd.	algorithm;boyce–codd normal form;computation;discretization;finite difference;gradient;image noise;image quality;john d. wiley;normal (geometry);pixel;shading;simulation;time complexity;tuple space;virtual artifact;voxel	Byeong Seok Shin	1999	Journal of Visualization and Computer Animation	10.1002/(SICI)1099-1778(199904/06)10:2%3C91::AID-VIS199%3E3.0.CO;2-W	computer vision;mathematics;geometry;computer graphics (images)	Graphics	65.2672769146045	-52.93005657750535	91070
6995e9309782a802ac1e9f166048c7606ec25e9d	spatial statistics of objects in 3-d sonar images: application to fisheries acoustics	distribution;economie;geophysical image processing;objet;vegetation mapping;statistique;lettre;educational institutions acoustics sonar feature extraction geometry ice training;fisheries acoustics;acoustics;underwater sound;training;point process;geometry;eau;colonne;vegetation mapping geophysical image processing oceanographic techniques underwater sound vegetation;spatial point process;vegetation;data analysis;point processes;multibeam sensor;feature extraction;spatial statistics fisheries acoustics multibeam sensor object patterns in images point processes;economies et finances;object patterns in images;pelagic fish schools 3 d sonar images fisheries acoustics water column multibeam echo sounder monobeam echo sounder pelagic biomasses spatial point processes descriptive spatial statistics;information gain;spatial statistics;acoustique;oceanographic techniques;analyse comparative;ice;poisson;sonar	In this letter, we address the characterization of objects in 3-D sonar images of the water column obtained by a multibeam echo sounder. Compared with classic 2-D images from a monobeam echo sounder, these 3-D images provide finer scale observation of the pelagic biomasses and new tools to characterize 3-D distributions. By viewing object patterns as realizations of spatial point processes, we investigate descriptive spatial statistics. This method is then applied to 3-D fisheries acoustics data set for characterization of the distribution of pelagic fish schools. Reported experiments illustrate the relevance of the proposed descriptors. The comparison of our method with 2-D sonar data analysis further demonstrates the information gain from using 3-D sonar imagery.	computer vision;echo (computing);experiment;kullback–leibler divergence;relevance;sonar (symantec);spatial analysis;spatial organization;visual descriptor	Riwal Lefort;Ronan Fablet;Laurent Berger;Jean-Marc Boucher	2012	IEEE Geoscience and Remote Sensing Letters	10.1109/LGRS.2011.2160328	acoustics;point process;mathematics;optics;statistics;remote sensing	Vision	73.28051494300186	-61.91437103505561	91086
682887527044ddaf07c723bd660e0cb968bc7ea0	cascaded image deblurring with combined image prior		In this paper, we propose a cascaded image deblurring scheme that adopts combined image prior followed by multi-scale separable kernel refinement. Specifically, we introduce a combined image prior made up of Aggressive Patch Recurrence (APR) prior and sparsity image prior, where the sparsity prior works as a good compensation for cases where APR prior fails to maintain the self-similarity assumption. We further propose a multi-scale separable kernel refinement method, which can effectively remove noise and ringing artifacts from kernels. Experimental results show that our cascaded deblurring scheme is capable of estimating noise-free blur kernels and achieves visually pleasant resultant images without obvious ringing artifacts when deblurring both synthetic and real-world blurry images.	arp spoofing;deblurring;gaussian blur;kernel (operating system);recurrence relation;refinement (computing);resultant;ringing artifacts;self-similarity;sparse matrix;synthetic data	Xiaoyun Yuan;Ziwei Xu;Haoqian Wang;Yebin Liu;Lu Fang	2017	2017 IEEE Global Conference on Signal and Information Processing (GlobalSIP)	10.1109/GlobalSIP.2017.8308595	kernel (linear algebra);ringing artifacts;computer vision;deblurring;mathematics;artificial intelligence	Vision	57.26996747229352	-69.49618887504985	91091
6bbb18245849be28d692b443762d7e1a949399c3	the sentinel-3 mission: overview and status	oceans;ocean temperature sea surface satellites sea measurements land surface instruments;low earth orbit satellites;artificial satellites;land surface;earth observing system;space research;space research artificial satellites;ocean and global land monitoring services sentinel 3 mission global monitoring for environment and security sentinel satellites european heritage envisat;land surface earth observing system low earth orbit satellites oceans	The series of Global Monitoring for Environment and Security (GMES) Sentinel satellites will continue and extend the European heritage of ENVISAT to provide data to numerous user communities. Sentinel-3 is being developed to support GMES Ocean and global Land monitoring services. Two Sentinel-3 satellites are in development with a first launch in 2014 and the second satellite expected approximately 18 months after the first. This paper provides an overview of the Sentinel-3 Mission.	communications satellite	Craig Donlon;Bruno Berruti;Susanne Mecklenburg;Jens Nieke;Helge Rebhan;Ulf Klein;Alessandra Buongiorno;Constantin Mavrocordatos;Johannes Frerick;Bernd Seitz;Philippe Goryl;Pierre Féménias;Juergen Stroede;Roberto Sciarra	2012	2012 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2012.6351194	meteorology;atmospheric sciences;space research;physics;satellite;remote sensing;european data relay system	Embedded	80.45729247232798	-62.63272338976589	91124
2d9be4bf45131ecdd618063eab406a2a0c8ccd54	dynamic receive aperture downsampling for ultrasound imaging	dynamic aperture ultrasonic imaging array signal processing;image quality loss dynamic receive aperture downsampling ultrasound imaging sampled array element reduction ultrasound signal reception analog digital conversion image acquisition;arrays apertures ultrasonic imaging imaging array signal processing acoustics coherence;ultrasonic imaging analogue digital conversion array signal processing signal sampling	We propose a simple method for reducing the number of sampled array elements during ultrasound signal reception. Our approach involves dynamic data-driven switching between various downsampling factors applied to the receive aperture in real time. Our simulation results show that one can achieve approximately 70-85% savings in the total number of sampled array elements per image (thus reducing the total number of expensive analog-to-digital conversions during image acquisition), without significant image quality losses.	analog-to-digital converter;decimation (signal processing);dynamic data;image quality;medical ultrasound;simulation	Mohammed Albulayli;Daler N. Rakhmatov	2014	2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	10.1109/ICASSP.2014.6854580	computer vision;image processing	Robotics	55.00127818916908	-79.40969853363053	91321
5a4fd7308770e354cecf7e092c3d8d685f1314ef	edge guided reconstruction for compressive imaging	edge detection;65k10;compressive sensing;68u10;magnetic resonance imaging;90c25;discrete fourier transform;65f22;total variation;65t50	We propose EdgeCS—an edge guided compressive sensing reconstruction approach—to recover images of higher quality from fewer measurements than the current methods. Edges are important image features that are used in various ways in image recovery, analysis, and understanding. In compressive sensing, the sparsity of image edges has been successfully utilized to recover images. However, edge detectors have not been used on compressive sensing measurements to improve the edge recovery and subsequently the image recovery. This motivates us to propose EdgeCS, which alternatively performs edge detection and image reconstruction in a mutually beneficial way. The edge detector of EdgeCS is designed to faithfully return partial edges from intermediate image reconstructions even though these reconstructions may still have noise and artifacts. For complex-valued images, it incorporates joint sparsity between the real and imaginary components. EdgeCS has been implemented with both isotropic and anisotropic discretizations of total variation and tested on incomplete k-space (spectral Fourier) samples. It applies to other types of measurements as well. Experimental results on large-scale real/complex-valued phantom and magnetic resonance (MR) images show that EdgeCS is fast and returns high-quality images. For example, it exactly recovers the 256×256 Shepp–Logan phantom from merely 7 radial lines (3.03% k-space), which is impossible for most existing algorithms. It is able to accurately reconstruct a 512 × 512 MR image with 0.05 white noise from 20.87% radial samples. On complex-valued MR images, it obtains recoveries with faithful phases, which are important in many medical applications. Each of these tests took around 30 seconds on a standard PC. Finally, the algorithm is GPU friendly.	algorithm;compressed sensing;edge detection;graphics processing unit;imaginary time;imaging phantom;iterative reconstruction;phantom reference;pixel;radial (radio);resonance;sensor;shepp–logan phantom;sparse matrix;white noise	Weihong Guo;Wotao Yin	2012	SIAM J. Imaging Sciences	10.1137/110837309	computer vision;mathematical optimization;edge detection;magnetic resonance imaging;discrete fourier transform;mathematics;compressed sensing;total variation	Vision	56.4600580358853	-74.5100442332165	91356
3c8c618e1b0343dd4f3d8e3089c665c9f7cdb077	piece-wise convex spatial-spectral unmixing of hyperspectral imagery using possibilistic and fuzzy clustering	hyperspectral imagery;possibilistic;cluster algorithm;visible spectroscopy;pattern clustering;piece wise convex;convex geometry model;possibilistic clustering;spatial spectral unmixing algorithm;visible spectroscopy face recognition fuzzy set theory image colour analysis infrared spectroscopy pattern clustering;linear mixing;endmember;vis nir hyperspectral face imagery;materials;fuzzy set theory;convex geometry;fuzzy clustering;face recognition;piecewise convex hyperspectral unmixing algorithm;fuzzy;hyperspectral imaging equations mathematical model materials clustering algorithms signal processing algorithms;image colour analysis;signal processing;material spectra;spatial image information;mathematical model;clustering algorithms;spectral unmixing;imaging spectroscopy;vis nir hyperspectral face imagery hyperspectral imagery material spectra piecewise convex hyperspectral unmixing algorithm spatial image information spectral image information fuzzy clustering possibilistic clustering spatial spectral unmixing algorithm imaging spectroscopy;infrared spectroscopy;hyperspectral imaging;signal processing algorithms;convex geometry model hyperspectral endmember spectral unmixing possibilistic fuzzy piece wise convex linear mixing;spectral image information;hyperspectral image;hyperspectral	Imaging spectroscopy refers to methods for identifying materials in a scene using cameras that digitize light into hundreds of spectral bands. Each pixel in these images consists of vectors representing the amount of light reflected in the different spectral bands from the physical location corresponding to the pixel. Images of this type are called hyperspectral images. Hyperspectral image analysis differs from traditional image analysis in that, in addition to the spatial information inherent in an image, there is abundant spectral information at the pixel or sub-pixel level that can be used to identify materials in the scene. Spectral unmixing techniques attempt to identify the material spectra in a scene down to the sub-pixel level. In this paper, a piece-wise convex hyperspectral unmixing algorithm using both spatial and spectral image information is presented. The proposed method incorporates possibilistic and fuzzy clustering methods. The typicality and membership estimates from those methods can be combined with traditional material proportion estimates to produce more meaningful proportion estimates than obtained with previous spectral unmixing algorithms. An analysis of the utility of using all three estimates produce a better estimate is given using real hyperspectral imagery.	algorithm;cluster analysis;fuzzy clustering;image analysis;pixel;reduction (complexity);spectral method	Alina Zare;Paul D. Gader	2011	2011 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE 2011)	10.1109/FUZZY.2011.6007622	full spectral imaging;infrared spectroscopy;computer vision;computer science;hyperspectral imaging;signal processing;pattern recognition;mathematics	Vision	69.90128777045375	-64.6283384219534	91403
