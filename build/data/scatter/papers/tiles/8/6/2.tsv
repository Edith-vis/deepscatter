id	title	keywords	abstract	entities	authors	year	journal	doi	fos	area	x	y	ix
463617de82e541cfb8aae2c243d6131a0cce07fc	improved specular highlights with adaptive shading	phong shading;interpolation;interpolation methods;rendering computer graphics graphics interpolation lighting equations reflection information geometry workstations hardware software quality;computational geometry;computational geometry interpolation rendering computer graphics;gouraud shading;adaptive shading;information geometry;surface geometry;curved surface;polygon mesh rendering;graphics hardware;polygonal meshes;interpolation method;workstations;specular highlights;illumination equation;lighting;rendering computer graphics;surface geometry specular highlights adaptive shading gouraud shading phong shading interpolation methods polygon mesh rendering curved surface illumination equation;reflection;software quality;graphics;hardware	Gouraud shading and Phong shading are widely used interpolation methods to render a polygon mesh of a curved surface. When an illumination equation has a specular reflection term, Phong shading produces more realistic results than does Gouraud shading. The specular highlights produced by Phong shading give visual information about surface geometry and properties. However, Phong shading is not implemented in most graphics workstations and software renderers due to its computational expense. This paper introduces an adaptive shading method that produces Phong-shaded quality images for a small increase in rendering time on Gouraud shading systems. It is possible to get higher quality images from existing graphics hardware or software within a resonable time by simple modifications of the application or library.	analysis of algorithms;gouraud shading;graphics hardware;interpolation;phong shading;polygon mesh;specular highlight;workstation	Youngkwan Cho;Ulrich Neumann;Jongwook Woo	1996		10.1109/CGI.1996.511785	phong shading;rasterisation;computer vision;shading;reflection;workstation;phong reflection model;gouraud shading;vertex normal;computational geometry;interpolation;computer science;graphics;lighting;specular highlight;blinn–phong shading model;graphics hardware;t-vertices;information geometry;software quality;deferred shading;computer graphics (images)	Graphics	67.41977929428779	-48.44653274880752	18652
40adc28d9870f0252c0aded39b042a640a0eb702	measuring coverage performances of a floor cleaning mobile robot using a vision system	vision system;robot sensing systems;floor coverage;performance evaluation;mobile robot;mobile robots;orbital robotics;floor coverage cleaning mobile robot;machine vision;lighting;robot vision systems;cameras;floors;cleaning;cleaning mobile robot;performance evaluation cleaning mobile robots machine vision lighting robot vision systems orbital robotics cameras robot sensing systems floors	This work introduces a method and apparatus for measuring real mobile robot cleaning performances based on a dedicated vision system. The measurement method can be applied to any kind of floor cleaning mobile robot but in this work it has been applied to a proprietary design. The paper presents the analysis of the first results obtained and ends with the main conclusions.	experiment;mobile robot;performance;plasma cleaning;sputter cleaning;system of measurement;time complexity	Jordi Palacín;Tomàs Pallejà;Ignasi Valgañón;Ramón Pernia;Joan Roca	2005	Proceedings of the 2005 IEEE International Conference on Robotics and Automation	10.1109/ROBOT.2005.1570771	mobile robot;embedded system;computer vision;simulation;machine vision;computer science;engineering;artificial intelligence;mobile robot navigation	Robotics	58.63123628724951	-34.226272804631634	18682
8eae753dc7d8ab02d98c000bfe2726e68f741e5f	robust rough-terrain locomotion with a quadrupedal robot		Robots working in natural, urban, and industrial settings need to be able to navigate challenging environments. In this paper, we present a motion planner for the perceptive rough-terrain locomotion with quadrupedal robots. The planner finds safe footholds along with collision-free swing-leg motions by leveraging an acquired terrain map. To this end, we present a novel pose optimization approach that enables the robot to climb over significant obstacles. We experimentally validate our approach with the quadrupedal robot ANYmal by autonomously traversing obstacles such steps, inclines, and stairs. The locomotion planner re-plans the motion at every step to cope with disturbances and dynamic environments. The robot has no prior knowledge of the scene, and all mapping, state estimation, control, and planning is performed in real-time onboard the robot.		Peter Fankhauser;Marko Bjelonic;Dario Bellicoso;Takahiro Miki;Marco Hutter	2018	2018 IEEE International Conference on Robotics and Automation (ICRA)	10.1109/ICRA.2018.8460731	terrain;control engineering;traverse;simulation;robot;motion planning;engineering;quadrupedalism;climb;stairs	Robotics	55.61426319614585	-27.226963757916877	18683
12935f28973b303ac4dc97c7b41b716a1f131f4b	evaluation of automatic calibration method for motion tracking using magnetic and inertial sensors		During the human motion tracking with miniature IMU sensors we cannot assume that the sensors are perfectly aligned with the segments to which they are attached. In order to find the relative rotation between the sensor and the segment, the sensor must be subjected to the step of calibration. The article concerns the evaluation of automatic calibration method searching for the sensor-to-segment orientation using linear acceleration of segments in the kinematic chain. Performance of the method is analyzed for simulated and real data.	sensor	Ewa Lach	2016		10.1007/978-3-319-39904-1_30	inertial reference unit;tracking system	Robotics	56.95352245706924	-38.05480048414986	18723
35d8b60274a8aab28da69a2c70ef872f88ec7b7a	a multigrid framework for real-time simulation of deformable bodies	strain measurement;real time simulation;computational geometry and object modeling;multigrid;dynamic range;equation of motion;deformable bodies;three dimensional graphics and realism;elastic modulus;object model	In this paper, we present a multigrid framework for construc ing implicit, yet interactive solvers for the governing equations of motion of deformable volumetric bodies. We have integrated linearized, corotational linearized and non-linear Green strain into this framework. Based on a 3 D finite element hierarchy, this approach enables realistic simulation of objects exhibiting an elastic modu lus with a dynamic range of several orders of magnitude. Using the linearized strain measure, we can simulate 50 thou sand tetrahedral elements with 20 fps on a single processor CPU. By using corotational linearized and non-li near Green strain, we can still simulate five thousand and two thousand elements, respectively, at the same rates.	central processing unit;collision detection;dynamic range;eurographics;finite element method;iteration;multigrid method;nonlinear system;numerical analysis;numerical stability;polygon mesh;real-time clock;real-time computing;real-time transcription;real-time web;simulation;virtual reality	Joachim Georgii;Rüdiger Westermann	2006	Computers & Graphics	10.1016/j.cag.2006.02.016	elastic modulus;computer vision;dynamic range;simulation;object model;computer science;equations of motion;geometry;programming language;multigrid method;computer graphics (images)	Robotics	70.26542410937734	-47.685776922647186	18730
f0ce2fc7e276fa92180c8374d58c8bfe20bfa81a	hardware experiments of autonomous space robot - a demonstration of truss structure assembly -	autonomous space robot;hardware simulator;truss assembly		autonomous robot	Kei Senda;Yoshisada Murotsu;Akira Mitsuya;Hirokazu Adachi;Shin-ichi Ito;Jynya Shitakubo	2000	JRM	10.20965/jrm.2000.p0343	control engineering;embedded system;simulation;engineering	Robotics	64.5295965572022	-28.30946135273395	18737
26d2721bacb0691660260bfaa5195a6914065552	practical 3d tracking using low-cost cameras		There exist solutions for tracking of objects in 3D space involving hi-tech cameras and powerful computer systems capable of tracking many objects in large dynamic space simultaneously in real time. On the other hand, there are situations where such functionality is not necessary and the conditions may be specified in more detail, which makes the task significantly easier. This paper shows the possibility to track a single object using low-cost cameras on an ordinary laptop in a small-scale and mostly static environment. This solution is useful for standalone tracking in mobile robotics and particularly in the debugging phases, where the user needs to judge the robot movement system independently on what the robot claims.	debugging;laptop;mobile robot;robotics	Roman Barták;Michal Koutný;David Obdrzálek	2016			laptop;debugging;robot;computer science;artificial intelligence;computer vision;robotics	Robotics	55.86995084094639	-38.73039270992622	18810
1bcf8a4e36cc045c8ffb37222c175a8ec080e14f	real-time simulation of interaction between colon and endoscope for the colonoscopy simulation		This paper proposes a novel simulation framework for the real-time deformation of the colon and endoscope using a skeleton-driven deformation method. Cylindrical lattices and a centerline are employed as the skeletons, and a mass-spring model is applied to the skeletons for the mechanics-based simulation. The centerline-based collision detection and resolution algorithm is applied to simulate the interaction between the colon and endoscope. The proposed simulation framework is integrated with a colonoscopy simulation. Simulation results show that the proposed method allows real-time simulation (28 Hz) using the colon model composed of up to 241,440 meshes.		Hoeryong Jung;Doo Yong Lee	2012	Studies in health technology and informatics	10.3233/978-1-61499-022-2-218	data mining;real-time simulation;computer vision;colonoscopy;endoscope;artificial intelligence;medicine	Robotics	69.85881432461254	-49.00261006592762	18906
6e446b642089bc0c17ea591334f835a273028318	autonomous planetary exploration using lidar data	mars;robot sensing systems;mobile robot autonomous planetary exploration lidar data canadian space agency rover sensing horizon lidar range sensors irregular triangular meshes path planning technique mars emulation terrain;planetary rovers collision avoidance mobile robots optical radar;lidar range sensors;mobile robot;path planning;laser radar;mobile robots;triangular mesh;mars emulation terrain;planetary rovers;canadian space agency;irregular triangular meshes;navigation;planetary exploration;laser radar mars navigation space technology path planning robot sensing systems space missions robotics and automation humans robustness;trajectory;optical radar;path planning technique;lidar data;spatial representation;rover sensing horizon;autonomous navigation;collision avoidance;long range;autonomous planetary exploration	In this paper we present the approach for autonomous planetary exploration developed at the Canadian Space Agency. The goal of this work is to autonomously navigate to remote locations, well beyond the sensing horizon of the rover, with minimal interaction with a human operator. We employ LIDAR range sensors due to their accuracy, long range and robustness in the harsh lighting conditions of space. Irregular Triangular Meshes (ITMs) are used for representing the environment providing an accurate yet compact spatial representation. In this paper a novel path-planning technique through the ITM is introduced, which guides the rover through flatter terrain and safely away from obstacles. Experiments performed in CSA's Mars emulation terrain that validate our approach are also presented.	a* search algorithm;autonomous robot;emulator;experiment;graph traversal;irish transverse mercator;iterative closest point;iterative method;loss function;motion planning;online and offline;planetary scanner;rover (the prisoner);sensor;stereo camera;traverse;triangulated irregular network;visual odometry;waypoint	Ioannis M. Rekleitis;Jean-Luc Bedwani;Erick Dupuis	2009	2009 IEEE International Conference on Robotics and Automation	10.1109/ROBOT.2009.5152504	mobile robot;simulation;geodesy;computer science;artificial intelligence;remote sensing	Robotics	53.826657874497464	-31.199674099968774	18931
ba161f88f0f120f1fe3a6796c89acc0fe4af9773	sensor fusion for depth estimation, including tof and thermal sensors	sensor fusion cameras computer graphics computer vision;image processing;cameras satellites image color analysis image reconstruction image segmentation smoothing methods sensor fusion;computer graphics;sensor fusion computer vision image processing;computer vision;occlusions sensor fusion depth estimation tof sensor thermal sensors depth maps high quality reference camera satellite sensors time of flight sensor;sensor fusion;cameras	This paper describes the computation of depth maps for a high-quality reference camera augmented by a set of satellite sensors. The satellite sensors include support cameras, a TOF (time-of-flight) sensor, and a thermal camera, all rigidly attached to the reference camera. There is extensive previous work on computing depth maps with stereo alone, and high-quality results have been achieved. However it has proved difficult to achieve good results for cases such as texture less areas, or similar fore- and background colors. We show that with our proposed sensor fusion we can achieve high quality results. The paper makes two contributions. The first is a method for combining TOF data with multi-camera data that includes reasoning about occlusions, to produce an improved depth estimate near depth discontinuities. The second contribution is to show the benefit of thermal sensing as a segmentation prior. Thermal cameras were formerly high-cost devices but are now available at the same cost as machine vision cameras. This work demonstrates their advantages, particularly for scenes including humans.	color;computation;depth map;display resolution;machine vision;sensor web;web colors	Jeroen van Baar;Paul A. Beardsley;Marc Pollefeys;Markus H. Gross	2012	2012 Second International Conference on 3D Imaging, Modeling, Processing, Visualization & Transmission	10.1109/3DIMPVT.2012.69	stereo cameras;computer vision;geography;soft sensor;image sensor format;image sensor;remote sensing;visual sensor network;computer graphics (images)	Robotics	54.24927778187862	-44.49101899475425	18947
d150cd559e72daa7ecf357102374a14209fb142a	double exponential smoothing for predictive vision based target tracking of a wheeled mobile robot	tracking error regulation double exponential smoothing predictive vision based target tracking wheeled mobile robot nonlinear kinematic controller measurement uncertainties robot relative position predictive estimation controller proportional gain;target tracking prediction algorithms machine vision smoothing methods algorithm design and analysis trajectory mobile robots;nonlinear control systems;mobile robots;smoothing methods;robot vision;object tracking;wheels mobile robots nonlinear control systems object tracking robot kinematics robot vision smoothing methods;robot kinematics;wheels	This paper describes the design of a novel nonlinear kinematic controller which allows a wheeled mobile robot to track a moving target at a given separation distance. The Double Exponential Smoothing algorithm is employed to deal with uncertainties in the measurements and to acquire a predictive estimate for the robot's relative position. This estimate is used to automatically adjust the proportional gain of the controller in order to regulate the tracking error.	algorithm;embedded system;kalman filter;mobile robot;motion capture;nonlinear system;smoothing	François Guerin;Simon G. Fabri;Marvin K. Bugeja	2013	52nd IEEE Conference on Decision and Control	10.1109/CDC.2013.6760426	control engineering;mobile robot;computer vision;computer science;engineering;video tracking;control theory;robot control;robot kinematics;robot calibration	Robotics	61.04785210951788	-31.508451571246678	18963
c26fb70a4b893ab2a27b846e31128736f76d17d1	off-road lidar simulation with data-driven terrain primitives		Developing software for large scale off-road robot applications is challenging and tedious due to cost, logistics, and rigor of field testing. High-fidelity sensor-realistic simulation can speed up the development process for perception and state estimation algorithms. We focus on Lidar simulation for robots operating in off-road environments. Lidars are integral sensors for robots, and Lidar simulation for off-road environments is particularly challenging due to the way Lidar rays interact with natural terrain such as vegetation. A hybrid geometric terrain representation has been shown to model Lidar observations well [1]. However, previous work has only been able to simulate a single, fixed scene, and the entire scene had to be precisely surveyed. In this work, we add semantic information to the hybrid geometric model. This allows us to extract terrain primitives, such as trees and shrubs, from data logs. Our approach uses these primitives to compose arbitrary scenes for Lidar simulation. We evaluate our simulator on a real-world environment of interest, and show that primitives derived using our approach generalize to new scenes.	algorithm;cluster analysis;data logger;deep learning;extrapolation;geometric modeling;geometric primitive;graphical model;ground truth;logistics;map;open-source software;point cloud;robot;scene graph;sensor;simulation;software development;voxel	Abhijeet Tallavajhula;Çetin Meriçli;Alonzo Kelly	2018	2018 IEEE International Conference on Robotics and Automation (ICRA)	10.1109/ICRA.2018.8461198	terrain;geometric modeling;software;speedup;computer vision;control engineering;lidar;engineering;artificial intelligence	Robotics	55.47602961582946	-42.29242475166159	19010
3a3e75a2f48d98ea0ed87d802d261541c560f1c5	compressing repeated content within large-scale remote sensing images	image epitomes;large scale remote sensing image	Large-scale remote sensing images, including both satellite and aerial photographs, are widely used to render terrain scenes in real-time geographic visualization systems. Such systems often require large memories in order to store fine terrain details and fast network speeds to transfer image data, if they are built as web applications. In this paper, we propose a progressive texture compression framework to reduce the memory and bandwidth cost by compressing repeated content within and among large-scale remote sensing images. Different from existing image factorization methods, our algorithm incrementally find similar regions in new images so that large-scale images can be more efficiently compressed over time. We further propose a descriptor, the Gray Split Rotate (GSR) descriptor, to accelerate the similarity search. The reconstruction quality is finally improved by compressing residual error maps using customized S3TC-like compression. Our experiment shows that even with the error maps, our system still has higher compression rate and higher compression quality than using S3TC alone, which is a typical compression solution in most existing visualization systems.	aerial photography;algorithm;codebook;data compression;geovisualization;graphics processing unit;map;real-time locating system;s3 texture compression;similarity search;web application	Wei Hua;Rui Wang;Xusheng Zeng;Ying Tang;Huamin Wang;Hujun Bao	2012	The Visual Computer	10.1007/s00371-012-0710-3	computer vision;computer science;texture compression;computer graphics (images)	Graphics	69.2093425660324	-51.969518243697706	19029
583d3b0a8bdb59fbf3efff291873648e67a1cb56	simple methods for drawing rational surfaces as four or six bezier patches	blow up;computational geometry;projective plane;parameter space;rational surface	In this paper, we give several simple methods for drawing a whole rational surface (without base points) as several Bézier patches. The first two methods apply to surfaces specified by triangular control nets and partition the real projective plane RP into four and six triangles respectively. The third method applies to surfaces specified by rectangular control nets and partitions the torus RP × RP into four rectangular regions. In all cases, the new control nets are obtained by sign flipping and permutation of indices from the original control net. The proofs that these formulae are correct involve very little computations and instead exploit the geometry of the parameter space (RP or RP ×RP). We illustrate our method on some classical examples. We also propose a new method for resolving base points using a simple “blowing up” technique involving the computation of “resolved” control nets.	approximation;bézier curve;computation;control theory;de casteljau's algorithm;rp (complexity);time complexity	Jean H. Gallier	1999	CoRR		projective plane;discrete mathematics;topology;computational geometry;mathematics;geometry;parameter space	Robotics	68.61282413142025	-41.34947040137972	19044
147fc4d66f851affd12d2512540400b2f6d52fbb	genetic algorithm based robot posture	robot posture;genetic algorithm;comparison analysis	Robot-posture with genetic algorithm is presented in this paper. As a robot platform walking biped robot is used. To cope with the difficulties and explain unknown empirical laws in the robot, practical robot walking on a descending sloped floor is modeled by genetic architecture. These results from the modeling strategy is analyzed and compared.	genetic algorithm;poor posture;robot	Dong Won Kim;Jong-Wook Park;Sung Wook Park	2012		10.1007/978-3-642-35585-1_9	computer vision;simulation;engineering;artificial intelligence;arm solution;robot control;robot calibration	Robotics	63.77490091655383	-24.079348611644846	19095
928f65dc1f0b0f6a8f3dcae68539b30eba754a3c	research on the universal platform for aerospace craft simulation	software;aerospace;aerodynamics;platform;platform distributed simulation simulator aerospace;upacs space task simulation modular simulators standardized simulators command and control functions task programming processes accurate mode rough mode multisimulators kinematic simulation optic simulation radar simulation universal platform for aerospace craft simulation;aerospace simulation;simulator;computational modeling mathematical model data models space vehicles software hardware;computational modeling;aerospace computing;aerospace simulation aerodynamics aerospace computing;mathematical model;distributed simulation;space vehicles;data models;hardware	A universal platform for aerospace craft simulation was proposed in order to satisfy the various requirements in space tasks simulation. The platform is composed of a series of modular and standardized simulators, in which the kinematic, optic, radar or other characters of crafts can be simulated. The command & control functions and task programming processes can also be simulated in either accurate mode or rough mode. The platform can simulate simple tasks using only one simulator or complex contributed tasks using multi-simulators. As a whole, the proposed platform can be used as a flexible infrastructure to simulate various space tasks.	control function (econometrics);development speed;effective method;radar;requirement;simulation	Dong Liu;Yi Li;Weiyan Xing;Bo Wang	2012	2012 Sixth International Conference on Innovative Mobile and Internet Services in Ubiquitous Computing	10.1109/IMIS.2012.24	embedded system;data modeling;simulation;aerodynamics;computer science;mathematical model;aerospace;platform;computational model	Robotics	65.2642527999545	-30.203671828399504	19130
3a16732668bdd8cc777a7890b1a6bdffb8e43ef7	gpu-based visualization techniques for 3d microscopic imaging data	0760p;image tridimensionnelle;cellular structure;canal multiple;aplicacion medical;modelo 3 dimensiones;microscopia confocal;multiple channels;volume rendering;modele 3 dimensions;0130c;texture image;imagerie;three dimensional model;three dimensional;image texture;systeme conversationnel;multiple channel;visualization;imagery;image generation;image acquisition;visualisation;visualization technique;weighted sums;graphics processing units;imaging;graphic processing unit;volume visualization;tridimensional image;formation image;computing systems;medical application;microscopie confocale;imagineria;confocal microscopy;4230v;interactive systems;interactive volume rendering;imagen tridimensional;application medicale	Three-dimensional (3D) microscopic imaging techniques such as confocal microscopy have become a common tool in measuring cellular structures. While computer volume visualization has advanced into a sophisticated level in medical applications, much fewer studies have been made on data acquired by the 3D microscopic imaging techniques. To optimize the visualization of such data, it is important to consider the data characteristics such as thin data volume. It is also interesting to apply the new GPU (graphics processing unit) technology to interactive volume rendering of the data. In this paper, we discuss several texture-based techniques to visualize confocal microscopy data by considering the data characteristics and with support of GPU. One simple technique generates one set of 2D textures along the axial direction of image acquisition. An improved technique uses three sets of 2D textures in the three principal directions, and creates the rendered image via a weighted sum of the images generated by blending the individual texture sets. In addition, we propose a new approach based on stencil such that textures are blended based on a stencil control. Given the viewing condition, a texel needs to be drawn only when its corresponding projection on the image plane is inside a stencil area. Finally, we have explored the use of multiple-channel datasets for flexible classification of objects. These studies are useful to optimize the visualization of 3D microscopic imaging data.	alpha compositing;computer graphics;graphics processing unit;image plane;modulation;opengl shading language;real-time clock;scientific visualization;transfer function;volume rendering;weight function	Qiqi Wang;Yinlong Sun;J. Paul Robinson	2007		10.1117/12.716136	medical imaging;computer vision;visualization;computer science;optics;computer graphics (images)	Visualization	70.88807863851771	-51.2411042347955	19149
f09df5c3580b083f99df504d2ba616dee1299425	a modular amphibious snake-like robot: design, modeling and simulation	robot kinematics design engineering mobile robots path planning robot dynamics;robot sensing systems robot kinematics inspection mathematical model modeling rails;mechanical design modular amphibious snake like robot hyper redundant bionic robots degrees of freedom dof robot modularized joints robot controllers robot structures robot locomotion pitch yaw pitch yaw configuration kinematics equations dynamic model webots gait planning	Snake-like robots are a class of hyper-redundant bionic robots. They have small cross-section and many degrees of freedom (DOFs), making them ideally suited to travel on confined spaces such as underwater caves, sunken vessels, collapsed buildings, and so on. Especially, an amphibious snake-like robot can move both on ground and underwater. In this paper, we proposed a kind of amphibious snake robot with modularized joints, controllers, and structures. It can perform tasks such as maritime accident rescue, amphibious environment detection, emergency response and life rescue, meeting the requirement on many fields. This robot is composed by 10 modularized joints with new structure. Each joint has 2 DOFs (pitch and yaw), which make the robot locomote in three-dimensional agilely. All the revolute joints are arranged in the configuration of Pitch-Yaw-Pitch-Yaw (abbreviated as PYPY structure). With this configuration, the robot has very dexterous movement ability. Then, we derived the analytical kinematics equations, based on which we planned the typical gait for it. At last, the dynamic model including the ground and aquatic environment was created by using Webots. The simulation study on typical cases was performed and the simulation results verified the mechanical design, kinematics and gait planning of the robotic system.	aquatic ecosystem;compiler;control system;mathematical model;mathematical optimization;online analytical processing;pypy;robot;shape optimization;simulation;yaws	Bingsong Yang;Liang Han;Guangming Li;Wenfu Xu;Bingshan Hu	2015	2015 IEEE International Conference on Robotics and Biomimetics (ROBIO)	10.1109/ROBIO.2015.7419054	kinematics equations;structural engineering;control engineering;mobile robot;robot end effector;cartesian coordinate robot;simulation;articulated robot;engineering;snake-arm robot;social robot;arm solution;robot control;robot kinematics;robot calibration	Robotics	64.75272627519878	-27.308886286441627	19182
c815589cc20f71a091605d572507ee7bce3db832	computer control of a mechanical arm through visual input			articulated robot;computer control company	Karl K. Pingle;Jonathan A. Singer;William M. Wichman	1968			computer hardware;robotic arm;computer science	Robotics	67.66262074293061	-27.957039384619883	19216
6a00746fc98248da0db1e6074090c2d513f9487d	dexterous manipulation graphs		We propose the Dexterous Manipulation Graph as a tool to address in-hand manipulation and reposition an object inside a robot's end-effector. This graph is used to plan a sequence of manipulation primitives so to bring the object to the desired end pose. This sequence of primitives is translated into motions of the robot to move the object held by the end-effector. We use a dual arm robot with parallel grippers to test our method on a real system and show successful planning and execution of in-hand manipulation.		Silvia Cruciani;Christian Smith;Danica Kragic;Kaiyu Hang	2018	2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)	10.1109/IROS.2018.8594303	grippers;computer science;computer vision;human–computer interaction;artificial intelligence;robot;graph;robot end effector	Robotics	63.94001061242712	-26.363457236269507	19224
430b4c70f7d01c54b848f43747d36ef4b86a834d	efficient rendering of strong secondary lighting in photon mapping algorithm	image sampling;photon mapping algorithm;efficient algorithm;image representations;layout;strong secondary lighting;image representation;image quality;lightning;rendering computer graphics layout light sources lighting cameras sampling methods monte carlo methods image sampling image quality production;rendering computer graphics image representation lightning;production;lighting;sampling methods;rendering computer graphics;photon mapping;monte carlo methods;cameras;light sources;image quality rendering strong secondary lighting photon mapping algorithm image representation;rendering	In this paper we propose an efficient algorithm for handling strong secondary light sources within the photon mapping framework. We introduce an additional photon map as an implicit representation of such light sources. At the rendering stage this map is used for the explicit sampling of strong indirect lighting in a similar way as it is usually performed for primary light sources. Our technique works fully automatically, improves the computation performance, and leads to a better image quality than traditional rendering approaches	algorithm;coherence (physics);computation;embedded system;image quality;importance sampling;photon mapping;rendering (computer graphics);sampling (signal processing)	Takehiro Tawara;Karol Myszkowski;Hans-Peter Seidel	2004	Proceedings Theory and Practice of Computer Graphics, 2004.	10.1109/TPCG.2004.1314468	computer vision;simulation;rendering;computer science;image-based lighting;computer graphics (images)	Graphics	64.48413568502009	-51.83704458596231	19283
8b43c81175260e4e72e14dda3f443ab5bdcba72f	exploring c4isr employment methods	surveillance command and control systems remotely operated vehicles user interfaces weapons information management sensor fusion;comparative analysis;user interface;surveillance;unmanned aerial vehicle;remotely operated vehicles;employment force sensors unmanned aerial vehicles force control intelligent control surveillance reconnaissance personnel helicopters eyes;information management;intelligence surveillance and reconnaissance;simulation analysis;sensor fusion;command and control systems;user interfaces;weapons;data volume reduction c4isr employment method command control intelligence surveillance reconnaissance collection asset force combat model unmanned aerial vehicle collection asset performance characteristic probabilistic identification weapon system enemy observation commander critical information requirement collection asset loss rate user interface information management intelligence fusion	We will investigate several employment schemes for Command, Control, Intelligence Surveillance and Reconnaissance (C4ISR) collection assets in a simulated Force combat model. These collection assets include Unmanned Aerial Vehicles (UAV) and any ground platforms, normally part of a conventional coalition force lay down. Samples of ground assets include: armored personnel carriers (APC), helicopters, tanks, trucks, binoculars and eyes. Collection asset performance characteristics, along with obtained sensor scans, enable probabilistic identification of participating adversaries or their weapon systems. Comparative analysis focuses on the time to initial enemy observation, threshold of commander's critical information requirements met, and prevention of collection asset loss rate. The analyst controls all thresholds via the user interface. Additionally, a paradigm for information management, i.e. intelligence fusion, is presented. We explore procedures for reducing data volume within this paradigm. We will also discuss implications for the coordination of simulation, analysis, and acquisition activities.	aerial photography;information management;programming paradigm;requirement;simulation;unmanned aerial vehicle;user interface	Terri G. Chang	2005	Proceedings of the Winter Simulation Conference, 2005.	10.1109/WSC.2005.1574378	simulation;computer science;engineering;information management;user interface;operations research;computer security	Robotics	56.58181795924974	-27.37606284584167	19297
61b599995a3ad4df78d6ef1b866035663a425e2d	an abstraction of the lidar measurements	robot sensing systems;sensor phenomena and characterization;measurement by laser beam;optical scanners collision avoidance laser beams mobile robots optical radar;mobile robots;navigation;mobile robots measurement by laser beam robot sensing systems navigation sensor phenomena and characterization;obstacle avoidance lidar measurement laser scanner autonomous car mobile robot localization radio signal laser beam firing angle	The laser scanner seems to be one of the favorite sensors used in mobile robots (autonomous car) localization. The Lidar is similar to the radar except radio signals are substituted with laser beams. Measurements are a collection of n lengths obtained for different firing angles. The paper presents an abstraction of this collection. The abstraction reduce the dimensions of data from n to 3 and can be used in obstacles avoiding or in localization. The paper presents the abstraction definition and a simulation scenario where the abstraction is used.	autonomous car;autonomous robot;internationalization and localization;mobile robot;radar;sensor;simulation	Claudiu Pozna;Erno Horvath;Janos Kovacs	2015	2015 IEEE 10th Jubilee International Symposium on Applied Computational Intelligence and Informatics	10.1109/SACI.2015.7208234	mobile robot;computer vision;navigation;simulation;computer science;engineering;artificial intelligence	Embedded	53.861958836761524	-34.873327545922535	19322
c99c1c79cc2d5af0ee3cb945fe9c8441b123a76a	adaptive unwrapping for interactive texture painting	system dynamics;interactive 3d graphics;texture mapping;multiresolution paint;3d model;zooming;dynamic texture;3d content creation;texture painting	We present a method for dynamically generating an efficient texture bitmap and its associated UV-mapping in an interactive texture painting system for 3D models. Typical 3D texture painting programs require the user to explicitly define the underlying UV-mapping from 3D geometry to 2D bitmap prior to painting. This mapping is unchanged by the painting process. However, a predefined UV-mapping can cause distortion at arbitrary locations and waste bitmap memory in unpainted areas. To solve these problems, we propose an adaptive unwrapping mechanism where the system dynamically creates a tailored UV-mapping for newly painted polygons during the interactive painting process. This eliminates the distortion of brush strokes, and the resulting texture bitmap is more compact because the system allocates texture space only for the painted polygons. In addition, this dynamic texture allocation allows the user to paint smoothly at any zoom level. This technique can be efficiently implemented using standard 3D rendering engines, and the painted models can be stored as standard textured polygonal models. We implemented a prototype system, called Chameleon, and our users’ experiences suggest that our technique is very useful for simple painting by casual users.	3d modeling;3d rendering;bitmap;distortion;prototype;smoothing;texture mapping;uv mapping;web browser engine	Takeo Igarashi;Dennis Cosgrove	2001		10.1145/364338.364404	texture mapping;computer vision;computer science;operating system;system dynamics;texture atlas;texture memory;texture compression;texture filtering;projective texture mapping;computer graphics (images)	Graphics	65.38520201116721	-48.54642275495336	19339
6e6ddd2eded001f3fc2ba1343ae10714eec58908	a prospective fuzzy logic approach to knowledge-based navigation of mobile lego-robot	obstacle avoidance.;fuzzy logic;path finding;mobile lego robot;navigation	The development of techniques for knowledge-based navigation constitutes one of the major trends in the current research on mobile robotics. Fuzzy logic provides tools that are of potential interest to mobile robot control. Most applications of fuzzy logic in this field concern the use of fuzzy control techniques to implement individual behavior units. In this paper we discuss how fuzzy logic computation techniques have been used in the mobile Lego robot for knowledgebased navigation. Also we implemented a robot that learns how to avoid obstacle using online selfadaptation. The outputs from each behaviour’s rule base are integrated using the command fusion process and made crisp using a modified defuzzification technique. The end result is very smooth motion control of the robot. The robot was built using the Lego RCX microcomputer and was designed with the subsumption architecture. We choose to implement the robot’s brain using the Lego RCX due to the lower cost.	computation;defuzzification;fuzzy control system;fuzzy logic;lego mindstorms;microcomputer;mobile robot;prospective search;robot control;robotics;rule-based system;subsumption architecture	Hrudaya K. Tripathy;B. K. Tripathy;Pradip K. Das	2008	JCIT		fuzzy logic;neuro-fuzzy;machine learning;artificial intelligence;robot control;mobile robot;defuzzification;mobile robot navigation;computer science;subsumption architecture;fuzzy control system	Robotics	59.36043207612939	-27.932645435835	19345
4ae7cd3d183a5d661940687cfbada0729ad349fb	a new speech enhancement method for adverse noise environment	metodo adaptativo;amelioration parole;beam forming;environnement hostile;energie minimale;minimum output energy;metodo energetico;energy method;microfono;methode adaptative;intelligence artificielle;independent component analysis;speech enhancement;time delay;senal vocal;medio ambiente hostil;signal vocal;formation voie;microphone array;methode energetique;adaptive method;retard;analyse composante independante;artificial intelligence;rapport signal bruit;temps retard;relacion senal ruido;inteligencia artificial;delay time;energia minima;hostile environment;analisis componente independiente;signal to noise ratio;vocal signal;retraso;tiempo retardo;formacion haz;microphone;minimum energy	A new speech enhancement method combined independent component analysis (ICA) with delay-sum beamforming is presented in this paper. The noise signals are separated from the speech signal by using ICA module whose inputs are the microphone array signals after time delay compensation. Then the output of the delay-sum beamforming and the separated noise signals are executed adaptive noise canceling according to the criterion of minimum output energy (MOE). Through this method, relatively 'pure' speech signal can be obtained in directional noise field or uncorrelated noise field. Some simulation results in the presence of different signal-to-noise ratio (SNR) are shown to demonstrate the validity of the proposed method especially in adverse noise environment.	speech enhancement	Xiaohong Ma;Yu Wang;Wenlong Liu;Fuliang Yin	2005		10.1007/11427445_96	gradient noise;gaussian noise;independent component analysis;effective input noise temperature;noise;speech recognition;colors of noise;value noise;telecommunications;noise temperature;computer science;noise measurement;artificial intelligence;machine learning;noise;noise figure;noise floor;beamforming;signal-to-noise ratio;noise;salt-and-pepper noise;noise gate	ML	81.2984547639138	-31.585086978970697	19356
86df78cdcd44d64028bddf05fad88dd443e545f0	robust control of cpg-based 3d neuromusculoskeletal walking model	robust control;walking model;cpg	This paper proposes a method for enhancing the robustness of the central pattern generator (CPG)-based three-dimensional (3D) neuromusculoskeletal walking controller. The CPG has been successfully applied to walking controllers and controllers for walking robots. However, the robustness of walking motion with the CPG-based controller is not sufficient, especially when subjected to external forces or environmental variations. To achieve a realistic and stable walking motion of the controller, we propose the use of an attracting controller in parallel with the CPG-based controller. The robustness of the proposed controller is confirmed through simulation results.	articular system;central pattern generator;controllers;handling (psychology);humans;information processing;large;limit cycle;living systems;memory disorders;movement;nonlinear system;projections and predictions;published comment;rem sleep behavior disorder;robot (device);robust control;robustness (computer science);simulation;skeletal system;walking speed;exoskeleton;width	Youngwoo Kim;Yusuke Tagawa;Goro Obinata;Kazunori Hase	2011	Biological Cybernetics	10.1007/s00422-011-0464-4	robust control;control engineering;simulation;engineering;control theory;mathematics;cpg site	Robotics	68.39163237248151	-26.622215191246386	19366
da204b3fd8546f9d883c39947843eec90d02b532	signal recognition and adapted filtering by non-commutative tomography	time resolved information;positive bilinear transforms;time resolved information signal recognition adapted filtering noncommutative tomography radon transform noncommuting operators positive bilinear transforms rigorous probabilistic interpretation time frequency operator pair;radon transform;rigorous probabilistic interpretation;noncommutative tomography;signal recognition;noncommuting operators;signal processing adaptive filters probability;adapted filtering;time frequency operator pair	Tomograms, a generalization of the Radon transform to arbitrary pairs of non-commuting operators, are positive bilinear transforms with a rigorous probabilistic interpretation which provide a full characterization of the signal and are robust in the presence of noise. Tomograms based on the time-frequency operator pair, were used in the past for component separation and denoising. Here we show how, by the construction of an operator pair adapted to the signal, meaningful information with good time resolution is extracted even in very noisy situations.	bilinear filtering;bilinear transform;noise reduction;tomography	Carlos Aguirre;Rui Vilela Mendes	2014	IET Signal Processing	10.1049/iet-spr.2012.0227	combinatorics;mathematical analysis;discrete mathematics;radon transform;mathematics	Theory	80.38477438343037	-36.969801711094036	19408
5773f67afb8edd2cae367b9acfabcb9f9ae42503	visual terrain identification and surface inclination estimation for improving human locomotion with a lower-limb prosthetic		Lower-limb robotic prosthetics can benefit from context awareness to provide comfort and safety to the amputee. In this work, we developed a terrain identification and surface inclination estimation system for a prosthetic leg using visual and inertial sensors. We built a dataset from which images with high sharpness are selected using the IMU signal. The images are used for terrain identification and inclination is also computed simultaneously. With such information, the control of a robotized prosthetic leg can be adapted to changes in its surrounding.	amputees;blurred vision;computation;context awareness;gyroscope;robot;silo (dataset);streaming media;accelerometers;sensor (device)	Jean P. Diaz;Rafael Lopez da Silva;Boxuan Zhong;He Helen Huang;Edgar J. Lobaton	2018	2018 40th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)	10.1109/EMBC.2018.8512614	terrain;computer vision;inertial measurement unit;accelerometer;artificial intelligence;computer science;context awareness;gyroscope	Robotics	58.55912456936543	-38.1072051773612	19416
30aa8235e4bb5606129a6d8888bf3d6b809a72a3	appropriate windowing for group delay analysis and roots of z-transform of speech signals		This study discusses the difficulties of phase spectrum analysis of speech signals and shows that appropriate windowing is very crucial for obtaining reliable phase spectra. The main difficulties of phase based analysis stem from the domination of spiky effects of roots (zeros) of the signal z-transform close to the unit circle. We show how this problem is linked to windowing by discussing zero-patterns for speech signals. Once windowing is performed properly, group delay functions are much less noisy and reveal clearly formant information.	dominating set;group delay and phase delay;spectral density	Baris Bozkurt;Boris Doval;Christophe d'Alessandro;Thierry Dutoit	2004	2004 12th European Signal Processing Conference		speech recognition;telecommunications;speech processing;mathematics;communication	EDA	80.90892813307575	-34.07101971170534	19447
3cfd0394a9b16d47f4f5d887547b88c1064644ae	an mri-compatible force sensor for measuring differential isometric precision grip force		Investigating neural correlates of fine motor control in a magnetically sensitive environment requires special considerations in sensor design. Our application requires measurement of forefinger and thumb forces during precision grip in a relatively low (< 20 N) force range. This work describes the design, characterization and performance evaluation of an MR-compatible precision grip sensor that independently measures forefinger and thumb forces. We selective laser sintered Nylon 12 into a flexure, measuring deformation using optic fibers which matches our finite element model simulation. We found that the device was capable of measuring forces within the desired range, with some hysteresis at higher frequencies as expected. We conclude that the device performs well compared to specifications.	consciousness;equilibrium;finite element method;flexure;hysteresis;index finger;influenza;isometric projection;mathematical optimization;multidisciplinary design optimization;nylons;optics;performance evaluation;sensor;simulation;specification;structural integrity and failure;tissue fiber	Chungmin Han;Ethan Oblak;Larry Abraham;Paul Ferrari;Mark McManis;David M. Schnyer;James S. Sulzer	2017	2017 39th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)	10.1109/EMBC.2017.8036943	deformation (mechanics);motor control;computer science;compatibility (mechanics);isometric exercise;hysteresis;control engineering	Robotics	75.36139038611896	-26.08142296468493	19520
83a153d841c6d149e59d79e31a3bc40cd73c16d3	a mca motion-planner for mobile robots with generic shapes and kinematics on variable terrains	settore ing inf 04 automatica;robot movil;estacion trabajo;settore inf 01 informatica;euclidean theory;hipersuperficie;trajectoire optimale;mobile robot;station travail;cinematica;kinematics;workstation;prevencion esquiva colision;robot mobile;optimal trajectory;automate cellulaire;prevention esquive collision;cinematique;trayectoria optima;theorie euclidienne;manufacturing industry;collision avoidance;cellular automata;cellular automaton;moving robot;hypersurface;teoria euclidiana;automata celular	In the present work, we describe a fast Motion-Planner for Mobile Robots. Considering robots moving with smoothed trajectories on variable terrains, we have developed an algorithm based on an anisotropic propagation of attracting potentials on a non-Euclidean manifold. The optimal collision-free trajectories are found following the minimum valley of a potential hypersurface embedded in a 4D space. The planner is very flexible: it can be use on a wide class of vehicles with different kinematics and with generic shapes. Because of the latest property, it is also applicable to plan the movements of generic objects (e.g. in assembly workstations in manufacturing industry) as in Piano Mover's problem. Thanks to the underlying Multilayered Cellular Automata (MCA) architecture, it is a distributed approach. This planner turn out to be very fast, allowing to react to the dynamics of the world, evolving toward new solutions every time the environment changes without to be re-initialized.	robot	Fabio M. Marchese	2004		10.1007/978-3-540-30479-1_28	cellular automaton;mobile robot;hypersurface;kinematics;simulation;workstation;computer science;artificial intelligence;distributed computing;manufacturing;algorithm	Robotics	60.03056544062258	-25.562958837706535	19522
0f6ebb0adba8e743420874378cbff330768fc827	robust estimation of a maneuvering target from multiple unmanned air vehicles' measurements	uav;estimation theory;sensor drifting;robust estimator;optimal estimation;kalman filters;h infinity filter;kalman filter;mobile robots;remotely operated vehicles;nonzero mean noise robust estimation maneuvering target multiple unmanned air vehicles measurements uav position measurement sensors sensor drifting zero mean noise assumption kalman filter optimal estimation h infinity filter;robustness unmanned aerial vehicles acceleration target tracking position measurement noise measurement h infinity control filters kinematics phase measurement;robust estimation;acceleration;cooperative;tracking kalman filter h infinity filter estimation cooperative;aerospace control;estimation;position control;nonzero mean noise;remotely operated vehicles aerospace control estimation theory h control kalman filters mobile robots position control;h control;target tracking;h infinity control;unmanned aerial vehicles;position measurement sensors;tracking;maneuvering target;zero mean noise assumption;noise;multiple unmanned air vehicles measurements	When multiple UAVs collaborate to track a maneuvering target, their position measurement sensors are sometimes corrupted by noise biases (e.g. sensor drifting). In this case, the zero-mean noise assumption of the Kalman filter is therefore violated and the desired optimal estimate will not be guaranteed. In this paper, an H-infinity filter is utilized to estimate the position of the maneuvering target to compensate for non-zero-mean noise. Furthermore, the constrained H-infinity filter is shown to be superior to the Kalman filter.	kalman filter;sensor;unmanned aerial vehicle	Randal Allen;Kuo-Chi Lin;Chengying Xu	2010	2010 International Symposium on Collaborative Technologies and Systems	10.1109/CTS.2010.5478465	kalman filter;simulation;computer science;moving horizon estimation;statistics	Robotics	55.30090287791364	-34.738421983111934	19592
d00ff1c7053250a31be5d92313f1be82d37ba651	natural representation of shapes with singularities	n rep data scheme;physical and natural surfaces;order of singularities;shape representation;manifold theory;rapid prototyping;shape singularities;natural shape representation	This paper reports on the theoretical fundamentals of a novel modeling approach that follows the singularity theory rather than the continuity theory. The singularity oriented modeling is very useful in certain applications, e.g. in form-giving and styling, rapid prototyping and shape generation based on gestural devices. The authors refer to this novel description technique as natural shape representation (N-rep). The key modeling entities are shape singularities of various order, structures formed by their arrangements, and natural surfaces. A shape singularity is an observable discontinuity of the boundary of an object that is featured by specific tangency and curvature characteristics. Besides the formal definition of singularities, the paper deals with their structural properties. A natural surface has been defined as a compound geometric entity that, as a domain of a boundary, obeys some specific continuity and finiteness conditions. The N-rep data scheme extends the conventional B-rep scheme with higher level constructs. The paper describes an application of the theory for shape generation by gestural device.	entity;observable;rapid prototyping;reflections of signals on conducting lines;scott continuity;the singularity	Imre Horváth;Joris S. M. Vergeest	1997	International Journal of Shape Modeling	10.1142/S0218654397000100	topology;pure mathematics;shape analysis;mathematics;geometry	Robotics	64.81946786337944	-42.18707236176401	19609
f8a62857de073d3868f5570fd121c23d813cd4ec	ground control testbed for space station freedom robot manipulators	automatic control;manipulators;ground to orbit time delays;distributed processing manipulators aerospace control virtual reality telerobotics real time systems;time delays;distributed processing;virtual reality;testing;camera control;robot verification display;orbital robotics;artificial camera views;time delay;robot manipulator;time delays space station freedom robot manipulators nasa johnson space center baseline ground control testbed ground to orbit time delays predictive display virtual realtime control remote robot graphical kinematic manipulator hand controllers user defined delay artificial camera views delayed camera control interface robot verification display distributed processing environment;aerospace control;user defined delay;testing space stations orbital robotics manipulators space technology robotics and automation displays automatic control robot vision systems cameras;remote robot;displays;delayed camera control interface;space stations;distributed processing environment;telerobotics;space technology;graphical kinematic manipulator;virtual realtime control;robot manipulators;robot vision systems;hand controllers;predictive display;robotics and automation;baseline ground control testbed;cameras;johnson space center;space station freedom;real time systems;nasa johnson space center	The Robotic Systems Technology Branch at the NASA/Johnson Space Center has completed a baseline ground control testbed for use in developing and evaluating technology for Space Station Freedom (SSF) Robotic Tasks. The focus of the first phase of this work has been addressing the effects of significant ground to orbit time delays on operations. This testbed uses a predictive display to enable virtual real-time control of a remote robot. The operator commands a graphical kinematic manipulator through hand controllers or automated sequences which in turn drive the actual manipulator after a user defined delay. The predictive display provides artificial camera views that enable the operator to measure clearances not available in actual camera views. A delayed camera control interface, and a robot verification display are also available. All testbed components are connected in a distributed processing environment. This paper describes the ground control testbed architecture and technology utilized to address the time delays.	baseline (configuration management);distributed computing;graphical user interface;real-time transcription;robot;shortest seek first;testbed	R. Scott Askew;Myron A. Diftler	1993		10.1109/VRAIS.1993.380796	telerobotics;computer vision;simulation;computer science;artificial intelligence;automatic control;virtual reality;software testing;space technology	Robotics	62.67036141591961	-29.375167754564675	19624
8fed4b7cd10e8f0ae4f4aee34121a54ed9066c6b	cooperative control of visual displays for telemanipulation	automatic control;cooperative control;task performance;visual displays;human operator s task level commands;human operator s task level commands visual displays telemanipulation cooperative control telerobot on the screen visual enhancements reference lines five degree of freedom robot frame grabber;manipulators;remote control;robot hand;on the screen visual enhancements;display devices;degree of freedom;frame grabber;teleoperators;two dimensional displays;space tools;autonomy;robotics;human robot interaction;image enhancement;robot control;position control;machine vision;five degree of freedom robot;robots;telerobot;telecontrol position control robots;telecontrol;telerobotics;algorithms;propulsion;reference lines;space technology;telerobotics space technology automatic control communication system control two dimensional displays cameras calibration propulsion human robot interaction machine vision;communication system control;systems integration;telemanipulation;calibration;cameras	Two cooperative control schemes for telerobot visual displays are addressed. In the first scheme, on-the-screen visual enhancements such as reference lines indicating the vertical height of the robot hand, a stick figure model of the robot hand, and its projection on the horizontal grid plane are constructed by the interactive cooperation between the human operator and the telerobotic system, and then superimposed on the video screen. Experimental results with a five-degree-of-freedom robot and a frame grabber indicate that superimposition of visual enhancements on the video screen greatly improves telemanipulation task performance. In the second scheme, the position and orientation of an object on video screens are determined interactively; these then assist the telerobotic system in executing the human operator's task-level commands autonomously. >	consensus dynamics;remote manipulator	Won S. Kim;Lawrence W. Stark	1989		10.1109/ROBOT.1989.100164	telerobotics;control engineering;computer vision;simulation;machine vision;computer science;engineering;artificial intelligence;automatic control;robotics	HCI	61.75879438379542	-30.860552073559727	19742
2a643cc87ca155e4b9ab8e101739859328c21ebb	accelerating urban fast response lagrangian dispersion simulations using inexpensive graphics processor parallelism	model system;wind tunnel;gpu;real time simulation;video game;computer graphic;visualization;graphics hardware;graphics processors;urban dispersion modeling;parallel computer;graphic processing unit;urban area;virtual environment;analytic solution;parallel simulation	Owing to the potential consequences associated with accidental or deliberate releases of chemical or biological agents in urban areas, fast response urban dispersion models must rapidly provide solutions that can be easily analyzed by researchers and emergency responders. In this paper, we describe a novel application of an existing Lagrangian dispersion modeling system to achieve real-time simulation and visualization of an urban plume that a user can interact with in a virtual environment (VE) through the utilization of commodity graphics hardware, utilizing the highly parallel computational capabilities available on graphics processing units (GPU). GPUs have quickly developed from video game technology to open up new avenues for enhancing simulation performance and visualization of engineering and science applications. For computer graphics applications, GPUs provide highly parallel and inexpensive data paths for processing geometry and pixels, but for simulation these parallel paths are exploited for solving general problems. In this paper, a newly developed dispersion model (GPU Plume) is tested against an analytical solution, a CPU implementation of the Lagrangian dispersion model and wind tunnel data for dispersion around a single building. GPU Plume is shown to provide results that are similar in accuracy to the CPU model, but with computation times that are up to two orders magnitude smaller. In addition, challenges associated with the implementation of Lagrangian dispersion models onto the GPU architecture are discussed in this paper.	graphics processing unit;parallel computing;simulation	Balwinder Singh;Eric R. Pardyjak;Andrew Norgren;Peter Willemsen	2011	Environmental Modelling and Software	10.1016/j.envsoft.2010.12.011	closed-form expression;simulation;visualization;computer science;virtual machine;theoretical computer science;wind tunnel;graphics hardware;computer graphics (images)	HPC	72.44542001219155	-50.749307729751536	19827
01ead18052aece8c01e05d9da6fa97ea50fe34de	abstracted biological principles applied with reduced actuation improve mobility of legged vehicles	gait analysis legged locomotion;legged locomotion;vehicles leg robot sensing systems mobile robots legged locomotion propulsion maintenance engineering biological systems circuits muscles;gait analysis;bidirectional servo driven body flexion joint legged vehicles abstracted biological locomotion principles vehicle mobility mass ratio whegs ii abstracted cockroach locomotion principles propulsion motor tripod gait	ed Biological Principles Applied with Reduced Actuation Improve Mobility of Legged Vehicles Thomas J. Allen, Roger D. Quinn1, Richard J. Bachmann, Roy E. Ritzmann Case Western Reserve University, Cleveland, Ohio, U.S.A. http://biorobots.cwru.edu, 1rdq@po.cwru.edu	biorobotics	Thomas J. Allen;Roger D. Quinn;Richard J. Bachmann;Roy E. Ritzmann	2003		10.1109/IROS.2003.1248835	control engineering;simulation;gait analysis;engineering;control theory	Robotics	66.54329470892763	-27.16195295211266	19835
02ec10ec49d3445d4aaffbdd91c4798810b1532d	multiple faults detection for rotating machinery based on bicomponent sparse low-rank matrix separation approach		Multifault detection of rotating machinery at the incipient fault stage presents a challenging issue due to its interaction feature, complexity, and coupling characteristics. Aiming at the concern of identifying the multiple faults pattern of rotating machinery, a novel multiple faults detection approach based on Bi-component sparse low-rank matrix separation is proposed in this paper. The core idea of the proposed method is that the measured vibration signal typically shows as the sum of transient component and oscillatory component, meanwhile, the multi-fault identification problem with regularization terms can be transformed into a sparse optimization formulation that could be solved by the alternating direction method of multipliers algorithm. The proposed approach is applied by simulated synthetic signal, experimental data including rolling bearing and gearbox with weak multiple faults, and its effectiveness and superiority are verified by comparing to some state-of-the-art methods such as L1-norm fused lasso optimization, maximum correlated kurtosis deconvolution, and ensemble empirical mode decomposition.	algorithm;augmented lagrangian method;complexity;deconvolution;hilbert–huang transform;lasso;mathematical optimization;matrix regularization;sparse approximation;sparse matrix;synthetic intelligence;taxicab geometry	Qing Li;Steven Y. Liang	2018	IEEE Access	10.1109/ACCESS.2018.2823719	hilbert–huang transform;lasso (statistics);experimental data;sparse matrix;computer science;deconvolution;mathematical optimization;feature extraction;distributed computing;fault detection and isolation;low-rank approximation	AI	79.05125501062888	-37.67111058925821	19932
1d29eede5c2f5ae196dad63e7931a1863785bd2b	extraction of 3d freeform surfaces as visual landmarks for real-time tracking	analysis by synthesis;decision models;omnidirectional vision;real time tracking;independent set;reference model;robust statistics;measurement uncertainty;visual landmarks;error propagation;surface model;field of view;depth estimation;depth map;triangle mesh;structure from motion	This work presents a system for the generation of a free-form surface model from video sequences. Although any single centered camera can be applied in the proposed system the approach is demonstrated using fish-eye lenses because of their good properties for tracking. The system is designed to function automatically and to be flexible with respect to size and shape of the reconstructed scene. To minimize geometric assumptions a statistic fusion of dense depth maps is utilized. Special attention is payed to the necessary rectification of the spherical images and the resulting iso-disparity surfaces, which can be exploited in the fusion approach. Before dense depth estimation can be performed the cameras’ pose parameters are extracted by means of a structure-from-motion (SfM) scheme. In this respect automation of the system is achieved by thorough decision model based on robust statistics and error propagation of projective measurement uncertainties. This leads to a scene-independent set of only a few parameters. All system components are formulated in a general way, making it possible to cope with any single centered projection model, in particular with spherical cameras. In using wide field-of-view cameras the presented system is able to reliably retrieve poses and consistently reconstruct large scenes. A textured triangle mesh constructed on basis of the scene’s reconstructed depth, makes the system’s results suitable to function as reference models in a GPU driven analysis-by-synthesis framework for real-time tracking.	algorithm;binocular disparity;bundle adjustment;depth map;freeform surface modelling;graphics processing unit;ground truth;image rectification;independent set (graph theory);map (higher-order function);propagation of uncertainty;real-time clock;software propagation;sparse matrix;speech coding;structure from motion;synthetic data;triangle mesh	Bogumil Bartczak;Kevin Köser;Felix Woelk;Reinhard Koch	2007	Journal of Real-Time Image Processing	10.1007/s11554-007-0042-0	robust statistics;computer vision;decision model;structure from motion;simulation;reference model;independent set;field of view;computer science;propagation of uncertainty;triangle mesh;speech coding;statistics;measurement uncertainty;depth map;computer graphics (images)	Vision	54.249585971651385	-47.589802418176276	20059
49bff3868a4b9eb5230cad20a634c2e9daa16f67	pose interpolation for laser-based visual odometry		In this paper, we present two methods for obtaining visual odometry VO estimates using a scanning laser rangefinder. Although common VO implementations utilize stereo camera imagery, passive cameras are dependent on ambient light. In contrast, actively illuminated sensors such as laser rangefinders work in a variety of lighting conditions, including full darkness. We leverage previous successes by applying sparse appearance-based methods to laser intensity images, and we address the issue of motion distortion by considering the timestamps of the interest points detected in each image. To account for the unique timestamps, we introduce two estimator formulations. In the first method, we extend the conventional discrete-time batch estimation formulation by introducing a novel frame-to-frame linear interpolation scheme, and in the second method, we consider the estimation problem by starting with a continuous-time process model. This is facilitated by Gaussian process Gauss-Newton GPGN, an algorithm for nonparametric, continuous-time, nonlinear, batch state estimation. Both laser-based VO methods are compared and validated using datasets obtained by two experimental configurations. These datasets consist of 11 km of field data gathered by a high-frame-rate scanning lidar and a 365 m traverse using a sweeping planar laser rangefinder. Statistical analysis shows a 5.3% average translation error as a percentage of distance traveled for linear interpolation and 4.4% for GPGN in the high-frame-rate scenario.	interpolation;visual odometry	Chi Hay Tong;Sean Anderson;Hang Dong;Tim D. Barfoot	2014	J. Field Robotics	10.1002/rob.21537	computer vision;simulation;optics	Robotics	54.23381046093999	-39.235144278040714	20071
266e5fa0770aa20ea2ca5febd771aa6845492ba2	a new calibration method of line scan camera for high-precision two-dimensional measurement		In this paper, a calibration method for line scan cameras with image distortion is proposed to perform high-precision planar measurement. The intrinsic parameter model is presented according to the imaging work principle of the line scan camera. Moreover, an improved camera model is proposed via integrating the perspective transformation with the extrinsic parameter model in the consideration of image distortion resulting from the non-parallelism of motion direction and object plane. On this basis, the parameters in above model are calibrated based on nonlinear damping least square method with a planar chessboard pattern. A set of measurement experiments are conducted and the results verify the effectiveness of proposed approaches.		Jiabin Zhang;Zhengtao Zhang;Fei Shen;Feng Zhang;Hu Su	2018	2018 IEEE 14th International Conference on Automation Science and Engineering (CASE)	10.1109/COASE.2018.8560438		Robotics	56.01979156204613	-49.44068616925973	20136
501c9fa318e231552d1d8b46dd28fa7024279463	walking mechanism for a lion-type robot	legged locomotion actuators shafts trajectory animals joints;biomimetic motion walking mechanism lion type robot biomimetic quadruped robot actuator electric motor theo jansen mechanism modified gallop gait pitch angle;velocity control actuators legged locomotion motion control	This paper describes a new type of locomotion for a quadruped robot. Recently, many biomimetic quadruped robots have been developed. Most of them use many actuators for running, which causes them to become big in size. We have developed a medium-sized quadruped robot by using only one electric motor as an actuator for walking and running. We also adapt to the robot the mechanism which is similar to Theo Jansen mechanism to make its gait biomimetic. In order to realize our mechanism, we propose “Modified Gallop Gait” that is derived from bounce gait and gallop gait. The experimental results show that the robot runs as the modified gallop gait at the velocity of 0.89 m/s, while its pitch angle oscillates periodically to realize biomimetic motion and its stable running.	biomimetics;experiment;gait analysis;robot;universal conductance fluctuations;velocity (software development)	Kyuhei Honda;Yugo Kajiwara;Shu Karube;Kenichi Takahashi	2014	2014 IEEE International Conference on Systems, Man, and Cybernetics (SMC)	10.1109/SMC.2014.6974454	simulation;control theory	Robotics	67.04663711590429	-24.373369998792864	20236
fd94e80dd0f8a05ccf0c7912da2a5b90ed75d210	tool for 3d gazebo map construction from arbitrary images and laser scans		Algorithms for mobile robots, such as navigation, mapping, and SLAM, require proper modelling of environment. Our paper presents an automatic tool that allows creating a realistic 3D-landscape in Gazebo simulation, which is based on the real sensor-based experimental results. The tool provides an occupancy grid map automatic filtering and import to Gazebo framework as a heightmap and enables to configure the settings for created simulation environment. In addition, the tool is capable to create a 3D Gazebo map from any arbitrary image.	compiler;heightmap;mobile robot;open-source software;robot operating system;simulation;simultaneous localization and mapping;vii	Roman Lavrenov;Aufar Zakiev	2017	2017 10th International Conference on Developments in eSystems Engineering (DeSE)	10.1109/DeSE.2017.33	occupancy grid mapping;filter (signal processing);computer vision;laser;mobile robot;computer science;heightmap;artificial intelligence	Robotics	55.4933881490196	-42.2161345233926	20250
a5da1e8de605360dd15f367e86a92a089f6e2268	real-time visual odometry for ground moving robots using gpus	real time visualization	This paper introduces a novel visual odometry framework for ground moving robots. Recent work showed that assuming non-holonomic motion can simplify the ego motion estimation task to one yaw and one scale parameter. Furthermore, a very efficient way of computing image frame to frame correspondences for those robots was presented by skipping rotational invariance and optimizing keypoint extraction and matching for massive parallelism on a GPU. Here, we combine both contributions to a closed framework. Long term correpondences are preserved, classified and stablized by motion prediction, building up and keeping a trusted map of depth-registered keypoints. We also allow other ground moving objects. From this map, the ego motion is infered, extended by constrained rotational perturbations in pitch and roll. A persistent focus is on keeping algorithms suitable for parallelization and thus achieving up to one hundred frames per second. Experiments are carried out to compare against ground-truth given by DGPS and IMU data.	algorithm;differential gps;experiment;graphics processing unit;ground truth;motion estimation;parallel computing;pitch (music);real-time transcription;robot;visual odometry;yaws	Michael Schweitzer;Alois Unterholzner;Hans-Joachim Wünsche	2010			computer vision;simulation;computer science;visual odometry;computer graphics (images)	Robotics	54.0611451502105	-39.37248631321148	20274
e9dcd5c0566d522a1b80f9ebbbd11e735467c810	visualization of simulated airflow in a clean room	stream line;proposed technique;simulated air flow;physics computing;probing;flow simulation;irregular volumes;clean rooms;efficient traverse;measurement techniques;efficient cell traverse;data visualisation;clean room;actual clean room;digital simulation;irregular volume;stream line display;tetrahedral cells;measurement technique;simulated airflow;pressure measurement;air flow;finite difference methods;data structures;algorithms;application software;displays;data visualization;computer aided manufacturing;computational fluid dynamics;computational geometry	Techniques for visualizing a simulated air flow in a clean room are developed by using an efficient cell traverse of tetrahedral cells generated from irregular volumes. The proposed techniques are probing and stream line display, which are related to the measurement techniques used in actual clean rooms. The efficient traverse makes it possible to move freely around a given irregular volume and to spawn off stream lines. A successful application of these techniques to a problem in a clean room is also described.	cleanroom;spawn (computing);traverse	K. Koyamada	1992			simulation;cleanroom;computer science;geometry;data visualization;statistics;computer graphics (images)	Visualization	71.98053941471854	-49.740094977208365	20284
2910f537f571979169a3f8a67bc35f42301117b2	exploring distance-aware weighting strategies for accurate reconstruction of voxel-based 3d synthetic models	truncated signed distance function tsdf;voxel models;weighting strategy;low cost depth sensor;3d reconstruction	In this paper, we propose and evaluate various distanceaware weighting strategies to improve reconstruction accuracy of a voxelbased model according to the Truncated Signed Distance Function (TSDF), from the data obtained by low-cost depth sensors. We look at two strategy directions: (a) weight definition strategies prioritizing importance of the sensed data depending on the data accuracy, and (b) model updating strategies defining the level of influence of the new data on the existing 3D model. In particular, we introduce Distance-Aware (DA) and Distance-Aware Slow-Saturation (DASS) updating methods to intelligently integrate the depth data into the synthetic 3D model based on the distance-sensitivity metric of a low-cost depth sensor. By quantitative and qualitative comparison of the resulting synthetic 3D models to the corresponding ground-truth models, we identify the most promising strategies, which lead to an accuracy improvement involving a reduction of the model error by 10 − 35%.	3d modeling;emoticon;ground truth;range imaging;sensor;synthetic data;synthetic intelligence;voxel	Hani Javan Hemmat;Egor Bondarev;Peter H. N. de With	2014		10.1007/978-3-319-04114-8_35	3d reconstruction;computer vision;computer science;machine learning;data mining;statistics	Vision	54.29090705193223	-46.265869006811556	20287
5570859525552ceff7591381243a071203693799	design and construction of tools with reflecting-disks fiducials for optical stereo trackers: an afforable technique for navigation tools development	cameras calibration optical reflection navigation surgery stimulated emission accuracy;rapid prototyping industrial design engineering navigation optical tracking;reflecting disk fiducials reflection loss object digitalization metrology calibration accuracy sticker fiducials reflection angle calibration errors circular reflective stickers 3d printer marker fiducials navigation optical systems rapid prototyping tool construction rapid prototyping tool design navigation tool development optical stereo trackers;optical trackers reflective stickers fiducials pivoting calibration stereo camera markers	In this article, a rapid prototyping tool design and construction for the development of tools for navigation optical systems is presented. Theses markers differentiate from commonly used ones because they use cheap reflective stickers as markers fiducials. We built markers with a 3D printer and tested two different sized circular reflective stickers with calibration errors bellow to 0.25 mm. The reflection angle of the sticker fiducials are their mayor problem. Nevertheless, the obtained calibration accuracy (quite similar to state of the art fiducials) could be a fast and cheap option to be used with non-risky applications, such as metrology or object digitalization in which the reflection loss due to critical angles is not an issue.	3d printing;printer (computing);rapid prototyping	Jorge Israel Perez-Arreguin;Saúl Tovar-Arriaga;Jesús Carlos Pedraza Ortega;José Emilio Vargas Soto;Jorge Álvares-Servín;S. Vega-Hernández	2014	2014 11th International Conference on Electrical Engineering, Computing Science and Automatic Control (CCE)	10.1109/ICEEE.2014.6978258	computer vision;engineering;optics;computer graphics (images)	Robotics	60.838103127237225	-36.49465022529657	20291
d00526a780ad353a885cfad32897f4144dcf097e	automatic parallel parking and returning to traffic manoeuvres	motion control;automobiles;motion control wheels automatic control velocity control servomechanisms traffic control axles equations automatic testing measurement units;range sensors automatic parallel parking traffic manoeuvring position control autonomous electric car motion control localization path planning range measurements;automatic parallelization	"""This paper describes the control approach developed to perform parallel parking and returning to traffic manoeuvres for a car capable of autonomous motion. The key idea is to carry out a motion control procedure involving a """"localization-planning-execution"""" cycle until a specified location of the car relative to its environment is reached. Range measurements are used to model environmental objects around the car. The automatic manoeuvres developed are demonstrated on an experimental electric autonomous car in a usual traffic environment."""		Igor E. Paromtchik;Christian Laugier	1997		10.1109/IROS.1997.656803	control engineering;motion control;simulation;computer science;engineering;automotive engineering;control theory;automatic parallelization	HPC	58.053736174019335	-28.796718003934522	20330
8bdcdb168388e1b8161e0135ae7fe1d2adb6b023	any-com multi-robot path-planning: maximizing collaboration for variable bandwidth		We identify a new class of algorithms for multi-robot proble ms called “Any-Com” and present the first algorithm belonging to that c lass “Any-Com intermediate solution sharing” (or Any-Com ISS) for multi-ro bot path planning. AnyCom algorithms find a suboptimal solution quickly and then re fine that solution subject to communication constraints. This is analogous to the “Any-Time” framework, in which a suboptimal solution is found quickly, and refined a s time permits. The current paper focuses on the task of finding a coordinated set of collision-free paths for all robots in a common area. The computational load of cal cul ting a solution is distributed among all robots, such that the robotic team bec om s a distributed computer. Any-Com ISS is probabilistically/resolution compl ete and a particular robot contributes to the global solution as much as communication reliability permits. Any-Com ISS is “Centralized” in the planning-algorithmic s ense that all robots are viewed as pieces of a composite robot; however, there is no de dicat d leader and all robots have the same priority. Previous centralized mul ti-robot navigation algorithms make assumptions about communication topology and b width that are often invalid in the real world. Any-Com allows for collabor ative problem solving with graceful performance declines as communication deter iorates. Results are validated experimentally with a team of 5 robots.	algorithm;centralized computing;eterna;experiment;motion planning;problem solving;robot;robotic mapping	Michael W. Otte;Nikolaus Correll	2010		10.1007/978-3-642-32723-0_12	real-time computing;simulation;computer science;distributed computing	Robotics	56.47682268659123	-25.016197758865346	20337
7dfe5b291fd38e29aecb3208e65b32ef79f69ac3	an algebraic model for parameterized shape editing	shape editing;symmetry;structural regularity;shape understanding	We present an approach to high-level shape editing that adapts the structure of the shape while maintaining its global characteristics. Our main contribution is a new algebraic model of shape structure that characterizes shapes in terms of linked translational patterns. The space of shapes that conform to this characterization is parameterized by a small set of numerical parameters bounded by a set of linear constraints. This convex space permits a direct exploration of variations of the input shape. We use this representation to develop a robust interactive system that allows shapes to be intuitively manipulated through sparse constraints.	convex set;high- and low-level;interactivity;linear algebra;numerical analysis;sparse matrix	Martin Bokeloh;Michael Wand;Hans-Peter Seidel;Vladlen Koltun	2012	ACM Trans. Graph.	10.1145/2185520.2185574	active shape model;mathematical optimization;combinatorics;shape optimization;shape analysis;mathematics;geometry;symmetry	Graphics	66.52118366432296	-45.5329882744128	20373
c0e58c4e37aa465bde992e297a23f6045e89510d	decorating surfaces with bidirectional texture functions	painting;painting image texture computational geometry solid modelling interactive systems;texture synthesis;bidirectional texture function;computational geometry;interactive surface painting arbitrary surface decoration bidirectional texture function patch based texture synthesis quilting graphcut algorithm graphcut texture painting algorithm real world texture fine scale geometry geometry model;interactive surface painting index terms bidirectional texture function texture synthesis;indexing terms;interactive surface painting;surface texture painting surface cracks geometry paints reflectivity surface fitting solid modeling graphics pipelines;image texture;algorithms computer graphics image enhancement image interpretation computer assisted imaging three dimensional information storage and retrieval paintings surface properties;index terms bidirectional texture function;user interaction;interactive systems;solid modelling	We present a system for decorating arbitrary surfaces with bidirectional texture functions (BTF). Our system generates BTFs in two steps. First, we automatically synthesize a BTF over the target surface from a given BTF sample. Then, we let the user interactively paint BTF patches onto the surface such that the painted patches seamlessly integrate with the background patterns. Our system is based on a patch-based texture synthesis approach known as quilting. We present a graphcut algorithm for BTF synthesis on surfaces and the algorithm works well for a wide variety of BTF samples, including those which present problems for existing algorithms. We also describe a graphcut texture painting algorithm for creating new surface imperfections (e.g., dirt, cracks, scratches) from existing imperfections found in input BTF samples. Using these algorithms, we can decorate surfaces with real-world textures that have spatially-variant reflectance, fine-scale geometry details, and surfaces imperfections. A particularly attractive feature of BTF painting is that it allows us to capture imperfections of real materials and paint them onto geometry models. We demonstrate the effectiveness of our system with examples.	algorithm;bidirectional texture function;graphics;interactivity;patch (computing);physical object;texture synthesis;texture:type:pt:calculus:nom	Kun Zhou;Peng Du;Lifeng Wang;Yasuyuki Matsushita;Jiaoying Shi;Baining Guo;Harry Shum	2005	IEEE Transactions on Visualization and Computer Graphics	10.1109/TVCG.2005.78	bidirectional texture function;image texture;computer vision;painting;computational geometry;computer science;texture synthesis;computer graphics (images)	Graphics	64.91102097388483	-48.24188249674716	20413
50d0bea94cc9ee8abc79c2015bc6cdbc1d0cbb42	a fuzzy ransac algorithm based on reinforcement learning concept	noise computational modeling computer vision learning artificial intelligence data models estimation algorithm design and analysis;fuzzy set theory;computer vision;random processes computer vision fuzzy set theory learning artificial intelligence;random sample consensus algorithm fuzzy ransac algorithm reinforcement learning concept computer vision approach sensing units robust modeling technique noise ratio numerical experiments calculation time model optimality modeling performance;random processes;learning artificial intelligence;computer vision ransac fuzzy set reinforcement learning robust estimation	In the computer vision approach, there are many problems of modeling to prevent affections of noises by sensing units such as cameras and projectors. In order to improve the performance of the modeling in the computer vision, it is necessary to develop a robust modeling technique for various functions. The RANSAC algorithm has been widely applied for such issues. However, the performance is deteriorated when the ratio of noises increases. In this study, a new fuzzy RANSAC algorithm based on the reinforcement learning concept is proposed. The essential performance of the algorithm is evaluated through numerical experiments. From the results, the method is found to be promising to improve calculation time, optimality of the model, and robustness in terms of modeling performance.	algorithm;computer vision;experiment;movie projector;numerical analysis;random sample consensus;reinforcement learning;robustness (computer science);sampling (signal processing)	Toshihiko Watanabe	2013	2013 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE)	10.1109/FUZZ-IEEE.2013.6622582	stochastic process;computer vision;ransac;computer science;artificial intelligence;machine learning;fuzzy set	Robotics	63.57560325880037	-36.50529275038662	20440
e9c32baa5897c193b61ebc21d6904c29044bfc01	automated modelling of real human faces for 3d animation	shape from stereo human face modelling 3d animation textured face mask 3d surface polygon face mask scaling shape adaptation stereo images;human face modelling;stereo images;3d animation;computational geometry;telecommunication computing;indexing terms;surface reconstruction;textured face mask;scaling;facial animation humans face shape telecommunication computing cameras muscles read only memory head surface reconstruction;shape;real time animation;facial animation;face modeling;facial features;face;computational geometry solid modelling computer animation;humans;head;computer animation;shape from stereo;read only memory;cameras;3d surface polygon face mask;solid modelling;muscles;shape adaptation	This paper describes the automated creation of a textured face mask of a natural person suitable for realtime animation. A 3D surface polygon face mask is used. A set of muscles is defined to animate the mask. The mask is adapted to a real person using 3D surface data from a calibrated stereo sensor. Firstly, the facial features of the mask are aligned to the 3D data by scaling the mask. Secondly, a local shape adaptation moves the mask vertices along their surface normals to be coplanar with the measured 3D surface. The adapted mask is textured from one of the stereo images yielding a highly realistic impression. The predefined muscles are used to animate the textured mask. Index terms Face Modeling, Shape from Stereo, 3D Adaptation, Facial Animation	computer animation;image scaling;image sensor;normal (geometry);real-time computing;the mask	Bruno Nagel;Jochen Wingbermühle;Sebastian Weik;Claus-E. Liedtke	1998		10.1109/ICPR.1998.711238	computer vision;simulation;computational geometry;computer science;geometry;computer animation;computer graphics (images)	Vision	57.66412756910667	-48.827515595339186	20517
56caec0294b70ca77efb0e82d176696d4c4be680	a mixed classification-regression framework for 3d pose estimation from 2d images		In Tables 2 and 3, we present the results of our eight models and three baselines compared to current state-of-the-art under the two metric of MedErr and Acc π 6 respectively. As we mentioned in the paper, we run all experiments three times and report the mean and standard deviation (in brackets) across these three trials. We also show figures of images where we obtain the least pose estimation error and the most pose estimation error for every object category using one run of model MG+. As can be seen from Figs. [1-12], we make the most error under three conditions: (i) when the objects are really blurry (very small in pixel size in the original image), (ii) the shape of the object is uncommon (possibly very few examples seen during training) and (iii) the pose of a test image is very different from common poses observed during training. The first condition is best observed in the bad cases for categories aeroplane and car where almost all the images shown are very blurry. The second condition is best observed in categories boat and chair where the bad cases contain uncommon boats and chairs. The third condition is best observed in categories bottle and tvmonitor where the bad images are in very different poses compared to the best images. We also present the performance of our models MG and MG+ across different object categories of the Pascal3D+ dataset during ablation experiments in Tables 4-11. These are detailed tables for the results shown in Tables 3 and 4 of the main paper and an overview of the experiments is shown below.	3d pose estimation;experiment;pixel;standard test image	Siddharth Mahendran;Haider Ali;René Vidal	2018			machine learning;pattern recognition;computer science;3d pose estimation;artificial intelligence;pose;discretization;augmented reality	Vision	55.792421384080185	-47.298281393285954	20583
4b37ae622528a4d1ffdd2fe93f6d3092deecd37e	finding surface correspondences using symmetry axis curves	symmetry detection;finding surface;surface map;similar reflective symmetry axis;symmetry axis curve;symmetry axis curves;curve alignment;useful map;extrapolating correspondence;correspondence extrapolation;global reflective symmetry axis;correspondence map	In this paper, we propose an automatic algorithm for finding a correspondence map between two 3D surfaces. The key insight is that global reflective symmetry axes are stable, recognizable, semantic features of most real-world surfaces. Thus, it is possible to find a useful map between two surfaces by first extracting symmetry axis curves, aligning the extracted curves, and then extrapolating correspondences found on the curves to both surfaces. The main advantages of this approach are efficiency and robustness: the difficult problem of finding a surface map is reduced to three significantly easier problems: symmetry detection, curve alignment, and correspondence extrapolation, each of which has a robust, polynomial-time solution (e.g., optimal alignment of 1D curves is possible with dynamic programming). We investigate of this approach on a wide range of examples, including both intrinsically symmetric surfaces and polygon soups, and find that it is superior to previous methods in cases where two surfaces have different overall shapes but similar reflective symmetry axes, a common case in computer graphics.	algorithm;align (company);apache axis;blackwell (series);computer graphics;control theory;dynamic programming;eurographics;experiment;extrapolation;isometric projection;map;optic axis of a crystal;polygon soup;polynomial;shape analysis (digital geometry);time complexity	Tianqiang Liu;Vladimir G. Kim;Thomas A. Funkhouser	2012	Comput. Graph. Forum	10.1111/j.1467-8659.2012.03166.x	combinatorics;topology;mathematics;geometry	Vision	61.86575526479055	-44.08271324801074	20596
41de5669cf6553b16d8563bb150e8b0e1f3787c6	foldsketch: enriching garments with physically reproducible folds		While folds and pleats add interest to garments and cloth objects, incorporating them into an existing design manually or using existing software requires expertise and time. We present FoldSketch, a new system that supports simple and intuitive fold and pleat design. FoldSketch users specify the fold or pleat configuration they seek using a simple schematic sketching interface; the system then algorithmically generates both the fold-enhanced 3D garment geometry that conforms to user specifications, and the corresponding 2D patterns that reproduce this geometry within a simulation engine. While previous work aspired to compute the desired patterns for a given target 3D garment geometry, our main algorithmic challenge is that we do not have target geometry to start with. Real-life garment folds have complex profile shapes, and their exact geometry and location on a garment are intricately linked to a range of physical factors such as fabric properties and the garment's interaction with the wearer's body; it is therefore virtually impossible to predict the 3D shape of a fold-enhanced garment using purely geometric means. At the same time, using physical simulation to model folds requires appropriate 2D patterns and initial drape, neither of which can be easily provided by the user. We obtain both the 3D fold-enhanced garment and its corresponding patterns and initial drape via an alternating 2D-3D algorithm. We first expand the input patterns by allocating excess material for the expected fold formation; we then use these patterns to produce an estimated fold-enhanced drape geometry that balances designer expectations against physical reproducibility. We use the patterns and the estimated drape as input to a simulation generating an initial reproducible output. We improve the output's alignment with designer expectations by progressively refining the patterns and the estimated drape, converging to a final fully physically reproducible fold-enhanced garment. Our experiments confirm that FoldSketch reliably converges to a desired garment geometry and corresponding patterns and drape, and works well with different physical simulators. We demonstrate the versatility of our approach by showcasing a collection of garments augmented with diverse fold and pleat layouts specified via the FoldSketch interface, and further validate our approach via comparisons to alternative solutions and feedback from potential users.		Minchen Li;Alla Sheffer;Eitan Grinspun;Nicholas Vining	2018	ACM Trans. Graph.	10.1145/3197517.3201310	computer graphics (images);clothing;schematic;fold (geology);computer science;annotation;sketch-based modeling	Graphics	68.00320080759506	-46.86989283922738	20610
9f7b2c65ab130b748e33769064b7ef1115d738c7	glottal inverse filtering using probabilistic weighted linear prediction		Glottal inverse filtering is a noninvasive method for getting the glottal flow estimate from the speech. In this paper, we propose a method for glottal inverse filtering based on probabilistic weighted linear prediction PWLP in which the speech is assumed to be the output of an all-pole filter with glottal flow as an excitation. First, we introduce a probabilistic interpretation of the WLP, and we propose a probabilistic temporal weighting as convolution of a binary vector and a fixed window. We construct the posterior distribution based on the PWLP likelihood and a Gaussian prior on the filter coefficients. The parameters are estimated using the Gibbs sampling. The experiments are performed using the Lijencrants–Fant LF model based synthetic data, a physical model based synthetic data of different vowels and real speech data. Results demonstrate that the proposed method outperforms the best of the existing state-of-the-art methods in terms of the normalized amplitude quotient by 0.035 and 0.12 for the LF model and physical model based synthetic data, respectively. The results based on real speech data show that the glottal flow estimated by the proposed method in the closed phase is flatter and has less formant ripple compared to existing state-of-the-art methods. We also show two key features of the proposed method: first, the proposed method does not need prior detection of glottal closure or opening instants. The temporal weights are learnt in a data-driven manner, which is often found to be high near the closed phase of the glottal cycle, second, the Gaussian prior helps in estimating the filter coefficients when the closed phase duration is small.	assumed;bit array;closure;coefficient;convolution;estimated;excitation;experiment;gibbs sampling;inverse filter;normal statistical distribution;predicate transformer semantics;ripple effect;sampling (signal processing);synthetic data;synthetic intelligence	Achuth Rao Mv;Prasanta Kumar Ghosh	2019	IEEE/ACM Transactions on Audio, Speech, and Language Processing	10.1109/TASLP.2018.2873897	formant;computer science;pattern recognition;ripple;filter (signal processing);artificial intelligence;linear prediction;filter design;gibbs sampling;posterior probability;weighting	AI	80.89643725818722	-35.084762419171284	20689
d519777f4145ee5700898e146f8dac99d8e2bf91	collision detection in densely packed fiber assemblies with application to hair modeling	bounding volume hierarchy;collision detection;complex dynamics;upper bound	In this paper we investigate the application of bounding volume hierarchies in collision detection among densely packed fiber assemblies like hair strands or cable looms. In particular, we glance at collision detection algorithms with sub-quadratic upper bound and their practicability and performance in complex dynamic hair scenes. Unlike common collision detection techniques our approach exploits the topological structure of the underlying filament assembly and allows for fast hierarchy updates in dynamic deformable scenes. Furthermore, we compare hierarchies of the wrapped and the layered type and show the feasibility of fiber based collision detection on full human hair models. We simulate each fiber of an assembly by means of Cosserat rod models. Keywords—collision detection, fiber assemblies, hair modeling, wrapped / layered hierarchies, COSSERAT rods	algorithm;bounding volume hierarchy;collision detection;optical fiber cable;rigs of rods;simulation	Gerrit Alexander Sobottka;Ebadollah Varnik;Andreas Weber	2005			computational physics;combinatorics;collision detection;fiber;bounding volume hierarchy;complex dynamics;upper and lower bounds;materials science	Robotics	70.40251286551272	-47.65029982121315	20691
4e077d9b69f8343edb1980bca25c31c661c6f8ac	party: a numerical calculation method for a dynamically deformable cloth model	animacion por computador;clothing simulation;numerical method;simulation;simulacion;numerical calculation;cloth simulation;metodo numerico;clothing;party environment;vestidura;computer animation;methode numerique;dynamically deformable cloth model;vetement;animation par ordinateur	A physically based environment of Artificial RealiTY for dress simulation (PARTY) which shows fully dressed humans in various environments is described. In PARTY, a dynamically deformable cloth model of a dress plays the central role. This paper proposes a new dynamically deformable cloth model that can handle actual nonlinear kinetic properties of cloth measured by mechanical experiments, and also propose a numerical method appropriate for PARTY. The numerical results of the Drape Test are compared with the shape of real cloth in experiments.	artificial reality;experiment;nonlinear system;numerical method;simulation	Yoshiyuki Sakaguchi;Michihiko Minoh;Katsuo Ikeda	1995	Systems and Computers in Japan	10.1002/scj.4690260808	simulation;numerical analysis;computer science;artificial intelligence;clothing;computer animation;computer graphics (images)	Robotics	71.4227435198323	-48.3704008038256	20744
e7a7cb4fadf68b0b603476703a1ec436cc1700fd	snap-to-fit, a haptic 6 dof alignment tool for virtual assembly	cranio maxillofacial surgery snap to fit haptic 6 dof alignment tool virtual assembly surgery planning skeletal anatomy archaeological artifacts graphical modeling visual feedback occlusion degrees of freedom;human computer interaction;interaktionsteknik;manniska datorinteraktion interaktionsdesign;virtual reality feedback haptic interfaces surgery;virtual reality;interaction technologies;medicinsk bildbehandling;feedback;medical image processing;3d puzzle virtual assembly force feedback haptic rendering fractured object virtual environments;surgery;force haptic interfaces torque assembly surgery couplings planning;haptic interfaces	Virtual assembly of complex objects has application in domains ranging from surgery planning to archaeology. In these domains the objective is to plan the restoration of skeletal anatomy or archaeological artifacts to achieve an optimal reconstruction without causing further damage. While graphical modeling plays a central role in virtual assembly, visual feedback alone is often insufficient since object contact and penetration is difficult to discern due to occlusion. Haptics can improve an assembly task by giving feedback when objects collide, but precise fitting of fractured objects guided by delicate haptic cues similar to those present in the physical world requires haptic display transparency beyond the performance of today's systems. We propose a haptic alignment tool that combines a 6 Degrees of Freedom (DOF) attraction force with traditional 6 DOF contact forces to pull a virtual object towards a local stable fit with a fixed object. The object forces are integrated into a virtual coupling framework yielding a stable haptic tool. We demonstrate the use of our system on applications from both cranio-maxillofacial surgery and archaeology, and show that we can achieve haptic rates for fractured surfaces with over 5000 points.	circuit restoration;haptic technology;sequence alignment	Pontus Olsson;Fredrik Nysjö;Jan-Michael Hirsch;Ingrid Carlbom	2013	2013 World Haptics Conference (WHC)	10.1109/WHC.2013.6548409	stereotaxy;computer vision;simulation;computer science;engineering;artificial intelligence;feedback;virtual reality;haptic technology;computer graphics (images)	Robotics	73.66945748355332	-32.20691922468092	20809
c7b18626b75aaa30671703ff0c9802d454ef64b1	nonlinear viscoelastic contact and deformation of freeform virtual surfaces	constitutive model;haptic surface rendering;contact and deformation;soft fingertip	This article is concerned with the haptic deformation display of discrete viscoelastic surfaces by means of a human fingertip. The virtual surface of a deformable quadrilateral mesh is interactively deformed by a Kelvin–Voigt soft fingertip model attached to the end-effector of a haptic interface device. In achieving this task, a nonlinear constitutive model approximating experimental data from literature is developed for determining the contact point deformations. By employing a new kernel weighting function, the deformations are distributed dependently on the discrete surface topology based on a nonlinear spring–damper net around the contact location. For illustration and evaluation of the proposed approach, a parallel robotic device with a constraint-based controller is adopted. The grip of the device is moved by the user to feel a sense of touch as the soft fingertip deforms the mesh surface of an ex vivo porcine liver tissue. Experimental data indicates stable realistic interactions thorough mechanical coupling between the soft fingertip and the deforming liver tissue. Dynamic response data of liver show rate-dependent hysteretic deformations and match closely with experimental indentation data from literature. A thorough analysis of mesh node count on the sample rate and the rendering quality is also presented.	haptic technology;hysteresis;interaction;interactivity;mesh networking;nonlinear system;robot end effector;sampling (signal processing);video-in video-out;weight function	Naci Zafer;Sezcan Yilmaz	2016	Advanced Robotics	10.1080/01691864.2015.1105868	computer vision;simulation;constitutive equation;engineering drawing	Robotics	71.36151961682005	-46.657405174934674	20841
97f88078c432b7e5a1aff471b33021215a15d17b	performance comparison between matrix-pencil and mode for 2-d harmonic retrieval	2d harmonic retrieval;gaussian noise;signal processing covariance matrices frequency estimation harmonic analysis;information retrieval;iron;performance comparison;frequency estimation;biomedical imaging;noise measurement;2d frequency estimation;covariance matrix australia signal processing noise measurement information retrieval electric variables measurement radar imaging biomedical imaging gaussian noise iron;single measurement data;2d frequency estimation performance comparison single measurement data 2d harmonic retrieval matrix pencil methods mode method fb memp method complex covariance matrix;covariance matrices;signal processing;radar imaging;matrix pencil;complex covariance matrix;fb memp method;mode method;australia;covariance matrix;matrix pencil methods;electric variables measurement;harmonic analysis	Two matrix-pencil methods have been compared with the MODE method, for a wide range of scenarios, when a single measurement of data is available. It has been observed that the FB-MEMP method slightly outperforms the MODE, in some scenarios. Real processing of a complex covariance matrix for 2-D frequency estimation is also discussed.		Qi Cheng	1999		10.1109/ISSPA.1999.818149	gaussian noise;computer vision;econometrics;covariance matrix;matrix pencil;computer science;noise measurement;signal processing;harmonic analysis;mathematics;radar imaging;iron;statistics	Vision	82.13450162292932	-37.90608800289904	20846
2c756da158a4e23de21bdb436efca1d942e1ba2b	spatio-temporal reflectance sharing for relightable 3d video	free viewpoint video;human performance;video streaming;model based approach;motion capture;biased sampling;3d video	In our previous work [21], we have shown that by means of a model-based approach, relightable free-viewpoint videos of human actors can be reconstructed from only a handful of multi-view video streams recorded under calibrated illumination. To achieve this purpose, we employ a marker-free motion capture approach to measure dynamic human scene geometry. Reflectance samples for each surface point are captured by exploiting the fact that, due to the person’s motion, each surface location is, over time, exposed to the acquisition sensors under varying orientations. Although this is the first setup of its kind to measure surface reflectance from footage of arbitrary human performances, our approach may lead to a biased sampling of surface reflectance since each surface point is only seen under a limited number of half-vector directions. We thus propose in this paper a novel algorithm that reduces the bias in BRDF estimates of a single surface point by cleverly taking into account reflectance samples from other surface locations made of similar material. We demonstrate the improvements achieved with this spatio-temporal reflectance sharing approach both visually and quanti-	algorithm;bidirectional reflectance distribution function;coherence (physics);collision detection;lambertian reflectance;motion capture;performance;real-time clock;resampling (statistics);robustification;sampling (signal processing);sensor;streaming media	Naveed Ahmed;Christian Theobalt;Hans-Peter Seidel	2007		10.1007/978-3-540-71457-6_5	human performance technology;computer vision;motion capture;simulation;sampling bias;computer science;computer graphics (images)	Vision	54.30032827286165	-47.508614366248665	20863
851b37d3f39acf02d9048b1627e5b94d3bee7238	rotational ranges of human precision manipulation when grasping objects with two to five digits	haptic interfaces biomechanics biomedical equipment;haptic devices human precision manipulation grasping objects writing precision tools turning knobs haptic interfaces unimpaired subjects finger object contact locations three orthogonal hand axes average rotational range distal proximal axis palmar dorsal axes ulnar radial axes rotation amplitude object size conditions human hand handheld tools;thumb yttrium market research haptic interfaces robots stability analysis	The ability to move and manipulate objects within the hand is important for the overall performance of the human hand. Such movements are key for many tasks, including writing, using precision tools, turning knobs, and operating various haptic interfaces. In this work we analyze the ability of 17 unimpaired subjects to rotate objects 50 and 80 mm in diameter using 2 to 5 digits, while maintaining the initial finger-object contact locations. Subjects were asked to rotate the object with a particular number of fingers around one of three orthogonal hand axes for 30 seconds and explore their rotational range. The average rotational range achieved over all conditions was 47 degrees, with the largest rotation of 82 degrees for the 3 digit case around a distal-proximal axis. The rotations around the palmar-dorsal and the ulnar-radial axes showed similar trends, where the smaller object resulted in 1.3 and 1.2 times larger rotation workspaces than the larger object (p <; 0.001), respectively. The rotation around the distal-proximal axis has a different trend, where the difference in rotation amplitude between different number of finger conditions is over 50% (p <; 0.003), but the difference in object size conditions is only 10%. The results highlight that the orientation of the rotation axis has significant influence on the rotation capabilities of the human hand. In designing handheld tools and haptic devices one should carefully consider around which axes a rotation is required.	apache axis;axis vertebra;diameter (qualifier value);digit structure;eighty;fingers, unit of measurement;handheld game console;haptic device component;haptic technology;large;largest;movement;optic axis of a crystal;physical object;radial (radio);robotics;small;workspace	Thomas Feix;Ian M. Bullock;Yuri Gloumakov;Aaron M. Dollar	2015	2015 37th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)	10.1109/EMBC.2015.7319707	computer vision;simulation;engineering;engineering drawing	Robotics	72.47088747300505	-26.26811364166339	20864
01bfe95ae5cfd824d9e2d59356c49f57419ba81a	parametric reconstruction of bent tube surfaces	program committee-nasagem workshop	We present a method for parametric reconstruction of a piecewise defined pipe surface, consisting of cylinder and torus segments, from an unorganized point set. Our main contributions are reconstruction of the spine curve of a pipe surface from surface samples, and approximation of the spine curve by G^1 continuous circular arcs and line segments. Our algorithm accurately outputs the parametric data required for bending machines to create the reconstructed tube.	algorithm;approximation;cylinder seal;williams tube	Ulrich Bauer;Konrad Polthier	2007	2007 International Conference on Cyberworlds (CW'07)	10.1109/CW.2007.59	mathematical optimization;surface reconstruction;interpolation;shape;level set;mathematics;geometry;least squares;approximation algorithm	Robotics	69.22991442884178	-41.55562772625354	20951
a38c1c11dd7cff02238f71da4d2a2d98b14ab9b7	measurement science for 6dof object pose ground truth	standards;spatial variables measurement;standards industrial robots optical sensors optical tracking pose estimation robot vision spatial variables measurement;robot vision;optical tracking;industrial standard measurement science object pose ground truth perception systems industrial manufacturing applications third party ground truth procedures manufacturing robotic applications object pose perception degrees of freedom laser tracker 6dof pose measurement aluminum fixture pose fixture mdf pose fixture medium density fiberboard;industrial robots;optical sensors;robotics measurement science object pose computer vision 6dof ground truth;standards fixtures measurement by laser beam measurement uncertainty robot sensing systems accuracy;pose estimation	Users of perception systems in industrial manufacturing applications need standardized, third party ground truth procedures to validate system performance before deployment. Many manufacturing robotic applications require parts and assemblies to be perceived, inspected or grasped. These applications need accurate perception of object pose to six degrees of freedom (6DOF) in X, Y, Z position with roll, pitch and yaw. A standardized 6DOF ground truth system should include test procedures, algorithms, artifacts, fixtures, and measurement equipment. Each of them must be openly documented so manufacturers, vendors, and researchers can recreate and apply the procedures. This article reports on efforts to develop an industrial standard for 6DOF pose measurement. It includes the design of test methods using a laser-tracker, an aluminum fixture pose fixture, and a modular, medium density fiberboard (MDF) pose fixture.		Roger D. Eastman;Jeremy Marvel;Joseph Falco;Tsai Hong	2013	2013 IEEE International Symposium on Robotic and Sensors Environments (ROSE)	10.1109/ROSE.2013.6698442	computer vision;simulation;pose;engineering;articulated body pose estimation;engineering drawing	Robotics	60.74086383817102	-36.347013717553246	20982
7986dd63ad59f1a7c91be0523899ff4dc409bfa1	an interpolant with tension defined over triangles	triangular patches;tension;surface interpolation	A C' interpolation scheme is described, which is defined over triangular grids. The interpolant is computed on the basis of curves with tension, which permit local control over the shape of the resulting surface.		Leila De Floriani;Giuliana Dettori	1985	Comput. Graph. Forum	10.1111/j.1467-8659.1985.tb00240.x	mathematical analysis;topology;tension;mathematics;geometry	Graphics	68.60805530258493	-40.88580064399547	21030
5f4e9723d69d39fe7d1fc65aa7028aebd7a3c9d3	câmbio: realistic three dimensional simulation of humanoids based on computer vision and robotics	humanoid robot;manipulators;computational modeling computer simulation computer vision humanoid robots robot vision systems animation avatars servomotors visual servoing manipulators;real time;virtual reality;three dimensional;computer vision;control visual motor commands;computer animated devices;computational modeling;robot vision;humanoid robots;visual perception robot vision manipulators servomechanisms computer animation virtual reality real time systems digital simulation feature extraction;feature extraction;real time robotics applications;computer vision algorithms;servomechanisms;animation;feature extraction techniques;realistic simulation;realistic 3d simulation control visual motor commands realistic simulation visual servoing visual perception robotics simulation computer animated devices virtual agents avatars humanoid robot feature extraction techniques computer vision algorithms real time robotics applications;avatars;servomotors;visual perception;robotics simulation;computer animation;visual servoing;virtual agents;realistic 3d simulation;computer simulation;robot vision systems;digital simulation;virtual agent;real time systems	We introduce concepts and algorithms for control of visual motor commands and realistic simulation of basic abilities as visual servoing and perception for robotics simulation. These tools can also be used in a straightforward way to build computer animated devices as virtual agents and avatars. We use them to build part of a humanoid (arms and head) robot, affectively named “Câmbio”. We will describe Câmbio’s design, providing an overview on the most used feature extraction techniques for perception, discussing implementation issues. We intend to show the usefulness of a simulated platform as an inexpensive alternative for testing and developing computer vision algorithms in real-time robotics applications.	algorithm;avatar (computing);binocular disparity;coat of arms;computer animation;computer vision;feature extraction;intelligent agent;opengl;population;real-time clock;real-time transcription;robot;robotics;simulation;sobel operator;thermal copper pillar bump;visual servoing	Claus C. Aranha;Schubert R. Carvalho;Luiz Marcos Garcia Gonçalves	2002		10.1109/SIBGRA.2002.1167170	computer vision;simulation;computer science;computer graphics (images)	Robotics	65.35918448009244	-30.562775044424285	21035
6abbf31f253ac08dc55291cab751fe53bca73f8a	electro-osmotic propulsion of helical nanobelt swimmers	energy conversion;human centered and life like robotics;biologically inspired robots;micro nanorobots;body length;and control;electric field;mechanics;low reynolds number;design;mobile agent;mechanism design;biomimetics	Micro and nanoscale mobile agents capable of self-propulsion in low Reynolds number fluids would have a great technological impact in many fields. Few known mechanisms are able to propel such devices. Here we describe helical nanobelt (HNB) swimmers actuated by an electric field-generated electro-osmotic force. These HNB swimmers are designed with a head and a tail, similar to natural micro-organisms such as bacteria and their flagella. We show that these electro-osmotic propulsion of HNB swimmers achieve speeds (24 body lengths per second), force (1.3 nN), and pressure (375.5 Pa) above those demonstrated by other artificial swimmers based on physical energy conversion. Although nature’s bacteria are still more dynamic, this paper reports that the demonstrated electro-osmotic HNB microswimmers made a big step toward getting closer to their performances. Moreover, an unusual swimming behavior with discontinuous pumping propulsion, similar to jellyfish, was revealed at or above the speculated marginal limit of linear propulsion. These electro-osmosis propelled HNB swimmers might be used as biomedical carriers, wireless manipulators, and as local probes for rheological measurements.	ambiguous name resolution;cleanroom;finite element method;gnu nano;gradient;hideki imai;marginal model;mathematical morphology;microelectromechanical systems;mobile agent;out run;performance;piezoelectricity;polymer;propel;pumping (computer systems);real-time bidding;semiconductor;simulation;spiral computed tomography;swarm;technical support;traffic enforcement camera;velocity (software development);windows 3.0;magnussoft zeta	Gilgueng Hwang;Rémy Braive;Laurent Couraud;Antonella Cavanna;Ouerghi Abdelkarim;Isabelle Robert-Philip;Alexios Beveratos;Isabelle Sagnes;D. Sinan Haliyo;Stéphane Régnier	2011	I. J. Robotics Res.	10.1177/0278364911407231	biomimetics;mechanism design;design;simulation;engineering;electric field;nanotechnology;mobile agent;quantum mechanics;mechanical engineering	HCI	77.66687592474347	-24.01113903062443	21156
0343b696ce2c1e23f5029a22a64cfa28f677ad0f	non-polynomial galerkin projection on deforming meshes	reduced models;solid fluid coupling;radiosity;fluid simulation	This paper extends Galerkin projection to a large class of non-polynomial functions typically encountered in graphics. We demonstrate the broad applicability of our approach by applying it to two strikingly different problems: fluid simulation and radiosity rendering, both using deforming meshes. Standard Galerkin projection cannot efficiently approximate these phenomena. Our approach, by contrast, enables the compact representation and approximation of these complex non-polynomial systems, including quotients and roots of polynomials. We rely on representing each function to be model-reduced as a composition of tensor products, matrix inversions, and matrix roots. Once a function has been represented in this form, it can be easily model-reduced, and its reduced form can be evaluated with time and memory costs dependent only on the dimension of the reduced space.	approximation algorithm;fluid animation;galerkin method;graphics;polynomial;radiosity (computer graphics);simulation	Matt Stanton;Yu Sheng;Martin Wicke;Federico Perazzi;Amos Yuen;Srinivasa G. Narasimhan;Adrien Treuille	2013	ACM Trans. Graph.	10.1145/2461912.2462006	fluid simulation;mathematical optimization;mathematical analysis;radiosity;computer science;mathematics;geometry;computer graphics (images)	Graphics	72.44248259121291	-42.577596091318945	21161
b1358090037f7285dcb80abe3fbb79488e6354b7	iso-planar interpolation for the machining of implicit surfaces	implicit surface;concepcion asistida;machining;computer aided design;surface implicite;interpolation;norme iso;cutting plane;ajustamiento curva;cutting;interpolacion;norma iso;courbure;iso standard;decoupage;superficie curva;curved surface;herramienta corte;outil coupe;usinage;surface plane;curved boundary;metodo plano secante;conception assistee;curvatura;ajustement courbe;surface courbe;curvature;troquelado;surface machining;numerical control;mecanizado;cutting tool;methode plan secant;curve fitting;plane surface;cnc;superficie plana;cutting plane method	The paper presents an approach for on-line path generation and interpolation for the machining of implicit surfaces. For a given implicit surface, once the cutting plane direction and cut-in points have been selected, iso-planar tool paths and interpolated points can be calculated on-line according to the feedrate and scallop height requirements. The approach enables the tool position and orientation to be correctly calculated at each interpolated point. Validation examples are provided for the interpolation of cyclide surfaces with planar and curved boundaries.	implicit surface;interpolation	Hon-Yuen Tam;Haiyin Xu;Zude Zhou	2002	Computer-Aided Design	10.1016/S0010-4485(01)00059-8	topology;interpolation;engineering;computer aided design;mathematics;geometry;numerical control;nearest-neighbor interpolation;engineering drawing;cutting-plane method;mechanical engineering	EDA	68.93736698792124	-37.99692198620876	21265
a57fbc595354b6e1625b6014aceda1dd6141cf30	reconstruction of fluid surface using physical property	reconstruction;fluid;height field;lbm;video	A novel technique for reconstructing fluid surface from video is introduced. Both fluid motion vectors as well as Lattice Boltzmann Method (LBM) are employed in the study. Region-based correlation method is used to initialize motion vectors field, after clustering fluid motion vector results can be obtained. Then the height geometry information of fluid surface can be calculated from fluid motion vector further. At last, the distribution of fluid particle is interpolated and the height field can be further refined. Reconstruction results are demonstrated with several challenge videos. The experimental results show that the method is convenient and efficient. The calculation results can reflect the characteristics of the fluid movement, and it is a valid method for reconstructing fluid surface.		Hongyan Quan;Maomao Wu	2015	IJMSSC	10.1142/S1793962315500063	classical mechanics;simulation;video;fluid;geometry;thermodynamics;cfd-dem;physics	HCI	72.69202300591496	-48.6747737853006	21324
a5f04a796edb107dea3157ed8c0a8715479e6bd1	performance enhancement of a haptic arm exoskeleton	engineering;damping;control systems;haptic i o;concurrent computing;engineering haptic i o;degree of freedom;actuators;kinematics;exoskeletons;computer control;humans;haptic interfaces exoskeletons damping kinematics humans costs actuators torque control concurrent computing control systems;haptic interfaces;torque control;haptic interface	A high-quality haptic interface is typically characterized by low apparent inertia and damping, high structural stiffness, minimal backlash, and absence of mechanical singularities in the workspace. In addition to these specifications, exoskeleton haptic interface design involves consideration of space and weight limitations, workspace requirements, and the kinematic constraints placed on the device by the human arm. In this paper, the authors present the redesign of an existing five degree-of-freedom haptic arm exoskeleton. The redesign efforts focus primarily on ensuring smooth operation of the exoskeleton’s moving parts to minimize backlash, reducing cost and build time by simplifying the design, and increasing the torque output while continuing to use electric actuators for ease of control. The accompanying computer control system was developed in parallel with the mechanical redesign effort. The newly redesigned exoskeleton presented is capable of providing kinesthetic feedback to the joints of the lower arm and wrist of the operator, and will be used in future work for robot-assisted rehabilitation and training.	arm architecture;benchmark (computing);computer control company;control system;haptic technology;isometric projection;iteration;requirement;robot;virtual reality;workspace	Alan Sledd;Marcia Kilchenman O'Malley	2006	2006 14th Symposium on Haptic Interfaces for Virtual Environment and Teleoperator Systems	10.1109/HAPTICS.2006.172	control engineering;simulation;engineering;control theory	Robotics	71.02679745093113	-24.50745647155999	21337
79a339bf4c5f5362017dd6f9a89b3b44f3716c2f	roughness encoding for discrimination of surfaces in artificial active-touch	doigt;mechanoception;metodo caso peor;robot sensing systems;reseau capteur;propiocepcion;microelectromechanical system tactile microsensors;capteur tactile;end effector velocity;distal phalanx;biomimetic fingerprints;tactile sensor;sensor tactil;force and tactile sensing;superficie rugosa;biomimetica;rugosidad;readout electronics;gratings;surface roughness;proprioception;microsensor;hombre;electromechanical system;robotics;microcaptador;classification;rough surfaces;captador medida;arrays;robot sensing systems arrays encoding gratings surface roughness rough surfaces;artificial active touch;vecino mas cercano;tactile sensing;measurement sensor;mems array;red sensores;capteur mesure;micromechanical devices;sistema electromecanico;microelectromechanical device;biomimetique;roughness;sensibilidad tactil;roughness encoding artificial touch force and tactile sensing microelectromechanical system mems sensors array robotic finger;human;dispositif microelectromecanique;methode cas pire;sensor array;surfaces discrimination;rugosite;robotica;anthropomorphic robotic finger;tactile sensors;polymeric packaging;rough surface;finger;plus proche voisin;nearest neighbour;k nearest neighbor;robotique;micro electromechanical system mems sensors array;microelectromechanical system;robotic finger;artificial finger;artificial touch;methode domaine temps frequence;roughness encoding;tactile sensors encoding end effectors mechanoception micromechanical devices microsensors;systeme electromecanique;end effector velocity roughness encoding surfaces discrimination artificial active touch microelectromechanical system tactile microsensors readout electronics distal phalanx anthropomorphic robotic finger artificial finger human merkel mechanoreceptors mems array polymeric packaging biomimetic fingerprints proprioceptive sensors;discriminacion;dedo;encoding;worst case method;microcapteur;dispositivo microelectromecanico;time frequency analysis;proprioceptive sensors;clasificacion	A 2 × 2 array of four microelectromechanical system (MEMS) tactile microsensors is integrated with readout electronics in the distal phalanx of an anthropomorphic robotic finger. A total of 16 sensing elements are available in a 22.3-mm area (i.e., 72 units/cm ) of the artificial finger, thus achieving a density comparable with human Merkel mechanoreceptors. The MEMS array is covered by a polymeric packaging with biomimetic fingerprints enhancing the sensitivity in roughness encoding. This paper shows the ability of the sensor array to encode roughness for discrimination of surfaces, without requiring dedicated proprioceptive sensors for end-effector velocity. Three fine surfaces with 400-, 440-, and 480- μm spatial periods are quantitatively evaluated. Core experiments consisted in active-touch exploration of surfaces by the finger executing a stereotyped human-like movement. A time-frequency analysis on pairs of tactile array outputs shows a clustering of the fundamental frequency, thus yielding 97.6% worst-case discrimination accuracy with a k -nearest-neighbor (k-NN) classifier. Hence, surfaces differing down to 40 μm are identified in active-touch by both hardware and processing methods based on exteroceptive tactile information. Finally, active-touch results with five textiles (which differ in texture or orientation) are shown as a preliminary qualitative assessment of discrimination in a more realistic tactile-stimulation scenario.	best, worst and average case;biomimetics;cluster analysis;encode;experiment;fingerprint;frequency analysis;k-nearest neighbors algorithm;microelectromechanical systems;robot end effector;sensor;time–frequency analysis;velocity (software development)	Calogero Maria Oddo;Marco Controzzi;Lucia Beccai;Christian Cipriani;Maria Chiara Carrozza	2011	IEEE Transactions on Robotics	10.1109/TRO.2011.2116930	electronic engineering;computer science;engineering;electrical engineering;artificial intelligence;robotics;tactile sensor	Robotics	63.644605832782794	-32.58178429140988	21377
b871859428eace1f0763c989bc51b11521fa9880	biologically inspired autoadaptive control of a knee prosthesis	electrical engineering and computer science;thesis	This thesis describes the electronic control of a knee prosthesis for amputees. A microprocessor receives data from sensors, processes it and determines the proper level of rotary resistance for the joint. Control is maintained through one of two algorithms -one for a system with sensors only for knee angle and axial force and one that also senses bending moment at the knee base. The electronic knee can control stance stability, adapt to walking cadence and detect stairs and standing modes, all advantages over the conventional mechanical knee. It will also allow flexion during stancean important component of normal gait that most prostheses do not allow. Parameters for the knee are set automatically from observing the subject walk, rather then relying on the judgment of the prosthetist doing the fitting. As the subject moves, the output of the microprocessor changes and adapts to the actions of the subject, who might be walking faster, picking up a suitcase, or changing shoes. The algorithms were developed using five amputees with varying physical characteristics. Safety, comfort, and natural-appearing movement were considered in the project. Thesis Supervisor: Gill A. Pratt Title: Assistant Professor of Electrical Engineering and Computer Science, MIT	computer science;knuth–morris–pratt algorithm;microprocessor;rotary system;sensor;shoes	Ari Wilkenfeld	2000			engineering;biological engineering;mechanical engineering	Robotics	72.04567373851175	-26.98608270567519	21549
df966a23e5e07d834326724f897364fb10ae3d1b	an experimental study on relative and absolute pose graph fusion for vehicle localization		In this work, we research and evaluate multiple pose-graph fusion strategies for vehicle localization. We focus on fusing a single absolute localization system, i.e. automotivegrade Global Navigation Satellite System (GNSS) at 1 Hertz, with a single relative localization system, i.e. vehicle odometry at 25 Hertz. Our evaluation is based on 180 Km long vehicle trajectories that are recorded in highway, urban and rural areas, and that are accompanied with post-processed Real Time Kinematic GNSS as ground truth. The results exhibit a significant reduction in the error’s standard deviation by 18% but the bias in the error is unchanged, when compared to non-fused GNSS. We show that the underlying principle is the fact that errors in GNSS readings are highly correlated in time. This causes a bias that cannot be compensated for by using the relative localization information from the odometry, but it can reduce the standard deviation of the error.	experiment;ground truth;odometry;real time kinematic;satellite navigation	Zhenfei Zhang;Gijs Dubbelman	2018	2018 IEEE Intelligent Vehicles Symposium (IV)	10.1109/IVS.2018.8500512	real time kinematic;geodesy;standard deviation;measurement uncertainty;odometry;hertz;ground truth;sensor fusion;mathematics;gnss applications	Robotics	55.75932069281482	-37.24269009435057	21571
38118d211b32552d43f5a9ead75d38b478f7cf21	collision avoidance in dynamic environment by estimation of velocity and location of object by robot using parallax			parallax;robot;velocity	Ajay Kumar Rai;Ritu Tiwari	2015	IJRAT	10.4018/IJRAT.2015070104	parallax;artificial intelligence;collision;computer vision;simulation;robot;computer science	Robotics	58.349836180624806	-30.680048365413107	21587
d374f4199bfcc675dc2c8bf944803b3a718fbec8	design and compatibility of a high-performance actuation system for fmri-based neuroscience studies	dynamic electromagnetic fields;functional magnetic resonance imaging;magnetic resonance imaging magnetic noise magnetic shielding saturation magnetization actuators dc motors;high performance actuation system;magnetic field;fmri based neuroscience study;actuators;saturation magnetization;magnetic shielding;electromagnetic field;fiber optic;detection threshold;human motor control;functional magnetic resonance images;magnetic resonance imaging;dynamic electromagnetic fields high performance actuation system fmri based neuroscience study functional magnetic resonance imaging haptic interface human motor control;magnetic noise;dc motors;haptic interfaces;high performance;motor control;biomedical mri;haptic interfaces biomedical mri;haptic interface	Haptic interfaces compatible with functional magnetic resonance imaging (fMRI) are finding increasing interest as a tool to explore the neural correlates of human motor control and related dysfunctions. To achieve safety and MR compatibility, such devices have mainly relied on unconventional actuation methods suffering from limited bandwidth and non-linearities. This has resulted in complex control and restricted their use in applications involving fine and dynamic interaction with the hand and fingers. To address these limitations, we propose a concept for a shielded high-performance actuation system to be located inside the MR room, evaluate the effectiveness of the shielding and perform detailed MR compatibility tests. A conventional electromagnetic actuator is located within a steel shield to prevent mutual disturbance with magnetic fields of the scanner, which, together with power and control hardware, is placed within a Faraday cage with only a fiber-optical USB link to the control room. Detailed compatibility tests show that disturbing dynamic electromagnetic fields generated by the actuation system are well below the detectable threshold of the scanner, and actuator performance is not degraded by the MR environment. In combination with a light and stiff cable or rod transmission, the presented actuator technology, providing high transparency and force bandwidth, paves the way for fMRI-based neuroscience studies, e.g., to investigate the fine motor control of hand and fingers.	consciousness;faraday cage;haptic technology;resonance;usb	Masayuki Hara;Julio Duenas;Tobias Kober;Dominique Chapuis;Olivier Lambercy;Hannes Bleuler;Roger Gassert	2010	2010 IEEE/RSJ International Conference on Intelligent Robots and Systems	10.1109/IROS.2010.5649544	control engineering;motor control;saturation;electromagnetic field;magnetic field;engineering;electrical engineering;optical fiber;magnetic resonance imaging;dc motor;electromagnetic shielding;haptic technology;nuclear magnetic resonance;quantum mechanics;actuator	Robotics	75.7897353533892	-26.611050321199965	21596
bb4c6e5d003b4e7f209716273bf852c8463a5719	a genus oblivious approach to cross parameterization	animacion por computador;alignement;calculo de variaciones;image morphing;concepcion asistida;computer aided design;silhouette;parameterization;general and miscellaneous;parametrizacion;morphage;tunnels;calcul variationnel;morphing;shape;deformation;alineamiento;conception assistee;tunnel;genus reduction;morphing de imagenes;computer animation;morse theory;tunel;silueta;alignment;parametrisation;variational calculus;cross parameterization;animation par ordinateur	In this paper we present a robust approach to construct a map between two triangulated meshes, M and M ’ of arbitrary and possibly unequal genus. We introduce a novel initial alignment scheme that allows the user to identify “landmark tunnels” and/or a “constrained silhouette” in addition to the standard landmark vertices. To describe the evolution of non-landmark tunnels we automatically derive a continuous deformation from M to M ’ using a variational implicit approach. Overall, we achieve a cross parameterization scheme that is provably robust in the sense that it can map M to M ’ without constraints on their relative genus. We provide a number of examples to demonstrate the practical effectiveness of our scheme between meshes of different genus and shape.	genus (mathematics);variational principle	Janine Bennett;Valerio Pascucci;Kenneth I. Joy	2008	Computer Aided Geometric Design	10.1016/j.cagd.2008.06.003	parametrization;topology;shape;computer aided design;mathematics;geometry;silhouette;deformation;morphing;morse theory	Vision	67.9366595772576	-43.794002599542964	21631
98aa4a71e67b28a31954345562881d7e7eb21a57	the role of white collar robots real-time expert systems with multi-media sensory systems	robot sensing systems;expert systems;real time;robot sensing systems real time systems expert systems multimedia systems;multimedia systems;sensory system;real time systems;expert system			M. Somalvico	1986		10.1109/ROBOT.1986.1087609	control engineering;sensory system;embedded system;simulation;intelligent decision support system;computer science;engineering;artificial intelligence;expert system	Robotics	57.56423505686756	-30.69956316500452	21644
301e103881a51f2b103896bc5fd6b631ffbc3d1a	blind speech separation using high order statistics	nongaussian sources;transfer functions;fastica algorithm;convolution;blind source separation;statistical independence;probability density function;speech processing;niobium;speech;transient response blind source separation convolution higher order statistics nonlinear functions speech processing transfer functions;independent component analysis;signal to interference ratio;data mining;time domain analysis;higher order statistics;linear functionals;blind speech separation;nonlinear functions;herault jutten algorithm;transient response;adaptation model;head related transfer function;principal component analysis;speech independent component analysis higher order statistics principal component analysis blind source separation source separation decorrelation time domain analysis equations niobium;convolutive mixtures;instantaneous mixture;separation criterion;mathematical model;high order nonlinear functions;impulse response;decorrelation;instantaneous mixtures;higher order statistics blind source separation instantaneous mixture convolutive mixture independent component analysis;high order statistics;source separation;convolutive mixture;fastica algorithm blind speech separation high order statistics nongaussian sources instantaneous mixtures convolutive mixtures separation criterion herault jutten algorithm high order nonlinear functions impulse response head related transfer function signal to interference ratio	This paper deals with blind speech separation of instantaneous and convolutive mixtures of non-Gaussian sources. The separation criterion is based on higher order statistics (HOS) on the assumption that the sources are statistically independent. We propose to simplify and to improve the classical Herault-Jutten algorithm by choosing adequate high order non-linear functions for adaptation. The convolutive case is investigated through a model with impulse responses modeling the Head Related Transfer Function (HRTF). Experimental results show the efficiency of the proposed approach in terms of signal-to-interference ratio, when compared to the widely used fastICA algorithm. In the convolutive case a satisfactory separation of the sources has been achieved.	algorithm;fastica;head-related transfer function;interference (communication);linear function;nonlinear system	Yasmina Benabderrahmane;Abderraouf Ben Salem;Sid-Ahmed Selouani;Douglas D. O'Shaughnessy	2009	2009 Canadian Conference on Electrical and Computer Engineering	10.1109/CCECE.2009.5090213	independence;independent component analysis;niobium;probability density function;speech recognition;signal-to-interference ratio;decorrelation;impulse response;computer science;speech;head-related transfer function;pattern recognition;mathematical model;speech processing;mathematics;blind signal separation;transfer function;convolution;transient response;statistics;principal component analysis	ML	82.79104861112661	-32.0281425547647	21753
d84ba9c93d4fd606e1eb94321e8dbcdde104956b	development of an inexpensive tri-axial force sensor for minimally invasive surgery		This work presents the design and evaluation of a low-cost tri-axial force sensor, that has been developed to regain the sense of touch in minimally invasive surgeries (MIS). The force sensor uses an array of force sensitive resistors (FSR) with a mechanically pre-loaded structure to perform the force sensing. The sensor has a built-in signal conditioning circuitry to provide on-board power regulation, programmable signal amplification and analog to digital conversion. The sensor is inexpensive and highly sensitive to low-amplitude force, critical in surgical applications. We validate the efficacy of the sensor with two surgical applications — robotic palpation for stiffness mapping and obstacle avoidance for a highly articulated robotic probe (HARP). The results show that the sensor is capable of accurately detecting the stiff inclusions embedded in the tissues as well as detecting obstacles and helping HARP safely navigate around them.	analog-to-digital converter;apache axis;baseline (configuration management);computer form factor;electronic circuit;embedded system;experiment;firmware;harp;minimally invasive education;obstacle avoidance;on-board data handling;preload (software);printed circuit board;repeatability;robot;sensor;signal processing;triangular function	Lu Li;Bocheng Yu;Chen Yang;Prasad Vagdargi;Rangaprasad Arun Srivatsan;Howie Choset	2017	2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)	10.1109/IROS.2017.8202253	control engineering;resistor;palpation;computer vision;artificial intelligence;computer science;signal conditioning;stiffness;obstacle avoidance	Robotics	73.67561046177819	-26.943424615526354	21847
82d28356f8e4124c7a9a5853b25ddd02485a4b4f	photometric stereo for archeological inscriptions	3d segmentation;virtual restoration;photometric stereo;texture editing	A challenge with photometric stereo is the estimation of the light source position and of the radiant intensity at each pixel, which varies from pixel to pixel due to source anisotropy and changing distance from the source to the surface point. Hence, the technique has mostly been used in controlled laboratory settings. Recently [Malzbender et al. 2001; Rushmeier and Bernardini 1999] have showed new applications for photometric data. We have constructed a low-cost device suitable for use in the field, that allows photometric data to be captured quickly using only a digital camera with a remotely mounted flash. This enables us to easily reconstruct geometry and reflectance properties.	digital camera;photometric stereo;pixel;radiant ai;word lists by frequency	Per Einarsson;Tim Hawkins;Paul E. Debevec	2004		10.1145/1186223.1186324	computer vision;photometric stereo;computer science;computer graphics (images)	Vision	60.222886294371534	-50.81031367736138	21862
2e3d9532365e24ec435cee4b689a115515e75068	a 2d laser rangefinder scans dataset of standard eur pallets		In the past few years, the technology of automated guided vehicles (AGVs) has notably advanced. In particular, in the field of factory and warehouse automation, different approaches have been presented for detecting and localizing pallets inside warehouses and shop-floor environments based on the data acquired from 2D laser rangefinders. In [1], we present a robust approach allowing AGVs to detect, localize, and track multiple pallets using machine learning techniques based on an on-board 2D laser rangefinder. In this paper, the data used in [1, 2] for solving the problem of detection, localization and tracking of pallets is described. Furthermore, we present an open repository of dataset and code1 to the community for further research activities. The dataset comprises a collection of 565 2D scans from real-world environments, which are divided into 340 samples where pallets are present, whereas 225 samples represent the case in which no pallets are present.	internationalization and localization;machine learning;on-board data handling;sensor	Ihab S. Mohamed;Alessio Capitanelli;Fulvio Mastrogiovanni;Stefano Rovetta;Renato Zaccaria	2018	CoRR		automation;robustness (computer science);bioinformatics;real-time computing;pallet;laser;biology	Robotics	53.76879666436148	-34.7301922850402	21952
dec3a89b32b3979b43ca978ead07080735274de6	converting underwater imaging into imaging in air	underwater stereo vision underwater image formation underwater camera model camera calibration;cameras calibration atmospheric modeling distortion physical optics adaptive optics	The application of imaging devices in underwater environments has become a common practice. Protecting the camera's constituent electric parts against water leads to refractive effects emanating from the water-glass-air transition of light rays. These non-linear distortions can not be modeled by the pinhole camera model. For our new approach we focus on flat interface systems. By handling refractive effects properly, we are able to convert the problem to imaging conditions in air. We show that based on the location of virtual object points in water, virtual parameters of a camera following the pinhole camera model can be computed per image ray. This enables us to image the same object as if it was situated in air. Our novel approach works for an arbitrary camera orientation to the refractive interface. We show experimentally that our adopted physical methods can be used for the computation of 3D object points by a stereo camera system with much higher precision than with a naive in-situ calibration.	3d reconstruction;algorithm;computation;computer vision;distortion;experiment;ground truth;nonlinear system;pinhole camera model;preprocessor;ray (optics);situated;stereo camera;triangulation (geometry);virtual camera system	Tim Dolereit;Arjan Kuijper	2014	2014 International Conference on Computer Vision Theory and Applications (VISAPP)	10.5220/0004685600960103	stereo camera;computer vision;camera auto-calibration;optics;remote sensing	Vision	59.74203412001702	-51.579675446405176	21968
5d3858afd47a2021d142d8fb6a48b21b73941380	realistic, real-time rendering of ocean waves	real time;reflectance;ocean wave;shading models;computer game;real time rendering	In computer games and other real-time graphics applications, the ocean surface is typically modeled as a texture or bump-mapped plane with simple lighting effects. This paper describes a system for realistically rendering the water surface in real time. Our system can render calm ocean waves with sophisticated lighting effects at 100 fps on a 680 MHz Pentium III with a GeForce 3 graphics card. The wave geometry is represented view-dependently as a dynamic displacement map with surface detail described by a dynamic bump map. The illumination model includes reflection, refraction, and Fresnel effects which are critical for producing the look and feel of water. CR Categories: I.3.7 [Three-Dimensional Graphics and Realism]—Color, shading, shadowing, and texture; I.3.3 [Picture/Image Generation]—Bitmap and framebuffer operations;	bitmap;bump mapping;displacement mapping;framebuffer;geforce 3 series;graphics;list of common shading algorithms;look and feel;pc game;real-time locating system;surface detail;video card	Yaohua Hu;Luiz Velho;Xin Tong;Baining Guo;Harry Shum	2006	Journal of Visualization and Computer Animation	10.1002/cav.74	wind wave;computer vision;real-time computing;simulation;image-based modeling and rendering;rendering;computer science;reflectivity;real-time rendering;computer graphics (images)	Graphics	64.27191222116988	-50.943756017065105	22008
dc6c9e6ad5f6f2a8a0e8885a96bcbb06c634707a	dynamic human body modeling using a single rgb camera	scape;single rgb camera;non rigid reconstruction;structure from motion;motion classification;pose estimation	In this paper, we present a novel automatic pipeline to build personalized parametric models of dynamic people using a single RGB camera. Compared to previous approaches that use monocular RGB images, our system can model a 3D human body automatically and incrementally, taking advantage of human motion. Based on coarse 2D and 3D poses estimated from image sequences, we first perform a kinematic classification of human body parts to refine the poses and obtain reconstructed body parts. Next, a personalized parametric human model is generated by driving a general template to fit the body parts and calculating the non-rigid deformation. Experimental results show that our shape estimation method achieves comparable accuracy with reconstructed models using depth cameras, yet requires neither user interaction nor any dedicated devices, leading to the feasibility of using this method on widely available smart phones.	3d modeling;body part;clinical use template;interaction;kinesiology;muscle rigidity;parametric model;part dosing unit;personalization;real life;smartphone;smartphone;usability;videocassette	Haiyu Zhu;Yao Yu;Yu Zhou;Sidan Du	2016		10.3390/s16030402	computer vision;structure from motion;simulation;pose;computer science;computer graphics (images)	HCI	54.47805126280358	-45.94745827569435	22021
9c268a501c5093d59cac266a6d9ad6237149c941	a parallel-fingered hand system with multiple sensing functions for grasping various objects	hand;coeficiente roce;rugosidad;prension;adaptive control;surface roughness;robotics;gripping;integration;algorithme;captador medida;algorithm;friction coefficient;commande force;measurement sensor;coefficient frottement;capteur mesure;control adaptativo;roughness;integracion;commande adaptative;rugosite;mano;robotica;control fuerza;a priori information;prehension;robotique;main;algoritmo;force control	This paper describes the development of a parallel-fingered hand with multiple sensing functions for grasping objects with varying hardness, surface roughness, and weight. The multiple sensing functions are: grasping force sensing, static friction coefficient sensing, and weight sensing. Hardware and algorithms are described for measuring the above parameters and for controlling the handu0027s grasping force by integrating those parameters into a unified control law. We present experimental results that verify the proposed hand systemu0027s capabilities of lifting and holding target objects, given only predetermined maximum force settings or limit displacements for the initial grasp. Further studies demonstrate adaptive grasping force control in response to changes in an external force applied to the object, using the static friction coefficient detected by our sensor as a priori information on the object surface roughness.		Yoji Yamada;Hiroaki Kozai;Nuio Tsuchida;Koji Imai	1993	Advanced Robotics	10.1163/156855394X00392	control engineering;surface roughness;adaptive control;engineering;artificial intelligence;control theory;robotics;engineering drawing	Robotics	64.1371881196854	-32.95664188948475	22028
375a303f3c8b9328b587d02e439ed08db60a90a1	towards dextrous manipulation using manipulation manifolds	manipulation movements;kernel regression;manifolds fingers robots turning joints construction industry aerospace electronics;motion control;manifolds;turning;manipulation manifolds;construction industry;regression analysis dexterous manipulators motion control;joints;dexterous manipulators;physically based simulation;robots;dextrous manipulation;fingers;aerospace electronics;unsupervised kernel regression;regression analysis;unsupervised kernel regression dextrous manipulation manipulation manifolds manipulation movements	In dextrous manipulation, the implementation of manipulation movements still is a complex and intricate undertaking. Often, a lot of object physics and modelling effort has to be incorporated into a controller working only for a very restricted task specification and performing quite artificially looking movements. In this paper, we present the first steps towards a representation of manipulation movements recorded from human demonstration which facilitates later application and promotes natural motion. We use manifolds of hand postures embedded in the finger joint angle space which are constructed such that manipulation parameters including the advance in time are represented by distinct manifold dimensions. This allows for purposive navigation within such manifolds. We present the manifold construction using the Unsupervised Kernel Regression (UKR) and the way of applying it for manipulation in the example of turning a bottle cap in a physics-based simulation.	controller (computing);embedded system;simulation	Jan Steffen;Robert Haschke;Helge J. Ritter	2008	2008 IEEE/RSJ International Conference on Intelligent Robots and Systems	10.1109/IROS.2008.4650720	robot;control engineering;motion control;kernel regression;computer vision;simulation;manifold;computer science;engineering;artificial intelligence;regression analysis	Robotics	63.989996541082384	-25.289522919833562	22059
a9fdcf5f6e5244b56c9fbb8dafde652355cb8dea	"""non-uniformity of a pattern and """"the best"""" single view 3d pose estimator"""	model based single vieww 3 d pose estimation;rev;universidad autonoma del estado de mexico;red de revistas cientificas de america latina y el caribe espanoa y portugal;3d pose estimation;uaem;robot control;redalyc;keywords model based single view 3d pose estimation spacecraft docking robot control visual servoing;cientifica;hemeroteca;visual servoing;article;spacecraft docking	VISUAL MODEL OF AN OBJECT IS PRESENTED AS COMPOSITION OF A MODEL - SHAPE FUNCTION AND A MODEL- PATTERN FUNCTION. NON - UNIFORMITY OF PATTERN IS DEFINED AS A QUADRATIC FORM RELATED TO THE GRADIENT OF INTENSITY. FOR A PLANAR MODEL IT IS PROVED THAT A MORE PRECISE ESTIMATION REPONDS TO A GEATER NON- UNIFORMITY. THIS IS APPLIED TO DEVELOP A CLASS OF SINGLE - VIEW 3- D POSE ESTIMOTORS EXPLORING EXTREMELY NON- UNIFORM PATTERNS. THE ESTIMATORS ARE OF HIGH PRECISION, FAST, ROBUST, AND ALGORITHMICALLY SIMPLE. POSSIBLE APPLICATION IS SPACECRAFT DOCKING, OR ANY ROBOT PROBLEM PERMITING USAGE OF A VISUAL MARK (TARGENT) ON REMOTE OBJECT.	circuit complexity	Georgii Khachaturov	1999	Computación y Sistemas		computer vision;simulation;3d pose estimation;computer science;artificial intelligence;operating system;robot control;visual servoing;rev	Vision	60.85418077446084	-34.18338345971197	22080
ca039524e8c0e21adef5e60548ee69564ecae669	extracting common spectral features by multichannel filtering using circulant matrices	eigenvalues and eigenfunctions;matrix algebra discrete fourier transforms eigenvalues and eigenfunctions feature extraction filtering theory;frequency synchronization;multichannel measurement;feature extraction filtering matrix decomposition eigenvalues and eigenfunctions covariance matrix frequency symmetric matrices independent component analysis finite impulse response filter discrete fourier transforms;circulant matrix;common spectral feature extraction;spectrum;frequency measurement;matrix algebra;eigenvalues;eigenvalue decomposition;multichannel filtering;frequency response;single channel;matrix decomposition;feature extraction;augmented windowed circular matrix;discrete fourier transform;augmented windowed circular matrix common spectral feature extraction multichannel filtering circulant matrices eigenvalue decomposition discrete fourier transform eigenvectors single channel measurements multichannel measurement block circulant matrix frequency response;circulant matrices;signal to noise ratio;discrete fourier transforms;single channel measurements;filtering theory;eigenvectors;covariance matrix;block circulant matrix	It is well known that the eigenvalue decomposition (EVD) of a circulant matrix returns the discrete Fourier transform (DFT) with the eigenvectors being the transformation vectors and the eigenvalues containing the spectral coefficient in the corresponding frequency band [R.N. Gray, 2006]. For single channel measurements this provides an easy way to calculate the DFT. Going to a multichannel measurement, this method provides a way of calculating the spectra of the different channels by means of one transformation of a block circulant matrix. However, the frequency response of the multichannel measurement is calculated per channel without exchanging information between channels and thus provides no information of common spectral bands. In this abstract, a method is presented to estimate the common spectral content in the different channels based on the circulant matrices of these channels. The spectrum is calculated from an augmented windowed circular matrix for which experiments show they give a better approximation to the common spectral components.	approximation;cholesky decomposition;circulant matrix;coefficient;discrete fourier transform;electroencephalography;experiment;frequency band;frequency response;magnetoencephalography;simulation;window function	Ronald Phlypo;Yves D'Asseler;Ignace Lemahieu	2007	2007 9th International Symposium on Signal Processing and Its Applications	10.1109/ISSPA.2007.4555547	mathematical optimization;combinatorics;discrete mathematics;eigenvalues and eigenvectors;circulant matrix;mathematics	Theory	82.15446575743067	-37.588151697693014	22110
c7f3c6ccb81d7ab6474a7d35e284acb7fbba696b	a universal virtual locomotion system: supporting generic redirected walking and dynamic passive haptics within legacy 3d graphics applications	surface structures;legacy 3d graphics applications universal virtual locomotion system redirected walking dynamic passive haptics large scale virtual environment motion compression virtual objects;generic redirected walking;virtual objects;legacy 3d graphics applications;legged locomotion;application software;computer graphics;motion compression;virtual realty;virtual reality;dynamic passive feedback virtual realty virtual locomotion interface generic redirected walking;navigation;large scale;shape;universal virtual locomotion system;virtual reality haptic interfaces;legged locomotion haptic interfaces navigation large scale systems virtual environment shape surface structures computer graphics application software computer science;computer science;dynamic passive feedback;virtual environment;haptic interfaces;large scale virtual environment;3d graphics;virtual locomotion interface;large scale systems;redirected walking;dynamic passive haptics	In this paper we introduce a virtual locomotion system that allows navigation within any large-scale virtual environment (VE) by real walking. In contrast to the work of Razzaque et al. (2001) we have developed generic redirected walking concepts by combining motion compression, i. e., scaling the real distance users walk, rotation gains, which make the real turns smaller or larger, and curvature gains, which bend the user's walking direction such that s/he walks on a curve. Furthermore, we introduce the new concept of dynamic passive haptics which extends passive haptics (Insko et al., 2001; Kohli et al., 2005) in such a way that any number of virtual objects can be sensed by means of real proxy objects having similar haptic capabilities, i. e., size, shape and surface structure. We have evaluated these concepts and explain technical details regarding their integration into legacy 3D graphics applications.	3d computer graphics;haptic technology;image scaling;passive optical network;redirected walking;virtual reality	Frank Steinicke;Timo Ropinski;Gerd Bruder;Klaus H. Hinrichs;Harald Frenz;Markus Lappe	2008	2008 IEEE Virtual Reality Conference	10.1109/VR.2008.4480806	computer vision;navigation;application software;simulation;shape;computer science;virtual machine;operating system;virtual reality;computer graphics;computer graphics (images)	Visualization	76.6616097248963	-27.894063210685616	22146
5a99362d0e20549bc650cabb9c2c0aa0d71757b9	reducing power and increasing accuracy of on-body sensing in motion capture application	biofeedback;signal separation;motion onbody sensing;journal article;assisted motor rehabilitation;motion capture application;motion capture system;human subjects;robot arm;power consumption requirements;principal component analysis body sensor networks;motion data;joint angles;human joint flexion extension motion;functional principal component analysis;onbody sensors;user movements;motion onbody sensing joint angles motion capture system human joint flexion extension motion robot arm human subjects signal separation functional principal component analysis motion data onbody sensors power consumption requirements user movements assisted motor rehabilitation biofeedback motion capture application	Abstract Motion capture coupled with on-body sensing and biofeedback are key enabling technologies for assisted motor rehabilitation. However, wearability, power efficiency and measurement repeatability remain the principle challenges that need to be addressed before widespread adoption of such systems becomes possible. The weight and the size of the on-body sensing system needs to be kept small, and the system should not interfere with the user’s movements or actions, but in general they are bulky due to their power consumption requirements. Furthermore, on-body sensors are very sensitive to positioning, which causes increased variability in the motion data. Isolating the characteristic patterns that represent the most important motion data affected by random positioning errors, while also reducing the power consumption, is our main concern. We consider an automated computational approach to address the two problems. We investigate the use of f-PCA for signal separation, whilst accounting for variability in the sensor position. In the designed experiments, we use human subjects and a robot arm to generate motion data, which is analogous to the human joint flexion-extension motion. The data are captured by an active marker-based motion capture system. As both the motion capture system and the robot arm are very accurate in their operation, we are able to introduce deliberate placement errors in a precisely controlled manner. The results are independent from the technology used to measure motion because we consider joint angles as variables in our analysis. The proposed approach can thus be applied to other motion capture systems. The proposed post-processing technique can compensate for uncertainties due to sensor positional changes, whilst allowing greater energy efficiency of the sensors, thus enabling improved flexibility and usability of on-body sensing.	computation;experiment;motion capture;performance per watt;principal component analysis;regular expression;repeatability;requirement;robotic arm;sampling (signal processing);sensor;signal processing;spatial variability;usability;video post-processing;while	Roya Haratian;Tijana Timotijevic;Chris Phillips	2016	IET Signal Processing	10.1049/iet-spr.2014.0496	control engineering;functional principal component analysis;computer vision;simulation;robotic arm;computer science;engineering	Robotics	71.70015805961246	-27.95309500040044	22167
bc25d2c31ac769cd786b866dc75d30329cb00fc7	determining fabrication orientations for rapid prototyping with stereolithography apparatus	computer aided design;layer by layer;computer model;machine outil;surface quality;surface texture;prototipo;set up orientation;rapid prototyping;conception assistee;machine tool;machine tools;prototype	Abstract   Traditionally, prototypes are built manually by skilled workers with the help of machine tools, which is very time consuming. The advent of rapid prototyping technology greatly eases the effort required for making prototypes. In this research we investigate geometric issues involved while using a particular rapid prototyping system, called Stereolithography Apparatus (SLA). SLA creates prototypes layer by layer, each layer being formed (solidified) by scanning a laser beam across the  x-y  surface of a vat of liquid monomer mix. In contrast to traditional methods, the planning of prototyping with SLA is done directly with the computer models of designed parts and requires little experience.  The performance of SLA is influenced by the orientation in which a design is fabricated. For example, sloped surfaces produced by the SLA process inherently have an undesirable stepped surface texture. Such surface texture can, however, be reduced by orienting as many faces as possible vertically or horizontally. This prompts us to establish decision criteria and develop algorithms—based on the considerations of surface quality, build time, and the complexity of support structure—for identifying desirable fabrication orientations for a given design.	rapid prototyping	Po-Ting Lan;Shuo-Yan Chou;Lin-Lin Chen;Douglas D. Gemmill	1997	Computer-Aided Design	10.1016/S0010-4485(96)00049-8	simulation;engineering;machine tool;computer aided design;engineering drawing;mechanical engineering	EDA	66.18747485088268	-38.43367731753512	22177
e89a661324778a5fed03b76a8909f3ce2691f76c	recovering 3-d motion and structure				Tarek M. Sobh	1994	Informatica (Slovenia)		distributed computing;computer science	Vision	60.68038070556603	-47.89341635385378	22213
b33873f69526ddaf83ade3edfbde395f3274388f	experimental evaluation of simple estimators for humanoid robots		This paper introduces and evaluates a family of new simple estimators to reconstruct the pose and velocity of the floating base. The estimation of the floating-base state is a critical challenge to whole-body control methods that rely on full-state information in high-rate feedback. Although the kinematics of grounded limbs may be used to estimate the pose and velocity of the body, modelling errors from ground irregularity, foot slip, and structural flexibilities limit the utility of estimation from kinematics alone. These difficulties have motivated the development of sensor fusion methods to augment body-mounted IMUs with kinematic measurements. Existing methods often rely on extended Kalman filtering, which lack convergence guarantees and may present difficulties in tuning. This paper proposes two new simplifications to the floating-base state estimation problem that make use of robust off-the-shelf orientation estimators to bootstrap development. Experiments for in-place balance and walking with the HRP-2 show that the simplifications yield results on par with the accuracy reported in the literature for other methods. As further benefits, the structure of the proposed estimators prevents divergence of the estimates, simplifies tuning, and admits efficient computation. These benefits are envisioned to help accelerate the development of baseline estimators in future humanoids.	baseline (configuration management);computation;control theory;coupling (computer programming);experiment;extended kalman filter;feedback;humanoid robotics project;humanoid robot;image noise;in-place algorithm;local convergence;rate of convergence;time complexity;velocity (software development);yaws	T. Flayols;Andrea Del Prete;P. Wensing;Alexis Mifsud;Mehdi Benallegue;Olivier Stasse	2017	2017 IEEE-RAS 17th International Conference on Humanoid Robotics (Humanoids)	10.1109/HUMANOIDS.2017.8246977	estimator;humanoid robot;control theory;simulation;computation;kalman filter;kinematics;sensor fusion;robot kinematics;convergence (routing);mathematics	Robotics	55.700514924349086	-37.872648414668696	22253
e59d49d42f0eedb49a7c4ea724b7d04c60f9cf0c	knot removal for b-spline curves	knot insertion;noeud topologique;geometrie algorithmique;degree of freedom;coaccion;computational geometry;contrainte;knot removal;b spline curve;discrete l2 approximationremes algorithm;nudo topologico;constraint;boundary constraint;boundary constraints;geometria computacional;b spline;remes algorithm;b splin;knot	Abstract   In this paper the problem of removing one inner knot from the knot sequence of a B-spline curve is discussed. Doing so, a local (geometric) construction of the new control points from the given ones is first introduced. Then the degrees of freedom appearing in this general construction are determined by minimizing three different norms between the old curve and the new curve. Here the best results are obtained by considering the local (continuous) min-max problem. This solution is based on a variant of the (second) algorithm of Remes.	b-spline;spline (mathematics)	Matthias Eck;Jan Hadenfeld	1995	Computer Aided Geometric Design	10.1016/0167-8396(94)00012-H	writhe;b-spline;mathematical optimization;topology;computational geometry;mathematics;geometry;degrees of freedom;constraint;knot	Graphics	69.15432481571209	-40.29310064664415	22399
276510e39a1bf7c4d527e2587bd02bc99216cfa1	extracting geometric models of muscles from the visible human data	medical simulation;human modelling;biological system modeling;computational geometry;muscle simulation;visual description;visible human data;joints;data mining;medical computing;data mining solid modeling muscles humans biological system modeling joints computational modeling computer simulation shape animation;computational modeling;shape;human body;solid modeling;realistic images medical computing computational geometry muscle digital simulation;animation;realistic images;feature based approach;geometric model;humans;geometric models;radiological data;realistic models geometric models muscle simulation visible human data human modelling feature based approach anatomical structures visual description medical simulation radiological data;computer simulation;digital simulation;muscle;anatomical structures;muscles;realistic models	Muscle simulation should be an important component of human modelling, but to date there have been few attempts to demonstrate muscle structures in an anatomically-correct way. This paper proposes a feature-based approach to muscle modelling which attempts to provide models for human musculature based on the real anatomical structures. These models provide a good visual description and form a sound basis for further developments towards medically-accurate simulation of human bodies. To allow for the wide variety of muscle shapes encountered in the body, the geometric models are based on muscle features identified from radiological data. These results are realistic models with correct anatomical structures.		Feng Dong;Gordon Clapworthy;Jialiang Yao;Meleagros A. Krokos	2000		10.1109/IV.2000.859782	computer vision;simulation;computer science;computer graphics (images)	Robotics	70.54207673269799	-46.61746317726569	22403
d8c10082caee2c2599642fea7e7dd20ebf6bbdf5	segmo: ct volume segmentation using a multi-level morse complex		Abstract The analysis of existing objects for developing new products is called reverse engineering and is a common process in industrial manufacturing. X-ray CT scanning is a powerful reverse-engineering tool that can acquire the entire geometry of an assembled object, including its inner structure, without disassembly. Before X-ray CT scanning can be used to accurately extract the parts of an assembled object from its CT volume, several challenges remain: CT artifacts, the non-uniqueness of the CT values, and limited resolution. Currently, an operator usually manually segments the target parts of the CT volume at voxel-level accuracy, which takes a long time. Hence, this paper proposes SegMo, a segmentation system which can perform segmentation of an assembled object to sub-voxel accuracy more quickly and with less effort than conventional methods. These advantages are achieved by suggesting the part boundary candidates that are coded as a hierarchical decomposition of the CT volume based on a Morse complex and polygonization at sub-voxel accuracy. SegMo consists of three steps: the generation of a hierarchical decomposition of a CT volume, segmentation using this hierarchy, and polygonization of the segmentation result. In this paper, we demonstrate how SegMo can achieve accurate and efficient segmentation on CT volumes of several complex assembled objects.		Yukie Nagai;Yutaka Ohtake;Hiromasa Suzuki	2019	Computer-Aided Design	10.1016/j.cad.2018.09.002	mathematical optimization;morse code;reverse engineering;computer vision;operator (computer programming);mathematics;segmentation;artificial intelligence	EDA	67.74660967401408	-43.18288812680638	22469
2b8ec9b4e0636df03351c604e81b7120a11a0c8e	a smoothed particle hydrodynamics algorithm for haptic rendering of dental filling materials	dentistry;kernel;virtual reality biomedical education computer based training dentistry further education graphics processing units haptic interfaces medical computing rendering computer graphics smoothed particle hydrodynamics smoothing methods;endnotes;force;adhesives;smoothing methods;graphics processing units;pubications;haptic interfaces;smoothing function smoothed particle hydrodynamics algorithm haptic rendering dental filling materials haptic interfaces skills training assistance undergraduate dentist curriculum advance rendering algorithm haptic device engineering sph filling material insertion training virtual dental cavity graphical processing unit gpu haptics control loop filling simulation cavity boundary;adhesives force haptic interfaces smoothing methods graphics processing units dentistry kernel	Using haptic interfaces to assist the training of skills in the curriculum of undergraduate dentists provides a unique opportunity to advance rendering algorithms and engineering of haptic devices. In this paper we use the dental context to explore a rendering technique called smoothed particle hydrodynamics (SPH) as a potential method to train the insertion of filling material into a previously prepared (virtual) dental cavity. The paper also considers how problems of haptic rendering might be implemented on a Graphical Processing Unit (GPU) that operates in the haptics control loop. The filling simulation used 3000 particles to represent the cavity boundary and filling material, running at an average of 447Hz. Novel smoothing function in SPH was developed and its flexibility is presented.		Brian Tse;Alastair Barrow;Barry F. A. Quinn;William S. Harwin	2015	2015 IEEE World Haptics Conference (WHC)	10.1109/WHC.2015.7177732	kernel;simulation;engineering;adhesive;multimedia;force;physics;computer graphics (images)	Visualization	70.90111188417339	-49.27756382301668	22488
ea94eea39e68fe5ffaf7070e866a1ca4e5b6ade3	bio-inspired motion vision for aerial course control		The visual system of the fly constitutes an ideal source of inspiration for technical deployment due to its high speed, precision and robustness. This interdisciplinary work focuses on neurobiological assessment, control oriented analysis, practical implementation and experimental evaluation of a biologically inspired motion sensor. This novel strategy exhibits substantial improvements over conventional approaches and thereby serves as a guidepost example of synergies between neurobiology and engineering.	aerial photography	Johannes Plett	2013			software deployment;robustness (computer science);control engineering;engineering	Robotics	66.27801253999084	-28.091904365079426	22576
e8bb00e823489aaec72e9e74dfd382ec0fcb53b4	modeling the surface swept by a generalized cutter for nc verification	forma libre;generateur balayage;machining;computer aided design;modele geometrique;trajectoire;cutting tools;free form;trajectories;outil coupe;forme libre;usinage;milling machines;conception assistee;generador barrido;fraiseuse;sweep generator;article;geometrical model;modelo geometrico	Presented in this article is a procedure for representing the cutterswept surface (CSS) of a generalized cutter in a single-valued form, ; =,f(x, v). The key idea is that the z-value of the CSS at a 2D point (x, y) is expressed as the sum of 1) the z-value at a point on the silhouette curve of the cutter bottom surface and 2) the incremental z-value along the cutter movement direction. Thus, the main part of the modeling method is to obtain the silhouette curvr equations. which becomes a root finding problem for a quartic polynomial (when the cutter bottom surface contains a toroidal surface). The proposed method not only renders a single-valued representation for the CSS of a generalized cutter (which was not possible with the existing methods) including rounded endmill but also results in a computational scheme that is faster than the existing schemes for balland flat endmills.	cascading style sheets;computation;cutter expansive classification;emoticon;polynomial;quartic function;rendering (computer graphics);root-finding algorithm;silhouette (clustering);toroidal graph	Yun C. Chung;Jung W. Park;Hayong Shin;Byoung Kyu Choi	1998	Computer-Aided Design	10.1016/S0010-4485(97)00033-X	simulation;machining;engineering;trajectory;computer aided design;geometry;engineering drawing;mechanical engineering	Graphics	68.23085372836456	-39.2983260179048	22640
85f35fde04c9be60826f08b97c58947e16dd3fb5	interactive simulation of virtual trees spray	spraying;vc virtual tree spray interactive simulation variable rate tree spraying precision agriculture particle system emitter position atomizing particle atomizing anger spray penetration depth 2 hierarchy collision detection algorithm;force;vegetation;computational modeling;spraying collision avoidance vegetation blades computational modeling force three dimensional displays;three dimensional displays;simulation variable rate spraying particle system controllable parameters collision detection;blades;spraying agriculture digital simulation interactive systems;collision avoidance	Variable-rate tree spraying is one of the most important technique of precision agriculture. This paper presented an interactive virtual tree spraying method based on particle system, which gain fine control flexible through parameters such as the emitter position and pitch angle, atomizing particle, atomizing anger and spray penetration depth. We proposed a 2-hierarchy collision detection algorithm to identify the leaves with dropping particles, which speed up the simulation for about 90%. Then, we implemented the prototype system using VC++ to carry out the precision of the spray as needed.	algorithm;collision detection;crown group;interaction;lambert's cosine law;minimum bounding box;motorola canopy;particle system;prototype;real-time clock;simulation	Hui Song;Ying Xu;Zhijie Li;Ding Lin	2015	2015 2nd IEEE International Conference on Spatial Data Mining and Geographical Knowledge Services (ICSDM)	10.1109/ICSDM.2015.7298046	simulation;computational model;force;vegetation	Robotics	72.91684719488886	-47.718614788572324	22659
40046c1759038cc4fa58a13f09a911a537e20627	a multi-sensor, cable-driven parallel manipulator based lower limb rehabilitation device : design and analysis. (analyse et conception d'un système de rééducation de membres inférieurs reposant sur un robot parallèle à câbles)		Gait analysis and human joint motion measurement has been studied extensively in the recent past. In order to address the effects of soft tissue artifacts (STA), a common source of error in most type of measurements, the standard procedure in gait analysis has been to use a combination of measurement methods for efficient estimation of joint angles and the body segment poses. This work proposes a gait analysis system based on a multi-sensor cable-driven parallel manipulator, focusing specifically on tracking the human knee. Our system assumes a human joint to be a general 6 DOF joint between 2 body segments. In order to measure pose of these body segments, up to 14 wires are attached to these human body segments and this permits the system to treat each of these body segments as the end-effector of a parallel mechanism. The pose of the body segments can thus be determined by measuring the wire lengths and solving the forward kinematics of this parallel architecture. The system is also equipped to use additional sensors including inertial sensors (accelerometers and gyroscopes), a 12 camera optical tracking system, inshoe pressure sensors, variable length resistive wires, IR distance sensors, force sensors to measure muscle contraction. A number of choices are available in the approach for analyzing the knee during gait activity and the design of the setup depends on these choices. This work discuses the options available and details how they have impacted the choices we make in developing the experimental setup. We discuss the hardware developed and used, and specifically discuss the flexible collar used to attach wires to the patient body and to hold the additional sensors. We treat the collar as a serial kinematic chain and propose a calibration method for it that, unlike commonly used calibration techniques, avoids using joint angle measurements. We then outline the experiment and the methods used to synchronize and fuse the data from all sensors to obtain a pose estimate for the collar and thus, the body segments. Finally, this work helps identify steps necessary to improve the current setup and lays the groundwork for a complete rehabilitation system.	forward kinematics;gait analysis;kinematic chain;parallel computing;parallel manipulator;robot end effector;sensor;tracking system	Mandar Harshe	2012				Robotics	59.66996539983798	-36.38870847646614	22689
079bbbf4c2e4b3f04c72e2b1ae74b4e0f5d5b055	an analysis of motion blending techniques		Motion blending is a widely used technique for character animation. The main idea is to blend similar motion examples according to blending weights, in order to synthesize new motions parameterizing high level characteristics of interest. We present in this paper an in-depth analysis and comparison of four motion blending techniques: Barycentric interpolation, Radial Basis Function, K-Nearest Neighbors and Inverse Blending optimization. Comparison metrics were designed to measure the performance across different motion categories on criteria including smoothness, parametric error and computation time. We have implemented each method in our character animation platform SmartBody and we present several visualization renderings that provide a window for gleaning insights into the underlying pros and cons of each method in an intuitive way.	alpha compositing;barycentric subdivision;comparison sort;computation;high-level programming language;interpolation;k-nearest neighbors algorithm;lagrange polynomial;mathematical optimization;radial (radio);radial basis function;time complexity	Andrew W. Feng;Yazhou Huang;Marcelo Kallmann;Ari Shapiro	2012		10.1007/978-3-642-34710-8_22	simulation;computer science;artificial intelligence;computer graphics (images)	Graphics	64.83564630321358	-46.1133434860998	22693
daaba94eb0b899c87ba06897e1cc7ab2746c5f47	torque-controlled lightweight arms and articulated hands: do we reach technological limits now?	lightweight robotics;international space station;robotersysteme;joint torque control;space robotics;institut fur robotik und mechatronik bis 2012;mechatronics;torque control	In this paper we briefly address DLR’s (German Aerospace Center) background in space robotics by hand of corresponding milestone projects including systems on the International Space Station. We then discuss the key technologies needed for the development of an artificial “robonaut” generation with mechatronic ultra-lightweight arms and multifingered hands. The third arm generation is nearly finished now, approaching the limits of what is technologically achievable today with respect to light weight and power losses. In a similar way DLR’s second generation of artificial four-fingered hands was a big step towards higher reliability, manipulability and overall	arm architecture;coat of arms;dynamic language runtime;mechatronics;robonaut;robotic spacecraft;robotics;torque	Gerd Hirzinger;Norbert Sporer;Markus Schedl;Jörg Butterfaß;Markus Grebenstein	2004	I. J. Robotics Res.	10.1177/0278364904042201	control engineering;simulation;mechatronics;international space station;engineering;mechanical engineering	Robotics	66.1029731609425	-28.218103214179198	22699
daeed7ac25e19e16b5510c0372e598adc8676277	influence of the number of humanoid vertebral column pitch joints in flexion movements	humanoid robot;robot kinematics couplings humanoid robots;joints pelvis legged locomotion acceleration thorax;humanoid robots;human body;couplings;sagittal plane humanoid vertebral column pitch joints flexion movements 2d humanoid robot simulations back bone pitch joints human like movements knee flexion object picking kid sized human body lumbar part thorax part;robot kinematics	This paper deals with 2D simulations of a humanoid robot equipped with back bone pitch joints to study the advantages of having such a mechanism for daily human-like movements. The movements under investigation here involve knee flexion for sitting down on a chair or picking up objects on the floor. The model used for the humanoid robot is based on a kid-sized human body. The trunk is decomposed into a thorax and a lumbar part. As the lumbar region is the most mobile part in the human vertebral column, vertebrae are only placed in the robots lumbar part. Simulations are carried out in the sagittal plane to investigate the influence of the number of vertebra pitch joint on the movements. Results show that a number of two pitch joints is a good tradeoff in matter of work at hip and thorax inclination.	computer simulation;experiment;humanoid robot;pitch (music);yaws	Mouna Souissi;Vincent Hugel;Pierre Blazevic	2011	The 5th International Conference on Automation, Robotics and Applications	10.1109/ICARA.2011.6144895	simulation;computer science;humanoid robot;artificial intelligence	Robotics	68.62397663666943	-24.52049752626249	22719
fa0297c69a0af8d8f4e11a9167239ec8b7bdd9cc	omni-directional person tracking on a flying robot using occlusion-robust ultra-wideband signals	clocks;mobile robots;distance measurement;robustness;target tracking;delays	We present a tracking system based on ultra-wideband (UWB) radio tranceivers mounted on a robot and a target. In comparison to typical UWB localization systems with fixed UWB tranceivers in the environment we only require instrumentation of the target with a single UWB tranceiver. Our system works in GPS-denied environments and does not suffer from long-term drift and limited fields of view. This paper reports the localization algorithm and implementation details. Additionally, we demonstrate a quantitative evaluation of the accuracy (10cm average position error for a square with side-length of 4m) and application scenarios with a quadrotor flying in close proximity to a person and handling occlusion of the target. Finally, we release our implementation as open-source software.	algorithm;global positioning system;mobile robot;open-source software;rejection sampling;robot;tracking system;transceiver;ultra-wideband	Benjamin Hepp;Tobias Naegeli;Otmar Hilliges	2016	2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)	10.1109/IROS.2016.7759054	mobile robot;embedded system;computer vision;simulation;computer science;engineering;robustness	Robotics	55.546520814728126	-36.805731733422206	22732
acfe6e04a6a7c2920cf9635d6789f866d9dd7dc9	mixture of attractors: a novel movement primitive representation for learning motor skills from demonstrations	robot kinematics;trajectory;convex functions;probability distribution;computational modeling	In this letter, we introduce Mixture of Attractors, a novel movement primitive representation that allows for learning complex object-relative movements. The movement primitive representation inherently supports multiple coordinate frames, enabling the system to generalize a skill to unseen object positions and orientations. In contrast to most other approaches, a skill is learned by solving a convex optimization problem. Therefore, the quality of the skill does not depend on a good initial estimate of parameters. The resulting movements are automatically smooth and can be of arbitrary shape. The approach is evaluated and compared to other movement primitive representations on data from the Omniglot handwriting dataset and on real demonstrations of a handwriting task. The evaluations show that the presented approach outperforms other state-of-the-art concepts in terms of generalization capabilities and accuracy.	convex optimization;hidden semi-markov model;moa;mpls-tp;mathematical optimization;optimization problem;smoothing	Simon Manschitz;Michael Gienger;Jens Kober;Jan Peters	2018	IEEE Robotics and Automation Letters	10.1109/LRA.2018.2792531	control engineering;machine learning;engineering;attractor;motor skill;artificial intelligence	Robotics	62.06006190225714	-25.189532989590745	22801
ade7aab4bf89c97ea7a33fc66a9d5d8ac0a607ae	skeleton extraction for tree models	laplacian contraction;curve skeleton;tree models;adaptive sampling;laser scanning;point cloud	The curve skeleton extraction for a given laser-scanned tree model plays an important role inmany virtual agricultural applications, such asmodelling, animation and growth simulation. To extract the curve skeletons of various tree models, which can capture the essential topology structures, a simple and robust algorithm based on point cloud contraction using constrained Laplacian smoothing is proposed. The adaptive sampling and post-processing steps designed for complex tree-like models can effectively reduce the computation time and reconstruct the correct curve skeleton from a contracted point cloud. The experimental results show that the curve skeletons extracted by this algorithm are faithful and smooth, and they can be well utilized in many fields. © 2010 Elsevier Ltd. All rights reserved.	adaptive sampling;algorithm;computation;laplacian smoothing;point cloud;sampling (signal processing);simulation;time complexity;video post-processing	Zhixun Su;Yuandi Zhao;Chunjiang Zhao;Xinyu Guo;Zhiyang Li	2011	Mathematical and Computer Modelling	10.1016/j.mcm.2010.11.043	laser scanning;mathematical optimization;combinatorics;point cloud;mathematics;geometry	AI	67.7201002109692	-44.649962340673206	22992
f15431af5e61e51fafdd9c4ac45bcaaad5c3018c	a comparison of fractal dimension estimators based on multiple surface generation algorithms	computadora;tratamiento datos;computers;filtering;errors;filtrage;fractals;desviacion tipica;erreur;probability;coeficiente correlacion;generic algorithm;cizalladura;ordinateur;brownian motion;standard deviation;root mean square error;deplacement;geometry;fractal brownian motion;fractal geometry;data processing;geometrie;traitement donnee;algorithme;fractal dimension;probabilidad;variogramme;probabilite;ecart type;fractal;algorithms;fractal dimension estimator;geometria;error;correlation coefficient;dimension fractale;shear;coefficient correlation;surface generation algorithms;fractal analysis;displacements;variograms;algoritmo;cisaillement	Fractal geometry has been actively researched in a variety of disciplines. The essential concept of fractal analysis is fractal dimension. It is easy to compute the fractal dimension of truly self-similar objects. Difficulties arise, however, when we try to compute the fractal dimension of surfaces that are not strictly self-similar. A number of fractal surface dimension estimators have been developed. However, different estimators lead to different results. In this paper, we compared five fractal surface dimension estimators (triangular prism, isarithm, variogram, probability, and variation) using surfaces generated from three surface generation algorithms (shear displacement, Fourier filtering, and midpoint displacement). We found that in terms of the standard deviations and the root mean square errors, the triangular prism and isarithm estimators perform the best among the five methods studied.	algorithm;fractal dimension	Guiyun Zhou;Nina S.-N. Lam	2005	Computers & Geosciences	10.1016/j.cageo.2005.03.016	t-square;multifractal system;correlation dimension;combinatorics;mathematical analysis;fractal derivative;self-affinity;fractal;data processing;effective dimension;fractal dimension on networks;fractal analysis;h tree;fractal landscape;mathematics;geometry;fractal dimension;minkowski–bouligand dimension;statistics	Vision	76.66450496722112	-49.254895985959145	23021
3b293d785a2a983a2fea1aa9d212e027e477ee33	autonomous control of flapping wing vehicles using graphical user interface	vision system image processing embedded system maltab gui ornithopters;aerial robots autonomous flapping wing vehicle control fwvs software units complex motion characteristics graphical user interface gui vision based computer control interface matrix laboratory matlab yaw control real time altitude control simulation tests proteus simulator color based control algorithm system software modules;real time systems graphical user interfaces image color analysis vehicles matlab navigation cameras;navigation;graphical user interfaces;image color analysis;vehicles;matlab;cameras;spatial variables control aerospace components aerospace computing aerospace robotics autonomous aerial vehicles control engineering computing graphical user interfaces image colour analysis mathematics computing object detection robot vision;real time systems	Autonomous control of Flapping Wing Vehicles (FWVs) through sophisticated software units is challenging due to its inherent complex motion characteristics. This article emphasize on the development of graphical user interface (GUI) for the control of FWVs to achieve superior maneuverability. A vision based computer control interface is developed for manual as well as autonomous performance of FWVs using Matrix Laboratory (MATLAB). In order to accomplish the real time altitude and yaw control of FMVs, a color detection algorithm is established. Simulation tests are carried out interfacing MATLAB GUI with proteus simulator. The color based control algorithm is tested in our lab environment and proven to be consistent. The proposed control interface serves as an effective solution towards interfacing aerial robots with system software modules.	aerial photography;algorithm;autonomous robot;computer control company;graphical user interface;matlab;proteus;simulation;yaws	S. Sankarasrinivasan;E. Balasubramanian;L. J. Yang;F. Y. Hsiao	2015	2015 International Conference on Advances in Computing, Communications and Informatics (ICACCI)	10.1109/ICACCI.2015.7275946	embedded system;computer vision;navigation;simulation;computer science;engineering;graphical user interface;user interface;graphical user interface testing	Robotics	64.19201964310479	-30.34030553555579	23037
e2e40dc2c71d32ff767640ef80292ce6d938e9ac	hybrid ray tracing - ray tracing using gpu-accelerated image-space methods	shadow mapping;parallel rendering;cluster computing;computational reflection;visual quality;ray tracing;graphic processing unit;interactive ray tracing;ray casting	In recent years, interactive ray tracing has become a reality, although mainly by using clustered workstations and sophisticated acceleration structures. On non-clustered computer architectures this is still not an easy task, especially when rendering animated scenes, even though the computation power of modern workstations is increasing rapidly. In this paper we propose known image-space rendering techniques to be used for accelerating ray tracing. Firstly, we describe a GPU-based visibility preprocessing algorithm to perform interactive ray casting by applying the standard depth testing capability of graphics processing units. This method – called object intersection buffer (OIB) – is particularly suitable for ray casting animated scenes, as it completely avoids the necessity of creating and updating any kind of spatial acceleration structures in order to achieve high frame rates. Then we integrate shadow rendering into our ray caster using the shadow mapping technique to avoid computationally expensive shadow rays. Then, we convert our GPU-based ray caster into a hybrid ray tracer by computing reflection and refraction rays on the CPU using a spatial acceleration structure. This allows us to exploit parallel rendering to increase the overall frame rate. Finally, we compare our implementations to each other and analyse their advantages and disadvantages in terms of visual quality and rendering performance.	algorithm;analysis of algorithms;central processing unit;computation;computer architecture;computer graphics;graphics hardware;graphics processing unit;parallel rendering;preprocessor;ray casting;ray tracing (graphics);rendering (computer graphics);shadow mapping;workstation;z-buffering	Philippe C. D. Robert;Severin Schoepke;Hanspeter Bieri	2007			cone tracing;distributed ray tracing;ray tracing;computer vision;computer cluster;computer science;parallel rendering;ray casting;shadow mapping;beam tracing;computer graphics (images)	Graphics	67.14100665780363	-51.876386064832126	23046
7832c367af52313d6f8468c8282767dfc5ef1de2	real-time pose estimation on elevation maps for wheeled vehicles		Fast and accurate obstacle detection is a crucial component for autonomous robot navigation. It becomes even more important for a shared control vehicle like an electric wheeled walker, since the safety of the vehicle and the user depend on the correct classification of obstacles. This work describes a method for pose estimation of four-wheeled vehicles, which utilizes the fixed resolution of digital elevation maps to generate a detailed vehicle model. The vehicle's wheels are also approximated using digital elevation maps, allowing efficient calculation of wheel to ground contact points and therefore fast and accurate estimation of valid vehicle poses. To evaluate the proposed method, pose estimates are compared to three datasets including ground truth poses: one created using an external tracking system and two created by simulations of wheeled robots. It is also shown that the method is fast enough for real time operation.	3d pose estimation;amiga walker;angularjs;approximation algorithm;autonomous robot;chassis;ground truth;map;real-time clock;real-time computing;real-time transcription;robotic mapping;simulation;tracking system;wheels	Julian Jordan;Andreas Zell	2017	2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)	10.1109/IROS.2017.8202311	robot;computer vision;elevation;control engineering;artificial intelligence;computer science;pose;ground truth;obstacle;autonomous robot;tracking system	Robotics	54.03543460797032	-36.68189426007974	23083
1c6349f49a8a808b4b645c08389b235dfb48ae6d	multispectral panoramic mosaicing	mosaicing;least squares estimation;geometric hashing;multispectral mosaicing;fast algorithm;least squares estimate;image mosaicing	Image mosaicing overcomes the limitations of a camera’s limited field of view by aligning and pasting frames in video sequences. We introduce the concept of multispectral mosaicing. The information from IR and visual images is directly fused at the pixel level so that subsequent operations can be carried out using the fused image instead of the individual sensor images. We develop a geometric relationship between a visual band and IR band panoramic mosaic. Our system uses a fast algorithm for automatic construction of panoramic mosaic. We show results of inter-band mosaic superposition in support of the proposed strategies.	algorithm;multispectral image;ncsa mosaic;pixel	Udhav Bhosle;Sumantra Dutta Roy;Subhasis Chaudhuri	2005	Pattern Recognition Letters	10.1016/j.patrec.2004.08.007	computer vision;computer science;machine learning;mathematics;least squares;statistics	Vision	55.29042874769608	-48.618288824567266	23163
9e73593ea5f662b0438f14cd55301920bcd27ff6	emulation of electronic instrumentation devices supporting sailboat's autonomous navigation		In this paper it is shown a system for the emulation of electronic instrumentation devices used in a sailboat (a scale model) capable of sailing autonomously. The emulated devices are a wind vane sensor, a compass sensor and a GPS receiver, that allow the laboratory recreation of sailing conditions through the communication protocols involved. The emulation system, implemented with an Arduino board, is also capable of acquiring sensor data when in a real world scenario for a later indoor reproduction (emulation), being also interconnected with a computer program that allows the analysis of the taken path as well defining new sailing routes to perform. The emulation system also provides support to validate inside the lab different control strategies for specific navigation situations (as far as only the wind vane can be manually adjusted, as GPS receiver does not properly work inside the laboratory, as well as the electronic compass cannot be fully cheated).	arduino;assisted gps;autonomous robot;communications protocol;computer program;emulator;global positioning system	Hugo Marques;Luís Gomes;Anikó Costa	2017	2017 IEEE 26th International Symposium on Industrial Electronics (ISIE)	10.1109/ISIE.2017.8001425	communications protocol;control theory;arduino;engineering;simulation;computer program;global positioning system;emulation;compass;embedded system;assisted gps;instrumentation	Embedded	58.11811022997501	-28.46294382628135	23210
7181840adb5eae0d8fc1a7194c8b28ac3e400e88	optimal coverage trajectories for a ugv with tradeoffs for energy and time	area coverage;optimal control;energy usage;unmanned ground vehicles	Area coverage is a common task for an unmanned ground vehicle (UGV) that requires time and energy to complete. We have developed a novel cost function that can be used to optimally traverse a path that covers a region. The UGV model and cost function are developed theoretically and verified experimentally. Our cost function weights force inputs, area covered and motor efficiency to create an optimal trajectory. This trajectory is constrained to follow a coverage path described in the literature. The path is modified based on the cost function by replacing turn-in-place maneuvers by moving turns. Tradeoffs are presented for three cases: (1) drive motor efficiency is not considered, (2) the motors are most efficient at the maximum velocity, and (3) the motors are most efficient below the maximum velocity. Optimality tradeoffs include the time required to cover the region, and the energy required to complete the trajectory. Experimental results using an iRobot Packbot are presented.		John A. Broderick;Dawn M. Tilbury;Ella M. Atkins	2014	Auton. Robots	10.1007/s10514-013-9348-x	simulation;optimal control	Robotics	54.78177631240281	-24.949948730558866	23223
f266e8351faa670452a04f73418e0d0b85a871d5	procedural modeling of architecture	procedural modeling	We combine image-based capturing and rendering with procedural modeling techniques to allow the creation of novel structures in the style of real-world structures. Starting with a simple model recovered from a sparse image set, the model is divided into feature regions, such as doorways, windows, and brick. These feature regions essentially comprise a mapping from model space to image space, and can be recombined to texture a novel model. Procedural rules for the growth and reorganization of the model are automatically derived to allow for very fast editing and design. Further, the redundancies marked by the feature labeling can be used to perform automatic occlusion replacement and color equalization in the finished scene, which is rendered using view-dependent texture mapping on standard graphics hardware. Results using four captured scenes show that a great variety of novel structures can be created very quickly once a captured scene is available, and rendered with a degree of realism comparable to the original scene.	brick (electronics);crossover (genetic algorithm);graphics hardware;microsoft windows;procedural modeling;procedural programming;rendering (computer graphics);sparse matrix;texture mapping	Peter Wonka	2006		10.1145/1185657.1185713	computer science;procedural modeling	Graphics	65.29021086269024	-48.28566709508825	23251
9ebc3fab4ccc30c7dc09a7985e5f194eefc2f90b	instrumented compliant wrist with proximity and contact sensing for close robot interaction control	compliance;contact;pose estimation;proximity;robot control;surface following;touch sensing	Compliance has been exploited in various forms in robotic systems to allow rigid mechanisms to come into contact with fragile objects, or with complex shapes that cannot be accurately modeled. Force feedback control has been the classical approach for providing compliance in robotic systems. However, by integrating other forms of instrumentation with compliance into a single device, it is possible to extend close monitoring of nearby objects before and after contact occurs. As a result, safer and smoother robot control can be achieved both while approaching and while touching surfaces. This paper presents the design and extensive experimental evaluation of a versatile, lightweight, and low-cost instrumented compliant wrist mechanism which can be mounted on any rigid robotic manipulator in order to introduce a layer of compliance while providing the controller with extra sensing signals during close interaction with an object's surface. Arrays of embedded range sensors provide real-time measurements on the position and orientation of surfaces, either located in proximity or in contact with the robot's end-effector, which permits close guidance of its operation. Calibration procedures are formulated to overcome inter-sensor variability and achieve the highest available resolution. A versatile solution is created by embedding all signal processing, while wireless transmission connects the device to any industrial robot's controller to support path control. Experimental work demonstrates the device's physical compliance as well as the stability and accuracy of the device outputs. Primary applications of the proposed instrumented compliant wrist include smooth surface following in manufacturing, inspection, and safe human-robot interaction.	compliance behavior;control system;controllers;drug vehicle;embedding;execution;feedback;heart rate variability;human–robot interaction;industrial robot;instrumentation (attribute);interface device component;license;modal logic;muscle rigidity;numerous;physical object;programming languages;programming language;real-time clock;refinement (computing);robot (device);robot control;robot end effector;signal processing;wrist;millimeter;multiplicity;sensor (device)	Pascal Laferriere;Pierre Payeur	2017		10.3390/s17061384	industrial robot;calibration;engineering;signal processing;robot control;control theory;haptic technology;embedded system;control engineering;pose;instrumentation	Robotics	73.47896681216484	-26.65416829532464	23259
14e2e3192f36f1e03c9b1c2ad92df581a22a752e	uav target tracking using an adversarial iterative prediction	automatic control;cost function;adversarial iterative prediction;visibility maximisation;prediction algorithms;remotely operated vehicles;iterative methods;distance measurement;obstacle avoidance;unmanned aerial vehicles target tracking robots iterative methods optimization methods robotics and automation predictive models aircraft navigation helicopters automatic control;unmanned aerial vehicles uav target tracking adversarial iterative prediction fixed wing uav pursuit evasion strategy obstacle avoidance visibility maximisation stealthy motions;roads;target tracking collision avoidance iterative methods remotely operated vehicles;uav target tracking;robots;stealthy motions;predictive models;collision avoidance;atmospheric modeling;target tracking;iteration method;visual tracking;unmanned aerial vehicles;fixed wing uav;helicopters;robotics and automation;pursuit evasion strategy;control strategy;optimization methods;aircraft navigation	We present a control strategy that permits a fixed wing UAV to visually track a ground target. A pursuit-evasion strategy aims at optimizing the visibility of the pursuer UAV after having predicted the best action for the evading target. This is achieved by using two iterative methods that optimise various mission based criteria: obstacle avoidance and visibility maximisation for the UAV and stealthy motions for the target.	control theory;evasion (network security);iterative method;obstacle avoidance;pursuit-evasion;unmanned aerial vehicle	Panagiotis Theodorakopoulos;Simon Lacroix	2009	2009 IEEE International Conference on Robotics and Automation	10.1109/ROBOT.2009.5152332	control engineering;computer vision;simulation;computer science;engineering;artificial intelligence;automatic control;iterative method	Robotics	54.812338536393526	-25.730148874004843	23274
1d875f42c113a894b789da4b5094ba0a135bd046	accuracy analysis for robotized assembly system		Robotized assembly with high precision is increasingly required in critical applications for high-end products. Considering the complexity of a robotized assembly system, a systematic analysis of the error chain is important to assess the success of an assembly case and to propose a proper assembly strategy. In this paper, a robotized assembly system is studied by defining the key problems, identifying the key consisting, and addressing the key procedures. In particular, this paper proposes an assembly accuracy analysis model for analyzing the error chain of misalignment, which provides a system level assembly accuracy estimation and strategy planning. A practical case is studied with the proposed accuracy analysis method, which is further verified via assembly experiments.	best, worst and average case;experiment;key management	Feifei Zhao;Hao Gu;Cheng Li;Chan-juan Chen	2017	2017 IEEE International Conference on Robotics and Biomimetics (ROBIO)	10.1109/ROBIO.2017.8324688	control engineering;chain of events (aeronautics);strategic planning;robot kinematics;engineering	Robotics	65.04721285936128	-33.25198777960214	23405
de0a9649a9cc71e540fde3cf50b411bc11ed51e7	a flexible capacitive tactile sensor array with micro structure for robotic application	it software telecommunications;柔软;tactile sensor;flexible;微针;industry sectorselectronics;capacitive sensor;journal;触觉传感;capacitive sensor flexible tactile sensor micro needle bionic robot;光电子学;bionic robot;micro needle;电容检测;智能机器人	A flexible capacitive tactile sensor array with micro needle structure is proposed in this paper for robotic application. Micro needle layer made of polydimethylsiloxane (PDMS) is sandwiched between the upper electrode layer made of PDMS and the bottom electrode layer fabricated on polyester (PET) film. The PDMS material renders the device adequate flexibility as it can be rolled into a cylinder. The single cell size in the fabricated 4 × 4 sensors array is 0.7 × 0.5 cm2 and the initial capacitance of each cell is 0.86 pF. The fabricated cell shows a sensitivity of 3.26%/mN within the full scale range of 1 kPa. The micro needle structure gives better repeatability and stability. The maximum error during each measurement is about 3.2%, while the minimum error is about 1.2%. 面向机器人触觉恢复的广大市场需求, 本文提出了一种具有微针结构的柔性触觉传感器. 微针结构作为电介质层, 被夹在上下电极层之间, 形成平行板电容. 微针采用PDMS(聚二甲基硅氧烷)材料, 以保障器件的柔软性和可伸缩性. 微针结构的使用增加了器件的稳定性, 延长了器件的使用寿命. 在制成的4 × 4 检测阵列中, 单个检测单元大小为0.7 cm × 0.5 cm, 电容初值为0.86 pF. 经多次压按测试, 结果显示该阵列的测量范围为1 kPa, 检测精度为3.26 %/mN. 相同压力在多次检测中, 最大输出偏移为3.2%, 最小为1.2%.	bump mapping;cylinder seal;full scale;pdms;polyethylene terephthalate;rendering (computer graphics);repeatability;robot;tactile sensor	Xiaohui Hu;Xin Zhang;Ming Liu;Yuanfang Chen;Peng Li;Weihua Pei;Chun Zhang;Hongda Chen	2014	Science China Information Sciences	10.1007/s11432-014-5191-8	embedded system;computer science;capacitive sensing;tactile sensor	Robotics	77.04504281214045	-25.045542753056882	23475
ce1f4b97657ae4030a24830d7ca0ea53fc986008	realistic video avatar	video signal processing;multimedia computing;conferencing applications;virtual reality;virtual environment;user interfaces;computer animation;photorealistic avatar;realistic images;dynamic video texture map;realistic video avatar;teleconferencing;3d mesh model;image texture;feature points;mpeg-4;facial expressions;geometrical optics;texture mapping;spatial interpolation;facial animation;videoconference;mpeg 4;facial expression;geometry;interpolation;head	In this paper, we present a system for the implementation of a photorealistic avatar using video captured from a user . This is achieved by constructing the dynamic video texture map and combining it with the 3D mesh model of the user to render the photorealistic avatar. The dynamic video texture map reflects the user’s facial expressions and is generated by composing the cylindrical texture map of the user with constant updates either directly from the input video or derived from a temporal and spatial interpolation scheme. To derive the 3D mesh model for the user, we define feature points on a generic model and use the feature points identified on the video sequence to deform and obtain the avatar model. The goal of this realistic video avatar project is to provide a vivid representation of participants with a more realistic quality avatar, as compared to using only the facial animation parameters defined in MPEG-4 without the corresponding image updates. This scheme is suitable for conferencing applications because it requires much lower bandwidth than live video, and yet provides a 3D avatar representation for any virtual environment.	3d computer graphics;bandwidth (signal processing);graphics pipeline;multivariate interpolation;texture mapping;virtual reality	Wing Ho Leung;Belle L. Tseng;Zon-Yin Shae;Ferdinand Hendriks;Tsuhan Chen	2000			image texture;texture mapping;computer vision;teleconference;computer facial animation;computer science;virtual machine;operating system;identicon;virtual reality;computer animation;multimedia;multivariate interpolation;user interface;facial expression;computer graphics (images)	Graphics	65.10091742405004	-49.13446642433403	23532
0875181eb3fce46f7df317f68d2927b9e6e307e0	signal waveform reconstruction from noisy bispectrum estimations pre-processed by vector filters	fluctuation error vector filters signal waveform reconstruction noisy bispectrum estimations snr vector filter application 2d complex valued bispectrum processing computer simulations;spectral analysis signal reconstruction filtering theory;system performance;filters biomedical signal processing telephony application software radar signal processing image reconstruction radio transmitters aerospace electronics laboratories system performance;output error;signal reconstruction;spectral analysis;computer simulation;filtering theory	The reconstruction of 1-D signal waveform from noisy bispectrum estimations in case of a limited ensemble realization number and low input SNRs leads to considerable output errors. In order to improve the signal bispectrum estimations we propose to smooth the obtained bispectrum estimations. The methods based on vector filter application to 2-D complex valued bispectrum processing are considered in this paper. The influence of input SNR, the filter type and the used norm selection on signal reconstruction system performance is analyzed using computer simulations. It is shown that the proposed methods decreases both fluctuation error and bias of reconstructed signal.	bispectrum;waveform	Vladimir V. Lukin;Alexander V. Totsky;Andrey A. Kurekin;Igor V. Kurbatov;Jaakko Astola;Karen O. Egiazarian	2003		10.1109/ISSPA.2003.1224842	computer simulation;bispectrum;signal reconstruction;speech recognition;computer science;statistics	Theory	82.88892138955498	-32.539722995144075	23540
72639157ac34ad6e79f938e5aa00ee082277172f	applications of complex augmented kernels to wind profile prediction	wind prediction complex augmented kernels;complex signal processing;kernel;support vector machines;wind series time prediction;kernel wind forecasting signal processing algorithms zirconium least squares methods biomedical signal processing wind turbines wind speed renewable energy resources wind energy;wind power;prediction algorithms;wind prediction;time series;nonlinear algorithms;wind profile prediction;wind forecasting;power engineering computing;complex data;prediction theory;ieee;signal processing;least square;complex augmented kernels;kernel method;support vector machine;correlation;signal processing algorithms;dual space;least squares kernel algorithms;support vector machine complex augmented kernels wind profile prediction complex signal processing least squares kernel algorithms nonlinear algorithms wind series time prediction;wind power power engineering computing prediction theory signal processing support vector machines time series	This paper combines complex signal processing with kernel methods for applications in wind prediction. Specifically, we consider developing least squares kernel algorithms for both complex data and augmented complex data. The augmented complex kernel algorithms have advantages over complex kernel algorithms in both the areas of performance and complexity. Use of kernels also allow implementation of nonlinear algorithms by working in the dual space. We apply our algorithm to wind series time prediction and show that our augmented complex algorithms outperform other complex least square algorithms.	algorithm;augmented reality;kernel (operating system);kernel method;least squares;nonlinear system;signal processing	Anthony Kuh;Danilo P. Mandic	2009	2009 IEEE International Conference on Acoustics, Speech and Signal Processing	10.1109/ICASSP.2009.4960400	support vector machine;mathematical optimization;computer science;theoretical computer science;machine learning;signal processing;mathematics;statistics	Robotics	78.61852492414586	-36.61118982224551	23625
d0f0eb5c6f04d030f6db82efe02e32d4d69ff247	artist material brdf database for computer graphics rendering	optics;justin c;computer science artist material brdf database for computer graphics rendering rochester institute of technology roy s berns ashbaugh;design	The primary goal of this thesis was to create a physical library of artist material samples. This collection provides necessary data for the development of a gonio-imaging system for use in museums to more accurately document their collections. A sample set was produced consisting of 25 panels and containing nearly 600 unique samples. Selected materials are representative of those commonly used by artists both past and present. These take into account the variability in visual appearance resulting from the materials and application techniques used. Five attributes of variability were identified including medium, color, substrate, application technique and overcoat. Combinations of these attributes were selected based on those commonly observed in museum collections and suggested by surveying experts in the field. For each sample material, image data is collected and used to measure an average bi-directional reflectance distribution function (BRDF). The results are available as a public-domain image and optical database of artist materials at art-si.org. Additionally, the database includes specifications for each sample along with other information useful for computer graphics rendering such as the rectified sample images and normal maps.	bidirectional reflectance distribution function;computer graphics;map;normal mapping;pixel;raw image format;rendering (computer graphics);spatial variability	Justin C. Ashbaugh;Roy S. Berns;Benjamin A. Darling;Lawrence A. Taplin	2009			design;human–computer interaction;computer science;3d computer graphics;computer graphics (images)	Graphics	61.512609848950454	-51.59374106081938	23676
0d0034cb154f2beef7baa23d084d1bd47ec24019	geometry and kinematics of the mecanum wheel	concepcion asistida;computer aided design;cinematica;parameterization;problema inverso;kinematics;parametrizacion;forward kinematics;inverse problem;toro;torus;mecanum wheel;tore;cinematique;conception assistee;inverse kinematics;probleme inverse;parametrisation;probleme direct;problema directo;direct problem	Mecanum wheels are used when omnidirectional movability of a vehicle is desired. That means that the vehicle can move along a prescribed path and at the same time rotate arbitrarily around its center. A Mecanum wheel consists of a set of rolls arranged around the wheel axis. In this paper we describe in detail the geometry of these rolls. We derive simple canonical parameterizations of the roll generating curve and the roll surface itself. These parametric representations reveal the geometry of the roll. With their help we can easily find an approximation of the roll surface by a torus for manufacture purposes. Based on the roll parametrization we study the kinematics of a vehicle featured with Mecanum wheels.	(formerly pro/engineer);angularjs;approximation;computer-aided design;geometric analysis;nortel meridian;velocity (software development);wheels;xfig	Anton Gfrerrer	2008	Computer Aided Geometric Design	10.1016/j.cagd.2008.07.008	mecanum wheel;parametrization;kinematics;inverse problem;torus;computer aided design;inverse kinematics;control theory;mathematics;geometry;forward kinematics	Robotics	68.22035759427727	-38.950566305176324	23677
0dcfea11a390b066095d30b94736a566dc19f7f6	research of integration simulation system of space dual-arm robot	mission planning integration simulation system modular design concept communication module task scheduling management module path planning module dynamic control module 3d geometric model collision detection module c programming language visual studio 2010 entity model simulation scenarios osg open scene graph closed loop control coordinated space dual arm robot;visual programming aerospace robotics c language closed loop systems collision avoidance control engineering computing digital simulation manipulators;solid modeling robot kinematics collision avoidance path planning planning mathematical model	A set of integrated simulation system of space dual-arm robot is developed in the paper. Based on modular design concept, the system is composed of the communication module, task scheduling management module, path planning module, dynamic control module, 3D geometric model and collision detection module and the system uses C programming language and Visual Studio 2010 to realize the key algorithm while the entity model and the simulation scenarios are created by OSG (Open Scene Graph). Compared with other simulation methods, this method is stronger in visualization and post-processing, which can also realize closed-loop control of the key algorithm. Finally, the application simulations are implemented to verify the algorithms of coordinated space dual-arm robot by using this system. The results show the effectiveness of the system and verify the feasibility of mission planning.	robot;simulation	Xiaodong Zhang;Yafang Liu;Yaobing Wang	2015		10.1109/ROBIO.2015.7419028	control engineering;computer vision;simulation;computer science	Robotics	64.87831328498841	-29.656050956957003	23738
5b5d7495ca0a75a1b1f31ccbd6b7bc3987755f14	dynamic modelling and adaptive traction control for mobile robots	rigid body;mobile robot;path planning;motion control	Mobile robots have been used in many application such as moving material between work stations. They can also be found in many areas such as industrial, medical, environmental and even domestic machines. Research on mobile robots has mounted and attracted so much attention in recent years since they are increasingly used in wide range of applications (Albagul, 2001); (Karam & Albagul, 1998); (DeSantis, 1995); (Yutaka & Yuta, 1988). At the beginning, most of research have been directed to the use of kinematic models of the mobile robots to achieve and accomplished the motion control (DeSantis, 1995); (Yutaka & Yuta, 1988); (Nelson & Cox, 1988). Later on, the research has taken another approach and has focused on robots with additional sensory system to develop autonomous guidance path planning systems (Nelson & Cox, 1988). This direction has led to produce sophisticated sensory systems that can learn about the operating environment and hence evaluating path constraints to the path planning objective itself (Wilfong, 1988). However, some research has also addressed some topics related to dynamic characteristics of the motion which are essential to path tracking objective. Shiller (Shiller, 1991) has studied the problem of computing suitable trajectories in the face of varying terrain topography and under road holding constraints. The problems of road handling and traction become very important when the robot is subjected to dynamic variations. These variations include changes in robot inertia and centre of gravity which caused by the variable carrying load. The changes in the terrain topography, texture or in wheel properties due to wear, contamination or deformation play a major role in the robot motion. These variations can easily affect the traction properties and hence the robot movement and may cause slippage to occur. Therefore, it is very important for the robot to be able to avoid slippage and handle is consequences. This requires some learning mechanism which will try to adapt the trajectory planning strategy to cope with any condition. This paper presents the work that has been done to explore the issue of dynamic modelling and motion control under varying loading conditions. This leads to the development of a dynamic model for a three wheeled mobile robot structure (Albagul, 2001); (Karam & Albagul, 1998). The model includes the capability for representing any shape of cart with variable density to accommodate any changes in the robot structure. The motion dynamic for the robot can be achieved by applying a number of forces acting at any point and in any direction. In fact, this model is not restricted to wheeled robot. It can be used to obtain general free body motion dynamics. For the purpose of this work, the motive forces driving the robot are exerted by two independent DC motors each	automated planning and scheduling;autonomous robot;mathematical model;mobile robot;motion planning;operating environment;terrain rendering;topography;traction teampage;yutaka yamamoto (mathematician)	A. Albagul;Wahyudi	2004	CoRR		robot control	Robotics	66.45727055077329	-25.67261878749689	23836
67b0d347a1eb079f7ce594b60509a6e1dcc6a008	fpga-based controller for a mobile robot	mobile robot;rapid prototyping	With application in the robotics and automation, more and more it becomes necessary the development of applications based on methodologies that facilitate future modifications, updates and enhancements in the original projected system. This project presents a conception of mobile robots using rapid prototyping, distributing the several control actions in growing levels of complexity and computing proposal oriented to embed systems implementation. This kind of controller can be tested on different platform representing the mobile robots using reprogrammable logic components (FPGA). This mobile robot will detect obstacle and also be able to control the speed. Different modules will be Actuators, Sensors, wireless transmission. All this modules will be interfaced using FPGA controller. I would like to construct a mechanically simple robot model, which can measure the distance from obstacle with the aid of sensor and accordingly should able to control the speed of motor. I would like to construct a mechanically simple robot model, which can measure the distance from obstacle with the aid of sensor and accordingly should able to control the speed of motor.	field-programmable gate array;mobile robot;rapid prototyping;robotics;sensor	Shilpa Kale;S. S. Shriramwar	2009	CoRR		control engineering;mobile robot;embedded system;simulation;computer science;engineering;artificial intelligence;social robot	Robotics	60.45901054152142	-28.45622273041757	23956
af853684719f11c4cb1c8a909f749631d0bdefcb	flexo-glove: a 3d printed soft exoskeleton robotic glove for impaired hand rehabilitation and assistance		This paper presents a compact and streamlined design of a soft exoskeleton glove for assistance in activities of daily livings and also rehabilitation purposes of patients with hand function impairment. Most of the existing hand exoskeletons have focused on either providing a customizable and modular design or making it portable to be used outside the hospital environment. We have developed a design of an exoskeleton glove that combines both of these features in one compact design. This was achieved by using a parameterised CAD design of glove, 3D printing of soft (i.e., compliant) materials, design a bidirectional cable driven spooling system and integrating them together in a modular fashion. The overall weight of the Flexo-glove is 330g including battery and is able to provide 22N pinch force, 48N power grasp force and object grasp size of up to 81mm in diameter. The device has two control modes: intention-sensing via wireless sEMG for assistive mode and externally-directed via an accompanying smartphone application for rehabilitation (repetitive exercise) programs, both managed through Bluetooth communication. The effectiveness of the proposed design is evaluated in performing cylindrical, hook, and pinch grasps on various objects.	3d printing;actuation dosing unit;bluetooth;compliance behavior;diameter (qualifier value);hospitals;mobile app;mobile device;modular design;patients;personalization;physical object;power glove;requirement;sema5b gene;smartphone;spooling;exoskeleton;grasp	Alireza Mohammadi;Jim Lavranos;Peter Choong;Denny Oetomo	2018	2018 40th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)	10.1109/EMBC.2018.8512617	computer vision;embedded system;3d printing;rehabilitation;computer aided design;bluetooth;modular design;artificial intelligence;computer science;spooling;grasp	Robotics	72.86123875850632	-26.364044043267615	24013
559248171b3992b725c6f06c4dafaf3c8a21a6c2	multi-view video contents viewing system by synchronized multi-view streaming architecture	video streaming;multi view video;multi view interface;free viewpoint tv	We developed a novel networked video viewing system for multi-view video contents with video streaming technology. This work's contribution is that our developed system confirmed the validity of simultaneous multiple video streaming architecture that incorporates real-time channel switching and a target-oriented viewing interface. In addition, we newly introduced an inter-channel bandwidth management scheme to achieve cost-effective multi-view streaming.	bandwidth management;real-time clock;streaming media	Takafumi Marutani;Kenji Mase;Toshiaki Fujii;Tetsuya Kawamoto	2012		10.1145/2393347.2396440	video compression picture types;real-time computing;video;uncompressed video;computer science;video capture;video tracking;multimedia;video processing;smacker video;multiview video coding;computer graphics (images)	Graphics	55.15280253146464	-43.917517459331414	24028
96c55342ada53885f4329d1666dd80957120d6c2	point-cloud-based model-mediated teleoperation	force feedback signal point cloud based model mediated teleoperation time of flight camera mmt method object surfaces complex geometry lossless h 264 codec simple point cloud based haptic rendering algorithm;video coding geometry rendering computer graphics;geometry;video coding;rendering computer graphics;cameras force three dimensional displays computational modeling solid modeling robot vision systems	In this paper, we extend the concept of model-mediated teleoperation (MMT) to six degrees-of-freedom in complex environments using a time-of-flight (ToF) camera. Compared to the original MMT method, the remote environment is no longer approximated by a simple planar surface, but by a point cloud model. Thus, object surfaces with complex geometry can be used in MMT. In our proposed system, the point cloud model is captured by the ToF camera with high temporal resolution (up to 160fps) and a flexible work range (10cm to 5m). Updating the model of the remote environment while the robot is in operation is thus easier compared to the original MMT approach. The point cloud model is transmitted from the teleoperator to the operator using a lossless H.264 codec. In addition, a simple point-cloud-based haptic rendering algorithm is adopted to generate the force feedback signal directly from the point cloud model without first converting it into polygons. Moreover, to compensate for the estimation error of the point cloud model, adaptive position and force control schemes are applied to enable stable and transparent teleoperation. Our experiments demonstrate the feasibility and benefits of utilizing the proposed method in MMT.	approximation algorithm;cloud computing;codec;experiment;feedback;h.264/mpeg-4 avc;haptic technology;lossless compression;mpeg media transport;point cloud;robot;six degrees of separation;telerobotics;time-of-flight camera	Xiao Xu;Burak Cizmeci;Eckehard G. Steinbach	2013	2013 IEEE International Symposium on Haptic Audio Visual Environments and Games (HAVE)	10.1109/HAVE.2013.6679613	computer vision;simulation;computer science;computer graphics (images)	Robotics	55.498888375494815	-46.54005945686093	24081
74bbe0aee975c25aa290332621afafab6371543b	digital image processing and illumination techniques for yarn characterization	engineering;mirrors;digital image processing;image processing;sensors;image quality;lenses;algorithms;optical sensors;mechatronics;article;cameras;light sources	This paper describes various illumination and image processing techniques for yarn characterization. Darkfield and back-lit illuminations are compared in terms of depth of field tolerance and image quality. Experiments show that back-lit illumination is superior in terms of depth of field tolerance and contrast. Three different back-lit illumination configurations are studied: one simply employing a light source placed behind the yarn, the other incorporating a field lens to increase the light intensity passing through the aperture, and the third using a mirror placed at 45° to the optical axis to enable imaging of two orthogonal views of the yarn core. Problems in defining the hair–core boundaries in high resolution yarn pictures are addressed and a filtering process is introduced for back-lit images. A comparison of the diameter and diameter coefficient of variation percentage measurements for different illumination and image processing techniques is given for several yarn samples. The data are also correlated with Premier 7000 diametric irregularity tester and Uster Tester 3 irregularity measurements. © 2005 SPIE and IS&T. [DOI: 10.1117/1.1902743]		Yasar A. Ozkaya;Memis Acar;Mike R. Jackson	2005	J. Electronic Imaging	10.1117/1.1902743	image quality;computer vision;mechatronics;image processing;computer science;sensor;köhler illumination;digital image processing;lens;computer graphics (images)	Vision	58.962067760567166	-48.519393348955134	24084
aa9348180f3a2b33ae3e3e6ff60933ca5984e924	a transform domain svd filter for suppression of muscle noise artefacts in exercise ecg's	artefacto;second order;noise free ecg;myocardium;filter order;filtering;ejercicio fisico;filtrage;muscle noise artefact suppression;decomposition valeur singuliere;electrodiagnostic;subspace decomposition;musculo;exercise;algorithms artifacts electrocardiography exercise humans muscles signal processing computer assisted;noisy ecg;second order characteristics;signal analysis;medical signal processing electrocardiography singular value decomposition discrete cosine transforms noise abatement electromyography;filtrado;singular value decomposition;additive noise;discrete cosine transform domain;hombre;analisis de senal;miocardio;noise suppression;muscles electrocardiography wiener filter additive noise discrete cosine transforms noise reduction discrete transforms narrowband singular value decomposition yield estimation;yield estimation;indexing terms;electrocardiographie;single lead ecg record;noise abatement;discrete cosine transform;artefact;artifacts;electrodiagnostico;deterministic nature;reduccion ruido;upper bound;signal processing computer assisted;band structure;circulatory system;electrocardiography;single lead ecg record transform domain svd filter muscle noise artefact suppression exercise ecg noisy electrocardiography deterministic nature additive muscle noise artefact second order characteristics noise free ecg narrow band structure discrete cosine transform domain second order statistical properties orthogonality property noise abatement subspace decomposition singular value decomposition suboptimal wiener filter ecg beat biased estimate mean square error filter order subspace smoothing minimum mean square error noisy ecg finite precision linear perturbation model;electrocardiografia;second order statistical properties;discrete transforms;discrete cosine transforms;mean square error;suboptimal wiener filter;noise reduction;finite precision linear perturbation model;human;reduction bruit;narrow band structure;additive muscle noise artefact;algorithms	The proposed filter assumes the noisy electrocardiography (ECG) to be modeled as a signal of deterministic nature, corrupted by additive muscle noise artefact. The muscle noise component is treated to be stationary with known second-order characteristics. Since noise-free ECG is shown to possess a narrow-band structure in discrete cosine transform (DCT) domain and the second-order statistical properties of the additive noise component is preserved due to the orthogonality property of DCT, noise abatement is easily accomplished via subspace decomposition in the transform domain. The subspace decomposition is performed using singular value decomposition (SVD), The order of the transform domain SVD filter required to achieve the desired degree of noise abatement is compared to that of a suboptimal Wiener filter using DCT. Since the Wiener filter assumes both the signal and noise structures to be statistical, with a priori known second-order characteristics, it yields a biased estimate of the ECG beat as compared to the SVD filter for a given value of mean-square error (mse). The filter order required for performing the subspace smoothing is shown to exceed a certain minimal value for which the mse profile of the SVD filter follows the minimum-mean-square error (mmse) performance warranted by the suboptimal Wiener filter. The effective filter order required for reproducing clinically significant features in the noisy ECG is then set by an upper bound derived by means of a finite precision linear perturbation model. A significant advantage resulting from the application of the proposed SVD filter lies in its ability to perform noise suppression independently on a single lead ECG record with only a limited number of data samples.	additive white gaussian noise;biologic preservation;discrete cosine transform;electrocardiography;electronic band structure;kalman filter;mean squared error;morphologic artifacts;muscle;singular value decomposition;smoothing (statistical technique);stationary process;utility functions on indivisible goods;visual artifact;wiener filter;zero suppression	Joseph S. Paul;M. Ramasubba Reddy;V. Jagadeesh Kumar	2000	IEEE Transactions on Biomedical Engineering	10.1109/10.841337	filter;minimum mean square error;raised-cosine filter;computer vision;electronic engineering;muscle;physical exercise;speech recognition;index term;kernel adaptive filter;electrodiagnosis;computer science;signal processing;circulatory system;discrete cosine transform;root-raised-cosine filter;noise reduction;mathematics;mean squared error;wiener filter;upper and lower bounds;noise control;filter design;singular value decomposition;second-order logic;statistics;salt-and-pepper noise;electronic band structure	Vision	81.32942413907325	-30.610814042733743	24120
29879321380ae2e605ec7171d9d35c69442ad568	development of shoulder complex structure	robot dynamics humanoid robots human robot interaction industrial robots;wire driven architecture shoulder complex structure human robot interaction industrial robots human workers;glenohumeral joint shoulde complex;human robot interaction;shoulder joints wires actuators service robots kinematics;humanoid robots;industrial robots;robot dynamics	Currently the interaction between human and robot are becoming important in the industrial application including hardware and software area. Industrial robot with human aspects needs more natural motion to be familiar to human workers. To do that, shoulder complex is very important. Here, human shoulder complex is designed with wire driven architecture.	industrial robot	Tae-Yong Choi;Hyunmin Do;Kwangcho Chung;Doo-Hyung Kim	2013	2013 10th International Conference on Ubiquitous Robots and Ambient Intelligence (URAI)	10.1109/URAI.2013.6677437	human–robot interaction;mobile robot;computer vision;simulation;articulated robot;computer science;humanoid robot;artificial intelligence;social robot;robot locomotion;robot control;personal robot;robot kinematics	Robotics	67.20701107404595	-26.739988216903324	24135
c7f8cd3b0a2b9d5c785d5c0de8027b63ca99d935	a data-driven approach for mass-spring model parametrization based on continuous models		Nowadays, the simulation of deformable objects play important roles in several fields related to Computer Science such as computer graphics, computer aided design, computer aided surgery and robotics. In this context, simulation of deformable objects with accuracy and in real-time is an extremely difficult task for applications that require interactive mechanical simulations such as virtual environment, surgical simulation and games. We can divide the approaches that offer support for the treatment of deformable models into two groups: based on continuous mechanics, like Finite Element Model (FEM) or Isogeometric Analysis (IGA); and using discrete representations, as Mass-Spring Model (MSM). Continuous-based methods are known for their high computacional cost and accuracy, while discrete methods, although simple and suitable for interactive mechanical simulations are difficult to parametrize. The absence of a general physically based or systematic method to determine the mesh topology or MSM parameters from a known material was the main motivation of this work, in the sense to generate a model of low computational cost, such as MSM, from a model of high accuracy as the FEM. Assuming the premise of simplicity and suitability of the MSM for interactive mechanical simulations, in this thesis we propose a methodology to parametrize the MSM based on continuous models. We developed two data-driven approaches to the parametrization of the MSM by using FEM and IGA models, the latter as reference for derivation with higher order elements. Based on experimental results, the precision achieved by these new methodologies is higher than other similar approaches in literature. In particular, our proposal achieves excellent results in the parametrization of the MSM with higher order elements.		Josildo Pereira da Silva	2015			mathematical optimization;parametrization;mathematics	Graphics	70.549742820159	-46.459076253153306	24145
8fcc985dbfe8072dd97ab6c5a382342ff0b23be7	underwater object tracking using electrical impedance tomography	robot sensing systems;inexpensive estimator underwater object tracking electrical impedance tomography murky underwater situation nonvisual sensing self generated electric field neotropical nocturnal freshwater fish active electrosense cross correlation method self generated field cylindrical pod shaped sensor rectangular tank position estimation velocity estimator online system;kalman filters;image sensors;electrodes kalman filters tomography conductivity voltage measurement estimation robot sensing systems;electrodes;conductivity;estimation;object tracking;tomography biosensors image sensors object tracking;tomography;voltage measurement;biosensors	Few effective technologies exist for sensing in dark or murky underwater situations. For this reason, we have been exploring the use of a novel biologically-inspired approach to non-visual sensing based on the detection of perturbations to a self generated electric field. This is used by many species of neotropical nocturnal freshwater fish. This approach, termed active electrosense, presents unique challenges for sensing and tracking of nearby objects. We explore two methods for estimating the velocity of objects through active electrosense. The first of these methods uses a simple cross-correlation method, which depends on the uniformity of the electric field. We show some of the ramifications of making this assumption for a self-generated field around a cylindrical pod-shaped sensor in a rectangular tank. We then evaluate the use of methods developed for electrical impedance tomography (EIT) for localization and tracking. This is an unusual application of EIT in that typical applications involve surrounding the volume of interest (such as the thorax of humans) with sensor/emitters. Here, rather than this “outside in” approach, we are using EIT “inside out.” In simulation, we nonetheless find significant improvements in the accuracy of estimated velocity when using the EIT approach. Additionally, we demonstrate how EIT may be used for accurate position estimation. Under the conditions evaluated, the computation time for inversion is low enough to make its use feasible as a primary position and velocity estimator in an on- line system or as a secondary system to augment a computationally inexpensive estimator.	active galactic nucleus;characteristic impedance;circuit complexity;computation;cross-correlation;electromagnetically induced transparency;kalman filter;lateral thinking;perturbation theory;region of interest;simulation;thresholding (image processing);time complexity;tomography;velocity (software development)	James Snyder;Yonatan Silverman;Yang Bai;Malcolm A. MacIver	2012	2012 IEEE/RSJ International Conference on Intelligent Robots and Systems	10.1109/IROS.2012.6386251	kalman filter;computer vision;estimation;electronic engineering;computer science;engineering;electrode;conductivity;video tracking;image sensor;tomography;biosensor;remote sensing	Robotics	62.709403680348096	-34.37766373120306	24154
6027a571a86e01612bf4f08ada4d6079af108de9	multi-imager compatible, mr safe, remote center of motion needle-guide robot	manipulators instruments kinematics magnetic resonance imaging needles optical fiber sensors;robot mr safe compatible multi imager pneumatic motor remote center of motion rcm direct igi digi	We report the development of a new robotic system for direct image-guided interventions (DIGI; images acquired at the time of the intervention). The manipulator uses our previously reported pneumatic step motors and is entirely made of electrically nonconductive, nonmetallic, and nonmagnetic materials. It orients a needle-guide with two degrees of freedom (DoF) about a fulcrum point located below the guide using an innovative remote center of motion parallelogram type mechanism. The depth of manual needle insertion is preset with a third DoF, located remotely of the manipulator. Special consideration was given to the kinematic accuracy and the structural stiffness. The manipulator includes registration markers for image-to-robot registration. Based on the images, it may guide needles, drills, or other slender instruments to a target (OD < 10 mm). Comprehensive preclinical tests were performed. The manipulator is MR safe (ASTM F2503-13). Electromagnetic compatibility (EMC) testing (IEC 60601-1-2) of the system shows that it does not conduct or radiate EM emissions. The change in the signal to noise ratio of the MRI due to the presence and motion of the robot in the scanner is below 1%. The structural stiffness at the needle-guide is 33 N/mm. The angular accuracy and precision of the manipulator itself are 0.177° and 0.077°. MRI-guided targeting accuracy and precision in vitro were 1.71 mm and 0.51 mm, at an average target depth of ∼38 mm, with no adjustments. The system may be suitable for DIGI where ${\text{1.07 + 0.0031}} \cdot \boldsymbol{d}$ [mm] accuracy lateral to the needle (2D) or  ${\text{1.59 + 0.0031}} \cdot \boldsymbol{d}$ [mm] in 3D is acceptable. The system is also multi-imager compatible and could be used with other imaging modalities.	angularjs;clinical act of insertion;electricity;emission - male genitalia finding;extraskeletal myxoid chondrosarcoma;image sensor;imager device component;in vitro [publication type];insertion mutation;instrument - device;lateral thinking;medical device incompatibility problem;needle device;numerous;phase i/ii trial;radiate;robot;scanning systems;signal-to-noise ratio;registration - actclass	Dan Stoianovici;Changhan Jun;Sunghwan Lim;Pan Li;Doru Petrisor;Stanley Fricke;Karun Sharma;Kevin Cleary	2018	IEEE Transactions on Biomedical Engineering	10.1109/TBME.2017.2697766	artificial intelligence;computer vision;parallelogram;computer science;robot;manipulator;kinematics;needle guide	Robotics	73.55460348443793	-29.171650606145768	24163
555c1e3bb71c1647e71055b7d05ef65c072fb7c7	an automatic sorting approach of surface bundle based on the shared space curve	face data structures boolean functions bismuth;topology;interpolation;boolean functions;sorting;search engines;bismuth;topology data structures interpolation mesh generation search engines solid modelling sorting;3d cadastre surface patch automatic sorting point set topology topological consistency feature polyline;point set topology;data structures;automatic sorting;3d cadastre;face;surface patch;feature polyline;urban space utilization cases automatic sorting approach surface bundle shared space curve data management topology maintenance 3d cadastre 3d objects construction closed patches discrete planes property right boundaries boundary surfaces mathematical expressions cutting plane point set topology topological consistency feature polyline cutting plane bundle triangulation interpolation google sketchup solid closed discrete surface patches;mesh generation;topological consistency;solid modelling	The construction of the property right volume is an important prerequisite for data management and topology maintenance in 3D cadastre, and the automatic sorting approach of patches is important to construction of the smallest solid. When property right volumes as true 3D objects are constructed, not only ideal situations that closed patches are discrete planes, but also general conditions that property right boundaries are surfaces should be taken into account. So, firstly, conceptual descriptions of boundary surfaces and mathematical expressions of both the shared curve and the cutting plane are proposed based on theory of point-set topology. Secondly, obeying the principle of topological consistency, an automatic sorting approach and corresponding restrictions are put forward by detailed processes about local interpolation of the surface, calculation of the feature polyline, sorting of the cutting plane bundle. Particularly, this paper emphasizes on the method to obtain the feature polyline of the cutting plane taking triangulation interpolation of the surface in Google SketchUp for example. It is hoped that what is discussed in this paper could provide some references for constructing the smallest solid closed by discrete surface patches applied in urban space utilization cases such as 3D cadastre.	cutting-plane method;interpolation;obedience (human behavior);sketchup;sorting	Changbin Yu;Shen Ying;Biao He;Zhigang Zhao	2012	2012 20th International Conference on Geoinformatics	10.1109/Geoinformatics.2012.6270269	combinatorics;discrete mathematics;topology;mathematics	Robotics	64.60692095323628	-42.00345163503785	24175
7781d767961bc173dc0b100e9d367267a30b4cc0	a unified paradigm for scalable multi-projector displays	tiled display;optimisation;projector blending method;visualization system;superimposed projection multi projector displays tiled displays large format displays blending stitching automatic geometric alignment photometric correction super resolution;high resolution;image resolution;photometric correction;tiled projection paradigm;high resolution images;real time;displays robustness visualization brightness image quality image resolution graphics large scale systems photometry solid modeling;stitching;automatic geometric alignment;blending;indexing terms;graphics platform;visual quality;visualization system scalable multiprojector display optimization projector blending method high resolution images nyquist resolution superimposed multiprojector projection paradigm tiled projection paradigm unified paradigm graphics platform real time interactive frame;superimposed multiprojector projection paradigm;brightness;data visualisation;large scale;visualization;photometry;image color analysis;displays;image quality;solid modeling;computer displays;real time interactive frame;mathematical model;super resolution;robustness;optimization;high resolution imager;multi projector displays;optimisation computer displays data visualisation image resolution;tiled displays;visual system;scalable multiprojector display;large format displays;cameras;graphics;unified paradigm;superimposed projection;large scale systems;nyquist resolution	We present a general framework for the modeling and optimization of scalable multi-projector displays. Based on this framework, we derive algorithms that can robustly optimize the visual quality of an arbitrary combination of projectors without manual adjustment. When the projectors are tiled, we show that our framework automatically produces blending maps that outperform state-of-the-art projector blending methods. When all the projectors are superimposed, the framework can produce high-resolution images beyond the Nyquist resolution limits of component projectors. When a combination of tiled and superimposed projectors are deployed, the same framework harnesses the best features of both tiled and superimposed multi-projector projection paradigms. The framework creates for the first time a new unified paradigm that is agnostic to a particular configuration of projectors yet robustly optimizes for the brightness, contrast, and resolution of that configuration. In addition, we demonstrate that our algorithms support high resolution video at real-time interactive frame rates achieved on commodity graphics platforms. This work allows for inexpensive, compelling, flexible, and robust large scale visualization systems to be built and deployed very efficiently.	algorithm;alice and bob;alpha compositing;contrast resolution;display resolution;expanded memory;genus colinus (organism);graphics processing unit;image quality;image resolution;imagery;lobular neoplasia;map;mathematical optimization;memory disorders;movie projector;numerous;programming paradigm;projection-slice theorem;real-time clock;scalability;seamless3d;texture memory;tom;video projector;william n. carrico, jr.;workstation;brightness	Niranjan Damera-Venkata;Nelson L. Chang;Jeffrey M. DiCarlo	2007	IEEE Transactions on Visualization and Computer Graphics	10.1109/TVCG.2007.70536	computer vision;image resolution;computer science;multimedia;data visualization;computer graphics (images)	Visualization	61.7084270922074	-49.796514467681206	24203
b43095d070c26e41858877698302e28d4db4f96c	sharpness in trajectory estimation by piecewise-quadratics(-cubics) and cumulative chords	associated interpolation knot;computer vision;cumulative chord parameterization;pertinent interpolation scheme;asymptotic order;computer graphics;trajectory estimation;trajectory modeling;trajectory approximation;so-called reduced data;arbitrary euclidean space	associated interpolation knot;computer vision;cumulative chord parameterization;pertinent interpolation scheme;asymptotic order;computer graphics;trajectory estimation;trajectory modeling;trajectory approximation;so-called reduced data;arbitrary euclidean space		Ryszard Kozera;Mateusz Smietanka	2012		10.1007/978-3-642-33564-8_18	mathematical optimization;combinatorics;discrete mathematics;mathematics;geometry;statistics	Robotics	70.35177574507134	-42.16417033399114	24305
45fcf2e6d20a694210ea7b0ded58d225d54be0dc	creating light atlases with multi-bounce indirect illumination	global illumination;gpu acceleration	Indirect illumination is an essential part of realistically rendering virtual scenes. In this paper we present a new method for computing multi-bounce indirect illumination for diffuse surfaces which is particularly well-suited for indoor scenes with complex occlusion, where an appropriate simulation of the indirect illumination is extremely important. The technique presented in this paper combines the benefits of shooting methods with the concept of photon mapping to compute a convincing light map for the scene with full diffuse lighting effects. The main idea is to carry out a multi-bounce light distribution almost entirely on the GPU using a shooting approach with virtual point lights. The final result is then stored in a texture atlas by projecting the energy from each virtual point light into the texels visible from its perspective. The technique uses only few resources on the graphics card and is flexible in the sense that it can easily be adjusted for either quality or speed, allowing the user to create convincing results in a matter of seconds or minutes, depending on the scene complexity. Citation Info Journal Computers & Graphics Volume 55, April 2016	global illumination;graphics processing unit;illumination (image);information;photon mapping;simulation;texel (graphics);texture atlas;video card	Randolf Schärfig;Marc Stamminger;Kai Hormann	2016	Computers & Graphics	10.1016/j.cag.2015.10.005	computer vision;computer science;global illumination;computer graphics (images)	Graphics	64.26379366409343	-51.1297121931387	24325
f130680eb646efd148d3eebdc9bcb0f8ee60f3b5	integrated vision and force control in suspended cell injection system: towards automatic batch biomanipulation	microrobots;impedance force control;motion control;automatic batch injection;force sensors;real time;microscopy;three dimensional;cell injection force;micro force sensor;feedback;suspended cell injection system;robot vision;position control;force control force sensors force measurement motion control robotics and automation microscopy cells biology sun feedback mechanical sensors;3d micromanipulation;injector pipette trajectory;mechanical sensors;sun;integrated vision;robot vision force control force sensors microrobots motion control position control;force measurement;force control algorithm;robotic cell injection system;robotics and automation;3d micromanipulation integrated vision suspended cell injection system automatic batch biomanipulation robotic cell injection system automatic batch injection micro force sensor cell injection force injector pipette trajectory force control algorithm motion control position control impedance force control;force sensor;cells biology;automatic batch biomanipulation;force control	"""Automatic cell injection has been the focus of many researches and commercial development for several years. In this paper, a robotic cell injection system for automatic batch injection of suspended cells is developed. To facilitate the process, these suspended cells are held and fixed to a cell array by a specially designed cell holding device, and injected one by one through an """"out-of-plane"""" cell injection process. A micropipette equipped with a PVDF micro force sensor is integrated in the proposed system. The force sensor is utilized to measure real time injection force applied to the cells during injection process. Through calibration of the relationship between the cell injection force and the desired injector pipette trajectory, a position (vision) and force control algorithm is proposed and applied to the motion control of the injection pipette in three-coordinate directions during an injection process. The out-of-plane cell injection task is decoupled into a position control in X-Y horizontal plane and an impedance force control in Z-axis. The depth motion of the injector pipette, a common problem of three-dimensional micromanipulation, is indirectly controlled by the force control. Finally, experimental results are given to demonstrate the effectiveness of the proposed approach."""	algorithm;batch processing;cell (microprocessor);characteristic impedance;experiment;optic axis of a crystal;robot;rotary woofer	Haibo Huang;Dong Sun;James K. Mills;Shuk Han Cheng	2008	2008 IEEE International Conference on Robotics and Automation	10.1109/ROBOT.2008.4543732	control engineering;motion control;three-dimensional space;simulation;computer science;engineering;microscopy;control theory;feedback;force-sensing resistor	Robotics	75.9523714165707	-25.837678567374045	24527
c50c55cbc3717bfe1e387e95ccb51d96151a78f7	qsplat compression	qsplat;data compression;huffman coding;volume rendering;point based rendering;level of detail;interactivity;relative delta encoding	The great advances in the field of 3D scanning technologies have enabled the creation of meshes with hundred millions of polygons. Rendering data sets of that size is time consuming even with commodity graphics hardware. The QSplat technique that has been introduced by S. Rusinkiewics and M. Levoy of Stanford University is used for the inter-active point based visualization of large 3D scenes. Nevertheless, it has some drawbacks like the storage requirement which is still higher. The objective of our work we present in this paper is to improve the per-node storage requirements of QSplat models and to minimize the transmission cost in streaming QSplat models across low-bandwidth networks or bottlenecked networks. To do that, we focus on coding strategies which provide reasonable data reduction at low decoding complexity. In this context, Huffman and relative delta encoding fit well with our purposes. The performances of the compression process are studied and the rendering algorithm is extended in order to be able to work on compressed data without loosing the original system interactivity.	3d scanner;algorithm;data compression;delta encoding;graphics hardware;huffman coding;interactivity;performance;requirement	Rachid Namane;Fatima Oulebsir-Boumghar;Kadi Bouatouch	2004		10.1145/1029949.1029952	data compression;computer vision;real-time computing;computer science;artificial intelligence;theoretical computer science;operating system;level of detail;multimedia;interactivity;volume rendering;statistics;huffman coding;computer graphics (images)	Visualization	67.84738816335303	-51.91729133718942	24624
2e92e18b2ef460d7b7f7ba413e37f0bd0268079b	innovation coding with a cross-correlated quantization noise model	signal to noise ratio;speech;encoding;kalman filters	We present the use of a cross-correlated quantization noise model in the recently proposed Kalman innovation speech coding scheme. Computer simulations and informal listening tests indicate that the incorporation of a cross-correlated noise model yields an improvement in both SNR and perceptual quality when compared to a uncorrelated noise model.	kalman filter;quantization (signal processing);signal-to-noise ratio;simulation;speech coding;white noise	Søren Vang Andersen;Morten Olesen;Søren Holdt Jensen;Egon Hansen	1996	1996 8th European Signal Processing Conference (EUSIPCO 1996)		electronic engineering;speech recognition;quantization;computer science;noise measurement;noise;communication	Robotics	82.87255046342283	-33.118100514888944	24666
97aea64698fffd2bb7c127fc45ba1cc712c1c3b9	omni-directional walking of a quadruped robot with optimal body postures on a slope	dynamic change;omni directional walking;legged locomotion;legged locomotion leg mobile robots stability computer simulation systems engineering and theory robot motion timing foot region 8;successive gait transition quadruped robot omni directional walking optimal body posture;foot;mobile robots;region 8;systems engineering and theory;stability;optimal body posture;successive gait transition;robot motion;quadruped robot;computer simulation;leg;timing	In this paper, we discuss the optimal body postures of a quadruped robot to perform omni-directional static walking on a slope. The optimal body posture is the posture with the maximum possible moving speed w. r. t. slope and moving direction. The proposed method based on dynamically changing body posture during gait-transitions, is used to maintain high robot motion velocity on slope. The timing of changing body posture is designed by considering the stability during gait-transition. Using the proposed method, the robot can walk into any direction with the fastest moving speed on a slope. Through walking experiments by computer simulation, the validity of the proposed method has been verified.	computer simulation;experiment;fastest;poor posture;robot;velocity (software development)	Shugen Ma;Kousuke Inoue;Yoshinori Honda	2005	Proceedings of the 2005 IEEE International Conference on Robotics and Automation	10.1109/ROBOT.2005.1570566	computer simulation;control engineering;mobile robot;simulation;stability;computer science;control theory;foot;statistics	Robotics	66.68443489251077	-24.121612053458243	24754
dace0869f8db5b9ca79449879ea05138e21b1a38	an integrated aerial system for landmine detection: sdr-based ground penetrating radar onboard an autonomous drone			aerial photography;autonomous robot;etsi satellite digital radio;unmanned aerial vehicle	Julián Colorado;Manuel Gil Pérez;I. Mondragon;D. Mendez;C. Parra;Carlos Andres Devia;Jesús J. Martinez Molina;L. Neira	2017	Advanced Robotics	10.1080/01691864.2017.1351393	control engineering;remote sensing;engineering;ground-penetrating radar;aeronautics;demining;drone	Robotics	56.18414564300498	-31.443901015913738	24757
da04f6b5794d80f78271bb43c467c658139fe816	corner detection with minimal effort on multiple scales	corner detection;multiple scales	Based on results of fitting linearly shaded blobs to rectangular image regions a new corner detector has been developed. A plane with least sum of errors squared is fit to the intensity distribution within a mask having four mask elements of same rectangular shape and size. Averaged intensity values in these mask elements allow very efficient simultaneous computation of pyramid levels and a new corner criterion at the center of the mask on these levels. The method is intended for real-time application and has thus been designed for minimal computing effort. It nicely fits into the ‘Unified Blob-edge-corner Method’ (UBM) developed recently. Results are given for road scenes.	computation;corner detection;fits;least squares;point process;real-time clock;real-time computing;shading	Ernst D. Dickmanns	2008			corner detection;computer vision;computer science	Graphics	63.1891660220126	-43.96145555750317	24798
831272e938ca568070a396ff025aa2f91d66e3e2	multi degree-of-freedom successive stiffness increment approach for high stiffness haptic interaction		In haptic interaction, stability and the object’s hardness perception are of great significance. Although numerous studies have been done for stable haptic interaction, however, most of them sacrifice the actual displayed stiffness as a cost of stability. In our recent work, we introduced the Successive Stiffness Increment (SSI) approach whereby the displayed stiffness successively increases with the increase of interaction cycles. It was shown that the haptic interaction was stable and the displayed stiffness was greater than other approaches. This paper extends the SSI approach for multi-DoF haptic interaction. The stiffness increment of the SSI approach depends on the number of interaction cycles which will vary for each axis, therefore, we decouple the interaction by adopting penetration depth-based rendering method using Virtual Proxy (VP). Since the decoupled system has unconstrained end point in the form of moving Virtual Environment (VE), so the boundary conditions are updated in the previously proposed SSI approach at every sample. Phantom Premium 1.5 is used to verify the stability and enhanced displayed stiffness of the proposed approach on a virtual sphere.	haptic technology;stiffness	Harsimran Singh;Aghil Jafari;Jee-Hwan Ryu	2016		10.1007/978-981-10-4157-0_49	degrees of freedom (statistics);rendering (computer graphics);boundary value problem;haptic technology;penetration depth;stiffness;virtual machine;control theory;engineering	Robotics	76.56467961828989	-27.867262948759002	24802
0707c47a21bb5e44ab273ac4660e254113aa40cc	blind deconvolution: errors, errors everywhere	spectroscopy;errors;blind source separation deconvolution spectroscopy spectral analysis signal reconstruction image restoration;error correction blind deconvolution model uncertainty data uncertainty spectroscopy spectrum reconstruction image deblurring;image processing;blind deconvolution;least mean squares methods;uncertainty;blind source separation;image deblurring;image restoration;spectrum;physics computing;error correction;deconvolution;modeling error correction uncertainty;signal reconstruction;deconvolution least squares methods error correction uncertainty home computing equations spectroscopy counting circuits matrix decomposition singular value decomposition;spectral analysis;modeling;error correction model	attempt to reconstruct a true spectrum from an observed one. The problem we're considering is sometimes called blind deconvolution, because we're trying to unravel not only the spectrum, but the function that caused the blurring. These problems also arise in image deblurring. Spectroscopy Consider the data in Figure 1, which represents counts measured by a spectrometer. Suppose we have particles whose energy ranges from e lo to e high and define some intermediate energy levels e lo = e 0 < e 1 < … < en b–1 < e n b = e high. This creates n b bins, where the count for the jth bin is the number of particles determined to have energies between ej –1 and ej. Our spectrometer records n b counts, one for each bin; in the figure, we've passed a curve through these counts. Ideally, the count in bin j is exactly the number of particles with energies in the range [e j–1 , e j ]. But some blurring occurs due to the measurement process, and a particle in that energy range might instead be included in the count for a different nearby bin. The probability that a particle with energy e is assigned to bin j is often mod-eled as a normal distribution with mean (e j + e j–1)/2 and variance s j 2. One way to model this system is to try to determine the correct counts f j and the correct blurring given the measured counts g j , j = 1, …, n b and estimates of the values s j. This gives us a matrix equation (K + E) f » g + r, where E accounts for errors in modeling the spectrometer's blur, and r accounts for errors in counts. The matrix entry k jᐉ is computed as the probability that a particle whose energy is in the interval [e ᐉ–1 , e ᐉ ] is assigned to bin j (j, ᐉ = 1, …, n b). There are several sources of differences between the true spectrum and the recorded spectrum: • We effectively assign energy (e j + e j–1)/2 to all particles in bin j, which isn't correct. • A count's value depends on the number of particles with the energies that it represents, but there is some smearing , so it also depends on the number of particles with nearby energies. • …	blind deconvolution;deblurring;emoticon;energy level;google+;modulo operation;the matrix	Dianne P. O'Leary	2005	Computing in Science and Engineering	10.1109/MCSE.2005.10	signal reconstruction;image restoration;spectrum;error correction model;computer vision;econometrics;error detection and correction;systems modeling;uncertainty;spectroscopy;image processing;computer science;deconvolution;mathematics;blind signal separation;blind deconvolution;statistics	Theory	82.85900235114865	-44.80012013339753	24900
619175d5f1a5507c831bfe1d95ea96984736ff4e	uavs as aviators: environment skills capability for uavs	uav;aircraft control;autonomous tasks aviators environment skills capability unmanned areal vehicle uav system automation system;supervisory control;abstraction hierarchy;cost function;levels of sophistication;levels of sophistication uav supervisory control cognitive systems engineering abstraction hierarchy;mobile robots;remotely operated vehicles;unmanned areal vehicle;data mining;aviators;cognitive systems engineering;unmanned aerial vehicles costs automation modeling aerospace engineering humans navigation automatic testing military aircraft aerospace simulation;navigation;remotely operated vehicles aerospace robotics aircraft control mobile robots;environment skills capability;pixel;aerospace robotics;uav system;automation system;unmanned aerial vehicles;autonomous tasks;buildings;automation	To reduce the workload of flying an Unmanned Areal Vehicle (UAV), some of the tasks of the human operator can be automated. In the Levels Of Sophistication (LOS) structure, the capabilities of a UAV system are subdivided. Using this structure, the capabilities concerned with the aviating of an UAV are selected to be automated for this research. The task of the aviating capabilities of an UAV is to integrate all the higher level mission and navigation constraints with constraints from the environment, in order to find a route for the UAV to fly which is safe and efficient. This is done by expressing the constraints in cost maps. The A* pathfinding algorithm then uses these cost maps to find a route for the UAV to fly, taking into account these constraints. The UAV aviating automation has been implemented in a simulation program. The system is capable of finding the best route in the cost map representing the constraints from different levels of sophistication, and let the UAV fly this route in the simulation. The complete automation system was tested in the 2007 Micro UAV flight competition, where the UAV was required to execute some autonomous tasks.	a* search algorithm;autonomous robot;map;pathfinding;simulation;unmanned aerial vehicle	Wijnko Oomkens;Max Mulder;René van Paassen;Matthijs H. J. Amelink	2008	2008 IEEE International Conference on Systems, Man and Cybernetics	10.1109/ICSMC.2008.4811658	remotely operated underwater vehicle;mobile robot;embedded system;computer vision;navigation;simulation;computer science;artificial intelligence;automation;supervisory control;pixel	Robotics	55.514779413034354	-27.568815813890893	24907
fd2b80a0fa06e7e54adf054726526bb3598994de	complete 3-d dynamic coverage in energy-constrained multi-uav sensor networks	coverage;multi-robot cooperation;aerial robots;autonomous vehicle	This paper considers dynamic coverage control of multiple power-constrained agents subject to 3D rigid body kinematics. The agents are deployed to patrol a domain until the entire space has reached a satisfactory level of coverage. This is achieved through the gathering of information by a forward-facing sensor footprint, modelled as an anisotropic spherical sector. Coverage and collision avoidance guarantees are met by a hybrid controller consisting of four operating modes: local coverage, global coverage, waypoint scan and subdomain transfer. Energy-aware methods are encoded into the global coverage state to shift the bulk of spatial redistribution onto less constrained agents. Additionally, a novel domain partitioning strategy is used that directs individual agents to explore within concentric hemispherical shells around a centralized charging station. This results in flight paths that are guaranteed to terminate at the charging station in the limit that agent batteries expire. The efficacy of this algorithm is presented through experimental trials with three agents in an indoor environment. Simulations are provided for ten agents.	unmanned aerial vehicle	William Bentz;Tru Hoang;Enkhmurun Bayasgalan;Dimitra Panagou	2018	Auton. Robots	10.1007/s10514-017-9661-x	wireless sensor network;control theory;collision;simulation;computer science;charging station;rigid body;waypoint	Robotics	56.20551173289967	-25.61019576528193	24910
5935343fd6f97f5b12e7dc5cdefc6cd167cc365b	scanline surfacing: building separating surfaces from planar contours	computational geometry;mixing time;low latency;image segmentation;region of interest;bifurcation;scanline;system on a chip;three dimensional;data visualisation	This paper presents several low-latency mixed-timing FIFO designs that interface systems on a chip working at different speeds. The connected systems can be either synchronous or asynchronous. The design are then adapted to work between systems with very long interconnection delays, by migrating a singel-clock solution by carloni et al. (for “latency-insensitive” protocols) to mixed-timing domains. THe new designs can be made arbitrarily robust with regard to metastability and interface operating speeds. Initials simulationsfor both latency and throughput are promising.	asynchronous serial communication;fifo (computing and electronics);interconnection;metastability in electronics;scan line;scanline rendering;synchronization (computer science);system on a chip;throughput	David M. Weinstein	2000	Proceedings Visualization 2000. VIS 2000 (Cat. No.00CH37145)	10.1145/375213.375256	system on a chip;three-dimensional space;computer vision;scan line;computational geometry;computer science;geometry;image segmentation;data visualization;computer graphics (images);region of interest;low latency	EDA	68.97183592496812	-50.27364068789794	25138
d64993646bca4c0dccfb5e6b9f4fc0ee5b720c63	nonlinear workspace mapping for telerobotic assistance of upper limb in patients with severe movement disorders		Telerobotic manipulation allows patients living with upper limb impairments to interact with a variety of environments and accomplish through teleoperation daily activities such as playing, feeding, self-care, and leisure, that would otherwise be difficult to perform. In this paper, we propose a nonlinear mapping between the patientu0027s range of motion and the workspace of an environment being manipulated. The objective is to identify the patientu0027s workspace and span it to that of the environment or an object, thus optimizing the scaling factor while soliciting the entire patientu0027s range of motion. The boundaries of each workspace are obtained from scattered measurements of the master and slave robots end-effector position. The nonlinear mapping is then achieved through thin plate spline interpolation that describes deformation between two surfaces by scattered point-to-point preponderances. Experimental results reported in three different scenarios confirm the suitability of the nonlinear transformation to map diverse workspace volumes.	bilateral filter;convex hull;distortion;euler;fibre channel point-to-point;file spanning;image scaling;nonlinear system;robot end effector;spline interpolation;telerobotics;thin plate spline;workspace	Carlos Rossa;Mohammad Najafi;Mahdi Tavakoli;Kim Adams	2017	2017 IEEE International Conference on Systems, Man, and Cybernetics (SMC)	10.1109/SMC.2017.8122956	movement disorders;interpolation;workspace;control theory;teleoperation;nonlinear system;computer vision;computer science;thin plate spline;robot kinematics;range of motion;artificial intelligence	Robotics	71.75578123242103	-28.978240801534948	25195
892fc28ae3bf56aca99dc7c7a436787d92e04754	a miniature tactor design for upper extremity prosthesis	design engineering;haptic device;skin;upper extremity;upper extremity prosthesis;tactile sensors artificial limbs design engineering haptic interfaces skin;vibration;reinnervation surgery;tactile sensors;reinnervation surgery miniature tactor design upper extremity prosthesis haptic device pressure vibration shear force temperature skin;artificial limbs;miniature tactor design;temperature;haptic interfaces;mechanism design;shear force;pressure;extremities prosthetics vibrations skin haptic interfaces displays temperature sensors surgery imaging phantoms prototypes	We have been developing a miniature haptic device - a tactor that can display pressure, vibration, shear force, and temperature to the skin of upper extremity amputees, especially those who have undergone targeted nerve rein-nervation (TRI) surgery. In TRI patients, regions of the rein-nervated skin are perceived as being on the phantom hand. This paper presents the mechanical design of the tactor.	haptic technology;imaging phantom	Keehoon Kim;J. Edward Colgate;Michael A. Peshkin;Julio J. Santos-Munné;Alex Makhlin	2007	2007 Frontiers in the Convergence of Bioscience and Information Technologies	10.1109/FBIT.2007.89	simulation;engineering;biological engineering;surgery	HCI	74.51943545901197	-26.814194329620413	25198
498d19a3553612229d0f12ab1981a2f5a72be358	diminishing returns of engineering effort in telerobotic systems	control systems;human interaction;dk atira pure researchoutput researchoutputtypes contributiontojournal article;dogs;virtual reality;testing;autonomy;human robot interaction;indexing terms;intelligent control;robot control;design and implementation;telerobotics robotics and automation human robot interaction control systems testing computer science dogs frequency robot control virtual reality;teleoperation telerobotics autonomous robot human interaction autonomy;telerobotics;computer science;frequency;intelligent control telerobotics man machine systems interactive systems;interactive systems;man machine systems;robotics and automation;autonomous robot;teleoperation	Robotic systems range from teleoperated (where the human operator is in full control of all aspects of the robot’s behavior) to fully autonomous (where no human intervention takes place). The word “telerobotic” describes robotic systems which, although guided by a human, have a degree of autonomous behavior. This paper examines the tradeoff between the increasing design and implementation effort necessary as the system moves through the continuum from teleoperated to autonomous and the amount of human intervention required. A case study of a human “shepherd” interacting with a robotic “sheepdog” which directs a robotic “sheep” is used.	apache continuum;autonomous robot;interaction;telerobotics	Myra S. Wilson;Mark James Neal	2001	IEEE Trans. Systems, Man, and Cybernetics, Part A	10.1109/3468.952720	telerobotics;computer vision;interpersonal relationship;teleoperation;simulation;index term;computer science;artificial intelligence;frequency;virtual reality;robot control;autonomy;software testing;intelligent control	Robotics	65.86819175707772	-29.033595596474196	25210
6e088353b22c6fb0286f3d79caf4dafdf0b375e8	force visualization mechanism using a moiré fringe applied to endoscopic surgical instruments	printing;internal organs;international organizations;moire fringe;operating room;grasping;instruments;visualization surgical instruments displays surgery force sensors surges force measurement gratings capacitive sensors wires;force sensors;force visualization mechanism;surgical instruments;biological organs;gratings;biomechanics;wires;endoscopic image;force;surges;visualization;10 mm forceps;pig;displays;endoscopes;surgery;force measurement;endoscopic image force visualization mechanism moire fringe endoscopic surgical instruments internal organs 10 mm forceps pig;moire fringes;endoscopic surgical instruments;capacitive sensors;strain gauge;surgery biological organs biomechanics endoscopes force sensors moire fringes	This paper presents a force visualization mechanism for endoscopic surgical instruments using a Moirée fringe. This mechanism can display fringes or characters that correspond to the magnitude of a force between the surgical instruments and internal organs without the use of electronic elements, such as amplifiers and strain gauges. As this mechanism is simply attached to the surgical instruments, there is no need for additional devices in the operating room or wires to connect these devices. The structure is simple, and its fabrication is inexpensive. An example is shown with the mechanism mounted on a 10-mm forceps. We experimentally verified in vivo, using a pig, that it can display characters corresponding to the magnitude of the force, thus visually displaying the force even in endoscopic image.	amplifier;experiment;printing;video-in video-out	Takeshi Takaki;Youhei Omasa;Idaku Ishii;Tomohiro Kawahara;Masazumi Okajima	2010	2010 IEEE International Conference on Robotics and Automation	10.1109/ROBOT.2010.5509708	computer vision;visualization;strain gauge;computer science;engineering;biomechanics;capacitive sensing;optics;force	Robotics	76.4809016051782	-26.861357739534387	25271
651ff8e258c3c70c03e7989b0def2d86fba71036	bounding uncertainty in ekf-slam: the robocentric local approach	robot sensing systems;nonlinear filters;uncertainty simultaneous localization and mapping state estimation computational efficiency robot sensing systems vehicles gaussian approximation noise reduction computational modeling large scale systems;uncertain systems;sensor model;uncertainty;path planning;kalman filters;mobile robots;state estimation;ekf slam;large scale;computational modeling;gaussian approximation;linearisation techniques;noise reduction;simultaneous localization and mapping;robocentric local map sequencing algorithm bounding uncertainty ekf slam extended kalman filter simultaneous localization and mapping location uncertainty;uncertain systems kalman filters linearisation techniques mobile robots nonlinear filters path planning;vehicles;bounding uncertainty;location uncertainty;extended kalman filter;computational efficiency;large scale systems;robocentric local map sequencing algorithm	This paper addresses the consistency issue of the extended Kalman filter approach to the simultaneous localization and mapping (EKF-SLAM) problem. Linearization of the inherent nonlinearities of both the motion and the sensor models frequently drives the solution of the EKF-SLAM out of consistency specially in those situations where location uncertainty surpasses a certain threshold. This paper proposes a robocentric local map sequencing algorithm which: (a) bounds location uncertainty within each local map, (b) reduces the computational cost up to constant time in the majority of updates and (c) improves linearization accuracy by updating the map with sensor uncertainty level constraints. Simulation and large-scale outdoor experiments validate the proposed approach	algorithm;algorithmic efficiency;clutter;computation;correspondence problem;ekf slam;emoticon;experiment;extended kalman filter;map;nonlinear system;simulation;simultaneous localization and mapping;time complexity	Ruben Martinez-Cantin;José A. Castellanos	2006	Proceedings 2006 IEEE International Conference on Robotics and Automation, 2006. ICRA 2006.	10.1109/ROBOT.2006.1641749	kalman filter;control engineering;mobile robot;computer vision;mathematical optimization;uncertainty;computer science;artificial intelligence;noise reduction;control theory;mathematics;motion planning;extended kalman filter;computational model;simultaneous localization and mapping	Robotics	54.089776822097726	-39.21735052679707	25281
9aa9d2088d762c8896faa61551e71b29e523d17a	generalized implicit functions for computer graphics	implicit surface;computer modeling;free vibration;computer model;deformations;three dimensional;computer graphic;collision detection;implicit surfaces;dynamics;solid modeling;dynamic simulation	We describe a method of generalizing implicit functions by use of modal deformations and displacement maps. Modal deformations, also known as free vibration modes, are used to describe the overall shape of a solid, while displacement maps provide local and fine surface detail by offsetting the surface of the solid along its surface normals. The advantage of this approach to geometric description is that collision detection and dynamic simulation become simple and inexpensive even for complex shapes. In addition, we outline an efficient method for fitting such models to three dimensional point data.	collision detection;computer graphics;displacement mapping;map;modal logic;normal (geometry);simulation;surface detail	Stan Sclaroff;Alex Pentland	1991		10.1145/122718.122745	computer simulation;three-dimensional space;computer vision;dynamic simulation;dynamics;simulation;computer science;solid modeling;collision detection;computer graphics (images)	Graphics	70.113198456146	-47.23878533919225	25303
0855b1c404b1a9cace3a2432137e3eafe57cf05a	a versatile and robust model for geometrically complex deformable solids	deformable modeling;complex environment;high-resolution surface mesh;collision handling;geometricallycomplex deformable solid;complex deformable solids;large variety;robust model;tetrahedral mesh;cloth simulation;computer an- imation;discrete shell;fortetrahedral mesh;physically-based modeling;integrated collision;discrete shells;asimulation environment;plastics;computer graphics;elastic deformation;computer animation;computational modeling;material properties;high resolution;robustness;computational geometry;potential energy;geometric modeling;solid modeling;visualization;data visualisation;triangle mesh;mesh generation;plastic deformation	In this paper, we present a versatile and robust model for geometrically complex deformable solids. Our approach can be applied to deformable tetrahedral meshes and to deformable triangle meshes. The model considers elastic and plastic deformation. It handles a large variety of material properties ranging from stiff to fluid-like behavior. Due to the computational efficiency of our approach, complex environments consisting of up to several thousand primitives can be simulated at interactive speed. The presented approach to deformable modeling is part of a simulation environment with integrated collision handling for tetrahedral meshes. For visualization purposes, tetrahedral meshes can be coupled with high-resolution surface meshes. Results are presented for deformable tetrahedral meshes and for deformable triangle meshes which are used to represent cloth and discrete shells	computation;experiment;image resolution;polygon mesh;simulation;switzerland;triangle mesh	Matthias Teschner;Bruno Heidelberger;Matthias Müller;Markus H. Gross	2004	Proceedings Computer Graphics International, 2004.	10.1109/CGI.2004.1309227	simulation;computational geometry;computer science;volume mesh;geometry;deformation;computer graphics (images)	Visualization	70.52263595384738	-47.695711079801185	25339
975d3987132cd5443060e9ac02a58b7e8a61cb4d	computing visibility on terrains in external memory	data structure;data structures and algorithms;digital elevation models;external memory;computational geometry;terrains;digital elevation model;visibility	We describe a novel application of the distribution sweeping technique to computing visibility on terrains. Given an arbitrary viewpoint v, the basic problem we address is computing the visibility map or viewshed of v, which is the set of points in the terrain that are visible from v. We give the first I/Oefficient algorithm to compute the viewshed of v on a grid terrain in external memory. Our algorithm is based on Van Kreveld’s O(n lg n) time algorithm for the same problem in internal memory. It uses O(sort(n)) I/Os, where sort(n) is the complexity of sorting n items of data in the I/O-model. We present an implementation and experimental evaluation of the algorithm. Our implementation clearly outperforms the previous (in-memory) algorithms and can compute visibility for terrains of up to 4GB in a few hours on a low-cost		Herman J. Haverkort;Laura Toma;Yi Zhuang	2007		10.1137/1.9781611972870.2	computer vision;simulation;digital elevation model;data structure;computational geometry;computer science;theoretical computer science	DB	68.58273106729875	-51.96958196170364	25355
01b5ebdeecc0e7377104300466863c112596f63a	macro 64-regions for uniform grids on gpu	gpu;accelerator;grid;ray tracing	Uniform grids are a spatial subdivision acceleration structure well suited for ray tracing. They are known for their fast build times and ease of use, but suffer from slow traversals in the presence of empty space. To address this issue, we present macro 64-regions, a new GPU based approach for finding and storing empty volumes in an underlying uniform grid. This allows for fast traversals through regions that do not contain scene geometry. Further, unlike previous solutions to this problem, we do not store a hierarchical structure and therefore the traversal steps are simplified. Because macro 64-regions are dependent on an underlying grid, we also introduce an improvement in the grid construction process. Our method does not rely on sorting as previous methods do, but instead uses atomic operators to manage bookkeeping during the build. Using our proposed methods, we show a substantial improvement in build time, trace time, as well as an improvement in the consistency of rendering times for randomly generated views.	algorithm;fastest;graphics processing unit;procedural generation;ray tracing (graphics);regular grid;sorting;space partitioning;sparse matrix;subdivision surface;tree traversal;usability;voxel	Eugene M. Taranta;Sumanta N. Pattanaik	2014	The Visual Computer	10.1007/s00371-014-0974-x	ray tracing;parallel computing;real-time computing;computer science;grid;computer graphics (images)	Graphics	67.03120430432432	-51.202049082931794	25368
5ad2db37c713a5288c834e259e6d80aa1edfc888	groovy graphics assignments: ray-traced transmission		This groovy graphics assignment introduces transmissive rays to a basic reflective ray tracer. The assignment is groovy because it introduces transparent objects, application of Snell's Law, and allows for testing of advanced variations (e.g., Schlick's approximation).	graphics;groovy;ray tracing (graphics);schlick's approximation	Andrew T. Duchowski	2018		10.1145/3215641.3215651	computer graphics (images);computer vision;refraction;ray tracing (graphics);artificial intelligence;graphics;computer science	Visualization	63.14548855770297	-52.00145510885165	25377
dc6be393843cd21abce4bfc4edc9ec231a83b745	op art rendering with lines and curves	optimisation;non photorealistic rendering;computational aesthetics;line art;op art	A common technique in Op Art is the use of densely packed line segments to depict simple shapes such as circles and squares. Some artists have attempted to create more complex images using this technique but are faced with the difficulty of avoiding undesirable artifacts such as line breaks and T-junctions within their artworks. We introduce an algorithm that takes an arbitrary image and automatically generates the corresponding Op Art composition in this style. For 2-colour images, the algorithm produces artworks without any unwanted artifacts; for images with more colours, the basic algorithm cannot guarantee the removal of all artifacts, but we use a global optimisation technique to minimise their number. We also examine the use of curves in creating the illusion of 3D forms and present a corresponding algorithm based on a physical simulation of heat flow. The algorithms for generating Op Art with straight lines and with curves can be combined to create an interesting new style of art. The results have applications in graphic design, puzzle creation and non-photorealistic rendering. Crown Copyright & 2012 Published by Elsevier Ltd. All rights reserved.	algorithm;artifact (software development);artistic rendering;color;compositing;computation;computational geometry;crown group;distortion;dynamical simulation;global optimization;graph coloring;human-readable medium;iteration;kaplan–meier estimator;local optimum;mathematical optimization;non-photorealistic rendering;simulated annealing;slitherlink;thickness (graph theory);unbiased rendering	Tiffany Inglis;Stephen Inglis;Craig S. Kaplan	2012	Computers & Graphics	10.1016/j.cag.2012.03.003	computer vision;computer science;artificial intelligence;non-photorealistic rendering;computer graphics (images)	Graphics	64.94329002534671	-47.200682285316766	25429
607f058d19514e6d4c145efe0d4a9ca92fd5925c	the investigation of 3d scene reconstruction algorithm based on laser scan data	three dimensional imaging;concave programming;laser scan data;3d scene reconstruction algorithm;interpolation;complexity theory;delaunay triangulation;convex programming;convex concave;optical scanners;triangular mesh;surface reconstruction;three dimensional;optical scanners blanking concave programming convex programming image reconstruction interpolation mesh generation;triangular mesh generation;laser scan data delaunay triangulation algorithm three dimensional reconstruction;large scale;surface treatment;blanking;linear interpolation;image reconstruction;mathematical model;three dimensional reconstruction;3d scene reconstruction;blanking 3d scene reconstruction algorithm laser scan data optimization triangular mesh generation convex concave delaunay triangulation algorithm linear interpolation;optimization;laser scanning;mesh generation;delaunay triangulation algorithm;algorithm design and analysis;algorithm design and analysis complexity theory surface reconstruction optimization mathematical model surface treatment image reconstruction	The surface reconstruction algorithm of the large-scale irregular data based on laser scan has been studied. A new algorithm for two-dimensional data which is based on the Delaunay triangulation is proposed. The algorithm is divided into two parts: the generation of initial triangular mesh and optimization of the initial triangular mesh. At the very first, put the data in sequence according to the x coordinate of the data, and generate the triangular mesh directly, then optimize the triangular mesh according to the convex-concave of the quadrilateral that has the public side. The efficiency of Delaunay triangulation is improved by this method. This article describes the specific algorithm. In this paper, do projection transformation to the data obtained from the laser scanning first, the data are transformed into two-dimensional plane from the three domains; secondly divide the two-dimensional data by the improved Delaunay triangulation algorithm, and then switch to three-dimensional curved surface for blanking and linear interpolation to obtain three-dimensional images. Use the laser scanning data obtained from coal-field as an example, the algorithm has been applied to practice and has a good display.	3d projection;3d scanner;algorithm;concave function;delaunay triangulation;linear interpolation;mathematical optimization;polygon mesh;stereoscopy	Yao-Quan Yang;Qi Xiao;Yan-Hui Song	2010	2010 International Conference on Machine Learning and Cybernetics	10.1109/ICMLC.2010.5580584	computer vision;mathematical optimization;convex optimization;delaunay triangulation;ruppert's algorithm;pitteway triangulation;mathematics;chew's second algorithm;surface triangulation;bowyer–watson algorithm	Visualization	70.00946797121378	-42.572287125753576	25467
1e7f24378dd5be28c72f117ef4316d0db378c3f3	exploiting input space symmetries in video deinterlacing using radial basis function networks	image sampling;interpolation;video signal processing;linear filtering;input output;radial basis function networks;interpolation video signal processing radial basis function networks image sampling;network complexity reduction input space symmetries video deinterlacing radial basis function networks video image interpolation video applications standards conversion linear filters input output space geometry images sampling moment based symmetry reduction;intelligent networks radial basis function networks sampling methods lattices tv equations least squares methods smoothing methods vectors eigenvalues and eigenfunctions;radial basis function network	Deinterlacing is the ability to estimate one field in a video image using the other field and as such is a form of interpolation. Such a task is required in many video applications, such as standards conversion. Unfortunately the performance of deinterlacers based on linear filters is unsatisfactory. In a previous paper, we have proposed radial basis function networks as a possible non-linear technique to address the problem. The focus of this paper is to exploit the symmetries that arise in the geometry of the input-output space originated from the sampling of the images. Since radial basis function networks create nonlinear mapping in this space, it is shown that these symmetries can be used to reduce the network's complexity.	deinterlacing;radial (radio);radial basis function	A. Giani;P. R. White;W. B. Collis;M. Weston	2001		10.1109/ICIP.2001.959072	input/output;mathematical optimization;radial basis function;discrete mathematics;interpolation;computer science;theoretical computer science;basis function;machine learning;linear filter;mathematics;activation function;video post-processing;radial basis function network	HCI	75.44556405978366	-41.494115057526095	25517
a00854ab41311142de447d041482288ebba3a80f	inertial aided dense & semi-dense methods for robust direct visual odometry	robot sensing systems;measurement units;visualization;trajectory;transforms;cameras	In this paper we give an evaluation of different direct methods for computing frame-to-frame motion estimates of a moving sensor rig composed of an RGB-D camera and an inertial measurement unit. In particular, we compare how semi-dense and fully dense tracking methods, with and without the aid of an inertial measurement unit (IMU), perform with respect to changes in image resolution, shutter speed, frame-rates, as well as image and depth noise. To perform an accurate and unbiased evaluation we employ a series of synthetically generated datasets using a simulated sensor rig composed of an RGB-D camera and an IMU. Our findings show that in the absence of motion blur or for cameras with high enough frame-rates relative to the camera motion, the methods are comparable when taking in consideration both accuracy and computation time.	computation;gaussian blur;image resolution;movie projector;semiconductor industry;time complexity;visual odometry	Juan M. Falquez;Michael Kasper;Gabe Sibley	2016	2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)	10.1109/IROS.2016.7759530	computer vision;simulation;visualization;engineering;trajectory;units of measurement;quantum mechanics;computer graphics (images)	Robotics	53.93048852166249	-42.116614599322205	25555
090a18e9276de9cf53235a38130c386a3960b03d	auto-calibration methods of kinematic parameters and magnetometer offset for the localization of a tracked mobile robot	localization;kinematic parameters calibration;field robot	Abstract: This paper describes an automatic calibration procedure adopted to improve the localization of an outdoor mobile robot. The proposed algorithm estimates, by using an extended Kalman filter, the main kinematic parameters of the vehicles, such as the wheel radii and the wheelbase as well as the magnetometer offset. Several trials have been performed to validate the proposed strategy on a tracked electrical mobile robot. The mobile robot is aimed to be adopted as a tool to help humanitarian demining operations.	algorithm;encoder;extended kalman filter;gps signals;global positioning system;internationalization and localization;mobile robot;odometry;sampling (signal processing);simulation;yaws	Luciano Cantelli;Samuel Ligama;Giovanni Muscato;Davide Spina	2016	Robotics	10.3390/robotics5040023	control engineering;computer vision;simulation;internationalization and localization;computer science;engineering;robot calibration	Robotics	56.875491072207936	-36.06960041832504	25622
52f3163fe7ea01e19be0721421b9f502a530c144	improving area coverage by reversible object pushing	robot sensing systems;safe robot behaviors area coverage reversible object pushing safety module robot control architecture intrinsic safety action reversibility;area coverage;service robots;robot control;safe robot behaviors;robots;safety;service robot;action reversibility;safety robots;collision avoidance;reversible object pushing;safety robot kinematics robot sensing systems collision avoidance service robots robot control;safety module;intrinsic safety;robot kinematics;robot control architecture	This article presents the implementation of an innovative safety module for a robot control architecture. It applies the principle of reversibility to assess intrinsic safety of actions and to adapt robot's behavior. The underlying idea is that all reversible actions are intrinsically safe. A practical experiment is conducted to demonstrate the approach. The robot's task is to cover a given area with a movable object inside. A governor, acting upon the principle of action reversibility, allows pushing only if such an action is reversible. It is compared with two other governors — one always allows all the actions and the other allows only actions that will not move the object. The covered area and changes between initial and final position of the object are measured in the end of each test run. The proposed governor allows full area coverage with minimal change in object position, while other governors exhibit either incomplete area coverage or significant change in object position. This is interpreted as the ability of the proposed reversibility-based approach to generate both effective and safe robot behaviors.	autonomous robot;intrinsic safety;multi-purpose viewer;obstacle avoidance;real life;reversible computing;robot control	Yuri Gavshin;Maarja Kruusmaa	2011	2011 15th International Conference on Advanced Robotics (ICAR)	10.1109/ICAR.2011.6088579	control engineering;simulation;engineering;control theory	Robotics	60.08974850011172	-25.056502827674837	25704
0956d4f5fb8788bb9abc10e788fa71b9b0f420bb	sketch-based path design	thesis	We present Drive, a system for the conceptual layout of 3D path networks. Our sketch-based interface allows users to efficiently author path layouts with minimal instruction. Our system incorporates some new and noteworthy components. We present the break-out lens, a novel widget for interactive graphics, inspired by break-out views used in engineering visualization. We also make three contributions specific to path curve design: First, we extend our previous work to fit aesthetic paths to sketch strokes with constraints, using piecewise clothoid curves. Second, we determine the height of paths above the terrain using a constraint optimization formulation of the occlusion relationships between sketched strokes. Finally, we illustrate examples of terrain sensitive path construction in the context of road design: automatically removing foliage, building bridges and tunnels across topographic features and constructing road signs appropriate to the sketched paths.	computer graphics;constrained optimization;lasso;locality of reference;mathematical optimization;sketch;topography;usability;user interface	James McCrae;Karan Singh	2009		10.1145/1555880.1555906	computer vision;simulation;computer science;artificial intelligence;machine learning;mathematics;geometry;computer graphics (images)	HCI	66.21106993293944	-46.4310080615566	25766
224cc7a09ff0b132a9708a348b6d36d1b5de8509	periodic component analysis: an eigenvalue method for representing periodic structure in speech	front end;independent com ponent analysis;cost function;periodic structure;auditory processing;eigenvalues;frequency spectrum;principal component analysis;component analysis	"""An eigenvalue method is developed for analyzing periodic structure in speech. Signals are analyzed by a matrix diagonalization reminiscent of methods for principal component analysis (PCA) and independent component analysis (ICA). Our method-called periodic component analysis (1l""""CA)-uses constructive interference to enhance periodic components of the frequency spectrum and destructive interference to cancel noise. The front end emulates important aspects of auditory processing, such as cochlear filtering, nonlinear compression, and insensitivity to phase, with the aim of approaching the robustness of human listeners. The method avoids the inefficiencies of autocorrelation at the pitch period: it does not require long delay lines, and it correlates signals at a clock rate on the order of the actual pitch, as opposed to the original sampling rate. We derive its cost function and present some experimental results."""	autocorrelation;clock rate;cochlear implant;emulator;independent component analysis;interference (communication);loss function;nonlinear system;principal component analysis;sampling (signal processing);spectral density	Lawrence K. Saul;Jont B. Allen	2000			frequency spectrum;speech recognition;eigenvalues and eigenvectors;computer science;front and back ends;machine learning;mathematics;principal component analysis	ML	80.7102651339776	-35.37162859822464	25776
5bb973bde8d6f5ea909853070eef3b9c1ed5fa7b	cooperative control for knee joint flexion-extension movement restoration		This paper describes a cooperative control approach that combines the use of a powered knee joint orthosis along with Functional Electrical Stimulation (FES) for knee joint flexion-extension movement restoration. A closed-loop adaptive control and an open-loop FES of the quadriceps muscle group are combined together to track a desired knee joint angle trajectory of flexion/extension movements. A nonlinear disturbance observer is used to estimate the torque provided by the subject's muscles through the FES. Simulations and experiments with a healthy subject show the feasibility of the proposed approach. Experiments show the repeatability of motion and the complementarity between the torque provided by the quadriceps muscle through FES and the one delivered by the orthosis actuator to ensure satisfactory tracking of the desired trajectory.		Mohamed Amine Alouane;Hala Rifai;Yacine Amirat;Samer Mohammed	2018	2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)	10.1109/IROS.2018.8594230	actuator;computer science;knee joint;control engineering;observer (quantum physics);torque;nonlinear system;control theory;trajectory;adaptive control;functional electrical stimulation	Robotics	70.71412477737326	-27.069385839004415	25777
5648d9ff9a5eec96a87e4cf2a3dd37ac1904b5ff	footprint-profile sweep surface: a flexible method for realtime generation and rendering of massive urban buildings	sweep surface;architectural design;tessellation;urban building;realtime rendering;gpu;large scale;level of detail;model building	Generation of a large-scale city requires a significant amount of manual work and computation to process massive location information and model building geometry with multi-level of details. Normally, an urban city is heavily built-up with different architectural building patterns across extensively and topographically varied landscapes. In this paper, we introduce Footprint-Profile Sweep Surfaces (FPSS), a flexible and computationally efficient approach for realtime generation and rendering of massive urban buildings in a heavily built-up city. A solid constituting an urban building is represented as an instance of FPSS and is generated by sweeping a footprint along a profile with specific parameters. We present two forms of FPSS: super FPSS to address the shapes from architecture design and poly FPSS to address the shapes from imported GIS data. We make use of hardware tessellation to allow dynamic LOD according to view distance. A special scaling-translation-rotation displacement performed on the simplified profile is proposed to support detail generation. Experimental results show that realtime performance can be achieved using our approach to generate varied styles of urban buildings. Even inexperienced users are able to generate a building group quickly in their own style based on FPSS.	algorithmic efficiency;computation;displacement mapping;experience;image scaling	Cheng Liang;George Baciu;Jiahua Zhang;Eddie C. L. Chan;Guiqing Li	2010		10.1145/1889863.1889896	computer vision;simulation;model building;operating system;level of detail;tessellation;computer graphics (images)	HCI	69.0122383633537	-50.47267209729539	25779
2e84deb2fbc518c0ed0ba4158fc063060e5ac1b3	real-time progressive 3d semantic segmentation for indoor scene		The widespread adoption of autonomous systems such as drones and assistant robots has created a need for realtime high-quality semantic scene segmentation. In this paper, we propose an efficient yet robust technique for on-the-fly dense reconstruction and semantic segmentation of 3D indoor scenes. To guarantee (near) real-time performance, our method is built atop an efficient super-voxel clustering method and a conditional random field with higher-order constraints from structural and object cues, enabling progressive dense semantic segmentation without any precomputation. We extensively evaluate our method on different indoor scenes including kitchens, offices, and bedrooms in the SceneNN and ScanNet datasets and show that our technique consistently produces state-of-the-art segmentation results in both qualitative and quantitative experiments.		Quang-Hieu Pham;Binh-Son Hua;Duc Thanh Nguyen;Sai-Kit Yeung	2018	CoRR		robot;precomputation;computer vision;artificial intelligence;iterative reconstruction;image segmentation;semantics;cluster analysis;conditional random field;pattern recognition;computer science;segmentation	Vision	53.93151069208111	-46.5371923085675	25800
ea98278a672a6ee6fbe43060a1ad181f4f8cc40c	subspace dynamic simulation using rotation-strain coordinates	elastic animation;model reduction	In this paper, we propose a full featured and efficient subspace simulation method in the rotation-strain (RS) space for elastic objects. Sharply different from previous methods using the rotation-strain space, except for the ability to handle non-linear elastic materials and external forces, our method correctly formulates the kinetic energy, centrifugal and Coriolis forces which significantly reduces the dynamic artifacts. We show many techniques used in the Euclidean space methods, such as modal derivatives, polynomial and cubature approximation, can be adapted to our RS simulator. Carefully designed experiments show that the equation of motion in RS space has less non-linearity than its Euclidean counterpart, and as a consequence, our method has great advantages of lower dimension and computational complexity than state-of-the-art methods in the Euclidean space.	approximation;centrifugal governor;computation;computational complexity theory;experiment;modal logic;nonlinear system;numerical integration;polynomial;reed–solomon error correction;simulation	Zherong Pan;Hujun Bao;Jin Huang	2015	ACM Trans. Graph.	10.1145/2816795.2818090	mathematical optimization;topology;computer science;hyperplane;mathematics;geometry;algorithm	Graphics	72.81176301410412	-33.17818615183079	25844
3526d9c7e89cf608f1e3493f8b6f6d53b8024918	gesture recognition based relative intensity profiler for different light sources		In this conference proceeding, a novel intensity profile measuring systems is presented that is controlled by gesture recognition principles. This low-cost device works much faster and can be used to measure profiles of wide variety of light sources oriented in elevation and azimuth. Presently, it provides relative intensity measurement but can potentially be used for absolute intensity, if suitably modified. From, the profiles of the standard sources clearly the faulty light sources can be identified and therefore, can save a lot effort.	computation;gesture recognition	Sabarna Choudhury;Shreyasi Bandyopadhyay;Kanik Palodhi	2016	2016 International Conference on Advances in Computing, Communications and Informatics (ICACCI)	10.1109/ICACCI.2016.7732409	computer vision;optics;remote sensing	Robotics	76.68101512892478	-51.09084300868187	25859
3964ba9505a1577339e76868a46cb2a7b9e1dabc	control of a camera for active vision: foveal vision, smooth tracking and saccade	control theory;image processing;degree of freedom;real time;saccade;smooth pursuit;oculomotor;linear optimization;active vision	Several characteristics of the human oculomotor system have been suggested to be useful also for active vision mechanisms. Among others, foveal vision and a tracking scheme based on two different modes, called smooth pursuit and saccade have often been postulated or implemented. The purpose of this paper is to formulate a setup in which the benefit of implementing these schemes can be evaluated in a systematic manner, based on control considerations but incorporating image processing constraints. First, the advantage of using foveal vision is evaluated by computing the size of the foveal window which will allow tracking of the largest possible class of signals. By using linear optimal control theory, this problem can be formulated as a one-variable maximization. Second, foveal vision leads naturally to smooth pursuit, defined as the performance that can be achieved by the controller resulting in the optimal size of the foveal window. This controller is relatively simple (i.e., linear, time-invariant) as is to be expected for this control loop. Finally, when smooth pursuit fails a corrective action must be performed to re-center the target on the fovea. Recent results in linear optimal control, provide the necessary tools for addressing this challenging problem in a systematic manner.	active vision;control system;control theory;entropy maximization;image processing;optimal control;time-invariant system	Ehud Rivlin;Héctor Rotstein	2000	International Journal of Computer Vision	10.1023/A:1008166825510	computer vision;simulation;active vision;image processing;computer science;smooth pursuit;degrees of freedom	Vision	61.67036822623852	-32.91883719929287	25882
1a4b86f2690ae98aa3422685d773b9501ee9ad1d	dielectric elastomer bender actuator applied to modular robotics	torque;experimental analysis;measurement;motor performance;actuators;materials;shape memory alloy;actuators robots dielectrics torque strain materials measurement;position control;robots;self reconfigurable robots;dielectrics;figure of merit;strain;spatial resolution	This paper addresses the miniaturization of the modules of a modular robot - a major challenge in the field. State of the art modules typically use electromagnetic motors for mobility and self-reconfiguration. However, electromagnetic motor performance reduces upon downscaling to the mesoscale. The smallest self-contained module uses shape memory alloy which is inherently inefficient, slow, and difficult to position control. This work surveys available actuation technologies with respect to appropriate figures of merit. It concludes that dielectric elastomer actuation is promising. We present the design and experimental analysis of an agonist-antagonist dielectric elastomer actuator configuration 7 times smaller than previously demonstrated. Demonstrations with two modules show module bending up to 15° in various modular robot morphologies. In addition, we demonstrate parallel actuation: a pair of modules acting in parallel can lift twice the load a single module can.	downscaling;experiment;high-κ dielectric;robotic arm;robotics;self-reconfiguring modular robot	Paul J. White;Stella Latscha;Steve Schlaefer;Mark Yim	2011	2011 IEEE/RSJ International Conference on Intelligent Robots and Systems	10.1109/IROS.2011.6094898	robot;control engineering;figure of merit;electronic engineering;image resolution;computer science;engineering;electrical engineering;artificial intelligence;shape-memory alloy;strain;torque;measurement;experimental analysis of behavior;dielectric;actuator	Robotics	74.8089372759762	-23.954833154483904	25897
f86a2e15c6a0dff3448c8da4fdc49fdf08daf817	an intelligent force control scheme for robotic applications : contact with non-rigid environments		This thesis describes an investigation into the use of a novel intelligent force control scheme that was developed to control the contact force between a mechanical manipulator's end-effector and a range of non-rigid contact environments. The scheme uses a Radial Basis Function (RBF) neural network to model idealised reaction to a range of environments, each with differing degrees of rigidity. During the development of the intelligent force control scheme's neural network, factors that may affect network performance were investigated, including aspects relating to network topology selection and RBF centre placement. Results presented show that a single RBF network was capable of modelling idealised reaction to a range of non-rigid environments to a high degree of accuracy. Once trained, the RBF network was incorporated into a single degree of freedom mechanical manipulator simulation that was developed in the Advanced Continuous Simulation Language and the control system's ability to apply forces to a range of nonrigid environments was investigated by simulation. Results presented demonstrate that satisfactory contact was achievable with a range of non-rigid environments without a priori knowledge of the contact environment's mechanical properties. The intelligent force control scheme's suitability for force application to varying environments was also investigated.		Christian Jay Kordich	1998			human–computer interaction;control engineering;computer science	Robotics	68.29789628897315	-27.208013806291373	26097
9c2d65aaa2672ad4c5361bcc802ebd2f98ad0d84	development of mobile gestural control system of a vehicle		The purpose of this study is development of Mobile Gestural Control System of a Vehicle. The designated coordinate was estimated from the intersection of the location information and the floor of the elbow and wrist. Position control system for moving the vehicle indicated coordinate was designed. When there is an obstacle on the path of the robot, vehicle avoid the obstacle by potential method.	control system;potential method	Ryosuke Okada;Shoshiro Hatakeyama;Masami Iwase	2017	2017 11th Asian Control Conference (ASCC)	10.1109/ASCC.2017.8287369	robot;elbow;potential method;obstacle;control engineering;control system;computer science	Robotics	58.045411387672665	-28.639472862582224	26103
14a97553cf2d5414ec94b14bf22700b1b3c93a0d	some techniques for shading machine renderings of solids	relative position;architectural design;automatic generation;computer graphic;line drawings;spatial organization;sheet metal;industrial design	Some applications of computer graphics require a vivid illusion of reality. These include the spatial organization of machine parts, conceptual architectural design, simulation of mechanisms, and industrial design. There has been moderate success in the automatic generation of wire frame, cardboard model, polyhedra, and quadric surface line drawings. The capability of the machine to generate vivid sterographic pictures has been demonstrated. There are, however considerable reasons for developing techniques by which line drawings of solids can be shaded, especially the enhancement of the sense of solidity and depth. Figures 1 and 2 illustrate the value of shading and shadow casting in spatial description. In the line drawing there is no clue as to the relative position of the flat plane and the sheet metal console. When shadows are rendered, it is clear that the plane is below and to the rear of the console, and the hollow nature of the sheet metal assembly is emphasized. Shading can specify the tone or color of a surface and the amount of light falling upon that surface from one or more light sources. Shadows when sharply defined tend to suggest another viewpoint and improves surface definition. When controlled, shading can also emphasize particular parts of the drawing. If techniques for the automatic determination of chiaroscuro with good resolution should prove to be competitive with line drawings, and this is a possibility, machine generated photographs might replace line drawings as the principal mode of graphical communication in engineering and architecture.	computer graphics;graphical user interface;line drawing algorithm;normal mode;polyhedron;shading;shadow volume;simulation;solidity;spatial organization	Arthur Appel	1968		10.1145/1468075.1468082	computer vision;engineering;engineering drawing;computer graphics (images)	Graphics	66.05783267629508	-38.6221438069517	26116
79f3edf40209fd2c725336457d017e8a038bf128	rotational and translational bias estimation based on depth and image measurements	lyapunov methods;image motion analysis;integro differential equations;spatial variables measurement;observers;computer vision;brightness;partial differential equations;asymptotic observer rotational bias estimation translational bias estimation depth measurement image measurement constant bias linear velocity angular velocity moving object static environment embedded camera depth sensor lyapunov based observer so 3 invariance partial differential equation brightness measurement depth field nonlinear integro partial differential system convergence analysis c3 regularity assumption object motion ascoli arzela theorem observer trajectory precompacity asymptotic convergence rotational symmetry axis;spatial variables measurement brightness cameras computer vision image motion analysis integro differential equations lyapunov methods nonlinear differential equations observers partial differential equations;nonlinear differential equations;cameras;cameras observers adaptation models convergence vectors brightness equations	Constant biases associated to measured linear and angular velocities of a moving object can be estimated from measurements of a static environment by embedded camera and depth sensor. We propose here a Lyapunov-based observer taking advantage of the SO(3)-invariance of the partial differential equations satisfied by the measured brightness and depth fields. The resulting observer is governed by a nonlinear integro/partial differential system whose inputs are the linear/angular velocities and the brightness/depth fields. Convergence analysis is investigated under C3 regularity assumptions on the object motion and its environment. Technically, it relies on Ascoli-Arzela theorem and pre-compacity of the observer trajectories. It ensures asymptotic convergence of the estimated brightness and depth fields. Convergence of the estimated biases is characterized by constraints depending only on the environment. We conjecture that these constraints are automatically satisfied when the environment does not admit any rotational symmetry axis. Such asymptotic observers can be adapted to any realistic camera model. Preliminary simulations with synthetic image and depth data (corrupted by noise around 10%) indicate that such Lyapunov-based observers converge for much weaker regularity assumptions.	angularjs;apache axis;converge;embedded system;lyapunov fractal;mathematical induction;nonlinear system;optic axis of a crystal;simulation;structured-light 3d scanner;synthetic data;time complexity	Nadège Zarrouati-Vissière;Pierre Rouchon;Karine Beauchard	2012	2012 IEEE 51st IEEE Conference on Decision and Control (CDC)	10.1109/CDC.2012.6426484	mathematical optimization;mathematical analysis;control theory;mathematics;partial differential equation;brightness	Robotics	61.2511335971805	-33.30027378996853	26166
37e9688c5be3b5b423acdfb6aea55d7f713a91d6	surface-surface intersection by hermite interpolation	hermite interpolation	A fast heuristic to approximate the intersection curve of two surface patches was originally proposed by Sederberg and Nishita. The patches are rationally parametrized and they cut each other transversely. This paper reports a simple generalization that greatly improves the accuracy of the original heuristic. The generalization either avoids or attenuates the approximation error. Avoidance is achieved when the improved heuristic produces the exact intersection curve; attenuation is accomplished with an aggregate square distance formula guiding the selection of a generalized constraint for a better fit.	aggregate data;approximation algorithm;approximation error;cubic hermite spline;cubic function;gauss–hermite quadrature;graph coloring;hermite interpolation;heuristic	Eng-Wee Chionh	2008			spline interpolation;bilinear interpolation;trigonometric interpolation;birkhoff interpolation;monotone cubic interpolation;interpolation;polynomial interpolation;computer science;hermite interpolation;stairstep interpolation;cubic hermite spline;inverse quadratic interpolation;hermite spline;bicubic interpolation;linear interpolation;nearest-neighbor interpolation;multivariate interpolation;trilinear interpolation	Robotics	70.37349739212891	-41.26787085128105	26275
c739f6a178740d776b3758e5da56ad8df4ea9bfb	rotational and helical surface approximation for reverse engineering	concepcion asistida;computer aided design;fabricacion asistida por computador;approximation numerique;espace euclidien;surface of revolution;geometrie algorithmique;etude experimentale;computational geometry;retroingenierie;espacio euclidiano;segmentation;aproximacion numerica;algorithme;algorithm;fabrication assistee;computer aided manufacturing;helical surface;conception assistee;superficie;euclidean space;surface;geometria computacional;method of lines;numerical approximation;surface revolution;estudio experimental;ingeniera inversa;segmentacion;revolution surface;line geometry;reverse engineering;algoritmo;surface approximation	Given a surface in 3-space or scattered points from a surface, we investigate the problem of deciding whether the data may be fitted well by a cylindrical surface, a surface of revolution or a helical surface. Furthermore, we show how to compute an approximating surface and put special emphasis to basic shapes used in computer aided design. The algorithms apply methods of line geometry to the set of surface normals in combination with techniques of numerical approximation. The presented results possess applications in reverse engineering and computer aided manufacturing.	algorithm;approximation;computer-aided design;normal (geometry);numerical analysis;reverse engineering	Helmut Pottmann;Thomas Randrup	1998	Computing	10.1007/BF02684378	computational geometry;euclidean space;line;calculus;surface of revolution;mathematics;geometry;surface;segmentation;method of lines;reverse engineering	Theory	67.56927102503475	-40.07392381585448	26361
e2efa6503277cbda1778d92a129f640848a6b266	spline fit made easy	interpolation;approximation;spline function;numerical algorithm;curve fitting;approximation curve fitting interpolation numerical algorithm spline function;cubic spline	In this paper, a new algorithm for a cubic spline fit with equally spaced data points and given end conditions is described. It provides a new understanding of how a spline fit works and possesses the following computational advantages: 1) It can solve large size problems (virtually unlimited). 2) The accuracy can be realistically controlled based on the characteristics of data. 3) The computation time-is linearly proportional to the size of the problem. 4) It can handle a localized fit. 4) It can handle a localizd. The new algorithm is particularly suitable to be implemented in minicomputers for cutting surfaces by numerically controlled machines and for other applications.	algorithm;computation;cubic hermite spline;cubic function;data point;minicomputer;numerical analysis;spline (mathematics);time complexity	Ming-Lei Liou	1976	IEEE Transactions on Computers	10.1109/TC.1976.1674640	spline interpolation;b-spline;spline;econometrics;mathematical optimization;perfect spline;smoothing spline;monotone cubic interpolation;interpolation;cubic hermite spline;hermite spline;mathematics;thin plate spline;polyharmonic spline;flat spline;m-spline;statistics;curve fitting	Visualization	70.6422400429147	-40.836495060925195	26384
7b18701e126978816f9f66f448f3c45c6f8c8b32	dynamic body transformation and matching from scanned data	complex objects;biological system modeling humans solid modeling computer graphics interpolation shape application software manufacturing industries animation computational modeling;design tool;interpolation;manufacturing studies dynamic body transformation data matching scanned data human body modelling computer graphics interpolation body shape modelling body size modelling graphical modeling entertainment industry character animation virtual reality ergonomic studies;computational geometry;virtual reality;satisfiability;computer graphic;human body model;3d scanning;human body;graphical model;character animation;interpolation computational geometry solid modelling;geometric constraints;interaction design;body shape;solid modelling	Summary form only given. Appropriate combinations of statistical and geometric methods permit modeling and estimation of complex objects. This paper investigates such combinations in the modeling of human body models in computer graphics. By concentrating on such a particular class of objects, we show how example based techniques together with interpolation ones can exploit existing data and knowledge about body shape and size modelling. Graphical modeling of human bodies obviously has applications in the entertainment industry for character animation and simulations involving people. Other applications range from virtual reality to ergonomic and manufacturing studies.	computer graphics;estimation theory;human factors and ergonomics;interpolation;simulation;virtual reality	Nadia Magnenat-Thalmann;Hyewon Seo	2004	Proceedings Shape Modeling Applications, 2004.	10.1109/SMI.2004.1314488	computer vision;simulation;computer science;computer graphics (images)	Graphics	68.90066596262976	-46.88069660595406	26405
d86447e9cb353b27f01353e1f7272a3fe2d146fe	study of quadruped walking robot climbing and walking down slope	robot sensing systems;legged locomotion;tactile sensor;tactile sensors angular measurement mobile robots position control;jtuwm ii;gravity;foot;angular measurement;mobile robots;slope ascent;tactile sensors slope climbing slope ascent slope descent gradient measurement quadruped walking robot jtuwm ii;stability;parallel robots;position control;slope climbing;walking robot;slope descent;servomechanisms;gradient measurement;tactile sensors;servomotors;legged locomotion robot sensing systems foot tactile sensors leg parallel robots gravity stability servomechanisms servomotors;quadruped robot;body height;quadruped walking robot;leg	Authors of this paper have made experimental s tudy on quadruped walking robot climbing and walking down the slope with JTUWM-I1 a quadruped robot designed and constructed by Shanghai Jiao Tong University. A scheme that the walking robot detects the slope and measures the gradient of the slope with tactile sensors is proposed. A n algorithm for t h e body turn t o parallel with t h e sloping surface is developed. In the transition area gait adjustment is made for stable walking. Also the maximum gradient of the slope for the robot and the optimum body height are given.	algorithm;bundle adjustment;gradient;hill climbing;human height;mobile robot;tactile sensor	Junmin Pan;Junshi Cheng	1991		10.1109/IROS.1991.174729	control engineering;simulation;computer science;engineering;artificial intelligence;control theory;tactile sensor	Robotics	67.04278437294012	-24.302292572253172	26413
1e6947c50052f935c6fe0a4c5d198bb0ec9a2992	least squares and maximum likelihood estimation of mixed spectra		In this paper, we propose a novel I-D spectral estimator for signals with mixed spectra. The proposed method is partly based on the recently introduced smooth spectral estimator LIMES, in which the smoothness is accounted for by assuming linearity within predefined segments of the spectrum. The proposed method utilizes this formulation but also allows segments to change size to better estimate the spectrum, thereby allowing for the estimation of spectra that are neither completely smooth or sparse in frequency, but rather contains a mixture of such components. Using simulated data, we illustrate the performance of the proposed estimator, comparing to other recent spectral estimation techniques.		Johan Brynolfsson;Johan Sward;Andreas Jakobsson;Maria Sandsten	2018	2018 26th European Signal Processing Conference (EUSIPCO)	10.23919/EUSIPCO.2018.8553105		Vision	81.49889372294376	-36.89475961321176	26427
c988e11d3e644675bbeab425589fe732e1bc94ad	compressing music recordings into audio summaries		We present a criterion to generate audible summaries of music recordings that optimally explain a given track with mutually disjoint segments of itself. We represent audio as sequences of beat-synchronous harmonic features and use an exhaustive search to identify the best summary. To demonstrate the merit of this approach, we evaluate the criterion and show consistency across a collection of multiple recordings of different works. Finally, we present a fast algorithm that approximates the exhaustive search and allows us to automatically learn the hyperparameters of the algorithm for a given track.	algorithm;brute-force search	Oriol Nieto;Eric J. Humphrey;Juan Pablo Bello	2012			speech recognition;computer science;machine learning;data mining	ML	79.59920948177705	-33.41667765827212	26497
8edea4205b864ce4dd32e7413eaf90d4ae0a392d	reliable positioning domain computation for urban navigation	reliability;uncertainty;confidence intervals;automatic vehicle monitoring;metrics quantitative assessment;ground truth equipment reliable positioning domain computation intelligent vehicle navigation interval based positioning method integrity monitoring global positioning system gps 3d map drivable area interval analysis constraint positioning problem robust set inversion redundant measurement set measurement noise confidence domain;navigation;urban areas;global positioning system;intelligent vehicles;global positioning system uncertainty road traffic reliability intelligent vehicles monitoring receivers navigation;traffic engineering computing;traffic engineering computing global positioning system;validation	Reliable positioning is a key issue for intelligent vehicle navigation. Interval-based positioning methods have shown to be capable of computing relevant confidence domains used for integrity monitoring in environments which are challenging for Global Positioning System (GPS). The approach presented in this paper consists in tightly coupling a GPS receiver with a 3D-map of the drivable area. Interval analysis is employed to solve the constraint positioning problem using contractions and bisections. Integrity is provided through the use of a robust set inversion scheme applied to a redundant measurement set. If the prior distribution of the measurement noise is known, it is possible to compute confidence domains that correspond to a given integrity risk, which is often set very low out of safety considerations. In this paper we examine a way of validating the proposed approach, using a real experimental dataset and a ground truth equipment. Different tunings of the method, corresponding to different risks, are assessed in terms of availability and integrity in order to compute statistical metrics. Results indicate that this methodology is relevant since the specified risk corresponds to experimental observations.	algorithm;computation;global positioning system;ground truth;interval arithmetic;risk aversion	Vincent Drevelle;Philippe Bonnifait	2013	IEEE Intelligent Transportation Systems Magazine	10.1109/MITS.2013.2252058	control engineering;embedded system;receiver autonomous integrity monitoring;navigation;simulation;confidence interval;uncertainty;global positioning system;engineering;precise point positioning;reliability;hybrid positioning system;statistics	Robotics	53.947434977125425	-28.252767976059815	26506
05af573e26ad07cf2509f1202c2faf541f254455	minkowski sum boundary surfaces of 3d-objects	quadratic approximation;signed distance function;distance function;envelope marching algorithm point set surface signed distance function;aproximacion cuadratica;envelope;convolution surface translation;computer graphics;convolution;convolution surface;digitizing;piecewise smooth;metrique minkowski;cinematica;metrico minkowski;convolucion;triangular mesh;numerisation;motion;kinematics;marching algorithm;approximation quadratique;translation;cinematique;distancia;numerizacion;minkowski metric;point cloud;minkowski sum;grafico computadora;infographie;point set surface;distance	Given two objects A and B with piecewise smooth boundary we discuss the computation of the boundary Γ of the Minkowski sum A+B. This boundary surface Γ is part of the envelope when B is moved by translations defined by vectors a ∈ A, or vice versa. We present an efficient algorithm working for dense point clouds or for triangular meshes. Besides this the global self-intersections of the boundary Γ are detected and resolved. Additionally we point to some relations between Minkowski sums and kinematics, and compute local quadratic approximations of the envelope. keywords: Minkowski sum, convolution surface, translation, motion, envelope, marching algorithm, point-set surface, signed distance function.	algorithm;approximation;computation;convolution;data point;data structure;matlab;minkowski addition;normal (geometry);numerical aperture;point cloud;triangle mesh;triangulated irregular network	Martin Peternell;Tibor Steiner	2007	Graphical Models	10.1016/j.gmod.2007.01.001	translation;signed distance function;envelope;kinematics;mathematical analysis;minkowski space;topology;metric;triangle mesh;motion;minkowski addition;point cloud;mathematics;geometry;convolution;computer graphics;distance	Vision	67.83190695070198	-40.82103194392952	26581
dbd1a0d085b7e41bd363fcc707eb5cd941409fd7	improving pitch detection through emphasized harmonics in time-domain		In speech signal processing, it is crucial to detect the accurate pitch period of voice in time domain. The concept of pitch period is being utilized in various fields, including systems for speech enhancement, automatic speech recognition, speaker classification, and even voice guiding for the visually impaired. The periodicity of a voice signal has been emphasized in order to detect the pitch period more accurately as we can see in the current techniques, such as ’peak and valley technique,’ ’auto-correlation method,’ or ’center-clipping and signal-square.’ However, all of these methods present a problem in finding accurate pitch period due to noise as well as the transitional section between voiced and unvoiced sounds. This paper proposes an improved method for detecting pitch period in time domain more accurately by using emphasized harmonics through non-linear clipping and synthesis technique.	pitch detection algorithm	Hyung-Woo Park;Myung-Sook Kim;Myung-Jin Bae	2012		10.1007/978-3-642-35603-2_27	computer vision;harmonics;signal processing;time domain;clipping (audio);pitch detection algorithm;speech enhancement;artificial intelligence;computer science	NLP	80.82918403495084	-33.95636445113164	26637
cd6bd1c5c6c7b1a933fce5e102ac8173865337a3	guest editorial: focused section on advances in soft robotics		Inspired by biological organisms including worms, octopuses, and starfish, the emerging field of soft robotics aims to create robots with soft structures, sensors, and actuators (Rus and Tolley 2015; Laschi et al. 2012; Brown et al. 2010; Shepherd et al. 2011; Rogers et al. 2010; Park et al. 2010). Compared with traditional ‘‘rigid’’ robots, soft robots can more safely interact with humans. Additionally, their ‘‘soft’’ and compliant bodies enable them to navigate through unstructured, cluttered environments, for example, squeezing through narrow openings and turning tight corners. Potential applications of soft robots include robotic surgery, prosthetics and orthotics, elder care, surveillance, search and rescue, among others. The development of soft robots presents a number of challenges in material synthesis, mathematical modeling, mechanism design, and control, and in recent years has attracted increasing attention from researchers. For instance, a soft robot comprised of sensors, actuators, and structures, all with soft, deformable, and compliant characteristics, requires advances in material development and manufacturing technology. Also, it is crucial to have distributed, effective control architecture that requires minimal computing power. Finally, it is of great importance to develop computationally-efficient modeling tools for soft and deformable materials and structures. The goal of this focused section (FS) is to highlight some of the recent advances made in the field of soft robotics. A total of 13 submissions were received. After a rigorous peer-review process, eight papers were accepted to be included in this FS. Among these, the first two papers focus on novel materials for soft robots, the next three papers explore sensing and actuation mechanisms, and the last three papers examine robotic systems involving soft or flexible elements. A brief description of each paper’s contributions follows.	humans;mathematical model;robot;sensor;soft robotics;tolley (company);word lists by frequency	Xiaobo Tan;Kam K. Leang;Zhou-Ping Yin	2017	International Journal of Intelligent Robotics and Applications	10.1007/s41315-017-0021-y	simulation;computer engineering;computer science;soft robotics	Robotics	66.95800821406124	-28.286650527381386	26688
8b2aabd4a3cd2be4f227e7ffcbb176f8dc369c28	new algorithm for efficient polygon decimation for virtual reality applications in medicine	treatment planning;plan tratamiento;informatica biomedical;biomedical data processing;realite virtuelle;aplicacion medical;realidad virtual;informatique biomedicale;polygone;virtual reality;plan traitement;algorithme;polygon;algorithm;chirurgie;surgery;poligono;medicine;cirugia;medical application;application medicale;algoritmo	The availability of high speed computers and high data storage capacities has facilitated the development of practicalvirtual reality (VR) systems. YR uses computer modeling and simulation to enable human interactions with artificialthree-dimensional visual or other sensory environments. In medicine, YR systems have the potential to significantly advancethe practice of surgery. Surgery planning and rehearsal can be effectively carried out on YR systems, eliminating or significantlyreducing the need for exploratory surgery.There are two components of YR applications that we consider in this paper. The first is three dimensional (3D)graphics modeling. YR and 3D graphics modeling is growing in medical applications, especially surgery (1-3). Toolkits havebeen developed to visualize and analyze three dimensional data sets and anatomic models (4). The second component is real timecontrol over anatomic models. Real time processing and rapid display updating are essential for a VR system to be practicallyuseful in medical applications. In order to give the general impression of reality to the user, the model must respond in real timeto user inputs. As the user interacts with the model, the visual display and response to peripheral input must be rapidly updatedin order to achieve the feel of a real system. This must take place at a high repetition rate, typically 30 frames per second.Most YR models are formed by connecting a set of polygons together to represent the shape of the surface of theunderlying object. This process is called tiling. It is analogous to how a cube is formed by connecting six squares together.Triangles are the most common drawing primitive used for tiling in computer graphics, and specialized graphics hardware canrender them very quickly. Polygons can generally represent any model to any desired degree of accuracy. Unfortunately, as theshape complexity increases, so does the number of required polygons to achieve a high level of accuracy. The increase of numberof polygons relative to the accuracy required is approximately exponential (5).	algorithm;decimation (signal processing);virtual reality	Dennis D. Crouch;Richard A. Robb	1997		10.1117/12.273930	simulation;engineering;artificial intelligence;cartography	Visualization	68.83591398881434	-49.502455222781784	26699
08d2f5a812e559167606e097cec5c943e0a4a4a1	a single-perspective novel panoramic view from radially distorted non-central images	radial distortion;satisfiability;multiple views;epipolar geometry;view synthesis;field of view	In this paper, we propose an image-based technique for panor amic novelview generation using three uncalibrated wide-angle image s s its input. State of the art in novel view generation presumes the calibration and removal of radial distortion or any other deformation resulting from t he geometry of a non-central camera. We propose a method which replaces this calibration with the assumption that the epipole corresponding to the no v l viewpoint is at the center of radial distortion and that it is known.	distortion;epipolar geometry;homography (computer vision);image rectification;norm (social);radial (radio)	Rana Molana;Kostas Daniilidis	2007		10.5244/C.21.45	distortion;computer vision;field of view;mathematics;geometry;epipolar geometry;satisfiability	Vision	55.23952415912629	-51.13834968741365	26797
83fe56678e68f505ef8955850b359ce2ecae157f	simplified vehicle calibration using multilinear constraints	matematik	An Autonomously Guided Vehicle using both odometry and visual data for navigation needs calibration parameters. These include camera placement as well as parameters relating odometry to vehicle motion. Calibration of these parameters is related to the Hand-Eye calibration problem. Instead of using a calibration target or trying to solve for structure and motion a novel method using the continuous multilinear constraint to test parameter combinations is proposed. A low order polynomial target function is calculated in linear time over the sample size resulting in very fast iterations in the optimisation step.#R##N##R##N#The method is tested on simulated data and increased sample size improves the parameter estimates.		Henrik Stewénius	2003		10.1007/3-540-45103-X_89	computer vision;mathematical optimization;computer science;odometry;control theory;mathematics	Vision	54.214186591133796	-40.63800499883393	26800
73845d4b09f8e7ee235d31690f4f1b5cb80918ed	verification of sinusoidal steady state system identification of a phantom omni haptic device using data driven modeling	sinusoidal steady state behaviour sinusoidal steady state system identification phantom omni haptic feedback device dynamic model sinusoidal steady state analysis data driven model pseudo random binary sequences phase response frequency response prbs response data spectral estimate dynamic equation;phantoms;joints;identification binary sequences frequency response haptic interfaces;accuracy;estimation;mathematical model;mathematical model data models phantoms joints accuracy haptic interfaces estimation;minimal modeling system identification data driven modeling;haptic interfaces;data models	Haptic feedback has two important sources of dynamics: the machine being controlled and the haptic device itself. This paper concentrates on the means of identifying the dynamics of a Phantom Omni haptic feedback device. Two models are compared: a dynamic model with parameters using results from sinusoidal steady state analysis and a data driven model that uses pseudo-random binary sequences (PRBS) for identification. The overall form of the frequency and phase response is well-defined for the dynamics model but for the data driven model a spectral estimate from PRBS response data is used to determine the model order. The results in this paper show that a dynamic equation based minimal model produces accuracy as good as the data driven model. While the data driven model has more fitting accuracy the increase in accuracy is not useful for modelling the physical response as the differences occur at high frequencies where the Phantom arm is not sensitive anyway. The dynamic model is particularly useful as it gives a physical basis for the observed output and the sinusoidal steady state behaviour is useful for exposing non-linearities. Future work includes development and verification an arm inertia model that allows system parameters to be identified from response data at arbitrary arm angles.	arm architecture;haptic technology;mathematical model;phantom reference;pseudorandom binary sequence;pseudorandomness;steady state;system identification	Bart Milne;H. P. G. J. Beelen;R. W. H. Merks;Siep Weiland;Xiaoqi Chen;Christopher E. Hann;R. J. Parker	2015	2015 6th International Conference on Automation, Robotics and Applications (ICARA)	10.1109/ICARA.2015.7081161	data modeling;estimation;simulation;computer science;mathematical model;control theory;accuracy and precision;statistics	Robotics	69.07895904314533	-28.478949734573952	26814
7a27ac487c58352313e94634b24b9117ff2da605	accurate pose and location estimation of uncalibrated camera in urban area	lens distortion;photogrammetry;location estimation;remote sensing calibration cameras photogrammetry pose estimation position measurement;urban areas optical distortion calibration layout lenses digital cameras surface reconstruction solid modeling image reconstruction urban planning;vanishing point;building reconstruction;remote sensing;position measurement;urban area;building reconstruction vanishing point camera calibration pose estimation rapid response;camera calibration;geometric constraints;geometric constraints uncalibrated camera pose estimation uncalibrated camera location estimation urban area calibration method multiview vanishing point building scene lens distortion parameters lens orientation parameters;calibration;cameras;rapid response;pose estimation	This paper proposes an improved calibration method based on multi-view's vanishing point to estimate the accurate pose and location parameters of camera in building scene. This method put the lens distortion and orientation parameters of camera directly into the calibration mode. Furthermore, using the line feature existing in the building surface, geometric constraints are introduced into the calibrating model. The orientation parameters of camera can be estimated accurately by this method.	distortion;vanishing point	Wenhan Xie;Xiang Lin;Guoqing Zhou;Yucai Xue	2009	2009 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2009.5417399	distortion;computer vision;camera auto-calibration;calibration;camera resectioning;pose;vanishing point;computer science;optics;physics;photogrammetry;pinhole camera model;remote sensing	Robotics	54.08409906386676	-49.363676842077226	26835
165a09e6a76af8c6e914c88dd6c7d1366464a921	facial metamorphosis using geometrical methods for biometric applications	biometric modeling;nonphotorealistic rendering;morphing;distance transform;facial expression synthesis;voronoi diagram	Facial expression modeling has been a popular topic in biometrics for many years. One of the emerging recent trends is capturing subtle details such as wrinkles, creases and minor imperfections that are highly important for biometric modeling as well as matching. In this paper, we suggest a novel approach to the problem of expression modeling and morphing based on a geometry-based paradigm. In 2D image space, a distance-based morphing system is utilized to create a line drawing style facial animation from two input images representing frontal and profile views of the face. Aging wrinkles and expression lines are extracted and mapped back to the synthesized facial NPR (nonphotorealistic) sketches. In 3D object space, we present a metamorphosis system that combines the traditional free-form deformation (FFD) model with data interpolation techniques based on the proximity preserving Voronoi diagram. With feature points selected from two images of the target face, the proposed system generates the 3D target facial model by transforming a generic model. Experimental results demonstrate that morphing sequences generated by our systems are of convincing quality.	biometrics	Yuan Luo;Marina L. Gavrilova;Patrick Shen-Pei Wang	2008	IJPRAI	10.1142/S0218001408006399	computer vision;voronoi diagram;computer science;distance transform;morphing;computer graphics (images)	HCI	63.827268522164104	-46.504486119017564	26865
b2a7be2dab8f8c6f8b38ac8373b25a4db16ab0ed	procedural 3d reconstruction of puuc buildings in xkipché	geographic information system;model system;categories and subject descriptors according to acm ccs f 4 2 mathematical logic and formal languages grammars and other rewriting systems i 3 5 computer graphics computational geometry and object modeling i 6 3 simulation and modeling applications j 6 computer aided engineering computer aided design cad;psi_visics;geometric model;building design;3d reconstruction	This paper examines how architectural shape grammars can be used to procedurally generate 3D reconstructions of an archaeological site. The Puuc-style buildings found in Xkipché, Mexico, were used as a test-case. We first introduce the ancient Mayan site of Xkipché and give an overview of the building types as distinguished by the archaeologists, based on excavations and surveys of the building remains at the surface. Secondly, we outline the elements of the building design that are characteristic of the Puuc architecture. For the creation of the actual building geometries, we further determine the shape grammar rules for the different architectural parts. The modeling system can then be used to reconstruct the whole site based on various GIS (Geographical Information Systems) data given as input, such as building footprints, architectural information, and elevation. The results demonstrate that our modeling system is, in contrast to traditional 3D modeling, able to efficiently construct a large number of high quality geometric models at low cost.	3d modeling;3d reconstruction;display resolution;encode;geographic information system	Pascal Müller;Tijl Vereenooghe;Peter Wonka;Iken Paap;Luc Van Gool	2006		10.2312/VAST/VAST06/139-146	3d reconstruction;computer vision;computer science;artificial intelligence;theoretical computer science;geometric modeling;building design;geographic information system	Graphics	58.75724556883356	-45.36266841070234	26877
831c5c21e1418147d0867843a59715c579b2e11d	efficient collision detection for spherical blend skinning	sbs;sphere refitting;real time;spherical blending;virtual reality;real time simulation;conference paper;3d model;collision detection;on demand refitting;virtual environment	Recently, two algorithms improving the real-time simulation of articulated models in virtual environments have been published: 1) fast collision detection for linear blend skinning and 2) spherical blend skinning. Both linear and spherical blending solve the skinning problem of a skeletally controlled 3D model (e.g., an avatar), but only spherical blending avoids artifacts such as the candy-wrapper. However, to date, fast collision detection has been limited to linear blending. This paper describes how to perform collision detection for models skinned with the more sophisticated spherical method. As a result, both high-quality skinning and fast and exact collision detection can be achieved - there is no longer any need for a trade-off. The generalization from linear to spherical blending involves the construction of rotation bounds, derived using a quaternion representation. The resulting algorithm is simple to implement and fast enough for real-time virtual reality applications.	algorithm;alpha compositing;collision detection;polygonal modeling;real-time locating system;simulation;skin (computing);virtual reality	Ladislav Kavan;Carol O'Sullivan;Jirí Zára	2006		10.1145/1174429.1174452	simulation;computer science;virtual machine;artificial intelligence;virtual reality;collision detection;computer graphics (images)	Graphics	69.00457279284488	-47.26221308242887	26910
d4e86f534fdeeb26b38cb1b1c5c46ebca60ae612	compressing color data for voxelized surface geometry		We explore the problem of decoupling color information from geometry in large scenes of voxelized surfaces and of compressing the array of colors without introducing disturbing artifacts. In this extension of our I3D paper with the same title, we first present a novel method for connecting each node in a sparse voxel DAG to its corresponding colors in a separate 1D array of colors, with very little additional information stored to the DAG. Then, we show that by mapping the 1D array of colors onto a 2D image using a space-filling curve, we can achieve high compression rates and good quality using conventional, modern, hardware-accelerated texture compression formats such as ASTC or BC7. We additionally explore whether this method can be used to compress voxel colors for off-line storage and network transmission using conventional off-line compression formats such as JPG and JPG2K. For real-time decompression, we suggest a novel variable bitrate block encoding that consistently outperforms previous work, often achieving two times the compression at equal quality.		Dan Dolonius;Erik Sintorn;Viktor Kampe;Ulf Assarsson	2017	IEEE transactions on visualization and computer graphics	10.1109/TVCG.2017.2741480	computer vision;computer science;compression;computer graphics (images)	Visualization	67.80407660014536	-50.2721557698433	26951
00325bc76e6660f83a64c8e9ceb49a7f97546bed	a p-multigrid algorithm using cubic finite elements for efficient deformation simulation	i 3 5 computer graphics;i 3 7 computer graphics;computational geometry and object modeling;animation;three dimensional graphics and realism;physically based modeling	We present a novel p-multigrid method for efficient simulation of co-rotational elasticity with higher-order finite elements. In contrast to other multigrid methods proposed for volumetric deformation, the resolution hierarchy is realized by varying polynomial degrees on a tetrahedral mesh. We demonstrate the efficiency of our approach and compare it to commonly used direct sparse solvers and preconditioned conjugate gradient methods. As the polynomial representation is defined w.r.t. the same mesh, the update of the matrix hierarchy necessary for co-rotational elasticity can be computed efficiently. We introduce the use of cubic finite elements for volumetric deformation and investigate different combinations of polynomial degrees for the hierarchy. We analyze the applicability of cubic finite elements for deformation simulation by comparing analytical results in a static scenario and demonstrate our algorithm in dynamic simulations with quadratic and cubic elements. Applying our method to quadratic and cubic finite elements results in speed up of up to a factor of 7 for solving the linear system.	algorithm;cubic function;finite element method;multigrid method;simulation	Daniel Weber;Johannes Mueller-Roemer;Christian Altenhofen;André Stork;Dieter W. Fellner	2014		10.2312/vriphys.20141223	computer representation of surfaces;computational science;scientific visualization;2d computer graphics;computer science;local feature size;theoretical computer science;polygonal modeling;ray casting;real-time computer graphics;computer graphics;3d computer graphics;computer graphics (images)	EDA	69.85660108034405	-46.95556697001781	26984
7907a20ebc5834c438f4b7608c8f1355ef7d96a9	iapcloud: a cloud control platform for heterogeneous robots		The cloud robotic technology makes multiple robots share resources and collaborate with each other more flexibly. Although this concept has been widely accepted by academia since it was put forward, it still faces many challenges in engineering. The main problems are that the functions of industrial robotic systems become more and more complex, and the programming language and computing environment of multiple vendor robots are significantly different, accordingly the cooperative control of different devices and the online testing become extremely difficult. Therefore, this paper proposes a new control platform for cloud robots, called IAPcloud, which has significant advantages in solving the problem of collaborative control among heterogeneous robots and their auxiliary devices, declining the programming difficulties of cloud robotic control systems and shortening the development and deployment cycle of the application. Finally, we verify the scientific and effectiveness of the IAPcloud platform by three cases, including the image recognition and tracking, the human–machine gobang game, and the online dynamic reconfiguration of control algorithms.	algorithm;computer vision;consensus dynamics;control system;gomoku;industrial robot;programming language;software deployment	Song Zheng;Zhicheng Lin;Qijun Zeng;Rong Zheng;Chaoru Liu;Huafeng Xiong	2018	IEEE Access	10.1109/ACCESS.2018.2837904	software deployment;cloud computing;vendor;control reconfiguration;robot;distributed computing;computer science;robot kinematics;control system	Robotics	64.5833507873521	-29.24889040599066	26985
8e8ff060215d8c3971b28f32d3c77744a86d1d44	cross-sectional design with curvature constraints	skinning;interpolation;tecnologia electronica telecomunicaciones;engineering design;computacion informatica;grupo de excelencia;b spline curve;approximation;b spline surface;ciencias basicas y experimentales;smoothing;industrial application;cross section;optimization;tecnologias;design methodology	A practical example of B-spline curve control points manipulation for the geometric construction of a free form shape is presented. Elements of a cross-sectional design methodology are used in conjunction with a skinning type operator for the definition of a B-spline surface. Skinning process are well established in the CAD community but further difficulties arise in producing smooth surfaces under constraints. This paper attempts to overcome the fairness problem by choosing an appropriate solution where the execution time has to be reasonably short. Main results include an industrial application in a preliminary aerodynamic design cycle where manufacturing tolerances defined by smoothness criteria are maintained.	algorithm;b-spline;computer-aided design;cross-sectional data;design for manufacturability;enriques–kodaira classification;fairness measure;geometric modeling;heuristic;mathematical optimization;rate of convergence;run time (program lifecycle phase);simulated annealing;skin (computing);spline (mathematics);type constructor	Anas Bentamy;François Guibault;Jean Yves Trépanier	2005	Computer-Aided Design	10.1016/j.cad.2005.03.005	design methods;interpolation;engineering;approximation;mathematics;cross section;geometry;engineering drawing;engineering design process;statistics;smoothing;mechanical engineering	EDA	70.50773597430647	-42.97455114250431	26992
350348c9fc1916c13034f901203a359d088f7db9	optimal path planning for an unmanned aerial vehicle under navigation relayed by multiple stations to intercept a moving target		The navigation relayed by multiple stations (NRMS) is a cooperative navigation technology which relies on multiple stations to guide an unmanned aerial vehicle (UAV) sequentially. The stations which are scattered in different spatial locations provide the navigation information or the control command for the UAV. This paper addresses the optimal path planning problem for a UAV navigated by the NRMS technology to intercept a moving target. This problem is formulated as a constrained optimization problem which involves four constraints: the navigation range constraint, the navigation handover constraint, the maximum turning angle constraint, and the time difference constraint. The first two constraints distinguish our problem from other path planning problems. A differential evolution based (DE-based) path planning algorithm is proposed to find a feasible and high-quality path for the UAV. The numerical stability and effectiveness of the DE-based path planning algorithm are demonstrated by computational experiments.	aerial photography;algorithm;automated planning and scheduling;computation;computer simulation;constrained optimization;constraint (mathematics);differential evolution;experiment;mathematical optimization;motion planning;numerical stability;optimization problem;prospective search;unmanned aerial vehicle;visual intercept;waypoint	Mingfeng Qi;Lihua Dou;Bin Xin;Jie Chen	2017	2017 IEEE 56th Annual Conference on Decision and Control (CDC)	10.1109/CDC.2017.8264057	mathematical optimization;handover;range constraint;differential evolution;computer science;motion planning;numerical stability;constrained optimization	Robotics	55.28235626034074	-25.512349628280667	27021
3ba43818d536422ae225db735d3ff21e0d06b6d2	a theory of multi-layer flat refractive geometry	pose estimation multilayer flat refractive geometry theory multiple parallel flat refractive mediums single flat refractive mediums axial camera 2d 3d correspondences calibration refracting layer orientation refractive indices axis estimation classical essential matrix computation 5 point algorithm layers thicknesses analytical forward projection equations afp equations 3d point projection computation nonlinear refinement reprojection error minimization 4 th degree equation 12 th degree equation noise stability two layer system single layer system;geometry;computational geometry;matrix algebra;vectors;estimation;light refraction;refractive index calibration cameras computational geometry light refraction matrix algebra pose estimation;mathematical model;refractive index;cameras calibration equations vectors geometry estimation mathematical model;calibration;cameras;pose estimation	Flat refractive geometry corresponds to a perspective camera looking through single/multiple parallel flat refractive mediums. We show that the underlying geometry of rays corresponds to an axial camera. This realization, while missing from previous works, leads us to develop a general theory of calibrating such systems using 2D-3D correspondences. The pose of 3D points is assumed to be unknown and is also recovered. Calibration can be done even using a single image of a plane. We show that the unknown orientation of the refracting layers corresponds to the underlying axis, and can be obtained independently of the number of layers, their distances from the camera and their refractive indices. Interestingly, the axis estimation can be mapped to the classical essential matrix computation and 5-point algorithm [15] can be used. After computing the axis, the thicknesses of layers can be obtained linearly when refractive indices are known, and we derive analytical solutions when they are unknown. We also derive the analytical forward projection (AFP) equations to compute the projection of a 3D point via multiple flat refractions, which allows non-linear refinement by minimizing the reprojection error. For two refractions, AFP is either 4th or 12th degree equation depending on the refractive indices. We analyze ambiguities due to small field of view, stability under noise, and show how a two layer system can be well approximated as a single layer system. Real experiments using a water tank validate our theory.	3d reconstruction;apache axis;approximation algorithm;autostereogram;computation;degree (graph theory);distortion;essential matrix;experiment;image noise;layer (electronics);nonlinear system;numerical linear algebra;optic axis of a crystal;refinement (computing);reprojection error;virtual reality headset	Amit K. Agrawal;Srikumar Ramalingam;Yuichi Taguchi;Visesh Chari	2012	2012 IEEE Conference on Computer Vision and Pattern Recognition	10.1109/CVPR.2012.6248073	mathematical optimization;estimation;calibration;pose;refraction;computational geometry;mathematical model;mathematics;geometry;refractive index	Vision	55.09509875004677	-51.73074355173379	27032
9823c63a4dfd0cb63a880c254f14aab1b1ac23ef	co-manipulation with multiple probabilistic virtual guides	rails;co manipulation robots pick and place task gaussian mixture models kinesthetic teaching multiple probabilistic virtual guides;service robots;force;mixture models gaussian processes human robot interaction;trajectory;probabilistic logic rails force service robots trajectory context;probabilistic logic;context	In co-manipulation, humans and robots solve manipulation tasks together. Virtual guides are important tools for co-manipulation, as they constrain the movement of the robot to avoid undesirable effects, such as collisions with the environment. Defining virtual guides is often a laborious task requiring expert knowledge. This restricts the usefulness of virtual guides in environments where new tasks may need to be solved, or where multiple tasks need to be solved sequentially, but in an unknown order. To this end, we propose a framework for multiple probabilistic virtual guides, and demonstrate a concrete implementation of such guides using kinesthetic teaching and Gaussian mixture models. Our approach enables non-expert users to design virtual guides through demonstration. Also, they may demonstrate novel guides, even if already known guides are active. Finally, users are able to intuitively select the appropriate guide from a set of guides through physical interaction with the robot. We evaluate our approach in a pick-and-place task, where users are to place objects at one of several positions in a cupboard.	cluster analysis;fundamental interaction;humans;mixture model;resultant;robot;smt placement equipment;statistical model	Gennaro Raiola;Xavier Lamy;Freek Stulp	2015	2015 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)	10.1109/IROS.2015.7353107	computer vision;simulation;computer science;artificial intelligence;trajectory;probabilistic logic;force;quantum mechanics	Robotics	61.75900571235681	-25.167758727905163	27038
846e1f657a7bcbeb8836c5eea7634c6366eb91ab	controllable roll-to-swim motion transition of helical nanoswimmers	robots magnetosphere propulsion robustness surface topography torque substrates;surgery closed loop systems feedback microfluidics mobile robots motion control robust control;cargo transport roll to swim motion transition magnetically actuated helical nanoswimmers in vitro microfluidics invasive surgery mobility robustness motion dexterity cork screw swimming closed loop microscopic visual feedback	Magnetically actuated helical nanoswimmers have various potential applications from in-vitro microfluidics to invivo less invasive surgery. However these applications provide more challenging environments for the helical nanoswimmers by often limiting their mobility robustness from their limited motion dexterity. That is why we propose in this paper a multimodal Roll-to-Swim motion transition of helical nanoswimmers. The proposed Roll-to-Swim is a robust swimmer that takes advantages of both a rolling motion and a cork-screw swimming. The Roll-to-Swim can switch between these two different propulsion modes by simply controlling the direction and the frequency of the rotating magnetic field. We also show that the proposed system can be controlled either manually or by a closed loop with microscopic visual feedback. The system proved to be used for cargo transport of micro scale particles. Thanks to the demonstrated multi-motion transition and the cargo transport capabilities, Roll-to-Swimmers can be very promising and useful tools toward in-vitro microfluidics or in-vivo applications.	closed-loop transfer function;cork encoding;experiment;multimodal interaction;robot;video-in video-out	Antoine Barbot;Dominique Decanini;Gilgueng Hwang	2014	2014 IEEE/RSJ International Conference on Intelligent Robots and Systems	10.1109/IROS.2014.6943224	control engineering;simulation;engineering;control theory	Robotics	74.29541168013789	-24.491032763621362	27259
4c78be90c1ce908403648896b5bea42042fb6dec	a learning model for personalized adaptive cruise control		This paper develops a learning model for personalized adaptive cruise control that can learn from human demonstration online and mimic a human driver's driving strategies in the dynamic traffic environment. Under the framework of the proposed model, reinforcement learning is used to capture the human-desired driving strategy, and the proportion-integration-differentiation controller is adopted to convert the learning strategy to low-level control commands. The performance of the learning model is tested in the simulation environment built in a driving simulator using PreScan. Experimental results show that the learning model can duplicate human driving strategies with acceptable errors. Moreover, compared with the traditional adaptive cruise control, the proposed model can provide better driving comfort and smoothness in the dynamic situation.	control unit;driving simulator;high- and low-level;lateral thinking;pid;personalization;reinforcement learning;simulation	Xin Chen;Yong Zhai;Chao Lu;Jianwei Gong;Gang Wang	2017	2017 IEEE Intelligent Vehicles Symposium (IV)	10.1109/IVS.2017.7995748	control theory;simulation;vehicle dynamics;reinforcement learning;data modeling;control engineering;engineering;driving simulator;cruise control	Robotics	62.90115126917932	-24.026441628344525	27311
2050682dfd4225435f717c960ab53c57a3f55067	shell representation and compression conscious manipulation for three dimensional graphical datasets	three dimensional imaging;autostereoscopic display;three dimensional dataset;image coding stereo image processing three dimensional displays data compression;image coding;history;data compression;three dimensional graphical dataset;stereo disparity;edge information;potential difference;shell representation;three dimensional manipulation operation;edge highlight;three dimensional;glass;controlled merging;shell tree simplification shell representation compression conscious manipulation three dimensional graphical dataset three dimensional dataset autostereo sequence dataset three dimensional manipulation operation autostereoscopic display three dimensional image stereo disparity human visual system edge information edge highlight image compression controlled merging contour tree image coding;image compression;shell tree simplification;three dimensional displays;human visual system;pixel;field of view;stereo image processing;autostereo sequence dataset;merging;contour tree image coding;system testing;bandwidth;compression ratio;image coding humans visual system pixel system testing three dimensional displays glass bandwidth merging history;humans;visual system;compression conscious manipulation;three dimensional image	Although there has been a large number of standards for two-dimension images, there has not been as extensive a study into representing three-dimensional datasets. Presented here is a test from an extended system to cater for initially autostereo sequence datasets, although still suitable for all types of three-dimensional datasets. Extensions to do three dimensional manipulation operations are defined that are both computationally efficient when applied to the coded form and are compression conscious in that they maintain compression performance. Autostereoscopic displays have been developed which create a three-dimensional image without the need for special glasses or headsets. They work by displaying multiple images each viewable over a very narrow field of view. This has the advantage of being able to look around objects. Increasing the number of images per view, increases the bandwidth required. To aid stereo disparity in the human visual system the important features to retain in stereo sets are potentially different from standard two-dimensional images. Edge information and highlights have been shown to be of paramount importance for the human visual system to accurately perceive depth. The theme of coding three-dimensional regions as separate entities allows for a potential high compression ratio and subsequent transmission rate speed-up. A controlled merging scheme of regions is also presented which, being designed to keep all highlights and avoid defocusing of the image, gives a corresponding compression ratio increase while retaining the majority of the stereo cues.	algorithmic efficiency;autostereoscopy;binocular disparity;codec;data compression;entity;tree structure;voxel	Martin J. Turner	2003		10.1109/TPCG.2003.1206944	computer vision;simulation;computer science;computer graphics (images)	Vision	62.13675611589398	-40.02667172503088	27323
d621f0d1f51c4aee8a5abe1bb82e704e6378fad3	stochastic simulation of channelized sedimentary bodies using a constrained l-system		Simulating realistic sedimentary bodies while conditioning all the available data is a major topic of research. We present a new method to simulate the channel morphologies resulting from the deposition processes. It relies on a formal grammar system, the Lindenmayer system, or L-system. The L-system puts together channel segments based on user-defined rules and parameters. The succession of segments is then interpreted to generate non-rational uniform B-splines representing straight to meandering channels. Constraints attract or repulse the channel from the data during the channel development. They enable to condition various data types, from well data to probability cubes or a confinement. The application to a synthetic case highlights the method’s ability to manage various data while preserving at best the channel morphology.	application programming interface;channelization (telecommunications);consortium;formal grammar;galaxy morphological classification;l-system;mathematical morphology;motion planning;non-uniform rational b-spline;olap cube;physical vapor deposition;point of view (computer hardware company);scott continuity;simulation;succession;synthetic intelligence	Guillaume Rongier;Pauline Collon;Philippe Renard	2017	Computers & Geosciences	10.1016/j.cageo.2017.05.006	data mining;theoretical computer science;mathematical optimization;computer science;data type;l-system;meander;conditioning;formal grammar;channelized;stochastic simulation;communication channel	Robotics	71.97802444414889	-48.52113634817023	27339
d06486f0f6509b74cf9346ddcdb4e9ca745e5573	phonetic segmentation of speech signal using local singularity analysis	multiscale signal processing;piece wise linear approximation;nonlinear speech processing;phonetic segmentation of speech signals	This paper presents the application of a radically novel approach, called the Microcanonical Multiscale Formalism (MMF) to speech analysis. MMF is based on precise estimation of local scaling parameters that describe the inter-scale correlations at each point in the signal domain and provides efficient means for studying local non-linear dynamics of complex signals. In this paper we introduce an efficient way for estimation of these parameters and then, we show that they convey relevant information about local dynamics of the speech signal that can be used for the task of phonetic segmentation. We thus develop a two-stage segmentation algorithm: for the first step, we introduce a new dynamic programming technique to efficiently generate an initial list of phoneme-boundary candidates and in the second step, we use hypothesis testing to refine the initial list of candidates. We present extensive experiments on the full TIMIT database. The results show that our algorithm is significantly more accurate than state-of-the-art ones.	algorithm;breakpoint;computational complexity theory;dynamic programming;dynamical system;experiment;image scaling;incremental funding methodology;nonlinear system;signal processing;timit;technological singularity;voice analysis	Vahid Khanagha;Khalid Daoudi;Oriol Pont;Hussein M. Yahia	2014	Digital Signal Processing	10.1016/j.dsp.2014.08.002	speech recognition;computer science;machine learning;pattern recognition;statistics	ML	80.94853263317758	-34.478905621096644	27355
35b278514f871e7d879c54462b060b9dc8368710	pedestrian tracking in car parks : an adaptive interacting multiple models based filtering method	parking lots;filtering method;probability;filters mathematics;adaptive filters filtering state estimation target tracking uncertainty bayesian methods predictive models state space methods adaptation model motion estimation;interacting multiple models;adaptive interacting multiple models;psychology;indexing terms;pedestrians;car park;mathematical models;traffic engineering computing filtering theory probability target tracking;on line adaptation;transition probability matrix pedestrian tracking car park adaptive interacting multiple models filtering method target tracking;traffic engineering computing;transition probability matrix;target tracking;pedestrian detectors;pedestrian tracking;filtering theory;interacting multiple model	To address perception problems we must be able to track dynamics targets of the environment. An important issue of tracking is filtering problem in which estimates of the target's state are computed while observations are progressively received. This paper presents an adaptive interacting multiple models (IMM) based filtering method. Interacting multiple models have been successfully applied to many applications as they allow, using several filters in parallel, to deal with the uncertainty on motion model, a critical component of filtering. Indeed targets can rapidly change their motion over a lapse of time. This is the case of pedestrians for which it is difficult to define a unique motion model which matches all their possible displacements. Nevertheless, the transition probability matrix (TPM) which models the interaction between different filters in an IMM is in currently defined a priori or needs an important amount of tuning to be used efficiently. In this paper, we put forward a method which automatically adapts online the TPM. The TPM adaptation using on-line data significantly improves the effectiveness of IMM filtering and so better target estimates are obtained. To validate our work we applied our method to pedestrian tracking in car parks on a real platform	content-control software;definition;filter (signal processing);interaction;markov chain;online and offline;semantics (computer science);stochastic matrix;trusted platform module	Julien Burlet;Olivier Aycard;Anne Spalanzani;Christian Laugier	2006	2006 IEEE Intelligent Transportation Systems Conference	10.1109/ITSC.2006.1706784	computer vision;simulation;engineering;machine learning	Vision	56.09437365546362	-35.58174605186569	27428
6d07a6d554e31fbf6e34c6b36668f6e06722ad45	variational bayesian algorithm for distributed compressive sensing	bayesian inference;distributed compressive sensing dcs;computational complexity variational bayesian algorithm distributed compressive sensing dcs multiple sensor signals bayesian dcs algorithm variational bayesian inference intersignal correlation innovation components intrasignal correlation;bayes methods signal processing algorithms joints technological innovation correlation compressed sensing computational complexity;compressed sensing bayes methods;signal reconstruction;signal reconstruction distributed compressive sensing dcs bayesian inference	Distributed compressive sensing (DCS) concerns the reconstruction of multiple sensor signals with reduced numbers of measurements, which exploits both intra- and inter-signal correlations. In this paper, we propose a novel Bayesian DCS algorithm based on variational Bayesian inference. The proposed algorithm decouples the common component, that characterizes inter-signal correlation, from innovation components, that represent intra-signal correlation. Such an operation results in a computational complexity of reconstruction which is linear with the number of signals. The superior performance of the algorithm, in terms of the computing time and reconstruction quality, is demonstrated by numerical simulations in comparison with other existing reconstruction methods.	algorithm;bayesian network;calculus of variations;compressed sensing;computational complexity theory;computer simulation;experiment;numerical analysis;variational principle	Wei Chen;Ian J. Wassell	2015	2015 IEEE International Conference on Communications (ICC)	10.1109/ICC.2015.7249097	signal reconstruction;econometrics;machine learning;mathematics;bayesian inference;statistics	Robotics	74.646009380445	-36.48397682493462	27430
d733e50592632e46c463f79eef169064f55dfd5c	region-of-interest visualization by cave vr system with automatic control of level-of-detail	automatic control;cave;interactive visualization;computation fluid dynamics;virtual reality;large scale data;three dimensional;scientific visualization;large scale;large scale simulation;level of detail;region of interest;scalar field;cfd;vector field	To specify the region of interest (ROI) is an effective approach to visualize large scale simulation data. We have developed a three-dimensional visualization software with ROI function for the CAVE virtual reality systems. This software enables the user to perform fully three-dimensional and interactive visualization of large scale computational fluid dynamics (CFD) data. The user specifies a ROI in the CAVE room by a three-dimensional “mouse-drag”. The data in the specified ROI is automatically extracted from the original CFD data. This ROI procedure can be repeated recursively. The resolution in each ROI is kept approximately constant. A data set of three vector fields and eight scalar fields whose size is about 1 GB each was successfully analyzed.	automatic control;level of detail	Nobuaki Ohno;Akira Kageyama	2010	Computer Physics Communications	10.1016/j.cpc.2009.12.002	three-dimensional space;computer vision;scalar field;scientific visualization;vector field;simulation;interactive visualization;computational fluid dynamics;computer science;level of detail;automatic control;virtual reality;cave;physics;quantum mechanics;computer graphics (images);region of interest	Visualization	71.25420216002257	-50.357454954223535	27433
cef14bd88cc5291f38f3670d1f0c692a382ddac4	self-calibration for a 3d laser	intrinsic;3d;3d laser scanner;point cloud quality;sick lms151;simulation;online optimization;laser scanner;robotics;density estimation;parzen window;gaussian mixture model;extrinsic;robust performance;temporal;renyi quadratic entropy;entropy;point cloud;clock skew;calibration	This paper describes a method for the automatic self-calibration of a 3D Laser sensor. We wish to acquire crisp point clouds and so we adopt a measure of crispness to capture point cloud quality. We then pose the calibration problem as the task of maximising point cloud quality. Concretely, we use Rényi Quadratic Entropy to measure the degree of organisation of a point cloud. By expressing this quantity as a function of key unknown system parameters, we are able to deduce a full calibration of the sensor via an online optimisation. Beyond details on the sensor design itself, we fully describe the end-to-end intrinsic parameter calibration process and the estimation of the clock skews between the constituent microprocessors. We analyse performance using real and simulated data and demonstrate robust performance over thirty test sites.	clock skew;computer performance;end-to-end principle;loss function;mathematical optimization;microprocessor;mixture model;modulation;monte carlo method;norm (social);point cloud;portable document format;simulation;sparse matrix;spherical model	Mark Sheehan;Alastair Harrison;Paul Newman	2012	I. J. Robotics Res.	10.1177/0278364911429475	laser scanning;entropy;calibration;simulation;density estimation;intrinsic value;clock skew;computer science;machine learning;mixture model;point cloud;robotics;statistics	Robotics	56.087655692358666	-42.352714713342635	27450
fd41d557b10afa31d18b089a812527fbff456915	local elevation mapping for automated vehicles using lidar ray geometry and particle filters		Two-dimensional occupancy grid mapping is a common approach for environment mapping and sensor data fusion but non-planar environments are still a remaining issue. The ground shape has to be considered in such environments, especially when low obstacles on the road need to be recognized. Elevation maps are a suitable model because the height is not discretized. This paper presents an improved lidar-based approach for elevation mapping that uses particle filters to estimate the height indirectly by a fusion of lower and upper height boundaries. These boundaries are extracted from lidar reflections and ray geometry of different time steps. Furthermore, a tailored interpolation algorithm is presented that takes the statistics of the particle population of each cell into account. A conclusive qualitative and quantitative evaluation highlights the performance of the presented approach.	algorithm;arbitrary-precision arithmetic;discretization;ground truth;interpolation;lateral thinking;local elevation;map;motion compensation;odometry;particle filter;point cloud;ramp simulation software for modelling reliability, availability and maintainability;reflection (computer graphics);reflection (computer programming);reflection mapping;sensor;virtual reality	Kai Stiens;Johannes Keilhacker;Georg Tanzmeister;Dirk Wollherr	2017	2017 IEEE Intelligent Vehicles Symposium (IV)	10.1109/IVS.2017.7995764	occupancy grid mapping;elevation;interpolation;reflection mapping;particle filter;remote sensing;sensor fusion;lidar;population	Robotics	55.171020094268144	-43.06600095377955	27488
2e166b87dc32135df68092413c144e62b763388e	synthesizing waves from animated height fields	fluid modeling;physically based animation;fluid control;animation;fluid simulation	Computer animated ocean waves for feature films are typically carefully choreographed to match the vision of the director and to support the telling of the story. The rough shape of these waves is established in the previsualization (previs) stage, where artists use a variety of modeling tools with fast feedback to obtain the desired look. This poses a challenge to the effects artists who must subsequently match the locked-down look of the previs waves with high-quality simulated or synthesized waves, adding the detail necessary for the final shot. We propose a set of automated techniques for synthesizing Fourier-based ocean waves that match a previs input, allowing artists to quickly enhance the input wave animation with additional higher-frequency detail that moves consistently with the coarse waves, tweak the wave shapes to flatten troughs and sharpen peaks if desired (as is characteristic of deep water waves), and compute a physically reasonable velocity field of the water analytically. These properties are demonstrated with several examples, including a previs scene from a visual effects production environment.	computer animation;deployment environment;previsualization;simulation;velocity (software development);visual effects	Michael Bang Nielsen;Andreas Söderström;Robert Bridson	2013	ACM Trans. Graph.	10.1145/2421636.2421638	fluid simulation;anime;physically based animation;computer vision;simulation;computer science;machine learning;optics;algorithm;computer graphics (images)	Graphics	63.99635484811548	-49.84651094685162	27494
31becfbabc7663a41c8fb14b3bffbc1f40c3b62a	azimuthal and elevation localization using inter-channel phase and level differences for a hemispheric object	security cam era;tecnologia electronica telecomunicaciones;security camera;frequency domain binaural model;performance improvement;sound source localization;tecnologias;frequency domain;grupo a;hemispheric object	The frequency domain binaural model (FDBM) has been previously proposed to localize multiple sound sources. Since the method requires only two input signals and uses interaural phase and level differences caused by the diffraction generated by the head, flexibility in application is very high when the head is considered as an object. When an object is symmetric with respect to the two microphones, the performance of sound source localization is degraded, as a human being has front-back confusion due to the symmetry in a median plane. This paper proposes to reduce the degradation of performance on sound source localization by a combination of the microphone pair outputs using the FDBM. The proposed method is evaluated by applying to a security camera system, and the results showed performance improvement in sound source localization because of reducing the number of cones of confusion.		Yoshifumi Chisaki;Toshimichi Takada;Masahiro Naganishi;Tsuyoshi Usagawa	2008	IEICE Transactions	10.1093/ietfec/e91-a.10.3059	speech recognition;perceptual-based 3d sound localization;mathematics;acoustic source localization;frequency domain	Visualization	59.49784247166887	-52.01310738246307	27495
d696a6f2d53cf81435493175b2518b1b04feeab0	gimbal influence on the stability of exterior orientation parameters of uav acquired images	photogrammetry;exterior orientation parameters;inertial measurement unit imu;unmanned aerial vehicle uav;gimbal	In this paper, results from the analysis of the gimbal impact on the determination of the camera exterior orientation parameters of an Unmanned Aerial Vehicle (UAV) are presented and interpreted. Additionally, a new approach and methodology for testing the influence of gimbals on the exterior orientation parameters of UAV acquired images is presented. The main motive of this study is to examine the possibility of obtaining better geometry and favorable spatial bundles of rays of images in UAV photogrammetric surveying. The subject is a 3-axis brushless gimbal based on a controller board (Storm32). Only two gimbal axes are taken into consideration: roll and pitch axes. Testing was done in a flight simulation, and in indoor and outdoor flight mode, to analyze the Inertial Measurement Unit (IMU) and photogrammetric data. Within these tests the change of the exterior orientation parameters without the use of a gimbal is determined, as well as the potential accuracy of the stabilization with the use of a gimbal. The results show that using a gimbal has huge potential. Significantly, smaller discrepancies between data are noticed when a gimbal is used in flight simulation mode, even four times smaller than in other test modes. In this test the potential accuracy of a low budget gimbal for application in real conditions is determined.	aerial photography;airplane mode;camera resectioning;controllers;flight simulator;gimbal lock;photogrammetry;radiation;simulation;small;unmanned aerial vehicle	Mateo Gasparovic;Luka Jurjevic	2017		10.3390/s17020401	gimbal;computer vision;simulation;engineering;gimbal lock;physics;photogrammetry	Robotics	57.23246839665611	-39.04734005291554	27570
1429ed6d33341df1670db45356b5374a2fe8a636	noctoslam: fast octree surface normal mapping and registration		In this paper, we introduce a SLAM front end called NOctoSLAM. The approach adopts an octree-based map representation that implicitly enables source and reference data association for point to plane ICP registration. Additionally, the data structure is used to group map points to approximate surface normals. The multi-resolution capability of octrees, achieved by aggregating information in parent nodes, enables us to compensate for spatially unbalanced sensor data typically provided by multi-line lidar sensors. The octree-based data association is only approximate, but our empirical evaluation shows that NOctoSLAM achieves the same pose estimation accuracy as a comparable, point cloud based approach. However, NOctoSLAM can perform twice as many registration iterations per time unit. In contrast to point cloud based surface normal maps, where the map update duration depends on the current map size, we achieve a constant map update duration including surface normal recalculation. Therefore, NOctoSLAM does not require elaborate and environment dependent data filters. The results of our experiments show a mean positional error of 0.029 m and 0.019 rad, with a low standard deviation of 0.005 m and 0.006 rad, outperforming the state-of-the-art by remaining accurate while running online.	approximation algorithm;benchmark (computing);computation;constant function;correspondence problem;data structure;experiment;image registration;iteration;map;normal (geometry);normal mapping;octree;point cloud;sensor;simultaneous localization and mapping;time complexity;unbalanced circuit	Joscha-David Fossel;Karl Tuyls;Benjamin Schnieders;Daniel Claes;Daniel Hennes	2017	2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)	10.1109/IROS.2017.8206594	computer science;point cloud;artificial intelligence;normal;computer vision;standard deviation;pose;front and back ends;octree;lidar;data structure	Robotics	54.722138878776164	-43.82748120516046	27571
3aca709ae47a8fb806523b96722e0994b782020f	exact and approximate computation of b-spline curves on surfaces	tecnologia electronica telecomunicaciones;computacion informatica;curve approximations;three dimensions;grupo de excelencia;least squares approximation;b spline curve;approximation;ciencias basicas y experimentales;approximate solution;b spline;tecnologias;curves on surfaces;computation;computer aided geometric design	Curves on surfaces are important elements in computer aided geometric design. After presenting a method to explicitly compute these curves in three-dimensions, practical algorithmic issues are discussed concerning the efficiency of the implementation. Good approximations are important because of the quite high degree of exact curves on surfaces. We present two approximate solutions to the problem. The first is derived from the exact representation, while the second extends conventional least-squares approximation by incorporating the geometry of the surface as well. The efficiency and behaviour of the algorithms are evaluated by means of examples.	approximation algorithm;b-spline;computation;spline (mathematics)	Gábor Renner;Volker Weiss	2004	Computer-Aided Design	10.1016/S0010-4485(03)00100-3	b-spline;three-dimensional space;mathematical optimization;combinatorics;geometric design;approximation;computation;mathematics;geometry;family of curves;least squares;algorithm	EDA	69.43917519759117	-40.13077611703089	27734
cf90742b26f466e98e821d03c6576c5e66d14367	an autonomous image-guided robotic system simulating industrial applications	image processing;industrial mechatronics robotic system manipulator arm;end effector autonomous image guided robotic system serial manipulator vertical articulated arm servo motors inverse kinematic model robotic arm industrial manipulator image processing;manipulator kinematics;production engineering computing;servomotors control engineering computing end effectors image processing industrial manipulators manipulator kinematics production engineering computing;servomotors;robot kinematics service robots joints kinematics image processing manipulators;control engineering computing;industrial manipulators;end effectors	This paper presents a robotic system based on a serial manipulator. The robot is a vertical articulated arm with 5 revolute joints having 6 Degree Of Freedom. Actuated with six precise servo motors, the system offers positional accuracy of ±0.5mm with a movement speed of 100mm/s. Forward and Inverse Kinematic model of the robot has been developed and its workspace has been analyzed to facilitate the use of robotic arm as a simulated industrial manipulator. Image processing has been done to make system more autonomous. Followed by a user's commands, the system acquires image of the environment using on-board camera. This image is processed to extract information about object's coordinates. Based on these coordinates, Inverse Kinematic model computes the required joint angles for the end-effector to reach at desired position and orientation thus enabling it to manipulate the object. The proposed system can be used in wide range of industrial applications involving pick and place, sorting and other object manipulation tasks. The system can also be potentially useful for heavy and `giant' industrial applications after scaling up i.e. using huge robotic arm, employing multiple and better cameras and optimizing algorithms.	algorithm;autonomous robot;image processing;image scaling;inverse kinematics;on-board data handling;robot end effector;robotic arm;smt placement equipment;serial manipulator;servo;simulation;sorting;workspace	Raza Ul Islam;Jamshed Iqbal;Sarah Manzoor;Aayman Khalid;Sana Khan	2012	2012 7th International Conference on System of Systems Engineering (SoSE)	10.1109/SYSoSE.2012.6384195	control engineering;computer vision;parallel manipulator;robot end effector;robotic arm;image processing;computer science;engineering;artificial intelligence;321 kinematic structure;mobile manipulator;control theory;servomotor	Robotics	65.37273119729443	-29.243791037062177	27846
e6dc14d56524daa49324643d6201b6875a2dabaa	accurately estimating sherd 3d surface geometry with application to pot reconstruction	application software;geometry;computational geometry;surface fitting;surface reconstruction;data mining;polynomials;computer vision;fitting;surface geometry;error analysis;symmetric algebra;shape;estimation;three dimensional displays;surface model;solid modeling;surface emitting lasers;3d laser scanning;curve estimation;three dimensional displays surface fitting estimation fitting data models geometry shape;data models;geometrical optics	This paper deals with the problem of precise automatic estimation of the surface geometry of pot sherds uncovered at archaeological excavation sites using dense 3D laser-scan data. Critical to ceramic fragment analysis is the ability to geometrically classify excavated sherds, and, if possible, reconstruct the original pots using the sherd fragments. To do this, archaelogists must estimate the pot geometry in terms of an axis and associated profile curve from the discovered fragments. In this paper, we discuss an automatic method for accurately estimating an axis/profile curve pair for each archeological sherd (even when they are small) based on axially symmetric implicit polynomial surface models. Our method estimates the axis/profile curve for a sherd by finding the axially symmetric algebraic surface which best fits the measured set of dense 3D points and associated normals. We note that this method will work on 3D point data alone and does not require any local surface computations such as differentiation. Axis/profile curve estimates are accompanied by a detailed statistical error analysis. Estimation and error analysis are illustrated with application to a number of sherds. These fragments, excavated from Petra, Jordan, are chosen as exemplars of the families of geometrically diverse sherds commonly found on an archeological excavation site. We then briefly discuss how the estimation results may be integrated into a larger pot reconstruction program.	3d scanner;algorithm;apache axis;computation;data point;error analysis (mathematics);fits;optic axis of a crystal;polynomial;sensor	Andrew R. Willis;Xavier Orriols;David B. Cooper	2003	2003 Conference on Computer Vision and Pattern Recognition Workshop	10.1109/CVPRW.2003.10014	symmetric algebra;geometrical optics;data modeling;computer vision;econometrics;mathematical optimization;estimation;application software;surface reconstruction;computational geometry;shape;computer science;mathematics;geometry;solid modeling;statistics;polynomial	Vision	55.2163996653188	-50.77961809784904	27882
6293a200dc5360cd0beaeb47de231753a5011b5c	point-based registration with known correspondence: closed form optimal solutions and properties	optimal solution	Point-based registration with known correspondence is often used as either a stand-alone method or a part of a more complex algorithm. The goal of this type of registration is to align two sets of points with the same number of corresponding points using a selected transformation type. Presented are closed form solutions for the transformation parameters that optimally align two point sets in the least squares sense for the following transformation types: rigid, similarity, rigid with nonuniform scales, and a linear combination of basis functions. It is shown that those registration methods whose underlying transformations form a group satisfy the identity, symmetry, transitivity, and distortion properties.		Oskar M. Skrinjar	2006		10.1007/11784012_38	point set registration;mathematical optimization;discrete mathematics;topology;computer science;mathematics	Theory	54.00614105662894	-51.40238017648382	27888
d310ead309a05c7a2e937fe156955c16f6dd8478	using program transformations to derive line-drawing algorithms	raster graphics;computer graphics;transformations;line drawing;program transformation;computer programs;line drawings;variations;performance engineering;parallel orientation;digital systems;algorithms	A wide variety of line-drawing algorithms can be derived by applying program transformations to a simple, obviously correct algorithm. The transformations increase the algorithm's performance and eliminate the need for floating-point computations. Two familiar algorithms are derived in this way: Bresenham's algorithm and the digital differential analyzer (DDA). The transformations are then used to derive several highly parallel variants of Bresenham's algorithm, designed for use on displays that can generate more than one pixel at a time. The treatment shows a complete, extended example of the practical use of program transformations. Moreover, the transformations derive Bresenham's algorithm without recourse to complex geometric arguments.	bresenham's line algorithm;computation;differential analyser;digital differential analyzer;pixel;program transformation	Robert F. Sproull	1982	ACM Trans. Graph.	10.1145/357311.357312	transformation;raster graphics;performance engineering;computer science;theoretical computer science;programming language;computer graphics;bresenham's line algorithm;algorithm;computer graphics (images)	Graphics	66.64596084409435	-49.01836142777994	27966
89a44fef6e57ddbfee909075ca7b0db15d49b6ac	image-based servoing of non-holonomic vehicles using non-central catadioptric cameras	image based nonholonomic robot control image based nonholonomic vehicle servoing noncentral catadioptric cameras central camera configurations radial model optical axis ibvs imu inertial measurement unit relative robot rotation measurement visual features;mobile robots;visual servoing cameras inertial systems mobile robots;cameras robot kinematics visualization mirrors visual servoing;inertial systems;visual servoing;cameras	Novel contributions on image-based control of a mobile robot using a general catadioptric camera model are presented in this paper. Visual servoing applications using catadioptric cameras have essentially been using central cameras and the corresponding unified projection model. So far only in a few cases more general models have been used. In this paper we address the problem of visual servoing using the socalled the radial model. The radial model can be applied to many camera configurations and in particular to non-central catadioptric systems with mirrors that are symmetric around an axis coinciding with the optical axis. In this case, we show that the radial model can be used with a non-central catadioptric camera to allow effective image-based visual servoing (IBVS) of a mobile robot. Two sets of experiments are carried. In one of the sets, IMU (Inertial Measurement Unit) is used to measure the relative rotation of the robot and in the other set visual features are solely used. The achieved results validate both the applicability and effectiveness of the proposed method for imaged-based control of a non-holonomic robot.	apache axis;experiment;extended euclidean algorithm;focal (programming language);interaction technique;international symposium on fundamentals of computation theory;mobile robot;optimal control;radial (radio);robot operating system;robotics;visual servoing	Hadi Aliakbarpour;Omar Tahri;Helder Araújo	2013	9th International Workshop on Robot Motion and Control	10.1109/RoMoCo.2013.6614584	computer vision;simulation;geography;control theory;visual servoing	Robotics	60.74005024896848	-31.355085009549512	28021
719a710abfdee06d4d42b33cccfb8eb447e7bda0	hidden-curve algorithm for correct grid surface representation of functions of two variables	representation graphique;visualizacion;surface representation;perspective projection;representacion grafica;superficie discontinuidad;grid shape;forma geometrica;funcion dos variables;surface lisse;surface discontinuite;smooth surface;algorithme;line drawings;algorithm;visualization;visualisation;polygonal meshes;discontinuity surface;geometrical shape;two variables function;forme geometrique;superficie lisa;graphics;forme tramee;forma tejido;algoritmo;fonction deux variables	Abstract   A common method for visualizing a function of two variables is to consider it as a nontransparent grid surface in 3-D space and to project it onto a view plane. Various computer algorithms exist which map such surfaces onto a screen. Each of these conventional techniques has its own disadvantage: either the graphical results are not very accurate, because the algorithm approximates the surface by a polygon mesh consisting of quadrilaterals or, indeed, the algorithm produces sufficiently true images of the grid curves, but is restricted to special viewing conditions. This paper gives details and a pseudocode of a new, universal line-drawing algorithm which yields correct images of grid surfaces conserving their geometrical properties such as smoothness or discontinuities. The functions to be represented may be continuous or piecewise continuous. Almost any position of the surface in relation to the viewer's eye and in relation to the view plane can be chosen and any parallel or perspective projection can be applied.	algorithm	Hans Werner Kohl	1996	Computers & Graphics	10.1016/0097-8493(95)00099-2	combinatorics;visualization;topology;computer science;mathematics;geometry;algorithm;computer graphics (images)	Vision	66.98667399157218	-41.06763380456148	28119
cc1eb5ae01c2243525c340c9df880f65c029b2ed	a development of force distribution measurement system with high resolution for total knee arthroplasty	conductive rubber;soft tissue balance;pressure sensor array;total knee arthroplasty tka			Mohd Hanafi Mat Som;Kouki Nagamune;Takashi Kamiya;Shogo Kawaguchi;Koji Takayama;Tomoyuki Matsumoto;Ryosuke Kuroda;Masahiro Kurosaka	2014	JACIII	10.20965/jaciii.2014.p0213	computer science;computer vision;machine learning;artificial intelligence;arthroplasty	Robotics	74.48126041167077	-26.754768379809246	28351
3226e9a2cf27ed6d93a46f9e712b92301fc27850	a process for surface fairing in irregular meshes	concepcion asistida;computer aided design;variational fairness criteria;curva bezier;surface fairing;quadratic program;history;linear system of equations;ajustamiento curva;surface representation;quadratic form;bibliografia;bibliography;variational formulation;biquartic c 1 composite bezier patches;higher order;courbe bezier;smoothing;bibliographie;alisamiento;conception assistee;ajustement courbe;local and global fairing;historia;curve fitting;iterative solution;higher order fairness measures;irregular mesh interpolation and approximation;lissage;histoire;bezier curve	This paper describes a stepwise, automatic fairing process to construct a smooth surface by optimizing suitably chosen quantitative fairness measures. The input consists of given point and/or curve data, each designated to be interpolated or approximated. These data may stem from digitizing drawings or mockup models or from prior individual curve fairing. The data are arranged in an arbitrary irregular mesh topology. The irregular, n-sided mesh cells are converted by midpoint subdivision into aggregates of quadrilateral patches (Peters, 1994), for which a biquartic Bézier surface representation is chosen everywhere. The resulting C1 surface minimizes the fairness measure, which is selected from a variety of geometrically relevant quadratic forms, including second and higher order derivative norms. This variational formulation of the fairing problem is of Quadratic Programming type and has a unique solution. Two algorithms are described, one for global, simultaneous and another for local, iterative solution of the corresponding large linear system of equations. This surface fairing technique will be illustrated by two main examples, viz., a car hood and a twisted tripod, demonstrating the performance of the fairing algorithms and the effects of the chosen fairness measures on the character of the resulting shapes.  2001 Elsevier Science B.V. All rights reserved.	approximation algorithm;bézier curve;calculus of variations;computer-aided design;concave function;data structure;fairness measure;geometric design;hood method;interpolation;iteration;iterative method;linear equation;linear system;list of variational topics;mesh networking;polygon mesh;quadratic equation;quadratic programming;refinement (computing);requirement;stepwise regression;subdivision surface;system of linear equations;tripod;twisted pair;variational principle;viz: the computer game	Geir Westgaard;Horst Nowacki	2001	Computer Aided Geometric Design	10.1016/S0167-8396(01)00057-7	system of linear equations;mathematical optimization;higher-order logic;topology;quadratic form;computer aided design;bézier curve;mathematics;geometry;bibliography;quadratic programming;statistics;smoothing;curve fitting	Graphics	68.70511571148408	-40.84741847063967	28369
98686dc014d290a23e924f6519edb8c5b9e2ebfe	voice source parameters estimation by fitting the glottal formant and the inverse filtering open phase	speech hidden markov models estimation mathematical model measurement uncertainty europe signal processing;z transforms deconvolution filtering theory parameter estimation speech processing;parameter estimation;zeros of the z transform voice source parameter estimation glottal formant fitting glottal open phase inverse filtering lf source model speech waveform zzt technique speech deconvolution anticausal components causal components source parameter extraction arx speech production model spectral division natural speech synthetic speech analysis synthesis test;speech production	This paper presents two approaches to the problem of extracting the parameters of the LF source model directly from the speech waveform. The first approach relies on the glottal formant estimated from the anticausal contribution of speech. Indeed the ZZT technique has recently shown its ability to deconvolve speech into its causal and anticausal components. The second method is based on the glottal open phase obtained by inverse filtering. The notion of unanalyzable frames and the way to detect and correct them are also presented. Once source parameters are extracted, the coefficients of the ARX speech production model are estimated by spectral division. Decomposition on both synthetic and natural speech, as well as an analysis-synthesis test confirm the accuracy of methods exposed.	anticausal system;arx;causal filter;coefficient;estimation theory;inverse filter;natural language;open-source software;synthetic intelligence;waveform;zzt	Thomas Drugman;Thomas Dubuisson;Nicolas D'Alessandro;Alexis Moinet;Thierry Dutoit	2008	2008 16th European Signal Processing Conference		speech recognition;acoustics;computer science;communication	ML	82.01589923286511	-35.706887584732414	28381
21c5ab5e20b532f0708af5ced3507b22f2e0bca9	a method of robotic visual tracking for a new automatic laser welding line	lasers;robot sensing systems;filtering;sensor system;radon transforms;image coordinate system;online visual tracking sensor system;image processing;median filter;features extraction;radon transform;features extraction image processing seam tracking structure light vision;method of image;laser welding;welding;search method;structured light;joints;image denoising robotic visual tracking laser welding line online visual tracking sensor system image processing features extraction structured light image radon transform image coordinate system;tracking feature extraction image denoising radon transforms robot programming robotic welding;robotics and automation welding service robots robot sensing systems robot kinematics sensor systems feature extraction image denoising filtering search methods;structured light image;feature extraction;robots;robotic visual tracking;structure light vision;seam tracking;image denoising;visual tracking;robotic welding;laser welding line;tracking;robot programming;coordinate system	An on-line visual tracking sensor system for the automation of laser welding processes in heavy industries is presented. A method of image process and features extraction for structured light image of laser welding has been developed. In order to set the range of interest, the Radon Transform is applied to determine the x and y coordinate in image coordinate system. For image de-noising, the median filtering and bi-level thresholding are used. Furthermore, the middle line of the laser stripe is extracted. Finally, a five step search method is carried out to examine the mid-point and gap width. A series of experiments show that the proposed method in this paper is effective, and its tracking detection precision is much better than traditional methods.	black and burst;data striping;experiment;median filter;noise reduction;online and offline;pulse-width modulation;structured light;thresholding (image processing);tracking system;video tracking	Yongliang Xie;Chuanyu Wu;Jianjun Yin	2008	2008 International Conference on Computer Science and Software Engineering	10.1109/CSSE.2008.1267	filter;robot;median filter;robot welding;computer vision;radon transform;simulation;structured light;laser;eye tracking;image processing;feature extraction;computer science;coordinate system;tracking;laser beam welding;welding	Robotics	59.855068047877694	-39.272008452609164	28390
8461ed7bdc7f8121e26c4587abdd3d12e94d0d04	integration of conditional random fields and attribute grammars for range data interpretation of man-made objects	attribute grammars;bottom up;range data;top down;random sampling;conditional random fields;attribute grammar;high and low level integration;conditional random field;facade interpretation;geometric constraints;3d reconstruction	(2009) 'Integration of conditional random fields and attribute grammars for range data interpretation of man-made objects', Annals of GIS, 15: 2, 117 — 126 To link to this Article: This article may be used for research, teaching and private study purposes. Any substantial or systematic reproduction, redistribution , reselling , loan or sub-licensing, systematic supply or distribution in any form to anyone is expressly forbidden. The publisher does not give any warranty express or implied or make any representation that the contents will be complete or accurate or up to date. The accuracy of any instructions, formulae and drug doses should be independently verified with primary sources. The publisher shall not be liable for any loss, actions, claims, proceedings, demand or costs or damages whatsoever or howsoever caused arising directly or indirectly in connection with or arising out of the use of this material. A new concept for the integration of low-and high-level reasoning for the interpretation of images of man-made objects is described. The focus is on the 3D reconstruction of facades, especially the transition area between buildings and the surrounding ground. The aim is the identification of semantically meaningful objects such as stairs, entrances, and windows. A low-level module based on random sample consensus (RANSAC) algorithm generates planar polygonal patches. Conditional random fields (CRFs) are used for their classification, based on local neighborhood and priors from the grammar. An attribute grammar is used to represent semantic knowledge including object partonomy and observable geometric constraints. The AND-OR tree-based parser uses the precision of the classified patches to control the reconstruction process and to optimize the sampling mechanism of RANSAC. Although CRFs are close to data, attribute grammars make the high-level structure of objects explicit and translate semantic knowledge in observable geometric constraints. Our approach combines top-down and bottom-up reasoning by integrating CRF and attribute grammars and thus exploits the complementary strengths of these methods. 1. Introduction In this article, we describe a concept for integrating low-and high-level reasoning for the interpretation of images of man-made objects. Our focus is on interpreting range data of building facades, especially the transition area between the building and the surrounding ground, what we call the 'build-ing collar'. The complexity of man-made objects requires flexible interpretation techniques that can handle the semantic knowledge about the domain as well as the richness of the appearance of all details in the image data. The variability of …	3d reconstruction;a* search algorithm;algorithmic inference;attribute grammar;bottom-up parsing;color-coding;complete (complexity);conditional random field;discriminative model;estimation theory;formal language;geographic information system;grammar induction;heuristic;high- and low-level;iterative method;level structure;meronomy;microsoft windows;observable;point cloud;primary source;random sample consensus;sampling (signal processing);selection rule;spatial variability;top-down and bottom-up design;x11 color names	Jörg Schmittwilken;Michael Ying Yang;Wolfgang Förstner;Lutz Plümer	2009	Annals of GIS	10.1080/19475680903464696	l-attributed grammar;computer science;machine learning;pattern recognition;top-down and bottom-up design;data mining;mathematics;conditional random field	AI	58.29378272874019	-45.25271205985725	28422
751f1db56bedd56979a23426348bceab893f0561	laser interferometry measurements based calibration and error propagation identification for pose estimation in mobile robots	mobile robots;robot localisation;navigation;pose estimation and registration;mechatronic systems		3d pose estimation;mobile robot;propagation of uncertainty;software propagation	Paulo A. Jiménez;Bijan Shirinzadeh	2014	Robotica	10.1017/S0263574713000660	control engineering;mobile robot;computer vision;navigation;simulation;computer science;artificial intelligence	Robotics	54.59732478005902	-36.495565839718616	28496
37e67da6bdb6499e4644d6321a05f82d2a2d85bb	on degeneracy of optimization-based state estimation problems	state estimation sensors robustness cameras eigenvalues and eigenfunctions laser radar;state space methods optimisation state estimation;online mapping degeneracy optimization based state estimation problems state estimation methods online method geometric structure problem constraints state space camera data lidar sensor 6 dof ego motion robustness online positioning	Positioning and mapping can be conducted accurately by state-of-the-art state estimation methods. However, reliability of these methods is largely based on avoiding degeneracy that can arise from cases such as scarcity of texture features for vision sensors and lack of geometrical structures for range sensors. Since the problems are inevitably solved in uncontrived environments where sensors cannot function with their highest quality, it is important for the estimation methods to be robust to degeneracy. This paper proposes an online method to mitigate for degeneracy in optimization-based problems, through analysis of geometric structure of the problem constraints. The method determines and separates degenerate directions in the state space, and only partially solves the problem in well-conditioned directions. We demonstrate utility of this method with data from a camera and lidar sensor pack to estimate 6-DOF ego-motion. Experimental results show that the system is able to improve estimation in environmentally degenerate cases, resulting in enhanced robustness for online positioning and mapping.	autonomous robot;computation;condition number;degeneracy (graph theory);image sensor;mathematical optimization;state space	Ji Zhang;Michael Kaess;Sanjiv Singh	2016	2016 IEEE International Conference on Robotics and Automation (ICRA)	10.1109/ICRA.2016.7487211	computer vision;mathematical optimization;control theory;mathematics	Robotics	54.58408140342386	-41.39469809855413	28625
e969bccbe4781425e604572b619a65965a5a8d61	aerial manipulation: a literature review		Aerial manipulation aims at combining the versatility and the agility of some aerial platforms with the manipulation capabilities of robotic arms. This letter tries to collect the results reached by the research community so far within the field of aerial manipulation, especially from the technological and control point of view. A brief literature review of general aerial robotics and space manipulation is carried out as well.	aerial photography;coat of arms;control point (mathematics);point of view (computer hardware company);robot;robotic arm;robotics	Fabio Ruggiero;Vincenzo Lippiello;Aníbal Ollero	2018	IEEE Robotics and Automation Letters	10.1109/LRA.2018.2808541	simulation;task analysis;control engineering;robotic arm;engineering;robotics;artificial intelligence	Robotics	66.557409469106	-28.365874400040738	28627
52afa82c948bf8a0c3ffb48e01dac4480bd18b76	a complex cross-spectral distribution model using normal variance mean mixtures	eeg data complex cross spectral distribution model normal variance mean mixtures cross spectral coefficients marginal density complex wishart distribution maximum likelihood estimation alpha brain wave sources;histograms;rhythm;medical signal processing electroencephalography maximum likelihood estimation;estimation cross spectrum coherence phase;phase;frequency estimation;random variables;independent component analysis electroencephalography scalp coherence rhythm brain modeling phase estimation frequency estimation random processes biomedical signal processing;spectrum;independent component analysis;indexing terms;maximum likelihood estimation;spectral density;complex cross spectral distribution model;brain modeling;maximum likelihood estimate;estimation;time series analysis;phase estimation;complex wishart distribution;normal variance mean mixtures;random processes;biomedical signal processing;distributed models;coherence;wishart distribution;cross spectrum;electroencephalography;cross spectral coefficients;alpha brain wave sources;medical signal processing;scalp;eeg data;marginal density	We propose a model for the density of cross-spectral coefficients using Normal Variance Mean Mixtures. We show that this model density generalizes the corresponding marginal density of the Complex Wishart distribution for the cross-spectral density. The Maximum Likelihood estimate of parameters in the distribution is derived, and examples are given from alpha brain wave sources in separated EEG data.	coefficient;electroencephalography;marginal model;neural oscillation;spectral density	Jason A. Palmer;Scott Makeig;Kenneth Kreutz-Delgado	2009	2009 IEEE International Conference on Acoustics, Speech and Signal Processing	10.1109/ICASSP.2009.4960397	half-normal distribution;stochastic process;econometrics;complex normal distribution;normal-gamma distribution;normal-wishart distribution;inverse-wishart distribution;pattern recognition;mathematics;wishart distribution;variance-gamma distribution;maximum likelihood;matrix normal distribution;statistics	Robotics	78.98712031182306	-39.27587627774279	28636
c92fdc748237d32be6ea4760afaf579dabaf2809	maccepa: the actuator with adaptable compliance for dynamic walking bipeds		Walking robots can be divided into two categories: on one hand the fully actuated robots that don’t use passive dynamics, and on the other hand the energy efficient passive walkers. For autonomous robots the energy storage is a problem, forecasting a bright future for passive walkers. At this moment the passive walkers are restricted to one walking speed due to the eigenfrequency, which is fixed by the mechanical constructions. Several actuators with adaptable compliant have been designed, but due to size, complexity or controllability these are difficult to implement in	autonomous robot;bram stoker's dracula;complexity;interaction;servo	Ronald Van Ham;Bram Vanderborght;Michaël Van Damme;Björn Verrelst;Dirk Lefeber	2005		10.1007/3-540-26415-9_91	control engineering;embedded system	Robotics	66.91592014524734	-24.935717935293344	28780
46bd66c21a31aab24b7c126ab116c9761a0dca51	towards a reliable set-up for bio-inspired collective experiments with real robots	mode collectif;etude experimentale;collective mode;robotics;biology;biologia;adaptive behaviour;robotica;robotique;estudio experimental;modo colectivo;biologie	"""This paper describes a set of tools developed at our laboratory that provide a reliable setup for conducting bio-inspired experiments with real robots. We focus on the hardware tools needed to monitor team performances as well as those to achieve collective adaptive behaviours. We propose concrete solutions to some of the main problems in collective robotics. The four main results we derive are: rst, the hardware modular-ity of the miniature robot Khepera 1] allows us to build a exible setup ; second, the energy autonomy problem is solved in a reliable way for experimenting with real robots during several hours; third, the communication architecture among teammates and/or with a supervisor unit is designed to prevent bandwidth bottlenecks with bigger robot teams; fourth, the use of programmable active pucks (also called \seeds"""" below) extends the set of possible bio-inspired experiments without increasing the sensorial complexity of the robots. A simple bio-inspired collective experiment, the gathering and clustering of randomly distributed passive seeds, is presented as an example as well as a test-bed for the extended autonomy tool. The results are compared with those reported in 2, 3]."""	british informatics olympiad;cluster analysis;experiment;khepera mobile robot;microbotics;performance;randomness;robotics;testbed	Alcherio Martinoli;E. Franzi;O. Matthey	1997		10.1007/BFb0112995	simulation;computer science;engineering;artificial intelligence;robotics	Robotics	58.4798210663574	-31.64654493275033	28833
40ef254bc2606e32feb1bc693e256023fd335818	reduction of angular position error of a machine vision system using the digital controller lm629		A new approach to position the Technical Vision System (TVS) laser ray, which determines the 3D coordinates of any objet under observation in the TVS Field-of-View (FOV), using the Digital Controller LM629 is proposed. This approach reduces significantly the angular position error by at least 82.97 per cent, compared to the previous implementation of a proportional algorithm in closed-loop configuration, using directly a single microcontroller. Present paper identifies the behavior of the DC motor shaft, which represents the main actuator of the TVS Positioning Laser (PL), adjusting an internal trapezoidal velocity profile, generated as the control signal for the DC motor. The reference value for the DC motor actual angular position is computed, using the Digital Controller LM629, which also tracks this actual angular position. The methodology of the new approach is developed in accordance with theoretical concepts. In addition, experimental results show the comparison between the previous implementation and this new approach.		Miguel Reyes-Garcia;Lars Lindner;Moises Rivas-López;Mykhailo Ivanov;Julio C. Rodríguez-Quiñonez;Fabian Natanael Murrieta-Rico;Alexander Gurko;Viktor Melnyk	2018	IECON 2018 - 44th Annual Conference of the IEEE Industrial Electronics Society	10.1109/IECON.2018.8592803		Robotics	64.68448914546958	-33.0200121454045	28895
b9014b0f0ffc602b31b85a3f08cd7c00df1307fd	tactile manipulation with biomimetic active touch	tactile sensors pins bayes methods real time systems biomembranes;trajectory control biomimetics end effectors tactile sensors;tactile manipulation complex trajectory robot arm end effector tactile fingertip biomimetic tactile sensor biomimetic active touch	Tactile manipulation is the ability to control objects in real-time using the sense of touch. Here we examine tactile manipulation from the perspective of active touch with a biomimetic tactile sensor, which combines tactile perception with control of sensor location. Experiments are performed with the tactile fingertip mounted as end effector to a robot arm, to manipulate (roll) a cylinder in contact with the fingertip. Performance is validated with offline (cross-validation) and online (real-time operation) assessments. Location perception is finer than the sensor resolution, leading to superresolved tactile manipulation along a complex trajectory. However, the original methods were non-robust to large unknown disturbances of object location, necessitating modification of the perceptual process to diminish prior beliefs relative to past posterior beliefs. In consequence robust and accurate tactile manipulation was attained. In general, it appears there is a trade-off between the responsiveness to unknown change and manipulation accuracy, which must be set appropriately for each task.	biomimetics;cross-validation (statistics);cylinder seal;norm (social);online and offline;real-time computing;real-time locating system;responsiveness;robot end effector;robotic arm;tactile sensor	Luke Cramphorn;Benjamin Ward-Cherrier;Nathan F. Lepora	2016	2016 IEEE International Conference on Robotics and Automation (ICRA)	10.1109/ICRA.2016.7487124	control engineering;computer vision;engineering;tactile sensor	Robotics	62.91493960173128	-33.71300397672749	28925
db1cdacb4275c6d13ada9e33bf2f2855f3aca11b	sound source localization using a single-point stereo microphone for robots	cameras robot vision systems robustness estimation microphone arrays;service robots disasters manipulators microphones mobile robots;estimation;robustness;microphone arrays;noise whitening functions sound source localization single point stereo microphone secondary sound source localizer robot applications secondary sound localizer hand manipulation disaster response robots parametric modeling mechanical scan;robot vision systems;cameras	In this study, a secondary sound source localizer for robot applications is developed. The purpose of using the secondary sound localizer is to assist the camera and hand manipulation of disaster-response robots. A key requirement for this application is the compactness of the input device. In this study, a single-point 13-mm diameter stereo microphone mountable on the robot hand is employed, and its observation model is developed. The localizer must be usable while the hand scans to collect visual information. This is realized by the conversion of the parameter scan in conventional parametric modeling to the mechanical scan of the hand. Another requirement is robustness against the ego noise of the robot. Two localization methods for a single-point stereo microphone that have noise-whitening functions are proposed. Experimental results show that the proposed method achieves a performance comparable to that achieved by the conventional time delay estimation approach but with a much more compact configuration.	broadcast delay;covox speech thing;decorrelation;humanoid robot;input device;microphone;multilateration;noise (electronics);observable;parametric model;region of interest;turing completeness	Futoshi Asano;Mitsuharu Morisawa;Kenji Kaneko;Kazuhito Yokoi	2015	2015 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA)	10.1109/APSIPA.2015.7415417	embedded system;computer vision;simulation;engineering	Robotics	64.87975596276391	-34.61194285875852	28936
57d36ce15ff13b4365398448e4df3638e23a3ee7	a simple yet effective obstacle avoider for the iara autonomous car	robot sensing systems;automobiles;trajectory;planning;autonomous automobiles;wheels	We present a simple yet effective obstacle avoider for the Intelligent and Autonomous Robotic Automobile (IARA). At each or several motion planning cycles, the IARA's obstacle avoider firstly receives as input an updated map of the environment around the car, the current car's state relative to the map, and a trajectory from the current car's state to the next goal state. Secondly, the obstacle avoider simulates the trajectory. Finally, if the trajectory crashes into an obstacle, then the obstacle avoider decreases the linear velocity commands of the trajectory to prevent the accident. To evaluate the performance of the obstacle avoider, we executed experiments with the IARA's simulator using a real-world sensor data log, which was acquired in the campus of the Universidade Federal do Espírito Santo (UFES). We also carried out experiments with IARA itself, which was driven autonomously on a parking lot of the UFES. Experimental results showed that the obstacle avoider, together with the motion planner, allows the IARA to go from objective to objective safely. In fact, in all the experiments executed with the IARA for about one year, the obstacle avoider operated successfully.	autonomous car;data logger;experiment;motion planning;simulation;smoothing;steering wheel;trajectory optimization;velocity (software development)	Ranik Guidolini;Claudine Badue;Mariella Berger;Lucas de Paula Veronese;Alberto Ferreira de Souza	2016	2016 IEEE 19th International Conference on Intelligent Transportation Systems (ITSC)	10.1109/ITSC.2016.7795866	computer vision;simulation;engineering;operations management	Robotics	57.00705379006516	-28.50163921144701	28962
6813e3c2102bd98a1328898e225c03f592e81a27	a separation of the boundary geometry from the boundary functions in pies for 3d problems modeled by the navier-lamé equation				Eugeniusz Zieniuk;Krzysztof Szerszen	2018	Computers & Mathematics with Applications	10.1016/j.camwa.2017.10.036		Theory	68.17838207653999	-41.2501317879837	28991
d0100cc87877f44cd5382459997137acb073741b	a soft pneumatic fabric-polymer actuator for wearable biomedical devices: proof of concept for lymphedema treatment		Soft actuators are ideal candidates for wearable biomedical devices, their inherent compliance, robustness, lightweight and the possibility to be washable take advantage over rigid actuators. Thus, a soft pneumatic fabric-polymer bending actuator as a base component for a robotic device for lymphedema treatment is reported in this work. The actuator is composed of two mechanical elements, one made of fabric and the other one made of a hyperelastic polymer which is stuck on the fabric element. The fabric element is designed and fabricated with a curved shape longer than the polymer element, that is a hyperelastic beam. To assemble both elements, the fabric element was folded before sticking in order to match the length of the polymer beam. Once the air is pumped into the fabric, it bends towards its original curved shape. Once the air is removed, the hyperelastic beam allows the actuator to recover its initial position. This actuator is capable of exerting compression and lateral force on a human arm mimicking manual lymphatic drainage. A mathematical model is presented which is in good agreement with the experimental data, it could serve to predict the actuator motion. An end-tip free bending displacement of about 2.2 cm and a bending force of about 0.35 N were achieved at 12.5 kPa. A proof-of-concept system for lymphedema treatment is presented as well.	displacement mapping;lateral thinking;mathematical model;polymer;robot;wearable computer	Etsel Suarez;Juan Julian Huaroto;Alberto A. Reymundo;Donal Holland;Conor J. Walsh;Emir Augusto Vela	2018	2018 IEEE International Conference on Robotics and Automation (ICRA)	10.1109/ICRA.2018.8460790	beam (structure);bending;proof of concept;experimental data;polymer;control engineering;actuator;engineering;compression (physics);hyperelastic material	Robotics	75.03833094629101	-24.81982085764946	29000
81f9abb0b907aaf8447b0c202a90162ada145cc4	accurate gpu-accelerated surface integrals for moment computation	real time;center of mass;volume;geometric algorithms;gpu;nurbs;moments;nurbs surface;physically based simulation;solid modeling;graphic processing unit;geometric algorithm;hybrid cpu gpu algorithms;deformable model	We present algorithms for computing accurate moments of solid models that are represented using multiple trimmed NURBS surfaces and triangles. Our algorithms make use of programmable Graphics Processing Units (GPUs) to accelerate the moment computations. For NURBS surfaces, we evaluate the surface coordinates and normals accurately, with theoretical bounds, using our GPU NURBS evaluator. We have developed a framework that makes use of this data to evaluate surface integrals of trimmed NURBS surfaces in real time. Since typical solid models also contain flat planes that are usually tessellated into triangles, our framework also includes GPU acceleration of the moment contributions of such flat faces. Using our framework, we can compute volume and moments of solid models with theoretical guarantees. Our algorithms support local geometry changes, which is useful for providing interactive feedback to the designer while the solid model is being designed. We can compute the center of mass and check for stability of the solid model interactively. Other applications of such real-time moment computation include deformation modeling, animation, and physically based simulations.	computation;graphics processing unit	Adarsh Krishnamurthy;Sara McMains	2011	Computer-Aided Design	10.1016/j.cad.2011.06.020	mathematical optimization;non-uniform rational b-spline;computer science;engineering;mathematics;geometry;computer graphics (images);mechanical engineering	EDA	69.46294795621124	-46.61330986384629	29118
26fe65b844f34be6dc89f7aaefe56d49cec83a4b	editorial: robot motion planning			motion planning;robot	Hiroshi Noborio;Takashi Tsubouchi	1996	JRM	10.20965/jrm.1996.p0001	robot;robot control;motion planning;computer vision;artificial intelligence;computer science	Robotics	58.151718507032164	-30.20548298640759	29297
1c57ea3a8d7fe9d687add04d3118b61e017a8a7f	development of human system with three micromanipulators for minimally invasive neurosurgery	surgery assisting system;micromanipulator;minimally invasive operation;neurosurgery;degree of freedom	A microsurgery assisting system for minimally invasive neurosurgery has been developed. Three sets of micromanipulators and a rigid endoscope are integrated together in a thin tubular insertion part. Each manipulator has three degrees of freedom and controlled through the control levers on the console. The manipulator has tubular structure, which allows a thin operating device to travel through it. It has been verified that the device can take up in-vivo tissue and the laser knife works well with the manipulator.		Kazutoshi Kan;Masakatsu G. Fujie;Fujio Tajima;Kouji Nishizawa;Toshikazu Kawai;Ako Shose;Kintomo Takakura;Shigeaki Kobayashi;Takeyoshi Dohi	2001			computer vision;rigid endoscope;microsurgery;artificial intelligence;neurosurgery;manipulator;medicine;micromanipulator	NLP	73.97675729471811	-28.729368625811368	29306
ae2d8e0c7d1b56e8d622df143c11f41333124a4e	a simple color prediction model based on multiple dot gain curves	color prediction;light scattering;engineering and technology;teknik och teknologier;superposition;prediction model	Most of the color prediction models use single dot gain curve, few assume that dot gain changes when ink superposition happens, but still, use single dot gain curve for each ink to compensate the effective ink coverage. Considering the fact that optical dot gain is the effect of light scattering in paper, it is reasonable that light with different wavelength might produce different optical dot gain for each ink. In this study, for each primary ink we utilized three different curves obtained by CIEX, Y and Z, which approximately stand for three special wavelength bands, to calculate color coordinates. In addition, we noticed that dot gain curves obtained from the print samples with single ink printed on paper do not work well for the prints where ink is printed on another, or others. Therefore, dot gain curves for different ink superposition situations are optimized by matching the calculated tri-stimulus values of training patches to their measurement counterpoints. For each ink, dividing the dot gain into several dot gain actions responding to different ink superposition situations, we got the final dot gain as a group of multiple curves that takes into account all possible ‘dot gain actions’ with certain probability coefficients.	coefficient;optical fiber;printing;triangular function	Yuanyuan Qu;Sasan Gooran	2011		10.1117/12.871628	superposition principle;dot gain;predictive modelling;light scattering;optics;physics;quantum mechanics	Vision	82.51634851298098	-47.24616963131317	29371
0c8141d94c0e5c944261fb19f446c0bab2767785	using particles to sample and control implicit surfaces	good sampling distribution;repulsion adaptively;surface topology;control point;local repulsion;surface move;local density;simple constraint;implicit surface;surface motion;interaction;constrained optimization;optimization;surface;solid;algorithms;curve	We present a new particle-based approach to sampling and controlling implicit surfaces. A simple constraint locks a set of particles onto a surface while the particles and the surface move. We use the constraint to make surfaces follow particles, and to make particles follow surfaces. We implement control points for direct manipulation by specifying particle motions, then solving for surface motion that maintains the constraint. For sampling and rendering, we run the constraint in the order direction, creating floater particles that roam freely over the surface. Local repulsion is used to make floaters spread evenly across the surface. By varying the radius of repulsion adaptively, and fissioning or killing particles based on the local density, we can achieve good sampling distributions very rapidly, and maintain them even in the face of rapid and extreme deformations and changes in surface topology.	constraint algorithm;control point (mathematics);direct manipulation interface;implicit surface;lock (computer science);sampling (signal processing)	Andrew P. Witkin;Paul S. Heckbert	1994		10.1145/192161.192227	mathematical optimization;constrained optimization;control theory;mathematics	Graphics	69.0202492846023	-44.27060670493453	29434
30fd6c78200162a9a10057d99b5b5dfbf00ed529	design and evaluation of a serial elastic actuator for human assistance	variable system inherent friction serial elastic actuator human assistance assistance robots partially paralyzed patients reference sensor data stiff fixation passive human test subject active human test subject;actuators;springs torque actuators sea measurements exoskeletons brushless motors current measurement;medical robotics;handicapped aids;medical robotics actuators friction handicapped aids;exoskeleton serial elastic actuator humans assistance;friction	In this article, the systematic development of a serial elastic actuator for human assistance is presented. First, requirements for the actuator are deduced from the specific application, as part of an assistance robots for partially paralyzed patients. A test bench was developed to evaluate the serial elastic actuator under various conditions and to produce reference sensor data. The device was tested in four different scenarios, ranging from stiff fixation of the output to interaction with the knee joint of an active or passive human test subject. A variable system inherent friction was identified and the potential of this (usually undesired) characteristic is discussed for the special case of human assistance.	advanced process control;coupling (computer programming);electromyography;requirement;robot;sensor;stiff equation;test bench;torsion (gastropod)	Kurt Gerlach-Hahn;Christian Dahmen;Berno J. E. Misgeld	2013	2013 XXIV International Conference on Information, Communication and Automation Technologies (ICAT)	10.1109/ICAT.2013.6684087	control engineering;engineering;control theory;mechanical engineering	Robotics	71.81316808161499	-25.87725033320122	29529
dbf641e2c7942274e9df2018740de2c2b961b774	reflection model of metallic paints for reflectance acquisition	global illumination;industrial production;reflection model;artificial intelligence;photon mapping	Nowadays metallic paints are used in many situations. Although a lot of industrial products are painted because of the significant appearance, the reflection of the metallic paint is very complex and it is difficult to generate a photo-realistic image of a particular metallic paint. Recently, Rump et al. [Rump et al. 2008] proposed a method to acquire the reflectance and to generate photo-realistic images of metallic paints. They used BTF to capture and represent flakes in metallic paints, however, it is hard to capture and to store. In this paper, we propose a simple model to express the metallic paints including the sparkling effect of the flakes in metallic paints.	bidirectional texture function;rump kernel	Masashi Baba;Naoki Asada	2009		10.1145/1599301.1599391	industrial production;computer science;artificial intelligence;photon mapping;global illumination	AI	61.0460343459867	-51.106794113565776	29561
e7cc033e2ee22c4db15812e260a06255d828c0f1	measurement and defect detection of the weld bead based on online vision inspection	image processing algorithms;image extraction algorithms;sensor systems;defect detection measurement;weld bead profile measurement;multilayer welding processes defect detection measurement online vision inspection weld bead inspection weld bead profile measurement structured light based vision inspection system image processing algorithms image extraction algorithms;automatic optical inspection;welding;manufacturing automation;service robots;structured light;welding inspection robotics and automation machine vision radiography sensor systems monitoring manufacturing automation productivity service robots;image sensors;inspection;journal;radiography;welding flaw detection inspection machine vision visual system;computer vision;structured light based vision inspection system;weld bead inspection;monitoring;flaw detection;machine vision;feature extraction;welding automatic optical inspection computer vision feature extraction image sensors;multilayer welding processes;online vision inspection;productivity;visual system;robotics and automation;defect detection	Weld bead inspection is important for high-quality welding. This paper summarizes our work on weld bead profile measurement, monitoring, and defect detection using a structured light-based vision inspection system. The configuration of the sensor is described and analyzed. In this configuration, the system presented in this paper can easily be calibrated. The image processing and extraction algorithms for laser profiles and feature points are presented. The dimensional parameters of the weld bead are measured, and the weld defects are detected during multilayer welding processes. Experiments using the vision inspection system were conducted with satisfactory results for online inspection.	algorithm;calibration (statistics);feature vector;image processing;multilayer perceptron;robot welding;software bug;structured light	Yuan Li;Youfu Li;Qinglin Wang;De Xu;Min Tan	2010	IEEE Transactions on Instrumentation and Measurement	10.1109/TIM.2009.2028222	computer vision;productivity;radiography;structured light;visual system;inspection;machine vision;feature extraction;computer science;engineering;image sensor;forensic engineering;engineering drawing;welding	Robotics	60.10028871171788	-40.3490740791766	29634
95a6f94a27b937673f05bb441e73f67bf8fbeec0	study of robustness of zero frequency resonator method for extraction of fundamental frequency	zfr;fundamental frequency extraction;mobile;spectrum analysis;helium;multispeaker;telephone;he;speech processing;frequency estimation;speech;linear predictive;f 0;telephone zero frequency resonator method fundamental frequency extraction speech signals hilbert envelope he linear prediction lp short term spectrum analysis zfr multispeaker mobile;lp;speech processing feature extraction;zero frequency resonator method;resonant frequency;feature extraction;speech signals;robustness;linear prediction;correlation;speech helium robustness resonant frequency frequency estimation correlation speech processing;fundamental frequency;hilbert envelope;short term spectrum analysis;robustness zfr f 0 hilbert envelope short term spectrum analysis	The objective of this work is to develop and study the robustness of the zero frequency resonator (ZFR) based method for extraction of the fundamental frequency (F0) of speech signals. The proposed ZFR method for estimating F0 consists of zero frequency filtering of the Hilbert envelope (HE) of the linear prediction (LP) residual of speech signal, followed by short-term spectrum analysis of the filtered output. The robustness of the proposed method is tested using speech signals collected in practical environments like distant, reverberant, telephone, mobile and multispeaker. Experimental results show that the proposed ZFR method estimates F0 in majority of the cases.		Bayya Yegnanarayana;S. R. Mahadeva Prasanna;S. Guruprasad	2011	2011 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	10.1109/ICASSP.2011.5947577	spectrum analyzer;speech recognition;resonance;linear prediction;feature extraction;computer science;speech;mobile technology;speech processing;mathematics;fundamental frequency;helium;correlation;statistics;robustness	Robotics	81.63385682983983	-33.73039301167624	29636
9df39b05120c7e7d76d5429261155cb215b94a19	active one-shot scan for wide depth range using a light field projector based on coded aperture	video signal processing calibration image coding stereo image processing;apertures cameras shape lenses image reconstruction optical imaging convolution;narrow depth range central projection model active stereo systems camera setup active one shot scan wide depth range light field projector coded aperture feature based search hierarchical approach image based techniques image based approach precise calibration method thin lens model video projector depth dependent pattern	The central projection model commonly used to model cameras as well as projectors, results in similar advantages and disadvantages in both types of system. Considering the case of active stereo systems using a projector and camera setup, a central projection model creates several problems, among them, narrow depth range and necessity of wide baseline are crucial. In the paper, we solve the problems by introducing a light field projector, which can project a depth-dependent pattern. The light field projector is realized by attaching a coded aperture with a high frequency mask in front of the lens of the video projector, which also projects a high frequency pattern. Because the light field projector cannot be approximated by a thin lens model and a precise calibration method is not established yet, an image-based approach is proposed to apply a stereo technique to the system. Although image-based techniques usually require a large database and often imply heavy computational costs, we propose a hierarchical approach and a feature-based search for solution. In the experiments, it is confirmed that our method can accurately recover the dense shape of curved and textured objects for a wide range of depths from a single captured image.	approximation algorithm;baseline (configuration management);coded aperture;computer stereo vision;database;distortion;experiment;light field;mathematical optimization;movie projector;requirement;shape context;video projector	Hiroshi Kawasaki;Satoshi Ono;Yuuki Horita;Yuki Shiba;Ryo Furukawa;Shinsaku Hiura	2015	2015 IEEE International Conference on Computer Vision (ICCV)	10.1109/ICCV.2015.407	computer vision;computer graphics (images)	Vision	57.64779878084167	-50.64730835297421	29663
f648977557b4def89828b390edd6d24d53ab631b	design of an integrated tactile display system	virtual reality;actuators;force feedback;sensitivity;tactile sensing;tactile feedback;displays skin force feedback piezoelectric actuators virtual environment vibrations fingers humans pins pneumatic actuators;tactile display;pressure distribution;tactile sensors;virtual reality tactile sensors haptic interfaces force feedback sensitivity actuators;2 dof translation force feedback device integrated tactile display system tactile sensation kinesthetic force pressure distribution vibration slip kinesthetic display tactile feedback device tactile sensitivity finger movement piezoelectric bimorph linear actuator;virtual environment;haptic interfaces	Tactile sensation is essential for many exploration and manipulation tasks not only in a real environment but also in a virtual environment. We suggest the design of an integrated tactile display system that provides kinesthetic force, pressure distribution, vibration and slip/stretch. The system consists of two parts: a 2 DOF force feedback device for kinesthetic display and a tactile feedback device for displaying the normal stimulation to the skin and the skin slip/stretch. Psychophysical experiments measure the effects of fingerpad selection, the direction of finger movements and the texture width on tactile sensitivity. We also investigate the characteristics of lateral finger movement while subjects perceive different textures. From the experimental results, the principal parameters for designing a tactile display are suggested. A tactile display device, using eight piezoelectric bimorphs and a linear actuator, is implemented and attached to a 2 DOF translational force feedback device to simultaneously simulate the texture and stiffness of the object. As a result, we find out that the capability of the suggested device is sufficient to display physical quantities for tactile sensing.	display device;experiment;haptic technology;lateral computing;lateral thinking;piezoelectricity;simulation;virtual reality	Ki-Uk Kyung;Seung-Woo Son;Dong-Soo Kwon;Munsang Kim	2004	IEEE International Conference on Robotics and Automation, 2004. Proceedings. ICRA '04. 2004	10.1109/ROBOT.2004.1307243	control engineering;computer vision;sensitivity;computer science;engineering;virtual machine;artificial intelligence;control theory;virtual reality;pressure coefficient;haptic technology;tactile sensor;actuator	Robotics	75.2763869243726	-26.597801617635927	29740
0702efd9024777b30f25259e6fd032e432a593f7	sensory based motion planning with global proofs	straight motion;robot sensing systems;sensory based motion planning;convergence;range data;unknown environment;turning;free range;uncertainty;global proofs;path planning;obstacle boundary following;distbug;mobile robots;global convergence;robot sensing systems convergence turning;fuzzy logic;navigation;motion planning;boundary following direction sensory based motion planning global proofs distbug unknown environment straight motion obstacle boundary following free range global convergence;robot motion;computer science;sensor fusion;convergence mobile robots path planning;boundary following direction	A sensory based algorithm DistBug, that is guaranteed to reach the target in an unknown environment or report that the target is unreachable, is presented. The algorithm is reactive in the sense that it relies on range data to make local decisions, and does not create a world model. The algorithm consists of two behaviors (modes of motion): straight motion between obstacles and obstacle boundary following. Simulation results as well as experiments with a real robot are presented. The condition for leaving obstacle boundary is based on the free range in the direction to the target. This condition allows the robot to leave the obstacle as soon as the local conditions guarantee global convergence. Range data is utilized for choosing the turning direction when the robot approaches an obstacle. A criterion for reversing the boundary following direction when it seems to be the wrong direction is also introduced. As a direct result of these local decisions, a significant improvement in the performance was achieved.	motion planning	Ishay Kamon;Ehud Rivlin	1995		10.1109/IROS.1995.526253	computer vision;simulation;computer science;artificial intelligence;control theory;mathematics;motion planning;obstacle avoidance	Robotics	58.636922569107526	-24.40064909516831	29813
816121b23b5929650a435591c625d9c8f49335eb	snapping of fuzzy objects using the multi-resolution fuzzy grid snapping technique	multi resolution	In the present paper, we propose an automatic snapping method that aligns fuzzy objects in a multi-resolution grid system in order to improve the efficiency of sketch-based CAD systems. The sketch-based CAD system that we have previously realized successfully identifies sketch drawings as primitive geometrical curve objects by treating the sketches as fuzzy objects, the fuzziness of which is associated with the roughness of the drawing manner. However, when the system aligns the identified objects with a grid system, difficulties in the grid resolution setting arise because the identified objects often consist of both fine and coarse portions and thus require different grid resolution settings for proper alignment. Meanwhile, the resolution problem with respect to cursor point snapping has been solved by multi-resolution fuzzy grid snapping (MFGS), which realizes automatic selection of the snapping resolution by treating the cursor as a fuzzy point, the fuzziness of which is associated with the roughness of the pointing manner of the user. The present paper proposes a method to apply MFGS to fuzzy objects in order to resolve the difficulties involved in the setting of the snapping resolution of the sketch-based CAD system. Experimental results show that users can align identified objects to an appropriate resolution through MFGS by controlling the roughness of the drawing manner.	align (company);caddie;computer-aided design;cursor (databases);image resolution	Sumudu Dematapitiya;Masatoshi Kawazoe;Akira Nishikawa;Masaki Sakurai;Sato Saga	2009	JIP	10.2197/ipsjjip.17.47	simulation;computer science;computer graphics (images)	Robotics	65.56293032800264	-44.71681429451857	29835
4fc81a6c68d38b3a3fbea8246754b88bd6c0ff50	parameter-unaware autocalibration for occupancy mapping	video cameras image motion analysis lenses object detection;image motion analysis;technology and engineering;video cameras;lenses;cameras apertures manuals government estimation error;calibration;object detection;multicamera environment parameter unaware autocalibration occupancy mapping localization mapping multicamera system manual extrinsic calibration focal length position angle viewing angle multicamera setup multicamera configuration detected object anisotropic scaling parameter ground plane position isotropic scale factor lens distortion	People localization and occupancy mapping are common and important tasks for multi-camera systems. In this paper, we present a novel approach to overcome the hurdle of manual extrinsic calibration of the multi-camera system. Our approach is completely parameter unaware, meaning that the user does not need to know the focal length, position or viewing angle in advance, nor will these values be calibrated as such. The only requirement to the multi-camera setup is that the views overlap substantially and are mounted at approximately the same height, requirements that are satisfied in most typical multi-camera configurations. The proposed method uses the observed height of an object or person moving through the space to estimate the distance to the object or person. Using this distance to backproject the lowest point of each detected object, we obtain a rotated and anisotropically scaled view of the ground plane for each camera. An algorithm is presented to estimate the anisotropic scaling parameters and rotation for each camera, after which ground plane positions can be computed up to an isotropic scale factor. Lens distortion is not taken into account. The method is tested in simulation yielding average accuracies within 5cm, and in a real multi-camera environment with an accuracy within 15cm.	3d projection;algorithm;anisotropic filtering;calibration (statistics);camera resectioning;distortion;experiment;focal (programming language);glossary of computer graphics;image scaling;internationalization and localization;need to know;requirement;semi-supervised learning;semiconductor industry;simulation;viewing angle	David Van Hamme;Maarten Slembrouck;Dirk Van Haerenborgh;Dimitri Van Cauwelaert;Peter Veelaert;Wilfried Philips	2013	2013 Seventh International Conference on Distributed Smart Cameras (ICDSC)	10.1109/ICDSC.2013.6778205	computer vision;calibration;simulation;lens;optics	Robotics	55.25986115344367	-47.88373702266981	29847
78b0bedab11775ff0d59b7b78ff8de769b9e189f	sensor fusion for augmented reality	kalman filtering;inertial navigation sensor fusion kalman filter augmented reality computer vision;sensor fusion augmented reality cameras computer vision magnetic sensors acoustic sensors layout delay application software tv;ar;dynamic model;kalman filters;inertial navigation;nonlinear filter;kalman filter;motion estimation;control engineering;computer vision;motion estimation sensor fusion augmented reality ar camera position estimation orientation estimation nonlinear estimation problem computer vision kalman filtering;camera motion;reglerteknik;low latency;nonlinear estimation problem;industrial robots;position estimation;nonlinear estimation;real time implementation;sensor fusion;augmented reality;orientation estimation;sensor fusion augmented reality computer vision kalman filters motion estimation;inertial sensor;camera;pose estimation	In augmented reality (AR), the position and orientation of the camera have to be estimated with high accuracy and low latency. This nonlinear estimation problem is studied in the present paper. The proposed solution makes use of measurements from inertial sensors and computer vision. These measurements are fused using a Kalman filtering framework, incorporating a rather detailed model for the dynamics of the camera. Experiments show that the resulting filter provides good estimates of the camera motion, even during fast movements	augmented reality;experiment;kalman filter;nonlinear system;sensor	Jeroen D. Hol;Thomas B. Schön;Fredrik Gustafsson;Per J. Slycke	2006	2006 9th International Conference on Information Fusion	10.1109/ICIF.2006.301604	computer vision;camera auto-calibration;augmented reality;simulation;engineering;control theory	Vision	56.0752689841643	-36.67790491369388	29876
aa36774ee1363cd9611500cc1b1d1806ea640e6f	the design and control of a tactile display based on shape memory alloys	closed loop systems;computer peripheral equipment;feedback;pulse width modulation;shape memory effects;pwm control scheme;closed loop resistive feedback;psychophysical tests;shape memory alloys;tactels;tactile display	Closed loop resistive feedback within a PWM control scheme has proved an effective method of controlling a 64 element tactile array. In particular it has allowed independent height control of all tactels with insensitivity to ambient temperature and external forces. It has also resulted in compact electronics. The elementary psychophysical tests show the potential of the surface to display complex surface structures. Future work will examine the performance combined with a visual VE system		P. M. Taylor;A. Moser;A. Creed	1997		10.1109/ROBOT.1997.614319	control engineering;electronic engineering;computer science;engineering;control theory;pulse-width modulation	Robotics	75.79911191820734	-26.673718808276483	29914
48dbfdc2319d440a6f75fd2fb1f07e43507e2a39	in-flight initial alignment scheme for radar-aided sins in the arctic	strapdown inertial navigation system;sins mechanisation equations;attitude divergence problem;radar information;radar equations;multipopulation genetic algorithm;radar aided sins;inflight initial alignment scheme numerical simulations unscented kalman filter mga multipopulation genetic algorithm nonlinear equations radar information grid frame radar equations sins mechanisation equations inherent sins error characteristics attitude divergence problem strapdown inertial navigation system radar aided sins;inherent sins error characteristics;inflight initial alignment scheme;mga;nonlinear equations;numerical simulations;unscented kalman filter;grid frame;radar inertial navigation kalman filters nonlinear filters genetic algorithms numerical analysis	This study proposes a novel in-flight initial alignment scheme for the strapdown inertial navigation system (SINS) in the Arctic, aiming to solve the attitude divergence problem caused by the inherent SINS error characteristics. Considering the special geographical conditions in the Arctic, the authors establish the SINS mechanisation equations and radar equations in the grid frame in this work. In the coarse alignment stage, the radar information is employed to solve the nonlinear equations by using the multi-population genetic algorithm (MGA), and then the unscented Kalman filter is applied to diminish the noise influence on MGA results. During the fine alignment process, the attitude information is further corrected by the Radar/SINS integrated navigation system under the Arctic coordinate frame. At last, numerical simulations are performed, and the results demonstrate that the proposed scheme achieves better accuracy compared with traditional approaches.	radar	Jing Li;Ningfang Song;Gongliu Yang;Shujie Yang;Jing Wang	2016	IET Signal Processing	10.1049/iet-spr.2015.0497	kalman filter;computer vision;simulation;nonlinear system;computer science;control theory;mathematics	NLP	55.16165232424316	-33.59132856727537	29932
33244ec0a8afdd121ffef7530ef5561923ff2888	multiresolution free form object modeling with point sampled geometry	modeling technique;surface representation;texture mapping;shape representation;boolean operation;object hierarchies;digital content;system and information processing;information processing;object hierarchy and geometric transformation;industrial application;free form deformation;feature representation;three dimensional graphics and realism;object model	In this paper an efficient framework for the creation of 3D digital content with point sampled geometry is proposed. A new hierarchy of shape representations with three levels is adopted in this framework. Based on this new hierarchical shape representation, the proposed framework offers concise integration of various volumetric- and surface-based modeling techniques, such as Boolean operation, offset, blending, free-form deformation, parameterization and texture mapping, and thus simplifies the complete modeling process. Previously to achieve the same goal, several separated algorithms had to be used independently with inconsistent volumetric and surface representations of the free-form object. Both graphics and industrial applications are presented to demonstrate the effectiveness and efficiency of the proposed framework.	algorithm;alpha compositing;digital recording;free-form deformation;graphics;multiresolution analysis;shape context;texture mapping	Yong-Jin Liu;Kai Tang;Matthew Ming-Fai Yuen	2004	Journal of Computer Science and Technology	10.1007/BF02945586	texture mapping;computer vision;object model;information processing;computer science;theoretical computer science;machine learning;function representation;programming language	Graphics	66.62166031607778	-44.986772886432355	30024
3c9885079e8e9c71f5a0ff44076abb4591c56008	phase i monitoring of spatial surface data from 3d printing	statistical process control;profile monitoring;registration;nonparametric regression;surface estimation;kernel smoothing	AbstractIn recent years, 3D printing gets more and more popular in manufacturing industries. Quality control of 3D printing products thus becomes an important research problem. However, this problem is challenging due to the facts that (i) the surface of a product from 3D printing can have arbitrary shape, even when the 3D printing process is in-control, (ii) surface observations of the product obtained from a laser scanner may not have regularly spaced locations, and (iii) the overall geometric positions of 3D printing products might be all different, making proper comparison among different products difficult. In this paper, we propose a Phase I control chart for monitoring products from 3D printing that addresses all these challenges. Numerical studies show that it works well in practice.	3d printing	Yangyang Zang;Peihua Qiu	2018	Technometrics	10.1080/00401706.2017.1321585	data mining;mathematics;nonparametric regression;statistical process control;statistics;kernel smoother	HCI	71.60743025738108	-38.18963729707777	30033
f6fbae2a880b5f71826cf5437bd4222833d7274f	analysis and design of a robotic distance sensor	contraste;modulation phase;optimisation;modulacion fase;optimizacion;fotodiodo;phase modulation;etude experimentale;analysis and design;manipulateur;photodiode;robotics;light emitting diode;electrooptique;capteur distance;manipulador;electrooptica;analyse performance;performance analysis;sensor distancia;diodo electroluminescente;robotica;etalonnage;optimization;distance sensor;transductor;robotique;diode electroluminescente;electrooptics;transducer;transducteur;estudio experimental;manipulator;calibration;analisis eficacia	Abstract#R##N##R##N#Analysis and design of a robotic electrooptical distance sensor, based on the phase-shift measurement of a modulated light intensity, is addressed in this article. The transducer of this sensor employs two light sources (light-emitting diodes), whose intensities are modulated by different-phase sine-wave signals, and one photodiode receiver. The distance of an object's surface with respect to the sensor is measured by investigating the received phase shift. The experimental set-up of the sensor, used in this research, was designed and manufactured such that various mechanical and electronic design parameters could be investigated independently. Experiments undertaken show that these parameters indeed affect the performance of the sensor. The exemplary optimization analysis carried out considered only two performance aspects of the sensor, namely, sensitivity and operational range, and yielded corresponding optimal design parameters. The optimal distance sensor analyzed illustrated that it has sufficient resolution to be useful for most existing industrial robots.	robot;sensor	O. Partaatmadja;Beno Benhabib;Andrew A. Goldenberg	1993	J. Field Robotics	10.1002/rob.4620100403	photodiode;electronic engineering;calibration;transducer;soft sensor;computer science;engineering;electrical engineering;artificial intelligence;manipulator;phase modulation;optics;robotics;transductor;light-emitting diode	Robotics	60.85304138991175	-35.64814936674091	30149
fa7f56d05f3a9000bce5e71160196e4e6f9e03c9	anticipative humanoid postural control system for locomotive tasks	robot sensing systems;control systems;feedforward neural networks;surprise anticipative humanoid postural control;position control feedback feedforward fuzzy reasoning humanoid robots motion control;foot;acceleration;humanoid robots;neuro fuzzy human style reasoning anticipative humanoid postural control system locomotive task humanoid robots feedback control system anticipative component feedforward system anticipative subsystem sensory input evaluation surprise theory motor reaction pattern synergy pattern;robot sensing systems control systems acceleration foot humanoid robots feedforward neural networks	Postural control of humanoid robots during locomotion tasks has been typically focused in keeping balance by means of classic feedback control systems. The study of human behaviour in postural control reveals the existence of an anticipative component for postural control introduced by means of a feedforward system. This anticipative subsystem is in charge of preparing the human or humanoid system to react against perturbations during locomotion. In this way, the reactions can be more complex and higher perturbations levels can be overcome. The anticipative system is supported by the evaluation of sensory inputs by means of applying concepts extracted from the Surprise Theory. The data captured from sensory sources are transformed into perceptions and then compared with pre-established parameters. The comparison mismatch causes the elicitation of unexpected events or surprises. Then, these events are evaluated to generate a parameter that can be used to fulfil motor reaction patters called synergies. Finally, the new anticipative system is enabled by the use of neuro-fuzzy human style reasoning computing modules.	biological organisation;control system;feedback;feedforward neural network;humanoid robot;neuro-fuzzy;perturbation theory;risk management;synergy	Santiago Martínez;D. Esteban;Alberto Jardón Huete;Carlos Balaguer	2014	2014 IEEE-RAS International Conference on Humanoid Robots	10.1109/HUMANOIDS.2014.7041351	acceleration;simulation;computer science;control system;humanoid robot;artificial intelligence;control theory;foot	Robotics	69.18789807635197	-26.152895299976183	30158
0b637063cefdd937de065b21ce758296ca89c911	fractured 3d object restoration and completion	voxel visibility;space reduction;ray tracing;surface area heuristic;kd tree construction	The problem of object restoration from eroded fragments where large parts could be missing is of high relevance in archaeology. Manual restoration is possible and common in practice but it is a tedious and error-prone process, which does not scale well. Solutions for specific parts of the problem have been proposed but a complete reassembly and repair pipeline is absent from the bibliography. We propose a shape restoration pipeline consisting of appropriate methods for automatic fragment reassembly and shape completion. We demonstrate the effectiveness of our approach using real-world fractured objects.	circuit restoration;cognitive dimensions of notations;relevance;scalability;segmentation and reassembly	Anthousis Andreadis;Robert Gregor;Ivan Sipiran;Pavlos Mavridis;Georgios Papaioannou;Tobias Schreck	2015		10.1145/2787626.2792633	ray tracing;computer vision;computer science	Vision	60.56930264542706	-49.10124002997017	30282
20023ecc5eece2e24062534875489bfcddaefae0	log-spectral amplitude estimation with generalized gamma distributions for speech enhancement	speech speech enhancement signal to noise ratio approximation methods gain;cosh distance log spectral amplitude estimation generalized gamma distributions speech enhancement lsa estimators ggd speech short time spectral amplitudes stsa noizeus database signal to noise ratio ssnr;approximation method;gain;generalized gamma distribution speech enhancement log spectral amplitude estimator;speech;speech enhancement;amplitude estimation;generalized gamma distribution;gamma distribution;approximation methods;speech enhancement amplitude estimation gamma distribution;signal to noise ratio;log spectral amplitude estimator	This paper presents a family of log-spectral amplitude (LSA) estimators for speech enhancement. Generalized Gamma distributed (GGD) priors are assumed for speech short-time spectral amplitudes (STSAs), providing mathematical flexibility in capturing the statistical behavior of speech. Although solutions are not obtainable in closed-form, estimators are expressed as limits, and can be efficiently approximated. When applied to the Noizeus database [1], proposed estimators are shown to provide improvements in segmental signal-to-noise ratio (SSNR) and COSH distance [2], relative to the LSA estimator proposed by Ephraim and Malah [3].	approximation algorithm;signal-to-noise ratio;speech enhancement	Bengt J. Borgstrom;Abeer Alwan	2011	2011 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	10.1109/ICASSP.2011.5947418	gamma distribution;speech recognition;gain;speech;pattern recognition;mathematics;generalized gamma distribution;signal-to-noise ratio;statistics	Robotics	82.10486653157051	-33.54209844142432	30424
53267f4446b9b9e435057516403d4a1547148ab3	force feedback device with pneumatic artificial muscles and magnetorheological clutches	pneumatic artificial muscle;mr clutch;force feedback device	Recently, force feedback devices that intuitively achieve excellent operation have attracted attention in a wide range of fields such as remote operation, virtual reality, and medical training systems. However, it is difficult for conventional devices to widely display soft and hard objects because of driving motors. Moreover, they are likely to be hazardous in the event of delayed response to an unexpected external force. To solve these problems, we previously developed a force feedback device using pneumatic artificial muscles, which are structurally flexible and have wide a range of stiffness, and magnetorheological clutches. Furthermore, we confirmed that any three-dimensional virtual object can be displayed using the developed device. However, when the operation part of the force feedback device is moved away from the virtual object, it remains stuck to the virtual object. In this study, we propose a system to reduce the sticking phenomenon and experimentally confirm the reduction rate (85%). Moreover, we displayed viscous torque as a new application of the feedback device.	experiment;haptic technology;pneumatic artificial muscles;virtual reality	Masatoshi Kobayashi;Junya Hirano;Taro Nakamura;Yasuyuki Yamada	2016	IECON 2016 - 42nd Annual Conference of the IEEE Industrial Electronics Society	10.1109/IECON.2016.7793056	control engineering;simulation;engineering;control theory	Robotics	74.2875887266192	-24.16906708152984	30517
bc16f115e307e2406ada3f0808a84bfd4ed697d8	a hierarchical system structure for coordinated control of industrial manipulators	robot sensing systems;hierarchical system;control systems;hierarchical systems;level control;manipulator dynamics;service robots;hierarchical systems control systems electrical equipment industry industrial control manipulator dynamics level control intelligent control service robots robot sensing systems robot kinematics;electrical equipment industry;intelligent control;control structure;coordinated control;industrial control;intelligent system;high level language;robot kinematics	This paper describes a framework for the intelligent control of industrial manipulators. The structure is designed to allow a robotic system to take full advantage of the improved sensing capabilities and more powerful languages that are now becoming available. The framework consists of two layers of hierarchy for the coordinated control of multi-jointed industrial manipulators. The low l e v e l control mechanism, responsible for servoing each joint, is adaptive to both manipulator dynamics and payload changes. The individual low-level joint controllers are integrated and coordinated by the h i g h l e v e l control structure. Together, the two levels provide a versatile basis for manipulator control. This basis forms a complete structure, and is suited for interfacing with yet higher level intelligent systems such as task planners, high level languages, and environment sensitive path planners.	control flow;high- and low-level;high-level programming language;intelligent control;robot	Kang G. Shin;Stuart B. Malin	1984		10.1109/ROBOT.1984.1087159	control engineering;simulation;computer science;engineering;control system;artificial intelligence;control theory;hierarchical control system;control flow;high-level programming language;robot kinematics;intelligent control	Robotics	62.591604364631706	-27.63678232623887	30526
62fe0a113ae5f38e6b0bad05c965d1608405b2bd	real-time view correction for mobile devices		We present a real-time method for rendering novel virtual camera views from given RGB-D (color and depth) data of a different viewpoint. Missing color and depth information due to incomplete input or disocclusions is efficiently inpainted in a temporally consistent way. The inpainting takes the location of strong image gradients into account as likely depth discontinuities. We present our method in the context of a view correction system for mobile devices, and discuss how to obtain a screen-camera calibration and options for acquiring depth input. Our method has use cases in both augmented and virtual reality applications. We demonstrate the speed of our system and the visual quality of its results in multiple experiments in the paper as well as in the supplementary video.	algorithm;calibration;camera resectioning;experiment;gradient;inpainting;mobile device;morphologic artifacts;partial;photopsia;preparation;real-time clock;real-time computing;sparse matrix;temporal logic;virtual artifact;virtual camera system;virtual reality	Thomas Schöps;Martin R. Oswald;Pablo Speciale;Shuoran Yang;Marc Pollefeys	2017	IEEE Transactions on Visualization and Computer Graphics	10.1109/TVCG.2017.2734578	inpainting;rendering (computer graphics);artificial intelligence;computer vision;computer science;use case;mobile device;classification of discontinuities;rgb color model	Visualization	58.18011520071441	-50.9778942818299	30552
4a851d86b5096ed083001cefc863bf5fd7177625	a new efficient algorithm for fitting rectangular boxes and cubes in 3d	shape computer science optimization methods tomography fitting solids;three dimensions;efficient algorithm;three dimensional;degeneration;curve fitting;cutting off vertices fitting rectangular boxes three dimensional voxel space normalization method	In this paper, we introduce a new approach for fitting rectangular boxes and cubes given as a set of voxels in a three-dimensional voxel space. This extends our work on fitting rectangles and squares described in H. Suesse et al, (2001) to three dimensions. It is also based on our normalization method published in K. Voss et al (1997) and (1999). Here we also encounter the problem of normalizing the rotation as it is necessary for rectangles and squares, but here we have two degenerate cases to handle. The first one are cubes, the second one are rectangular boxes with two edges of equal length and the length of the third edge different from them. Our method delivers good fitting results, even if the boxes are heavily distorted for example by cutting-off vertices.	3d computer graphics;algorithm;database normalization;degenerate energy levels;olap cube;voxel space	Frank Ditrich;Herbert Süße;Klaus Voss	2005	IEEE International Conference on Image Processing 2005	10.1109/ICIP.2005.1530260	three-dimensional space;combinatorics;mathematics;geometry;statistics	Robotics	63.64322582553911	-43.22778727165996	30567
9da8e85112d03e601fb916799f975f2d6b0a2207	high accuracy spline interpolation for 5-axis machining	qa75 electronic computers computer science szamitastechnika;time dependent;tecnologia electronica telecomunicaciones;computacion informatica;szamitogeptudomany;grupo de excelencia;pythagorean hodograph;natural selection;ciencias basicas y experimentales;inverse kinematics;generalized inverse;tecnologias;analytic solution;spline interpolation	This article presents a new algorithm for simultaneous 5-axis spline interpolation. The algorithm basically merges two concepts: (1) the interpolation of the toolpath with Pythagorean Hodograph (PH) curves and (2) the analytic solution of the inverse kinematic problem using the template equation method. The first method allows one to obtain a analytic relation between the arclength and the parameter of the toolpath curve. This one enables one to control the velocity of the tool on the workpiece. The second method allows one to determine the analytic solution of the parameterized inverse kinematic problem that permits us to introduce arbitrary number of geometric parameters. A natural selection of the possible parameters can be the parameters of tool geometry and the workpiece placement. This way, the off-line generated inverse solutions—that transform the cutter contact curve into axis values—can be online compensated, as soon as the exact parameter values are become known. Based on these two approaches, a robust and fast method for the simultaneous 5-axis spline interpolation is developed. The result of this new algorithm is time-dependent axis splines which represent the given toolpath with high accuracy. q 2004 Elsevier Ltd. All rights reserved.	3d computer graphics;algorithm;apache axis;computer-aided design;cubic hermite spline;cubic function;cutter expansive classification;discretization;inverse kinematics;maximal set;online and offline;optic axis of a crystal;personal computer;spline (mathematics);spline interpolation;switzerland;tree of primitive pythagorean triples;velocity (software development);whittaker–shannon interpolation formula	Matthias Müller;Gábor Erdös;Paul C. Xirouchakis	2004	Computer-Aided Design	10.1016/j.cad.2004.02.007	spline interpolation;closed-form expression;mathematical optimization;natural selection;generalized inverse;interpolation;artificial intelligence;inverse kinematics;calculus;inverse quadratic interpolation;mathematics;geometry;thin plate spline	Robotics	69.49900273280049	-39.03676464387085	30571
8891e20c62f6faf717b7a4b3663a1ae30e0b5188	determining knots by minimizing the second derivative	second derivative;determining knots;minimizing;polynomial curve	In constructing a parametric curve interpolating a set of data points, one of the key problems is to specify a parameter value node for each data point. A new method of choosing knots is presented. For each data points, the new method constructs a quadratic polynomial curve by three adjacent data points. The node parameters of the quadratic curve are determined by minimizing the second derivative of the quadratic curve. And the knot interval between two adjacent data points is determined by two quadratic curves associated with the two adjacent data points. Experiments showed that the curves constructed using the knots by the new method generally have better interpolation precision.		Fan Zhang;Xueying Qin	2015	Trans. Edutainment	10.1007/978-3-662-48247-6_12	mathematical optimization;discrete mathematics;mathematics;geometry;curve fitting	HCI	70.0213676382156	-40.530466581760145	30599
9551b49742495675da901831fe0c5a3860a6172d	coding 3d connected regions with f26 chain code		There are many applications in different fields, as diverse as computer graphics, medical imaging or pattern recognition for industries, where the use of three dimensional objects is needed. By the nature of these objects, it is very important to develop thrifty methods to represent, study and store them. In this paper, a new method to encode surfaces of three-dimensional objects that are not isomorphic to the plane is developed. In the proposed method, a helical path that covers the contour is obtained and then, the Freeman F26 chain code is used to encode the helical path. In order to solve geometric problems to find optimal paths between adjacent slices, a modification of the A star algorithm was carried out. Finally, our proposed method is applied to three-dimensional objects obtained from real data.		Osvaldo A. Tapia-Dueñas;Hermilo Sánchez-Cruz;Hiram H. López;Juan Humberto Sossa Azuela	2018		10.1007/978-3-030-04497-8_1	a* search algorithm;encode;coding (social sciences);algorithm;chain code;artificial intelligence;isomorphism;pattern recognition;computer graphics;medical imaging;computer science	Theory	62.19357879458314	-39.97725036005862	30777
7bfb32095e49127a3a39b1d6d3aa051090bbd5a2	landmark based sensing and positioning in robotic nano manipulation	thermal drift;robot localization;robot sensing systems;local scan;landmark based sensing;descartes coordinate;local scan nanoassembly robotic landmark based positioning;sensors;probability density function;positioning method;data mining;nanoassembly;distance measurement;robotic;position control;robot sensing systems robot kinematics uncertainty surface topography atomic force microscopy optical sensors temperature sensors humidity biomimetics laboratories;robots;atomic force microscopy robotic nanomanipulation landmark based sensing positioning method descartes coordinate pzt nonlinearity thermal drift;landmark based positioning;micromanipulators;atomic force microscopy;robot dynamics;pzt nonlinearity;robotic nanomanipulation;robot dynamics atomic force microscopy micromanipulators position control;robot kinematics	AFM based nanomanipulation is still hindered by large spatial uncertainties encountered in tip positioning caused by PZT nonlinearity and thermal drift. In this paper, a landmark based positioning method is proposed to solve these problems. Its pivotal idea is that the tip position is described in a feature based landmark coordinate instead of length based Descartes coordinate. During manipulation, the landmarks selected from surface features, which is sensed through the new developed local scan method, acts as coordinate reference for tip localization. In this way, the positioning error aroused from PZT nonlinearity and thermal drift can be effectively suppressed. The details about landmark selecting, sensing, identifying will be discussed. Experiments of nanoparticle manipulation are presented to demonstrate the efficiency and effectiveness of the proposed method.	atomic-force microscopy;experiment;gnu nano;nonlinear system;robot;thermal grease	Lianqing Liu;Ning Xi;Yuechao Wang;Zaili Dong;Uchechukwu C. Wejinya	2008	2008 IEEE International Conference on Robotics and Biomimetics	10.1109/ROBIO.2009.4912976	robot;control engineering;computer vision;probability density function;atomic force microscopy;computer science;engineering;sensor;artificial intelligence;nanotechnology;robot kinematics	Robotics	62.41881923815698	-35.20391863454751	30808
26b2228d0608f55ba3a1514eb6f87d7295d8f94d	a musculo-skeletal mechanism simulating human forearm and its control method				Hiroshi Endo;Mitsuo Wada	1993	JRM	10.20965/jrm.1993.p0248	forearm;anatomy;control engineering;computer science	Robotics	74.03414916641158	-26.101419680405165	30885
350ca841844db11193571a2c726bf709acd8e793	constrained kalman filtering for indoor localization of transport vehicles using floor-installed hf rfid transponders	radiofrequency identification transponders vehicles kalman filters antennas measurement uncertainty accuracy;kalman filters;transponders kalman filters logistics radiofrequency identification;measurement uncertainty;accuracy;antennas;particle filter constrained kalman filtering indoor localization transport vehicles floor installed hf rfid transponders intralogistics applications global localization rfid readings odometry omnidirectional vehicle navifloor installation;vehicles;transponders;radiofrequency identification	Localization of transport vehicles is an important issue for many intralogistics applications. The paper presents an inexpensive solution for indoor localization of vehicles. Global localization is realized by detection of RFID transponders, which are integrated in the floor. The paper presents a novel algorithm for fusing RFID readings with odometry using Constraint Kalman filtering. The paper presents experimental results with a Mecanum based omnidirectional vehicle on a NaviFloor® installation, which includes passive HF RFID transponders. The experiments show that the proposed Constraint Kalman filter provides a similar localization accuracy compared to a Particle filter but with much lower computational expense.	algorithm;analysis of algorithms;computation;encoder;experiment;extended kalman filter;helicon filter;internationalization and localization;nonlinear system;odometry;particle filter;passive optical network;pose (computer vision);radio-frequency identification;robot;tag cloud;transponder	Christof Röhrig;Daniel Hess;Frank Künemund	2015	2015 IEEE International Conference on RFID (RFID)	10.1109/RFID.2015.7113081	control engineering;electronic engineering;telecommunications;engineering	Robotics	56.39518756356665	-36.31710779051357	30895
ef86a2aa697cd2a5d4bbec968efda734274fa4e4	development of intelligent integrated bedding system transformable pillow and mattress with multiple flexible actuators	comfortable;intelligent bedding system;sleep;posture;flexible actuator;pressure;feedback control	This study proposes an intelligent bedding system that actively changes its shape and stiffness with multiple flexible actuators. The proposed system provides mechanical conditions for comfortable sleep by feedback control. The system comprises air bag actuators, feedback control system and an individual body simulator. Authors plan to control the actuators on the basis of the body simulator, which calculates appropriate body support condition. To develop the simulator, this paper discusses a mathematical model of human body to obtain pressure distribution and posture in supine position. Devices of pillow and mattress with flexible actuators are also described.	control system;feedback;mathematical model;poor posture;prototype;simulation	Akisue Kuramoto;Wataru Inoue;Yasuhito Otake;Hitoshi Kimura;Norio Inou;Tomu Ichikawa;Hiroyuki Ono;Naoto Sekiyama	2016	IECON 2016 - 42nd Annual Conference of the IEEE Industrial Electronics Society	10.1109/IECON.2016.7793832	control engineering;simulation;engineering;control theory	Robotics	71.96824530838641	-25.373952356189143	30983
a34000305ee95996ae6031e262180eab6aa158db	dimensionapp : android app to estimate object dimensions		In this project, we develop an android app that uses computer vision techniques to estimate an object dimension present in field of view. The app while having compact size, is accurate upto +/5 mm and robust towards touch inputs. We use single-view metrology to compute accurate measurement. Unlike previous approaches, our technique does not rely on line detection and can be generalize to any object shape easily.	android;computer vision;edge detection;quantum metrology	Suriya Singh;Vijay Kumar	2016	CoRR		computer vision;simulation;computer science;computer graphics (images)	Mobile	56.055042432219594	-48.37672596573456	31038
48a885cd6d91df3ca8f0d690b6d5bbbc90c79c35	changing variables	computer graphics;computational geometry	In computer graphics and geometric modeling, changing the variables is a useful technique that appears in many guises. It lets us change how we traverse curves or surfaces, modify their derivatives or place, and interpret textures or other properties associated with them. It is shown that while changing variables of a parametric curve or surface leaves its geometric shape untouched, changing the way we associate parameters to curves or surfaces does have an impact: computer graphics deals with sampled geometry, and the sampled geometry changes. We can take advantage of the change of variables to improve how the surface is textured. Moreover, change of variables makes it possible to combine curve segments or curved surface patches into a smooth ensemble when the shape is more general than the graph of a function.	computer graphics;geometric modeling;graph of a function;impact (computer graphics);sampling - surgical action;traverse;texture mapping	Jörg Peters	2012	IEEE Computer Graphics and Applications	10.1109/MCG.2012.51	geometric design;computational geometry;computer science;mathematics;geometry;computer graphics;computer graphics (images)	Graphics	67.75517050669623	-47.253090074419255	31110
bfc871fd68522b116968b25071608e8b7323486a	use of magnetic field for mitigating gyroscope errors for indoor pedestrian positioning †	gyroscope bias;indoor pedestrian positioning;magnetometer calibration;quasi-static magnetic field	In the field of indoor pedestrian positioning, the improved Quasi-Static magnetic Field (iQSF) method has been proposed to estimate gyroscope biases in magnetically perturbed environments. However, this method is only effective when a person walks along straight-line paths. For other curved or more complex path patterns, the iQSF method would fail to detect the quasi-static magnetic field. To address this issue, a novel approach is developed for quasi-static magnetic field detection in foot-mounted Inertial Navigation System. The proposed method detects the quasi-static magnetic field using the rate of change in differences between the magnetically derived heading and the heading derived from gyroscope. In addition, to eliminate the distortions caused by system platforms and shoes, a magnetometer calibration method is developed and the calibration is transformed from three-dimensional to two-dimensional coordinate according to the motion model of a pedestrian. The experimental results demonstrate that the proposed method can provide superior performance in suppressing the heading errors with the comparison to iQSF method.	calibration;course (navigation);distortion;gyroscope;horner's method;inertial navigation system;magnetic fields;magnetic resonance imaging;shoes;magnetometers	Ming Ma;Qian Song;Yang Gu;Zhimin Zhou	2018		10.3390/s18082592		Robotics	55.30474470402475	-38.977784475039925	31158
9a0a6fd286e7f9ebae033338d69e2c36e09a4669	intuitive peg-in-hole assembly strategy with a compliant manipulator	manipulators;compliance assembly peg in hole manipulator;force sensors;passive compliance control intuitive peg in hole assembly strategy compliant manipulator multidegree of freedom manipulator dof manipulator precise hole position orientation information force sensor torque sensor manipulator wrist position estimation assembly task intuitive assembly strategy human behavior hybrid force position control;compliance control;position control;robotic assembly;torque control compliance control force control force sensors manipulators position control robotic assembly;indexes trajectory jamming robots;torque control;force control	To realize a peg-in-hole assembly with a multi-degree of freedom (DOF) manipulator, the precise position of the hole is required. If the hole is not circular, orientation information is also necessary. A force/torque (F/T) sensor is widely used to sense the position and orientation of the hole. Attaching the F/T sensor on the wrist of a manipulator helps in estimating the position between the peg and hole. However, a person does not need precise information of an object when completing an assembly task. For example, when inserting a plug into an outlet, a person does not need to know the exact information and coordination about the position and orientation of the plug and outlet. A closer look at the process shows that the person tries to place a plug near the outlet and then finds the two holes by rubbing the plug against the outlet without looking. This paper introduces an intuitive assembly strategy inspired by this human behavior. This strategy does not need the precise location of the hole. Instead of an F/T sensor, this strategy adopts hybrid force/position control and passive compliance control for successful peg-in-hole assembly. The feasibility of the proposed strategy was verified through simulation and a hardware experiment.	assembly language;need to know;simulation	Hyeonjun Park;Ji-Hun Bae;Jae-Han Park;Moonhong Baeg;Jaeheung Park	2013	IEEE ISR 2013	10.1109/ISR.2013.6695699	simulation	Robotics	70.9555919107726	-24.119447837896054	31171
704958b53823a919814aad9c6019f45f29a221a3	robot geometric parameter identification with extended kalman filtering algorithm		This paper proposes a calibration method for enhancing position accuracy of robotic manipulators. In order to increase the robot accuracy, the method first develops a robot kinematic model and then identifies the robot geometric parameters by using an extended Kalman filtering (EFK) algorithm. The Kalman filter has advantages in identifying geometric parameters from the noisy measurements. Therefore, the obtained kinematic parameters are more precise. A simulation study of this calibration is performed for a PUMA 560 robot to prove the effectiveness of the method in increasing robot position accuracy.	algorithm;kalman filter;robot	Hoai-Nhan Nguyen;Jian Zhou;Hee-Jun Kang;Young Shick Ro	2013		10.1007/978-3-642-39678-6_28	computer vision;fast kalman filter;machine learning;control theory;extended kalman filter	Robotics	57.196085306623935	-36.03382749236658	31218
0c793f68537b51d975bd49d6029838658ca9200e	elastic moduli of simple mass spring models	mass spring model;soft body deformation;physically based modeling	Mass spring models (MSMs) are a popular choice for representation of soft bodies in computer graphics and virtual reality applications. In this paper, we investigate physical properties of the simplest MSMs composed of mass points and linear springs. The nodes are either placed on a cubic lattice or positioned randomly within the system. We calculate the elastic moduli for such models and relate the results to other studies. We show that there is a well-defined relationship between the geometric characteristics of the MSM systems and physical properties of the modeled materials. It is also demonstrated that these models exhibit a proper convergence to a unique solution upon mesh refinement and thus can represent elastic materials with a high precision.	adaptive mesh refinement;coefficient;computer graphics;cubic function;design pattern;discretization;elastic matching;elasticity (data store);image resolution;markov switching multifractal;mind;modulus robot;principle of good enough;randomness;refinement (computing);semantics (computer science);simulation;software propagation;virtual reality	Maciej Kot;Hiroshi Nagahashi;Piotr Szymczak	2014	The Visual Computer	10.1007/s00371-014-1015-5	geometry	Graphics	71.61469746599238	-46.534010943649996	31246
6deaa9d6a17eab8232631ac8c58d3cf6103d81b3	partial entity structure: a compact non-manifold boundary representation based on partial topological entities	boundary representation;time complexity;non manifold;boolean operation;topological entity;geometric modeling;geometric model;data structure	Non-manifold boundary representations have gained a great deal of popularity in recent years and various representation schemes have been proposed because they allow an even wider range of objects for various applications than conventional manifold representations. However, since these schemes are mainly interested in describing sufficient adjacency relationships of topological entities, the models represented in these schemes occupy too much storage space redundantly although they are very efficient in answering queries on topological adjacency relationships. Storage requirement can arise as a crucial problem in models in which topological data is more dominant than geometric data, such as tessellated or mesh models. To solve this problem, in this paper, we propose a compact non-manifold boundary representation, called the partial entity structure, which allows the reduction of the storage size to half that of the radial edge structure, which is known as a time efficient non-manifold data structure, while allowing full topological adjacency relationships to be derived without loss of efficiency. This representation contains not only the conventional primitive entities like the region, face, edge, and vertex, but also the partial topological entities such as the partial-face, partial-edge, and partial-vertex for describing non-manifold conditions at vertices, edges, and faces. In order to verify the time and storage efficiency of the partial entity structure, the time complexity of basic query procedures and the storage requirement for typical geometric models are derived and compared with those of existing schemes. Furthermore, a set of the generalized Euler operators and typical high-level modeling capabilities such as Boolean operations are also implemented to confirm that our data structure is sound and easy to be manipulated.	boolean operations on polygons;boundary representation;data structure;entity;euler;high- and low-level;radial (radio);storage efficiency;time complexity;topological derivative;vertex (graph theory)	Sang-Hun Lee;Kunwoo Lee	2001		10.1145/376957.376976	combinatorics;discrete mathematics;topology;data structure;geometric modeling;mathematics;geometry;topological quantum number	DB	67.8305500811157	-43.067029724004925	31360
9e7b04446ce41523d94a4d49db692343932fa5a6	haptics for product design and manufacturing simulation	machining;impedance;manufacture simulation;maintenance;haptic interfaces force product design manufacturing solid modeling computational modeling impedance;haptics;solid modelling assembling cad haptic interfaces human computer interaction machining product design production engineering computing;force;survey haptics manufacture simulation product design machining assembly maintenance;assembly;computational modeling;solid modeling;manufacturing;product design;haptic interfaces;survey;maintenance simulation product design manufacturing simulation haptics human computer interaction force feedback torque feedback physical mock ups cad mode computer aided design shape modelling machining simulation virtual assembly	Product design and manufacturing simulation is a promising research and application area for haptics. By benefiting from its natural human-computer interaction and realistic force/torque feedback, haptics can change the traditional design and manufacturing approaches which are mainly based on physical mock-ups or CAD (Computer Aided Design) modes. This paper provides a detailed and comprehensive survey of haptics for product design and manufacturing simulation in the past 10 years, mainly from 2004-2014, including haptics for product design and shape modelling, haptics for machining simulation, and haptics for virtual assembly and maintenance simulation. The new haptic devices and rendering algorithms involved in this area are introduced, the major research efforts and the typical systems are discussed, and the new ideas and research progresses are investigated. Then, conclusions and future trends are summarized.	algorithm;computer-aided design;haptic device component;haptic technology;human–computer interaction;malignant fibrous histiocytoma;mock object;simulation;benefit	Pingjun Xia	2016	IEEE Transactions on Haptics	10.1109/TOH.2016.2554551	simulation;machining;engineering;electrical impedance;assembly;solid modeling;haptic technology;manufacturing;product design;computational model;engineering drawing;force;manufacturing engineering;mechanical engineering	EDA	69.78887001048078	-33.208687294075574	31445
8f637bebd9583954ad8bdda3dcb08a057fb80f2d	water level estimation based on image of staff gauge in smart city		In the automatic measurement of water level, the hydrological satiation also uses a traditional staff gauge to calibrate the water depth measured by the sensor. And in the most of water-covered areas, such as underpass overpasses, low-lying roads and tunnels, staff gauges have been installed to monitor road water. Therefore, the automatic water level measurement method based on staff gauge image, has drawn more and more attention. So we propose a method for the water level estimation based on images of staff gauge in this paper. First, we proposed a two-step method for segmenting the staff gauge. We implemented the initial positioning by HSV color space and morphological processing, and then we defined a component map to achieve precise positioning. Next, we split the characters on the staff gauge image and recognized those characters through a Convolutional Neural Network. Finally, we measured the water level by using a quadratic function to determine the mapping relationship between pixels and the metric values. Compared with the traditional method of extracting water line, the two-step positioning method improves the water level detection accuracy. The measurement result in a real world image of a pond shows more accurate detection with the algorithm and the feasibility of applying it to road water monitoring.		Zhikang Xu;Jing Feng;Zhizheng Zhang;Chaofan Duan	2018	2018 IEEE SmartWorld, Ubiquitous Intelligence & Computing, Advanced & Trusted Computing, Scalable Computing & Communications, Cloud & Big Data Computing, Internet of People and Smart City Innovation (SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI)	10.1109/SmartWorld.2018.00233	convolutional neural network;distributed computing;gauge (firearms);smart city;computer science;calibration;quadratic function;pixel;hsl and hsv;water level;computer vision;artificial intelligence	Robotics	59.99175918785519	-41.88726321005794	31559
930e039d7dbfa5eda2104f91fb6eb32e63934284	a new set of normalized geometric moments based on schlick's approximation	conference contributions published;conference contribution paper in published proceedings	Schlick’s approximation of the term x is used primarily to reduce the complexity of specular lighting calculations in graphics applications. Since moment functions have a kernel defined using a monomial xy, the same approximation could be effectively used in the computation of normalized geometric moments and invariants. This paper outlines a framework for computing moments of various orders of an image using a simplified kernel, and shows the advantages provided by the approximating function through a series of experimental results.	approximation algorithm;computation;graphics;image moment;kernel (operating system);monomial;schlick's approximation;specular highlight	Ramakrishnan Mukundan	2007		10.1007/978-3-540-76856-2_20	mathematical optimization;combinatorics;computer science;theoretical computer science;mathematics;statistics	Robotics	63.95980912664754	-43.83123793296652	31682
16f90a3802533cfb7806eaf3d5a3c19cb49c003c	haptic interface for robot-assisted ophthalmic surgery	biological patents;biomedical journals;text mining;surgery robot sensing systems robot kinematics force force feedback;europe pubmed central;citation search;citation networks;telerobotics end effectors eye force feedback haptic interfaces human robot interaction medical robotics micromanipulators position control surgery;control modes haptic interface robot assisted ophthalmic surgery vitreo retinal surgery tremor elimination comfortable micromanipulation eye surgery robot telemanipulation setup robotic system haptic device force feedback user interface hybrid parallel serial micromanipulator control position error control scheme;research articles;abstracts;open access;life sciences;clinical guidelines;full text;rest apis;orcids;europe pmc;biomedical research;bioinformatics;literature search	Vitreo-retinal surgery is challenging, as delicate structures have to be manipulated. Eliminating tremor caused by human motions when doing micromanipulation can therefore improve the outcome of such an intervention. An eye surgery robot has been built to overcome this problem. The contribution of this paper is the design of a telemanipulation setup for the robotic system. A telemanipulation setup using a haptic device featuring force feedback as a user interface for controlling a hybrid parallel-serial micromanipulator is designed and developed. The position error control scheme is chosen and different control modes are provided. The output forces of the haptic device are analyzed. The system allows the surgeon to perform precise and comfortable micromanipulation. Nevertheless a way to provide more meaningful force feedback still has to be found.	error detection and correction;eye;feedback;haptic device component;haptic technology;micromanipulation;ophthalmic dosage form;ophthalmologic surgical procedures;preparation;remote manipulator;retina;retinal implant;robot;tremor;user interface device component;video-in video-out;micromanipulator	A. Barthel;D. Trematerra;M. Ali Nasseri;Daniel Zapp;Chris P. Lohmann;Alois Knoll;Mathias Maier	2015	2015 37th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)	10.1109/EMBC.2015.7319492	control engineering;computer vision;text mining;medical research;simulation;computer science;engineering	Robotics	73.48759207136848	-28.276893357751174	31832
5642640b3a6033df575fd40350872c46bd01e5aa	melting and burning solids into liquids and gases	gas;phase change;solid;physics based modeling;adaptive mesh;computer graphics;computational geometry;surface fitting;lagrangian mesh;melting;indexing terms;liquid;burning;eulerian grid;adaptive mesh physically based modeling melting burning solid liquid gas phase change lagrangian mesh eulerian grid;liquids gases solid modeling viscosity deformable models robustness friction stacking level set elasticity;surface fitting digital simulation computer graphics mesh generation computational geometry;particle level set method melting burning solid materials liquid simulation gas simulation mesh based techniques grid based techniques vorticity confinement;algorithms computer graphics computer simulation gases heat image enhancement image interpretation computer assisted models chemical models molecular phase transition solutions user computer interface;mesh generation;level set method;physically based modeling;digital simulation	We propose a novel technique for melting and burning solid materials, including the simulation of the resulting liquid and gas. The solid is simulated with traditional mesh-based techniques (triangles or tetrahedra) which enable robust handling of both deformable and rigid objects, collision and self-collision, rolling, friction, stacking, etc. The subsequently created liquid or gas is simulated with modern grid-based techniques, including vorticity confinement and the particle level set method. The main advantage of our method is that state-of-the-art techniques are used for both the solid and the fluid without compromising simulation quality when coupling them together or converting one into the other. For example, we avoid modeling solids as Eulerian grid-based fluids with high viscosity or viscoelasticity, which would preclude the handling of thin shells, self-collision, rolling, etc. Thus, our method allows one to achieve new effects while still using their favorite algorithms (and implementations) for simulating both solids and fluids, whereas other coupling algorithms require major algorithm and implementation overhauls and still fail to produce rich coupling effects (e.g., melting and burning solids).	gases;handling (psychology);liquid substance;muscle rigidity;physical object;simulation;stacking;vorticity confinement;algorithm;collision;solid substance	Frank Losasso;Geoffrey Irving;Eran Guendelman;Ronald Fedkiw	2006	IEEE Transactions on Visualization and Computer Graphics	10.1109/TVCG.2006.51	melting;mesh generation;simulation;index term;computational geometry;computer science;solid;computer graphics;level set method;phase change;combustion	Visualization	70.7939939331633	-47.30602489058383	31852
30dea9deb277da2d1fbe9c0fef56f65871a7b4e1	interpolation on the hypersphere with thiele type rational interpolants	65d05;samelson inverse;interpolation on a hypersphere;thiele type rational interpolant	In order to interpolate 2n + 1 points on the unit hypersphere $ \mathcal{S}^{d-1}$ with a vector-valued rational function, we use the Generalised Inverse Rational Interpolants (GIRI) of Graves–Morris. The construction process of these Thiele type rational interpolants is based on the Samelson’s inverse for vectors. We show that in general any GIRI of 2n + 1 points of $ \mathcal{S}^{d-1}$ lies on $ \mathcal{S}^{d-1}$ . We also show that the stereographic projection induces a one-to-one correspondence between the set of vector-valued rational functions lying on $ \mathcal{S}^{d-1}$ and the set of Generalised Inverse Rational Fractions in the equator plane.	interpolation;one-to-one (data model);stereoscopy	Thierry Gensane	2011	Numerical Algorithms	10.1007/s11075-011-9528-8	mathematical analysis;topology;mathematics;geometry	ML	69.0282761683079	-41.10030869525282	31934
5fed5528eef433934f36cfbf98f9ff24893c1243	minimum triangle separation for correct z-buffer occlusion	categories and subject descriptors according to acm ccs i 3 1 computer graphics graphics processors	We show that, and how, window coordinate precision (the representations of xwin and ywin), field of view, and error accumulated by single-precision mapping arithmetic contribute to, and sometimes dominate, effective z-buffer resolution. Our results are developed analytically, then verified through simulation. Using our approach system designers can allocate numeric precision more efficiently, and programmers can more confidently predict the minimum triangle-to-triangle separation required to ensure correct z-buffer occlusion.	programmer;simulation;single-precision floating-point format;window function;x window system;z-buffering	Kurt Akeley;Jonathan Su	2006		10.1145/1283900.1283904	computer vision;real-time computing;computer science;artificial intelligence;theoretical computer science;machine learning;mathematics;geometry;programming language;algorithm;computer graphics (images)	HCI	66.72192810123725	-50.17428410454788	31950
ac18f053204bbd478fe775047be54710ba30177e	intelligent synchronized robot/conveyor system		A robotrconveyor system is an important part of the manufacturing system. As such, the robotrconveyor system must comply with all the requirements of a modern manufacturing system: high flexibility, high efficiency, and smart reasoning processes to lead the system to its next status based on its current status and varied inputs. An expert system consisting of a knowledge base and an inference engine was developed to operate and control a robotrconveyor system. A large variety of robotrconveyor system runs were performed to explore the efficiency of its operations. These system runs explore all the parameters associated with robotrconveyor system operations: manipulators specifications and velocities, pick-up methods, types of arriving parts, their locations, and orientations. The performed runs verified a well-known fact that a robotrconveyor system based on variable pick-up locations is more efficient than a robotrconveyor system based on a single, predefined, and unchanged pick-up location. The implementations of the variable pick-up locations method is associated with the need to implement real-time complicated software algorithms to track the arriving parts and to synchronize their maneuvers with the conveyor belt. Therefore, the implementation of variable pick-up locations method must be performed only when they result in most significant benefits. The system runs show that the benefits of the variable pick-up locations approach are inversely related to manipulations’ velocities. If the variable pick-up location method is incorporated with efficient and reliable tracking algorithms, most efficient robotrconveyor systems will be resulted. Therefore, future efforts should address the advance of tracking algorithms of arriving parts, thus improving the synchronization of these parts with manipulator’s maneuver, in order to achieve the most efficient robotrconveyor system. Q 1999 John Wiley & Sons, Inc.	algorithm;expert system;inference engine;john d. wiley;knowledge base;real-time clock;requirement;robot	Gideon Cohen	1999	Int. J. Intell. Syst.	10.1002/(SICI)1098-111X(199907)14:7%3C653::AID-INT2%3E3.0.CO;2-A	embedded system;knowledge base;simulation;computer science;artificial intelligence;robotics;expert system	Robotics	60.98729843568436	-28.668486797477176	31966
63bb8af83011488cc45a3046f8258e058942a174	controlling the entire path of a virtual camera	rational interpolation;camera control;collision detection	This paper considers the design of a camera path through a scene. Given a valid set of keyframes for the camera, we want to build a camera path that avoids collisions with the scene. The first problem is to define a camera path that interpolates the keyframes. We build a rational interpolating motion using rational interpolation of both position and orientation. The second problem is to detect collisions of the planned path with the scene. A spatial decomposition is used to accelerate this detection. The third problem is to correct the path to avoid the detected collisions. Keyframes are added in the neighbourhood of the collision to correct the collision.	interpolation;key frame;virtual camera system	Ross Ptacek;John K. Johnstone	2006		10.1145/1185448.1185630	computer vision;camera auto-calibration;simulation;mathematics;computer graphics (images)	Vision	57.407716336539	-50.3217996160224	32125
8ad1d8ce42f0f47fb0e0bc664bab953c4514dc7f	rodbot: a rolling microrobot for micromanipulation	torque;force;micro agent rolling microrobot micromanipulation rodbot microobjects magnetic visual control system rod shaped microrobot magnetic actuation system rotating magnetic field noncontact transportation fluid vortex approach pushing strategy;visualization;trajectory;magnetic resonance imaging;robots;drag;micromanipulators magnetic actuators magnetic fields;force magnetic resonance imaging robots drag torque visualization trajectory	We introduce the modelling and control of a rolling microrobot. The microrobot is capable of manipulating micro-objects through the use of a magnetic visual control system. This system consists of a rod-shaped microrobot, a magnetic actuation system and a visual control system. Motion of the rolling microrobot on a supporting surface is induced by a rotating magnetic field. As the robot is submerged in a liquid this motion creates a rising flow in front, a sinking flow behind, and a vortex above the robot, thus enabling non-contact transportation of micro-objects. Besides this fluid-vortex approach, the microrobot is also able to manipulate micro-objects via a pushing strategy. We present the design and modelling of the 50×60×300 μm micro-agent, the visual control system, and an experimental analysis of the micromanipulation and control methods.	control system;lifting scheme;microbotics;optic axis of a crystal;robot;vortex	Roel Pieters;Hsi-Wen Tung;Samuel Charreyron;David F. Sargent;Bradley J. Nelson	2015	2015 IEEE International Conference on Robotics and Automation (ICRA)	10.1109/ICRA.2015.7139764	robot;control engineering;simulation;visualization;engineering;trajectory;magnetic resonance imaging;drag;control theory;torque;force	Robotics	74.12079507822246	-24.37360143595918	32236
493877d462d26115a515370d98244b8bd288e8b2	the modular telerobot task execution system for space telerobotics	telerobotics control systems space stations orbital robotics robot programming space vehicles communication system control space technology robot control delay effects;telecontrol aerospace computer control manipulators redundancy robots space vehicles;manipulators;seven degree of freedom manipulator motes architecture multisensor based space telerobotics space station freedom modular telerobot task execution system remote site task execution capability local remote telerobotic system constraints limited computational power supervised autonomous control shared control redundant manipulator reflex motion command interpreter multiple control modules command parameterization;degree of freedom;control system;redundancy;robots;telecontrol;autonomous control;space vehicles;aerospace computer control	A telerobot task execution system is described which has been developed f o r space station Freedom applications. The Modular Telerobot Task Execution System (hfOTES) provides the remote site task execution capability in a local-remote telerobotic system. The design addresses the constraints of limited computational power available at the remote sate control system while proaiding a large range of control capabiliiies. The system provides supervised autonomous control, shared control, and teleoperation f o r a redundant manipulator. The system is capable of nominal task execution as well as monitoring and reflex motion. A command interpreter similar to one used o n robotic spacecraft is used to interpret commands received from the local site. Execution utilizes multiple control modules which execafe based upon command parameterization. The syst em is written in Ada and runs in a VhlE environment on 68020 processors and controls a Robotics Research K1207 seven degree of freedom m.anipulator.	ada;autonomous robot;central processing unit;command-line interface;control system;robotic spacecraft;robotics;telerobotics	Paul G. Backes;Mark K. Long;Robert D. Steele	1993		10.1109/ROBOT.1993.292225	robot;control engineering;embedded system;simulation;computer science;engineering;control system;artificial intelligence;degrees of freedom;redundancy	Robotics	62.45201547359183	-29.133576959653325	32359
7fe83fec8a0b0b45b7f1a05c920ece76dab09297	a piecewise affine warping algorithm for image rectification in an industrial application for ship hull repair		Ship hull maintenance is a periodical task. It requires working conditions extremely hard for operators. The authors have developed a robotized system that makes it possible to carry out these tasks remotely and semi-automatically, by means of an automated visual inspection system. Due to the hard work environment conditions the vision system needs to be placed far from the front and central position opposite the surface to be inspected. As a consequence, the produced images show strong perspective distortions, which need to be corrected. In this paper we present an image correction algorithm, based on affine warping transformation techniques, which allows us to correct distortions in images of strongly warped surfaces. In addition, this algorithm provides a final image equivalent to a front image consisting of the image fragments that the camera would obtain should it be placed opposite each of the points of the inspected surface from which the image is taken. The algorithm produces high precision corrected images which make it possible to locate any point in that surface with a maximum error of 3 cm over a            200  ×  160      cm    2          surface (1.17%). We have used this algorithm to correct images of ship surfaces with different profiles and curvatures, where traditional techniques based on calibration grids are not applicable due to the unavailability of a grid pattern for each new surface to be inspected.	algorithm;image rectification	Pedro María Alcover;Juan Suardíaz Muro;Pedro J. Navarro;Carlos Fernández-Isla;Juan José Torrens	2014	J. Franklin Institute	10.1016/j.jfranklin.2013.09.023	computer vision;mathematical optimization;mathematics;engineering drawing	Vision	60.11185877351131	-48.97431574504148	32373
6e6574f0b45ebf666da3602ffd36f330a097b7b4	a virtual target approach for resolving the limit cycle problem in navigation of a fuzzy behaviour-based mobile robot	behaviour based control;mobile robot;limit cycle;intelligent navigation;virtual target	A virtual target approach is proposed for resolving the limit cycle problem in navigation of a behaviour-based mobile robot. Starting from the onset point of a possible limit cycle path, the real target is switched to a virtual location and the robot is navigated according to the virtual target set up temporarily and the real environment information sensed, until a switching-back condition is reached. The cause of the limit cycle is analysed and the abrupt change in target orientations at two consecutive reaction instants is then identified to be the condition for shifting the target from the real location to the virtual one. The condition for switching back to the real target is established using a specific change in the obstacle information sensed. The algorithm is described together with some particular considerations in implementation. Efficiency and effectiveness of the proposed approach are verified through simulation and experiments conducted with a Nomad 200 robot incorporating a fuzzy behaviour-based controller.	limit cycle;mobile robot	W. L. Xu	2000	Robotics and Autonomous Systems	10.1016/S0921-8890(99)00099-8	mobile robot;computer vision;simulation;computer science;artificial intelligence;limit cycle;mobile robot navigation	Robotics	59.00490490584985	-26.88634130538311	32451
66e51097e3bff7730d35eb639c9bcdf219e3e658	improving transparency in passive teleoperation by combining cutaneous and kinesthetic force feedback	passive teleoperation teleoperated needle insertion teleoperation loop stability stability preservation remote environment haptic rendering independently controlled cutaneous feedback operator independently controlled kinesthetic feedback operator sensory subtraction cutaneous force feedback kinesthetic force feedback;telerobotics force feedback haptic interfaces stability;needles force force feedback virtual environments robot sensing systems;stability;force feedback;telerobotics;haptic interfaces	A novel idea for improving transparency of teleoperation systems with force feedback is presented. This approach is based on the idea of sensory subtraction presented in [12], and consists of providing the operator with independently controlled kinesthetic and cutaneous feedback to improve the realism of haptic rendering of the remote environment (i.e., transparency), while preserving stability. More specifically, cutaneous force feedback is employed to recover transparency when a lack of kinesthetic feedback has to be enforced to keep the teleoperation loop stable. The viability of this approach is demonstrated with two experiments of teleoperated needle insertion. Results showed improved performance with respect to common control techniques not employing the proposed cutaneous compensation.	experiment;feedback;haptic technology;hoc (programming language);interaction	Claudio Pacchierotti;Asad Tirmizi;Gianni Bianchini;Domenico Prattichizzo	2013	2013 IEEE/RSJ International Conference on Intelligent Robots and Systems	10.1109/IROS.2013.6697072	telerobotics;control engineering;simulation;stability;computer science;engineering;artificial intelligence;control theory;haptic technology	Robotics	70.01673584233784	-25.788585341736074	32496
6c4af2eae48f0dad552bc4273dc2e64c46e7e584	history consideration in reconstructing polyhedral surfaces from parallel slices	polyhedral surface;interpolation;reconstruction;parallel slice;history consideration;triangulation;cross section	We introduce an algorithm for reconstructing a solid model given a series of planar cross sections. The main contribution of this work is the use of knowledge obtained during the interpolation of neighboring layers while attempting to interpolate a particular layer. This knowledge is used to reconstruct a surface in which consecutive layers are connected smoothly. In most previous work, each layer is interpolated independently of what happened or will happen in the other layers. We also discuss various objective functions which aim to optimize the reconstruction, and present an evaluation of the different objective functions by using various criteria.	algorithm;combinatorial optimization;cross section (geometry);heuristic (computer science);interpolation;mathematical optimization;polygon triangulation;polyhedron;smoothing;solid modeling;tiling window manager	Gill Barequet;Daniel Shapiro;Ayellet Tal	1996	Proceedings of Seventh Annual IEEE Visualization '96		mathematical optimization;interpolation;computer science;geometric modeling;statistics	Visualization	67.78722002187193	-43.40123184297564	32507
57aaa8c2e050f16977b5276efa2be5050acc26ce	gnss/ins-based vehicle lane-change estimation using imm and lane-level road map	traffic state estimation;kalman filtering;nonlinear filters;lane keeping;inertial navigation;state estimation;kinematics;interactive models;inertial navigation systems;mathematical models;lane change estimation scheme gnss ins based vehicle lane change estimation lane level road map imm global navigation satellite system inertial navigation system location based cooperative transportation lane resolution vehicle positioning lane occupancy identification filter based sensor fusion scheme interactive multiple models kinematic models lane map information lane changing maneuver lane keeping state estimation process field tests intersection scenario fault tolerance capability obd ii interface beidou navigation satellite system bds device location based traffic applications;fault tolerance;vehicle dynamics fault tolerance filtering theory inertial navigation kinematics nonlinear filters road vehicles satellite navigation sensor fusion state estimation;satellite navigation;vehicles global positioning system filtering roads state estimation kinematics;sensor fusion;lane changing;vehicle dynamics;filtering theory;road vehicles;global navigation satellite system	Vehicle positioning at the lane-level is becoming an enabling factor for the location-based cooperative transportation applications. With the assistance from lane-level road map data, the developing Global Navigation Satellite System (GNSS) and Inertial Navigation System (INS) can be effectively integrated to achieve a desired positioning performance stage. In this paper, the lane-resolution vehicle positioning in lane change scenarios is concentrated to solve the uncertainty in lane occupancy and state estimation. According to a filter-based sensor fusion scheme, the Interactive Multiple Models (IMM) based strategy is adopted. By developing kinematic models that represent the lane keeping and lane changing maneuver, lane map information is coupled to restrain the state estimation process, and provides benefits to the identification of lane occupancy. Results from field tests in the practical intersection scenario illustrate the effectiveness of the proposed IMM-based solution. The fault tolerance capability is tested under the challenging GNSS availability condition, where assistance from OBD-II interface and BDS (BeiDou Navigation Satellite System) device shows great potential in application.	autonomous robot;beidou navigation satellite system;experiment;fault tolerance;galileo (satellite navigation);global positioning system;inertial navigation system;location-based service;lock (computer science);satellite navigation;systemverilog	Jiang Liu;Baigen Cai;Jian Wang;Shangguan Wei	2013	16th International IEEE Conference on Intelligent Transportation Systems (ITSC 2013)	10.1109/ITSC.2013.6728225	computer vision;simulation;geography;transport engineering	Robotics	55.25624433449144	-31.823468301526553	32592
cd0a421b1799f9998f30d0b7f7f7f4e63cc1a471	tracking of a moving object using one-dimensional optical flow with a rotating observer	one dimensional optical flow object tracking rotating observer;moving object;tracking angular velocity control gradient methods image sequences motion estimation object detection observers position control;image motion analysis optical filters tracking brightness motion estimation optical devices object detection motion detection gradient methods surveillance;angular velocity moving object optical flow rotating observer gradient method object tracking stationary environment object linear signal trajectory synthesized images;angular velocity control;rotating observer;gradient method;apparent motion;motion estimation;observers;linear signal trajectory;position control;ill posed problem;object tracking;gradient methods;angular velocity;optical flow;synthesized images;stationary environment object;tracking;object detection;image sequences;one dimensional optical flow	The optical flow is a useful tool for the tracking of a moving object. Estimation of the optical flow based on the gradient method is an ill-posed problem. In order to avoid this ill-posed problem, we proposed a tracking method using a one-dimensional optical flow, which is calculated on a straight line (called the calculation axis) spanning several directions. However, the motion of the observer was not considered. In this paper, we propose object tracking by a one-dimensional optical flow under a rotating observer. The apparent motion of a stationary environment object should be eliminated for calculating the one-dimensional optical flow. Hence, we introduce the detection method of a moving object by mapping, which converts the motion of a stationary environment object into a linear signal trajectory. We calculate the one-dimensional optical flow by using pixels, which belong to the moving object, to eliminate the apparent motion of the stationary environment object. In order to verify the efficacy of the proposed method, simulation is performed using synthesized images. The proposed method successfully tracks the moving object when the observer rotates at a constant angular velocity	angularjs;apache axis;file spanning;gradient method;image;optical flow;pixel;simulation;stationary process;velocity (software development);well-posed problem	Koji Kinoshita;Masaya Enokidani;Masanori Izumida;Kenji Murakami	2006	2006 9th International Conference on Control, Automation, Robotics and Vision	10.1109/ICARCV.2006.345264	computer vision;angular velocity;computer science;gradient method;video tracking;motion estimation;optical flow;control theory;tracking	Robotics	56.4031382584054	-41.42458136736198	32629
ad0892467a17b73fa9bf163038fef5060699d6cf	a new approach to an old problem: the reconstruction of a go game through a series of photographs		Given a series of photographs taken during a Go game, we describe the techniques we successfully employ for pinpointing the grid lines of the Go board and for tracking their small movements between consecutive photographs; then we discuss how to approximate the location and orientation of the observer’s point of view, in order to compensate for projection effects. Finally we describe the different criteria that jointly form the algorithm for stones’ detection, thus enabling us to automatically reconstruct the whole move sequence.	approximation algorithm;hough transform;image processing;opencv;pixel;precondition;streaming media;video content analysis	Mario Corsolini;Andrea Carta	2015	CoRR		computer vision;simulation;computer science;artificial intelligence;machine learning	Vision	57.91271863185353	-50.76775456140106	32653
e37b107d81acd49ce4622f95f1dba00f15a0d8e7	exploiting image collections for recovering photometric properties	radiometric calibration;illumination conditions;photo collections;reflectance estimation	We address the problem of jointly estimating the scene illumination, the radiometric camera calibration and the reflectance properties of an object using a set of images from a community photo collection. The highly ill-posed nature of this problem is circumvented by using appropriate representations of illumination, an empirical model for the nonlinear function that relates image irradiance with intensity values and additional assumptions on the surface reflectance properties. Using a 3D model recovered from an unstructured set of images, we estimate the coefficients that represent the illumination for each image using a frequency framework. For each image, we also compute the corresponding camera response function. Additionally, we calculate a simple model for the reflectance properties of the 3D model. A robust non-linear optimization is proposed exploiting the high sparsity present in the problem.	3d modeling;camera resectioning;coefficient;frequency response;linear programming;mathematical optimization;nonlinear programming;nonlinear system;sparse matrix;well-posed problem	Mauricio Díaz;Peter F. Sturm	2011		10.1007/978-3-642-23678-5_29	computer vision	Vision	55.5014320149322	-51.690841302305394	32657
e4438032797700890169a72f0a0a67076cd7cbba	brain peeling: viewing the inside of a laminar three-dimensional solid	vision ordenador;medical imagery;brain;human interaction;representation tridimensionnelle;high resolution;geophysics;image processing;tangents;procesamiento imagen;self operation;laminates;traitement image;three dimensional;voxel;computer vision;sintesis imagen;algorithme;image synthesis;algorithm;reconstruction image;estructura lamelar;lamellar structure;reconstruccion imagen;image reconstruction;peeling;structure lamellaire;interactions;imagerie medicale;superficie;synthese image;algorithms;surface;visual perception;three dimensional representation;vision ordinateur;surfaces;imageneria medical;monkeys;methodology;tomography;visual cortex;representacion tridimensional;tracking;algoritmo;layers	We describe a 3D surface-tracking algorithm that is used to detect the interior laminar surfaces of a solid shell. Each of these surfaces is called a “peel”. Successive peels may be generated, thus representing the solid shell by its tangential layers. This algorithm is based on voxel surface-tracking methods and solves the problems associated with transforming a surface-tracking algorithm into a “brain peeler”. We also discuss the properties of the voxel surfaces produced by this algorithm. Using the connectivity properties of these objects, we are able to convert voxel representations into polyhedral representations without human interaction. We illustrate this work with a high-resolution reconstruction of a monkey visual cortex. Additional application domains of this work are in areas in which there is a natural laminar structure to a 3D solid, such as in geophysics (earth strata).	algorithm;application domain;image resolution;polyhedron;voxel	Carl Frederick;Eric L. Schwartz	1990	The Visual Computer	10.1007/BF01902628	computer vision;image processing;computer science;artificial intelligence;mathematics;geometry;tomography;surface;computer graphics (images)	Graphics	65.33304901576945	-41.18131504922233	32667
de55b777200fbcbcf93f4440c71cb05f1988ba64	segmentation et mesures géométriques : application aux objets tubulaires métalliques. (segmentation and geometric measurements : application to metal tubular objects)				Nicolas Aubry	2017				Vision	61.108473242892806	-46.84089157215668	32705
fa1e7e78146d0c59bd583cd572aaa8cbe2cad73e	depth-scale method in 3d registration of rgb-d sensor outputs	robot sensing systems;estimation;three dimensional displays;feature extraction;solid modeling;robustness;iterative closest point algorithm	Automatic registration of 3D scans with RGB data is studied in this paper. In contrast to bulk of research in the field which deploy 3D geometry consistency, local RGB image feature matches are used to solve the unknown 3D rigid transformation. The key novelty in this work is the introduction of a new simple measure, we call “Depthscale measure”, which logically represents the size of the local image features in 3D world, thanks to the availability of the depth data from the sensor. Depending on the operating characteristics of the target application, we show this measure can be useful and efficient in eliminating outliers through experimental results. Also system level details are given to help scientists who want to build a similar system.	3d modeling;computer vision;experiment;feature (computer vision);kinect;open-source software;receiver operating characteristic;sensor	Ismail Bozkurt;Egemen Özden	2014	2014 International Conference on Computer Vision Theory and Applications (VISAPP)	10.5220/0004673204700475	computer vision;estimation;simulation;feature extraction;computer science;machine learning;solid modeling;statistics;robustness	Vision	57.39929958505414	-46.6668082973369	32730
0adcf2cadf95f42d2ebb9ef19f92fde15ffae72c	regularised marching tetrahedra: improved iso-surface extraction	implicit surface;vertex clustering;mesh simplification;marching cubes;three dimensional;iso surface extraction;cross section;marching cube;algorithm design;marching tetrahedra;aspect ratio	Marching cubes is a simple and popular method for extracting iso-surfaces from implicit functions or discrete three-dimensional (3-D) data. However, it does not guarantee the surface to be topologically consistent with the data, and it creates triangulations which contain many triangles of poor aspect ratio. Marching tetrahedra is a variation of marching cubes, which overcomes this topological problem. Improvement in triangle aspect ratio has generally been achieved by mesh simplification, a group of algorithms designed to reduce the large number of triangles. Vertex clustering is one of the simplest of these algorithms, but does not in general maintain the topology of the original mesh. We present a new algorithm, regularised marching tetrahedra, which combines marching tetrahedra and vertex clustering to generate iso-surfaces which are topologically consistent with the data and contain a number of triangles appropriate to the sampling resolution (typically 70% fewer than marching tetrahedra) with significantly improved aspect ratios. This improvement in aspect ratio greatly enhances the display of the surface, particularly when it is rendered using simple interpolated shading. Surface triangulations are shown for implicit surfaces, thresholded medical data, and surfaces created from object cross-sections. The application to data sampled on non-parallel planes is also considered.	adobe freehand;algorithm;cluster analysis;conditional (computer programming);discrete mathematics;edge enhancement;emoticon;gouraud shading;implicit surface;interpolation;isosurface;marching cubes;marching tetrahedra;maximal set;medical ultrasound;olap cube;sampling (signal processing);shading;symbolic computation;variable shadowing;virtual economy	Graham M. Treece;Richard W. Prager;Andrew H. Gee	1999	Computers & Graphics	10.1016/S0097-8493(99)00076-X	combinatorics;marching tetrahedra;topology;marching squares;computer science;isosurface;mathematics;geometry;marching cubes;algorithm	Visualization	67.50380827672619	-44.76690773119089	32872
740bc8a56a738b1b53fcf04a90151c15c54ba8e5	lucie the robot excavator-design for system safety	excavators;mobile robots;soil type;intelligent control;safety intelligent robots optical sensors competitive intelligence robot sensing systems soil humans cables hardware software architecture;software architecture;materials handling;optical distance sensor system safety lucie autonomous robot excavator lancaster university self contained system software architectures;safety;optical sensors;optical sensors excavators materials handling mobile robots intelligent control safety;system safety;autonomous robot;ta engineering general civil engineering general	Staff and students at Lancaster University have, for the past five years, been involved in the development of an autonomous robot excavator LUCIE the Lancaster University Computerised Intelligent Excavator. An excavator provides a good opportunity for development, as it is basically a highly efficient and well developed four degree-of-freedom manipulator arm, but with the complete absence of automation or intelligence. The aim of the project is to add autonomy in order to produce a robot excavator with the following characteristics:	autonomous robot;excavator (microarchitecture);system safety	Derek W. Seward;Frank Margrave;Ian Sommerville;Richard Morrey	1996		10.1109/ROBOT.1996.503897	excavator;control engineering;mobile robot;software architecture;simulation;computer science;engineering;artificial intelligence;robot control;system safety;intelligent control;soil type;mechanical engineering	Robotics	63.37582982557622	-29.12398908899141	32900
8c9c3468f7f14a9e5164fef6679929ac75828138	volume/surface octrees for the representation of three-dimensional objects	calcul matriciel;moment inertie;moment of inertia;algoritmo busqueda;quad tree;modelo 3 dimensiones;binary image;computer graphics;quad arbol;algorithme recherche;modele 3 dimensions;search algorithm;volume;three dimensional model;interseccion;three dimensional;traversee arbre;volumen;estructura datos;image binaire;momento inercia;imagen binaria;quad arbre;structure donnee;matrix calculus;intersection;data structure;infographie;calculo de matrices	The octree structure for the representation of 3D objects is an extension of the quadtree representation of 2D (binary) images. It is generated from the 3D binary array of the object it represents. However, the acquisition of a 3D array is not a trivial problem. In this study, we propose a scheme to generate an octree of an object from its three orthogonal views (silhouettes) exploiting a volume intersection technique. A multi-level boundary search algorithm is developed to incorporate surface information into the octree representation. This makes the octree representation compact, informative, and especially useful for graphic displays and object recognition tasks. An algorithm is also designed for computing the moment of inertia matrix, which is useful for object recognition. All the algorithms developed in this study are essentially tree traversal procedures and therefore are suitable for implementation on parallel processors.	octree	Chiun-Hong Chien;Jake K. Aggarwal	1986	Computer Vision, Graphics, and Image Processing	10.1016/S0734-189X(86)80031-7	three-dimensional space;combinatorics;topology;data structure;binary image;matrix calculus;computer science;quadtree;intersection;moment of inertia;mathematics;geometry;sparse voxel octree;computer graphics;volume;search algorithm;octree	Vision	65.44535177197768	-40.14550399965841	32910
0bc06ab777dd88b271e3be95389677e91a4b2428	shape preserving mesh deformation	mesh deformation	Deformation is the process of interactively transforming the surface of a model in response to some control mechanism. It is commonly used for model editing and animation. Typically, mesh deformation techniques require global knowledge of the model structure (such as a skeleton) and are quite time consuming. We propose a new approach for 3D mesh deformation based on a small number of user-specifiedcontrol vertices. Given the positions of the control vertices, our method computes the positions of the rest of the vertices, in a manner that best preserves the shape parameters of the source model. As demonstrated by Figure 1, we generate natural looking deformations in seconds with minimal user interaction.	interactivity;open-source software;vertex (geometry)	Alla Sheffer;Vladislav Kraevoy	2004		10.1145/1186223.1186272	computer science	Graphics	66.60528186335527	-46.5938147820069	32911
fa4520a88a551d7ff3d0b11a029f55009269e3d2	design and control of a smart bed for pressure ulcer prevention	multiunit bed platform;torque;microcontrollers;dynamic model;hospitals;caregiver;actuators;overall bed control system;intelligent control;mechanical structure;trajectory;microcontrollers actuators health care hospitals intelligent control medical control systems;single unit control system;smart bed control;turning process;mathematical model;smart bed design;approximation methods;smart hospital bed;friction;multiunit bed platform smart bed design smart bed control pressure ulcer prevention smart hospital bed turning process caregiver mechanical structure dynamic model smartbed actuating system single unit control system overall bed control system microcontroller;pressure ulcer prevention;microcontroller;smartbed actuating system;medical control systems;mathematical model equations torque approximation methods trajectory friction;health care	This work details the design, simulation, and experimental testing of a mechanically actuated smart hospital bed for the prevention of pressure ulcers in hospital patients. The smart hospital bed, or Smartbed, is designed to improve the “turning” process currently performed by health care workers, ensuring that patients are turned consistently and decreasing the labor requirement for caregivers. The mechanical structure of the bed is described, along with its advantages over current Smartbed products. Next, dynamic models of the Smartbed actuating systems are discussed along with descriptions of the devised single-unit and overall bed control systems. The control equations determined in simulation are then simplified, allowing them to be implemented in real time by a microcontroller. Finally, the simplified control system is tested against the original dynamic model in simulation, and the actuation of one constructed unit of the multi-unit bed platform is tested with open loop user input, validating design choices and improvements made to the hardware of the mechanism.	control system;curve fitting;hierarchical and recursive queries in sql;mathematical model;microcontroller;polynomial;prototype;simulation;software propagation;velocity (software development)	Zachary Brush;Alan P. Bowling;Michael Tadros;Michael Russell	2013	2013 IEEE/ASME International Conference on Advanced Intelligent Mechatronics	10.1109/AIM.2013.6584230	control engineering;embedded system;simulation;engineering	Robotics	72.13503896613219	-25.474284238030833	32933
4d6dfdcbeca99243a465aaba7bc3f9eee6fcc1f5	robotic manipulation of a biological cell using multiple optical traps	charge carrier processes;optical refraction;manipulator dynamics;laser beams;automated cell manipulation robotic manipulation biological cell multiple optical traps optical tweezers single focused laser beam refractive index automatic control techniques robotic control technique microparticle mathematical formulations;optical sensors;biomedical optical imaging;laser beams charge carrier processes optical sensors biomedical optical imaging optical refraction optical variables control manipulator dynamics;refractive index biology manipulators mathematical analysis radiation pressure;optical variables control	Existing control techniques for optical tweezers utilize a single focused laser beam to directly trap and manipulate a target cell. However, a typical force generated by an optical trap is extremely small (few pico-newtons) and therefore it is not sufficient to manipulate a larger cell or object. The optical trap is also sensitive to the shape of the biological cell and the refractive index. Therefore, current automatic control techniques for optical tweezers cannot be used to manipulate a large cell or cell with irregular shape. In addition, excessive irradiation of the laser beam to the cell may also cause photodamage of even lead to death of the cell. In this paper, we propose a robotic control technique for optical tweezers to achieve automated manipulation of cell, which is beyond the capability of a single optical trap. First, multiple laser beams are generated, and each laser beam is used to trap one micro-particle to create a formation around the target cell to hold it. Then the target cell is manipulated to a desired position by controlling the motorized stage. The proposed control technique is particularly suitable for automated manipulation of sensitive biological cells, cells with large size or cells of irregular shape. Rigorous mathematical formulations have been developed to analyze the control system for automated cell manipulation. Experimental results are presented to illustrate the performance of the proposed controller.	automatic control;control system;interaction;robot	Chien Chern Cheah;Quang Minh Ta;Reza Haghighi	2015	2015 IEEE International Conference on Robotics and Automation (ICRA)	10.1109/ICRA.2015.7139270	control engineering;optics	Robotics	77.0548850338819	-26.121271226182017	32944
6c73418ed123872b6de9a9963c71476262df4d2c	animation of human diving	modelo dinamico;animacion por computador;systeme commande;sistema control;proportional derivative;degree of freedom;simulation;dynamic model;state machine;simulacion;control system;imagen virtual;modele dynamique;image virtuelle;analyse performance;performance analysis;dynamic parameter;human diving;computer animation;virtual image;realistic motion;analisis eficacia;animation par ordinateur	The motion of a human platform diver was simulated using a dynamic model and a control system. The dynamic model has 32 actuated degrees of freedom and dynamic parameters within the range of those reported in the literature for humans. The control system uses algorithms for balance, jumping, and twisting to initiate the dive, sequences of desired values for proportional{derivative servos to perform the aerial portion of the dive, and a state machine to sequence the actions throughout the dive. The motion of the simulated diver closely resembles video footage of dives performed by human athletes. The control and simulation techniques presented in this paper are useful for providing realistic motion for synthetic actors in computer animations and virtual environments and may someday be useful for analysis of sports performance.	aerial photography;algorithm;control system;finite-state machine;mathematical model;simulation;synthetic intelligence;virtual reality	Wayne L. Wooten;Jessica K. Hodgins	1996	Comput. Graph. Forum	10.1111/1467-8659.1510003	virtual image;simulation;computer science;control system;artificial intelligence;computer animation;degrees of freedom;computer graphics (images)	Robotics	65.31431677512514	-31.603034895488122	32996
466e3be4c0f929dfcda0310267e5ff726aa62d33	a vocabulary for a multiscale process description for fast transmission and continuous visualization of spatial data	object representation;computadora;tratamiento datos;computers;maps;streaming;pedestrian navigation;location based service;mapa;spatial data;ordinateur;real time;deplacement;geometry;data processing;geometrie;individual object;mobile computer;traitement donnee;cartographie;web service;carte;navigation;visualization;cartografia;internet;level of detail;edificio;cartography;geometria;bâtiment;generalization;displacements;buildings	With the increasing availability of small mobile computers there is also an increasing demand for visualizing spatial data on those devices. Prominent applications are location based services in general, and car and pedestrian navigation in particular. In order to be able to offer both detail and overview of a spatial situation, the devices have to provide flexible zooming in and out in real-time. The same demands arise from the increasing amounts of data available and accessible by web services through limited bandwidth channels. The presentation of spatial data sets in different zoom levels or resolutions is usually achieved using generalization operations. When larger scale steps have to be overcome, the shape of individual objects typically changes dramatically; also objects may disappear or merge with others to form new objects. As theses steps typically are discrete in nature, this leads to visual ‘popping effects‘ when going from one level of detail to the other. In this paper, we will present an approach to decompose generalization into simple geometric and topologic operations that allow describing the complete generalization chain to generate a multiscale object representation. The goal is to generate a representation without redundancy and to transmit only that information which is needed when scale changes occur. This representation scheme ultimately also enables a continuous visualization, where the changes between the representations are visually indistinguishable. We identify elementary generalization operations and apply these concepts for polyline simplification, the generalization of building ground plans and for displacement.	computer;displacement mapping;level of detail;location-based service;mobile computing;real-time clock;redundancy (engineering);text simplification;vocabulary;web service	Monika Sester;Claus Brenner	2009	Computers & Geosciences	10.1016/j.cageo.2008.11.003	web service;generalization;computer vision;navigation;the internet;simulation;visualization;data processing;computer science;theoretical computer science;machine learning;level of detail;location-based service;database;mathematics;spatial analysis	Visualization	69.61189738354481	-52.03877053246654	33067
20224e01bbe5b07a1e152537f6f8f65c53575fdd	grasp synthesis for dextrous hands optimised for tactile manipulation	databases;grasping;force;tactile sensors;planning;databases grasping tactile sensors planning force			Jimmy A. Jørgensen;Henrik Gordon Petersen	2010			control engineering;computer vision;communication	Robotics	67.75160132190793	-28.00306987359284	33077
decced588b363f4205d822681ea3ebde23ea4e36	feature based shape similarity measurement for retrieval of mechanical parts	algorithms;dimensions;databases;machining;information retrieval;shapes			Madhumati Ramesh;Derek Yip-Hoi;Debasish Dutta	2001	J. Comput. Inf. Sci. Eng.		computer vision;machining;shape;computer science;engineering;pattern recognition;mathematics;geometry;dimension;engineering drawing;mechanical engineering	AI	65.91261264888954	-37.57918284945745	33090
973d12b95f50dc6673e16d271b208775f150dc66	a method for fast encoder-free mapping in unstructured environments	disaster site;fast encoder-free mapping;unknown environment;wiley periodicals;disaster environment;accurate position tracking;rescue robot;effective motion encoders;unstructured environment;constant contact;mapping problem;range finder device	disaster site;fast encoder-free mapping;unknown environment;wiley periodicals;disaster environment;accurate position tracking;rescue robot;effective motion encoders;unstructured environment;constant contact;mapping problem;range finder device	encoder	Adam Milstein;Matthew J. McGill;Timothy Wiley;Rudino Salleh;Claude Sammut	2011	J. Field Robotics	10.1002/rob.20408	computer vision;simulation;engineering;computer graphics (images)	Robotics	54.62126434879363	-36.32472492460678	33093
68b1d466d5491d71f6f9ebc11183351b97cd21d7	real-time full-field 3-d surface-shape measurement using off-the-shelf components and a single processor	ccd camera;high resolution;software synchronization;off the shelf components;digital light processing;real time;projection method;solid modelling digital signal processing chips image reconstruction;phase shifting fringe projection;phase shift;shape measurement;three dimensional;computer generated fringe patterns;real time full field 3d surface shape measurement;digital light processing projector;3d object surface modeling;3d shape acquisition system real time full field 3d surface shape measurement off the shelf components phase shifting fringe projection 3d object surface modeling permit full field measurement high resolution 3d surface shape measurement system 3d shape measurement pipeline software synchronization single computer processor computer generated fringe patterns digital light processing projector ccd camera 3d shape reconstruct triangular pattern phase shifting algorithms;3d shape reconstruct;single computer processor;image reconstruction;field measurement;surface model;3d shape measurement pipeline;3d shape acquisition system;digital signal processing chips;permit full field measurement;high resolution 3d surface shape measurement system;off the shelf;triangular pattern phase shifting algorithms;phase measurement shape measurement real time systems software measurement pipelines charge coupled devices charge coupled image sensors computer displays image reconstruction pixel;solid modelling;component software	Phase-shifting fringe-projection methods have been increasingly used for three-dimensional (3D) object surface modeling to permit full-field measurement. This paper presents a real-time full-field high-resolution 3D surface-shape measurement system implemented with an efficient 3D shape measurement pipeline and triangular-pattern phase-shifting based on off-the-shelf components, software synchronization and a single computer-processor. The system projects computer-generated fringe patterns with a triangular intensity profile onto an object via a Digital Light Processing (DLP) projector. The projected patterns are electronically shifted and a CCD camera synchronized with the DLP projector by software captures the images from another direction. The captured images are processed by a single computer to reconstruct the 3D shape using triangular-pattern phase-shifting algorithms, and the model is displayed in real time. The 3D shape acquisition system achieved a speed of 5.6 fps for an image size of 648times494 pixels using the two-step triangular-pattern phase-shifting method, without any hardware synchronization or dual processing.	algorithm;central processing unit;computer-generated holography;digital light processing;image resolution;pixel;real-time clock;structured-light 3d scanner;system of measurement	Peirong Jia;Jonathan Kofman;Chad English	2007	Sixth International Conference on 3-D Digital Imaging and Modeling (3DIM 2007)	10.1109/3DIM.2007.43	iterative reconstruction;three-dimensional space;computer vision;radiology;image resolution;digital light processing;computer science;phase;projection method;charge-coupled device;computer graphics (images)	Robotics	57.65602793154794	-48.667434893242934	33123
02c3f486a63486e66feaae1fc872eb30dbe3e3c4	model predictive trajectory tracking and collision avoidance for reliable outdoor deployment of unmanned aerial vehicles		We propose a novel approach for optimal trajectory tracking for unmanned aerial vehicles (UAV), using a linear model predictive controller (MPC) in combination with non-linear state feedback. The solution relies on fast onboard simulation of the translational dynamics of the UAV, which is guided by a linear MPC. By sampling the states of the virtual UAV, we create a control command for fast non-linear feedback, which is capable of performing agile maneuvers with high precision. In addition, the proposed pipeline provides an interface for a decentralized collision avoidance system for multi-UAY scenarios. Our solution makes use of the long prediction horizon of the linear MPC and allows safe outdoors execution of multi-UAV experiments without the need for in-advance collision-free planning. The practicality of the tracking mechanism is shown in combination with priority-based collision resolution strategy, which performs sufficiently in experiments with up to 5 UAVs. We present a statistical and experimental evaluation of the platform in both simulation and real-world examples, demonstrating the usability of the approach.		Tomáš Bača;Daniel Hert;Giuseppe Loianno;Martin Saska;Vijay Kumar	2018	2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)	10.1109/IROS.2018.8594266	control theory;software deployment;linear model;computer science;control engineering;collision avoidance system;collision;usability;robot kinematics;trajectory	Robotics	56.04532031527407	-27.31902794119418	33139
fef2f34c1016c52811629cfffc7fe4f43caafea8	volumetric reconstruction of objects and scenes using range images	occupancy grid;surface reconstruction;scene reconstruction;3d model;range image;scanner data;marching cube;object model	Abstract   This paper reviews volumetric methods for fusing sets of range images to create 3D models of objects or scenes. It also presents a new reconstruction method, which is a hybrid that combines several desirable aspects of techniques discussed in the literature. The proposed reconstruction method projects each point, or voxel, within a volumetric grid back onto a collection of range images. Each voxel value represents the degree of certainty that the point is inside the sensed object. The certainty value is a function of the distance from the grid point to the range image, as well as the sensor's noise characteristics. The super-Bayesian combination formula is used to fuse the data created from the individual range images into an overall volumetric grid. We obtain the object model by extracting an isosurface from the volumetric data using a version of the marching cubes algorithm. Results are shown from simulations and real range finders.		D. L. Elsner;Ross T. Whitaker;Mongi A. Abidi	1999	Digital Signal Processing	10.1006/dspr.1999.0339	computer vision;surface reconstruction;object model;computer science;data mining;marching cubes;computer graphics (images)	Robotics	56.83511882687853	-48.22804112355246	33166
0dde30b9cc8147e8d1662c9b7f8c4d4f0e7ffd5f	on the direct determination of epipoles: a case study in algebraic methods for geometric problems	minimisation;closed form solution;computer aided software engineering robustness minimization methods geometry cameras stability statistics closed form solution calibration application software;algebraic methods;application software;epipoles;plane cubics;geometry;fundamental matrix;minimization methods;sturm method;closed form solutions;stability;algebraic constraints;computer aided software engineering;algebraic method;statistics;uncalibrated images;nonlinear minimizations epipoles algebraic methods geometric problems uncalibrated images algebraic constraints statistics closed form solutions sturm method plane cubics;robustness;calibration;cameras;geometric problems;nonlinear minimizations	Studies experimentally the problem of computing the position of the epipoles in a pair of uncalibrated images. The approach, which is based on the definition of the epipolar transformation, exploits algebraic constraints obtained from point correspondences and provides a direct solution in which only the epipoles are involved. This is in opposition with the methods based on the computation of the fundamental matrix. In order to obtain a robust solution, three families of methods are successively considered: the first one uses statistics on closed-form solutions provided by the so-called Sturm method, the second one finds the intersection of plane cubics by deterministic procedures, and the third one is based on non-linear minimizations of a difference of cross-ratios. The authors discuss the shortcomings of each of these and show, using numerous experimental comparisons, that a drastic improvement can be obtained.		Quang-Tuan Luong;Olivier D. Faugeras	1994		10.1109/ICPR.1994.576265	minimisation;closed-form expression;mathematical optimization;application software;discrete mathematics;calibration;stability;computer science;mathematics;geometry;fundamental matrix;computer-aided software engineering;statistics;robustness	Robotics	53.902892311115586	-50.55576570385591	33282
72c6c91ae43e38b6a9fdc14c939f92d3d704ca9b	image-based rendering from handheld cameras using quad primitives	image based rendering;real time;depth map	In this paper we will present a novel approach of using surface patches for Image Based Rendering. Based on image sequences acquired with a freely moving portable multi-camera-rig we can extrapolate novel views of complex real scenes in realtime. The cameras are calibrated from the image sequence itself and dense depth maps are computed for each camera view using an improved multiview depth estimation technique. The depth maps are then approximated with quad surface patches for efficient rendering.	2d-plus-depth;approximation algorithm;depth map;distortion;extrapolation;handheld game console;static mesh;synthetic data	Jan-Friso Evers-Senne;Reinhard Koch	2003				Graphics	54.88798343902952	-46.95622432209585	33297
6277647c77430eebadeb297376d6706693e76d81	multi-component heart reconstruction from volumetric imaging	distance function;high resolution;delaunay triangulation;image processing;computed tomography;boundary element;generic model;cardiac imaging;data collection;three dimensional;finite element;ct angio imaging;stable manifold;geometric model;geometry processing;image modeling;voronoi diagram	Computer Tomography (CT) and in particular super fast, 64 and 256 detector CT has rapidly advanced over recent years, such that high resolution cardiac imaging has become a reality. In this paper, we briefly introduce a framework that we have built to construct three dimensional (3D) finite-element and boundary element mesh models of the human heart directly from high resolution CT imaging data. Although, the overall IMAGING-MODELING framework consists of image processing, geometry processing and meshing algorithms, our main focus in this paper will revolve around three key geometry processing steps which are parts of the so-called IMAGING-MODELING framework. These three steps are geometry cleanup or CURATION, anatomy guided annotation or SEGMENTATION and construction of GENERALIZED OFFSET SURFACE. These three algorithms, due to the very nature of the computation involved, can also be thought as parts of a more generalized modeling technique, namely geometric modeling with distance function. As part of the results presented in the paper, we will show that our algorithms are robust enough to effectively deal with the challenges posed by the real-world patient CT data collected from our radiologist collaborators.	algorithm;boundary element method;ct scan;computation;digital curation;geometric modeling;geometry processing;high-resolution computed tomography;image processing;image resolution;radiology	Chandrajit L. Bajaj;Samrat Goswami	2008		10.1145/1364901.1364928	three-dimensional space;computer vision;boundary element method;image resolution;delaunay triangulation;voronoi diagram;metric;image processing;geometric modeling;finite element method;mathematics;geometry;stable manifold;data collection;computer graphics (images)	Graphics	64.24687692923236	-44.235033661217265	33313
81b1de1b4debb0298836c8d78031cf9b881fae7f	global and local path planning in natural environment by physical modeling	path planning mobile robots;complex dynamics;complex dynamic behavior global path planning local path planning natural environment physical modeling autonomous vehicles robotics potential fields;autonomous vehicle;path planning;mobile robots;potential field;autonomic system;natural environment;off road vehicle;dynamic simulation;physical model;wave propagation;path planning remotely operated vehicles vehicle dynamics computational modeling mobile robots automatic control environmentally friendly manufacturing techniques marine pollution testing spinning;new physics	In the field of robotics, some autonomous vehicles work in natural sites. One problem for the autonomous system is to plan a path to the goal. A usual method uses potential fields to find a global path. With this method, obstacles must be clearly defined. But this is not the case in such natural environments. A new physically based potential method is introduced to find paths such as, for instance, a winding path to a pass. Moreover, locally, vehicles have to cope with a geometrically unstable environment and thus have a complex dynamic behavior. Thus it is necessary to elaborate a physical model of the robot-environment system. Generally, the two plannings, global and local, are independent. The introduced potential method resorts to the simulations of the vehicles to find a feasible path.	motion planning	Benoit Chanclou;Annie Luciani	1996		10.1109/IROS.1996.568960	physics beyond the standard model;control engineering;mobile robot;computer vision;dynamic simulation;simulation;complex dynamics;physical model;wave propagation;computer science;engineering;artificial intelligence;motion planning;natural environment	Robotics	60.20462546965105	-25.538328727738012	33352
51e293636cbb67120ff631b100b15716d315b2e5	fuzzy voxel object	fuzzy set theory;computer vision;a priori knowledge;three dimensional	In this paper, computer vision and fuzzy set theory are merged for the robust construction of three-dimensional objects using a small number of cameras and minimal a priori knowledge about the objects. This work extends our previously defined crisp model, which has been successfully used for recognizing and linguistically summarizing human activity. The objects true features more closely resemble the fuzzy object than those of the crisp object. This is demonstrated both empirically and through the comparison of features used in tracking human activity. Keywords—computer vision, human activity analysis, fuzzy objects, fuzzy voxel person.	approximation algorithm;computer vision;fuzzy set;image warping;map;set theory;stereopsis;t-norm;voxel	Derek Anderson;Robert H. Luke;Erik E. Stone;James M. Keller	2009			voxel;fuzzy logic;fuzzy set;optics;a priori and a posteriori;liquid crystal;computer vision;fuzzy classification;artificial intelligence;mathematics	Vision	56.55644987127851	-48.46161211788716	33384
9051265a390f887001c512b3f94aa135be52993e	engineering drawing database retrieval using statistical pattern spotting techniques	engineering;database system;diseno industrial;base donnee;industrial drawing;hidden markov model;modele hidden markov;interrogation base donnee;database;interrogacion base datos;base dato;construction mecanique;ingenierie;mechanical engineering;construccion mecanica;dessin industriel;pattern recognition;ingenieria;reconnaissance forme;stochastic model;reconocimiento patron;modelo estocastico;database query;modele stochastique	An experimental mechanical engineering drawing database system, which allows a user to retrieve images by presenting sketches or shapes which represent details such as e.g. screws or holes, is presented in this paper. Due to the use of novel augmented pseudo 2-D Hidden Markov Models with filler states, images can be retrieved, where the detail that corresponds to the query is embedded in e.g. hatching or is connected to other elements in the image. The proposed technique achieves a good performance which is demonstrated by a number of query and retrieval examples in this paper.	engineering drawing	Stefan Müller;Gerhard Rigoll	1999		10.1007/3-540-40953-X_21	computer science;artificial intelligence;stochastic modelling;database;hidden markov model	Vision	65.14978812638368	-37.52577032216524	33401
8f9f170a4af3a005f68f0926b57ddfccceb3ec0c	fast terrain mapping from low altitude digital imagery	large scale modeling;terrain reconstruction;mav;aerial triangulation;structure from motion	We present a linear time Real Terrain Reconstruction (RTR) framework for fixed-wing micro aerial vehicles (MAVs) in this paper. Single-shot aerial images labeled with GPS and IMU signals are acquired by a fixed-wing MAV in several flights. Then these images are fed into our structure from motion (SfM) processing to generate accuracy pose estimation and 3D points. RTR improves existing state of the art algorithms VisualSFM [1] in multiaspect so as to make it more suitable for large-scale terrain reconstruction from aerial imagery. Firstly, we present a novel strategy of combining signals from airborne sensors (GPS/IMU) with the traditional SfM method, which can improve speed and accuracy of pose estimation observably. Secondly, a delayed aerial triangular method is designed to reconstruct a point visible in more than two cameras with an appropriate baseline. Thirdly, we also release 5 aerial imagery datasets which contain over 15 thousands images totally with the detailed MAV pose information from airborne sensors (GPS/IMU). These resources can be used as a new benchmark to facilitate further research in the area. We test our algorithm on these aerial image sets with various settings, and show that RTR offers state of the art performance for large-scale terrain reconstructions.	3d pose estimation;aerial photography;airborne ranger;algorithm;baseline (configuration management);benchmark (computing);bundle adjustment;chi;emoticon;global positioning system;google earth;iterator;map;point cloud;poo-chi;real-time recovery;sensor;sparse matrix;structure from motion;time complexity;triangulation (geometry)	Yawei Luo;Tao Guan;Benchang Wei;Hailong Pan;Junqing Yu	2015	Neurocomputing	10.1016/j.neucom.2014.12.079	computer vision;structure from motion;simulation;computer science	Robotics	54.56194509463285	-44.69954603060077	33414
8cf6a6682be3c0b17fe70aee6aa82f80f258bc79	image processing experiments	home computing;program template;image processing;edge detection;distance learning;microcomputer;teaching of programming;image processing techniques;undergraduate research;monte carlo technique	The purpose of our CSIP grant* was to develop an image processing laboratory that could be used in undergraduate courses and for undergraduate research projects. The results from three research projects are presented, The first experiment uses image processing techniques to extract the letters and numbers from license plates. First, a camera-recorder records the license plates on the rear of automobiles. Then, the images are digitized and processed. The processed images yield the correct results in about 90 percent of the licenses examined. The second experiment uses image processing techniques to calculate the acceleration (due to gravity) of a freely falling ball. First, the camcorder observes and records the motion of the falling ball. Then, the recorded images are played back into the computer and digitized. Next, two different programs are written to determine how far the center of the ball has traveled in a fixed amount of time. These programs use background extraction, edge detection, circle fitting algorithms, and Monte Carlo techniques to find the center of the ball. Once the center of the ball is located, the acceleration can be easily calculated. The third experiment uses image processing to calculate the horizontal and vertical velocity, and the pitch angle of an aircraft at touchdown. A program is written to find the position of an aircraft just prior to touchdown. Once this position is known the velocities and pitch angle are calculated. Permission to copy without fee all or part of this material is granted provided that the copies are not made or distributed for direct commercial advantage, the ACM copyright notice and the title of the publication and its date appear, and notice is given that copying is by permission of the Association for Computing Machinery. To copy otherwise, or to republish, requires a fee and/or specific permission.	algorithm;computer simulation;computer vision;curve fitting;edge detection;experiment;image processing;monte carlo method;pitch (music);printing;robotics;velocity (software development)	Timothy S. Kula;Raymond Konopka;John A. Cicero	1990		10.1145/323410.323441	distance education;computer vision;edge detection;image processing;computer science;theoretical computer science;digital image processing;microcomputer;monte carlo method;computer graphics (images)	Graphics	60.085709907647185	-35.438228591706434	33415
4fe919ac134564c20e2e36814a4a70b2a5bf213c	occluding edges soft shadows - a new approach for realistic shadows using occluding edges		In this paper, a new algorithm to render soft shadows in real time applications is introduced, namely the Occluding Edges Soft Shadow algorithm (short OESS). The algorithm approximates the shadow cast from linear lights by finding the outlines of an occluding object (Occluding Edges) and considering these in a fragment’s illumination. The method is based on the shadow mapping technique, whereby its capability of rendering the shadow at an interactive rate does not depend on the complexity of the scene. The paper supplies an overview for several methods to produce shadows and soft shadows in real time computer graphics, a detailed description of the newly developed algorithm, and a section with results and future possibilities for	algorithm;approximation algorithm;compression artifact;computer graphics;illumination (image);pixel;shadow mapping;shadow volume	Christian Liwai Reimann;Bernd Dreier	2016		10.5220/0005777701770184		Graphics	63.9360730209024	-51.50987431727159	33429
f7c9c3ebe846e4c0e82d66e3177af90476645807	video frames reconstruction based on time-frequency analysis and hermite projection method	signal image and speech processing;projection method;quantum information technology spintronics;time frequency analysis	A method for temporal analysis and reconstruction of video sequences based on the time-frequency analysis and Hermite projection method is proposed. The S-method-based time-frequency distribution is used to characterize stationarity within the sequence. Namely, a sequence of DCT coefficients along the time axes is used to create a frequency-modulated signal. The reconstruction of nonstationary sequences is done using the Hermite expansion coefficients. Here, a small number of Hermite coefficients can be used, which may provide significant savings for some video-based applications. The results are illustrated with video examples.	3d projection;closed-circuit television;coefficient;cubic hermite spline;digital video;discrete cosine transform;frequency analysis;jpeg;modulation;projection method (fluid dynamics);signal processing;stationary process;time–frequency analysis;time–frequency representation	Srdjan Stankovic;Irena Orovic;Andrey S. Krylov	2010	EURASIP J. Adv. Sig. Proc.	10.1155/2010/970105	computer vision;mathematical optimization;time–frequency analysis;theoretical computer science;mathematics;projection method	Vision	75.6742323420984	-40.56920095336245	33435
416a68d73804ef61fffe424761ced2fb83dea71b	improving the surface cycle structure for hexahedral mesh generation	mesh quality;satisfiability;three dimensional;mesh refinement;hexahedral mesh generation;mesh generation	"""Although these methods can be shown to work in principle, the quality of the generated meshes heavily relies on the dual cycle structure of the given surface mesh. In particular, it seems that difficulties in the hexahedral meshing process and poor mesh qualities are often due to self-intersecting dual cycles. Unfortunately, all previous work on quadrilateral surface mesh generation has focused on quality issues of the surface mesh alone but has disregarded its suitability for a high-quality extension to a three-dimensional mesh. In this paper, we develop a new method to generate quadrilateral surface meshes without self-intersecting dual cycles. This method reuses previous b-matching problem formulations of the quadrilateral mesh refinement problem. The key insight is that the bmatching solution can be decomposed into a collection of simple cycles and paths of multiplicity two, and that these cycles and paths can be consistently embedded into the dual surface mesh. A second tool uses recursive splitting of components into simpler subcomponents by insertion of internal two-manifolds. We show that such a two-manifold can be meshed with quadrilaterals such that the induced dual cycle structure of each subcomponent is free of self-intersections if the original component satisfies this property. First experiments indicate that the hexahedral mesh quality can greatly benefit from both methods proposed in this paper. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the lull citation on the first page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Computational Geometry 2000 Hong Kong China Copyright ACM 2000 1-58113-224-7/00/6...$5.00 1. I N T R O D U C T I O N The automatic generation of finite element meshes is essential for the numerical analysis and simulation in a wide variety of applications. Recent years showed many research efforts and brought up several approaches, but up to now, hexahedral mesh generation for an arbitrary 3D solid is still a challenge. Prescribed surface meshes. In many applications, in particular in structural mechanics simulations, high mesh quality is required near the boundary of the solid and is much more important than """"deep inside the domain"""". Therefore, it is often preferred to start the volume meshing subject to a fixed quadrilateral surface mesh of an excellent quality. Moreover, the complete solid may consist of several components, for example, solid parts of different material or a solid and its complement within a larger box. Many subdomains may also arise for algorithmic reasons: we may want to divide the domain into smaller and simpler regions either to facilitate the meshing process for each part or to allow parallelism which can be crucial for some large-scale applications. In all such cases, it is usually essential to have a compatible mesh at the common boundary of adjacent components, that is the surface meshes must be compatible. The only solution for this problem we can envision is to prescribe the surface mesh for each component. Thurston [ 19] and Mitchell [7] independently characterized quadrilateral surface meshes which can be extended to hexahedral meshes. They showed that for a volume which is topologically a ball and which is equipped with an all-quadrilateral surface mesh, there exists a combinatorial hexahedral mesh without further boundary subdivision if and only if the number of quadrilaterals is even. Furthermore, Eppstein [4] used this existence result and proved that a linear number of hexahedra (in the number of quadrilaterals) are sufficient in such cases. Unfortunately, all these results are nonconstructive and it remains unclear whether they can be extended to constructive methods for geometrically well-shaped hexahedral meshes. There are quite simple solids with natural looking quadrilateral surface meshes, for example the quadratic pyramid problem of Schneiders [16], where only rather complicated combinatorial meshes are known, but no mesh with an acceptable quality is available. Related work. We briefly review approaches to hexahedral mesh generation based on prescribed quadrilateral surface meshes. For a more complete survey, online information and data bases on meshing literature see [15] and [13]."""	adaptive mesh refinement;algorithm;computation;computational geometry;cycle (graph theory);database;embedded system;experiment;finite element method;hexahedron;image-based meshing;mesh generation;mitchell corporation;numerical analysis;parallel computing;polygon mesh;recursion;refinement (computing);simulation;subdivision surface	Matthias Müller-Hannemann	2000		10.1145/336154.336167	three-dimensional space;mesh generation;mathematics;satisfiability	Graphics	69.97062049982449	-44.18649613495447	33507
fdbd439f0b57bf95dd05ef3596f1fb1aa35b5010	rational zoom of bit maps using b-spline interpolation in computerized 2-d animation	b spline interpolation;rational zoom;2 d animation;key frame interpolation;spline interpolation;bit map processing	This paper desgibes the application of &spline interpolation to the problem of rational transformation in computerized 2-D animation. The technique described herewith can also be applied to the rcsolution independence problem which arises when the same production workstation is used to produce animation series to be recorded on variable film sizes This article fully explains our solution to the problem of rational zoom. An algorithm has bcen written to speed up computations by spreading the computing load among similar technical workstations hooked up in a network. Large	algorithm;b-spline;computation;device independence;spline interpolation;workstation	Charles X. Durand;D. Faguy	1990	Comput. Graph. Forum	10.1111/j.1467-8659.1990.tb00372.x	spline interpolation;interpolation;computer vision;interpolation;computer science;theoretical computer science;stairstep interpolation;mathematics;geometry;nearest-neighbor interpolation;multivariate interpolation;computer graphics (images)	Graphics	67.6315360468504	-50.556646455765666	33513
fecce45f794697de670b03de99ac2e1b352ff7d8	development and calibration of karola, a compact, high-resolution 3d laser scanner	particle swarm optimisation calibration compensation laser ranging optical sensors;three dimensional displays lasers measurement by laser beam robots systematics measurement uncertainty calibration;mounting precision karola 3d laser scanner control software stack ros framework 2d laser range finders particle swarm based calibration method mounting offset compensation rotational axis	We present KaRoLa, a new rotating 3D laser scanner with a modular and flexible hardware design and an integrated control software stack implemented in the ROS framework. Based on our requirements - light-weight and compact hardware, high resolution and accuracy - we compare different 2D laser range finders which are commercially available. We describe the hardware design, including the mechanical and electrical components, and the included software stack in detail. Furthermore, we present a particle swarm based calibration method to compensate mounting offsets between the 2D laser scanner and the rotational axis. The calibration significantly improves the overall accuracy and lowers the requirements for the mounting precision. Field studies for evaluating KaRoLa in real-world application scenarios such as planetary exploration and search and rescue missions complete this article.	3d scanner;apache axis;component-based software engineering;electronic component;image resolution;mathematical optimization;particle swarm optimization;planetary scanner;plug-in (computing);point cloud;requirement;robot operating system	Lars Pfotzer;Jan Oberländer;Arne Rönnau;Rüdiger Dillmann	2014	2014 IEEE International Symposium on Safety, Security, and Rescue Robotics (2014)	10.1109/SSRR.2014.7017677	computer vision;electronic engineering;engineering;optics	Robotics	59.08249427893482	-35.04909603161385	33538
1ad949b62658f5feb0330b5593879bd37b862fd6	image jacobian estimation using structure from motion on a centralized point	visual servoing cameras end effectors jacobian matrices robot vision;jacobian matrices cameras estimation trajectory approximation methods calibration convergence;image jacobian estimation online calibration algorithm starting positions average condition number wam ibvs system whole arm manipulation ibvs system dynamic feature points stationary feature points camera motion pixel coordinate cma centralized motion algorithm external parameters internal parameters ibvs control systems image based visual servoing centralized point	Image based visual servoing (IBVS) has become increasingly common in automated systems. IBVS control systems are dependent on the accuracy of an image Jacobian, which requires the knowledge of the internal and external parameters of the system. In most systems, some or all of these parameters are unknown. A centralized motion algorithm (CMA) is proposed to compute the image Jacobian with fast convergence and low iterations. Centralized motion is defined as a motion where a single feature point does not change its pixel coordinate value through the camera's motion. Therefore, the CMA is an algorithm that exploits the fact that the chosen feature point will have little to no changes in pixel coordinates. As a result, the CMA requires only a single stationary feature point, along with a minimum of two more feature points that will be dynamic, in the image to compute the image Jacobian. Using a Whole-Arm Manipulation (WAM) IBVS system, it was shown that an image Jacobian with an average condition number of 45, converges in an average of 4 iterations from 6 different starting positions. Experiments show that the CMA is a fast and effective online calibration algorithm.	algorithm;cma-es;camera resectioning;centralized computing;condition number;control system;experiment;information extraction;iteration;jacobian matrix and determinant;machine vision;pixel;stationary process;structure from motion;visual servoing	Victor Nevarez;Ronald Lumia	2014	2014 IEEE/RSJ International Conference on Intelligent Robots and Systems	10.1109/IROS.2014.6942646	computer vision;mathematical optimization;control theory;mathematics	Robotics	55.638283992150704	-39.32359684192488	33539
24748f990a1fcade0f4af55fb655de387b34fdf5	explicit control of vector field based shape deformations	differential forms;application software;computer graphics;differential geometry;geometry;surface fitting;surface fitting geometry curve fitting computer graphics application software finite difference methods physiology shape polynomials noise robustness;noise robustness;polynomials;finite difference method;physiology;shape;geometric algorithm;curve fitting;triangle mesh;finite difference methods;surface approximation	Vector field based shape deformations (VFSD) have been introduced as an efficient method to deform shapes in a volume-preserving foldover-free manner. However, mainly simple implicitly defined shapes like spheres or cylinders have been explored as deformation tools by now. In contrast, boundary constraint modeling approaches enable the user to exactly define the support of the deformation on the surface. We present an approach to explicitly control VFSD: a scalar function together with two thresholds is placed directly on the shape to mark regions of full, zero, and blended deformation. The resulting deformation is volume-preserving and free of local self-intersections. In addition, the full deformation is steered by a 3D parametric curve and a parametric twisting function. This way our deformations appear to be a generalization of the boundary constraint modeling metaphor. We apply our approach in different scenarios. A parallelization of the computation on the GPU allows for editing high-resolution meshes at interactive speed.	central processing unit;computation;graphics processing unit;image resolution;measure-preserving dynamical system;parallel computing	Wolfram von Funck;Holger Theisel;Hans-Peter Seidel	2007	15th Pacific Conference on Computer Graphics and Applications (PG'07)	10.1109/PG.2007.26	gaussian curvature;differential geometry;mathematical optimization;combinatorics;finite difference method;mathematics;geometry;curvature	Graphics	67.94759856921056	-45.940923754202416	33678
a44436051d68f2f763a6529f23a64cd99b2bbec2	an adaptive acceleration structure for screen-space ray tracing	screen;gpu;screen space ray tracing;acceleration structure;space ray tracing	We propose an efficient acceleration structure for real-time screen-space ray tracing. The hybrid data structure represents the scene geometry by combining a bounding volume hierarchy with local planar approximations. This enables fast empty space skipping while tracing and yields exact intersection points for the planar approximation. In combination with an occlusion-aware ray traversal our algorithm is capable to quickly trace even multiple depth layers. Compared to prior work, our technique improves the accuracy of the results, is more general, and allows for advanced image transformations, as all pixels can cast rays to arbitrary directions. We demonstrate real-time performance for several applications, including depth-of-field rendering, stereo warping, and screen-space ray traced reflections.	algorithm;approximation;bounding volume hierarchy;data structure;glossary of computer graphics;pixel;ray tracing (graphics);real-time clock;reflection (computer graphics);tree traversal	Sven Widmer;Dawid Pajak;André Schulz;Kari Pulli;Jan Kautz;Michael Goesele;David P. Luebke	2015		10.1145/2790060.2790069	cone tracing;distributed ray tracing;ray tracing;ray;mathematics;geometry;optics;beam tracing;computer graphics (images)	Graphics	66.18792315023305	-51.18110117885972	33681
f1d124866314abe45820ac75ca20ac6c47a3d8c3	camera calibration for plate refractive imaging system	calibration;target imaging environment;infrared navigator;infrared imaging;light refraction;plate refractive imaging system;image sensors;infrared filter;plate refractive camera calibration model;planar parallel plate;cameras	This paper presents a study of an important imaging system, called the plate refractive imaging system. The system comprises of a perspective camera looking through one or more planar parallel plates to the target imaging environment. Such as the perspective camera captures the object through an infrared filter which is used in the infrared navigator for surgeries. Sometimes, we have to calibrate the camera without removing the plate. Up to now, it does not have a valid algorithm to do so. In this paper, a plate refractive camera calibration model is proposed for the imaging systems that incorporate a refractive plate at the front end of the camera. The proposed model is based on the refractive effect of variations in the viewpoint of such systems. Both synthetic and real data show that our proposed camera model is insensitive to noise and can achieve high accuracy.	algorithm;camera resectioning;lattice problem;object point;synthetic data;synthetic intelligence	Longxiang Huang;Yuncai Liu	2014	2014 22nd International Conference on Pattern Recognition	10.1109/ICPR.2014.697	camera resectioning	Robotics	56.24903326759356	-49.17917837439456	33708
ed8daebafebe85636dfa587d1fd99befb8b8603d	a reconfigurable modular robotic endoluminal surgical system: vision and preliminary results	mechanical design;surgical robot;endoluminal surgery;modular robot;interval analysis	Miniaturized surgical devices are promising for the future development of minimally invasive and endoluminal surgery. However, the dexterity and therapeutic functions of these devices are limited. In this paper, a reconfigurable modular robotic system is proposed to perform screening and interventions in the gastrointestinal tract. In the proposed system, millimeter-sized robotic modules are ingested and tasked to assemble into an articulated mechanism in the stomach cavity. The modules are assembled according to the target location to perform precise intervention. Based on this concept, a preliminary report is presented covering the robotic schemes for the endoluminal reconfigurable platform, the design with structural functions, the control strategy, and the interval-based constraint satisfaction algorithm to determine the suitable topologies of the reconfigurable robot for the given task.	algorithm;constraint satisfaction;control theory;robot;tract (literature)	Kanako Harada;Denny Oetomo;Ekawahyu Susilo;Arianna Menciassi;David Daney;Jean-Pierre Merlet;Paolo Dario	2010	Robotica	10.1017/S0263574709990610	control engineering;simulation;engineering;biological engineering;interval arithmetic	Robotics	73.27432916520866	-28.20255321019107	33725
cc32b64941302367e2248f9f6dfd50f0841d7753	a cad service for fusion physics codes	design automation;kernel;geometry;design automation solid modeling physics shape geometry kernel magnetic separation;physics;shape;tokamak devices cad computational geometry physics computing;magnetic separation;solid modeling;open source cad kernel cad service library fusion physics codes machine description computer aided design cad geometrical data level of detail lod iter tokamak	There is an increased need for coupling machine descriptions to various fusion physics codes. We present a computer aided design (CAD) service library that interfaces geometrical data requested by fusion physics codes in completely programmatic way for use in scientific workflow engines. Fusion codes can request CAD geometrical data at different levels of details (LOD) and control major assembly parameters. This service can be part of the scientific workflow that delivers meshing of the CAD model and/or variation of the parameters. In this paper we present re-engineering of the ITER tokamak using an open source CAD kernel providing standalone library of services. Modelling of the machine is done with several LOD, starting from the rough one and building/replacing with more detailed models by adding more details and features. Such CAD modelling of the machine with LODs delivers flexibility and data provenance records for the complete CAD to physics codes workflow chain.	code;computer-aided design;geometric modeling kernel;open-source software	Marijo Telenta;Leon Kos	2016	2016 39th International Convention on Information and Communication Technology, Electronics and Microelectronics (MIPRO)	10.1109/MIPRO.2016.7522154	kernel;simulation;electronic design automation;shape;computer science;theoretical computer science;operating system;solid modeling	HPC	67.00857918792138	-42.603962734837374	33772
e6304cf86af9bc7b17386fdab94e4da8afc0770c	handling edge lists in 2d vector graphics hardware	accelerator;vector graphics;edge lists;active edge lists	In rendering two-dimensional (2D) vector graphics, edge lists are often so large that their handling hinders the desired operation of portable devices. This paper proposes and evaluates an efficient edge-list handling method for a 2D vector graphics hardware accelerator. The proposed method selects edges that span the next scanline from among those spanning the current scanline and stores them in a small list in the internal memory. An edge list is assigned to each scanline and it stores only those edges that have not appeared in previous edge lists. Given that most active edges span only a few scanlines, the internal list can be small and implemented in the accelerator, whereas the edge lists are held in the external memory. Experimental results show that the proposed method can reduce external memory access by 23.4%–76.6% for the benchmark images considered compared to the prior methods.	graphics hardware;vector graphics	Sang-Woo Seo;Yong-Luo Shen;Kwan-Young Kim;Hyeong-Cheol Oh	2012	Journal of Circuits, Systems, and Computers	10.1142/S0218126612500223	vector graphics;computer hardware;computer science;theoretical computer science;scanline rendering;computer graphics (images)	Theory	68.11573716017637	-50.19865618434828	33779
2229713f4396299a84f1bdc33cb6b19d69916a0c	a new localization method for mobile robot by data fusion of vision sensor data and motion sensor data	velocity control accelerometers gyroscopes image sensors kalman filters mobile robots position control robot vision sampled data systems sensor fusion;velocity estimation localization method mobile robot data fusion vision sensor data motion sensor data vision sensor measurements motion sensor measurements robot wheel encoders accelerometer gyroscope multirate sampled data system robot position robot velocity extended kalman filter normal operation mode wheel slip mode kidnap mode orientation estimation position estimation	This paper presents a new localization method by the data fusion of vision sensor and motion sensor measurements, which can be used for mobile robots. The developed system estimates the orientation, position and velocity of a mobile robot. This is achieved by using data from a camera, robot wheel encoders, an accelerometer, and a gyroscope. The developed system is a multi-rate sampled data system. For the accurate estimation of robot position and velocity, the developed method detects the slip of robot wheels, by comparing the data from the encoders and the accelerometer. The developed method estimates the robot orientation and position by using an extended Kalman filter. The experiments are performed to verify the localization performance of the developed method in several motion scenarios, including a normal operation mode, a wheel slip mode, and a kidnap mode.	encoder;experiment;extended kalman filter;gyroscope;mobile robot;motion detector;sampled data system;velocity (software development);wheels	Tae-Jae Lee;Wook Bahn;Byung-Moon Jang;Ho-Jeong Song;Dong-Il Cho	2012	2012 IEEE International Conference on Robotics and Biomimetics (ROBIO)	10.1109/ROBIO.2012.6491053	control engineering;computer vision;computer science;engineering;control theory	Robotics	56.99299845491884	-35.54783493919991	33785
3fbef56fd3096bf7dbb20acb923d3df6350f0649	a synergetic brain-machine interfacing paradigm for multi-dof robot control	robot arm dynamic condition synergetic brain machine interfacing paradigm multidof robot control multijoint redundant robot system motor imagery electroencephalography signal co adaptive decoder synergetic motor learning algorithm energy optimality tacit learning torque control paradigm robot arm end point movement simultaneous multijoints control bmi support vector machine based decoder;motor drives;adaptive control adaptive decoding electroencephalography human robot interaction learning artificial intelligence manipulator dynamics redundant manipulators support vector machines torque control;decoding;decoding robot kinematics electroencephalography redundancy motor drives electrodes;brain machine interfacing bmi co adaptive decoder joint redundancy multijoint robot synergetic learning control tacit learning;electrodes;redundancy;torque control adaptive control adaptive decoding electroencephalography human robot interaction learning artificial intelligence manipulator dynamics redundant manipulators support vector machines;synergetic brain machine interfacing paradigm multidof robot control multijoint redundant robot system motor imagery electroencephalography signal co adaptive decoder synergetic motor learning algorithm energy optimality tacit learning torque control paradigm robot arm end point movement simultaneous multijoints control bmi support vector machine based decoder robot arm dynamic condition;electroencephalography;tacit learning brain machine interfacing bmi co adaptive decoder joint redundancy multijoint robot synergetic learning control;robot kinematics;torque control	This paper proposes a novel brain-machine interfacing (BMI) paradigm for control of a multijoint redundant robot system. Here, the user would determine the direction of end-point movement of a 3-degrees of freedom (DOF) robot arm using motor imagery electroencephalography signal with co-adaptive decoder (adaptivity between the user and the decoder) while a synergetic motor learning algorithm manages a peripheral redundancy in multi-DOF joints toward energy optimality through tacit learning. As in human motor control, torque control paradigm is employed for a robot to be adaptive to the given physical environment. The dynamic condition of the robot arm is taken into consideration by the learning algorithm. Thus, the user needs to only think about the end-point movement of the robot arm, which allows simultaneous multijoints control by BMI. The support vector machine-based decoder designed in this paper is adaptive to the changing mental state of the user. Online experiments reveals that the users successfully reach their targets with an average decoder accuracy of over 75% in different end-point load conditions.		Saugat Bhattacharyya;Shingo Shimoda;Mitsuhiro Hayashibe	2016	IEEE Transactions on Systems, Man, and Cybernetics: Systems	10.1109/TSMC.2016.2560532	robot learning;simulation;electroencephalography;computer science;electrode;artificial intelligence;arm solution;control theory;robot control;redundancy;robot kinematics	Robotics	69.57103721985628	-27.134361813388093	33825
2d98650ec911168ec241e4060dddbe4594ffb24e	force-directed methods for smoothing unstructured triangular and tetrahedral meshes	graph drawing;direct method	 We develop and implement new algorithms for smoothing triangular and tetrahedral unstructured meshes. Our approach is based on a variation of the force-directed method used in graph drawing. This method assumes that on each vertex a certain force is applied that moves the vertex relative to its neighbors so that the shapes of its incident elements are improved. The final stable configuration often corresponds to a graph with good global properties. In this paper we show that this method can be... 	polygon mesh;smoothing	Hristo Djidjev	2000			mathematical optimization;smoothing;polygon mesh;mathematics;graph drawing;tetrahedron	Visualization	69.25091173312985	-43.71229006173956	33957
0455208ba6b60ec2f3ef4f4992faa4828ee3a852	presenting a deep motion blending approach for simulating natural reach motions			alpha compositing	Felix Gaisbauer;Philipp Froehlich;Jannes Lehwald;Philipp Agethen;Enrico Rukzio	2018		10.2312/egp.20181010		Vision	62.03166971874541	-45.97530439181457	33966
b7ca7d9f18d50da5358175a0004146482c0b7b84	contour-based terrain model reconstruction using distance information	modelizacion;model based reasoning;raisonnement base sur modele;modele geometrique;branching;tiling;three dimensional;processing time;modelisation;ramificacion;pavage;courbe niveau;ramification;temps traitement;terrain modeling;geometric model;curva nivel;modeling;tiempo proceso;contour line;triangle strip;geometrical model;modelo geometrico	In order to create three-dimensional terrain models, we reconstruct geometric models from contour lines on two-dimensional map. Previous methods divide a set of contour lines into simple matching regions and clefts. Since long processing time is taken for reconstructing clefts, performance might be degraded while manipulating complicated models. We propose a fast reconstruction method, which generates triangle strips by computing distance of corresponding vertex pairs in adjacent slices for simple matching region. If there are some branches or dissimilarities, it computes midpoints of corresponding vertices and reconstructs geometry of those areas by tiling the midpoints and remaining vertices. Experimental results show that our method reconstructs geometric models fairly well and it is faster than the previous method.	contour line;strips;tiling window manager;triangle strip;vertex (geometry);virtual reality	Byeong Seok Shin;Hoe Sang Jung	2005		10.1007/11424857_126	three-dimensional space;systems modeling;branching;computer science;artificial intelligence;geometric modeling;model-based reasoning;mathematics;geometry;ramification;contour line	Vision	65.99863147058448	-41.800808373706396	34028
0eb5c77f968cbfffda4eb8edbb0fe01f300552e9	simultaneous estimation of reflectance parameters from images	finite element method analysis;strain measurement;user interface;force	Although the reflection model has been improved to generate realistic images, it is difficult to determine appropriate values of specular and diffuse reflectance parameters. Sato et al. [Sato et al. 1997] proposed an approach to estimate each parameter from images of actual objects by separating the observed data into two reflection components. However, it is not necessarily possible to distinguish the mixed data into two reflections precisely. This paper presents a method to estimate both reflectance parameters simultaneously from real images without separating the specular and diffuse components. We have defined an integrated space as two reflection characteristics and developed a procedure to determine the model parameters from distribution of the observed data in the space.	reflection (computer graphics)	Sachiko Miura;Masashi Baba;Masayuki Mukunoki;Naoki Asada	2006		10.1145/1179622.1179737	computer science;operating system;user interface;force	Vision	60.72031875972498	-51.868725609334	34032
64ca547ad136987e90a293ca02a8d45b7ddbf1e7	autonomy mode suggestions for improving human-robot interaction	robot sensing systems cognitive robotics orbital robotics switches navigation computer science cognition humans sonar detection collaboration;robot design;intelligent robots;mixed initiative;adjustable autonomy;mobile robots;human robot interaction;intelligent robots man machine systems telerobotics mobile robots;urban search and rescue;collaborative control human robot interaction fully autonomous robot system teleoperated robot system urban search and rescue application;telerobotics;man machine systems	Robot systems can have autonomy levels ranging from fully autonomous to teleoperated. Some systems have more than one autonomy mode that an operator can select. In studies, we have found that operators rarely change autonomy modes, even when it would improve their performance. This paper describes a method for suggesting autonomy mode changes on a robot designed for an urban search and rescue application.	autonomous robot;autonomy;human–robot interaction	Michael Baker;Holly A. Yanco	2004	2004 IEEE International Conference on Systems, Man and Cybernetics (IEEE Cat. No.04CH37583)	10.1109/ICSMC.2004.1400781	telerobotics;human–robot interaction;mobile robot;robot learning;computer vision;simulation;computer science;artificial intelligence;social robot;robot control;mobile robot navigation;personal robot	Robotics	60.81375901920281	-27.11615554730235	34142
2901a187614afa455a147093f7dbc483485ad1fb	robust data modelling using thin plate splines	swinburne;splines mathematics;computer vision;splines mathematics computer vision;robust data modelling pseudo outliers computer vision robust spline fitting techniques least k th order statistical model fitting thin plate splines;splines mathematics robustness computational modeling data models cost function mathematical model computer vision	Using splines to model spatio-temporal data is one of the most common methods of data fitting used in a variety of computer vision applications. Despite its ubiquitous applications, particularly for volumetric image registration and interpolation, the existing estimation methods are still sensitive to the existence of noise and outliers. A method of robust data modelling using thin plate splines, based upon the well-known least K-th order statistical model fitting, is proposed and compared with the best available robust spline fitting techniques. Our experiments show that existing methods are not suitable for typical computer vision applications where outliers are structured (pseudo-outliers) while the proposed method performs well even when there are numerous pseudo-outliers.	algorithm;computer vision;curve fitting;data modeling;experiment;image registration;interpolation;iterative method;smoothing spline;spline (mathematics);statistical model;synthetic data;thin plate spline;volumetric display;whole earth 'lectronic link	Ruwan B. Tennakoon;Alireza Bab-Hadiashar;David Suter;Zhenwei Cao	2013	2013 International Conference on Digital Image Computing: Techniques and Applications (DICTA)	10.1109/DICTA.2013.6691522	computer vision;econometrics;computer science;statistics;box spline	Vision	62.66794486032393	-43.04461530304104	34163
63042ee1ef82ddc97c6097f6b25c45cbd0825fc4	global illumination via density estimation	simple module;density estimation;global illumination	 This paper presents a new method for the production of view-independent global illuminationsolutions of complex static environments. A key innovation of this new approachis its decomposition of the problem into a loosely coupled sequence of simple modules.This approach decouples the global energy transport computation from the constructionof the displayable shaded representation of the environment. This decoupling eliminatesmany constraints of previous global illuminationapproaches,... 	decimation (signal processing);global illumination;mathematical optimization;parallel computing;progressive refinement;radiosity (computer graphics);refinement (computing)	Peter Shirley;Bretton Wade;Philip M. Hubbard;David Zareski;Bruce Walter;Donald P. Greenberg	1995		10.1007/978-3-7091-9430-0_21	simple module;computer vision;density estimation;computer science;global illumination	Vision	66.083730095644	-49.624095500088835	34195
1faef6a2069e4ac332c9da4ddd30cea28086a99f	adaptive non-stationary kernel regression for terrain modeling	yield prediction;kernel regression;path planning;gaussian process regression;three dimensional;digital terrain model;local adaptation;terrain modeling;covariance function	Three-dimensional digital terrain models are of fundamental importance in many areas such as the geo-sciences and outdoor robotics. Accurate modeling requires the ability to deal with a varying data density and to balance smoothing against the preservation of discontinuities. The latter is particularly important for robotics applications, as discontinuities that arise, for example, at steps, stairs, or building walls are important features for path planning or terrain segmentation tasks. In this paper, we present an extension of the well-established Gaussian process regression approach that utilizes non-stationa ry covariance functions to locally adapt to the structure of the terrain data. In this way, we achieve strong smoothing in flat areas and along edges and at the same time preserve edges and corners. The derived model yields predictive distributions for terrain elevations at arbitrary locations and thus allows to fill gaps in the data and to perform conservative predictions in occluded areas.	areal density (computer storage);digital elevation model;kriging;motion planning;robotics;smoothing;stationary process;whole earth 'lectronic link	Tobias Lang;Christian Plagemann;Wolfram Burgard	2007		10.15607/RSS.2007.III.011	kernel;principal component regression;three-dimensional space;kernel regression;digital elevation model;machine learning;pattern recognition;mathematics;motion planning;kriging;nonparametric regression;statistics;covariance function	Robotics	62.56665103204991	-44.955835636306254	34212
1aa4306a105221a54a5c760747c7bc7cdee6c805	ergonomic quadcopter control using the leap motion controller		In this paper, an ergonomic quadcopter control system for aircraft equipped with MAVLink compatible flight control unit is described. Our system is based on the broadly known Robotic Operating System (ROS) and the Leap Motion Controller. The users control the flight with specific hand gestures detected by the Leap Motion Controller, instead of using the original remote controller. The new control method was tested with a small number of users in an outdoor scenario, and this first round shows promising user feedbacks.	control system;control unit;feedback;human factors and ergonomics;mavlink;motion controller;operating system;remote control	Gergely Gubcsi;Tamas Zsedrovits	2018	2018 IEEE International Conference on Sensing, Communication and Networking (SECON Workshops)	10.1109/SECONW.2018.8396348	control theory;control unit;software;control engineering;motion controller;small number;quadcopter;computer science;control system	Robotics	61.63574139412605	-29.484839189600255	34258
98916adb4ca7425fd6b38788a96f50512c634b3a	quadrilateral meshing with directionality control through the packing of square cells	vector field	This paper proposes a computational method for fully automated quadrilateral meshing. Unlike previous methods, this new scheme can create a quadrilateral mesh whose directionality is precisely controlled. Given as input: (1) a 2D geometric domain, (2) a desired node spacing distribution as a scalar function deened over the domain, and (3) a desired mesh directionality as a vector eld deened over the domain, the proposed method rst packs square cells closely in the domain. The centers of the squares are then connected by Delaunay triangulation, yielding a triangular mesh topology. The triangular mesh is further converted into a quad-dominant mesh or an all-quad mesh that satisses the given mesh directionality. Since the closely packed square cells mimic a pattern of Voroni polygons corresponding to a well-shaped graded quadrilateral mesh, the proposed method generates a high quality mesh whose element sizes and mesh directionality conform well to the given input.	delaunay triangulation;display resolution;mesh networking;polygon mesh;set packing;types of mesh	Kenji Shimada;Jia-Huei Liao;Takayuki Itoh	1998			vector field;quadrilateral;geometry;mathematics	Visualization	69.37288010532971	-44.024892590922995	34260
411666a51255eb6662847f363d4edde7294a44e9	haptic teleoperation of multiple unmanned aerial vehicles over the internet	humans internet haptic interfaces kinematics collision avoidance trajectory master slave;kinematic virtual point;unmanned aerial vehicle;vp vp obstacle collision avoidance;mobile robots;remotely operated vehicles;multirobot systems;kinematics;multiple unmanned aerial vehicles;aerospace control;trajectory;internet;uav control layer;community networks;remote sensing;aerospace robotics;telecontrol;control engineering computing;humans;collision avoidance;haptic teleoperation;autonomous control;haptic interfaces;master slave;teleoperation layer;teleoperation layer haptic teleoperation multiple unmanned aerial vehicles internet uav control layer kinematic virtual point vp vp obstacle collision avoidance;telecontrol aerospace control aerospace robotics collision avoidance control engineering computing internet mobile robots remotely operated vehicles;haptic interface	We propose a novel haptic teleoperation control framework for multiple unmanned aerial vehicles (UAVs) over the Internet, consisting of the three control layers: 1) UAV control layer, where each UAV is abstracted by, and is controlled to follow the trajectory of, its own kinematic virtual point (VP); 2) VP control layer, which modulates each VP's motion according to the teleoperation commands and local artificial potentials (for inter-VP/VP-obstacle collision avoidance and inter-VP connectivity preservation); and 3) teleoperation layer, through which a remote human user can command all (or some) of the VPs' velocity while haptically perceiving the state of all (or some) of the UAVs over the Internet. Master-passivity/slave-stability and some asymptotic performance measures are proved. Semi-experiment results are presented to validate the theory.	aerial photography;experiment;haptic technology;internet;semiconductor industry;television;unmanned aerial vehicle;velocity (software development)	Dongjun Lee;Antonio Franchi;Paolo Robuffo Giordano;Hyoung Il Son;Heinrich H. Bülthoff	2011	2011 IEEE International Conference on Robotics and Automation	10.1109/ICRA.2011.5979993	remotely operated underwater vehicle;control engineering;mobile robot;embedded system;kinematics;master/slave;the internet;simulation;computer science;engineering;artificial intelligence;trajectory;haptic technology	Robotics	61.74664514906424	-27.495327434468006	34546
2f9b7e8ca1b0efd597785af26665f9d2c7a14d45	3-d modelling of buildings using high-level knowledge	object recognition;automated 3d modeling;solid modelling object recognition image reconstruction;high level constraints;application software;computer graphics;surface reconstruction techniques;surface roughness;computer graphics applications;layout;surface reconstruction;computer graphic;explicit knowledge;rough surfaces;semantic net;three dimensional displays surface reconstruction image reconstruction rough surfaces surface roughness layout application software cameras computer graphics buildings;explicit knowledge base;scene analysis system;three dimensional displays;image reconstruction;interpretation phase;high level knowledge;contour information high level knowledge scene analysis system automated 3d modeling object recognition surface reconstruction techniques computer graphics applications high level constraints explicit knowledge base semantic net interpretation phase;contour information;cameras;buildings;solid modelling;scene analysis	A scene analysis system for automated 3–D modeling of buildings is presented. It combines surface reconstruction techniques with object recognition to generate 3–D models for computer graphics applications. The system permits the insertion of high level constraints, like a specific angle between two house walls, in an explicit knowledge base as a semantic net. The applicability of those constraints is proved by asserting and testing hypotheses in an interpretation phase. In the case of rejection, a more general constraint or model is selected. The capabilities of the system were shown for the modeling of buildings using depth from stereo and contour information. The system reconstructs the surface of scene objects using constraints selected in the prior interpretation.	computer graphics;high-level programming language;knowledge base;outline of object recognition;rejection sampling;semantic network;stereoscopy	Oliver Grau	1998		10.1109/CGI.1998.694319	iterative reconstruction;layout;computer vision;application software;simulation;surface reconstruction;surface roughness;computer science;explicit knowledge;cognitive neuroscience of visual object recognition;computer graphics;computer graphics (images)	Vision	58.22097318040445	-45.78628784652183	34584
68e424646907200d2d2e02e6235b9ec2cfdef375	inter-vehicle sensor fusion for accurate vehicle localization supported by v2v and v2i communications	kalman filtering;lasers;nonlinear filters;global navigation satellite systems cognition lasers;road accidents;wheels driver information systems kalman filters multi agent systems nonlinear filters road accidents road traffic sensor fusion steering systems traffic engineering computing;road traffic;kalman filters;in vehicle sensors;data fusion;intervehicle absolute positioning data intervehicle sensor fusion vehicle localization cooperative driving system accident minimisation traffic congestion minimisation environmental cost road traffic traffic management system agent based traffic simulator automotive sensor vehicle to vehicle communication vehicle to infrastructure communication vehicle agent infrastructure agent multisensor localization algorithm vehicle positioning wheel encoder steering encoder ekf robust odometric information wheels slippage second fusion stage odometric absolute positioning data;multi agent systems;traffic congestion;vehicle to infrastructure communications;cognition;advanced traffic management systems;global navigation satellite systems;vehicle to vehicle communications;crashes;traffic engineering computing;sensor fusion;driver information systems;wheels;steering systems	Cooperative driving system techniques aim to minimize accidents, traffic congestion and consequently the environmental costs of road traffic. An accurate vehicle's pose is of extreme importance for the inner working of the traffic management systems. An agent based traffic simulator was developed integrating typical automotive sensors, vehicle-to-vehicle (V2V) and vehicle-to-infrastructure (V2I) communications, vehicle's agent and infrastructure agent. In this paper, we propose to further enhance a multi-sensor localization algorithm in environments where V2V and V2I communication is possible. This paper describes an inter-vehicle sensor fusion for an accurate vehicle positioning, where each vehicle is modeled by an agent, and each agent provides information depending on its vehicle sensors. In the first fusion stage, data from four wheel encoders and one steering encoder are fused by means of an EKF, providing robust odometric information, namely in face of undesirable effects of wheels slippage. Next, a second fusion stage is processed for integrating odometric and inter-vehicle absolute positioning data.	agent-based model;algorithm;approximation algorithm;encoder;extended kalman filter;global positioning system;inertial navigation system;lattice problem;microsoft research;network congestion;odometry;sensor;simulation;synchronization (computer science);vehicle-to-vehicle;wheels	Luís Conde Bento;Ricardo Parafita;Urbano Nunes	2012	2012 15th International IEEE Conference on Intelligent Transportation Systems	10.1109/ITSC.2012.6338889	simulation;engineering;automotive engineering;transport engineering	Robotics	54.61616634144691	-32.17245162428998	34610
67774417c50722d38df0face7a1e4b5607e4eec2	adaptive feature-preserving non-local denoising of static and time-varying range data	time varying;range data;non local filtering;region based filtering;anisotropy;structured light;time varying geometry;feature preservation;denoising;similarity measure;noise removal	We present a new method for noise removal on static and time-varying range data. Our approach predicts the restored position of a perturbed vertex using similar vertices in its neighborhood. It defines the required similarity measure in a new non-local fashion which compares regions of the surface instead of point pairs. This allows our algorithm to obtain a more accurate denoising result than previous state-of-the-art approaches and, at the same time, to better preserve fine features of the surface. Another interesting component of our method is that the neighborhood size is not constant over the surface but adapted close to the boundaries which improves the denoising performance in those regions of the dataset. Furthermore, our approach is easy to implement, effective, and flexibly applicable to different types of scanned data. We demonstrate this on several static and interesting new time-varying datasets obtained using laser and structured light scanners.	noise reduction	Oliver Schall;Alexander G. Belyaev;Hans-Peter Seidel	2008	Computer-Aided Design	10.1016/j.cad.2008.01.011	computer vision;mathematical optimization;structured light;computer science;machine learning;noise reduction;mathematics;anisotropy	EDA	68.43691227528174	-44.614618240601025	34659
2e924103f206ad6fd99147bb5b9bfc6ac215503d	airborne three-dimensional cloud tomography	clouds scattering atmospheric modeling three dimensional displays tomography mathematical model computational modeling;remote sensing clouds computerised tomography geophysical image processing light scattering radiative transfer;volumetric recovery airborne three dimensional cloud tomography scatterers 3d volumetric distribution water droplets computational tomography passive multiangular imagery light matter interaction 3d radiative transfer equation forward model	We seek to sense the three dimensional (3D) volumetric distribution of scatterers in a heterogenous medium. An important case study for such a medium is the atmosphere. Atmospheric contents and their role in Earth's radiation balance have significant uncertainties with regards to scattering components: aerosols and clouds. Clouds, made of water droplets, also lead to local effects as precipitation and shadows. Our sensing approach is computational tomography using passive multi-angular imagery. For light-matter interaction that accounts for multiple-scattering, we use the 3D radiative transfer equation as a forward model. Volumetric recovery by inverting this model suffers from a computational bottleneck on large scales, which include many unknowns. Steps taken make this tomography tractable, without approximating the scattering order or angle range.	3d film;airborne ranger;amazon simple storage service;angularjs;approximation algorithm;bean scripting framework;cobham's thesis;computer vision;daylight;decision problem;image formation;intel matrix raid;louis rosenfeld;online codes;storage module device;tomography;uncontrolled format string;waist-to-height ratio	Aviad Levis;Yoav Y. Schechner;Amit Aides;Anthony B. Davis	2015	2015 IEEE International Conference on Computer Vision (ICCV)	10.1109/ICCV.2015.386	radiative transfer	Vision	60.66375914860489	-51.77443569761554	34664
846985982d86768102081bdc8a466609591b634c	autonomous uav surveillance in complex urban environments	cybernetics;urban environment;art;surveillance;path planning;unmanned aerial vehicles surveillance intelligent agent cameras intelligent sensors conferences cybernetics art traveling salesman problems testing;testing;three dimensional;intelligent agent;uavs;occlusions surveillance coordination uavs;traveling salesman problems;art gallery problem;unmanned aerial vehicles;occlusions;intelligent sensors;cameras;conferences;coordination	We address the problem of multi-UAV-based surveillance in complex urban environments with occlusions. The problem consists of controlling the flight of UAVs with on-board cameras so that the coverage and recency of the information about the designated area is maximized. In contrast to the existing work, sensing constraints due to occlusions and UAV motion constraints are modeled realistically and taken into account. We propose a novel \emph{occlusion-aware} surveillance algorithm based on a decomposition of the surveillance problem into a variant of the 3D art gallery problem and an instance of traveling salesman problem for Dubins vehicles. The algorithm is evaluated on the high-fidelity \textsc{AgentFly} UAV simulation testbed which accurately models all constraints and effects involved. The results confirm the importance of occlusion-aware flight path planning, in particular in the case of narrow-street areas and low UAV flight altitudes.	algorithm;art gallery problem;motion planning;on-board data handling;simulation;testbed;travelling salesman problem;unmanned aerial vehicle	Eduard Semsch;Michal Jakob;Dusan Pavlícek;Michal Pechoucek	2009	2009 IEEE/WIC/ACM International Joint Conference on Web Intelligence and Intelligent Agent Technology	10.1109/WI-IAT.2009.132	three-dimensional space;computer vision;simulation;cybernetics;computer science;artificial intelligence;motion planning;software testing;art gallery problem;intelligent agent;intelligent sensor	Robotics	53.81612199686828	-26.90210180406757	34681
33ac3b642219e82f87eb0b6798c46e6a5adada85	fuzzy logic control strategy for functional electrical stimulation in bipedal cycling		This paper presents the development of a fuzzy logic control (FLC) strategy for rehabilitation cycling by using functional electrical stimulation (FES) applied on disabled knee extensors, to achieve a steady crank cadence. Two fuzzy logic (FL) controllers are used to apply stimulation to both left and right knee extensors to achieve the desired knee joint motion. To guarantee the smoothness of the cycling motion and also to enhance the performance of the cycling process, an assistant actuation is applied on the crank to obtain optimum stability of the crank cadence.	functional electrical stimulation;fuzzy logic;logic control	Rasha Massoud;M. Osman Tokhi;Samad Gharooni	2005		10.1007/3-540-26415-9_6	control engineering;artificial intelligence;control theory	Robotics	70.99278431577793	-27.294980799149425	34683
d94149c157fd830b37be3293be53579edc4c4685	an earthworm-inspired soft crawling robot controlled by friction		We present the design, fabrication, modeling and feedback control of an earthworm-inspired soft robot that crawls on flat surfaces by actively changing the frictional forces acting on its body. Earthworms are segmented and composed of repeating units called metameres. During crawling, muscles enable these metameres to interact with each other in order to generate peristaltic waves and retractable setae (bristles) produce variable traction. The proposed robot crawls by replicating these two mechanisms, employing pneumatically-powered soft actuators. Using the notion of controllable subspaces, we show that locomotion would be impossible for this robot in the absence of friction. Also, we present a method to generate feasible control inputs to achieve crawling, perform exhaustive numerical simulations of feedforward-controlled locomotion, and describe the synthesis and implementation of suitable real-time friction-based feedback controllers for crawling. The effectiveness of the proposed approach is demonstrated through analysis, simulations and locomotion experiments.		Joey Zaoyuan Ge;Ariel A. Calderon;Néstor Osvaldo Pérez-Arancibia	2017	2017 IEEE International Conference on Robotics and Biomimetics (ROBIO)	10.1109/ROBIO.2017.8324521	control theory;actuator;controllability;simulation;control engineering;robot;engineering;earthworm;robot kinematics;crawling	Robotics	67.89233945830497	-24.059751316560853	34685
c0b80bbe44686f96d514ac4298af2cbba1ada167	network-based intelligent space approach for car-like mobile robots by fuzzy decentralized variable structure control	ccd camera;network based intelligent space;translation velocity;wireless local area network;network based intelligent space approach;online planning reference command network based intelligent space approach car like mobile robots fuzzy decentralized variable structure control trajectory tracking obstacle avoidance distributed charge coupled device cameras steering angle translation velocity internet network wireless local area network quality of service;mobile robot;car like mobile robots;fuzzy control;mobile robots;variable structure systems;car like mobile robot;online planning reference command;distributed charge coupled device cameras;ccd image sensors;wireless lan ccd image sensors collision avoidance control engineering computing decentralised control fuzzy control internet mobile robots variable structure systems;upper bound;internet;decentralised control;obstacle avoidance;mathematical model;variable structure control;internet network;control engineering computing;fuzzy decentralized variable structure control network based intelligent space car like mobile robot trajectory tracking obstacle avoidance;charged couple device;collision avoidance;wireless lan;trajectory tracking;steering angle;quality of service;fuzzy decentralized variable structure control;intelligent networks intelligent robots intelligent structures mobile robots fuzzy control wireless lan charge coupled devices robot vision systems charge coupled image sensors cameras	To realize trajectory tracking and obstacle avoidance, two distributed CCD (charge-coupled device) cameras are constructed to obtain the dynamic poses of the car-like mobile robots (CLMRs) and the obstacles. Based on the control authority of these two CCD cameras, a suitable reference command including desired steering angle and translation velocity for the fuzzy decentralized variable structure control (FDVSC) in the client computer is on-line planned. Due to the delay of signal transmission through an internet network and wireless local area network (WLAN), suitable sampling time of the FDVSC is determined by the Quality of Service (QoS). The proposed control can track an on-line planning reference command without the requirement of a mathematical model of the CLMR. Only the information of the upper bound of system knowledge (including the dynamics of the CLMR, the delay feature of internet network and WLAN) is required to select the suitable scaling factors and the coefficients of switching surface so that an acceptable performance is achieved.	charge-coupled device;client (computing);coefficient;gadu-gadu;image scaling;mathematical model;mobile robot;normalization (image processing);obstacle avoidance;online and offline;quality of service;reflections of signals on conducting lines;sampling (signal processing);velocity (software development)	Chih-Lyang Hwang;Li-Jui Chang	2008	2008 IEEE International Conference on Robotics and Automation	10.1109/ROBOT.2008.4543494	control engineering;mobile robot;simulation;computer science;engineering;artificial intelligence;control theory;charge-coupled device;fuzzy control system	Robotics	60.44431488041399	-30.068416891369296	34741
723b3676b9309d5c46077f3767d14b003887f212	data processing of inertial sensors in strong-vibration environment	vibrations;vibrations aircraft filtering theory microsensors;ultra light aircraft data processing vibration inertial sensors;sensors finite impulse response filter iir filters delay vibrations aircraft filtering theory;inertial sensor based mems technology data processing strong vibration environment measurement unit navigation system ultralight aircraft atec 321 artificial horizon system angular rate sensing acceleration rate sensing data filtering;microsensors;filtering theory;aircraft	Data processing of low-cost inertial sensors has been and still is a big issue for many engineers in commercial companies, laboratories, and academia. Inertial sensors compose a measurement unit used as the basis of navigation systems. These systems can be found almost everywhere; it does not matter if it is in pharmaceutics, robotics, automotive industry, aerospace etc. However, there is always a need to specify under which conditions the systems are supposed to operate. This paper deals with the processing of inertial sensor data measured in an environment with strong vibrations on the ultra-light aircraft ATEC 321. It was a great challenge to process the data in such a way as to ensure the acceptable behavior of the artificial horizon system. Because the system should rely only on acceleration and angular rate sensing, the correctness and efficiency of data filtering as well as consecutive data processing play a key role. Results regarding data analyses and comparisons of different approaches are presented.	angularjs;attitude indicator;correctness (computer science);robotics;sensor	Jan Rohac;Michal Reinstein;Karel Draxler	2011	Proceedings of the 6th IEEE International Conference on Intelligent Data Acquisition and Advanced Computing Systems	10.1109/IDAACS.2011.6072713	simulation;electrical engineering;vibration;inertial navigation system	Robotics	56.53728776524983	-33.659926986523246	34765
4177ea564dc0e54beaba5b56896ef831c5859e74	an efficient approximation of arbitrary curves and surfaces using intersecting polylines and meshes	approximation error;curve;approximation;theoretical analysis;engineering software;surface;curves and surfaces;surface approximation	This paper presents an efficient method for approximating curves and surfaces. An idea is introduced using a circle, where an arc-intersecting polyline is used instead of the traditional inner-arc polyline. The approach is then generalized to arbitrary 2D curves. The method is extended into 3D, where the approximation of spherical surface is developed based on surface-intersecting facets. Finally, a method is described for approximating the general curved surface. Theoretical analysis and the experimental results showed that the new algorithm requires considerably less geometric data at the same approximation error than the traditional one.	approximation	Yong Kui Liu;Jian Yun;Xiao Niu Li;Borut Zalik	2008	Advances in Engineering Software	10.1016/j.advengsoft.2007.05.012	mathematical optimization;approximation error;combinatorics;approximation;mathematics;geometry;curve;surface	Robotics	69.62418136298918	-41.531846160364154	34848
8d88292dcbd06253057596ae853a3a507555c5ca	linear bellman combination for control of character animation	physically based animation;optimal control;physics based animation;character animation	Controllers are necessary for physically-based synthesis of character animation. However, creating controllers requires either manual tuning or expensive computer optimization. We introduce linear Bellman combination as a method for reusing existing controllers. Given a set of controllers for related tasks, this combination creates a controller that performs a new task. It naturally weights the contribution of each component controller by its relevance to the current state and goal of the system. We demonstrate that linear Bellman combination outperforms naive combination often succeeding where naive combination fails. Furthermore, this combination is provably optimal for a new task if the component controllers are also optimal for related tasks. We demonstrate the applicability of linear Bellman combination to interactive character control of stepping motions and acrobatic maneuvers.		Marco da Silva;Frédo Durand;Jovan Popovic	2009	ACM Trans. Graph.	10.1145/1531326.1531388	character animation;physically based animation;mathematical optimization;simulation;optimal control;computer science;machine learning;control theory;mathematics;algorithm;computer graphics (images)	Graphics	61.979865935564	-24.130892732523595	34851
8cc57bf0d11befbaba22f184ac263587b18e291c	design of algorithm for the 3d object representation based on the web3d using x3d	object representation;forma libre;modelizacion;free surface;surface libre;record format;representation graphique;modele geometrique;design of algorithms;realite virtuelle;realidad virtual;etat surface;format enregistrement;xml language;free form;polygone;distributed computing;virtual reality;surface reconstruction;data format;surface conditions;polygon;modelisation;reconstruction surface;forme libre;object oriented;polygonal meshes;estado superficie;superficie libre;grafo curva;poligono;calculo repartido;oriente objet;3d representation;formato grabacion;reconstruccion superficie;modeling;orientado objeto;calcul reparti;3d graphics;langage xml;lenguaje xml;graphics;geometrical model;modelo geometrico	The data volume of Web3D representation based on polygon meshes is so large that transferring practical data fast is a difficult problem. This paper proposes 3D object structure, a new framework for a compact 3D representation with high quality surface shape. By utilizing a free form surface technique, qualified surfaces are transferred with limited amount of data size and rendered. 3D graphic structure can be regarded as both polygon meshes and free form surfaces. Therefore, it can be easily integrated to existing Web3D data formats, for example VRML & XML. The 3D object’s structure also enables modeling free form surface shapes intuitively with polygon modeling like operations. In this paper, we propose and verify an algorithm on representation of 3D objects using X3D.	algorithm;web3d	Yun-bae Lee;Sung-Tae Lee;Gun-Tak Oh;Young-Kook Kim;Young-Ho Kim	2004		10.1007/978-3-540-30501-9_24	computer science;winged edge;polygon;distributed computing;virtual reality;programming language;algorithm;computer graphics (images)	ML	66.57966582265963	-41.59556701186042	34852
8f4ac4329a1a6cdedcffd331d55ca322044b4206	distributed lod algorithm for complex virtual environments		The method of level-of-detail (LoD) is effective in conquering complex models of virtual environments. In LoD each object has multiple models with different complexity. Depending on a set of decision criteria (like size and focus) an LoD algorithm analyses objects' importance and chooses a suitable LoD for each object. Here we present a distributed LoD algorithm which accurately decides the objects' importance. The algorithm uses a server to pre-display all objects and calculate their criteria by reading the image buffer. The idea behind this algorithm is to decide an object's importance according to its size, position and shape on the screen.		Wenwei Liu;Jintao Li	1996		10.1145/3304181.3304187		Visualization	62.41487066242743	-48.81846486967999	34873
d266603cda8a086ead0ff869876cd78aa1d096b1	a deformable surface model with volume preserving springs	mass spring system;mass spring systems;qa76 electronic computers computer science computer software;deformable surface model;deformable model;volume preservation	This paper discusses the possibility of employing a surface model to emulate volume behaviour. This is inspired by a significant interest in employing the surface data due to its simplicity. However, there are issues in properties estimation and volume preservation. Therefore, the aim of the ongoing research includes exploring the potential of a surface mass spring model with shape-preserving springs for volume simulation. Initial evaluations illustrate the feasibility of employing a mass spring model with volume preserving springs to simulate the dynamic behaviour of a soft volume. The proposed framework can be further explored to address other material properties.		Sylvester Arnab;Vinesh H. Raja	2008		10.1007/978-3-540-70517-8_25	simulation;computer science;artificial intelligence;effective mass;computer graphics (images)	Vision	70.81380450240094	-47.1373673020755	34875
f842696cb90693d58e47d96baedbab373ccb3bb0	quantitative analysis of the human upper-limp kinematic model for robot-based rehabilitation applications	manipulators;elbow;kinematics;estimation;shoulder;tracking	Upper-limb robotic rehabilitation systems should inform the therapists for their patients status. Such therapy systems must be developed carefully by taking into consideration real life uncertainties that associate with sensor error. In our paper, we describe a system which is composed of a depth camera that tracks the motion of the patients upper limb, and a robotic manipulator that challenges the patient with repetitive exercises. The goal of this study is to propose a motion analysis system that improves the readings of the depth camera, through the use of a kinematic model that describes the motion of the human arm. In our current experimental set-up we are using the Kinect v2 to capture a participant who performs rehabilitation exercises with the Barrett WAM robotic manipulator. Finally, we provide a numerical comparison among the stand alone measurements from the Kinect v2, the estimated motion parameters of our system and the VICON, which we consider as an error-free ground truth apparatus.	barrett reduction;ground truth;kinect;numerical analysis;real life;rehabilitation robotics;robot	Alexandros Lioulemes;Michail Theofanidis;Fillia Makedon	2016	2016 IEEE International Conference on Automation Science and Engineering (CASE)	10.1109/COASE.2016.7743521	computer vision;simulation;engineering;surgery	Robotics	58.383998756291966	-37.4407639558671	34908
bad83c4f44b9706279e8bbcb3129374cbdceac88	towards an application if intelligent image analysis system to robotic fettling of castings			image analysis	Boiko M. Balev;Dimitar P. Dimitrov	1992				Robotics	60.02832822751714	-42.28592185884509	34966
6c90d2498d529f8266b9ddb313b2829aedd6f624	angle of arrival geolocation using non-linear optimization	systematic error;measurement error;measurement uncertainty;triangulation;nonlinear programming;localization;probability density function;optimization;estimation;mesh generation;angle of arrival;measurement errors;accuracy;sensors;geolocation;nonlinear optics	This paper addresses the problem of object localization using only angle-of-arrival (AoA) data from satellites. Traditionally, this is performed by a triangulation algorithm (TA) that minimizes the distances between the estimated object location to all lines-of-sight representing measurements of the object. However, when observing objects from satellites, the differences in distance from each satellite to the object can be significant. The error this induces in measurements from farther-distant satellites results in an inordinate impact on the geo-location error. To overcome this problem, we introduce a non-linear optimization (NLO) approach that models the measurement error at each satellites as a probability density function. By finding the most-probable geo-location of the object, this systematic error is eliminated. We found that the NLO provides a more accurate estimate of the object's location than the TA in 93% of instances. In addition, we analyze the uncertainty estimates generated by both the TA and NLO approaches. The NLO estimates of uncertainty are also considerably more accurate than the TA estimates in all cases.	algorithm;angle of arrival;geolocation;linear programming;mathematical optimization;nonlinear programming;nonlinear system	Lee Burchett;Stephen Hartzell;Garrett Hoffar;Jonathan Mautz;Clark N. Taylor;Andrew J. Terzuoli	2012	2012 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2012.6350462	nonlinear optics;mesh generation;computer vision;mathematical optimization;estimation;nonlinear programming;sensor;accuracy and precision;statistics;measurement uncertainty;observational error	Embedded	54.39216246792852	-49.15991513179395	34967
17667ce25d8524fa3b87b68b4b3a1e6279ee04a3	on the validation of spdm task verification facility	international space station;mathematical model;hardware in the loop	This paper describes a methodology for validating a ground-based, hardware-in-theloop, space-robot simulation facility. This facility, called ‘‘SPDM task verification facility,’’ is being developed by the Canadian Space Agency for the purpose of verifying the contact dynamics performance of the special purpose dexterous manipulator (SPDM) performing various maintenance tasks on the International Space Station because the real SPDM cannot be physically tested for 3D operations on the ground due to the gravity. The facility uses a high-fidelity SPDM mathematical model, known as the ‘‘truth model’’ of the space robot, to drive a hydraulic robot to mimic the space robot performing contact operations. In this research different techniques were studied for practically verifying that the complex simulation facility preserves the dynamics of the truth model of the space robot for space-representative contact robotic tasks. Based upon the study and many years of experience in developing and verifying space robotic systems, a practical validation strategy including detailed test cases was developed along with a set of quantitative criteria for judging the validation test results. © 2004 Wiley Periodicals, Inc. • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • •		Ou Ma;Jiegao Wang;Sarthak Misra;Michael Liu	2004	J. Field Robotics	10.1002/rob.20011	control engineering;simulation;international space station;computer science;engineering;artificial intelligence;mathematical model;hardware-in-the-loop simulation	Robotics	60.329655012228486	-25.965735725925246	35050
8b18119baf99416df8e90d59eb4089d02ec666a6	accurate camera calibration with new minimizing function	lens distortion;virtual stereo calibration pattern;photogrammetry;3d space points;radial distortion;stereo image processing calibration cameras computer vision;camera calibration parameters;linear optimization parameter estimation;measurement system;light emitting diode;maximum likelihood estimation;satisfiability;computer vision;vision measurement system;nonlinear refinement;maximum likelihood estimate;minimizing function;stereo image processing;optical ray;cameras calibration optical distortion machine vision coordinate measuring machines nonlinear optics light emitting diodes nonlinear distortion computer vision pixel;infrared light emitting diode feature point;linear optimization;maximum likelihood estimation camera calibration lens distortion virtual stereo calibration pattern;parameter estimation;camera calibration;infrared;photogrammetry minimizing function vision measurement system camera calibration parameters virtual stereo calibration pattern infrared light emitting diode feature point radial distortion decentering distortion linear optimization parameter estimation nonlinear refinement 3d space points optical ray image points computer vision;calibration;cameras;decentering distortion;image points	Camera calibration has been studied extensively in computer vision and photogrammetry. But almost all the camera calibration techniques iterate with the general minimizing function by minimizing the discrepancy between the real position in pixels of a 2D image point and the calculated projection of the 3D object point on the image plane. Though the imaging distance errors are equal, the spatial anti-projection distance errors are not identical at different distance before the camera. As far as vision measurement system, its final object is to obtain the accurate space coordinate of the measured point. Theoretically, the space point should on the optical ray generated by its projection image point and the center of camera. To satisfy the special request of vision measurement system for camera calibration parameters, we present a valid camera calibration method based on new minimizing function using high precision virtual stereo calibration pattern, which is formed by moving an infrared light-emitting diode (IR LED) feature point with CMM on pre-defined paths. Radial distortion and decentering distortion are molded. The proposed technique consists of linear optimization parameter estimation and nonlinear refinement, which is carried out by minimizing the distance of all the 3D space points from the corresponding optical ray generated by their projections image points and the center of camera. Simulated data and real data are both shown that the calibration precision of the proposed method is better than that of the general minimizing the distance between the imaged points and the modeled projections. This method considerable reduces the distance of all the 3D space points from the corresponding optical ray generated from their projections image points and the center of camera, enhances the precision of camera calibration parameters, and improves the precision of the vision measurement system.	camera resectioning;capability maturity model;computer vision;diode;discrepancy function;distortion;estimation theory;image plane;iteration;linear programming;mathematical optimization;nonlinear system;object point;photogrammetry;pixel;radial (radio);rate–distortion optimization;refinement (computing);spatial anti-aliasing;system of measurement	Qiaoyu Xu;Dong Ye;Rensheng Che;Yan Huang	2006	2006 IEEE International Conference on Robotics and Biomimetics	10.1109/ROBIO.2006.340312	distortion;computer vision;camera auto-calibration;camera matrix;camera resectioning;linear programming;mathematics;maximum likelihood;optics;motion field;pinhole camera model;statistics;remote sensing	Vision	54.39968945079103	-49.6174522834383	35098
22e1454a7fb50f2729f3b8294a14584e88eed8ee	estimation of speech spectra from whispers	manuals;spectral difference;vocal tract;speech;spectrum;linear predictive;spectral estimation;speech manuals	The most obvious difference between normal and whispered speech is the excitation. However, there are other significant spectral differences between these two modes of speech. In particular, the formant locations are raised in whispers because of increased coupling between the vocal tract and the trachea. In addition, the noise excitation increases the variance of spectral estimates such as linear prediction. In order to reconstruct quality phonated speech from whispers, it is necessary to remove the bias in the formants and reduce the variance of spectrum. Methods for estimating the linear prediction spectrum from whispered speech are proposed. These include modification of the formants in the line spectrum domain and smoothing of the noisy linear prediction spectra.	smoothing;speech synthesis;tract (literature)	Robert W. Morris;Mark A. Clements	2002	2002 IEEE International Conference on Acoustics, Speech, and Signal Processing	10.1109/ICASSP.2002.5745577	vocal tract;spectrum;linear predictive coding;speech recognition;computer science;speech;mathematics;spectral density estimation	Vision	80.57789362858198	-34.162672273788196	35229
c2eade1a36262f9290475bcc1bfd65942b3e92ca	naturally convergent and optimal 3d surface mesh generation	automatic mesh generation;optimal solution;solution optimale;formation image tridimensionnelle;multimedia;modelo 3 dimensiones;3d imaging;generation automatique maille;agent based;modele 3 dimensions;three dimensional shape;generation maille;duality;three dimensional model;problema np duro;multimedia application;forma tridimensional;optimization problem;np hard problem;generacion automatica red;dualite;data storage;forme tridimensionnelle;triangulacion;probleme np difficile;solucion optima;data visualization;visualisation donnee;dualidad;triangulation;formacion imagen tridimensional;mesh generation	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	mesh generation;shebang (unix)	Hai Wei;David Y. Y. Yun	2002		10.1117/12.458794	mathematical optimization;mathematics;engineering drawing;algorithm	ML	65.91694503832359	-41.12542465385093	35246
eb33f45d19f99234c428b1d73b1c1cc4a389943f	degree, multiplicity, and inversion formulas for rational surfaces using u-resultants	fonction rationnelle;concepcion asistida;computer aided design;modele geometrique;geometrie solide;computer graphics;implementation;geometria solidos;parametrization;parametrizacion;superficie curva;algorithme;curved surface;algorithm;ejecucion;u resultante;conception assistee;rational surface;surface courbe;funcion racional;inversion formula;rational function;grafico computadora;infographie;solid geometry;parametrisation;geometrical model;algoritmo;modelo geometrico	Rational surface patches are popular in computer aided geometric design. But for any given rational parametrization, many questions arise: “Are there base points?”, “What is the degree of the surface?”, “How to do inversion?”, “Is the representation redundant?”, “Is a point exceptional?” These and many other problems can be solved in one stroke by using the u-resultant. With a computer algebra system, the implementation of our algorithms is straightforward. A method to speed up the computation is also provided.	resultant	Eng-Wee Chionh;Ron Goldman	1992	Computer Aided Geometric Design	10.1016/0167-8396(92)90009-E	parametrization;topology;computer aided design;solid geometry;calculus;mathematics;geometry	EDA	67.86544019675894	-40.189256383922945	35268
08c456e002ed44a2723c120fb78bb07104f812c1	a real-time markerless augmented reality framework based on slam technique		The most common way to perform Augmented Reality (AR) is to use markers to calibrate the camera pose, which enables later placement/projection of virtual content into the captured real scene accordingly. However, marker-based AR has an inherent drawback, i.e. the requirement of specific marker(s), which may limit the development of its applications. In contrast, markerless AR uses visual or depth information of the captured scene to estimate the camera pose, thus no special marker is needed for calibaration, nonetheless, requires higher computation complexity. In this work, we design a markerless AR framework that simultanesously considers mobility, accuracy, and computation complexity. The proposed AR framework can achieve real-time 3D environment reconstruction by using a mobile device equipped with a depth camera and Inertial Measurement Units (IMUs). We further design an AR game based on the Unity3D engine to validate the feasibility and accuracy of the proposed markerless AR framework, which successfully improves the game experience.	augmented reality;computation;mobile device;real-time clock;real-time transcription;unity	Chien-Wen Chen;Wen-Zheng Chen;Jain-Wei Peng;Bo-Xun Cheng;Tse-Yu Pan;Hsu-Chan Kuo	2017	2017 14th International Symposium on Pervasive Systems, Algorithms and Networks & 2017 11th International Conference on Frontier of Computer Science and Technology & 2017 Third International Symposium of Creative Computing (ISPAN-FCST-ISCC)	10.1109/ISPAN-FCST-ISCC.2017.87	computer vision;computation;augmented reality;mobile device;artificial intelligence;computer science	Visualization	53.872752864429906	-45.639394473208895	35406
bd9d4d70fc4458e4946ca4a9773eab9aed60f8d0	a study on clustering for anomalous signal detections from electromagnetic wave data	probability;statistical analysis earth crust earthquakes electromagnetic wave propagation geophysical techniques probability;hidden markov models ground penetrating radar geophysical measurement techniques earthquakes training data signal detection noise;hidden markov model;acceptance probability electromagnetic wave data anomalous signal radiation earth crust earthquake precursor extremely low frequency band false detection techniques hmm based anomalous signal detection amplitude density distribution electromagnetic wave signals;signal detection;electromagnetic wave propagation;earthquakes;amplitude density distribution;statistical analysis;signal detection electromagnetic wave hidden markov model extremely low frequency band amplitude density distribution;electromagnetic wave;extremely low frequency band;geophysical techniques;earth crust	Detection of an anomalous signal radiated from the earth's crust is useful for predicting the precursor of the earthquakes. Using the Extremely Low Frequency (ELF) band, we have observed the electromagnetic (EM) wave. Various methods for detection of an anomalous signal have been proposed. The known problems for those techniques are related to a false detection due to the limitation of training data for great earthquake. We proposed the HMM based anomalous signal detection whose training data are the amplitude density distribution extracted from normal EM wave signals. However, acceptance probability in this technique is not corresponded appropriately to a change of anomalous signal. In this paper, anomalous signal detection using amplitude density distribution calculated by short term signals to track a temporal change is proposed.	anomaly detection;cluster analysis;detection theory;hidden markov model;norm (social);sensor	Satoshi Urata;Hiroshi Yasukawa;Akitoshi Itai;Ichi Takumi	2012	2012 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2012.6352219	geophysics;seismology;electromagnetic radiation;wave propagation;probability;physics;hidden markov model;statistics;remote sensing;detection theory	Embedded	82.12528106282834	-42.37700140728127	35531
1039835a30010dc1fdaefea2ad43a40f283cbc6f	monaural speech/music source separation using discrete energy separation algorithm	circuit a signal mixte;traitement signal;time varying;frequency modulation;signal estimation;modulacion frecuencia;signal audio;modulation frequence;single channel source separation;localization;time frequency;audio signal;frequence instantanee;instantaneous frequency;localizacion;mixed signal circuit;senal vocal;algorithme;musical sound;algorithm;signal vocal;filtre variation temporelle;masquage;localisation;frecuencia instantanea;single channel;frequency modulated;enmascaramiento;signal processing;estimacion senal;separacion senal;estimacion parametro;signal acoustique;masking;time frequency masking;separation source;acoustic signal;time varying filters;synthetic data;parameter estimation;estimation parametre;methode domaine temps frequence;desa;son musical;circuito de senal mixto;vocal signal;source separation;procesamiento senal;estimation signal;metodo dominio tiempo frecuencia;senal acustica;senal audio;sonido musical;time frequency domain method;algoritmo	In this paper, we address the problem of monaural source separation of a mixed signal containing speech and music components. We use Discrete Energy Separation Algorithm (DESA) to estimate frequency-modulating (FM) signal energy. The FM signal energy is used to design a time-varying filter in the time-frequency domain for rejecting the interfering signal. The FM signal energy was chosen due to its good ability to differentiate between speech and music signals using localized information both in time and frequency. We present experimental results which demonstrate the advantages and limitations of the proposed method using synthetic data and real audio signals. Index Terms Single-channel source separation, instantaneous frequency, time-frequency masking, frequency modulation, DESA.	algorithm;audio editing software;computational complexity theory;energy level;experiment;fm broadcasting;fast fourier transform;frequency band;google map maker;information retrieval;instantaneous phase;internationalization and localization;mixed-signal integrated circuit;modulation;pitch (music);portable document format;real life;real-time clock;real-time computing;semi-supervised learning;semiconductor industry;signal processing;smoothing;software remastering;source separation;spectral leakage;speech enhancement;statistical model;synthetic data;time–frequency analysis;whole earth 'lectronic link	Yevgeni Litvin;Israel Cohen;Dan Chazan	2010	Signal Processing	10.1016/j.sigpro.2010.05.020	frequency modulation;instantaneous phase;speech recognition;time–frequency analysis;internationalization and localization;telecommunications;computer science;audio signal;signal processing;masking;speech processing;mathematics;blind signal separation;estimation theory;statistics;synthetic data	ML	81.01070425294252	-31.97611892539623	35576
9b4313005851a9288ad0421394209768e8054027	a new approach for determining the spectral data of multichannel harmonic signals in noise	spectral estimation	The problem of detecting and estimating the frequencies associated with harmonic signals in the presence of additive noise can be found in a wide variety of application areas. Some of these include radar, seismology, mechanical vibrations, climatology, and paleontology. In all of these areas the use of multichannel measurements or arrays of data sets is commonplace, so that multichannel estimation schemes are applicable. The vast majority of multichannel frequency estimation schemes attempt to extract this information directly from the power spectrum matrix associated with the observation (i.e., signal-plus-noise) process. Two of the most popular schemes are the multichannel periodogram and the multichannel autoregressive (AR) approach. The AR approach is the more recent and currently more popular of the two. It can be traced to results of Whittle [WI, Wiggins and Robinson [WR], Hannan [H3], Morf et al. [MVLK], and others. Even though it has potential for greater frequency resolution than the periodogram method, Marple [M] has noted that very sharp false spectral peaks can occur at relatively low AR model orders. This effect is in addition to the well-known spectral artifact caused by excessively high model orders.	additive white gaussian noise;autoregressive model;radar;sensor;spectral density estimation;stellar classification;utility functions on indivisible goods;whole earth 'lectronic link	C. Foias;Arthur E. Frazho;Peter J. Sherman	1990	MCSS	10.1007/BF02551354	mathematical optimization;electronic engineering;mathematics;spectral density estimation;statistics	Metrics	80.48133643558299	-40.770875210513154	35633
928a09b544aa24c1abc7485ff942c7dd4cc5c75a	optimal trajectory planning for a constrained functional electrical stimulation-based human walking	muscle activity;legged locomotion;trajectory planning;hip;dynamic model;muscle fatigue;joints;force;trajectory;hip joint;knee;algorithms electric stimulation therapy gait disorders neurologic humans leg muscle contraction muscle skeletal therapy computer assisted;tracking control;legged locomotion muscles knee hip joints force trajectory;functional electrical stimulation;optimal algorithm;able bodied;muscles	In contrast to the muscle recruitment during voluntary walking, only a limited number of muscles are activated during functional electrical stimulation (FES)-based walking. This implies that a trajectory designed or recorded from the normal human walking data may not be the best choice for tracking control. Another major challenge during FES-based walking is the rapid onset of muscle fatigue. Two methods to reduce fatigue during FES-based walking are employing an orthosis and minimizing muscle activations. To deal with these aforementioned challenges, this paper presents firstly a dynamic model representing FES-elicited walking constrained by an orthosis and a walker. Secondly, this paper deals with the design of optimal stimulation and force profiles (instead of gait-trajectories from able-bodied humans) that minimize muscle activations via FES and arm reaction forces from the walker. Ten walking steps are simulated to show the feasibility of the walking model and optimization algorithm.	amiga walker;chronic fatigue syndrome;functional electrical stimulation;mathematical model;mathematical optimization;muscle;onset (audio);orthotic devices;shin megami tensei: persona 3;walkers;algorithm	Nitin Sharma;Richard Stein	2011	2011 Annual International Conference of the IEEE Engineering in Medicine and Biology Society	10.1109/IEMBS.2011.6090134	physical medicine and rehabilitation;engineering;physical therapy;trajectory;force;physics;anatomy;quantum mechanics	Robotics	69.90744187196039	-28.27735035584685	35731
9c70d4c58ff141af2518449f4e39a4b51a99d22d	sequence-to-sequence model for trajectory planning of nonprehensile manipulation including contact model		Nonprehensile manipulation is necessary for robots to operate in humans’ daily lives. As nonprehensile manipulation should satisfy both kinematics and dynamics requirements simultaneously, it is difficult to manipulate objects along given paths. Previous studies have considered the problems with sequence-to-sequence models, which are neural networks for time-series conversion. However, they did not consider nonlinear contact models, such as friction models. When we train the seq2seq models using end-to-end backpropagation, training losses vanish owing to static friction. In this letter, we realize sequence-to-sequence models for trajectory planning of nonprehensile manipulation including contact models between the robots and target objects. This letter proposes a training curriculum that commences training without contact models to bring the seq2seq models outside of the gradient-vanishing zone. This letter discusses sliding manipulation, which includes a friction model between objects and tools, such as frying pans fixed onto the robots. We validated the proposed curriculum through a simulation. In addition, we observed that the trained seq2seq models could handle parameter fluctuations that did not exist during training.	artificial neural network;backpropagation;end-to-end principle;friction;gradient;neural network simulation;nonlinear system;physical object;population parameter;requirement;robot (device);time series	Kyo Kutsuzawa;Sho Sakaino;Toshiaki Tsuji	2018	IEEE Robotics and Automation Letters	10.1109/LRA.2018.2854958	control engineering;engineering;control theory;trajectory	Robotics	62.5559719724671	-24.49749601098092	35818
3c84e3091bb5389227ff2f5af9b228b597bad435	matrix and tensor-based approximation of 3d face animations from low-cost range sensors		Three-dimensional animation is often represented in the form of a sequence of 3D meshes, also called dynamic animation or Temporally Coherent Mesh Sequence (TCMS). Widespread availability of affordable range sensors makes capturing such data easy, however, its huge volume complicates both storage and further processing. One of the possible solutions is to approximate the data using matrix or tensor decomposition. However the quality the animation may have different impact on both approaches. In this work we use the Microsoft Kinect™ to crate sequences of human face models and compare the approximation error obtained from modelling animations using Principal component analysis (PCA) and Higher Order Singular Value Decomposition (HOSVD). We focus on distortion introduced by reconstruction of data from its truncated factorization. We show that while HOSVD may outperform PCA in terms of approximation error, it may be significantly affected by distortion in animation data.	approximation;sensor	Michal Romaszewski;Arkadiusz Sochan;Krzysztof Skabek	2018		10.1007/978-3-030-00840-6_26	tensor;higher-order singular value decomposition;distributed computing;principal component analysis;animation;computer science;mathematical optimization;matrix (mathematics);factorization;distortion;approximation error	HCI	76.07451412798827	-47.18766412119529	35830
0b7f397c4a0e6a625af456a4459161897dee0ef1	wearable electromyography sensor based outdoor-indoor seamless pedestrian navigation using motion recognition method	ventilation electromyography global positioning system health and safety motion estimation radio receivers traffic engineering computing;radio receivers;electromyography legged locomotion muscles force global navigation satellite systems;legged locomotion;electromyography signal;motion estimation;force;outdoor indoor seamless navigation;motion recognition electromyography signal pedestrian dead reckoning outdoor indoor seamless navigation;motion recognition;pdr solution wearable electromyography sensor outdoor indoor seamless pedestrian navigation motion recognition method smart phone mobile user gnss self contained sensors gps receiver open sky environment sensor measurements digital compass ventilation facility health situation stride length estimation pedestrian dead reckoning;ventilation;global positioning system;health and safety;global navigation satellite systems;traffic engineering computing;electromyography;pedestrian dead reckoning;muscles	Navigation and position applications are now becoming standard built-in features in a smart phone. However, locating a mobile user in GNSS unfriendly and denied environments such as urban canyons and indoor environments ubiquitously is still a challenging task. Several self-contained sensors, such as accelerometer, digital compass, gyroscope and barometer, have been adapted as assistance augmentation technologies to a GPS receiver to make a seamless outdoor-indoor pedestrian navigation system. Since the indoor environment is more complex than an open-sky environment, such GNSS signal-degraded areas are typically also contaminated with disturbance sources that affect sensor measurements, a digital compass can be disturbed significantly by e.g. an elevator that bears magnetic perturbance. And a ventilation facility may cause inconsistencies in the barometer's measurements; not to mention that the indoor surrounding attenuates or blocks the GNSS signal. In this paper, a novel outdoor-indoor seamless solution for pedestrian navigation is introduced, which is based on Electromyography (EMG) sensors. The EMG sensor measures the electrical potentials generated by muscle contractions of human body. Therefore it is immune against the environment disturbance; moreover, it has potential capability to exploit the health situation of the pedestrian, since the EMG sensor has been applied on the biomedical field for decades. In the paper, five different motions are classified to estimate the stride length, including: walking horizontally, walking up along a slope, stepping upstairs/downstairs and standing still. The stride length estimation is based on a simple empirical module where fix stride length is donated to each classified motion. In order to evaluate the EMG-based pedestrian dead reckoning (PDR) solution developed in this study, an outdoor-indoor field test had been carried out in the Finnish Geodetic Institute. The test results demonstrated that the EMG-based PDR solutions are comparable to the commercial GPS stand-alone solutions for a period of 9 minutes outdoors, which is equivalent to a walking distance of 667 meters and also demonstrates its robustness for indoor navigation for a period of 3 minutes.	algorithm;canonical account;context awareness;course (navigation);dead reckoning;design review (u.s. government);electromyography;geodetic datum;global positioning system;gyroscope;satellite navigation;seamless3d;sensor;smartphone;stepping level;wearable technology	Yuwei Chen;Ruizhi Chen;Xiang Chen;Wei Chen;Qian Wang	2011	2011 International Conference on Indoor Positioning and Indoor Navigation	10.1109/IPIN.2011.6071913	embedded system;simulation;telecommunications;engineering	Mobile	57.12363369732491	-37.075552237788706	35840
5c20de6a4117a9cd8a87339be2908ab68d4928e5	locomotion control of a novel snake-like robot	mobile robots wheels motion control kinematics tracking computer simulation animals parallel robots spine lyapunov method;motion control;collision avoidance mobile robots motion control;mobile robots;nonholonomic constraint;collision avoidance;rough terrain;computer simulations locomotion control snake like robot dof omnidirectional mechanism grouping alternation motion control method composite motion method;computer simulation;control method	It is essential to design a joint mechanism for snake-like robots to exhibit more mobility, no singularity and powerful actuation for many applications. By adding a series of passive wheels to the perimeter of the newly designed joint mechanism with 3 DOFs, a snake-like robot provided with the characteristic of omnidirectional mechanism can traverse rough terrain and compensate the lack of actuation due to passive wheels. The nonholonomic constraints and kinematics are analyzed as well as the redundancy. The composite motion method and grouping alternation motion control method are thus proposed for the locomotion of robot and the avoidance of singularity. Also, the grouping alternation motion adds a new explanation to the sinus lifting locomotion of natural snake. Computer simulations validate both mobility of mechanism and effectiveness of control methods.	computer simulation;lambda lifting;lifting scheme;perimeter;robot;singularity project;traverse;wheels	Changlong Ye;Shugen Ma;Bin Li;Yuechao Wang	2004	2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) (IEEE Cat. No.04CH37566)	10.1109/IROS.2004.1389471	computer simulation;control engineering;motion control;mobile robot;simulation;computer science;engineering;artificial intelligence;robot locomotion;control theory;robot control	Robotics	68.15792735422981	-24.264755020570245	35859
8caefedc202f0eb9954fea8d205d534dd4116a30	interactive fluid-particle simulation using translating eulerian grids	moving object;paper;participating media;gpu computing;volume rendering;nvidia geforce gtx 285;real time;hardware accelerator;velocity field;cuda;interactive system;particle simulation;nvidia;fluid dynamics;fluid simulation;rendering	We describe an interactive system featuring fluid-driven animation that responds to moving objects. Our system includes a GPU-accelerated Eulerian fluid solver that is suited for real-time use because it is unconditionally stable, takes constant calculation time per frame, and provides good visual fidelity. We dynamically translate the fluid simulation domain to track a user-controlled object. The fluid motion is visualized via its effects on particles which respond to the calculated fluid velocity field, but which are not constrained to stay within the bounds of the simulation domain. As particles leave the simulation domain, they seamlessly transition to purely particle-based motion, obscuring the point at which the fluid simulation ends. We additionally describe a hardware-accelerated volume rendering system that treats the particles as participating media and can render effects such as smoke, dust, or mist. Taken together, these components can be used to add fluid-driven effects to an interactive system without enforcing constraints on user motion, and without visual artifacts resulting from the finite extents of Eulerian fluid simulation methods.	computational fluid dynamics;fluid animation;graphics processing unit;hardware acceleration;interactivity;lagrangian and eulerian specification of the flow field;lagrangian–eulerian advection;real-time clock;rendering (computer graphics);simulation;solver;velocity (software development);visual artifact;volume rendering	Jonathan M. Cohen;Sarah Tariq;Simon Green	2010		10.1145/1730804.1730807	fluid simulation;vector field;simulation;hardware acceleration;computer hardware;rendering;computer science;volume rendering;general-purpose computing on graphics processing units;computer graphics (images);fluid dynamics	Graphics	70.55181781038716	-48.65096349215581	35907
3121a5d3fcecab28832b1ceab4f39bd34ec616c2	configuration analysis of the ers points in large-volume metrology system	biological patents;biomedical journals;text mining;europe pubmed central;large volume metrology;citation search;configuration of the ers points;aircraft assembly;citation networks;research articles;abstracts;open access;layout of the ers points;life sciences;clinical guidelines;full text;transformation matrix errors;rest apis;orcids;europe pmc;biomedical research;bioinformatics;literature search	In aircraft assembly, multiple laser trackers are used simultaneously to measure large-scale aircraft components. To combine the independent measurements, the transformation matrices between the laser trackers' coordinate systems and the assembly coordinate system are calculated, by measuring the enhanced referring system (ERS) points. This article aims to understand the influence of the configuration of the ERS points that affect the transformation matrix errors, and then optimize the deployment of the ERS points to reduce the transformation matrix errors. To optimize the deployment of the ERS points, an explicit model is derived to estimate the transformation matrix errors. The estimation model is verified by the experiment implemented in the factory floor. Based on the proposed model, a group of sensitivity coefficients are derived to evaluate the quality of the configuration of the ERS points, and then several typical configurations of the ERS points are analyzed in detail with the sensitivity coefficients. Finally general guidance is established to instruct the deployment of the ERS points in the aspects of the layout, the volume size and the number of the ERS points, as well as the position and orientation of the assembly coordinate system.	amelogenesis imperfecta nephrocalcinosis;coefficient;deploy;extended rotated sidebent;laser tracker;mathematical model;population parameter;transformation matrix	Zhangjun Jin;Cijun Yu;Jiangxiong Li;Yinglin Ke	2015		10.3390/s150924397	text mining;medical research;simulation;telecommunications;computer science;bioinformatics;engineering;electrical engineering;data mining;remote sensing	Robotics	60.53111708473964	-36.65360695731709	35909
07286aff45767ac3096edbf4cafa1fbeca2d1b63	joint dereverberation and residual echo suppression of speech signals in noisy environments	background noise;chambre reverberante;microphones;nivel ruido;traitement signal;acoustic devices;reverberation;reverberation time;microphone acoustic echo canceller;speech intelligibility;beneficial use;sistema mano libre;residual echo suppression acoustic echo cancellation aec dereverberation;speech processing;working environment noise;hand free system;tiempo reverberacion;niveau bruit;loudspeaker;acoustic signal processing;microfono;suppression echo;dereverberation;acoustic echo path;signal interference;residual echo suppression;speech enhancement;statistical reverberation model joint dereverberation residual echo suppression speech signals microphone acoustic echo canceller room reverberation acoustic coupling speech intelligibility spectral variance estimator acoustic echo path adaptive filter;statistical model;statistical reverberation model;joint dereverberation;senal vocal;reduccion ruido;inteligibilidad;signal vocal;interference signal;adaptive filters;noise level;working environment noise reverberation background noise microphones speech enhancement echo cancellers adaptive filters acoustic noise echo interference acoustic devices;spectral variance estimator;loudspeakers;temps reverberation;haut parleur;noise source;signal processing;acoustic noise;noise reduction;source bruit;systeme mains libres;speech signals;camara reverberante;reduction bruit;bruit acoustique;modele statistique;echo interference;acoustic coupling;filtro adaptable;signal acoustique;echo suppression;ruido fondo;altoparlante;modelo estadistico;acoustic signal;traitement signal acoustique;room reverberation;variance estimation;speech processing adaptive filters echo suppression loudspeakers microphones reverberation speech intelligibility;fuente ruido;filtre adaptatif;vocal signal;bruit fond;echo cancellers;intelligibilite;procesamiento senal;intelligibility;adaptive filter;senal acustica;acoustic echo cancellation aec;acoustic echo canceller;reverberation room;microphone	Hands-free devices are often used in a noisy and reverberant environment. Therefore, the received microphone signal does not only contain the desired near-end speech signal but also interferences such as room reverberation that is caused by the near-end source, background noise and a far-end echo signal that results from the acoustic coupling between the loudspeaker and the microphone. These interferences degrade the fidelity and intelligibility of near-end speech. In the last two decades, post filters have been developed that can be used in conjunction with a single microphone acoustic echo canceller to enhance the near-end speech. In previous works, spectral enhancement techniques have been used to suppress residual echo and background noise for single microphone acoustic echo cancellers. However, dereverberation of the near-end speech was not addressed in this context. Recently, practically feasible spectral enhancement techniques to suppress reverberation have emerged. In this paper, we derive a novel spectral variance estimator for the late reverberation of the near-end speech. Residual echo will be present at the output of the acoustic echo canceller when the acoustic echo path cannot be completely modeled by the adaptive filter. A spectral variance estimator for the so-called late residual echo that results from the deficient length of the adaptive filter is derived. Both estimators are based on a statistical reverberation model. The model parameters depend on the reverberation time of the room, which can be obtained using the estimated acoustic echo path. A novel postfilter is developed which suppresses late reverberation of the near-end speech, residual echo and background noise, and maintains a constant residual background noise level. Experimental results demonstrate the beneficial use of the developed system for reducing reverberation, residual echo, and background noise.	acoustic coupler;acoustic cryptanalysis;adaptive filter;echo (computing);echo suppression and cancellation;edge enhancement;intelligibility (philosophy);loudspeaker;microphone;noise (electronics);zero suppression	Emanuel A. P. Habets;Sharon Gannot;Israel Cohen;P. Sommen	2008	IEEE Transactions on Audio, Speech, and Language Processing	10.1109/TASL.2008.2002071	loudspeaker;adaptive filter;speech recognition;acoustics;computer science;signal processing;speech processing;intelligibility	Vision	81.44498749400599	-32.19896845901917	35915
5ab82dce0e85dd83550369047c543c58bf6d03dd	representing concave objects using virtual images	virtual image;concave object;spatial reasoning	Recent research in the design of image database systems emphasizes the necessity of defining an indexing methodology which is not based on form features but rather on invariant numerical, topological or geometrical characteristics of the images. In this paper, we concentrate on the spatial data and relationships which represent the most important method for recognizing images. In particular, we focus on iconic indexing methodologies based on order theory and symbolic projections and we address the problem of ambiguity arising from the description of concave objects with these representations. Towards this end, we extend the cutting mechanism of the 2D C-string iconic index to perform cutting lines whenever a concave point (split point) might lead to ambiguity during the reconstruction process. The iconic index obtained according to this set of rules can be managed by the Atomic Relation Extraction Method to derive the corresponding virtual images which represent the normalized pictorial information.	concave function	Timothy Arndt;Gennaro Petraglia;Monica Sebillo;Genny Tortora	1995			computer vision;theoretical computer science;data mining;mathematics	Vision	64.4562945703775	-41.97957732385089	35926
cb76bb923ce50bc954314796fa7c74f0591aac18	a pc-based orientation sensing using 9-dof strapdown inertial measurement unit	gradient decent algorithm 9 dof strapdown inertial measurement unit pc based orientation sensing system 9 degree of freedom simu 3 dof gyroscope 3 dof accelerometer 3 dof magnetometer data fusion measurement accuracy improvement orientation measurement kalman filter;gyroscopes;kalman filters;magnetometers;sensor fusion accelerometers computerised instrumentation gradient methods gyroscopes kalman filters magnetometers position measurement;position measurement;gradient methods;computerised instrumentation;sensor fusion;accelerometers kalman filters equations gyroscopes position measurement magnetic field measurement magnetometers;accelerometers;magnetometer inertial measurement unit sensor fusion accelerometer gyroscope	This paper presents the design and development of a PC-based orientation sensing system using strapdown inertial measurement unit (SIMU). A 9-DOF (degree of freedom) SIMU, which consists of 3-DOF gyroscopes, 3-DOF accelerometers, and 3-DOF magnetometers, are used to estimate the orientation. Data fusion is performed to improve measurement accuracy. In this paper, the orientation measurements are compared and discussed using three different approaches, known as the conventional accelerometer/gyroscope approach, the Kalman filter based 9-DOF SIMU approach, and the gradient decent algorithm based 9-DOF SIMU approach. The derivation of each approach together with the design of the PC-based orientation sensing system is outlined in this paper.	algorithm;gradient;graphical user interface;gyroscope;image processing;kalman filter;system testing	Lim Chot Hun;Tien Sze Lim;Voon Chet Koo	2012	2012 12th International Conference on Control Automation Robotics & Vision (ICARCV)	10.1109/ICARCV.2012.6485163	kalman filter;control engineering;inertial measurement unit;computer vision;inertial reference unit;magnetometer;gyroscope;geodesy;computer science;engineering;machine learning;control theory;sensor fusion;accelerometer;quantum mechanics	Robotics	57.39093317278307	-35.808922197096365	35964
f5abb9490ec914f6cddadc46a8f57304bed524c1	"""design of the """"army-ant"""" cooperative lifting robot"""	physical tasks;robot sensing systems;group actions;group action;performance evaluation;design and development;computerised control;mobile robot;coordinated team;cooperative decisions;group dynamical behavior army ant cooperative lifting robot homogeneous team group actions physical tasks cooperative decisions coordinated team;mobile robots;group dynamic;army ant cooperative lifting robot;cooperative systems;materials handling;material storage;homogeneous team;group dynamical behavior;cranes;robotic assembly;payloads;computerised control mobile robots cooperative systems materials handling;robotics and automation;robot kinematics;robot kinematics robotics and automation robot sensing systems payloads mobile robots robotic assembly cranes material storage materials handling performance evaluation	"""This paper describes the design and development of a new class of mobile robot. These small robots are intended to be simple and inexpensive, and will all be physically identical, thus constituting a homogeneous team of robots. They derive their usefulness from their group actions, performing physical tasks and making cooperative decisions as a coordinated team. All mechanical and electrical design aspects are decided with the group-dynamical behavior in mind. Because of their behavioral resemblance to their insect counterparts, they have been named """"army ant"""" robots. >"""	lambda lifting;robot	John S. Bay	1995	IEEE Robot. Automat. Mag.	10.1109/100.388293	control engineering;mobile robot;simulation;computer science;engineering;artificial intelligence;group action	Robotics	65.07321834292617	-26.503786550573203	36008
6d69dff044ae1bae3991640684bdb11cce428f03	road selection using multicriteria fusion for the road-matching problem	differential global positioning system receiver;multicriteria analysis;belief;navegacion informacion;belief function;brake;systeme information geographique;freno;digital roadmap road selection multicriteria fusion road matching advanced driving assistance systems belief theory antilock brake system sensors differential global positioning system receiver;geographic information system;belief theory;ada;traffic engineering computing automated highways brakes global positioning system road traffic;navigation information;road traffic;real time;localization;systeme gps;advanced driving assistance systems;information browsing;automated highways;reference frame;global position system;geographic information sys tem;kalman filter;fusion capteur;localizacion;data fusion;indexing terms;global positioning system databases navigation intelligent transportation systems road vehicles remotely operated vehicles automatic control design methodology velocity measurement particle measurements;gps system;navigational aid;global positioning system gps;user assistance;captador medida;relative error;measurement sensor;capteur mesure;localisation;croyance;assistance utilisateur;global positioning system;geographic information systems;fusion donnee;theory;antilock braking system;temps reel;asistencia usuario;frein;brakes;route choice;geographical information system gis;tiempo real;aide navigation;differential global positioning system;traffic engineering computing;road matching;analisis multicriterio;sensor fusion belief theory geographical information system gis global positioning system gps localization;analyse multicritere;digital roadmap;sensor fusion;creencia;ada language;ayuda navegacion;fusion datos;radiolocalizacion;radiolocalisation;road selection;sistema informacion geografica;driver support systems;sistema gps;antilock brake system sensors;multicriteria fusion;matching method	This paper presents a road selection strategy for novel road-matching methods that are designed to support real-time navigational features within Advanced Driving-Assistance Systems (ADAS). Selecting the most likely segment(s) is a crucial issue for the road-matching problem. The selection strategy merges several criteria using Belief theory. Particular attention is given to the development of belief functions from measurements and estimations of relative distances, headings, and velocities. Experimental results using data from antilock brake system sensors, the differential Global Positioning System receiver, and the accurate digital roadmap illustrate the performances of this approach, particularly in ambiguous situations	architecture design and assessment system;global positioning system;matching (graph theory);performance;real-time transcription;sensor	Maan El Badaoui El Najjar;Philippe Bonnifait	2007	IEEE Transactions on Intelligent Transportation Systems	10.1109/TITS.2007.895312	computer vision;simulation;global positioning system;computer science;engineering;sensor fusion;transport engineering;geographic information system;brake	Robotics	56.51233136876601	-32.928634246840026	36066
0cbe386d4d3048f8c8cb5f99d2456d92fd908068	calligraphic packing	non photorealistic rendering;mosaics;packing;tilings;calligraphy	"""There are many algorithms in non-photorealistic rendering for representing an image as a composition of small objects. In this paper, we focus on the specific case where the objects to be assembled into a composition are letters rather than images or abstract geometric forms. We develop a solution to the """"calligraphic packing"""" problem based on dividing up a target region into pieces and warping a letter into each piece. We define an energy function that chooses a warp that best represents the original letter. We discuss variations in rendering style and show results produced by our system."""	algorithm;image;mathematical optimization;non-photorealistic rendering;set packing;unbiased rendering	Jie Xu;Craig S. Kaplan	2007		10.1145/1268517.1268527	mosaic;calligraphy;non-photorealistic rendering;computer graphics (images)	Graphics	64.83512068032542	-47.307757373642985	36131
2d3e094b874c302d2fb1d17343417eae3baaddc8	improved quantum-inspired genetic algorithm based time-frequency analysis of radar emitter signals	atomic decomposition;linear frequency modulation;time frequency;phase shift;quantum inspired genetic algorithm;genetic algorithm;radar emitter signal;feature analysis;time frequency analysis;time frequency atom decomposition	This paper uses an improved quantum-inspired genetic algorithm (IQGA) based time-frequency atom decomposition to analyze the construction of radar emitter signals. With time-frequency atoms containing the detailed characteristics of a signal, this method is able to extract specific information from radar emitter signals. As IQGA has good global search capability and rapid convergence, this method can obtain time-frequency atoms of radar emitter signals in a short span of time. Binary phase shift-key radar emitter signal and linear-frequency modulated radar emitter signal are taken for examples to analyze the structure of decomposed time-frequency atoms and to discuss the difference between the two signals. Experimental results show the huge potential of extracting fingerprint features of radar emitter signals.	frequency analysis;genetic algorithm;quantum;radar	Gexiang Zhang;Haina Rong	2007		10.1007/978-3-540-72458-2_60	time–frequency analysis;computer science;pulse-doppler radar	EDA	82.38328340037621	-40.6815225946382	36171
4e72dfbff8ac59ff54140c449369f050e2c48042	exploring the world through grasping: a developmental approach	grasping skills;robot sensing systems;humanoid robot;control systems;humanoid robotics;cognitive systems humanoid robotics development;cognitive systems;cognitive robotics;development;explorative behavior;geometry;computational geometry;motor competencies;network address translation;sensorimotor coordination;bootstrap learning;physics;control system;humanoid robots;cognition;system testing;external environment;learning artificial intelligence;cognitive systems humanoid robots learning artificial intelligence;robot kinematics humanoid robots robot sensing systems cognitive robotics cognition control systems network address translation physics computational geometry system testing;developmental path;cognitive artificial system;perceptual competencies;visual routine;robot kinematics;cognitive artificial system grasping skills humanoid robot perceptual competencies motor competencies bootstrap learning external environment sensorimotor coordination control system explorative behavior visual routine developmental path physics geometry	This paper is about the implementation of grasping skills in a humanoid robot. Following a developmental approach, the robot is initially equipped with little perceptual and motor competencies whose role is to bootstrap learning through the exploration of the external environment. This crude form of sensorimotor coordination consists of a set of control systems and explorative behaviors as well as simple visual routines. The developmental path leads the robot from the exploration of the physics and geometry of its body to the probing of the external environment. The robot experience builds and modifies continuously its internal representations of the environment, being this, its body or the objects it encounters. We discuss the implications of our approach to the study of cognition and our effort to build a cognitive artificial system.	cognition;control system;humanoid robot	Lorenzo Natale;Francesco Orabona;Giorgio Metta;Giulio Sandini	2005	2005 International Symposium on Computational Intelligence in Robotics and Automation	10.1109/CIRA.2005.1554336	robot learning;simulation;computer science;control system;humanoid robot;artificial intelligence;social robot	Robotics	62.15738693684131	-25.935950796337718	36178
fcb91be2d9acb6572488c0d5b03ce6d9507cc443	a cooperative approach to multiple uavs searching for moving targets based on a hybrid of virtual force and receding horizon	uav;uncertainty;vfrh;path planning;virtual reality;mobile robots;cooperative search;receding horizon;force;virtual force;force search problems uncertainty mathematical model path planning algorithm design and analysis optimization;aerospace computing;vfrh uav cooperative search virtual force receding horizon;mathematical model;telerobotics;optimization;search problems;autonomous aerial vehicles;algorithm design and analysis;virtual reality aerospace computing autonomous aerial vehicles military computing mobile robots telerobotics;military computing;battlefield applications cooperative approach multiple uav searching receding horizon hybrid method vfrh virtual force method horizon method	This paper addresses the problem of multiple Unmanned Aerial Vehicles (UAVs) cooperative searching for several moving targets with a hybrid method, which is named VFRH. This method is a combination of the virtual force method and the receding horizon method. Its main idea is that the virtual force method is used to help the receding horizon method improve searching efficiencies and reduce the computational burdens. The cooperative tactics based on VFRH is subsequently proposed to make the search more effective for multiple UAVs. At last, performance of multi-UAV cooperatively searching for hidden targets based on VFRH shows the promising results.	algorithm;computation;computer simulation;motion planning;unmanned aerial vehicle	Xiao Xiao;Zhuoning Dong;Jiang Wu;Haibin Duan	2012	IEEE 10th International Conference on Industrial Informatics	10.1109/INDIN.2012.6301188	control engineering;simulation;engineering;control theory	Robotics	56.02144152692674	-24.088752795968915	36304
c1187eabb0c66333c4db4e4cfacf89720685726d	hybrid data visualization based on depth complexity histogram analysis	i 3 7 computer graphics three dimensional graphics and realism i 3 8 computer graphics applications;computer and information science;scientific visualization;visualization;i 3 3 computer graphics picture image generation display algorithms;ray tracing;datavetenskap datalogi;computer science;data och informationsvetenskap;real time rendering;rendering	In many cases, only the combination of geometric and volumetric data sets is able to describe a single phenomenon under observation when visualizing large and complex data. When semi-transparent geometry is present, correct rendering results require sorting of transparent structures. Additional complexity is introduced as the contributions from volumetric data have to be partitioned according to the geometric objects in the scene. The A-buffer, an enhanced framebuffer with additional per-pixel information, has previously been introduced to deal with the complexity caused by transparent objects. In this paper, we present an optimized rendering algorithm for hybrid volume-geometry data based on the A-buffer concept. We propose two novel components for modern GPUs that tailor memory utilization to the depth complexity of individual pixels. The proposed components are compatible with modern A-buffer implementations and yield performance gains of up to eight times compared to existing approaches through reduced allocation and reuse of fast cache memory. We demonstrate the applicability of our approach and its performance with several examples from molecular biology, space weather, and medical visualization containing both, volumetric data and geometric structures.	a-buffer;algorithm;alpha compositing;cpu cache;computer graphics;data structure;data visualization;encode;framebuffer;graphics processing unit;hybrid drive;medical imaging;pixel;semiconductor industry;sorting	Stefan Lindholm;Martin Falk;Erik Sundén;Alexander Bock;Anders Ynnerman;Timo Ropinski	2015	Comput. Graph. Forum	10.1111/cgf.12460	ray tracing;computer vision;scientific visualization;image-based modeling and rendering;information visualization;visualization;3d rendering;rendering;computer science;theoretical computer science;parallel rendering;real-time computer graphics;real-time rendering;texture memory;computer graphics;alternate frame rendering;software rendering;3d computer graphics;computer graphics (images)	Visualization	67.92857937251924	-51.2133724500336	36309
9a1e9bb44c51bc16bdfd9dfbcbb9c10d3362d018	local injectivity conditions of 2d and 3d uniform cubic b-spline functions	image morphing;electrical capacitance tomography;spline;lattices;volume morphing;computer graphics;mapping functions;computational geometry;uniform cubic b spline functions;sufficient conditions;local injectivity conditions;splines mathematics;geometric interpretation;spline function;computational geometry splines mathematics image morphing;control point displacements;world wide web;computer science;control point displacements local injectivity conditions uniform cubic b spline functions mapping functions image warping image morphing 3d deformation volume morphing geometric interpretation;image warping;reactive power;3d deformation;spline lattices electrical capacitance tomography computer science reactive power computer graphics world wide web sufficient conditions	Uniform cubic B-spline functions have been used for mapping functions in various areas such as image warping and morphing, 3D deformation, and volume morphing. The injectivity (one-to-one property) of a mapping function is important to obtain good results in these areas. This paper considers the local injectivity conditions of 2D and 3D uniform cubic B-spline functions. We propose a geometric interpretation of the local injectivity of a uniform cubic Bspline function, with which 2D and 3D cases can be handled in a similar way. Based on the geometric interpretation, we present sufficient conditions for the local injectivity that are represented in terms of control point displacements. These sufficient conditions are simple and easy to check and will be useful to guarantee the injectivity of mapping functions in application areas.	b-spline;control point (mathematics);cubic function;displacement mapping;image warping;jacobian matrix and determinant;morphing;one-to-one (data model);spline (mathematics)	Yongchoel Choi;Seungyong Lee	1999		10.1109/PCCGA.1999.803374	spline;computer vision;mathematical optimization;computational geometry;computer science;mathematics;geometry	Graphics	68.80521057610281	-41.02597592163074	36341
4b580462856236c651ad8d52c5f77450f500c9c7	cm-pack'01: fast legged robot walking, robust localization, and team behaviors	robot movil;legged locomotion;localization;locomotion avec jambes;localizacion;ingenieria logiciel;software engineering;asynchronisation;computer vision;localisation;asynchronism;robot mobile;genie logiciel;completitud;vision ordinateur;completeness;completude;legged robot;asincronia;moving robot	CM-Pack’01 came in second place at RoboCup-2001 in the Sony Legged League. This is our fourth year competiting in this league. We used a simplified architecture this year. Our vision, localization, and behaviors ran synchronously with the camera input while our motions remained an asynchronous process. We focused on reducing latency and increasing timeliness and completeness of environment modelling for this year. We used more structured software engineering this year than in previous years and found this very useful[4].	software engineering	William T. B. Uther;Scott Lenser;James Bruce;Martin Hock;Manuela M. Veloso	2001		10.1007/3-540-45603-1_115	computer vision;simulation;internationalization and localization;completeness;computer science;artificial intelligence;statistics	Robotics	59.054194637682116	-33.66928177183214	36396
b0d51503918389e4b9c9347dc00dceb3a7722de3	active-steering control system based on human hand impedance properties	computers;torque;impedance;active steering;vehicles steering systems;human hand impedance;impedance computers torque humans;driving simulator;control system;upper limb;control structure;humans;active steering human hand impedance impedance control;vehicles;impedance control;stationary driving simulator active steering control system human hand impedance properties steering device steering angle torque;control method;dynamic properties;steering systems	This paper proposes an active-steering control method that uses human hand impedance properties. In this method, the dynamic properties of a steering device manipulated by the upper limbs are automatically regulated according to the damping coefficient of the human-steering system. Human hand impedance in steering operations is measured and modeled depending on the steering angle and torque for use in the proposed control structure. The effectiveness of the proposed method was demonstrated by performing an emergency avoidance task using a stationary driving simulator.	characteristic impedance;control flow;control system;driving simulator;experiment;human interface device;matthews correlation coefficient;simulation;stationary process	Yoshiyuki Tanaka;Yusuke Kashiba;Naoki Yamada;Takamasa Suetomi;Kazuo Nishikawa;Takahide Nouzawa;Toshio Tsuji	2010	2010 IEEE International Conference on Systems, Man and Cybernetics	10.1109/ICSMC.2010.5642313	simulation;control system;electrical impedance;control theory;torque;control flow	Robotics	69.67961428549906	-25.735355889336113	36413
7f949f8fc7684e7e87560b273e1296c54259f25a	realizing cad/cam by polygonal meshes	polygonal meshes		computer-aided design;polygon mesh	Charlie C. L. Wang	2011	Computer-Aided Design	10.1016/j.cad.2011.01.012	computer science;volume mesh;mathematics	EDA	65.9294226196371	-43.512017212290075	36462
79725712d12bc9aac8377ec9eac2a56ccb7cc87e	method of the determination of exterior orientation of sensors in hilbert type space †	multi-centroid isometric transformation—mcit;multi-centroid transformation—mct;total free station—tfs;big rotation angles;close range photogrammetry;exterior orientation of sensor;geodesy surveying;isometric transformation;oblique orthogonal coordinate system;similarity transformation	The following article presents a new isometric transformation algorithm based on the transformation in the newly normed Hilbert type space. The presented method is based on so-called virtual translations, already known in advance, of two relative oblique orthogonal coordinate systems-interior and exterior orientation of sensors-to a common, known in both systems, point. Each of the systems is translated along its axis (the systems have common origins) and at the same time the angular relative orientation of both coordinate systems is constant. The translation of both coordinate systems is defined by the spatial norm determining the length of vectors in the new Hilbert type space. As such, the displacement of two relative oblique orthogonal systems is reduced to zero. This makes it possible to directly calculate the rotation matrix of the sensor. The next and final step is the return translation of the system along an already known track. The method can be used for big rotation angles. The method was verified in laboratory conditions for the test data set and measurement data (field data). The accuracy of the results in the laboratory test is on the level of 10-6 of the input data. This confirmed the correctness of the assumed calculation method. The method is a further development of the author's 2017 Total Free Station (TFS) transformation to several centroids in Hilbert type space. This is the reason why the method is called Multi-Centroid Isometric Transformation-MCIT. MCIT is very fast and enables, by reducing to zero the translation of two relative oblique orthogonal coordinate systems, direct calculation of the exterior orientation of the sensors.	aerial photography;algorithm;angularjs;apache axis;arabic numeral 0;assumed;calibration;camera resectioning;coefficient;correctness (computer science);displacement mapping;geodetic datum;hilbert space;identifier;isometric projection;laboratory procedures;language translations;license;machine translation;mathematics;mobile data terminal;national origin;neoplastic cell transformation;numbers;numerous;oblique projection;photogrammetry;psychologic displacement;ships;team foundation server;test data;unmanned aerial vehicle;sensor (device)	Grzegorz Stepien	2018		10.3390/s18030891		Visualization	57.416638144654094	-40.18782364377622	36499
5fab4d756b89771fb68d6902bcbd7dd2af91e58a	keep region for constructing lod of terrain regular mesh	splitting vertex;roam algorithm;rendering computer graphics surface texture vehicle dynamics error correction visualization virtual environment land vehicles graphics visual effects deformable models;computational geometry;terrain rendering;level of detail;region broken problem;terrain mapping;optimum triangulation;triangle splitting condition;terrain regular mesh;rendering computer graphics;mesh generation;active vertex;rending algorithm;active vertex terrain regular mesh roam algorithm terrain rendering region broken problem triangle splitting condition optimum triangulation splitting vertex rending algorithm;terrain mapping computational geometry mesh generation rendering computer graphics	We present an improved ROAM algorithm for keeping region when rendering terrain. Concerning the region broken problem of ROAM algorithm in rendering terrain, a method of keeping region in rendering terrain with enhancing the triangle splitting condition is proposed. The concept of optimum triangulation for region is used to set the splitting vertex and its parent active. The rending algorithm sets status of the active vertex according to the view direction and the distance between viewpoint and region, and produces the terrain region s level of detail. The results of experiments show that our algorithm with LOD has a satisfactory performance in keeping region during rending terrain	algorithm;experiment;level of detail;roam	Guojun Chen;Qinping Zhao;Yuan Yin	2006	2006 12th International Multi-Media Modelling Conference	10.1109/MMMC.2006.1651332	mesh generation;terrain rendering;computer vision;computational geometry;level of detail;computer graphics (images)	Visualization	67.3003507588606	-46.76731796905474	36500
8a0191fe00c14c6c3603206c4d81b444b67eb9bd	a biophysically-based model of the optical properties of skin aging	computer graphics i 3 3;categories and subject descriptors according to acmccs;picture image generation;computer graphics i 3 3 picture image generation;computer graphics i 3 7;three dimensional graphics and realism;computer graphics i 3 7 three dimensional graphics and realism;categories and subject descriptors according to acm ccs	This paper presents a time-varying, multi-layered biophysically-based model of the optical properties of human skin, suitable for simulating appearance changes due to aging. We have identified the key aspects that cause such changes, both in terms of the structure of skin and its chromophore concentrations, and rely on the extensive medical and optical tissue literature for accurate data. Our model can be expressed in terms of biophysical parameters, optical parameters commonly used in graphics and rendering (such as spectral absorption and scattering coefficients), or more intuitively with higher-level parameters such as age, gender, skin care or skin type. It can be used with any rendering algorithm that uses diffusion profiles, and it allows to automatically simulate different types of skin at different stages of aging, avoiding the need for artistic input or costly capture processes.	algorithm;british informatics olympiad;coefficient;graphics;high- and low-level;real-time locating system;rendering (computer graphics);simulation;skin (computing);sparse matrix;structural complexity (applied mathematics);subsurface scattering	José Antonio Iglesias Guitián;Carlos Aliaga;Adrian Jarabo;Diego Gutierrez	2015	Comput. Graph. Forum	10.1111/cgf.12540	computer vision;scientific visualization;2d computer graphics;simulation;image-based modeling and rendering;computer science;artificial intelligence;real-time computer graphics;computer graphics;algorithm;3d computer graphics;computer graphics (images)	Graphics	69.74430370117709	-48.1753258442576	36648
7a33304feec19e08fb2c63c1dae1147fde99597a	cubature split covariance intersection filter-based point set registration		Point set registration is a basic but still an open problem in numerous computer vision tasks. In general, there are more than one type of error sources for registration, for example, noise, outliers, and false initialization, may exist simultaneously. These errors could influence the registration independently and dependently. Previous works usually test performance under one of the two types of errors at one time, or they do not perform well under some extreme situations with both of the error sources. This paper presents a robust point set registration algorithm under a filtering framework, which aims to be robust under various types of errors simultaneously. The point set registration problem can be cast into a non-linear state space model. We use a split covariance intersection filter (SCIF) to capture the correlation between the state transition and the observation (moving point set). The two above-mentioned types of errors can be represented as dependent and independent parts in the SCIF. The covariance of the two types of errors will be updated every iteration. Meanwhile, the non-linearity of the observation model is approximated by a cubature transformation. First, the recursive cubature split covariance intersection filter is derived based on the non-linear state space model. Then, we use this algorithm to solve the point set registration problem. This algorithm can approximate non-linearity by a third-order term and consider correlations between the process model and the observation model. Compared with other filtering-based methods, this algorithm is more robust and precise. Tests on both public data sets and experiments validate the precision and robustness of this algorithm to outliers and noise. Comparison experiments show that this algorithm outperforms the state-of-the-art point set registration algorithms in certain respects.	approximation algorithm;collaborative product development;computer vision;convergence (action);covariance intersection;cyclosporine;each (qualifier value);experiment;extended kalman filter;greater than;heuristic;heuristics;information privacy;intersection of set of elements;iteration;maxima and minima;muscle rigidity;nonlinear system;numerical integration;part dosing unit;point set registration;process modeling;recursion;robot (device);simulated annealing;state transition table;state-space representation;vena cava filters;with high probability;one time;registration - actclass	Liang Li;Ming Yang;Chunxiang Wang;Bing Wang	2018	IEEE Transactions on Image Processing	10.1109/TIP.2018.2823427	point set registration;robustness (computer science);approximation algorithm;filter (signal processing);covariance intersection;outlier;artificial intelligence;data set;mathematics;pattern recognition;covariance	Vision	54.45366484974417	-40.93827095124889	36697
a75cdb35335a8d410732440f542f8e077b837276	gpu-accelerated visualization of protein dynamics in ribbon mode	organisms;4230;proteine;protein dynamics;0130c;interactive visualization;imagerie;structural change;systeme conversationnel;algorithme;molecules;visualization;imagery;proteins;structural dynamics;visualisation;graphics processing units;algorithms;imagineria;interactive systems	Proteins are biomolecules present in living organisms and essential for carrying out vital functions. Inherent to their functioning is folding into different spatial conformations, and to understand these processes, it is crucial to visually explore the structural changes. In recent years, significant advancements in experimental techniques and novel algorithms for post-processing of protein data have routinely revealed static and dynamic structures of increasing sizes. In turn, interactive visualization of the systems and their transitions became more challenging. Therefore, much research for the efficient display of protein dynamics has been done, with the focus being space filling models, but for the important class of abstract ribbon or cartoon representations, there exist only few methods for an efficient rendering. Yet, these models are of high interest to scientists, as they provide a compact and concise description of the structure elements along the protein main chain. In this work, a method was developed to speed up ribbon and cartoon visualizations. Separating two phases in the calculation of geometry allows to offload computational work from the CPU to the GPU. The first phase consists of computing a smooth curve along the protein’s main chain on the CPU. In the second phase, conducted independently by the GPU, vertices along that curve are moved to set up the final geometrical representation of the molecule.	algorithm;central processing unit;computation;computer;design of experiments;existential quantification;graphics processing unit;interactive visualization;requirement;shader;software deployment;spline (mathematics);time complexity;vertex (graph theory);video post-processing	Manuel Wahle;Stefan Birmanns	2011		10.1117/12.872458	simulation;visualization;interactive visualization;computer science;bioinformatics;optics;quantum mechanics;computer graphics (images)	Visualization	74.30420215395685	-47.209142437073425	36701
22da062acf4176df60ad906033fe62b521e902c2	assimilation de données images : application au suivi de courbes et de champs de vecteurs		This thesis presents the use of sequential and variational methods for tracking applications in image sequences. These techniques aim at estimating a system state from a dynamical model and a set of noisy and sparse observations. Sequential methods are usually used in computer vision community but limited to small dimensional state spaces. In metorology or oceanography, data assimilation methods are often considered. These approaches enable to deal with high dimensional state spaces. In order to consider the imperfection of complex dynamics visualised in image plane (due to 3D/2D projection), we study the use of imperfect modeling in data assimilation. In our applications, the observations are obtained directly or indirectly from images. We first apply these methods to various tracking problems of computer vision (with an imperfect modelisation of the dynamical model) : curve tracking, fluid motion estimation and joint tracking of curve and motion. We thus show that data assimilation enables to deal with complete data occlusions. Two particular applications where an accurate modelisation of the dynamic can be considered are finally studied : atmospheric layer motion estimation from satellite imagery and control of low order dynamical system from experimental visualisation.	bibliothèque de l'école des chartes;bibliothèque des ecoles françaises d'athènes et de rome;calculus of variations;complex dynamics;computer vision;data assimilation;dynamical system;image plane;linear algebra;motion estimation;sparse matrix;triple des;variational principle	Nicolas Papadakis	2007			humanities;assimilation (phonology);physics	Vision	59.83785432520304	-46.97969664562264	36711
ea391034c989956f85b979c6448a46da4aeb8d63	system identification: 3d measurement using structured light system	circular patterns;system identification;structured light system;3d reconstruction;modulation demodulation theory;ratio of the output to input	The problem of 3D reconstruction from 2D captured images is solved using a set of cocentric circular light patterns. Once the number of light sources and cameras, their location and the orientations, and the sampling density (the number of circular patterns) are determined, we propose a novel approach to representation of the reconstruction problem as system identification. Akin to system identification using the relationship between input and output, to develop an efficient 3D functional camera system, we identify the reconstruction system by choosing / defining input and output signals appropriately. One algorithm states that an input and an output are defined as projected circular patterns and 2D captured image (overlaid with deformed circular patterns) respectively. Another one is that a 3D target and the captured 2D image are defined as the input and the output respectively, leading to a problem of input estimation by demodulating an output (received) signal. The former approach identifies the system from the ratio of output to input, and is akin to a modulation-demodulation theory, the latter identifies the reconstruction system by estimating the input signal. This paper proposes the approach to identification of reconstruction system, and also substantiates the algorithm by showing results using inexpensive and simple experimental setup.	structured light;system identification	Deokwoo Lee;Hamid Krim	2012		10.1007/978-3-642-33140-4_1	3d reconstruction;computer vision;system identification;computer science;control theory;mathematics	Vision	58.75134166536009	-50.72489343445301	36737
277c2e1f18103c0402384d605b1281ca02999058	buried pipe localization using an iterative geometric clustering on gpr data	sweep line algorithm;ground penetrating radar gpr;hyperbola recognition;clustering;object detection	Ground penetrating radar is a non-destructive method to scan the shallow subsurface for detecting buried objects like pipes, cables, ducts and sewers. Such buried objects cause hyperbola shaped reflections in the radargram images achieved by GPR. Originally, those radargram images were interpreted manually by human experts in an expensive and time consuming process. For an acceleration of this process an automatization of the radargram interpretation is desirable. In this paper an efficient approach for hyperbola recognition and pipe localization in radargrams is presented. The core of our approach is an iterative directed shape-based clustering algorithm combined with a sweep line algorithm using geometrical background knowledge. Different to recent state of the art methods, our algorithm is able to ignore background noise and to recognize multiple intersecting or nearby hyperbolas in radargram images without prior knowledge about the number of hyperbolas or buried pipes. The whole approach is able to deliver pipe position estimates with an error of only a few millimeters, as shown in the experiments with two different data sets.	cluster analysis;computation;experiment;iterative method;kriging;reflection (computer graphics);sensor;sweep line algorithm	Ruth Janning;André Busche;Tomás Horváth;Lars Schmidt-Thieme	2013	Artificial Intelligence Review	10.1007/s10462-013-9410-2	computer vision;sweep line algorithm;computer science;machine learning;cluster analysis	AI	59.25983924795547	-48.311340680735015	36744
acba62e33261600636ccd2bfa34009cbd69d33af	gpu-based light wavefront simulation for real-time refractive object rendering	theoretical framework;ordinary differential equation;real time;poisson disk;blue noise;sampling;eikonal equation;data structure	In our paper on Eikonal Rendering [1], presented in the SIGGRAPH 2007 main paper program, we propose a novel algorithm to render a variety of sophisticated lighting effects in and around refractive objects in real-time on a single PC. Our method enables us to realistically display objects with spatially-varying refractive indices, inhomogeneous attenuation characteristics, as well as well as spatially-varying reflectance and anisotropic scattering properties. We can reproduce arbitrarily curved light paths, volume and surface caustics, anisotropic scattering as well as total reflection by means of the same efficient theoretical framework. In our approach, scenes are represented volumetrically. One core component of our method is a fast GPU particle tracer to compute viewing ray trajectories. It uses ordinary differential equations derived from the eikonal equation. The second important component is a light simulator, which utilizes a similar ODE-based framework to adaptively trace light wavefronts through the scene in a few seconds. While the conference paper [1] focuses on the development of the theory and the validation of our results, this sketch describes in detail the new concepts and data structures that we developed to implement view rendering and light wavefront tracing on the GPU (see figure 1 for a stage overview).	algorithm;data structure;graphics processing unit;open dynamics engine;ray tracing (graphics);real-time clock;real-time locating system;siggraph;simulation;subsurface scattering	Gernot Ziegler;Christian Theobalt;Ivo Ihrke;Marcus A. Magnor;Art Tevs;Hans-Peter Seidel	2007		10.1145/1278780.1278846	ordinary differential equation;sampling;computer vision;eikonal equation;colors of noise;data structure;rendering;computer science;geometry;programming language;statistics;computer graphics (images)	Graphics	65.31239912763326	-51.28394126662835	36986
5b2f875397f95d5be73596bb6a3f216917561f19	accurate stitching for polygonal surfaces	optimisation;closed form solution;natural stitching;probability density function;model repair;optimal method;computational geometry;local surface optimization method polygonal surfaces mesh composition model repair natural stitching general placement method directional polylines;data mining;general placement method;local surface optimization method;polygonal surfaces;solid modeling;merging;directional polylines;mathematical model;optimization;optimisation computational geometry mesh generation;mesh generation;mesh composition;quaternions;merging mesh generation surface reconstruction closed form solution solid modeling extrapolation machine intelligence optimization methods design methodology hardware	Various applications, such as mesh composition and model repair, ask for a natural stitching for polygonal surfaces. Unlike the existing algorithms, we make full use of the information from the two feature lines to be stitched up, and present an accurate stitching method for polygonal surfaces, which minimizes the error between the feature lines. Given two directional polylines as the feature lines on polygonal surfaces, we modify the general placement method for points matching and arrive at a closed-form solution for optimal rotation and translation between the polylines. Following calculating out the stitching line, a local surface optimization method is designed and employed for postprocess in order to gain a natural blending of the stitching region	algorithm;alpha compositing;image stitching;mathematical optimization	Lifeng Zhu;Shengren Li;Guoping Wang	2009	2009 11th IEEE International Conference on Computer-Aided Design and Computer Graphics	10.1109/CADCG.2009.5246898	mesh generation;closed-form expression;mathematical optimization;probability density function;computational geometry;engineering;polygonal chain;mathematical model;mathematics;geometry;solid modeling;engineering drawing;statistics;quaternion	Robotics	66.8518903230171	-42.803893229360924	36996
ebe8183fc41c6513a3326dda2f90d4b803784574	variable admittance control preventing undesired oscillating behaviors in physical human-robot interaction		Admittance control is a widely used approach for guaranteeing a compliant behavior of the robot in physical human-robot interaction. When an admittance-controlled robot is coupled with a human, the dynamics of the human can cause deviations from the desired behavior of the robot, mainly due to a stiffening of the human arm, and thus generate high-frequency unsafe oscillations of the robot. In this paper we present a novel methodology for detecting the rising oscillations in the human-robot interaction. Furthermore, we propose a passivity-preserving strategy to adapt the parameter of the admittance control in order to get rid of the high-frequency oscillations and, when possible, to restore the desired interaction model. A thorough experimental validation of the proposed strategy is performed on a group of 26 users performing a cooperative task.	admittance parameters;computer multitasking;human–robot interaction;robot;sensor;velocity (software development)	Chiara Talignani Landi;Federica Ferraguti;Lorenzo Sabattini;Cristian Secchi;Marcello Bonfé;Cesare Fantuzzi	2017	2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)	10.1109/IROS.2017.8206207	control engineering;computer science;software;robot;interaction model;admittance;stiffening;human–robot interaction;oscillation	Robotics	70.03956340171456	-25.25674993026226	37005
2fc1c57f84b8256e3bf152ffef72781cfdefa9d0	isotropic surface remeshing using constrained centroidal delaunay mesh	i 3 5 computer graphics computational geometry and object modeling geometric algorithms;refinement;article;languages;and systems;voronoi tessellations	We develop a novel isotropic remeshing method based on constrained centroidal Delaunay mesh (CCDM), a generalization of centroidal patch triangulation from 2D to mesh surface. Our method starts with resampling an input mesh with a vertex distribution according to a user-defined density function. The initial remeshing result is then progressively optimized by alternatively recovering the Delaunay mesh and moving each vertex to the centroid of its 1-ring neighborhood. The key to making such simple iterations work is an efficient optimization framework that combines both local and global optimization methods. Our method is parameterization-free, thus avoiding the metric distortion introduced by parameterization, and generating more well-shaped triangles. Our method guarantees that the topology of surface is preserved without requiring geodesic information. We conduct various experiments to demonstrate the simplicity, efficacy, and robustness of the presented method. © 2012 Wiley Periodicals, Inc.	computer graphics (computer science);delaunay triangulation	Zhonggui Chen;Juan Cao;Wenping Wang	2012	Comput. Graph. Forum	10.1111/j.1467-8659.2012.03200.x	mathematical optimization;combinatorics;voronoi diagram;computer science;mathematics;geometry;refinement;constrained delaunay triangulation;programming language	HCI	68.66141020121705	-44.312550362276596	37023
154e1d71d0025b6316e15f6f9b9d92be2555737a	haptic exploration of fine surface features	haptic interfaces surface topography shape fingers face detection tactile sensors humans robot sensing systems object detection geometry;computational geometry;optical tactile sensor surface feature detection dextrous manipulator surface geometry local curvature fingertips haptic sensing;dexterous manipulators;feature extraction;tactile sensors;computational geometry dexterous manipulators feature extraction tactile sensors	In this paper we consider the detection of small surface features, such as ridges and bumps, on the surface of an object during dextrous manipulation. First we review the representation of object surface geometry and present de nitions of surface features based on local curvature. These de nitions depend on the geometries of both the robot ngertips and the object being explored. We also show that the trajectory traced by a round ngertip rolling or sliding over the object surface has some intrinsic properties that facilitate feature detection. Next, several algorithms based on the feature de nitions are presented and compared. Finally, we present simulated and experimental results for feature detection using a hemispherical ngertip equipped with an optical tactile sensor.	algorithm;concave function;data structure;feature detection (computer vision);feature detection (web development);haptic technology;hemispherical resonator gyroscope;robot;smoothing;tactile sensor	Allison M. Okamura;Mark R. Cutkosky	1999		10.1109/ROBOT.1999.774042	control engineering;computer vision;simulation;feature extraction;computational geometry;computer science;engineering;tactile sensor	Robotics	62.533929438359095	-34.4599695567171	37037
7a9f9885c78cf70101c06cc202cd8bd5ef9c955f	online learning and adaptation of autonomous mobile robots for sustainable agriculture	tecnologia industrial tecnologia mecanica;life long learning;mobile robot;grupo de excelencia;mobile robots;online learning;autonomous mobile robot;genetics;fuzzy logic;organic farming;genetic algorithm;genetic algorithms;sustainable agriculture;tecnologias	In this paper we will introduce the application of our newly patented double hierarchical Fuzzy-Genetic system (British patent 99-10539.7) to produce an intelligent autonomous outdoor agricultural mobile robot capable of learning and calibrating its controller online in a short time interval and implementing a life long learning strategy. The online and life long learning strategy allow the outdoor robots to increase their experience and adapt their controllers in the face of the changing and dynamic unstructured outdoor agricultural environments. Such characteristics permit prolonged periods of operation within dynamic agricultural environments, which is an essential feature for the realization of a platform vehicle for use in sustainable agriculture and organic farming.	autonomous robot;autonomous system (internet);continuous operation;experiment;machine vision;mobile robot;robotic mapping;sensor;stepping level;usability	Hani Hagras;Martin Colley;Victor Callaghan;Malcolm Carr-West	2002	Auton. Robots	10.1023/A:1015626121039	mobile robot;robot learning;simulation;genetic algorithm;computer science;artificial intelligence	Robotics	57.22317961720149	-29.22322734636986	37104
ca115f1c46a9a98b1009af2c527e36a352a4bb29	3d reconstruction of temples in the special region of yogyakarta by using close-range photogrammetry		Object reconstruction is one of the main problems in cultural heritage preservation. This problem is due to lack of data in documentation. Thus in this research we presented a method of 3D reconstruction using closerange photogrammetry. We collected 1319 photos from five temples in Yogyakarta. Using A-KAZE algorithm, keypoints of each image were obtained. Then we employed LIOP to create feature descriptor from it. After performing feature matching, L1RA was utilized to create sparse point clouds. In order to generate the geometry shape, MVS was used. Finally, FSSR and Large Scale Texturing were employed to deal with the surface and texture of the object. The quality of the reconstructed 3D model was measured by comparing the 3D images of the model with the original photos utilizing SSIM. The results showed that in terms of quality, our method was on par with other commercial method such as PhotoModeler and PhotoScan.	3d modeling;3d reconstruction;algorithm;central processing unit;documentation;photomodeler;photogrammetry;point cloud;quality of results;random-access memory;sparse matrix;structural similarity;visual descriptor	Adityo Priyandito Utomo;Canggih Puspo Wibowo	2016	CoRR		computer vision;computer graphics (images)	Vision	54.80490107620349	-47.05397006537213	37154
f1f64e46dbd9975ab7f50b595701753331c95448	the quadric reference surface: applications in registering views of complex 3d objects	point to point;technical report	The theoretical component of this work involves the following question: given any two views of some unknown textured opaque quadric surface in 3D, is there a finite number of corresponding points across the two views that uniquely determine all other correspondences coming from points on the quadric? A constructive answer to this question is then used to propose a transformation, we call a nominal quadratic transformation, that can be used in practice to facilitate the process of achieving full point-to-point correspondence between two grey-level images of the same (arbitrary) object.	reference surface	Amnon Shashua;Sebastian Tölg	1994		10.1007/BFb0028372	computer vision;topology;point-to-point;computer science;technical report;mathematics;geometry	Vision	55.3145077763625	-50.94903435477083	37224
92bf125dde22275a84b47538fde7dbc1b469bb0c	improving dme performance for apnt using alternative pulse and multipath mitigation	shape;facility location dme aircraft navigation alternative position navigation and time apnt;aerospace electronics;aircraft navigation alternative position navigation and time apnt distance measuring equipment dme facility location;transponders;shape transponders aerospace electronics aircraft navigation algorithm design and analysis delays aircraft;algorithm design and analysis;delays;aircraft;aircraft navigation	This paper investigates the feasibility of the distance measuring equipment (DME)-based alternative position, navigation, and timing architecture using the recent advances on DME/N (normal) signal processing techniques; an improved DME/N pulse waveform and learning-based multipath mitigation algorithm. This paper evaluates the achievable DME range accuracy by using the advanced signal processing techniques, and provides the analysis on the required augmentation of ground DME stations in a selected test region in contiguous United States.	algorithm;icl direct machine environment;multipath mitigation;multipath propagation;signal processing;simulation;software deployment;waveform	Euiho Kim	2017	IEEE Transactions on Aerospace and Electronic Systems	10.1109/TAES.2017.2667058	algorithm design;performance-based navigation;simulation;shape;aerospace engineering;computer science;engineering;aeronautics;transponder;mathematics;tactical air navigation system	Mobile	54.230086621582394	-27.915074489416135	37246
1f1e475894bdefc5b91d610f52e5beaf528f1565	a heuristic learning algorithm for preferential area surveillance by unmanned aerial vehicles		A heuristic learning algorithm is presented in this paper to solve the problem of persistent preferential surveillance by an Unmanned Aerial Vehicle (UAV). The algorithm helps a UAV perform surveillance as per quantitative priority specifications over a known area. It allows the specification of regional priorities either as percentages of visitation to be made by a UAV to each region or as percentages of surveillance time to be spent within each. Additionally, the algorithm increases the likelihood of target detection in an unknown area. The neighborhood of a detected target is suspected to be a region of a high likelihood of target detection, and the UAV plans its path accordingly to verify this suspicion. Similar to using the target information, the algorithm uses the risk information to reduce the frequency of visits to risky regions. The technique of using risk map to avoid risky regions is adapted from the existing geometric reinforcement learning technique. The effectiveness of this algorithm is demonstrated using simulation results.	aerial photography;algorithm;heuristic;unmanned aerial vehicle	Manickam Ramasamy;Debasish Ghose	2017	Journal of Intelligent and Robotic Systems	10.1007/s10846-017-0498-5	simulation;data mining;computer security	Robotics	54.71939858596866	-25.764323739460803	37251
c283efdd87721a1f8b8050bddd392ca7f35a374d	motion control of a robotic puppet through a hybrid motion capture device	sensor system;motion control;online control motion control robotic puppet hybrid motion capture device marionette motion mapping technique bend twist sensor system offline control;robotic puppet;sensors;path planning;real time;mobile robots;robotics;motion capture data;motion capture;human motion;sensors control engineering computing mobile robots motion control path planning;online control;bend twist sensor system;hybrid motion capture device;control;control engineering computing;motion control humans control systems humanoid robots magnetic sensors robot sensing systems sensor systems service robots biomedical measurements robotics and automation;human robot interation;marionette motion mapping technique;control method;offline control	In this paper we explore the motion control of a robotic puppet through motion capture data. A motion mapping technique is investigated to map the human motion into marionette motion, and from that calculate the rotation of the servo motors to achieve desired marionette motions. A software was developed to capture human motions utilizing a bend-twist sensor system, and use the motion data to control the robotic marionette by either offline control method or online control method (real-time). We also propose the idea of integrating human into the system to close the control loop. Experimental results show that our motion mapping enables puppet to follow the actor motions with good correspondence.	astar;closing (morphology);control system;feedback;interaction;kinesiology;motion capture;online and offline;pc game;real-time locating system;robot;servo;supercomputer education research centre	Kim Doang Nguyen;I-Ming Chen;Song Huat Yeo;Henry Been-Lirn Duh	2007	2007 IEEE International Conference on Automation Science and Engineering	10.1109/COASE.2007.4341793	control engineering;computer vision;match moving;simulation;engineering	Robotics	68.73373897342934	-24.630890309759913	37314
f76b84adf00f44617fc991654239962c868b1ee5	tessellation analysis of the cosmic web	complex network;structure formation;alpha shape;scg487it;delaunay tessellation;high sensitivity;computer simulation;betti number;computational topology	The large scale distribution of matter and galaxies features a complex network of interconnected filamentary galaxy associations. This network, which has become known as the Cosmic Web, contains structures from a few megaparsecs up to tens and even hundreds of Megaparsecs of size. Galaxies and mass exist in a wispy weblike spatial arrangement consisting of dense compact clusters, elongated filaments, and sheetlike walls, amidst large near-empty void regions. An important additional aspect of this mass distribution is that it is marked by substructure over a wide range of scales and densities. The vast Megaparsec cosmic web is one of the most striking examples of complex geometric patterns found in nature, and certainly the largest in terms of sheer size.  The overwhelming complexity of both the individual structures as well as their connectivity, the lack of structural symmetries, the intrinsic multiscale nature and the wide range of densities that one finds in the cosmic matter distribution has prevented the use of simple and straightforward instruments. In this lecture, I describe the considerable advances that have been made over the past decade towards unravelling the structure of the Cosmic Web, enabled by a range of tools and concepts from computational geometry and computational topology. This will include our own work, in which Voronoi and Delaunay tessellations figure prominently through their high sensitivity to density and local shape of the local galaxy distribution, or particle distribution in the case of computer simulations of cosmic structure formation. It has led to the development of the Delaunay Tessellation Field Estimator (DTFE) formalism, which forms the basis of a range of techniques to identify different aspects of the Cosmic Web [weyschaap2009]. Examples are the Watershed Void Finder to trace voids, the Nexus multiscale morphology formalism and the Morse-based SpineWeb formalism to find walls, filaments and clusters. Recently, we used alpha shapes to study the multiscale topology of the Cosmic Web, in terms of Betti numbers and persistence diagrams. I will also review a number of other astronomical applications of tesssellations, motivated by their quickly proliferaating use in astrophysics and cosmology.	alpha shape;betti number;cosmic;complex network;computational geometry;computational topology;computer simulation;delaunay tessellation field estimator;delaunay triangulation;diagram;formal system;galaxy;intrinsic function;kripke semantics;mathematical morphology;persistence (computer science);semantics (computer science);watershed (image processing)	Rien van de Weygaert	2012		10.1145/2261250.2261296	computer simulation;betti number;combinatorics;computational topology;structure formation;mathematics;geometry;alpha shape;complex network	Theory	76.1425784918582	-44.070326546807934	37318
daf91986ec53c12994103379a644bfbc97b20623	parameterized gait synthesis	moving image;animacion por computador;legged locomotion computer animation computational geometry two term control;parametric programming;legged locomotion;commande;programmation parametrique;computational geometry;imagen movil;image mobile;sintesis imagen;image synthesis;simulation of legged locomotion;programacion parametrica;two term control;animation;synthese image;control;leap size physics based animation technique windup toys parameterized control optimization virtual windup toys periodic gaits turns leaps aperiodic motions synthesis method hopping gait turning walk;computer animation;imagen color;motion control animation animals windup turning robot kinematics humans biomechanics muscles force control;image couleur;color image;active control;animation par ordinateur	over ba I a n ce. synthesis, using either physicsbased simulations or rea1 robotic mechanisms. Solutions to this problem hold promise as powerful tools for animation, enabling the creation of realistic motions with minimal effort. However, gait synthesis is still a challenge. This article presents a method of producing gaits by using control mechanisms analogous to windup toys. The synthesis technique is based on optimization. One of the primary characteristics of “virtual windup toys” is that they are oblivious to their environment. This means that these creatures or simulated toys have no active control over balance. Nevertheless, “blind” parameterized control mechanisms can produce many common periodic gaits as well as aperiodic motions such as (urns and leaps. The possibilities and limitations of this technique are presented in the context of example creatures having one, two, four, and sixlegs. Figures 1 and 2 show animations of two of these creatures. An important attribute of the proposed synthesis method is that the motions produced can be parameterized. Thus, you can synthesize a family of motions instead of just a single fixed instance of a motion. The examples used here are	control system;mathematical optimization;robot;simulation;toys	Michiel van de Panne	1996	IEEE Computer Graphics and Applications	10.1109/38.486679	anime;computer vision;simulation;color image;computational geometry;computer science;artificial intelligence;geometry;computer animation;scientific control;computer graphics (images)	Graphics	66.27895641434318	-26.183157958825547	37408
f603f0adb10b8714ae8dc864c51d70a2d07df959	a simulation environment for robot motion planning	robot motion motion planning physics robot sensing systems mechatronics system testing actuators kinematics electromagnetic forces hardware;robot sensing systems;ibex;rigid body;sensors;mobile robot;rigid body simulation;real time;robot sensors;actuators;mobile robots;mechatronic system simulation;robotics;physics simulation;kinematics;physics computing;physics;collision detection;robot motion planning;industrial robots;collision resolution;sensors and actuators;motion planning;hardware in the loop simulation;modular design;system testing;robot motion;control loop;real time system;mobile robots collision avoidance robot kinematics robot dynamics real time systems physics computing digital simulation sensors actuators mechatronics industrial robots;collision avoidance;mechatronics;robot dynamics;electromagnetic forces;i o interfaces;mechatronic systems;robot actuators;simulation environment;digital simulation;physical simulation;hardware in the loop simulation robot motion planning ibex real time system physics simulation mechatronic system simulation control loop robotics robot sensors robot actuators rigid body simulation robot kinematics robot dynamics collision detection collision resolution electromagnetic forces i o interfaces;robot kinematics;hardware;real time systems	We introduce Ibex, a real-time capable physics simulation framework. Ibex is ideally suited to simulate mechatronic systems as well as environments in which robot motion planning algorithms can be developed and tested. The entire control loop encountered in robotics can be simulated. This includes the simulation of robot sensors and actuators. The current implementation includes a rigid-body simulation which encompasses not only kinematic but also dynamics effects. It performs collision detection and resolution in real-time or faster for typical setups. The completely modular design of Ibex means the framework is easily configurable and extensible. Additional physics simulation modules covering phenomena such as electromagnetic forces can be integrated transparently. These modules can interact with existing entities to build an overall system. Ibex can communicate with external hardware through I/O interfaces, thus allowing hardware-in-the-loop simulations. We present example Ibex applications from both industrial and mobile robotics. We also describe why Ibex is a real asset for robot motion planning and how we intend to apply it in this field.	as-interface;algorithm;collision detection;control system;dynamical simulation;entity;hardware-in-the-loop simulation;input/output;mathematical optimization;mechatronics;mobile robot;modular design;motion planning;physx;real-time clock;real-time locating system;real-time transcription;robotics;semantics (computer science)	Alan Ettlin;Patrick Büchler;Hannes Bleuler	2005	Proceedings of the Fifth International Workshop on Robot Motion and Control, 2005. RoMoCo '05.	10.1109/ROMOCO.2005.201436	control engineering;embedded system;simulation;engineering	Robotics	64.7328233870478	-28.537252795637247	37427
3066f196a37d7d0170f3472281071c88d411fa67	a model based method for overall well focused catadioptric image acquisition with multi-focal images	image acquisition;catadioptric system;spatial distribution;robust performance;multi focal images;well focused image	Based on an analysis on the spatial distribution property of virtual features, we propose that the shapes of the best focused image regions in multi-focal catadioptric images can be modeled by a series of neighboring concentric annuluses. Based on this model, an over-all well focused image can be obtained by combining the best focused regions from a set of multi-focal images in a fast and reliable manner. A robust algorithm for estimating the model parameters is presented. Experiments with real catadioptric images under a variety of scenes verify the validity of the model and the robust performance of the algorithm.	focal (programming language)	Weiming Li;Youfu Li;Yihong Wu	2009		10.1007/978-3-642-03767-2_56	catadioptric system;computer vision;computer graphics (images)	Vision	57.50461693204763	-49.580457080126266	37509
7329752b60b688f5ea2fbf4b9e836d2c096e2535	fur simulation with spring continuum	procedural modeling;statistical model;polygonal meshes;fur animation;spring continuum;parametric surface;physical simulation	We propose a practical method for generating and animating fur on parametrized surfaces using a spring continuum. Springs are physically simulated at the vertices of the polygon mesh, and spring behavior is interpolated across the mesh to provide realistic dense fur animation. Our method handles collisions between furry surfaces using a procedural model and self-collisions with a statistical model. The goal of this method is to make it easy for an animator to generate realistic dynamic fur which is efficient to simulate. The technique is most applicable to short fur, rather than long hair.	autodesk maya;coupling (computer programming);interpolation;polygon mesh;shading;simulation;statistical model;triune continuum paradigm	Alexis Angelidis;Brendan McCane	2008	The Visual Computer	10.1007/s00371-008-0218-z	statistical model;simulation;computer science;parametric surface;mathematics;procedural modeling;statistics;computer graphics (images)	Graphics	69.52858569579017	-47.75057078329405	37520
f49bf8ef3cfe0d5307836208dd9c4edc3c868967	cubic bézier spiral segments for planar g2 curve design	g 2 matching;fair curve;cubic bezier spiral	In curve design it is often desirable to match G2 Hermite data with a pair of spirals. An existing method addresses this problem using cubics by first requiring the joint to be placed, and then matching tangents at the joint. It is now shown that an alternative method of first matching tangents, which then determine an interval along a line for placement of the joint, is more convenient and requires less computation.	bézier curve;computation;cubic function	Desmond J. Walton;Dereck S. Meek	2010		10.1145/1811158.1811162	mathematical optimization	Robotics	69.82639393384387	-40.47871406242776	37547
80ae68252b9c5c23530c1310db5b31acc73585e4	3d game engine for real-time facial animation	reconnaissance visage;modele reference;modelizacion;animacion por computador;gestion memoire;facies;storage management;real time;reference model;data management;game engine;facial modeling;local deformation;intelligence artificielle;modelisation;gestion memoria;face recognition;temps reel;facial animation;face modeling;wire deformation;tiempo real;artificial intelligence;inteligencia artificial;computer animation;real time facial animation;modeling;multiple face models;modelo referencia;animation par ordinateur	For 3D game engine, we present facial animation method based on multiple face models. In order to overcome the heavy burden of geometry data management on game engine, we employ wire curve [22] which is a simple, intuitive interface to local deformation of complex geometric objects such as human face models. Given multiple face models, we first extract wire curves and deformation parameters from a facial model. In runtime, given an input of expression parameters, only the extracted wire curves are blended to create new expression. Then, the blended output of the wire curves is applied to the reference model of neutral expression. The resulting animation preserves the characteristic features of the multiple face models as well real-time performance. Our method promotes local deformation and non-uniform blending by making use of the power of wire curve.	game engine;real-time transcription	Hye Won Pyun	2005		10.1007/11589990_74	computer vision;simulation;reference model;systems modeling;computer facial animation;facies;data management;computer science;artificial intelligence;computer animation;computer graphics (images)	Graphics	63.02915966969411	-48.03086150684541	37560
5e945882cb8faf7c59b94669c78e6541f2c2022f	orbital slam	gravity;orbits;moon;simultaneous localization and mapping;extraterrestrial measurements;monte carlo methods;space vehicles	This paper demonstrates infrastructure-free orbital Simultaneous Localization and Mapping (SLAM). Individual surface landmarks are tracked through images taken in orbit and the filter receives measurements of these landmarks in the form of bearing angles. The filter then updates the spacecraft's position and velocity as well as landmark locations, thus building a map of the orbited body. In contrast to other approaches that use an IMU, which doesn't work in orbit, to resolve scale, the contribution of this paper is to demonstrate that scale can be resolved using orbital dynamics. Radio localization can be replaced with onboard localization, enabling truly autonomous missions to both under-mapped and unmapped planetary bodies. Overall system convergence is shown by simulating landmark detection from an orbit of the Clementine Mission on a Moon model constructed using Lunar Reconnaissance Orbiter (LRO) digital elevation data in conjunction with the filter. The techniques developed in this work demonstrate that when combined with a gravity model, visual SLAM converges to a full scale solution.	autonomous robot;clementine;full scale;google lunar xprize;gravity model of trade;large receive offload;molecular orbital;planetary scanner;simulation;simultaneous localization and mapping;velocity (software development)	Corinne Vassallo;Wennie Tabib;Kevin Peterson	2015	2015 12th Conference on Computer and Robot Vision	10.1109/CRV.2015.47	geography;geodesy;optics;remote sensing	Robotics	54.91671931988379	-36.14187628688266	37594
29b389eef96c797b1d961450b995be3a6c0b500a	tight linear envelopes for splines	spline;piecewise linear;interpolation;polygon caracteristique;convergence;envelope;capsula convexa;esplin;implementation;interpolacion;polygone;control polygon;enveloppe;enveloppe convexe;polygon;ejecucion;convergencia;envoltura;bernstein polynomial;linear interpolation;poligono;b spline;convex hull;polinomio bernstein;polynome bernstein;b splin	A sharp bound on the distance between a spline and its B-spline control polygon is derived. The bound yields a piecewise linear envelope enclosing spline and polygon. This envelope is particularly simple for uniform splines and splines in Bernstein-Bezier form and shrinks by a factor of 4 for each uniform subdivision step. The envelope can be easily and efficiently implemented due to its explicit and constructive nature.	spline (mathematics)	David Lutterkort;Jörg Peters	2001	Numerische Mathematik	10.1007/s002110100181	mathematical optimization;mathematical analysis;smoothing spline;interpolation;polygon;mathematics;geometry;box spline	Theory	68.64788981798598	-40.19014869923738	37647
45bf4a0b43ec97caaf73cab615f0d33ec24c3995	uncalibrated 1d projective camera and 3d affine reconstruction of lines	cameras image reconstruction tensile stress europe image segmentation motion estimation ear;1d projective camera;2d projective reconstruction;projection matrices;edge detection;uncalibrated affine cameras;motion;rescaling image coordinates;shape;rescaling image coordinates 3d affine reconstruction lines shape motion line correspondences 1d projective camera uncalibrated affine cameras 2d projective reconstruction tensorial representation image sequences projection matrices;line correspondences;image representation;image reconstruction;image sequences image reconstruction image representation edge detection;3d affine reconstruction;tensorial representation;projective reconstruction;lines;image sequences	We describe a linear algorithm to recover 3D affine shape/motion from line correspondences over three views with uncalibrated affine cameras. The key idea is the introduction of a one-dimensional projective camera. This converts the 3D affine reconstruction of “lines” into 2D projective reconstruction of “points”. Using the full tensorial representation of three uncalibrated 1D views, we prove that the 3D affine reconstruction of lines from minimal data is unique up to a re-ordering of the views. 3D affine line reconstruction can be performed by properly rescaling image coordinates instead of using projection matrices. The algorithm is validated on both simulated and real image sequences.	algorithm;compiler	Long Quan	1997		10.1109/CVPR.1997.609298	iterative reconstruction;affine space;computer vision;edge detection;topology;affine coordinate system;affine involution;shape;computer science;affine plane;hyperplane;motion;line;affine geometry of curves;affine hull;affine transformation;harris affine region detector;mathematics;geometry;affine shape adaptation;affine combination;hessian affine region detector	Vision	53.89439881287909	-50.91842016966528	37663
291380bf27e9b7d6664f51292b97cf7904f4c4ac	towards automatic character skeletonization and interactive skin deformation				Thomas Di Giacomo;Laurent Moccozet;Nadia Magnenat-Thalmann;Ronan Boulic;Daniel Thalmann	2007		10.2312/egst.20071054	computer vision;engineering drawing;computer graphics (images)	Vision	63.67216906013267	-46.095775782027964	37688
d2803ae2f1d7e202714781ff38b0de99b718afed	motivation of a new approach for shape reconstruction based on fbg-optical fibers: considering of the bragg-gratings composition as a sensornetwork	flexible instrument tracking;shape estimation;shape gratings tensile stress robot sensing systems bragg gratings measurement units interpolation;snakelike objects reconstructed;robot sensing systems;shape sensors;interpolation;surface characterization approach;tensile stress;radiation fields;distributed measurement units;shape sensing;measurement units;optical fibres;gratings;medical technology;shape detection;sensor network;sensor deformation;distributed sensors;temperature fields;shape;navigation systems;image reconstruction;shape reconstruction;medical image processing;sensor manufacturing process;minimally invasive surgical interventions;fbg optical glass fibers;surgery;discrete value measurement;bragg gratings;biomedical optical imaging;object detection;tensor field	In various fields of application, the shape and the tip position of flexible, snakelike objects have to be reconstructed. For this, the considered objects are fitted with so-called shape sensors. This shape sensors are e.g. applied in medical technology to support minimally invasive surgical interventions by tracking flexible instruments; this way navigation systems can be considerably supported. The sensors consist of a solid snakelike body out of flexible carrier material, as silicone, with embedded FBG - optical glass fibers along the object-axis. Guided along the observed instruments, the sensor is supposed to detect the instruments shape by detecting its own ones. The fibers measure the strain at discrete points along the sensor body, which is caused by deformation of the sensor. From these values the shape is estimated. This estimation is performed using specific algorithms. Accordingly, certain requirements regarding the position, orientation and exact number of the measurement units are made. As part of the manufacturing process of the sensor, however, exact control of fiber positioning cannot be realized. To compensate this inaccuracy and also further occurring problems, a fundamentally new calculation approach is presented in this paper. The basic idea is, to consider the system of measurement units as a sensor network. The position and orientation of the units are not considered to be static, because they can only be detected after production but cannot be exactly implemented in a controlled way with a planned position and orientation. The idea is realized by initializing a tensor field on a manifold, representing the surface of the object. This allows to apply the algorithm to measurement values, measured at randomly distributed positions along the sensor body. The new approach is promising and more accuracy in shape sensing is expected do be achieved. The approach of surface characterization is developed in a way that it is transferable to other applications. In the future, also areas in general can be analysed by applying to adapted algorithms based on the same idea. Interpolation of e.g. temperature- and radiation fields can be done in an intelligent way by measuring discrete values by efficiently distributed measurement units.	algorithm;embedded system;interpolation;optic axis of a crystal;optical fiber;randomness;requirement;sensor;shape context;system of measurement	Hendrikje Pauer;Christoph Ledermann;Heinz Wörn	2014	2014 IEEE Ninth International Conference on Intelligent Sensors, Sensor Networks and Information Processing (ISSNIP)	10.1109/ISSNIP.2014.6827645	materials science;computer vision;optics;engineering drawing	Robotics	61.084371580052604	-36.726671282814394	37821
027cee464fb1c0ec17b9454dfeb42f17829d9e1b	the synthesis of solids bounded by many faces	computer aided design;shape synthesis;computational geometry;three dimensional modeling;three dimensional;machined components;graphics;polyhedra	A technique is presented which allows a class of solid objects to be synthesized and stored using a computer. Synthesis begins with primitive solids like a cube, wedge, or cylinder. Any solid can be moved, scaled, or rotated. Solids may also be added together or subtracted. Two algorithms to perform addition are described. For practical designers, the technique has the advantage that operations are concise, readily composed, and are given in terms of easily imagined solids. Quite short sequences of operations suffice to build up complex solids bounded by many faces.	algorithm;cube;cylinder seal;imagined speech	I. C. Braid	1975	Commun. ACM	10.1145/360715.360727	three-dimensional space;computational geometry;computer science;graphics;theoretical computer science;mathematics;polyhedron;computer graphics (images)	Graphics	65.13625610161799	-45.37292815669872	37987
d4e95b15ca7813801bf29347b938f9b649d46011	robot-assisted prostate brachytherapy	robotic system for prostate brachytherapy computer aided surgery;degree of freedom;patient care;force feedback;robot control	In contemporary brachytherapy procedures, needle placement at the desired target is challenging due to a variety of reasons. A robot-assisted brachytherapy system can improve the needle placement and seed delivery resulting in enhanced patient care. In this paper we present a 16 DOF (degrees-of-freedom) robotic system (9DOF positioning module and 7 DOF surgery module) developed and fabricated for prostate brachytherapy. Techniques to reduce needle deflection and target movement have been incorporated after verifying with extensive experiments. Provisions for needle motion and force feedback have been included into the system for improving the robot control and seed delivery. Preliminary experimental results reveal that the prototype system is quite accurate (sub-millimeter) in placing brachytherapy needles.	asea irb;brachytherapy;ct scan;chemical vapor deposition;clinical protocols;clinical act of insertion;entity class - imaging modality;experiment;haptic technology;insertion mutation;modality (human–computer interaction);needle device;patients;phantoms, imaging;prototype;radioactivity;repeatability;robot control;semiconductor industry;systems design;verifying specimen;x-ray computed tomography;sensor (device)	Yan Yu;Tarun Kanti Podder;Yongde Zhang;Wan Sing Ng;Vladimir Misic;Jason Sherman;Luke Fu;Dave Fuller;Edward Messing;Deborah J. Rubens;John G. Strang;Ralph Brasacchio	2006	Medical image computing and computer-assisted intervention : MICCAI ... International Conference on Medical Image Computing and Computer-Assisted Intervention	10.1007/11866565_6	medicine;computer science;artificial intelligence;robot control;haptic technology;degrees of freedom;surgery;medical physics	Robotics	73.81525562343921	-28.84232630590932	38000
becfe87eb83e452afce0f0e5e270eab8f5f21784	an exoskeleton for gait rehabilitation: prototype design and control principle	automatic control;ankle assistance;gait rehabilitation exoskeleton;human computer interaction;pneumatic artificial muscle;exoskeletons prototypes robotics and automation rehabilitation robotics foot actuators automatic control human robot interaction muscles sliding mode control;mechanical design;prototypes;patient rehabilitation;proxy based sliding mode control approach;foot;actuators;variable structure systems;human robot interaction;robotic gait rehabilitation;orthopaedics;pleated pneumatic artificial muscles;medical robotics;tracking performance robotic gait rehabilitation ankle assistance body weight support human robot interaction gait rehabilitation exoskeleton pleated pneumatic artificial muscles mechanical design proxy based sliding mode control approach;pneumatic actuators;exoskeletons;rehabilitation robotics;body weight support;gait analysis;experimental validation;tracking performance;mechanism design;robotics and automation;sliding mode control;muscle;variable structure systems gait analysis human computer interaction medical robotics muscle orthopaedics patient rehabilitation pneumatic actuators;muscles	Research in robotic gait rehabilitation still faces many challenges regarding ankle assistance, body weight support and human-robot interaction. This paper reports on the development, focusing on these challenges, of a gait rehabilitation exoskeleton powered by pleated pneumatic artificial muscles. The first prototype is intended as a platform for the evaluation of design and control concepts. The mechanical design procedure is explained with the emphasis on optimization. A proxy-based sliding mode control approach is proposed and evaluated by means of simulation. Simulation results indicate good tracking performance and safe system behavior, encouraging experimental validation on the prototype.	dummy variable (statistics);experiment;human body weight;human–robot interaction;mathematical optimization;pneumatic artificial muscles;prototype;requirement;robot;simulation;video game rehabilitation	Pieter Beyl;Michaël Van Damme;Ronald Van Ham;Rino Versluys;Bram Vanderborght;Dirk Lefeber	2008	2008 IEEE International Conference on Robotics and Automation	10.1109/ROBOT.2008.4543506	control engineering;mechanism design;muscle;simulation;gait analysis;exoskeleton;sliding mode control;pneumatic actuator;computer science;engineering;automatic control;control theory;prototype;foot;actuator	Robotics	70.21601849420982	-26.16690507809833	38224
913a2be5f45cd3f42dcabfbefac77202c8c2f2aa	design of a biomimetic gecko adhesion array for microrobots	microrobots;moment equilibrium;adhesives;actuation mechanism biomimetic gecko adhesion array microrobots moment equilibrium;microrobots adhesives biomimetics;biomimetics adhesives atomic force microscopy rough surfaces surface roughness scanning electron microscopy intelligent robots robotics and automation hair foot;biomimetic gecko adhesion array;actuation mechanism;biomimetics	In this work the design of a biomimetic gecko adhesion array for future microrobots is described. First, models for understanding the array design are issued, and based on moment equilibrium the theory of actuation mechanism of the array is discussed in detail. Then the design parameters such as length, diameter, separation distance, and density of array are determined for non-matting. Finally, the fabrication technique is proposed	biomimetics;diameter (protocol);gecko;microbotics	Hui-Jing Wang;Shirong Chen;Xiaohua Wang;Deyi Kong;Tao Mei	2005	2005 IEEE International Conference on Robotics and Biomimetics - ROBIO	10.1109/ROBIO.2005.246317	biomimetics;adhesive;nanotechnology;mechanical engineering	Robotics	77.26580231853879	-24.6173997200721	38352
ff8505feef39c3198f9248f363e89f28e398dbe4	a method for recognizing three-dimensional position of a rigid body using its shape. error analysis and an optimization of observation system	rigid body;three dimensional;error analysis	Abstract#R##N##R##N#In the problem of measuring three-dimensional positions and motion of a rigid body, methods to determine the three-dimensional position from its optical projection data on a two-dimensional plane have been widely used. We have proposed a method using positional relations among the marked points and applied it to three-dimensional movement measurement of the human law.#R##N##R##N##R##N##R##N#If the positions of three marked points on a rigid body are known, measuring these positions requires only one projection datum at each point to determine the three-dimensional position of the points, since the degree of freedom of a rigid body is six. A previous paper presented formulation of the problem in general form, its solution and theoretical analysis of stability of solution, as well as observation method.#R##N##R##N##R##N##R##N#This paper analyzes the effect of error associated with measurement on estimating the position of marked points at implementation. Error propagation equations are derived effective for design of measuring instruments. The optimum measuring method is obtained from the viewpoint of error propagation using the result.	error analysis (mathematics);mathematical optimization	Toyohiko Hayashi;Taizo Iijima	1987	Systems and Computers in Japan	10.1002/scj.4690181007	three-dimensional space;mathematical optimization;rigid body;mathematics;geometry	Robotics	55.492345946468454	-49.27987858733126	38397
ad6307333847cb2b22af6624576a218cd471bb18	aibo and webots: simulation, wireless remote control and controller transfer	software tool;remote control;physics based modeling;wireless communication;cross compilation;webots;robot simulation;aibo;software component;graphic user interface;quadruped robot;robot programming	This article introduces a new software tool that provides an accurate simulation of Sony Aibo robots and the capability to transfer controller programs from the simulation to the real robot. Five components are described: (1) a simulated physics-based model of the Sony Aibo ERS-210(A) and ERS-7 quadruped robots; (2) a graphical user interface for controlling the simulated and real robots; (3) a wireless communication protocol for controlling the robot from within Webots; (4) software components on the robot that enable remote control; and (5) a method for cross-compiling Webots robot controllers. The complete system has been calibrated and proof tested. It enables simultaneous control of both a simulated and a real Aibo robot and provides the user with a platform for convenient robot programming without any knowledge of the underlying robot firmware. c © 2006 Elsevier B.V. All rights reserved.	aibo;calibration (statistics);communications protocol;component-based software engineering;cross compiler;firmware;graphical user interface;programming tool;remote control;robot;simulation	Lukas Hohl;Ricardo A. Téllez;Olivier Michel;Auke Jan Ijspeert	2006	Robotics and Autonomous Systems	10.1016/j.robot.2006.02.006	mobile robot;embedded system;real-time computing;simulation;computer science;artificial intelligence;component-based software engineering;social robot;aibo;graphical user interface;robot control;personal robot;wireless;remote control	Robotics	64.79723272907054	-29.593497393951765	38447
05aeb2a3322d0a467e7ba6378dd51b11fe8ad478	compliance control and human-robot interaction: part 1 - survey	impedance;hri;compliance;humanoids;phri;optimal adaptive control	Compliance control is highly relevant to human safety in human–robot interaction (HRI). This paper presents a review of various compliance control techniques. The paper is aimed to provide a good background knowledge for new researchers and highlight the current hot issues in compliance control research. Active compliance, passive compliance, adaptive and reinforcement learning-based compliance control techniques are discussed. This paper provides a comprehensive literature survey of compliance control keeping in view physical human robot interaction (pHRI) e.g., passing an object, such as a cup, between a human and a robot. Compliance control may eventually provide an immediate and e®ective layer of safety by	control theory;emergence;humanoid robot;human–robot interaction;intelligent control;mathematical model;reinforcement learning;relevance;robot;sensor;social robot;soft robotics	Said Ghani Khan;Guido Herrmann;Mubarak Al Grafi;Anthony G. Pipe;Chris Melhuish	2014	I. J. Humanoid Robotics	10.1142/S0219843614300013	simulation;electrical impedance	Robotics	70.06917652264283	-25.418047974134442	38457
851b93f9b60ae2f7b5ab7a25495cf0938ff2b6ec	mechanical impedance characteristics of robots for coexistence with humans	stiffness mechanical impedance characteristics robots physical softness parameters desirable values rating scale method linear regression model human emotions;elasticity;linear regression model;mechanical properties;impedance humans orbital robotics service robots robot control robot motion acceleration force sensors mechanical engineering humanoid robots;human factors;rating scale;elasticity robots human factors mechanical properties;robots;point of view	In the future, it is expected that robots will play important roles in coexisting with humans. Whenever humans come into contact with these robots they must be able to adjust their physical .softness parameters, which will help humans remain calm and which will be favorable for human emotions. Therefore, it is desirable for robots to control their impedance characteristics in such cases. From these points of view, desirable values of the impedance parameters of robots are investigated in this paper through a rating scale method. In terms of the results, the emotions felt by humans with regard to the robots being sop, pleasant, and human-like are explained by a linear regression model of the impedance values, and the emotions of being reassuring are classijied into four groups.	characteristic impedance;coexist (image);humans;impedance parameters;rating scale;robot;standard operating procedure	Mohamed Sahbi Ben-Lamine;Satoru Shibata;Kanya Tanaka;Akira Shimizu	1997		10.1109/ROBOT.1997.620149	robot;control engineering;simulation;rating scale;computer science;engineering;linear regression;artificial intelligence;human factors and ergonomics;elasticity;statistics	Robotics	70.23617014305538	-25.47267305211227	38515
01582a84a9ea8a4e12901f794cbe438458a856b4	repeated structures: image correspondence constraints and 3d structure recovery	3d structure	Recently, a number of classes of 3D structures have been identified which permit structure recovery and 3D invariants to be measured from a single image of the structure. A large class with this property is the case of repeated structures where a structure (such as a pointset, curve or surface), and a transformed copy of the structure are both observed in a single perspective image. In general the 3D reconstruction is only possible up to a 3D projectivity of space, but smaller ambiguities are possible, depending on the nature of the 3D transformation between the repeated structures. An additional theme of the paper is the development of feature correspondence relations based on the epipolar geometry induced in the image by the repeated structure. In some cases, correspondence is based on projective homologies rather than a true epipolar geometry.		Joseph L. Mundy;Andrew Zisserman	1993		10.1007/3-540-58240-1_5	3d reconstruction;projective test;epipolar geometry;fundamental matrix (computer vision);invariant (mathematics);topology;affine transformation;homography;mathematics	Vision	53.95043668370319	-51.396043478605954	38552
baee8f09cae1b9a29326c49e36224366cde41240	a real time distributed approach to collision avoidance for industrial manipulators	microprocessors;service robots;joints;computer architecture;three dimensional displays;collision avoidance service robots computer architecture microprocessors three dimensional displays joints;collision avoidance;velocity control collision avoidance control engineering computing digital simulation distributed processing industrial manipulators microcomputers real time systems service robots;speed override control real time distributed approach collision avoidance industrial manipulators robot interaction industrial robotics service robotics robot tool center point tcp 3d robotic cell simulation personal computer tcp ip socket robot controller anticollision policies	Robot interaction with the surrounding environment is an important and newsworthy problem in the context of industrial and service robotics. Collision avoidance gives the robot the ability to avoid contacts with objects around it, but most of the industrial controls implementing collision avoidance checks only the robot Tool Center Point (TCP) over the objects in the cell, without taking into account the shape of the tool, mounted on the robot flange. In this paper a novel approach is proposed, based on an accurate 3D simulation of the robotic cell. A distributed real time computing approach has been chosen to avoid any overloading of the robot controller. The simulator and the client application are implemented in a personal computer, connected via a TCP-IP socket to the robot controller, which hosts and manages the anti-collision policies, based on a proper speed override control. The real time effectiveness of the proposed approach has been confirmed by experimental tests, carried out for a real industrial setup in two different scenarios.	centrality;client (computing);communications protocol;formal verification;function overloading;industrial robot;library (computing);linux;microsoft dynamics c5;open architecture;operating system;performance;personal computer;programming paradigm;real-time clock;real-time computing;real-time transcription;robot control;robotics;sensor;simulation;workspace	Alba Fenucci;Marina Indri;Fabrizio Romanelli	2014	Proceedings of the 2014 IEEE Emerging Technology and Factory Automation (ETFA)	10.1109/ETFA.2014.7005160	mobile robot;embedded system;real-time computing;simulation;computer science;engineering;robot control;personal robot	Robotics	65.00996773300432	-30.48469503482717	38593
ce4f82c40cae2a6b9b318020419f73d23d5b43db	bilateral teleoperation of a group of mobile robots for cooperative tasks	cooperative tasks;time delay;bilateral teleoperation;multiple mobile robots;interaction force	A visual and force feedback-based teleoperation scheme is proposed for cooperative tasks. The bilateral teleoperation system includes a haptic device, an overhead camera and a group of wheeled robots. The commands of formation and average velocities of the multiple robots are generated by the operator through the haptic device. The state of the multiple robots and the working environment is sent to the human operator. The received information contains the feedback force through the haptic device and visual information returned by a depth camera. The feedback force based on the difference between the desired and actual average velocities is presented. The wave variable method is employed in the bilateral teleoperation of multiple mobile robots with time delays. The effectiveness of the bilateral teleoperation system is demonstrated by experiments. The robots in the slave side are able to follow the commands from the master side to interact with the environments, including moving in different formations and pushing a box. The results show that the scheme enables the operator to manipulate a group of robots to complete cooperative tasks freely.	mobile robot	Guangming Song;Zhong Wei;Huiyu Sun;Yong Zhang	2016	Intelligent Service Robotics	10.1007/s11370-016-0204-7	teleoperation;simulation	Robotics	60.756628197408766	-29.302266531228774	38636
df9c8cf47237904d6353e248df2510debbd7ba89	rtr-trees for space robotics behavior simulation and visualization	direct kinematic scheme;orbital robotics visualization kinematics hydrogen computational modeling tree graphs skeleton legged locomotion space technology shape control;tree data structures;null;visualization;aerospace control;reorderable tree structure space robotics behavior simulation visualization variable order relation direct kinematic scheme 3d object simulation;aerospace computing;space robotics;tree data structures aerospace computing aerospace control robot kinematics;space robotics behavior simulation;variable order relation;reorderable tree structure;3d object simulation;robot kinematics	New types of trees of structure and linked lists with variable order relations (RTR-trees and RTR-lists) are discussed. Using them enables application of the direct kinematic scheme for simulation of 3D-objects with reorderable structure, making the logic of behavior simulation more natural	linked list;real-time recovery;robotics;simulation;x3d	Valery Afanasiev;Dmitry Baigozin;Ilia Kazanski;Sergey Fomin;Stanislav V. Klimenko	2006	2006 International Conference on Cyberworlds	10.1109/CW.2006.33	computer vision;simulation;visualization;computer science;artificial intelligence;theoretical computer science;tree;robot kinematics	Robotics	65.83738764498487	-31.601767436890267	38681
03b9311d447e838f61d6fe9ffe7d7ce3eda8a390	model based in situ calibration of six axis force torque sensors		This paper proposes and validates an in situ calibration method to calibrate six axis force torque (F/T) sensors once they are mounted on the system. This procedure takes advantage of the knowledge of the model of the robot to generate the expected wrenches of the sensors during some arbitrary motions. It then uses this information to train and validate new calibration matrices, taking into account the calibration matrix obtained with a classical Workbench calibration. The proposed calibration algorithm is validated on the F/T sensors mounted on the iCub humanoid robot legs.	algorithm;apache axis;humanoid robot;icub;loss function;maxima and minima;optic axis of a crystal;playstation 3 wireless keypad;sensor;workbench	Francisco Javier Andrade Chavez;Silvio Traversaro;Daniele Pucci;Francesco Nori	2016	2016 IEEE-RAS 16th International Conference on Humanoid Robots (Humanoids)	10.1109/HUMANOIDS.2016.7803310	control engineering;computer vision;simulation;engineering;robot calibration	Robotics	71.85583625097875	-29.150342632286037	38729
119e9609b7ce88c26012dd1a95a93bcfc6fcce9b	modelling human falling process based on a five-link bipedal robot	bipedal robot;legged locomotion;hip;knee joint trajectory;dynamic model;biology;joints;humans robots legged locomotion leg robotics and automation sun knee hip stability analysis accidents;stability;stability biology collision avoidance legged locomotion;obstacle avoidance;accidents;hip joint trajectory;biological characteristic;knee;robots;stability analysis;sun;mathematical model;humans;collision avoidance;robotics and automation;leg;reaction time;stability analysis human falling process bipedal robot obstacle avoidance knee joint trajectory hip joint trajectory biological characteristic;human falling process	In this paper we develop a dynamic model to mimic and simulate human falling process when tripping over an obstacle. The work consists of three parts. First a 5-link bipedal model is established, the joint trajectories of knee and hip are generated. Next several constraints are taken into consideration, which take the physical, physiological and environmental constraints into consideration. Hence the fall process can be modeled in a realistic manner. A number of important factors that characterize the fall process, such as reaction time, inclining angle, stable range, initial speed, are investigated. The whole falling process is formulated according to biological characteristics and stability analysis, which further offers an effective way to identify and distinguish falling from normal activities, so that the falling can be predicted and a prevention device can be activated in advance.	coat of arms;consciousness;mathematical model;robot;simulation;stepping level	Jian-Xin Xu;Yuanguang Sun;Chee Khiang Pang	2010	IEEE ICCA 2010	10.1109/ICCA.2010.5524383	robot;control engineering;mental chronometry;von neumann stability analysis;simulation;stability;computer science;engineering;artificial intelligence;mathematical model;mathematics;obstacle avoidance;statistics	Robotics	67.56778859601971	-25.02667694943211	38738
1fda837692584da94f078b82660a43fb0883ae31	pairwise lidar calibration using multi-type 3d geometric features in natural scene	intelligent transportation systems;laser radar calibration three dimensional displays robot sensing systems feature extraction vehicles;optical radar calibration intelligent transportation systems;optical radar;calibration;feature extractions lidar calibration multitype geometric features 3d measurement mobile platform transformation parameters intelligent vehicle platform peking university	It has become a well-known technology that 3D measurement of a large environment could be achieved by using a number of 2D LIDARs on a mobile platform. In such a system, calibration is essential for making collaborative use of different LIDAR data, while existing methods usually require modifications to the environments, such as putting calibration targets, or rely on special facilities, which is labor intensive and put many restrictions to potential applications. This research aims at developing a calibration method for multiple 2D LIDAR sensing systems, which could be conducted in a general outdoor environment using the features of a nature scene. Special focus is cast on solving the noisy sensing in a complex environment and the occlusions caused by largely different sensor viewpoints. A multi-type geometric feature based calibration algorithm is proposed, which extracts the features such as points, lines, planes and quadrics from the 3D points of each LIDAR sensing. Transformation parameters from each sensor to the frame on a moving platform is estimated by matching the multi-type features. Experiments are conducted using the data sets of an intelligent vehicle platform (POSS-V) through a driving in the campus of Peking University. Results of calibrating two LIDAR sensors with largely different viewpoints are presented, and the accuracy and robustness concerning noisy feature extractions are examined intensively.	algorithm;experiment;mobile operating system;sensor	Mengwen He;Huijing Zhao;Franck Davoine;Jinshi Cui;Hongbin Zha	2013	2013 IEEE/RSJ International Conference on Intelligent Robots and Systems	10.1109/IROS.2013.6696597	computer vision;intelligent transportation system;calibration;simulation;computer science;remote sensing	Robotics	55.638406067372436	-40.3681205234776	38809
f4b96253f96adbafceb62cf2478fb9e50ca13399	evaluation of an optical flow method for measuring 2d and 3d corn seedling growth	optical flow;seedling growth	We propose the use of optical flow as a means of accurately measuring 2D and 3D growth of young corn seedlings. Our method is ultra-sensitive and operates in a non-intrusive, non-contact manner and can measure motions whose magnitude is as minuscule as 5 microns/second. Our 2D analysis, started in 1994 (Barron and Liptay, 1994), uses a least squares integration method to locally integrate spatio-temporal image derivatives into an optical flow field (Lucas and Kanade, 1981). Thus the work described here is an evaluation and verification of just one optical flow method for the use in (accurately) measuring young corn seedling growth. The 2D plant motion is displayed as a vector field of nearly uniform 2D velocities. A key assumption of the 2D growth analysis is that growth motion occurs locally in a 3D plane and its accuracy depends on this assumption being satisfied. We observed that the plant sways in 3D space as it grows, so this assumption does not hold over long time intervals. To capture this swaying over longer time intervals we extended our optical flow approach to 3D (Barron and Liptay, 1997). We use a single least squares calculation to integrate all spatio-temporal image derivatives into a single 3D velocity. Each image in the sequence consists of two views of the same seedling; one view of the corn seedling is front-on while the second view is an orthogonal view (at 90 degrees) of the seedling made by projecting the plant’s orthogonal image onto a mirror oriented at 45° with respect to the camera. We compute 3D optical flow at the corn seedling’s tip by using a simple extension of the 2D motion constraint equation. Both the 2D and 3D methods assume orthographic projection, which holds locally in the image plane. This allowed motions in pixels/frame to be directly scaled to meters/second. We conclude this chapter by showing the accuracy of optical flow as a means of measuring 2D and 3D corn seedling growth.	optical flow	John L. Barron;Albert Liptay	1998		10.1007/978-94-015-9538-4_15	botany	Vision	54.77689842646392	-50.6580303434707	38882
20567ca234e42b4d1553cb9565531b7ce92e01b4	modeling non-convex configuration space using linear complementarity problems	contact model;computational geometry;usa councils;geometry information;information geometry;configuration space;computational modeling;simulation methods;collision detection;shape;error correction;games;solid modeling;mathematical model;nonconvex configuration space;computational modeling error correction solid modeling computer science tunneling robotics and automation usa councils information geometry friction games;face;computer science;numerical models;linear complementarity problem;friction;collision detection nonconvex configuration space linear complementarity problem contact model geometry information;new physics;robotics and automation;tunneling	In this paper, we proposed a new physical simulation method that can model non-convex configuration space. The new method employs a novel contact model that take into account geometry information of objects. It can also be shown that it reduces the work for collision detection routines.	collision detection;complementarity theory;dynamical simulation;linear complementarity problem;physics engine	Binh Nguyen;Jeffrey C. Trinkle	2010	2010 IEEE International Conference on Robotics and Automation	10.1109/ROBOT.2010.5509728	face;physics beyond the standard model;configuration space;games;mathematical optimization;simulation;error detection and correction;computational geometry;shape;artificial intelligence;friction;mathematical model;mathematics;geometry;quantum tunnelling;solid modeling;linear complementarity problem;computational model;collision detection;information geometry	Robotics	72.05721247016005	-34.37323902351234	38908
a33be54a51785553b578eb50102bc65122cf2412	interactive visualization of high density streaming points with heat-map	heating;会议论文;visualization;streaming media;image color analysis;pipelines;data visualization;colour analysis interactive high density streaming point visualization heat map overlapping problem regular streaming format large point set kernel density estimation point distribution estimation perceptive feature interactive feature real time interaction geographical dataset computational complexity;data visualization heating image color analysis pipelines streaming media visualization;image colour analysis computational complexity;visual interaction large data information visualization streaming points heat map	Visualization of high density streaming points has become a challenge in information exploration. In this paper, we present a new pipeline for the interactive visualization of large points set. The pipeline is based on the idea that heat-map can overcome the overlapping problem in visualization of high density streaming points. Thus, we firstly define a regular streaming format for large point set which can be updated or changed continually. Based on streaming points, we use kernel density estimation to estimate the point distribution and visualize the density image. Perceptive and interactive features are also considered in our visualization. To our knowledge, our pipeline is the first work that focuses on perceptive visualization of high density streaming points. The main step of our pipeline is accelerated via GPU rendering in order to make scene of real-time interaction in visualization. We demonstrate the visual effectiveness of our pipeline on a geographical dataset of high-density streaming points.	apache spark;big data;graphics processing unit;heat map;interactive visualization;interactivity;kernel density estimation;layer (electronics);product binning;real-time transcription;streaming media;visual effects	Chenhui Li;George Baciu;Yu Han	2014	2014 International Conference on Smart Computing	10.1109/SMARTCOMP.2014.7043852	computer vision;information visualization;computer science;theoretical computer science;computer graphics (images)	Visualization	69.10469917565086	-51.61279048168843	38967
013303d1aae9f7bea225383ca4e7eb27f4168a69	new probabilistic approaches to the ax = xb hand-eye calibration without correspondence	convolution probabilistic logic calibration covariance matrices robot sensing systems;probability calibration dexterous manipulators filtering theory manipulator kinematics matrix algebra;calibration accuracy improvement ax xb hand eye calibration problem rigid body transformations asynchronous sensors missing data probabilistic approach data streams ill conditioned data pair filtering batch method	The hand-eye calibration problem was first formulated decades ago and is widely applied in robotics, image guided therapy, etc. It is usually cast as the “AX = XB” problem where the matrices A, B, and X are rigid body transformations in SE(3). Many solvers have been proposed to recover X given data streams {Ai} and {Bi} with correspondence. However, exact correspondence might not be accessible in the real world due to the asynchronous sensors and missing data, etc. A probabilistic approach named “Batch method” was introduced in previous research of our lab, which doesn't require a prior knowledge of the correspondence between the two data streams {Ai} and {Bj}. Analogous to non-probabilistic approaches which require data selection to filter out ill-conditioned data pairs, the Batch method has restrictions on the data set {Ai} and {Bj} that can be used. We propose two new probabilistic approaches built on top of the Batch method by giving new definitions of the mean on SE(3), which alleviate the restrictions on the data set and significantly improve the calibration accuracy of X.	approximation;condition number;microsoft dynamics ax;missing data;numerical linear algebra;robotic arm;robotics;sensor;simulation;xb machine	Qianli Ma;Haiyuan Li;Gregory S. Chirikjian	2016	2016 IEEE International Conference on Robotics and Automation (ICRA)	10.1109/ICRA.2016.7487635	mathematical optimization;artificial intelligence;theoretical computer science;machine learning;control theory;mathematics;statistics	Robotics	54.23085309360505	-41.08644891983044	38977
cc7954e696ea7e5ce41a858c2218d93fd8cf2c9c	fast matching of feature point and relative motion estimation for asteroid landing phase	entry descent and landing spacecraft;image matching;position control aerospace computing altimeters data acquisition entry descent and landing spacecraft feature extraction image matching laser ranging motion estimation numerical analysis;motion estimation;laser ranging;numerical analysis;aerospace computing;position control;feature extraction;real deep space missions real time calculation ability positioning accuracy robust image feature matching algorithm searching vector small searching window distance data acquisition laser altimeter multiple image matching process lander motion numerical simulation asteroid images fast feature point matching relative motion estimation asteroid landing phase;vectors navigation surface morphology cameras probes surface treatment quaternions;data acquisition;altimeters	Due to the extremely high requirements of real-time calculation ability and positioning accuracy, a rapid and robust image feature matching algorithm based on searching vector and small searching window is presented in this paper. Firstly, the image is obtained during landing, and then, combines the distance data acquired by laser altimeter and estimated information from the matching process of multiple images, the motion of the lander relative to asteroid can be precisely estimated. Finally, the validity and speediness of the proposed algorithm is confirmed by numerical simulations according to asteroids' images obtained in real deep space missions.	algorithm;feature (computer vision);lunar lander (video game series);motion estimation;numerical analysis;real-time clock;requirement;simulation	Shengying Zhu;Rui Xu;Huan Wang;Haijing Hu	2013	2013 10th IEEE International Conference on Control and Automation (ICCA)	10.1109/ICCA.2013.6565119	computer vision;geodesy;feature extraction;numerical analysis;computer science;altimeter;motion estimation;data acquisition;remote sensing	Robotics	55.62913371989145	-38.930346963290894	38980
4ae8aa3dde52972536db961995e0e9ce3d32e46c	cross-field haptics: multiple direction haptics combined with magnetic and electrostatic fields		We present a new method of rendering haptic textures that utilizes electrostatic and magnetic fields. In conventional research, a single physical quantity is used to render haptic textures. By contrast, our method combines multiple fields (electrostatic and magnetic). Although these fields have no direct interference, combining them provides benefits such as the ability to produce multi-resolution haptic images and synergistic effects on haptic perception. We investigate the increase in the variation of texture by comparing each single field method. Furthermore, we conduct user experiments and quantitative measurements.	experiment;haptic technology;interference (communication);synergy	Satoshi Hashizume;Kazuki Takazawa;Amy Koike;Yoichi Ochiai	2017	2017 IEEE World Haptics Conference (WHC)	10.1109/WHC.2017.7989930	computer vision;control engineering;computer science;rendering (computer graphics);artificial intelligence;electrostatics;haptic perception;magnetic field;electromagnet;haptic technology;tactile sensor;interference (wave propagation)	Robotics	79.89152005589143	-27.128583666094862	39010
e090eefaea3bb1e3c1ffcb47b75b64620fe69c6f	a stochastic self-replicating robot capable of hierarchical assembly	self repair;robotic self diagnosis;mobile robots;multi robot systems;manufacturing;robotic self replication;swarm robotics;modular robots;mechatronic systems	Robotica / Volume 29 / Special Issue 01 / January 2011, pp 137 152 DOI: 10.1017/S0263574710000780, Published online: 14 January 2011 Link to this article: http://journals.cambridge.org/abstract_S0263574710000780 How to cite this article: Georgios Kaloutsakis and Gregory S. Chirikjian (2011). A stochastic self-replicating robot capable of hierarchical assembly. Robotica, 29, pp 137-152 doi:10.1017/S0263574710000780 Request Permissions : Click here	aggregate data;aggregate function;attachments;computer cluster;control flow;control system;here document;image scaling;initial condition;randomness;robot;self-replicating machine;self-replication	Georgios Kaloutsakis;Gregory S. Chirikjian	2011	Robotica	10.1017/S0263574710000780	control engineering;mobile robot;swarm robotics;simulation;articulated robot;computer science;engineering;artificial intelligence;social robot;self-reconfiguring modular robot;robot control;manufacturing;personal robot	Robotics	58.76487205124495	-24.064282354928658	39034
df7e50d83c23f9068174fd23cf395b4f987f6541	on the sensor-based navigation by changing a direction to follow an encountered obstacle	mobile robot;path planning;mobile robots;navigation;natural environment;2d complicated environments sensor based navigation obstacle following sensor based navigation algorithms mobile robot cockroaches bug2 classl graphics simulator;navigation mobile robots path planning;navigation mobile robots shape system recovery orbital robotics clocks graphics infrared sensors tactile sensors kinematics	In the last decade, many sensor-based navigation algorithms have been proposed. In the sensor-based navigation, a robot arrives at its goal globally while avoiding neighbr obstacles locally by sensor information. in every environment, a mobile robot arrives at its goal surely. However if an environment has complicated shape, a mobile robot sometimes joins a loop and consequently runs long until its goal. In general, a loop consists of routes which a robot foliows obstacles in the same direction. Nevertheless in almost previous algorithms, a mobile robot follows an encountered obstacle in a constant direction. On this observation, a robot is exempted from participation of a loop by reversing a direction io follow an obstacle. Firstly, we propose previous algorithms whose following direction is alternatively changed. This strategy has been adopted by cockroaches living in a naPral environment. Secondly, wepropose the algorithms whose following dkrection is randomly reversed. Then we compare paths generated by constant, alternative, and random selections in Bug2 and Class1 under a graphics simulator for 2D complicated environments.	algorithm;graphics;mobile robot;randomness;reversing: secrets of reverse engineering;sensor	Hiroshi Noborio;Takashi Yoshioka;Shoji Tominaga	1997		10.1109/IROS.1997.655060	control engineering;mobile robot;computer vision;simulation;computer science;engineering;artificial intelligence;social robot;robot control;mobile robot navigation	Robotics	57.93251949157143	-27.471512997683647	39048
6dade77b8f9450e563bcc9b7e74c6f0c0dfc0e9e	automatic uav image geo-registration by matching uav images to georeferenced image data	unmanned aerial vehicle;geo registration;image registration;point cloud	Recent years have witnessed the fast development of UAVs (unmanned aerial vehicles). As an alternative to traditional image acquisition methods, UAVs bridge the gap between terrestrial and airborne photogrammetry and enable flexible acquisition of high resolution images. However, the georeferencing accuracy of UAVs is still limited by the low-performance on-board GNSS and INS. This paper investigates automatic geo-registration of an individual UAV image or UAV image blocks by matching the UAV image(s) with a previously taken georeferenced image, such as an individual aerial or satellite image with a height map attached or an aerial orthophoto with a DSM (digital surface model) attached. As the biggest challenge for matching UAV and aerial images is in the large differences in scale and rotation, we propose a novel feature matching method for nadir or slightly tilted images. The method is comprised of a dense feature detection scheme, a one-to-many matching strategy and a global geometric verification scheme. The proposed method is able to find thousands of valid matches in cases where SIFT and ASIFT fail. Those matches can be used to geo-register the whole UAV image block towards the reference image data. When the reference images offer high georeferencing accuracy, the UAV images can also be geolocalized in a global coordinate system. A series of experiments involving different scenarios was conducted to validate the proposed method. The results demonstrate that our approach achieves not only decimeter-level registration accuracy, but also comparable global accuracy as the reference images.	aerial photography;airborne ranger;digital elevation model;digital geometry;experiment;feature detection (computer vision);feature detection (web development);geolocation;heightmap;image resolution;on-board data handling;one-to-many (data model);orthophoto;photogrammetry;satellite navigation;scale-invariant feature transform;terrestrial television;unmanned aerial vehicle	Xiangyu Zhuo;Tobias Koch;Franz Kurz;Friedrich Fraundorfer;Peter Reinartz	2017	Remote Sensing	10.3390/rs9040376	computer vision;simulation;image registration;point cloud;remote sensing	Vision	54.8485369459865	-44.27676948747661	39055
9e8c428348a4084e250d6e31fc61e30ca3248321	action observation in collision-free motion planning for mobile robots	mobile robot;cooperative systems mobile robots path planning;path planning;mobile robots;work environment;simulation experiment;cooperative systems;mobile robots collision avoidance mobile communication robot sensing systems motion planning;action observation;inter robot communication action observation collision free motion planning mobile robots mutual collision avoidance narrow uncertain environment;motion planning;collision avoidance	This paper addresses the problem of mutual collision avoidance of mobile robots in a narrow and uncertain environment. The minimal application of inter-robot communication is required to develop an autonomous and flexible mobile robot in such an environment. In order to reduce communication application function of action observation is introduced into a robot. A mobile robot gains more information about the local working environment by observing actions of other robots. It always tries to plan motions for avoiding a collision with its own sensory data. The effectiveness of this approach on collision avoidance is verified with simulation experiments.	mobile robot;motion planning	Landi Shan;Tsutomu Hasegawa	1995		10.1109/IROS.1995.526134	control engineering;mobile robot;computer vision;simulation;computer science;artificial intelligence;motion planning;robot control	Robotics	57.85460389038266	-23.972094265337468	39068
2590733bdd08f9fc884e87fea3417d114bb9ed3f	façade segmentation in a multi-view scenario	image segmentation civil engineering computing construction industry;industrial street view dataset facade segmentation multiview scenario facade areas;urban environment;image segmentation;multi view context semantic segmentation;construction industry;semantics;laser scanner;laser radar;image segmentation buildings semantics context three dimensional displays laser radar pixel;semantic interpretation;three dimensional;civil engineering computing;3d model;three dimensional displays;pixel;semantic segmentation;limit of detection;multi view;context;buildings;architectural style	"""We examine a new method of façade segmentation in a multi-view scenario. A set of overlapping, thus redundant street-side images exists and each image shows multiple buildings. A semantic segmentation identifies primary areas in the image such as sky, ground, vegetation, and façade. Subsequently, repeated patterns are detected in image segments previous labeled as """"façade areas"""" and are applied to separate specific facades from each other. Experimentation is based on an industrial street-view dataset from a moving car by well-designed, calibrated, automated cameras. High overlap images define a multi-view scenario. We achieve 97% pixel-wise segmentation effectiveness, outperforming current state-of-the-art methods."""	autostereogram;calibration (statistics);computer vision;digital data;experiment;free viewpoint television;pixel;procedural modeling	Michal Recky;Andreas Wendel;Franz Leberl	2011	2011 International Conference on 3D Imaging, Modeling, Processing, Visualization and Transmission	10.1109/3DIMPVT.2011.52	computer vision;simulation;geography;segmentation-based object categorization;image segmentation;scale-space segmentation;engineering drawing	Vision	56.69421192420014	-45.83654748595433	39154
a94f79f5dee444eb793d2f3882a6dcb33bd2c804	fast and reliable autonomous surgical debridement with cable-driven robots using a two-phase calibration procedure		Automating precision subtasks such as debridement (removing dead or diseased tissue fragments) with Robotic Surgical Assistants (RSAs) such as the da Vinci Research Kit (dVRK) is challenging due to inherent nOnlinearities in cable-driven systems. We propose and evaluate a novel two-phase coarse-to-fine calibration method. In Phase I (coarse), we place a red calibration marker on the end effector and let it randomly move through a set of open-loop trajectories to obtain a large sample set of camera pixels and internal robot end-effector configurations. This coarse data is then used to train a Deep Neural Network (DNN) to learn the coarse transformation bias. In Phase II (fine), the bias from Phase I is applied to move the end -effector toward a small set of specific target points on a printed sheet. For each target, a human operator manually adjusts the end -effector position by direct contact (not through teleoperation) and the residual compensation bias is recorded. This fine data is then used to train a Random Forest (RF) to learn the fine transformation bias. Subsequent experiments suggest that without calibration, position errors average 4.55mm. Phase I can reduce average error to 2.14mm and the combination of Phase I and Phase II can reduces average error to 1.08mm. We apply these results to debridement of raisins and pumpkin seeds as fragment phantoms. Using an endoscopic stereo camera with standard edge detection, experiments with 120 trials achieved average success rates of 94.5 %, exceeding prior results with much larger fragments (89.4%) and achieving a speedup of 2.1x, decreasing time per fragment from 15.8 seconds to 7.3 seconds. Source code, data, and videos are available at https://sites.google.com/view/calib-icra/.	clutter;deep learning;discretization;edge detection;experiment;human–computer interaction;in-phase and quadrature components;pixel;printing;radio frequency;random forest;randomness;robot end effector;speedup;stereo camera;two-phase locking	Daniel Seita;Sanjay Krishnan;Roy Fox;Stephen McKinley;John F. Canny;Kenneth Y. Goldberg	2018	2018 IEEE International Conference on Robotics and Automation (ICRA)	10.1109/ICRA.2018.8460583	simulation;engineering;calibration;pixel;speedup;pumpkin seed;stereo camera;computer vision;teleoperation;edge detection;artificial intelligence;robot end effector	Robotics	59.26790490300066	-34.54131909056168	39220
e7cba753ab12771e61639d738479b135a74844cc	ekf-slam for auv navigation under probabilistic sonar scan-matching	acoustic images;autonomous underwater vehicle;auv navigation;underwater vehicles;mechanical scanning imaging sonar;uncertainty;image matching;path planning;acoustics;slam;kalman filters;sonar uncertainty simultaneous localization and mapping vehicles acoustics acoustic beams;mobile robots;remotely operated vehicles;sonar imaging;scan matching;simultaneous localization and mapping;uncertainty estimation;position estimation;range scan;acoustic imaging;vehicles;dead reckoning;ekf;acoustic images ekf extended kalman filter slam simultaneous localization and mapping auv navigation autonomous underwater vehicle probabilistic sonar scan matching range scan mechanical scanning imaging sonar robot displacement uncertainty estimation;extended kalman filter;acoustic beams;slam robots;underwater vehicles acoustic imaging image matching kalman filters mobile robots path planning remotely operated vehicles slam robots sonar imaging;robot displacement;probabilistic sonar scan matching;sonar	This paper proposes a pose-based algorithm to solve the full Simultaneous Localization And Mapping (SLAM) problem for an Autonomous Underwater Vehicle (AUV), navigating in an unknown and possibly unstructured environment. A probabilistic scan matching technique using range scans gathered from a Mechanical Scanning Imaging Sonar (MSIS) is used together with the robot dead-reckoning displacements. The proposed method utilizes two Extended Kalman Filters (EKFs). The first, estimates the local path traveled by the robot while forming the scan as well as its uncertainty, providing position estimates for correcting the distortions that the vehicle motion produces in the acoustic images. The second is an augmented state EKF that estimates and keeps the registered scans poses. The raw data from the sensors are processed and fused in-line. No priory structural information or initial pose are considered. Also, a method of estimating the uncertainty of the scan matching estimation is provided. The algorithm has been tested on an AUV guided along a 600 m path within a marina environment, showing the viability of the proposed approach.	acoustic cryptanalysis;algorithm;dead reckoning;differential gps;distortion;extended kalman filter;ground truth;marina;robot;sonar (symantec);sensor;simultaneous localization and mapping;velocity (software development)	Angelos Mallios;Pere Ridao;David Ribas;Francesco Maurelli;Yvan R. Petillot	2010	2010 IEEE/RSJ International Conference on Intelligent Robots and Systems	10.1109/IROS.2010.5649246	computer vision;simulation;computer science;engineering;artificial intelligence;extended kalman filter;remote sensing	Robotics	54.575298951915585	-36.19218525445611	39310
53577db64e1ba64936d1eb31b75a1e3bf05e8234	design and navigation of wheeled, running, swimming and flying robots	microrobots;aircraft control;goods distribution;legged locomotion;path planning;inspection;quadruped walker wheeled robot navigation running robot navigation swimming robot navigation flying robot navigation factory workhorses workcells search and rescuing task surveillance and inspection task planetary exploration task autonomous good transportation task legged robot navigation aerial robot navigation natural dynamics exploitation serial elastic actuation exploitation microhelicopters projects optimal propulsion small fixed wing airplane solar powered generator;robot dynamics aircraft control autonomous aerial vehicles goods distribution helicopters industrial robots inspection legged locomotion microrobots path planning propulsion;mobile robots inspection navigation airplanes conferences robot motion;industrial robots;propulsion;robot dynamics;helicopters;autonomous aerial vehicles	Summary form only given. Robots are rapidly evolving from factory workhorses, which are physically bound to their workcells, to increasingly complex machines capable of performing challenging tasks as search and rescuing, surveillance and inspections, planetary exploration or autonomous transportation of goods. This requires robots to operate in unstructured and unpredictable environments and various terrains. My talk will focus on design and navigation aspects of wheeled, legged, swimming and aerial robots operating in complex environments. Our wheeled inspection robots are designed for crawling into machine and take various measurement. For our quadruped walker we are researching optimal ways for exploiting the natural dynamics and serial elastic actuation. Our swimming robots take inspiration from natural counterpart for optimal propulsion and with our micro-helicopters projects we approach autonomous flight and inspections in cluttered and very narrow indoor environments as well as GPS denied visual navigation in cities. And with the solar airplanes we develop a small fixed-wing airplane capable of staying in the air indefinitely due to its solar powered generator.	aerial photography;amiga walker;autonomous robot;global positioning system;machine vision;planetary scanner;robotics	Roland Siegwart	2013	9th International Workshop on Robot Motion and Control	10.1109/RoMoCo.2013.6614591	control engineering;mobile robot;computer vision;simulation;engineering;robot locomotion;robot control;mobile robot navigation	Robotics	55.41270798676619	-28.281609267495693	39323
beb668061545c0a8b549a57ec41515791bd29356	an algorithm for the interpolation of hybrid curves	implicit surface;second order;concepcion asistida;machining;computer aided design;interpolation;modele geometrique;error reduction;ajustamiento curva;trajectoire optimale;numerical method;surface parametrique;real time;superficie parametrica;implicit theory;computer digital control;herramienta corte;outil coupe;usinage;algebraic surfaces;nurbs surface;metodo numerico;optimal trajectory;temps reel;trayectoria optima;teoria implicita;conception assistee;tool paths;tiempo real;ajustement courbe;mecanizado;cutting tool;curve fitting;theorie implicite;parametric surface;tool path generation;control numerico computador;parametric curve;methode numerique;computer numerical control;geometrical model;commande numerique calculateur;hybrid curves;modelo geometrico	Real time tool path generation consists of off-line design and real time interpolation of tool paths. An hybrid curve is the intersection of a parametric surface and an implicit surface. Previous work in tool path interpolation focused mainly in the interpolation of parametric curves. Tool paths designed by drive surface methods are hybrid curves which, in general, cannot be represented as parametric curves. An algorithm for the interpolation of hybrid curves is proposed in this paper. The algorithm is based on interpolation of the projection of the hybrid curve into the parametric domain. Each increment involves a second-order interpolation step augmented by iterative error reduction.#R##N##R##N#Simulations of hybrid curve interpolation have been carried out. They are based on practical surfaces represented as NURB surfaces and implicit surfaces including a plane, a cylinder and a high order algebraic surface. They demonstrate that under typical machining conditions, interpolation error is well within the accuracy requirements of typical machining and that the use of one iteration error reduction can significantly reduce the path deviation. These show that the proposed algorithm is potentially useful for tool path interpolation for the machining of parametric surfaces.	algorithm;interpolation	Hon-Yuen Tam;Haiyin Xu;Peter W. Tse	2003	Computer-Aided Design	10.1016/S0010-4485(01)00211-1	spline interpolation;interpolation;bilinear interpolation;non-uniform rational b-spline;parametric equation;machining;numerical analysis;monotone cubic interpolation;interpolation;polynomial interpolation;stairstep interpolation;computer aided design;parametric surface;inverse quadratic interpolation;bicubic interpolation;mathematics;geometry;numerical control;algebraic surface;linear interpolation;nearest-neighbor interpolation;multivariate interpolation;engineering drawing;implicit personality theory;second-order logic;algorithm;curve fitting;trilinear interpolation;mechanical engineering	EDA	68.68312282291451	-38.15569169567818	39344
0fe838e4ee059ff0f1273210e6f9eba89e3cccf6	an analysis of symmetry for plane curves and plane curve algorithms	curva;concepcion asistida;computer aided design;modele geometrique;plane curve;curve algorithms;geometrie solide;geometrie plane;plane geometry;computer graphics;parametric curves;geometria solidos;courbe;curve;symetrie;symmetry;algorithme;algorithm;conception assistee;mathematical foundations;geometric modeling;simetria;geometria plana;grafico computadora;infographie;solid geometry;geometrical model;algoritmo;modelo geometrico	Bez, H.E., An analysis of symmetry for plane curves and plane curve algorithms, Computer Aided Geometric Design 9 (1992) 125-142. Precise geometric concepts of symmetry are defined, initially for planar paths and then for planar curves, and these are shown to give rise to an interesting connection with a functional equation. The definitions are then modified and applied to general curve algorithms that require finite sets of data points as input. Two symmetry properties are seen to arise in a natural way for these algorithms and are investigated for a general class of axis-invariant curves. Some results are then obtained for a sub-class of curves in common usage in computer graphics and constructive geometry applications for computer aided design. Finally, extensions of the concepts to non-planar curves and to surfaces are considered briefly. Throughout the treatment is from first principles, using simple group-theoretic methods to both express and investigate symmetry.	algorithm;apache axis;computer graphics;computer-aided design;data point;geometric design;theory	Helmut E. Bez	1992	Computer Aided Geometric Design	10.1016/0167-8396(92)90012-E	cubic plane curve;glide plane;plane curve;osculating curve;plane symmetry;parametric equation;affine plane;quartic plane curve;geometric modeling;computer aided design;solid geometry;plane;calculus;differential geometry of curves;mathematics;geometry;curve;symmetry;convex curve;computer graphics;butterfly curve	Theory	67.71651464354636	-40.25597123670543	39450
e36bd99596c646bc9f7ddd05e73f159e9d4ba66e	colonoscope 3d display integration medical robotics system	three dimensions;integrable system;endoscopy;fbg sensor based shape sensing;reference frame;intelligent colonoscope;lan based data acquisition;fbg;medical robotics;minimum invasive surgery;binocular vision;medical image processing;endoscopes;stereo image processing;surgery;medical robotics system;pose estimation binocular vision 3d reconstruction fbg;surgery endoscopes medical image processing medical robotics solid modelling stereo image processing;human intestinal tract;pose parameters;data acquisition;3d display;three dimensional displays medical robotics colonoscopy shape intelligent sensors head robot kinematics endoscopes surgical instruments minimally invasive surgery;3d reconstruction;binocular vision based position;colonoscope 3d display integration;solid modelling;coordinate system;lan based data acquisition colonoscope 3d display integration medical robotics system endoscopy minimum invasive surgery human intestinal tract intelligent colonoscope pose parameters fbg sensor based shape sensing binocular vision based position 3d reconstruction;pose estimation	Endoscopy is nearly the most typical instruments that meet the demand of minimum invasive surgery (MIS). However, owing to the complex condition of human intestinal tract and the limitation of traditional colonoscopy, colonoscopy is sometimes a difficult and dangerous procedure. Most difficulties during colonoscopy arise as a result of unpredictable looping of the instrument shaft within the colonic anatomy. In order to recognize and straighten the loops, therefore, three-dimension shape detection becomes a key technology for both traditional and intelligent colonoscope. In the operation for straitening the loops, it is necessary to twist the colonoscope. To acquire the turning angle relative to the patient position, it is very valuable for surgeon to know pose parameters of head of colonoscope. In this paper, integration system of FBG sensor-based shape sensing and binocular vision-based position of head are presented, which use spatial curve curvature information to reconstruction flexible rod and binocular vision-based to detect the pose relative to reference frame. Using 3D reconstruction technology and LAN-based data acquisition for FBG sensor, two systems are integrated into an effective system which can be used to display the shape and pose relative to world coordinate system in real time and provide an intelligent platform for doctor in the process of colonoscopy to reduce the pain of patient. Some experiments have been done to verify the validity of the whole system.	3d reconstruction;binocular vision;data acquisition;experiment;reference frame (video);robotics;stereo display;tract (literature)	Xinhua Yi;Jinwu Qian;Zhen Zhang;Linyong Shen	2007	2007 IEEE International Conference on Robotics and Biomimetics (ROBIO)	10.1109/ROBIO.2007.4522204	3d reconstruction;reference frame;binocular vision;three-dimensional space;integrable system;computer vision;simulation;pose;stereo display;computer science;engineering;coordinate system;data acquisition	Robotics	73.96020687967842	-30.359592970446062	39497
097f26cd6d09dd945a0c3599b1e44f6f42bdf09a	combining multi-localization methods for fault diagnosis in autonomous mobile robot systems		Autonomous mobile robots have been widely employed for many applications in indoor and outdoor environments. Most of these robots have to operate in environments where human intervention is expensive, slow, unreliable or even impossible. It is therefore essential for robots to monitor their behavior to diagnose and address faults before they result in catastrophic failures. In this paper we introduce a new approach to diagnose faults of autonomous mobile robot systems. The proposed methodology firstly computes the poses of the robot by using the onboard stereo camera, the wheels' encoders and the commanded velocities, respectively. Then, the residuals between each pair of the localization methods are used to evaluate the occurrence of faults. Experimental tests, in ideal fault free cases, have been carried out to find a reference threshold for each residual. A bool value is assigned to each residual by comparing it with the respective threshold. The bool values of all residuals are then combined and used to detect and isolate a fault in the robotic system. The pose of ground truth, obtained from a motion capture system, is used here to evaluate the errors of the poses obtained from three localization methods and validate their accuracy. Our approach can potentially detect and identify different faults of the robot systems. Experimental tests have shown its effectiveness in determine fault on the robot's wheel.	autonomous robot;encoder;ground truth;mobile robot;motion capture;stereo camera;wheels	Xiaojun Lu;Angela Faragasso;Yonghoon Ji;Hitoshi Kono;Atsushi Yamashita;Hajime Asama	2017	2017 IEEE International Conference on Real-time Computing and Robotics (RCAR)	10.1109/RCAR.2017.8311860	residual;encoder;robot;computer vision;ground truth;stereo camera;robot kinematics;motion capture;mobile robot;artificial intelligence;computer science	Robotics	56.580153816411226	-36.08848910226784	39499
9f00d42b5cfc7e9db9681e06b001b2bfe72b7d00	hardware implementation of ewa - for point-based three-dimensional graphics rendering	hardware acceleration;point-based graphics;graphics rendering;surfels	This paper presents a novel algorithm for rasterization of circular scene elements projected as ellipses, suitable for hardware acceleration of point- based scene rendering. The algorithm is based on the screen space Elliptical Weighted Average (EWA) filter, promising high quality rendering, support for transparent objects, screen space and texture space antialiasing, etc.		Adam Herout;Pavel Zemcík;Julien Reptin	2004		10.1007/1-4020-4179-9_85	computer vision;tiled rendering;simulation;image-based modeling and rendering;rendering;computer science;texture memory;software rendering;computer graphics (images)	Graphics	66.7610018812891	-51.30590079497074	39565
c34c547bd8166cc0d59bee204f018b96cb6dd53f	adaptive hybrid grids for diverse industrial applications.	grid generation;industrial application	An adaptive hybrid prismatic/tetrahedral grid generation method is described and applied to complex geometries for diverse industrial applications. The method consists of using a surface mesh generator to triangulate the geometry to be modeled. The volume mesh is then created using prismatic and tetrahedral elements. The prisms cover the region close to each body's surface for better resolution of viscous gradients, while tetrahedra are created in the remainder of the domain. An adaptive redistribution scheme is used to better resolve boundary layers. The grid generator is tested with various complex geometries and the resulting hybrid meshes are presented. The applicability of the adaptive hybrid grid generator over a wide range of geome-tries with minimal user interaction demonstrates the robustness and universality of the method.	gradient;mesh generation;universality probability;volume mesh	Aly Khawaja;Yannis Kallinderis;Harlan McMorris	1998			mesh generation;distributed computing;computer science	Visualization	69.7487268941759	-45.359413034223394	39584
9dda13311afcd820491750f7e6bc495e2369888c	a new uniform format for 360 vr videos		Recent breakthroughs in VR technologies, especially in economic VR headsets and massive smartphones are creating a fast-growing demand for 3D immersive VR content. 360 VR videos record a surrounding environment in every direction and give users a fully immersive experience. Thanks to a ton of 360 cameras that launched in the past years, 360 video content creation is exploding and 360 VR videos are becoming a new video standard in the digital industry. When ERP and CMP are perhaps the most prevalent projection and packing layout for storing 360 VR videos, they have severe projection distortion, internal discontinuous seams or disadvantages in aspect ratio. We introduce a new format for packing and storing 360 VR videos using two stage mappings. Hemispheres are uniformly mapped onto squares. Two respective squares are stitched to form a rectangle with the aspect ratio 2 : 1. Our approach is able to avoid internal discontinuity and generate uniform pixel distribution, while keeping the aspect ratio close to the majority standard aspect ratio of 16 : 9. In our manuscript, we demonstrate some experimental results. In Section 6, we design a spherical surface where its latitude and longitude lines are evenly distributed, and there are a few red disks with the same area spreading on the surface. We have demonsrate that CMP/EAC, COHP, and CISP all have variance with disk’s areas at different regions after projection (see Figure 12). Their discontinuous seams can be clearly observed. Our results exhibit better performance against other methods. From Figure 13 to Figure 15, we show three different 360 video scenarios: buildings with regular and structured textures, aquarium with unstructured texture and indoor conference with dense crowd. However, due to the space limit, there are many more results that we could not include in the submission. We include these results in this separate document. The commonly used projections and packing layouts are compared.	360-degree video;3d computer graphics;digital video;distortion;erp;geographic coordinate system;pixel;reflections of signals on conducting lines;set packing;smartphone;virtual reality headset	Jishun Guo;Q. K. Pei;G. L. Ma;Long Liu;X. Y. Zhang	2018	Comput. Graph. Forum	10.1111/cgf.13564	computer vision;computer science;human–computer interaction;artificial intelligence;virtual reality;computing methodologies	Vision	64.09319247564184	-51.32938281992894	39611
d7d928ef2a691bdfb6f22625c7c29ada75f8c53a	virtual video camera: image‐based viewpoint navigation through space and time	free viewpoint video;view interpolation;i 3 3 computer graphics picture image generation i 3 8 applications;image based rendering	Abstract#R##N##R##N#We present an image-based rendering system to viewpoint-navigate through space and time of complex real-world, dynamic scenes. Our approach accepts unsynchronized, uncalibrated multivideo footage as input. Inexpensive, consumer-grade camcorders suffice to acquire arbitrary scenes, for example in the outdoors, without elaborate recording setup procedures, allowing also for hand-held recordings. Instead of scene depth estimation, layer segmentation or 3D reconstruction, our approach is based on dense image correspondences, treating view interpolation uniformly in space and time: spatial viewpoint navigation, slow motion or freeze-and-rotate effects can all be created in the same way. Acquisition simplification, integration of moving cameras, generalization to difficult scenes and space–time symmetric interpolation amount to a widely applicable virtual video camera system.		Christian Lipski;Christian Linz;Kai Berger;Anita Sellent;Marcus A. Magnor	2010	Comput. Graph. Forum	10.1111/j.1467-8659.2010.01824.x	computer vision;image-based modeling and rendering;computer science;multimedia;video post-processing;computer graphics (images)	Vision	59.681114192708066	-50.57923651206153	39619
1c2c2d2a16e706311f761c924918ed2cd2d660c1	ellipsoidal-blob approximation of 3d models and its applications	implicit surface;ellipsoidal blobby model;geometry data reduction;3d model;animation;data reduction	This paper presents a technique for automatically approximating a given mesh model with an ellipsoidal blobby model. Firstly, an ellipsoid decomposition algorithm is introduced to approximate given models by ellipsoids. After that, a blobby implicit surface employing ellipsoidal blobs is modelled to fit the sampling points on the given mesh. Finally, the reconstructed ellipsoidal blobby model is applied in two applications: the geometry data reduction and the target shape controlled cloud animation.	3d modeling;aliasing;approximation algorithm;approximation error;converge;ellipsoid method;implicit surface;polygon mesh;sampling (signal processing)	Shengjun Liu;Xiaogang Jin;Charlie C. L. Wang;Kin-Chuen Hui	2007	Computers & Graphics	10.1016/j.cag.2006.12.004	anime;mathematical optimization;data reduction;computer science;theoretical computer science;mathematics;geometry	Graphics	67.59020094916988	-45.73877000215846	39643
7db63279a6cbc5a6f79f893105566466c02cabe7	pattern formation in constrained environments: a swarm robot target trapping method	charge carrier processes;pattern formation;mathematical model;collision avoidance;adaptation models;robot kinematics	Inspired by the morphogenesis of biological organisms, gene regulatory network (GRN) based methods have been used in complex pattern formation of swarm robotic systems. In this paper, obstacle information was embedded into the GRN model to enhance the robots trap targets with a expected pattern while avoiding the obstacles in a distributed manner. Based on the modified GRN model, we adopt implicit function method to represent the expected pattern which is easily adjusted by adding extra feature points. With the existence of environmental constraints (e.g. tunnels or gaps in which robots have to adjust their pattern to conduct trapping task), we proposed a pattern adaptation strategy for the pattern modeler to adaptively adjust the expected pattern. The proposed model and strategies were verified through a set of simulation with complex environmental constraints.	algorithm;embedded system;gene regulatory network;pattern formation;robot;simulation;swarm;swarm robotics	Xingguang Peng;Shuai Zhang;Yunke Huang	2016	2016 International Conference on Advanced Robotics and Mechatronics (ICARM)	10.1109/ICARM.2016.7606963	simulation;engineering;artificial intelligence;machine learning	Robotics	59.564251522564135	-24.250358767425006	39650
d11252d01d19809c2874139671767710c249ab61	relay communications for mars exploration		Abstract#R##N##R##N#Telecommunication is an essential and challenging aspect of planetary exploration. For Mars landers, the constraints of mass, volume, power and energy typically limit their communications capabilities on the long-distance link back to Earth. By deploying relay spacecraft in Martian orbit, these landers can achieve much greater data return and can obtain contact opportunities at times when Earth is not in view. Currently, both NASA and European Space Agency (ESA) have pursued this strategy, deploying relay payloads on their Mars science orbiters. This relay infrastructure has significantly benefited the science return from the 2003 Mars Exploration Rovers and is poised to support the Phoenix Lander and Mars Science Laboratory missions later this decade. Longer-term plans call for continued growth in relay capability, greatly increasing data return from the Martian surface to enable exciting new Mars exploration concepts and advance our understanding of our planetary neighbour. Copyright © 2007 John Wiley & Sons, Ltd.	relay	Charles D. Edwards	2007	Int. J. Satellite Communications Networking	10.1002/sat.871	mars exploration program	HPC	54.42493384075341	-29.24006000858145	39658
ee6f04a40527a9b6cc480d49a271e0702c35462a	reviewtool: a database-driven visual effects editing application	participating media;shadows;area lights;voxelization		visual effects	Damien Fagnou;Christopher J. Cameron;Adam Valdez	2013		10.1145/2504459.2504494	computer vision;shadow;multimedia;computer graphics (images)	HCI	64.11373140513994	-50.726217690974245	39659
4804521dc0bf50ebd2092bd5203654940ce94b9d	a homing guidance law for binary range-rate measurements	path planning;vehicles measurement errors observers sensors vehicle dynamics mathematical model time measurement;variable structure systems;variable structure systems navigation observers path planning;observers;navigation;homing guidance law omnidirectional transmitting beacon omnidirectional receiver measurement errors vehicle location observer sliding mode controller heading angle planar homing guidance binary range rate measurements	In this paper we consider the problem of planar homing guidance for a vehicle with a known heading angle traveling to a beacon with unknown location and using only a measurement of binary range-rate. We present a planar homing guidance law utilizing a sliding mode controller and an observer. This guidance law does not require knowledge of the vehicle's location, the closest points of approach for multiple headings, or the time history of binary range-rate measurements. We also present this guidance law's response to initial conditions and measurement errors. This approach provides a method of low-cost, autonomous homing-guidance that utilizes a single, omnidirectional receiver to guide a vehicle to a single, omnidirectional transmitting beacon.	autonomous robot;course (navigation);initial condition;missile guidance;motion planning;multiple homing;proximity problems;transmitter	Dave W. Oyler;Pierre T. Kabamba;Anouck R. Girard	2013	52nd IEEE Conference on Decision and Control	10.1109/CDC.2013.6760061	control engineering;computer vision;navigation;computer science;engineering;control theory;motion planning	Robotics	56.235685296998284	-34.10033625274095	39707
266ab38d3f9f3753945e8ee9f7a00dbe5f1752f7	application of human body movements on theavatars model for the purpose of virtual trainingsystem				Branislav Sobota;Ladislav Jacho;Stefan Korecko	2016	Open Computer Science	10.1515/comp-2016-0008	computer vision;simulation;computer graphics (images)	Theory	60.78943533521451	-47.3633198876256	39724
b4d953f04d1521194235ad41047cda9e9556bbc9	on the timing of operator commands for the navigation of a robot swarm		A human-swarm interactive system has been shown to benefit from neglect benevolence. This means if the human interacts too often with a swarm of robots, it will degrade its performance in achieving the operational goal. Past works have focused on human-swarm interaction (HSI) for reaching rendezvous points. In this paper, we aim to establish neglect benevolence for realignment in a leader-follower Cucker-Smale system. The human operator issues heading commands to the leader and the follower robots tries to realign with the leader through Cucker-Smale model dynamics. Simulation results show that there is a minimum time interval that the operator should wait before issuing a new heading command in order for the swarm to remain in a flocking state.		Jing Ma;Edmund Lai;Jun Ren	2018	2018 15th International Conference on Control, Automation, Robotics and Vision (ICARCV)	10.1109/ICARCV.2018.8581236	operator (computer programming);swarm behaviour;flocking (texture);neglect;control engineering;rendezvous;robot;computer science	Robotics	59.436709447480254	-26.7184212232067	39729
5d3cede3a4d9c17baddef441005ff984e08d0c8f	mobile robot navigation by distributed vision agent	vision system;robot movil;distributed system;multiagent system;systeme reparti;systeme vision;path planning;distributed vision system;robot navigation;navigational aid;computer network;planification trajectoire;intelligent robot;sistema repartido;robot mobile;mobile robot navigation;aide navigation;robot inteligente;ayuda navegacion;sistema multiagente;moving robot;robot intelligent;systeme multiagent	A Distributed Vision System (DVS) is an infrastructure for mobile robot navigation. The system consists of vision agents embedded in an environment and connected with a computer network, observes events in the environment, and provides various information to robots. We have developed a prototype of the DVS which consists of sixteen vision agents and simultaneously navigates two robots. This paper describes the detail of the prototype system, shows the robustness through experimentation, and considers problems in applying a multi-agent system to a real robot system through development of the DVS.	mobile robot	Takushi Sogo;Hiroshi Ishiguro;Toru Ishida	1999		10.1007/3-540-46693-2_8	mobile robot;embedded system;computer vision;simulation;machine vision;computer science;artificial intelligence;motion planning;robot control;mobile robot navigation	Robotics	58.44085396958757	-31.45658291962534	39782
755e134ec5cd300b861e4cb591a75ebfa6163f6f	a correction algorithm for stereo matching with general digital cameras and web cameras	3d modelling and rendering;image processing;computer graphics;space based and situated computing;disparity;numerical analysis;stereo matching	We introduce stereo matching into our 3D computer graphics modelling because of its good interaction and convenience. Instead of the special standard stereo camera we evolve a network that consists of a series of the general digital cameras and web cameras and apply it to 3DCG modelling and motion capture. In this paper we propose a stereo axes correction algorithm to resolve the non-paralleled axes problem of the traditional stereo matching method and examine our new equations with experimental results.	algorithm;computer stereo vision;digital camera	Ningping Sun;Soichiro Murakami;Hiroshi Nagaoka;Takuya Shigemoto	2013	IJSSC	10.1504/IJSSC.2013.056408	computer stereo vision;stereo cameras;stereo camera;computer vision;simulation;computer science;computer graphics (images)	Vision	58.06815439858081	-50.00243494727874	39878
b88a2bc153133c5e64fd02a6f0bf1646e2cd8655	illuminating and rendering heterogeneous participating media in real time using opacity propagation		We present a new approach to illuminate and render single sca ttering effects in heterogeneous participating media in real time. The medium’s density is modeled as a sum of radial basis functions, and is then sampled into a first volumetric grid. We then integrate the extinctio n function from each light source to each cell in the volume by a fast cell-to-cell propagation process on the GPU, and store the result in a second volume. We finally render both scattering medium and surfaces using a re ular step ray-marching from the observer to the nearest surface. As we traverse the medium, we fetch data fro m both volumes and approximate a solution to the scattering equation. Our method is real-time, easy to im ple ent and to integrate in a larger pipeline. Figure 1: Left : the original scene. Right : a scattering media is added.	approximation algorithm;game engine;graphics processing unit;opengl shading language;radial (radio);radial basis function;real-time clock;real-time computing;rendering (computer graphics);shader;software propagation;traverse	Anthony Giroud;Venceslas Biri	2011			simulation;computer science;computer graphics (images)	Graphics	65.30609809837586	-50.846336072146194	39889
485e14818340ce634344d8512a184da104dcbb96	a non-invasive real-time method for measuring variable stiffness		The need for adaptability to the environment, energy conservation, and safety during physical interaction with humans of many advanced robotic applications has prompted the development of a number of Variable Stiffness Actuators (VSA). These have been implemented in a variety of ways, using different transduction technologies (electromechanical, pneumatic , hydraulic, but also piezoelectric, active polymeric, etc. ) and arrangements with elastic elements. All designs share a fundamentally unavoidable nonlinear behavior. The control schemes proposed for these actuators typically aim at independently controlling the position (or force) of the link, and its stiffness with respect to external disturbances. Although effective feedba ck control schemes using position and force sensors are commonplace in robotics, control of stiffness is at present completely open–loop . In practice, instead of measuring stiffness, it is inferred from the mathematical model of the actuator. Being this in most cases only roughly known, model mismatches affect severely stiffness control, undermining its utility. It should be noticed that, while for constant stiffness elements an accurate calibration of the model is possible, the same approach is hardly viable for variable stiffness systems. We propose a method for estimating stiffness while it is varied, either intentionally or not, hence without knowledge of the command inputs. The method uses instantaneous measurements of force and position at one of the ends of the compliant elements in the system, and derives a measure that asymptotically converges to the current value of stiffness, up to an error which can be bounded by an arbitrarily small value. Simulation and experimental results are provided, which illustrate the performance of the proposed measurement method. I. I NTRODUCTION To fully characterize the motion of human limbs, not only knowledge of their position and velocity, but also of their physical behavior in interaction with the environment, i.e . their mechanical impedance is needed [1, 2, 3]. Analogously , many modern robots are capable of changing their mechanical impedance to better perform a task and adapt to an environment. Variable impedance is obtained in these system by eith er intrinsic physical properties of the actuators (e.g. muscl es in humans, or Variable Stiffness Actuators [4] in robots) or by low-level control (neural reflexes or impedance control). Because of its ubiquitous importance, accurate measurements of the mechanical impedance of limbs are very important. Unfortunately, impedance is a rather elusive obje ct to measure, as it is not, strictly speaking, a physical quant ity (a) robotic application (b) biometric application Fig. 1. Two possible applications for Non-invasive real-ti me stiffness measurments: control of a Variable Impedance Actuated robot (a) and i dent fication of human limb impedance (b) [6]. per se (where by physical quantity it is meant “a property of a phenomenon, body, or substance, where the property has a magnitude that can be expressed as a number and a reference” [5]. Indeed, impedance is rather a differentia l operator relating the time course of physical quantities (f orces and displacements). In full generality, therefore, the pro cess of characterizing impedance of a system is more a problem of dynamical system identification than a direct measurement i n a traditional sense. Current protocols for identifying impedance in human motion typically measure the basic parameters of mass, dampin g, and stiffness, which concur in forming impedance, by experi ments in which perturbations are purposefully injected in t he system, and their effects are measured. These experiments a r designed specifically so as to isolate the effects of differe nt parameters of impedance, while at the same time minimizing perturbation of the task during which the measurement is needed [3]. In artificial robotic systems, impedance parame ters are either calculated on the basis of a precise description o f the model (wherever this is available), or obtained through accurate calibration procedures. In both natural and artificial systems (e.g. see fig.1), it wou ld be of great utility to have a method which could measure Robotics: Science and Systems 2010 Zaragoza, Spain June 27-30, 2010	biometrics;characteristic impedance;differentia;dynamical system;emoticon;experiment;high- and low-level;humans;human–computer interaction;kinesiology;mathematical model;nominal impedance;nonlinear system;piezoelectricity;real-time transcription;robot;robotics;sensor;simulation;stiffness;system identification;transduction (machine learning);velocity (software development)	Giorgio Grioli;Antonio Bicchi	2010		10.15607/RSS.2010.VI.012	calibration;actuator;machine learning;computer science;artificial intelligence;control engineering;adaptability;nonlinear system;bounded function;robotics;stiffness	Robotics	69.7526118005447	-24.126857849974687	39907
301a83dd289bfb30b63bee6fa3675db77d030f47	rgbdtam: a cost-effective and accurate rgb-d tracking and mapping system		Simultaneous Localization and Mapping using RGB-D cameras has been a fertile research topic in the latest decade, due to the suitability of such sensors for indoor robotics. In this paper we propose a direct RGB-D SLAM algorithm with state-of-the-art accuracy and robustness at a los cost. Our experiments in the RGB-D TUM dataset [34] effectively show a better accuracy and robustness in CPU real time than direct RGB-D SLAM systems that make use of the GPU. The key ingredients of our approach are mainly two. Firstly, the combination of a semi-dense photometric and dense geometric error for the pose tracking (see Figure 1), which we demonstrate to be the most accurate alternative. And secondly, a model of the multi-view constraints and their errors in the mapping and tracking threads, which adds extra information over other approaches. We release the open-source implementation of our approach1. The reader is referred to a video with our results 2 for a more illustrative visualization of its performance.	algorithm;box counting;central processing unit;experiment;graphics processing unit;open-source software;parallax;real-time computing;robotics;scientific visualization;semiconductor industry;sensor;simultaneous localization and mapping	Alejo Concha;Javier Civera	2017	2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)	10.1109/IROS.2017.8206593	computer vision;simulation;robustness (computer science);computer science;thread (computing);simultaneous localization and mapping;visualization;rgb color model;artificial intelligence;robotics	Robotics	53.766919157504034	-45.495592335104	39993
ab9d53c6faa0d8d85a13c03c9a9d32aca721c10f	the clapper: a dual-drive mobile robot with internal correction of dead-reckoning errors	internal correction;distance measurement;differential-drive mobile robots;positioning accuracy;relative position;compliant linkage;mobile robots;wheel encoders;multi-degree-of-freedom mobile platform;relative distance;clapper;path planning;dead-reckoning errors;position control;linear encoder;rotary encoders;error correction;bearing;compliant linkage autonomous platform with position error recovery;dual-drive mobile robot	"""This paper presents a new approach to accurate and reliable dead-reckoning with mobile robots. The approach makes use of special properties of our recently developed Multi-Degreeof-Freedom (MDOF) mobile platform, in which two differential-drive mobile robots (called """"trucks"""") are physically connected through a compliant linkage. Using one linear and two rotary encoders, the system can measure the relative distance and bearing between the two trucks. During operation, both trucks perform conventional dead-reckoning with their wheel encoders, but, in addition, use information about their relative position to correct dead-reckoning errors. Our system, called Compliant Linkage Autonomous Platform with Position Error Recovery (CLAPPER), requires neither external references (such as navigation beacons, artificial landmarks, known floorplans, or satellite signals), nor inertial navigation aids (such as accelerometers or gyros). Nonetheless, the experimental results included in this paper show one to two orders of magnitude better positioning accuracy than systems based on conventional dead-reckoning."""	dead reckoning;encoder;inertial navigation system;linkage (software);mobile operating system;mobile robot;rotary system	Johann Borenstein	1994		10.1109/ROBOT.1994.351095	control engineering;mobile robot;simulation;computer science;engineering;artificial intelligence;control theory	Robotics	57.013058542024034	-36.19497051068364	40070
591f4e9c6ade3051543bb3adcb5642472e891d11	improved vehicle based multibeam bathymetry using sub-maps and slam	time scale;localization vehicle based multibeam bathymetry sub sea acoustic multibeam bottom mapping simultaneous mapping underwater water vehicles vehicle position estimation terrain estimation vehicle trajectory extended kalman filter mid atlantic ridge jason rov acoustic mapping slam;simultaneous localization and mapping terrain mapping marine vehicles underwater vehicles underwater acoustics large scale systems yield estimation assembly delay remotely operated vehicles;kalman filters bathymetry underwater vehicles position control mobile robots terrain mapping;underwater vehicles;bepress selected works;mid atlantic ridge;kalman filters;mobile robots;multibeam bathymetry acoustic mapping slam;large scale;position control;position estimation;terrain mapping;extended kalman filter;bathymetry;assembly delay large scale systems marine vehicles remotely operated vehicles simultaneous localization and mapping terrain mapping underwater acoustics underwater vehicles yield estimation kalman filters bathymetry mobile robots position control terrain mapping underwater vehicles jason rov slam acoustic mapping extended kalman filter localization mid atlantic ridge simultaneous mapping sub sea acoustic multibeam bottom mapping terrain estimation underwater water vehicles vehicle based multibeam bathymetry vehicle position estimation vehicle trajectory slam acoustic mapping bathymetry multibeam	This paper presents an algorithm to improve sub-sea acoustic multibeam bottom mapping based on the simultaneous mapping and localization (SLAM) methodology. Multibeam bathymetry from underwater water vehicles can yield valuable large scale terrain maps of the sea door, but the overall accuracy of these maps is typically limited by the accuracy of the vehicle position estimates. The solution presented here uses small bathymetric patches created over short time scales in a sub-mapping context. These patches are registered with respect to one another and assembled in a single coordinate frame to produce a more accurate terrain estimate and provide improved renavigation of the vehicle trajectory. The mapping is implemented using a delayed state extended Kalman filter (EKF) and results are shown for a real world multibeam data set collected at the mid-Atlantic ridge using the JASON ROV.	acoustic cryptanalysis;algorithm;bathymetry;extended kalman filter;map;simultaneous localization and mapping	Christopher N. Roman;Hanumant Singh	2005	2005 IEEE/RSJ International Conference on Intelligent Robots and Systems	10.1109/IROS.2005.1545340	kalman filter;mobile robot;geodesy;computer science;bathymetry;control theory;extended kalman filter;marine engineering;remote sensing	Robotics	55.69027528189118	-34.70650456247306	40074
e5495de934a703f47b4304b19b914e486c22d992	adaptive geospatial joins for modern hardware		textabstractGeospatial joins are a core building block of connectedrnmobility applications. An especially challenging problemrnare joins between streaming points and static polygons. Sincernpoints are not known beforehand, they cannot be indexed.rnNevertheless, points need to be mapped to polygons with lowrnlatencies to enable real-time feedback.rnWe present an adaptive geospatial join that uses true hitrnfiltering to avoid expensive geometric computations in mostrncases. Our technique uses a quadtree-based hierarchical gridrnto approximate polygons and stores these approximations in arnspecialized radix tree. We emphasize on an approximate versionrnof our algorithm that guarantees a user-defined precision. Thernexact version of our algorithm can adapt to the expected pointrndistribution by refining the index. We optimized our implementationrnfor modern hardware architectures with wide SIMD vectorrnprocessing units, including Intel’s brand new Knights Landing.rnOverall, our approach can perform up to two orders of magnitudernfaster than existing techniques.	avx-512;alljoyn;approximation algorithm;computation;computer data storage;graphics processing unit;knights;materialized view;online and offline;quadtree;radix tree;real-time clock;simd;skylake (microarchitecture);streaming algorithm;vector processor	Andreas Kipf;Harald Lang;Varun Pandey;Raul Alexandru Persa;Peter A. Boncz;Thomas Neumann;Alfons Kemper	2018	CoRR		geospatial analysis;grid;computer hardware;vector processor;polygon;computer science;radix tree;joins;quadtree;simd	DB	67.97736551061944	-51.62137036375802	40192
3f8d3eee0f61f17c53315c62cecf2107482f3a35	motion planning and manipulation of multiple nanowires simultaneouly under electric-fields in fluid suspension	nanowires electrodes planning trajectory routing suspensions complexity theory;path planning electric fields electrodes microfluidics micromanipulators motion control nanowires;two stage motion planning algorithm multiple nanowire simultaneouly electric field fluid suspension automated steering electric field based design microfluidic device electrodes motion control algorithm electrophoretic force background electro osmotic flow	The automated steering and manipulation of multiple nanowires independently would enable the potentially scalable assembly of nanodevices for a variety of applications. We present an electric-field-based design for simultaneous motion planning and manipulation of multiple nanowires in liquid suspension. The design is built on a micro-fluidic device that is actuated by a simple, generic set of electrodes. We first present a motion-control algorithm to simultaneously steer multiple nanowires along desired trajectories under controlled electrophoretic forces, while compensating for background electro-osmotic flow. A two-stage motion-planning algorithm is then presented to generate the desired trajectory for each individual nanowire. Numerical simulations and experimental results confirm and demonstrate the performance of the proposed motion planning and control design.	algorithm;automated planning and scheduling;computational complexity theory;computational fluid dynamics;expectation propagation;experiment;flow network;motion planning;numerical linear algebra;scalability;simulation	Kaiyan Yu;Jingang Yi;Jerry Shan	2015	2015 IEEE International Conference on Automation Science and Engineering (CASE)	10.1109/CoASE.2015.7294127	control engineering;electronic engineering;simulation;engineering	Robotics	75.54022788492654	-24.778805093091982	40303
f95fe1365b79784ed0dd32eb1267670c46363180	comparison of misalignment estimation techniques between handheld device and walking directions	smart phones indoor environment pedestrians principal component analysis;legged locomotion;sensors;fis handheld device pedestrian navigation systems smartphone indoor environment pedestrian dead reckoning approaches inertial sensors quality magnetic field sensor drifts hand dynamic angular misalignment estimation pointing direction walking directions principal component analysis pca forward and lateral accelerations modeling flam frequency analysis of inertial signals;acceleration legged locomotion sensors estimation navigation principal component analysis accelerometers;acceleration;navigation;estimation;principal component analysis;pedestrian dead reckoning heading misalignment imu smartphone pedestrian navigation;accelerometers	Pedestrian navigation systems based on smartphone are experiencing fast progress in indoor environment. Pedestrian dead reckoning approaches combined with improved inertial sensors' quality and the exploitation of magnetic field are used to mitigate the sensor drifts. The last remaining issue is related to the hand dynamic. It consists in estimating the angular misalignment between the smartphone pointing direction and the walking direction. Even though, some methods exist, their performances are lacking accuracy and reliability. A comparison of the three main methods to estimate this angular misalignment is performed. These methods are based on Principal Component Analysis (PCA), Forward and Lateral Accelerations Modeling (FLAM) and Frequency analysis of Inertial Signals (FIS). Despite better results for the FIS method all algorithm suffer from large outliers and a need for improved robustness is identified.	algorithm;angularjs;database;dead reckoning;design review (u.s. government);experience;experiment;frequency analysis;lateral thinking;maximal set;microelectromechanical systems;mobile device;performance;principal component analysis;sensor;serial ata;smartphone	Christophe Combettes;Valérie Renaudin	2015	2015 International Conference on Indoor Positioning and Indoor Navigation (IPIN)	10.1109/IPIN.2015.7346766	embedded system;computer vision;simulation;engineering	Robotics	57.50811016739059	-37.34619050156966	40309
f6d1d149f80c20674353a2a615eb834f7684db91	learning motion dynamics to catch a moving object	robot learning;moving object;robot sensing systems;autonomous dynamical system;human demonstration learning motion dynamic moving object motion timing autonomous dynamical system robot motion encoding time independent encoding robustness violent perturbation trajectory icub robot;motion control;violent perturbation;motion timing;trajectory timing robot kinematics robot sensing systems joints dynamics;learning motion dynamic;human demonstration;dynamic system;robust control motion control position control robot dynamics;robust control;joints;trajectory;machine learning;position control;dynamics;icub robot;on the fly;robustness;robot dynamics;robot motion encoding;robot kinematics;time independent encoding;timing	In this paper, we consider a novel approach to control the timing of motions when these are encoded with autonomous dynamical systems (DS). Accurate timing of motion is crucial if a robot must synchronize its movement with that of a fast moving object. In previous work of ours [1], we developed an approach to encode robot motion into DS. Such a time-independent encoding is advantageous in that it offers robustness against violent perturbation by adapting on the fly the trajectory while ensuring high accuracy at the target. We propose here an extension of the system that allows to control the timing of the motion while still benefitting from all the robustness properties deriving from the time-independent encoding of the DS. We validate the approach in experiments where the iCub robot learns from human demonstrations to catch a ball on the fly.	autonomous robot;dynamical system;encode;experiment;icub;on the fly	Seungsu Kim;Elena Gribovskaya;Aude Billard	2010	2010 10th IEEE-RAS International Conference on Humanoid Robots	10.1109/ICHR.2010.5686332	robust control;motion control;robot learning;computer vision;dynamics;icub;computer science;artificial intelligence;trajectory;dynamical system;control theory;robot kinematics;robustness	Robotics	64.51163986784199	-24.881268879701576	40315
7c64f7a64b12bdecbede8b12f16ec3bca1280d0c	a compact shader for fpga-based volume rendering accelerators	volume rendering;image quality	We describe a map-based shading unit for volumetric ray-casting architectures. This is a critical part of volume rendering accelerators with respect to image quality, achievable performance, and resource consumption. The typical problem with map-based shaders is that highlights might not be rendered correctly on highly glossy surfaces due to the limited resolution of the maps. As a solution to this problem we introduce the use of detail light maps.	field-programmable gate array;shader;volume rendering	Günter Knittel	2007		10.1007/978-3-540-71431-6_25	image quality;computer vision;3d rendering;computer hardware;rendering;computer science;volume rendering;software rendering;computer graphics (images)	Visualization	66.22352303712593	-52.06189404474591	40380
0565d21a9cb5930ebe4ffda2e4ee7564dc0b57aa	new shank mechanism for humanoid robot mimicking human-like walking in horizontal and frontal plane	lateral displacement shank mechanism humanoid robot mimicking human like walking horizontal plane frontal plane human walking characteristics com motion center of mass motion lateral direction foot rotation angle humanoid robot wabian 2riii parallel mechanism shank size narrow step width;motion control humanoid robots legged locomotion;motion control;legged locomotion;humanoid robots;legged locomotion foot joints prototypes mimics educational institutions	This paper describes the development of a new shank mechanism and mimicking the human-like walking in the horizontal and frontal plane. One of human walking characteristics is that the COM (Center Of Mass) motion in the lateral direction is as small as 30 mm. We assume that it is thanks to the human walking characteristics in the horizontal plane that the step width is as narrow as 90 mm and the foot rotation angle is 12 deg. To mimic these characteristics, we developed a new shank and implemented it in a humanoid robot WABIAN-2RIII. It has a parallel mechanism which mimics the shank's size of human. Thanks to its size almost the same as human's the robot is capable of realizing gait with the narrow step width of 90 mm and the foot rotation angle of 12 deg. We evaluated the performance of the shank using WABIAN-2RIII. The robot could realize stepping in place with lateral displacement of CoM within 34 mm, which is almost as small as that of human.	displacement mapping;humanoid robot;lateral computing;lateral thinking;stepping level	Takuya Otani;A. Iizuka;D. Takamoto;Hiromitsu Motohashi;Tatsuhiro Kishi;Przemyslaw Kryczka;Nobutsuna Endo;Lorenzo Jamone;Kenji Hashimoto;Takamichi Takashima;Hun-ok Lim;Atsuo Takanishi	2013	2013 IEEE International Conference on Robotics and Automation	10.1109/ICRA.2013.6630644	motion control;computer vision;simulation;computer science;engineering;humanoid robot;artificial intelligence	Robotics	67.20874245197442	-24.44083925285369	40568
b82092d4557d1009a03ff736580a6ab6ceb889e0	rmap: a rectangular cuboid approximation framework for 3d environment mapping	3d mapping;robotics;robotteknik och automation;point cloud approximation	This paper presents a rectangular cuboid approximation framework (RMAP) for 3D mapping. The goal of RMAP is to provide computational and memory efficient environment representations for 3D robotic mapping using axis aligned rectangular cuboids (RC). This paper focuses on two aspects of the RMAP framework: (i) An occupancy grid approach and (ii) A RC approximation of 3D environments based on point cloud density. The RMAP occupancy grid is based on the Rtree data structure which is composed of a hierarchy of RC. The proposed approach is capable of generating probabilistic 3D representations with multiresolution capabilities. It reduces the memory complexity in large scale 3D occupancy grids by avoiding explicit modelling of free space. In contrast to point cloud and fixed resolution cell representations based on beam end point observations, an approximation approach using point cloud density is presented. The S. Khan (B) · D. Wollherr · M. Buss Institute of Automatic Control Engineering, Technische Universität München, Munich, Germany e-mail: sheraz.khan@tum.de D. Wollherr e-mail: dw@tum.de M. Buss e-mail: mb@tum.de A. Dometios · C. Verginis · C. Tzafestas Division of Signals, Control and Robotics, School of Electrical and Computer Engineering, National Technical University of Athens (NTUA), Athens, Greece e-mail: ath.dometios@gmail.com C. Verginis e-mail: chrisverginis@gmail.com C. Tzafestas e-mail: ktzaf@softlab.ntua.gr proposed approach generates variable sized RC approximations that are memory efficient for axis aligned surfaces. Evaluation of the RMAP occupancy grid and approximation approach based on computational and memory complexity on different datasets shows the effectiveness of this framework for 3D mapping.	algorithmic efficiency;apache axis;approximation algorithm;automatic control;computer engineering;control engineering;cuboid;data structure;email;minimum bounding box;multiresolution analysis;point cloud;r-tree;reflection mapping;robot;robotic mapping;robotics	Sheraz Khan;Athanasios Dometios;Chris Verginis;Costas S. Tzafestas;Dirk Wollherr;Martin Buss	2014	Auton. Robots	10.1007/s10514-014-9387-y	mathematical optimization;simulation;computer science;artificial intelligence;theoretical computer science;machine learning;robotics	Robotics	55.446190933678366	-42.087156813447976	40575
1fe934b19b7cf6e8c6005d0664eaa439081d08c4	design of an mri compatible haptic interface	robot sensing systems;high magnetic field;force sensors;degree of freedom;prototypes;loading;magnetic resonance image;force;mri compatible robot;delrin;abs plastic;magnetic resonance imaging;multiple axis sensing;post print;magnetic resonance imaging robot sensing systems force sensors loading force;surgical robots;force sensor;haptic interface	This paper proposes an MRI-compatible, 1-axis force sensing unit which is designed to be used as a haptic interface on an MRI compatible robot. Recently, it became a popular research direction to enable MRI in surgical operations and brain studies with the help of robotic devices. However, due to high magnetic field in MRI environment, conventional sensors and robots cannot be used in MRI rooms. Existing MRI-compatible force sensors have limited number of degrees of freedom or they do not offer compact solutions for multiple-axis sensing. In this paper, a compact 1-axis force sensing unit which employs a compliant displacement amplification mechanism is introduced and then analyzed for better sensitivity and accuracy. A combination of multiple proposed sensing units can be assembled to have a force sensor with desired number of degrees of freedom. Prototypes made of delrin and ABS-plastic are tested. Experiments indicated that the proposed sensor is suitable for force sensing and fully compatible to MRI. Also, the sensor made of delrin is superior in mechanical performance and MRI compatibility to ABS-plastic sample.	displacement mapping;experiment;haptic technology;optic axis of a crystal;robot;sensor	Melih Turkseven;Jun Ueda	2011	2011 IEEE/RSJ International Conference on Intelligent Robots and Systems	10.1109/IROS.2011.6095170	control engineering;simulation;computer science;engineering;electrical engineering;magnetic resonance imaging;prototype;haptic technology;degrees of freedom;force;force-sensing resistor	Robotics	75.15347347581454	-25.698691795924642	40652
8a7a2d4e833d4fa88eb504587e1f332e9d369750	whole body haptics for augmented humanoid task capabilities		A whole body tactile skin with a novel design is presented. It is installed on the entire surface of our adult-size humanoid robot. Experiments on various contact motion control, such as handling a 66kg human dummy, are realized.		Yasuo Kuniyoshi;Yoshiyuki Ohmura;Akihiko Nagakubo	2007		10.1007/978-3-642-14743-2_6	humanoid robot	Robotics	73.90480567465117	-26.17721830616821	40726
00a97dd596f2b8c96b1be195bfe2cf2843f0bf7d	the radiometry of multiple images	radiometric recovery;radiometry geometry image reconstruction lighting layout cameras reflectivity surface reconstruction light sources photometry;ambiant illumination radiometric reconstruction multiple image radiometry simultaneous recovery multiple illuminants surface albedo multiple views scene geometry camera geometry linear theory geometric recovery linear implementation nonlinear implementation simulation image reconstruction radiometric recovery lambertian reflection point light sources;linear theory;reflectivity;albedo;radiometric reconstruction;reconstruction;geometric recovery;simulation;lambertian reflection;geometry;layout;surface reconstruction;camera geometry;computer vision radiometry image reconstruction lighting albedo geometry;multiple views;computer vision;radiometry;nonlinear implementation;photometry;image reconstruction;scene geometry;linear model;lighting;ambiant illumination;surface albedo;multiple image radiometry;linear models;simultaneous recovery;linear implementation;cameras;light sources;multiple illuminants;point light sources	We introduce a methodology for radiometric reconstruction, the simultaneous recovery of multiple illuminants and surface albedoes from multiple views, assuming that the geometry of the scene and of the cameras is known. We formulate the linear theory of multiple illuminants and show its similarities with the theory of geometric recovery of multiple views. Linear and non-linear implementations are proposed; simulation results are discussed; and, finally, results on real images are presented. keywords reconstruction, multiple views, linear models, radiometric recovery, Lambertian reflection, point light sources, ambiant illumination, surface albedo	algorithm;analysis of algorithms;bundle adjustment;computation;experiment;global illumination;http 404;illumination (image);image noise;iteration;lambertian reflectance;least squares;linear model;linear system;metric;nonlinear system;normal (geometry);observable;shadow volume;simulation;solver;specularity;synthetic data	Quang-Tuan Luong;Pascal Fua;Yvan G. Leclerc	2002	IEEE Trans. Pattern Anal. Mach. Intell.	10.1109/34.982882	computer vision;computer science;linear model;mathematics;statistics	Vision	55.17477415595515	-51.92557551607027	40735
57984ab2339ff2832a8a00cbcaf82b100b7dcf77	boundary identification and triangulation of stl model	finite element methods;topology;boundary identification;delaunay triangulation;arteries;topology boundary value problems medical computing mesh generation;balanced binary tree;medical computing;finite element mesh generation;finite element mesh;biomedical engineering;topology reconstruction;data structures;image reconstruction;finite element mesh generation boundary identification delaunay triangulation stl model topology structure steiner point insertion;steiner point insertion;solid modeling;delaunay triangulation topology reconstruction half edge data structure double linked list balanced binary tree;double linked list;topology structure;constrained delaunay triangulation;data structures image reconstruction arteries topology mesh generation solid modeling educational institutions finite element methods rendering computer graphics biomedical engineering;stl model;boundary value problems;half edge data structure;rendering computer graphics;mesh generation;data structure;binary tree	In order to identify the border of STL model with open border, topology structure of STL model was reconstructed using half edge data structure. On this basis, border segments of STL model can be identified by a process of edge traversing. Then constrained Delaunay triangulation with Steiner point insertion was used to triangulate the border regions of STL model. In this way, STL model was closed and it provides necessary foundation to further finite element mesh generation.	algorithm;closing (morphology);computation;computational fluid dynamics;constrained delaunay triangulation;data structure;federal enterprise architecture;finite element method;mesh generation;stl (file format);steiner tree problem	Wenyu Fu;Aike Qiao;Pengbin Fu	2008	2008 International Conference on BioMedical Engineering and Informatics	10.1109/BMEI.2008.35	combinatorics;data structure;binary tree;computer science;mathematics;geometry	Robotics	69.79655483108176	-43.056554948448415	40746
01a08c6284e31478aa5168e2c15a57a4732b7cdb	efficient sub-regional multiple-source detection based on subspace matrix filtering	filtering;interference;arrays;matrix decomposition;covariance matrices;spatial filters signal detection;signal processing;signal plus interference subspace matrix filter multiple source detection;arrays interference matrix decomposition covariance matrices filtering signal processing narrowband;estimated signal plus interference subspace subregional multiple source detection subspace matrix filtering signals of interest;narrowband	We present an efficient approach for the sub-regional multiple-source detection. The essence of this approach is to extract the characteristic components of the signals of interest (SOIs) from the estimated signal-plus-interference subspace by a matrix filter. Compared with some other spatial filtering-based approaches, it has two significant advantages. First, since the power of each source in the signal-plus-interference subspace is normalized, the proposed approach is effective to filter out interferences regardless of their strengths. Second, the matrix filter would not reduce the dimension of SOIs, thus, the proposed approach is able to distinguish multiple SOIs from the output of the matrix filter.	basis (linear algebra);interference (communication);the matrix	Zhan Fan;Guolong Liang;Yan Wang;Yilin Wang;Qing Li	2015	IEEE Signal Processing Letters	10.1109/LSP.2014.2379619	filter;computer vision;computer science;signal processing;root-raised-cosine filter;pattern recognition;filter bank;mathematics;interference;matrix decomposition;statistics	ML	82.23393327935494	-37.499000991647634	40759
c31fd8fdb19aa2362a4c3a33d02130ae17566aa0	automated model acquisition from range images with view planning	automatic control;automated model acquisition;viewpoint planning;surface mesh;image processing;application software;hip;hip joint prosthesis;geometry;virtual reality;shape recovery;prosthetics;model acquisition;view planning;mechanical strut automated model acquisition range images view planning accurate cad models multiple range images surface mesh volumetric representations 3d model 3d models computer game controller hip joint prosthesis;computer vision;computer game controller;3d model;shape;range image;solid modeling;hip joint;volumetric representations;range images;computer vision image processing;solid modeling computer science automatic control hip prosthetics application software reverse engineering virtual reality geometry shape;computer science;multiple range images;accurate cad models;3d models;mechanical strut;computer game;reverse engineering	We present an incremental system that builds accura CAD models of objects from multiple range images. Usin a hybrid of surface mesh and volumetric representation the system creates a “water-tight” 3D model at each step the modeling process, allowing reasonable models to built from a small number of views. We also present method that can be used to plan the next view and reduce number of scans needed to recover the object. Results presented for the creation of 3D models of a computer gam controller, a hip joint prosthesis, and a mechanical strut.	3d modeling;computer-aided design;generalized additive model	Michael K. Reed;Peter K. Allen;Ioannis Stamos	1997		10.1109/CVPR.1997.609300	computer vision;application software;simulation;image processing;shape;computer science;automatic control;geometry;virtual reality;solid modeling;reverse engineering	Vision	66.10485247887922	-42.507409276972865	40766
46193f9b0ab07a44db3ac7f180b1c8a98e11f22f	non-photorealistic rendering of ink painting style diffusion	interior shading;painting;chinese drawing simulation;non photorealistic rendering;art;ink painting style diffusion;nonphotorealistic rendering;optical fiber networks;ink painting brushes rendering computer graphics pigments paints water optical mixing springs writing;skeleton;computational modeling;chinese drawing simulation nonphotorealistic rendering ink painting style diffusion contour drawing interior shading;contour drawing;ink;rendering computer graphics;rendering computer graphics art;model simulation;brushes	By mixing water and ink properly, ink painting obtains different concentrations to show the contrast of an object. It presents an effective rendering algorithm for ink painting that include contour drawing and interior shading to simulate the Chinese drawing. Paint model consists of water and pigments with different physical and optical characteristics. Paper and brush are modeled by multi-layers for realistic painting simulation. It proposed describes hairy brush behavior by the curving spring model on the base of the mechanical model simulation writing brush, and proposed the rice paper model to simulate by the fiber structure by considering rice paper thickness influence to water ink proliferation, In our simulation, water and pigments are not only transferred passively among paper surface, palette, and brush bristle but are also moved actively inside the paper. Experiment result for rendering example demonstrates this system can render images in impressively good non-photorealistic rendering styles.	algorithm;computation;non-photorealistic rendering;palette (computing);pigment;rendering (computer graphics);shading;simulation;thickness (graph theory);unbiased rendering	Tianding Chen	2009	2009 IEEE International Conference on Granular Computing	10.1109/GRC.2009.5255155	computer vision;painting;computer science;non-photorealistic rendering;skeleton;computer graphics (images)	Robotics	64.5406971040793	-48.57178517528093	40786
2de574451376bb2f77b47ba9fbce53e572c06779	coherence based double talk detector with soft decision	microphones;detectors;estimation theory;human computer interaction;probability;acoustic echo cancellation;acoustics;speech;adaptive filters;loudspeakers;speech noise detectors microphones loudspeakers acoustics coherence;acoustic signal detection;echo suppression;coherence;double talk detector;probability acoustic signal detection adaptive filters echo suppression estimation theory;adaptive filter;noise;acoustic echo canceller;coherence acoustic echo cancellation double talk detector;microphone soft decision coherence based double talk detector acoustic echo cancellation adaptive filter speakerphone double talk presence probability estimation baseline algorithm	Acoustic echo cancellation is one of the oldest applications of adaptive filters and today is a part of each speakerphone. An important block of each acoustic echo canceller is the double talk detector. It blocks the adaptation of the filter when near end voice is present and thus preventing the adaptive filter from diverging from the optimal position. In this paper we present an improved version of coherence based double talk detector. It provides estimation of the double talk presence probability per bin and per frame and has better precision compared to the baseline algorithm.	acoustic cryptanalysis;adaptive filter;algorithm;baseline (configuration management);echo suppression and cancellation	Ivan Tashev	2012	2012 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	10.1109/ICASSP.2012.6287843	adaptive filter;speech recognition;computer science;mathematics;statistics	Robotics	82.67014243796945	-33.255142380493936	40945
524409ab8b1f765c56b625c73a29c977981e8a24	i-rok: a human like robotic head	humanoid robot;robot design;social context;magnetic heads;neck;degree of freedom;human like robotic head;developmental head;i rok;developmental head i rok human like robotic head human robot interaction anthropomorphic head robot middle east technical university;robot design humanoid robot anthropomorphic robotic head;human robot interaction;joints;data mining;middle east technical university;anthropomorphic head robot;mechanical engineering;robots;face;humans;middle east;anthropomorphic;humanoid robots magnetic heads intelligent robots human robot interaction service robots anthropomorphism robot sensing systems eyes educational robots mechanical engineering;robotic head	In order to explore issues of human-robot interaction in a social context, we have constructed a humanoid robotic head called i-RoK. This paper focuses on the study and design of the anthropomorphic head robot developed at the Mechanical Engineering Department of Middle East Technical University. The robot has a total of 8 mechanical degrees of freedom. This allows the robot to mimic the same movements performed by human head. We discuss major design issues of the developmental head and the design characteristics of the robot, i-RoK, in this paper.	human–robot interaction;robot	O. Olcucuoglu;A. Bugra Koku;E. Ilhan Konukseven	2007	2007 7th IEEE-RAS International Conference on Humanoid Robots	10.1109/ICHR.2007.4813907	human–robot interaction;face;computer vision;simulation;computer science;humanoid robot;artificial intelligence;social robot;robot control;middle east	Robotics	67.17602704558612	-27.094359589273655	40948
b55bb5c4d768d9899798c34e7827b7271cfde882	on full aspect conveyed object inspection at high speed	lasers;belts faulty products production line waste reduction conveyed object inspection structured light system laser sources high speed cameras;waste reduction belts cameras conveyors failure analysis inspection;high speed cameras;conveyed object inspection;surface roughness;dimensional analysis;structured light;laser sources;length measurement;product line;inspection;belts;production line;failure analysis;waste reduction;multiple objectives;lasers cameras inspection belts image edge detection length measurement surface roughness;image edge detection;conveyors;faulty products;structured light system;high speed;cameras	Removing faulty products from a production line at an early production stage can lead to significant waste reduction and an improvement in quality. In order to inspect all of the visible surfaces of conveyed objects, a structured light system comprising two cameras and laser sources is presented. High speed cameras are used to provide accurate inspection at high belt speeds. The system locates and extracts information from multiple objects within a scene and then performs dimensional analysis on the extracted data from two opposing viewpoints. The objects are tracked as they move through the inspection area allowing for a full inspection. The dimensional measurements from each viewpoint are then brought together for a final accept or reject decision.	cuboid;structured light;traffic enforcement camera	Marc Pearson;Tim Clarke	2008	2008 IEEE International Conference on Emerging Technologies and Factory Automation	10.1109/ETFA.2008.4638367	computer vision;failure analysis;structured light;inspection;surface roughness;laser;automated x-ray inspection;production line;length measurement;engineering;dimensional analysis;forensic engineering;engineering drawing	Robotics	60.02296461689233	-40.15849517606787	41014
8792ba17a7a875c692543803c2bc99b5a6da6768	body extender: whole body exoskeleton for human power augmentation	torque;whole body;motion control;legged locomotion;body exoskeleton;degree of freedom;actuators;robot kinematics legged locomotion motion control;joints;robotic limbs;body extender;force servo amplification body extender body exoskeleton human power augmentation advanced wearable robot robotic limbs anthropomorphic kinematics leg locomotion;robots leg exoskeletons humans actuators joints torque;advanced wearable robot;force servo amplification;exoskeletons;robots;humans;human power augmentation;leg locomotion;functional assessment;leg;anthropomorphic kinematics;robot kinematics	The PERCRO laboratory of Scuola Superiore Sant'Anna has recently completed the development and functional assessment of the Body Extender (BE) system, an advanced wearable robot expressly conceived for augmenting the human strength for handling of heavy materials in unstructured environment. The system is composed by four robotic limbs with anthropomorphic kinematics and has a total of 22 independently actuated degrees of freedom. The leg locomotion and the force servo-amplification allow operations in environments that are hardly accessible by the conventional handling systems preserving the force sensibility during the manipulative tasks. Possible applications are handling of military materials in narrow spaces, rescuing of victims in natural and human provoked disasters and handling of heavy parts in the manufacturing of large products. The paper reports the system specifications taken as a reference for the design, the criteria and verification methods, the architectural solutions used for the implementation of mechanics, electronic and control components and the results of the preliminary experimental assessment.	digital media player;robot;servo;structural load;wearable computer	Simone Marcheschi;Fabio Salsedo;Marco Fontana;Massimo Bergamasco	2011	2011 IEEE International Conference on Robotics and Automation	10.1109/ICRA.2011.5980132	robot;control engineering;motion control;simulation;exoskeleton;computer science;engineering;artificial intelligence;control theory;torque;degrees of freedom;robot kinematics;actuator	Robotics	72.2237955288097	-25.4025677169424	41054
0d414082a4a660c2eb410db944c7b3bf40eda2e0	automatic detection of checkerboards on blurred and distorted images	image resolutions checkerboards automatic detection distorted images blurred images camera calibration toolboxes omnidirectional cameras distorted test image sets omnidirectional images;corner detection;cameras image resolution kernel distance measurement mirrors joining processes calibration;image resolution;omnidirectional image;object detection calibration cameras image resolution;omnidirectional camera;automatic detection;camera calibration;calibration;cameras;object detection	Most of the existing camera calibration toolboxes require the observation of a checkerboard shown by the user at different positions and orientations. This paper presents an algorithm for the automatic detection of checkerboards, described by the position and the arrangement of their corners, in blurred and heavily distorted images. The method can be applied to both perspective and omnidirectional cameras. An existing corner detection method is evaluated and its strengths and shortcomings in detecting corners on blurred and distorted test image sets are analyzed. Starting from the results of this analysis, several improvements are proposed, implemented, and tested. We show that the proposed algorithm is able to consistently identify 80% of the corners on omnidirectional images of as low as VGA resolution and approaches 100% correct corner extraction at higher resolutions, outperforming the existing implementation significantly. The performance of the proposed method is demonstrated on several test image sets of various resolution, distortion, and blur, which are exemplary for different kinds of camera-mirror setups in use.	algorithm;camera resectioning;corner detection;distortion;executable;gaussian blur;image resolution;knowledge acquisition;matlab;omnidirectional camera;opencv;orientation (graph theory);sensor;standard test image;video graphics array	Martin Rufli;Davide Scaramuzza;Roland Siegwart	2008	2008 IEEE/RSJ International Conference on Intelligent Robots and Systems	10.1109/IROS.2008.4650703	corner detection;computer vision;calibration;camera resectioning;image resolution;computer science;mathematics;optics;computer graphics (images)	Robotics	56.294774918725096	-49.13486447771778	41084
22c44633b054251adf5ff3328cc6561adec19f09	a practical self-shadowing algorithm for interactive hair animation	hair simulation;frames per second;shadow algorithm;graphics hardware;space use;interactive rendering;hair self shadowing	This paper presents a new fast and accurate selfshadowing algorithm for animated hair. Our method is based on a 3D light-oriented density map, a novel structure that combines an optimized volumetric representation of hair with a light-oriented partition of space. Using this 3D map, accurate hair self-shadowing can be interactively processed (several frames per second for a full hairstyle) on a standard CPU. Beyond the fact that our application is independent of any graphics hardware (and thus portable), it can easily be parallelized for better performance. Our method is especially adapted to render animated hair since there is no geometry-based precomputation and since the density map can be used to optimize hair self-collisions. The approach has been validated on a dance motion sequence, for various hairstyles.	3d computer graphics;algorithm;angularjs;approximation;automated planning and scheduling;central processing unit;computation;graphics hardware;interactivity;interpolation;map;parallel computing;precomputation;ray (optics);rendering (computer graphics);self-shadowing;simulation	Florence Bertails;Clément Ménier;Marie-Paule Cani	2005		10.1145/1089508.1089521	computer vision;simulation;computer science;graphics hardware;frame rate;computer graphics (images)	Graphics	66.5275107966888	-51.06306502748316	41136
7df3f7cbb9296211587bbe57db877d0f5125f2cb	neural-body coupling for emergent locomotion: a musculoskeletal quadruped robot with spinobulbar model	robot sensing systems;legged locomotion biomimetics;integrated circuit;legged locomotion;nervous system;biological system modeling;sensory feedback;muscles robot sensing systems robot kinematics biological system modeling nervous system integrated circuit modeling;sensorimotor flows neural body coupling emergent locomotion musculoskeletal quadruped robot spinobulbar model nervous system animal locomotion biological realistic morphology muscle configuration sensory feedback muscle spindles golgi tendon organs biological plausible model biological systems;integrated circuit modeling;biological systems;self organization;quadruped robot;computer simulation;robot kinematics;biomimetics;muscles	To gain a synthetic understanding of how the body and nervous system co-create animal locomotion, we propose an investigation into a quadruped musculoskeletal robot with biologically realistic morphology and a nervous system. The muscle configuration and sensory feedback of our robot are compatible with the mono- and bi-articular muscles of a quadruped animal and with its muscle spindles and Golgi tendon organs. The nervous system is designed with a biologically plausible model of the spinobulbar system with no pre-defined gait patterns such that mutual entrainment is dynamically created by exploiting the physics of the body. In computer simulations, we found that designing the body and the nervous system of the robot with the characteristics of biological systems increases information regularities in sensorimotor flows by generating complex and coordinated motor patterns. Furthermore, we found similar results in robot experiments with the generation of various coordinated locomotion patterns created in a self-organized manner. Our results demonstrate that the dynamical interaction between the physics of the body with the neural dynamics can shape behavioral patterns for adaptive locomotion in an autonomous fashion.	autonomous robot;behavioral pattern;biological system;brainwave entrainment;computational anatomy;computer simulation;emergence;experiment;feedback;galaxy morphological classification;self-organization;synthetic intelligence	Yasunori Yamada;Satoshi Nishikawa;Kazuya Shida;Ryuma Niiyama;Yasuo Kuniyoshi	2011	2011 IEEE/RSJ International Conference on Intelligent Robots and Systems	10.1109/IROS.2011.6094752	computer simulation;biomimetics;self-organization;simulation;computer science;engineering;artificial intelligence;integrated circuit;nervous system;robot kinematics	Robotics	65.37395193476424	-25.89985234584104	41156
d7215dd3b5451402d86b8babb89c90099f449fd5	multi-objective optimization for characterization of optical flow methods	multi objective optimization;computer vision;optical imaging;statistics;optimization;optical flow;biomedical optical imaging;sociology;adaptive optics	Optical flow methods are among the most accurate techniques for estimating displacement and velocity fields in a number of applications that range from neuroscience to robotics. The performance of any optical flow method will naturally depend on the configuration of its parameters. Beyond the standard practice of manual (ad-hoc) selection of parameters for a specific application, in this article we propose a framework for automatic parameter setting that allows searching for an approximated Pareto-optimal set of configurations in the whole parameter space. This final Pareto front characterizes each specific method, enabling proper method comparison. We define two performance criteria, namely the accuracy and speed of the optical flow methods.	approximation algorithm;displacement mapping;hoc (programming language);mathematical optimization;multi-objective optimization;optical flow;pareto efficiency;robotics;velocity (software development)	José Delpiano;Luis Pizarro;Rodrigo Verschae;Javier Ruiz-del-Solar	2014	2014 International Conference on Computer Vision Theory and Applications (VISAPP)	10.5220/0004736305660573	computer vision;mathematical optimization;simulation;computer science;horn–schunck method;multi-objective optimization;optical imaging;optical flow;adaptive optics	Vision	56.371829846417434	-40.20668332929642	41255
1eac0f40b7839837a5f67e372f620800cfbe7106	robot foraging: autonomous sample return in a large outdoor environment		A fundamental aspect of biological intelligence, from microbes to megafauna, is the ability to forage for the provisions required to sustain life. This sometimes underrated ability to seek out, identify, and use objects of interest in an environment with limited prior knowledge is an important capability that is also needed by robots. Many robotics applications can be modeled as foraging problems, such as search and rescue, wildlife tracking, crop pollination and harvesting, mining and in-situ-resource utilization, and scientific data/sample collection.	autonomous robot;gps wildlife tracking;robotics;simpl	Yu Gu;Jared Strader;Nicholas Ohi;Scott Harper;Kyle Lassak;Chizhao Yang;Lisa Kogan;Boyi Hu;Matthew Gramlich;Rahul Kavi;Jason N. Gross	2018	IEEE Robotics & Automation Magazine	10.1109/MRA.2018.2803174	engineering;simulation;simultaneous localization and mapping;robot;environmental resource management;intelligent decision support system;foraging;forage;artificial intelligence;robotics	Robotics	55.38708214601876	-29.838007258389325	41278
95b00fceb9f8e5c38091bc66390b5533839c6988	robot navigation using velocity potential fields and particle filters for obstacle avoidance		Autonomous robots are required to avoid the obstacles during navigation. For this purpose unknown and unexpected obstacles have to be detected during motion. The proposed approach uses particle filters to process sensors data and estimate relative position of the robot with regard to the obstacles and to the goal. These relative position estimations are inputs to the velocity potential field approach for obtaining time varying velocity commands for the robot to avoid all obstacles and reach the goal.	autonomous car;maxima and minima;obstacle avoidance;particle filter;robot;robotic mapping;sensor;simulation;velocity (software development)	Dan S. Necsulescu;Jin Bai;Jerzy Z. Sasiadek	2015	2015 12th International Conference on Informatics in Control, Automation and Robotics (ICINCO)		control engineering;monte carlo localization;computer vision;particle filter;computer science;artificial intelligence;control theory;obstacle avoidance	Robotics	54.22545356096942	-33.32156763602743	41284
b14b07d8627cd77299db1dad029cdfe5a9240538	a navigation mesh for dynamic environments	real time;navigation mesh;dynamic environments;dynamic environment;computer animation;medial axis;voronoi diagram	Games and simulations frequently model scenarios where obstacles move, appear, and disappear in an environment. A city environment changes as new buildings and roads are constructed, and routes can become partially blocked by small obstacles many times in a typical day. This paper studies the effect of using local updates to repair only the affected regions of a navigation mesh in response to a change in the environment. The techniques are inspired by incremental methods for Voronoi diagrams. The main novelty of this paper is that we show how to maintain a 2D or 2.5D navigation mesh in an environment that contains dynamic polygonal obstacles. Experiments show that local updates are fast enough to permit real-time updates of the navigation mesh.	2.5d;algorithm;experiment;gate;navigation mesh;real-time clock;simulation;voronoi diagram	Wouter van Toll;Atlas F. Cook;Roland Geraerts	2012	Journal of Visualization and Computer Animation	10.1002/cav.1468	navigation mesh;simulation;voronoi diagram;medial axis;artificial intelligence;computer animation;computer graphics (images)	Visualization	62.659254863078516	-45.56420589422923	41289
9823dd7b0acf0c7bbb234c1fcbede553cc3d9631	automated tracking of filmed radar echoes	pattern recognition;moving images;image sequences;scene analysis;image analysis;tracking;models	Abstract   The paper describes a general methodology for tracking fuzzy planar objects. It involves a five-stage tracking cycle with an internal fuzzy object locator sub-cycle. The methodology is illustrated by an application to tracking radar echoes of shipping in the English Channel on 16 mm film.	radar	G. Preston	1981	Pattern Recognition	10.1016/0031-3203(81)90060-1	computer vision;simulation;telecommunications	Vision	59.10658696302374	-42.67479907556718	41308
479e6db7a5c9e91cc02931160f5a32e86d555fc6	a survey on exploiting grids for ray tracing	categories and subject descriptors according to acm ccs i 3 6 computer graphics methodology and techniques graphics data structures and data types i 3 7 computer graphics three dimensional graphics and realism ray tracing;ray tracing	Grid is one of the first data structure introduced at the very beginning of computer graphics. Grids are used in several applications of computer graphics, especially in rendering algorithms. Lately, in ray tracing dynamic scenes, grid has received attention for its appealing linear time building time. In this paper, we aim to survey several aspects behind the use of grids in ray tracing. In particular we investigate grid traversal algorithms, building techniques and several approaches for hierarchical grids.	algorithm;computer graphics;data structure;parallel computing;ray tracing (graphics);rendering (computer graphics);traverse;time complexity;tree traversal	Biagio Cosenza	2008		10.2312/LocalChapterEvents/ItalChap/ItalianChapConf2008/089-096	computational science;ray tracing;rendering;computer science;theoretical computer science;ray casting;real-time computer graphics;computer graphics;3d computer graphics;computer graphics (images)	Graphics	67.03147696378527	-51.49257872926844	41348
ed7a5eae37d3947149ee81aa3854ae6c0d1bdbab	fast implementation of an improved parametric audio coder based on a mixed dictionary	transformation ondelette;audio signal processing;methode parametrique;parametric audio coding;metodo parametrico;persecusion adaptativa;parametric method;poursuite adaptative;overcomplete dictionary;sparse approximation;wavelet packet;audio coding;codificacion;traitement signal audio;feature extraction;coding;representacion parsimoniosa;matching pursuit;transformacion ondita;extraction caracteristique;wavelet packets;sparse representation;wavelet transformation;codage;representation parcimonieuse;complex exponentials	This paper deals with the application of adaptive signal models for representing transients and sinusoids at the same stage in a parametric audio coder. To accomplish such a goal, we search for sparse approximations by means of matching pursuit with a mixed dictionary, instead of using two different dictionaries that operate in cascade. In such sense, complex exponentials and wavelet packets are chosen for modeling the tonal and transient features of an audio signal, respectively. At each iteration of the pursuit, the mixed dictionary function that extracts the most energy from the residue is selected. This function will be either a complex exponential or a wavelet packet, depending on the characteristics of the residue at that iteration. Experimental results clearly show the objective (compression rate) and subjective (% preference) advantages of the mixed dictionary over two cascaded dictionaries. The approach proposed in this paper is successfully applied for parametric audio coding purposes, assuring better perceptual audio quality than MPEG2/4-AAC at 16 Kbits/s for most of the CD-quality one channel audio signals considered for testing.	dictionary	Pedro Vera-Candeas;Nicolás Ruiz-Reyes;Manuel Rosa-Zurera;Juan C. Cuevas-Martínez;Francisco López-Ferreras	2006	Signal Processing	10.1016/j.sigpro.2005.05.022	speech recognition;k-svd;computer science;machine learning;pattern recognition;sparse approximation	Graphics	80.79410134392084	-31.746200773486624	41380
de8e7da514bd65b7e8f66d1bfe91b1751b6087ad	a position control design for uavs low-altitude visual tracking of linear ground structures by the designed variant pid controller		This paper presents a control mechanism based on the actual distance between the Unmanned Aerial Vehicles (UAV) and the tracking structure for UAV visual tracking of linear ground structures in a low altitude. This control mechanism is called position control briefly in the following sections. The whole technique methods is divided into two parts: structure identification part and navigation control part. The linear structure is considered as a line in camera image, so the Canny Edge Detector (CED) and Probabilistic Hough Transformation (PHT) are used in image processing to recognize edges, identify the line and extract parameters (angle and distance in image). For autonomous tracking, the navigation and control play significant roles which impacts the response time, flight stability and tracing accuracy severely. By position control, the actual distance between the UAV body frame and the detected structure can be calculated. Then the UAV position will be regulated by the variant PID controller to do corrections until the UAV is flying exactly over the linear structure tracked.	aerial photography;angularjs;autonomous car;autonomous robot;canny edge detector;hough transform;image processing;lateral computing;lateral thinking;line level;pid;process identifier;pseudo-hadamard transform;response time (technology);unmanned aerial vehicle;video tracking	Huang Xiaoqian;Amit Shukla;Hamad Karki;Xiaoxiong Zhang	2017	2017 11th Asian Control Conference (ASCC)	10.1109/ASCC.2017.8287360	image processing;computer vision;canny edge detector;pid controller;response time;eye tracking;altitude;computer science;artificial intelligence;hough transform	Robotics	60.175587282711625	-32.282432663470026	41427
3f59d352dfc23994b9e78922119ad05bdbee5946	geometric algebra: a powerful tool for solving geometric problems in visual computing	linear algebra;mathematical tool geometric algebra geometric problem solving visual computing computer graphics computer vision image processing linear algebra plucker coordinates high level specification language;geometric computing;subspaces geometric algebra geometric computing applied mathematics plucker coordinates quaternion;computer graphics;quaternion;model transformation;computer vision and image processing;argon;specification language;computer graphic;computer vision quaternions computer graphics image processing solid modeling linear algebra vectors aggregates filling specification languages;subspaces;computer vision;vectors;tutorials;higher dimensions;blades;applied mathematics;plucker coordinates;linear algebra computer graphics computer vision;geometric algebra;quaternions	Geometric problems in visual computing (computer graphics, computer vision, and image processing) are typically modeled and solved using linear algebra (LA). Thus, vectors are used to represent directions and points in space, while matrices are used to model transformations. LA, however, presents some well-known limitations for performing geometric computations. As a result, one often needs to aggregate different formalisms (e.g., quaternions and Plücker coordinates) to obtain complete solutions. Unfortunately, such extensions are not fully compatible among themselves, and one has to get used to jumping back and forth between formalisms, filling in the gaps between them. Geometric algebra (GA), on the other hand, is a mathematical framework that naturally generalizes and integrates useful formalisms such as complex numbers, quaternions and Plücker coordinates into a high-level specification language for geometric operations. Due to its consistent structure, GA equations are often universal and generally applicable. They extend the same solution to higher dimensions and to all kinds of geometric elements, without having to handle special cases, as it happens in conventional techniques. This tutorial aims at introducing the fundamental concepts of GA as a powerful mathematical tool to describe and solve geometric problems in visual computing.	aggregate data;algorithm;collision detection;computation;computer graphics;computer vision;dos;encode;edge detection;entity;file spanning;fractal;high- and low-level;image processing;inverse kinematics;linear algebra;magma;model transformation;polygon mesh;robot;robotics;semantics (computer science);software development;software engineering;software release life cycle;specification language;synthetic intelligence;vii;visual computing	Leandro A. F. Fernandes;Manuel Menezes de Oliveira Neto	2009	2009 Tutorials of the XXII Brazilian Symposium on Computer Graphics and Image Processing	10.1109/SIBGRAPI-Tutorials.2009.10	universal geometric algebra;geometric transformation;computer science;theoretical computer science;pure mathematics;geometry;conformal geometric algebra;geometric networks	Graphics	63.075661342333326	-41.05117748263971	41544
f1facc15d3c54bb7e869807e1e1c0547a8e17981	optimization approach for the development of humanoid robots’ behaviors		Humanoid robots usually have a large number of degrees of freedom which turns humanoid control into a very complex problem. Humanoids are used in several RoboCup soccer leagues. In this work, the SimSpark simulator of the Simulation 3D will be used. This paper presents an automatic approach for developing humanoid behaviors based on the development of a generic optimization system. The paper describes the adopted architecture, main design choices and the results achieved with the optimization of a side kick and a forward kick. For both skills, the optimization approach allowed the creation of faster and more powerful and stable behaviors.	algorithm;humans;loss function;mathematical optimization;optimization problem;robot;server (computing);simulation	Luis Cruz;Luís Paulo Reis;Nuno Lau;Armando Sousa	2012		10.1007/978-3-642-34654-5_50	humanoid robot	Robotics	62.123785602685565	-24.720808611886174	41550
c2ce1efbefbf56f4a7813538fe081ec0e91823c9	simulation of rc helicopter based on dynamics of quaternion by using opengl and simulink	simulink;computer animation radio controlled helicopter quaternion dynamics rotating object kinematics robust sliding mode control algorithm stability matlab simulink software tool opengl virtual training environments embedded system s3c6410 arm11 based embedded board 3d autostereoscopic lcd module rc helicopter remote controller rigid body main body main rotor tail rotor;simulink quaternion sliding mode control helicopter;software tool;mathematics computing;rigid body;virtual training;quaternion;robust control;variable structure systems;embedded system;embedded systems;vehicle dynamics computer animation control engineering computing embedded systems helicopters mathematics computing robust control telecontrol variable structure systems;telecontrol;control engineering computing;helicopter;virtual environment;computer animation;computer simulation;quaternions helicopters three dimensional displays hardware attitude control mathematical model programming;helicopters;vehicle dynamics;sliding mode control	In this paper, we present a sliding mode control for the radio controlled helicopter based on quaternion dynamics. We also introduce the kinematics of the rotating object based on quaternion and then propose a robust sliding mode control algorithm which can guarantee the over all stability of the whole system. We will show the simulation results by using the matlab simulink software tool and then implement the computer animation by using OpenGL based on the data of the simulation results. In this paper, we introduce implementation of virtual training environments based on Embedded System. Our virtual environment consists of S3C6410 ARM11 based embedded board, 3D Auto-Stereoscopic LCD Module, and RC Helicopter's remote controller. We use the simple dynamics of the helicopter which we derived in previous research work under the assumption that it can be modeled as rigid body composed of three main parts, such as main body, main rotor, and tail rotor. From the computer simulation, we can check the validness of proposed control law.	algorithm;computer animation;computer simulation;embedded system;liquid-crystal display;matlab;object-based language;opengl;optimal control;programming tool;r.o.t.o.r.;radio control;remote control;simulink;stereoscopy;virtual reality	Woonchul Ham;Jaebyung Park;Enkhbaatar Tumenjargal;Luubaatar Badarch;Hyeokjae Kwon	2011	2011 8th International Conference on Ubiquitous Robots and Ambient Intelligence (URAI)	10.1109/URAI.2011.6145874	computer simulation;robust control;embedded system;rigid body;vehicle dynamics;simulation;sliding mode control;computer science;virtual machine;computer animation;quaternion	Robotics	65.12371228748567	-30.062734976900614	41587
2777a027addec64cea34ef45ccd5e24a955df19f	cooperative navigation system for multiple unmanned underwater vehicles	estimation algorithms;extended kalman filter;vehicles;navigation system;cooperation	Abstract   In recent yeas, long-range accuracy cooperative navigation(CN) for multiple UUVs under complex marine environment is getting more and more attention. In this paper, firstly, the state-of-the-art of multiple UUV cooperation system is introduced. Then, the characteristic and system structure of multiple UUVs CN are analyzed, as well as the CN methods. Finally, based on the current development of CN system, the prospect of CN for multiple UUVs is brought forward in terms of the requirement, hardware, communication, and so on.	unmanned aerial vehicle	Yao Yao	2013		10.3182/20130902-3-CN-3020.00127	simulation	Robotics	56.662519876097946	-27.326672165341947	41762
55d0f9afd53eb3c068fb42c990991bf682149c28	artificial landmark map building method based on grid slam in large scale indoor environment	lasers;estimation theory;measurement by laser beam;map building;mobile robot;path planning;mobile robot artificial landmark map grid slam mapping cart;mobile robots artificial landmark map building method grid slam large scale indoor environment grid based simultaneous localization and mapping grid slam mapping cart position estimation grid based map mapping process t city;large scale;position control;indoor environment;robots;simultaneous localization and mapping;mapping cart;artificial landmark map;slam robots;slam robots estimation theory path planning position control;lasers measurement by laser beam robots;grid slam	This paper proposes the artificial landmark map building method using a Grid-based Simultaneous Localization And Mapping (Grid SLAM). The Grid SLAM method is employed to simultaneously localize the position of mapping cart and construct the map of working area. Based on the estimated position of the mapping cart and the grid-based map, the artificial landmarks are localized and their positions are saved to the artificial landmark map. The proposed method reduces the complexity and the cost of mapping process which is usually done by hand. The real implementation has been carried out to build the artificial landmark map of large scale indoor environment named T-City. The implementation results show that the proposed method gives a convenient way to construct the artificial landmark map while still maintaining the accuracy of map. The correctness of the artificial landmark map has been confirmed through the real operation of the mobile robots which rely on the artificial landmark map for their navigation at T-City.	correctness (computer science);mobile robot;simultaneous localization and mapping	Yu-Cheol Lee;Christiand;Heesung Chae;Wonpil Yu	2010	2010 IEEE International Conference on Systems, Man and Cybernetics	10.1109/ICSMC.2010.5642489	robot;mobile robot;computer vision;laser;computer science;artificial intelligence;motion planning;estimation theory;simultaneous localization and mapping	Robotics	54.25179617581319	-34.30469117335731	41807
51d9189888e65ade7580cee6f52de02aa074eec5	implementing irradiance cache in a gpu realistic renderer	realistic rendering;ray tracing;irradiance cache;gpu global illumination	This work presents an approach to integrating irradiance caching (IC) technique in a complete GPU photorealistic renderer. This work proposes a GPU friendly IC solution, where performance critical parts of an irradiance cache algorithm are done completely on the GPU. The modified algorithm for the GPU is different from a traditional implementation in 2 ways. The first distinction is a predictive nature of our algorithm that allows us to insert a large record set at once instead of inserting records one by one, as in traditional approaches. The second distinction is a new heuristic for validity radius computations. We also consider some low-level details and provide performance analysis of our solution.	graphics processing unit	Vladimir A. Frolov;Konstantin Vostryakov;Alexander Kharlamov;Vladimir A. Galaktionov	2013	Trans. Computational Science	10.1007/978-3-642-39759-2_2	parallel computing;real-time computing;computer science;computer graphics (images)	Graphics	66.02876359186398	-51.42306374514448	41901
78bbf7acdcf36f5e3405e3605db748fe39dca0ee	calibration-free line-based tracking for video augmentation	tracking;augmented reality;registration;camera calibration.;pose estimation;augmented virtuality;camera calibration	This paper presents a calibration-free line-based tracking method to augment virtual objects into a video sequence. The presented method uses a cube on the first image to calibrate camera parameters. Then the 3D model for the cube is refined by adding 3D lines to its surface. For the remaining images in the sequence, the image lines are automatically detected and matched with their 3D correspondents. The matched line pairs are used for pose estimation. The experiments show that the presented method can achieve robust performance for video augmentation without any prior knowledge of 3D model and camera parameters.	3d modeling;experiment	Bolan Jiang	2006			calibration;augmented virtuality;computer graphics (images);computer vision;video tracking;camera resectioning;pose;augmented reality;computer science;artificial intelligence	Vision	55.09211528725858	-48.05055400950931	42004
23c9d3b229691d4e0b3e6d1a2615ec3957bc2f37	comparative studies of line-based panoramic camera calibration	optical distortion;sensor phenomena and characterization;image segmentation;panoramic camera;layout;sensitivity;distance measurement;three dimensional displays;pixel;cameras calibration distance measurement three dimensional displays pixel sensitivity image segmentation;optical sensors;transmission line matrix methods;computer science;optoelectronic and photonic sensors;calibration;cameras;geometrical optics	The calibration of a line-based panoramic camera can be split into two independent subtasks: first calibrate the effective focal length and the principal row, and second, calibrate the off-axis distance and the principal angle. The paper provides solutions for three different methods, and compares these methods based on experiments using a superhigh resolution line-based panoramic camera. It turns out that the second subtask is solved best if a straight-segment based approach is used, compared to point-based or correspondence-based calibration methods, all already known for traditional (planar) pinhole cameras, but not yet previously discussed for panoramic cameras.	camera resectioning;experiment;focal (programming language);numerical stability;optic axis of a crystal	Fay Huang;Shou-Kang Wei;Reinhard Klette	2003	2003 Conference on Computer Vision and Pattern Recognition Workshop	10.1109/CVPRW.2003.10086	layout;geometrical optics;computer vision;calibration;camera resectioning;sensitivity;computer science;image segmentation;pixel;computer graphics (images)	Vision	55.296528071866035	-48.901724903879106	42012
3cf95eb46265ffc012cad7330aa367a1a68e10dc	a virtual reality toolkit for path planning and manipulation at nano-scale	path planning;haptics atomic force microscopy afm path planning virtual reality vr nano manipulation;virtual reality;haptics;potential field;virtual reality vr;atomic force microscopy afm;haptic feedback;nano manipulation;atomic force microscopy;virtual environment;virtual reality path planning haptic interfaces atomic force microscopy humans feedback surface topography probes virtual environment design engineering	A virtual reality (VR) toolkit that integrates the human operator into a virtual environment by means of visual and haptic feedback has been developed to design and test manipulation strategies at nano-scale. Currently, the toolkit is capable of modeling the mechanistic interactions between an AFM tip and spherical particles on a substrate surface and generating optimum manipulation paths using a potential field approach. In addition, haptic fixtures were designed to guide the user to follow the calculated paths.	atomic-force microscopy;gnu nano;haptic technology;interaction;motion planning;virtual reality	Aydin Varol;Ihsan Gunev;Cagatay Basdogan	2006	2006 14th Symposium on Haptic Interfaces for Virtual Environment and Teleoperator Systems	10.1109/VR.2006.30	computer vision;simulation;computer science;artificial intelligence;virtual reality;haptic technology;computer graphics (images)	Visualization	77.28939362125115	-27.300347435272986	42022
16739e9d4bbed2bcdab8aeb2baa8d0d66ae64a2c	ladar scan preprocessing for robust motion estimation	edge detection ladar scan preprocessing robust motion estimation two dimensional laser radar mobile robotics frequency domain analysis spectral information;obstacle detection;map building;sensors;mobile robot;edge detection;frequency domain analysis;laser radar robustness motion estimation working environment noise information filtering information filters mobile robots robot sensing systems radar detection sampling methods;mobile robotics;finite impulse response filter;information filtering;motion estimation;laser radar;mobile robots;two dimensional laser radar;robust motion estimation;optical radar;image edge detection;ladar scan preprocessing;radar imaging;spectral information;low pass filters;approximation methods;radar imaging edge detection frequency domain analysis mobile robots motion estimation optical radar;short period;frequency domain;noise	Two-dimensional laser radars (2D-ladars) are sensors extensively used in mobile robotics for map building, self-localization, and obstacle detection due to their accuracy and reliability. Due to their fast sampling of the environment they also perfectly suit incremental ego-motion estimation, that is, to find how the position of the vehicle changes in short periods of time only by comparing sensor readings. Some of the most accurate methods dealing with this problem rely on a consistent computation of derivatives of range scans provided by the ladar. In practice, edges in the environment and sensor noise lead to inconsistencies in this computation. In this work we introduce an approach in the frequency domain, which robustly detects the continuous contour patches in the scan and then filters out the noise in those sections. In contrast with other methods based on batches of filters and heuristic rules, our approach employs spectral information to automatically select the filter parameters. We validate our method with experimental results on real environments.	butterworth filter;ct scan;computation;heuristic;image noise;mobile robot;motion estimation;noise power;preprocessor;radar;robotics;robustness (computer science);sampling (signal processing);sensor	Rafael Gutiérrez;Javier González;José L Blanco	2007	2007 9th International Symposium on Signal Processing and Its Applications	10.1109/ISSPA.2007.4555522	mobile robot;computer vision;computer science;frequency domain	Robotics	54.67689249209722	-36.345906339502605	42074
883c8c49751babc06261d322a6caf694452b7962	a 2d geometric constraint solver for parametric design using graph analysis and reduction	rigid body;geometric constraint solving;numerical method;degree of freedom;parametric design;algebraic method;constraint solving;geometric constraints	This paper proposes a DOF-based graph reduction approach to geometric constraint solving. The proposed approach incrementally solves a geometric constraint problem that is not ruler-and-compass constructible by incrementally identifying a set of constrained geometric entities with 3 DOF (degree of freedom) as a rigid body and determining the geometric entities in the rigid body using one of the two solving procedures: algebraic method and numerical method, instead of solving it simultaneously using a numerical method. However, the use of the numerical method is restricted to solve only those parts that must be solved numerically. By combining the advantages of algebraic solving with the universality of numerical solving, the proposed method can maximize the efficiency, robustness, and extensibility of a geometric constraint solver.	parametric design;solver	Jae Yeol Lee	1998		10.1007/3-540-47997-X_13	mathematical optimization;combinatorics;discrete mathematics;constraint graph;mathematics	EDA	64.06057050943055	-39.492916752703955	42099
b0e57820057baf747a6afe5d12aef0f3e700ff2d	maximum likelihood estimation for multiple camera target tracking on grassmann tangent subspace	manifolds maximum likelihood estimation cameras geometry target tracking transforms;tangent subspace grassmann manifold maximum likelihood estimation mle multiple view tracking	In this paper, we introduce a likelihood model for tracking the location of object in multiple view systems. Our proposed model transforms conventional nonlinear Euclidean estimation model to an estimation model based on the manifold tangent subspace. In this paper, we show that by decomposition of input noise into two parts and description of model by exponential map, real observations in the Euclidean geometry can be transformed to the manifold tangent subspace. Moreover, by obtained tangent subspace likelihood function, we propose two iterative and noniterative maximum likelihood estimation approaches which numerical results show their good performance.	computation (action);data center;extended kalman filter;iterative method;maximum likelihood estimation;nonlinear system;numerical analysis;open educational practices;penicillin g;phenylephrine hydrochloride 10 mg oral tablet;portable document format;simulation;tracking system;exponential;manifold	Mojtaba Amini-Omam;Farah Torkamani-Azar;Seyed Ali Ghorashi	2018	IEEE Transactions on Cybernetics	10.1109/TCYB.2016.2624309	mathematical optimization;computer science;mathematics;geometry;maximum likelihood sequence estimation;statistics	Vision	54.87979925833434	-49.620653821922566	42124
be71dee6203dbcc3c17ff08b781b211d5d4b4155	underwater slam with robocentric trajectory using a mechanically scanned imaging sonar	underwater vehicles kalman filters mobile robots motion control path planning position control robot vision slam robots sonar imaging;motion control;world centric trajectory method underwater slam robocentric trajectory mechanically scanned imaging sonar underwater simultaneous localization and mapping msis data robot motion extended kalman filter world fixed coordinate frame ekf linearization errors underwater environment;history;underwater vehicles;path planning;kalman filters;mobile robots;sonar imaging;robot vision;trajectory;position control;simultaneous localization and mapping;robot motion;simultaneous localization and mapping vectors trajectory robot kinematics robot motion;extended kalman filter;slam robots;robot kinematics	This paper proposes a novel approach to perform underwater Simultaneous Localization and Mapping (SLAM) using a Mechanically Scanned Imaging Sonar (MSIS). This approach starts by processing the MSIS data in order to obtain range scans while taking into account the robot motion. Then, the relative motions between consecutively gathered scans are stored in the state vector. Thus, the whole sequence of robot motions between gathered scans is used to perform SLAM using an Extended Kalman Filter (EKF). One of the novelties is that this sequence is not represented with respect to a world-fixed coordinate frame, but with respect to a coordinate frame locked to the robot. Thanks to this, EKF linearization errors are reduced. The experimental results in underwater environments validate the proposal comparing the new robocentric approach to the world-centric trajectory method.	acoustic cryptanalysis;experiment;extended kalman filter;quantum state;robot;sonar (symantec);simultaneous localization and mapping;trajectory optimization;vii	Antoni Burguera;Yolanda González Cid;Gabriel Oliver	2011	2011 IEEE/RSJ International Conference on Intelligent Robots and Systems	10.1109/IROS.2011.6094850	kalman filter;motion control;mobile robot;computer vision;simulation;computer science;engineering;artificial intelligence;trajectory;control theory;motion planning;extended kalman filter;robot kinematics;simultaneous localization and mapping	Robotics	54.786860758415386	-36.13610049310729	42210
4097e3c0f13e041d97850099baf579f7d12b2d7b	preliminary study on accuracy of step length measurement for cie exoskeleton	legged locomotion;hip;length measurement;kinematics;exoskeletons;knee;tracking	While exoskeletons for paraplegic users are used nowadays only in laboratory environments for therapy, their use in less orderly environments, or for climbing stairs is still troublesome for operators. One of the factors is the high step length variance. In this paper, potential sources of this problem are investigated. The step length estimations based on the CIE Exoskeleton internal sensors and step length measurements from the BTS motion tracking system are compared. Influence of the rotation of the exoskeleton sagittal plane in relation to environment coordinate system is evaluated. Results show that the sagittal plane of rotation has minimal influence on step length and planar exoskeleton models should suitable for motion planning.	broadcast television systems inc.;computability in europe;encoder;experiment;motion planning;sensor;tracking system	Rafal Kabacinski;Mateusz Kowalski	2016	2016 IEEE International Conference on Multisensor Fusion and Integration for Intelligent Systems (MFI)	10.1109/MFI.2016.7849561	simulation;engineering;anatomy;surgery	Robotics	59.90121609622119	-36.8330467519545	42216
bec10ae1bd61f94cf3108d9248d23ce0fc34a2ba	sequence-to-sequence models for trajectory deformation of dynamic manipulation		In dynamic manipulation, robots can manipulate objects without grasping by utilizing inertia effect. However, the trajectory planning for dynamic manipulation is a difficult issue due to dynamic constraint. Trajectory deformation considering dynamic constraint after original trajectories are generated is necessary for the issue. To realize such deformation methods, we introduce on sequence-to-sequence (seq2seq) models, which can convert a time series to another time series. This paper proposes a trajectory deformation method with seq2seq models deforming trajectories to satisfy dynamic constraint. Users can obtain trajectories for dynamic manipulation by designing outlines of motion and inputting them to the proposed seq2seq model. In addition, this paper proposes a learning curriculum that does not need labeled dataset. Only mathematical representation of constraint and unlabeled trajectories are necessary. We implement a seq2seq model by the proposed method to a robot turning over pancakes and confirm the validity by a simulation and an experiment.	mathematics;outlines (document);physical object;robot (device);simulation;time series;tracer;unsupervised learning	Kyo Kutsuzawa;Sho Sakaino;Toshiaki Tsuji	2017	IECON 2017 - 43rd Annual Conference of the IEEE Industrial Electronics Society	10.1109/IECON.2017.8216904	deformation (mechanics);control engineering;inertia;engineering;trajectory;representation (mathematics);decoding methods	Robotics	62.30849984717001	-25.24555855335731	42295
ad1ed98a3d88dfb4bae99a67cdd10699dcf9485e	surface motion capture animation. (animation de capture de mouvement de surface)			motion capture	Adnane Boukhayma	2017				Graphics	61.21194758901444	-46.904990320886	42322
80b8f44f9b6a706b5841946ff68903001a6b4693	kinematic characterisation of hexapods for industry	mecanismo paralelo;contraste;modelizacion;concepcion asistida;3d interaction;computer aided design;aeroespacial;fabricacion asistida por computador;posicionamiento;modele geometrique;singularite;aerospace;motion control;aerospatiale;cinematica;parallel mechanism;robotics;aerospace industry;kinematics;hexapod;robot industriel;production process;process design;commande mouvement;geometric approach;modelisation;dominio trabajo;control movimiento;positioning;fabrication assistee;mecanisme parallele;industrial robots;domaine travail;computer aided manufacturing;cinematique;robot industrial;processus fabrication;singularidad;conception assistee;robotica;etalonnage;mecanisme articule;workspace;robotique;industria aeroespacial;hexapodo;mecanismo articulado;modeling;industrie aerospatiale;calibration;hexapode;proceso fabricacion;linkage mechanism;geometrical model;singularity;industrial robot;positionnement;modelo geometrico	Purpose – The purpose of this paper is to propose two simple tools for the kinematic characterization of hexapods. The paper also aims to share the experience of converting a popular commercial motion base (Stewart-Gough platform, hexapod) to an industrial robot for use in heavy duty aerospace manufacturing processes. Design/methodology/approach – The complete workspace of a hexapod is a six-dimensional entity that is impossible to visualize. Thus, nearly all hexapod manufacturers simply state the extrema of each of the six dimensions, which is very misleading. As a compromise, a special 3D subset of the complete workspace is proposed, an approximation of which can be readily obtained using a computer-aided design (CAD)/computer-aided manufacturing (CAM) software suite, such as computer-aided 3D interactive application (CATIA). While calibration techniques for serial robots are readily available, there is still no generally agreed procedure for calibrating hexapods. The paper proposes a simple calibration method that relies on the use of a laser tracker and requires no programming at all. Instead, the design parameters of the hexapod are directly and individually measured and the few computations involved are performed in a CAD/CAM software such as CATIA. Findings – The conventional octahedral hexapod design has a very limited workspace, though free of singularities. There are important deviations between the actual and the specified kinematic model in a commercial motion base. Practical implications – A commercial motion base can be used as a precision positioning device with its controller retrofitted with state-of-the-art motion control technology with accurate workspace and geometric characteristics. Originality/value – A novel geometric approach for obtaining meaningful measures of the workspace is proposed. A novel, systematic procedure for the calibration of a hexapod is outlined. Finally, experimental results are presented and discussed.	approximation;catia;computation;computer-aided design;industrial robot;integrated computer-aided manufacturing;laser tracker;software suite;workspace	Julien Blaise;Ilian A. Bonev;Bruno Monsarrat;Sébastien Briot;Jason Michel Lambert;Claude Perron	2010	Industrial Robot	10.1108/01439911011009984	simulation;engineering;artificial intelligence;aerospace;robotics;engineering drawing;mechanical engineering	Robotics	64.78327447726309	-33.14452108990289	42362
27a790a0ca254006fbe37d41e1751516911607ca	estimation of planar curves, surfaces, and nonplanar space curves defined by implicit equations with applications to edge and range image segmentation	implicit surface;analisis imagen;object position estimation pattern recognition algebra optimisation edge segmentation planar curves surfaces nonplanar space curves implicit equations range image segmentation parametric representation 2 d 3 d zeros object recognition;curva;complex objects;object recognition;optimisation;vision ordenador;nonplanar space curves;object position estimation;zeros;invarianza;courbe;segmentation;curve;eigenvector;range image segmentation;computer vision;invariance;vector propio;parametric representation;2 d;algebra;edge segmentation;equations surface fitting least squares approximation object recognition concurrent computing curve fitting computer vision surface reconstruction image segmentation object detection;position estimation;planar curves;distancia;pattern recognition;image analysis;pattern recognition algebra curve fitting optimisation;vision ordinateur;surfaces;reconnaissance forme;curve fitting;reconocimiento patron;analyse image;vecteur propre;3 d;implicit equations;segmentacion;curves and surfaces;distance	This paper addresses the problem of parametric representation and estimation of complex planar curves in 2-D, surfaces in 3-D and nonplanar space curves in 3-D. Curves and surfaces can be defined either parametrically or implicitly, and we use the latter representation. A planar curve is the set of zeros of a smooth function of two variables X-Y, a surface is the set of zeros of a smooth function of three variables X-~-Z, and a space curve is the intersection of two surfaces, which are the set of zeros of two linearly independent smooth functions of three variables X-!/-Z. For example, the surface of a complex object in 3D can be represented as a subset of a single implicit surface, with similar results for planar and space curves. We show how this unified representation can be used for object recognition, object position estimation, and segmentation of objects into meaningful subobjects, that is, the detection of “interest regions” that are more complex than high curvature regions and, hence, more useful as features for object recognition. Fitting implicit curves and surfaces to data would be ideally based on minimizing the mean square distance from the data points to the curve or surface. Since the distance from a point to a curve or surface cannot be computed exactly by direct methods, the approximate distance, which is a first-order approximation of the real distance, is introduced, generalizing and unifying previous results. We fit implicit curves and surfaces to data minimizing the approximate mean square distance, which is a nonlinear least squares problem. We show that in certain cases, this problem reduces to the generalized eigenvector fit, which is the minimization of the sum of squares of the values of the functions that define the curves or surfaces under a quadratic constraint function of the data. This fit is computationally reasonable to compute, is readily parallelizable, and, hence, is easily computed in real time. In general, the generalized eigenvector lb provides a very good initial estimate for the iterative minimization of the approximate mean square distance. Although we are primarily interested in the 2-D and 3-D cases, the methods developed herein are dimension independent. We show that in the case of algebraic curves and surfaces, i.e., those defined by sets of zeros of polynomials, the minimizers of the approximate mean square distance and the generalized eigenvector fit are invariant with respect to similarity transformations. Thus, the generalized eigenvector lit is independent of the choice of coordinate system, which is a very desirable property for object recognition, position estimation, and the stereo matching problem. Finally, as applications of the previous techniques, we illustrate the concept of “interest regions” Manuscript received April 13, 1988; revised April 30, 1991. This work was supported by an IBM Fellowship and NSF Grant IRI-8715774. The author was with the Laboratory for Engineering Man/Machine Systems, Department of Engineering, Brown University, Providence, RI 02912. He is now with the Exploratory Computer Vision Group, IBM T. J. Watson Research Center, Yorktown Heights, NY 10598. IEEE Log Number 9102093. for object recognition and describe a variable-order segmentation algorithm that applies to the three cases of interest.	approximation algorithm;computer vision;constraint (mathematics);curve fitting;data point;ibm notes;image segmentation;implicit curve;implicit surface;iterative method;linear algebra;mean squared error;non-linear least squares;order of approximation;outline of object recognition;planar graph;polynomial;quadratically constrained quadratic program;range segmentation;thomas j. watson research center	Gabriel Taubin	1991	IEEE Trans. Pattern Anal. Mach. Intell.	10.1109/34.103273	computer vision;image analysis;geometric design;topology;eigenvalues and eigenvectors;invariant;cognitive neuroscience of visual object recognition;mathematics;geometry;family of curves;curve;surface;distance;segmentation;curve fitting	Vision	62.00018106481388	-42.77208188402162	42381
ab616680c357ad6296b8d181c3f2536794502f15	path planning for power transmission line inspection robot based on visual obstacle detection	graph theory;robot vision automatic optical inspection collision avoidance graph theory mobile robots object recognition power transmission lines;object recognition;automatic optical inspection;mobile robots;visual graph algorithm path planning power transmission line inspection robot mechanism visual obstacle detection autonomous mobile robot mountainous regions line climbing obstacle recognition visual method feasible obstacle crossing path;robot vision;collision avoidance;inspection power transmission lines grippers mobile robots wires poles and towers;power transmission lines	In this paper an autonomous mobile robot is proposed for inspecting power transmission lines in mountainous regions. After a brief introduction of background and the robot mechanism, the key functionalities of the inspection robot - obstacle detection in traveling, path planning in obstacle crossing and large-angle line climbing, are discussed in detail. Obstacles are detected and recognized efficiently by a visual method. The obstacle description is built based on visual obstacle detection and a feasible obstacle crossing path is found using a visual graph algorithm. Finally, some field experiments are carried out to show that the robot can work well on the power transmission lines in mountainous regions with the aforementioned functionalities.	algorithm;autonomous robot;experiment;hill climbing;list of algorithms;mobile robot;motion planning;pixel;transmission line;velocity obstacle;workspace	Zhenhui Li;Hongguang Wang;Yuechao Wang	2013	2013 IEEE International Conference on Robotics and Biomimetics (ROBIO)	10.1109/ROBIO.2013.6739452	mobile robot;computer vision;simulation;computer science;engineering;graph theory;cognitive neuroscience of visual object recognition;obstacle avoidance;electric power transmission	Robotics	57.25275688762914	-31.385569674664215	42391
8e5aa9b244593e5f8aaf6b160a4b5e3b554c5831	spectrum estimation of short-time stationary signals in additive noise and channel distortion	sufficient statistic;gaussian noise;traitement signal;evaluation performance;restauration signal;optimisation;performance evaluation;spectral analysis hidden markov models degradation distortion maximum likelihood estimation iterative algorithms additive noise signal processing signal generators gaussian noise;signal estimation;least mean squares methods;spectral representation;maximum likelihood;modelo autorregresivo;hidden markov model;evaluacion prestacion;simulation;modele markov variable cachee;maximum vraisemblance;ruido gaussiano;additive noise;ruido aditivo;senal estacionaria;simulacion;bruit additif;spectrum;state dependence;maximum likelihood estimation;signal stationnaire;estimation algorithm;autoregressive model;maximum likelihood estimate;hidden markov models;expectation maximization;autoregressive processes;signal processing;bruit gaussien;estimacion senal;autoregressive processes spectral analysis maximum likelihood estimation telecommunication channels hidden markov models optimisation gaussian noise least mean squares methods;algorithme em;canal lineaire;linear time invariant;signal restoration;mixture of gaussians;algoritmo em;fir filter spectrum estimation short time stationary signals additive noise channel distortion maximum likelihood estimation mle algorithm degradation system short time signal spectra source signal hidden markov model hmm state dependent short time spectral distributions gaussian densities linear time invariant channel gaussian noise expectation maximization em channel parameters short time signal power spectra posterior sufficient statistics spectral representation parameters autoregressive model parameters cepstral parameters minimum mean squared error estimation mmse estimation power spectral estimates estimation algorithm simulated signals signal to noise ratio snr convergent estimation spectral distortion;spectral estimation;linear channel;spectral analysis;signal to noise ratio;telecommunication channels	In this work, spectrum estimation of a short-time stationary signal that is degraded by both channel distortion and additive noise is addressed. A maximum likelihood estimation (MLE) algorithm is developed to jointly identify the degradation system and estimate short-time signal spectra. The source signal is assumed to be generated by a hidden Markov model (HMM) with state-dependent short-time spectral distributions described by mixtures of Gaussian densities. The distortion channel is linear time-invariant, and the noise is Gaussian. The algorithm is derived by using the principle of expectation-maximization (EM), where the unknown parameters of channel and noise are estimated iteratively, and the short-time signal power spectra are obtained from the posterior sufficient statistics of the source signal. Other spectral representation parameters, such as autoregressive model parameters or cepstral parameters, are obtained by minimum mean-squared error (MMSE) estimation from the power spectral estimates. The estimation algorithm was evaluated on simulated signals at the signal-to-noise ratios (SNRs) of 20 dB down to 0 dB, where it produced convergent estimation and significantly reduced spectral distortion.	additive white gaussian noise;distortion;spectral density estimation;stationary process;utility functions on indivisible goods	Yunxin Zhao	2001	IEEE Trans. Signal Processing	10.1109/78.928694	noise spectral density;econometrics;computer science;pattern recognition;mathematics;maximum likelihood;maximum entropy spectral estimation;hidden markov model;statistics	EDA	81.98524778388752	-32.23146395851555	42517
5939f1aa4feec3c8a21709543924971cbac87357	application of transferable belief model to navigation system	vehicle position;new map-matching algorithm;map-matching method;vehicle move;navigation system;correct road;vehicle navigation system;dead reckoning;digital road map;transferable belief model;general justification	In general, navigation systems estimating a vehicle position is done either by using the Global Positioning System (GPS) or the Dead Reckoning (DR) systems. Other modern estimations are based on the combination of the two systems (GPS/DR). However, the position of a vehicle determined by GPS/DR is far from being perfect since it produces many errors. To solve this problem, a map-matching method is proposed in order to reduce the errors of localization caused by GPS/DR. This algorithm, which uses a digital road map, allows the detection of the correct road where a vehicle moves. In this paper, we introduce a new map-matching algorithm that employs the Transferable Belief Model (TBM). The TBM presents a general justification of belief theory and provides a flexible and adapted representation to manage uncertainty and imprecision. Experimental results show the effectiveness of the utilization of the TBM to the vehicle navigation system.		Khalid Touil;Mourad Zribi;Mohammed Benjelloun	2007	Integrated Computer-Aided Engineering	10.3233/ica-2007-14108	computer vision;simulation;artificial intelligence	DB	54.609706774792144	-36.784155033583154	42590
db4df1a969192e66f4c544725a07a3b35869894b	dual-channel noise reduction based on a mixture of circular-symmetric complex gaussians on unit hypersphere	pattern clustering;elektroteknik och elektronik;electrical engineering electronic engineering information engineering;speech enhancement;time frequency analysis direction of arrival estimation discrete fourier transforms gaussian distribution pattern clustering signal denoising speech enhancement;mixture of gaussians speech enhancement dual channel noise reduction soft masking;unit hypersphere time frequency bin speech enhancement soft masking strategy direction of arrival speech components noise clustering mixture model frequency domain modeling noisy speech signals complex discrete fourier transform coefficients circular symmetric complex gaussian distributions model based dual channel noise reduction approach;noise speech noise reduction noise measurement speech enhancement microphones discrete fourier transforms;discrete fourier transforms;time frequency analysis;gaussian distribution;direction of arrival estimation;signal denoising	In this paper a model-based dual-channel noise reduction approach is presented which is an alternative to conventional noise reduction algorithms essentially due to its independence of the noise power spectral density estimation and of any prior knowledge about the spatial noise field characteristics. We use a mixture of circular-symmetric complex-Gaussian distributions projected on the unit hypersphere for modeling the complex discrete Fourier transform coefficients of noisy speech signals in the frequency domain. According to the derived mixture model, clustering of the noise and the target speech components is performed depending on their direction of arrival. A soft masking strategy is proposed for speech enhancement based on responsibilities assigned to the target speech class in each time-frequency bin. Our experimental results show that the proposed approach is more robust than conventional dual-channel noise reduction systems based on the single- and dual-channel noise power spectral density estimators.	algorithm;cluster analysis;coefficient;direction of arrival;discrete fourier transform;mixture model;multi-channel memory architecture;noise (electronics);noise power;noise reduction;rewriting;spectral density estimation;speech enhancement;unsharp masking	Jalal Taghia;Rainer Martin;Jalil Taghia;Arne Leijon	2013	2013 IEEE International Conference on Acoustics, Speech and Signal Processing	10.1109/ICASSP.2013.6639078	normal distribution;gradient noise;gaussian noise;speech recognition;time–frequency analysis;colors of noise;value noise;noise measurement;pattern recognition;mathematics;phase noise;noise;statistics	EDA	82.55572128267532	-36.50707233594081	42598
e358178db5dc793ec84374fe773ed0e806cd6b8b	direct manipulation of blendshapes using a sketch-based interface		"""We introduce a method that localizes the direct manipulation of blendshape models for facial animation with a customized sketch-based interface. Direct manipulation methods address the problem of cumbersome weight editing process using the traditional tools with a practical """"pin-and-drag"""" operation directly on the 3D facial models. However, most of the direct manipulation methods have a global deformation impact, which lead to unintuitive and unexpected results. To this end, we propose a new way to localize the theory of direct manipulation method, using geodesic circles for confining the edits to the local geometry. Inspired by artists' brush painting on canvas, we additionally introduce a sketch-based interface as an application that provides direct manipulation and produces expressive facial poses efficiently and intuitively. Our method allows the artists to simply sketch directly onto the 3D facial model and automatically produces the expeditious manipulation until the desired facial pose is obtained. We show that localized blendshape direct manipulation has the potential to reduce the time-consuming blendshape editing process to an easy freehand stroke drawing."""	adobe freehand;coat of arms;direct manipulation interface;display resolution;interconnection;key frame	Ozan Cetinaslan;Verónica Orvalho	2018		10.1145/3208806.3208811	geodesic;computer vision;computer facial animation;sketch;facial expression;artificial intelligence;computer science	Graphics	66.1409687184982	-46.52890877898309	42613
9d1a5773dd606808b3cded054302279feea30222	radio frequency interference mitigation in radioastronomy	rfi mitigation;antenna measurements;antenna arrays;radioastronomical techniques radiofrequency interference interference suppression radioastronomy signal processing statistical analysis;symbol stream;doppler shifted spectral lines;radiofrequency interference telescopes radio astronomy antenna arrays antenna measurements extraterrestrial measurements noise level australia communication industry protection;spectrum;telescopes;radiofrequency interference;postcorrelation techniques;interference suppression;communication industry;radioastronomical techniques;protection;noise level;statistical analysis;radio frequency interference;signal processing;radio frequency interference mitigation;statistics;doppler shift;radio astronomy;extraterrestrial measurements;radioastronomy;australia;postcorrelation techniques radio frequency interference mitigation rfi mitigation radioastronomy doppler shifted spectral lines symbol stream statistics	RFI is increasingly a problem for radioastronomy with the ever expanding use of the radio spectrum by both the communications industry (transmitting) and the radioastronomers (receiving). Regulation can protect a few windows in the radio spectrum, but many experiments now need to access parts of the spectrum outside the reserved regions. Spectral lines, for example, may be significantly Doppler-shifted, and therefore require an observation window far from their rest frequencies. A variety of RFI mitigation techniques have been developed in recent years. Most of these have analogues in other disciplines, but the specifics of the radioastronomers' experiments allow for some interesting refinements. The astronomer is generally not interested in recovering a symbol stream in the data, but rather wants a more general description of the statistics. This makes a number of post-correlation techniques valuable and computationally viable.	ddos mitigation;doppler effect;experiment;interference (communication);microsoft windows;radio frequency;spectral efficiency;transmitter	Michael J. Kesteven	2005	Proceedings. (ICASSP '05). IEEE International Conference on Acoustics, Speech, and Signal Processing, 2005.	10.1109/ICASSP.2005.1416443	electromagnetic interference;spectrum;radio astronomy;doppler effect;telecommunications;signal processing;statistics	Robotics	80.65312489780885	-40.90665952907114	42831
b073ffeb0229b3738e5920191cb34f27b20d0745	experiments with tentacle robots	cameras manipulators robot vision systems robot kinematics kinematics graphics	An ideal tentacle manipulator is a non-conventional robotic arm with an infinite mobility. It has the capability of taking sophisticated shapes and of achieving any position and orientation in a 3D space. A tentacle manipulator is a hyper redundant or hyper degree of freedom manipulator. Hyper redundant robots produce changes of configuration using a continuous backbone made of sections which bend. The lack of no discrete joints is a serious and difficult issue in the determination of the robot's shape. A solution for this problem is the vision based control of the robot, kinematics and dynamics. A tentacle arm prototype was designed and the practical realization is now running. The control system is an image based visual servo control where the error control signal is defined directly in terms of image feature parameters.	control system;error detection and correction;feature (computer vision);internet backbone;prototype;redundancy (engineering);robot;robotic arm;servo;visual servoing	Dorian Cojocaru;Mircea Ivanescu;Razvan Tudor Tanasie;Sorin Dumitru;Florin Manta	2010			control engineering;mobile robot;computer vision;simulation;inverse kinematics;robot control;robot kinematics	Robotics	61.179746211998484	-30.236636208224418	42894
7ed89589e6325c4a30080b3393f8db834f02ec74	rear vehicle tracking on a bicycle using active sensor orientation control		This paper focuses on the development of an active sensing system for a bicycle to accurately detect and track rear vehicles. A collision detection sensor on a bicycle is required to be inexpensive, small, and lightweight. A single beam laser sensor that meets these constraints is mounted on a rotationally controlled platform for this sensing mission. The rotational orientation of the laser sensor needs to be actively controlled in real time in order to continue to focus on a rear vehicle, as the vehicle’s lateral and longitudinal distances change. This tracking problem requires controlling the real-time angular position of the laser sensor without knowing the future trajectory of the vehicle. The challenge is addressed using a novel receding horizon framework for active control and an interacting multiple model framework for estimation. The features and benefits of this active sensing system are shown first using simulation results. Then, extensive experimental results are presented using an instrumented bicycle to show the performance of the system in detecting and tracking rear vehicles during both straight and turning maneuvers.	algorithm;angularjs;collision detection;control system;crash (computing);interaction;lateral thinking;optimal control;radar tracker;real-time clock;real-time computing;real-time transcription;sensor;simulation;vehicle tracking system;video	Woongsun Jeon;Rajesh Rajamani	2018	IEEE Transactions on Intelligent Transportation Systems	10.1109/TITS.2017.2764006	vehicle tracking system;simulation;collision detection;angular displacement;trajectory;beam laser;laser;engineering	Robotics	57.255394753860585	-33.73886344458979	42949
377dddfba8eb91e706c07f12515e63f628ddb85a	imitation learning framework based on principal component analysis	humanoid robot;motion reconstruction;principal component analysis;evolutionary algorithm;imitation learning	In this paper, an imitation learning framework that includes an evolutionary process based on principal component analysis (PCA) is presented. The framework comprises offline and online processes. In the offline process, human demonstrations are used to develop a motion database. The database covers the workspace and includes robot properties. The evolved database has a clustered structure for efficiency. In the online process, a robot can generate desired motions using a real-time motion reconstruction method based on PCA. The performance of this method is verified through two case studies. The proposed framework is applied to the generation of reaching motions to an object on a table and a shelf.		Garam Park;Atsushi Konno	2015	Advanced Robotics	10.1080/01691864.2015.1007084	computer vision;computer science;humanoid robot;artificial intelligence;machine learning;evolutionary algorithm;principal component analysis	Robotics	61.92827635858297	-25.774402761974308	42965
c81a488b4af07e4e913516737c4e2631a9d8900b	n-ary implicit blends with topology control	implicit surfaces	Constructive implicit surfaces are attractive for modeling and animation because they seamlessly handle shapes with complex and dynamic topology. However, the way they merge shapes is difficult to control. This paper introduces a solution: an improved blend operator that provides control over how topology changes are handled. It is based on a correction applied to the standard blending operator: the sum. Building on summation preserves the n-ary nature of the blend, providing the simplicity of arbitrary (e.g. flat) construction trees and segmentation invariance. The correction is based on projection to a reference case in the variation-space defined by the field and the norm of its gradient. It provides a single parameter, allowing for tuning behavior to achieve effects ranging from avoiding topological combination, through merging only during overlap, to merging at a distance. Dynamic adjustment of the parameter allows for context-dependent effects. Applications range from skeleton-based modeling, where shapes keep the topology of their skeleton, to objects that change topology during animation, with controllable merging. We illustrate the latter with Manga-style hair, where merging depends on the angle between hair wisps. & 2014 Elsevier Ltd. All rights reserved.		Cedric Zanni;Michael Gleicher;Marie-Paule Cani	2015	Computers & Graphics	10.1016/j.cag.2014.09.012	mathematical optimization;combinatorics;computer science;mathematics;geometry;algorithm;computer graphics (images)	Graphics	67.59969352443775	-45.579299609852626	42970
1d2d42a94b6bc41ccbf42e688023f579999ab361	behaviour based mobile robot navigation technique for real world environments using fuzzy logic system	fuzzy reasoning;expert systems;design and development;mobile robot;path planning;mobile robots navigation fuzzy logic robot kinematics design methodology expert systems sensor systems decision making fuzzy control fuzzy systems;mobile robots;fuzzy logic;associative processing;obstacle avoidance;decision making process;mobile robot navigation;fuzzy logic system;associative memory;associative processing mobile robots path planning fuzzy logic expert systems fuzzy reasoning decision making;fuzzy associative memory mobile robot navigation fuzzy logic expert system inference system decision making processes;autonomous robot;expert system	A key issue in the research of an autonomous robot is the design and development of the navigation technique that enables the robot to navigate in a real world environment. In this research, the focus is to develop the techniques and methods to: (1) design the individual behavior, coordination, and fusion of these behaviors using fuzzy logic expert system. Each behavior design is based on the situation context of applicability (SCA). (2) Design of the controller, which maps the sensors input to the motor output through fuzzy logic inference system. (3) Formulation of the decision-making processes by using fuzzy associative memory (FAM). (4) Obtain experimental results using simulation. The above methods and techniques are applied for active media pioneer robot and tested through simulation.	autonomous robot;content-addressable memory;expert system;fuzzy associative matrix;fuzzy logic;inference engine;map;mobile robot;robotic mapping;sensor;simulation	Subramaniam Parasuraman;Velappa Ganapathy;Bijan Shirinzadeh	2004	2004 IEEE International Conference on Systems, Man and Cybernetics (IEEE Cat. No.04CH37583)	10.1109/ICSMC.2004.1400861	mobile robot;computer vision;fuzzy electronics;adaptive neuro fuzzy inference system;computer science;artificial intelligence;expert system;mobile robot navigation	Robotics	59.432411216689715	-27.76464633331231	42986
ffbba15eaf119695fa4f6df354bd57f3545218e0	generalized higher order energy based instantaneous amplitude and frequency estimation and their applications to power disturbance detection	instantaneous amplitude;instantaneous frequency;higher order differential energy operator;power disturbances	The instantaneous amplitude (IA) based on the higher order differential energy operator is proposed. And its general form for arbitrary order is also proposed. The various definitions of the IA and the instantaneous frequency (IF) estimators are considered. The IA and IF estimators based on the energy operators need less computational cost than the conventional IF and IA estimators exploiting the Hilbert transform. The IF and IA estimators are compared in terms of the frequency and amplitude tracking accuracy of the AM-FM signals. For noiseless case, the IA and IF estimators based on the Teager-Kaiser energy operator show better tracking performance than the IF and IA estimators based on the higher energy operators. However, under noisy condition, the IF and IA estimator based on the higher order energy operators with the order 3 and 4 show better tracking than the Teager-Kaiser energy based estimators. The IF and IA estimators are applied to signals in the various power anomalies to show their usefulness as the disturbance detectors.	algorithmic efficiency;amplitude damping channel;computation;electronic signature;energy operator;fm broadcasting;hilbert transform;instantaneous phase;onset (audio);sensor;spectral density estimation	Byeong-Gwan Iem	2012	Int. J. Fuzzy Logic and Intelligent Systems	10.5391/IJFIS.2012.12.2.162	mathematical optimization;calculus;mathematics;statistics	Mobile	80.36733217984484	-38.20270463000466	43137
601d665d36138f91b3fd6e01c9358576552fa107	computational steering for implant planning in orthopedics		In this thesis, I present novel, sophisticated simulation and visualization techniques for the realization of a computational steering environment for preoperative implant planning in orthopedics. In particular, I present real-time techniques for the physicsbased simulation of deformable objects, for the visualization of stress tensor fields in elastic bodies, and for the visualization of the spatial distances between two objects. The presented methods are specifically designed to be executed on the GPU to exploit the GPU’s massive computing power and memory bandwidth. In addition, this thesis addresses the efficient simulation of cuts in deformable objects. First, I present a novel real-time multigrid finite element method for the physicsbased simulation of deformable objects that is realized entirely on the GPU. This method is based on linear elasticity and the corotational formulation of strain. The governing system of partial differential equations is discretized by using hexahedral finite elements aligned on a uniform Cartesian grid and the implicit Newmark time integration scheme. To efficiently solve the arising linear system of equations, a geometric multigrid method is employed. I present a specific restructuring of the multigrid scheme that enables an efficient GPU implementation using the CUDA computing API. Compared to an optimized and parallelized CPU implementation, significant speed-ups are demonstrated. Second, I present a novel approach for the simulation of cuts in deformable objects that is based on a geometric multigrid solver to achieve high computational efficiency. This approach is built upon an octree discretization of the simulation domain. Finite elements that are cut are regularly subdivided, until a finest level is reached. At the finest level, face adjacent elements are disconnected. I present a novel strategy to embed complex topology changes induced by cuts into the multigrid hierarchy, and I give a detailed analysis to demonstrate the superior performance of the proposed solver in comparison to alternative numerical solution methods. Third, I present novel methods for the visualization of stress tensor fields arising in elasticity simulations. In particular, I present a method for the visualization of principal	application programming interface;cuda;cartesian closed category;central processing unit;computation;computational steering;cut (graph theory);discretization;elasticity (data store);finite element method;graphics processing unit;hexahedron;linear system;memory bandwidth;multigrid method;newmark-beta method;numerical methods for ordinary differential equations;numerical partial differential equations;octree;parallel computing;real-time clock;regular grid;simulation;solver;system of linear equations	Christian Dick	2012			visualization;biomedical engineering;bone tissue;computational steering;implant;engineering	Visualization	69.98199666489393	-46.50233971144641	43142
20a2b7946d48fa40c4176ea3cffb2e9a36074577	image compression with anisotropic triangulations	image sampling;image compression method;spline;seeding points;image coding;delaunay triangulation;tensile stress;measurement;linear spline approximation;data compression;anisotropic geodesic distances;differential geometry;geometry;linear approximation;splines mathematics;geodesic distance;fast marching;rate distortion theory;wavelet transforms;approximation theory;anisotropic geodesic delaunay triangulations;geometric images;geophysics computing;image compression;image edge detection;feature extraction;wavelet based encoder;euclidean delaunay triangulation;anisotropic magnetoresistance;encoder;approximation methods;jpeg 2000;progressive geodesic meshing algorithm;sampling strategy;mesh generation;riemannian fast marching	We propose a new image compression method based on geodesic Delaunay triangulations. Triangulations are generated by a progressive geodesic meshing algorithm which exploits the anisotropy of images through a farthest point sampling strategy. This seeding is performed according to anisotropic geodesic distances which force the anisotropic Delaunay triangles to follow the geometry of the image. Geodesic computations are performed using a Riemannian Fast Marching, which recursively updates the geodesic distance to the seed points. A linear spline approximation on this triangulation allows to approximate faithfully sharp edges and directional features in images. The compression is achieved by coding both the coefficients of the spline approximation and the deviation of the geodesic triangulation from an Euclidean Delaunay triangulation. Numerical results show that taking into account the anisotropy improves the approximation by isotropic triangulations of complex images. The resulting encoder competes well with wavelet-based encoder such as JPEG-2000 on geometric images.	anisotropic diffusion;approximation algorithm;coefficient;computation;delaunay triangulation;distance (graph theory);encoder;fast marching method;geodesic grid;image compression;jpeg 2000;nearest-neighbor interpolation;numerical method;recursion;sampling (signal processing);spline (mathematics);wavelet	Sébastien Bougleux;Gabriel Peyré;Laurent D. Cohen	2009	2009 IEEE 12th International Conference on Computer Vision	10.1109/ICCV.2009.5459425	data compression;magnetoresistance;spline;mesh generation;differential geometry;mathematical optimization;encoder;geodesic;topology;delaunay triangulation;rate–distortion theory;feature extraction;image compression;pitteway triangulation;fast marching method;jpeg 2000;mathematics;geometry;constrained delaunay triangulation;stress;measurement;linear approximation;wavelet transform;approximation theory	Vision	70.06362247359701	-43.91056674459904	43164
b4d54d1dc81e3ff222ff1b329d60c2f5e9a81bf4	relative positioning system using simultaneous round trip time of flight measurements	relative position;simultaneous round trip time of flight measurements;object positions;relative positioning system;acoustic variables measurement;mobile object;round trip time;acoustic emissions;navigation;spatial relation;multidimensional scaling technique;least square;multidimensional scaling;position measurement time measurement signal processing algorithms computer architecture acoustic emission radio frequency hardware acoustic transducers multidimensional systems aerospace electronics;navigation acoustic emission acoustic variables measurement;acoustic emission;least square algorithms;mobile objects;least square algorithms relative positioning system mobile objects robot team acoustic emissions simultaneous round trip time of flight measurements object positions multidimensional scaling technique;robot team	The determination of the relative position among mobile objects or members of a robot team is a useful information when the systems are not restricted to a particular environment and they cannot depend on an external infrastructure to obtain their location information. The solution for this kind of problems cannot be divided and treated separately for each object. Therefore it is necessary to implement mechanisms that allow to simultaneously determine the spatial relations among objects not knowing their absolute location in the environment. After that, a positioning algorithm can be computed whose complexity depends on the number of observations made and the precision required in the system. In this work, the implementation of a relative positioning system is described where only acoustic emissions are made in order to obtain information about the other objects. These data are obtained by using simultaneous round-trip-time-of-flight measurements. Finally, using this information, the object positions are computed with a multidimensional scaling technique, and a closer solution is achieved with least-square algorithms.	acoustic cryptanalysis;algorithm;algorithmic efficiency;image scaling;location (geography);multidimensional scaling;non-linear least squares;perturbation theory;positioning system;signal processing;vii	Carlos De Marziani;Jesús Ureña;Manuel Mazo;Álvaro Hernández;Juan Jesús García;Ana Jiménez;María del Carmen Pérez;A. Ochoa;Jose M. Villadangos	2006	2006 IEEE Conference on Emerging Technologies and Factory Automation	10.1109/ETFA.2006.355244	spatial relation;embedded system;computer vision;navigation;electronic engineering;simulation;multidimensional scaling;computer science;engineering;acoustic emission;machine learning;least squares;round-trip delay time	Robotics	55.62666907158068	-33.93915420405571	43204
0ce66e9b6712b352c31e7bbc92868655ab3b646c	computing the 3d voronoi diagram robustly: an easy explanation	3d geometric computing;computational geometry;delaunay tetrahedralization;3d voronoi diagram;spatial distribution;delaunay tetrahedralization 3d voronoi diagram 3d geometric computing;robustness algorithm design and analysis programming profession data mining geographic information systems distributed computing computational geometry sorting application software data structures;voronoi diagram	Many algorithms exist for computing the 3D Voronoi diagram, but in most cases they assume that the input is in general position. Because of the many degeneracies that arise in 3D geometric computing, their implementation is still problematic in practice. In this paper, I describe a simple 3D Voronoi diagram (and Delaunay tetrahedralization) algorithm, and I explain, by giving as many details and insights as possible, how to ensure that it outputs a correct structure, regardless of the spatial distribution of the points in the input.	algorithm;degenerate energy levels;delaunay triangulation;voronoi diagram	Hugo Ledoux	2007	4th International Symposium on Voronoi Diagrams in Science and Engineering (ISVD 2007)	10.1109/ISVD.2007.10	combinatorics;discrete mathematics;voronoi diagram;centroidal voronoi tessellation;computer science;theoretical computer science;bowyer–watson algorithm	Theory	62.269123745576096	-47.44883460852455	43223
0a20db147a9dcf30da7968236698f60bc5b35141	isotropic remeshing of surfaces: a local parameterization approach	centroidal voronoi tessellation;local parameterization;mesh adaptation;isotropic triangle meshing;mesh generation;surface mesh generation;triangle mesh;density functional	We present a method for isotropic remeshing of arbitrary genus surfaces. The method is based on a mesh adaptation process, namely, a sequence of local modifications performed on a copy of the original mesh, while referring to the original mesh geometry. The algorithm has three stages. In the first stage the required number or vertices are generated by iterative simplification or refinement. The second stage performs an initial vertex partition using an area-based relaxation method. The third stage achieves precise isotropic vertex sampling prescribed by a given density function on the mesh. We use a modification of Lloyd’s relaxation method to construct a weighted centroidal Voronoi tessellation of the mesh. We apply these iterations locally on small patches of the mesh that are parameterized into the 2D plane. This allows us to handle arbitrary complex meshes with any genus and any number of boundaries. The efficiency and the accuracy of the remeshing process is achieved using a patch-wise parameterization technique. Key-words: Surface mesh generation, isotropic triangle meshing, centroidal Voronoi tessellation, local parameterization. ∗ Technion, Haifa, Israel † INRIA Sophia-Antipolis ‡ Technion, Haifa, Israel Remaillage isotrope de surfaces utilisant une paramétrisation locale Résumé : Cet article décrit une méthode de remaillage isotrope de surfaces triangulées. L’approche repose sur une technique d’adaptation locale du maillage. L’idée consiste à opérer une séquence d’opérations élémentaires sur une copie du maillage original, tout en faisant référence au maillage original pour la géométrie. L’algorithme comporte trois étapes. La première étape ramène la complexité du maillage au nombre de sommets désiré par raffinement ou décimation itérative. La seconde étape opère une première répartition des sommets via une technique de relaxation optimisant un équilibrage local des aires sur les triangles. La troisième étape opère un placement isotrope des sommets via une relaxation de Lloyd pour construire une tessellation de Voronoi centrée. Les itérations de relaxation de Lloyd sont appliquées localement dans un espace paramétrique 2D calculé à la volée sur un sous-ensemble de la triangulation originale de telle que sorte que les triangulations de complexité et de genre arbitraire puissent être efficacement remaillées. Mots-clés : Maillage de surfaces, maillage triangulaire isotrope, diagrammes de Voronoi centrés, paramétrisation locale. Isotropic Remeshing of Surfaces	bibliothèque de l'école des chartes;centroidal voronoi tessellation;computer graphics (computer science);delaunay triangulation;espace;genus (mathematics);iteration;level of detail;linear algebra;linear programming relaxation;lloyd's algorithm;mesh generation;refinement (computing);relaxation (approximation);relaxation (iterative method);sampling (signal processing);voronoi diagram	Vitaly Surazhsky;Pierre Alliez;Craig Gotsman	2003			combinatorics;topology;centroidal voronoi tessellation;mathematics;geometry;laplacian smoothing;t-vertices	Graphics	66.0839588394755	-40.905815029806966	43235
7b03dec05a719368db7e7ee68039e13c88e6dab5	scale-invariant probabilistic latent component analysis	latent signal reconstruction probabilistic latent component analysis scale invariant decomposition musical spectrograms constant q spectrograms fourier transform spectrograms;audio signal processing;probability;music signal processing;spectrogram;non negative decomposition;acoustics;singular value decomposition;random variables;spectrogram harmonic analysis source separation random variables probabilistic logic acoustics;probabilistic latent component analysis;shiftinvariant decomposition;shiftinvariant decomposition music signal processing non negative matrix factorization probabilistic latent component analysis;nonnegative matrix factorization;principal component analysis;non negative matrix factorization;fourier transforms;signal reconstruction;probabilistic logic;source separation;music;singular value decomposition audio signal processing fourier transforms music principal component analysis probability signal reconstruction;shift invariant decomposition;harmonic analysis	In this paper, we present a new method for decomposing musical spectrograms. This method is similar to shift-invariant Probabilistic Latent Component Analysis, but, when the latter works with constant Q spectrograms (i.e. with a logarithmic frequency resolution), our technique is designed to decompose standard short time Fourier transform spectrograms (i.e. with a linear frequency resolution). This makes it possible to easily reconstruct the latent signals (which can be useful for source separation).	source separation;spectrogram	Romain Hennequin;Roland Badeau;Bertrand David	2011	2011 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA)	10.1109/ASPAA.2011.6082265	speech recognition;acoustics;harmonic analysis;pattern recognition;mathematics;non-negative matrix factorization;statistics	Vision	80.63375671147986	-36.91786418159258	43294
1659c5afbe71875ade334a214c219f91025fa95a	the minnesota scanner: a prototype sensor for three-dimensional tracking of moving body segments	cartesian coordinate;system structure;systeme mesure;commande;laser;data collection;espacio 3 dimensiones;corps mobile;photodetecteur;robots computer vision image sensors;fotodetector;robotics;image sensors;signal integrity;three dimensional;pipelined architecture image sensors computer vision minnesota scanner three dimensional tracking moving body segments robot motion robot endpoint control laser light photovoltaic diode;tracking movable target;computer vision;prototypes target tracking testing sensor phenomena and characterization humans robot motion robot sensing systems robot kinematics motion control robot control;captador medida;measurement sensor;light source;capteur mesure;structure systeme;human motion;espace 3 dimensions;cuerpo movil;coordenadas cartesianas;robots;three dimensional space;source lumineuse;fuente luminosa;robotica;control;measuring system;laser scanning;poursuite;robotique;moving body;coordonnee cartesienne;sistema medida;persecucion y continuacion;estructura sistema;photodetector	"""An advanced method of tracking the three-dimensional motion of bodies has been developed. This system, which is presently being used for human motion tracking, has the potential for dynamically characterizing robot motion and also provides a means for facilitating robot endpoint control. Three rotating planes of laser light, fined and moving photovoltaic diode targets, and a pipelined architecture of analog and digital electronics are used to locate multiple targets whose number is only limited by available computer memory. Data collection rates are a function of the laser scan rotation speed and are currently selectable up to 480 Hz. The tested performance on a preliminary prototype designed for 0.1-in accuracy (for tracking human motion) at a 480-Hz data rate includes a resolution of 0.8 mm (0.03 in), a repeatability of k0.635 mm (k0.025 in), and an absolute accuracy of *2.0 mm ( f 0.08 in) within an eight cubic meter volume with all results applicable at the 95-percent level of confidence along each coordinate direction. The system can be used to reduce XYZ target position data to body angular orientation which, for this first prototype, ranges in accuracy from k0.5"""" to f 1"""". Moving targets can be tracked at speeds exceeding 1 m/s with signal integrity tested but not limited to 25-Hz motions."""		Brett R. Sorensen;Max Donath;Guo-Ben Yang;Roland C. Starr	1989	IEEE Trans. Robotics and Automation	10.1109/70.88064	control engineering;three-dimensional space;computer vision;simulation;computer science;engineering;control theory;mathematics;robotics	Robotics	57.904756214058075	-33.84025331756778	43377
3612afd4417b2373541c2b9c9f23bf7a924bbe7a	high dynamic range imaging and image-based lighting	texturing;weathering;material models;high dynamic range imaging;erosion;ray tracing;subsurface scattering;natural phenomena;volume modeling;physical simulation		dynamic range;high-dynamic-range imaging;image-based lighting;range imaging	Erik Reinhard;Paul E. Debevec;Greg Ward;Sumanta N. Pattanaik	2005		10.1145/1198555.1198707	ray tracing;subsurface scattering;erosion;weathering;computer science;computer graphics (images)	Robotics	63.8821339318821	-51.3729123763254	43478
efdaee98f9c1f6fb9f11689c7a60c640f5fe92b2	efficient asynchronous bvh reconstruction with vertex prediction	bvh reconstruction;ray tracing;vertex prediction	We present a BVH quality maintenance scheme using vertex prediction. This scheme improves the rebuild latency problem with an asynchronous BVH reconstruction scheme. The experimental results indicate that the proposed scheme achieved the increased frame rate up to 45.1% compared with an asynchronous BVH reconstruction at the worst frame rate.	bounding volume hierarchy	Jin Woo Kim;Jinhong Park;Jongsup Baek;Jung-Min Kim;Tack-Don Han	2016		10.1145/3005274.3005303	ray tracing;real-time computing;computer science;theoretical computer science;mathematics;distributed computing	Mobile	66.91885006667846	-50.354358887407486	43557
3bf8f4cb28e4e1a7a10d8b114d2e06dfbab1ebb8	the design of anthropomorphic prosthetic hands: a study of the southampton hand	hand;prosthetics;control;electromyography	The design of prosthetic hands is constrained by a series of strict conditions. Despite this, many different design strategies have been explored. One particular form is the Southampton Hand system. This is a hierarchically controlled, electrically driven hand, with multiple axes, in an anthropomorphic form. This paper details the range of mechanical solutions adopted to address the conditions. It also compares them with other solutions.		Peter J. Kyberd;Colin Light;Paul H. Chappell;Jim M. Nightingale;Dave R. Whatley;Mervyn Evans	2001	Robotica	10.1017/S0263574701003538	simulation;engineering;biological engineering;scientific control	HCI	72.2239453691166	-25.59548672875083	43562
0d52e3ca78681013b8fd4ddea0157f7bd8a408b9	antenna pointing for high bandwidth communications from mobile robots	mobile robot;error analysis mobile robots antennas tracking position control radio links robot kinematics;mobile robots;requirement analysis;wireless communication;error analysis;position control;low mass;antennas;atacama desert trek antenna pointing system high bandwidth communications mobile robots tracking sensor configuration nomad planetary robot kinematics error analysis;rough terrain;mechanism design;mobile antennas bandwidth mobile communication mobile robots communication system control payloads receiving antennas space technology vehicles target tracking;tracking;robot kinematics;radio links	This paper discusses the challenge of achieving high bandwidth, distant range wireless communication from mobile robots by way of antenna tracking. In the case of robots traversing rough terrain at moderate speeds, tracking demands high slew rates and large motion ranges due to vehicle motion disturbances. Attaining tracking accuracy, particular with the low mass and power inherent to mobile robots, requires an innovative approach. This paper presents requirements analysis, mechanism design, sensor configuration and some experimental results for an antenna pointing mechanism that was developed for Nomad, a planetary-relevant mobile robot. The mechanism was demonstrated during the summer of 1997 in Nomad’s 200 km traverse in the Atacama Desert of Chile.	google summer of code;mobile robot;planetary scanner;requirement;requirements analysis;traverse	Deepak Bapna;Eric Rollins;Alex Foessel;William Whittaker	1998		10.1109/ROBOT.1998.680974	control engineering;mobile robot;simulation;computer science;artificial intelligence;control theory	Robotics	60.20582604304267	-29.520130890954444	43590
ef49d3c5246fd03185ec8fe382384b773c72c36e	an embedded system for image sensor control and date processing			embedded system;image sensor	Peter Scott	2009				Robotics	58.6379534135112	-42.64474105643244	43593
d2482f71626651300d31798c7d98069f073be6e5	collision avoidance strategies for unmanned aerial vehicles in formation flight	collision avoidance;aircraft;geometry;military aircraft;unmanned aerial vehicles;heuristic algorithms;real-time systems	Collision avoidance strategies for multiple unmanned aerial vehicles (UAVs) based on geometry are investigated in this study. The proposed strategies allow a group of UAVs to avoid obstacles and separate if necessary through a simple algorithm with low computation by expanding the collision-cone approach to formation of UAVs. The geometric approach uses line-of-sight vectors and relative velocity vectors where dynamic constraints are included in the formation. Each UAV can determine which plane and direction are available for collision avoidance. An analysis is performed to define an envelope for collision avoidance, where angular rate limits and obstacle detection range limits are considered. Based on the collision avoidance envelope, each UAV in a formation determines whether the formation can be maintained or not while avoiding obstacles. Numerical simulations are performed to demonstrate the performance of the proposed strategies.		Joongbo Seo;Youdan Kim;Seungkeun Kim;Antonios Tsourdos	2017	IEEE Transactions on Aerospace and Electronic Systems	10.1109/TAES.2017.2714898	collision;mathematics;control theory;obstacle;simple algorithm;obstacle avoidance	Robotics	55.74111343577646	-24.914187237724942	43695
bea865d7888305287abefb868b6e9a70dc547c58	computer modeling and simulation of fruit sunscald	cell mechanics;mass spring model;virtual reality;fruit sunscald;computer simulation	Although the simulation of many kinds of natural phenomena has been studied in the field of computer simulation and graphics, the reproduction of natural fruit diseases processes has not received much attention. Sunscald is the representative of physiological diseases. This paper presented a novel computer modeling and simulation method for fruit sunscald. We mainly focus on the morphology change of fruit appearance affected by sunscald disease under the condition of water loss. An improved mass spring model is proposed, by combining cell turgor pressure with mass spring. We adopt this physical deformation model for dynamic simulation of fruit sunscald disease. We calculate the cell turgor pressure variation due to water loss and thereby get the displacement changing of every mass particle in our simulation system. Finally, the software of Maya is adopted to render the deform model to render the simulation result. Experiments demonstrate the effectiveness of our method.	autodesk maya;computer simulation;displacement mapping;dynamic simulation;experiment;galaxy morphological classification;graphics;mathematical morphology	Shiguang Liu;Dongfang Fan	2015	Int. J. Image Graphics	10.1142/S0219467815500138	computer simulation;simulation;computer science;virtual reality;computer graphics (images)	Graphics	70.98262482400253	-47.29758786785038	43705
4b82084fb1f66ff90e45a73aed4779f74559b900	high qualitiy simplification and repair of polygonal models		Because of the rapid evolution of 3D acquisition and modelling methods, highly complex and detailed polygonal models with constantly increasing polygon count are used as three-dimensional geometric representations of objects in computer graphics and engineering applications. The fact that this particular representation is arguably the most widespread one is due to its simplicity, flexibility and rendering support by 3D graphics hardware. Polygonal models are used for rendering of objects in a broad range of disciplines like medical imaging, scientific visualization, computer aided design, film industry, etc. The handling of huge scenes composed of these high-resolution models rapidly approaches the computational capabilities of any graphics accelerator. In order to be able to cope with the complexity and to build level-of-detail representations, concentrated efforts were dedicated in the recent years to the development of new mesh simplification methods that produce high-quality approximations of complex models by reducing the number of polygons used in the surface while keeping the overall shape, volume and boundaries preserved as much as possible. Many well-established methods and applications require “well-behaved” models as input. Degenerate or incorectly oriented faces, T-joints, cracks and holes are just a few of the possible degenaracies that are often disallowed by various algorithms. Unfortunately, it is all too common to find polygonal models that contain, due to incorrect modelling or acquisition, such artefacts. Applications that may require “clean” models include finite element analysis, surface smoothing, model simplification, stereo lithography. Mesh repair is the task of removing artefacts from a polygonal model in order to produce an output model that is suitable for further processing by methods and applications that have certain quality requirements on their input. This thesis introduces a set of new algorithms that address several particular aspects of mesh repair and mesh simplification. One of the two mesh repair methods is dealing with the inconsistency of normal orientation, while another one, removes the inconsistency of vertex connectivity. Of the three mesh simplification approaches presented here, the first one attempts to simplify polygonal models with the highest possible quality, the second, applies the developed technique to out-of-core simplification, and the third, prevents selfintersections of the model surface that can occur during mesh simplification.	3d computer graphics;approximation;computer-aided design;finite element method;graphics hardware;graphics processing unit;image resolution;k-vertex-connected graph;level of detail;medical imaging;out-of-core algorithm;polygon (computer graphics);requirement;scientific visualization;smoothing	Pavel M Borodin	2009			discrete mathematics;mathematics	Graphics	68.30513109246859	-45.331343000324466	43766
7a179ff8f7e3437a19e744ce248b854ae1131dbf	acquisition of a large pose-mosaic dataset	motion analysis;textured 3d cad models;instruments;computer graphics;cad;solid modelling image reconstruction cad;3 dof position;layout;large pose mosaic dataset acquisition;computer vision;automatic reconstruction;image reconstruction;prototype mechanical pan tilt head;textured 3d cad models large pose mosaic dataset acquisition digital images spatial position spherical mosaics 3 dof position 3 dof orientation absolute coordinate system prototype mechanical pan tilt head optimization correlation scheme point correspondences evaluation metrics automatic reconstruction;evaluation metrics;absolute coordinate system;image analysis;head;digital image;point correspondences;spherical mosaics;digital images;cameras image reconstruction instruments image analysis computer graphics laboratories head computer vision motion analysis layout;3 dof orientation;cameras;solid modelling;coordinate system;optimization correlation scheme;spatial position	"""We describe the generation of a large pose-mosaic dataset: a collection of several thousand digital images , grouped by spatial position into spherical mosaics , each annotated with estimates of the acquiring camera's 6 DOF pose (3 DOF position and 3 DOF orientation) in an absolute coordinate system. The pose-mosaic dataset was generated by acquiring images, grouped by spatial position into nodes (essentially , spherical mosaics). A prototype mechanical pan-tilt head was manually deployed to acquire the data. Manual surveying provided initial position estimates for each node. A back-projecting scheme provided initial rotational estimates. Relative rotations within each node, along with internal camera parameters , were reened automatically by an optimization-correlation scheme. Relative translations and rotations among nodes were reened according to point correspondences , generated automatically and by a human operator. The resulting pose-imagery is self-consistent under a variety of evaluation metrics. Pose-mosaics are useful \\rst-class"""" data objects, for example in automatic reconstruction of textured 3D CAD models which represent urban exteriors."""	computer-aided design;digital image;mathematical optimization;prototype	Satyan R. Coorg;Neel Master;Seth J. Teller	1998		10.1109/CVPR.1998.698707	computer vision;image analysis;computer science;digital image;computer graphics (images)	Vision	56.65442356595927	-48.20375907566573	43985
1001cd3c5a39d31fdc7e2e29961de01ed0151570	super-resolution from noisy data		This paper studies the recovery of a superposition of point sources from noisy bandlimited data. In the fewest possible words, we only have information about the spectrum of an object in the lowfrequency band [−flo, flo] and seek to obtain a higher resolution estimate by extrapolating the spectrum up to a frequency fhi > flo. We show that as long as the sources are separated by 2/flo, solving a simple convex program produces a stable estimate in the sense that the approximation error between the higher-resolution reconstruction and the truth is proportional to the noise level times the square of the super-resolution factor (SRF) fhi/flo.	approximation error;bandlimiting;convex optimization;extrapolation;noise (electronics);signal-to-noise ratio;super-resolution imaging	Emmanuel J. Candès;Carlos Fernandez-Granda	2012	CoRR		mathematical optimization;deconvolution;mathematics;sparsity-of-effects principle;statistics	ML	82.82825330265993	-44.62732158695297	43989
4d5667402a8c17922ffcd9945449f63aa85e829d	interpretation of an axonometric projection of a polyhedron	proyeccion;man machine relation;computer vision;interpretacion;trace ligne axonometrique;projection;interpretation;vision ordinateur;pattern analysis;relation homme machine;analyse forme	Abstract   This paper addresses some problems in interpretation of axonometric line drawings of polyhedrons, especially the problems of how much and what kind of further information is necessary to reconstruct uniquely the shape of objects from their axonometric line drawings. For line drawings which are precise, in the sense that vertices are drawn in correct position, the problems can be treated in terms of linear algebra, and a method for solving them is established. When line drawings are roughly drawn, on the other hand, the problems are much more difficult; a solution based on some combinatorial technique is given to a restricted object world in which each vertex lies on exactly three faces.	axonometric projection;polyhedron	Kokichi Sugihara	1984	Computers & Graphics	10.1016/0097-8493(84)90037-2	computer vision;projection;interpretation;computer science;artificial intelligence;isometric projection;mathematics;geometry;algorithm	Graphics	65.00862380540495	-40.78224574783517	44023
1b5a0bfc3456462ef6f80126d795eac56393a989	harmonics estimation based on instantaneous frequency and its application to pitch determination of speech	instantaneous frequency;pitch determination;harmonic components;fundamental frequency;tracking		instantaneous phase	Toshihiko Abe;Takao Kobayashi;Satoshi Imai	1995	IEICE Transactions		instantaneous phase;frequency multiplier;speech recognition;audio frequency;pitch detection algorithm;harmonic;tracking;fundamental frequency;audio time-scale/pitch modification	HCI	81.53210743306876	-34.369525738963596	44075
0a4e9c7ac837e2b31a8f14e0776df0d22f0cdb4f	real time grasping of freely placed cylindrical objects	real time	In the near future, service robots will support people with different handicaps to improve the quality of their life. One of the required key technologies is to setup the grasping ability of the robot. This includes an autonomous object detection and grasp motion planning to fulfil the task of providing objects from any position on a table to the user. This paper presents a complete system, which consists of a fixed working station equipped with a laser-range scanner, a seven degrees of freedom arm manipulator and an arm prothesis as gripper. The contribution of this work is to use only one sensor system based on a laser-range scanning head to solve this challenge. The goal is that the user can select any defined object on the table and the robot arm delivers it to a target position or to the disabled person.	autonomous robot;complex system;cylinder-head-sector;feature detection (computer vision);feature detection (web development);mobile robot;motion planning;object detection;recursion (computer science);robot end effector;robotic arm;stereopsis	Mario Richtsfeld;Wolfgang Ponweiser;Markus Vincze	2008			computer science	Robotics	58.59735066252775	-32.286251906739864	44213
7ac1b21a5af3c70c5b111e10ba4a8fe41636a002	stabilizing first person 360 degree videos		The use of 360 degree cameras, enabling one to record and share full-spherical 360° X 180° view without any cropping in the viewing angle, is on the rise. Shake in such videos is problematic, especially when used in conjunction with VR headsets causing cybersickness to the viewer. The current state-of-the-art video stabilization algorithm [17] designed specifically for 360 degree videos considers the special geometrical constraints in such videos. However, the specific steps in the algorithm can abruptly change the viewing direction in a video leading to unnatural experience for the viewer. In this paper, we propose to fix this anomaly by the use of L1 smoothness constraints on the camera path, as suggested by Grundmann et al. [7]. The modified algorithm is generic and our experiments indicate that the proposed algorithm not only gives a more natural and smoother stabilization for 360 degree videos but can be used for stabilizing normal field of view videos as well.	algorithm;anomaly detection;experiment;mathematical optimization;modulus of smoothness;viewing angle;viewing cone;virtual reality headset;virtual reality sickness	Chetan Arora;Vivek Kwatra	2018	2018 IEEE Winter Conference on Applications of Computer Vision (WACV)	10.1109/WACV.2018.00158	artificial intelligence;headphones;computer vision;shake;cropping;computer science;viewing angle;trajectory;image stabilization;field of view	Vision	58.18995674869807	-50.7485100653361	44219
d0762042e4a4afbe7d44026953dab23c9424bc88	real-time 3d artistic rendering system	modelizacion;image tridimensionnelle;texture;rendu image;representation graphique;tinta;3d imaging;restitucion imagen;humedad;real time;peinture art;intelligence artificielle;hardware accelerator;chino;three dimensional;humidite;modelisation;rendering system;3d model;graphics hardware;pintura arte;humidity;textura;image rendering;grafo curva;tridimensional image;artificial intelligence;ink;inteligencia artificial;chinois;chinese;modeling;encre;graphics;imagen tridimensional;painting art	This paper presents an artistic rendering system for generating 3D images of Chinese paintings using graphics hardware. The user can adjust suitable parameters flexibly to generate different brush styles as his/her hobby, and see rendering results in real time. In this system, we propose a hardware-accelerated method to draw Chinese painting strokes efficiently along visible silhouettes. Three-dimensional texture and multi-texture from normal graphics hardware is used to speed up generating various brushes with Chinese painting stylized strokes. The features of the traditional Chinese painting such as ink diffusion and moisture effects are simulated. Several examples of aesthetically pleasing Chinese-paintings rendered from 3D models are demonstrated using the proposed method.	3d modeling;artistic rendering;graphics hardware;hardware acceleration;real-time transcription;rendering (computer graphics)	Tong-Yee Lee;Shaur-Uei Yan;Yong-Nien Chen;Ming-Te Chi	2005		10.1007/11553939_65	computer vision;computer science;graphics;artificial intelligence;humidity;texture;graphics hardware;chinese;software rendering;computer graphics (images)	Graphics	63.09716528869877	-48.22595178981699	44250
559bfc2a5d5644e039ea97f4e0196ba2e55aea0e	adapting and reconfiguring human figure motion capture data through the application of inverse kinematics and biomechanics-based optimisation		This thesis investigates the issue of modifying motion capture data, specifically the reconfiguration process which includes retargeting and individualisation. To perform modifications, a series of novel algorithms are introduced, where the first is grounded in the domain of inverse kinematics and the second is in dynamics. By applying the algorithms to existing motions, it is shown how the tasks of simple retargetting problem, individualisation and injury simulation can be achieved. These are the limit of the inverse kinematics technique. In contrast, the dynamics-based algorithm also provides the ability to add in plausible environmental or force-based changes. Aside from the algorithms themselves, the reconfiguration of motions demonstrates the most significant portion of this work in that it is possible to take a single piece of motion data from a source actor and spawn many different versions of it in order to produce motions that better portray the build and biomechanical structure of a target character. This addresses the issue of using the same motion for each and every character regardless of its shape and size, which looks unrealistic. The reconfigured motions are produced using an example motion of a source actor and the biomechanical information of the target actor. Comparing the reconfigured motions to the real motions of target actors provides a validation for these techniques. In addition to the two main threads of work that come from the inverse kinematics and dynamics-based modification algorithms, a new method of processing positional motion capture marker data to result in an animated hierarchical data structure is presented.	actor model;algorithm;data structure;hierarchical database model;inverse kinematics;mathematical optimization;motion capture;retargeting;simulation;spawn (computing)	Michael Meredith	2005				Graphics	62.76477112223633	-45.365817601757804	44441
6855bd49b9baaad0ab165dffc6c6518328f20491	the invariance of weak convexity conditions of b-nets with respect to subdivision	concepcion asistida;computer aided design;triangular bernstein be zier surface;computer graphics;invarianza;b net;invariance;b reseau;condition convexite faible;weak convexity conditions;neak convexity condition;conception assistee;subdivision;surface triangulaire bernstein bezier;triangular bernstein bezier surface;grafico computadora;infographie	Abstract   In (Grandine, 1989), it is proved that some types of subdivision do not preserve the convexity of Bezier nets and that for most triangulations,  C  1  continuous convex Bernstein-Bezier triangular surface with convex Bezier nets must be linear. In this paper, it is first shown that subdivision always preserves weak convexity of Bezier nets, that is, the weak convexity condition of Bezier nets defined on a base triangle  T  is preserved on any subtriangles inside  T . Then the invariance of weak convexity for elevation B-nets is proved. At last a necessary and sufficient condition characterized by the weak convexity of elevation B-net for the strict convexity of Bernstein-Bezier surface is given.	subdivision surface	Yu-Yu Feng;Falai Chen;Hong Ling Zhou	1994	Computer Aided Geometric Design	10.1016/0167-8396(94)90026-4	mathematical optimization;topology;invariant;computer aided design;subdivision;mathematics;geometry;computer graphics;mechanical engineering	EDA	68.20453170894558	-40.08197097435817	44599
c797b05c2687b7bd5470645ba5c2009e094bab6f	3d mesh fairing based on lighting and geometric conditions for interactive smooth rendering	rendu image;curved shape;representation graphique;ombre;realite virtuelle;illumination;realidad virtual;restitucion imagen;virtual reality;realite augmentee;realidad aumentada;sombra;shadow;forma curva;forme courbe;image rendering;grafo curva;augmented reality;interactive graphics;eclairement;graphics;alumbrado	In this paper, we propose a fairing method of 3D rough meshes based on illuminations and geometric conditions for smooth rendering. In applications of interactive graphics such as virtual reality or augmented reality, rough meshes are widely used for fast optical interactions owing to their simple representation. However, in vertex-based shading, rough meshes may produce non-smooth rendering results; Distinct normal vectors and comparatively longer distance between consecutive vertices increase the difference of radiances. In order to improve the smoothness of the rendering results, the difference of radiances among vertices should be minimized by considering lighting conditions as fairing parameters. We calculated illuminations using diffuse lighting models at each vertex. Then normalized illumination is linearly integrated with the curvedness to prevent the shape distortion. By adapting integrated values to Laplacian weight factors, the difference of radiances is minimized and rendering result is improved, while maintaining the important curved shapes of the rough meshes. The proposed method also improves the compactness of triangles. The comparative study of our method with other existing fairing schemes has been discussed. We also applied our method to arbitrarily simplified meshes for demonstration.		Seung Man Kim;Kwan-Heng Lee	2004		10.1007/978-3-540-30497-5_182	computer vision;augmented reality;shadow;rendering;computer science;graphics;mathematics;virtual reality;computer graphics (images)	Visualization	66.79889509379812	-46.149841894412695	44755
bc179c132da2b004c027978b7322716a390103a5	a virtual reality system for ptcd simulation using direct visuo-haptic rendering of partially segmented image data	image segmentation;needle insertion virtual reality visualization haptic rendering;needles haptic interfaces rendering computer graphics force image segmentation springs solid modeling;force;springs;solid modeling;virtual reality biomedical ultrasonics convergence data visualisation graphics processing units haptic interfaces image segmentation needles parallel architectures rendering computer graphics;volume deformation algorithm visuohaptic virtual reality training system visuohaptic virtual reality planning system percutaneous transhepatic cholangio drainage virtual patient models surface mesh model volume mesh model haptic interaction virtual palpation ultrasound probing needle insertion vr simulator image guided training gpu accelerated visualization techniques cuda multigrid approach deformation algorithms partially segmented patient data needle insertion procedures ptcd simulation partially segmented image data;haptic interfaces;rendering computer graphics;needles	This study presents a new visuo-haptic virtual reality (VR) training and planning system for percutaneous transhepatic cholangio-drainage (PTCD) based on partially segmented virtual patient models. We only use partially segmented image data instead of a full segmentation and circumvent the necessity of surface or volume mesh models. Haptic interaction with the virtual patient during virtual palpation, ultrasound probing and needle insertion is provided. Furthermore, the VR simulator includes X-ray and ultrasound simulation for image-guided training. The visualization techniques are GPU-accelerated by implementation in Cuda and include real-time volume deformations computed on the grid of the image data. Computation on the image grid enables straightforward integration of the deformed image data into the visualization components. To provide shorter rendering times, the performance of the volume deformation algorithm is improved by a multigrid approach. To evaluate the VR training system, a user evaluation has been performed and deformation algorithms are analyzed in terms of convergence speed with respect to a fully converged solution. The user evaluation shows positive results with increased user confidence after a training session. It is shown that using partially segmented patient data and direct volume rendering is suitable for the simulation of needle insertion procedures such as PTCD.	cuda;clinical act of insertion;computation;convergence (action);drainage, postural;graphics processing unit;haptic device component;haptic technology;imagery;insertion mutation;multigrid method;palpation;patients;real-time clock;simulation;vr - veterans rand health survey;virtual reality;volume mesh;volume rendering;x-ray (amazon kindle);algorithm;biologic segmentation	Dirk Fortmeier;André Mastmeyer;Julian I Schroeder;Heinz Handels	2016	IEEE Journal of Biomedical and Health Informatics	10.1109/JBHI.2014.2381772	computer vision;simulation;computer science;parallel rendering;image segmentation;solid modeling;force;quantum mechanics;computer graphics (images)	Visualization	70.78724236223725	-49.254595046109856	44766
58fe488603405b15343db7269760535d73bf135f	tutorial sessions	lyapunov methods;velocity control;motion control;discrete time systems;time varying systems;robust control;observers;asymptotic stability;finite state machines;ac motors;compensation;control system synthesis;control system analysis;collision avoidance;visual servoing;fork lift trucks;wheels	MATLAB Fundamentals provides a working introduction to the MATLAB technical computing environment and its applications. This course is intended for beginners and intermediate users. No prior knowledge of MATLAB is required. Themes of data analysis, visualization, modeling, and programming are explored throughout the course. Hands-on examples and exercises apply basic techniques to problems in a variety of application areas. Topics include: ✻ Working with the MATLAB user interface ✻ Working with MATLAB variables and expressions ✻ Plotting and visualization ✻ M-files ✻ Basic statistics and data analysis ✻ Data types ✻ M-file programming ✻ Troubleshooting M-files	hands-on computing;matlab;scientific visualization;user interface	José Miguel David Báez-López	2011	CONIELECOMP 2011, 21st International Conference on Electrical Communications and Computers	10.1109/CONIELECOMP.2011.5749315	control engineering;simulation;engineering;control theory	Visualization	70.30093432722823	-29.650136998541957	44781
b74498581b5f963135705100b84a091c81a18e96	modeling of cutting geometry and forces for 5-axis sculptured surface machining	forma libre;modelizacion;concepcion asistida;machining;computer aided design;modele geometrique;contact area;five axis machine;trajectoire optimale;machine outil;free form;force coupe;machine 5 axes;modelisation;herramienta corte;outil coupe;forme libre;usinage;optimal trajectory;trayectoria optima;conception assistee;maquina 5 ejes;maquina herramienta;geometric model;machine tool;fuerza corte;mechanistic model;mecanizado;cutting tool;5 axis force estimation;modeling;cutting force;5 axis machining simulation;geometrical model;sculptured surface machining;modelo geometrico	5-Axis sculptured surface machining is simulated using discrete geometric models of the tool and workpiece to determine the tool contact area, and a discrete mechanistic model to estimate the cutting forces. An extended Z-buffer model represents the workpiece, while a discrete axial slice model represents the cutting tool. Determination of the contact area for a given tool move requires a swept envelope (SWE) of the tool path. The SWE is used to find the intersections of the tool envelope with Z-buffer elements (ZDVs) representing the workpiece. A 3-axis approximation of the 5-axis tool movement is used to simplify the calculations while maintaining a desired level of accuracy. The intersection of the SWE with each ZDV yields segments which are used to find the contact area between the cutter and the workpiece for a given tool path. The contact area is subsequently used with the discrete force model to calculate the vector cutting force acting on the tool.		Barry K. Fussell;Robert B. Jerard;Jeffrey G. Hemmett	2003	Computer-Aided Design	10.1016/S0010-4485(02)00055-6	simulation;systems modeling;machining;engineering;contact area;geometric modeling;machine tool;computer aided design;engineering drawing;mechanical engineering	EDA	68.93284456830098	-37.51894424740121	44787
129cddda22b79ba0f983fcac87feeb8e63f4717c	laser scanning and data integration for three-dimensional digital recording of complex historical structures: the case of mevlana museum	cultural heritage;time of flight camera;three dimensional modeling;registration;point cloud;terrestrial laser scanner	Terrestrial laser scanning method is widely used in three-dimensional (3-D) modeling projects. Nevertheless it usually requires measurement data from other sources for full measurement of the shapes. In this study a 3-D model of the historical Mevlana Museum (Mevlana Mausoleum) in Konya, Turkey was created using state-of-the art measurement techniques. The building was measured by terrestrial laser scanner (TLS). In addition, some shapes of the indoor area were measured by a time-of-flight camera. Thus, a 3-D model of the building was created by combining datasets of all measurements. The point cloud model was created with 2.3 cm and 2.4 cm accuracy for outdoor and indoor measurements, and then it was registered to a georeferenced system. In addition a 3-D virtual model was created by mapping the texture on a mesh derived from the point cloud.	3d computer graphics;3d modeling;cpu cache;central processing unit;control point (mathematics);digital image;digital recording;list of intel core i5 microprocessors;point cloud;random-access memory;sampling (signal processing);self-information;sensor;six days in fallujah;terrestrial television;texture mapping;time-of-flight camera;usability	Cihan Altuntas;Ferruh Yildiz;Marco Scaioni	2016	ISPRS Int. J. Geo-Information	10.3390/ijgi5020018	computer vision;geography;remote sensing;computer graphics (images)	Graphics	56.35073443932917	-46.75470210642971	44813
818205fe5bb0a6f16090c571ecd18b3db43f041c	analysis of inverse snyder optimizations		Modern area preserving projections employed by cartographers and geographers have closed forms when transitioning between the sphere and the plane. Inversions from the planar map to the spherical approximation of the Earth are slower, requiring iterative root finding approaches or entirely undetermined. Recent optimizations of the common Inverse Snyder Equal Area Polyhedral projection have been fairly successful, however the work herein improves it further by adjusting the approximating polynomial. An evaluation against the original and improved optimizations is provided, along with a previously unexplored real-time analysis.	approximation algorithm;cartography;computer graphics;cubic function;distortion;gene expression programming;imperative programming;inversion (discrete mathematics);iteration;iterative method;nonlinear system;planar graph;polyhedral;polynomial;real-time clock;real-time computing;real-time locating system;real-time transcription;real-time web;regular icosahedron;root-finding algorithm	Erika Harrison;Ali Mahdavi-Amiri;Faramarz F. Samavati	2012	Trans. Computational Science	10.1007/978-3-642-32663-9_8		Graphics	70.97992341077885	-40.884151746999095	44840
a42304a1f507a00c2ff632ad6388bb5fe4d7dee0	real-time spherical harmonics based subsurface scattering	subjective metrics;computer graphics;subsurface scattering;3d models	In this paper we present an algorithm for a subsurface scattering simulation (SHSS) based on spherical harmonics. The approach has a physical basis. As we focus on specifying an algorithm suitable for commercial games, it contains simplifications designed for real-time calculations. Spherical harmonics (SH) functions were used to encode the thickness of an object in every possible direction for each vertex of a graphical model. The information about the thickness of an object is the basis for a simulation of light absorption. The starting point of our approach was the Green method [3], where the thickness is calculated by a shadow casting algorithm. In our technique the model volume is encoded by spherical harmonics similarly to the Precomputed Radiance Transfer where the SH are used to encode the values of a transfer function. The quality of our approach is presented in comparison with the other algorithms.	real-time transcription;subsurface scattering	Anna Lewandowska;Krzysztof Stefanowski	2012		10.1007/978-3-642-31295-3_47	mathematical optimization;subsurface scattering;computer science;mathematics;computer graphics;spherical harmonic lighting	Vision	63.96022201685053	-49.349548306349675	44859
5fe13636877d1203362f4270793d851883869cd8	virtual design of bike based on solidworks	cad;virtual manufacturing assembling bicycles cad;parameterized modeling bike solidworks virtual design;assembling;bicycles;solid modeling stress software analytical models strain materials shape;virtual assembling process virtual design bike solidworks;virtual manufacturing	Taking a new bike as an example, the parameterized modeling process is discussed under SolidWorks 2009. Meanwhile, it can be seen that the whole virtual assembling process of the bike accord with the actual assembly process completely.	solidworks	Lifang Zhao;Shuguo Zhao	2011	Proceedings of 2011 International Conference on Electronic & Mechanical Engineering and Information Technology	10.1109/EMEIT.2011.6022879	simulation;engineering;automotive engineering;cad;engineering drawing	Robotics	69.51093100857669	-33.29611010812819	44961
d45b7715d849d1e643afc4c761dff400412c7100	initialization-free monocular visual-inertial state estimation with application to autonomous mavs		The quest to build smaller, more agile micro aerial vehicles has led the research community to address cameras and Inertial Measurement Units (IMUs) as the primary sensors for state estimation and autonomy. In this paper we present a monocular visual-inertial system (VINS) for an autonomous quadrotor which relies only on an inexpensive off-the-shelf camera and IMU, and describe a robust state estimator which allows the robot to execute trajectories at 2 m/s with roll and pitch angles of 20 degrees, with accelerations over 4 m/(text {s}^2). The main innovations in the paper are an approach to estimate the vehicle motion without initialization and a method to determine scale and metric state information without encountering any degeneracy in real time.		Shaojie Shen;Yash Mulgaonkar;Nathan Michael;Vijay Kumar	2014		10.1007/978-3-319-23778-7_15	computer vision;units of measurement;estimator;monocular;inertial frame of reference;initialization;inertial measurement unit;artificial intelligence;degeneracy (mathematics);computer science	Robotics	55.1151043669243	-37.886391413211726	45036
f4ced10e44dcae64a7f4c75774660a17de8c82fd	a real-time gesture-based unmanned aerial vehicle control system	control system;gesture-based;realsense;uav	Unmanned aerial vehicles (UAVs) are playing important roles in many fields for their stability and flexibility. However, controlling a UAV by its remote-controller is very difficult especially for the beginners. In this paper, we propose a real-time UAV control system that only exploits shape and movements of the user’s hands. A set of gestures that map the hand actions to all motions of the UAV is designed based on subjective experience assessment. 94.898% of motion accuracy can be achieved with only 0.19 s of latency on average. Compared with other systems, our system reduces 40.625% and 36.667% in the latency. To the best of our knowledge, our control system is the first one to realize all motions of the UAV in the actual experiments by only utilizing hand motions. © Springer International Publishing AG 2016.	aerial photography;control system;real-time transcription;unmanned aerial vehicle	Leye Wei;Xin Jin;Zhiyong Wu	2016		10.1007/978-3-319-48890-5_52	artificial intelligence;latency (engineering);computer vision;computer science;gesture;exploit;control system	Robotics	61.435673768366414	-29.579580755303425	45110
b77bfeb4237761ec1d4d066ac2424ca3df697d77	data reduction by generating 3d image	large scale visualization data reduction image based rendering;large scale visualization;three dimensional displays solid modeling data models rendering computer graphics cameras buffer storage computers;data reduction;data visualization data reduction 3d image generation image based rendering;image based rendering;solid modelling data reduction data visualisation image processing rendering computer graphics	Increasing computer power, the size of 3D model is larger and larger. On the other hand, wearable devices become popular. Due to the restriction of the physical size, such devices can not have the same computer resources as personal computers. Therefore, the data reduction is required when 3D models are transferred from PC to wearable devices. So I have developed a data reduction technique for applying to 3D model. Considering the view point area at observing, any data can be reduced to a specified size that does not depend on the complexity of the original data. The reduced data is expressed as a 3D image. As the result of some tests, the size is reduced to the expected volume and the significant noise and error could not be detected at the reduced data in visual confirmation.	3d modeling;captcha;personal computer;power supply unit (computer);wearable technology	Hideo Miyachi	2015	2015 18th International Conference on Network-Based Information Systems	10.1109/NBiS.2015.79	computer vision;tiled rendering;data reduction;image-based modeling and rendering;3d rendering;rendering;computer science;theoretical computer science;parallel rendering;real-time rendering;alternate frame rendering;software rendering;computer graphics (images)	Visualization	69.3976207421129	-51.60549195001433	45135
771b2e9c729fa695608830434fa59684b26d70e6	semi-physical simulation research of the antenna acquiring and tracking system without turn tables	computers;digital signal processing;tdrs simulator;semi phsical simulation;tracking system;satellite antennas mathematical model control system synthesis computer languages antenna measurements artificial satellites attitude control actuators communication system control logic;real time simulation;control system cad;tdrs simulator turn table antenna semi phsical simulation matlab simulink xpc;control system;computational modeling;turn table;mixed model;satellites;antennas;sensors and actuators;functional model;matlab simulink xpc;antenna;satellite antennas;attitude movement semiphysical simulation antenna acquiring system antenna tracking system control systems design satellite attitude dynamics antenna control logics;tracking control system cad satellite antennas;tracking;physical simulation	Simulation is an important step during the design of control systems. Based on the series tools of MATLAB\Simulink\xPC, the real-time simulation environment is constructed. By adopting the mixed modeling measures that comprise Simulink, Stateflow and S-function, models for satellite attitude dynamics, all sensors and actuators, control logics of the antenna and etc are all built successfully, then the modes selecting, scheduling and interfaces communication are realized effectively. The tracking and data relay satellite (TDRS) simulator is designed. It simplifies the experiment system. The turn table is eliminated and the experiment system can also reflect the effect of the attitude movement acting on the antenna pointing by using the TDRS simulator. The experiment results indicate that the experiment system can verify the antenna acquiring and tracking processes and is beneficial to the design of the user satellite’s antenna pointing control system for engineers.	as-interface;communications satellite;control system;dynamical simulation;real-time clock;relay;scheduling (computing);self-protecting digital content;semiconductor industry;simulink;stateflow;tracking system	Zhai Kun;Baoyin Hexi;Qu Xi	2009	2009 International Conference on Computer Modeling and Simulation	10.1109/ICCMS.2009.48	control engineering;electronic engineering;simulation;engineering;control system;antenna;control theory	Robotics	64.91094943008648	-29.622705050804754	45191
1265bc425fd7082324ad45d3bccd8c86e3c15e65	towards co-operative autonomous 1cm/sup 3/ robots for micro and nanomanipulation applications: micron	mobile robot;mobile robots;microactuators cooperative autonomous 1cm sup 3 robots micron micromanipulation nanomanipulation microrobots mobile robots mixed analog digital integrated circuits analog systems;microactuators;cooperative systems mobile robots microactuators micromanipulators;cooperative systems;micromanipulators;robots atomic force microscopy needles communication system control cells biology instruments silicon carbide robotics and automation mixed analog digital integrated circuits microactuators;microactuators mobile robots mixed analog digital integrated circuits analog systems;mixed analog digital integrated circuits	The micro and nanomanipulation is one of the main challenges in our days. One approach is based on the use of a limited cluster of microrobots working in a cooperative way. For the development of the activity each robot of the cluster has assigned a different task. This implies that each robot has a different specialization. Our objective is to present in this paper the design of the electronics developed for these robots, taking into account the important challenges regarding the available area, and that the robot should possess enough autonomy. The most versatile solution is pursued because a particular electronics is not to be developed for each specialized robot. In function of the robot's specialty it will receive the necessary orders, being permeable the electronics to any case. In this paper is presented in a general way these different specializations.	autonomous robot;autonomy;full custom;microbotics;partial template specialization;performance;switzerland;xfig	Raimon Casanova;A. Saiz;Junajo Lacort;Jordi Brufau-Penella;Anna Arbat;Ángel Diéguez;Pedro Lluís Miribel-Català;Manel Puig-Vidal;Josep Samitier	2005	2005 IEEE/RSJ International Conference on Intelligent Robots and Systems	10.1109/IROS.2005.1545072	control engineering;mobile robot;electronic engineering;simulation;computer science;engineering;artificial intelligence	Robotics	76.93955061862253	-24.929693121759755	45275
9f19f07cf6dfe7403a9cb92370aa313e3926f21c	hierarchical model predictive control of uavs performing multitarget-multisensor tracking	trajectory control adaptive control aerospace components aircraft control autonomous aerial vehicles multi robot systems predictive control sensor fusion stability target tracking;system stability multitarget multisensor tracking enemy emitter tracking enemy emitter detection radar carrying platforms adaptive trajectory control autonomous unmanned aerial vehicle team autonomous uav team emitter localization error minimization no fly zone avoidance computational complexity long term goals physically implementable method suboptimal solution short term goals hierarchical model predictive control algorithm hierarchical mpc algorithm myopic control approach fixed wing aircraft model;sensors trajectory radar tracking optimization aerospace electronics dynamic programming	Detection and tracking of enemy emitters such as radar-carrying platforms is a task of considerable military significance. In the work presented here, the problem of adaptively controlling the trajectories of an autonomous team of unmanned aerial vehicles (UAVs) performing this task, in order to minimize emitter localization error, while simultaneously avoiding no-fly zones, is considered and a solution developed. Because of the computational complexity of the problem when long-term goals are considered, an optimal solution cannot be found in practice by any physically implementable method. Hence, in this paper an approach is developed that enables implementation of a computationally feasible, suboptimal solution that takes into account both short-term and long-term goals. To this end, the problem is addressed by developing a new hierarchical model predictive control (MPC) algorithm. To evaluate the effectiveness of the approach, first a controller is developed using an idealized UAV model and simulations are performed. Its performance is compared with a commonly used “myopic” control approach and found to give important improvements. Subsequently an improved planner is incorporated and tested, and then a version of the controller using a fixed-wing aircraft model for the UAVs is implemented. This version is also tested by simulation and found to perform successfully. Finally, a brief discussion on system stability is provided as part of the evaluation.	aerial photography;algorithm;approximation;autonomous robot;computation;computational complexity theory;computer simulation;control system;disk controller;dynamic programming;extensibility;fits;heuristic;hierarchical database model;lambert's cosine law;mathematical optimization;motion planning;offset binary;real-time clock;real-time computing;requirement;robotics;scalability;scientific literature;simulation;stationary process;unmanned aerial vehicle;usability	Peter Sarunic;Robin J. Evans	2014	IEEE Transactions on Aerospace and Electronic Systems	10.1109/TAES.2014.120780	control engineering;simulation;tracking system;engineering;control theory	Robotics	55.648675812025914	-26.83657539021076	45326
d535ef058543f801f36280cb6f6567dbce36186f	time synchronization and data fusion for rgb-depth cameras and inertial sensors in aal applications	sensors;light emitting diodes;signalbehandling;timed up and go depth camera inertial sensor data fusion synchronization;joints;acceleration;media engineering;synchronization;signal processing;sensors synchronization light emitting diodes cameras acceleration joints;telemedicine assisted living biomedical optical imaging body sensor networks cameras sensor fusion;cameras;wearable inertial sensors data fusion rgb depth cameras aal applications ambient assisted living applications;mediateknik	Ambient Assisted Living applications often need to integrate data from multiple sensors, to provide consistent information on the observed phenomena. Data fusion based on samples from several sensors requires accurate time synchronization with sufficient resolution, depending on the sensor sampling frequency. This work presents a technical platform for the efficient and accurate synchronization of the data captured from RGB-Depth cameras and wearable inertial sensors, that can be integrated in AAL solutions. A case study of sensor data fusion for Timed Up and Go test is also presented and discussed.	atm adaptation layer;algorithm;error analysis (mathematics);performance;sampling (signal processing);sensor;the quality of life;wearable computer	Enea Cippitelli;Samuele Gasparrini;Ennio Gambi;Susanna Spinsante;Jonas Wåhslén;Ibrahim Orhan;Thomas Lindh	2015	2015 IEEE International Conference on Communication Workshop (ICCW)	10.1109/ICCW.2015.7247189	acceleration;embedded system;synchronization;computer vision;telecommunications;computer science;sensor;signal processing;light-emitting diode	Robotics	57.2580360329676	-37.57872448613217	45460
5fee0c715a4441c509ef340323027f7d8e2c0b11	bio-inspired rough terrain contact patch perception	human subject traversing rocky trail analysis bio inspired rough terrain contact patch perception foot scale curved surface patches rough rocky terrain higher level footfall selection algorithms depth camera 9 dof inertial measurement unit quality patches target patch properties single foothold selection;cameras foot three dimensional displays gravity robot vision systems;rough surfaces humanoid robots legged locomotion	We present a new bio-inspired system for automatically finding foot-scale curved surface patches in rough rocky terrain. These patches are intended to provide a reasonable set of choices for higher-level footfall selection algorithms, and are pre-filtered for several attributes - including location, curvature, and normal - that we observed humans to prefer. Input is from a 640 × 480 depth camera augmented with a 9-DoF inertial measurement unit to sense the direction of gravity. The system is capable of finding approximately 700 patches/second on commodity hardware, though the intention is not to find as many patches as possible but to reasonably sample upcoming terrain with quality patches. Sixty recordings of human subjects traversing rocky trails were analyzed to give a baseline for target patch properties. While the presented system is not designed to select a single foothold, it does find a set of patches for possible footholds which are statistically similar to the patches humans select.	algorithm;baseline (configuration management);british informatics olympiad;coherence (physics);commodity computing;patch (computing);point cloud;real-time computing;real-time locating system;rough set;selection algorithm;sparse matrix	Dimitrios Kanoulas;Marsette Vona	2014	2014 IEEE International Conference on Robotics and Automation (ICRA)	10.1109/ICRA.2014.6907083	computer vision;simulation;remote sensing	Robotics	58.626599266067146	-34.66194672628353	45490
27edcc81c57ccad1838c7afba4413a002492f757	simple and efficient 2d and 3d span clipping algorithms	software;vision ordenador;algorithm analysis;logiciel;computer graphics;estudio comparativo;computer vision;etude comparative;descrestacion;comparative study;clipping;logicial;vision ordinateur;analyse algorithme;ecretage;grafico computadora;infographie;analisis algoritmo	-A machine-independent comparison of several 2D and 3D line segment clipping algorithms is presented. The Nicholl-Lee-Nicholl (NLN), Liang-Barsky (LB), an improved implementation of the CohenSutherland (CS), and Sutherland-Hodgman (SH) algorithms are compared for 2D. The LB, CS and SH algorithms are compared for 3D. The trivial acceptance of the NicholI-Lee-Nicholl (NLN) algorithm and the Newman-Sproull (NS) implementation of the CS algorithm is proved to be nonoptimal. A new optimal trivial acceptance algorithm is presented, which is similar to the MIN/MAX algorithm. The NLN trivial rejection method is proved to be optimal in the worst case, but is shown to be nonoptimal in the average case. The NS implementation of the CS algorithm is improved by incorporating this optimal trivial rejection method. An alternate implementation of the CS algorithm is presented by incorporating the optimal trivial acceptance method. This method is shown to be more efficient than the implementation that incorporates the optimal trivial rejection method if more than 60% of the line segments are completely inside the clipping window for 2D, and more than 62.5% for 3D. The CS implementation is further improved by reducing the number of redundant comparisons, and the amount of floating-point computation per intersection point. The modifications are performed so as to allow easy extension of the 2D algorithm to 3D. Finally, the SH polygon clipping algorithm is reduced to line segment clipping. It is shown to be conceptually simple, compact, efficient, extendible to polygonal convex window shapes, and applicable to pipeline and systolic architectures.	3d computer graphics;best, worst and average case;cs games;clipping (computer graphics);computation;extensibility;glossary of computer graphics;lattice boltzmann methods;liang-jie zhang;max;newman's lemma;rejection sampling;sutherland–hodgman algorithm	Victor J. Duvanenko;Ronald S. Gyurcsik;Woodrow E. Robbins	1993	Computers & Graphics	10.1016/0097-8493(93)90050-J	computer vision;computer science;clipping;comparative research;computer graphics;algorithm	Graphics	66.92028473693087	-48.85300761829127	45503
85c3d7c39242629d5a20d9508d37c32f77b97a38	bi-level programming based real-time path planning for unmanned aerial vehicles	bi level programming blp;unmanned aerial vehicles uavs;real time path planning;heuristic algorithms;leader follower decision making	This paper presents a novel real-time path planning approach for unmanned aerial vehicles (UAVs) based on bi-level programming (BLP), in which the planning problem is described as a leader–follower decision making model. The proposed approach can fulfill an integrated path planning requirement, including several realistic abilities of convergence to target, obstacle avoidance, path length optimization, flight path smoothing and adaptability to the changes of the UAV’s kinematic and sensory properties. In the BLP model, opposition obstacles and UAV’s interrelated performances are described to construct path searching constraints, and variable planning time intervals are introduced to generate navigable flight paths only when necessary. A discretization solution algorithm embedded with five heuristic optimization strategies is particularly designed to speed up the planning. Moreover, convergence and computational cost, as well as potential extensions, are discussed to expose the efficiency and applicability of the approach. Numerous simulations in stochastic and representative scenarios demonstrate not only the effectiveness of the approach in generating optimized flight paths for UAVs, but also its clear advantages through comparisons with four typical methods, while synthetically considering the crucial abilities. 2013 Elsevier B.V. All rights reserved.	aerial photography;algorithm;algorithmic efficiency;black and burst;discretization;embedded system;heuristic;mathematical optimization;motion planning;obstacle avoidance;performance;real-time clock;real-time path planning;simulation;smoothing;unmanned aerial vehicle	Wei Liu;Zheng Zheng;Kai-Yuan Cai	2013	Knowl.-Based Syst.	10.1016/j.knosys.2013.01.011	mathematical optimization;simulation;any-angle path planning;obstacle avoidance	AI	54.03406796524901	-24.350340906048377	45515
429ca8046e8e03baea4a89dd771713c069cfbbbf	locomoting robots composed of immobile robots		"""Robotic materials are multi-robot systems formulated to leverage the low-order computation and actuation of the constituents to manipulate the high-order behavior of the entire material. We study the behaviors of ensembles composed of smart active particles, smarticles. Smarticles are small, low cost robots equipped with basic actuation and sensing abilities that are individually incapable of rotating or displacing. We demonstrate that a """"supersmarticle"""", composed of many smarticles constrained within a bounding membrane, can harness the internal collisions of the robotic material among the constituents and the membrane to achieve diffusive locomotion. The emergent diffusion can be directed by modulating the robotic material properties in response to a light source, analogous to biological phototaxis. The light source introduces asymmetries within the robotic material, resulting in modified populations of interaction modes and dynamics which ultimately result in supersmarticle biased locomotion. We present experimental methods and results for the robotic material which moves with a directed displacement in response to a light source."""	chris sawyer's locomotion;computation;displacement mapping;emergence;population;robot;robotic materials	Ross Warkentin;William Savoie;Daniel I. Goldman	2018	2018 Second IEEE International Conference on Robotic Computing (IRC)	10.1109/IRC.2018.00047	control engineering;robot;engineering;phototaxis;computation;robot kinematics;material properties	Robotics	64.87246422273007	-26.30611041923231	45543
540459a8e298e7c4ca4fc9ad283394c2ce1696ab	a modular scalable approach to occlusion-robust low-latency optical tracking	image processing;004 informatik;robot manipulator;low latency;robot control;optical tracking;system architecture;computer assisted surgery	  An advanced optical tracking system for computer assisted surgery (CAS) is presented. The system supports an arbitrary number  of cameras that may be placed at suitable positions e.g. fixed cameras at the ceiling of the operating theater or movable  cameras on the operating lamps. The modular scalable system architecture reduces occlusion problems and allows adaptation  to tracking scenarios of different complexity. The camera modules each integrate hardware-based image processing to allow  for low latency of 10ms required in demanding applications like robot control. As a first application tracking of a handheld  robotic manipulator has been implemented.    		Andreas Köpfle;Markus A. Schill;Markus Ludwig Rupert Schwarz;Peter Pott;Achim Wagner;Reinhard Männer;Essameddin Badreddin;Hans-Peter Weiser;Hanns-Peter Scharf	2004		10.1007/978-3-540-30136-3_148	computer vision;simulation;tracking system;image processing;computer science;artificial intelligence;robot control;low latency	Vision	58.9464379591339	-32.393450676112046	45593
d653239e106c31895d4fe98cfe87b954dbafded6	genetic programming applied to biped locomotion control with sensory information	cpg central pattern generator;biped locomotion;sensory information	Generating biped locomotion in robotic platforms is hard. It has to deal with the complexity of the tasks which requires the synchronization of several joints, while monitoring stability. Further, it is also expected to deal with the great heterogeneity of existing platforms. The generation of adaptable locomotion further increases the complexity of the task.	central pattern generator;chris sawyer's locomotion;displacement mapping;experiment;feedback;gait analysis;genetic programming;humanoid robot;international symposium on fundamentals of computation theory;mathematical optimization	César Ferreira;Pedro Silva;João André;Cristina P. Santos;Lino A. Costa	2014	2014 11th International Conference on Informatics in Control, Automation and Robotics (ICINCO)	10.5220/0005062700530062	control engineering;sensory system;simulation;computer science;artificial intelligence	Robotics	66.49837517326111	-25.70549584046517	45633
b692edd4024a4fa1a81198d17b5004ddd278c7bc	robot self-protection by virtual actuator fatigue: application to tendon-driven dexterous hands during grasping		We present a novel force-limitation algorithm to protect fragile robot actuation and transmission systems (like tendon-driven systems) from early wear-out. Inspired by human muscle fatigue, we model artificial actuator fatigue by integrating applied forces over time, gradually limiting applicable forces when fatigue increases. The algorithm is applied to protect from long-term tendon wear-out on our Shadow Dexterous Hands as well as to restrict grasping forces for compliant grasping in unknown environments. In grasping experiments the efficiency of various grasp-force limitation approaches are compared to each other, including one exploiting tactile-based slip detection.	algorithm;artificial neural network;control flow;experiment;robot;smoothing;tactile imaging;tactile sensor;time complexity	Guillaume Walck;Robert Haschke;Martin Meier;Helge J. Ritter	2017	2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)	10.1109/IROS.2017.8206039	actuator;computer science;control engineering;tendon;robot;slip (materials science);limiting;shadow	Robotics	70.89522084570483	-24.586789588508676	45930
198f4199520ec0bd62183298284ad50d8ca7eedc	enhanced anomaly detection in wire ropes by combining structure and appearance	image based analysis;surface inspection;anomaly detection	Automatic visual surface inspection is a challenging task, which has become important for quality assurance in the last years. Wire rope inspection is a special problem within this field. Usually, the huge and heavy ropes cannot be detached. Thus, an inspection of the ropes must be conducted, while the ropes are in use. The rope surface exhibits various appearance characteristics so that the existing, purely appearance-based approaches tend to fail. We explicitly integrate information about the object geometry, which we obtain by aligning a sequence of 2d rope images with a perfectly regular 3d model of the rope. The rendering equation is used to link object geometry to the observed rope appearance. Based on the connection between geometry and surface appearance we build a probabilistic appearance model which serves as representation for normal surface variations. A robust localization of rope surface defects is achieved by means of anomaly detection. The presented approach has no need for knowledge about the illumination setting or the reflectance properties of the material. An evaluation on real-world data from ropeways leads to an accuracy comparable to that of a human expert. With an accuracy of 95% and a false-alarm-rate of 1.5% the approach outperforms all other existing approaches.	3d modeling;anomaly detection;rendering equation	Esther-Sabrina Wacker;Joachim Denzler	2013	Pattern Recognition Letters	10.1016/j.patrec.2013.01.025	computer vision;anomaly detection;simulation;computer science;machine learning	Vision	58.797966471304356	-51.58106468812207	45986
2ace307ff8e6f5ec4628e5e088cb40628109c5d5	surface-based deformation for disconnected mesh models	partial differential equation	Surface-based deformation [Sorkine 2005] plays an important role to reuse existing mesh models. This technique encodes geometric shapes using linear partial differential equations and deforms mesh models in an interactive manner. However, surface-based deformation cannot consistently deform mesh models that include (1) Multiple disconnected components, (2) T-vertices, and (3) Non-manifold edges. These conditions commonly appear in mesh models. This paper shows how to deform such models consistently.	t-vertices	Kenta Ogawa;Hiroshi Masuda	2007		10.1145/1280720.1280741	topology;computer science;mathematics;geometry;partial differential equation	Visualization	68.68419815559143	-45.09770492377962	46018
3b2850c4464610d9428a06b71278e12ca41da702	a survey of research on control of teams of small robots in military operations		While a number of excellent review articles on military robots have appeared in existing literature, this paper focuses on a distinct sub-space of related problems: small military robots organized into moderately sized squads, operating in a ground combat environment. Specifically, we consider the following: • Command of practical small robots, comparable to current generation, small unmanned ground vehicles (e.g., PackBots) with limited computing and sensor payload, as opposed to larger vehicle-sized robots or micro-scale robots; • Utilization of moderately sized practical forces of 3–10 robots applicable to currently envisioned military ground operations; • Complex three-dimensional physical environments, such as urban areas or mountainous terrains and the inherent difficulties they impose, including limited and variable fields of observation, difficult navigation, and intermittent communication; • Adversarial environments where the active, intelligent enemy is the key consideration in determining the behavior of the robotic force; and • Purposeful, partly autonomous, coordinated behaviors that are necessary for such a robotic force to survive and complete missions; these are far more complex than, for example, formation control or field coverage behavior.	autonomous robot;consensus dynamics;military robot;unmanned aerial vehicle	Stuart Young;Alexander Kott	2016	CoRR		simulation;engineering;operations research	Robotics	54.89648293975295	-28.034903975484934	46044
ec5f401063067cc098dfa235df214d515eddab46	generalized b-spline camera model		Previously proposed camera calibration methods either use a local camera model in a complex, cumbersome, time consuming and often manual calibration process or a lens specific global camera model, which can be automatically calibrated by simply recording images of chessboards. The drawback of using a global hand crafted camera model is its limited capability of modeling distortions caused by the mounted lens or optical devices in front of the lens like windshields. Therefore, we propose a local camera model based on B-splines which can handle various distortions. Moreover, it will be shown how such a model can be calibrated in an easy-to-use calibration process which were up to now only applicable to global camera models. We demonstrate the benefit of using the proposed local camera model by an extensive evaluation using single and multi-camera setups with different types of lenses, some mounted behind a windshield.	b-spline;camera resectioning;distortion;reprojection error;virtual reality headset	Johannes Beck;Christoph Stiller	2018	2018 IEEE Intelligent Vehicles Symposium (IV)	10.1109/IVS.2018.8500466	calibration;computer vision;b-spline;camera resectioning;windshield;distortion;computer science;lens (optics);artificial intelligence	Vision	56.10717047943286	-49.62020162366658	46053
e44173d1d4050b624a552f164e865ce02a0d7d7b	a flexible inspection system for gauging precision industrial parts	contraste;avionics;vision ordenador;tubo onda progresiva;travelling wave tube;concepcion sistema;flexibilidad;automatisation;application case;robotics;automatizacion;robot industriel;computer vision;cas application;system design;tube onde progressive;robot industrial;avionica;visual control;robotica;controle visuel;flexibilite;vision ordinateur;etalonnage;robotique;materiel informatique;calibration;material informatica;conception systeme;control visual;flexibility;radar;industrial robot;hardware;avionique;automation	This paper presents an overview of an inspection system called Automated Robotic Visual Inspection System (ARVIS). The ARVIS system concept, hardware components, work-cell, and calibration and inspection procedures are described. Application of ARVIS is currently focused on inspecting precision industrial parts, specifically, traveling wave tube (TWT) components for avionic radar systems. The variability of parts which comprise a TWT requires a general purpose flexible inspection system that is both adaptable and programmable. ARVIS integrates robotics and computer technology together with vision processing software to achieve a flexible system.		D. R. Sollberger;Marcus Thint;Paul P. Wang	1989	Robotics and Autonomous Systems	10.1016/0921-8890(89)90008-0	avionics;embedded system;computer vision;calibration;simulation;traveling-wave tube;computer science;automation;robotics;radar;automated optical inspection;systems design	Robotics	63.00646035367748	-32.72346279674956	46066
1fbbf6fbd21a94ca594fe18b43dad3c101078b93	synergic comanipulation despite underactuated robot	institutional repositories;human robot interaction actuators;fedora;robots probes force surgery breast lesions;actuators;human robot interaction;breast;force;probes;vital;lesions;us breast examinations synergic comanipulation underactuated robot human robot tool comanipulation robot user synergy;robots;surgery;vtls;ils	The possibility to provide an adequate task assistance using underactuated robots for human-robot tool comanipulation is investigated. This novel approach does not take into account any a priori knowledge about user depending parameters however optimizes the robot-user synergy, for instance during US breast examinations. Results show that the examination time can be reduced and a tendency for increasing scanning accuracy using underactuated robots.	attachments;ct scan;feedback;haptic technology;maximal set;mobile device;performance;region of interest;requirement;robot;robot end effector;synergy;underactuation;workspace	Anja Marx;Marie-Aude Vitrani;Benoit Herman;Razvan Iordache;Serge Muller;Guillaume Morel	2011	2011 IEEE International Conference on Robotics and Automation	10.1109/ICRA.2011.5979938	human–robot interaction;robot;control engineering;simulation;computer science;engineering;artificial intelligence;force;actuator	Robotics	72.58578575155416	-28.312027325220313	46076
86c1ff80198fdeee0fe1feb5bfc3991c6ea22ee5	watermarking of 3d-polygon-based models with robustness against mesh simplification	digital watermarking;simplification;formation image tridimensionnelle;mesh simplification;3d imaging;normal distribution;three dimensional shape;polygone;filigrane;curva gauss;three dimensional;forma tridimensional;polygon;forme tridimensionnelle;robustesse;methode maille;mesh method;simplificacion;watermark;loi normale;poligono;robustness;metodo malla;private watermark;formacion imagen tridimensional;gaussian distribution;robustez	This paper presents a watermarking algorithm suitable for embedding private watermarks into three dimensional polygon based models. The algorithm modifies the models normal distribution to store information solely in the geometry of the model. The watermarks show significant robustness against mesh simplifying methods.	algorithm;digital watermarking;iteration;level of detail;mesh networking;outline of object recognition;subgraph isomorphism problem	Oliver Benedens	1999		10.1117/12.344683	mathematics;geometry;engineering drawing;algorithm	Vision	66.1650010733706	-41.17465368701755	46123
230339ac00c912eb1a85a632b4212bbc1246c294	variable-precision rendering	levels of detail;variable precision rendering;level of detail;laser scanning;temporal coherence;hierarchical rendering;3d graphics;view dependent rendering	We propose the idea of using variable-precision geometry transformations and lighting to accelerate 3D graphics rendering. Multiresolution approaches reduce the numberof primitives to be rendered; our approach complements the multiresolution techniques as it reduces theprecisionof each graphics primitive. Our method relates the minimum number of bits of accuracy required in the input data to achieve a desired accuracy in the display output. We achieve speedup by taking advantage of (a) SIMD parallelism for arithmetic operations, now increasingly common on modern processors, and (b) spatial-temporal coherence in frame-to-frame transformations and lighting. We show the results of our method on datasets from several application domains including laser-scanned, procedural, and mechanical CAD datasets. CR Categories: I.3.3 [Computer Graphics]: Picture/Image Generation—Viewing algorithms; I.3.5 [Computer Graphics]: Computational Geometry and Object Modeling—Hierarchy and geometric transformations; I.3.6 [Computer Graphics]: Methodology and Techniques—Graphics data structures and data types. Additional	3d computer graphics;algorithm;central processing unit;coherence (physics);computation;computational geometry;computer-aided design;data structure;emoticon;geometric primitive;multiresolution analysis;parallel computing;procedural programming;rendering (computer graphics);simd;speedup	Xuejun Hao;Amitabh Varshney	2001		10.1145/364338.364384	laser scanning;computer vision;tiled rendering;image-based modeling and rendering;3d rendering;rendering;computer science;level of detail;multimedia;optics;real-time rendering;volume rendering;3d computer graphics;computer graphics (images)	Graphics	67.61849877844743	-50.92120161434712	46127
ab2b60dbb68658987972ffee95d6812a83101942	range image segmentation combining edge-detection and region-growing techniques with applications sto robot bin-picking using vacuum gripper	edge detection;prensor robot;materials handling computer vision industrial robots;image;robotics;segmentation;experimental result;computer vision;prehenseur;deteccion contorno;image segmentation image edge detection robot sensing systems image sensors robot vision systems robotics and automation sensor systems application software vacuum technology grippers;detection contour;holdsite determination range image segmentation edge detection region growing techniques robot bin picking vacuum gripper industrial parts residual analysis;imagen;materials handling;industrial robots;resultado experimental;robotica;robotique;gripper;resultat experimental;segmentacion	A new segmentation algorithm that can be used for robot applications is presented. The input images are dense range data of industrial parts. The image is segmented into a number of surfaces. The segmentation algorithm uses residual analysis to detect edges, then a region-growing technique is used to obtain the final segmented image. The use of the segmentation output for determining the best holdsite position and orientation of objects is studied. As compared to techniques based on intensity images, the use of range images simplifies the holdsite determination. This information can then be used to instruct the robot to grip the object and move it to the required position. The performance of the algorithm on a number of range images is presented. >	edge detection;image segmentation;range imaging;range segmentation;region growing;robot end effector	Ezzet Al-Hujazi;Arun K. Sood	1990	IEEE Trans. Systems, Man, and Cybernetics	10.1109/21.61203	computer vision;range segmentation;simulation;edge detection;computer science;image;segmentation-based object categorization;image segmentation;robotics;scale-space segmentation;segmentation	Robotics	60.0902475532974	-39.98881301675371	46177
24e65751eb67cc5badfe5586d8671bbe3d8efa02	low cost 3d shape acquisition system using strip shifting pattern	digital camera;shape recovery;surface reconstruction;image sequence;3d scanner;high light	We present a simple and low cost 3D shape acquisition method that can measure the objects with interreflection and high light. The capture system employs a projector to project line shifting shadow on the object, and a digital camera to record videos (image sequence) of the object and the distorted shadow. A novel spacetime edge finding method is introduced to get the shadow edge accurately and overcome the interreflection and high light. The 3D data of the object are got by using the spacetime information. A postprocessing 3D filter is proposed to filter the bad data. The 3D filter makes full use of the neighborhoods' geometric constrains and the view point constrain.		Li Yao;Lizhuang Ma;Di Wu	2007		10.1007/978-3-540-73321-8_33	computer vision;geography;optics;computer graphics (images)	Robotics	57.19327575565776	-51.88939551615688	46286
633740afa080e814bf4a68820b840b464e481562	the prediction of profile deviations from multi process machining of complex geometrical features using combined evolutionary and neural network algorithms with embedded simulation	grinding;hole making;cutting forces;spindle power;profile and cylindrical deviations;genetic programming;neural networks and real-time simulations	The capability to generate complex geometrical features at tight tolerances and fine surface roughness is a key element in the implementation of Creep Feed grinding process in specialist applications such as the aerospace manufacturing environment. Based on the analysis of 3D cutting forces this paper proposes a novel method of predicting the profile deviations of tight geometrical features generated using Creep Feed grinding. In this application, there are several grinding passes made at varying depths providing an incremental geometrical change with the last cut generating the final complex feature. With repeatable results from co-ordinate measurements both the radial and tangential forces can be gauged versus the accuracy of the ground features. The tangential force was found more sensitive to the deviation of actual cut depth from the theoretical one. However, to make a more robust prediction on the profile deviation its values were considered as a function of both force components (proportional to force: power was also included). For multi process, one machining platforms hole making was also investigated in terms of monitoring the force to ensure the mean cylinder was kept within required tolerances and with minimal subsequent machining (due to these imposed accuracies this is also considered a complex feature). Genetic programming (GP), an evolutionary programming technique, has been used to compute the prediction rules of part profile deviations based on the extracted radial and tangential force correlated with the said chosen “gauging” methodology (for grinding process). GP was also used to correlate the force and flank wear (VB) for hole deviations. It was found that using this technique, complex rules can be achieved and used online to dynamically control the geometrical accuracy of ground and drilled hole features. The GP complex rules are based on the correlation between the measured forces and recorded deviation of the theoretical profile (both grinding and hole making). The mathematical rules are generated from Darwinian evolutionary strategy which provides the mapping between different output classes. GP works from crossover recombination of different rules and the best individual is evaluated in terms of the given ‘best fitness value so far’ which closes on an optimal solution. The best obtained GP terminal sets were realised in rule-based embedded coded systems which were finally implemented into a real-time Simulink simulation. This realisation gives a view of how such a control regime can be utilised within an industrial capacity. Neural networks were used for GP decision verification ensuring less sensitivity to possible outliers giving more robustness to the integrated system.	algorithm;artificial neural network;embedded software;embedded system;process management (computing);simulation	James M. Griffin	2018	J. Intelligent Manufacturing	10.1007/s10845-015-1165-y	structural engineering;mathematical optimization;engineering;artificial intelligence;machine learning;engineering drawing;statistics	Robotics	69.439592237328	-36.17305779945662	46311
126b98ec9d1684faf72d46b51899c8ec859cce73	surface reflectance recovery under point light illumination		In this paper, a novel algorithm for colour recovery is presented. It assumes that the 3-D geometry of the scene is known. The spectral power distribution of a point illumination source, and the response function of the sensor are calibrated jointly. This algorithm has been used for the colour recovery part of an integrated system, developed in our laboratory, for environmental modelling. The geometry of the scene is recovered using a laser stripe range-nder and this information is exploited by the colour recovery algorithm. A point light source, attached to the whole system, has been used for the illumination of the scene, in order to connne undesirable side-eeects of the ambient light. The joint spectral power distribution of this point light source and the response function of the camera are obtained with oo-line calibration.	algorithm;frequency response;global illumination;magnetic stripe card	Robert B. Fisher;Aristides Gionis	1996		10.5244/C.10.16	köhler illumination;critical illumination	Vision	57.71099587836289	-50.217262962276116	46348
54590faabc61e1bc1ec15ce52662d178716f9b1e	iterative coupling of standardised earthquake detection & wavelet thresholding to determine simplified earthquake event waveforms (seew)	borehole station;discrete wavelet transforms;wavelet analysis;seismology earthquakes geophysical techniques iterative methods;weaving discrete wavelet transforms wavelet analysis;seismology;seew;wavelet thresholding;seew earthquake detection wavelet simplified earthquake event waveform;earthquakes;iterative methods;standardisation;dynamic information;simplified earthquake event waveform;iterative coupling;seismic noise;weaving;matata region;seismological signal;new zealand;wavelet;geophysical techniques;earthquake detection;new zealand iterative coupling earthquake detection wavelet thresholding simplified earthquake event waveform seismological signal seismic noise borehole station matata region	This paper introduces a new method to determine simplified earthquake event waveforms (SEEW) of regional earthquakes from their seismological signals which are heavily plagued with seismic noise. This method iteratively couples a standardised earthquake detection procedure with a wavelet thresholding procedure in order to cut through the seismic noise floor and determine the SEEW. The suggested method is implemented and tested for 3 events from a deep borehole station URZ in the Matata region of New Zealand. These preliminary results show that it is possible to dramatically simplify the earthquake event and hence reveal important underlying dynamical information of the system.	coda (file system);declaration (computer programming);dynamical system;emoticon;iterative method;list of code lyoko episodes;noise floor;thresholding (image processing);waveform;wavelet	Sepideh J. Rastin;C. P. Unsworth;Ken R. Gledhill;George G. Coghill;Mark Chadwick;Russell Robinson	2010	10th International Conference on Information Science, Signal Processing and their Applications (ISSPA 2010)	10.1109/ISSPA.2010.5605547	wavelet;earthquake simulation;mathematics;statistics	Robotics	81.14368309898838	-42.15392767614159	46360
0c986ef4a1d066a0a8ff6a8a84ea3bb966a5ae34	seam tracking monitoring based on adaptive kalman filter embedded elman neural network during high-power fiber laser welding	sensor system;fibre lasers;weld detection seam tracking monitoring sage husa adaptive kalman filter embedded elman neural network high power fiber laser welding visual sensor system infrared images molten pools weld seam position image difference centroid algorithms noise statistical characteristics error estimator filtering errors;measurement by laser beam;elman neural network;image processing;metals;neural nets;sage husa adaptive kalman filter;kalman filters;laser welding;welding;kalman filter;laser beams;seam tracking monitoring elman neural network fiber laser welding sage husa adaptive kalman filter;laser beam welding;infrared imaging;fiber laser welding;adaptive kalman filters;fiber laser;seam tracking monitoring;error estimate;high power;welding laser beams measurement by laser beam kalman filters noise measurement cameras neural networks target tracking;cameras;eigenvectors;noise;neural nets adaptive kalman filters fibre lasers image processing infrared imaging laser beam welding	This paper proposes a method of seam tracking monitoring during high-power fiber laser welding. A visual sensor system was employed to capture the infrared images of molten pools and the surroundings in the laser welding process. A weld seam position variable was extracted by the image difference and centroid algorithms. The state and measurement equations for weld seam position were established based on an eigenvector derived from the weld seam position variable. A Sage-Husa adaptive Kalman filter (AKF), as an estimator of the noise statistical characteristics, was applied in order to enhance the filtering precision. By embedding an Elman neural network into the AKF, an error estimator was used to compensate for the filtering errors. The results of the welding experiments have demonstrated the effectiveness of the proposed method to improve the accuracy of weld detection.	algorithm;artificial neural network;experiment;fiber laser;kalman filter	Xiangdong Gao;Deyong You;Seiji Katayama	2012	IEEE Transactions on Industrial Electronics	10.1109/TIE.2012.2193854	kalman filter;control engineering;computer vision;electronic engineering;image processing;computer science;engineering;laser beam welding;physics	Robotics	59.55500797663909	-38.207926174827215	46386
132b82361ea3241ddcf12379f90a4ac5690b9d2c	computing camera orientation relative to a world coordinate frame by detecting its projected axes	fourier transform;manhattan world assumption;spectrum;principal axes;camera orientation;nonlinear equation	In this paper a new approach is presented to compute the camera orientation relative to some man-made objects coordinate frame, the world coordinate frame. The approach is based on the observation, that man-made structures expose many lines, which are aligned with three principal orthogonal directions, belonging to a cartesian world coordinate frame. Modeling the camera as an orthographic one, a nonlinear equation system is derived, which solutions yield three angles, that describe the camera orientation relative to the scene. In order to detect the projected principal axes of the world coordinate frame, an analysis of the log-magnitude spectrum of an image is used, followed by an algorithm that uses line information from the input image directly. The algorithm has been tested on a variety of rendered test images and real images of ships.	algorithm;camera matrix;edge detection;line fitting;microsoft outlook for mac;nonlinear system;orthographic projection;sensor;system of polynomial equations;trust region;vanishing point	Matthias Lieberei;Christian Ruwwe;Bjoern Keck;Oliver Rusch;Udo Zölzer	2008		10.1145/1400885.1400953	principal axis theorem;fourier transform;spectrum;computer vision;camera auto-calibration;rotation of axes;nonlinear system;mathematics;geometry;computer graphics (images)	Vision	54.49334318690502	-50.50365229178218	46403
e9395677aad8739ef6db0b39318345467ac5a4bc	preliminary insights from the meteron supvis justin space-robotics experiment		As the human race expands its horizon toward a multiplanetary existence, infrastructures on the target planets have to be constructed and maintained to pave the way for humans. The support of robotic coworkers plays a key role in setting up habitats, energy supplies, and return vehicles, until the completion of such infrastructures in the hazardous planetary environment. The operation of these robots require capabilities including autonomy, communication, and human-robot interface design to meet the challenges of the harsh conditions in space deployment. This letter examines these topics through German Aerospace Center (DLR) and European Space Agency's METERON SUPVIS Justin space telerobotics experiments, during that astronauts on-board the International Space Station command DLR's humanoid robot Rollin’ Justin to survey and maintain a simulated Martian solar farm on Earth. Based on the first experiments conducted on August 25, 2017, this letter discusses several astronaut–robot collaboration concepts in real space-to-ground deployment and provides preliminary insights for future manned Mars missions.	autonomy;deploy;drug vehicle;dynamic language runtime;experiment;habitat;humanoid robot;interface device component;justin (robot);manufactured supplies;on-board data handling;planetary scanner;religious missions;robot (device);robotics;telerobotics;user interface design	Peter Schmaus;Daniel Leidner;Thomas Kr&#x00FC;ger;Andre Schiele;Benedikt Pleintinger;Ralph Bayer;Neal Y. Lii	2018	IEEE Robotics and Automation Letters	10.1109/LRA.2018.2856906	simulation;humanoid robot;exploration of mars;international space station;robot;control engineering;telerobotics;engineering;aerospace;artificial intelligence;robotics;mars exploration program	Robotics	55.93053110241271	-29.803021349405984	46405
4b07a82eb6c877e473388e3272b48cd47790221c	disparity estimation for high resolution stereoscopic reconstruction using the gnc approach	urban area aerial images;large scale nonconvex optimization problem;high resolution;topography earth;pixel image reconstruction digital elevation models image resolution geometry layout large scale systems constraint optimization cost function simulated annealing;image resolution;constraint optimization;non convex optimization;cost function;image matching;gnc approach;disparity estimation;regularization term;geometry;stereo matching high resolution stereoscopic reconstruction gnc approach disparity estimation digital elevation model topographic description ground rectified stereoscopic images large scale nonconvex optimization problem disparity image cost function correlation coefficients regularization term graduated nonconvexity technique simulated annealing urban area aerial images;layout;digital elevation model;correlation methods;simulated annealing;topographic description;disparity image;aerial image;large scale;stereo matching;image reconstruction;pixel;stereo image processing;correlation coefficients;urban area;high resolution stereoscopic reconstruction;digital elevation models;ground;graduated nonconvexity technique;correlation coefficient;rectified stereoscopic images;image matching stereo image processing image reconstruction simulated annealing topography earth correlation methods;large scale systems	An algorithm for the fast automatic construction of a 3D model of any real object using images from multiple views is presented. The images are taken from a real object ro tating in front of a stationary calibrated CCD TV camera. The presented algorithm generates the object shape in a first step. For that purpose an fective implementation of the method of occluding contours is used to obtain a convex volume model of th object. This model is refined in order to detect shape concavities by using additional depth information from disparity estimation and finally approximated by a triangle mesh. In a second step the texture is estimated from the image sequence and projected onto the surface model to obtain natural looking models. Results with real image se quences have confirmed the suitability of the developed algorithm even for the model ling of real objects with highly detailed and complex surfaces.	approximation algorithm;binocular disparity;charge-coupled device;stationary process;stereoscopy;triangle mesh	Guy Le Besnerais;Hélène Oriot	1998		10.1109/ICIP.1998.723536	computer vision;mathematical optimization;constrained optimization;image resolution;digital elevation model;computer science;computer graphics (images)	Vision	55.07865961760702	-50.95766478148402	46410
8d9b438c1569f2780897dc623827518869cce1b5	a loosely-coupled approach for metric scale estimation in monocular vision-inertial systems		In monocular vision systems, lack of knowledge about metric distances caused by the inherent scale ambiguity can be a strong limitation for some applications. We offer a method for fusing inertial measurements with monocular odometry or tracking to estimate metric distances in inertial-monocular systems and to increase the rate of pose estimates. As we performed the fusion in a loosely-coupled manner, each input block can be easily replaced with one's preference, which makes our method quite flexible. We experimented our method using the ORB-SLAM algorithm for the monocular tracking input and Euler forward integration to process the inertial measurements. We chose sets of data recorded on UAVs to design a suitable system for flying robots.	algorithm;computer vision;euler;loose coupling;odometry;robot;robotics;simultaneous localization and mapping;unmanned aerial vehicle	Ariane Spaenlehauer;Vincent Frémont;Y. Ahmet Sekercioglu;Isabelle Fantoni	2017	2017 IEEE International Conference on Multisensor Fusion and Integration for Intelligent Systems (MFI)	10.1109/MFI.2017.8170419	computer vision;artificial intelligence;euler's formula;odometry;ambiguity;inertial frame of reference;metric system;computer science;monocular vision;accelerometer;monocular	Robotics	55.27229601508801	-37.96545597212743	46417
14018f51b901708f0b7ba2292826588bf9d42aa9	detection of haemolytic transfusion bags		The aim of this work is to design a method that can detect hemolysis of the blood bag with blood plasma. At this time hemolysis in blood bag detects by subjective method. The nurses are comparing the color of blood plasma with reference samples and according to their own opinion and then they evaluate if blood plasma is damaged. Parameter for compare is color. For analysis, it is best to use image sensors cameras or camera. Software that is designed in MATLAB programming environment is able to detect the color of blood plasma according reference samples. Detecting color is realized in three color spaces and RGB, Lab and xyY.	color space;digital single-lens reflex camera;image sensor;integrated development environment;matlab;plasma active	David Vala;Petra Rajmanova;Zdenek Slanina	2013		10.3182/20130925-3-CZ-3023.00111	medicine;pathology;forensic engineering;surgery	Vision	76.1468821840577	-31.34047470342015	46494
40629c10b39553535804fea9d7843a7aa7427388	planetary rovers' wheel-soil interaction mechanics: new challenges and applications for wheeled mobile robots	performance evaluation;path planning;soil parameter identification;journal;parameter identification;dynamics simulation;wheeled mobile robot;mobility control;planetary exploration;design and performance evaluation;dynamic simulation;control;planetary rover;terramechanics	With the increasing challenges facing planetary exploration missions and the resultant increase in the performance requirements for planetary rovers, terramechanics (wheel–soil interaction mechanics) is playing an important role in the development of these rovers. As an extension of the conventional terramechanics theory for terrestrial vehicles, the terramechanics theory for planetary rovers, which is becoming a new research hotspot, is unique and puts forward many new challenging problems. This paper first discusses the significance of the study of wheel–soil interaction mechanics of planetary rovers and summarizes the differences between planetary rovers and terrestrial vehicles and the problems arising thereof. The application of terramechanics to the development of planetary rovers can be divided into two phases (the R&D phase and exploration phase for rovers) corresponding to the high-fidelity and simplified terramechanics models. This paper also describes the current research status by providing an introduction to classical terramechanics and the experimental, theoretical, and numerical researches on terramechanics for planetary rovers. The application status of the terramechanics for planetary rovers is analyzed from the aspects of rover design, performance evaluation, planetary soil parameter identification, dynamics simulation, mobility control, and path planning. Finally, the key issues for future research are discussed. The current planetary rovers are actually advanced wheeled mobile robots L. Ding · Z. Deng · H. Gao (B) Harbin Institute of Technology, Harbin, China e-mail: gaohaibo@hit.edu.cn; liangding@hit.edu.cn K. Nagatani · K. Yoshida Department of Aerospace Engineering, Tohoku University, Sendai 980-8579, Japan (WMRs), developed employing cutting-edge technologies from different fields. The terramechanics for planetary rovers is expected to present new challenges and applications for WMRs, making it possible to develop WMRs using the concepts of mechanics and dynamics.	algorithm;chassis;computer simulation;email;experiment;hill climbing;hysteresis;lateral thinking;mathematical model;mathematical optimization;mobile robot;motion planning;numerical analysis;performance evaluation;planetary scanner;real-time clock;real-time computing;requirement;resultant;rover (the prisoner);sensor;simulation;terrestrial television;velocity (software development);wheels	Liang Ding;Zongquan Deng;Haibo Gao;Keiji Nagatani;Kazuya Yoshida	2011	Intelligent Service Robotics	10.1007/s11370-010-0080-5	dynamic simulation;simulation;computer science;artificial intelligence;motion planning;scientific control	Robotics	63.76924860443986	-27.55060780134048	46534
78b169bead645b361d5556346bb620a189e9de07	energy concentration enhancement using window width optimization in s transform	optimisation;energy concentration enhancement;low frequency;transforms optimisation signal processing time frequency analysis;time frequency analysis signal analysis fourier transforms power engineering and energy energy measurement performance analysis geophysical measurements optimization methods wavelet analysis wavelet transforms;s transform time frequency analysis;energy measurement;signal processing;fourier transforms;transforms;optimization;time frequency analysis energy concentration enhancement window width optimization s transform;s transform;window width optimization;time frequency analysis;algorithm design and analysis	The S transform is a useful time-frequency analysis algorithm. Based on the concentration measure, a method to optimize the window width in the S transform has been proposed by previous studies along with some examples demonstrating its effectiveness. However, it is found that although this method performs well for the high and middle frequency signals, it may fail for the low frequency ones. In this paper, a new method, which is more flexible than the previous one, is proposed to deal with this problem. Comparison of these two methods for energy concentration enhancement is also provided. Experimental result shows that the proposed method achieves higher energy concentration in comparison to the previous one and the original ST.	algorithm;frequency analysis;mathematical optimization;s transform;time–frequency analysis;window function	Soo-Chang Pei;Pai-Wei Wang	2010	2010 IEEE International Conference on Acoustics, Speech and Signal Processing	10.1109/ICASSP.2010.5495742	fourier transform;algorithm design;computer vision;mathematical optimization;s transform;time–frequency analysis;computer science;signal processing;mathematics;low frequency	Robotics	80.89131783094123	-41.28587620177023	46624
e26a1319ee8edad66bbad150c656b9efae4c307f	high performance disk systems for workstation environments	evaluation criteria;high performance;high speed;quantum chemistry;type system	Real-time rendering of iso-contour surfaces is problematic for large complex data sets. In this paper, an algorithm is presented that allows very rapid representation of an interval set surrounding a iso-contour surface. The algorithm draws upon three main ideas. A fast indexing scheme is used to select only those data points near the contour surface. Hardware assisted splatting is then employed on these data points to produce a volume rendering of the interval set. Finally, by shifting a small window through the indexing scheme or data space, animated volumes are produced showing the changing contour values. In addition to allowing fast selection and rendering of the data, the indexing scheme allows a much compressed representation of the data by eliminating ``noise`` data points.	workstation	Marc D. Cozzi	1995		10.1007/BFb0046694	parallel computing;type system;computer hardware;computer science;theoretical computer science;operating system;distributed computing;programming language;quantum chemistry;computer graphics (images)	OS	68.19373673179565	-50.944786515236785	46625
4e85e1607219474add890e3391e03a56fc01668c	minimal mean-curvature-variation surfaces and their applications in surface modeling	modelizacion;calculo de variaciones;concepcion asistida;surface minimale;computer aided design;vision ordenador;euler lagrange equation;modele geometrique;ecuacion euler lagrange;image processing;equation euler lagrange;superficie minima;casco buque;etat surface;remplissage;gradiente;discretization;procesamiento imagen;courbure;filling;blending;gradient;surface reconstruction;traitement image;energy function;computer vision;surface conditions;resolucion problema;modelisation;reconstruction surface;calcul variationnel;coupage;surface modeling;estado superficie;surface model;energy functional;divided difference;pattern recognition;conception assistee;curvatura;integral functional;invariante;curvature;vision ordinateur;minimal mean curvature variation flow;critere plasticite;minimal surface;reconnaissance forme;reconstruccion superficie;reconocimiento patron;mean curvature;order flow;coque navire;modeling;variational calculus;invariant;yield criterion;geometric flow;problem solving;resolution probleme;criterio plasticidad;ship hull;mezcla;geometrical model;relleno;modelo geometrico	Physical based and geometric based variational techniques for surface construction have been shown to be advanced methods for designing high quality surfaces in the fields of CAD and CAGD. In this paper, we derive a Euler-Lagrange equation from a geometric invariant curvature integral functional–the integral about the mean curvature gradient. Using this Euler-Lagrange equation, we construct a sixth-order geometric flow (named as minimal mean-curvature-variation flow), which is solved numerically by a divided-difference-like method. We apply our equation to solving several surface modeling problems, including surface blending, N-sided hole filling and point interpolating. The illustrative examples provided show that this sixth-order flow yields high quality surfaces.	alpha compositing;business continuity;calculus of variations;computer-aided design;discretization;display resolution;divided differences;euler;euler–lagrange equation;freeform surface modelling;gradient;interpolation;linear system;noise reduction;nonlinear system;numerical analysis;scott continuity;semiconductor industry;solver;yousef saad	Guoliang Xu;Qin Zhang	2006		10.1007/11802914_25	freeform surface modelling;geometric flow;systems modeling;topology;surface reconstruction;image processing;hull;invariant;calculus;mean curvature;discretization;mathematics;geometry;curvature;divided differences;gradient;energy functional;minimal surface;calculus of variations	Graphics	67.47475717335955	-41.2924083458238	46643
a94c4a065cd7821847774fa8b7e262bf54a0a34c	an experimental study of reconstruction of tool cutting edge features using space carving method	ccd camera;surface of revolution;3d model;machine tool	The precedent of this project is to obtain a surface of revolution model of the machine tool cutter by using a single CCD camera on-machine. This paper introduces the possibility of locating the cutting edges of the cutter with reconstructed 3D models by using the same setup. Space carving method is proven useful for 3D model reconstruction of objects on a turn table. The spindle rotation of the cutter can simulate this effect. Using a calibrated camera and a known spindle speed, the images of a cutter are captured. The edge features of the cutter observed can be used for model reconstruction. Using this model of the cutter, the approximate location of the cutting edge can be located. The initial investigation shows that the accurate motion of the spindle is very important to obtain accurate results.		Wai Ming Tsang;Xi Zhang;Kazuo Yamazaki;Xiaodong Tian;Masahiko Mori	2008		10.1007/978-3-540-89646-3_86	computer vision;machine tool;surface of revolution;charge-coupled device;computer graphics (images)	HCI	57.13814368401441	-49.7414961504498	46681
153fe2434adb70d07875a160060ab96d87d2f96f	the roboknee: an exoskeleton for enhancing strength and endurance during walking	degree of freedom;human strength enhancement roboknee exoskeleton system series elastic actuator;prosthetics;medical control systems prosthetics;exoskeletons legged locomotion knee impedance humans torque muscles actuators gravity videos;medical control systems	Exoskeletons that enhance human strength, endurance, and speed while being transparent to the wearer are feasible. In order to be transparent, the exoskeleton must determine the user's intent, apply forces when and where appropriate, and present low impedance to the wearer. We present a one degree of freedom exoskeleton called the RoboKnee which achieves a high level of transparency. User intent is determined through the knee joint angle and ground reaction forces. Torque is applied across the knee in order to allow the user's quadriceps muscles to relax. Low impedance is achieved through the use of series elastic actuators. The RoboKnee allows the wearer to climb stairs and perform deep knee bends while carrying a significant load in a backpack. The device provides most of the energy required to work against gravity while the user stays in control, deciding when and where to walk, as well as providing balance and control. Videos, photographs, and more information about the RoboKnee can be found at http://www.yobotics.com.	algorithm;characteristic impedance;high-level programming language;rechargeable battery;torque	Jerry E. Pratt;Benjamin T. Krupp;Christopher J. Morse;Steven H. Collins	2004	IEEE International Conference on Robotics and Automation, 2004. Proceedings. ICRA '04. 2004	10.1109/ROBOT.2004.1307425	control engineering;simulation;computer science;engineering;degrees of freedom;statistics;mechanical engineering	Robotics	73.07746828117303	-25.668699830867155	46682
fa1c6f74b9b8a7a7b2e06d6a0feb0f8526f92c89	globally optimal hand-eye calibration	rotational components;optimisation;benchmark dataset;upper bound;robot vision;branch and bound parameter space search;vectors;optimization;tree searching;tree searching calibration end effectors optimisation robot vision;calibration cameras vectors upper bound robot vision systems robot kinematics;globally optimal hand eye self calibration;robot vision systems;calibration;translational components;cameras;end effectors;end effectors globally optimal hand eye self calibration rotational components translational components branch and bound parameter space search optimization benchmark dataset;robot kinematics	This paper introduces simultaneous globally optimal hand-eye self-calibration in both its rotational and translational components. The main contributions are new feasibility tests to integrate the hand-eye calibration problem into a branch-and-bound parameter space search. The presented method constitutes the first guaranteed globally optimal estimator for simultaneous optimization of both components with respect to a cost function based on reprojection errors. The system is evaluated in both synthetic and real world scenarios. The employed benchmark dataset is published online1 to create a common point of reference for evaluation of hand-eye self-calibration algorithms.	algorithm;benchmark (computing);branch and bound;dhrystone;global optimization;gradient descent;loss function;map projection;mathematical optimization;maxima and minima;optimization problem;simulation;virtual reality headset	Thomas Ruland;Tomás Pajdla;Lars Krüger	2012	2012 IEEE Conference on Computer Vision and Pattern Recognition	10.1109/CVPR.2012.6247781	computer vision;robot end effector;calibration;simulation;computer science;control theory;mathematics;upper and lower bounds;robot kinematics	Vision	55.65374168283018	-39.840796055278055	46705
68905b2d117e69d708e101be8fbf8373418eee83	irregular, unknown light sources in dynamic global illumination	dynamic global illumination;global illumination;dynamic environment;hierarchical radiosity	The goal in global illumination solutions for dynamic environments is to update a scene based on past scenes. For this difficult problem, current state of the art solutions are either not applicable, or unduly complex, when there are large changes in the illumination of unbounded number of objects. Such changes may be caused by the appearance of unexpected (at modeling time), irregular light sources.#R##N##R##N#We define a subset of dynamic environments in which new light sources may be user introduced, and implement solutions that complement existing schemes.	global illumination;illumination (image)	Sharat Chandran;Mayur P. Srivastava	2004	Image Vision Comput.	10.1016/j.imavis.2004.03.014	computer vision;computer science;global illumination;computer graphics (images)	Vision	62.132103511575444	-47.740328565855535	46777
a07dc08b05832464c1ab8acbfdc27300fc14fc25	a shading model for atmospheric scattering considering luminous intensity distribution of light sources	light scattering	Studio spotlights produce dazzling shafts of light, while light scattered from fog illuminated by automobile headlights renders driving difficult. This is because the particles in the illuminated volume become visible by scattering light. A shading model for scattering and absorption of light caused by particles in the atmosphere is proposed in this paper. The method takes into account luminous intensity distribution of light sources, shadows due to obstacles, and density of particles. The intensity at a viewpoint is calculated by integration of light scattered by particles between the viewpoint and a given point on an object. The regions to be treated in this manner are localized by considering illumination volumes and shadow volumes caused by obstacles in the illumination volumes.	illumination (image);list of common shading algorithms;luminous studio;rendering (computer graphics);shadow volume	Tomoyuki Nishita;Yasuhiro Miyawaki;Eihachiro Nakamae	1987		10.1145/37401.37437	multiangle light scattering;tyndall effect;computer science;light scattering	Vision	61.70985412463808	-51.99069651167602	46896
73210675e03e71b07dedd666aa0599822874798d	integrating dynamic deformations into interactive volume visualization	categories and subject descriptors according to acm ccs i 3 computer graphics;interactive application;volume visualization	Non-linear geometric deformation (or warping) is a useful tool for working with volumes. Unfortunately, the computational expense of performing the resampling needed to implement volu me deformation has precluded its use in interactive applications. In this paper, we show how non-linear deformatio ns can be integrated into interactive volume visualization allowing for dynamic deformations to be used along with inter active viewing, exploration, and manipulation tools. We describe how hardware assisted volume rende ring can be adapted to resample volume deformations, leveraging programmable shaders to compute deformation s and the local coordinate transformations required for shading effects. We describe how volume interaction tech iques, such as ray picking and plane slicing, can be used in concert with our deformation methods. Our methods extend to simultaneous display of multiple volumes enabling comparisons. We demonstrate dynamic volume de formation at interactive rates on commodity hardware for interactive deformation control, animated deformatio ns, and volume widgets.	analysis of algorithms;commodity computing;computation;nonlinear system;scientific visualization;shader;shading;windows me	Tom Brunet;K. Evan Nowak;Michael Gleicher	2006		10.2312/VisSym/EuroVis06/219-226	computer vision;simulation;computer science;computer graphics (images)	Visualization	67.19685870311747	-51.04693955857335	46984
f5a1158eb34b992c7209ae8cf93aec7c6a99bfa0	supervisory movement coordination in pipeless chemical plants	motion control;flexible manufacturing systems;raw materials;industrial plants;mobile robots;formal verification;industrial robots;multi robot systems;telerobotics automatic guided vehicles chemical technology flexible manufacturing systems formal verification industrial plants industrial robots mobile robots motion control multi robot systems raw materials;telerobotics;automatic guided vehicles;timed model checking supervisory movement coordination pipeless chemical plants reconfigurable production scalable production flexible production high valued chemical products raw materials automated guided vehicles supervisory control problem vehicles movement coordination timeliness recipe completion reliable recipe completion formal verification stochastic model checking;vehicles chemicals stochastic processes analytical models reliability supervisory control color;chemical technology	Pipeless chemical plants provide an alternative way for flexible, scalable, and reconfigurable production of high valued chemical products on demand. The main feature of these pipeless plants is that the raw materials needed for production are transferred in the system by means of automated guided vehicles. Given recipes that describe the production of the desired products, the supervisory control problem is to coordinate the movement of the vehicles such that all recipes are successfully completed on time. To safely coordinate the movement of the vehicles, we propose to employ supervisory coordination. To validate timeliness and reliable completion of the recipes, we propose multiple alternatives relying on formal verification using timed and stochastic model checking.	formal verification;model checking;reconfigurable computing;scalability	Jasen Markovski;Michel A. Reniers	2013	2013 IEEE 18th Conference on Emerging Technologies & Factory Automation (ETFA)	10.1109/ETFA.2013.6648105	telerobotics;control engineering;motion control;mobile robot;embedded system;simulation;formal verification;computer science;engineering;artificial intelligence;raw material	Robotics	58.690102975311646	-25.601115610169142	47141
6f798d5aca20c38c56b3417dee0a7756725e731f	geometric compression through topological surgery	3d mesh compression;mesh compression;polyhedral model;digital communication;geometry compression;vrml;spanning tree;random access	The abundance and importance of complex 3-D data bases in major industry segments, the affordability of interactive 3-D rendering for office and consumer use, and the exploitation of the Internet to distribute and share 3-D data have intensified the need for an effective 3-D geometric compression technique that would significantly reduce the time required to transmit 3-D models over digital communication channels, and the amount of memory or disk space required to store the models. Because the prevalent representation of 3-D models for graphics purposes is polyhedral and because polyhedral models are in general triangulated for rendering, this article introduces a new compressed representation for complex triangulated models and simple, yet efficient, compression and decompression algorithms. In this scheme, vertex positions are quantized within the desired accuracy, a vertex spanning tree is used to predict the position of each vertex from 2,3, or 4 of its ancestors in the tree, and the correction vectors are entropy encoded. Properties, such as normals, colors, and texture coordinates, are compressed in a similar manner. The connectivity is encoded with no loss of information to an average of less than two bits per triangle. The vertex spanning tree and a small set of jump edges are used to split the model into a simple polygon. A triangle spanning tree and a sequence of marching bits are used to encode the triangulation of the polygon. Our approach improves on Michael Deering's pioneering results by exploiting the geometric coherence of several ancestors in the vertex spanning tree, preserving the connectivity with no loss of information, avoiding vertex repetitions, and using about three fewer bits for the connectivity. However, since decompression requires random access to all vertices, this method must be modified for hardware rendering with limited onboard memory. Finally, we demonstrate implementation results for a variety of VRML models with up to two orders of magnitude compression.	algorithm;binary tree;bridge (graph theory);color;data compression;database;disk space;dual graph;encode;entropy encoding;euler characteristic;file spanning;graphics;level of detail;michael deering;normal (geometry);polygon triangulation;polyhedron;random access;spanning tree;texture mapping;tree (data structure);triangle mesh;vrml;vertex (graph theory)	Gabriel Taubin;Jarek Rossignac	1998	ACM Trans. Graph.	10.1145/274363.274365	mathematical optimization;combinatorics;vrml;spanning tree;computer science;theoretical computer science;machine learning;mathematics;geometry;programming language;algorithm;random access;computer graphics (images)	Graphics	67.78257437699563	-49.75334851256907	47147
1edd597ce0d497d36c169afdd27409b918698173	comparison of guidance modes for the auv “slocum glider” in time-varying ocean flows	path planning autonomous underwater vehicles;vehicles oceans path planning software vectors heuristic algorithms mathematical model;software stack simulator guidance mode comparison auv slocum glider time varying ocean flows mission;dead reckoning auv slocum glider path planning glider simulator time varying ocean flows	This paper presents possibilities for the reliable guidance of an AUV “Slocum Glider” in time-varying ocean flows. The presented guidance modes consider the restricted information during a real mission about the actual position and ocean current conditions as well as the available control modes of a glider. A faster-than-real-time, full software stack simulator for the Slocum glider will be described in order to test the developed guidance modes under real mission conditions.	general slocum;glider (conway's life);real-time transcription;simulation	Mike Eichhorn;Hans C. Woithe;Ulrich Kremer	2014	OCEANS 2014 - TAIPEI	10.1109/OCEANS-TAIPEI.2014.6964583	control engineering;simulation;engineering;marine engineering;underwater glider	Robotics	58.618635870902295	-25.815499548959405	47148
51b1b09b0d573e96b8410f6e6ed79ddbf84455e3	smoothing normal vectors on discrete surfaces while preserving slope discontinuities	discrete normals;discrete shading;visualization;discrete surfaces	A new method is proposed which smoothes normal vectors over a discrete surface, preserving slope discontinuities and small details. Assume an estimate of the normal vector at each surface point is known and these estimates are computed from small neighbourhoods such that slope discontinuities and small details are still reflected by these normals. To smooth these normals, the normal vectors at points in a certain neighbourhood are averaged. The size of the neighbourhood considered for the smoothing at a point is adapted according the local surface configuration. The adaptation is performed, depending on the tangent plane at the point considered as well as the angles between the normals at neighbouring points and the normal at the point in question.	smoothing	Grit Thürmer	2001	Comput. Graph. Forum	10.1111/1467-8659.00482	mathematical optimization;visualization;topology;computer science;mathematics;geometry	Vision	70.05200084132085	-42.4754483513964	47268
af5a368ca1788bb693e6b1e899ab055f21fc7f0f	visuo-motor coordination of a robot manipulator based on neural networks	manipulators;motion control;robot kinematics manipulators neural networks robot sensing systems cameras orbital robotics robot vision systems calibration robot control motion control;multilayer perceptrons;multilayer perceptrons motion control manipulators robot vision image sensors backpropagation;motion processing;backpropagation;image sensors;robot manipulator;robot vision;motor coordination;flexible environment visuo motor coordination robot manipulator neural networks motion determination problem end effector end effector mounted cameras calibration geometric;neural network	A visuo-motor coordination scheme is proposed for a robot manipulator in this paper. The motion determination problem is learned b y this scheme using the neural networks. The motion process consists of basic motion and adjusting motion in this work. A basic network is employed to determine the gross configuration of the robot end-effector using the visual information from two fixed cameras. A n adjusting network is served to adjust the configuration of the robot finely using the visual information from two on the end-eflector mounted cameras, so that the robot can handle an object according to the task. The e-@ciency and the adaptability of the basic network is shown in the simulation. The proposed scheme essentially regards complex calibration and geometric calculations as a simple mapping of the neural networks. 'The e f i ciency of this scheme will lead to expand the application of the robot in a flexible environment.	artificial neural network;robot end effector;simulation	Liping Sun;Christian Doeschner	1998		10.1109/ROBOT.1998.677417	control engineering;motion control;mobile robot;robot learning;computer vision;robot end effector;cartesian coordinate robot;articulated robot;computer science;backpropagation;arm solution;image sensor;control theory;robot control;motor coordination;artificial neural network;robot kinematics;robot calibration	Robotics	62.812901130296126	-26.74896368105756	47282
c2307265b2c8e122ed0632aa0c8114077741ba84	the mats robotic system to assist disabled people in their home environments	quality of life;manipulators;mobile robots wheelchairs rehabilitation robotics electronic equipment prototypes power supplies psychology service robots senior citizens software prototyping;concept design;patient rehabilitation;social integration;power supply;medical robotics;software architecture;handicapped aids;distributed software architecture;distributed programming;service robot;power supplies to apparatus;elderly people;manipulators medical robotics handicapped aids patient rehabilitation power supplies to apparatus distributed programming software architecture robot programming;distributed software architecture mats robotic system disabled people home environments rehabilitation robotics elderly people day life activities common living environment kitchen bathroom bedroom population social integration prototype climbing;robot programming	Absnact-This paper reviews a new approach in the ares of rrhabilitation robotics. The service robot MATS helps dsable and elderly people in their day life activities in common living environment like kitchen, bathroom, bedroom, etc. In this way the quality of life of the important part of population improves toward their social integration. This new prototype has new abilities Like climb from one wall to another or from the table to the wheelchair, and at the same time to he attached and move with the wheelchair. The robot is totally autonomous and needs only power supply to he operated. This paper presents the distributed software architecture and the concept design of the HMI which handles the robotic system.	autonomous robot;distributed computing;power supply;prototype;service robot;software architecture;the quality of life;user interface	Antonio Giménez;Carlos Balaguer;Angelo M. Sabatini;Vincenzo Genovese	2003		10.1109/IROS.2003.1249264	embedded system;software architecture;simulation;quality of life;computer science;engineering;concept art	Robotics	62.24741532795786	-28.515024106019233	47286
7d2e0804683cfbca2d6485e9773bb6d4cda2a6f6	memory technology and applications	automotive engineering;memory management;two dimensional displays;three dimensional displays;intelligent vehicles;rendering computer graphics;throughput	◢ Factors driving advanced memory designs - Applications requiring real time video, VR, advanced graphics ◢ Increased CPU/GPU performance - Need for balancing BW, capacity - HBM solutions ◢ Emerging applications with unique memory requirements - ML - training and inference ◢ Novel solutions for PE-Mem structures ◢ Big Data - More data upload - Cloud DL: massive parameter and training data sets	big data;central processing unit;graphics processing unit;high bandwidth memory;requirement;upload	Allen Rush	2016	2016 IEEE Hot Chips 28 Symposium (HCS)	10.1109/HOTCHIPS.2016.7936173	embedded system;computer hardware;computer science;computer graphics (images)	Embedded	69.94475172400563	-51.862142429616405	47293
54893d859872da4eafb768318c3ce4c8677246dd	statistical identification and macroscopic transitional model between disorder and order	covariance matrix statistical identification macroscopic transitional model food processing discrete food products degree of disarray concept vibratory feeders multihead weighers pick and place operations symmetry categorisation eigenvectors;principal component analysis covariance matrices eigenvalues and eigenfunctions food products food technology materials handling;food products entropy three dimensional displays us department of defense covariance matrices equations mathematical model	Food processing provides a lot of possibilities to apply robotics and automation. In this paper, we identify disordered and ordered states of discrete food products. The concept of Degree of Disarray is introduced. Food ordering processes such as vibratory feeders, multi-head weighers, pick and place operations are common automation in food industry to transfer products from a higher to a lower Degree of Disarray. Parts entropy is introduced to describe a product's individual state based on the symmetry categorisation. A macroscopic transitional model is presented which determines a subspace of the disordered arrangement using the eigenvectors of the largest eigenvalues of the covariance matrix. A projection into this created subspace follows. As soon as the disorder state in only one dimension is achieved, the point of disorder can be derived which finally transfers the objects into order. From here, a transformation to any order arrangement in any dimension is possible. This methodology is applied to pick and place operations and experiments are conducted.	categorization;entropy (information theory);experiment;hungarian algorithm;mathematical optimization;point cloud;randomness;robotics;smt placement equipment;transformation matrix;travelling salesman problem	Helge A. Wurdemann;Vahid Aminzadeh;Jian S. Dai	2014	2014 IEEE International Conference on Robotics and Automation (ICRA)	10.1109/ICRA.2014.6907462	econometrics;mathematics;statistics	Robotics	68.44257218160402	-34.67829329427886	47343
efb51b7513b720ffa61be325b102ef31ae9aff62	integrating recursive minimum tracking and codebook-based noise estimation for improved reduction of non-stationary noise	recursive noise tracking;non stationary noise;speech enhancement;codebooks	Conventional single-channel noise reduction algorithms typically have problems with non-stationary noise. Popular algorithms such as minimum statistics or voice-activity-detector-based methods rely on the assumption that the noise spectral characteristics change very slowly over time. Codebook-based approaches try to overcome this problem by incorporating a priori knowledge about speech and different noise types. These approaches perform a joint estimation of the speech and noise spectra on a frame-by-frame basis. The frames are typically 20-40ms long so that fast fluctuations of the signal characteristics can be tracked instantaneously. However, these methods require a pitch estimator to prevent speech distortion as well as residual noise in voiced speech frames. In addition, they are not very robust against model mismatch. In this paper, we propose an integrated noise estimation algorithm that combines the ability of codebook-based algorithms to track non-stationary noise with the robustness of a recursive minimum-tracking-based noise estimation algorithm. An objective and subjective evaluation is provided. Results confirm the superiority of the proposed algorithm in non-stationary noise scenarios compared to state-of-the-art algorithms.	codebook;recursion;stationary process	Tobias Rosenkranz;Henning Puder	2012	Signal Processing	10.1016/j.sigpro.2011.09.021	gradient noise;gaussian noise;median filter;speech recognition;value noise;computer science;noise measurement;machine learning;noise;pattern recognition	EDA	82.49296323238156	-34.340847557057984	47375
7d6673254dab65b32789934661a6b7362dd99a9b	multi-camera systems for rehabilitation therapies: a study of the precision of microsoft kinect sensors	kinect sensor rehabilitation system capture precision multi camera system;miguel oliver francisco montero jose pascual molina pascual gonzalez antonio fernandez caballero multi camera systems for rehabilitation therapies a study of the precision of microsoft kinect sensors	This paper seeks to determine how the overlap of several infrared beams affects the tracked position of the user, depending on the angle of incidence of light, distance to the target, distance between sensors, and the number of capture devices used. We also try to show that under ideal conditions using several Kinect sensors increases the precision of the data collected. The results obtained can be used in the design of telerehabilitation environments in which several RGB-D cameras are needed to improve precision or increase the tracking range. A numerical analysis of the results is included and comparisons are made with the results of other studies. Finally, we describe a system that implements intelligent methods for the rehabilitation of patients based on the results of the tests carried out.	experiment;incidence matrix;interference (communication);kinect;mind;numerical analysis;pattern recognition;pixel;sensor	Miguel Oliver;Francisco Montero Simarro;José Pascual Molina;Pascual González;Antonio Fernández-Caballero	2016	Frontiers of Information Technology & Electronic Engineering	10.1631/FITEE.1500347	simulation;computer science;computer graphics (images)	Robotics	57.60356601929494	-38.87323949048924	47427
58d451213d7526c419d484d824194a2b1912d349	on interacting with physics-based models of graphical objects	contact reconstruction;physics based modeling;deformable objects;realistic deformation;mass spring damper system;global filter	Enhancing graphical objects whose behaviors are governed by the laws of physics is an important requirement in modeling virtual physical environments. In such environments, the user can interact with graphical objects and is able to either feel the simulated reaction forces through a physical computer interface such as a force feedback mouse or through such interactions, objects behave in a natural way. One of the key requirements for such interaction is determination of the type of contact between the user controlled object and the objects representing the environment. This paper presents an approach for reconstructing the contact configuration between two objects. This is accomplished through usage of the time history of the motion of the approaching objects for inverse trajectory mapping of polygonal representation. In the case of deformable objects and through usage of mass-springdamper system this paper also presents a special global filter that can map the local deformation of an object to the adjacent vertices of polygonal mesh. In addition to offering a fast computational framework, the proposed method also offers more realistic representation of the deformation. The results of this paper are shown through detailed examples and comparison analysis using different computational platforms.	computation;emoticon;graphical user interface;haptic technology;initial condition;interaction;mathematical model;neighbourhood (graph theory);numerical analysis;numerical integration;polygon mesh;real-time clock;requirement;simulation;virtual reality	Shahram Payandeh;John Dill;Zhu Liang Cai	2004	Robotica	10.1017/S0263574703005617	computer vision;simulation;computer science;object-oriented design;computer graphics (images)	Robotics	70.75691700291898	-47.75313580023168	47432
860d70d7b6af770b06e6d307a9e4dfa167e3423e	robust mmse filtering for single-microphone speech enhancement		MMSE filtering of signals contaminated with additive noise is addressed with explicit uncertainty of the second-order target signal statistics. The unfortunate lack of stationarity of speech, and hence the phenomenon of musical noise in speech enhancement, is an ideal problem for the proposed approach. Specifically, we complement the established short-time power-spectral subtraction for speech power estimation with a prior of the momentary speech-power level. The MMSE estimator for Gaussian speech amplitudes is then derived under these circumstances. The potential for the enhancement of noisy speech is briefly demonstrated by SNR and PESQ analysis.	additive white gaussian noise;microphone;pesq;signal-to-noise ratio;speech enhancement;stationary process;utility functions on indivisible goods	Gerald Enzner;Philipp Thuene	2017	2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	10.1109/ICASSP.2017.7952909	artificial intelligence;filter (signal processing);noise measurement;microphone;estimator;computer science;pattern recognition;time–frequency analysis;pesq;speech recognition;phenomenon;speech enhancement	Robotics	82.26285438587782	-35.0465207282973	47462
3c0f89d7bf781b102cb69d22b0307e618c9ddf81	flotation surface bubble displacement motion estimation based on phase correlation method		Phase correlation technique combined of bubble tracking algorithm is investigated to estimate the flotation surface bubble displacement movement in this work. Image segmentation is used to extract the high gray value area of each bubble after the two continuous images in a sequence are preprocessed by zooming out on minimum. Because of the bubble motion varying at different parts of the cell surface, block phase correlation is employed to obtain the detailed displacement feature for each block. A lead zinc flotation plant is used to carry out experiments for the estimation of the bubble displacement motion. Experimental results show that the bubble displacement motion of each flotation cell is in a certain cycle. The displacement motion curve distribution and the turbulence degree curve distribution of the same level flotation cell are the similar.	displacement mapping;motion estimation;phase correlation	Liangqin Chen;Weixing Wang	2015		10.1007/978-3-319-26181-2_19	bubble;physics;control theory;image segmentation;motion estimation;turbulence;phase correlation	Vision	73.1966341353681	-48.655747893892396	47556
6223a8c8ab1b4435fa3ae2d032646da1bd6a1a75	photometric approach to surface reconstruction of artist paintings	sensors;reflectivity;specular reflections;numerical optimization;bidirectional reflectance transmission function;surface texture;surface reconstruction;image texture;specular reflection;bidirectional reflectance distribution function;image reconstruction;nonlinear optimization;reflection;cameras;light sources	We propose a method for surface reconstruction of artist paintings. In order to reproduce the appearance of a painting, including color, surface texture, and glossiness, it is essential to acquire the pixel-wise light reflection property and orientation of the surface and render an image under an arbitrary lighting condition. A photometric approach is used to estimate bidirectional reflectance distribution functions (BRDFs) and surface normals from a set of images photographed by a fixed camera with sparsely distributed point light sources. A robust and computationally less expensive nonlinear optimization algorithm is proposed that optimizes the small number of parameters to simultaneously determine all of the specular BRDF, diffuse albedo, and surface normal. The proposed method can be applied to moderately glossy surfaces without separating captured images into diffuse and specular reflections beforehand. Experiments were conducted using oil paintings with different surface glossiness. The effectiveness of the proposed method is validated by comparing captured and rendered images. © 2011 SPIE and IS&T. [DOI: 10.1117/1.3533329]	algorithm;amiga reflections;bidirectional reflectance distribution function;color;estimation theory;experiment;mathematical optimization;nonlinear programming;nonlinear system;normal (geometry);photometric stereo;pixel;r-cast;reflection (computer graphics);robustness (computer science);synthetic intelligence	Takayuki Hasegawa;Norimichi Tsumura;Toshiya Nakaguchi;Koichi Iino	2011	J. Electronic Imaging	10.1117/1.3533329	bidirectional texture function;computer vision;specular reflection;photometric stereo;nonlinear programming;computer science;optics	Vision	57.853691172507226	-51.8824901232282	47564
1ea6e298f0958e5d8dcd80209142b4f5383d46d3	emergence and motion analysis of 3d quasi-passive dynamic walking by excitation of lateral rocking	legged locomotion;oscillators;mobile robots;rocking motion 3d quasi passive dynamic walking lateral rocking excitation supple locomotion adaptive locomotion dynamic walking robots human looking walking three dimensional quasi passive dynamic walking;dynamics;mathematical model;humans;robot dynamics;robot dynamics mobile robots;legged locomotion oscillators dynamics mathematical model equations humans	Human is capable of adaptive and supple locomotion in the real world characterized by rapid changes, high uncertainly, and limited availability of information. In order to understand the human walking, this work was motivated by the concept of passive dynamic walking robots, which have no actuation or control system except for gravity are capable of stable, human-looking walking. On the other hand, human can produce a stepping motion not only depend on the legs, but also the rotation of the Center of Mass, arm-swing, the motion of the torso and so on. In this paper, a three dimensional quasi-passive dynamic walking provoked by rocking motion in lateral plane has been investigated. The behavioral analyses with the robot experiments show that this robot can walk on a flat ground and a gait speed is related to the period of lateral rocking.	control system;double pendulum;emergence;emoticon;excite;experiment;lateral computing;lateral thinking;limited availability;mobile robot;stepping level	Daisuke Nakanishi;Yuichiro Sueoka;Yasuhiro Sugimoto;Masato Ishikawa;Koichi Osuka;Yoshiyuki Sankai	2012	2012 IEEE/RSJ International Conference on Intelligent Robots and Systems	10.1109/IROS.2012.6385816	control engineering;mobile robot;dynamics;simulation;computer science;engineering;artificial intelligence;mathematical model;control theory;oscillation;quantum mechanics	Robotics	67.06981486642253	-24.31531509336263	47595
4613c3161440b324dab0e9b6141a700276ad29c2	feasible spaces in weld gun selection	bridges usa councils automation conferences;unigraphics nx4 weld gun selection robot assisted welding process robot weld gun assembly weld gun verification standard geometric modeling operations commercial cad system;welding equipment;welds;standard geometric modeling operations;bridges;weld gun verification;usa councils;configuration space;welds planning robotic welding welding equipment;robot assisted welding process;planning;geometric model;process planning;weld gun selection;robotic welding;conferences;unigraphics nx4;robot weld gun assembly;commercial cad system;automation	An important requirement of any robot-assisted welding process is to ensure that a set of weld locations on a work assembly can be reached by the robot-weld gun assembly without colliding with the work assembly and surrounding tooling. A weld gun that maintains a valid contact at the a weld location without interference is said to be feasible at that location. An important class of problems in welding process planning and optimization reduce to the problems of verification and synthesis of feasible weld guns for a given set of weld locations. We formulate these problems using standard geometric modeling operations and show how they can be solved in a commercial CAD system. Our approach exemplifies a more general strategy for planning in reconfigurable manufacturing in terms of configuration spaces. A prototype implementation in Unigraphics NX4 with realistic industrial models demonstrates the effectiveness of the proposed approach to weld process planning.	algorithm;approximation;computation;computer-aided design;geometric analysis;geometric modeling;interference (communication);mathematical optimization;maximal set;nes zapper;nx (software);prototype;reconfigurable computing;robot welding;springer (tank)	Saigopal Nelaturi;Atul Abhyankar;Vadim Shapiro;Robert B. Tilove	2008	2008 IEEE International Conference on Automation Science and Engineering	10.1109/COASE.2008.4626483	engineering;forensic engineering;engineering drawing;manufacturing engineering	Robotics	68.89818603429961	-32.66223261170679	47745
d98aa424587e0ad02b16adb86ede10647dffce2c	large scale urban scene modeling from mvs meshes		In this paper we present an eicient modeling framework for large scale urban scenes. Taking surface meshes derived from multiview-stereo systems as input, our algorithm outputs simpliied models with semantics at diferent levels of detail (LODs). Our key observation is that urban building is usually composed of planar roof tops connected with vertical walls. There are two major steps in our framework: segmentation and building modeling. The scene is irst segmented into four classes with a Markov random ield combining height and image features. In the following modeling step, various 2D line segments sketching the roof boundaries are detected and slice the plane into faces. Through assigning each face with a roof plane, the inal model is constructed by extruding the faces to the corresponding planes. By combining geometric and appearance cues together, the proposed method is robust and fast compared to the state-of-the-art algorithms.	3d modeling;algorithm;citygml;level of detail;markov chain;markov random field;polygon mesh	Lingjie Zhu;Shuhan Shen;Xiang Gao;Zhanyi Hu	2018		10.1007/978-3-030-01252-6_38	feature (computer vision);markov random field;artificial intelligence;computer vision;computer science;line segment;polygon mesh;planar	Vision	57.99089550171926	-46.05557672496289	47860
b7b12d9175de90ad05e22a0948b7d914928b449d	incremental dense reconstruction from sparse 3d points with an integrated level-of-detail concept		For decades scene reconstruction from multiple images is a topic in computer vision and photogrammetry communities. Typical applications require very precise reconstructions and are not bound to a limited computation time. Techniques for these applications are based on complete sets of images to compute the scene geometry. They require a huge amount of resources and computation time before delivering results for visualization or further processing. In the application of disaster management these approaches are not an option since the reconstructed data has to be available as soon as possible. Especially, when it comes to Miniature Unmanned Aerial Vehicles (MUAVs) sending aerial images to a ground station wirelessly while flying, operators can use the 3D data to explore the virtual world and to control the MUAVs. In this paper an incremental approach for dense reconstructions from sparse datasets is presented. Instead of focussing on complete datasets and delivering results at the end of the computation process, our incremental approach delivers reasonable results while computing, for instance, to quickly visualize the virtual world or to create obstacle maps.	aerial photography;algorithm;baseline (configuration management);computation;computer vision;map;photogrammetry;scientific visualization;sparse matrix;time complexity;unmanned aerial vehicle;virtual world;visual descriptor;visualization (graphics)	Jan Roters;Xiaoyi Jiang	2012		10.1007/978-3-642-40303-3_13	computer vision;simulation;computer science;data mining	Vision	56.2387367353108	-45.32984306689472	47869
031c85444315163fa44b65c945e2ac46156f7341	a probe-camera system for 3d ultrasound image reconstruction		This paper proposes a probe-camera system for 3D ultrasound (US) image reconstruction with probe-camera calibration and probe localization methods. The probe-camera calibration method employs an existing US phantom for convenience with a simple procedure. The probe localization method employs structure from motion (SfM) to estimate the camera motion. SfM is used to reconstruct 3D point clouds from multiple-view images and simultaneously estimate each camera position. Through experiments using the developed system, we demonstrate that the proposed method exhibits good performance to reconstruct 3D US volume.		Koichi Ito;Kouya Yodokawa;Takafumi Aoki;Jun Ohmiya;Satoshi Kondo	2017		10.1007/978-3-319-67552-7_16	iterative reconstruction;computer vision;point cloud;imaging phantom;structure from motion;physics;artificial intelligence;3d ultrasound	Vision	55.17736792820163	-46.980169620384366	48079
abaef541ac8cdaf183391e688e56ba644a475168	an autonomic indoor positioning application based on smartphone	successive peaks merging;zero velocity compensation;gyroscopes;smart phones gyroscopes inertial navigation kalman filters moving average processes;acceleration legged locomotion accelerometers kalman filters gyroscopes jitter indexes;legged locomotion;gyroscope;kalman filters;smart phone;inertial navigation;smart phones;kalman filter;vertical acceleration signals;navigation technology;positioning technology;acceleration;moving average filter;indexes;indoor location information;autonomic indoor positioning application;moving average processes;autonomic indoor positioning application successive peaks merging kalman filter moving average filter zero velocity compensation vertical acceleration signals attitude measurement gyroscope indoor location information pedestrian dead reckoning technique navigation technology positioning technology smart phone;pedestrian dead reckoning pdr;pedestrian dead reckoning technique;jitter;attitude measurement;indoor autonomic positioning;accelerometers;moving variance analysis;moving variance analysis indoor autonomic positioning inertial navigation pedestrian dead reckoning pdr zero velocity compensation kalman filter	Nowadays positioning and navigation technologies based on smartphone are sprouting up for numerous application scenarios. In this paper a more self-contained approach is introduced by which merely inertial units within the smartphone are utilized. By the Pedestrian Dead Reckoning technique, all kinds of indoor location information are provided at users' disposal. With the gyroscope, the attitude of smartphone is measured. So the real time accelerations in standard coordinate system without gravity component can be calculated. Here only vertical acceleration signals are made use of to extract the features for steps counting as well as step lengths estimation. A series of algorithms are employed to eliminate the noise and deviation, such as Zero Velocity Compensation, Moving Average Filter, Kalman Filter, and Successive Peaks Merging. Particularly the whole walking process is divided into small segments in each of which only straight walking, no stop, no turn is contained. So, different segments are processed respectively with distinctive parameters. The breakpoints are determined by moving variance analysis for accelerations and rotation angles, after which the heading and length of every step are acquired so that the mileage and position can be updated, closely followed by moving trajectory. In experiments, the average deviation of our approach is 0.48 m.	algorithm;autonomic computing;breakpoint;course (navigation);dead reckoning;experiment;gyroscope;kalman filter;smartphone;velocity	Yi Sun;Yubin Zhao;Jochen H. Schiller	2014	2014 IEEE Wireless Communications and Networking Conference (WCNC)	10.1109/WCNC.2014.6953086	kalman filter;simulation;gyroscope;computer science;control theory	Robotics	57.57928177587561	-37.27746140906997	48080
2073371b3abd75d11cbd05fa8521241338ef465e	online accelerated rendering of visual hulls in real scenes	shadow mapping;shape from silhouette;image based modeling and rendering;video streaming;texture mapping;hardware accelerator;dynamic texture;natural environment;region of interest;visual hull;real time rendering	This paper presents an online system which is capable of reconstructing and rendering dynamic objects in real scenes. We reconstruct visual hulls of the objects by using a shape-from-silhouette approach. During rendering, a novel blending scheme is employed to compose multiple background images. Visibility artifacts on the dynamic object are removed by using opaque projective texture mapping. We also propose a dynamic texture packing technique to improve rendering performance by exploiting region-of-interest information. Our system takes multiple live or pre-recorded video streams as input. It produces realistic real-time rendering results of dynamic objects in their surrounding natural environment in which the user can freely navigate.	alpha compositing;projective texture mapping;real-time computing;real-time locating system;rendering (computer graphics);set packing;streaming media;on-line system	Ming Li;Marcus A. Magnor;Hans-Peter Seidel	2003			texture mapping;terrain rendering;computer vision;tiled rendering;image-based modeling and rendering;hardware acceleration;3d rendering;rendering;computer science;parallel rendering;multimedia;shadow mapping;natural environment;real-time rendering;texture memory;alternate frame rendering;projective texture mapping;software rendering;image-based lighting;computer graphics (images);region of interest	Graphics	64.7331925802055	-50.491203926970414	48181
0401c05b9485b6c559e91738d6427f5e5364746c	appearance-guided synthesis of element arrangements by example	by example synthesis;vector texture synthesis;texture synthesis;point process;npr;point of view;spatial statistics	We present a technique for the analysis and re-synthesis of 2D arrangements of stroke-based vector elements. The capture of an artist's style by the sole posterior analysis of his/her achieved drawing poses a formidable challenge. Such by-example techniques could become one of the most intuitive tools for users to alleviate creation process efforts. Here, we propose to tackle this issue from a statistical point of view and take specific care of accounting for information usually overlooked in previous research, namely the elements' very appearance. Composed of curve-like strokes, we describe elements by a concise set of perceptually relevant features. After detecting appearance dominant traits, we can generate new arrangements that respect the captured appearance-related spatial statistics using multitype point processes. Our method faithfully reproduces visually similar arrangements and relies on neither heuristics nor post-processes to ensure statistical correctness.	care-of address;correctness (computer science);heuristic (computer science);sensor;spatial analysis	Thomas Hurtut;Pierre-Edouard Landes;Joëlle Thollot;Yann Gousseau;R. Drouillhet;Jean-François Coeurjolly	2009		10.1145/1572614.1572623	visual arts;computer vision;artificial intelligence;machine learning;point process;mathematics;geometry;spatial analysis;texture synthesis;statistics;computer graphics (images)	Graphics	63.67930888398499	-46.65860507950365	48226
6a9ef247cf0f36624992212e5ac9c017b1546433	cooperative exploration strategy for micro-aerial vehicles fleet		In this paper, the problem of the exploration of an unknown environment by deploying a fleet of Micro-Aerial Vehicles (MAV) is considered. As a single robot has already proven its efficiency for this task, the challenge is to extend it to a multi-robots system to reduce the exploration time. For this purpose, a cooperative navigation strategy is proposed based on a specific utility function and inter-robots data exchange. The novelty comes from the exchange of the frontiers points instead of maps, which allows to reduce computation and data amount within the network. The proposed system has been implemented and tested under ROS using the Gazebo simulator. The results demonstrate that the proposed navigation strategy efficiently spreads robots over the environment for a faster exploration.	aerial photography;computation;cooperative mimo;experiment;map;on-board data handling;robot operating system;simulation;utility	Nesrine Mahdoui;Vincent Frémont;Enrico Natalizio	2017	2017 IEEE International Conference on Multisensor Fusion and Integration for Intelligent Systems (MFI)	10.1109/MFI.2017.8170426	simulation;machine learning;novelty;artificial intelligence;robot;computer science;data exchange;computation;robot kinematics	Robotics	56.172356392690276	-26.15253881728079	48245
38ab43e0647b724b663c2191227e10f5bfe8eb4f	efficient large scale slam including data association using the combined filter		In this paper we describe the Combined Filter, a judicious combination of Extended Kalman (EKF) and Extended Information filters (EIF) that can be used to execute highly efficient SLAM in large environments. With the CF, filter updates can be executed in as low as O(log n) as compared with other EKF and EIF based algorithms: O(n2) for Map Joining SLAM, O(n) for Divide and Conquer (D&C) SLAM, and O(n1.5) for the Sparse Local Submap Joining Filter (SLSJF). We also study an often overlooked problem in computationally efficient SLAM algorithms: data association. In situations in which only uncertain geometrical information is available for data association, the CF Filter is as efficient as D&C SLAM, and much more efficient than Map Joining SLAM or SLSJF. If alternative information is available for data association, such as texture in visual SLAM, the CF Filter outperforms all other algorithms. In large scale situations, both algorithms based on Extended Information filters, CF and SLSJF, avoid computing the full covariance matrix and thus require less memory, but still the CF Filter is the more computationally efficient. Both simulations and experiments with the Victoria Park dataset, the DLR dataset, and an experiment using visual stereo are used to illustrate the algorithms’ advantages.	algorithm;algorithmic efficiency;correspondence problem;dynamic language runtime;experiment;exponential integrate-and-fire;extended kalman filter;simulation;simultaneous localization and mapping;sparse;victoria (3d figure)	Cesar Dario Cadena Lerma;Fabio Tozeto Ramos;José Neira	2009			divide and conquer algorithms;kalman filter;covariance matrix;machine learning;artificial intelligence;extended kalman filter;binary logarithm;computer science	Robotics	55.1454815168788	-41.13298581473063	48263
2435223cd63fd9d0738f8d5e8bc40b106c432b7a	representation of pwm signals through time warping	frequency modulation;fourier series;phase modulation;pulse width modulation harmonic analysis educational institutions time frequency analysis frequency modulation fourier series;time warping;pwm signal generation pwm signals representation time warping pulse width modulated signal representation sign manipulation warped fourier series phase modulated sinusoids warped harmonic comprehends pwm signal zero crossing exponential components decays;fourier transforms;signal representation;signal representation fourier transforms phase modulation pulse width modulation;time frequency analysis;pulse width modulation;time warping pulse width modulation;harmonic analysis	In this work a novel approach for representing pulse width modulated (PWM) signals is introduced. PWM signals are usually represented according to the way they are generated, that is, by manipulating the sign of the comparison between the input signal and a reference wave. On the contrary, the new representation consists of a warped Fourier series, that is, a series of properly phase-modulated sinusoids, such that the zero-crossings of each warped harmonic comprehends the zero-crossing of the PWM signal. Yet, in contrast with the original signal, the spectrum of the resulting components decays exponentially, so they can be sampled at reasonable low rate while maintaining aliasing negligible. Being band-limited and keeping zero-crossings unaltered, this representation is suitable for computationally efficient PWM signal generation.	algorithmic efficiency;aliasing;bandlimiting;laguerre polynomials;pulse-width modulation;recursion;zero crossing	Salvatore Caporale;Riccardo Rovatti;Gianluca Setti	2012	2012 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	10.1109/ICASSP.2012.6288692	frequency modulation;fourier transform;pulse-frequency modulation;time–frequency analysis;computer science;dynamic time warping;harmonic analysis;control theory;pulse-width modulation;mathematics;phase modulation;fourier series	Robotics	79.96721249335451	-34.09172324984528	48324
b00f7b29e30b952529b920dc1eff812d192cf20b	extending the classical ai planning paradigm to robotic assembly planning	manipulators;grasping;spatial reasoning;uncertainty;intelligent manufacturing systems;geometric goals;planning artificial intelligence;kinematics;assembly;assembly planning;puma 762;artificial intelligence robotic assembly uncertainty robot vision systems laboratories kinematics motion planning robotics and automation manipulators intelligent manufacturing systems;spar;assembling;robots;spatial reasoning assembling planning artificial intelligence robots;robotic assembly planning;motion planning;artificial intelligence;robotic assembly;manipulation plans;world description;robot vision systems;robotics and automation;ai planning;nonlinear constraint posting planner;task planner;maximum uncertainty;nonlinear constraint posting planner ai planning robotic assembly planning spar task planner puma 762 assembly manipulation plans grasping geometric goals maximum uncertainty world description	This paper describes SPAR, a task planner that has been implemented on a PUMA 762. SPAR is capable of formulating manipulation plans to meet specified assembly goals; these manipulation plans include grasping and regrasping operations if they are deemed necessary for successful completion of assembly. SPAR goes beyond the classical AI planners, in the sense that SPAR is capable of solving geometric goals associated with high-level symbolic goals. So if a high-level symbolic goal is on(A,B), SPAR can also entertain the geometric conditions associated with such a goal. Therefore, a simple goal such as on(A,B) may or may not be found to be feasible depending on the kinematic constraints implied b y the associated geometric conditions. SPAR has available to it a user-defined repertoire of actions for solving goals and associated with each action is an uncertainty precondition that defines the mazimum uncertainty in the world description that would guarantee the successful ezecution of that action. SPAR has been implemented as a nonlinear constraint posting planner.	automated planning and scheduling;bcl-2-binding component 3;hl7publishingsubsection <operations>;high- and low-level;high-level programming language;hoc (programming language);motion planning;nonlinear system;paradigm;precondition;robot;transformation matrix;verification of theories;cell transformation	Seth A. Hutchinson;Avinash C. Kak	1990		10.1109/ROBOT.1990.125969	robot;automated planning and scheduling;kinematics;simulation;uncertainty;computer science;engineering;artificial intelligence;assembly;motion planning;spatial intelligence	Robotics	63.44243788626331	-25.754458008599123	48346
31fda7dd6c4ad0046a9623d2acc81a4e00fd6d15	development of data registration and fusion methods for measurement of ultra-precision freeform surfaces	precision metrology;data fusion;intrinsic surface features;data registration;ultra precision freeform surfaces	The measurement of ultra-precision freeform surfaces commonly requires several datasets from different sensors to realize holistic measurements with high efficiency. The effectiveness of the technology heavily depends on the quality of the data registration and fusion in the measurement process. This paper presents methods and algorithms to address these issues. An intrinsic feature pattern is proposed to represent the geometry of the measured datasets so that the registration of the datasets in 3D space is casted as a feature pattern registration problem in a 2D plane. The accuracy of the overlapping area is further improved by developing a Gaussian process based data fusion method with full consideration of the associated uncertainties in the measured datasets. Experimental studies are undertaken to examine the effectiveness of the proposed method. The study should contribute to the high precision and efficient measurement of ultra-precision freeform surfaces on multi-sensor systems.	algorithm;freeform surface modelling;gaussian process;holism;ink serialized format;instrument - device;normal statistical distribution;numerous;unification (computer science);registration - actclass;sensor (device)	Ling Bao Kong;Ming Jun Ren;Min Xu	2017		10.3390/s17051110	computer vision;computer science;engineering;data mining;sensor fusion;engineering drawing	Robotics	56.25657502717355	-42.448822076703266	48357
23155546c450e1e0ab49334a3ba48c08f81acacd	customizing painterly rendering styles using stroke processes	perceptual characteristic;stroke based rendering;reaction diffusion;point process;contrast;painterly rendering	In this paper, we study the stroke placement problem in painterly rendering, and present a solution named stroke processes, which enables intuitive and interactive customization of painting styles by mapping perceptual characteristics to rendering parameters. Using our method, a user can adjust styles (e.g., Fig.1) easily by controlling these intuitive parameters. Our model and algorithm are capable of reflecting various styles in a single framework, which includes point processes and stroke neighborhood graphs to model the spatial layout of brush strokes, and stochastic reaction-diffusion processes to compute the levels and contrasts of their attributes to match desired statistics. We demonstrate the rendering quality and flexibility of this method with extensive experiments.	algorithm;experiment	Mingtian Zhao;Song-Chun Zhu	2011		10.1145/2024676.2024698	computer vision;simulation;rendering;contrast;computer science;point process;multimedia;reaction–diffusion system;statistics;computer graphics (images)	Graphics	65.10328584258961	-47.79142731576801	48397
aa7fd2158c9a7ab9bc4fd2d1e45491958a9b7331	recursive least-squares estimation of the evolution of partials in sinusoidal analysis	performance measure;recursive least square;recursive estimation;sinusoidal modelling;least squares approximations;audio signal processing;instruments;measurement;decision directed recursive least squares estimation method;estimation method;adaptive filtering;signal analysis;recursive estimation audio signal processing least squares approximations;frequency estimation;resonance light scattering;event detection;peak detection;linear predictive;deterministic algorithm sinusoidal analysis partial tracking mechanism decision directed recursive least squares estimation method frequency amplitude tracking;adaptive filtering sinusoidal modelling partial tracking linear prediction;deterministic algorithm;multiple signal classification;recursive estimation signal analysis amplitude estimation multiple signal classification resonance light scattering frequency estimation measurement instruments coherence event detection;amplitude estimation;coherence;sinusoidal analysis;linear prediction;partial tracking;partial tracking mechanism;adaptive filter;decision directed;frequency amplitude tracking	Classic methods for sinusoidal analysis rely on partial tracking, a technique where successive sets of spectral peaks of an audio signal must be properly associated in time. The resulting tracks describe, in terms of amplitude and frequency, the continuous evolution of the so-called partials which, combined, model the complex sounds emitted by a given instrument. A well-known challenge in this context is preserving amplitude and frequency coherence in the tracking mechanism, specially in cases where failure in peak detection may occur, or perhaps in the event of crossing partials. This paper presents a new decision-directed recursive least-squares (RLS) estimation method for frequency and amplitude tracking in sinusoidal analysis. Different performance measurements show that the proposed deterministic algorithm outperforms some procedures currently found in the literature.	deterministic algorithm;recursion (computer science);recursive least squares filter	Leonardo O. Nunes;Ricardo Merched;Luiz W. P. Biscainho	2007	2007 IEEE International Conference on Acoustics, Speech and Signal Processing - ICASSP '07	10.1109/ICASSP.2007.366664	adaptive filter;computer vision;speech recognition;computer science;signal processing;pattern recognition;mathematics;statistics	Robotics	81.15901239940658	-35.766100691111674	48415
8913a5b7ed91c5f6dec95349fbc6919deee4fc75	bigbird: a large-scale 3d database of object instances	robot vision calibration cameras control engineering computing data handling mobile robots object recognition;three dimensional displays cameras calibration image color analysis sensor systems robots;multisensor calibration bigbird large scale 3d database object instance recognition computer vision shared image dataset image collection 3d information pose information object category recognition robotic tasks perception related problems mobile robots sensing based robots multicamera system data collection system software components	The state of the art in computer vision has rapidly advanced over the past decade largely aided by shared image datasets. However, most of these datasets tend to consist of assorted collections of images from the web that do not include 3D information or pose information. Furthermore, they target the problem of object category recognition - whereas solving the problem of object instance recognition might be sufficient for many robotic tasks. To address these issues, we present a high-quality, large-scale dataset of 3D object instances, with accurate calibration information for every image. We anticipate that “solving” this dataset will effectively remove many perception-related problems for mobile, sensing-based robots. The contributions of this work consist of: (1) BigBIRD, a dataset of 100 objects (and growing), composed of, for each object, 600 3D point clouds and 600 high-resolution (12 MP) images spanning all views, (2) a method for jointly calibrating a multi-camera system, (3) details of our data collection system, which collects all required data for a single object in under 6 minutes with minimal human effort, and (4) multiple software components (made available in open source), used to automate multi-sensor calibration and the data collection process. All code and data are available at http://rll.eecs.berkeley.edu/bigbird.	benchmark (computing);component-based software engineering;computer graphics;computer vision;field (computer science);file spanning;ibm notes;image resolution;instance (computer science);open-source software;point cloud;robot;taiwan fellowship editor	Arjun Singh;James Sha;Karthik S. Narayan;Tudor Achim;Pieter Abbeel	2014	2014 IEEE International Conference on Robotics and Automation (ICRA)	10.1109/ICRA.2014.6906903	computer vision;simulation;computer science;machine learning;3d single-object recognition	Robotics	54.73524805494424	-44.9672671058926	48528
9c77fe2db9cf6abb7b1c11acebd38cad1f2ea35c	distribution of the sum of clutter and thermal noise	radar detection radar clutter thermal noise weibull distribution;probability density function noise level density functional theory narrowband radar scattering radar clutter random processes distributed computing additive noise rayleigh scattering;approximation method;probability density function;rayleigh distribution amplitude probability density function approximate method weibull distributed radar clutter thermal noise clutter noise sum quadrature components in phase components joint circular symmetric density function additive noise gaussian random variables;weibull distribution;thermal noise;radar detection;radar clutter;exact distribution;density functional	The results of an approximate method for calculating the probability density function of the amplitude of the sum of Weibull-distributed radar clutter and thermal noise are compared with the exact distributions and found to be inaccurate except in one special case. It is shown how the assumption that the in-phase (I) and quadrature (Q) components of clutter have a joint circular-symmetric density function can be used to compute the density functions of the I- and Q-components themselves from the hypothesized distribution of the amplitude.	clutter;johnson–nyquist noise	Carl W. Helstrom	2000	IEEE Trans. Aerospace and Electronic Systems	10.1109/7.845265	gaussian noise;noise spectral density;weibull distribution;probability density function;electronic engineering;noise;constant false alarm rate;mathematics;clutter;optics;statistics	EDA	80.74518043937606	-43.46707817054857	48553
55170a8f9eb1ac3bb99a8fe05629d2e720a5deb6	contouring for power systems using graphical processing units	data visualization graphical processing unit power system data contouring contour rendering;real time;computer graphic equipment;power systems data visualization central processing unit concurrent computing interpolation power generation substations rendering computer graphics scattering computer graphics;gpu programming;data visualisation;power system;situation awareness;graphic processing unit;power system analysis computing;rendering computer graphics computer graphic equipment data visualisation power system analysis computing;rendering computer graphics	To improve situational awareness in power systems, one useful tool used in control centers is bus (or substation) data contouring. Traditionally, the methods developed have used CPU processing, leading to long contour rendering times that reduce interactivity with the visualization. To improve interactivity and increase the data rate which can be handled, contouring methods utilizing graphical processing units (GPU's) show much promise. This paper proposes a GPU-based contouring algorithm which can easily outperform state-of-the-art CPU-based contouring algorithms. In addition, sample rendering times for a typical power system display, along with comments on the relative advantages and disadvantages of using the CPU and GPU to perform contouring, are provided.	algorithm;central processing unit;graphical user interface;graphics processing unit;ibm power systems;interactivity;traction substation;uncompressed video	Joseph Euzebe Tate;Thomas J. Overbye	2008	Proceedings of the 41st Annual Hawaii International Conference on System Sciences (HICSS 2008)	10.1109/HICSS.2008.102	situation awareness;computer vision;tiled rendering;scientific visualization;3d rendering;computer hardware;rendering;computer science;parallel rendering;real-time computer graphics;electric power system;real-time rendering;computer graphics;alternate frame rendering;general-purpose computing on graphics processing units;data visualization;software rendering;computer graphics (images)	Visualization	70.85948607169536	-51.84999695860232	48564
978c431e5e6e6a99e43a27c9016d0335329a738c	estimation of human arm impedance in accordance with the master device types and gripping posture	telerobotics dexterous manipulators estimation theory force feedback force sensors grippers haptic interfaces;robot sensing systems;impedance;elbow;impedance force robot sensing systems elbow impedance measurement force measurement;force;impedance measurement;force measurement;teleoperation task human arm impedance estimation master device type gripping posture teleoperation system master operator impedance slave robot impedance estimation method 1 dof force sensor commercial haptic master device operator position change master feedback force	In the teleoperation system, several researches are under investigating to carry out remote task effectively by measuring or estimating master operator's impedance and transferring the impedance to slave robot. However, previously proposed method provide equal amount of impedance for different axis so the method cannot guarantee transparency. Even if accurate amount of impedance are transmitted to each orthogonal axis, there exists disadvantage that the overall teleoperation system becomes complicated. In this paper, a novel impedance estimation method is proposed by utilizing grasping posture of the master operator. The proposed teleoperation system is composed of 1-dof force sensor and a commercial haptic master device. Thus, for each posture when the operator grasps the master device, operator's impedance is transmitted to the slave robot for each direction. Two experimental tests were conducted to show its feasibility by measuring amount of operator's position change and impedance when two different kinds of master feedback force were transmitted to the operator. Moreover, during teleoperation task of opening a door, an experimental test was carried out to show the effectiveness of the proposed method by comparing constant impedance case and the proposed method.	apache axis;chaitin's constant;characteristic impedance;experiment;frequency response;haptic technology;master/slave (technology);poor posture;robot	Eun-Cheol Shin;Jee-Hwan Ryu;Gi-Hun Yang	2015	2015 IEEE International Conference on Advanced Intelligent Mechatronics (AIM)	10.1109/AIM.2015.7222798	control engineering;simulation;engineering;control theory	Robotics	71.48252866713547	-24.660879802265082	48598
9f38f1ce711ca89c6e8ff2756775c08e45901b31	fast registration based on noisy planes with unknown correspondences for 3-d mapping	metodo cuadrado menor;iterative method;simultaneous localization and mapping slam;robot sensing systems;3d mapping;methode moindre carre;least squares approximations;clutter;consensus;closed form solution;least squares method;visualizacion;iterative algorithms;normal distribution;uncertainty;point to point;localization;exact solution;systeme echantillonne;geometric consistency fast registration noisy planes 3d mapping robot pose registration large planar surface point clouds 3d sensor point to point iterative closest point algorithm 3d normal distribution transform least squares pose estimation plane parameter uncertainty plane extraction minimally uncertain maximal consensus;geometric consistency;fusion capteur;localizacion;robotics;data fusion;cartographie;solucion exacta;curva gauss;three dimensional;consistencia;3d sensor;metodo iterativo;identificacion sistema;configuration space;captador medida;posture;systeme incertain;visualization;cartografia;measurement sensor;fouillis echo;robot pose registration;point clouds;capteur mesure;localisation;plane extraction;least squares pose estimation;system identification;visualisation;consenso;methode iterative;clouds;3d normal distribution transform;fusion donnee;image registration;confusion eco;robots;field of view;consistance;least square;simultaneous localization and mapping;postura;estimacion parametro;loi normale;iterative closest point;robotica;cartography;parameter uncertainty;sistema muestreado;robustness;mapping;robotique;point cloud;plane parameter uncertainty;iterative closest point algorithm;parameter estimation;estimation parametre;sensor fusion;solution exacte;fusion datos;sistema incierto;large planar surface;planes based pose registration;simultaneous localization and mapping slam localization mapping planes based pose registration sensor fusion;uncertain system;laser modes;point to point iterative closest point algorithm;minimally uncertain maximal consensus;consistency;gaussian distribution	We present a robot-pose-registration algorithm, which is entirely based on large planar-surface patches extracted from point clouds sampled from a three-dimensional (3-D) sensor. This approach offers an alternative to the traditional point-to-point iterative-closest-point (ICP) algorithm, its point-to-plane variant, as well as newer grid-based algorithms, such as the 3-D normal distribution transform (NDT). The simpler case of known plane correspondences is tackled first by deriving expressions for least-squares pose estimation considering plane-parameter uncertainty computed during plane extraction. Closed-form expressions for covariances are also derived. To round-off the solution, we present a new algorithm, which is called minimally uncertain maximal consensus (MUMC), to determine the unknown plane correspondences by maximizing geometric consistency by minimizing the uncertainty volume in configuration space. Experimental results from three 3-D sensors, viz., Swiss-Ranger, University of South Florida Odetics Laser Detection and Ranging, and an actuated SICK S300, are given. The first two have low fields of view (FOV) and moderate ranges, while the third has a much bigger FOV and range. Experimental results show that this approach is not only more robust than point- or grid-based approaches in plane-rich environments, but it is also faster, requires significantly less memory, and offers a less-cluttered planar-patches-based visualization.	algorithm;authorization;exptime;event dispatching thread;experiment;hessian;ieee xplore;iterative closest point;iterative method;least squares;maximal set;moore–penrose pseudoinverse;point cloud;point-to-point protocol;portable document format;pose (computer vision);quadratic function;range imaging;region growing;round-off error;sensor;swiss cheese model;switzerland;viz: the computer game;ranger	Kaustubh Pathak;Andreas Birk;Narunas Vaskevicius;Jann Poppinga	2010	IEEE Transactions on Robotics	10.1109/TRO.2010.2042989	normal distribution;computer vision;mathematical optimization;visualization;computer science;point cloud;mathematics;geometry;sensor fusion;robotics;least squares;statistics	Robotics	54.02480700846282	-40.7073431359465	48622
b2a7de059587b452556b9d09ae3074d5d2a95e2a	acquiring scattering properties of participating media by dilution	oscillations;construccion arquitectura tecnologia ambiental;participating media;computacion informatica;raindrops;robust estimator;rain streak appearance;grupo de excelencia;rain streak database;computer graphic;rain rendering;ciencias basicas y experimentales;multiple scattering;monte carlo method;particle system;tecnologias;physical properties;monte carlo technique	The visual world around us displays a rich set of volumetric effects due to participating media. The appearance of these media is governed by several physical properties such as particle densities, shapes and sizes, which must be input (directly or indirectly) to a rendering algorithm to generate realistic images. While there has been significant progress in developing rendering techniques (for instance, volumetric Monte Carlo methods and analytic approximations), there are very few methods that measure or estimate these properties for media that are of relevance to computer graphics. In this paper, we present a simple device and technique for robustly estimating the properties of a broad class of participating media that can be either (a) diluted in water such as juices, beverages, paints and cleaning supplies, or (b) dissolved in water such as powders and sugar/salt crystals, or (c) suspended in water such as impurities. The key idea is to dilute the concentrations of the media so that single scattering effects dominate and multiple scattering becomes negligible, leading to a simple and robust estimation algorithm. Furthermore, unlike previous approaches that require complicated or separate measurement setups for different types or properties of media, our method and setup can be used to measure media with a complete range of absorption and scattering properties from a single HDR photograph. Once the parameters of the diluted medium are estimated, a volumetric Monte Carlo technique may be used to create renderings of any medium concentration and with multiple scattering. We have measured the scattering parameters of forty commonly found materials, that can be immediately used by the computer graphics community. We can also create realistic images of combinations or mixtures of the original measured materials, thus giving the user a wide flexibility in making realistic images of participating media.		Srinivasa G. Narasimhan;Mohit Gupta;Craig Donner;Ravi Ramamoorthi;Shree K. Nayar;Henrik Wann Jensen	2006	ACM Trans. Graph.	10.1145/1141911.1141986	simulation;mathematics;optics;statistics;monte carlo method;computer graphics (images)	Graphics	61.08554759471789	-51.77033231206393	48709
ac74a182becd8732cd0590175b41e468e572a21d	object's tracking by advection of a distance map	object s tracking;image matching;motion estimation;distance map;object tracking;advection;data assimilation;image sequences	This paper has two coupled objectives: estimating motion and tracking a given object on an image sequence. It relies on a data assimilation approach, that solves evolution equations of motion, those of image brightness, and those of the distance map modeling the object's boundary. The two last express the optical flow constraint, which assumes that image brightness and distance map are advected by velocity. The method assimilates contour points by an innovative approach combining two criteria. First, the boundary of the object should match contour points at acquisition dates; second, the control of the distance between each pixel and the object's boundary allows to better motion estimation on the whole domain. The method is tested on synthetic data and satellite acquisitions.	data assimilation;distance transform;motion estimation;optical flow;pixel;synthetic data;the last express;velocity (software development)	Yann Lepoittevin;Isabelle Herlin;Dominique Béréziat	2013	2013 IEEE International Conference on Image Processing	10.1109/ICIP.2013.6738745	computer vision;mathematical optimization;data assimilation;advection;computer science;video tracking;motion estimation;geometry;distance transform	Robotics	54.616227005997125	-49.90432459817118	48725
8596b80e7473afabeb533ccd9042712dc6a059e3	positive time-frequency distributions via maximum entropy deconvolution of the evolutionary spectrum	evolutionary spectrum;unit energy normalization;energy density;spectrogram;integral equations;time frequency;time frequency analysis entropy spectral analysis;envelope function;time frequency analysis entropy deconvolution spectrogram yield estimation frequency estimation integral equations density functional theory interactive systems laboratories;frequency estimation;spectrum;marginal densities evolutionary spectrum evolutionary densities unit energy normalization envelope function maximum entropy deconvolution;yield estimation;density functional theory;evolutionary densities;deconvolution;entropy;spectral analysis;marginal densities;interactive systems;time frequency analysis;maximum entropy;time frequency distribution;maximum entropy deconvolution	"""This material is posted here with permission of the IEEE. Internal or personal use of this material is permitted. However, permission to reprint/republish this material for advertising or promotional purposes or for creating new collective works for resale or redistribution must be obtained from the IEEE by sending a blank email message to info.pub.permission@ieee.org. By choosing to view this document, you agree to all provisions of the copyright laws protecting it. Abstract The relationship between Priestley's definition of the evolutionary spectrum (ES) and the Cohen-Posch class of positive time-frequency energy densities (TFDs) is explored, and a synthesis method is presented. As defined by Priestley, the ES is not a member of the Cohen-Posch class of TFDs. However, it is shown that by choosing a unit-energy normalization for the envelope function of Priestley's formulation, the """" energetic """" ES thus obtained is a member of the Cohen-Posch class of TFDs; this nor-malization differs from that chosen by Priestley. A method is then presented to obtain an estimate of the energetic ES. This method employs maximum entropy deconvolution of the spectrogram, which is itself a blurred version of the ES. Because the energetic ES is everywhere nonnegative and yields the correct marginal densities, it is a legitimate, joint time-frequency energy density of the signal, unlike the Wigner and other bilinear distributions that go negative."""	bilinear filtering;choose (action);copyright;deconvolution;email;marginal model;spectrogram;density	Patrick J. Loughlin	1993		10.1109/ICASSP.1993.319688	mathematical optimization;time–frequency analysis;calculus;mathematics;statistics	Vision	82.50106977883038	-30.161911640720998	48735
5c218d28d358fc596a8583b4cc8aaaf2ee1c0fac	new stiff-flop module construction idea for improved actuation and sensing	software;manipulators;sensors;electrical and electronic engineering;force;liquids;shape;sensors manipulators force shape friction liquids;artificial intelligence;robot vision biomedical mri manipulators medical robotics;friction;control and systems engineering;arm construction stiff flop manipulator module construction actuation improvement sensing improvement mri compatibility medical soft robot projects soft silicone manipulator	MRI compatibility, which often is a requirement for the new medical soft robot projects, greatly reduces available actuation methods and sensors. An example of such project is STIFF-FLOP, which aims to develop a soft silicone manipulator actuated by pressure. The current arm construction and method of actuation cause several undesirable effects, which pose problems for actuation and sensing. In this paper, the authors identify the source of those negative effects and propose improvements over the current construction to eliminate or limit their influence. The new construction concept is tested and compared with the current one. Possible ideas for further development are also proposed.	cylinder seal;flip-flop (electronics);robot;sensor	Jan Fras;Jan Czarnowski;Mateusz Macias;Jakub Glówka;Matteo Cianchetti;Arianna Menciassi	2015	2015 IEEE International Conference on Robotics and Automation (ICRA)	10.1109/ICRA.2015.7139595	control engineering;simulation;shape;engineering;sensor;artificial intelligence;friction;control theory;force;quantum mechanics;mechanical engineering	Robotics	74.99588366774101	-24.866457437880513	48846
83898fad67e39255203df72db6299d0524f0551b	automatically generating large urban environments based on the footprint data of buildings	urban environment;roof modelling;high resolution;straight skeleton;model generation;data capture;virtual environments;three dimensional;automatic generation;aerial image;virtual environment	This paper focuses on the generation of three dimensional models of large urban/suburban environments. Previous work on the reconstruction of particular environments is based on multiple overlapping aerial or street level images. Unfortunately these approaches do not extend well to large environments. The main reasons for this are that they require expensive high-resolution aerial images and a labour intensive modelling or data capture procedure. Consequently methods have been developed to generate large urban environments based on environmental data such as elevation data or building footprints. This permits the model to be based on actual data for the area being modelled and at a cost far less than that of aerial images. By reducing the data given to the model generation procedure various parameters are undetermined. These include roof style and textured appearance. This paper focuses on the use of building footprint information to construct a three dimensional model. It uses LIDAR data to give the buildings a height value and assigns them a roof using new techniques for roof modelling.	3d modeling;aerial photography;image resolution	R. G. Laycock;Andrew M. Day	2003		10.1145/781606.781663	three-dimensional space;computer vision;simulation;image resolution;virtual machine;automatic identification and data capture;straight skeleton;mathematics;geometry	Graphics	58.14445281996774	-45.39890918580963	48872
bb438f4d1c97a4d9335415ae23c0dea0efb4a684	a single frame depth visual gyroscope and its integration for robot navigation and mapping in structured indoor environments	robot localization;tecnologia industrial tecnologia mecanica;tecnologia electronica telecomunicaciones;kalman filter;orthogonal planes extraction;vanishing point;tecnologias;grupo a;depth visual gyroscope	An accurate navigation system is an essential and important part for the mobile robot. The recent appearance of low cost RGBD cameras has made 3D point clouds together with RGB information easy accessible, and they have been widely applied in many applications. Relative poses of a mobile robot can be estimated from consecutive visual information. However, such incremental registration methods still suffer from accumulated errors which makes the estimated trajectory as weird as by only using wheel mounted encoders. In contrast, we introduce a novel and inexpensive sensor fusion based approach to solve the robot localization problem. The key idea is to use visual gyroscope as a complementary source for robot heading estimation. Aided with constraints, the unscented Kalman filter is used for robot pose estimation. A field experiment has been carried out in order to verify the introduced method. Accordingly, the 3D map of the environment is also presented based on the estimated robot trajectory.	course (navigation);encoder;gyroscope;kalman filter;mobile robot;point cloud;robotic mapping;sensor;simultaneous localization and mapping;vanishing point	Cheng Chen;Wennan Chai;H. Roth	2014	2014 IEEE International Conference on Autonomous Robot Systems and Competitions (ICARSC)	10.1007/s10846-014-0167-x	kalman filter;embedded system;monte carlo localization;computer vision;simulation;vanishing point;computer science;engineering;mobile robot navigation;robot calibration	Robotics	55.2515540576425	-38.020600418571995	48889
b8e55998d77f76c092ad596631c2e88e72fe41c0	decomposition of the ebi signal into components using two channel cross-compensating singular spectrum analysis		The paper describes a decomposition method of the Electrical Bioimpedance (EBI) signal into its components, in general, into cardiac and respiratory components respectively. Two-channel approach with cross-compensation is proposed in combination with the Singular Spectrum Analysis (SSA), which is applied for each channel individually. Moreover, a grouping algorithm of the SSA components is proposed, which is based on the cardiac signal periodicity and on the trajectory matrix features. The proposed algorithm is processing the EBI signal by frames of 9 seconds duration and can be extended for continuous EBI signal. The proposed algorithm makes possible to separate the cardiac and respiratory components of the total EBI signal in non-stationary conditions and with partially overlapping spectra of the cardiac and respiratory components.	algorithm;external bus interface;quasiperiodicity;selection algorithm;stationary process;waveform;xslt/muenchian grouping	Andrei Krivoshei;Mart Min;Paul Annus;Maksim Butsenko	2018	2018 IEEE International Symposium on Medical Measurements and Applications (MeMeA)	10.1109/MeMeA.2018.8438702	decomposition method (constraint satisfaction);spectral line;singular spectrum analysis;matrix (mathematics);control theory;mathematics;communication channel	Embedded	80.17094998114551	-38.35459286384382	48954
4458fb8c4f15b5b7ce76c9513ce3d45a56a33ec4	surface waves for active transport of bedridden patients	bedridden patient;periodic circular motion;manipulators;kinematic analysis;active transport;prototypes;wave equations;actuators;mobile robots;orbital robotics;kinematics;kinematics natural wave transport periodic circular motion bedridden patient surface wave distributed actuation actuators;surface waves robot kinematics mobile robots actuators medical services orbital robotics prototypes injuries pain manipulators;handicapped aids;surface wave;medical services;natural wave transport;surface wave distributed actuation;transportation;injuries;pain;surface waves;kinematics handicapped aids transportation actuators wave equations;robot kinematics;modeling and analysis	Natural surface waves, created by periodic circular motion of material particles, can transfer a long object placed upon the crests of the waves in an arbitrary direction within the horizontal plane. Inspired by this natural behavior, a surface wave distributed actuation method and its potential for transporting bedridden patients is explored in this paper. First, the basic principle of surface wave distributed actuation is presented, followed by kinematic modeling and analysis. Based on the analysis, modifications to natural wave transport are made to enhance transport efficiency and human comfort. Further kinematic analysis reveals that an object can be transferred by a simplified actuator architecture that makes the concept amenable to hardware realization. Finally, design trade-offs and guidelines for developing a feasible and practical surface wave bed are discussed based on the prototyping and experiments.	surface wave	Joseph Spano;H. Harry Asada	2000		10.1109/ROBOT.2000.844112	structural engineering;control engineering;simulation;surface wave;computer science;engineering;artificial intelligence	Vision	74.04128761675018	-24.70968633296552	48958
91a598366ef31da032a9c8e11487911001b62587	a new method of cepstrum analysis by using comb lifter	fluctuations;transfer functions;signal analysis;speech analysis;cepstrum cepstral analysis frequency speech analysis signal analysis poles and zeros transfer functions fluctuations radio access networks;poles and zeros;cepstral analysis;cepstrum;frequency;radio access networks	This paper describes the use of comb lifter in the Cepstrum analysis which is usefull for extraction of formant frequencies. Good result is obtained with Han lifter in case of low pitch frequency. But, in case of high pitch frequency, the separation of two formants is sometimes impossible. The comb lifter is presented to overcome this difficulty, that is, the length of the lifter is fixed so as to separate the closest formants, and the peaks in the cepstrum due to the periodicity of speech are suppressed by using comb lifter. Successful results have been obtained in the experiments using two types of comb lifter. A new type of adaptive lifter is also presented which does not need the pitch detection and is useful in case of connected speech.	cepstrum;comb filter	Gen Ooyama;Sigeru Katagiri;Ken'iti Kido	1978		10.1109/ICASSP.1978.1170476	pole–zero plot;speech recognition;computer science;frequency;cepstrum;signal processing;transfer function	Robotics	80.96492382109975	-33.93323913001311	48998
4f6d03604c8a58e73032ef6277d16a2d929f229a	dimension reduction on polyspheres with application to skeletal representations		We present a novel method that adaptively deforms a polysphere (a product of spheres) into a single high dimensional sphere which then allows for principal nested spheres (PNS) analysis. Applying our method to skeletal representations of simulated bodies as well as of data from real human hippocampi yields promising results in view of dimension reduction. Specifically in comparison to composite PNS (CPNS), our method of principal nested deformed spheres (PNDS) captures essential modes of variation by lower dimensional representations.		Benjamin Eltzner;Sungkyu Jung;Stephan Huckemann	2015		10.1007/978-3-319-25040-3_3	combinatorics;topology;geometry	NLP	56.54392228241579	-50.71454964353231	49036
d4eb8fc1be5ad28be89217146337b828924952bb	improved formulation of the imu and marg orientation gradient descent algorithm for motion tracking in human-machine interfaces		Wearable motion tracking systems are becoming increasingly popular in human-machine interfaces. For inertial measurement, it is vital to efficiently fuse inertial, gyroscopic, and magnetometer data for spatial orientation. We introduce a new algorithm for this fusion based on using gradient descent to correct for the integral error in calculating the orientation quaternion of a rotating body. The algorithm is an improved formulation of the well-known estimation of orientation using a gradient descent algorithm. The new formulation ensures that the gradient descent algorithm uses the steepest descent, resulting in a five order of magnitude increase in the precision of the calculated orientation quaternion. We have also converted the algorithm to use fixed point integers instead of floating point numbers to more than double the speed of the calculations on the types of processors used with Inertial Measurement Units (IMUs) and Magnetic, Angular Rate and Gravity sensors (MARGs). This enables the corrections to not only be faster than the original formulations, but also remain valid for a larger range of inputs. The improved efficiency and accuracy show significant potential for increasing the scope of inertial measurement in applications where low power or greater precision is necessary such as very small wearable or implantable systems.	algorithm;central processing unit;fixed point (mathematics);gradient descent;gyroscope;sensor;tracking system;user interface;wearable computer;whole earth 'lectronic link	Marcel Admiraal;Samuel Wilson;Ravi Vaidyanathan	2017	2017 IEEE International Conference on Multisensor Fusion and Integration for Intelligent Systems (MFI)	10.1109/MFI.2017.8170354	computer vision;artificial intelligence;floating point;inertial measurement unit;angular velocity;computer science;inertial frame of reference;gradient descent;fixed point;gyroscope;control theory;match moving	Robotics	58.2864798733172	-37.21487188906911	49053
637efbc98f8045789680eb36693f3a34b98a2c4e	hospital nurse following robot: hardware development and sensor integration	ultrasonic sensor bank;hardware development;mobile hospital robot;sensor integration;obstacle avoidance;hospital nurse following robot;working paper;article	Hospital nurse regularly bring her instrument to the patient using cart. They need to push or pull the cart to the patient bed and bring it back many times in a day. This can be tiresome for nurses because they need to treat many patients in the hospital. This research is mainly to solve this problem by constructing a mobile robot for nurses that is able to follow and carry the medical equipment and at the same time perform obstacle avoidance. The designed robot has ability to move in and out at constricted space and is able to avoid any obstacles either static or dynamic. This robot can carry a load of 20 kg and used dc geared motor to move. The mobile platform is able to rotate at axial axis with the construction of special wheel and the placement of the motor. A suitable ultrasonic sensor bank is selected so that robot can detect obstacle around the mobile platform and avoid the obstacle. The robot control and obstacle avoidance system is designed by adopting the facilities of Basic ATOM microcontrolle...	robot	Bukhari Ilias;R. Nagarajan;M. Murugappan;Khaled Helmy;Awang Sabri Awang Omar;Muhammad Asyraf Abdul Rahman	2014	IJMEI	10.1504/IJMEI.2014.058521	embedded system;simulation;computer science;artificial intelligence;obstacle avoidance	Robotics	72.80458549866455	-25.19389193793879	49082
95cd61347d7bd3d7a3040e60c36f74d3a2b75b08	a dynamic-model-based wheel slip detector for mobile robots on outdoor terrain	modelo dinamico;modelizacion;robot movil;nonlinear filters;tyres braking global positioning system kalman filters mobile robots nonlinear filters robot dynamics traction;dynamique vehicule;detectors;medida velocidad;immobilization;extended kalman filter ekf;tire traction model;wheel slip extended kalman filter ekf mobile robots robot terrain interaction;mobile robot;measurement units;autonomous system;immobilisation;immobilized condition detection;wheels detectors mobile robots orbital robotics tires global positioning system vehicle dynamics force measurement velocity measurement measurement units;systeme gps;dynamic model;kalman filters;inertial navigation;model based approach;aplicacion espacial;mobile robots;mesure vitesse;roue;robotics;derapage;rueda;indexing terms;autonomous mobile robot;gps system;orbital robotics;dynamic model based wheel slip detector;sistema autonomo;inertial measurement unit;pneumatique;vehicle dynamic forces;filtre kalman etendu;modelisation;captador medida;systeme incertain;speed measurement;measurement sensor;capteur mesure;gps;robot mobile;wheel slip;braking;global positioning system;robot terrain interaction;side slip;traction;gps dynamic model based wheel slip detector autonomous mobile robots outdoor terrain immobilized condition detection tire traction model tire braking model vehicle dynamic forces extended kalman filter framework robot velocity wheel encoders inertial measurement unit;autonomous mobile robots;space robotics;modele dynamique;systeme autonome;navegacion por inercia;robotteknik och automation;tyres;navigation inertie;force measurement;robotica;freinage;filtro kalman extendido;tires;neumatico;robotique;extended kalman filter framework;robot velocity;extended kalman filter;robot dynamics;velocity measurement;sistema incierto;wheel;modeling;tire braking model;tyre;wheel encoders;uncertain system;inmovilizacion;application spatiale;vehicle dynamics;moving robot;derrapaje;space application;dinamica vehiculo;sistema gps	This paper introduces a model-based approach to estimating longitudinal wheel slip and detecting immobilized conditions of autonomous mobile robots operating on outdoor terrain. A novel tire traction/braking model is presented and used to calculate vehicle dynamic forces in an extended Kalman filter framework. Estimates of external forces and robot velocity are derived using measurements from wheel encoders, inertial measurement unit, and GPS. Weak constraints are used to constrain the evolution of the resistive force estimate based upon physical reasoning. Experimental results show the technique accurately and rapidly detects robot immobilization conditions while providing estimates of the robot's velocity during normal driving. Immobilization detection is shown to be robust to uncertainty in tire model parameters. Accurate immobilization detection is demonstrated in the absence of GPS, indicating the algorithm is applicable for both terrestrial applications and space robotics.	algorithm;autonomous robot;encoder;extended kalman filter;global positioning system;immobiliser;mobile robot;robotic spacecraft;robotics;sensor;terrestrial television;traction teampage;velocity (software development)	Chris C. Ward;Karl Iagnemma	2008	IEEE Transactions on Robotics	10.1109/TRO.2008.924945	control engineering;simulation;global positioning system;computer science;engineering;artificial intelligence;control theory;robotics	Robotics	57.627700326549196	-35.06145864689535	49123
d93b91a371befc20a073a4971d07053e26e52c27	rendering of spherical light fields	modified significance map;incremental decoding technique spherical light field rendering plenoptic function parameterized function light flow image based rendering systems representation scheme spherical coordinates lumigraph object space algorithm polygonal rendering system 3d graphics boards primitive functionality smooth shading encoding scheme wavelets data compression lumigraph data compression ratios multi resolutional representation future applications modified significance map;add on boards;primitive functionality;image coding;multi resolutional representation;data compression;smooth shading;light flow;plenoptic function;light field;computer graphic equipment;lumigraph;image based rendering systems;polygonal rendering system;wavelet transforms;representation scheme;rendering system;future applications;image representation;spherical coordinates;compression ratios;object space algorithm;compression ratio;3d graphics boards;incremental decoding technique;image based rendering;multi resolution;spherical light field rendering;lumigraph data;rendering computer graphics;wavelets;encoding scheme;3d graphics;wavelet transforms rendering computer graphics image representation add on boards computer graphic equipment image coding data compression image sequences;parameterized function;rendering computer graphics layout image generation computer science encoding sampling methods decoding testing computer graphics ray tracing;image sequences	A plenoptic function is a parameterized function describing the flow of light in space, and has served as a key idea in building some of the recent image-based rendering systems. This paper presents a new representation scheme, called a spherical light field, of the plenoptic function, that is based on spheres. While methods using spherical coordinates are thought to require substantially more computation than those using planar or cylindrical coordinates, we show that spheres can also be used efficiently in representing and resampling the flow of light. Our image-based rendering algorithm is different from the previous systems, the light field and lumigraph, in that it is an “object-space” algorithm that can be easily embedded into the traditional polygonal rendering system. Our method is easily accelerated by 3D graphics boards that support the primitive functionality, such as viewing and smooth shading. In addition, we introduce an encoding scheme based on wavelets for compression of the huge data resulting from sampling of the spherical light field. The proposed technique can be easily adapted to compress the light field and lumigraph data, and offers as high compression ratios as the previous methods. Furthermore, it naturally creates a multi-resolutional representation of the light flow that can be exploited effectively in the future applications. We show how to access the compressed data efficiently using a modified significance map and an incremental decoding technique, and report experimental results on several test data sets.	3d computer graphics;algorithm;computation;data compression;embedded system;geographic coordinate system;light field;line code;rendering (computer graphics);sampling (signal processing);shading;test data;wavelet	Insung Ihm;Sanghoon Park;Rae Kyoung Lee	1997		10.1109/PCCGA.1997.626172	computer vision;image-based modeling and rendering;rendering;computer science;theoretical computer science;compression ratio;mathematics;statistics;3d computer graphics;computer graphics (images)	Graphics	67.40615233751066	-50.12757486261465	49236
547398ebb3785b7e243d4c64a49df3d4f93d657b	reconfigurable wireless control system for a dual-arm cooperative robotic system		Dual-arm robots have large potentials in many fields, including automobile, aerospace, consumer electronics, and so on. However, the design of the coordinated controller is very challenging, since it is required to meet the real-time computation need of much more complex planning and control algorithm. Moreover, there exist a large number of cables for traditional design between the arms and the controller, resulting in inconveniences for installation, debugging, maintenance, updating, and so on. In this paper, we developed a reconfigurable wireless control system for a dual-arm cooperative robotic system to solve the above problems. It was designed as a distributed multi-layer system, consisting of a coordinated controller, two motion controllers corresponding to the two arms, and ZibBee wireless communication modules. The specific functions of each layer were defined. The processors of each layer are redundant and can be backed up for each other. The ZibBee modules establish the communication between the arm motion controller and the servo controllers of the joints. Furthermore, a human-machine interface, i.e. an interactive 3D graphic program OSG, was also developed. The virtual work environment together with the geometry model of a dual-arm robot was created by OSG in the PC. Finally, semi-physical simulations and prototype experiments were completed. Results show that the developed dual-arm cooperative control system has good stability and high reliability.	3d computer graphics;algorithm;backup;central processing unit;coat of arms;computation;consensus dynamics;control system;debugging;existential quantification;experiment;graphics software;layer (electronics);motion controller;open science grid consortium;openscenegraph;prototype;real-time clock;robot;semiconductor industry;servo;simulation;user interface;virtual work	Liang Han;Xiangliang Cheng;Wenfu Xu;Guodeng Tan	2017	2017 IEEE International Conference on Robotics and Biomimetics (ROBIO)	10.1109/ROBIO.2017.8324418	control theory;control engineering;electronics;debugging;engineering;robot kinematics;motion controller;servo;servomotor;control system	Robotics	64.56206402111404	-29.3430367320825	49252
706de3d3aac38409cddcf0dda05edce304c45f35	design, development and preliminary assessment of a force sensor for robotized medical applications	telerobotics bending strength compliant mechanisms control system synthesis finite element analysis force sensors medical robotics needles radiology robot kinematics shear modulus;force sensor constraints force sensor design force sensor development force sensor assessment robotized medical applications needle insertion interventional radiology flexural element design rigid body equivalent compliant model flexural element fem analysis force sensor prototype calibration experimental force sensor prototype validation force profile force variation force sensor requirements;force sensors needles force strain robot sensing systems force measurement;medical robotics mechatronics sensors and sensing systems	This paper presents the design, development and the preliminary assessment of a force sensor designed for robotized medical applications. The requirements and constraints for the force sensor are derived from the targeted application of needle insertion in the context of interventional radiology. These constraints rule out the feasibility of commercially available force sensors necessitating the design of a novel force sensor. A discussion on the various force sensing principles utilized in medical robotics and the choice of a suitable sensible principle is done. Next, the solution principles are offered for the design of the flexural element. Starting from the rigid body equivalent, a compliant model of the flexural element is obtained. Simulation using FEM analysis is utilized to verify that the force sensor indeed satisfies the requirements and the constraints of the targeted application. Finally, the calibration and the experimental validation of the force sensor prototype is done using a realistic force profile showing actual force variation during needle insertion.	apache axis;experiment;finite element method;haptic technology;hysteresis;item unique identification;mathematical model;prototype;radiology;requirement;robotics;sensor;simulation;steam rupture;test bench	Nitish Kumar;Olivier Piccin;Laurence Meylheuc;Laurent Barbé;Bernard Bayle	2014	2014 IEEE/ASME International Conference on Advanced Intelligent Mechatronics	10.1109/AIM.2014.6878273	structural engineering;control engineering;engineering;mechanical engineering	Robotics	74.41834845624466	-26.78308237212194	49320
21ee1cefae4103f4ee9b6b296a37de87435cc43f	an optimal path-tracking algorithm for unstructured environments based on uncalibrated vision	estimation vision camera space manipulation;structured light;three dimensional;camera space manipulation;optimal path;estimation;industrial robots;image analysis;computational geometry service robots coatings welding plasma temperature spraying plasma applications robot vision systems testing optical arrays;vision;path tracking	This paper presents aspects related to the development of a technique for three-dimensional path tracking over unstructured surfaces. Path tracking is performed by an industrial robot, using a vision-based technique known as camera-space manipulation. In this work a previously-defined, three-dimensional trajectory is placed, in an optimal fashion, over a curved, unstructured surface. The method was tested with an industrial Fanuc ArcMate 100i robot, together with structured lighting in the form of a matrix array of laser beams. Such source of light provides a way to facilitate the image-analysis process required to characterize the surface where the task is going to be performed. A demanding industrial task such as welding was performed with the methodology presented herein. Experimental results show a complex path welded over a surface of unknown geometry.	algorithm;image analysis;industrial robot;robot welding;structured light	Emilio J. González-Galván;Ambrocio Loredo-Flores;J. Jesus Cervantes-Sanchez;Felipe Pazos-Flores	2005	Proceedings of the 2005 IEEE International Conference on Robotics and Automation	10.1109/ROBOT.2005.1570496	control engineering;three-dimensional space;vision;computer vision;estimation;image analysis;simulation;structured light;computer science;engineering	Robotics	61.65744569462013	-35.814821473458494	49367
3aac92ed6b4bc5b44a82cb5881be87a502761e0f	surgical manipulator with balloon for stabilizing fetus in utero under ultrasound guidance	relative position;stabilizer;3d imaging;ultrasound;standard deviation;myelomeningocele;ultrasound imaging;intrauterine fetal surgery;balloon;ultrasound guidance;in utero	This paper describes a surgical manipulator to stabilize intrauterine fetus with ultrasound image guidance. The manipulator includes an outline of 4 mm in diameter, a mechanism with 7 joints, and a set of balloons. The manipulator is arranged as straight form and the balloon is fold to be a minimum size before the insertion. Accuracy evaluation of bending performance showed that the standard deviations were ±3.6 degrees on wired-driven mechanism and ±1.6 degrees on linkage-driven mechanism. Experimental results also demonstrated high repeatability of the mechanisms. In feasibility experiments, ultrasound images in 2D and 3D modes were examined for guiding the manipulator. The 2D images provided wide view and easily viewable display of the balloon inflation. The 3D images provided easily viewable display of bending motion of the arm and the relative position of a phantom. It is possible to operate the manipulator in utero under the ultrasound guidance in 2D and 3D by switching them in each procedural stage.	3d computer graphics;experiment;fold (higher-order function);imaging phantom;linkage (software);medical ultrasound;performance;prototype;repeatability;shepp–logan phantom	Noriaki Yamanaka;Hiromasa Yamashita;Kiyoshi Matsumiya;Hongen Liao;Ken Masamune;Toshio Chiba;Takeyoshi Dohi	2008		10.1007/978-3-540-79982-5_29	radiology;engineering;biological engineering;surgery	Robotics	73.55000842299728	-29.031216295050726	49381
2937031e39933eb894f9d517f9a01576a165dddc	high quality time-scale modification of speech using a peak alignment overlap-add algorithm (paola)	time scale;audio signal processing;speech synthesis;computational saving high quality time scale modification peak alignment overlap add algorithm paola speech passage duration audio time scale modification time domain overlapping synthesis frames peak alignment technique synchronization;peak alignment overlap;speech processing;paola;speech modification;time domain analysis;synchronisation;speech processing time domain analysis synchronisation speech synthesis audio signal processing;time domain;frequency synchronization frequency domain analysis signal synthesis equations time domain analysis signal analysis degradation speech enhancement natural languages telephony	The duration of a speech passage can be altered using audio time-scale modification techniques. Time-scale modification can be achieved in the time domain by segmenting the input signal into overlapping frames and recombining the frames with an overlap differing from the analysis overlap. We present a time-scale modification algorithm that uses a simple peak alignment technique to synchronize overlapping synthesis frames. The peak alignment overlap-add (PAOLA) algorithm also takes advantage of waveform properties to ensure a high quality output for the minimum number of iterations. The new algorithm produces a time-scaled output of approximately equal quality to that of an adaptive implementation of the commercially popular synchronised overlap-add (SOLA) algorithm, but offers a computational saving ranging from a factor of 15 (for a time-scale factor of 0.5) to 170 (for a time-scale factor of 1.1).	algorithm;approximation;computation;display resolution;iteration;overlap–add method;waveform	David Dorran;Robert Lawlor;Eugene Coyle	2003		10.1109/ICASSP.2003.1198877	synchronization;real-time computing;speech recognition;audio signal processing;time domain;computer science;speech coding;speech processing;speech synthesis	Comp.	80.53903303183313	-33.83250178285627	49389
bd7ac4bb97e7241f1d7b0a8a383e74fa7d914939	a hand-held instrument to maintain steady tissue contact during probe-based confocal laser endomicroscopy	biological tissues;high resolution;confocal endomicroscopy;pcle;phantoms;tissue characterization;closed loop systems;adaptive control;feature tracking;tissue characterization confocal endomicroscopy force adaptive control hand held imaging probe pcle;actuators;instrument force control handheld instrument steady tissue contact probe based confocal laser endomicroscopy intraoperative tissue characterization contact force pcle probe image consistency linear voice coil actuator donut load cell mechanical design system level modeling closed loop force control bench testing physiological movement involuntary hand movement pcle video feature tracking colonic crypt mucosal surface;force;probes;hand held imaging probe;manganese;in vivo imaging;laser applications in medicine;portable instruments benchmark testing biological tissues biomedical optical imaging closed loop systems endoscopes feature extraction force control laser applications in medicine;feature extraction;endoscopes;force adaptive control;force probes force control manganese actuators phantoms;aberrant crypt foci animals colon colonic neoplasms endoscopy equipment design humans image processing computer assisted intestinal mucosa lasers microscopy confocal models biological phantoms imaging surgery computer assisted swine;portable instruments;biomedical optical imaging;mechanism design;benchmark testing;force control	Probe-based confocal laser endomicroscopy (pCLE) provides high-resolution in vivo imaging for intraoperative tissue characterization. Maintaining a desired contact force between target tissue and the pCLE probe is important for image consistency, allowing large area surveillance to be performed. A hand-held instrument that can provide a predetermined contact force to obtain consistent images has been developed. The main components of the instrument include a linear voice coil actuator, a donut load-cell, and a pCLE probe. In this paper, detailed mechanical design of the instrument is presented and system level modeling of closed-loop force control of the actuator is provided. The performance of the instrument has been evaluated in bench tests as well as in hand-held experiments. Results demonstrate that the instrument ensures a consistent predetermined contact force between pCLE probe tip and tissue. Furthermore, it compensates for both simulated physiological movement of the tissue and involuntary movements of the operator's hand. Using pCLE video feature tracking of large colonic crypts within the mucosal surface, the steadiness of the tissue images obtained using the instrument force control is demonstrated by confirming minimal crypt translation.	actuator device component;animal model;body tissue;coil device component;confocal laser endomicroscopy;experiment;galaxy morphological classification;human factors and ergonomics;image resolution;medical device incompatibility problem;minimally invasive surgical procedures;mobile device;modulus robot;motion estimation;movement;mucous membrane;necrosis;neoplasms;preclinical imaging;real-time data;sentinel lymph node biopsy;simulation;video-in video-out;voice coil;science of ergonomics	Win Tun Latt;Richard Newton;Marco Visentini Scarzanella;Christopher J. Payne;David P. Noonan;Jianzhong Shang;Guang-Zhong Yang	2011	IEEE Transactions on Biomedical Engineering	10.1109/TBME.2011.2162064	mechanism design;pathology;adaptive control;feature extraction;computer science;engineering;manganese;biological engineering;optics;force;physics	Robotics	73.13277527154474	-29.037626665223744	49410
d34586c4be52a71aa14fc2eb17f5596f7d023124	emotion embodiment in robot-assisted rehabilitation system using hybrid automata	ta164 bioengineering;actuators;emotion recognition;automata;rehabilitation platform hybrid automata emotion embodiment;computational modeling;grippers;patient rehabilitation automata theory medical robotics;automata grippers computational modeling actuators emotion recognition muscles;ta engineering general civil engineering general;muscles;hybrid automata emotion embodiment robot assisted rehabilitation system	The embodiment of emotions in the paper is structured under hybrid automata framework. In particular, the paper focuses on the description of the automata model designed for robot-assisted rehabilitation system in term of its initialization value, modes, condition for each mode, guard conditions, and transition between modes. A structured experimental setup was designed to evaluate the performance of the hybrid automata proposed. The result demonstrates the efficacy of hybrid automata approach in the rehabilitation application where emotion of the subject is taken into consideration in deploying suitable rehabilitation tasks.	automata theory;guard (computer science);hybrid automaton;robot;simulation;software deployment	Shahrul Naim Sidek;Aimi Shazwani Ghazali;Saodah Wok	2014	2014 IIAI 3rd International Conference on Advanced Applied Informatics	10.1109/IIAI-AAI.2014.106	simulation;engineering;artificial intelligence;communication	Robotics	70.14493750571641	-25.862439790213767	49447
f597bdb6de05c25c6dee605a21eafea19a06fa50	obstacle detection model implementation based on information fusion of ultrasonic and vision		Obstacle Avoidance plays an important role in robotics, which is widely used in advanced technologies. This paper adopts the ultrasonic obstacle detection model with circle buffers and the visual obstacle detection model with ObstacleWheel data structure. Besides, an obstacle detection model based on information fusion is proposed to collect environment information and calculate the confidence of obstacles in real time after ultrasonic and vision information are fused. Moreover, experiments are designed in obstacle avoidance system of NAO. The result reveals that the obstacle detection model based on information fusion performs better than either of the sensor models.	data structure;experiment;nao (robot);obstacle avoidance;real-time clock;robotics;velocity obstacle	Jimin Wang;Qijun Chen	2016	2016 IEEE International Conference on Real-time Computing and Robotics (RCAR)	10.1109/RCAR.2016.7784028	computer vision;simulation;engineering;communication	Robotics	53.9850668337154	-33.06654691108938	49487
23e90432e2aedd673c1b2ecd9c90d07fcc4e8ad0	hair modeling using kinect sensors and dslr cameras	kinect sensors hair modeling particle system spline representation;sensors;geometry;three dimensional displays;image reconstruction;image resolution image reconstruction;solid modeling;hidden hair pieces recovery algorithm 3d hair reconstruction kinect sensors dslr cameras hair modeling field 2d images hair capture methods digital single lens reflex camera particle system high resolution image alignment techniques spline curve 3d control points;cameras;hair three dimensional displays cameras sensors image reconstruction solid modeling geometry;hair	3D Hair reconstruction based on real-life hair capture is an important and challenging work in hair modeling field. Most of existing hair capture methods use 2D images to reconstruct 3D hair, and these methods usually adopt 3D polygons to present hair wisp. In this paper, we introduce an approach to capture real-life hair using Kinect sensor and digital single-lens reflex (DSLR) camera and to reconstruct 3D hair model using particle system. First, our method collects four views of point clouds and high resolution image for real-life hair. We register DSLR image and point cloud to build the mapping relationship between 2D and 3D and the alignment techniques are utilized to merge the point clouds. With the manually extracted 2D hair strands from the DSLR image, the system used control points to represent hair strands as spline curve. Furthermore, these control points are projected on the point cloud to find the corresponding 3D control points. Finally the system reconstructs 3D hair model where the strands are represented in particle system. We also present a hidden hair pieces recovery algorithm to generate final well-connected 3D hair strands. Our method is novel and has many advantages: (i) hardware setting is simple and affordable (ii) combination of high quality image of DSLR and depth of Kinect taking advantage of each of them (Hi) the 2D and 3D combined method allows us to repair and improve the quality of 3D depth (iv) Hair representation is spline based which is a particle system and most common hair animation is based on particle system.	algorithm;digital single-lens reflex camera;display resolution;image resolution;kinect;music download;particle system;point cloud;real life;sensor;spline (mathematics);wisp	Zhongrui Li;Chao Sun;Won-Sook Lee;Ig-Jae Kim	2014	2014 11th International Conference on Ubiquitous Robots and Ambient Intelligence (URAI)	10.1109/URAI.2014.7057514	iterative reconstruction;computer vision;simulation;sensor;solid modeling;computer graphics (images)	Graphics	57.85850765219611	-48.42706827497113	49494
46077944d3ed2fbfc3f401d4ba4afa852a0c4fb6	real time lidar and radar high-level fusion for obstacle detection and tracking with evaluation on a ground truth		Both Lidars and Radars are sensors for obstacle detection. While Lidars are very accurate on obstacles positions and less accurate on their velocities, Radars are more precise on obstacles velocities and less precise on their positions. Sensor fusion between Lidar and Radar aims at improving obstacle detection using advantages of the two sensors. The present paper proposes a real-time Lidar/Radar data fusion algorithm for obstacle detection and tracking based on the global nearest neighbour standard filter (GNN). This algorithm is implemented and embedded in an automative vehicle as a component generated by a real-time multisensor software. The benefits of data fusion comparing with the use of a single sensor are illustrated through several tracking scenarios (on a highway and on a bend) and using real-time kinematic sensors mounted on the ego and tracked vehicles as a ground truth.	algorithm;autonomous car;embedded system;ground truth;kalman filter;radar;real time kinematic;real-time clock;real-time transcription;sensor web	Hatem Hajri;Mohamed-Cherif Rahal	2018	CoRR		control engineering;computer vision;engineering;kinematics;radar;obstacle;sensor fusion;ground truth;lidar;artificial intelligence	Robotics	54.246902588067464	-36.085297669550144	49562
1e2363a264bfa8d3c2cfa98f48e4a46f43d5ad6b	a simple method to obtain visual attention data in head mounted virtual reality	virtual reality;omnidirectional visual content;360 degree images and video;visual attention;fixation maps	Automatic prediction of salient regions in images is a well developed topic in the field of computer vision. Yet, virtual reality omnidirectional visual content brings new challenges to this topic, due to a different representation of visual information and additional degrees of freedom available to viewers. Having a model for visual attention is important to continue research in this direction. In this paper we develop such a model for head direction trajectories. The method consists of three basic steps: First, a computed head angular speed is used to exclude the parts of a trajectory where motion is too fast to fixate viewer's attention. Second, fixation locations of different subjects are fused together, optionally preceded by a re-sampling step to conform to the equal distribution of points on a sphere. Finally, a Gaussian based filtering is performed to produce continuous fixation maps. The developed model can be used to obtain ground truth experimental data when eye tracking is not available.	angularjs;computer vision;eye tracking;ground truth;map;sampling (signal processing);virtual reality	Evgeniy Upenik;Touradj Ebrahimi	2017	2017 IEEE International Conference on Multimedia & Expo Workshops (ICMEW)	10.1109/ICMEW.2017.8026231	computer science;angular velocity;experimental data;artificial intelligence;computer vision;omnidirectional antenna;filter (signal processing);eye tracking;ground truth;virtual reality;trajectory	Visualization	54.23873111248131	-42.760479290650125	49641
f65d27013e70017b53fd57afd4d01992a18153a2	on constructing rags via homogeneous splines	splines on triangulations;piecewise rational function;homogeneous geometry;arbitrary topological genus;unstructured mesh;homogeneous spline	Piecewise rational functions, called rational geometric splines (or RAGS), are studied.RAGS are suitable for representing surfaces of arbitrary genus and continuity.A construction of parametric homogeneous splines is proposed.Interpolation and approximation methods for constructing smooth splines are presented.It is shown how homogeneous splines can be used to obtain RAGS. Recently, a construction of spline spaces suitable for representing smooth parametric surfaces of arbitrary topological genus and arbitrary order of continuity has been proposed. These splines, called RAGS (rational geometric splines), are a direct generalization of bivariate polynomial splines on planar triangulations. In this paper we discuss how to construct parametric splines associated with the three homogeneous geometries (spherical, affine, and hyperbolic) and we also consider a number of related computational issues. We then show how homogeneous splines can be used to obtain RAGS. As examples of RAGS surfaces we consider direct analogs of the Powell-Sabin macro-elements and also spline surfaces of higher degrees and higher orders of continuity obtained by minimizing an energy functional.	spline (mathematics)	Carolina Vittoria Beccari;Marian Neamtu	2016	Computer Aided Geometric Design	10.1016/j.cagd.2016.02.010	mathematical optimization;topology;mathematics;geometry;box spline	EDA	69.03026087333454	-42.03610694411464	49643
8e1fd329a820af15e69437266fa6d8a77fe2cbdc	a 3d ir camera with variable structured light for home service robots	robot sensing systems;digital mirror device;mirrors;variable structure;robot vision systems cameras service robots humans robustness lighting costs optical reflection robot sensing systems mirrors;optical reflection;real time;service robots;structured light;3d sensor;service robot;robustness;structured light 3d sensor infrared light digital mirror device;humans;lighting;infrared;infrared light;high performance;high speed;robot vision systems;cameras	There has shown a significant interest in a high performance of, at the same time, a compact size and low cost of, 3D sensor, in reflection of a growing need of 3D environmental sensing for service robotics. One of the important requirements associated with such a 3D sensor is that sensing does not irritate or disturb human in any way while working in close and continuous contact with human. Furthermore, such a 3D sensor should be reliable and robust to the change of environmental illumination as service robots are required to work day and night. This paper presents a 3D IR camera with variable structured light that is human friendly and robust enough for application to home service robots. Infrared is chosen as the sensing medium in order to meet the requirement of human friendliness and robustness to illumination change. A Digital Mirror Device (DMD) is employed to generate and project variable patterns at a high speed for real-time operation. In implementation, we emphasize the integration of modular components to support real-time sensing and compactness in size. A number of real-world experimentations are conducted, including a human face, a statue, and a plastic model. The experimental results have demonstrated that the implemented 3D IR Camera is robust to illumination change, in addition to its advantage of human friendliness.	3d scanner;day and night (cellular automaton);kinetic data structure;real-time clock;real-time transcription;requirement;robot;robotics;structured light	Sukhan Lee;Jongmoo Choi;Seungmin Baek;Byungchan Jung;Changsik Choi;Hunmo Kim;Jeongtaek Oh;Seungsub Oh;DaeSik Kim;Jaekeun Na	2005	Proceedings of the 2005 IEEE International Conference on Robotics and Automation	10.1109/ROBOT.2005.1570384	computer vision;simulation;infrared;computer science;engineering;optics	Robotics	60.27032255280697	-37.88380650081598	49822
a51131eaa49deff6a05f6a84a063f594d809b558	a novel tactile device considering nail function for changing capability of tactile perception	tactile device;chip;touch enhancing;tactile perception;nail	"""Nails are not just an instrument to protect fingers and scratch an object. They improve our tactile sensitivity. In this paper, a novel tactile device considering nail function, which we call a """"tactile nail chip,"""" is proposed. This device is mounted on the nail and deforms the nail to change the capability of tactile perception. The effectiveness of the tactile nail chip is supported by results through psychophysical experiments. Then, the effect is discussed through photoelasticity experiment and analysis using a simple nail model. In addition, the tactile nail chip with adjustable function is presented."""		Yoshihiro Tanaka;Akihito Sano;Mayumi Ito;Hideo Fujimoto	2008		10.1007/978-3-540-69057-3_69	computer vision;engineering;communication;surgery	Robotics	75.56474208890704	-26.61056748139596	49848
18e6d559de5884657399ae21a373dd37bf37e421	a general approach to spatiotemporal calibration in multisensor systems	sensor synchronization;clocks;spatial displacement spatiotemporal calibration multisensor system sensor fusion domain specific heuristics spatial transformation temporal offsets continuous time batch estimation maximum likelihood estimation robotics inertial measurement unit stereo camera laser range finder;sensor fusion maximum likelihood estimation robots;estimation;synchronization;calibration cameras synchronization estimation clocks robot vision systems;sensor fusion;robot vision systems;calibration;multisensor calibration;cameras	With growing demands for accuracy in sensor fusion, increasing attention is being paid to temporal offsets as a source of deterministic error when processing data from multiple devices. Established approaches for the calibration of temporal offsets exploit domain-specific heuristics of common sensor suites and utilize simplifications to circumvent some of the challenges arising when both temporal and spatial parameters are not accurately known a priori. These properties make it difficult to generalize the work to other applications or different combinations of sensors. This work presents a general and principled approach to joint estimation of temporal offsets and spatial transformations between sensors. Our framework exploits recent advances in continuous-time batch estimation and thus exists within the rigorous theoretical framework of maximum likelihood estimation. The derivation is presented without relying on unique properties of specific sensors and, therefore, represents the first general technique for temporal calibration in robotics. The broad applicability of this approach is demonstrated through spatiotemporal calibration of a camera with respect to an inertial measurement unit as well as between a stereo camera and a laser range finder. The method is shown to be more repeatable and accurate than the current state of the art, estimating spatial displacements to millimeter precision and temporal offsets to a fraction of the fastest measurement interval.	fastest;heuristic (computer science);robotics;sensor web;stereo camera	Jörn Rehder;Roland Siegwart;Paul Timothy Furgale	2016	IEEE Transactions on Robotics	10.1109/TRO.2016.2529645	synchronization;computer vision;estimation;calibration;simulation;computer science;sensor fusion;statistics;remote sensing	Robotics	54.774261622126076	-38.57040815768562	49892
16c6fa08e7130fd784ae5a6fec5bdc607d7d7099	an inexpensive 3d camera	hand held device;digital camera;3d camera;3d shape acquisition	We describe the implementation of a portable 3D-camera prototype based on a consumer grade digital camera and an inexpensive laser raster generator. Such hand-held device can be used to capture smooth shapes by acquiring one or more images. Its output can be either a 3D wireframe or a textured model.	digital camera;mobile device;prototype;stereo camera;wire-frame model	Askold V. Strat;Manuel Menezes de Oliveira Neto	2002		10.1145/1242073.1242159	smart camera;stereo camera;computer vision;camera auto-calibration;camera resectioning;computer hardware;computer science;computer graphics (images)	Graphics	59.06181471477128	-48.650026654734155	49895
e990089c30472d304f35be373b1b221811e9cc2b	r-one swarm robot: developing the accelerometer and gyroscope	multi robots;robotics;r one	Mobile robots are becoming more relevant and an essential part of our everyday lives. They are increasingly taking their place in service oriented applications including domestic and entertainment roles. They are beginning to open up many potential opportunities, but they still come with challenges in terms of their limited sensing capability and accuracy. In this project, we addressed these fundamental problems with mobile robotics and demonstrate our approach to each of the problems with a mobile robot equipped with low cost and low end devices. The r one swarm robot is a low cost multi robot systems platform that is advanced enough for multi robot research, robust enough for undergraduate and graduate education and cheap enough for K 12 outreach. As robots become more and more useful, multiple robots working together on a single task will become commonplace. Many of the most useful applications of robots are particularly well suited to this “swarm” approach. Groups of robots can perform these tasks more efficiently, and can perform them in fundamentally different ways than robots working individually. However, swarms of robots are difficult to program and coordinate.	gyroscope;mobile robot;oneswarm;robotics;swarm	Ebrima Jobe;James McLurkin;Chutima Boonthum-Denecke	2012			mobile robot;swarm robotics;simulation;ant robotics;computer science;artificial intelligence;social robot;robot combat;self-reconfiguring modular robot;robotics;personal robot;aisoy1	Robotics	64.94146201985748	-28.72918840076074	49966
3f30582217ecec0336ed9538c0348ebcde138a59	topological volume skeletonization using adaptive tetrahedralization	global isosurface transition;topology;level set graph;interpolation;art;topological isosurface transition;top down;degenerate features;global skeleton;topological criterion;level set;computational geometry;skeleton isosurfaces interpolation art computer science data visualization data mining large scale systems acceleration rendering computer graphics;feature tracking;large scale data;isosurfaces;data mining;adaptive tetrahedralization;skeleton;acceleration;data visualisation;large scale;small amplitude noise;topological features topological volume skeletonization adaptive tetrahedralization level set graph 3d scalar field global isosurface transition large scale data small amplitude noise top down approach linear interpolation topological criterion geometric criterion topological isosurface transition global skeleton feature tracking degenerate features;degeneration;linear interpolation;data visualization;scalar field;geometric criterion;top down approach;topological volume skeletonization;3d scalar field;computer science;image thinning;rendering computer graphics;topological features;data visualisation image thinning topology interpolation computational geometry rendering computer graphics;large scale systems	Topological volume skeletons represent level-set graphs of 3D scalar fields, and have recently become crucial to visualizing the global isosurface transitions in the volume. However, it is still a time-consuming task to extract them, especially when input volumes are large-scale data and/or prone to small-amplitude noise. The paper presents an efficient method for accelerating the computation of such skeletons using adaptive tetrahedralization. The tetrahedralization is a top-down approach to linear interpolation of the scalar fields in that it selects tetrahedra to be subdivided adaptively using several criteria. As the criteria, the method employs a topological criterion as well as a geometric one in order to pursue all the topological isosurface transitions that may contribute to the global skeleton of the volume. The tetrahedralization also allows us to avoid unnecessary tracking of minor degenerate features that hide the global skeleton. Experimental results are included to demonstrate that the present method smoothes out the original scalar fields effectively without missing any significant topological features.	adaptive histogram equalization;approximation algorithm;automatic control;computation;experiment;gradient;ibm notes;image noise;isosurface;linear interpolation;smoothing;subdivision surface;top-down and bottom-up design;topological derivative	Shigeo Takahashi;Gregory M. Nielson;Yuriko Takeshima;Issei Fujishiro	2004	Geometric Modeling and Processing, 2004. Proceedings	10.1109/GMAP.2004.1290044	computer vision;topology;computer science;top-down and bottom-up design;mathematics;geometry;data visualization;statistics	Visualization	71.47743473659065	-44.81030477968131	49990
529672c3c7fc1e40b89d3dad1e432785488e0417	subdivision surfaces with creases and truncated multiple knot lines	solid and object representations;nurbs;crease;surface;b spline;subdivision;multiple knot;i 3 5 computer graphics computational geometry and object modelling curve	We deal with subdivision schemes based on arbitrary degree B-splines. We focus on extraordinary knots which exhibit various levels of complexity in terms of both valency and multiplicity of knot lines emanating from such knots. The purpose of truncated multiple knot lines is to model creases which fair out. Our construction supports any degree and any knot line multiplicity and provides a modelling framework familiar to users used to B-splines and NURBS systems.	algorithm;basis function;complexity;expectation propagation;non-uniform rational b-spline;null (sql);reflections of signals on conducting lines;smoothing;subdivision surface;t-spline;vertex (geometry)	Jirí Kosinka;Malcolm A. Sabin;Neil A. Dodgson	2014	Comput. Graph. Forum	10.1111/cgf.12258	b-spline;combinatorics;finite subdivision rule;t-spline;topology;non-uniform rational b-spline;subdivision;knot;mathematics;geometry;surface	Vision	69.18796004670006	-42.41207050531149	50061
4e1ab1ecf3d09e5da8ce482fce1bfb3882dad286	automatic analyzing of a weaving design with the spatial frequency components	design process;spatial frequency	In the textile design process, textile samples are often copied for reference. In these cases, weaving information is required to produce copies of that textile. This information includes the thread placement of the stripe patterns, the weaving design that shows the intersecting and twisting conditions, and the textile's density. In the past, these tasks replied on manual labor, which took a long time and was the source of error. Therefore, a method for extracting information on a weaving design from the patterns on the textile's surface with the objective of automating a part of the textile design process is proposed.		Ken'ichi Ohta;Yoshito Nonaka;Fujio Miyawaki	1995		10.1007/3-540-60697-1_152	design process;computer science;spatial frequency	EDA	73.12107492225336	-38.35081853891572	50074
a74ad46f5d7eb3872ea6badd207f263900162fa4	an overview of physicomimetics	esquiva colision;reseau capteur;multiagent system;surveillance;robotics;commande repartie;surveillance drones;physics;liquids;gases;vigilancia;red sensores;obstacle avoidance;monitoring;fault tolerance;robots;sensor array;robotica;control;collision avoidance;robotique;monitorage;control repartido;behavior;esquive collision;sistema multiagente;microminiaturization;monitoreo;self organizing systems;distributed sensing;distributed control;ecoulement polyphasique;multiphase flow;systeme multiagent;solids;flujo polifasico;automation	This paper provides an overview of our framework, called physicomimetics, for the distributed control of swarms of robots. We focus on robotic behaviors that are similar to those shown by solids, liquids, and gases. Solid formations are useful for distributed sensing tasks, while liquids are for obstacle avoidance tasks. Gases are handy for coverage tasks, such as surveillance and sweeping. Theoretical analyses are provided that allow us to reliably control these behaviors. Finally, our implementation on seven robots is summarized.	distributed control system;handy board;obstacle avoidance;physicomimetics;robot	William M. Spears;Diana F. Spears;Rodney Heil;Wesley Kerr;Suranga Hettiarachchi	2004		10.1007/978-3-540-30552-1_8	fault tolerance;simulation;computer science;artificial intelligence;automation;obstacle avoidance;robotics;sensor array;behavior	Robotics	58.534609335990325	-31.65179715505093	50093
f0babfdfc22c9bd183ca7e435471f0940a0e7f8f	3d depth information extraction with omni-directional camera	structured light;infrared laser;depth measurement;omni directional image;real time systems	This paper presents a novel 3D depth information extraction method without calibration. Firstly, this paper develops an omni-directional 3D camera system, which consists of a CCD camera, hyperbolic mirror, infrared laser diodes and diffractive of element (DOE). Secondly, a depth measurement model is proposed to obtain the 3D depth information. Finally, in order to calculate the speckle shift accurately between the reference image and the object image, a dot matrix pattern and sequence coding algorithm are designed to find the corresponding speckles in the two images. Experimental results show that the reconstructed depth data have a good correlation with the actual distance. The accuracy of the data is also found to be influenced by the distance between the object and the camera. A novel omni-directional 3D camera framework is proposed.The omni-directional camera and infrared dot matrix structured light can be merged.The model can reveal the relation between the object depth and its pixel offset.We can obtain the pixel offset with the sequence coding algorithm.	information extraction	Tong Jia;Yan Shi;ZhongXuan Zhou;Dongyue Chen	2015	Inf. Process. Lett.	10.1016/j.ipl.2014.09.029	computer vision;camera auto-calibration;camera matrix;camera resectioning;structured light;computer science;measured depth;far-infrared laser;pinhole camera model;depth map;computer graphics (images)	DB	56.12139373667146	-49.12644973136558	50157
a7e1664936d0e6108f2ee84aea565d59d60ab454	communication expressive de la forme au travers de l'éclairement et du rendu au trait. (expressive shape depiction through shading and lines)		Expressive rendering aims at designing algorithms that allow to control the way images are created. More precisely, it provides the possibility to convey a specific message using a given style, even if non-physically based techniques have to be used. In this thesis, we propose a formalization for expressive rendering, by decomposing it into a message to convey in a 3D scene, and the style used to create the final image. We will concentrate our work on two topics that have a same message : object shape enhancement on dynamic scenes. In the first part of this thesis, we propose new solutions for exaggerating surface details through shading. We show how to extract relevant surface features by taking the human visual system into account. Our approach then allows to detect view-dependant surface details and provides automatic levels-of-detail on dynamic scenes. This message is used for modifying the way lights interact with 3D objects and for creating various styles, from minimal black and white toon shading to realistic rendering. In the second part of this thesis, we propose a new approach for conveying surface details using line-based rendering. We show that all kind of lines may be extracted via a single general definition, in a temporally and spatially coherent way. Next, we show how to apply an implicit stylization along the detected features, in order to obtain various styles and original effects. We discuss the limitations of both techniques in the third part of the thesis. We show that our perception of appearance is an essential element that have to be taken into account in future work. Messages and styles could evoluate in a more coherent and intuitive model. Key-Words : Expressive rendering, Non-photorealistic rendering, Shape enhancement, Line-based rendering.		Romain Vergne	2010				Graphics	63.15192209608526	-48.96431412806892	50165
87447c27f17ad3262535633dfa0c1707ecde138e	blink-spot projection method for fast three-dimensional shape measurement	structured light;3d shape measurement;high speed image processing;camera projector system		projection method (fluid dynamics)	Jun Chen;Qingyi Gu;Tadayoshi Aoyama;Takeshi Takaki;Idaku Ishii	2015	JRM	10.20965/jrm.2015.p0430	structured-light 3d scanner;computer vision;optics;computer graphics (images)	Theory	60.51572432411898	-47.56683098921636	50214
63ef09842172dbb1b6dd73127a8800b32a26767f	exploiting mirrors in interactive reconstruction with structured light	structured light	This paper describes how a mirror can be integrated as another view and another source of light patterns in an interactive reconstruction system with structured light, where the object, the camera, and the mirror can move. We show how a single pass of structured light can provide 3D points to accurately estimate the pose of a mirror, while also reconstructing 3D points on the object. We develop new structured light patterns that are unaffected by the reversed order created by some mirror configurations. We also describe hardware rendering support to avoid conflicting emitted/captured light patterns, and demonstrate how all the proposed realizations extend naturally for multiple mirror configurations. We finally conclude with results, discuss limitations, and suggest further improvements.	structured light	Emric Epstein;Martin Granger-Piché;Pierre Potilin	2004			computer vision;computer science;rendering (computer graphics);artificial intelligence;structured light	Vision	58.56143888076825	-50.28433193148835	50243
58506f9c31cd72bcf6cbf0a88eaa7b182d7b70ce	a two-speed actuator for robotics with fast seamless gear shifting	torque;impedance;robot dynamics actuators gears power transmission mechanical;actuators;force;gears;robots;brakes;linear actuator two speed actuator robotics seamless gear shifting gear ratio powertrain low pass filter dual speed dual motor architecture dynamic model;actuators gears robots brakes torque impedance force	In many applications, robots have to bear large loads while moving slowly and also have to move quickly through the air with almost no load. This leads to conflicting requirements for their actuators. Multiple gear ratios, like in a powertrain, address this issue by allowing an effective use of power over a wide range of output speed. However in robotics, as opposed to powertrains, the controlled load is not always inertial and acting as a low-pass filter; hence gear shifting is a more challenging issue in a robotics context. In this paper, it is proposed to address this problem using a dual-speed dual-motor architecture to maintain full control of the output during gear shifting. A dynamic model is developed and a controller using the redundancy of motors is proposed to enable fast seamless gear shifting even when interacting with unknown dynamic environments. Results are demonstrated with a proof-of-concept linear actuator.	characteristic impedance;controller (computing);dynamic systems development method;interaction;intrinsic function;iteration;low-pass filter;mathematical model;nonlinear system;prototype;requirement;robot;robotics;seamless3d	Alexandre Girard;H. Harry Asada	2015	2015 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)	10.1109/IROS.2015.7354047	robot;control engineering;gear;engineering;artificial intelligence;electrical impedance;automotive engineering;control theory;non-circular gear;torque;force;brake;actuator	Robotics	70.45237116885559	-24.44178311057829	50287
0d4bcb492bd3dd52b20374bce95ea16c32635a2a	manifolds' projective approximation using the moving least-squares (mmls)		In order to avoid the curse of dimensionality, frequently encountered in Big Data analysis, there was a vast development in the field of linear and non-linear dimension reduction techniques in recent years. These techniques (sometimes referred to as manifold learning) assume that the scattered input data is lying on a lower dimensional manifold, thus the high dimensionality problem can be overcome by learning the lower dimensionality behavior. However, in real life applications, data is often very noisy. In this work, we propose a method to approximate a d-dimensional Cm+1 smooth submanifoldM residing in Rn (d << n) based upon scattered data points (i.e., a data cloud). We assume that the data points are located ”near” the noisy lower dimensional manifold and perform a non-linear moving least-squares projection on an approximating manifold. Under some mild assumptions, the resulting approximant is shown to be infinitely smooth and of high approximation order (i.e., O(hm+1), where h is the fill distance and m is the degree of the local polynomial approximation). Furthermore, the method presented here assumes no analytic knowledge of the approximated manifold and the approximation algorithm is linear in the large dimension n.	admissible rule;approximation algorithm;curse of dimensionality;data point;moving least squares;nonlinear dimensionality reduction;nonlinear system;order of approximation;polynomial;real life;tag cloud	Barak Sober;David Levin	2016	CoRR		mathematical optimization;combinatorics;topology;mathematics;geometry;statistics;manifold alignment	ML	62.65117657851873	-42.094863668213634	50288
70032f5d497f8c13b407f3b778310e30a0b2fb93	parallel algorithms for line detection on a 1×n array processor	parallel algorithms orbital robotics parallel robots robot vision systems parallel processing concurrent computing image processing image analysis service robots shape;parallel algorithm;concurrent computing;image processing;service robots;computerised pattern recognition;line detection;indexing terms;orbital robotics;cellular arrays;computer vision;robot vision;shape;parallel robots;ais 5000;computational complexity;straight line detection;parallel vision computer;transforms;mesh arrays;image analysis;hough transform;mesh arrays straight line detection parallel algorithms computational complexity hough transform 1 n array processors ais 5000 parallel vision computer;transforms cellular arrays computational complexity computer vision computerised pattern recognition parallel algorithms;robot vision systems;parallel processing;1 n array processors;parallel algorithms	A description is given of two algorithms that compute the Hough transform for straight lines on N*N images using 1*N processing arrays. The algorithms are developed for 1*N array processors and have been implemented on the AIS-5000 parallel vision computer. The complexity of both algorithms is O(N/sup 2/+PN) on the 1*N array processor (P is the number of angles polled which determines the theta -resolution of the Hough space), which compares well with the known optimal O(N+P) algorithms for N*N mesh arrays. >	array processing;edge detection;parallel algorithm;vector processor	Ze-Nian Li;Frank Tong;Robert G. Laughlin	1991		10.1109/ROBOT.1991.131539	parallel processing;computer vision;image analysis;concurrent computing;image processing;computer science;theoretical computer science;machine learning;parallel algorithm	Robotics	61.00033742175185	-38.21656828000503	50319
0fe2010a5607dbbef7d76f4fa6220d2c01260256	free-form deformation with rational dms-spline volumes	direct manipulation;rational dms spline volume;control lattice of arbitrary topology;free form deformation;geometric model;multiresolution deformation	In this paper, we propose a novel free-form deformation (FFD) technique, RDMS-FFD (Rational DMS-FFD), based on rational DMS-spline volumes. RDMS-FFD inherits some good properties of rational DMS-spline volumes and combines more deformation techniques than previous FFD methods in a consistent framework, such as local deformation, control lattice of arbitrary topology, smooth deformation, multiresolution deformation and direct manipulation of deformation. We first introduce the rational DMS-spline volume by directly generalizing the previous results related to DMS-splines. How to generate a tetrahedral domain that approximates the shape of the object to be deformed is also introduced in this paper. Unlike the traditional FFD techniques, we manipulate the vertices of the tetrahedral domain to achieve deformation results. Our system demonstrates that RDMS-FFD is powerful and intuitive in geometric modeling.	b-spline;computer animation;direct manipulation interface;free-form deformation;geometric modeling;interaction;newton's method;relational database management system;solid modeling;spline (mathematics);spline wavelet	Gang Xu;Guozhao Wang;Xiao-Diao Chen	2008	Journal of Computer Science and Technology	10.1007/s11390-008-9182-3	mathematical optimization;computer science;geometric modeling	Vision	68.16708792205992	-45.45349488466709	50326
02185fefbb714994d2a3ff7489e32bde35a8c81a	human/robot interaction for human support system by using a mobile manipulator	manipulators;design engineering;dynamic model;manipulator dynamics;service robots;mobile robots;human robot interaction;force;support system;mobile communication humans force manipulator dynamics robot kinematics;mobile communication;humans;human robot interaction mobile manipulator dynamic model human support modes singularity manipulability;mobile manipulator;service robots design engineering human robot interaction manipulators mobile robots;robot kinematics	This paper shows how to use a mobile manipulator as a human support to assist human on accomplishing some complicated tasks. Dynamic model and control of the mobile manipulator are introduced. Two kinds of human support modes are designed by considering singularity, manipulability and safety of the whole system. Experimental results implemented on a mobile manipulator validate the proposed methods.	human–robot interaction;mobile manipulator;singularity project	Yunyi Jia;Hai Wang;P. Sturmer;Ning Xi	2010	2010 IEEE International Conference on Robotics and Biomimetics	10.1109/ROBIO.2010.5723325	human–robot interaction;control engineering;mobile robot;parallel manipulator;simulation;mobile telephony;computer science;artificial intelligence;mobile manipulator;control theory;force;robot kinematics	Robotics	68.23670594063992	-25.605857404890312	50333
7e53f25f4eead9f7e24f9356898f2f12d4420a80	teleoperated micromanipulation system manufactured by cut-and-fold techniques	cutting hydraulic systems industrial manipulators microassembling microfabrication micromanipulators robotic assembly telerobotics;teleoperated micromanipulation system manufacturing cut and fold slave micromanipulator hydraulic mechanism microobject manipulation feature fabrication folded machines wearable robots microrobotics;exoskeletons thumb micromanipulators indexes;micromanipulators rapid prototyping telerobotics;thumb;indexes;exoskeletons;telerobotics micromanipulators rapid prototyping;micromanipulators	We present a new teleoperated micromanipulation system in which all units of the system, wearable user interface devices and a slave micromanipulator, are manufactured by engraving, cutting, and folding two-dimensional materials. The designed manipulation system employs a simple hydraulic mechanism consisting of pairs of syringes that have different diameters, which allows for motion reduction and physical interaction between the master and the slave. As a result, users can precisely manipulate micro-objects without tremor, which was previously difficult with bare hands. This paper presents design considerations and features fabrication methods, performance metrics of this creative manipulation system, and a range of high-level micromanipulation abilities such as pick-and-place, microseparation, and three-dimensional microassembly. Highlighting rapid design and fabrication of a low-cost precision micromanipulation system, this paper proposes new applications of folded machines to wearable robots and microrobotics.	high- and low-level;human–computer interaction;microbotics;powered exoskeleton;robot;smt placement equipment;user interface;wearable computer	Sehyuk Yim;Shuhei Miyashita;Daniela Rus;Sangbae Kim	2017	IEEE Transactions on Robotics	10.1109/TRO.2016.2636904	control engineering;database index;embedded system;simulation;exoskeleton;computer science;engineering	Robotics	73.3748730132411	-25.072352901810206	50337
15cb2263caf26ac68906858093ae8d7749ad7827	evaluating the roomba: a low-cost, ubiquitous platform for robotics research and education	control engineering education;robot sensing systems;monte carlo localization;software testing;protocols;roomba vacuum;spatial reasoning;robotics ducation;fastslam;fastslam ubiquitous platform robotics research robotics ducation roomba vacuum spatial reasoning monte carlo localization;robotics research;educational robots;computer science education;slam robots control engineering education monte carlo methods robots;robots;sensors and actuators;indoor environments;bluetooth;educational robots robot sensing systems robotics and automation computer science education monte carlo methods indoor environments hardware software testing protocols bluetooth;slam robots;ubiquitous platform;robotics and automation;monte carlo methods;hardware	This paper presents the iRobot corporation's Roomba vacuum as a low-cost resource for robotics research and education. Sensor and actuation models for unmodified Roombas are presented in the context of both special- and general-purpose spatial-reasoning algorithms, including Monte Carlo Localization and FastSLAM. Further tests probe the feasibility of sensor extensions to the platform. Results demonstrate that, with some caveats, the Roomba is a viable foundation for both classroom and laboratory use, especially for work seeking to leverage robots to other ends, as well as robotics per se with a computational focus.	algorithm;computation;general-purpose modeling;monte carlo localization;robot;robotics;simultaneous localization and mapping	Ben Tribelhorn;Zachary Dodds	2007	Proceedings 2007 IEEE International Conference on Robotics and Automation	10.1109/ROBOT.2007.363179	robot;embedded system;monte carlo localization;communications protocol;simulation;computer science;engineering;artificial intelligence;software testing;spatial intelligence;bluetooth;educational robotics;monte carlo method	Robotics	65.20065690176713	-28.81275417999412	50343
2d8d49c2d36ff2490e891d5df974459236919efe	automatic self-calibration of a full field-of-view 3d n-laser scanner		This paper describes the design, build, automatic self-calibration and evaluation of a 3D Laser sensor using conventional parts. Our goal is to design a system, which is an order of magnitude cheaper than commercial systems, with commensurate performance. In this paper we adopt point cloud “crispness” as the measure of system performance that we wish to optimise. Concretely, we apply the information theoretic measure known as Rényi Quadratic Entropy to capture the degree of organisation of a point cloud. By expressing this quantity as a function of key unknown system parameters, we are able to deduce a full calibration of the sensor via an online optimisation. Beyond details on the sensor design itself, we fully describe the end-to-end extrinsic parameter calibration process, the estimation of the clock skews between the four constituent microprocessors and analyse the effect our spatial and temporal calibrations have on point cloud quality.	clock skew;end-to-end principle;information theory;mathematical optimization;microprocessor;point cloud	Mark Sheehan;Alastair Harrison;Paul Newman	2010		10.1007/978-3-642-28572-1_12	order of magnitude;point cloud;mixture model;control engineering;calibration;engineering;laser;laser scanning;field of view	Robotics	56.085138317081416	-42.36340723570639	50370
5429de15f18e19f6fe9bbc71ef5b1c71f78d1ba9	information based indoor environment robotic exploration and modeling using 2-d images and graphs	tecnologia industrial tecnologia mecanica;image processing;map building;mobile robot;localization;slam;feature tracking;grupo de excelencia;mobile robots;iterative algorithm;information presentation;level of detail;indoor environment;service robot;mobile robot localization;geometric model;panoramic image;graph model;tecnologias;information theory;mellin transform	As the autonomy of personal service robotic systems increases so has their need to interact with their environment. The most basic interaction a robotic agent may have with its environment is to sense and navigate through it. For many applications it is not usually practical to provide robots in advance with valid geometric models of their environment. The robot will need to create these models by moving around and sensing the environment, while minimizing the complexity of the required sensing hardware. Here, an information-based iterative algorithm is proposed to plan the robot’s visual exploration strategy, enabling it to most efficiently build a graph model of its environment. The algorithm is based on determining the information present in sub-regions of a 2-D panoramic image of the environment from the robot’s current location using a single camera fixed on the mobile robot. Using a metric based on Shannon’s information theory, the algorithm determines potential locations of nodes from which to further image the environment. Using a feature tracking process, the algorithm helps navigate the robot to each new node, where the imaging process V. A. Sujan Advanced Controls Division, Cummins Engine Company, Columbus, IN 47201 e-mail: vivek.a.sujan@cummins.com M. A. Meggiolaro Department of Mechanical Engineering, Pontifical Catholic University of Rio de Janeiro, Rio de Janeiro 22453-900, RJ-Brazil e-mail: meggi@alum.mit.edu F. A. W. Belo Department of Electrical Engineering, Pontifical Catholic University of Rio de Janeiro, Rio de Janeiro 22453-900, RJ-Brazil e-mail: felipe-belo@uol.com.br is repeated. A Mellin transform and tracking process is used to guide the robot back to a previous node. This imaging, evaluation, branching and retracing its steps continues until the robot has mapped the environment to a pre-specified level of detail. The set of nodes and the images taken at each node are combined into a graph to model the environment. By tracing its path from node to node, a service robot can navigate around its environment. This method is particularly well suited for flat-floored environments. Experimental results show the effectiveness of this algorithm.	algorithm;autonomous robot;columbus;electrical engineering;email;graph (discrete mathematics);information theory;iterative method;level of detail;mobile robot;motion estimation;registered jack;requirement;robotic spacecraft;self-information;sensor;service robot;shannon (unit);springer (tank);winsock	Vivek A. Sujan;Marco A. Meggiolaro;Felipe A. W. Belo	2006	Auton. Robots	10.1007/s10514-005-6066-z	mobile robot;monte carlo localization;computer vision;simulation;image processing;information theory;computer science;artificial intelligence;machine learning;mobile robot navigation	Robotics	54.86321712527523	-28.826311702406656	50371
aae9540d3a45da55ba4125787d34961f21443a58	complex water effects at interactive frame rates		Due to the complexity of the effects, it is difficult to achieve photorealism and physically correct motion in interactive 3-D water simulations. We present a simulation and visualization method which goes a long way towards physical reality, e. g. by producing Kelvin ship waves and displaying images of real caustics on the water surface. Using efficient approximations and employing the specialized 3-D and CPU features of modern PCs, this simulation runs at rates of several frames per second. Part of this solution is the emulation of a hardware accumulation buffer on consumer 3-D graphics cards with the help of texture shaders.	approximation;central processing unit;emulator;graphics;shader;simulation;tree accumulation;video card	Jörn Loviscach	2003			computer vision;computer graphics (images);artificial intelligence;frame rate;visualization;shader;graphics;emulation;computer science	Graphics	64.6601233262866	-51.19065825068278	50393
10d2a912775f5a4b93d3ab2ac56989ff16bee9b3	interactive soft-fabrics watering simulation on gpu	watering dynamics;gpus;paper;soft fabrics modeling;real time simulation;cuda;nvidia;computer science;physics based simulation	Physics-based simulation is usually complex and time consuming, and consequently not suitable for real-time applications. In this paper, we propose the efficient dynamics models for the real-time simulation of soft fabrics interacting with water, including multi-soaking effect and underwater dynamics. The multi-soaking effect of soft fabrics is modeled based on the physics processes. Further, we develop the optimized mass–spring model that supports the large flow forces interacting with the fabrics underwater. The fabric spring forces are linearly derived and integrated with GPU–CUDA acceleration, feasible for real-time VR applications with large set of fabric particles. Copyright # 2011 John Wiley & Sons, Ltd.	cuda;fundamental interaction;graphics processing unit;hardware acceleration;interactive storytelling;john d. wiley;open-source software;parallel computing;physics engine;real-time clock;real-time locating system;simulation;user-generated content;virtual reality	Chen Huang;Hanqiu Sun;Shiguang Liu;Ping Li	2011	Journal of Visualization and Computer Animation	10.1002/cav.402	computational science;simulation;computer science;computer graphics (images)	EDA	71.13694920334332	-48.431489679462615	50503
2675181380ebb0009fb52ae2bb332ac680f90958	a planar quadratic clipping method for computing a root of a polynomial in an interval	quadratic clipping;root finding;convergence rate;optimal approximation order	This paper presents a new quadratic clipping method for computing a root of a polynomial f(t) of degree nwithin an interval. Different from the traditional one in R1 space, it derives three quadratic curves in R2 space for approximating ðt; f ðtÞÞ instead, which leads to a higher approximation order. Two bounding polynomials are then computed in Oðn2Þ for bounding the roots of f(t) within the interval. The new clipping method achieves a convergence rate of 4 for a single root, compared with that of 3 from traditional method using quadratic polynomial approximation in R1 space. When f(t) is convex within the interval, the two bounding polynomials are able to be directly constructed without error estimation, which leads to computational complexity O(n). Numerical examples show the approximation effect and efficiency of the new method. The method is particularly useful for the fly computation in many geometry processing and graphics rendering applications. & 2014 Elsevier Ltd. All rights reserved.	computation;computational complexity theory;cubic function;geometry processing;graphics;horner's method;numerical analysis;numerical method;order of approximation;polynomial;quadratic function;rate of convergence;rendering (computer graphics)	Xiao-Diao Chen;Weiyin Ma	2015	Computers & Graphics	10.1016/j.cag.2014.09.014	mathematical optimization;combinatorics;discrete mathematics;quadratic function;computer science;root-finding algorithm;mathematics;rate of convergence;algorithm	Graphics	70.31289107015603	-40.667785429980434	50601
04f225e17da048e45cf0cbaee185b31794194374	a hierarchical csp search for path planning of cooperating self-reconfigurable mobile fixtures	hierarchic csp;mobile robots;constraint satisfaction;partial csp;action planning;active supports	The paper presents the application of artificial intelligence tools for the path planning of complex multi-agent robotic systems. In particular, a solution is proposed to the planning problem for the conjoint operation of two or more mobile robotic fixtures used for the manufacturing of large workpieces, like those used in the aerospace industry. Such fixturing systems have been recently designed and tested, raising hopes to better satisfy the dynamic conditions of modern manufacturing, with its increasing emphasis on flexibility, adaptability, and automation. The proposed planning method is novel in two fundamental aspects. First, it interprets planning as a constraint satisfaction problem (CSP), rather than as a constrained optimisation, an approach ubiquitous in the path and motion planning literature. Secondly, the formulated CSP is solved by a hierarchy of incremental state space search algorithms which differ in some way from the existing state of the art. This hierarchy includes levels related to the robot and workpiece arrangement parameters and to three components of mobile fixture agents: a supporting head, a mobile base, and a parallel manipulator, respectively. Due to the use of CSP search, the planner constitutes a largely application-independent framework, on the basis of which specific industrial implementations can be defined by supplying the relevant physical, geometrical, and time-related constraints.		Wlodzimierz Kasprzak;Wojciech Szynkiewicz;Dimiter Zlatanov;Teresa Zielinska	2014	Eng. Appl. of AI	10.1016/j.engappai.2014.05.013	mobile robot;simulation;constraint satisfaction;computer science;artificial intelligence	AI	64.29975101301372	-27.023721857679178	50618
ee5d7ac46d31d6a526c6ab87ef1e0fd4ecea6282	volumetric tracking of 3d deformable shapes. (suivi volumétrique de formes 3d non rigides)				Benjamin Allain	2017				Vision	61.13122945916943	-47.042029978650795	50623
c14acab8f994244225d2754b07c487fe4696312a	complete coverage planning: achieving human interaction and maximum coverage during an autonomous robotic vehicle navigation of an unknown terrain			motion planning	Balasubramaniyan Chandrasekaran;James M. Conrad	2017				Robotics	55.20963049113598	-27.837862228877867	50655
15a2d83d779ee63f4f0996888d5d63263e32fae4	an experimental study of the autonomous helicopter landing problem	experimental tests;control algorithm;degree of freedom;inertial navigation;visual landmarks;hybrid control system;control system;finite state machine	Image-based information is useful for a variety of autonomo us vehicle applications such as obstacle avoidance, map generation, target tracking and motion estimation. Camera s a e inexpensive and operate at a high temporal rate. This, coupled with advances in processing power, makes images-base d techniques invaluable in autonomous systems operation. In this paperwe propose and experimentally investigate a vision-based te chnique for autonomously landing a robotic helicopter. We model the solution to the landing problem discretely usin g a finite state machine, responsible for detecting the landing site, navigating toward it, and landi ng on it. Data from a single on-board camera are combined with attitude and position measurements from an on-board inerti al navigation unit. These are the inputs to the on-board cont rol system: a set of controllers running in parallel which are res pon ible for controlling the individual degrees of freedom f the helicopter. The resulting hybrid control system is simp le, yet effective as shown experimentally by trials in nomina l and perturbed conditions. We experimentally test our algorithm by initializing the he licopter in hover at an arbitrary location. The helicopter i s required to autonomously locate a helipad (imprinted with a k nown visual landmark), align with it and land on it. Results from experiments show that our method is able to land the heli copter on the helipad repeatably and accurately. On an average the helicopter landed to within 35 cm position accuracy and to within 7 in orientation as measured from the center of the helipad and its principal axis respectively. I n this paper we focus on experimental evidence showing the robustness of the algorithm. In particular we show that 1. the helicopter is able to visually re-acquire the helipad after losing it momentarily, and 2. the helicopter is capable of tr acking a moving helipad and landing on it, once the helipad has stopped. In the tracking experiments the helipad was mov ed a significant distance ( 7 m on an average). Importantly the same algorithm is used across these conditions no speci fic modifications were made to handle the various cases. In the following section, we give an overview of the vision and c ontrol algorithms. Following this, a representative sample of the results obtained are shown. A detailed analysis of the assumptions made, algorithms used, and results obtained will be presented in the final paper.	algorithm;align (company);apache axis;autonomous system (internet);control system;crystal structure;experiment;finite-state machine;integrated development environment;motion estimation;obstacle avoidance;on-board data handling;real-time clock;real-time computing;robot;sensor;sion's minimax theorem	Srikanth Saripalli;Gaurav S. Sukhatme;James F. Montgomery	2002		10.1007/3-540-36268-1_42	control engineering;computer vision;simulation;computer science;engineering;control system;control theory;degrees of freedom;inertial navigation system	Robotics	57.945181214881	-29.475705567249666	50738
099ff6a75fa3a31fddc18941c61dba38cdf927d5	feature-based hybrid inspection planning: a mathematical programming approach	quality assurance;inspection planning;knowledge based system;travelling salesperson problem tsp;inspection time;sensor selection;traveling salesperson problem;coordinate measuring machine;mathematical programming;mathematical model;travelling salesperson problem;task assignment;point cloud;measurement technique;coordinate measuring machine cmm;product development	Intelligent planning for inspection of parts with complex geometric surfaces using contact or non-contact devices is still a major challenge. Contact measurement is widely used in manufacturing owing to its superiority in point accuracy. However, the volumetric accuracy of non-contact measurement techniques is better owing to the large number of points that can be measured in a short time. Consequently, contact measurement is usually used for mechanical parts with prismatic shapes while non-contact measurement methods are mostly used with free-form shapes. Complex parts that include both prismatic and free form shapes may require inspection using both techniques. It may not be possible to fully digitise a part using a single type of sensor owing to occlusion or accessibility issues. This paper proposes a hybrid (contact/non-contact) inspection planning approach that capitalises on the advantages of both inspection techniques. In the beginning, a knowledge-based system has been developed for selecting the ...	mathematical optimization	A. Mohib;A. Azab;H. ElMaraghy	2009	Int. J. Computer Integrated Manufacturing	10.1080/09511920802382368	quality assurance;mathematical optimization;simulation;computer science;engineering;artificial intelligence;marketing;operations management;mathematical model;point cloud;travelling salesman problem;engineering drawing;new product development	Robotics	59.28515503399402	-39.51581182542578	50800
75d4ec90da390bb3137a0fafdae91a142ff3b419	enhancement of performance parameters of speech signal using model order reduction approach	speech signal;signal to noise ratio snr;international phonetic alphabet ipa;normalized root mean square error nrmse;original higher order system;reduced order system;spectral distortion sd	In this paper, a model order reduction approach is used with the aim to enhance the performance parameters of the speech signal. Initially, this model reduction technique is applied on the original higher order system for the reduction of the order of system while keeping all the features of the original one in it. The performance parameters such as SNR, NRMSE and SD for the reduced order system have been improved compared to the same performance parameters with original higher order one. Finally, the comparisons of these performance parameters are made to show to enhance the performance of reduced order system irrespective of the order and values of state space parameters.	model order reduction	Mohammad Arif;R. S. Anand	2011	I. J. Speech Technology	10.1007/s10772-011-9117-1	speech recognition	NLP	82.65681434519384	-31.24054011369418	50825
10ee8f8f3982aa65725710bfbf13ec3672a7c3c6	skeleton comparisons: the junction neighbourhood histogram	comparison;multi dimensional;similarity;distance metric;topology preservation;characters;skeletons	For analysing and comparing characters, using skeletons is a promising approach due to their topology-preserving nature and the resemblance of the skeleton to the original writing movement. We suggest a novel qualitative approach to skeleton comparison that is based on the adjacency of junctions and end points and the steps of a preceding skeleton simplification. By using a multi-dimensional histogram that contains information about the adjacency and the degree of joints, we gain high comparison speeds which, when combined with the multi-step approach, can be used for a generic topology distance metric.	junction grammar;level of detail	Jannis Stoppe;Björn Gottfried	2011		10.1145/2034691.2034712	morphological skeleton;similarity;metric;topological skeleton	AI	65.79627185797175	-45.05468191929753	50832
ec5563d181473ef3b5433919274f8d47f325801d	a novel approach to sampling the coiled tubing surface with an application for monte carlo direct lighting	parabolic interpolation;tecnologia electronica telecomunicaciones;stratified sampling algorithms;coiled tubing surface;monte carlo method;tecnologias;grupo a;hierarchical allocation strategy		monte carlo method	Chung-Ming Wang;Peng-Cheng Wang	2004	IEICE Transactions		successive parabolic interpolation;simulation;statistics;monte carlo method	Visualization	73.5534229079979	-39.43650383133858	50910
fafb7a3d9c539395ce487f9e1b5e7acd9f50c0da	host–target vehicle model-based lateral state estimation for preceding target vehicles considering measurement delay		Automated vehicle control requires full knowledge of motion behavior of the preceding target vehicles (PTVs), and the states such as longitudinal/lateral velocity and yaw rate are critical for the PTV behavior description. However, the PTV's lateral states estimation have seldom been addressed in the state-of-the-art literatures. Aimed at providing reliable PTV lateral states, this paper presents a novel combined model-based estimation scheme. Different from the conventional PTV models, the proposed model is constructed based on the host–target vehicle dynamics and road constraints. Specifically, steering angle of the PTV is included in the state vector. The measurements, such as heading angle, road curvature, and lateral distance to the lane center, are available from an onboard vision system. As a vision system inevitably has measurement delay, a modified Kalman filter is developed to address the sampling issue. To verify the proposed approach, hardware-in-the-loop experiments are conducted in designed testing scenarios.	course (navigation);experiment;hardware-in-the-loop simulation;kalman filter;lateral computing;lateral thinking;sampling (signal processing);velocity (software development);yaws	Yafei Wang;Zhisong Zhou;Chongfeng Wei;Yahui Liu;Chengliang Yin	2018	IEEE Transactions on Industrial Informatics	10.1109/TII.2018.2828125	control engineering;computer science;kalman filter;sampling (statistics);curvature;yaw;vehicle dynamics;machine vision;state vector	Robotics	57.00523250033495	-34.93297139993462	51116
9176044796b2e268150e6da905e58358a97effd1	design and calibration of an opto-mechanical appliance for 3d non-contact orthopedic measurements part i: mathematical model and laboratory prototype	non contact orthopedic measurements;image acquisition procedure;3d scanning;structured light vision	An opto-mechanical system performing fast and accurate non-contact foot measurements is proposed. By processing the measured data it is possible to get three-dimensional foot models and to design custom-made shoes. This work is subdivided into two parts: in Part I, after introducing the system operating method and describing the vision technology employed, a mathematical model of the system is developed accounting for the main internal parameters of the camera. In order to reduce scanning time and the time necessary to create the 3D foot model, the measured data have been arranged in a particular structure and a suitable acquisition procedure has been developed. A laboratory prototype has been built to test the performances of the system: a detailed analysis of its geometry and of its components is provided as well as a concise description of the simple user interface developed to run and control the system.	mathematical model;performance;prototype;shoes;user interface	Roberto Caracciolo;Alberto Trevisani	2003	Journal of Intelligent and Robotic Systems	10.1023/A:1022334202039	simulation;engineering;biological engineering;engineering drawing	Robotics	74.38949195748847	-29.840467530681227	51158
3800fb2c9e6a78f0cd32db4451bc74cddd3c49b6	a laboratory goniometer system for measuring reflectance and emittance anisotropy	laboratory goniometer;anisotropy;robotics;reflectance anisotropy;earth planet;humans;brdf;biophysical parameter retrieval;climatic processes;emittance anisotropy	In this paper, a laboratory goniometer system for performing multi-angular measurements under controlled illumination conditions is described. A commercially available robotic arm enables the acquisition of a large number of measurements over the full hemisphere within a short time span making it much faster than other goniometers. In addition, the presented set-up enables assessment of anisotropic reflectance and emittance behaviour of soils, leaves and small canopies. Mounting a spectrometer enables acquisition of either hemispherical measurements or measurements in the horizontal plane. Mounting a thermal camera allows directional observations of the thermal emittance. This paper also presents three showcases of these different measurement set-ups in order to illustrate its possibilities. Finally, suggestions for applying this instrument and for future research directions are given, including linking the measured reflectance anisotropy with physically-based anisotropy models on the one hand and combining them with field goniometry measurements for joint analysis with remote sensing data on the other hand. The speed and flexibility of the system offer a large added value to the existing pool of laboratory goniometers.	angularjs;anisotropy;malignant fibrous histiocytoma;numerous;oren–nayar reflectance model;robot;robotic arm;soil;span distance;spectrometers;goniometers	Peter P. J. Roosjen;Jan G. P. W. Clevers;Harm M. Bartholomeus;Michael E. Schaepman;Gabriela Schaepman-Strub;Henk Jalink;Rob van der Schoor;Arjan de Jong	2012		10.3390/s121217358	computer science;bidirectional reflectance distribution function;optics;mineralogy;robotics;anisotropy;physics;remote sensing	Robotics	74.18674847841872	-33.379097564380935	51197
6c2c9cc8c74cfa1b542e6acce558b102cdace87f	ruled tracing	ray tracing — light wave- fronts — direct freeform surface rendering — shadow computation — reflection/ refraction	The traditional ray-tracing technique based on a ray-surface intersection is reduced to a ruled or developable surface—surface intersection problem. That enables direct freeform surface rendering. By exploiting the spatial coherence gained in the ruled/developable surface-tracing approach presented, the emulation of shadows, specular reflections, and/or refractions in a freeform surface environment can all be implemented efficiently. The approach provides a direct freeform surface-rendering alternative to ray tracing. An implementation of a direct freeform surface renderer that emulates shadows as well as specular reflections is discussed. This renderer processes isoparametric curves as its basic building block, eliminating the need for polygonal approximation.	approximation;coherence (physics);emulator;freeform surface modelling;ray tracing (graphics);reflection (computer graphics);rendering (computer graphics)	Gershon Elber;Jung-Ju Choi;Myung-Soo Kim	1997	The Visual Computer	10.1007/s003710050091		Graphics	65.45998103506462	-50.63407524828976	51219
7d8efe7db11d3380df6639a7481a194f9a370231	statistical and geometrical approaches to visual motion analysis, 13.07. - 18.07.2008					2008				Vision	60.37063353872685	-46.691554356595596	51260
33f89735e9347be686e6dfd2c205f0f851c684e1	real-time manipulation of texture-mapped surfaces	real time;texture mapping;real time processing;linear functionals;approximation scheme	"""A system for real-time texture mapping was constructed, Here, """"real-time"""" means that the system reacts to changes in parameter values which define the shape of surfaces and the viewing point that are given by its operator 30 times per second. This real-time processing enables interactive manipulation of texture-mapped free-form surfaces and various application software has been developed taking advantage of this ability. The system owes its performance to a new algorithm for texture mapping which is based on a newly proposed approximation scheme of mapping functions. In this scheme, a mapping function from the texture plane into the output screen is approximated by a linear function on each of the small regions which form the texture plane altogether. The algorithm is very simple and applicable to any smooth surface. It is especially efficient when implemented by a special-purpose hardware."""	aliasing;approximation algorithm;interactivity;linear approximation;linear function;real-time clock;real-time computing;real-time transcription;sony reader family;spatial anti-aliasing;texture mapping;user interface	Masaaki Oka;Kyoya Tsutsui;Akio Ohba;Yoshitaka Kurauchi;Takashi Tago	1987		10.1145/37401.37424	texture mapping;computer vision;mathematical optimization;real-time computing;displacement mapping;computer science;mathematics;geometry;uvw mapping;texture filtering;projective texture mapping	Graphics	66.02849017224734	-50.4611026310652	51262
4f3822290f76fa4c02b7898601a0613f37063ad5	real-time defocus rendering with level of detail and sub-sample blur	level of details;gpu;defocus blur;depth of field rendering;i 3 3 computer graphics picture image generation display algorithms;real time rendering	This paper presents a GPU-based rendering algorithm for real-time defocus blur effects, which significantly improves the accumulation buffering. The algorithm combines three distinctive techniques: (1) adaptive discrete geometric level of detail (LOD), made popping-free by blending visibility samples across the two adjacent geometric levels; (2) adaptive visibility/shading sampling via sample reuse; (3) visibility supersampling via height-field ray casting. All the three techniques are seamlessly integrated to lower the rendering cost of smooth defocus blur with high visibility sampling rates, while maintaining most of the quality of brute-force accumulation buffering.	algorithm;alpha compositing;blackwell (series);box blur;display resolution;eurographics;gaussian blur;graphics processing unit;heightmap;level of detail;rasterisation;real-time clock;real-time transcription;sampling (signal processing);shader;shading;supersampling;tree accumulation	Yuna Jeong;Kangtae Kim;Sungkil Lee	2013	Comput. Graph. Forum	10.1111/cgf.12075	computer vision;3d rendering;rendering;computer science;multimedia;real-time rendering;computer graphics (images)	Graphics	65.09181063119155	-51.79582859009948	51278
7c09b8547c56c71b7e4d88e0c8506fac891c5fcc	about some specificities of embedded multiagent systems design	social welfare;agent modeling;unmanned aerial vehicle;remotely operated vehicles;multirobot systems;remotely operated vehicles air traffic aircraft collision avoidance iterative methods multi agent systems peer to peer computing;collision avoidance unmanned aerial vehicles aircraft iterative algorithms protocols air traffic control centralized control communication system control intelligent agent laboratories;iterative methods;multi agent systems;distributed cooperative collision avoidance;multiagent model;cooperative systems;air traffic multiparty collision avoidance distributed cooperative collision avoidance autonomous unmanned aerial vehicles iterative peer to peer collision avoidance multiagent model;iterative peer to peer collision avoidance;collision avoidance;peer to peer computing;multiparty collision avoidance;peer to peer;autonomous unmanned aerial vehicles;air traffic;aircraft;multiagent systems	This paper addresses the problem of distributed cooperative collision avoidance that supports efficient utilization of air space shared by several autonomous unmanned aerial vehicles. The novel multi-party collision avoidance (MPCA) algorithm is described. It is compared to the iterative peer-to-peer collision avoidance (IPPCA) algorithm that iteratively optimizes social welfare. The paper provides a set of experiments and a comparison of different collision avoidance mechanisms in a multi-agent model of air traffic.	agent-based model;algorithm;autonomous robot;embedded system;experiment;iterative method;multi-agent system;multilinear principal component analysis;peer-to-peer;systems design;television antenna;unmanned aerial vehicle	Jean-Paul Jamont;Michel Occello	2007		10.1109/IAT.2007.71	embedded system;simulation;engineering;obstacle avoidance;computer security	Robotics	57.46458472734265	-25.33989484256331	51322
a785c314504301801297c9b8d170292378f75999	grasping objects with a cable-driven parallel robot designed for transfer operation by visual servoing	positioning accuracy object grasping cable driven parallel robot transfer operation visual servoing assistance functionalities marionet assist crane robot translational dof camera end effector translational velocity robot controller;visual servoing cranes end effectors image sensors position control robot vision velocity control;wires visual servoing cameras kinematics grasping accuracy	Our objective is to extend the assistance functionalities of the cable-driven parallel robot Marionet-Assist, designed principally for transfer operation, by allowing it to grasp usual objects (knives, box of medicines, phone, ···) by using visual servoing. Our crane robot has a configuration that provides three translational d.o.f., and a camera was added to its end-effector. In order to compute the translational velocity sent to the robot controller, the area and center of gravity in the image of the object to be grasped are used. Experimental results are presented. They show the robustness of our scheme with respect to modeling errors and an excellent positioning accuracy allowing grasping.	apache axis;displacement mapping;experiment;image moment;parallel manipulator;robot end effector;semi-supervised learning;semiconductor industry;velocity (software development);visual servoing	Rémy Ramadour;François Chaumette;Jean-Pierre Merlet	2014	2014 IEEE International Conference on Robotics and Automation (ICRA)	10.1109/ICRA.2014.6907510	control engineering;computer vision;robot end effector;engineering;control theory;robot control;visual servoing	Robotics	61.36023876174237	-30.610573808932475	51327
2ed58cb019358a6a3fa1f10e1c503ea3edc0140a	detail preserving continuum simulation of straight hair	hair simulation;continuum models;virtual characters;hair modeling;degree of freedom;continuum model	Hair simulation remains one of the most challenging aspects of creating virtual characters. Most research focuses on handling the massive geometric complexity of hundreds of thousands of interacting hairs. This is accomplished either by using brute force simulation or by reducing degrees of freedom with guide hairs. This paper presents a hybrid Eulerian/Lagrangian approach to handling both self and body collisions with hair efficiently while still maintaining detail. Bulk interactions and hair volume preservation is handled efficiently and effectively with a FLIP based fluid solver while intricate hair-hair interaction is handled with Lagrangian self-collisions. Thus the method has the efficiency of continuum/guide based hair models with the high detail of Lagrangian self-collision approaches.	simulation;triune continuum paradigm	Aleka McAdams;Andrew Selle;Kelly Ward;Eftychios Sifakis;Joseph Teran	2009	ACM Trans. Graph.	10.1145/1531326.1531368	classical mechanics;simulation;computer science;machine learning;mathematics;geometry;degrees of freedom;physics;statistics	Graphics	71.40388676802098	-47.39153164886981	51388
f5866a81d92ac265befaed06eb003e07a4b64306	bézier surfaces with linear isoparametric lines	bezier surface;concepcion asistida;computer aided design;curva bezier;ruled surface;surface parametrique;superficie parametrica;courbe bezier;necessary and sufficient condition;conception assistee;parametric surface;bezier curve	We provide control point based necessary and sufficient conditions for (n,m) Bezier surfaces to have linear isoparametric lines.	bernstein polynomial;bézier curve;control point (mathematics)	Imre Juhász;Ágoston Róth	2008	Computer Aided Geometric Design	10.1016/j.cagd.2007.09.003	topology;ruled surface;computer aided design;parametric surface;bézier surface;bézier curve;mathematics;geometry	AI	68.26640866684833	-40.069991694438116	51391
407b27c2b8e59575eb92c35fc4903c2215b1c650	experimental evaluation of a semg-based control for elbow wearable assistive devices during load lifting tasks		In this work, a surface skin electromyography(sEMG)-based control solution for elbow wearable assistive devices during load lifting tasks is presented. The goal of the controller consists in limiting the user's muscle activity during the task execution, in such a way that the assistive device can partially compensate the load-related biceps muscle effort. Since sEMG-driven control strategies based on the estimation of the joint torques generally requires complex task- and subject-dependent training sessions for tuning the control algorithms, here a more direct control approach is proposed, based on a muscle activity error related proportional-integral action together with an double-threshold activation logic. The controller's parameters are easily set by means of a fast, online and automatic subject calibration procedure, ensuring a simple adjustability to different users. An experimental phase has been conducted in order to evaluate the sEMG-based control performance involving four healthy subjects, using as wearable assistive device a twisted string action module, which is particularly suitable for assistive applications because of its lightness and compactness. Results show that the control strategy is able to successfully limit the EMG activity of the subjects during the lifting tasks, providing preliminary outcomes and promising possibilities for the use of twisted string-based technologies to assist human joints and muscles.	articular system;assistive technology;biceps brachii muscle structure;calibration;control theory;controllers;dermatologic disorders;elbow joint structure;electromyography;experiment;game demo;human–robot interaction;lambda lifting;lifting scheme;limb structure;neuromuscular diseases;performance tuning;population parameter;self-help devices;stage level 1;traditional serrated adenoma;triceps brachii muscle structure;twisted;wearable computer;weyers acrofacial dysostosis;algorithm	Roberto Meattini;Gianluca Palli;Claudio Melchiorri	2017	2017 International Conference on Rehabilitation Robotics (ICORR)	10.1109/ICORR.2017.8009236	elbow;control theory;simulation;torque;robot;wearable computer;biceps;electromyography;engineering;control engineering;control system	Robotics	71.00191231845992	-26.919437047578004	51444
4f91df4a05ab669981d18b2ef153b02e2c01d654	motion pianning of multiple mobile robots	robot sensing systems;motion control;flexible manufacturing systems;mobile robot;mobile robots;remotely operated vehicles;navigation;multiple mobile robots;system recovery;production facilities;mobile robots motion planning motion control robot sensing systems machinery system recovery production facilities navigation remotely operated vehicles flexible manufacturing systems;motion planning;machinery	As mobile robots expand their working area, motion planning of multiple mobile robots becomes more important than ever. In this paper, various researches are surveyed and categorized f rom the two v iewpoint s : centra l i zed / decentralized mechanism, and o n-1 i ne/o ffline system. Since three kinds of combinations may be realizable, the three are discussed. The imotion planning of a group of mobile robots is also discussed. I t is dif f icul t to evaluate each research. We therefore proposed two standard problems. The first has 8 mobile robot!; who come easily to a deadlock. The second includes 2 groups of 4 robots respectively, which needs cooperative actions to each other.	categorization;data interchange format;deadlock;mobile robot;motion planning	Tamio Arai;Jun Ota	1992		10.1109/IROS.1992.601383	control engineering;mobile robot;computer vision;simulation;computer science;engineering;artificial intelligence;robot control;mobile robot navigation	Robotics	59.982315352456574	-28.582184169936664	51479
b2eb905a0d1703fbdcbe80b135c0e1737528749b	quadrangular parameterization for reverse engineering	geometric feature;quadrangular remeshing;numerical computation;global parameterization;laser scanning;reverse engineering	The aim of Reverse Engineering is to convert an unstructured representation of a geometric object, emerging e.g. from laser scanners, into a natural, structured representation in the spirit of CAD models, which is suitable for numerical computations. Therefore we present a user-controlled, as isometric as possible parameterization technique which is able to prescribe geometric features of the input and produces high-quality quadmeshes with low distortion. Starting with a coarse, user-prescribed layout this is achieved by using affine functions for the transition between non-orthogonal quadrangular charts of a global parameterization. The shape of each chart is optimized non-linearly for isometry of the underlying parameterization to produce meshes with low edge-length distortion. To provide full control over the meshing alignment the user can additionally tag an arbitrary subset of the layout edges which are guaranteed to be represented by enforcing them to lie on iso-lines of the parameterization but still allowing the global parameterization to relax in the direction of the iso-lines.	algorithm;chart;computation;computer-aided design;distortion;isometric projection;iterative method;mathematical optimization;numerical analysis;requirement;reverse engineering;t-vertices	David Bommes;Tobias Vossemer;Leif Kobbelt	2008		10.1007/978-3-642-11620-9_5	mathematical optimization;mathematics;geometry;engineering drawing	Graphics	67.97848021749866	-44.18238238129222	51516
3f406216dc649239bddf8e75895caaa52808f779	self-adjusting locomotion on a partially broken-down quadrupedal biomorphic robot by evolutionary algorithms	particle swarm optimization self adjusting locomotion broken down quadrupedal biomorphic robot evolutionary algorithms wheel based robots feedback pso;self adjusting systems evolutionary computation feedback mobile robots particle swarm optimisation	Biomorphic robots have become an interesting topic recently. These robots can achieve certain goals that wheel-based robots cannot. The biomorphic robots usually have more joints and more legs. However, the more motors on a robot the more risk that one of them might break down at an unexpected moment. Self-adjusting locomotion ability can be a help to make a partially dysfunctional biomorphic robot move. Online evolutionary algorithm is a promising way to achieve such a task. The robot receives feedback from the environment as to the fitness for its evolutionary goal. In this paper, we adopt the PSO (particle swarm optimization) algorithm as our online evolutionary algorithm and test it on a partially broken-down quadrupedal biomorphic robot. The experimental results show that the robot can adjust its actions to move even when one leg is removed.	evolutionary algorithm;feedback;mathematical optimization;particle swarm optimization;robot	Guo-Yuan Qiu;Shih-Hung Wu	2012	2012 IEEE International Conference on Robotics and Biomimetics (ROBIO)	10.1109/ROBIO.2012.6490942	control engineering;mobile robot;simulation;computer science;engineering;artificial intelligence;robot locomotion;robot control	Robotics	59.529152227451476	-24.649053984257918	51546
8378119e6742059b6e16104dccd8faab4e7d2cb7	control of a manipulator with a minimum number of motion primitives	control systems;control theory;motion control;motion control control systems principal component analysis control system synthesis rats muscles mathematical model kinematics control theory feedback;rats;vector space;motor system;kinematics;feedback;control system synthesis;principal component analysis;mathematical model;linear optimization;feedback linearization;spinal fields;linear optimal control;linear optimal control spinal fields feedback linearization;admission control;muscles	Recent experiments on sensory-motor systems of frogs and rats have revealed that those systems have a modular structure. Apparently, control actions form a vector space with a handful of elementary controls as a basis. The reduction of admissible controls to a vector space plays in control theory a similar role to PCA in learning and recognition applications. Inspired by these observations, we first propose a mathematical model of the experimentally observed modular structure. We then show how to choose elementary control actions so as to make the system reach any desired final state. Finally, we determine the minimum number of elementary control actions to perform reaching.	control theory;elementary;experiment;mathematical model	Francesco Nori;Ruggero Frezza	2005	Proceedings of the 2005 IEEE International Conference on Robotics and Automation	10.1109/ROBOT.2005.1570463	control engineering;motion control;kinematics;simulation;vector space;linear programming;control system;motor system;mathematical model;control theory;feedback;mathematics;feedback linearization;principal component analysis	Robotics	65.29702743768574	-24.374386904504576	51552
f50adb846e6099050a8d586d4bcedd01c37fdb3d	double loop control strategy with different time steps based on human characteristics	protocols;protocols cooperative systems human robot interaction position control;human robot interaction;force humans robot sensing systems impedance conferences force sensors;cooperative systems;position control;adult analysis of variance biomechanical phenomena human characteristics humans male movement robotics time factors young adult;two degree of freedom robot double loop control human characteristics cooperative control strategy force sensitivity intention estimation loop position control loop protocol human robot interaction pull and push movement	This paper proposes a cooperative control strategy in consideration of the force sensitivity of human. The strategy consists of two loops: one is the intention estimation loop whose sampling time can be variable in order to investigate the effect of the sampling time; the other is the position control loop with fixed time step. A high sampling rate is not necessary for the intention estimation loop due to the bandwidth of the mechanoreceptors in humans. In addition, the force sensor implemented in the robot is sensitive to the noise induced from the sensor itself and tremor of the human. Multiple experiments were performed with the experimental protocol using various time steps of the intention estimation loop to find the suitable sampling times in physical human robot interaction. The task involves pull-and-push movement with a two-degree-of-freedom robot, and the norm of the interaction force was obtained for each experiment as the measure of the cooperative control performance.	consensus dynamics;control system;control theory;experiment;human–robot interaction;mechanoreceptors;robot;sampling (signal processing);sampling - surgical action;tremor	Gwang Min Gu;Jinoh Lee;Jung Hyun Kim	2012	2012 Annual International Conference of the IEEE Engineering in Medicine and Biology Society	10.1109/EMBC.2012.6346330	human–robot interaction;control engineering;communications protocol;simulation;computer science;engineering;artificial intelligence;control theory;robot control	Robotics	70.57969077493782	-26.753791323795802	51594
62981c388904785c1365be9b6a0fd6e385d13afa	interactive volume rendering using multi-dimensional transfer functions and direct manipulation widgets	three-dimensional transfer function;direct volume;direct manipulation widget;multi-dimensional transfer function;transfer function;interactive volume rendering;data value;interactive volume exploration;one-dimensional transfer function;modern graphics hardware;good transfer function;computational geometry;dataset;three dimensional;directional derivative;computational complexity;transfer functions;interpolation;visualization;graphics hardware;object modelling;three dimensions;time series;power system;data visualisation	Most direct volume renderings produced today employ one-dimensional transfer functions, which assign color and opacity to the volume based solely on the single scalar quantity which comprises the dataset. Though they have not received widespread attention, multi-dimensional transfer functions are a very effective way to extract specific material boundaries and convey subtle surface properties. However, identifying good transfer functions is difficult enough in one dimension, let alone two or three dimensions. This paper demonstrates an important class of three-dimensional transfer functions for scalar data (based on data value, gradient magnitude, and a second directional derivative), and describes a set of direct manipulation widgets which make specifying such transfer functions intuitive and convenient. We also describe how to use modern graphics hardware to interactively render with multi-dimensional transfer functions. The transfer functions, widgets, and hardware combine to form a powerful system for interactive volume exploration.	direct manipulation interface;directional derivative;gradient;graphics hardware;interactivity;transfer function;volume rendering	Joe Michael Kniss;Gordon L. Kindlmann;Charles D. Hansen	2001	Proceedings Visualization, 2001. VIS '01.		three-dimensional space;computer vision;computational geometry;computer science;theoretical computer science;mathematics;transfer function;data visualization;statistics;computer graphics (images)	Visualization	66.15495171700299	-47.34603800176513	51635
1125cd3b2744e024d0340ba08be027f64856daf6	hrhatrac algorithm for spectral line tracking of musical signals	eigenvalues and eigenfunctions;piano note recording;high resolution harmonics tracking;additive noise;high resolution harmonics tracking hrhatrac algorithm spectral line tracking musical signals fast subspace tracking algorithms gradient update signal poles estimation line spectral tracker robust frequency estimation piano note recording;frequency estimation;fast subspace tracking algorithms;acoustic signal processing;hidden markov models;matrix decomposition;power harmonic filters;signal poles estimation;acoustic noise;musical signals;spectral analysis acoustic signal processing frequency estimation harmonic analysis music;line spectral tracker;robustness;robust frequency estimation;covariance matrix matrix decomposition signal processing algorithms frequency estimation power harmonic filters additive noise hidden markov models eigenvalues and eigenfunctions robustness acoustic noise;spectral analysis;signal processing algorithms;gradient update;music;spectral line tracking;covariance matrix;hrhatrac algorithm;harmonic analysis	HRHATRAC combines the last improvements regarding the fast subspace tracking algorithms with a gradient update for adapting the signal poles estimates. It leads to a line spectral tracker which is able to robustly estimate the frequencies, even in a noisy context, when the lines are close to each other and when a modulation occurs. HRHATRAC is also successfully applied in this paper to a piano note recording	algorithm;gradient;modulation	Bertrand David;Roland Badeau;Gaël Richard	2006	2006 IEEE International Conference on Acoustics Speech and Signal Processing Proceedings	10.1109/ICASSP.2006.1660586	covariance matrix;speech recognition;computer science;harmonic analysis;music;mathematics;matrix decomposition;statistics;robustness	Robotics	81.5492598942575	-34.586098069972856	51681
e29bf8b4b0af61e862b45ecedb0ceda2d8de9619	introduction to the special section on in-vehicle computer vision systems	special issues and sections computer vision road accidents vehicle detection vehicle safety intelligent vehicles remotely operated vehicles mobile robots cameras layout;road accidents;special issues and sections;vehicle detection;mobile robots;remotely operated vehicles;layout;computer vision;intelligent vehicles;vehicle safety;cameras			Rita Cucchiara;David Lovell;Andrea Prati;Mohan Manubhai Trivedi	2004	IEEE Trans. Vehicular Technology	10.1109/TVT.2004.839616	remotely operated underwater vehicle;layout;mobile robot;simulation;computer science;engineering;automotive engineering;transport engineering	Vision	55.81117227037246	-31.815787391406516	51710
a0f0b2942e0d292c90bcce57e9827a2b76d07218	multi-sensory feedback control in door approaching and opening		In the article the robotic system behavior is investigated for the complex door opening task. The system consists of the 7-DOF KUKA LWR4+ manipulator, which is controlled in an impedance way and the BarrettHand gripper, which is controlled in a position way. The system utilizes multi-sensory feedback. The visual feedback is used to roughly localize door and to plan a door approach trajectory. The tactile feedback detects the contact with the door, and handle and determines an exact contact position with the handle. The system does not form a grip in a door opening stage, but the contact between the robot and the door is maintained by the gripper’s fingers (with intrinsic backlash), which are pushing the handle from its one side. This concept allows to open the door when there are obstacles in the neighborhood of the handle (e.g. door jamb or frame), which make the grip impossible.	opening (morphology)	Tomasz Winiarski;Konrad Banachowicz;Dawid Seredynski	2014		10.1007/978-3-319-11310-4_6	backlash;jamb;control engineering;manipulator;sensory system;trajectory;service robot;impedance control;computer science	Robotics	70.32370345988757	-24.011802925518726	51718
eeb381c955d135ae15a12ce2c356d4afa740cb55	a two-point algorithm for stereo visual odometry in open outdoor environments	two point algorithm image pixel noise stereo vision camera distance unconstraint motion recovery 3d space calibrated stereo camera pose estimation open outdoor environment stereo visual odometry;stereo image processing computer vision image denoising pose estimation;cameras uncertainty vectors estimation accuracy three dimensional displays noise	This paper proposes a novel method to estimate relative poses for a calibrated stereo camera. Three corresponding points in 3D space are theoretically required to recover unconstraint motion which has six degrees of freedom. The proposed method solves this problem with only two 3D points by exploiting a common reference direction between poses. Two points are selected in accordance with the distance to the camera: one distant point is used for deriving a reference direction, and one near point is used for estimating accurate translation. The distance is computed by triangulation in stereo vision. The uncertainty of triangulation can be mitigated by the appropriate selection strategy. The experiments using synthetic and real data demonstrate the effectiveness and higher stability of the proposed method against image pixel noise.	algorithm;experiment;pixel;random sample consensus;robot;six degrees of separation;solver;stereo camera;stereopsis;synthetic data;synthetic intelligence;triangulation (geometry);visual odometry;world-system	Kyohei Otsu;Takashi Kubota	2014	2014 IEEE International Conference on Robotics and Automation (ICRA)	10.1109/ICRA.2014.6906982	computer stereo vision;stereo cameras;stereo camera;computer vision;visual odometry;remote sensing;computer graphics (images)	Robotics	54.14071731765009	-42.008246755351955	51752
3c4cc1d417d95025977fb9cecf96f8176627beb6	gaze tracking system model based on physical parameters	system modeling;gaze tracking;optical axis;bright pupil technique;eye tracking;modeling;calibration;visual axis	In the past years, research in eye tracking development and applications has attracted much attention and the possibility of interacting with a computer employing just gaze information is becoming more and more feasible. Efforts in eye tracking cover a broad spectrum of fields, system mathematical modeling being an important aspect in this research. Expressions relating to several elements and variables of the gaze tracker would lead to establish geometric relations and to find out symmetrical behaviors of the human eye when looking at a screen. To this end a deep knowledge of projective geometry as well as eye physiology and kinematics are basic. This paper presents a model for a bright-pupil technique tracker fully based on realistic parameters describing the system elements. The system so modeled is superior to that obtained with generic expressions based on linear or quadratic expressions. Moreover, model symmetry knowledge leads to more effective and simpler calibration strategies, resulting in just two calibration points needed to fit the optical axis and only three points to adjust the visual axis. Reducing considerably the time spent by other systems employing more calibration points renders a more attractive model.	apache axis;complexity;expect;eye tracking;heuristic;interaction;mathematical model;nl (complexity);numerical aperture;rendering (computer graphics);tracking system;whole earth 'lectronic link	Arantxa Villanueva;Rafael Cabeza;Sonia Porta	2007	IJPRAI	10.1142/S0218001407005697	computer vision;simulation;systems modeling	AI	59.13726870050297	-46.131525507350645	51769
586cda48d6bb84f8746e8862c800e9b6c4071414	transferring human motion to mechanical manipulator in insertion of deformable tubes	insertion;deformable objects;deformation;human motion;manipulation			Shinichi Hirai	1998	JRM	10.20965/jrm.1998.p0209	computer vision;simulation;optics	Robotics	64.49343297661046	-35.589950981414	51780
c3a0d3629bbb3ce6f18a3d31b488c71239958846	efficient palette-based decomposition and recoloring of images via rgbxy-space geometry		We introduce an extremely scalable and efficient yet simple palette-based image decomposition algorithm. Given an RGB image and set of palette colors, our algorithm decomposes the image into a set of additive mixing layers, each of which corresponds to a palette color applied with varying weight. Our approach is based on the geometry of images in RGBXY-space. This new geometric approach is orders of magnitude more efficient than previous work and requires no numerical optimization. We provide an implementation of the algorithm in 48 lines of Python code. We demonstrate a real-time layer decomposition tool in which users can interactively edit the palette to adjust the layers. After preprocessing, our algorithm can decompose 6 MP images into layers in 20 milliseconds.		Jianchao Tan;Jose I. Echevarria;Yotam I. Gingold	2018	ACM Trans. Graph.	10.1145/3272127.3275054		Graphics	65.69552879872343	-47.94566937310066	51799
74c87cda8a77659e19019e4824c6987c49df9176	simultaneous localization and mapping of mines with unmanned aerial vehicle	ventilation system mines localization mines mapping unmanned aerial vehicle uav extended kalman filter algorithms ultrasound sensors;kalman filters;ultrasonic transducers autonomous aerial vehicles coal kalman filters mining nonlinear filters;kalman filters unmanned aerial vehicles simultaneous localization and mapping mathematical model;simultaneous localization and mapping;mathematical model;unmanned aerial vehicles;extended kalman filter ekf unmanned aerial vehicle uav coal mine simultaneous localization and mapping	In this study, the position information from ultrasound sensors on UAV related to floor gallery mine passed through the filter, it is aimed to control the position of simultaneously creating the optimum environmental map. The simultaneous in galleries made mapping, mine the data of air to the designated central monitoring system with real-time location information is transmitted to the ventilation system, which is intended to more effectively work in the mines. The gallery maps which simultaneous location and mapping information obtained by UAV Extended Kalman Filter algorithms processed were obtained experimentally.	aerial photography;algorithm;experiment;extended kalman filter;map;real-time locating system;sensor;simultaneous localization and mapping;unmanned aerial vehicle	Aytac Altan;Koksal Bayraktar;Rifat Hacioglu	2016	2016 24th Signal Processing and Communication Application Conference (SIU)	10.1109/SIU.2016.7496019	control engineering;computer vision;engineering;remote sensing;simultaneous localization and mapping	Robotics	54.23516619960067	-32.69644621800868	51831
3d88563c449c506bf2546a7a8961085158f0114e	multiview marker-free registration of forest terrestrial laser scanner data with embedded confidence metrics	measurement by laser beam;laser radar;laser beams;image edge detection;three dimensional displays;imaging	Terrestrial laser scanning has demonstrated increasing potential for rapid comprehensive measurement of forest structure, especially when multiple scans are spatially registered in order to reduce the limitations of occlusion. Although marker-based registration techniques (based on retro-reflective spherical targets) are commonly used in practice, a blind marker-free approach is preferable, insofar as it supports rapid operational data acquisition. To support these efforts, we extend the pairwise registration approach of our earlier work, and develop a graph-theoretical framework to perform blind marker-free global registration of multiple point cloud data sets. Pairwise pose estimates are weighted based on their estimated error, in order to overcome pose conflict while exploiting redundant information and improving precision. The proposed approach was tested for eight diverse New England forest sites, with 25 scans collected at each site. Quantitative assessment was provided via a novel embedded confidence metric, with a mean estimated root-mean-square error of 7.2 cm and 89% of scans connected to the reference node. This paper assesses the validity of the embedded multiview registration confidence metric and evaluates the performance of the proposed registration algorithm.	airborne ranger;algorithm;computer vision;data acquisition;embedded system;graphical user interface;image registration;mean squared error;multiview video coding;point cloud;terrestrial television	David Kelbe;Jan van Aardt;Paul Romanczyk;Martin van Leeuwen;Kerry Cawse-Nicholson	2017	IEEE Transactions on Geoscience and Remote Sensing	10.1109/TGRS.2016.2614251	medical imaging;lidar;computer vision;simulation;remote sensing	Visualization	55.10854779239973	-44.57862216207445	51903
a0035da21455c6c42a194e6d5d2b74ed0fe7a2fa	simulating decorative mosaics	halftoning;error diffusion;image quality;color quantization;voronoi diagram	This paper presents a method for simulating decorative tile mosaics. Such mosaics are challenging because the square tiles that comprise them must be packed tightly and yet must follow orientations chosen by the artist. Based on an existing image and user-selected edge features, the method can both reproduce the image's colours and emphasize the selected edges by placing tiles that follow the edges. The method uses centroidal voronoi diagrams which normally arrange points in regular hexagonal grids. By measuring distances with an manhattan metric whose main axis is adjusted locally to follow the chosen direction field, the centroidal diagram can be adapted to place tiles in curving square grids instead. Computing the centroidal voronoi diagram is made possible by leveraging the z-buffer algorithm available in many graphics cards.	algorithm;centroidal voronoi tessellation;color;distortion;first-order reduction;graphics;optic axis of a crystal;pixel;set packing;simulation;taxicab geometry;video card;voronoi diagram;z-buffering	Alejo Hausner	2001		10.1145/383259.383327	image quality;computer vision;color quantization;voronoi diagram;centroidal voronoi tessellation;computer science;mathematics;geometry;error diffusion;computer graphics (images)	Graphics	66.35545097968975	-48.61409273576628	51918
b7070e89161f3de82d43bb52baf1712652a2dd14	a new 3-d surface measurement system using a structured light	image recognition;surface topography measurement image recognition image texture;surface geometrical study;surface measurement;surface topography measurement;3d surface measurement;structured light;testing;image sensors;data mining;cameras calibration data mining shape pixel image sensors problem solving sampling methods calculus testing;image texture;shape;calculus;pixel;triangulation principle;sampling methods;object surfaces;calibration;surface geometrical study 3d surface measurement structured light imaged grid triangulation principle object surfaces;cameras;problem solving;imaged grid	"""In this paper, we present a new 3-0 measurement method using a projected grid which permits an optimal geometrical exploitation of the calculated 3-0 data. An important contribution of our work is the correspondence problem solving. We propose a new and reliable correspondence method which establishes the link between the imaged grid and the original grid curve per curve withput any ambiguity. The imaged grid is extracted from an efficient method which describes the distorted grid as a network of curves rather than a graph and hence provides a regular and precise 2 0 information. The 30 projected grid is calculated per curves by using triangulation principle. Thus, we obtain two independent families of 30 curves which parametrize the object surfaces and permits to tackle a surface geometrical study. 1. Introduction Up to now the published works in this area [ST0861 consider the projected grid as a graph taking account only of nodes and the relation between them. Thus, the 3D projected grid is reconstituted per nodes and the surface orientation is calculated approximative1 y from this surface sampling. This approach provides discontinued 3D information which doesn't favour the calculus of second order shape parametem. The distorted curves by the object surfaces permit to extract important information on the surface shape and therefore, we have to safeguard the whole information contained in the projected grid. With this aim in view, we consider the distorted grid as a network of curves rather than a graph and we have developed 2D and 3D uniform methods : each imaged curve is extracted entirely, the correspondence between the original grid and the imaged grid is done per curves by using global and metric criterion exploiting the geometrical constraints in the 3D space and each 3D curve is reconstituted via triangulation point per point. For the calibration of the camera and the projector we have developed an optid and precise method which calibrate the projector from the camera without any manual measurements. Since our system has been designed and developed for a metrological use, the 3D precision has been estimated on a reference object. The result of this test and those given by our methods are illustrated in this paper. 2The svste m outlina Our 3D sensor works in three phases: imaged grid extraction, 3D reconstitution and geometrical study of object surfaces. The content of each phase is the exP@'on which consists of fitring, thinning, node detection and following algorithms. 3 0 D 'ected erid r e c o w u t i o a roi the calibration of the system camera-projector and the matching between the imaged grid and the projected grid. Gf""""?trical i n f e r e n c a which includes surface parametrizalion and shape parameter ComDutations. following:"""	algorithm;correspondence problem;problem solving;sampling (signal processing);structured light;system camera;system of measurement;thinning;video projector	Latifa Guisser;René Payrissat;Serge Castan	1992		10.1109/CVPR.1992.223173	image texture;sampling;computer vision;calibration;structured light;gaussian grid;shape;computer science;image sensor;mathematics;geometry;software testing;pixel	Robotics	56.86127658421667	-48.463236072771025	51934
9b978fdc0f28545ac004f984bdbbe1dc9ca309bb	blind bandwidth extension of audio signals based on harmonic mapping in phase space	gaussian processes;audio coding;superwideband audio signal audio bandwidth extension decoder low frequency signal transmission blind bandwidth extension harmonic mapping audio signal spectral series phase space reconstruction evolutionary trajectory nonlinear prediction spectral envelope estimation gaussian mixture model wideband audio signal;signal representation;signal reconstruction;gaussian mixture model audio bandwidth extension phase space reconstruction harmonic mapping;signal representation audio coding gaussian processes signal reconstruction;harmonic analysis vectors bandwidth hafnium speech spectrogram estimation	Audio bandwidth extension can artificially restore the truncated high frequencies at the decoder from the transmitted low-frequency signal. This paper presents a new method for blind bandwidth extension of wideband audio based on harmonic mapping in phase space. First, the spectral series of audio signal is represented by using phase space reconstruction. Then, the harmonics of high frequencies are mapped out from the evolutionary trajectories of low-frequency components in phase space by using nonlinear prediction. Combining with spectral envelope estimation of high frequencies based on Gaussian mixture model, the bandwidth of wideband audio signals can be effectively extended to super wideband, without any side information. Subjective and objective testing results indicate that the proposed method improves the harmonic characteristics of the extended super-wideband audio and achieves a better quality than conventional blind bandwidth extension methods.	audio signal processing;bandwidth extension;extension method;in-phase and quadrature components;mixture model;nonlinear system	Xin Liu;Changchun Bao	2013	2013 36th International Conference on Telecommunications and Signal Processing (TSP)	10.1109/TSP.2013.6613973	signal reconstruction;speech recognition;bandwidth extension;audio signal processing;audio normalization;speech coding;gaussian process;mathematics;audio crossover;audio signal flow;audio analyzer;statistics	EDA	79.36732842557252	-35.617320514686234	51937
857a8b26061ef777aff7a7e0c08ce4e15f7cfa1d	anthropomorphic movement analysis and synthesis: a survey of methods and applications	robot sensing systems;elasticity;movement science anthropomorphic modeling control dynamics kinematics;actuators;muscles humanoid robots actuators robot sensing systems elasticity dynamics;humanoid robots;dynamics;human movement science anthropomorphic movement analysis anthropomorphic body form complex articulated system redundant system underactuated system sophisticated movement physiology anatomy biomechanics neuroscience humanoid robot design humanoid robot control literature review robotics research anthropomorphic design principles anthropomorphic body modeling motion analysis synthesis techniques;reviews control system synthesis humanoid robots motion control;muscles	The anthropomorphic body form is a complex articulated system of links/limbs and joints, simultaneously redundant and underactuated, and capable of a wide range of sophisticated movement. The human body and its movement have long been a topic of study in physiology, anatomy, biomechanics, and neuroscience and have served as inspiration for humanoid robot design and control. This survey paper reviews the literature on robotics research using anthropomorphic design principles as an inspiration, at both the design and control levels. Next, anthropomorphic body modeling, motion analysis, and synthesis techniques are overviewed. Finally, key applications arising at the intersection of robotics and human movement science are introduced. The survey ends with a discussion of open research questions and directions for future work.	humanoid robot;open research;robotics	Dana Kulic;Gentiane Venture;Katsu Yamane;Emel Demircan;Ikuo Mizuuchi;Katja D. Mombaur	2016	IEEE Transactions on Robotics	10.1109/TRO.2016.2587744	control engineering;computer vision;dynamics;simulation;computer science;engineering;humanoid robot;artificial intelligence;elasticity;actuator	Robotics	67.0925306550739	-27.32134074547673	51951
6b4c132f9b65f735e23e7a5cd16477736655ba97	wifi based indoor localization with adaptive motion model using smartphone motion sensors	ios device wifi adaptive motion model smartphone motion sensors accelerometer magnetometer gyroscope particle filter indoor localization system gaussian process regression wifi received signal strength rss dataset;legged locomotion;sensors;adaptive motion model wifi rss indoor localization gaussian process regression particle filter smartphone motion sensors;adaptation models ieee 802 11 standard mathematical model particle filters legged locomotion sensors hidden markov models;wireless lans;wireless communication systems;simulation;smartphones;wireless lan gaussian processes image sensors particle filtering numerical methods regression analysis rssi smart phones;signaling;hidden markov models;mathematical model;matlab computer program;particle filters;ieee 802 11 standard;automatic tracking;adaptation models	We present an adaptive motion model for tracking the movement of smartphone user by using the motion sensors (accelerometer, gyroscope and magnetometer) embedded in the smartphone. A particle filter based estimator is used to seamlessly fuse the adaptive motion model with a WiFi based indoor localization system. The system applies Gaussian process regression to train the collected WiFi received signal strength (RSS) dataset, and particle filter for the estimation of the smartphone user's location and movement. Simulations were conducted in MATLAB to provide more insights of the proposed approach. The experiments carried out with an iOS device in typical library environment illustrate that our system is an accurate, real-time, highly integrated system.	computer simulation;embedded system;experiment;gyroscope;indoor positioning system;kriging;matlab;motion detector;particle filter;prototype;rss;real-time clock;sensor;smartphone;tango;tracking system;ios	Xiang He;Jia Li;Daniel N. Aloi	2014	2014 International Conference on Connected Vehicles and Expo (ICCVE)	10.1109/ICCVE.2014.7297659	embedded system;electronic engineering;simulation;engineering	Robotics	56.92630627378776	-36.546054284945086	51968
bbe107c4dcd240874235b97b3e91757aa6b3664f	successive mappings: an approach to polygonal mesh simplification with guaranteed error bounds	linear programming;simplification;levels-of-detail;mapping;orthogonal projection;error bounds;surface approximation	We present the use of mapping functions to automatically generate levels of detail with known error bounds for polygonal models. We develop a piece-wise linear mapping function for each simplification operation and use this function to measure deviation of the new surface from both the previous level of detail and from the original surface. In addition, we use the mapping function to compute appropriate texture coordinates if the original model has texture coordinates at its vertices. Our overall algorithm uses edge collapse operations. We present rigorous procedures for the generation of local orthogonal projections to the plane as well as for the selection of a new vertex position resulting from the edge collapse operation. The algorithm computes guaranteed error bounds on surface deviation and produces an entire continuum of levels of detail with mappings between them. We demonstrate the effectiveness of our algorithm on several models: a Ford Bronco consisting of over 300 parts and 70; 000 triangles, a textured lion model consisting of 49 parts and86; 000 triangles, a textured, wrinkled torus consisting of 79; 000 triangles, a dragon model consisting of 871; 000 triangles, a Buddha model consisting of 1,000,000 triangles, and an armadillo model consisting of 2; 000; 000 triangles.	armadillo c++ library;bellman–ford algorithm;level of detail;polygon mesh;text simplification;texture mapping;triune continuum paradigm	Jonathan D. Cohen;Dinesh Manocha;Marc Olano	2003	Int. J. Comput. Geometry Appl.		mathematical optimization;combinatorics;linear programming;level of detail;mathematics;geometry;orthographic projection;simplification;algorithm	Graphics	69.000255568093	-42.630459728724	51986
f91797dd8e779c7f216caf0db23a22ce817bf775	supervised navigation: optimal algorithm example and needs for autonomous supervision	ifremer;sensor systems;attitude and heading reference system;intelligent control supervised navigation autonomous underwater vehicles acoustic beacons kalman filter ultra short base line array doppler log depthmeter attitude and heading reference system ifremer;underwater vehicles;kalman filters;depthmeter;kalman filter;doppler log;intelligent control;navigation;attitude control;reference systems;geophysics computing;autonomous underwater vehicles;ultra short base line array;position measurement;dead reckoning acoustic sensors acoustic measurements sea measurements underwater vehicles sonar navigation sensor systems geophysics computing position measurement switches;acoustic beacons;sonar navigation;doppler measurement;dead reckoning;acoustic sensors;supervised navigation;switches;acoustic measurements;optimal algorithm;attitude control sonar navigation marine systems intelligent control kalman filters doppler measurement;sea measurements;marine systems;sonar	This paper presents an algorithm which allows an AUV to reset its localization (position and orientation) and to estimate the water current while moving in the vicinity of two acoustic beacons. The algorithm is based on a Kalman filter which integrates the measurements provided by an ultra short base line array located in the vehicle, a Doppler log, a depthmeter and an attitude and heading reference system. After such an estimation phase, the vehicle can start to dead reckon away from the beacons in the best conditions and come back for a reset when necessary. Various considerations about the algorithm allow us to introduce the concept of 'navigation supervisor' currently under development at IFREMER. This study is conducted based on the work previously done for implementation of high-level intelligent control and mission programming.	algorithm	Jerome Vaganay;Vincent Rigaud	1995		10.1109/ROBOT.1995.525539	kalman filter;control engineering;computer vision;computer science;engineering;remote sensing;intelligent control	Robotics	56.124839634381125	-33.77429711805856	52029
6cf64559b1535f2aec7d30326b71ecc735e48db4	motor compositionality and timing: combined geometrical and optimization approaches		Human movements are characterized by their invariant spatiotemporal features. The kinematic features and internal movement timing were accounted for by the mixture of geometries model using a combination of Euclidean, affine and equi-affine geometries. Each geometry defines a unique parametrization along a given curve and the net tangential velocity arises from a weighted summation of the logarithms of the geometric velocities. The model was also extended to deal with geometrical singularities forcing unique constraints on the allowed geometric mixture. Human movements were shown to optimize different costs. Specifically, hand trajectories were found to maximize motion smoothness by minimizing jerk. The minimum jerk model successfully accounted for a range of human end-effector motions including unconstrained and path-constrained trajectories. The two modeling approaches involving motion optimality and the geometries’ mixture model are here further combined to form a joint model whereby specific compositions of geometries can be selected to generate an optimal behavior. The optimization serves to define the timing along a path. Additionally, new notions regarding the nature T. Flash · M. Karklinsky · R. Fuchs Department of CS and Applied Mathematics, Weizmann Institute of Science, Rehovot, Israel e-mail: tamar.flash@weizmann.ac.il M. Karklinsky e-mail: matan.karklinsky@weizmann.ac.il R. Fuchs e-mail: ronit.fuchs@gmail.com A. Berthoz College de France, Paris, France e-mail: alain.berthoz@gmail.com D. Bennequin Institut de Mathématiques de Jussieu, Paris 7, Paris, France e-mail: bennequin@math.univ-paris-diderot.fr Y. Meirovitch (B) Department of Computer Science and Artificial Intelligence Laboratory, MIT, 77 Massachusetts Ave, 02139 Cambridge, MA, USA e-mail: yaron.mr@gmail.com © Springer International Publishing AG, part of Springer Nature 2019 G. Venture et al. (eds.), Biomechanics of Anthropomorphic Systems, Springer Tracts in Advanced Robotics 124, https://doi.org/10.1007/978-3-319-93870-7_8 155	email;mit computer science and artificial intelligence laboratory;mathematical optimization;mixture model;robot end effector;robotics;springer (tank);velocity (software development)	Tamar Flash;Matan Karklinsky;Ronit Fuchs;Alain Berthoz;Daniel Bennequin;Yaron Meirovitch	2016		10.1007/978-3-319-93870-7_8	mixture model;jerk;smoothness;mathematical optimization;parametrization;kinematics;affine transformation;invariant (mathematics);euclidean geometry;mathematics	Robotics	67.05151323542438	-30.11786121111068	52106
5e398b4267e77c609b5c2c6e9503306d701d6111	calibration of a head-mounted operating microscope for augmented reality visualization in cas	augmented reality		augmented reality	Wolfgang Birkfellner;Michael Figl;Klaus Huber;Franz Watzinger;Felix Wanschitz;Rudolf Hanel;Johann Hummel;Rolf Ewers;Helmar Bergmann	2001			computer vision;calibration;operating microscope;visualization;computer graphics (images);artificial intelligence;augmented reality;medicine	Visualization	60.531214086929154	-47.542007461595404	52107
9deb6c8258b6599331cf6547307bbd63f460f33b	learning for autonomous navigation	navegacion;vegetation mapping;robot sensing systems;movilidad;field robotics;mobile robot;autonomous system;mobility;path planning;mobile robots;robotics;mobilite;crusher autonomous navigation robotics defense advanced research projects agency ugcv perceptor integration program autonomous outdoor mobile robot design safe autonomous traverse machine learning techniques;sistema autonomo;autonomic system;navigation;control system;machine learning techniques;crusher;machine learning;autonomic systems;navigation mobile robots machine learning service robots remotely operated vehicles control systems defense industry electrical equipment industry industrial control robustness;systeme autonome;defense advanced research projects agency;next generation;safe autonomous traverse;robotica;autonomous navigation;ugcv perceptor integration program;robotique;vehicles;learning artificial intelligence;vehiculo todo terreno;crosscountry vehicle;defense advanced research project agency;path planning learning artificial intelligence mobile robots;cameras;autonomous outdoor mobile robot design;vehicule tout terrain	Autonomous navigation by a mobile robot through L natural, unstructured terrain is one of the premier k challenges in field robotics. Tremendous advances V in autonomous navigation have been made recently in field robotics. Machine learning has played an increasingly important role in these advances. The Defense Advanced Research Projects Agency (DARPA) UGCV-Perceptor Integration (UPI) program was conceived to take a fresh approach to all aspects of autonomous outdoor mobile robot design, from vehicle design to the design of perception and control systems with the goal of achieving a leap in performance to enable the next generation of robotic applications in commercial, industrial, and military applications. The essential problem addressed by the UPI program is to enable safe autonomous traverse of a robot from Point A to Point B in the least time possible given a series of waypoints in complex, unstructured terrain separated by 0.2-2 km. To accomplish this goal, machine learning techniques were heavily used to provide robust and adaptive performance, while simultaneously reducing the required development and deployment time. This article describes the autonomous system, Crusher, developed for the UPI program and the learning approaches that aided in its successful performance.	autonomous robot;autonomous system (internet);control system;fermat's principle;machine learning;mobile robot;next-generation network;robotics;software deployment;traverse	J. Andrew Bagnell;David M. Bradley;David Silver;Boris Sofman;Anthony Stentz	2010	IEEE Robotics & Automation Magazine	10.1109/MRA.2010.936946	control engineering;mobile robot;robot learning;computer vision;simulation;computer science;engineering;control system;artificial intelligence;robotics	Robotics	55.081915412954146	-30.532129540523965	52137
d7498321121c85c863b790bd85e124e564bd4e34	coding of video-conference stereo image sequences using 3d models	prediction error;image coding;video conference;virtual reality;motion estimation;image texture;3d model;image sequence;video transmission	In this paper we propose an object-based stereo image coding algorithm. The algorithm relies on modeling of the object structure using 3D wire-frame models, and motion estimation using globally rigid and locally deformable motion models. Algorithms for the estimation of motion and structure parameters from stereo images are described. Motion parameters are used to construct predicted images at subsequent time instances by mapping the image texture on the object surface. Coding of object parameters, appearing background regions and prediction errors is investigated and experimental results with video-conference scenes are presented. The proposed algorithm is very efficient for applications like stereoscopic video transmission, and is especially suited to advanced applications such as generation and transmission of intermediate views for multiview receiver systems, as well as applications in which an object-wise editing of the bit-stream is required, such as video-production using preanalysed scenes or virtual reality applications.	3d modeling;algorithm;bitstream;image texture;motion estimation;object-based language;stereoscopy;virtual reality;wire-frame model	Sotiris Malassiotis;Michael G. Strintzis	1997	Sig. Proc.: Image Comm.	10.1016/S0923-5965(96)00014-8	image texture;computer vision;simulation;quarter-pixel motion;computer science;mean squared prediction error;motion estimation;virtual reality;videoconferencing;computer graphics (images)	Vision	59.26737088292566	-49.58681009550771	52173
7756d39e6a702bd239711b73c2f41fca2fa8e2ef	development of femoral bone fracture model simulating muscular contraction force by pneumatic rubber actuator	radiography biomechanics bone fracture muscle;muscles force atmospheric modeling robots mathematical model bones force measurement;artificial muscle femoral bone fracture model muscular contraction force orthopedic surgeons 2d fluoroscopic images robotic assistance cadavers animals mckibben type pneumatic rubber actuator	In femoral fracture reduction, orthopedic surgeons must pull distal bone fragments with great traction force and return them to their correct positions, by referring to 2D-fluoroscopic images. Since this method is physically burdensome, the introduction of robotic assistance is desirable. While such robots have been developed, adequate control methods have not yet been established because of the lack of experimental data. It is difficult to obtain accurate data using cadavers or animals because they are different from the living human body's muscle characteristics and anatomy. Therefore, an experimental model for simulating human femoral characteristics is required. In this research, human muscles are reproduced using a McKibben-type pneumatic rubber actuator (artificial muscle) to develop a model that simulates typical femur muscles using artificial muscles.	actuator device component;anatomic structures;bone tissue;cadaver;femoral fractures;fracture;muscle contraction;orthopedics;pneumatic artificial muscles;robot (device);simulation;traction teampage	Shin Sen;Takehiro Ando;Etsuko Kobayashi;Hideaki Miyamoto;Satoru Ohashi;Sakae Tanaka;Sanghyun Joung;Ilhyung Park;Ichiro Sakuma	2014	2014 36th Annual International Conference of the IEEE Engineering in Medicine and Biology Society	10.1109/EMBC.2014.6945207	biological engineering;anatomy;surgery	Robotics	74.13858792405132	-28.820078258997306	52253
c4da64332820621a24a1971d709545b85acd4df7	multi-purpose environment awareness approach for single line laser scanner in a small rotorcraft ua	tecnologia industrial tecnologia mecanica;tecnologia electronica telecomunicaciones;unbemannte luftfahrzeuge;environment detection;small uav;laser scanning;tecnologias;grupo a	"""The work presents an environment awareness approach for a small rotorcraft unmanned aircraft (UA) which operates at low height using a single line laser scanner which enables a height estimation with a concurrent detection of ground fixed obstacles. The approach is suitable for small UA which are not able to carry complex and heavy 3D laser scanner mountings having additional drives or mirrors. It works without using external reference systems like DGPS. The approach was especially developed for a mission of the """"International Micro Air Vehicle Conference"""" outdoor contest, where it is the aim to fly through a 6x6m artificial gate. The sensor data processing enables the height estimation above ground as well as the detection of obstacles in order to meet the mission's goal. The height estimation enables a near-ground flight to prevent a collision with a top boundary of the gate, and a terrain following. The obstacle detection senses the pillars of the gate and finds a safe way through the narrow gate passage. The development and optimisation of the mounting and the sensor processing, as well as the validation, was realized under operational conditions with manual remote control (RC) helicopter flights and virtual flights at a simulation environment. The results of the experiments show that with this approach the mission can be fulfilled as a reliable ground estimation and object detection is ensured."""	user agent	Stefan Krause	2012	Journal of Intelligent and Robotic Systems	10.1007/s10846-011-9572-6	laser scanning;embedded system;simulation;engineering;electrical engineering	Robotics	57.14083609753747	-29.46775957354021	52311
37340038625f6782fa1997b0c04d4b41de47914e	positional kinematics of humanoid arms	reachable workspace;humanoid arm;reachability;human arm;humanoid manipulator;kinematical model;self motion	We present the positional abilities of a humanoid manipulator based on an improved kinematical model of the human arm. This was synthesized from electro-optical measurements of healthy female and male subjects. The model possesses three joints: inner shoulder joint, outer shoulder joint and elbow joint. The first functions as the human sternoclavicular joint, the second functions as the human glenohumeral joint, and the last replicates the human humeroulnar rotation. There are three links included, the forearm and the upper arm link which are of a constant length, and the shoulder link which is expandable. Mathematical interrelations between the joint coordinates are also taken into consideration. We determined the reachability of a humanoid arm, treated its orienting redundancy in the shoulder complex and the positional redundancy in the shoulder-elbow complexes, and discussed optimum configurations in executing different tasks. The results are important for the design and control of humanoid robots, in medicine and sports.	coat of arms;inverse kinematics	Jadran Lenarcic;Nives Klopcar	2006	Robotica	10.1017/S0263574705001906	simulation;engineering;humanoid robot;reachability;engineering drawing	Robotics	69.29790124428739	-24.003947184978667	52390
222e5d6ff5d3b0ea5918a04b5e054f07e57a1cfd	volume rendering by adaptive refinement	trazado rayos;metodo adaptativo;vision ordenador;medical imagery;representation tridimensionnelle;image processing;computer graphics;volume rendering;echantillonnage;espacio 3 dimensiones;trace rayon;methode adaptative;adaptive refinement;voxel;computer graphic;computer vision;sintesis imagen;sampling;algorithme;image synthesis;algorithm;refinement method;medical image;espace 3 dimensions;image quality;adaptive method;three dimensional space;ray tracing;imagerie medicale;adaptive sampling;synthese image;three dimensional representation;vision ordinateur;imageneria medical;methode affinement;muestreo;grafico computadora;metodo afinamiento;infographie;representacion tridimensional;algoritmo	Volume rendering is a technique for visualizing sampled scalar functions of three spatial dimensions by computing 2D projections of a colored semi-transparent gel. This paper presents a volume-rendering algorithm, in which image quality is adaptively refined over time. An initial image is generated by casting a small number of rays into the data, less than one ray per pixel, and interpolating between the resulting colors. Subsequent images are generated by alternately casting more rays and interpolating. The usefulness of these rays is maximized by distributing them according to measures of local image complexity. Examples from two applications are given: molecular graphics and medical imaging.	algorithm;color;image quality;interpolation;medical imaging;molecular graphics;pixel;refinement (computing);semiconductor industry;volume rendering	Marc Levoy	1990	The Visual Computer	10.1007/BF01902624	image quality;three-dimensional space;sampling;ray tracing;computer vision;image processing;computer science;computer graphics;voxel;volume rendering;computer graphics (images)	Graphics	70.71052609807133	-50.796792519752984	52409
4dfffb0f10a33283a3793f03d83f932ebab75d97	remote interactive visualization for particle-based simulations on graphics clusters		Particle-based models are widely spread in the field of Computer Graphics, and mainly used for real-time simulations of soft deformable bodies. However, simulations including high-resolution models have a great computational cost and, when adding the need for real-time rendering and interaction, they fall way outside the range of applications that traditional computing architectures can accommodate. Graphics clusters can offer the raw computing power needed for such simulations but, due to their physical design and operating mode, introduce a series of challenges that must be overcome, such as efficient distributed rendering and remote visualization and interaction with the simulated scenes. This paper presents a solution to interactive visual particle-based simulations on graphics clusters using an optimized in-situ distributed rendering approach which, coupled with state-of-the-art remote visualization and interaction techniques and tools, provide efficient means for highly scalable interactive simulations.	algorithm;algorithmic efficiency;computation;computer graphics;image resolution;interaction technique;interactive visualization;parallel rendering;particle filter;physical design (electronics);real-time clock;real-time computing;real-time transcription;scalability;simulation	Adrian Sabou;Dorian Gorgan	2017	2017 40th International Convention on Information and Communication Technology, Electronics and Microelectronics (MIPRO)	10.23919/MIPRO.2017.7973429	computer network;software rendering;theoretical computer science;parallel rendering;scientific visualization;rendering (computer graphics);real-time computer graphics;computer graphics;alternate frame rendering;computer science;tiled rendering;computational science	Visualization	69.33768606610248	-50.84249401552689	52441
517f3c699885efaf314c85bd999aec3fc29dc60e	interpolation of curve data by blended generalized circles	cubic spline	Abstract   We present a  GC  1 -interpolant for 2D curve data. The idea is to assign certain circles or straight lines (both are so-called generalized circles when identifying   C   and   R     2   ) to a given data set of 2D points and to blend these frames. Several properties of the interpolant are presented and practical experience in comparison to parametric cubic spline interpolants is reported.	interpolation	Hans-Jörg Wenz	1996	Computer Aided Geometric Design	10.1016/0167-8396(95)00054-2	spline interpolation;spline;mathematical optimization;discrete mathematics;smoothing spline;monotone cubic interpolation;mathematics;geometry	EDA	69.33012886022651	-40.84294251620119	52516
1f2260119ec721e13117086392d3196aa7ef42fd	a preliminary experimental study on haptic teleoperation of mobile robot with variable force feedback gain	variable force feedback gain;motion control;sensors;mobile robot;gain;haptic interfaces mobile robots force feedback robot motion force control motion control robot control distortion measurement gain measurement force measurement;mobile robots;force;force feedback;haptic feedback haptic teleoperation mobile robot variable force feedback gain obstacle range information human operator command force rendering;telerobotics force feedback haptic interfaces mobile robots;obstacle range information;telerobotics;haptic feedback;haptic teleoperation;haptic interfaces;force rendering;human operator command	In this paper, new force feedback rendering scheme for mobile robot teleoperation is presented. Previous research indicated the problem of the low quality of mobile robot's motion control during the teleoperation with feedback force based on obstacle range information. Human-operator's commands were distorted by the feedback force, as a result, mobile robot could not follow human-operator's intention. To solve this problem, a new force rendering approach with variable feedback gain is proposed. Force feedback gain is variable based on measured distances to the obstacle and derivatives of the distances. Simulation and experimental study showed that the variable haptic feedback improves the quality of mobile robot teleoperation. variable feedback force improved the quality of mobile robot teleoperation by making robot's trajectory smooth and accurate.	experiment;feedback;haptic technology;meltwater entrepreneurial school of technology;mobile robot;simulation	Ildar Farkhatdinov;Jee-Hwan Ryu;Jinung An	2010	2010 IEEE Haptics Symposium	10.1109/HAPTIC.2010.5444649	control engineering;computer vision;control theory;robot control	Robotics	62.301278753030104	-27.10963132374079	52662
90b71c93f2a2db381e6b0c18ec6a7b430878af42	encoder-camera-ground penetrating radar tri-sensor mapping for surface and subsurface transportation infrastructure inspection		We report system and algorithmic development for a sensing suite comprising multiple sensors for both surface and subsurface transportation infrastructure inspection focusing on multi-modal mapping for inspection. The sensing suite contains a camera, a ground penetrating radar (GPR), and a wheel encoder. We design the sensing suite and propose a data collection scheme using customized artificial landmarks (ALs). We use ALs to synchronize two types data streams: camera images that are temporally evenly-spaced and GPR/encoder data that are spatially evenly-spaced. We also employ pose graph optimization with synchronization as penalty functions to further refine synchronization and perform data fusion for 3D reconstruction. We have implemented the system and tested it in physical experiments. The results show that our system successfully fuses three sensory data and product metric 3D reconstruction. The sensor fusion approach reduces the end-to-end distance error from 7.45cm to 3.10cm.	3d reconstruction;algorithm;analysis of algorithms;encoder;end-to-end principle;experiment;kriging;mathematical optimization;modal logic;sensor;synchronization (computer science);systems design;triangular function;warez	Chieh Chou;Aaron Kingery;Di Wang;Haifeng Li;Dezhen Song	2018	2018 IEEE International Conference on Robotics and Automation (ICRA)	10.1109/ICRA.2018.8461080	encoder;control engineering;ground-penetrating radar;data collection;3d reconstruction;computer vision;data stream mining;synchronization;sensor fusion;engineering;graph;artificial intelligence	Robotics	54.508512982673516	-35.549296383718996	52671
646c196162161536eee9f9c6511351b28b8e8336	learning manipulation actions from human demonstrations	grasping;motion segmentation;trajectory;grippers;optimization	Learning from demonstration is a popular approach for teaching robots as it allows service robots to acquire new skills without explicit programming. However, for manipulation actions mostly kinesthetic teaching is used as these actions require precise knowledge about the interactions between the robot and the object. In this paper, we present a novel approach that allows a robot to learn actions carried out by a teacher from observations. We achieve this by first transforming RGBD observations to consistent hand-object trajectories, which are then adapted to the robot's grasping capabilities. Experimental results show that the robot is able to learn complex tasks such as opening doors or drawers.	experiment;interaction;motion capture;robot	Tim Welschehold;Christian Dornhege;Wolfram Burgard	2016	2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)	10.1109/IROS.2016.7759555	robot learning;computer vision;simulation;engineering;trajectory;social robot	Robotics	61.87832599998805	-25.28163408703959	52789
5cb75b95b930a1f46809efb60750d67b25c72f05	spherical assistant for stereotactic surgery	stereotactic surgery;manipulator kinematics;medical robotics;robot manipulator;forward kinematics;spherical assistant;kinematic design;control system synthesis;surgery;inverse kinematics;inverse kinematics stereotactic surgery robotic manipulator spherical assistant kinematic design small animals forward kinematics;surgery control system synthesis manipulator kinematics medical robotics;robotic manipulator;surgery manipulators kinematics probes implants animals satellite broadcasting error correction robots neurotransmitters;small animals	This contribution reports the development of a novel robotic manipulator for stereotactic surgery on small animals, the spherical assistant for stereotactic surgery (SAS- SU). A kinematic design is deduced based on the surgical task requirements. Forward and inverse kinematics are derived analytically. As the system is required to position medical probes of varying size and shape, details on the calibration for different probe configurations are provided. The kinematic design of the novel manipulator is compared to an existing stereotactic instrument in terms of kinematic accuracy. Results show that the SASSU systems is less sensitive to translational positioning errors induced by changes in the joint variables.	computer simulation;fixed point (mathematics);inverse kinematics;repeatability;requirement;robot;workspace	Lukas Ramrath;Ulrich G. Hofmann;Achim Schweikard	2007	2007 IEEE/RSJ International Conference on Intelligent Robots and Systems	10.1109/IROS.2007.4398985	control engineering;computer vision;simulation;computer science;engineering;artificial intelligence;inverse kinematics;321 kinematic structure;forward kinematics	Robotics	72.82805833905954	-28.423202557891248	52861
97c5878e6d5e29ca00f53d95394ad10739c7cca4	screen space anisotropic blurred soft shadows by efficient separable filtering method	shadow mapping;computer graphics;geometry;rendering computer graphics filtering theory real time systems;receivers;real time rendering computer graphics shadow mapping soft shadow screen space;shape;soft shadow;rendering computer graphics geometry shadow mapping light sources receivers approximation methods shape;real time rendering screen space anisotropic blurred soft shadows method efficient separable filtering method shadow mapping method real time computer graphics;approximation methods;rendering computer graphics;filtering theory;light sources;real time rendering;real time systems;screen space	Shadow mapping is an efficient method to generate shadows in real time computer graphics and has broad variations from hard to soft shadow synthesis. Soft shadowing based on shadow mapping is a blurring technique on a shadow map or on screen space. Blurring on screen space can easily combine with a deferred shading pipeline. However, blurring on screen space has a drawback: the generated shadow is not correct when a view direction has a large angle to the normal of the shadowed plane. In this paper, we introduce a new screen space based method for soft shadowing that is faster and generates more accurate soft shadows than the previous screen space soft shadow mapping method. The resultant images show shadows by our method just stand in the same place, while shadows by the previous method change in terms of penumbra while the view moves. Surprisingly, although our method is more complex than the previous method, the measurement of the calculation time shows our method is also faster than the previous method. This is because our method controls the blurring area more accurately and thus successfully reduces multiplications for blurring.	algorithm;algorithmic efficiency;approximation;bilateral filter;computation;deferred shading;gaussian blur;graphics processing unit;ground truth;resultant;self-shadowing;separable polynomial;shadow mapping	Zhongxiang Zheng;Suguru Saito	2013	2013 International Conference on Cyberworlds	10.1109/CW.2013.75	computer vision;shape;computer science;geometry;shadow mapping;shadow volume;real-time rendering;computer graphics;computer graphics (images)	Graphics	65.85121023866652	-51.23272280628174	52979
adaa1ded5004c6857e2e543a775838ee5ccc87c6	manifold-based surfaces with boundaries	concepcion asistida;computer aided design;modele geometrique;manifolds;flexibilidad;piecewise smooth;variedad matematica;derivee;conception assistee;high order surfaces;geometric modeling;flexibilite;geometric model;derivada;flexibility;derivative;geometrical model;variete mathematique;manifold;modelo geometrico	We present a manifold-based surface construction extending the C∞ construction of Ying and Zorin (2004a). Our surfaces allow for pircewise-smooth boundaries, have user-controlled arbitrary degree of smoothness and improved derivative and visual behavior. 2-flexibility of our surface construction is confirmed numerically for a range of local mesh configurations.	b-spline;basis function;catmull–clark subdivision surface;concave function;numerical analysis;spline (mathematics);vertex (geometry)	Elif Tosun;Denis Zorin	2011	Computer Aided Geometric Design	10.1016/j.cagd.2010.07.005	combinatorics;topology;manifold;geometric modeling;computer aided design;mathematics;geometry	Graphics	68.13059137248128	-40.692867133930456	52996
ca9ca34abec82eaaba9517a4fa3fffcca746f4c0	control strategies for the index finger of a tendon-driven hand	tendon driven robots;robot hand control;joint stiffness control;human hand control	To understand how versatile dexterity is achieved in the human hand and to achieve it in a robotic form, we have constructed an anatomically correct testbed (ACT) hand. This paper focuses on the development of control strategies for the index finger motion and implementation of joint passive behavior in the ACT hand. A direct muscle position control and a force-optimized joint control are implemented for position tracking through muscle force control. The relationships between the muscle and joint motions play a critical role in both of the controllers and we implemented a Gaussian process regression technique to determine these relationships. Our experiments demonstrate that the direct muscle position controller allows for fast position tracking, while the force-optimized joint controller allows for the exploitation of actuation redundancy in the finger critical for this redundant system. We demonstrate that by implementing a passive force-length relationship at each muscle we are able to precisely match joint stiffness of the metacarpophalangeal (MCP) joint of the ACT to that of a human MCP joint. We also show the results from improved position tracking when implemented in the presence of passive muscle control schemes. The control schemes for position tracking and passive behavior are inspired by human neuromuscular control, and form the building blocks for developing future human-like control approaches.		Ashish D. Deshpande;Jonathan Ko;Dieter Fox;Yoky Matsuoka	2013	I. J. Robotics Res.	10.1177/0278364912466925	control engineering;simulation;engineering;control theory	Robotics	69.3511732720991	-24.631208433874537	53054
8c80d1ef7576016ce6ad6f9f09a685192dbdd629	manifold learning for the emulation of spatial fields from computational models	qa mathematics	Repeated evaluations of expensive computer models in applications such as design optimization and uncertainty quantification can be computationally infeasible. For partial differential equation (PDE) models, the outputs of interest are often spatial fields leading to high-dimensional output spaces. Although emulators can be used to find faithful and computationally inexpensive approximations of computer models, there are few methods for handling high-dimensional output spaces. For Gaussian process (GP) emulation, approximations of the correlation structure and/or dimensionality reduction are necessary. Linear dimensionality reduction will fail when the output space is not well approximated by a linear subspace of the ambient space in which it lies. Manifold learning can overcome the limitations of linear methods if an accurate inverse map is available. In this paper, we use kernel PCA and diffusion maps to construct GP emulators for very high-dimensional output spaces arising from PDE model simulations. For diffusion maps we develop a new inverse map approximation. Several examples are presented to demonstrate the accuracy of our approach.	computational model;emulator;nonlinear dimensionality reduction	W. W. Xing;V. Triantafyllidis;A. A. Shah;P. B. Nair;Nicholas Zabaras	2016	J. Comput. Physics	10.1016/j.jcp.2016.07.040	diffusion map;mathematical optimization;discrete mathematics;machine learning;mathematics;physics;algorithm;statistics	Logic	76.21023054578386	-47.180008566480446	53113
e7278665258dd2793684d5ff3e7e24fd9a6a5674	mechanical design and tactile sensing in dexterous robot hands manipulation		Mechanical design and tactile sensing are essential parts for dexterous hands, which decide stability and flexibility of robotics fingers movements. They are used on various application scenarios, IC equipment, medical apparatus and instruments, etc. This paper introduces mechanical structure and tactile sensing in domestic and overseas dexterous hands, such as Robonaut multifingers dexterous hand, Shadow hand, Gifu II hand, etc. The characters of these hands are also introduced in detail. According to various of dexterous hands, mechanical design of them are divided into two series, conventional design and creative design. Tactile sensors layout scheme and application are presented. This paper gives some probable future research directions in the end.	robot	Wenliang Zhang;Yiyong Yang;Fuchun Sun;Bin Xing Fang	2016		10.1007/978-981-10-5230-9_6	computer vision;robot;shadow hand;tactile sensor;computer science;robotics;robonaut;artificial intelligence	Robotics	67.00959980119971	-29.67288831055236	53121
347c5026c666a469de644aa78b9074bf0dee22ab	double actuator unit with planetary gear train for a safe manipulator	position control actuators feedback force control manipulators mobile robots;manipulators;actuators gears force control force sensors safety manipulators control systems torque robot control robot sensing systems;indirect impedance control;double actuator unit;service robots;actuators;mobile robots;robot manipulator;direct feedback control system;feedback;service robots double actuator unit planetary gear train robot manipulator direct feedback control system force torque sensor indirect impedance control force control position control collision safety;position control;service robot;planetary gear train;force torque sensor;impedance control;collision safety;feedback control;force sensor;force control	Control of a robot manipulator in contact with the environment is usually conducted by the direct feedback control system using a force-torque sensor or the indirect impedance control scheme. Although these methods have been successfully applied to many applications, simultaneous control of force and position cannot be achieved. Furthermore, collision safety has been of primary concern in recent years with emergence of service robots in direct contact with humans. To cope with such problems, redundant actuation has been used to enhance the performance of a position/force controller. In this paper, the novel design of a double actuator unit (DAU) composed of double actuators and a planetary gear train is proposed to provide the capability of simultaneous control of position and force as well as the improved collision safety. Since one actuator controls position and the other actuator modulates stiffness, DAU can control the position and stiffness simultaneously at the same joint. The torque exerted on the joint can be estimated without an expensive torque/force sensor. DAU is capable of detecting dynamic collision by monitoring the speed of the stiffness modulator. Upon detection of dynamic collision, DAU immediately reduces its joint stiffness according to the collision magnitude, thus providing the optimum collision safety. It is shown from various experiments that DAU can provide good performance of position tracking, force estimation and collision safety.	characteristic impedance;control system;emergence;encoder;experiment;feedback;humanoid robot;humans;modulation;planetary scanner;rf modulator;robot;sensor	Byeong-Sang Kim;Jung-Jun Park;Jae-Bok Song	2007	Proceedings 2007 IEEE International Conference on Robotics and Automation	10.1109/ROBOT.2007.363139	control engineering;simulation;computer science;engineering;control theory;feedback	Robotics	70.61526096570913	-24.47914445688054	53132
aea8d9c4becfe4dadd05609455a86a885de21c62	efficient magnetic localization and orientation technique for capsule endoscopy	optimisation biomedical optical imaging endoscopes permanent magnets position control;optimisation;magnetic field;magnetic sensor;position control;wireless capsule endoscopy;optimization wireless capsule endoscopy localization and orientation magnet;endoscopes;sensor array;wireless capsule endoscopy magnetic localization wireless robotic capsule endoscope external guidance controllable gi tract examination interactive gi tract examination 3d location tracking 2d orientation capsule movement permanent magnet magnetic field magnetic sensor array optimization algorithm nonlinear optimization algorithms levenberg marquardt method sensor arrays;capsule endoscopy;permanent magnet;biomedical optical imaging;permanent magnets;nonlinear optimization;optimal algorithm;levenberg marquardt method;endoscopes sensor arrays magnetic sensors wireless sensor networks robot sensing systems control systems gastrointestinal tract tracking permanent magnets magnetic fields	To build a new wireless robotic capsule endoscope with external guidance for controllable and interactive GI tract examination, a sensing system is needed for tracking 3D location and 2D orientation of the capsule movement. An appropriate sensing approach is to enclose a small permanent magnet in the capsule. The magnet establishes a magnetic field around the patient's body. With the sensing data of magnetic sensor array outside the patient's body, the 3D location and 2D orientation of the capsule can be calculated. Higher localization and orientation accuracy can be obtained if more sensors and proper optimization algorithm are applied. In this paper, different nonlinear optimization algorithms are evaluated, and we have found that Levenberg-Marquardt method provides higher accuracy and faster speed. Simulations were done for investigating the de-noise ability of this algorithm based on different sensor arrays. Furthermore, the real experiment shows that the results are satisfactory with high accuracy.		Chao Hu;Max Q.-H. Meng;Mrinal Kanti Mandal	2005		10.1109/IROS.2005.1545490	control engineering;magnet;electronic engineering;nonlinear programming;engineering;biological engineering;quantum mechanics	Robotics	72.0376831879971	-30.903966166699252	53134
16e4cf5fb17ab2b403137429888993ddf691e7b9	passive range estimation for rotorcraft low-altitude flight	analisis imagen;obstaculo;vision ordenador;helicoptero;filtro kalman;aircraft guidance;monitoring control system;nap of the earth navigation;image understanding;filtre kalman;kalman filters;systeme controle commande;automatisation;electro optics;kalman filter;flight;intelligence artificielle;air transportation;sistema control mando;automatizacion;navigational aid;computer vision;aterrizaje;captador medida;vol;transport aerien;transporte aereo;prevencion esquiva colision;helicoptere;measurement sensor;capteur mesure;rangefinding;obstacle avoidance;feature extraction;prevention esquive collision;intelligent system;low altitude;pattern recognition;aide navigation;estimating;artificial intelligence;algorithms;image analysis;vision ordinateur;optical flow;collision avoidance;helicopter;inteligencia artificial;rotary wing aircraft;landing;ayuda navegacion;vuelo;analyse image;obstacle;atterrissage;automation	The automation of rotorcraft low-altitude flight presents challenging problems in control, computer vision, and image understanding. A critical element in this problem is the ability to detect and locate obstacles, using on-board sensors, and to modify the nominal trajectory. This requirement is also necessary for the safe landing of an autonomous lander on Mars. This paper examines some of the issues in the location of objects, using a sequence of images from a passive sensor, and describes a Kalman filter approach to estimate range to obstacles. The Kalman filter is also used to track features in the images leading to a significant reduction of search effort in the feature-extraction step of the algorithm. The method can compute range for both straightline and curvilinear motion of the sensor. An experiment is designed in the laboratory to acquire a sequence of images along with the sensor motion parameters under conditions similar to helicopter flight. The paper presents range estimation results using this imagery.	algorithm;autonomous robot;computer vision;critical graph;feature extraction;kalman filter;lunar lander (video game series);on-board data handling;sensor	Banavar Sridhar;Raymond E. Suorsa;Bassam Hussien	1992	Machine Vision and Applications	10.1007/BF01212428	kalman filter;computer vision;image analysis;simulation;computer science	Robotics	57.061176198632076	-33.39351170485402	53144
39b3df9ef84443b3f8d10ab773fd7e2addaa6bfe	noise power spectrum estimation using constrained variance spectral smoothing and minima tracking	spectre puissance;noise estimation;nivel ruido;traitement signal;metodo adaptativo;noise power spectrum;evaluation performance;amelioration parole;voice activity detector;performance evaluation;signal estimation;spectrum analysis;analyse spectre;data smoothing;analisis espectro;evaluacion prestacion;signal analysis;speech processing;tratamiento palabra;niveau bruit;traitement parole;analisis de senal;methode adaptative;noise power spectrum estimation;speech enhancement;power spectrum;noise measurement;senal vocal;espectro potencia;reduccion ruido;algorithme;algorithm;signal vocal;spectre bruit;noise level;mesure bruit;signal processing;noise reduction;adaptive method;estimacion senal;poursuite cible;reduction bruit;methode moyenne;lissage donnees;acoustic signal detection;signal acoustique;adaptive smoothing;acoustic signal;temps retard;delay time;noise spectrum;target tracking;vocal signal;procesamiento senal;estimation signal;alisadura datos;tiempo retardo;averaging method;detection signal acoustique;analyse signal;senal acustica;metodo medio;espectro ruido;algoritmo	In this paper, we propose a new noise estimation algorithm based on tracking the minima of an adaptively smoothed noisy short-time power spectrum (STPS). The heart of the proposed algorithm is a constrained variance smoothing (CVS) filter, which smoothes the noisy STPS independently of the noise level. The proposed smoothing procedure is capable of tracking the non-stationary behavior of the noisy STPS while reducing its variance. The minima of the smoothed STPS are tracked with a low delay and are used to construct voice activity detectors (VAD) in frequency bins. Finally, the noise power spectrum is estimated by averaging the noisy STPS on the noise-only regions. Experiments show that the proposed noise estimation algorithm possesses a very short delay in tracking the non-stationary behavior of the noise. When the proposed algorithm is utilized in a noise reduction system, it exhibits superior performance over the other recently proposed noise estimation algorithms.	maxima and minima;noise power;smoothing;spectral density estimation	Nima Derakhshan;Ahmad Akbari;Ahmad Ayatollahi	2009	Speech Communication	10.1016/j.specom.2009.04.008	spectrum analyzer;speech recognition;telecommunications;computer science;noise measurement;signal processing;noise reduction;mathematics;spectral density;smoothing	Vision	81.25759854664703	-32.0663011196166	53282
c47d21bc440f5eb1af87223ce864b599da60fa51	sparse bayesian hierarchical prior modeling based cooperative spectrum sensing in wideband cognitive radio networks	belief networks;variational techniques belief networks cognitive radio cooperative communication learning artificial intelligence message passing network theory graphs radio spectrum management signal representation spectral analysis;variational techniques;cognitive radio;cooperative communication;variational message passing bayesian hierarchical model cognitive radio compressive sensing cooperative spectrum sensing sparse estimation;signal representation;psd map sparse bayesian hierarchical prior modeling cooperative spectrum sensing wideband cognitive radio network sparse bayesian learning penalization factor graph signal model representation variational message passing vmp algorithm power spectral density;message passing;radio spectrum management;learning artificial intelligence;spectral analysis;network theory graphs;sensors vectors bayes methods niobium signal processing algorithms estimation cognitive radio	This letter proposes a new method for cooperative spectrum sensing by exploiting sparsity. The novel scheme uses the theory of Bayesian hierarchical prior modeling in the framework of sparse Bayesian learning. This model has sparsity-inducing penalization terms leading to sparser solutions compared with typically l1 norm based ones. Based on the factor graph that represents the signal model of the hierarchical prior models, the variational message passing (VMP) algorithm is implemented to estimate the power spectral density (PSD) map.	algorithm;bayesian network;boundary element method;cognitive radio;estimation theory;factor graph;hierarchical database model;iterative method;sparse matrix;spectral density;taxicab geometry;variational message passing;variational principle	Feng Li;Zongben Xu	2014	IEEE Signal Processing Letters	10.1109/LSP.2014.2311902	cognitive radio;message passing;computer science;theoretical computer science;machine learning;pattern recognition	Vision	74.63855982563086	-36.47411705733013	53310
bffb197c4b1011d7898ded423a7c1542359fae94	automatic ship positioning and radar biases correction using the hausdorff distance	satellite images;kalman filtering;radar imaging image matching kalman filters;gps denied environments automatic ship positioning radar biases correction association algorithms ship borne radar image matching geo referenced satellite images partial hausdorff kalman filter automatic radar calibration position sensor;radar tracking;image matching;kalman filters;filters;kalman filter;gps denied environments;yield estimation;automatic radar calibration;association algorithms;marine vehicles;geo referenced satellite images;satellites;radar imaging;marine vehicles radar imaging spaceborne radar radar tracking yield estimation satellites robustness velocity measurement filters calibration;position estimation;track to track association radar biases satellite images hausdorff distance kalman filtering;hausdorff distance;satellite image;robustness;partial hausdorff;radar biases;velocity measurement;calibration;automatic ship positioning;radar biases correction;ship borne radar image matching;track to track association;position sensor;spaceborne radar	This paper describes a novel technique to obtain radar biases estimates that can effectively reduce mismatches in track association algorithms. This is accomplished by matching ship-borne radar images to geo-referenced satellite images. The matching is performed through the minimization of the averaged partial Hausdorff distance between data points in each image. The minimization rapidly yields robust latitude and longitude position estimates, as well as ship heading and radar biases. The accuracy of the measurements is improved by feeding them into a Kahnan filter, which also yields estimates for the ship's velocity. The method can be employed for automatic radar calibration of bearing and range biases, while it also serves as an alternative effective position sensor for GPS-denied environments.	algorithm;course (navigation);data point;dynamical system;encoder;geographic coordinate system;global positioning system;guidance system;hausdorff dimension;kalman filter;landmark point;lateral thinking;particle filter;radar;real-time clock;sensor;software maintenance;velocity (software development)	Miguel Torres-Torriti;Andres Guesalaga	2007	2007 10th International Conference on Information Fusion	10.1109/ICIF.2007.4408137	computer vision;geography;geodesy;remote sensing	Robotics	54.00683546818414	-36.95655899427501	53317
d2a839a07e5cb9ff5ed66e03e3a5ba042a868827	force control strategy for a hand exoskeleton based on sliding mode position control	rehabilitation;motion control;force sensors;patient rehabilitation;hand exoskeleton;force control rehabilitation exoskeleton;variable structure systems force control force sensors friction medical robotics motion control patient rehabilitation position control robot dynamics;variable structure systems;medical robotics;exoskeleton;position control;force sensors force control hand exoskeleton sliding mode position control rehabilitation process hand injuries motion control friction;rehabilitation process;force control exoskeletons position control sliding mode control force sensors fingers humans injuries software safety hardware;sliding mode;software design;robot dynamics;friction;force sensor;hand injuries;sliding mode control;sliding mode position control;force control	This paper presents a force-based control mode for a hand exoskeleton. This device has been developed with focus on support of the rehabilitation process after hand injuries or strokes. As the device is designed for the later use on patients, which have limited hand mobility, fast undesired movements have to be averted. Safety precautions in the hardware and software design of the system must be taken to ensure this. The construction allows controlling motions of the finger joints. However, due to friction in gears and mechanical construction, it is not possible to move finger joints within the construction without help of actuators. Therefore force sensors are integrated into the construction to sense force exchanged between human and exoskeleton. These allow the human to control the movements of the hand exoskeleton, which is useful to teach new trajectories or can be used for diagnostic purposes. The force control scheme presented in this paper uses the force sensor values to generate a trajectory which is executed by a position control loop based on sliding mode control	characteristic impedance;control system;feedback;finger tree;sensor;simulation;software design;virtual reality;zero suppression	Andreas Wege;Konstantin Kondak;Günter Hommel	2006	2006 IEEE/RSJ International Conference on Intelligent Robots and Systems	10.1109/IROS.2006.282169	control engineering;motion control;simulation;exoskeleton;sliding mode control;engineering;software design;friction;control theory;force-sensing resistor	Robotics	71.1013650457101	-26.001922879195963	53338
918350dcfb9f91bcf909f1712948fbf5fe60d239	pattern formation theory for electroactive polymer gel robots	wave shape pattern formation pattern formation theory electroactive polymer gel robots mathematical model gel robot deformation surfactant driven ionic polymer gel constant electric fields poly 2 acrylamido 2 methylpropane sulfonic acid adsorption induced deformation;degree of freedom;pattern formation;polymer gels;electric field;mathematical analysis;electroactive polymer;mathematical analysis pattern formation polymer gels robots;robots;mathematical model;robots polymer gels pattern formation deformable models spatiotemporal phenomena mathematical model shape information science paper technology pattern analysis	This paper proposes the mathematical model of deformation for gel robots and develops the pattern formation theory. The robots are made of surfactant-driven ionic polymer gel in constant electric fields, which is a typical electroactive polymer gel containing poly 2-acrylamido-2-methylpropane sulfonic acid (PAMPS). A beam of gel in uniform electric fields develops wave forms through penetration of the surfactant solution. The model is to be built on the hypothesis of adsorption-induced deformation. The mechanism of wave-shape pattern formation is then analyzed utilizing the model. The results of this study provide the foundation to develop deformable machines with virtually infinite degrees of freedom.	computer simulation;electroactive polymers;experiment;ionic;mathematical model;nonlinear system;numerical analysis;pattern formation;polymer;robot;sol-gel	Mihoko Otake;Yoshihiko Nakamura;Hirochika Inoue	2004	IEEE International Conference on Robotics and Automation, 2004. Proceedings. ICRA '04. 2004	10.1109/ROBOT.2004.1307482	robot;computer science;artificial intelligence;electric field;electroactive polymers;mathematical model;nanotechnology;pattern formation;degrees of freedom;statistics	Robotics	78.47826759946882	-24.41704981113519	53358
772f625463a3a4061b08745c6a2026c84c02d9d7	real-time soft shadows in mixed reality using shadowing planes	mixed reality;real time	A continuous anionic solution process for preparing star-block copolymers of monovinylaromatic compounds and conjugated dienes having either monomodal or bimodal arm structure is described. The process utilizes a continuous tubular reactor made up of a sequence of four static mixer zones followed by a pressure control valve.	mixed reality;real-time transcription	Tetsuya Kakuta;Takeshi Oishi;Katsushi Ikeuchi	2007			artificial intelligence;computer vision;mathematics;pressure control;static mixer;mixed reality;computer graphics (images);plug flow reactor model	HCI	64.82236070683287	-36.01097629325926	53412
3db1d3c4e54a232409ac3e07e6547882f60c29b5	focus: europa: life elsewhere?	autonomous vehicle;propulsion earth probes land surface sea surface jupiter moon marine vehicles remotely operated vehicles mobile robots;mobile robots;intelligent control;extraterrestrial life;autonomous vehicle jet propulsion lab life existance existance of life europa extraterrestrial life probe;aerospace control;aerospace control extraterrestrial life mobile robots intelligent control	At the Jet Propulsion Lab. scientists and engineers are spearheading far-reaching research efforts to prove beyond all doubt that life exists, or once existed, elsewhere than on Earth. In their most promising initiative, they hope to land a probe on the surface of Jupiter's moon Europa, considered a likely site for extraterrestrial life, within the next 15 years. As planned this autonomous vehicle will melt down through the ice to a vast ocean below where it will conduct tests to investigate if life exists there.		Dick Price	1998	IEEE Intelligent Systems	10.1109/5254.722383	mobile robot;extraterrestrial life;computer science;artificial intelligence;intelligent control	Robotics	55.10263235634551	-30.287821045796814	53434
a2ffabad5ab6aeda64d40dcfe848dc55defda603	fine positioning of micro-tubular-tools for investigating the stimulus response of swimming paramecium		We propose a new driving method for actuating micro-tubular-tool inside the fluidic environment to apply local stimulation to a freely swimming Paramecium. The hydrodynamic drag force acting on the very thin tool is significant and the resultant deflection was compensated by utilizing permanent magnets. The positioning accuracy of the microtools were enhanced more than ten times compared to normal actuation without magnets. The microtools can be integrated as robotic arms in a robotic platform that can track a single motile cell inside a microfluidic chip for a long-time. The specific design of the stimulation system using microtools was described and the effectiveness of the new driving method was confirmed through the basic experiments. Finally, the microtools were used to apply mechanical and electrical stimulation to a freely swimming Paramecium. The microtools can be used to achieve simultaneous multi-stimulation which can induce new behaviors of the motile cells and lead for unprecedented discoveries in biological fields.	coat of arms;experiment;functional electrical stimulation;resultant;robot	Belal Ahmad;Hironobu Maeda;Tomohiro Kawahara;Fumihito Arai	2018	2018 7th IEEE International Conference on Biomedical Robotics and Biomechatronics (Biorob)	10.1109/BIOROB.2018.8487974	microfluidics;paramecium;deflection (engineering);fluidics;stimulus (physiology);control engineering;robotic arm;drag;materials science;stimulation	Robotics	75.5266426714162	-25.12955345409189	53435
14dbe6fe9d09c05d66cd4bbde2a30a399fddfffa	study of the widely linear wiener filter for noise reduction	minimum mean squared error;frequency domain analysis;short time fourier transform coefficients;speech;wiener filters;acoustic signal processing;random variables;wiener filters acoustic signal processing fourier transforms;noise measurement;subband signal to noise ratio widely linear noise reduction wiener filter short time fourier transform coefficients speech signals speech distortion minimum mean squared error;short time fourier transform;speech distortion;noncircularity noise reduction wiener filter widely linear wiener filter circularity;widely linear;circularity;noise reduction;fourier transforms;speech signals;subband signal to noise ratio;wiener filter;signal to noise ratio;wiener filter noise reduction random variables signal to noise ratio nonlinear filters higher order statistics frequency domain analysis fourier transforms speech enhancement filtering theory;minimum mean square error;noncircularity;widely linear noise reduction wiener filter;widely linear wiener filter	This paper develops a new widely linear noise-reduction Wiener filter based on the variance and pseudo-variance of the short-time Fourier transform coefficients of speech signals. We show that this new noise-reduction filter has many interesting properties, including but not limited to: 1) it causes less speech distortion as compared to the classical noise-reduction Wiener filter; 2) its minimum mean-squared error (MSE) is smaller than that of the classical Wiener filter; 3) it can increase the subband signal-to-noise ratio (SNR), while the classical Wiener filter has no effect on the subband SNR for any given signal frame and subband.	coefficient;distortion;mean squared error;noise reduction;short-time fourier transform;signal-to-noise ratio;wiener filter	Jacob Benesty;Jingdong Chen;Yiteng Huang	2010	2010 IEEE International Conference on Acoustics, Speech and Signal Processing	10.1109/ICASSP.2010.5496033	minimum mean square error;raised-cosine filter;speech recognition;kernel adaptive filter;computer science;root-raised-cosine filter;mathematics;wiener filter;filter design;statistics;wiener deconvolution	Robotics	82.69510234464292	-33.64602679994104	53562
3cf50e37cb5aabf386a1125db0adfa5f80928300	safety design and control algorithm for robotic spinal surgical system	orthopedic surgery;robot sensing systems;design principle;surgery force safety milling robot sensing systems haptic interfaces;control algorithm;surgery drilling health and safety medical robotics orthopaedics;drilling process robotic spinal surgical system pedicle screw implanting surgery orthopedic surgeries safety design principles admittance control safety control;dynamic force sense;admittance control;orthopaedics;force;medical robotics;spinal surgery;drilling;dynamic force sense spinal surgery fmeca admittance control;health and safety;safety;surgery;clinical practice;haptic interfaces;fmeca;milling;haptic interface	This paper is based on a new Robotic Spinal Surgical System (RSSS) we have developed in last 2 years. This robotic surgical system focuses on pedicle screw implanting surgery, but can be used on some other orthopedic surgeries. Some safety design principles are presented during development of the RSSS. In this paper, two main aspects of them based on force messages are described. One is admittance control, the other is safety control during drilling process. We perform experiments to build safety control experience formula and test its availability. Our works here will support subsequent clinical practice of the RSSS.	algorithm;experiment;failure mode, effects, and criticality analysis;haptic technology;operation payback;robot	Haiyang Jin;Ying Hu;Feng Li;Jianwei Zhang	2011	2011 First International Conference on Robot, Vision and Signal Processing	10.1109/RVSP.2011.49	engineering;biological engineering;surgery;mechanical engineering	Robotics	73.88872713507311	-27.22552271188845	53648
d75d0ded20c1bb850262002110399339882165eb	monitoring of cutting state in end-milling based on measurement of tool behavior using ccd image				Shinichi Yoshimitsu;Daiki Iwashita;Kenji Shimana;Yuya Kobaru;Shunichi Yamashita	2019	IJAT	10.20965/ijat.2019.p0133	computer vision;computer science;artificial intelligence	Robotics	60.06399144481898	-42.233478792640234	53677
e5b685ea662d65e3d324744f497a6203305abb29	improving radiosity solutions through the use of analytically determined form-factors	numerical technique;form factor;global illumination	Current radiosity methods rely on the calculation of geometric factors, known as form-factors, which describe energy exchange between pairs of surfaces in the environment. The most computationally efficient method for form-factor generation is a numerical technique known as the hemi-cube algorithm. Use of the hemi-cube is based on assumptions about the geometry of the surfaces involved. First, this paper examines the types of errors and visual artifacts that result when these assumptions are violated. Second, the paper shows that these errors occur more frequently in progressive refinement radiosity than in the originally proposed full matrix radiosity solution. Next, a new analytical technique for determining form-factors that is immune to the errors of the hemi-cube algorithm is introduced. Finally, a hybrid progressive refinement method that invokes the new technique to correctly compute form-factors when hemi-cube assumptions are violated is presented.	algorithm;algorithmic efficiency;form factor (design);numerical analysis;progressive refinement;radiosity (computer graphics);refinement (computing);visual artifact	Daniel R. Baum;H. E. Rushmeire;James M. Winget	1989		10.1145/74333.74367	mathematical optimization;radiosity;form factor;computer science;theoretical computer science;global illumination;computer graphics (images)	Graphics	72.32295173701813	-43.69582537164251	53733
156158b0605eeb4620298227cf838e11de2aa967	bee slam: a probabilistic framework for studying orientation flights in bees and wasps	slam;navigation;orientation flight	An engine ignition system includes a throttle sensor for detecting the position of a throttle valve. A control circuit is responsive to the detected throttle signal as well as the signals from other negative pressure and engine rpm sensors to generate a spark plug discharge start signal and a discharge stop signal. A high voltage generator supplies a high voltage to the respective spark plugs during the time interval between the time that the discharge start signal is generated and the time that the discharge stop signal is generated.		Bart Baddeley;Andrew Philippides	2007		10.1145/1276958.1277022	computer vision;navigation;simulation	Vision	69.42550643052653	-31.111164183338794	53827
e76426c417f1a316e0dc837b8edd8df90531cfda	robot farmers: autonomous orchard vehicles help tree fruit production	robot sensing systems;perception system robot farmer autonomous orchard vehicle tree fruit production navigation system;mobile robots;vegetation;intelligent vehicles;path planning agricultural machinery agricultural products farming mobile robots;food production;farming;laser noise;intelligent vehicles vegetation robot sensing systems laser noise mobile robots food production farming	This article presents perception and navigation systems for a family of autonomous orchard vehicles. The systems are customized to enable safe and reliable driving in modern planting environments. The perception system is based on a global positioning system (GPS)-free sensor suite composed of a twodimensional (2-D) laser scanner, wheel and steering encoders, and algorithms that process the sensor data and output the vehicle's location in the orchard and guidance commands for row following and turning. Localization is based on range data to premapped landmarks, currently one at the beginning and one at the end of each tree row. The navigation system takes as inputs the vehicle's current location and guidance commands, plans trajectories for row following and turning, and drives the motors to achieve fully autonomous block coverage. The navigation system also includes an obstacle detection subsystem that prevents the vehicle from colliding with people, trees, and bins. To date, the vehicles sporting the perception and navigation infrastructure have traversed over 350 km in research and commercial orchards and nurseries in several U.S. states. Time trials showed that the autonomous orchard vehicles enable efficiency gains of up to 58% for fruit production tasks conducted on the top part of trees when compared with the same task performed on ladders. Anecdotal evidence collected from growers and workers indicates that replacing ladders with autonomous vehicles will make orchard work safer and more comfortable.	3d scanner;algorithm;autonomous robot;encoder;global positioning system;orchard	Marcel Bergerman;Silvio M. Maeta;Ji Zhang;Gustavo M. Freitas;Bradley Hamner;Sanjiv Singh;George Kantor	2015	IEEE Robotics & Automation Magazine	10.1109/MRA.2014.2369292	control engineering;mobile robot;simulation;computer science;engineering;artificial intelligence;food processing;mobile robot navigation;vegetation	Robotics	57.4985113564173	-29.087437712982073	53846
1961c811eb65de548c8e74ed6b2634ecf6629c8c	absolute hodograph winding number and planar ph quintic splines	algebraic topology;methode newton raphson;concepcion asistida;homotopie;bending;topologie algebrique;computer aided design;winding number;rational interpolation;ajustamiento curva;hodographe pythagorien;topologia algebraica;surface parametrique;homotopia;superficie parametrica;polynomial interpolation;elastic bending energy;newton raphson method;sistema complejo;homotopy;energia deformacion;tridiagonal matrix;homotopy method;aproximacion esplin;interpolacion racional;pythagorean hodograph;systeme complexe;covering space;complex system;spline approximation;approximation spline;flexion;metodo newton raphson;numerical algorithm;energie deformation;matriz tridiagonal;conception assistee;ajustement courbe;esplin cubico;spline cubique;interpolacion polinomial;curve fitting;hodografo pythagor;parametric surface;strain energy;matrice tridiagonale;spline interpolation;interpolation polynomiale;cubic spline;interpolation rationnelle	We present a new semi-topological quantity, called the absolute hodograph winding number, that measures how close the quintic PH spline interpolating a given sequence of points is to the cubic spline interpolating the same sequence. This quantity then naturally leads into a new criterion of determining the best quintic PH spline interpolant. This seems to work favorably compared with the elastic bending energy criterion developed by Farouki [Farouki, R.T., 1996. The elastic bending energy of Pythagoreanhodograph curves. Comput. Aided Geom. Design 13 (3), 227–241]. We also present a fast method that is a modification of the method of Albrecht, Farouki, Kuspa, Manni, and Sestini [Albrecht, G., Farouki, R.T., 1996. Construction of C2 Pythagoreanhodograph interpolating splines by the homotopy method. Adv. Comput. Math. 5 (4), 417–442; Farouki, R.T., Kuspa, B.K., Manni, C., Sestini, A., 2001. Efficient solution of the complex quadratic tridiagonal system for C2 PH quintic splines. Numer. Algorithms 27 (1), 35–60]. While the basic scheme of our approach is essentially the same as theirs, ours differs in that the underlying space in which the Newton–Raphson method is applied is the double covering space of the hodograph space, whereas theirs is the hodograph space itself. This difference, however, seems to produce more favorable results, when viewed from the above mentioned semi-topological criterion. © 2008 Elsevier B.V. All rights reserved.	algorithm;computation;covering space;cubic hermite spline;cubic function;interpolation;katherine albrecht;newton;newton's method;numerical analysis;numerical method;ph (complexity);quintic function;semiconductor industry;simplicial complex;spline (mathematics);turing test;word lists by frequency	Hyeong In Choi;Song-Hwa Kwon	2008	Computer Aided Geometric Design	10.1016/j.cagd.2007.12.007	spline interpolation;winding number;spline;tridiagonal matrix;mathematical optimization;bending;topology;covering space;polynomial interpolation;computer aided design;homotopy;calculus;parametric surface;mathematics;geometry;newton's method;strain energy;algebraic topology;curve fitting	Theory	69.01563360518257	-39.64525929300952	53892
146d14c19a1db45f1d6b96749d54dafa3c3419de	a database and evaluation methodology for optical flow	image database optical flow nonrigid motion optical tracking hidden fluorescent texture stereo sequence high frame rate video average angular error absolute flow endpoint error frame interpolation error statistics;interpolation;stereo sequence;evaluation method;image database;image texture;frame interpolation error;error analysis;visual databases error analysis image sequences image texture interpolation optical tracking statistical analysis stereo image processing;nonrigid motion;statistical analysis;optical tracking;evaluation methodology;stereo image processing;next generation;statistics;ground truth;optical flow;hidden fluorescent texture;databases image motion analysis optical sensors optical noise layout interpolation benchmark testing tracking fluorescence fluid flow measurement;absolute flow endpoint error;natural scenes;quantitative evaluation;average angular error;high frame rate video;image sequences;visual databases	The quantitative evaluation of optical flow algorithms by Barron et al. led to significant advances in the performance of optical flow methods. The challenges for optical flow today go beyond the datasets and evaluation methods proposed in that paper and center on problems associated with nonrigid motion, real sensor noise, complex natural scenes, and motion discontinuities. Our goal is to establish a new set of benchmarks and evaluation methods for the next generation of optical flow algorithms. To that end, we contribute four types of data to test different aspects of optical flow algorithms: sequences with nonrigid motion where the ground-truth flow is determined by tracking hidden fluorescent texture; realistic synthetic sequences; high frame-rate video used to study interpolation error; and modified stereo sequences of static scenes. In addition to the average angular error used in Barron et al., we compute the absolute flow endpoint error, measures for frame interpolation error, improved statistics, and flow accuracy at motion boundaries and in textureless regions. We evaluate the performance of several well-known methods on this data to establish the current state of the art. Our database is freely available on the Web together with scripts for scoring and publication of the results at http://vision.middlebury.edu/flow/.	database;optical flow	Simon Baker;Daniel Scharstein;J. P. Lewis;Stefan Roth;Michael J. Black;Richard Szeliski	2007		10.1109/ICCV.2007.4408903	image texture;computer vision;ground truth;interpolation;computer science;theoretical computer science;optical flow;mathematics;statistics;computer graphics (images)	Vision	54.77035225574477	-48.727740865659825	53964
c352f679482dcea78e1abe0913b8e12d1c52ae5b	fast, effective bvh updates for animated scenes	bounding volume hierarchy;bounding volume hierarchies;parallel update;ray tracing;acceleration structures;tree rotations;dynamic scenes	Bounding volume hierarchies (BVHs) are a popular acceleration structure choice for animated scenes rendered with ray tracing. This is due to the relative simplicity of refitting bounding volumes around moving geometry. However, the quality of such a refitted tree can degrade rapidly if objects in the scene deform or rearrange significantly as the animation progresses, resulting in dramatic increases in rendering times and a commensurate reduction in the frame rate. The BVH could be rebuilt on every frame, but this could take significant time. We present a method to efficiently extend refitting for animated scenes with tree rotations, a technique previously proposed for off-line improvement of BVH quality for static scenes. Tree rotations are local restructuring operations which can mitigate the effects that moving primitives have on BVH quality by rearranging nodes in the tree during each refit rather than triggering a full rebuild. The result is a fast, lightweight, incremental update algorithm that requires negligible memory, has minor update times, parallelizes easily, avoids significant degradation in tree quality or the need for rebuilding, and maintains fast rendering times. We show that our method approaches or exceeds the frame rates of other techniques and is consistently among the best options regardless of the animated scene.	algorithm;bounding volume hierarchy;elegant degradation;incremental backup;online and offline;parallel computing;refit	Daniel Kopta;Thiago Ize;Josef B. Spjut;Erik Brunvand;Al Davis;Andrew E. Kensler	2012		10.1145/2159616.2159649	ray tracing;bounding interval hierarchy;real-time computing;simulation;computer science;artificial intelligence;theoretical computer science;geometry;bounding volume hierarchy;computer graphics (images)	Graphics	66.68056952735967	-50.629628350172574	54019
705a9760691bebf37ec78ed2892881605b4673aa	separatrix persistence: extraction of salient edges on surfaces using topological methods	sra e vetenskap serc;edge extraction;g 2 3 mathematics of computing discrete mathematics;topological analysis;datalogi;topological methods;datavetenskap datalogi;sra e science serc;computer science;applications i 3 0 computer graphics general	Salient edges are perceptually prominent features of a surface. Most previous extraction schemes utilize the notion of ridges and valleys for their detection, thereby requiring curvature derivatives which are rather sensitive to noise. We introduce a novel method for salient edge extraction which does not depend on curvature derivatives. It is based on a topological analysis of the principal curvatures and salient edges of the surface are identified as parts of separatrices of the topological skeleton. Previous topological approaches obtain results including non-salient edges due to inherent properties of the underlying algorithms. We extend the profound theory by introducing the novel concept of separatrix persistence, which is a smooth measure along a separatrix and allows to keep its most salient parts only. We compare our results with other methods for salient edge extraction.	algorithm;blackwell (series);compiler;computation;derivative-free optimization;edge detection;eurographics;image processing;persistence (computer science);scientific visualization;thresholding (image processing);topological skeleton	Tino Weinkauf;David Günther	2009	Comput. Graph. Forum	10.1111/j.1467-8659.2009.01528.x	computer vision;combinatorics;topology;computer science;mathematics;geometry;algorithm	NLP	64.28525952493783	-40.212058865050054	54085
a240d2ec6d33a6a91a5f7274379f9febf9b15a03	efficiency assessment of performance of decentralized autonomous multi-robot systems	multirobot systems;autonomous robots;simulated agents;multi agent systems;robot efficiency;team performance		autonomous robot	Arvin Agah;George A. Bekey	1996	JRM	10.20965/jrm.1996.p0286	control engineering;simulation;control theory	Robotics	57.836629239056776	-24.30332050931827	54088
216cf653f873796269ffe778c79c9d5e4f3591ed	application of discrete scatterer technique for scene response estimation in fopen radar simulations		An analytical solver is developed for characterizing the coherent scattering responses of tree scenes. Realistic 3-D tree structures are first constructed using an open-source random tree generation engine. The trees are then parsed into discrete, canonical scatterers, such as cylinders and disks, and a multiray approach is applied to calculate the aggregate response of the scene, with the transmissivity of each ray determined from a cell-based representation of the computational domain. As each scatterer in the outlined framework is assigned a deterministic position, the spatial distribution of the trees and their canopy structures is fully preserved. A cell-by-cell strategy is also proposed for speeding up the calculations of the responses from small components such as secondary stems and leaves, which are expected to far outnumber those scatterers composing the trunks and primary branches. The accuracy of the analytical solver is assessed by comparing simulation results for a forest stand with solutions from a large-scale, full-wave solver. In addition, as an application of interest, the detection and imaging of a tree-obscured walking human target is demonstrated.	aggregate data;airborne ranger;c file input/output;coherence (physics);computation;motorola canopy;moving target indication;open-source software;parsing;radar;random tree;simulation;solver	DaHan Liao	2017	IEEE Geoscience and Remote Sensing Letters	10.1109/IGARSS.2017.8127990	spatial distribution;random tree;computer science;computer vision;radar imaging;tree structure;radar;finite difference method;artificial intelligence;scattering;solver	Robotics	72.62725729025054	-50.829982992094756	54109
f82c2df1a2718419b1b09135d9060b5d65eed3a8	identifying gait phases from joint kinematics during walking with switched linear dynamical systems*		Human-robot interaction (HRI) for gait rehabilitation would benefit from data-driven gait models that account for gait phases and gait dynamics. Here we address the current limitation in gait models driven by kinematic data, which do not model interlimb gait dynamics and have not been shown to precisely identify gait events. We used Switched Linear Dynamical Systems (SLDS) to model joint angle kinematic data from healthy individuals walking on a treadmill with normal gaits and with gaits perturbed by electrical stimulation. We compared the model-inferred gait phases to gait phases measured externally via a force plate. We found that SLDS models accounted for over 88% of the variation in each joint angle and labeled the joint kinematics with the correct gait phase with 84% precision on average. The transitions between hidden states matched measured gait events, with a median absolute difference of 25ms. To our knowledge, this is the first time that SLDS inferred gait phases have been validated by an external measure of gait, instead of against predefined gait phase durations. SLDS provide individual-specific representations of gait that incorporate both gait phases and gait dynamics. SLDS may be useful for developing control policies for HRI aimed at improving gait by allowing for changes in control to be precisely timed to different gait phases.	dynamical system;functional electrical stimulation;human–robot interaction	R Grönholm;Irfan Essa;Lena H. Ting	2018	2018 7th IEEE International Conference on Biomedical Robotics and Biomechatronics (Biorob)	10.1109/BIOROB.2018.8487216		Robotics	69.42164345858983	-28.02787712566151	54112
a31ab7d4829d15ba5a1bd9413a73fe4822d6a8d2	enhancing an automated inspection system on printed circuit boards using affine-sift and triz techniques	theory of inventive problem solving;image matching;automated visual inspection;printed circuit board;affine sift	Automated visual inspection is an important step to assure the quality of printed circuit boards (PCB). Component placement errors such as missing, misaligned or incorrectly rotated component are major causes of defects on surface mount PCB. This paper proposes a novel automated visual inspection method for PCB. The proposed method uses a sequence of image processing techniques inspired by the theory of inventive problem solving (TRIZ) with Affine-SIFT image matching techniques to enhance the component placement inspection. Only analytic discussions are presented in this paper to support the potential of the proposed method.	printed circuit board	Amirhossein Aghamohammadi;Mei Choo Ang;Anton Satria Prabuwono;Marzieh Mogharrebi;Kok Weng Ng	2013		10.1007/978-3-319-02958-0_12	computer vision;5dx;simulation;automated x-ray inspection;engineering;engineering drawing;automated optical inspection	HCI	61.394363003732224	-40.81778916933049	54132
4c822fad8e0b8c53af4fad5337a0c6298b97e55f	a robotic system for rehabilitation of distal radius fracture using games	xna;protocols;robotic rehabilitation;electronic games;performance evaluation;distal radius fracture rehabilitation;wrist;patient rehabilitation;data storage robotic system distal radius fracture rehabilitation electronic games attractive therapeutic activities;robotic system;robotic games integration;xna robotic rehabilitation robotic games integration;data storage;healthy subjects;games;robots;patient rehabilitation computer games passive radar;passive radar;dc motors;computer games;games robots wrist hardware protocols performance evaluation dc motors;attractive therapeutic activities;hardware	This work integrates robotics and electronic games with the objective of producing more motivating and attractive therapeutic activities in distal radius fracture rehabilitation (wrist region). The proposed robotic system allows the reliable measurement of all wrist angular motion amplitudes. To this end, a framework is proposed to allow the full integration of the designed game to the developed hardware. The framework stores data from the game and from the robot movements for further analysis. The prototype was tested in healthy subjects, and a questionnaire was used to produce qualitative impressions on the system.	angularjs;electronic game;prototype;robot	Kleber O. Andrade;Gisele G. Ito;Ricardo C. Joaquim;Bruno Jardim;Adriano A. G. Siqueira;Glauco A. P. Caurin;Marcelo Becker	2010	2010 Brazilian Symposium on Games and Digital Entertainment	10.1109/SBGAMES.2010.26	control engineering;embedded system;simulation;engineering	Robotics	73.63860994170865	-27.262539670131304	54170
8a964efbb95b21e3ee854f61fcf0f8317f70916f	bionic upper orthotics with integrated emg sensory	torque;orthotics;elbow;permanent magnet motors;torque control biocybernetics biomedical measurement electromyography medical robotics motion control neurophysiology orthotics position control prosthetics torque;exoskeletons;orthotics torque permanent magnet motors robots exoskeletons electromyography elbow;robots;electromyography;exoskeleton robots bionic upper orthotics integrated emg sensory actively powered arm orthotics light electromechanical motor gear combination effective electromechanical motor gear combination elbow modular design drive system prosthetics nerve impulses reference torque motion control unit european research project apoplectic stroke	In this paper a novel design of an actively powered arm orthotics is discussed. A light and effective electromechanical motor gear combination is designed which produces torque directly at the elbow. The modular design of the drive system makes it possible to use it in different applications in the field of orthotics, prosthetics and exoskeletons. The EMG sensors are used to measure the nerve impulses. These impulses are then analyzed to generate the reference torque and position values and send it to the motion control unit. This type of actively powered orthotics is developed as a part of an European research project for patients with apoplectic stroke. However, the same principle can also be used in exoskeleton robots.	arm architecture;action potential;control theory;control unit;electromyography;modular design;robot;sensor	Afshin Ebrahimi;D. Minzenmay;B. Budaker;Ulrich Schneider	2014	The 23rd IEEE International Symposium on Robot and Human Interactive Communication	10.1109/ROMAN.2014.6926337	robot;exoskeleton;computer science;artificial intelligence;torque	Robotics	71.67204588457007	-26.324087363188042	54330
2dec3f00310205f52159cc86dace49a603a9f024	rapid development of vision-based control for mavs through a virtual flight testbed	control algorithm;surveillance;aerospace control;aircraft propulsion;hardware in the loop;intelligent vehicles;machine intelligence;object tracking;system testing;infrared image sensors;unmanned aerial vehicles;micro air vehicle;unmanned aerial vehicles surveillance sensor arrays system testing costs infrared image sensors machine intelligence aerospace control aircraft propulsion intelligent vehicles;sensor arrays	We seek to develop vision-based autonomy for small-scale aircraft known as Micro Air Vehicles (MAVs). Development of such autonomy presents significant challenges, in no small measure because of the inherent instability of these flight vehicles. Therefore, we propose a virtual flight testbed that seeks to mitigate these challenges by facilitating the rapid development of new vision-based control algorithms that would have been, in its absence, substantially more difficult to transition to successful flight testing. The proposed virtual testbed is a precursor to a more complex Hardware-In-the-Loop (HILS) facility currently being constructed at the University of Florida. These systems allow us to experiment with vision-based algorithms in controlled laboratory settings, thereby minimizing loss-of-vehicle risks associated with actual flight testing. In this paper, we first discuss our testbed system, both virtual and real. Second, we present our vision-based approaches to MAV stabilization, object tracking and autonomous landing. Finally, report experimental flight results for both the virtual testbed as well as for flight tests in the field, and discuss how algorithms developed in the virtual testbed were seamlessly transitioned to real flight testing.	algorithm;autonomous robot;hardware-in-the-loop simulation;instability;prototype;testbed	Jason Grzywna;Ashish Jain;Jason Plew;Michael C. Nechyba	2005	Proceedings of the 2005 IEEE International Conference on Robotics and Automation	10.1109/ROBOT.2005.1570683	simulation;aerospace engineering;computer science;engineering;artificial intelligence;aeronautics;flight simulator;video tracking;flight management system;system testing;hardware-in-the-loop simulation	Robotics	56.51815129299199	-29.662838095881416	54401
b7a3706e40672506bdec08f7426c60470116ed5e	a geometric approach to spectral subtraction	spectre puissance;biological patents;amelioration parole;modele geometrique;sistema experto;biomedical journals;text mining;europe pubmed central;retardo fase;implementation;phase difference;speech processing;citation search;erreur quadratique moyenne;tratamiento palabra;traitement parole;analisis objetivos;speech enhancement;citation networks;power spectrum;retard phase;espectro potencia;algorithme;geometric approach;algorithm;spectral subtraction;research articles;abstracts;mean square error;acoustic noise;musical noise;open access;life sciences;bruit acoustique;clinical guidelines;systeme expert;error medio cuadratico;full text;implementacion;analyse objective;phase delay;rest apis;objective analysis;orcids;europe pmc;biomedical research;geometrical model;bioinformatics;algoritmo;literature search;expert system;modelo geometrico	The traditional power spectral subtraction algorithm is computationally simple to implement but suffers from musical noise distortion. In addition, the subtractive rules are based on incorrect assumptions about the cross terms being zero. A new geometric approach to spectral subtraction is proposed in the present paper that addresses these shortcomings of the spectral subtraction algorithm. A method for estimating the cross terms involving the phase differences between the noisy (and clean) signals and noise is proposed. Analysis of the gain function of the proposed algorithm indicated that it possesses similar properties as the traditional MMSE algorithm. Objective evaluation of the proposed algorithm showed that it performed significantly better than the traditional spectral subtractive algorithm. Informal listening tests revealed that the proposed algorithm had no audible musical noise.	atxn2l gene;accidental falls;addresses (publication format);analog-to-digital converter;appendix;arabic numeral 0;auditory perception;denominator;distortion;emoticon;equivalent weight;error analysis (mathematics);estimated;fe(iii)-reducing bacterium jx-a20;iodine i 124 pu-ad;matlab;mental suffering;national institute on deafness and other communication disorders (u.s.);noise-induced hearing loss;quantum phase estimation algorithm;rule (guideline);signal-to-noise ratio;software release life cycle;spectrogram;stellar classification;visual inspection;zero suppression;algorithm;sentence	Yang Lu;Philipos C. Loizou	2008	Speech communication	10.1016/j.specom.2008.01.003	text mining;speech recognition;computer science;artificial intelligence;group delay and phase delay;noise;speech processing;mean squared error;implementation;spectral density;expert system;statistics	ML	81.18944163038562	-31.322334430493864	54424
43722fb9c69e90342657230718d5c9bda2fc8fc7	a perceptually reweighted mixed-norm method for sparse approximation of audio signals	sparse approximations;convex programming;audio modeling;convex optimization;sparse approximation;audio modeling audio coding sparse approximations perceptual distortion measures;vectors distortion measurement dictionaries matching pursuit algorithms encoding speech spectrogram;iterative algorithm;signal representation audio coding convex programming iterative methods rate distortion theory;rate distortion theory;iterative methods;audio coding;signal representation;perceptual distortion measures;rate distortion optimization perceptually reweighted mixed norm method sparse approximation audio signals sparse representation audio coding iterative algorithm 1 norm based measure of sparsity perceptual distortion measure convex optimization;sparse representation;rate distortion optimization;computer simulation	In this paper, we consider the problem of finding sparse representations of audio signals for coding purposes. In doing so, it is of utmost importance that when only a subset of the present components of an audio signal are extracted, it is the perceptually most important ones. To this end, we propose a new iterative algorithm based on two principles: 1) a reweighted 1-norm based measure of sparsity; and 2) a reweighted 2-norm based measure of perceptual distortion. Using these measures, the considered problem is posed as a constrained convex optimization problem that can be solved optimally using standard software. A prominent feature of the new method is that it solves a problem that is closely related to the objective of coding, namely rate-distortion optimization. In computer simulations, we demonstrate the properties of the algorithm and its application to real audio signals.		Mads Græsbøll Christensen;Bob L. Sturm	2011	2011 Conference Record of the Forty Fifth Asilomar Conference on Signals, Systems and Computers (ASILOMAR)	10.1109/ACSSC.2011.6190067	mathematical optimization;machine learning;pattern recognition;mathematics	Robotics	78.73886417924024	-36.14585965947585	54436
892f99c68984ebd98b709455574079baeff7f8a2	comparison of walsh and fourier spectroscopy of geomagnetic reversals and nonsinusoidal palaeoclimatic time series	geologic strata;spectroscopy;palaeomagnetic data;fourier spectroscopy;mathematics;nonsinusoidal palaeoclimatic time series;multivariate analysis;magnetism;fourier transform;paleontology;frequency analysis;correlations;geologic ages;spectrum analysis;walsh function;walsh transform;real time;signal analysis;geomagnetism;time series;geologic structures;time domain analysis;autocorrelation analysis;walsh functions climatology fourier transform spectroscopy geomagnetic variations time series;data analysis;walsh functions;paleomagnetism;surveys 580000 geosciences;walsh transform techniques;time series analysis;orbital periodicities;geomagnetic reversals;fourier transforms;comparative evaluations;milankovitch frequency;age estimation;geophysical surveys;maximum entropy method;geophysical survey;statistics;geosciences;fourier analysis;time series data;binary telegraphic wave;time domain;paleoclimatology;evaluation;spectral estimation;spectral analysis;frequency;computational efficiency;geophysical geological time series palaeomagnetic data fourier spectroscopy geomagnetic reversals nonsinusoidal palaeoclimatic time series walsh transform techniques binary telegraphic wave milankovitch frequency orbital periodicities autocorrelation analysis;functions;fourier transform spectroscopy;spectroscopy geomagnetism spectral analysis fourier transforms frequency autocorrelation signal analysis time series analysis time domain analysis computational efficiency;climatology;geophysical geological time series;autocorrelation;geomagnetic variations	Higher resolving capabilities and theoretical appropriateness of Walsh spectral techniques as compared to Fourier spectral analyses are presented for synthetic and nonsinusoidal geotime series. Theoretical developments of Walsh transform techniques and a comparative study of Walsh and Fourier spectral estimates are presented. The Walsh spectral technique is applied specifically to two actual time series data of geomagnetic reversals in binary telegraphic wave form and nonsinusoidal palaeomagnetic and palaeoclimate time series. Walsh spectra reveal periodicities in Milankovitch frequency bands and provide exceptionally well-resolved spectral lines. The possible physical significance of these orbital periodicities is discussed. A comparative example of autocorrelation analysis in the real time domain and dyadic time domain is also presented using a telegraphic signal model of actual geomagnetic reversal time series. and the result is briefly discussed. The computational efficiency of the Walsh function could be exploited further for many other binary and nonsinusoidal geophysical/geological time series. >	hadamard transform;time series	Janardan G. Negi;R. K. Tiwari;K. N. N. Rao	1993	IEEE Trans. Geoscience and Remote Sensing	10.1109/36.210453	geophysical survey;spectroscopy;calculus;time series;paleoclimatology;mathematics;nuclear magnetic resonance;statistics	EDA	79.88445619682437	-40.36496479012117	54512
71fd9e2edba403821edb660a12ea739337d7527d	optimal time-domain noise reduction filters - a theoretical study			noise reduction	Jacob Benesty;Jingdong Chen	2011		10.1007/978-3-642-19601-0	median filter;noise;salt-and-pepper noise	EDA	81.52704831943255	-35.42443519223607	54577
046e0651299eea54dc67ebb51340e0b5c258ba0e	ahura: a heuristic-based racer for the open racing car simulator	sensors wheels acceleration gears automobiles australia	Designing automatic drivers for car racing is an active field of research in the area of robotics and artificial intelligence. A controller called Ahura (a heuristic-based racer) for the open racing car simulator is proposed in this paper. Ahura includes five modules, namely steer controller, speed controller, opponent manager, dynamic adjuster, and stuck handler. These modules have 23 parameters all together that are tuned using an evolutionary strategy for a particular car to ensure fast and safe drive on different tracks. These tuned parameters are further modified by the dynamic adjuster module during the run according to the width, friction, and dangerous zones of the track. The dynamic adjustment enables Ahura to decide on-the-fly based on the current situation; hence, it eliminates the need for prior knowledge about the characteristics of the track. The driving performance of Ahura is compared with other state-of-the-art controllers on 40 tracks when they drive identical cars. Our experiments indicate that Ahura performs significantly better than other controllers in terms of damage and completion time especially on complex tracks (road tracks). Also, experiments show that the overtaking strategy of Ahura is safer and more effective compared to other controllers.	artificial intelligence;electronic speed control;experiment;heuristic;robotics;simulation	Mohammad Reza Bonyadi;Zbigniew Michalewicz;Samadhi Nallaperuma;Frank Neumann	2017	IEEE Transactions on Computational Intelligence and AI in Games	10.1109/TCIAIG.2016.2565661	computer science;safer;acceleration;control theory;simulation;overtaking;evolution strategy;artificial intelligence;heuristic;electronic speed control;robotics	Robotics	57.90174531800444	-27.891549097216277	54633
3ea01d5c139a0716c0887369d263b0d70efa83d2	a low-cost positioning system for parallel tracking applications of agricultural vehicles by using kalman filter	gps;kalman filter;low-cost;parallel tracking;positioning system	A position-velocity (PV) model and a multi-sensor system, consisted of a consumer application GPS, a MEMS gyro, two encoders, and a turning angle sensor, was constructed for the positioning system. The two encoders augmented the positioning accuracy greatly that the fluctuation of vehicle position was greatly smoothed comparing with a GPS-only system. The minimal fluctuation was falling from 2.21 m to 0.52 m (east direction), from 0.68 m to 0.23 m (north direction). The maximum XTE was reduced from 2.5 m to 0.77 m, and the RMS value was improved to 0.22m. The GPS bias error was the major difficulty to produce better performance.	computer;course (navigation);ecc memory;embedded system;encoder;gyro;global positioning system;kalman filter;local coordinates;mean squared error;microcomputer;microelectromechanical systems;pic microcontroller;quantum fluctuation;rs-485;smoothing;universal conductance fluctuations;velocity (software development)	Fangming Zhang;Ximing Feng;Yuan Li;Xiuqin Rao;Di Cui	2011		10.1007/978-3-642-27281-3_52	control engineering;simulation;engineering;control theory	Robotics	57.79081091609202	-36.41450528667233	54652
3ed4ef1032ca643f0694742d1fa02382161eea3f	ray-traced diffusion points	vector graphics;ray tracing;diffusion curves	Diffusion curves [Orzan et al. 2008] (DCs) has risen as an attractive vector primitive for representing complex colour gradients. Its flexible mathematical definition, taking curves with colour values as input, can be easily adopted by artists and designers because curves represent an intuitive approach to 2D drawing and design. However, the (Laplacian) diffusion process is computationally expensive and naive DCs (solving the large sparse PDE naively) are consequently unattractive as a practical vector graphics primitive. Lots of work has therefore been undertaken to identify a practical framework for defining and rendering DCs.	analysis of algorithms;geometric primitive;gradient;sparse matrix;vector graphics	Henrik Lieng	2016		10.1145/2945078.2945085	ray tracing;computer vision;vector graphics;simulation;computer science;geometry;computer graphics (images)	Graphics	65.92633650082546	-46.24014157568409	54679
09e55a40e1497479d99ecba480f1c0176a32ed87	flexible 3d localization of planar objects for industrial bin-picking with monocamera vision system	robot vision cad cameras control engineering computing industrial robots materials handling object detection pose estimation production engineering computing;cad;production engineering computing;robot vision;production plants flexible 3d localization planar objects industrial bin picking monocamera vision system flexible vision system industrial robots conveyor belt planar shape 2d image analysis 6 degrees of freedom pose single camera solution industrial 3d cameras laser triangulation systems laser range finders localization algorithm cad data computer aided design localization software candidates selection step voting scheme best match selection step refinement step robust iterative optimize and score procedure search in the stack strategy;materials handling;industrial robots;image edge detection cameras three dimensional displays solid modeling search problems optimization feature extraction;control engineering computing;cameras;object detection;pose estimation	In this paper, we present a robust and flexible vision system for 3D localization of planar parts for industrial robots. Our system is able to work with nearly any object with planar shape, randomly placed inside a standard industrial bin or on a conveyor belt. Differently from most systems based on 2D image analysis, which usually can manage parts disposed in single layers, our approach can estimate the 6 degrees of freedom (DoF) pose of planar objects from a single 2D image. The choice of a single camera solution makes our system cheaper and faster with respect to systems using expensive industrial 3D cameras, or laser triangulation systems, or laser range finders. Our system can work virtually with any planar piece, without changing the software parameters, because the input for the recognition and localization algorithm is the CAD data of the planar part. The localization software is based on a two step strategy: i) a candidates selection step based on a well-engineered voting scheme ii) a refinement and best match selection step based on a robust iterative optimize-and-score procedure. During this second step, we employ a novel strategy we called search-in-the-stack that avoids the optimization from being stuck on local minima (representing false positives) created when objects are almost regularly stacked. Our system is currently installed in seven real world industrial plants, with different setups, working with hundreds of different models and successfully guiding the manipulators to pick several hundreds of thousands of pieces per year. In the experiment section, we report statistics about our system at work in real production plants on more than 60000 cycles.	algorithm;computer-aided design;experiment;graphics processing unit;image analysis;image gradient;industrial pc;industrial robot;iterative method;mathematical optimization;maxima and minima;merge sort;randomness;refinement (computing);scoring functions for docking;speedup	Alberto Pretto;Stefano Tonello;Emanuele Menegatti	2013	2013 IEEE International Conference on Automation Science and Engineering (CASE)	10.1109/CoASE.2013.6654067	computer vision;simulation;engineering;engineering drawing	Robotics	59.59087565061534	-39.77543749901668	54780
6e7fb321d338521971d0677b2631722196835c30	mutual localization: two camera relative 6-dof pose estimation from reciprocal fiducial observation	bundler two camera relative 6 dof pose estimation reciprocal fiducial observation multiple cameras multiple robots contemporary robotics mutually observable world landmarks egomotion estimate low quality odometry imu camera fiducials reciprocal observation algebraic formulation two camera mutual localization setup egomotion free cooperative localization method turtlebots artoolkit translation estimation accuracy;robot vision;robot kinematics cameras robot vision systems equations;slam robots cameras pose estimation robot vision sensor fusion;sensor fusion;slam robots;cameras;pose estimation	Concurrently estimating the 6-DOF pose of multiple cameras or robots - cooperative localization - is a core problem in contemporary robotics. Current works focus on a set of mutually observable world landmarks and often require inbuilt egomotion estimates; situations in which both assumptions are violated often arise, for example, robots with erroneous low quality odometry and IMU exploring an unknown environment. In contrast to these existing works in cooperative localization, we propose a cooperative localization method, which we call mutual localization, that uses reciprocal observations of camera-fiducials to obviate the need for egomotion estimates and mutually observable world landmarks. We formulate and solve an algebraic formulation for the pose of the two camera mutual localization setup under these assumptions. Our experiments demonstrate the capabilities of our proposal egomotion-free cooperative localization method: for example, the method achieves 2cm range and 0.7 degree accuracy at 2m sensing for 6-DOF pose. To demonstrate the applicability of the proposed work, we deploy our method on Turtlebots and we compare our results with ARToolKit [1] and Bundler [2], over which our method achieves a tenfold improvement in translation estimation accuracy.	3d pose estimation;3d reconstruction;artoolkit;camera resectioning;experiment;fiducial marker;observable;open-source software;robot;robotics;visual odometry	Vikas Dhiman;Julian Ryde;Jason J. Corso	2013	2013 IEEE/RSJ International Conference on Intelligent Robots and Systems	10.1109/IROS.2013.6696524	computer vision;simulation;pose;computer science;control theory;sensor fusion	Robotics	55.14998775796004	-38.402171785521936	54826
883231e576444a95bb1bd494ad2d76d00cef8f34	flexible entrainment in a bio-inspired modular oscillator for modular robot locomotion	robust autonomous locomotion;fast servo;different servo;new oscillator model;oscillator model;modular robot;different responsiveness;modular robot locomotion;bio-inspired modular oscillator;previous work;central pattern generator;mechanical response;flexible entrainment	The ability of a Central Pattern Generator to adapt its activity to the mechanical response of the robot is essential for robust autonomous locomotion in unknown environments. In previous works we have introduced a new oscillator model for locomotion in modular robots. In this paper, we study the ability of our oscillator model to entrain a servo. For a given configuration of the oscillator, we simulate different servos with different responsiveness, ranging from very slow to very fast servos. The result is that our oscillator adapts its frequency of oscillation to the responsiveness of the servo up to several orders of magnitude, without changing the parameters of the oscillator itself.		Fernando Herrero-Carrón;Francisco B. Rodríguez;Pablo Varona	2011		10.1007/978-3-642-21498-1_67	control theory	Robotics	66.07375413563989	-25.218600600923885	54867
2e40aefe6a1d3fe106493ef2600aff166ac0a794	a new time-independent image path tracker to guide robots using visual servoing	tracking robots;oscillations;tracking system;path planning;visual servoing trajectory cameras robot vision systems calibration orbital robotics physics systems engineering and theory tracking robustness;mobile robots;eye in hand camera system image path tracking robot visual servoing image trajectory tracking tracking velocity oscillating behavior;visual servoing mobile robots path planning position control robot vision tracking;robot vision;position control;visual servoing;info eu repo semantics bookpart;tracking	In this paper, a new method to track image trajectories by visual servoing is proposed. This method solves the problem of the previous proposed time-independent tracking systems based on visual servoing. With the proposed method, the robot can track a previously generated trajectory affording a correct tracking not only in the image but also in the 3D space. This new method presents several improvements over the previous ones such as the possibility of specifying the desired tracking velocity, a less oscillating behavior or a correct tracking in the 3D space when high velocities are used. In order to demonstrate the correct behavior of the visual servoing system, an eye-in-hand camera system is used.	algorithm;bibliothèque de l'école des chartes;iteration;robot;serial digital video out;tracking system;velocity (software development);visual servoing	Gabriel J. García;Jorge Pomares;Fernando Torres Medina	2007	2007 IEEE Conference on Emerging Technologies and Factory Automation (EFTA 2007)	10.1109/EFTA.2007.4416887	mobile robot;computer vision;simulation;tracking system;computer science;artificial intelligence;control theory;motion planning;tracking;visual servoing;oscillation	Robotics	59.918598358744404	-32.15401616813815	54944
66e0bcc25551d4abfbe4fb1ed6b3866fcb8bd732	coherent culling and shading for large molecular dynamics visualization	i 3 7 computer graphics computer graphics three dimensional graphics and realism;molecular dynamic	Molecular dynamics simulations are a principal tool for studying molecular systems. Such simulations are used to investigate molecular structure, dynamics, and thermodynamical properties, as well as a replacement for, or complement to, costly and dangerous experiments. With the increasing availability of computational power the resulting data sets are becoming increasingly larger, and benchmarks indicate that the interactive visualization on desktop computers poses a challenge when rendering substantially more than millions of glyphs. Trading visual quality for rendering performance is a common approach when interactivity has to be guaranteed. In this paper we address both problems and present a method for high-quality visualization of massive molecular dynamics data sets. We employ several optimization strategies on different levels of granularity, such as data quantization, data caching in video memory, and a two-level occlusion culling strategy: coarse culling via hardware occlusion queries and a vertex-level culling using maximum depth mipmaps. To ensure optimal image quality we employ GPU raycasting and deferred shading with smooth normal vector generation. We demonstrate that our method allows us to interactively render data sets containing tens of millions of high-quality glyphs.	coherent;computation;computer data storage;deferred shading;desktop computer;dynamic data;experiment;fragment processing;geometry processing;glossary of computer graphics;glyph;graphics processing unit;hidden surface determination;image processing;image quality;interactive visualization;interactivity;mathematical optimization;mipmap;molecular dynamics;normal (geometry);out-of-core algorithm;parallel rendering;pixel;ray casting;rendering (computer graphics);sampling (signal processing);simulation;sparse matrix;subdivision surface;supersampling;video ram (dual-ported dram);workstation	Sebastian Grottel;Guido Reina;Carsten Dachsbacher;Thomas Ertl	2010	Comput. Graph. Forum	10.1111/j.1467-8659.2009.01698.x	computer vision;simulation;computer science;theoretical computer science;operating system;computer graphics (images)	Visualization	68.37902825695254	-51.44301541465811	54945
fd206b48efdf1287e6dbdea1e4a24c05de591cd4	manipulation extrapolation: a system for controlling trainable robots			extrapolation;robot	Ronald W. Colman	1979				Robotics	68.00033220050715	-28.71704210524797	54969
43127b8e88f41cc10238ead6dc1765bdf81bf273	a new integrated data structure for 3d gis	ground contour lines;visualization integrated data structure 3d gis spatial data 3d spatial entity simulation modeling algorithm tin model csg model buildings ground contour lines triangulating terrains;building;triangulating terrains;spatial data;integrable model;3d gis spatial data;tin model;3d gis;csg model;boundary subdivision;simulation experiment;data visualisation;visualization;gis;computational complexity;geographic information systems;data structures geographic information systems tin data models buildings educational institutions automation data visualization computational modeling application software;simulation modeling algorithm;visual databases building data visualisation geographic information systems terrain mapping;opengl tin csg boundary subdivision gis;opengl;terrain mapping;tin;3d spatial entity;data structure;simulation model;buildings;csg;integrated data structure;visual databases	In order to organize and manage 3D GIS spatial data effectively, and represent 3D spatial entity integrally, a new simulation modeling algorithm is put forward, which combines data structures of constrained TIN and CSG. In this algorithm, TIN model is used to represent terrain and CSG model is used to represent buildings. The two simulation models are integrated by extracting ground contour lines of buildings as constrained conditions when carrying out triangulating terrains. And the visualization for all parts of the integrated model can be processed synchronously. The results of simulation experiments made with empirical data demonstrate that the algorithm simplifies modeling process and to a certain extent, reduces computing complexity for visualization	algorithm;constrained delaunay triangulation;constructive solid geometry;contour line;data model;data structure;entity;experiment;geographic information system;simulation;solid modeling;synchronization (computer science);wire-frame model	Huixin Wu;Huifeng Xue	2006	2006 9th International Conference on Control, Automation, Robotics and Vision	10.1109/ICARCV.2006.345092	computer vision;simulation;visualization;data structure;tin;computer science;simulation modeling;spatial analysis;building;computational complexity theory;statistics;computer graphics (images)	Robotics	64.6523880013869	-43.291867755108065	55016
3f663eeadfcb01493f497e3de10872037b38bddb	a novel sensor for real-time measurement of force and torque of colonoscope		Colonoscopy is widely used in the diagnosis and treatment of colorectal diseases due to its minimal invasiveness, convenience and efficiency. However, it has two problems: bowel perforation and looping. In order to overcome these problems, it is necessary to get the information of the force and posture of the distal end of the colonoscope in the colonoscopy procedure. Elsewhere, we have reported an approach to have a sensor on the hose of colonoscope, which is outside the human body, to infer the force information at the distal end which is inside the human body, via a kinetic model. This paper presents a work on developing such a sensor. The goal of this work is to improve the accuracy of the senor while maintaining its low cost.	colonoscopes;hematological disease;hysteresis;inference;intestinal perforation;intestines;kinetics;loop perforation;medical device material perforation;poor posture;real-time clock;regular expression;repeatability;requirement;sensor;simulation;colonoscopy	Changyuan Zheng;Zhiqin Qian;Kang Zhou;Hao Liu;Dongyuan Lv;Wenjun Zhang	2017	IECON 2017 - 43rd Annual Conference of the IEEE Industrial Electronics Society	10.1109/IECON.2017.8216552	colonoscopy;control theory;control engineering;engineering;torque	Robotics	74.23749173645528	-28.766629994873384	55069
29e5d2bbaca3485bb3c987c9300fa09d512b6238	stiffening in soft robotics: a review of the state of the art	robot sensing systems;soft robotics;service robots;actuators;intelligent robots controllability elastic deformation elasticity;actuators soft robotics robot sensing systems service robots morphological operations;morphological operations;robot compliance soft robotics soft materials service robots natural environments physical body movement control embodied intelligence morphological computation paradigm robot deformability	The need for building robots with soft materials emerged recently from considerations of the limitations of service robots in negotiating natural environments, from observation of the role of compliance in animals and plants [1], and even from the role attributed to the physical body in movement control and intelligence, in the so-called embodied intelligence or morphological computation paradigm [2]-[4]. The wide spread of soft robotics relies on numerous investigations of diverse materials and technologies for actuation and sensing, and on research of control techniques, all of which can serve the purpose of building robots with high deformability and compliance. But the core challenge of soft robotics research is, in fact, the variability and controllability of such deformability and compliance.	computation;heart rate variability;programming paradigm;robot;soft robotics	Mariangela Manti;Vito Cacucciolo;Matteo Cianchetti	2016	IEEE Robotics & Automation Magazine	10.1109/MRA.2016.2582718	behavior-based robotics;control engineering;simulation;ant robotics;engineering;robot control;actuator;mechanical engineering	Robotics	67.14547296928609	-27.249919700026705	55118
c8df0a46e4e7b0da4a9996acef7ecfc5c11f7092	a survey of inverse surface design from light transport behavior specification	light transport;luminaire design;computacion informatica;inverse surface design;i 3 7 computer graphics three dimensional graphics and realism;grupo de excelencia;i 4 7 image processing and computer vision feature measurement;i 3 6 computer graphics methodology and techniques;ciencias basicas y experimentales;i 4 1 image processing and computer vision digitization and image capture;physical model;inverse rendering;reflector design	Inverse surface design problems from light transport behavior specification usually represent extremely complex and costly processes, but their importance is well known. In particular, they are very interesting for lighting and luminaire design, in which it is usually difficult to test design decisions on a physical model in order to avoid costly mistakes. In this survey, we present the main ideas behind these kinds of problems, characterize them, and summarize existing work in the area, revealing problems that remain open and possible areas of further research.	specification language;test design	Gustavo Patow;Xavier Pueyo	2005	Comput. Graph. Forum	10.1111/j.1467-8659.2005.00901.x	computer vision;simulation;physical model;computer science;artificial intelligence;geometry;computer graphics;algorithm;computer graphics (images)	Graphics	64.66245287002998	-44.34535602601719	55153
83e957a1a00829a107bcc53999d5f26c97a8a3f7	collision detection for 6-dof parallel-link cmm	mechanical engineering computing;virtual reality application program interfaces cad computer graphics coordinate measuring machines mechanical engineering computing virtual prototyping;computer graphics;cad;virtual reality;coordinate measuring machines prototypes solid modeling educational institutions machine tools real time systems numerical models;virtual prototyping;collision detection;virtual prototype system 6 dof parallel link cmm collision detection coordinate measuring machine probe posture graphics functions opengl library bounding box algorithm;application program interfaces;coordinate measuring machines;bounding box opengl parallel link cmm collision detection	Generally, the parallel-link Coordinate Measuring Machine(CMM) has higher measuring accuracy and more flexible probe posture than the serial-link CMM. Therefore, theoretical and experimental research for the parallel-link CMM has become a hot topic for both industry and academia. In this paper, the virtual prototype of the 6-DOF parallel-link CMM was designed using the graphics functions in the OpenGL library. On the basis of above, a bounding box algorithm was developed to detect collision in the movement process, the detail method of the detection and the programming are also presented. This method improves not only the detection efficiency but also the reality of virtual prototype system.	capability maturity model;collision detection	Wei Zhou;Dali Gong;Yaru Xue;Caiping Liu	2011		10.1109/EMEIT.2011.6022886	embedded system;simulation;computer science;artificial intelligence;operating system;cad;virtual reality;computer graphics;collision detection;computer graphics (images)	Robotics	66.5528174170269	-31.666689172933104	55167
1180f374ea48d585149334129d90208196f3387b	a scheme for interpolation with trigonometric spline curves	interpolation;computacion informatica;shape parameters;bezier spline;blending;ciencias basicas y experimentales;matematicas;grupo a;trigonometric spline;overhauser spline	We present a method for the interpolation of a given sequence of data points with C n continuous trigonometric spline curves of order n + 1 ( n ? 1 ) that are produced by blending elliptical arcs. Ready to use explicit formulae for the control points of the interpolating arcs are also provided. Each interpolating arc depends on a global parameter α ? ( 0 , π ) that can be used for global shape modification. Associating non-negative weights with data points, rational trigonometric interpolating spline curves can be obtained, where weights can be used for local shape modification. The proposed interpolation scheme is a generalization of the Overhauser spline, and it includes a C n Bezier spline interpolation method as the limiting case α ? 0 .	interpolation;spline (mathematics)	Imre Juhász;Ágoston Róth	2014	J. Computational Applied Mathematics	10.1016/j.cam.2013.12.034	spline interpolation;spline;mathematical optimization;mathematical analysis;trigonometric interpolation;perfect spline;smoothing spline;monotone cubic interpolation;interpolation;polynomial interpolation;cubic hermite spline;hermite spline;mathematics;geometry;thin plate spline;polyharmonic spline;multivariate interpolation;m-spline;algorithm;statistics	Theory	69.44281820662131	-40.6018718118777	55214
70ba5f28662cbf09a699758c4168d97436a1df9c	a simple technique for nurbs shape modification	spline surface topography surface reconstruction shape control focusing polynomials h infinity control;computer graphics;non uniform rational b spline;computational geometry;surface fitting;nurbs;splines mathematics;shape;geometric concepts nurbs shape modification nonuniform rational b splines de facto industry standard mathematical form freeform shapes analytical curves surfaces;constrained manipulation;computer graphics splines mathematics computational geometry curve fitting surface fitting;curve fitting;conics;perspective transformation	Non-uniform rational B-splines (NURBS) have become a de-facto industry standard primarily because they offer a unified mathematical form for representing both freeform shapes and analytical curves or surfaces. Despite these advantages, designers need software that lets them work with NURBS in a natural way. The paper presents a unified approach to NURBS shape modification that builds on a perspective functional transformation of arbitrary origin and provides a homogeneous interface based on simple, easily understood geometric concepts.	non-uniform rational b-spline	Javier Sánchez-Reyes	1997	IEEE Computer Graphics and Applications	10.1109/38.576858	mathematical optimization;non-uniform rational b-spline;computational geometry;shape;mathematics;geometry;conic section;computer graphics;curve fitting	Visualization	67.03235228383642	-42.487444192458575	55248
1cdacbf5c6bf810efcebd5d8cdfc89ae5425f70d	robotized skin harvesting	medical robotics	Medical robots especially allow to enhance accuracy and reproducibility of the surgical gesture, while the surgeon keeps the control and decision actions. In reconstructive surgery, it has been shown that the robot could improve significantly unskilled surgeons who don’t achieve regularly these operations: the tool used to harvest skin samples, called dermatome, is mounted at the tip of a dedicated robot, which precisely controls the force pressure on the tissue and the harvesting velocity. In this paper, we describe the robotic system which has been deigned and which is currently in a validation process. Emphasis is laid on a skin model which is used to optimize the control law performance. Safety is also discussed and finally in vivo experimental results are reported.	experiment;human–computer interaction;intrinsic safety;optimal control;robot;scara;skin (computing);velocity (software development);video-in video-out	Gilles Duchemin;Etienne Dombre;François Pierrot;Philippe Poignet	2002		10.1007/3-540-36268-1_36	simulation;computer science;engineering;biological engineering	Robotics	73.49365742267126	-27.937093272751774	55260
47d70d766bec321d1c1ae1c69734675d415bde4a	radio module for fast real-time control of inverse triple pendulum	automatic control;wireless sensor;ieee 802 15 4;inverse triple pendulum;rex control system	The paper demonstrates use of wireless sensor as input data source for fast real-time automatic control. Fast, underactuated and highly unstable inverse triple pendulum system is controlled on the basis of values measured on the pendulum arms and wirelessly transmitted to the controller. The presented solution working in 2.4 GHz band and based on Atmel SAM R21 SoC on the sensor side and Atmel AT86RF233 transceiver on the controller side delivers data from 2 IRC sensors and 3-axis gyroscope with latency as low as 350 us.	atmel avr;automatic control;coat of arms;control theory;gyroscope;internet relay chat;real-time clock;sensor;transceiver	Roman Cecil;Vlastimil Setka;Milos Schlegel	2016	2016 3rd International Symposium on Wireless Systems within the Conferences on Intelligent Data Acquisition and Advanced Computing Systems (IDAACS-SWS)	10.1109/IDAACS-SWS.2016.7805791	control engineering;electronic engineering;engineering;control theory	Embedded	56.38768233107949	-34.41902533179439	55335
26a4d601ff046d8e2ab5cc8809e8dab29ad708a6	a delayed force-reflecting haptic controller for master-slave neurosurgical robots	haptics;force reflection;minimally invasive surgery;surgeon training	This paper presents a new force-reflecting control system for master–slave haptic devices. This controller has been implemented and tested on the robotic systems for minimally invasive neurosurgery developed by our Research Group. Robot-assisted surgery is a very valuable treatment, since it allows benefits of high precision, accuracy, and repeatability of robotic devices. The proposed controller is meant to be used for master–slave haptic robotic surgery, but it can be used for any device that provides haptic feedback. The new controller merges the paradigms of force reflection (FR) control and delayed reference control. Unlike the FR control, the proposed solution enhances the safety since it does not allow an unwanted motion of the slave device once the operator releases the haptic controller. Experimental tests are provided to show the capabilities and the performance of the controller. Closed-loop stability is investigated both theoretically and experimentally. The analytic results on stability impos...	haptic technology;robot	Paolo Boscariol;Alessandro Gasparetto;Renato Vidoni;Vanni Zanotto	2015	Advanced Robotics	10.1080/01691864.2014.977947	control engineering;simulation;computer science;engineering;artificial intelligence;control theory;haptic technology	Robotics	73.53568414211858	-27.670234331200195	55349
ff7acbd31dfade6ceffb0753d4a31b8a74bb4ff7	construction and central pattern generator-based control of a flipper-actuated turtle-like underwater robot	three dimensional;nonlinear oscillation;control architecture;swimming patterns;2 d o f flippers;smooth transition;central pattern generator;turtle like underwater robot;rowing action	This paper deals with the construction and control of a turtle-like underwater robot with four mechanical flippers. Each flipper consists of two joints generating a rowing motion by a combination of lead-lag and feathering motions. With cooperative movements of four flippers, the robot can propel and maneuver in any direction without rotation of its main body and execute complicated three-dimensional movements, including ascending, submerging, rolling and hovering. The control architecture is constructed based on a central pattern generator (CPG). A model for a system of coupled nonlinear oscillators is established to construct a CPG and has been successfully applied to the eight-joint turtle-like robot. The CPGs are modeled as nonlinear oscillators for joints and inter-joint coordination is achieved by altering the connection weights between joints. Rowing action can be produced by modulating the control parameters in the CPG model. The CPG-based method performs elegant and smooth transitions between swimming gaits, and enhanced adaptation to the transient perturbations due to nonlinear characteristics. The effectiveness of the proposed method is confirmed via simulations and experimental results. © Koninklijke Brill NV, Leiden and The Robotics Society of Japan, 2009	autonomous robot;central pattern generator;feathering;mathematical optimization;nonlinear system;nv network;propel;robot combat;robotics;sensor;simulation;turtle graphics;x image extension	Wei L Z Zhao;Yonghui Hu;Long Wang	2009	Advanced Robotics	10.1163/156855308X392663	three-dimensional space;central pattern generator;simulation;engineering;marine engineering	Robotics	66.45126108723363	-24.62289251728625	55441
3714823dd22c8f9a39407f235e710338d78bbab5	modeling of human strategy in controlling light source	automatic control;light source control;machining;lighting control;neural networks;illumination;neural nets;automatic light control;inspection;computer vision human control strategy modelling light source control illumination automatic light control dynamical placement pose estimation cascade neural network shadow avoidance;computer vision;shadow avoidance;learning systems;dynamic environment;cascade neural network;human control strategy modelling;computer vision lighting control learning systems neural nets;robots;surgery;humans;space application;light sources;humans lighting control light sources neural networks automatic control robots machining surgery inspection automation;pose estimation;dynamical placement;automation	In this paper, we present a method of modeling human strategy in controlling light source in dynamic environment. We take a simple example of how to control the light source to avoid a shadow and maintain appropriate illumination condition on the target area of attention to illustrate the procedure and method. The work is valuable to various applications of automatic light control from surgical room and space applications to inspections.		Jiong Zhang;Yangsheng Xu	1999		10.1109/ROBOT.1999.774076	robot;control engineering;computer vision;simulation;pose;inspection;machining;computer science;engineering;artificial intelligence;automation;artificial neural network	Vision	62.40771844461285	-26.60320454251977	55450
8abe148f4a7a3814d3c8bd44d29e7be367e231aa	3d motion and shape representations in visual servo control	visual servo control;interfaces;real time;visual navigation;robotics;motion;integration;three dimensional;motors;computer vision;shape representation;automotive vehicles;shape;servomechanisms;cognition;motor activity;control;visual perception;autonomous navigation;surface navigation;visual servoing;visual processing;problem solving;motor control	The study of visual navigation problems requires the integration of visual processes with motor control. Most essential in approaching this integration is the study of appropriate spatiotemporal representations that the system computes from the imagery and that serve as interfaces to all motor activities. Since representations resulting from exact metric reconstruction of the environment have turned out to be very hard to obtain in real time, the authors argue for the necessity of representations that can be computed easily, reliably, and in real time and that recover only the information about the 3D world that is really needed to solve the navigational problems at hand. In this paper, the authors introduce a number of such representations capturing aspects of 3D motion and scene structure that are used to solve navigational problems implemented in visual	autonomous robot;encode;emoticon;machine vision;real-time computing;servo;visual servoing	Cornelia Fermüller;Loong Fah Cheong;Yiannis Aloimonos	1998	I. J. Robotics Res.	10.1177/027836499801700103	control engineering;motor control;three-dimensional space;computer vision;simulation;cognition;visual perception;shape;computer science;motion;interface;robotics;visual servoing;scientific control	Robotics	62.271139403286995	-32.878593802462895	55545
df292dc07845668a63e3953a9073f6ac73266f0a	a three-dimensional configuration-space method for 5-axis tessellated surface machining	3d c space;path planning;optimal method;three dimensional;objective function;configuration space;tool path planning;machine tool;5 axis finish machining;tessellated surfaces;matching method;penalty function	This paper presents a three-dimensional configuration-space (3D C-space) machining method for 5-axis finish machining of tessellated surfaces. To maximize the step-over distance, the curvature matched method (CM2) is used to approximate the cusp height and the step-over distance. A 3D C-space is then built for each cutter contact point (CC point). Every configuration set in this 3D C-space guarantees that the cutter is gouge-free and that the cusp height is less than the machining tolerance. The inclination angle λ by which the cutter is rotated about LY, the yaw angle ω by which the cutter is rotated about LZ and the height δ by which the cutter is lifted along the normal of the surface are three variables used to build the 3D C-space. Next, the optimal cutter orientation is obtained in this corresponding 3D C-space via a special optimization process. The ideal 3D C-space set, the initial 3D C-space set and the objective function of the optimization process are based on machine tool kinematics. Boundary functions are determined by the geometry feature of the 3D C-space. The penalty function method is employed as the optimization method. In this paper, the cutting accuracy is self-guaranteed to be less than the machining tolerance. The cutting speed is set to be as high as possible based on optimal cutter orientation and maximized step-over distance.		Jinhu Lu;R. Cheatham;C. G. Jensen;Yunxia Chen;B. Bowman	2008	Int. J. Computer Integrated Manufacturing	10.1080/09511920701263313	configuration space;three-dimensional space;computer vision;mathematical optimization;engineering;machine tool;penalty method;geometry;motion planning;engineering drawing	Robotics	69.39923117854902	-37.85666428759429	55679
a2285ec33dc1bd105118ec71e7073484aab40b1d	compressive optical deflectometric tomography: a constrained total-variation minimization approach		Optical Deflectometric Tomography (ODT) provides an accurate characterization of transparent materials whose complex surfaces present a real challenge for manufacture and control. In ODT, the refractive index map (RIM) of a transparent object is reconstructed by measuring light deflection under multiple orientations. We show that this imaging modality can be made compressive, i.e., a correct RIM reconstruction is achievable with far less observations than required by traditional minimum energy (ME) or Filtered Back Projection (FBP) methods. Assuming a cartoon-shape RIM model, this reconstruction is driven by minimizing the map Total-Variation under a fidelity constraint with the available observations. Moreover, two other realistic assumptions are added to improve the stability of our approach: the map positivity and a frontier condition. Numerically, our method relies on an accurate ODT sensing model and on a primal-dual minimization scheme, including easily the sensing operator and the proposed RIM constraints. We conclude this paper by demonstrating the power of our method on synthetic and experimental data under various compressive scenarios. In particular, the potential compressiveness of the stabilized ODT problem is demonstrated by observing a typical gain of 24 dB compared to ME and of 30 dB compared to FBP at only 5% of 360 incident light angles for moderately noisy sensing.	flow-based programming;modality (human–computer interaction);numerical integration;on-die termination;on-line debugging tool;ray (optics);synthetic data;tomography	Adriana Gonzalez;Laurent Jacques;Christophe De Vleeschouwer;Philippe Antoine	2012	CoRR		geometry;optics	Vision	60.53768325798287	-51.735835628425114	55685
865fb2f9be526090e2be33a71c28cb9c93e835d0	compression of large-scale terrain data for real-time visualization using a tiled quad tree	real time visualization;e 2 data storage representations;data compression;i 3 7 computer graphics three dimensional graphics and realism;i 3 6 computer graphics methodology and techniques;large scale;tiled quad tree;terrain visualization;e 1 data structures trees;rendering	The aim of the rapid world modeling project is to implement a system to visualize the topography of the entire world on consumer-level hardware. This presents a significant problem in terms of both storage requirements and rendering speed. This paper presents the ‘Tiled Quad Tree’, a technique and format for the storage of digital terrain models, to work as part of an integrated system for the visualization of global terrain data. We show how this format efficiently stores and compresses elevation data, in a way that allows the data to be read very rapidly from hard disk or similar storage medium, to facilitate real-time rendering. The results of compressing several distinct data sets are presented.	digital elevation model;hard disk drive;quadtree;real-time clock;real-time locating system;requirement;topography	M. Platings;Andrew M. Day	2004	Comput. Graph. Forum	10.1111/j.1467-8659.2004.00806.x	data compression;terrain rendering;computer vision;tiled rendering;scientific visualization;simulation;rendering;computer science;computer graphics (images)	Visualization	69.14797596507985	-51.84727488952568	55693
451a43ae9fc2b278fd15d9e76a9fbd73e0446b6a	action annotated trajectory generation for autonomous maneuvers on structured road networks	mobile robots action annotated trajectory generation autonomous maneuvers structured road networks path planning method autonomous vehicles global state machine madeingermany;trajectory vehicles roads spline mobile robots planning;autonomous vehicle;road network;path planning;trajectory control finite state machines mobile robots path planning road vehicles;state machine;mobile robots;finite state machines;trajectory generation;trajectory control;road vehicles	This paper presents a simple path-planning method with low computational cost for autonomous vehicles driving on structured road networks. Characteristics of the road structure are exploited for efficient planning and evaluation. Instead of using a global state machine, necessary actions for maneuvers are generated online and are annotated into the trajectory itself. The method has been tested with our vehicle “MadeInGermany” over several thousand kilometers driving autonomously in urban city scenarios and highway tracks.	algorithmic efficiency;autonomous robot;computation;cubic hermite spline;cubic function;finite-state machine;lateral computing;lateral thinking;madeingermany;map;motion planning;planner;spline interpolation	Miao Wang;Tinosch Ganjineh;Raúl Rojas	2011	The 5th International Conference on Automation, Robotics and Applications	10.1109/ICARA.2011.6144858	mobile robot;computer vision;simulation;computer science;artificial intelligence;motion planning;finite-state machine	Robotics	54.925225314038165	-26.93667854352385	55820
8572c2a5b0351e16a7dc72e91aac2d6326f19dcc	algoritmo para el cálculo del ritmo en una señal de audio digital		In this paper presents an algorithm for extraction of audio rhythm of a digital signal. The rhythm is formed by changes of intensity in the audio data signal. The rhythm marks significant changes in the acoustic signals. Through a procedure of filtering for extraction the envelope of the audio signal, then through a square signal marked the start point and duration of changes on the envelope. The algorithm is tested with a signal of a metronome of 60bps to validate this proposal.	acoustic cryptanalysis;algorithm;digital signal (signal processing);filter (signal processing);unique name assumption	Luis Felipe Romero Morales;José Martín Flores Albino	2016	Research in Computing Science			HCI	80.52640101494335	-33.0765748590536	55831
9b0a2cc2b353e57f011480e59e6e2f8f8c7a4f01	semiglobal deformation and correction of free- form surfaces using a mechanical alternative		Free-form surfaces deformation is difficult since more than one control point must be moved to achieve satisfying results. Simultaneous movement of control vertices provides semiglobal deformation. The method uses an analogy between the control polyhedron of a surface and the mechanical equilibrium of a bar network. Changes of mechanical parameters produce real-time shape modifications. A toolkit of basic deformation functions achieve surface inflation, tweaking and shrinking. Each equilibrium position of the network is the solution of a linear system of equations. The surface can be deformed on a local, semiglobal or global basis. Higher-level interactive functions suppress undesired bumps or wrinkles and provide real-time surface adjustment and precise control of curvature distribution.	control point (mathematics);interpolation;linear system;polyhedron;real-time locating system;real-time transcription;system of linear equations;tweaking;vertex (geometry);vertex (graph theory)	Jean-Claude Léon;Philippe Véron	1997	The Visual Computer	10.1007/s003710050093	control theory	Graphics	69.30811743791077	-42.97742596233231	55851
754f0e8b422a5e4ffd84d1ff4c6a36034e94010a	a two-stage framework for denoising electrooculography signals	swt;snr;kalman filter;emd;particle filter;eog	Denoising of electrooculography (EOG) signals is a challenging task as the noise and signal share the same frequency band. This paper proposes a two-stage framework for denoising EOG signals. The first stage approach is based on preserving the nature of eye movements while the second stage is based on the nature of noise (Gaussian or not). In the first stage, denoising is carried out using one out of four filtering methods, each filter being optimal for a particular EOG pattern. The four methods used in the first stage are linear bandpass filtering, stationary wavelet transform (SWT), empirical mode decomposition (EMD) and median filtering. The Stage I framework selects the output that provides the highest estimated signal to noise ratio (SNR). In case, the Stage I filtering does not provide a significant SNR, the system uses Stage II filtering. In the second stage, we use two recursive state estimators, i.e. a Kalman filter and a particle filter for further denoising. The two-stage method is found to provide a better SNR as compared to a single stage method.	electrooculography;noise reduction	Anirban Dasgupta;Suvodip Chakraborty;Aurobinda Routray	2017	Biomed. Signal Proc. and Control	10.1016/j.bspc.2016.08.012	kalman filter;computer vision;speech recognition;particle filter;computer science;machine learning;pattern recognition;signal-to-noise ratio;statistics	ML	81.78582293362776	-39.05225304547185	55929
9a29dedfb06a0d24f41267299c66cbb81d91cc56	frequency space representation of transitions of quadruped robot gaits	fourier series;higher order;quadruped robot	The locomotion of a quadruped robot was examined with the emphasis on the creation, optimization and merging of motions and gaits. A Fourier Series Expansion was performed on the controller commands used in the robot gait. It was found that omitting higher order terms has very little, at times even positive effect on the robot’s performance yet yields a greatly reduced parameter set describing the motion. The parameter reduction is desirable for creating, optimizing and adapting motions. Furthermore, the acquired frequency space representation allows for simple creation of new motions by merging of existing ones and also for creating transitions from one type of motion to another.	mathematical optimization;perturbation theory;robot	Jan Hoffmann;Uwe Düffert	2004			control engineering;computer vision;control theory	Robotics	65.89396808629145	-24.238913751322478	55993
1003f6e3ee55b9e550791c69aaa85055663c7e66	a new two-omni-camera system with a console table for versatile 3d vision applications and its automatic adaptation to imprecise camera setups	3d data computation;computer vision;omni directional camera;computer vision applications;proceedings paper;3d vision;camera calibration;adaptation to imprecise camera setups	A new two-omni-camera system for 3D vision applications and a method for adaptation of the system to imprecise camera setups are proposed in this study. First, an efficient scheme for calibration of several omni-camera parameters using a set of analytic formulas is proposed. Also proposed is a technique to adapt the system to imprecise camera configuration setups for infield 3D feature point data computation. The adaptation is accomplished by the use of a line feature of the console table boundary. Finally, analytic formulas for computing 3D feature point data after adaptation are derived. Good experimental results are shown to prove the feasibility and correctness of the proposed method.	nvidia 3d vision	Shen-En Shih;Wen-Hsiang Tsai	2011		10.1007/978-3-642-17832-0_19	smart camera;computer vision;camera auto-calibration;camera resectioning;simulation;computer science;computer graphics (images)	Vision	55.60580615572771	-44.84645814511671	56029
389c8ef8bd5547ae96caea2efb839d4bc4f6f6e6	processing 3d geo-information for augmenting georeferenced and oriented photographs with text labels	label placement;spatial data;computer vision;object identification;image retrieval	Online photo libraries face the problem of organizing their rapidly growing image collections. Fast and reliable image retrieval requires good qualitative captions added to a photo; however, this is considered by photographers as a time-consuming and annoying task. In order to do it in a fully automated way, the process of augmenting a photo with captions or labels starts by identifying the objects that the photo depicts. Previous attempts for a fully automatic process using computer vision technology only proved not to be optimal due to calibration issues. Existing photo annotation tools from GPS or geo-tagging services can only apply generic location information to add textual descriptions about the context and surroundings of the photo, not actually what the photo shows. To be able to exactly describe what is captured on a digital photo, the view orientation is required to exactly identify the captured scene extent and identify the features from existing spatial datasets that are within the extent. Assumption that camera devices with integrated GPS and digital compass will become available in the near future, our research introduces an approach to identify and localize captured objects on a digital photo using this full spatial metadata. It proposes the use of GIS technology and conventional spatial data sets to place a label next to a pictured object at its best possible location.	computer vision;digital photography;geographic information system;geotagging;global positioning system;image retrieval;library (computing);organizing (structure)	Arnoud De Boer;Eduardo Dias;Edward Verbree	2008		10.1007/978-3-540-68566-1_20	computer vision;computer science;multimedia;information retrieval	Vision	56.0693230453186	-45.652321314283206	56044
17f8c3fb177f96dda2f871cb2dd189d7142df434	etl-humanoid-a high-performance full body humanoid system for versatile actions	chin up experiment etl humanoid high performance full body humanoid system versatile actions 46 dof robot humanoid robot mechanical configuration low level network based control system compactness modularity compliant robots backdrivable robots;humanoid robots control systems laboratories legged locomotion mechanical systems humans neck manufacturing actuators sensor systems;legged locomotion;degree of freedom;control system;range of motion;body weight;perception and action;mechanical systems;high performance;generalization capability	"""This paper presents the final stage of development of the humanoid system, ETL-Humanoid. It is full-scale humanoid system with 46 degrees of freedom, with the height and weight of an average Japanese person. It was designed as an experimental platform, to explore the general principle of controls of complex embodied systems. The complete system will be presented; the mechanical configuration of the system and the low-level network-based control system will also be presented. The final system possesses properties of compactness, modularity and is light in weight. The mechanical system is high in performance, is backdrivable and compliant, allowing the possibility of a wide range of motions and capabilities. The general capability of being able to support itself is demonstrated. A """"Chin Up"""" experiment showing the physical strength of our system is presented. The system is able to support its own body weight while rising up to a supporting bar. Aside from its physical strength, the system is also capable of performing higher-level perceptions and actions. These capabilities will be briefly presented."""		Akihiko Nagakubo;Yasuo Kuniyoshi;Gordon Cheng	2001		10.1109/IROS.2001.976313	control engineering;simulation;range of motion;engineering;control system;humanoid robot;body weight;control theory;degrees of freedom;mechanical system	Robotics	72.39964903213756	-24.07568747389839	56059
84a9cf8aab65fea8fce45b92cf07aa5a8b71d52f	simple yet stable bearing-only navigation		This article describes a simple monocular navigation system for a mobile robot based on map and replay technique. The presented method is robust, easy to implement, does not require sensor calibration or structured environment and its computational complexity is independent of the environment size. The method can navigate a robot while sensing only one landmark at a time, making it more robust than other monocular approaches. The aforementioned properties of the method allow even low-cost robots effectivelly act in large outdoor and indoor environments with natural landmarks only. The basic idea is to utilize monocular vision to correct robot heading only and leaving distance measurements to odometry. The heading correction itself can suppress odometric error keeping the position error bound. The article examines influence of map-based heading estimation and odometric errors on the overall position uncertainty. A claim that for a certain set of trajectories the localization error of this type of navigation remains bound is stated. This claim is defended mathematically and by simulated and real-world experiments. This method was demonstrated in a ∗Use footnote for providing further information about author (webpage, alternative address). Acknowledgments to funding agencies should go in the Acknowledgments section at the end of the paper. Robotour autonomous robot competitions, during which it has successfully completed paths over 1 km length with localization errors lower than 0.5 m.	autonomous robot;computational complexity theory;course (navigation);experiment;internationalization and localization;mobile robot;odometry;robustness (computer science);sensor;simulation;web page	Tomás Krajník;Jan Faigl;Vojtech Vonásek;Karel Kosnar;Miroslav Kulich;Libor Preucil	2010	J. Field Robotics	10.1002/rob.20354	computer vision;simulation;chemistry;artificial intelligence;mobile robot navigation	Robotics	54.434323387812555	-34.9163463223723	56151
cc14d6b43494c6b2a79fa54abd7cf0ca5d350af9	synthesizing balancing character motions	i 3 5 computer graphics;i 3 7 computer graphics;computational geometry and object modeling;animation;three dimensional graphics and realism;physically based modeling;categories and subject descriptors according to acm ccs	This paper presents a novel method for generating balancing character poses by means of a weighted inverse kinematic constraint algorithm. The weighted constraints enable us to control the order of priority so that more important conditions such as balancing can take priority over less important ones. Maintaining a balancing pose enables us to create a variety of physically accurate motions (e.g., stepping, crouching). Balancing is achieved by controlling the location of the overall centre of mass of an articulated character; while the secondary constraints generate poses from end-effectors and trajectory information to provide continuous character movement. The poses are created by taking into account physical properties of the articulated character, that include joint mass, size, strength and angular limits. We demonstrate the successfulness of our method by generating balancing postures that are used to produce controllable character motions with physically accurate properties; likewise, our method is computationally fast, flexible and straightforward to implement.	angularjs;constraint algorithm;inverse kinematics;stepping level	Ben Kenwright	2012		10.2312/PE/vriphys/vriphys12/087-096	computer vision;simulation;computer science;computer graphics (images)	Graphics	64.8477777224819	-46.07875324303595	56166
1fe2da4d62d3a93d4a8105b94b7878379b92698c	mobility evaluation of a wheeled microrover using a dynamic model	mobile robots robot sensing systems mars wheels navigation sonar detection robot vision systems cameras energy measurement time measurement;robot design;mobile robot;marsian surface wheeled microrover dynamic model mobility evaluation statistical technique mobile robot navigation simulation kinematics dynamics;dynamic model;evaluation method;mobile robots;multiple criteria;wheeled mobile robot;energy cost;statistical techniques	This paper describes a multiple criterion, statistical technique for mobile robot evaluation. The evaluation method measures the time and energy costs of a particular class of exploratory missions. The method is implemented in the special case of one wheeled mobile robot in the lab which was made to execute several (approximately 100) instances of the mission. It is proposed that a validated, dynamic model of the robot embedded in a simulated mission scenario be used to study alternate robot designs in a smalìneighborhood' of the existing physical system. Such a simulation was built and is described here. Results from trials with the physical robot and its simulated counterpart are compared and shown to agree well. The simulation is used to evaluate designs not constructed in the lab and the results are discussed.	embedded system;lazy evaluation;mathematical model;mobile robot;simulation	Gaurav S. Sukhatme;Scott Brizius;George A. Bekey	1997		10.1109/IROS.1997.656558	control engineering;mobile robot;computer vision;simulation;computer science;engineering;artificial intelligence;arm solution;robot control;mobile robot navigation;robot calibration	Robotics	54.643715758934604	-31.96024922765716	56253
74e505a664caf82cc9d5110aa654184abcaab161	tracking of 2d or 3d irregular movement by a family of unscented kalman filters	2d 3d tracking;unscented kalman filter;detection by tracking	The paper reports about the design of an object tracker which utilizes a family of unscented Kalman filters, one for each tracked object. This is a more efficient design than having one unscented Kalman filter for the family of all moving objects. The performance of the designed and implemented filter is shown by using simulated movements, and also for object movements in 2D an 3D space.	dynamic programming;kalman filter;relevance;robustness (computer science);simulation;visual odometry	Junli Tao;Reinhard Klette	2012	J. Inform. and Commun. Convergence Engineering	10.6109/jicce.2012.10.3.307	control engineering;computer vision;invariant extended kalman filter;fast kalman filter;unscented transform;control theory;extended kalman filter;moving horizon estimation;alpha beta filter	Robotics	55.967072473734774	-35.65684234071926	56333
9c93aee250ca8f44ed3b0f982b06057a28f8ce56	the geometric meaning of nielson's affine invariant norm	scattered data interpolation;affine invariant norm;geometric mean;methods of scattered data interpolation	This paper presents a geometric interpretation of the aane invariant metric introduced in (Nielson, 1987) and (Nielson and Foley, 1989). The norm allows the modiication of several methods of scattered data interpolation to achieve aane invariance of the interpolating surfaces.	multivariate interpolation	Wendelin L. F. Degen;Volker Milbrandt	1997	Computer Aided Geometric Design	10.1016/S0167-8396(97)81782-7	discrete mathematics;geometric mean;topology;affine coordinate system;affine plane;affine geometry of curves;affine hull;affine transformation;mathematics;geometry;affine shape adaptation;affine combination;affine group	Vision	54.35639186294168	-51.6898067266621	56382
253d065b234ab9a5415cb74e84b5fe383fa12a07	coupling effect on thermal comfort in a typical cubicle-based office with personalized floor diffuser control	temperature control biothermics diffusion heat transfer indoor environment numerical analysis office environment physiological models;heating couplings atmospheric modeling computational modeling temperature sensors heat transfer floors;constant heat flux coupling effect cubicle based office comfort personalized floor diffuser control office layout cubicle microenvironment control air flow rate control numerical analysis personal thermal sensation preference discrepancy effect local thermal comfort neighboring cubicle thermal comfort effect closed doorway effect open doorway effect upper space openness effect thermoregulation effect	A typical office layout with cubicles, in which occupants have their own control of the micro-environment by adjusting supply air flow rate of the floor diffuser, is numerically investigated for the impact of the discrepancy in personal thermal sensation preference on thermal comfort. The comparison among different scenarios indicates that whether the local thermal comfort is significantly affected by the neighboring cubicle (coupling effect) depends on whether the doorway is closed or not whereas the “openness”, of upper space has no influence on such coupling effect but observably on the thermal comfort. The effect of thermoregulation is also presented and compared with conventional constant heat flux assumption for the occupants.	discrepancy function;doppler effect;flow rate;numerical analysis;openness;personalization;physiologic thermoregulation;thermosensing	Z. Y. Shi;T. Dong	2014	2014 36th Annual International Conference of the IEEE Engineering in Medicine and Biology Society	10.1109/EMBC.2014.6943722	simulation;architectural engineering;engineering;engineering drawing	EDA	77.85843286571509	-27.682448571064135	56498
bd005faea0651c264396a462f95b7440db2ba336	development of a pneumatic soft actuator with pleated inflatable structures		Many soft actuators have been studied for use in robots that come into contact with humans, including communication, entertainment, and medical/health care robots. One reason for this is that soft robots are expected to exhibit intrinsic safety in case an accident occurs. This paper proposes a plastic-film pneumatic actuator with a pleated structure that do not undergo the elastic deformation typical of rubber materials. By utilizing thin plastic films, the mass of an actuator can be significantly reduced, even if the actuators are the same size as a human arm. If the mass of the actuator is reduced, the kinetic energy when contacts with humans mechanically can be reduced considerably without reducing the working speed. More specifically, we propose a pleated structure made of plastic to achieve structural deformation generated from a two-dimensional pleated film. The pleated structure easily generates various bending motions. In this paper, a design method for determining the shape parameters of the pleated actuator structure using approximate models with considering measurement results of generating force is presented. We evaluated the adequacy of our approach in experiments using sample actuators. Furthermore, we show the constraints required to determine the necessary parameters. Thus, this paper provides an easy method for designing a lightweight and flexible plastic-film actuator.	3d film;approximation algorithm;artificial intelligence;displacement mapping;experiment;fitness approximation;humans;intrinsic safety;mathematical model;nonlinear system;polymer;prototype;reduction (complexity);repeatability;robot;welding power supply	Yasutaka Nishioka;Megumi Uesu;Hisae Tsuboi;Sadao Kawamura;Wataru Masuda;Toshihiko Yasuda;Mitsuhiro Yamano	2017	Advanced Robotics	10.1080/01691864.2017.1345323	bending;inflatable;deformation (mechanics);engineering;deformation (engineering);kinetic energy;control engineering;actuator;pneumatic actuator;pneumatics	Robotics	74.3037971438622	-23.968611585700035	56506
002c52efa435ce9fc42bf72875e322816fb4fa43	adaptive radiosity textures for bidirectional ray tracing	texture mapping;global illumination;level of detail;ray tracing;on the fly;realistic image synthesis	"""We present a rendering method designed to provide accurate, general simulation of global illumination for realistic image synthesis. Separating surface interaction into diffuse plus specular, we compute the specular component on the fly, as in ray tracing, and store the diffuse component (the radiosity) for later-reuse, similar to a radiosity algorithm. Radiosities are stored in adaptive radiosity textures (rexes)1 that record the pattern of light and shadow on every diffuse surface in the scene. They adaptively subdivide themselves to the appropriate level of detail for the picture being made, resolving sharp shadow edges automatically.We use a three-pass, bidirectional ray tracing algorithm that traces rays from both the lights and the eye. The """"size pass"""" records visibility information on diffuse surfaces; the """"light pass"""" progressively traces rays from lights and bright surfaces to deposit photons on diffuse surfaces to construct the radiosity textures; and the """"eye pass"""" traces rays from the eye, collecting light from diffuse surfaces to make a picture."""	algorithm;global illumination;level of detail;on the fly;radiosity (computer graphics);ray tracing (graphics);rendering (computer graphics);simulation;tracing (software)	Paul S. Heckbert	1990		10.1145/97879.97895	texture mapping;ray tracing;computer vision;radiosity;computer science;level of detail;global illumination;computer graphics (images)	Graphics	65.32032473192525	-50.28605082423464	56565
52d158d103fa9eba864b3b1ba57256a9c16f7809	frame field smoothness-based approach for hex-dominant meshing	tetrahedra recombination;mixed hexahedral meshes;hexahedral meshing	An indirect approach for building hex-dominant meshes is proposed: a tetrahedral mesh is constructed at first and is recombined to create a maximum amount of hexahedra. The efficiency of the recombination process is known to significantly depend on the quality of the sampling of the vertices. A good vertex sampling depends itself on the quality of the underlying frame field that has been used to locate the vertices. An iterative procedure to obtain a high quality three-dimensional frame field is presented. Then, a new point insertion algorithm based on a frame field smoothness is developed. Points are inserted in priority in smooth frame field regions. The new approach is tested and compared with simpler strategies on various geometries. The new method leads to hex-dominant meshes exhibiting either an equivalent or a larger volume ratio of hexahedra (up to 20%) compared to the frontal point insertion approach.	algorithm;algorithmic efficiency;computation;display resolution;hexahedron;iterative method;sampling (signal processing);vertex (geometry)	Paul-Emile Bernard;Jean-François Remacle;Nicolas Kowalski;Christophe Geuzaine	2016	Computer-Aided Design	10.1016/j.cad.2015.10.003	mathematical optimization;mathematics;geometry;engineering drawing	Graphics	69.02627405484635	-43.93760613670179	56679
ba9e037e9d2ccc152f5626dfa696364d525c08a4	automatic three-dimensional inspection measurement and detection of errors in transparent pipes	three dimensional			Robert Schmidt;Ullrich Schramm;Ralf Hofmann;Yannick Caulier;Klaus Spinnler;Thomas Wittenberg	2000			computer science;computer vision;computer graphics (images);artificial intelligence	Metrics	60.70049075611437	-47.35585031917919	56685
62549ea0cdfd2ffa3c828e1e632a544db5bfabe1	steering of pedal wave of a snake-like robot by superposition of curvatures	mobile robots;joints;kinematics;curvature superposition;shape;robots;robots shape joints kinematics surface waves mathematical model microcomputers;mathematical model;steering systems mobile robots robot kinematics;continuous snake like robot model;surface waves;pedal wave steering;microcomputers;robot kinematics;steering systems;continuous snake like robot model pedal wave steering curvature superposition robot kinematics	A snake-like robot has an advantage in moving into a narrow space. Particularly “pedal wave”, which is one of its locomotion styles, is suitable for entering a thin path. However, pedal wave have been used only for going straight in most of the prior studies. In particular horizontal steering of pedal wave by a real robot has not been investigated sufficiently. Therefore in this paper we studied a kinematically appropriate steering method of pedal wave using a continuous snake-like robot model. We proposed steering by superposition of a steering curvatures and a pedal wave's curvature, and investigated the condition of suitable steering curvature using kinematic simulations. The proposed steering method was verified by experiments with a real snake-like robot.	experiment;robot;simulation	Hiroya Yamada;Shigeo Hirose	2010	2010 IEEE/RSJ International Conference on Intelligent Robots and Systems	10.1109/IROS.2010.5652118	robot;control engineering;mobile robot;computer vision;kinematics;simulation;shape;surface wave;computer science;engineering;artificial intelligence;mathematical model;torque steering;microcomputer;robot kinematics	Robotics	68.57143136051995	-25.25391478475446	56692
b6ba33862c5fc5821b90f21a9cbe4fbf5cdd0ac7	fuzzy dynamical model of epidemic spreading taking into account the uncertainties in individual infectivity		A multiple-layered medium includes a preprinted image and impact imaged variable information applied to a surface. Subsequently, a layered portion containing such image and information is separated from the remaining layered portion which also retains such image and information. The multiple layered medium provides a pressure-sensitive label that is fastened by adhesive to a surface and a non-adhesive portion of the label that is separated from the fastened portion.		Fabiano de Sant'Ana dos Santos;Neli Regina Siqueira Ortega;Dirce Maria Trevisan Zanetta;Eduardo Massad	2007		10.3233/978-1-58603-936-3-180	algorithm;fuzzy logic;simulation;geography	ML	74.56835501930345	-49.63573744613273	56697
61c65baa3b7e2db8b8e1b2485ae3e937d3c454bb	colour printer characterization by regression with greyspace constraint		The White-Point Preserving Least Squares (WPPLS) algorithm is a method for colour correction that constrains the white point to be exactly mapped into its correct XYZ equivalent. For printers, however, the mapping is from device coordinates to colorimetric densities: the device white is thus mapped into a zero vector and the WPPLS method cannot go forward. Here we use a polynomial regression model and specify that both white (the zero vector) and an average grey be exactly mapped. Moreover we extend the method to accurately but approximately map a subspace of the entire achromatic curve, thus reproducing the neutral tones with far greater accuracy.	algorithm;least squares;polynomial;printer (computing);xyz file format	Mark S. Drew;Graham D. Finlayson;M. Ronnier Luo;Ján Morovic	1998			computer science;artificial intelligence;computer vision	Vision	70.67796122603197	-40.17255362251174	56793
7cfcc5a15fe3167ec5d09ae426a1d95a44150564	appearance-based minimalistic metric slam	resource limitation;image recognition;linear estimation;extended kalman filter appearance based minimalistic metric slam simultaneous localization and mapping resource limited robots odometry single monocular camera bearing information distinctive sensor nonlinear estimation problem position measurements image recognition algorithm;sensors;image matching;simultaneous localization and mapping robot kinematics robot sensing systems robot vision systems mobile robots cameras position measurement motion estimation machine vision computer science;robot vision sensors nonlinear estimation position control kalman filters image matching;kalman filters;robot vision;position control;simultaneous localization and mapping;nonlinear estimation;extended kalman filter	This paper addresses the problem of Simultaneous Localization and Mapping (SLAM) for the case of very small, resource-limited robots which have poor odometry and can typically only carry a single monocular camera. We propose a modification to the standard SLAM algorithm in which the assumption that the robots can obtain metric distance/bearing information to landmarks is relaxed. Instead, the robot registers a distinctive sensor “signature”, based on its current location, which is used to match robot positions. In our formulation of this non-linear estimation problem, we infer implicit position measurements from an image recognition algorithm. The Iterated form of the Extended Kalman Filter (IEKF) is employed to process all measurements.	algorithm;computer vision;estimation theory;extended kalman filter;iterated function;nonlinear system;odometry;robot;simultaneous localization and mapping	Paul E. Rybski;Stergios I. Roumeliotis;Maria L. Gini;Nikolaos Papanikolopoulos	2003		10.1109/IROS.2003.1250627	kalman filter;monte carlo localization;computer vision;simulation;computer science;sensor;control theory;extended kalman filter;simultaneous localization and mapping	Robotics	53.81011195917575	-40.068861550023136	56825
e0b2e8622c2c8f3cc416b64cac20c1c14a0eec31	real-time visualization of the east china sea based on priceton ocean model and volume rendering	real time visualization;free surface;gpu techniques;horizontal curvilinear orthogonal grid;east ocean sea;east china sea;wave submodel;ocean temperature;volume rendering;real time;optimal method;marine geographic information system;time step;turbulence geographic information systems ocean temperature ocean waves oceanographic techniques real time systems;three dimensional;volume rendering technology;sea surface;visualization;opengl rendering techniques;boundary condition;pom;geographic information systems;3d real time visualization;image color analysis;turbulence submodel;data visualization;marine gis;princeton ocean model;surface elevation;ocean temperature 3d real time visualization east china sea priceton ocean model volume rendering technology marine geographic information system turbulence submodel wave submodel horizontal curvilinear orthogonal grid surface elevation time step opengl rendering techniques gpu techniques;priceton ocean model;numerical models;virtual environment;rendering computer graphics;visual system;oceanographic techniques;rendering computer graphics ocean temperature data visualization sea surface numerical models image color analysis;ocean waves;east ocean sea pom volume rendering ray casting marine gis visualization;real time systems;ray casting;turbulence	This paper presents a real-time three dimensional visualization system of the East China Sea, composed by an ocean model with volume rendering technology and a marine GIS system. In the system, the spatiotemporal marine data of East China Sea is retrieved from an ocean modeling called the Princeton Ocean Model (POM), which is a sigma coordinate, free surface ocean model with embedded turbulence and wave submodels, and wet-dry capability. The East China Sea model is implemented on a 1/15 ° × 1/15 ° horizontal curvilinear orthogonal grid with 16 sigma levels. The system rewrites the Princeton Ocean Model on C#.net to provide a whole control upon the model. In the rewritten POM code, data calculated from every time step is transferred to the drawing module for the real time visualization; also, users can in turn modulate parameters and setups of the model or reload initial and boundary conditions during the simulation any time they want to. The paper puts its emphasis on the visualization of the three dimensional physical data-fields of the East China Sea, in which the three dimensional physical data comes from every single internal time step while two dimensional physical data like surface elevation comes from every single external time step. With the data calculated, the virtual environment is established on modern OpenGL rendering techniques complex. Volume rendering technology as well as its optimal methods is used to rebuild the three-dimensional ocean data-fields. GPU techniques and C for graphics (Cg) are also used for a better perform of the volume rendering. Finally, the ocean model and its visualization are integrated into a marine GIS system. The system is trying not only to reveal a realistic ocean environment of the East China Sea, but also to reproduce the scene of the distribution of the three dimensional physical scalar data (e.g. temperature) to the life.	cg (programming language);embedded system;geographic information system;graphics processing unit;opengl;princeton ocean model;real-time locating system;real-time transcription;sigma coordinate system;simulation;turbulence;virtual reality;volume rendering	Liangying Wei;Huiping Xu;Ding Liu	2010	2010 18th International Conference on Geoinformatics	10.1109/GEOINFORMATICS.2010.5567985	meteorology;oceanography;geography;cartography	Visualization	72.80991456486502	-50.847481248655214	56858
240eecd9c28656ff2f9514b08e2f87ffef54bc34	practical global illumination for hair rendering	shadow mapping;image space approximation;frames per second;irradiance samples;real time;real time approximate subsurface scattering;scattering;animated scenes real time approximate subsurface scattering graphics hardware image space approximation irradiance samples;graphics hardware;hardware light scattering optical scattering particle scattering computer graphics shadow mapping animation application software image sampling layout;multiple scattering;subsurface scattering;scattering rendering computer graphics;rendering computer graphics;animated scenes	Both hair rendering and global illumination are known to be computationally expensive, and for this reason we see very few examples using global illumination techniques in hair rendering. In this paper, we elaborate on different simplification approaches to allow practical global illumination solutions for high quality hair rendering. We categorize light paths of a full global illumination solution, and analyze their costs and illumination contributions both theoretically and experimentally. We also propose two different implementation techniques using our novel projection based indirect illumination computation approach and state of the art ray tracing for hair. Our results show that by using our simplifications, a global illumination solution for hair is practical.	analysis of algorithms;categorization;computation;display resolution;experiment;global illumination;level of detail;map;ray tracing (graphics);shadow mapping	Cem Yuksel;Ergun Akleman;John Keyser	2007	15th Pacific Conference on Computer Graphics and Applications (PG'07)	10.1109/PG.2007.53	computer vision;subsurface scattering;computer science;real-time computer graphics;shadow mapping;scattering;computer graphics;graphics hardware;frame rate;software rendering;3d computer graphics;computer graphics (images)	Graphics	64.69293274172296	-51.457702640045426	56908
12038bfb75bd0521a9826c1f2c19885b24c97874	sources of variability in the set-up of an indoor gps	moving object;distributed coordination;uncertainty;fixed effects;standard deviation;large volume metrology;measurement system;physical sciences;statistical model;large scale metrology;igps;large scale;distributed coordinate measuring systems;bundle adjustment;mixed effects;uncertainty of measurement;indoor gps	An increasing demand for an extended flexibility to model types and production volumes in the manufacture of large-size assemblies has generated a growing interest in the reduction of jig and fixtures deployment during assembly operations. A key factor enabling and sustaining this reduction is the constantly expanding availability of instruments for dimensional measurements of large-size products. However, the increasing complexity of these measurement systems and their set-up procedures may hinder the final users in their effort to assess whether the performance of these instruments is adequate for pre-specified inspection tasks. In this paper, mixed-effects and fixed-effects linear statistical models are proposed as a tool to assess quantitatively the effect of set-up procedures on the uncertainty of measurement results. This approach is demonstrated on a Metris Indoor GPS system (iGPS). The main conclusion is that more than 99 % of the variability in the considered measurements is accounted for by the number of points used in the bundle adjustment procedure during the set-up phase. Also, different regions of the workspace have significantly different error standard deviations and a significant effect on the transient duration of measurement. This is expected to affect adversely the precision and unbiasedness of measurements taken with Indoor GPS when tracking moving objects.	algorithm;bundle adjustment;dots per inch;envelope (motion);fixed effects model;global positioning system;mathematical model;ordinary least squares;software deployment;spatial variability;statistical model;system of measurement;transmitter;workspace	Carlo Ferri;Luca Mastrogiacomo;Julian J. Faraway	2010	Int. J. Computer Integrated Manufacturing	10.1080/09511921003642147	statistical model;simulation;uncertainty;engineering;fixed effects model;operations management;system of measurement;physical science;bundle adjustment;standard deviation;engineering drawing;statistics;measurement uncertainty	Mobile	58.69500541846499	-39.36513576411527	56917
f1aa81328e55995e6ee5e0dbf501cb2cd102f213	a proximity-tactile sensor to detect obstacles for a cylindrical arm	proximity tactile sensor;pressure sensitive conductive rubber;capacitance;collision avoidance control;interference checking	近接覚及び触覚の機能を有する新しいセンサの開発を行った.このセンサはマニピュレータの円筒形アームの表面に装着され, 障害物回避制御のための障害物検出及び干渉チェックを実時間で実現するために用いられる.本論文では, まずセンサの検出部の構造について述べ, 次に, 障害物を検出する原理に関して検討する.近接覚センシングのために静電容量の変化が利用され, 触覚センシングのために感圧導電性ゴムの抵抗値の変化が利用されている.センサの検出特性を決定づけるこれらの量を理論的に解析し, 障害物の種類や形状によって変化が異なることを実験値とともに示す.最後に, LCハートレー発振器を中心として構成されている検出回路を説明し, さらに, センサの特性に関する実験結果を示す.本センサは, 接近あるいは接触する障害物を確実に検出でき, 触覚の応答が速いという特徴をもつ.また, その検出部は柔らかくてかつ頑丈で単純な構造となっている.	tactile sensor	Yoji Yamada;Nuio Tsuchida;Minoru Ueda	1990	JRM	10.20965/jrm.1990.p0172	materials science;control engineering;embedded system;electronic engineering;proximity sensor	Robotics	76.41268349801223	-24.3157821283609	56921
1f2b974b8f30d66d99c2686950bb98c44ad8b234	environment-scale fabrication: replicating outdoor climbing experiences		Despite rapid advances in 3D printing, fabricating large, durable and robust artifacts is impractical with current technology. We focus on a particularly challenging environment-scale artifact: rock climbing routes. We propose a prototype fabrication method to replicate part of an outdoor climbing route and enable the same sensorimotor experience in an indoor gym. We start with 3D reconstruction of the rock wall using multi-view stereo and use reference videos of a climber in action to identify localized rock features that are necessary for ascent. We create 3D models akin to traditional indoor climbing holds, fabricated using rapid prototyping, molding and casting techniques. This results in robust holds accurately replicating the features and configuration of the original rock route. Validation was performed on two rock climbing sites in New Hampshire and Utah. We verified our results by comparing climbers' moves on the indoor replicas and original outdoor routes.	3d modeling;3d printing;3d reconstruction;climber (beam);hill climbing;pet rock;piaget's theory of cognitive development;prototype;rapid prototyping;self-replicating machine;times ascent	Emily Whiting;Nada Ouf;Liane Makatura;Christos Mousas;Zhenyu Shu;Ladislav Kavan	2017		10.1145/3025453.3025465	simulation	HCI	57.01929696184811	-43.36739970483976	56983
bd34e8e90be0ac3be911d086439b2a029d6278f2	comprehensive facial performance capture	i 4 8 image processing and computer vision scene analysis;stereo	We present a system for recording a live dynamic facial performance, capturing highly detailed geometry and spatially varying diffuse and specular reflectance information for each frame of the performance. The result is a reproduction of the performance that can be rendered from novel viewpoints and novel lighting conditions, achieving photorealistic integration into any virtual environment. Dynamic performances are captured directly, without the need for any template geometry or static geometry scans, and processing is completely automatic, requiring no human input or guidance. Our key contributions are a heuristic for estimating facial reflectance information from gradient illumination photographs, and a geometry optimization framework that maximizes a principled likelihood function combining multi-view stereo correspondence and photometric stereo, using multiresolution belief propagation. The output of our system is a sequence of geometries and reflectance maps, suitable for rendering in off-the-shelf software. We show results from our system rendered under novel viewpoints and lighting conditions, and validate our results by demonstrating a close match to ground truth photographs.	belief propagation;energy minimization;facial motion capture;gaussian blur;global illumination;gradient descent;ground truth;heuristic;illumination (image);jules;list of 3d rendering software;list of minor characters in the matrix series;map;mathematical optimization;performance;photometric stereo;rendering (computer graphics);software propagation;subsurface scattering;v-ray;virtual reality	Graham Fyffe;Tim Hawkins;Chris Watts;Wan-Chun Ma;Paul E. Debevec	2011	Comput. Graph. Forum	10.1111/j.1467-8659.2011.01888.x	computer vision;simulation;computer science;stereophonic sound;computer graphics (images)	Vision	59.31821013862532	-50.18671246235107	57081
bd87c1d69b5bb6aee484c589d9a682d417c4ece5	pedestrian positioning with physical activity classification for indoors	gyroscopes;legged locomotion;zupt algorithm;hidden markov model;electromagnetic perturbance;magnetometers;physical activity classification;inertial navigation;wearable inertial measurement unit pedestrian positioning system;physical activity;acceleration;position measurement acceleration measurement accelerometers compasses gyroscopes inertial navigation inertial systems magnetometers microsensors;hidden markov models;estimation;step stance phase;gyroscope data;sensor data;position measurement;magnetometers physical activity classification wearable inertial measurement unit pedestrian positioning system hidden markov model sensor data zupt algorithm walking velocity step stance phase acceleration based approach gyroscope data electromagnetic perturbance;hidden markov models legged locomotion gyroscopes acceleration magnetometers estimation accelerometers;acceleration based approach;inertial systems;walking velocity;acceleration measurement;accelerometers;microsensors;compasses	This paper presents a wearable Inertial Measurement Unit pedestrian positioning system for indoors. Hidden Markov Model (HMM) is introduced to pre-process the sensor data and classify common activities. HMM also complements local minimum angular rate value for capturing the onset/end of each step. ZUPT algorithm are implemented to correct the walking velocity at step stance phase when errors existed. A novel acceleration-based approach combined with gyroscope data is developed to achieve a better heading estimation. Proposed method is able to reduce drift errors from gyroscopes and avoid electromagnetic perturbance to magnetometers when estimate subject's position. Experiment results show the positioning system achieves approximately 99% accuracy.	algorithm;angularjs;course (navigation);gyroscope;hidden markov model;markov chain;maxima and minima;onset (audio);positioning system;preprocessor;velocity (software development);wearable computer	Xi Chen;Sheng Hu;Zhenzhou Shao;Jindong Tan	2011	2011 IEEE International Conference on Robotics and Automation	10.1109/ICRA.2011.5980236	acceleration;control engineering;estimation;magnetometer;simulation;gyroscope;computer science;control theory;physical fitness;inertial navigation system;accelerometer;physics;hidden markov model;quantum mechanics	Robotics	57.58273283428936	-37.01739240439061	57165
bdaab4e21876e3009205cffd18bf8b6bb5451d58	an application of continuous wavelet transform in l2(rn)	continuous wavelet transform		continuous wavelet;wavelet transform	H. Qu;Cheng Xu	2003				HCI	67.56053196195165	-35.44651397029692	57297
c0e9c475340ca57b6b1812845ad17d51bc4001ae	forget the checkerboard: practical self-calibration using a planar scene	calibration cameras image reconstruction nonlinear distortion robustness;extrinsic camera parameter camera self calibration method planar scene scene texture planar surface checkerboard based calibration intrinsic camera parameter;nonlinear distortion;image reconstruction;robustness;calibration;cameras;image texture calibration cameras computer vision	We introduce a camera self-calibration method using a planar scene of unknown texture. Planar surfaces are everywhere but checkerboards are not, thus the method can be more easily applied outside the lab. We demonstrate that the accuracy is equivalent to a checkerboard-based calibration, so there is no need for printing checkerboards any more. Moreover, the use of a planar scene provides improved robustness and stronger constraints than a self-calibration with an arbitrary scene. We utilize a closed-form initialization of the focal length with minimal and practical assumptions. The method recovers the intrinsic and extrinsic parameters of the camera and the metric structure of the planar scene. The method is implemented in a real-time application for non-expert users that provides an easy and practical process to obtain high accuracy calibrations.	camera resectioning;focal (programming language);printing;real-time clock;real-time computing	C. Herrera DanielHerrera;Juho Kannala;Janne Heikkilä	2016	2016 IEEE Winter Conference on Applications of Computer Vision (WACV)	10.1109/WACV.2016.7477641	iterative reconstruction;computer vision;camera auto-calibration;nonlinear distortion;calibration;computer science;mathematics;robustness;computer graphics (images)	Vision	55.65863274830305	-49.6304838392887	57306
860ec0c05d29aea84479a9a51f4c89c80b7fb559	control point removal algorithm for t-spline surfaces	insertion;spline;vision ordenador;image processing;esplin;procesamiento imagen;traitement image;computer vision;grid;aproximacion esplin;insercion;rejilla;spline approximation;approximation spline;pattern recognition;grille;vision ordinateur;reconnaissance forme;reconocimiento patron	This paper discusses the problem of removing control points from a T-spline control grid while keeping the surface unchanged. An algorithm is proposed to detect whether a specified control point can be removed or not and to compute the new control points if the point is removable. The algorithm can be viewed as a reverse process of the T-spline local knot insertion algorithm. The extension of the algorithm to remove more control points is also discussed.	algorithm;spline (mathematics);t-spline	Yimin Wang;Jianmin Zheng	2006		10.1007/11802914_27	insertion;spline;computer vision;simulation;image processing;computer science;mathematics;grid;computer graphics (images)	Vision	66.46973978566439	-41.079233989477196	57323
1d50a0ba5ed1777ca5736361b3c4d5f2be9f3fad	on speech enhancement under psd uncertainty		Many well-known and frequently employed Bayesian clean speech estimators have been derived under the assumption that the true power spectral densities PSDs of speech and noise are exactly known. In practice, however, only power spectral density PSD estimates are available. Simply neglecting PSD estimation errors and handling the estimates as true values leads to speech estimation errors causing musical noise and undesired suppression of speech. In this paper, the uncertainty of the available speech PSD estimates is addressed. The main contributions are the following. First, we summarize and examine ways to model and incorporate the uncertainty of PSD estimates for a more robust speech enhancement performance. Second, a novel nonlinear clean speech estimator is derived that takes into account prior knowledge about the absolute value of typical speech PSDs. Third, we show that the derived statistical framework provides uncertainty-aware counterparts to a number of well-known conventional clean speech estimators such as the Wiener filter and Ephraim and Malah's amplitude estimators. Fourth, we show how modern PSD estimators can be incorporated into the theoretical framework and propose to employ frequency dependent priors. Finally, the effects and benefits of considering the uncertainty of speech PSD estimates are analyzed, discussed, and evaluated via instrumental measures and a listening experiment.	bayesian network;nonlinear system;spectral density;speech enhancement;wiener filter;zero suppression	Martin Krawczyk-Becker;Timo Gerkmann	2018	IEEE/ACM Transactions on Audio, Speech, and Language Processing	10.1109/TASLP.2018.2816241	statistics;estimator;wiener filter;amplitude;pattern recognition;artificial intelligence;noise measurement;computer science;prior probability;nonlinear system;spectral density;speech enhancement	ML	82.22262276263518	-35.273384528601134	57332
175aa0546acc43d7cf4f47bf28b2b862a7619a34	high accuracy nc milling simulation using composite adaptively sampled distance fields	nc milling simulation;adf;distance fields;swept volumes	We describe a new approach to shape representation called a composite adaptively sampled distance field (composite ADF) and describe its application to NC milling simulation. In a composite ADF each shape is represented by an analytic or procedural signed Euclidean distance field and the milled workpiece is given as the Boolean difference between distance fields representing the original workpiece volume and distance fields representing the volumes of the milling tool swept along the prescribed milling path. The computation of distance field of the swept volume of a milling tool is handled by an inverted trajectory approach where the problem is solved in tool coordinate frame instead of a world coordinate frame. An octree bounding volume hierarchy is used to sample the distance functions and provides spatial localization of geometric operations thereby dramatically increasing the speed of the system. The new method enables very fast simulation, especially of free-form surfaces, with accuracy better than 1 micron, and low memory requirements. We describe an implementation of 3 and 5-axis milling simulation. Journal Computer-Aided Design This work may not be copied or reproduced in whole or in part for any commercial purpose. Permission to copy in whole or in part without payment of fee is granted for nonprofit educational and research purposes provided that all such whole or partial copies include the following: a notice that such copying is by permission of Mitsubishi Electric Research Laboratories, Inc.; an acknowledgment of the authors and individual contributions to the work; and all applicable portions of the copyright notice. Copying, reproduction, or republishing for any other purpose shall require a license with payment of fee to Mitsubishi Electric Research Laboratories, Inc. All	acknowledgment index;analytic signal;bounding volume hierarchy;computation;computer-aided design;die (integrated circuit);display resolution;distance transform;euclidean distance;mathematical optimization;numerical partial differential equations;octree;requirement;simulation;stationary process	Alan Sullivan;Hüseyin Erdim;Ronald N. Perry;Sarah F. Frisken	2012	Computer-Aided Design	10.1016/j.cad.2012.02.002	combinatorics;mathematics;geometry;engineering drawing	Robotics	65.90223926030684	-42.94680076416919	57463
fcbcef071ad4c82d1ba37850606413237a9982ab	multi-dimensional average-interpolating refinement on arbitrary lattices	wavelet analysis;multidimensional dataset subdivision;sobolev method;scale function;interpolation;multi resolution analysis;lattices;application software;smooth scaling functions;signal analysis;biomedical imaging;charge coupled devices;polynomials;multidimensional average interpolating refinement;quincunx lattice;2d polynomial average interpolating subdivision;multi dimensional;smoothing methods;medical image;multidimensional signal processing;lattices signal processing algorithms polynomials multidimensional signal processing charge coupled devices wavelet analysis application software biomedical imaging signal analysis algorithm design and analysis;arbitrary dimension lattices;smooth function local averaging;signal processing algorithms;smoothing methods multidimensional signal processing interpolation;multiresolution analysis;algorithm design and analysis;sobolev method multidimensional average interpolating refinement arbitrary dimension lattices smooth scaling functions multiresolution analysis multidimensional dataset subdivision smooth function local averaging 2d polynomial average interpolating subdivision quincunx lattice	Multi-dimensional datasets containing local averages of a function arise in many applications such as processing of CCD captures and medical images. Motivated by this fact we introduce multi-dimensional average-interpolating refinement on arbitrary lattices in arbitrary dimensions. Our refinement algorithm results in smooth scaling functions of compact support. This method forms a basis for multi-dimensional multi-resolution analysis and subdivision on datasets obtained by locally averaging a smooth function. As an example, we present two-dimensional polynomial average-interpolating subdivision on the quincunx lattice and show that the resulting scaling functions are highly regular in the sense of Sobolev.	algorithm;charge-coupled device;distribution (mathematics);image scaling;interpolation;multiresolution analysis;polynomial;refinement (computing);subdivision surface;wavelet	Pouya Dehghani Tafti;Shahram Shirani;Xiaolin Wu	2005	Proceedings. (ICASSP '05). IEEE International Conference on Acoustics, Speech, and Signal Processing, 2005.	10.1109/ICASSP.2005.1416079	multidimensional signal processing;medical imaging;multiresolution analysis;wavelet;algorithm design;mathematical optimization;combinatorics;application software;discrete mathematics;interpolation;computer science;signal processing;lattice;mathematics;polynomial	Visualization	71.20743010218887	-44.593892917827375	57496
b0406558a73ea951d1fa18581b1535b2ded15348	a hybrid shape representation for free-form modelling (figures 7, 9, and 10)	free-form modelling;hybrid shape representation			Rémi Allègre;Aurélien Barbier;Eric Galin;Samir Akkouche	2004		10.1109/SMI.2004.10011	active shape model;geometry;shape analysis (digital geometry);mathematics	Vision	65.7378507426776	-43.66710026206888	57532
bace05e5038bbb1a1c934164a3a65cdde1bc49f2	a variable step-size normalized sign algorithm for acoustic echo cancelation	background noise;robust adaptive filter;double talk;convergence;sign algorithm echo canceler double talk robust adaptive filter variable step size;convergence stability steady state background noise speech change detection algorithms acoustical engineering computer errors acoustic signal detection noise robustness;near end signal;acoustic echo cancellation;acoustics;variable step size;normalized triple state sign algorithm;speech;acoustic signal processing;dual sign algorithm;convergence rate;noise measurement;stability;variable step size normalized sign algorithm;sign algorithm;double talk detection;posteriori error;stability acoustic noise acoustic signal processing convergence echo echo suppression;acoustic noise;stability variable step size normalized sign algorithm acoustic echo cancellation posteriori error background noise near end signal double talk detection dual sign algorithm normalized triple state sign algorithm convergence rate;echo;echo suppression;robustness;echo canceler;signal processing algorithms;adaptive filter;steady state	A variable step size normalized sign algorithm (VSS-NSA) is proposed, for acoustic echo cancelation, which adjusts its step size automatically by matching the L1 norm of the a posteriori error to that of the background noise plus near-end signal. Simulation results show that the new algorithm combined with double-talk detection outperforms the dual sign algorithm (DSA) and the normalized triple-state sign algorithm (NTSSA) in terms of convergence rate and stability.	acoustic cryptanalysis;algorithm;rate of convergence;simulation;t-norm;taxicab geometry	Tiange Shao;Yahong Rosa Zheng;Jacob Benesty	2010	2010 IEEE International Conference on Acoustics, Speech and Signal Processing	10.1109/ICASSP.2010.5495873	adaptive filter;speech recognition;convergence;stability;computer science;noise measurement;speech;noise;mathematics;background noise;rate of convergence;steady state;robustness	Robotics	82.71390768991982	-33.120663406289594	57561
7400a2a324b358f4ac5ab91f6ac3cfce08184285	a new approach to rapid image morphing for lip motion synthesis	animation system;motion synthesis;image metamorphosis;human subjects;image generation;morphing;facial animation;smooth transition;lip motion synthesis;optical flow;vector field;image warping	Animating a human face with visual speech in a way that is accurate enough to look natural and aid both conscious and subconscious lipreading is a major goal of animation systems. One method of creating such animations is to collect a set of images of a human subject speaking, then combine these images together in a manner simulating natural speech. Image morphing techniques can be used to create transitions between the static images. A range of morphing techniques have been used in this context, covering traditional techniques and methods that reflect the specific problem domain. In this paper I present a morphing technique that combines the image warping techniques of traditional field morphing with a rapid morphing method developed specifically for facial animation. This new technique avoids complex computation and difficulties involved in optical flow calculation as is used in other methods, and instead uses simple geometrical correspondence to create smooth transitions. This allows for simplicity and flexibility in calculation while preserving the speed of image generation. The technique assumes that the motion of pixels between the two images can be approximated by a vector field; this vector field can then be calculated and stored. New intermediate images can then be generated rapidly by morphing the images along the calculated vector flows.	morphing	Anna Buttfield	2003			computer vision;simulation;computer science;computer graphics (images)	Robotics	63.67879415643625	-47.13971411944983	57569
95cd2a0d6d6d2047e9de0b872b39220f83f2a3d7	optical-inertial tracking of an input device for real-time robot control	medical robotics optical inertial tracking real time robot control minimally invasive robotic surgery systems tracking algorithm handheld input device inertial measurements optical measurements robust state estimates error state extended kalman filter robustness partial device occlusions active optical markers 2d positions camera planes fusion process quality measure;cameras robots surgery kalman filters biomedical optical imaging optical devices acceleration;surgery image fusion kalman filters medical robotics nonlinear filters optical tracking position control real time systems robot vision robust control state estimation	Minimally invasive robotic surgery systems are usually controlled by input devices, that are mechanically linked to the environment. These input devices often have a limited workspace, which makes intuitive operation difficult. This paper presents a tracking algorithm of a handheld input device, which combines inertial and optical measurements to obtain accurate and robust state estimates with high update rates and low latency. It is based on the fusion of inertial and optical data in an error state extended Kalman filter. To achieve a high degree of robustness with respect to partial device occlusions, active optical markers are tracked and their 2D positions in the camera planes are directly forwarded to the fusion process. The algorithm can handle partial occlusions of the device in one or all of the cameras. A quality measure is defined, which indicates if tracking performance is sufficient to control a robot. An exemplary task in a medical robotics context verifies the assumption that the tracking system can be used for real-time robot control despite frequent marker occlusions.	algorithm;enigma machine;experiment;extended kalman filter;handheld game console;haptic technology;image noise;input device;multimodal interaction;output device;prospective search;real-time clock;requirement;robot control;robotics;sensor;tracking system;workspace	Florian Steidle;Andreas Tobergte;Alin Albu-Schäffer	2016	2016 IEEE International Conference on Robotics and Automation (ICRA)	10.1109/ICRA.2016.7487202	control engineering;computer vision;simulation;engineering	Robotics	57.944483260763015	-37.50433111750421	57605
7323b54b85f96432629ab2a717b0f545378b8bac	robust 3d object modeling with a low-cost rgbd-sensor and ar-markers for applications with untrained end-users	rgbd sensor;object modeling;graph slam;pose uncertainty;augmented reality ar marker	An approach for generating textured 3D models of objects without the need for complex infrastructure such as turn-tables or high-end sensors on precisely controlled rails is presented. The method is inexpensive as it uses only a low-cost RGBD sensor, e.g., Microsoft Kinect or ASUS Xtion, and Augmented Reality (AR) markers printed on paper sheets. The sensor can be moved by hand by an untrained person and the AR-markers can be arbitrarily placed in the scene, thus allowing themodeling of objects of a large range of sizes. Due to the use of the simple AR markers, the method is significantly more robust than just using the RGBD sensor or amonocular camera alone and it hence avoids the typical need formanual postprocessing of alternative approaches like Kinect-Fusion, 123D Catch, Photosynth, or similar. This article has two main contributions: First, the development of a simple, inexpensive method for the quick and easy digitization of physical objects is presented. Second, the development of an uncertainty model for AR-marker pose estimation is introduced. The latter is of interest beyond the object modeling application presented here. The uncertainty model is used in a graph-based relaxation method to improve modelconsistency. Realistic modeling of various objects, such as parcels, sport balls, coffee sacks, human dolls, etc., is experimentally demonstrated. Good model-accuracy is shown for several ground-truth objects with simple geometries and known dimensions. Furthermore, it is shown that the models obtained using the uncertainty model have fewer errors than the ones obtained without it. © 2015 Elsevier B.V. All rights reserved.	3d modeling;algorithm;augmented reality;experiment;ground truth;jt (visualization format);kinect;linear programming relaxation;microsoft photosynth;point cloud;printing;relaxation (approximation);relaxation (iterative method);robustness (computer science);sensor;simultaneous localization and mapping	Razvan-George Mihalyi;Kaustubh Pathak;Narunas Vaskevicius;Tobias Fromm;Andreas Birk	2015	Robotics and Autonomous Systems	10.1016/j.robot.2015.01.005	computer vision;simulation;object model;computer science;computer graphics (images)	Robotics	54.948328814015795	-46.463536829914084	57651
4457a49e657ba0b3dfbb71cb27efe37e53bb37c3	progressive streaming and massive rendering of 3d city models on web-based virtual globe	massive rendering;chunked lod;virtual globe;3d urban models;gis;progressive streaming;view dependent lod control	The need for the real-time interactive co-visualization of 3D urban environments on a Web-based virtual Globe arises naturally in GIS but it still remains challenging due to the complexity of city models and their huge data sizes which largely overload the computational power and memory capacity of client devices. Especially on the Web, the visualization of city models makes their rendering not real-time because of the lack of content adaptation and progressive data transmission. This paper presents technical solutions for the co-visualization of massive city models in a Web-based virtual globe, allowing navigation over 3D cities on the globe in real-time. The volume of 3D city data, such as building data, does not allow us to render them directly, nor to keep them in the main memory. We propose to use not only a hierarchical presentation of geo-spatial data to create a chunk-based multiple resolution data structure which reduces complexity of the geometry being rendered; but also a view dependent algorithm so that only small subsets of 3D city models are streamed progressively in real-time and kept in client memory to contribute efficiently to the rendered image. Experimental results show that we can navigate over 3D cities on the Globe in real-time.	3d city models;algorithm;computation;computer data storage;content adaptation;data structure;geographic information system;real-time clock;real-time transcription;real-time web;streaming media;virtual globe;web application;world wide web	Quoc-Dinh Nguyen;Mathieu Brédif;Didier Richard;Nicolas Paparoditis	2016		10.1145/2996913.2997008	simulation;geomatics;geography;multimedia;cartography;remote sensing;computer graphics (images)	Visualization	69.3043655239657	-51.9375028817136	57777
94a458e180fc860bc47dfa6a40f1d66a90b74ab6	cognitive radio sensing using hilbert huang transform	hilbert huang transform;empirical mode decomposition emd;cognitive radio;spectrum sensing;intrinsic mode function imf;ensemble empirical mode decomposition eemd;guard band;noise assisted data analysis nada	Vast segments of the frequency spectrum are reserved for primary (licensed ) users. These legacy users often under-utilize their reserved spectrum thus causing bandwidth waste. The unlicensed (secondary) users can take advantage of this fact and exploit the spectral holes (vacant spectrum segments). Since spectrum occupancy is transient in nature it is imperative that the spectral holes are identified as fast as possible. To accomplish this, we propose a novel adaptive spectrum sensing procedure. This procedure scans a wideband spectrum using Hilbert Huang Transform and detects the spectral holes present in the spectrum.	algorithmic efficiency;cognitive radio;computation;computational complexity theory;frequency band;hilbert–huang transform;imperative programming;legacy system;sensor;spectral density	K. A. Narayanankutty;Abhijith A. Nair;Dilip Soori;Deepak Pradeep;V. Ravi Teja;B. VishnuK.	2010	Wireless Engineering and Technology	10.4236/wet.2010.11006	cognitive radio;electronic engineering;speech recognition;telecommunications;computer science;engineering;hilbert–huang transform;hilbert spectral analysis;computer network	Mobile	81.39335073782566	-40.555842373891274	57853
92c0396bc0c86277e00ab11b9d468ffe6c5489d7	predicting high resolution image edges with a generic, adaptive, 3-d vehicle model	edge detection;learning artificial intelligence;predictive models;image resolution	In traffic surveillance applications a good prior model of vehicle shape and appearance is becoming increasingly more important for tracking, shape recovery, and recognition from video. The usefulness of 2-d vehicle models is limited to a fixed viewing direction; 3-d models are nearly always more suitable. Existing 3-d vehicle models are either generic but far too simple to utilize high resolution imagery, or far too complex and limited to specific vehicle instances. This paper presents a deformable vehicle model that spans these two extremes. The model is constructed with a multi-resolution approach to fit various image resolutions. At each resolution, a small number of parameters controls the deformation to accurately represent a wide variety of passenger vehicles. The parameters control both 3-d shape and appearance of parts that deform in the 2-d manifold of the vehicle surface. These parts are regions representing windows, headlights, taillights, etc. The combination of part boundaries and surface occluding contours account for the most consistent edges observed in images of vehicles. It is shown that the model parameters can be recovered by fitting the deformable model to real images of vehicles.	color;computer-aided design;consistency model;experiment;image resolution;microsoft windows;shading;specular highlight;statistical model;viewing cone	Matthew J. Leotta;Joseph L. Mundy	2009	2009 IEEE Conference on Computer Vision and Pattern Recognition	10.1109/CVPRW.2009.5206738	computer vision;simulation;edge detection;image resolution;computer science;computer graphics (images)	Vision	58.17536216019934	-46.236626348863666	58027
134f703011505f03c3454b436173d4e7d1ad10e8	skeleton based implicit surfaces for modeling, animation, and visualization			implicit surface	Hans-Christian Rodrian	1999				Visualization	66.02653518546478	-44.52955470227358	58031
6658649981b7862899e081b30398e8aa9cc29561	improving label placement quality by considering basemap detail with a raster-based approach	gis mapping;image segmentation;quality evaluation;automated label placement;automated cartography	Topographic maps are arguably one of the most information-dense, yet intuitively usable, graphical artifacts produced by mankind. Cartography as science and practice has developed and collected a wealth of design principles and techniques to cope with the problems of high graphical density, especially for the case of label placement. Many of the more sophisticated techniques that take into account figure-ground relationships for lettering have not been fully operationalized until now. We present a novel generic quality evaluation model that allows full automation of refined techniques for improving map feature overlap, visual contrast and layer hierarchy. We present the objective function as a set of metrics corresponding to the design principles and provide exemplary parameterization via the set of experiments on global real-world datasets. The approach designed for labeling of point-like objects and can potentially be applied to linear and areal features. It has a low computational and memory requirement. Furthermore, it is conceivably applicable to annotate any kind of visualization beyond maps. The results of the conducted tests and comparison with a commercial labeling package illustrate the ability to produce highly legible and readable map lettering with our approach. Presented method heeds more cartographic design principles and is computationally less costly compared to commercially available methods.	3d modeling;algorithm;apache axis;automatic label placement;cartography;central processing unit;clutter;color;computation;computational complexity theory;experiment;figure-ground in map design;graphical user interface;graphics processing unit;image segmentation;interference (communication);loss function;mathematical optimization;mobile device;optimization problem;parallel computing;pixel;raster graphics;real-time clock;resampling (statistics);server (computing);server-side;topography	Maxim A. Rylov;Andreas W. Reimer	2015	GeoInformatica	10.1007/s10707-014-0214-6	computer vision;computer science;data mining;database;image segmentation;cartography	HCI	66.02554757070111	-47.70631356390771	58067
7fc3d9957b92ea73727aadac1efde7b940ea67cb	rational pythagorean-hodograph space curves	fonction rationnelle;concepcion asistida;computer aided design;rational interpolation;ruled surface;envelope;hermite interpolation;ajustamiento curva;hodographe pythagorien;surface parametrique;interpolation hermite;pythagorean hodograph curves;superficie parametrica;geometrie constructive;polynomial interpolation;enveloppe;orientation;satisfiability;edge of regression;envoltura;interpolacion racional;interpolacion hermite;pythagorean hodograph;tangent developable;geometria constructiva;derivee;conception assistee;orientacion;ajustement courbe;surface developpable;developable surface;interpolacion polinomial;superficia desarrollable;rational frames;funcion racional;curve fitting;constructive geometry;hodografo pythagor;rational space curves;parametric surface;derivada;rational function;interpolation polynomiale;derivative;support function;interpolation rationnelle	A method for constructing rational Pythagorean-hodograph (PH) curves in R^3 is proposed, based on prescribing a field of rational unit tangent vectors. This tangent field, together with its first derivative, defines the orientation of the curve osculating planes. Augmenting this orientation information with a rational support function, that specifies the distance of each osculating plane from the origin, then completely defines a one-parameter family of osculating planes, whose envelope is a developable ruled surface. The rational PH space curve is identified as the edge of regression (or cuspidal edge) of this developable surface. Such curves have rational parametric speed, and also rational adapted frames that satisfy the same conditions as polynomial PH curves in order to be rotation-minimizing with respect to the tangent. The key properties of such rational PH space curves are derived and illustrated by examples, and simple algorithms for their practical construction by geometric Hermite interpolation are also proposed.		Rida T. Farouki;Zbynek Sír	2011	Computer Aided Geometric Design	10.1016/j.cagd.2011.01.002	support function;rational function;polynomial and rational function modeling;envelope;tangent vector;mathematical analysis;osculating curve;topology;developable surface;osculating circle;polynomial interpolation;derivative;hermite interpolation;ruled surface;computer aided design;parametric surface;rational motion;mathematics;geometry;orientation;tangential developable;rational point;curve fitting;algebra;satisfiability	Vision	68.50168925921537	-40.0354778693679	58071
31d037286f987094a9b06b97f481458198792cf8	interpolation over arbitrary topology meshes using a two-phase subdivision scheme	topology;computer aided design;interpolation;solid;computer graphics;algorithms computer graphics computer simulation computer aided design image interpretation computer assisted models theoretical signal processing computer assisted user computer interface;computational geometry;surface fitting;indexing terms;curve;and object representations;splines mathematics;computer graphic;tangent plane interpolation topology mesh two phase subdivision scheme catmull clark subdivision smooth surface construction computational complexity interactive free form shape design shape control control mesh;computational geometry mesh generation topology surface fitting interpolation computational complexity splines mathematics solid modelling;computational complexity;computer aided engineering;interpolation topology spline surface topography surface reconstruction shape control solid modeling computer graphics electrical equipment industry equations;computational geometry and object modeling;subdivision scheme;surface;shape control;linear equations;computer aided design computer graphics computational geometry and object modeling curve surface solid and object representations computer aided engineering;mesh generation;shape design;solid modelling	The construction of a smooth surface interpolating a mesh of arbitrary topological type is an important problem in many graphics applications. This paper presents a two-phase process, based on a topological modification of the control mesh and a subsequent Catmull-Clark subdivision, to construct a smooth surface that interpolates some or all of the vertices of a mesh with arbitrary topology. It is also possible to constrain the surface to have specified tangent planes at an arbitrary subset of the vertices to be interpolated. The method has the following features: 1) it is guaranteed to always work and the computation is numerically stable, 2) there is no need to solve a system of linear equations and the whole computation complexity is O(K) where K is the number of the vertices, and 3) each vertex can be associated with a scalar shape handle for local shape control. These features make interpolation using Catmull-Clark surfaces simple and, thus, make the new method itself suitable for interactive free-form shape design.	algorithm;algorithmic efficiency;anatomy, regional;catmull–clark subdivision surface;computation;computer-aided design;energy, physics;entity name part qualifier - adopted;exhibits as topic;experiment;fairness measure;graphics;interpolation imputation technique;iteration;iterative method;linear equation;linear system;non-uniform rational b-spline;numerical stability;polygon mesh;polyhedron;preprocessor;rule (guideline);solutions;subgroup;system of linear equations;tissue membrane;topological derivative;triangle mesh;two-phase commit protocol;two-phase locking;undulation of the geoid;vertex	Jianmin Zheng;Yiyu Cai	2006	IEEE Transactions on Visualization and Computer Graphics	10.1109/TVCG.2006.49	mesh generation;index term;computational geometry;interpolation;computer science;theoretical computer science;mathematics;geometry;curve;linear equation;solid;computer graphics;computational complexity theory;surface;subdivision surface	Visualization	69.80166266990513	-43.04395219514809	58247
1448f185e815d171327602a988e233d190c3f2df	modeling natural sounds with modulation cascade processes	time scale;ucl;discovery;theses;conference proceedings;digital web resources;time frequency representation;ucl discovery;open access;ucl library;book chapters;open access repository;auditory scene analysis;ucl research	Auditory scene analysis is extremely challenging. One approach, perhaps that adopted by the brain, is to shape useful representations of sounds on prior knowledge about their statistical structure. For example, sounds with harmonic sections are common and so time-frequency representations are efficient. Most current representations concentrate on the shorter components. Here, we propose representations for structures on longer time-scales, like the phonemes and sentences of speech. We decompose a sound into a product of processes, each with its own characteristic time-scale. This demodulation cascade relates to classical amplitude demodulation, but traditional algorithms fail to realise the representation fully. A new approach, probabilistic amplitude demodulation, is shown to out-perform the established methods, and to easily extend to representation of a full demodulation cascade.	algorithm;blind signal separation;fold (higher-order function);modulation;source separation	Richard E. Turner;Maneesh Sahani	2007			speech recognition;computer science;artificial intelligence;machine learning;time–frequency representation;auditory scene analysis	ML	80.31241193184911	-35.19654971793044	58263
b4e438e11c2a75e0b5c6454d27f3b89f732bb964	online serial manipulator calibration based on multisensory process via extended kalman and particle filters	position measurement calibration kalman filters manipulator kinematics nonlinear filters parameter estimation particle filtering numerical methods;robot kinematics kinematics robot sensing systems kalman filters particle filters;googol grb3016 robot online serial manipulator calibration multisensory process extended kalman filter particle filter online robot self calibration method inertial measurement unit imu position sensor position marker robot tool manipulator position estimation method manipulator orientation estimation method kf pose measurement accuracy improvement pose measurement reliability improvement kinematic parameter error estimation dynamic manufacturing environment	An online robot self-calibration method based on an inertial measurement unit (IMU) and a position sensor is presented in this paper. In this method, a position marker and an IMU are required to be rigidly attached to the robot tool to obtain the position of the manipulator from the position sensor and the orientation of the manipulator from the IMU in real time. An efficient approach that incorporates a Kalman filter (KF) and a particle filter to estimate the position and orientation of the manipulator is proposed in this paper. The use of these pose (orientation and position) estimation methods improves the reliability and accuracy of pose measurements. Finally, an extended KF is used to estimate the kinematic parameter errors. The primary advantage of this method over existing automated self-calibration methods is that it does not involve complex steps, such as camera calibration, corner detection, and laser alignment, which makes the proposed robot calibration procedure more autonomous in a dynamic manufacturing environment. Moreover, the reduction of complex steps improves the accuracy of calibration. Experimental studies on a GOOGOL GRB3016 robot show that the proposed method has better accuracy, convenience, and effectiveness.	algorithm;autonomous robot;corner detection;experiment;extended kalman filter;google videos;pf (firewall);particle filter;robot calibration;serial manipulator	Guanglong Du;Ping Zhang	2014	IEEE Transactions on Industrial Electronics	10.1109/TIE.2014.2314051	control engineering;computer vision;engineering;control theory;extended kalman filter;robot calibration	Robotics	57.24250642113583	-36.13226017626887	58272
88a15ec4fc7ae35b9290cfea7f9ae1449b70ea6d	three-dimensional polygonal building model estimation from single satellite images	shape estimation;3 d building reconstruction building detection height estimation satellite image processing;satellite image processing;time complexity;edge detection;three dimensional;fuzzy logic;polygonal rooftops three dimensional polygonal building model estimation single satellite images automatic detection height estimation polygonal shape roofs multiple flat polygonal buildings fuzzy logic based approach;buildings shape estimation image edge detection satellites image reconstruction solid modeling;shape;estimation;automatic detection;image edge detection;height estimation;image reconstruction;building reconstruction;satellites;solid modeling;3 d building reconstruction;satellite image;shape priors;building model;buildings;building detection;object detection;object detection fuzzy logic image reconstruction	This paper introduces a novel system for automatic detection and height estimation of buildings with polygonal shape roofs in singular satellite images. The system is capable of detecting multiple flat polygonal buildings with no angular constraints or shape priors. The proposed approach employs image primitives such as lines, and line intersections, and examines their relationships with each other using a graph-based search to establish a set of rooftop hypotheses. The height (mean height from rooftop edges to the ground) of each rooftop hypothesis is estimated using shadows and acquisition geometry. The potential ambiguities in identification of shadows in an image and the uncertainty in identifying true shadows of a building have motivated for a fuzzy logic-based approach that estimates buildings heights according to the strength of shadows and the overlap between identified shadows in the image and expected shadows according to the building profile. To reduce the time complexity of the implemented system, a maximum number of eight sides for polygonal rooftops is assumed. Promising experimental results verify the effectiveness of the presented system with overall mean shape accuracy of 94% and mean height error of 0.53 m on QuickBird satellite (0.6 m/pixel) imageries.	aerial photography;angularjs;computational complexity theory;fuzzy logic;ground truth;mean squared error;pixel;search algorithm;sensor;time complexity	Mohammad Izadi;Parvaneh Saeedi	2012	IEEE Transactions on Geoscience and Remote Sensing	10.1109/TGRS.2011.2172995	iterative reconstruction;fuzzy logic;time complexity;three-dimensional space;computer vision;estimation;edge detection;shape;mathematics;geometry;solid modeling;satellite;remote sensing	Vision	57.66919563365983	-45.65130914536697	58280
3a9ccbf83c143114e32f39511c858f053cfc94d6	1-point ransac for ekf-based structure from motion	visual odometry;bundle adjustment structure from motion techniques global optimization sliding window visual odometry image sequence slam methods extended kalman filter estimation errors 1 point ransac;1 point ransac;location estimation;prior information;motion estimation;data mining;estimation errors;visualization;robot vision;trajectory;estimation;slam robots image sequences robot vision;global positioning system;structure from motion techniques;robots;image sequence;global optimization;ground truth;estimation error;extended kalman filter;branch and bound;slam robots;structure from motion;inertial sensor;cameras;sliding window;slam methods;bundle adjustment;image sequences;image sequences cameras motion estimation filters recursive estimation image sensors wheels simultaneous localization and mapping global positioning system estimation error	Recently, classical pairwise Structure From Motion (SfM) techniques have been combined with non-linear global optimization (Bundle Adjustment, BA) over a sliding window to recursively provide camera pose and feature location estimation from long image sequences. Normally called Visual Odometry, these algorithms are nowadays able to estimate with impressive accuracy trajectories of hundreds of meters; either from an image sequence (usually stereo) as the only input, or combining visual and propioceptive information from inertial sensors or wheel odometry.	algorithm;bundle adjustment;business architecture;extended kalman filter;global optimization;mathematical optimization;nonlinear system;random sample consensus;recursion;sensor;structure from motion;visual odometry	Javier Civera;Oscar G. Grasa;Andrew J. Davison;J. M. M. Montiel	2009	2009 IEEE/RSJ International Conference on Intelligent Robots and Systems	10.1109/IROS.2009.5354410	robot;sliding window protocol;computer vision;estimation;structure from motion;simulation;visualization;global positioning system;ground truth;computer science;visual odometry;trajectory;motion estimation;odometry;control theory;extended kalman filter;bundle adjustment;branch and bound;global optimization	Robotics	54.21675566469767	-39.75085113796076	58285
ae482c36838aba15c642ea56e2a2d58d5fa8b26e	interproximation using cubic b-spline curves		An algorithm for the construction of a non-uniform cubic B-spline curve that interpolates a set of 2D data { D i } is presented. Each D i is either a point or a region. If D i is a point, the curve interpolates it. Otherwise, the curve passes through the region specified by D i The curve is constructed based on minimizing the energy of each of its components. The parametric knots of the curve are parametrized using the centripetal model. These processes facilitate the geometric smoothness and fairness of the curve. The new technique allows a user to design a curve with more flexibility and fewer trial-and-error iterations than conventional approach. This work is a continuation of the paper “Interproximation: Interpolation and Approximation Using Cubic Spline Curves” published in 1991.	b-spline;cubic hermite spline;cubic function;spline (mathematics)	Fuhua Cheng;Brian A. Barsky	1993		10.1007/978-3-642-78114-8_22	tschirnhausen cubic	Vision	69.49979463397759	-41.134628539504625	58373
c8985aebc3536c1e0e6d90a40d5438df33feb0df	vocal activity informed singing voice separation with the ikala dataset	information services;informed source separation low rank and sparse decomposition singing voice separation;internet;speech processing principal component analysis;electronic publishing;mir ik dataset vocal activity informed singing voice separation ikala dataset robust principal component analysis predefined sparsity pattern;information services electronic publishing internet harmonic analysis matlab;matlab;harmonic analysis	A new algorithm is proposed for robust principal component analysis with predefined sparsity patterns. The algorithm is then applied to separate the singing voice from the instrumental accompaniment using vocal activity information. To evaluate its performance, we construct a new publicly available iKala dataset that features longer durations and higher quality than the existing MIR-1K dataset for singing voice separation. Part of it will be used in the MIREX Singing Voice Separation task. Experimental results on both the MIR-1K dataset and the new iKala dataset confirmed that the more informed the algorithm is, the better the separation results are.	algorithm;robust principal component analysis;sparse matrix	Tak-Shing Chan;Tzu-Chun Yeh;Zhe-Cheng Fan;Hung-Wei Chen;Li Su;Yi-Hsuan Yang;Jyh-Shing Roger Jang	2015	2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	10.1109/ICASSP.2015.7178063	the internet;speech recognition;computer science;harmonic analysis;mathematics;electronic publishing;information system	Visualization	82.43262534563951	-36.65447106571703	58401
5ef52908ff4600a2905c3b7a1b0bec8969a8bb7b	multiple view geometry for non-rigid motions viewed from translational cameras	space time;image sequence;multiple view geometry	This paper introduces multiple view geometry under projective projections from four-dimensional space to two-dimensional space which can represent multiple view geometry under the projection of space with time. We show the multifocal tensors defined under space-time projective projections can be derived from non-rigid object motions viewed from multiple cameras with arbitrary translational motions, and they are practical for generating images of non-rigid object motions viewed from cameras with arbitrary translational motions. The method is tested in real image sequences.		Cheng Wan;Kazuki Kozuka;Jun Sato	2007		10.1007/978-3-540-76390-1_34	computer vision;topology;space time;mathematics;geometry	Vision	53.88713370857725	-50.90940436982874	58424
a2be1d5d4a0e7706f3d4470a2a4529db07f5e726	a new meccanotechnique for adaptive 3-d triangulations		This paper introduces a new automatic strategy for adaptive tetrahedral mesh generation. A local refinement/derefinement algorithm for nested triangula-tions and a simultaneous untangling and smoothing procedure are the main involved techniques. The mesh generator is applied to 3-D complex domains whose boundaries are projectable on external faces of a coarse object meccano composed of cuboid pieces. The domain surfaces must be given by a mapping between meccano surfaces and object boundary. This mapping can be defined by analytical or discrete functions. At present we have fixed mappings with orthogonal , cylindrical and radial projections, but any other one-to-one projection may be considered. The mesh generator starts from a coarse tetrahedral mesh which is automatically obtained by the subdivision of each hexahedra, of a meccano hexahedral mesh, into six tetrahedra. The main idea is to construct a sequence of nested meshes by refining only those tetrahedra which have a face on the meccano boundary. The virtual projection of meccano external faces defines a valid triangulation on the domain boundary. Then a 3-D local refinement/derefinement is carried out such that the approximation of domain surfaces verifies a given precision. Once this objective is reached, those nodes placed on the meccano boundary are really projected on their corresponding true boundary, and inner nodes are relocated using a suitable mapping. As the mesh topology is kept during node movement, poor quality or even inverted elements could appear in the resulting mesh. For this reason, we finally apply a mesh optimization procedure. The efficiency of the proposed technique is shown with several applications to complex objects.	algorithm;algorithmic efficiency;approximation;code;computer-aided design;cuboid;domain-specific language;hexahedron;mathematical optimization;mesh generation;mesh networking;olap cube;one-to-one (data model);radial (radio);refinement (computing);smoothing;subdivision surface	José Manuel Cascón;Rafael Montenegro;José María Escobar;Eduardo Rodríguez;Gustavo Montero	2007				Graphics	68.68223391869316	-43.26471880261995	58550
0072916063a19e9fa6ec43aa8286e00b5f7bc9a0	homotopy-based controller for physical human-robot interaction	time varying;human interaction;robotic platform;leader role;human human interaction;collaboration;time varying systems;homotopy based controller;follower role;human robot interaction;force;acceleration;human robot interaction collaborative work communication system control switches impedance international collaboration usability force control control systems manipulator dynamics;cooperative systems;lead;robots;multi robot systems;dyadic collaborative tasks;robotic platform homotopy based controller physical human robot interaction dyadic collaborative tasks leader role follower role human human interaction;humans;switches;physical human robot interaction;physical interaction;time varying systems cooperative systems human robot interaction multi robot systems	This paper presents a model that describes physical interactions during dyadic collaborative tasks. This model is based on a homotopy between two controllers and defines the behavior of each partner as the result of a time-varying balance between two roles: the leader role, which consists in acting according to a plan without considering the other partner's intentions; and the follower role, which conversely consists in acting only based on the intentions of the other partner. The continuous switch between these two attitudes is described by two variables whose time-profile can define a task signature. After a brief presentation of the model, two illustrative scenarios are detailed to give more insights on how the homotopy parameter can be used to describe different situations that can occur in collaborative tasks between two partners. We especially focus on how some recent results in the human-human interaction can be encompassed by our proposed model. Experiments are performed to assess the usability of the model as a control scheme to implement advanced collaborative behaviors on a robotic platform.	dyadic transformation;experiment;fundamental interaction;humanoid robotics project;humanoid robot;human–robot interaction;network switch;partial template specialization;race condition;robot;usability	Paul Evrard;Abderrahmane Kheddar	2009	RO-MAN 2009 - The 18th IEEE International Symposium on Robot and Human Interactive Communication	10.1109/ROMAN.2009.5326065	acceleration;human–robot interaction;robot;lead;interpersonal relationship;simulation;network switch;computer science;artificial intelligence;force;collaboration	Robotics	61.38002276429651	-26.58267160109731	58558
22fab099f0c1912ef1877828c1ae0945fbd85b69	animal and robotic locomotion on wet granular media		Most of the terrestrial environments are covered with some type of flowing ground; however, inadequate understanding of moving bodies interacting with complex granular substrates has hindered the development of terrestrial/all-terrain robots. Although there has been recent performance of experimental and computational studies of dry granular media, wet granular media remain largely unexplored. In particular, this encompasses animal locomotion analysis, robotic system performance, and the physics of granular media at different saturation levels. Given that the presence of liquid in granular media alters its properties significantly, it is advantageous to evaluate the locomotion of animals inhabiting semi-aquatic and tropical environments to learn more about effective locomotion strategies on such terrains. Lizards are versatile and highly agile animals. Therefore, this study evaluated the brown basilisk, which is a lizard species from such habitats that are known for their performance on wet granular media. An extensive locomotion study was performed on this species. The animal experiments showed that on higher saturation levels, velocity of the animal was increased due to an increase in the stride length. A basilisk-inspired robot was then developed to further study the locomotion on wet granular media and it was observed that the robot can also achieve higher velocities at increased saturation levels. This work can pave the way for developing robotic systems which can explore complex environments for scientific discovery, planetary exploration, or search-and-rescue missions.	agile software development;aquatic ecosystem;computation;experiment;habitat;interaction;planetary scanner;robot;semiconductor industry;terrestrial television;velocity (software development)	Hosain Bagheri;Vishwarath Taduru;Sachin Panchal;Shawn White;Hamidreza Marvi	2017		10.1007/978-3-319-63537-8_2	simulation;saturation (chemistry);biological system;animal locomotion	Robotics	75.58073911803332	-24.039092144483224	58644
39b0d99df50a28449727e0044498047a81cd226a	asynchronous multi-sensor fusion for 3d mapping and localization		In this paper, we address the problem of optimally fusing multiple heterogeneous and asynchronous sensors for use in 3D mapping and localization of autonomous vehicles. To this end, based on the factor graph-based optimization framework, we design a modular sensor-fusion system that allows for efficient and accurate incorporation of multiple navigation sensors operating at different sampling rates. In particular, we develop a general method of out-of-sequence (asynchronous) measurement alignment to incorporate heterogeneous sensors into a factor graph for mapping and localization in 3D, without requiring the addition of new graph nodes, thus allowing the graph to have an overall reduced complexity. The proposed sensor-fusion system is validated on a real-world experimental dataset, in which the asynchronous-measurement alignment is shown to have an improved performance when compared to a naive approach without alignment.	autonomous robot;factor graph;internationalization and localization;mathematical optimization;sampling (signal processing);sensor	Patrick Geneva;Kevin Eckenhoff;Guoquan Huang	2018	2018 IEEE International Conference on Robotics and Automation (ICRA)	10.1109/ICRA.2018.8460204	control engineering;factor graph;sampling (statistics);modular design;asynchronous communication;sensor fusion;engineering;graph;distributed computing	Robotics	54.53597820403676	-35.67275478678258	58737
2102ee8807cbfdde164e846f86410677b7ebd7f3	precise position/force hybrid control with modal mass decoupling and bilateral communication between different structures	communication system;grasping;haptic communication dynamic behavior;bilateral control;cooperative robotics;surgery acceleration control actuators force control haptic interfaces jacobian matrices medical robotics position control robot dynamics;hybrid control;actuators;force;acceleration;medical robotics;hybrid control system;cardiac surgery;position control;dynamics;force robots actuators dynamics grasping acceleration;haptic communication system;tactile sensation;robots;modal mass decoupling;acceleration control;surgery;position force hybrid control;haptic interfaces;robot dynamics;kinetics;cardiac surgery haptic communication system modal mass decoupling position control force control cooperating robots tactile sensation actuators haptic communication kinetic behavior haptic communication dynamic behavior;jacobian matrices;haptic communication kinetic behavior;cooperating robots;dynamic behavior;force control;dynamics bilateral control position force hybrid control acceleration control	In this study, we achieve haptic communication between different structures. In haptic communication, tactile sensation is transmitted to a remote place by cooperating robots. Conventional haptic communication is implemented under the assumption that the masses of the actuators are equal. We have found that haptic communication system is a kind of position/force hybrid control system and that it is not necessary to follow that assumption. In addition, exact modeling of haptic communication system and decoupling of tasks are essential for highly precise haptic communication. First, we describe the kinetic and dynamic behaviors of haptic communication system for cardiac surgery. The deterioration of haptic performance is shown to depend on an interference term, due to off-diagonal parameters in the modal mass matrix. Second, we propose a novel hybrid controller for the decoupling of the responses, and we analyze its performance, stability, and robustness. Simulations and experiments toward cardiac surgery are shown, and the effectiveness of the proposed method is verified.	bilateral filter;computer simulation;control system;coupling (computer programming);experiment;haptic technology;interference (communication);mass matrix;modal logic;robot;robustness (computer science)	Sho Sakaino;Tomoya Sato;Kouhei Ohnishi	2011	IEEE Transactions on Industrial Informatics	10.1109/TII.2011.2121077	acceleration;robot;control engineering;dynamics;simulation;engineering;control theory;force;communications system;kinetics;actuator	Robotics	69.58760110379295	-24.37294354886164	58749
c88a506707962070649bc965a82be317014f7f79	ground experiment system of reconfigurable robot satellites	degree of freedom;self adjusting systems;ground support systems;manipulator dynamics;two degree of freedom;space robotics;aerospace robotics;manipulator dynamics aerospace robotics ground support systems self adjusting systems end effectors;extra vehicular activity;satellites robot kinematics orbital robotics space technology arm robot sensing systems testing manipulators costs aerospace engineering;reconfigurable end effectors ground experiment system reconfigurable robot satellite inorbit servicing mission extra vehicular activities multiple satellites reconfigurable arms reconfigurable brachiating space robot;end effectors	Future in-orbit servicing missions will include capturing, inspecting and repairing damaged satellites, constructing large space structures, and supporting EVA (extra vehicular activities) of astronauts. In order to conduct the above missions, we have proposed a system of reconfigurable robot satellite clusters. The system consists of multiple satellites with reconfigurable arms. Utilizing its reconfigurability and mobility, the system can perform the tasks as well as far-site installation of a reconfigurable arm for constructing and inspecting structures. In order to investigate the proposed system, we construct a ground experiment system consisting two configurable arm models, three floating satellite simulators with gas-thrusters and a ground station. One arm is a reconfigurables brachiating space robot, RBR we have developed and the other is a newly developed one that consists of two parts; an arm part of 5 degrees of freedom with two reconfigurable end-effectors and a pivot; a docking part with two degrees of freedom. In the paper, we introduce the experimental system and the reconfigurable arms and show the results of functional and demonstration experiments using the system.	robot	Saburo Matunaga;Ryuichi Hodoshima;Hideto Okada;Naoki Miyashita;Nobumasa Yamaguchi	2002		10.1109/ICARCV.2002.1234790	control engineering;embedded system;robot end effector;simulation;computer science;engineering;artificial intelligence;arm solution;machine learning;extra-vehicular activity;degrees of freedom;statistics	Robotics	63.640119567622	-28.473931005025513	58789
013bc6d47ae1703085a29ddc0e7c51da44dc1003	trivariate solid t-spline construction from boundary triangulations with arbitrary genus topology	polycube;arbitrary genus topology;isogeometric analysis;trivariate solid t spline	A comprehensive scheme is described to construct rational trivariate solid T-splines from boundary triangulations with arbitrary topology. To extract the topology of the input geometry, we first compute a smooth harmonic scalar field defined over the mesh, and saddle points are extracted to determine the topology. By dealing with the saddle points, a polycube whose topology is equivalent to the input geometry is built, and it serves as the parametric domain for the trivariate T-spline. A polycube mapping is then used to build a one-to-one correspondence between the input triangulation and the polycube boundary. After that, we choose the deformed octree subdivision of the polycube as the initial T-mesh, and make it valid through pillowing, quality improvement and applying templates to handle extraordinary nodes and partial extraordinary nodes. The T-spline that is obtained is C2-continuous everywhere over the boundary surface except for the local region surrounding polycube corner nodes. The efficiency and robustness of the presented technique are demonstrated with several applications in isogeometric analysis. © 2012 Elsevier Ltd. All rights reserved.	algorithm;isogeometric analysis;octree;one-to-one (data model);periodic boundary conditions;spline (mathematics);subdivision surface;t-spline	Wenyan Wang;Yongjie Zhang;Lei Liu;Thomas J. R. Hughes	2013	Computer-Aided Design	10.1016/j.cad.2012.10.018	combinatorics;topology;mathematics;geometry	Graphics	68.88788002690472	-42.470340950078196	58824
791429f84c71b3389ead69914e528a91cabdf807	evaluation framework for passive assistive device based on humanoid experiments		"""This study presents an enhanced framework for evaluating an assistive e®ect generated by a passive assistive device using a humanoid robot. The humanoid robotic experiments can evaluate wearable devices by measuring the joint torque, which cannot be measured directly from the human body. In this paper, we introduce an \assistive torque estimation map"""" as an e±cient means for estimating the supportive torque within the range of motions by interpolating the measured joint torques and joint angles of the robot. This map aims to estimate the supportive torques for complex motions without conducting humanoid experiments or human-subject experiments with these motions. We generated an estimation map for an actual assistive suit that decreases the load on the lumbar region and we veri ̄ed the validity of the proposed method by experimentation. In addition, the geometric simulation model of the assistive suit was validated based on the proposed experiments by using the humanoid robot HRP-4. The proposed framework is expected to lead to an e±cient design of such assistive devices so that fewer human-subject experiments need to be conducted."""	assistive technology;experiment;humanoid robot;interpolation;simulation;wearable technology	Yumeko Imamura;Ko Ayusawa;Eiichi Yoshida;Takayuki Tanaka	2018	I. J. Humanoid Robotics	10.1142/S0219843617500268	simulation;wearable technology;humanoid robot;artificial intelligence;computer vision;computer science;robot;torque;assistive suit	Robotics	71.6349808946441	-28.285492555144014	58825
db12e02a884cf90c962165208710632cafe4d4dc	assembly model data in robot cell systems	intelligent manufacturing systems;laser ranging;data format;product model;robotic assembly assembly systems product development product design design automation production manufacturing data mining robotics and automation concurrent engineering;laser range finder assembly model data intelligent manufacturing system autonomous assembly robot cell product development process 3d cad data driven assembly robot cell system virtual environment hand eye system;robot vision;laser range finder;assembling;cad cam;industrial robots;product development process;laser ranging product development cad cam assembling industrial robots robot vision;virtual environment;product development	Describes the intelligent manufacturing system (IMS) program progress in the autonomous assembly robot cell research. We focus on the information which is generated by the designers during the product development process. From the assembly process viewpoint, this information is extracted and integrated into the product model as an assembly model. This information is called assembly model data (AMD). Therefore, the main purpose of our research is to investigate the utility of AMD and the best format for these data in the assembly process. To solve the assembly problem, a 3D CAD data driven assembly robot cell (ARC) system was proposed. Robot task programs for the assembly process are generated automatically from 3D CAD data and AMD with this system in the virtual environment. The system can show the designers visually the difficult parts of an assembly. ARC with only products' CAD data and AMD can then assemble actual products in the real environment using a hand eye system equipped with a laser range finder. The products' CAD data and AMD are supplied to each ARC through a network. The data format was evaluated through loading actual AMD in the ARC system.	robot	Satori Kojima;Peter Kerites;Takunori Hayashi;Hideki Hashimoto	1998		10.1109/IROS.1998.724693	embedded system;assembly modelling;simulation;computer science;engineering;new product development;manufacturing engineering	Robotics	64.01106811421545	-30.597998764147746	58862
6e17118753423e6a9130f5624ecc6e7473171864	anisotropic matcap: easy capture and reproduction of anisotropic materials		We propose Anisotropic MatCap, a simple data structure based on a small volumetric texture that is able to represent, under a fixed lighting, the behavior of anisotropic materials. The data structure is designed to allow fast and practical capture of real-world anisotropic materials (like for example fabrics) and to be used in real-time renderings, requiring only negligible time and texture memory overheads. The resulting technique is suited for application scenarios where digital objects must be inspected by an end user, recreating the look of an object made of a captured anisotropic material and seen under the predetermined lighting conditions. The technique proved particularly useful for garments and cloth visualization and design.	anisotropic diffusion;data structure;real-time clock;texture memory	Dario Magri;Paolo Cignoni;Marco Tarini	2016		10.2312/stag.20161366	computer vision;image-based modeling and rendering;3d rendering;rendering;rendering equation;multimedia;anisotropic filtering;computer graphics (images)	Graphics	64.6557345463336	-50.743753607999935	58885
4a185e6093c53fa0e4d61fb17eddafc9554b3f49	implementation of wide-field integration of optic flow for autonomous quadrotor navigation	size weight and power;information extraction;visual navigation;wide field integration;autonomous;vision based control;optical flow;micro air vehicle;optic flow	Insects are capable of robust visual navigation in complex environments using efficient information extraction and processing approaches. This paper presents an implementation of insect inspired visual navigation that uses spatial decompositions of the instantaneous optic flow to extract local proximity information. The approach is demonstrated in a corridor environment on an autonomous quadrotor micro-air-vehicle (MAV) where all the sensing and processing, including altitude, attitude, and outer loop control is performed on-board. The resulting methodology has the advantages of computation speed and simplicity, hence are consistent with the stringent size, weight, and power requirements of MAVs.	optical flow	Joseph K. Conroy;Gregory Gremillion;Badri Ranganathan;James Sean Humbert	2009	Auton. Robots	10.1007/s10514-009-9140-0	computer vision;simulation;computer science;optical flow;information extraction	Robotics	55.873677289379806	-32.66682485561983	58914
5a8800f0f2e4d1be2ae4494aae8786d0e49ad1ed	three-dimensional kinematic modeling of helix-forming lamina-emergent soft smart actuators based on electroactive polymers	soft robotics 3 d kinematic modeling electroactive polymer eap actuators lamina emergent mechanism soft and smart actuators;actuators kinematics polymers shape spirals robot sensing systems	Robotic systems consisting of rigid elements connected to each other with single degree of freedom joints have been studied extensively. Robotic systems made of soft and smart materials are expected to provide a high dexterity and adaptability to their physical environment, like their biological counterparts. Electroactive polymer (EAP) actuators, also known as artificial muscles, which can operate both in wet and in dry environments with their promising features such as a low foot-print in activation and energy consumption, suitability to miniaturization, noiseless, and fully compliant operation can be employed to articulate a soft robotic system. This paper reports on kinematic modeling of a polypyrrole-based EAP actuator which is designed and fabricated to form helical configurations in 3-D from its initially spiral 2-D configuration. Denavit–Hartenberg transformations are combined with the backbone model of the actuator to establish the kinematic model. A parametric model has then been incorporated into the kinematic model to accurately estimate the helical configurations of the EAP actuator as a function of time under an electrical input. Experimental and simulation results, which are in good correlation, suggest that the proposed modeling approach is effective enough to estimate the 3-D helical configurations of the EAP actuator.	camera phone;displacement mapping;electroactive polymers;emergence;experiment;internet backbone;lamina emergent mechanism;mathematical model;mobile phone;parametric model;polymer;real-time computing;robot;simulation;spiral model;torsion (gastropod)	Rahim Mutlu;Gursel Alici;Weihua Li	2017	IEEE Transactions on Systems, Man, and Cybernetics: Systems	10.1109/TSMC.2016.2523940	artificial muscle;parametric model;degrees of freedom (statistics);control theory;electroactive polymers;miniaturization;actuator;computer science;smart material;kinematics	Robotics	73.66806790312714	-24.167668826391093	58918
a5a6e1a2c3ba3b329f397e92ce87d45ec10becb3	dense shape correspondences using spectral high-order graph matching	databases;graph theory;assignment problem;optimisation;np hard assignment problem;tensile stress;linear assignment problem;spectral decomposition;3d objects;computational geometry;psi_mic;np hard assignment problem dense shape correspondences graph matching point correspondences object instances 3d objects spectral decomposition transforms;graph matching;three dimensional;higher order;symmetric matrices;shape;matrix decomposition;computational complexity;three dimensional displays;shape matching;tensile stress shape matrix decomposition face three dimensional displays symmetric matrices databases;structure preservation;face;optimisation computational geometry graph theory;object instances;missing data;dense shape correspondences;point correspondences;spectral decomposition transforms	This paper addresses the problem of establishing point correspondences between two object instances using spectral high-order graph matching. Therefore, 3D objects are intrinsically represented by weighted high-order adjacency tensors. These are, depending on the weighting scheme, invariant for structure-preserving, equi-areal, conformal or volume-preserving object deformations. Higher-order spectral decomposition transforms the NP-hard assignment problem into a linear assignment problem by canonical embedding. This allows to extract dense correspondence information with reasonable computational complexity, making the method faster than any other previously published method imposing higher-order constraints to shape matching. Robustness against missing data and resampling is measured and compared with a baseline spectral graph matching method.	adjacency matrix;assignment problem;baseline (configuration management);computational complexity theory;connectivity (graph theory);database;instance (computer science);matching (graph theory);measure-preserving dynamical system;missing data;np-hardness;oasis tosca;singular value decomposition;spectral method	Dirk Smeets;Jeroen Hermans;Dirk Vandermeulen;Paul Suetens	2011	CVPR 2011 WORKSHOPS	10.1109/CVPRW.2011.5981675	graph energy;mathematical optimization;combinatorics;discrete mathematics;computational geometry;graph theory;3-dimensional matching;mathematics;geometry;assignment problem;matrix decomposition	Vision	61.15825693091169	-41.92940739398649	58924
711f827b2d3fd845d2c22b187d389a04cf67a5f7	optimal mission planning for underwater environment	euclidean distance optimal mission planning underwater environment mission planning method autonomous underwater vehicle optimal mission scheduling traveling salesman problem genetic algorithm;path planning;travelling salesman problems autonomous underwater vehicles genetic algorithms optimal control path planning;optimal control;cost function mission planner traveling salesman problem genetic algorithm;autonomous underwater vehicles;travelling salesman problems;genetic algorithms;cost function genetic algorithms euclidean distance vectors traveling salesman problems planning robots	In this paper, we suggest the mission planning method for autonomous underwater vehicle. In order to set the optimal mission scheduling, we solve the traveling salesman problem using genetic algorithm, and we suggest the cost function which considering both Euclidean distance and current information. In additionally, constraints such as priority and obstacles is considered. By checking the simulation, we achieved the valuable simulation results.	autonomous robot;euclidean distance;genetic algorithm;loss function;scheduling (computing);simulation;travelling salesman problem	Daegil Park;Jonghui Han;Wan Kyun Chung	2013	2013 10th International Conference on Ubiquitous Robots and Ambient Intelligence (URAI)	10.1109/URAI.2013.6677395	2-opt;mathematical optimization;simulation;genetic algorithm;optimal control;computer science;artificial intelligence;machine learning;motion planning;3-opt;bottleneck traveling salesman problem	Robotics	54.80731822082264	-24.841684519252727	58930
95d2cb8cdafd6dced2112ec2f4892d0e92fc25b8	on the value of collaboration in anchorless robot self-localization	least mean squares methods;bayes methods;mobile robots;collaboration standards robot sensing systems bayesian methods geometry approximation methods;mobile robots anchorless robot self localization location estimation interrobot collaboration estimator confidence measure minimum mean squares error estimation collaborative position location;mobile robots bayes methods least mean squares methods;minimum mean square error mmse estimation collaborative position location self localization tracking sampling importance resampling sir filter particle filtering	In this paper, we consider the value of collaboration in anchorless robot self-localization. Robots which rely solely on data from imperfect inertial measurement units become increasingly less certain of their locations over time. Without anchors or landmarks to help them regain their bearings, these robots reach a point at which they essentially have no idea of their locations. If, however, these robots are given the ability to communicate with one another, they can utilize additional information gained through collaboration to correct their beliefs and collectively improve their location estimates. In this work, we characterize how inter-robot collaboration impacts self-localization performance and discuss whether any additional information, such as an estimator confidence measure, may be gleaned from the resulting corrected beliefs.	html element;robot	Javier Schloemann;R. Michael Buehrer	2012	MILCOM 2012 - 2012 IEEE Military Communications Conference	10.1109/MILCOM.2012.6415822	simulation;engineering;machine learning;statistics	Robotics	55.000779466992086	-34.622137072599415	58957
f5c2705bdd6adb521e9a7384926c13ddc9206e64	fixture-based industrial robot calibration for silicon wafer handling	contraste;semiconducteur;repetabilite;design criteria;prensor robot;repetibilidad;bridage;robotics;satisfiability;semiconductor material;apriete;statistical model;robot industriel;prehenseur;porte piece;portapieza;systeme incertain;semiconductor materials;silicon wafer;materials handling;industrial robots;robot industrial;modele statistique;clamping;robotica;etalonnage;modelo estadistico;robotique;gripper;sistema incierto;semiconductors;uncertain system;calibration;work holder;repeatability;semiconductor manufacturing;industrial robot;design methodology;manutention materiau	1 This work was supported in part by Adept Technology, Inc. and 2000 California State MICRO Grant 00-032. 4 Sr. automation engineer, TMG, Intel Corp., 2501 NW 229 Street, Hillsboro, OR 97124. Former postdoctoral researcher in ALPHA Lab. Abstract Semiconductor manufacturing industry requires highly accurate robot operation with short downtime. We develop a fast, low cost and easy-to-operate calibration system for wafer-handling robots. The system is defined by a fixture and a simple compensation algorithm. Given robot repeatability, endeffector uncertainties, and the tolerance requirements of wafer placement points, we derive fixture design and placement specifications based on (1) worst-case and (2) statistical tolerance models. We verify our resultant design by physical experiments in a factory-floor environment.	algorithm;best, worst and average case;downtime;experiment;industrial robot;microsoft forefront threat management gateway 2010;netware;romp;repeatability;requirement;resultant;robot calibration;semiconductor;systems engineering;test fixture;wafer (electronics)	Mike Tao Zhang;Kenneth Y. Goldberg	2005	Industrial Robot	10.1108/01439910510573282	control engineering;statistical model;repeatability;calibration;design methods;clamping;engineering;semiconductor;robotics;semiconductor device fabrication;engineering drawing;wafer;manufacturing engineering;robot calibration;satisfiability	Robotics	64.83383856890597	-33.038845823346605	58963
2201be25e01aca7b2c188a924abfcf71beebf53e	a spectral multi-resolution image encoding network	multirate system;quantization;neural nets transform coding image coding;image coding;filter bank;neural networks;neural nets;whitening filter;transform coding;optimal localized basis functions;multi resolution encoding;image coding filter bank frequency sampling methods transform coding low pass filters quantization principal component analysis neural networks encoding;principal component analysis;network model;multi resolution encoding spectral multi resolution image encoding network multirate systems multiscale signal coding neural network network model optimal localized basis functions whitening filter;low pass filters;multirate systems;spectral multi resolution image encoding network;sampling methods;multi resolution;frequency;encoding;multiscale signal coding;neural network	After a short introduction into traditional image transform coding, multirate systems and multiscale signal coding the paper focuses on the subject of image encoding by a neural network. Taking also noise into account a network model is proposed which not only learns the optimal localized basis functions for the transform but also learns to implement a whitening filter by multi-resolution encoding. A simulation showing the multi-resolution capabilitys concludes the contribution.	adaptive algorithm;artificial neural network;basis function;decorrelation;line code;network model;nonuniform sampling;sampling (signal processing);simulation;transform coding;whitening transformation	Rüdiger W. Brause;Jürgen Glitsch	1995		10.1109/TAI.1995.479416	sampling;computer vision;transform coding;quantization;low-pass filter;computer science;network model;machine learning;frequency;filter bank;artificial neural network;encoding;principal component analysis	Vision	75.50406931922689	-41.3556844981257	58986
44f97844eb132d985bef7fb1416ed47aba34b146	hip-knee control for gait assistance with powered knee orthosis	knee hip joints testing torque legged locomotion emulation;orthosis;orthotics;gait;polynomials;polynomials gait analysis orthotics;heel condition hip knee control algorithm gait assistance powered knee orthosis disordered gait patients elderly normal walking pko performance system complexity kinematic gait model knee joint angle hip joint angle polynomial model embedded controller realtime control control method inertia measurement unit footswitch;gait analysis;elderly people;knee joint;article	A Powered Knee Orthosis (PKO) was developed for the elderly and patients with disordered gait to regain normal walking. In order to enhance the PKO performance and reduce system complexity especially for people with muscle weakness in their knee joints, an algorithm named HIP-KNEE control is proposed. This algorithm is based on the analysis of kinematic gait model, and the desired knee joint angle (KNEE) is estimated from the measurements of hip joint angle (HIP). The relationship between HIP and KNEE is modeled as a polynomial, which can be easily implemented to an embedded controller for real-time control. This control method is suitable to subjects with good function in hip joint, and it can provide help in walking without special training. An Inertia Measurement Units (IMU) is used for obtaining HIP input, and integrated with a footswitch for checking the heel condition; the gait assistance performance can be further improved.	algorithm;embedded controller;embedded system;polynomial;real-time clock;switch;waist–hip ratio	Wai-Yin Lai;Hao Ma;Wei-Hsin Liao;Daniel Tik-Pui Fong;Kai-Ming Chan	2013	2013 IEEE International Conference on Robotics and Biomimetics (ROBIO)	10.1109/ROBIO.2013.6739554	simulation;gait analysis;gait;polynomial	Robotics	70.61045966196892	-27.319932523087747	59030
5d61125716036183fd9c0a527464efebacab7b51	enhancing adaptability of amoeboid robot by synergetically coupling two decentralized controllers inspired by true slime mold	soft robotics;amoeboid locomotion;coupled oscillator system;true slime mold;autonomous decentralized control	Autonomous decentralized control is a key concept for understanding the adaptive and versatile behaviors of living systems. To establish a design methodology for such a controller for robotic systems, we have proposed a fully decentralized control system, inspired by biochemical oscillators in true slime mold (Physarum polycephalum), which allows a modular robot to exhibit adaptive and versatile behaviors. However, in real living systems, many adaptation mechanisms with different time constants co-exist without conflict in the body (e.g., reflex, learning, growth and evolution); this contributes to the amazingly resilient and intelligent behaviors of living systems. It is well known that in true slime mold, long time-scale morphological changes coexist with the oscillatory behavior stemming from biochemical oscillators. In the present study, we have designed a mathematical model and real physical robot in which two decentralized controllers are incorporated. Numerical and experimental results show that by combining the controllers with different time constants, a robot can use the proposed model to successfully negotiate a narrow aisle by deforming its body shape dynamically.	automated theorem proving;coexist (image);distributed control system;ellis–numakura lemma;experiment;h+: the digital series;kentaro toyama;living systems;mathematical model;numerical analysis;numerical method;slime;sakai project;self-reconfiguring modular robot;simulation;stemming	Takuya Umedachi;Shunya Horikiri;Ryo Kobayashi;Akio Ishiguro	2015	Adaptive Behaviour	10.1177/1059712315573334	simulation;communication	Robotics	65.21925440235732	-25.792488866873065	59036
cdce8ce17e3c8c1e37d3db4759da33a93f93d0f5	multi robot collision avoidance in a shared workspace		This paper presents a decentralised humanaware navigation algorithm for shared human-robot work-spaces based on the velocity obstacles paradigm. By extending our previous work on collision avoidance, we are able to include and avoid static and dynamic obstacles, no matter whether they are induced by other robots and humans passing through. Using various cost maps and Monte Carlo sampling with different cost factors accounting for humans and robots, the approach allows human workers to use the same navigation space as robots. It does not rely on any external positioning sensors and shows its feasibility even in densely packed environments.		Daniel Claes;Karl Tuyls	2018	Auton. Robots	10.1007/s10514-018-9726-5	robot;computer science;simulation;workspace;collision;monte carlo method	Robotics	56.651232693885504	-25.450520143193675	59084
1ee7d13d849368f8b47ec489292e88f2b923cbb3	an improved description method of the bumpy texture	height map;three dimensional;bumpy texture;gao ronghua kong dehui yin baocai 纹理 高度图 绘制方法 凹凸映射 三维效果 照明效果 生成过程 颠簸 an improved description method of the bumpy texture;bumpy map;bump mapping	Bump mapping is a texture-based rendering approach for simulating surface details to make its illumination results have three-dimensional effects. The bumpy properties of an object are determined by height maps. But in the process of generating height maps, a problem arises, i.e. to get a correct value of the pixel height, empirical data should be calculated repeatedly, which proves very complicated, and meanwhile the realistic rendering effect is reduced, because the bumpy property is exaggerated in the height map. Therefore, in this paper, we present a method for describing the details of the bumpy texture, where a new concept “bumpy map” is introduced to replace the height map. Experimental results demonstrate that the bumpy details produced by the “bumpy map” are more consistent with the original bumpy texture than by the method of height map.	bump mapping;global illumination;heightmap;map;pixel;rendering (computer graphics);simulation;star height	RongHua Gao;Dehui Kong;Baocai Yin	2009	Science in China Series F: Information Sciences	10.1007/s11432-009-0070-4	three-dimensional space;simulation;bump mapping;computer science;heightmap;mathematics;computer graphics (images)	Graphics	64.18849243441792	-50.30943873981542	59139
ac1a32b91ef5adbb3128be5413edc9cd8dae5817	drawing contours from arbitrary data points		This paper describes a computer method for drawing, on an incremental plotter, a set of contours when the height is available only for some arbitrary collection of points. The method is based on a distance-weighted, least-squares approximation technique, with the weights varying with the distance of the data points. It is suitable not only for mathematically derived data, but also for data of geographical and other non-mathematical origins, for which numerical approximations are not usually appropriate. The paper includes a comparison with other approximation techniques.	data point	D. H. McLain	1974	Comput. J.	10.1093/comjnl/17.4.318	plotter;theoretical computer science;algorithm;data point;derived data;computer science	Theory	70.11199616520733	-41.453986657515976	59154
3ce1a0a8d3a36bf472bdd8e39ea9a4f228d416d0	reducing state changes with a pipeline buffer	limiting factor;rendering system;graphics hardware	A limiting factor in the performance of a rendering system is the number of state changes, i.e., changes of the attributes material, texture, shader program, etc., in the stream of rendered primitives. We propose to include a small buffer between application and graphics hardware in the rendering system. This pipeline buffer is used to rearrange the incoming sequence of primitives on-line and locally in such a way that the number of state changes is minimized. This method is generic; it can be easily integrated into existing rendering systems. In our experiments a pipeline buffer reduces the number of state changes by an order of magnitude and achieves almost the same rendering time as an optimal, i.e., presorted, sequence without pipeline buffer. Due to its simple structure and its low memory requirements this method can easily be implemented in software or even hardware.	experiment;generic programming;graphics hardware;graphics pipeline;online and offline;rendering (computer graphics);requirement;shader;texture mapping	Jens Krokowski;Harald Räcke;Christian Sohler;Matthias Westermann	2004			tiled rendering;graphics pipeline;real-time computing;stencil buffer;limiting factor;computer hardware;rendering;computer science;texture memory;graphics hardware;computer graphics (images)	Visualization	66.499877498793	-51.12609022779609	59168
c691a9ddce1b7f81c46aa74beaeeb1b4ebe00516	decomposing complex thin-walled cad models for hexahedral-dominant meshing		Abstract This paper describes an automatic method for identifying thin-sheet regions (regions with large lateral dimensions relative to the thickness) for complex thin-walled components, with a view to using this information to guide the hexahedral (hex) meshing process. This fully automated method has been implemented in a commercial CAD system (Siemens NX) and is based on the interrogation and manipulation of face pairs, which are sets of opposing faces bounding potential thin-sheet regions. Careful consideration is given to the mapping, merging and intersection of face pairs to generate topologies suitable for sweep meshing the thin-sheet regions, and for treating the junctions between adjacent thin-sheet regions. It is proposed that hex meshes be applied to thin-sheet regions by quad meshing one of the faces bounding the thin-sheet region and sweeping it through the thickness to create hex elements. Decisions on the generation and positioning of the cutting surfaces required to isolate thin-sheet regions are made by considering the likely impact on the quality of the resulting mesh. The method delivers a substantial step towards automatic hex meshing for complex thin-walled geometries. A significant reduction of the degrees of freedom (DOF) can be achieved by applying anisotropic hex elements to the identified thin-sheet regions.	computer-aided design;hexahedron	Liang Sun;Christopher M. Tierney;Cecil G. Armstrong;Trevor T. Robinson	2018	Computer-Aided Design	10.1016/j.cad.2017.11.004	mathematical optimization;merge (version control);hexahedron;network topology;mathematics;polygon mesh	EDA	68.25470270435414	-43.65222876117869	59214
207ac634e2cdc772a751c04de0343a4869b8600b	fuzzy-based intelligent control strategy for a person following robot	velocity control;the turning gain adjustment controller fuzzy based intelligent control strategy rfid stereo camera the reference linear velocity adjustment controller;fuzzy control;velocity control fuzzy control image sensors intelligent control mobile robots radiofrequency identification robot vision robust control stereo image processing;mobile robots;robust control;image sensors;intelligent control;robot vision;stereo image processing;pioeer3 dx fuzzy based intelligent control strategy person following robot mobile robot rfid stereo camera id tag sensors robust control strategy fuzzy based reference linear velocity adjustment controller fuzzy based turning gain adjustment controller field of view fov;robot kinematics cameras target tracking robot vision systems radiofrequency identification mobile robots;radiofrequency identification	This paper presents a fuzzy-based intelligent control strategy allowing a mobile robot to safely follow a given person. The robot is embedded with two sensors: a RFID and a stereo camera. The RFID can locate the given person with an ID tag, and the stereo camera can be used to detect the target. Based on the two sensors, a robust control strategy is designed according to the target's speed and his distance from the robot. The strategy consists of two fuzzy controllers. The first is a fuzzy based reference linear velocity adjustment controller, and the other is a fuzzy based turning-gain adjustment controller. Up to the results from the two controllers, the robot's left wheel velocity and right wheel velocity are adaptively varied for driving the robot towards the target as soon as possible. Moreover, the RFID can provide a wider field of view (FOV) than the camera. If the person turns out of the FOV of the camera, the control strategy will drive the robot towards the target according to the information from RFID as soon as possible. Finally, the algorithm is evaluated on the Pioeer3-DX, and it shows that the presented algorithm can follow the target robustly.	algorithm;control theory;embedded system;field of view in video games;intelligent control;mobile robot;radio-frequency identification;robust control;sensor;stereo camera;velocity (software development)	Songmin Jia;Lijia Wang;Shuang Wang;Congxuan Bai	2013	2013 IEEE International Conference on Robotics and Biomimetics (ROBIO)	10.1109/ROBIO.2013.6739831	robust control;control engineering;mobile robot;computer vision;computer science;engineering;artificial intelligence;image sensor;control theory;robot control;intelligent control	Robotics	60.53055592239658	-31.27033229373215	59235
3e20b0866a9a021e65f3c4827b94b49a1d4a74e4	an improved texture-related vertex clustering algorithm for model simplification	vertex clustering;3d gis;texture related;model simplification;adaptive partitioning	As an important data source in 3D GIS, 3D landmark models are built to simulate the real-world scenario. However, due to the enormous volume and complexity of 3D models, the data transmission under limited bandwidth and the real-time rendering have always been an open problem. In order to improve the visualization and the efficiency, this paper proposes a novel model simplification algorithm in consideration of texture after the analysis of the existing model simplification approaches. Differing from the previous research, our approach defines a new error metric related to the model texture, which extends the vertex clustering scheme in 3D geometry space and 2D texture space independently. Since the uneven distribution of vertices is taken into account, the clustering unit is divided adaptively in consideration of both geometry and texture information. In view of reducing the memory overhead and improving the algorithm efficiency, we don’t create new vertices by iterative calculations, but use the inherent vertices in the initial meshes as the characteristic vertices. To demonstrate the feasibility and effectiveness of our strategy, a series of simplification experiments have been carried out on the platform of DirectX 3D, a widely used 3D application programming interface. The results show that the simplified models in consideration of texture preserve more texture details than those traditional ones. It apparently makes a good balance between the reduction rate and visual effects. & 2015 Elsevier Ltd. All rights reserved.	3d modeling;algorithm;algorithmic efficiency;application programming interface;cluster analysis;directx;distortion;error detection and correction;experiment;geographic information system;iterative method;level of detail;overhead (computing);polygon mesh;real-time clock;residual (numerical analysis);simulation;subdivision surface;symbolic computation;text simplification;texture mapping;vertex (geometry);visual effects	Jing Chen;Mo Li;Jiawei Li	2015	Computers & Geosciences	10.1016/j.cageo.2015.07.005	mathematical optimization;combinatorics;machine learning;mathematics	Graphics	67.80244378727804	-49.44954639340747	59372
d538f48ac95df47b9d71650b0e92cd72e2c3bb1d	"""creating of control systems for dynamically complicated objects on the basis of using of adaptive algorithms with a """"model"""""""	automatic control;reservoirs;control systems;motion control;computerised control materials handling adaptive control model reference adaptive control systems helicopters motion control assembling;computerised control;adaptive control;programmable control;object handling;assembly;adaptive algorithm;model reference adaptive control systems;materials handling;assembling;universal platform;model based control;helicopter;valves;motion control control systems object handling adaptive control assembly universal platform helicopter computerised control model based control;accelerometers;control systems programmable control adaptive control helicopters assembly adaptive algorithm automatic control reservoirs valves accelerometers;helicopters	The authors propose the new principle solution of task on the automatic installation of loads during the assembly work with the help of helicopter. We develop an original method and a special device, called the universal platform, that is fixed directly to a load and operates in conjunction with the helicopter. The platform on-board computer uses a specially developed model-based adaptive control algorithm. This algorithm can provide a completely automatic correction of the load and helicopter motion, in order to realize a smooth, highly accurate matching of the assembly points of the load and the support. A description of platform's construction and the main principles of its operation are given. It is shown that the platform with corresponding control algorithm is a universal device and can operate both on Earth and in space with any kind of lifting mechanism.	algorithm;control system	G. P. Arumov;V. A. Frolov;I. M. Sidorov;G. V. Veselova;V. P. Bogomolov;R. A. Myllyla	1998		10.1109/ICSMC.1998.727538	motion control;simulation;adaptive control;automatic control;control theory;assembly;accelerometer;reservoir	Robotics	64.0826679961188	-29.961445445519857	59515
2c2a1ae4d8d03573c3d185ceb4bfa12555cb3a40	an ai planning-based tool for scheduling satellite nominal operations	ai planning;automatic control	of research within the AI community due to the complexity of the problems that satellite domains need to solve. With the current U.S. and European focus on launching satellites for communication, broadcasting, or localization tasks, among others, the automatic control of these machines becomes an important problem. Many new techniques in both the planning and scheduling fields have been applied successfully, but still much work is left to be done for reliable autonomous architectures. The purpose of this article is to present CONSAT, a real application that plans and schedules the performance of nominal operations in four satellites during the course of a year for a commercial Spanish satellite company, HISPASAT. For this task, we have used an AI domain-independent planner that solves the planning and scheduling problems in the HISPASAT domain thanks to its capability of representing and handling continuous variables, coding functions to obtain the operators’ variable values, and the use of control rules to prune the search. We also abstract the approach in order to generalize it to other domains that need an integrated approach to planning and scheduling.	automated planning and scheduling;automatic control;autonomous robot;internationalization and localization;scheduling (computing)	María Dolores Rodríguez-Moreno;Daniel Borrajo;Daniel Meziat	2004	AI Magazine		automated planning and scheduling;operator (computer programming);simulation;planner;scheduling (computing);automatic control;real-time computing;satellite;schedule;artificial intelligence;computer science;broadcasting	AI	55.895388121018506	-28.435694880747693	59538
5c2966b0c3b039e8d3bd48e80b411af92b6c1f30	physically-based real-time lens flare rendering	real time;lens flare;real time application;real time rendering	Lens flare is caused by light passing through a photographic lens system in an unintended way. Often considered a degrading artifact, it has become a crucial component for realistic imagery and an artistic means that can even lead to an increased perceived brightness. So far, only costly offline processes allowed for convincing simulations of the complex light interactions. In this paper, we present a novel method to interactively compute physically-plausible flare renderings for photographic lenses. The underlying model covers many components that are important for realism, such as imperfections, chromatic and geometric lens aberrations, and antireflective lens coatings. Various acceleration strategies allow for a performance/quality tradeoff, making our technique applicable both in real-time applications and in high-quality production rendering. We further outline artistic extensions to our system. CR Categories: I.3.3 [Computer Graphics]: Image Generation	algorithm;computer graphics;context (computing);high-dynamic-range imaging;holomatix rendition;interaction;interactivity;online and offline;real-time clock;real-time computing;real-time transcription;simulation;speech coding;time stretch analog-to-digital converter;visual computing;xara flare	Matthias B. Hullin;Elmar Eisemann;Hans-Peter Seidel;Sungkil Lee	2011	ACM Trans. Graph.	10.1145/2010324.1965003	computer vision;simulation;computer science;lens flare;optics;real-time rendering;computer graphics (images)	Graphics	63.52971606022185	-50.90769264098123	59598
e96de548f52d647ed769d0b3544b444aee5f89a8	shading models for point and linear sources	convex polyhedra;lighting simulation;luminous intensity distribution	The degree of realism of the shaded image of a tree-dimensional scene depends on the successful simulation of shading effects. The shading model has two main ingredients, properties of the surface and properties of the illumination falling on it. Most previous work has concentrated on the former rather than the latter. This paper presents an improved version for generating scenes illuminated by point and linear light sources. The procedure can include intensity distributions for point light sources and output both umbrae and penumbrae for linear light sources, assuming thr environment is composed of convex polyhedra. This paper generalizes Crow's procedure for computing shadow volumes caused by the end points of the linear source results in an easy determination of the reions of penumbrae and umbrae on the face prior to shading calculation. This paper also discusses a method for displaying illuminance distribution on a shaded image aby using colored isolux contours.	glossary of computer graphics;line source;list of common shading algorithms;polyhedron;reflow soldering;shadow volume;simulation	Tomoyuki Nishita;I. Okamura;Eihachiro Nakamae	1985	ACM Trans. Graph.	10.1145/282918.282938	computer vision;mathematics;optics;computer graphics (images)	Graphics	63.07929991168154	-51.47981095719896	59656
9cfeb490a27253b538990e3414ee3fae3f74d0be	a framework for outdoor urban environment estimation	automatic vehicle location;data handling cartography;network analysis planning;data fusion;urban scene understanding framework outdoor urban environment estimation framework urban road layout estimation vehicle localization problem openstreetmap cartographic map kitti dataset urban residential scenario highway road scenario intelligent vehicles application;urban areas;roads sensors layout global positioning system vehicles buildings probabilistic logic;intelligent vehicles;settore ing inf 01 elettronica	In this paper we present a general framework for urban road layout estimation, altogether with a specific application to the vehicle localization problem. The localization is performed by synergically exploiting data from different sensors, as well as map-matching with OpenStreetMap cartographic maps. The effectiveness is proven by achieving real-time computation with state-of-the-art results on a set of ten not trivial runs from the KITTI dataset, including both urban/residential and highway/road scenarios. Although this paper represents a first step implementation towards a more general urban scene understanding framework, here we prove its flexibility of application to different intelligent vehicles applications.	ambiguous grammar;cartography;computation;displacement mapping;lateral thinking;map matching;openstreetmap;real-time clock;scoring functions for docking;sensor;time complexity;vii;visual odometry;whole earth 'lectronic link	Augusto Luis Ballardini;Simone Fontana;Axel Furlan;Dario Limongi;Domenico Giorgio Sorrenti	2015	2015 IEEE 18th International Conference on Intelligent Transportation Systems	10.1109/ITSC.2015.437	simulation;geography;civil engineering;transport engineering	Robotics	54.527872742371436	-42.801315408931345	59657
a878d5034eaf8e5126709fe48387be7e2794ca38	realistic modeling and animation of human body based on scanned data	real time;real time simulation;triangular mesh;motion capture data;human body model;deformation;feature extraction;human body;surface model;real time animation;animation;virtual reality environment;geometric model;animal model;3d reconstruction;human body modeling	In this paper we propose a novel method for building animation model of real human body from surface scanned data. The human model is represented by a triangular mesh and described as a layered geometric model. The model consists of two layers: the control skeleton generating body animation from motion capture data, and the simplified surface model providing an efficient representation of the skin surface shape. The skeleton is generated automatically from surface scanned data using the feature extraction, and then a point-to-line mapping is used to map the surface model onto the underlying skeleton. The resulting model enables real-time and smooth animation by manipulation of the skeleton while maintaining the surface detail. Compared with earlier approach, the principal advantages of our approach are the automated generation of body control skeletons from the scanned data for real-time animation, and the automatic mapping and animation of the captured human surface shape. The human model constructed in this work can be used for applications of ergonomic design, garment CAD, real-time simulating humans in virtual reality environment and so on.	computer-aided design;feature extraction;geometric modeling;human factors and ergonomics;motion capture;polygon mesh;real-time computing;real-time locating system;simulation;surface detail;virtual reality	Yong-You Ma;Hui Zhang;Shou-Wei Jiang	2004	Journal of Computer Science and Technology	10.1007/BF02944754	3d reconstruction;anime;computer vision;human body;simulation;skeletal animation;feature extraction;computer science;geometric modeling;triangle mesh;machine learning;deformation;computer graphics (images)	Graphics	70.19682873942673	-46.66008219302263	59664
06c33d206b4db8b235d34616e24d60c8d108ff82	example-based interactive illustration of multi-field datasets	interactive exploration;real time;visual interaction;multi field visualization;medical image;visualization technique;illustrative visualization;physical simulation	Multi-fields are widely used in areas ranging from physical simulations to medical imaging. Illustrative visualization techniques can help to effectively communicate features of interest found in a given field. Current techniques for multi-field visualization are mostly focused on showing subsets of local attributes such as single values or vector directions, e.g., using colors, texture, streamlines or glyphs. Instead, we present an approach based on highlighting areas with similar characteristics, considering all attributes of the field. Our approach is example-based and interactive. A user simply selects a point within the field, upon which the system automatically derives the characteristic combination of attributes for that point. Our system then automatically creates a visualization highlighting areas within the field which are similar to the example point with respect to these characteristics. The visualizations are presented using sparse, illustrative techniques, using contours and colors to clearly delineate and identify separate areas. Users can interact with the visualizations in real-time, by moving the example point or, optionally, by changing the characteristics or adjusting other parameters used to determine similarity. & 2010 Elsevier Ltd. All rights reserved.	brushing and linking;color;computer graphics;connected component (graph theory);contour line;feature selection;feature vector;glyph;interactive visualization;medical imaging;motion estimation;point of interest;prototype;real-time computing;real-time locating system;self-similarity;similarity measure;simulation;sparse matrix	Stef Busking;Charl P. Botha;Frits H. Post	2010	Computers & Graphics	10.1016/j.cag.2010.07.004	computer vision;visual analytics;computer science;multimedia;computer graphics (images)	HCI	65.3257975896093	-46.721229862420465	59738
163b4ac28510840f2da1ebc82d7e19617752bd52	instant radiosity	realtime rendering algorithms;jittered low discrepany sampling;quasi monte carlo integration;accumulation buffer;monte carlo integration;quasi random walk;radiosity;photorealism;radiance equation;hardware;shading	We present a fundamental procedure for instant rendering from the radiance equation. Operating directly on the textured scene description, the very efficient and simple algorithm produces photorealistic images without any finite element kernel or solution discretization of the underlying integral equation. Rendering rates of a few seconds are obtained by exploiting graphics hardware, the deterministic technique of the quasi-random walk for the solution of the global illumination problem, and the new method of jittered low discrepancy sampling. CR Categories: I.3.3 [Computer Graphics]: Picture/ Image Generation—Antialiasing— Bitmap and framebuffer operations— Display algorithms— Viewing algorithms; I.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism—Animation— Color, shading, shadowing, and texture— Radiosity	algorithm;bitmap;computer graphics;discrepancy function;discretization;finite element method;framebuffer;global illumination;graphics hardware;low-discrepancy sequence;radiosity (computer graphics);sampling (signal processing);shading;spatial anti-aliasing	Alexander Keller	1997		10.1145/258734.258769	mathematical optimization;shading;radiosity;simulation;computer science;monte carlo integration;computer graphics (images)	Graphics	65.2468152018576	-50.886543780738194	59768
e2ccc6bd592aea2defe4277f7365c328c8ecb5e0	an n-dimensional pseudo-hilbert scan for arbitrarily-sized hypercuboids	hypercube;look up table;tecnologia electronica telecomunicaciones;digital image processing;lattice points;euclidean distance;space filling curve;spatial relationships;tecnologias;grupo a;hilbert scan;hilbert curve	The N-dimensional (N-D) Hilbert curve is a one-to-one mapping between N-D space and one-dimensional (1-D) space. It is studied actively in the area of digital image processing as a scan technique (Hilbert scan) because of its property of preserving the spatial relationship of the N-D patterns. Currently there exist several Hilbert scan algorithms. However, these algorithms have two strict restrictions in implementation. First, recursive functions are used to generate a Hilbert curve, which makes the algorithms complex and computationally expensive. Second, all the sides of the scanned region must have the same size and the length must be a power of two, which limits the application of the Hilbert scan greatly. Thus in order to remove these constraints and improve the Hilbert scan for general application, a nonrecursive N-D Pseudo-Hilbert scan algorithm based on two look-up tables is proposed in this paper. The merit of the proposed algorithm is that implementation is much easier than the original one while preserving the original characteristics. The experimental results indicate that the Pseudo-Hilbert scan can preserve point neighborhoods as much as possible and take advantage of the high correlation between neighboring lattice points, and it also shows the competitive performance of the Pseudo-Hilbert scan in comparison with other common scan techniques. We believe that this novel scan technique undoubtedly leads to many new applications in those areas can benefit from reducing the dimensionality of the problem.		Jian Zhang;Sei-ichiro Kamata	2008	IEICE Transactions	10.1093/ietfec/e91-a.3.846	spatial relation;mathematical optimization;discrete mathematics;lookup table;hilbert r-tree;digital image processing;euclidean distance;mathematics;geometry;lattice;hypercube	Visualization	67.27684175364904	-47.76499444678475	59851
37064ee8002e932edc8ed4383a99e06696e41b89	novel low cost 3d surface model reconstruction system for plant phenotyping		Accurate high-resolution three-dimensional (3D) models are essential for a non-invasive analysis of phenotypic characteristics of plants. Previous limitations in 3D computer vision algorithms have led to a reliance on volumetric methods or expensive hardware to record plant structure. We present an image-based 3D plant reconstruction system that can be achieved by using a single camera and a rotation stand. Our method is based on the structure from motion method, with a SIFT image feature descriptor. In order to improve the quality of the 3D models, we segmented the plant objects based on the PlantCV platform. We also deducted the optimal number of images needed for reconstructing a high-quality model. Experiments showed that an accurate 3D model of the plant was successfully could be reconstructed by our approach. This 3D surface model reconstruction system provides a simple and accurate computational platform for non-destructive, plant phenotyping.	3d modeling;3d reconstruction;algorithm;computer stereo vision;computer vision;display resolution;emoticon;experiment;feature (computer vision);image resolution;open-source software;polygonal modeling;scale-invariant feature transform;structure from motion;tree accumulation;visual descriptor;visual inspection	Suxing Liu;Lucia M. Acosta-Gamboa;Xiuzhen Huang;Argelia Lorence	2017	J. Imaging	10.3390/jimaging3030039	structure from motion;mathematics;computer vision;artificial intelligence;scale-invariant feature transform	Vision	58.19595414573519	-47.32368345960229	59854
e3d4699b72d9254433f854e88fe021ec8682e2be	an electrically tunable zoom system using liquid lenses	liquid lens;optical imaging;gaussian bracket;stabilized zoom system	A four-group stabilized zoom system using two liquid lenses and two fixed lens groups is proposed. We describe the design principle, realization, and the testing of a 5.06:1 zoom system. The realized effective focal length (EFL) range is 6.93 mm to 35.06 mm, and the field of view (FOV) range is 8° to 40°. The system can zoom fast when liquid lens 1's (L₁'s) optical power take the value from 0.0087 mm(-1) to 0.0192 mm(-1) and liquid lens 2's (L₂'s) optical power take the value from 0.0185 mm(-1) to -0.01 mm(-1). Response time of the realized zoom system was less than 2.5 ms, and the settling time was less than 15 ms.The analysis of elements' parameters and the measurement of lens performance not only verify the design principle further, but also show the zooming process by the use of two liquid lenses. The system is useful for motion carriers e.g., robot, ground vehicle, and unmanned aerial vehicles considering that it is fast, reliable, and miniature.	aerial photography;aspartate transaminase;contain (action);datasheet;deep zoom;drug vehicle;electricity;enlightenment foundation libraries;experiment;focal (programming language);field of view in video games;lens (device);move-to-front transform;normal statistical distribution;period-doubling bifurcation;population parameter;responsiveness;robot;settling time;stationary state;unmanned aerial vehicle	Heng Li;Xuemin Cheng;Qun Hao	2015		10.3390/s16010045	computer vision;lens speed;simulation;engineering;digital zoom;optical imaging;optics;physics	Robotics	81.68847694572446	-25.863701365303026	59855
e7a347722a4c761a17e731131f180f6f7c67d1c2	a hierarchical and view dependent visualization algorithm for tree based amr data in 2d or 3d	huge quantity of data;hierarchy;tree based amr;view dependent	In this paper, a solution to the visualization of huge amount of data provided by solvers using tree based AMR method is proposed. This approach strongly relies on the hierarchical structure of data and view dependent arguments: only the visible cells will be drawn, reducing consequently the amount of rendered data, selecting only the cells that intersect the screen and whose size is bigger than one pixel.#R##N##R##N#After a brief statement of the problem, we recall the main principles of AMR methods.We then proceed to the data analysis which shows notable differences related to the dimension (2 or 3). A natural view dependent decimation algorithm is derived in the 2D case (only visible cells are plotted), while in 3D the treatment is not straightforward. The proposed solution relies then on the use of perspective in order to keep the same guidelines that were used in 2D. We then give a few hints about implementation and perform numerical experiments which confirm the efficiency of the proposed algorithms.We finally discuss this approach and give the sketch for future improvements.		Stéphane Del Pino	2004		10.2312/EGPGV/EGPGV04/049-058	parallel computing;computer science;theoretical computer science;operating system;data mining;algorithm;hierarchy;computer graphics (images)	Visualization	70.00305895956487	-51.618159979964396	59888
3195ac49ed0cb63dc20d43e57d0625780f62a143	determination of free parameters in algebraic surface blending	surface energy minimization algebraic surface blending;surface energy;algebra computational geometry;computational geometry;algebraic surfaces;algebra;computer graphics shape control paper technology mathematics application software computer aided manufacturing animation irrigation topology interpolation	In the paper we propose a method to determine parameters that appear in algebraic surface blending. By minimizing the surface energy and adding some point restrictions, we can select the free parameters such that a blending surface with reasonable shape is constructed. The method seems to be extensible for other surface blending problems, although we concentrate on algebraic surface blending.	alpha compositing;linear algebra	Chendong Xu;Falai Chen;Jiansong Deng	2005	Ninth International Conference on Computer Aided Design and Computer Graphics (CAD-CG'05)	10.1109/CAD-CG.2005.31	surface energy;mathematical optimization;combinatorics;computational geometry;mathematics;geometry;real algebraic geometry;algebraic surface	Vision	68.3343607718975	-41.83775888417838	60014
fe15f30ed732105c7e961d5c2b85187d6989ebd8	depth estimation using shifted digital still camera	high resolution;digital still camera;stereo vision;image analysis;depth estimation;canonical stereovision system	The present work investigates a simple method for determining the distance to objects in a scene using the principles of the canonical stereo vision systems. The objective is to prove by the physical experiments that using conventional digital still camera in combination with image analysis techniques relying on binocular cues it is possible to effectively determine the distance to particular objects in a given scene. The main request is that the camera should have precise horizontal movement, high resolution and possibilities of adjusting the parameters of the optical system. Experimental results with structured scenes and camera shifted on various distances demonstrate the effectiveness of the method in providing a reliable estimation of the depth of a scene, and also outline some of its limitations and shortcomings.	depth perception;digital camera;experiment;image analysis;image resolution;stereopsis	Iva Nikolova;Atanas Nikolov;Georgi Zapryanov	2011		10.1145/2023607.2023648	computer stereo vision;stereo camera;computer vision;camera auto-calibration;image analysis;camera resectioning;image resolution;computer science;stereopsis;pinhole camera model;computer graphics (images)	Vision	56.79434383252101	-50.259593587311734	60029
0e5d69d155878bcae96041964b61e6c13890343c	tri-view morphing	image processing;trinocular stereo;dynamic view morphing;4d video;multiple views;trifocal geometry;multi image processing;augmented reality;image based rendering;multiple view morphing	This paper presents an efficient image-based approach to navigate a scene based on only three wide-baseline uncalibrated images without the explicit use of a 3D model. After automatically recovering corresponding points between each pair of images, an accurate trifocal plane is extracted from the trifocal tensor of these three images. Next, based on a small number of feature marks using a friendly GUI, the correct dense disparity maps are obtained by using our trinocular-stereo algorithm. Employing the barycentric warping scheme with the computed disparity, we can generate an arbitrary novel view within a triangle spanned by three camera centers. Furthermore, after self-calibration of the cameras, 3D objects can be correctly augmented into the virtual environment synthesized by the tri-view morphing algorithm. Three applications of the tri-view morphing algorithm are demonstrated. The first one is 4D video synthesis, which can be used to fill in the gap between a few sparsely located video cameras to synthetically generate a video from a virtual moving camera. This synthetic camera can be used to view the dynamic scene from a novel view instead of the original static camera views. The second application is multiple view morphing, where we can seamlessly fly through the scene over a 2D space constructed by more than three cameras. The last one is dynamic scene synthesis using three still images, where several rigid objects may move in any orientation or direction. After segmenting three reference frames into several layers, the novel views in the dynamic scene can be generated by applying our algorithm. Finally, the experiments are presented to illustrate that a series of photo-realistic virtual views can be generated to fly through a virtual environment covered by several static cameras. 2004 Elsevier Inc. All rights reserved. 1077-3142/$ see front matter 2004 Elsevier Inc. All rights reserved. doi:10.1016/j.cviu.2004.03.014 * Corresponding author. E-mail addresses: jxiao@cs.ucf.edu (J. Xiao), shah@cs.ucf.edu (M. Shah). 346 J. Xiao, M. Shah / Computer Vision and Image Understanding 96 (2004) 345–366	algorithm;barycentric subdivision;baseline (configuration management);binocular disparity;camera phone;computer vision;experiment;graphical user interface;map;morphing;speech synthesis;synthetic data;triangular function;trifocal tensor;view-master;virtual reality	Jiangjian Xiao;Mubarak Shah	2004	Computer Vision and Image Understanding	10.1016/j.cviu.2004.03.014	computer vision;augmented reality;image-based modeling and rendering;image processing;computer science;multimedia;computer graphics (images)	Vision	58.220338829502964	-49.15102106676293	60060
47c2d62cbd1448f642cb36559047fbfaced95363	three-dimensional surface texture characterization of portland cement concrete pavements	concrete pavements;modelizacion;correlacion;texture;metodo matematico;mathematical method;portland cement;ciment portland;image processing;modelo 3 dimensiones;analyse surface;pavement;portland cement concrete;modele 3 dimensions;wavelet base;base ondita;procesamiento imagen;three dimensional model;recommandation;beton;surface texture;traitement image;transformacion fourier rapida;three dimensional;hormigon;chaussee;modelisation;mathematical models;analisis superficie;tomographie;textura;cemento portland;characterization;methode mathematique;pavement components;recomendacion;recommendation;calzada;image analysis;correlation;caracterisation;tomografia;pavement design;transformation fourier rapide;base ondelette;modeling;surface texture tests;tomography;caracterizacion;concrete;fast fourier transformation;surface analysis	This article investigates the effectiveness of different mathematical methods in describing the threedimensional surface texture of Portland cement concrete (PCC) pavements. Ten PCC field cores of varying surface textures were included in the analysis. X-ray Computed Tomography (CT) was used to scan the upper portion of these cores, resulting in a stack of two-dimensional grayscale images. Image processing techniques were utilized to isolate the void pixels from the solid pixels and reconstruct the three-dimensional surface topography. The resulting three-dimensional surfaces were reduced to two-dimensional “map of heights” images, whereby the grayscale intensity of each pixel within the image represented the vertical location of the surface at that point with respect to the lowest point on the surface. The “map of heights” images were analyzed using four mathematical methods, namely the Hessian model, the Fast Fourier transform (FFT), the wavelet analysis, and the power spectral density (PSD). Results obtained using these methods were compared to the mean profile depth (MPD) computed in accordance with ASTM E1845. ∗To whom correspondence should be addressed. E-mail: abbas@ uakron.edu.	ct scan;concrete security;fast fourier transform;grayscale;hessian;image processing;pixel;portable c compiler;spectral density;the void (virtual reality);tomography;topography;wavelet	Ala Abbas;M. Emin Kutay;Haleh Azari;Robert Rasmussen	2007	Comp.-Aided Civil and Infrastruct. Engineering	10.1111/j.1467-8667.2007.00479.x	surface finish;three-dimensional space;fast fourier transform;systems modeling;concrete;computer science;engineering;surface weather analysis;mathematical model;mathematics;tomography;texture;forensic engineering;correlation	Graphics	78.8444447894443	-49.8731201909212	60113
32db17a0ba908b0282d2d77a2d6ed7b78318fa06	false cue reduction in moving flight simulators	aerospace simulation adaptive systems;aerospace simulation;vestibular organs false cue reduction linear washout filter moving flight simulators roll motion pilot adaptive approach real time simulation;adaptive systems;adaptive filters aircraft trajectory adaptation models maximum likelihood detection nonlinear filters cybernetics	When roll motion is simulated on a moving flight simulator, false cues are frequently perceived by the subject pilot that degrade the quality of the simulation. In order to reduce the false cues, an adaptive approach based on a real-time simulation of the subject's vestibular organs is suggested. This approach is compared both to a linear washout filter commonly used in moving base simulators and to a previous adaptive attempt to eliminate the false cues.	flight simulator;real-time clock;simulation;washout filter	Dan Ariel;Raphael Sivan	1984	IEEE Transactions on Systems, Man, and Cybernetics	10.1109/TSMC.1984.6313342	simulation;computer science;artificial intelligence;adaptive system;control theory	Visualization	70.83437862776115	-31.620975314652114	60136
113b2c8ab513a0b3e535c3975b19da10db775b37	design and analysis of an artificial finger joint for anthropomorphic robotic hands	second order;ligaments;robot hand;degree of freedom;regression analysis dexterous manipulators;linear regression;joints humans ligaments bones indexes shape robots;joints;two degree of freedom;natural interaction;higher order;dexterous manipulators;indexes;bones;shape;indexation;robots;impulse response;damping artificial finger joint anthropomorphic robotic hands dexterous tasks metacarpophalangeal joint index finger ball joint crocheted ligaments silicon rubber sleeve impulse response linear regression nonlinear stiffness;regression analysis;humans;dynamic characteristic;parameter estimation;functional requirement	In order to further understand what physiological characteristics make a human hand irreplaceable for many dexterous tasks, it is necessary to develop artificial joints that are anatomically correct while sharing similar dynamic features. In this paper, we address the problem of designing a two degree of freedom metacarpophalangeal (MCP) joint of an index finger. The artificial MCP joint is composed of a ball joint, crocheted ligaments, and a silicon rubber sleeve which as a whole provides the functions required of a human finger joint. We quantitatively validate the efficacy of the artificial joint by comparing its dynamic characteristics with that of two human subjects' index fingers by analyzing their impulse response with linear regression. Design parameters of the artificial joint are varied to highlight their effect on the joint's dynamics. A modified, second-order model is fit which accounts for non-linear stiffness and damping, and a higher order model is considered. Good fits are observed both in the human (R2 = 0.97) and the artificial joint of the index finger (R2 = 0.95). Parameter estimates of stiffness and damping for the artificial joint are found to be similar to those in the literature, indicating our new joint is a good approximation for an index finger's MCP joint.	approximation;fits;hood method;nonlinear system;robot;robotic arm;system identification	Zhe Xu;Emanuel Todorov;Brian Dellon;Yoky Matsuoka	2011	2011 IEEE International Conference on Robotics and Automation	10.1109/ICRA.2011.5979860	structural engineering;robot;database index;simulation;higher-order logic;impulse response;shape;computer science;engineering;linear regression;degrees of freedom;estimation theory;engineering drawing;functional requirement;second-order logic;regression analysis;statistics	Robotics	69.26045274519919	-24.68696265879682	60162
77d98b4d4b484c3623c99536cc42b16f3f4c3ce2	distant human motion programming of hexapods with the help of stereoscopic visualization	robot sensing systems;microcontrollers;motion control;capacitive accelerometer;stereoscopic visualization;legged locomotion;degree of freedom;motion programming;mobile robots;computer animation distant human motion programming robot hexapod stereoscopic visualization capacitive accelerometer microcontroller sensor;image sensors;hexapod;data visualisation;visualization;distant human motion programming robot;stereo image processing accelerometers computer animation data visualisation humanoid robots image sensors microcontrollers mobile robots robot programming;robot control;humanoid robots;sensor;human motion;human body;solid modeling;robots;stereo image processing;humans visualization robot sensing systems leg robot programming hardware legged locomotion accelerometers robot control motion control;humans;computer animation;motion programming hexapod;accelerometers;leg;robot programming;microcontroller;robot kinematics;hardware	This paper describes a hardware and a method for motion programming robots having six or more legs. The hardware consists of 3 low-cost capacitive accelerometers placed on the human body. Each accelerometer can measure 3 perpendicular axis. Each sensor has a microcontroller connected to it, this way the generated signal can be post-processed, avoiding a few noise sources. The controlled robot has six legs, each leg has 3 degrees of freedom. The whole robot has eighteen degrees of freedom. Because of this the motion control is a very difficult task and there are situations that can't be solved with algorithms. That is why we used human motion for controlling the robot. The method can be used even when the robot is far from the user, because the movements are animated using 3D stereoscopic visualization.	algorithm;apache axis;henrik wann jensen;kinesiology;microcontroller;printed circuit board;robot;sampling (signal processing);sensor;stereoscopy	Henrik Frindt;Gyula Horváth	2009	2009 5th International Symposium on Applied Computational Intelligence and Informatics	10.1109/SACI.2009.5136211	microcontroller;embedded system;computer vision;bang-bang robot;simulation;computer science;engineering;artificial intelligence;data visualization	Robotics	66.36816898468041	-30.344649035392486	60176
0d1119955ee90dca860206b7fd092c614fe243a6	minimal brdf sampling for two-shot near-field reflectance acquisition	reconstruction;merl;reflectance;brdf;rendering	We develop a method to acquire the BRDF of a homogeneous flat sample from only two images, taken by a near-field perspective camera, and lit by a directional light source. Our method uses the MERL BRDF database to determine the optimal set of lightview pairs for data-driven reflectance acquisition. We develop a mathematical framework to estimate error from a given set of measurements, including the use of multiple measurements in an image simultaneously, as needed for acquisition from near-field setups. The novel error metric is essential in the near-field case, where we show that using the condition-number alone performs poorly. We demonstrate practical near-field acquisition of BRDFs from only one or two input images. Our framework generalizes to configurations like a fixed camera setup, where we also develop a simple extension to spatially-varying BRDFs by clustering the materials.	bidirectional reflectance distribution function;cluster analysis;condition number;sampling (signal processing)	Zexiang Xu;Jannik Boll Nielsen;Jiyang Yu;Henrik Wann Jensen;Ravi Ramamoorthi	2016	ACM Trans. Graph.	10.1145/2980179.2982396	computer vision;rendering;computer science;bidirectional reflectance distribution function;mathematics;reflectivity;optics;remote sensing;computer graphics (images)	Graphics	58.57166848704796	-51.43459920257941	60195
2e0cdfbf0909d68c35f60abd0f08f97812c69e4c	a robust method for calculating the simplicity and orientation of planar polygons	numerical stability;estabilidad numerica;polygone;ecuacion lineal;orientation;algorithme;polygon;algorithm;robustesse;graphical system;robust method;orientacion;poligono;robustness;stabilite numerique;linear equation;sistema grafico;systeme graphique;equation lineaire;robustez;algoritmo	Computational difficulties can arise when determining whether a planar polygon is simple, in particular, when two or more sides are ‘almost’ parallel. This paper presents algorithms which utilize winding numbers to avoid most of the difficulties associated with this problem and, for simple polygons, to also calculate their orientation.		Raymond Balbes;Jerrold Siegel	1991	Computer Aided Geometric Design	10.1016/0167-8396(91)90019-8	polygon mesh;mathematical optimization;combinatorics;point in polygon;polygon;mathematics;geometry	EDA	67.70395490580884	-39.91186750280507	60261
a5eaa7c3346e1548bfea42fa413dc97c0226a98e	display of surfaces from volume data	tratamiento datos;medical imaging computer graphics volume data volume rendering picture plane surface classification isovalue contour surfaces region boundary surfaces smooth silhouettes molecular graphics;concepcion asistida;detectors;displays surface fitting rendering computer graphics data visualization application software biomedical imaging computer graphics computed tomography detectors surface treatment;computer aided design;isovalue contour surfaces;computed tomography;visualizacion;application software;computer graphics;volume rendering;medicina;picture plane;surface fitting;molecula;data processing;biomedical imaging;traitement donnee;medecine;molecules;visualization;region boundary surfaces;surface treatment;chimie;medical image;visualisation;displays;image quality;medical imaging;tomographie;surface classification;data visualization;chemistry;quimica;conception assistee;medicine;binary classification;molecule;tomografia;rendering computer graphics;molecular graphics;grafico computadora;tomography;infographie;smooth silhouettes;volume data	The application of volume-rendering techniques to the display of surfaces from sampled scalar functions of three spatial dimensions is discussed. It is not necessary to fit geometric primitives to the sampled data; images are formed by directly shading each sample and projecting it onto the picture plane. Surface-shading calculations are performed at every voxel with local gradient vectors serving as surface normals. In a separate step, surface classification operators are applied to compute a partial opacity of every voxel. Operators that detect isovalue contour surfaces and region boundary surfaces are examined. The technique is simple and fast, yet displays surfaces exhibiting smooth silhouettes and few other aliasing artifacts. The use of selective blurring and supersampling to further improve image quality is described. Examples from molecular graphics and medical imaging are given.<<ETX>>	active contour model;aliasing;contour line;gradient;image quality;medical imaging;molecular graphics;normal (geometry);shading;supersampling;volume rendering;voxel	Marc Levoy	1988	IEEE Computer Graphics and Applications	10.1109/38.511	medical imaging;computer vision;simulation;visualization;molecule;computer science;tomography;computer graphics (images)	Visualization	70.5779404838792	-50.938321136046426	60329
0a2270f069ada66ceb50931e95c6f66b881fe89b	using boolean networks for consensus in multi-robot environmental monitoring tasks	robot dynamics boolean functions chaos environmental monitoring geophysics multi robot systems;chaos theory boolean networks multirobot environmental monitoring tasks dynamical systems data misinterpretation data aggregation multirobotic system dynamics;robot sensing systems mathematical model environmental monitoring robot kinematics multi robot systems	Robotic systems have been shown to be effective for environmental monitoring tasks, in which one or more robots survey an environment for a particular event. Multi-robot systems, consisting of several interacting robots, have been successful in a variety of applications where their ability to accomplish tasks as a team surpasses the abilities and capacities of a single robot. However, multi-robot systems can generate a large degree of complexity due to the required coordination of movement, communication, and the tolerance for incorrect sensor readings. In this paper, we present a novel approach to multi-robot environmental monitoring based on dynamical systems, in which a robot team overcomes data misinterpretation and aggregation difficulties through an effort of collaboration between all members of the team. Our approach makes use of Boolean networks, which allow for a non-complex method of corroboration, while still retaining meaningful information regarding the dynamics of the robotic system. Using our Boolean network model we apply mathematical tools from dynamical systems and chaos theory to analyze the overall behavior of the robotic dynamic over time. Here we observe how different parameters affect the behaviors of the system. We also empirically and experimentally show that, despite the simplification of the robots' states into Boolean states, our Boolean network model produces accurate results when compared to real events of the environment.	approximation algorithm;boolean network;chaos theory;dynamical system;dynamical systems theory;experiment;interaction;kalman filter;level of detail;mathematical model;network model;robot;sensor	Hanzhong Zheng;Janyl Jumadinova	2016	2016 IEEE International Conference on Electro Information Technology (EIT)	10.1109/EIT.2016.7535301	control engineering;embedded system;computer vision;simulation;computer science;artificial intelligence;machine learning	Robotics	54.55451518744933	-27.89645008056152	60380
d3523b7ca08a6b44e15234625d9487066f472e10	approach maneuvers for autonomous landing using visual servo control	journal article;measurement noise nonlinear image based visual servo control algorithm autonomous landing maneuvers fixed wing aircraft primary sensor system vision sensor yielding image sequence 2d linear features 2d point features nonlinear dynamics airplane;visual servoing aerospace components aircraft control feature extraction image sensors image sequences measurement errors measurement uncertainty nonlinear control systems;aerodynamics aircraft atmospheric modeling vehicle dynamics visualization vehicles	A nonlinear image-based visual servo control algorithm for autonomous landing of a fixed wing aircraft is described. The primary sensor system is a vision sensor yielding a sequence of images from which 2D linear and point features of the runway are extracted. The first two phases of a landing maneuver, alignment to the runway and glide (descent to the runway) are treated in the work presented here. The final landing maneuvers, flare to touchdown, and taxiing require additional sensor modalities and are not treated. The proposed control scheme deals with unknown wind conditions and incorporates the full nonlinear dynamics of the airplane. Simulation results based on realistic environmental conditions and measurement noise are presented that validate the control design approach.	algorithm;autonomous robot;carrier-to-noise ratio;differential gps;glide os;global positioning system;image processing;initial condition;lateral thinking;nonlinear system;optical flow;semantics (computer science);servo;simulation;software architecture;visual servoing	Florent Le Bras;Tarek Hamel;Robert E. Mahony;Christian Barat;Julien Thadasack	2014	IEEE Transactions on Aerospace and Electronic Systems	10.1109/TAES.2013.110780	control engineering;computer vision;engineering;control theory	Robotics	53.95050243634702	-36.61905447517153	60395
577c73c54ac85cf49a668f0cfb0d27603eebce42	using quadratic simplicial elements for hierarchical approximation and visualization	quadratic approximation;decomposition domaine;modele geometrique;aproximacion cuadratica;domain decomposition;visualizacion;best approximation;hierarchized structure;approximation method;descomposicion dominio;structure hierarchisee;analyse multiresolution;linear elements;geometric feature;approximation quadratique;visualization;aproximacion esplin;triangulacion;visualisation;spline approximation;approximation spline;mejor aproximacion;triangulation;multiresolution analysis;estructura jerarquizada;analisis multiresolucion;geometrical model;meilleure approximation;modelo geometrico	Best quadratic simplicial spline approximations can be computed, using quadratic Bernstein-Bézier basis functions, by identifying and bisecting simplicial elements with largest errors. Our method begins with an initial triangulation of the domain; a best quadratic spline approximation is computed; errors are computed for all simplices; and simplices of maximal error are subdivided. This process is repeated until a user-specified global error tolerance is met. The initial approximations for the unit square and cube are given by two quadratic triangles and five quadratic tetrahedra, respectively. Our more complex triangulation and approximation method that respects field discontinuities and geometrical features allows us to better approximate data. Data is visualized by using the hierarchy of increasingly better quadratic approximations generated by this process. Many visualization problems arise for quadratic elements. First tessellating quadratic elements with smaller linear ones and then rendering the smaller linear elements is one way to visualize quadratic elements. Our results show a significant reduction in the number of simplices required to approximate data sets when using quadratic elements as compared to using linear elements.	approximation algorithm;basis function;bézier curve;error-tolerant design;maximal set;phil bernstein;quadratic function;spline (mathematics)	David F. Wiley;Hank Childs;Bernd Hamann;Kenneth I. Joy;Nelson L. Max	2002		10.1117/12.458802	periodic points of complex quadratic mappings;mathematical optimization;combinatorics;quadratic field;quadratic residuosity problem;quadratic residue;completing the square;solving quadratic equations with continued fractions;quadratic function;quadratic probing;isotropic quadratic form;binary quadratic form;quadratically constrained quadratic program;mathematics;geometry;quadratic programming;quadratic growth	Visualization	68.70706480797877	-40.303428667010714	60480
4fb87b2ab2e348ae1b79bb19c160a52b1433a124	a new probability distribution for simultaneous representation of uncertain position and orientation	probability theory pose estimation dual quaternions bingham distribution directional statistics se 2 lie groups;statistical distributions lie groups motion estimation parameter estimation;probability distribution uncertain position uncertain orientation closed form bayesian measurement fusion parameter estimation techniques normalization constant bingham distribution measurement noise rigid body motion reprsentation lie group uncertainty representation orientation representation position representation;quaternions estimation vectors transmission line matrix methods probability distribution bayes methods robot sensing systems	This work proposes a novel way to represent uncertainty on the Lie group of rigid-body motions in the plane. This is achieved by using dual quaternions for representation of a planar rigid-body motion and proposing a probability distribution from the exponential family of distributions that inherently respects the underlying structure of the representation. This is particularly beneficial in scenarios involving strong measurement noise. A relationship between the newly proposed distributional model and the Bingham distribution is discussed. The presented results involve formulas for computation of the normalization constant, the mode, parameter estimation techniques, and a closed-form Bayesian measurement fusion.	computation;estimation theory;time complexity	Igor Gilitschenski;Gerhard Kurz;Simon J. Julier;Uwe D. Hanebeck	2014	17th International Conference on Information Fusion (FUSION)		mathematical optimization;inverse-chi-squared distribution;mathematics;geometry;statistics	Robotics	54.666998055277354	-39.44465555376555	60626
f30d5e1eb5fc62d58bc76c8ccc5148c7f234ec80	geodesic conic subdivision curves on surfaces	subdivision curve geodesic conic;differential geometry;splines mathematics;geodesic;convergence manifolds interpolation spline euclidean distance geometry vectors;subdivision scheme;splines mathematics curve fitting differential geometry;curve fitting;convex hull;conic;triangulated surfaces geodesic conic subdivision curves nonlinear curve subdivision scheme geodesic bezier curves geodesic control polygon;subdivision curve	In this paper we present a nonlinear curve subdivision scheme, suitable for designing curves on surfaces. Starting with a geodesic control polygon with vertices on a surface, the scheme generates a sequence of geodesic polygons that converges to a continuous curve on the surface. In the planar case, the limit curve is a conic Bezier spline curve. Each section of the subdivision curve, corresponding to three consecutive points of the control polygon, depends on a free parameter which can be used to obtain a local control of the shape of the curve. Furthermore, it has the convex hull property. Results are extended to triangulated surfaces showing that the scheme is suitable for designing curves on these surfaces and has the convex hull property.	convex hull;nonlinear system;spline (mathematics);subdivision surface	Jorge Estrada-Sarlabous;Victoria Hernández-Mederos;Nayla López Gil;Luiz Velho;Dimas Martínez Morera	2011	2011 24th SIBGRAPI Conference on Graphics, Patterns and Images	10.1109/SIBGRAPI.2011.18	mathematical optimization;topology;geodesic map;mathematics;geometry;curve orientation	Robotics	69.42531595090976	-40.684810852662636	60627
0a3603247570e5843de3ab78aa4207bb3d76f65a	descending-stair detection, approach, and traversal with an autonomous tracked vehicle	gyroscopes;autonomous tracked vehicle;edge detection;path planning;degree of freedom;gyroscope;dynamic model;robot navigation;image edge detection cameras optical imaging robot vision systems estimation;irobot packbot descending stair detection autonomous tracked vehicle vision modules robot navigation degree of freedom rotational velocity measurement gyroscope edge detection;velocity measurement automatic guided vehicles edge detection gyroscopes path planning robot vision;optical imaging;robot vision;descending stair detection;estimation;image edge detection;vision modules;real time implementation;irobot packbot;automatic guided vehicles;optical flow;rotational velocity measurement;velocity measurement;robot vision systems;cameras	This paper presents a strategy for descending-stair detection, approach, and traversal using inertial sensing and a monocular camera mounted on an autonomous tracked vehicle. At the core of our algorithm are vision modules that exploit texture energy, optical flow, and scene geometry (lines) in order to robustly detect descending stairwells during both far- and near-approaches. As the robot navigates down the stairs, it estimates its three-degrees-of-freedom (d.o.f.) attitude by fusing rotational velocity measurements from an on-board tri-axial gyroscope with line observations of the stair edges detected by its camera. We employ a centering controller, derived based on a linearized dynamical model of our system, in order to steer the robot along safe trajectories. A real-time implementation of the described algorithm was developed for an iRobot Packbot, and results from real-world experiments are presented.	algorithm;autonomous robot;dynamical system;experiment;gyroscope;humanoid robot;inertial navigation system;on-board data handling;online and offline;online machine learning;optical flow;packbot;real-time clock;region of interest;sensor;support vector machine;tree traversal;triangular function;velocity (software development)	Joel A. Hesch;Gian Luca Mariottini;Stergios I. Roumeliotis	2010	2010 IEEE/RSJ International Conference on Intelligent Robots and Systems	10.1109/IROS.2010.5649411	control engineering;computer vision;simulation;gyroscope;computer science;engineering	Robotics	57.31129341127289	-34.18564096131332	60662
2f2e9a7aa7587670529ae6112d2c89aeae2fab28	generic self-calibration of central cameras from two rotational flows	closed form solution;camera rotation;optical flow using splines;closed form solutions;camera motion;image sequence;self calibration;optical flow;orthogonal transformation;generic camera	We address the self-calibration of a smooth generic central camera from only two dense rotational flows produced by rotations of the camera about two unknown linearly independent axes passing through the camera centre. We give a closed-form theoretical solution to this problem, and we prove that it can be solved exactly up to a linear orthogonal transformation ambiguity. Using the theoretical results, we propose an algorithm for the self-calibration of a generic central camera from two rotational flows. In order to solve the self-calibration problem using real images, we also study the computation of dense optical flows from image sequences acquired by the rotation of a smooth generic central camera. We propose a method for the computation of dense smooth generic flows from rotational camera motions using splines. The proposed methods are validated using both simulated and real image sequences.	algorithm;computation;spline (mathematics)	Ferran Espuny	2007	International Journal of Computer Vision	10.1007/s11263-010-0335-9	computer vision;camera auto-calibration;closed-form expression;camera matrix;camera resectioning;computer science;optical flow;mathematics;geometry;pinhole camera model;orthogonal transformation	Vision	54.000770832595066	-50.03864276881437	60726
bd1cbb915f7637e1994ed3678670f7f7812e265a	the bubble box: towards an automated visual sensor for 3d analysis and characterization of marine gas release sites	methane;bubbles;flux;underwater photogrammetry;size distribution;stereo;rise speed;3d reconstruction	Several acoustic and optical techniques have been used for characterizing natural and anthropogenic gas leaks (carbon dioxide, methane) from the ocean floor. Here, single-camera based methods for bubble stream observation have become an important tool, as they help estimating flux and bubble sizes under certain assumptions. However, they record only a projection of a bubble into the camera and therefore cannot capture the full 3D shape, which is particularly important for larger, non-spherical bubbles. The unknown distance of the bubble to the camera (making it appear larger or smaller than expected) as well as refraction at the camera interface introduce extra uncertainties. In this article, we introduce our wide baseline stereo-camera deep-sea sensor bubble box that overcomes these limitations, as it observes bubbles from two orthogonal directions using calibrated cameras. Besides the setup and the hardware of the system, we discuss appropriate calibration and the different automated processing steps deblurring, detection, tracking, and 3D fitting that are crucial to arrive at a 3D ellipsoidal shape and rise speed of each bubble. The obtained values for single bubbles can be aggregated into statistical bubble size distributions or fluxes for extrapolation based on diffusion and dissolution models and large scale acoustic surveys. We demonstrate and evaluate the wide baseline stereo measurement model using a controlled test setup with ground truth information.	acoustic cryptanalysis;baseline (configuration management);calibration;camera interface;carbon dioxide;computer stereo vision;deblurring;dot-com bubble;estimated;extrapolation;flux;gases;ground truth;large;matching;methane;preparation;small;stereo camera	Anne Jordt;Claudius Zelenka;Jens Schneider von Deimling;Reinhard Koch;Kevin Köser	2015		10.3390/s151229825	3d reconstruction;computer vision;simulation;methane;computer science;organic chemistry;flux;optics;stereophonic sound;physics;quantum mechanics	Vision	61.10863890108232	-51.74889904948582	60800
2e3b9723633733d5fd550f6b433ed45cee6768e8	constructing surface features through deformation	interpolation;rib;deformation;surface curve;parametric surface;g2 continuity	A frequent problem in computer aided mechanical design is the construction of arbitrarily-shaped ribs and beads on surfaces, to increase their rigidity or for aesthetic reasons. We improve upon a previous mathematical approach for defining such ribs and beads, based on using so-called extension functions to define a deformation matrix, which is then applied to the underlying shape. Our improvements offer important practical advantages: firstly, by use of cosine extension functions, we get a greater control over, and flexibility of, rib shape, including the possibility of repeating ribs; secondly, we can directly control the spine curves. We give experimental results to demonstrate that the method is simple and intuitive, has low computational cost, and is potentially useful for computer aided design, computer graphics and other applications.		Xiaoping Wang;Shenglan Liu;Liyan Zhang	2010	Int. J. Image Graphics	10.1142/S0219467810003652	mathematical optimization;interpolation;parametric surface;mathematics;geometry;deformation;statistics	Vision	67.11750481966915	-44.15433999151752	60822
6dd648e5e1d8ac6769b4ba14220d01e161019f24	three dimensional rotation of bovine oocyte by using magnetically driven on-chip robot	force friction accuracy vibrations permanent magnets angular velocity glass;position control medical robotics;cell manipulation 3d mammalian bovine oocyte rotational control magnetically driven on chip robot embryo fertilization oocyte enucleation oocyte microinjection cell rotation electrorotation magnetically driven microtool mmt oocyte orientation control	In the study of the oocytes/embryos, such as enucleation, microinjection in order to increase the success ratio of the fertilization and characteristics study of the oocytes, all of these research and clinical applications involve 3-D rotation of mammalian oocytes. The gesture or the orientation of the oocyte is critical for improving the enucleation success rate, and characteristics investigation of the oocyte. Cell rotation in conventional approaches mainly are electrorotation or manual operation by skilled professionals based on trial-and-error, repeating the vacuum aspiration and release. The poor reproducibility and inconsistency entail a simple and convenient approach for single oocyte rotation. This paper reports a 3-D rotational control of bovine oocyte. By using customer designed magnetically driven microtool (MMT), the oocyte orientation control could be achieved. Comparing with the conventional works, rotation control by using MMT shows great advantage in control accuracy and the rotation speed. Orientation with an accuracy of 7°, and the average rotation velocity of 3 rad/s have been achieved. Rotation by utilizing MMT demonstrated overall out-of-plane and in-plane in a quite simple way. And by utilizing this approach, the cell manipulation for cell study becomes much easier on investigating single cell characteristics and analysis mechanism properties.	bovine metabolome database;mpeg media transport;robot;velocity (software development)	Lin Feng;Bilal Turan;U. Ningga;Fumihito Arai	2014	2014 IEEE/RSJ International Conference on Intelligent Robots and Systems	10.1109/IROS.2014.6943225	simulation;engineering	Robotics	76.07090221769481	-25.65322028117028	60850
d2a5f050668c7ca3706d0df0d0fabec3ce474e36	task-level planning of pick-and-place robot motions	motion planning robotic assembly service robots intelligent robots strategic planning assembly systems robot motion artificial intelligence laboratories kinematics;robots position control;handey task level planning heuristic motion planning pick and place robot motions task level robot system;position control;robots	A task-level robot system named Handey, which is under development, is described. The current system is limited to pick-and-place operations, and it has successfully carried out dozens of such operations involving a variety of parts in relatively complex environments. The pick-and-place problem is described, and approximate approaches to the problem are examined. Heuristic motion planning in Handey is then discussed.<<ETX>>	approximation algorithm;heuristic;motion planning;robot;smt placement equipment	Tomás Lozano-Pérez;Joseph L. Jones;Emmanuel Mazer;Patrick A. O'Donnell	1989	Computer	10.1109/2.16222	robot;mobile robot;computer vision;simulation;articulated robot;computer science;artificial intelligence;social robot;robot locomotion;motion planning;robot control;personal robot;robot kinematics	Robotics	63.76015681500663	-26.116647246831477	60858
c8f3d7b88cef4fc93aecdfbedc9f92f4cf9ab2bb	dependency by concentration of pheromone trail for multiple robots	signal strength;high concentrate;swarm robotics	In this paper, we discuss the concentration dependency of pheromone communication in swarm robotics. Instead of a pheromone trail and the insect antenna, we used ethanol and an alcohol sensor. This experimental system has a trade-off problem; high concentrations of the pheromone yield high signal strength but the signal duration is short, while low pheromone concentrations yield low signal strength but a long signal duration. We examined the optimal pheromone concentration for a swarm of robots. For this purpose, we developed a swarm behaviour algorithm and swarm robots that communicate using a pheromone trail. In addition, we discuss the effects of the pheromone concentration.	algorithm;experimental system;robot;swarm robotics	Ryusuke Fujisawa;Shigeto Dobata;Daisuke Kubota;Hikaru Imamura;Fumitoshi Matsuno	2008		10.1007/978-3-540-87527-7_28	simulation;engineering;artificial intelligence;communication	Robotics	57.353230065776536	-24.031629472570632	60909
aa817667eb483bdf27833d8201b054fbd46b5521	model fabrication using surface layout projection	programmation booleenne;boolean programming;modelizacion;concepcion asistida;computer aided design;ruled surface;decomposition;image processing;geometrie algorithmique;materiau anisotrope;computational geometry;procesamiento imagen;programacion booleana;traitement image;modelisation;prototipo;surface plane;material anisotropo;conception assistee;geometria computacional;developable surface;descomposicion;plane surface;modeling;prototype;anisotropic material;superficie plana	Abstract   The paper presents a model fabrication scheme that automatically approximates a model whose boundary consists of several freeform surfaces by developable surfaces and then unrolls these developable surfaces onto a plane. The model can then be fabricated by assembling the sets of developable surfaces which have been cut from planar sheets and rolled back to their proper Euclidean locations. Both the approximation and the rolling methods can be made arbitrarily precise.		Gershon Elber	1995	Computer-Aided Design	10.1016/0010-4485(95)91138-B	computer vision;systems modeling;developable surface;image processing;computational geometry;ruled surface;computer aided design;mathematics;geometry;prototype;decomposition;tangential developable;anisotropy;engineering drawing	EDA	67.61836225533624	-39.957335700381506	60960
90e2292a6412f2723766b2e9b5330c6b563edb9f	ga-tuned fuzzy logic control of knee-fes-ergometer for knee swinging exercise	fuzzy control;knee swinging exercise ga fuzzy functional electrical stimulation;niobium matlab manuals trajectory cities and towns muscles;parameter identifications ga tuned fuzzy logic control knee fes ergometer knee swinging exercise stroke patients functional electrical stimulation flc knee trajectory genetic algorithm;medical control systems biomedical equipment fuzzy control genetic algorithms;genetic algorithms;biomedical equipment;medical control systems	Knee-FES-ergometer for knee swinging exercise is introduced as a hybrid exercise for restoration of function of the knee for stroke patients through the application of functional electrical stimulation (FES). The aim of the new knee-FES-ergometer is to provide high intensity knee swinging exercise. It is able to reduce required electrical stimulation and will able to elongate the exercise duration while avoiding early muscle fatigue. Fuzzy logic control (FLC) is used to control the knee trajectory for the purpose of smooth knee swinging exercise. However, conventional FLC rely on human experiences and trial and error for parameter identifications. In this work, a genetic algorithm (GA) is used to tune the FLC to maintain a smooth swinging exercise. The performance of the proposed GA tuned FLC is compared with a manually tuned FLC. Results shows that the GA tuned FLC offers encouragingly better performance.	circuit restoration;functional electrical stimulation;fuzzy logic;genetic algorithm;logic control;shin megami tensei: persona 3;software release life cycle	Rozan Boudville;Zakaria Hussain;Saiful Zaimy Yahaya;K. A. Ahmad;Mohd Nasir Taib	2013	2013 IEEE International Conference on Control System, Computing and Engineering	10.1109/ICCSCE.2013.6720037	control engineering;engineering;physical therapy;control theory	Robotics	70.70289657742481	-27.57863414264294	61047
b7691ac487b55e221279269c9952ce6abc95d485	hexahedral mesh modification to preserve volume		Abstract In this work, we provide a new post-processing procedure for automatically adjusting node locations of an all-hex mesh to better match the volume of a reference geometry. This process is particularly well-suited for mesh-first approaches, as overlay grid ones. In practice, hexahedral meshes generated via an overlay grid procedure, where a precise reference geometry representation is unknown or is impractical to use, do not provide for precise volumetric preservation. A discrete volume fraction representation of the reference geometry M I on an overlay grid is compared with a volume fraction representation of a 3D finite element mesh M O . This work introduces the notion of localized discrepancy between M I and M O and uses it to design a procedure that relocates mesh nodes to more accurately match a reference geometry. We demonstrate this procedure on a wide range of hexahedral meshes generated with the Sculpt code and show improved volumetric preservation while still maintaining acceptable mesh quality.	hexahedron	Nicolas Le Goff;Franck Ledoux;Steven J. Owen	2018	Computer-Aided Design	10.1016/j.cad.2018.07.001	grid;mathematical optimization;hexahedron;volume fraction;overlay;finite element method;polygon mesh;mathematics	EDA	68.8341458562157	-44.707036914670944	61100
f1452fdf3a47c86a5dc651a345f1e5ded57c268f	distributed small sensor system for autonomous mobile robots	sensor system;autonomous mobile robot	A robust and reliable sensor system is the enabling technology for automation processes. Especially in the field of mobile robots, a high performance perception system is required to cope with an unknown environment. While many approaches are based upon vision systems where an expensive signal processing is required, this paper describes new development results in the field of ultrasonic sensors to meet the low cost requirements of a sensor system.	autonomous robot	Rolf Dieter Schraft;Martin Hägele;Jörg Dahlkemper;Winfried Baum	1995		10.1007/978-3-642-80064-1_7	mobile robot;robot control;mobile wireless sensor network	Robotics	56.5091019448408	-31.01619133743774	61179
f2bc745ff3bd07c43de4569173194ba94910a9f0	a new detecting algorithm for chip based on b-spline wavelet	canny algorithm detecting algorithm b spline wavelet locating algorithm visual detection electronic manufacturing process printed circuit board locating accuracy susan algorithm;locating accuracy;spline;printed circuits;edge detection;wavelet transforms edge detection printed circuit manufacture splines mathematics;canny algorithm;manufacturing automation;locating algorithm;electronic manufacturing process;data mining;splines mathematics;chip;b spline wavelet;wavelet transforms;assembly;accuracy;manufacturing processes;smoothing methods;image edge detection;susan algorithm;detection algorithm;visual detection;printed circuit manufacture;printed circuit board;educational technology;signal processing algorithms;electronic equipment manufacture;spline image edge detection manufacturing automation assembly algorithm design and analysis electronic equipment manufacture educational technology manufacturing processes printed circuits data mining;algorithm design and analysis;detecting algorithm;noise	Locating and detecting algorithm for chip is important in visual detection of electronic manufacturing process. Its performance directly affects the speed and accuracy of assembling chip on Printed Circuit Board. This paper analyzed the common algorithms' disadvantages in locating accuracy. Then based on the above analysis, a new algorithm was proposed, in which B-spline is used to detect edge accurately and help to mount chip more precisely. Experiment results demonstrated that the proposed algorithm's performance is better than SUSAN and Canny algorithms' in locating accuracy and stability, and can meet the practical demand of mounting chip.	algorithm;b-spline;canny edge detector;printed circuit board;sensor;spline wavelet	Qian Mai;Hongxia Gao;Yueming Hu	2010	2010 International Conference on Networking, Sensing and Control (ICNSC)	10.1109/ICNSC.2010.5461529	computer vision;educational technology;electronic engineering;telecommunications;computer science;engineering;printed circuit board;engineering drawing;statistics	EDA	60.15167291813395	-40.65593671187011	61181
e4afe34d4fd4aa4395ffc811e92855aa3694c3fa	nice perspective projections	graph drawing;perspective projection;computational geometry;three dimensional;computer graphic;computer vision;knot theory;rooted tree	Abstract   A polyhedral object in three-dimensional space is often well represented by a set of points and line segments that act as its features. By a nice perspective projection of an object we mean a projection that gives an image in which the features of the object, relevant for some task, are visible without ambiguity. In this paper we consider the problem of computing a variety of nice perspective projections of three-dimensional objects such as simple polygonal chains, wire-frame drawings of graphs, and geometric rooted trees. These problems arise in areas such as computer vision, computer graphics, graph drawing, knot theory, and computational geometry.		Francisco Gómez;Ferran Hurtado;Joan Antoni Sellarès;Godfried T. Toussaint	2001	J. Visual Communication and Image Representation	10.1006/jvci.2001.0488	three-dimensional space;computer vision;oblique projection;combinatorics;discrete mathematics;perspective;projection plane;computational geometry;knot theory;parallel projection;mathematics;geometry;graph drawing;graphical projection	Vision	64.855225903921	-40.82271531856377	61191
122b17c2cfe1231d14e3300a11ddbf9a2372a5a5	real time local approximation of deformations using rotations	real time;polyhedral morphing;geometric animations;multiresolution progressive representation	Additional realism can be achieved in computer generated images using smooth and increasingly complex deformations. Though significant effort has been spent on improving these deformations, no general method has been proposed yet to deal with rigid pieces connected to soft objects. This paper proposes a general framework to solve this problem. We will present several types of applications, such as flowing small objects in a deformation field, animating rigid features connected to some deformed object, or smoothly attached limbs to a deforming body. All the calculations presented here can be applied to any type of deformation, provided that the deformation at each point only depends on the point itself. Even though we can directly compute the result for some analytical deformation fields, we will show that a good sampling of the deformation in the area of interest is generally enough. One intermediate result consists of a practical method to find the best rotation that approximates a linear transformation. The proposed method is a superset of the Gram-Schmidt orthonormalization process, and is much easier to compute than global methods based on Taylor series.	approximation;real-time business intelligence	Jérôme Maillot	2000	Comput. Graph. Forum	10.1111/1467-8659.00435	mathematical optimization;topology;computer science;mathematics;geometry;computer graphics (images)	Theory	67.89972950047286	-45.34353765398907	61222
8408e3f3401df373a2f386e587a6fc72400b1e98	calibration of a hand/eye matrix and a connection matrix using relative pose measurements	manipulators;robot hand;optical scanners;spatial variables measurement;image sensors;three dimensional;iterative methods;spatial variables measurement calibration parameter estimation image sensors manipulators iterative methods jacobian matrices optical scanners;parameter estimation;error parameters calibration hand eye matrix connection matrix relative pose measurements gimbal three dimensional sensor x y z type robot linear solution uniqueness observability;calibration robot sensing systems robot kinematics equations sensor systems coordinate measuring machines computational geometry position measurement electric variables measurement observability;jacobian matrices;calibration	The problem investigated in this paper is an extension of the robotic handeye calibration problem. The system consists of a robot, a gimbal anda three dimensional sensor. The task is to determine the handeye matrix that relates the sensor coordinate frame to the first coordinate frame in the gimbal and the connection matrix that relates the first coordinate frame in the gimbal to the tool frame in the robot. The paper focuses on a special case of the mentioned problem. In this study, the robot is a x-y-z type and the gimbal has two rotary joints. Two solution methods, one of which is linear and another is nonlinear, are presented in this paper. Issues such as the uniqueness of the linear solution and the observability of error parameters are also investigated. Simulation and experimental results are given to demonstrate the feasibility of the method.	gimbal lock;nonlinear system;robot;rotary woofer;simulation	Hanqi Zhuang;Andreas Melchinger	1997		10.1109/ROBOT.1997.606725	control engineering;three-dimensional space;computer vision;calibration;image sensor;control theory;mathematics;iterative method;estimation theory;robot kinematics;statistics;robot calibration	Robotics	56.61284070810405	-37.54048679946481	61231
4be056fbb601d7357162a42c9dc3ed4322ae785e	formal resolution of geometrical constraint systems by assembling	computer aided design;local solving;multi agent system;geometric formal construction;assembling of figures;system of geometric constraints;geometric constraints;blackboard	Handling geometric objects described declaratively by a system of geometric constraints is an important issue in CAD. But until now, this requires the effective geometric construction of the objects. This paper presents an original approach to formal geometric constructions in the Euclidian plane, based on invariance under displacements and relaxation of positional constraints. This approach allows to efficiently generalize and join different methods for local solving. The paper also describes the main features of a powerful and extensible operational prototype based on these ideas, which can be viewed as a simple multi-agent system with a blackboard.	computer-aided design;linear programming relaxation;multi-agent system;prototype	Jean-François Dufourd;Pascal Mathis;Pascal Schreck	1997		10.1145/267734.267804	computer science;artificial intelligence;theoretical computer science;computer aided design;multi-agent system	AI	63.976026215265975	-40.366883820218796	61234
36cc723731d90c37952349ce6807d818377f9a26	visual coordination task for human-robot collaboration		In the framework of Human-Robot Collaboration, a robot and a human operator may need to move in close coordination within the same workspace. A contactless coordinated motion can be achieved using vision, mounting a camera either on the robot end-effector or on the human. We consider here one instance of such a visual coordination task, with the robot end-effector that should maintain a prescribed position with respect to a moving RGB-D camera while pointing at it. For the 3D localization of the moving camera, we compare three different techniques and introduce some improvements to the best solution found for our application. For the motion tracking problem, we introduce a relaxed version of the pointing part of the task. This allows to take advantage of the redundancy of the robot, distributing the control effort over the available degrees of freedom. The effectiveness of the proposed approach is shown by V-REP simulations and experiments with the 7-dof KUKA LWR manipulator.	artoolkit;coexist (image);contactless smart card;experiment;extended kalman filter;gradient;human–robot interaction;kernel (linear algebra);optimal control;real-time clock;robot end effector;simulation;workspace	Maram Khatib;Khaled Al Khudir;Alessandro De Luca	2017	2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)	10.1109/IROS.2017.8206225	computer science;redundancy (engineering);operator (computer programming);artificial intelligence;workspace;control engineering;computer vision;robot;manipulator;human–robot interaction;match moving	Robotics	61.05933700046054	-30.288893136236634	61238
0b580570da67c9aec3d1e39ba18772da4b729a19	research on the locomotion of german shepherd dog at different speeds and slopes		Quadruped can take the initiative to adjust their gait for adapting to different external environment. Its superior coordination ability provides bionic design inspiration for the quadruped robot. The motion of three German Shepherd Dogs on a treadmill was recorded using a three-dimensional motion capture system VICON MX. The speed of the treadmill was respectively set at 4 km·h−1 and 10 km·h−1, and the slope was set at 0° and 20°. Workstation, Polygon and MATLAB were utilized for data processing to obtain the joint angles of the German shepherd dog’s forelimbs and hind limbs. The motion frequency of the dog increases, it indicates that the joints move faster to adjust the speed of the treadmill. As the speed of the treadmill increases, the cycle and the stance phase of each limb decrease, the percentages of the stance phase in total cycle are 68.0%, 49.0%, respectively for 4 km·h−1, 10 km·h−1 at 0° slope of the treadmill and 65.6%, 47.1% for 20° slope of the treadmill, it indicates that speed affected the time characteristics, while the slope had little effect on the time characteristics. The joint angles of forelimb and hindlimb show that movement of different joints between different speeds and slopes are various.		Weijun Tian;Qi Zhang;Zhen Yang;Jiyue Wang;Ming Li;Qian Cong	2017		10.1007/978-3-319-65289-4_6	german shepherd dog;engineering;forelimb;control theory;physical medicine and rehabilitation;treadmill;gait;motion capture;kinematics	Robotics	67.51663757004182	-24.72063100008418	61279
cca27e11a55e0b5107249b5211835619bc12ef95	image-error-based level of detail for landscape visualization	level of detail;categories and subject descriptors according to acm ccs i 3 3 computer graphics picture image generation display algorithms i 3 6 computer graphics methodology and techniques graphics data structures and data types	We present a quasi-continuous level of detail method that is based on an image error metric to minimize the visual error. The method is designed for objects of high geometric complexity such as trees. By successive simplifications, it constructs a level of detail hierarchy of unconnected primitives (ellipsoids, lines) to approximate the input models at increasingly coarser levels. The hierarchy is constructed automatically without manual intervention. When rendering roughly 100k model instances at a low visual error compared to rendering the full resolution model, our method is two times faster than billboard clouds.	approximation algorithm;central processing unit;dapper;data structure;eurographics;hall-effect thruster;image quality;level of detail;overhead (computing);randomness extractor;tree (data structure);ubuntu version history	Malte Clasen;Steffen Prohaska	2010		10.2312/PE/VMV/VMV10/267-274	computer vision;vector graphics;scientific visualization;2d computer graphics;computer graphics metafile;computer science;theoretical computer science;level of detail;real-time computer graphics;graphics software;computer graphics;data visualization;3d computer graphics;computer graphics (images)	Graphics	67.85400659718864	-51.052576406940716	61298
1b44b4e6c52ce76e0efb8e6296c7da1c352662be	surface registration from range image fusion	visio per ordinador;image fusion motion estimation feature extraction image registration computer vision registers application software reverse engineering robot vision systems navigation;three dimensional display systems;range finders surface registration range image fusion computer vision;visualitzacio tridimensional informatica;info eu repo semantics article;multiple views;computer vision;distance measurement;range image;computer vision distance measurement	The registration of full 3-D models is an important task in computer vision. Range finders only reconstruct a partial view of the object. Many authors have proposed several techniques to register 3D surfaces from multiple views in which there are basically two aspects to consider. First, poor registration in which some sort of correspondences are established. Second, accurate registration in order to obtain a better solution. A survey of the most common techniques is presented and includes experimental results of some of them.	computer vision;image fusion;image registration;iterative closest point;range imaging;rough set	Carles Matabosch;Joaquim Salvi;Xavier Pinsach;Rafael García	2004	IEEE International Conference on Robotics and Automation, 2004. Proceedings. ICRA '04. 2004	10.1109/ROBOT.2004.1307227	computer vision;simulation;computer science;image registration;kanade–lucas–tomasi feature tracker;computer graphics (images)	Robotics	54.772751698551446	-48.629649247169795	61338
622d520f01bc91a0c1dbd9bb46fdc1e9977c2572	an embedded artificial skin for humanoid robots	whole body;robot sensing systems;humanoid robot;microcontrollers;serial bus communication links;sensors;skin;transducers;contact pressure distribution embedded artificial skin humanoid robots sensor interconnection smooth curved surfaces tactile measurements serial bus communication links spatial resolution;contact pressure distribution;pressure measurement;smooth curved surfaces;humanoid robots;pressure distribution;tactile sensors humanoid robots sensors;robots;tactile sensors;embedded artificial skin;sensors robot sensing systems robots skin humanoid robots transducers microcontrollers;network structure;sensor interconnection;tactile measurements;spatial resolution	A novel artificial skin for covering the whole body of a humanoid robot is presented. It provides pressure measurements and shape information about the contact surfaces between the robot and the environment. The system is based on a mesh of sensors interconnected in order to form a networked structure. Each sensor has 12 capacitive taxels, has a triangular shape and is supported by a flexible substrate in order to conform to smooth curved surfaces. Three communications ports placed along the sides of each sensor sides allow communications with adjacent sensors. The tactile measurements are sent to embed microcontroller boards using serial bus communication links. The system can adaptively reduce its spatial resolution, improving the response time. This feature is very useful for detecting the first contact very rapidly, at a lower spatial resolution, and then increase the spatial resolution in the region of contact for accurate reconstruction of the contact pressure distribution.	artificial skin;communications protocol;embedded system;experiment;humanoid robot;icub;microcontroller;polyethylene terephthalate;prototype;response time (technology);sensor;serial communication;star trek: first contact;transduction (machine learning);xfig	Giorgio Cannata;Marco Maggiali;Giorgio Metta;Giulio Sandini	2008	2008 IEEE International Conference on Multisensor Fusion and Integration for Intelligent Systems	10.1109/MFI.2008.4648033	control engineering;embedded system;computer vision;engineering	Robotics	76.57033668191303	-24.75140930642764	61351
1ef84c59190bdc46cf6baa7028d5503ca90d6bfe	design and prototyping a cable-driven multi-stage telescopic arm for mobile surveillance robots	mechanical cables;surveillance dc motors end effectors mobile robots;surveillance;pulleys;pulleys mechanical cables cameras mobile communication surveillance robot vision systems;mobile communication;end effectors design prototyping cable driven multistage telescopic arm mobile surveillance robots telescopic mechanism transmission system dc motor harmonic drive actuation system pulleys numerical analysis camera lifting tasks mobile surveillance systems;robot vision systems;cameras	Telescopic mechanism has lots of merits and is used in devices and equipment long before the appearance of robots. This paper explores the merits of telescopic mechanism and designs a cable-driven multi-stage telescopic arm with only one actuated degree of freedom (DOF) for mobile surveillance robots. We use pulleys and cables as the transmission system and use a DC motor together with harmonic drive as the actuation system. We analyze the integration of pulleys and cables to reduce cost and carry out numerical analysis by simulation and prototyping. The results show that our arm is fast, portable, stable and has low cost. We expect it to be widely employed for camera lifting tasks in mobile surveillance systems without significantly increasing costs. We also expect its general usage as an arm to support various end-effectors.	lifting scheme;numerical analysis;prototype;robot;simulation;software portability	Jianjun Yuan;Weiwei Wan;Kaiwei Chen;Qi Fang;Weijun Zhang	2014	2014 IEEE International Conference on Robotics and Biomimetics (ROBIO 2014)	10.1109/ROBIO.2014.7090604	control engineering;embedded system;simulation;mobile telephony;computer science;engineering;pulley	Robotics	71.91659093914224	-24.437914839749048	61380
97dbe397f6303aa63edefe21b6bad9e394be6d6f	distortion and quality measures for validating and generating high-order tetrahedral meshes	3d;high order unstructured methods;initial meshes;curved domains;cad;mesh optimization;metrics;mesh quality;curved high order meshes;finite element transformations;mesh validity;surface;error;article	A procedure to quantify the distortion (quality) of a high-order mesh composed of curved tetrahedral elements is presented. The proposed technique has two main applications. First, it can be used to check the validity and quality of a high-order tetrahedral mesh. Second, it allows the generation of curved meshes composed of valid and high-quality high-order tetrahedral elements. To this end, we describe a method to smooth and untangle high-order tetrahedral meshes simultaneously by minimizing the proposed mesh distortion. Moreover, we present a $$p$$ p -continuation procedure to improve the initial configuration of a high-order mesh for the optimization process. Finally, we present several results to illustrate the two main applications of the proposed technique.	distortion;mathematical optimization	Abel Gargallo-Peiró;Xevi Roca;Jaime Peraire;Josep Sarrate	2014	Engineering with Computers	10.1007/s00366-014-0370-1	mathematical optimization;computer science;volume mesh;cad;mathematics;geometry;surface;engineering drawing;t-vertices;metrics;3d computer graphics	Visualization	69.14297999787324	-44.386234792618694	61429
34be7a408e9fddc2e00c6efb2ee4e2507994e1f4	geometric modeling and processing 2006	geometric model	The fourth international conference on Geometric Modeling and Processing (GMP2006) was held on July 26–28, 2006, in Pittsburgh, PA, USA. The conference provided a forum for researchers and practitioners to present and discuss new approaches to solving geometric problems using a range of computational techniques. This special issue consists of extended versions of selected papers presented at the conference. Aigner et al. present an iterative evolution-based least-square fitting algorithm for unorganized data points using the approach of active curves adapted to the family of Pythagorean Hodograph curves. The best fitting curve is shown to be the stationary point of one differential point derived from the evolution process. Dai et al. present a theoretical analysis and explicit formulas for the errors of Hausdorff distance and normal distance of a smooth surface and its triangulation. The authors suggest Delaunay triangulation as a reasonable choice for triangulation of surfaces. Li and Ma describe a unified framework for surface subdivision based on the √ 2 splitting operator. Using various atomic operators, the proposed approach reproduces most existing surface subdivision schemes. Finally, Ni et al. present a ternary version of Catmull–Clark subdivision with special rules at extraordinary vertices. This scheme produces bounded curvature and guarantees the convex hull property at extraordinary nodes. The guest editors would like to thank all authors and reviewers who contributed to this special issue and to the conference. Our special thanks go to Professor Dave Gossard of MIT who served as the conference chair and also to the past GMP chairs who have established the high standard of the GMP conference series.	algorithm;catmull–clark subdivision surface;convex hull;data point;delaunay triangulation;gnu multiple precision arithmetic library;geometric modeling;goto;hausdorff dimension;iterative method;office chair;stationary process;unified framework	Myung-Soo Kim;Kenji Shimada	2007	Computer-Aided Design	10.1016/j.cad.2007.02.003	geometric design;computer science;geometric modeling;geometric modeling kernel;mathematics;geometry;solid modeling;geometric data analysis	Robotics	62.007565362944625	-42.618326614030636	61445
b415633db3fc9386ed83c9a306526f7d42d37269	optimizing scientist time through in situ visualization and analysis		In situ processing produces reduced size persistent representations of a simulations state while the simulation is running. The need for in situ visualization and data analysis is usually described in terms of supercomputer size and performance in relation to available storage size.	accessibility;diameter (qualifier value);imagery;optimizing compiler;simulation;supercomputer;tsunamis	John Patchett;James P. Ahrens	2018	IEEE Computer Graphics and Applications	10.1109/MCG.2018.011461533	data visualization;computer vision;computer graphics (images);visualization;artificial intelligence;feature extraction;computer science;data modeling;in situ;lossless compression;supercomputer	Visualization	69.28172701946136	-51.922796249226984	61508
33eb166894046034578289f9be0836fca30ce80d	servoing mechanisms for peg-in-hole assembly operations	vision ordenador;architecture systeme;movie camera;computer vision;computerized monitoring;camara;binocular vision;surveillance automatisee;visual feedback;arquitectura sistema;vision ordinateur;vision binocular;system architecture;vision binoculaire;videosurveillance;camera	Image-based effector servoing is a process of perception-action cycles for handling a robot effector under continual visual feedback. Apart from the primary goal of manipulating objects we apply servoing mechanisms also for determining camera features, e.g. the optical axes of cameras, and for actively changing the view, e.g. for inspecting the object shape. A peg-in-hole application is treated by a 6-DOF manipulator and a stereo camera head. The two robot components are mounted on separate platforms and can be steered independently. In the first phase (inspection phase), the robot hand carries an object into the field of view of one camera, then approaches the object along the optical axis to the camera, rotates the object for reaching an optimal view, and finally inspects the object shape in detail. In the second phase (insertion phase), the system localizes a board containing holes of different shapes, determines the relevant hole based on the extracted object shape, then approaches the object, and finally inserts it into the hole. At present, the robot system has the competence to handle cylindrical and cuboid pegs. For treating more complicated objects the system must be extended with more sophisticated strategies for the inspection and/or insertion phase.	apache axis;automation;autoregressive model;comstock–needham system;cuboid;dini derivative;emoticon;hut 8;hyperbolic absolute risk aversion;international journal of computer vision;robot;servo;stereo camera;tor messenger;velo 1;visual servoing	Josef Pauli;Arne Schmidt;Gerald Sommer	2001		10.1007/3-540-44690-7_20	binocular vision;computer vision;simulation;computer science;systems architecture;computer graphics (images)	Robotics	60.821669715646365	-34.243944264917815	61528
b98146b253aab0f9e4487e17e71a6c9211e573a0	ranging consistency based on ranging-compensated temperature-sensing sensor for inter-satellite link of navigation constellation	inter-satellite link;navigation constellation;ranging compensation;ranging consistency;temperature-sensing sensor	Global Navigation Satellite System performance can be significantly enhanced by introducing inter-satellite links (ISLs) in navigation constellation. The improvement in position, velocity, and time accuracy as well as the realization of autonomous functions requires ISL distance measurement data as the original input. To build a high-performance ISL, the ranging consistency among navigation satellites is an urgent problem to be solved. In this study, we focus on the variation in the ranging delay caused by the sensitivity of the ISL payload equipment to the ambient temperature in space and propose a simple and low-power temperature-sensing ranging compensation sensor suitable for onboard equipment. The experimental results show that, after the temperature-sensing ranging compensation of the ISL payload equipment, the ranging consistency becomes less than 0.2 ns when the temperature change is 90 °C.	alzheimer's disease assessment scale-cognitive cdisc version questionnaire;autonomous robot;conflict (psychology);experiment;field-programmable gate array;inter-satellite service;low-power broadcasting;numerous;sampling (signal processing);satellite communications;satellite viruses;satellite navigation;sensor;thermistors;velocity (software development);isl	Zhijun Meng;Jun Yang;Xiye Guo;Yongbin Zhou	2017		10.3390/s17061369	electronic engineering;satellite system;engineering;remote sensing;satellite;payload;satellite navigation;ranging	Robotics	56.919340114898255	-36.95243464512916	61560
34aa56c241e990aa5c4d0aeb120c607de4ec9a1e	interactive deformation and visualization of level set surfaces using graphics hardware	graphics hardware;real-time volume renderer operating;surface processing;visualizing level-set solution;level set;surface reconstruction;interactive volume visualization;interactive deformation;level-set isosurface data;level-set method;level-set solver;volume renderer;deformable level-set surface;level sets;real time;volume rendering;region of interest;image segmentation;data visualisation;message passing;level set method;computational geometry;sparse data;visualization	Deformable isosurfaces, implemented with level-set methods, have demonstrated a great potential in visualization for applications such as segmentation, surface processing, and surface reconstruction. Their usefulness has been limited, however, by their high computational cost and reliance on significant parameter tuning. This paper presents a solution to these challenges by describing graphics processor (GPU) based on algorithms for solving and visualizing level-set solutions at interactive rates. Our efficient GPU-based solution relies on packing the level-set isosurface data into a dynamic, sparse texture format. As the level set moves, this sparse data structure is updated via a novel GPU to CPU message passing scheme. When the level-set solver is integrated with a real-time volume renderer operating on the same packed format, a user can visualize and steer the deformable level-set surface as it evolves. In addition, the resulting isosurface can serve as a region-of-interest specifier for the volume renderer. This paper demonstrates the capabilities of this technology for interactive volume visualization and segmentation.	algorithm;algorithmic efficiency;central processing unit;computation;data structure;graphics hardware;graphics processing unit;image segmentation;isosurface;message passing;real-time transcription;scientific visualization;set packing;solver;sparse matrix;volume rendering	Aaron E. Lefohn;Joe Michael Kniss;Charles D. Hansen;Ross T. Whitaker	2003	IEEE Visualization, 2003. VIS 2003.		computer vision;computational geometry;computer science;level set;theoretical computer science;data visualization;computer graphics (images)	Visualization	69.24517019514664	-50.92076042863307	61586
c120ef81a1b35dcb066bc36e7a5e52044d332c71	pixel-based representation of geometrical distortions in a camera/projector model	optical center;stereovision;geometric distortions;modeling	A model of a camera and a projector, accounting for the inherent geometric distortions of devices, is presented. The model includes coordinates of an optical center for the device and matrices with the values and the coordinates of the individual image pixels, considered in a plane at a given distance from the optical center and perpendicular to the optical axis of the device. The parameters of the model are determined experimentally. The model can successfully be used for the purposes of computer vision.	apache axis;computer vision;distortion;experiment;pixel;video projector	Hristian Rusev	2013		10.1145/2516775.2516810	computer vision;systems modeling;computer science;stereopsis;pinhole camera model;computer graphics (images)	Vision	56.64917208009109	-50.17249370432093	61747
1e672e1c4f123e770600203d7bbee36638573c67	a new approach to multichannel audio signal acquisition and subband processing	microphones;speech;array signal processing;speaker recognition system multichannel audio signal acquisition subband processing voice signal gsc structure audio acquisition card microphone array mark iii structure subband transforms arithmetic harmonic sphericity distance computation;speaker recognition;wavelet transforms;arrays;transforms acoustic signal detection audio signal processing microphone arrays speaker recognition;microphones arrays wavelet transforms speaker recognition speech array signal processing	This paper presents results obtained when processing a voice signal collected by several microphones using GSC structure with subband processing. The acquisition has been realized in two ways: by means of an audio acquisition card and a microphone array developed for the work and through an specific system (Mark III structure). We have evaluated the results with different subband transforms (in the adaptive branch of GSC), maintaining the microphones number constant and considering all or part of the adaptive coefficients. The aim of the structure is that, in an environment with several speakers talking in front of the array, the output is as close as possible to the signal of one of them (the one placed orthogonally to the array) and that it adapt quickly to possible environment changes. Thus, by means of arithmetic-harmonic sphericity distances computation quantitative results of a speaker recognition system will be defined.	array data structure;coefficient;computation;gsc bus;microphone;speaker recognition;surround sound	Antonio Satué-Villar;Juan Fernández-Rubio	2005	2005 13th European Signal Processing Conference		electronic engineering;speech recognition;acoustics;computer science;audio signal flow	Robotics	82.72865815033549	-34.511094666713966	61937
894f4b1cf260c77e6b721a58608c2bd23dfad26f	circular arc reconstruction of digital contours with chosen hausdorff error	efficient algorithm;hausdorff distance;numerical experiment	We address the problem of constructing an approximate continuous representation of a digital contour with guarantees on the Hausdorff error between the digital shape and its reconstruction. Instead of polygonalizing the contour, we propose to reconstruct the shape with circular arcs. To do so, we exploit the recent curvature estimators. From their curvature field, we introduce a new simple and efficient algorithm to approximate a digital shape with as few arcs as possible at a given scale, specified by a maximal admissible Hausdorff distance. We show the potential of our reconstruction method with numerous experiments and we also compare our results with some recent promising approaches. Last, all these algorithms are available online for comparisons on arbitrary shapes.	approximation algorithm;contour line;experiment;global motion compensation;hausdorff dimension;maximal set;run time (program lifecycle phase)	Bertrand Kerautret;Jacques-Olivier Lachaud;Thanh Phuong Nguyen	2011		10.1007/978-3-642-19867-0_21	hausdorff distance;mathematical optimization;combinatorics;topology;hausdorff dimension;mathematics;geometry;hausdorff measure	Vision	67.6453960926491	-43.96124657662131	61995
02894643ecc64c7dc5cc49ac780274a8a5fc9fc5	lighting grid hierarchy for self-illuminating explosions		Rendering explosions with self-illumination is a challenging problem. Explosions contain animated volumetric light sources immersed in animated smoke that cast volumetric shadows, which play an essential role and are expensive to compute. We propose an efficient solution that redefines this problem as rendering with many animated lights by converting the volumetric lighting data into a large number of point lights. Focusing on temporal coherency to avoid flickering in animations, we introduce lighting grid hierarchy for approximating the volumetric illumination at different resolutions. Using this structure we can efficiently approximate the lighting at any point inside or outside of the explosion volume as a mixture of lighting contributions from all levels of the hierarchy. As a result, we are able to capture high-frequency details of local illumination, as well as the potentially strong impact of distant illumination. Most importantly, this hierarchical structure allows us to efficiently precompute volumetric shadows, which substantially accelerates the lighting computation. Finally, we provide a scalable approach for computing the multiple scattering of light within the smoke volume using our lighting grid hierarchy. Temporal coherency is achieved by relying on continuous formulations at all stages of the lighting approximation. We show that our method is efficient and effective approximating the self-illumination of explosions with visually indistinguishable results, as compared to path tracing. We also show that our method can be applied to other problems involving a large number of (animated) point lights.	approximation algorithm;carder.su;computation;control knob;definition;flicker (screen);illumination (image);list of common shading algorithms;path tracing;rendering (computer graphics);ron sun;scalability;shadow volume;subsurface scattering;volumetric lighting	Can Yuksel;Cem Yuksel	2017	ACM Trans. Graph.	10.1145/3072959.3073604	grid;computer vision;artificial intelligence;volumetric lighting;mathematics;image-based lighting;rendering (computer graphics);scalability;hierarchy;light scattering;path tracing	Graphics	64.4644251232877	-51.23192932248151	62051
f7dd8a5a20f35640e5f356dad33af4dc4f6a82c9	automatic g1 arc spline interpolation for closed point set	tecnologia electronica telecomunicaciones;computacion informatica;evaluation method;grupo de excelencia;satisfiability;g1 continuity;ciencias basicas y experimentales;circular arc interpolation;closed point set;weight function;tecnologias;spline interpolation;arc spline	A method for generating an interpolation closed G arc spline on a given closed point set is presented. For the odd case, i.e. when the number of the given points is odd, this paper disproves the traditional opinion that there is only one closed G arc spline interpolating the given points. In fact, the number of the resultant closed G arc splines fulfilling the interpolation condition for the odd case is exactly two. We provide an evaluation method based on the arc length as well such that the choice between those two arc splines is made automatically. For the even case, i.e. when the number of the given points is even, the points are automatically moved based on weight functions such that the interpolation condition for generating closed G arc splines is satisfied, and that the adjustment is small. And then, the G arc spline is constructed such that the radii of the arcs in the spline are close to each other. Examples are given to illustrate the method. q 2003 Elsevier Ltd. All rights reserved.	resultant;spline (mathematics);spline interpolation;weight function	Xiao-Diao Chen;Jun-Hai Yong;Guo-Qin Zheng;Jia-Guang Sun	2004	Computer-Aided Design	10.1016/j.cad.2003.12.001	spline interpolation;mathematical optimization;combinatorics;weight function;perfect spline;smoothing spline;interpolation;hermite spline;mathematics;geometry;thin plate spline;polyharmonic spline;statistics;satisfiability	Robotics	69.66981564604178	-40.16485327672435	62061
7862bc432633e25555a0f50209c5688bd2e1b614	development of image stabilization system for remote operation of walking robots	ccd camera;oscillations;gyroscopes;legged locomotion;mobile robot;legged locomotion mobile robots robot vision systems cameras attitude control image sensors robot sensing systems inspection power generation vehicles;ccd image sensors;mine detection;power plant;12 ms image stabilization system remote operation walking robots terrain variation adaptability mobile robots hazardous tasks mine detection atomic power plant inspection visual information high speed ccd camera gyrosensors oscillation estimation template matching method pentium mmx template matching calculation external attitude sensor damping control attitude control attitude sensor;attitude control;robot vision;long distance;operating system;image stabilization;walking robot;telerobotics;template matching;high speed;gyroscopes legged locomotion telerobotics robot vision ccd image sensors	Walking robots have high adaptability for terrain variation, and thus, have been expected as e ective moving platform on uneven terrain, stairs, forest, marshy surface, and on ice. On the other hand, mobile robots that perform several hazardous tasks such as mine detection or the inspection of an atomic power plant are typically controlled by operators from distant places. For a remote operation system, use of visual information from a camera mounted on a robot body is very useful. However, unlike wheeled vehicles, the camera mounted on the walking robot oscillates because of the impact of walking, and the obtained unstable images cause inferior operation performance. In this paper, we introduce an image stabilization system for remote operation of walking robots using a high speed CCD camera and gyrosensors. The image stabilization is executed in two phases, that is, the estimation of the amount of oscillation by the combination of the template matching method and gyrosensors, and change of the display region. Pentium MMX instruction is used for template matching calculation, and the estimated amount of oscillation is outputted in every 12 [msec.]. Furthermore, developed image stabilization mechanism can be used an external attitude sensor from the visual information, and the damping control of the robot body while walking is also possible. Experimental results showed stabilized images that eliminates the oscillation component are taken even when the robot moves dynamically or in long distance, and veri ed that the performance of attitude control using the developed image stabilization system is almost same as the case using an attitude sensor.	charge-coupled device;control theory;mobile robot;operating system;p5 (microarchitecture);pentium 4;template matching	Ryo Kurazume;Shigeo Hirose	2000		10.1109/ROBOT.2000.844865	telerobotics;control engineering;mobile robot;power station;computer vision;simulation;template matching;gyroscope;computer science;engineering;artificial intelligence;attitude control;charge-coupled device;oscillation;image stabilization	Robotics	57.94083435224715	-33.62512436127828	62065
567bf6cb15c5a0533c69973a4bce931c0ea6d4c4	vertical glider robots for subsea equipment delivery	task performance;oil and gas industry;underwater vehicles aerospace robotics lifts mobile robots path planning;sensors;underwater vehicles;path planning;elevators;vehicles cameras elevators navigation sensors sea measurements marine vehicles;mobile robots;navigation;performance improvement;marine vehicles;lifts;aerospace robotics;model scale experiment vertical glider robot subsea equipment delivery underwater vehicle active steering navigation instrumentation at sea mission requirement prototype device;vehicles;remotely operated vehicle;deep water;high performance;cameras;sea measurements	We have developed an underwater vehicle that offers significant performance improvements over existing subsea elevators. Our Vertical Glider Robot falls under its own weight to a precise location on the seafloor, employing streamlining, active steering, and basic navigation instrumentation. We examine typical at-sea mission requirements, mention several key governing parameters, and outline our design approach. We then describe a prototype device, and present results from model-scale experiments.	experiment;glider (conway's life);prototype;requirement;robot	Brooks L. Reed;Charles Ambler;Julio Guerrero;Franz S. Hover	2011	2011 IEEE International Conference on Robotics and Automation	10.1109/ICRA.2011.5980486	mobile robot;navigation;simulation;remotely operated vehicle;computer science;engineering;sensor;artificial intelligence;aeronautics;motion planning;marine engineering	Robotics	56.70281327126818	-30.38458319400302	62127
c028b9669f7401508bfb689b1a415970c98af09b	design of a continuum wearable robot for shoulder rehabilitation		A wearable robot for rehabilitation therapy is often shared by a group of patients in a clinic. If the wearable robot only consists of rigid links, the link dimensions usually need to be adjusted from time to time to fit different patients. It is then difficult to make sure these on-site adjustments could introduce the desired kinematic compatibility between the robot and each individual patient. A previous investigation shows it is possible to construct a compliant wearable robot that can provide Anatomy Adaptive Assistances (AAA), which means the robot passively adapts to different patient anatomies while providing consistent motion assistances. However, the previous design also possesses drawbacks such as limited motion ranges and limited payload capabilities. This paper presents a kinematics-based type synthesis for the construction of a new continuum wearable shoulder robot, aiming at overcoming these drawbacks as well as maintaining the capabilities of providing AAA. Three structural concepts of such a continuum wearable shoulder robot are studied through kinematic modeling. One concept is eventually selected based on the comparison results. Preliminary experiments are also presented to demonstrate the feasibility of the selected design.		Kai Xu;Yilin Wang;Zhixiong Yang	2014		10.1007/978-3-319-13966-1_36	control engineering;simulation;engineering;biological engineering	Robotics	71.98655575182042	-27.342223300098112	62147
fc07f302c6009345cb73e516bad4b18b5719ced1	radar cross-section reduction via route planning and intelligent control	aircraft control;observability radar cross section reduction route planning intelligent control autonomous precision guided munitions radar threat environment yaw angles bank angles;missile control;remotely operated vehicles;intelligent control;radar cross section intelligent control aggregates weapons observability vehicle dynamics airborne radar motion planning aerodynamics;military aircraft;radar cross section;missile control radar cross sections intelligent control aircraft control military aircraft remotely operated vehicles;radar cross sections;route planning	Establishes a methodology for minimizing the peak and/or aggregate radar cross sections (RCSs) of autonomous precision guided munitions (APGMs) as they ingress to a selected target through a radar threat environment. This research demonstrates how route planning may be combined with the simultaneous specification of aerodynamically feasible yaw and bank angles to significantly reduce APGM observability. The approach described in the paper has the potential to considerably enhance APGM effectiveness against enemy defense systems.	intelligent control;radar	Frank W. Moore	2002	IEEE Trans. Contr. Sys. Techn.	10.1109/TCST.2002.801879	remotely operated underwater vehicle;control engineering;man-portable radar;radar engineering details;simulation;radar lock-on;radar configurations and types;semi-active radar homing;radar warning receiver;computer science;engineering;air traffic control radar beacon system;3d radar;procedural control;radar cross-section;remote sensing;intelligent control	Robotics	54.80235991072732	-26.805473338782914	62244
2a5a360bf041e4150493e1a6174a90ec9a04f58b	mobile microrobot characterization through performance-based competitions	intelligent sensor;microrobots;performance characterization;robot competition;autonomous navigation;microelectromechanical system;microrobotics;medical diagnosis;national institute of standards and technology	Recent advances in the design and fabrication of microelectromechanical systems (MEMS) have enabled the development of mobile microrobots that can autonomously navigate and manipulate in controlled environments. It is expected that this technology will be critical in applications as varied as intelligent sensor networks, in vivo medical diagnosis and treatment, and adaptive microelectronics. However, many challenges remain, particularly with respect to locomotion, power storage, embedded intelligence, and motion measurement. As a result, the National Institute of Standards and Technology has organized performance-based competitions for mobile microrobots that are designed to: 1) accelerate microrobot development by providing researchers a venue to demonstrate and observe novel technologies, 2) reveal the most pressing technical challenges, and 3) evaluate the most successful methods for locomotion and manipulation at the microscale (e.g., actuation techniques for crawling). This paper will discuss the goals and structure of the competition, results from past competitions, and plans to make performance characterization methods an integral component of future competitions.	chris sawyer's locomotion;embedded system;microbotics;microelectromechanical systems;venue (sound system);video-in video-out	Jason J. Gorman;Craig D. McGray;Richard A. Allen	2009		10.1145/1865909.1865934	simulation;engineering;nanotechnology;biological engineering	Robotics	66.92642228112416	-28.648798055108767	62273
b342023424394a825685f16d77823aa36635f6ee	combining arm and hand metrics for sensible grasp selection	robot sensing systems;grasping;measurement;shape;robustness;planning	In this paper we propose an approach to robot grasp prioritization based on a combined arm-and-hand metric. Most traditional approaches evaluate grasps based on hand-centric metrics such as force-closure, finger spread, contact surface area and similar measures. While these are certainly important factors to predict the robustness of a grasp, they do not carry information on the feasibility of the reaching action needed to execute the grasp. Based on our observations of physical pick-up experiments, we suggest that the execution success of a pick-up task is partially dependant on the easiness of the reaching movement. We present our metric, which combines 2 measures involving arm-kinematics and an existing hand heuristic metric. Results of simulated as well as physical experiments in our robot, Crichton, are presented.	experiment;heuristic (computer science);pick operating system;pose (computer vision);robot;smt placement equipment;simulation	Ana C. Huamán Quispe;Heni Ben Amor;Henrik I. Christensen	2016	2016 IEEE International Conference on Automation Science and Engineering (CASE)	10.1109/COASE.2016.7743537	computer vision;computer science;artificial intelligence;machine learning	Robotics	71.48026667359849	-28.212122265890088	62315
68e609a903632502ec4ff01bd728edb98cc0face	hierarchical vortex regions in swirling flow	computer graphics i 3 8 applications physical sciences and engineering j 2 physics;swirling flow	We propose a new criterion to characterize hierarchical two-dimensional vortex regions induced by swirling motion. Central to the definition are closed loops that intersect the flow field at a constant angle. The union of loops belonging to the same area of swirling motion defines a vortex region. These regions are disjunct but may be nested, thus introducing a spatial hierarchy of vortex regions. We present a parameter free algorithm for the identification of these regions. Since they are not restricted to staror convex-shaped geometries, we are able to identify also intricate regions, e.g., of elongated vortices. Computing an integrated value for each loop and mapping these values to a vortex region, introduces new ways for visualizing or filtering the vortex regions. Exemplary, an application based on the Rankine vortex model is presented. We apply our method to several CFD datasets and compare our results to existing approaches.	adobe streamline;algorithm;arithmetical hierarchy;blue (queue management algorithm);clutter;computational fluid dynamics;critical point (network science);foreach loop;gradient;simulation;turbulence;vergence;vortex	Christoph Petz;Jens Kasten;Steffen Prohaska;Hans-Christian Hege	2009	Comput. Graph. Forum	10.1111/j.1467-8659.2009.01463.x	simulation;computer science;geometry	Visualization	72.85681076929504	-45.20407498470845	62332
8e83a425befadecd2ddb272ef4d408c656538be3	predicting the next best view for 3d mesh refinement		3D reconstruction is a core task in many applications such as robot navigation or sites inspections. Finding the best poses to capture part of the scene is one of the most challenging topic that goes under the name of Next Best View. Recently many volumetric methods have been proposed; they choose the Next Best View by reasoning into a 3D voxelized space and by finding which pose minimizes the uncertainty decoded into the voxels. Such methods are effective but they do not scale well since the underlaying representation requires a huge amount of memory. In this paper we propose a novel mesh-based approach that focuses the next best view on the worst reconstructed region of the environment. We define a photo-consistent index to evaluate the model accuracy, and an energy function over the worst regions of the mesh that takes into account the mutual parallax with respect to the previous cameras, the angle of incidence of the viewing ray to the surface and the visibility of the region. We tested our approach over a well known dataset and achieve state-of-the-art results.	3d printing;3d reconstruction;algorithm;incidence matrix;mathematical optimization;mesh networking;parallax;precomputation;refinement (computing);robotic mapping;voxel	Luca Morreale;Andrea Romanoni;Matteo Matteucci	2018		10.1007/978-3-030-01370-7_59	visibility;3d reconstruction;pattern recognition;voxel;parallax;artificial intelligence;angle of incidence;computer science;polygon mesh	Vision	56.73613759366694	-46.903857690516524	62360
f2e1627dd26809c13e424b395c3444ff9b3d1e7f	active self-calibration of hand-mounted laser range finders	calibration;unknown orientation;active self-calibration;unknown position;laser ranging;robotic hand-mounted laser range finders;active motion;manipulators;systematic measurement errors;nonlinear equations;robot kinematics;laser radar;measurement errors;measurement error;nonlinear equation	In this paper, we propose a method for self-calibration of robotic hand-mounted laser range finders by means of active motion of the robot. Through range-measuring a plane of unknown position and orientation, the mounting parameters of the range finders and the coordinates of the world planes are estimated. Systematic measurement errors can also be calibrated at the same time. The approach is fully autonomous, in that no initial guesses of the unknown parameters are to be provided from the outside by humans for the solution of a set of nonlinear equations. In fact, the initial values are all found in closed forms by the algorithm itself. Sufficient conditions for a unique solution are derived in terms of controlled motion sequences. Experimental results in both a simulated and a real environments are reported		Guo-Qing Wei;Gerd Hirzinger	1997		10.1109/ROBOT.1997.606709	control engineering;computer vision;nonlinear system;computer science;engineering;artificial intelligence;control theory;mathematics;observational error	Robotics	56.29553885796875	-35.99611980157079	62364
683d47a1ece96f0f98f397784b3dc0b46c9f5fa9	manual welding with robotic assistance compared to conventional manual welding		This paper demonstrates the effectiveness of impedance compensation type robotic assistance, presented in a previous work, by comparing manual welding with robotic assistance to conventional manual welding without a robot. The novelty of the current paper is comparison of two sets of data that were published in separate studies, but were not yet compared to each other. One of these previous studies had demonstrated the effectiveness of the robotic assistance in comparison to welding with the robot interactively while the assistance-scheme was off, but not to the case of conventional manual welding as applied every-day in workshops without a robot. The other previous work had collecting welding data with a motion capture system while conventional manual welding in order to demonstrate the differences between novice and professional welders. The comparison presented in the current paper demonstrates that the robotic assistance significantly improves the performance of novice welders in comparison to conventional welding without a robot, whereas the performance of the professional welders remains almost constant across conventional welding and with robotic assistance. The results of this paper show the effectiveness of physically interactive robotic assistance technology to improve the performance of novice welders in the every-day industrial task of manual welding.		Mustafa Suphi Erden	2018	2018 IEEE 14th International Conference on Automation Science and Engineering (CASE)	10.1109/COASE.2018.8560489	welding;control engineering;computer science	Robotics	73.3943427761287	-27.850587921995142	62479
354b697ed6e453d55b67b9969eec2cb3217999b4	topologically faithful fitting of simple closed curves	simple closed curves;homeomorphic mapping;implicit representation;certain advantage;explicit representation;special case;correct topology;inside-outside function;unit circle;topologically faithful fitting;simple closed curve;topology;curve fitting	Implicit representations of curves have certain advantages over explicit representation, one of them being the ability to determine with ease whether a point is inside or outside the curve (inside-outside functions). However, save for some special cases, it is not known how to construct implicit representations which are guaranteed to preserve the curve's topology. As a result, points may be erroneously classified with respect to the curve. The paper offers to overcome this problem by using a representation which is guaranteed to yield the correct topology of a simple closed curve by using homeomorphic mappings of the plane to itself. If such a map carries the curve onto the unit circle, then a point is inside the curve if and only if its image is inside the unit circle.	anatomy, regional;approximation algorithm;classification;closed-world assumption;complexity;computation;curve fitting;description;grapes (dietary);map;numerical analysis;outlines (document)	Daniel Keren	2004	IEEE Transactions on Pattern Analysis and Machine Intelligence	10.1109/TPAMI.2004.10006	computer vision;combinatorics;discrete mathematics;machine learning;mathematics;geometry;jordan curve theorem;curve orientation;curve fitting	Robotics	70.89486210536522	-41.81111691614752	62485
074bb7ade720e1b8b501dda3e4b2f622d6a36ccb	visualizing local vector field topology	engineering;piecewise linear;mathematics;computation fluid dynamics;mathematical analysis;computational fluid dynamics;visualization;local structure;feature extraction;topological methods;vector field;vector field topology	The visualization of vector fields has attracted much attention over the last decade due to the vast variety of applications in science and engineering. Topological methods have been used intensively for global structure extraction and analysis. Recently, there has been a growing interest in local structure analysis due to its connection to automatic feature extraction and speed. We present an algorithm that extracts local topological structure of arbitrary regions in a two-dimensional vector field. It is based on a mathematical analysis of the topological vector field structure in these regions. The algorithm deals with piecewise linear vector fields and arbitrary polygonal regions. We have tested the algorithm for well known analytic vector fields and data sets resulting from computational fluid dynamics.		Gerik Scheuermann;Bernd Hamann;Kenneth I. Joy;Wolfgang Kollmann	2000	J. Electronic Imaging	10.1117/1.1289350	mathematical optimization;vector field;computational topology;visualization;topology;piecewise linear function;feature extraction;computational fluid dynamics;computer science;mathematics;weak topology;computational physics;digital topology	Theory	74.87240659459496	-44.189850070240205	62613
658e8a562f8c79c853d60190ab53158b3f8a5404	differentiating alcohol-induced driving behavior using steering wheel signals	sensors;drunk driving;steering systems entropy road safety road traffic control sensors statistical analysis;road traffic control;condition monitoring real time systems human factors simulation genetic algorithms;statistical analysis;differentiating capability alcohol induced driving behavior steering wheel signal alcohol induced driving impairment vehicle based sensor signal road safety high fidelity driving simulator steering wheel movement simple statistics mean standard deviation sample entropy lyapunov exponent;quantitative analysis;genetic algorithms;entropy;road safety;driver performance;steering wheels;sample entropy alcohol induced impairment nonlinear invariant measures parallel genetic algorithm pga;steering systems	Detection of alcohol-induced driving impairment through vehicle-based sensor signals is of paramount importance for road safety. To differentiate the driving conditions with and without alcohol-induced impairment, data were collected from 108 drivers under both conditions in a high-fidelity driving simulator. With this data set, various quantitative measures of steering wheel movement, including not only simple statistics such as the mean and the standard deviation but nonlinear dynamic invariant measures such as sample entropy and Lyapunov exponent as well, are compared in terms of their differentiating capabilities. Nonlinear invariant measures are more robust and consistent than the simple measures in differentiating the impairment. Furthermore, people respond to alcohol-induced impairment quite differently, and for a certain group of people, the alcohol-induced impairment can be well detected using these nonlinear invariant measures. Many interesting insights into characterizing the effect of alcohol on driving behavior are obtained in this paper. This paper lays a foundation for the future development of a real-time detection method for alcohol-induced impairment.	algorithm;combinatorial optimization;driving simulator;entropy (information theory);lyapunov fractal;mathematical optimization;nonlinear system;real-time transcription;sample entropy;sensor;simulation;steering wheel	Devashish Das;Shiyu Zhou;John D. Lee	2012	IEEE Transactions on Intelligent Transportation Systems	10.1109/TITS.2012.2188891	control engineering;entropy;simulation;genetic algorithm;computer science;quantitative analysis;engineering;sensor;forensic engineering;statistics	Robotics	68.57132361815808	-31.102233912415738	62627
08c7e9abd36ecc2ae8d3557d33170531a8aac32b	rendering trees with indirect lighting in real time	and texture;real time;shadowing;i 3 7 computer graphics color;shading	High quality lighting is one of the challenges for interactive tree rendering. To this end, this paper presents a lighting model allowing real-time rendering of trees with convincing indirect lighting. Rather than defining an empirical model to mimic lighting of real trees, we work at a lower level by modeling the spatial distribution of leaves and by assigning them probabilistic properties. We focus mainly on precise low-frequency lighting that our eyes are more sensitive to and we add high-frequency details afterwards. The resulting model is efficient and simple to implement on a GPU.	global illumination;interaction;real-time clock;shading	Kevin Boulanger;Kadi Bouatouch;Sumanta N. Pattanaik	2008	Comput. Graph. Forum	10.1111/j.1467-8659.2008.01257.x	computer vision;shading;simulation;rendering;computer science;volumetric lighting;per-pixel lighting;image-based lighting;computer graphics (images)	Graphics	64.17683081791091	-50.69649392441202	62684
2ff842b228476cc4c9c1dc3562c7452b5bfed5d1	distributed control architecture for smart surfaces	object recognition;manipulators;sensors image reconstruction surface reconstruction distributed control computer architecture manipulators image sensors;intelligent actuators;object recognition closed loop systems decentralised control distributed control image reconstruction intelligent actuators microactuators microassembling micromanipulators;sensors;closed loop systems;closed loop control;image sensors;surface reconstruction;computer architecture;microactuators;microelectromechanical system actuator arrays distributed control architecture smart surface part recognition closed loop control decentralized cell object reconstruction object recognition contactless distributed manipulation device mems arrayed manipulation surface control microsystem assembly line;microelectromechanical system actuator arrays;decentralised control;image reconstruction;part recognition;micromanipulators;microassembling;object reconstruction;distributed control architecture;mems arrayed manipulation surface control;peer to peer;contactless distributed manipulation device;distributed control;microsystem assembly line;decentralized cell;smart surface	This paper presents a distributed control architecture to perform part recognition and closed-loop control of a distributed manipulation device. This architecture is based on decentralized cells able to communicate with their four neighbors thanks to peer-to-peer links. Various original algorithms are proposed to reconstruct, recognize and convey the object levitating on a new contactless distributed manipulation device. Experimental results show that each algorithm does a good job for itself and that all the algorithms together succeed in sorting and conveying the objects to their final destination. In the future, this architecture may be used to control MEMS-arrayed manipulation surfaces in order to develop Smart Surfaces, for conveying, fine positioning and sorting of very small parts for micro-systems assembly lines.	algorithm;contactless smart card;control theory;distributed computing;distributed control system;electronic circuit;mos technology agnus;microelectromechanical systems;peer-to-peer;sensor;sorting	Kahina Boutoustous;Guillaume J. Laurent;Eugen Dedu;Laëtitia Matignon;Julien Bourgeois;Nadine Le Fort-Piat	2010	2010 IEEE/RSJ International Conference on Intelligent Robots and Systems	10.1109/IROS.2010.5650668	iterative reconstruction;control engineering;electronic engineering;surface reconstruction;computer science;engineering;sensor;cognitive neuroscience of visual object recognition;image sensor;control theory	Robotics	63.43656404903546	-34.877441614902644	62733
09c7cd28e058f7290aefdcc514f87738e390a964	detecting and parsing architecture at city scale from range data	grammar;object detection image representation;urban environment;pediatrics;range data;complex structures;3d point cloud;parsing architecture;complex structure;layout;computer architecture;hierarchical representation;large scale;three dimensional displays;image representation;clouds;semantic description;production;cities and towns;cities and towns buildings clouds laboratories large scale systems robustness computer architecture computer science layout encoding;robustness;tree representation;point cloud;dependency parsing;computer science;semantic decomposition;complex structures parsing architecture city scale unorganized 3d point clouds hierarchical representation large scale urban environment tree representation semantic decomposition;encoding;city scale;buildings;object detection;large scale urban environment;large scale systems;unorganized 3d point clouds	We present a method for detecting and parsing buildings from unorganized 3D point clouds into a compact, hierarchical representation that is useful for high-level tasks. The input is a set of range measurements that cover large-scale urban environment. The desired output is a set of parse trees, such that each tree represents a semantic decomposition of a building – the nodes are roof surfaces as well as volumetric parts inferred from the observable surfaces. We model the above problem using a simple and generic grammar and use an efficient dependency parsing algorithm to generate the desired semantic description. We show how to learn the parameters of this simple grammar in order to produce correct parses of complex structures. We are able to apply our model on large point clouds and parse an entire city.	algorithm;high- and low-level;observable;parse tree;parsing;point cloud;polynomial;sensor;shlaer–mellor method	Alexander Toshev;Philippos Mordohai;Ben Taskar	2010	2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition	10.1109/CVPR.2010.5540187	layout;parser combinator;computer science;bottom-up parsing;theoretical computer science;machine learning;s-attributed grammar;data mining;point cloud;grammar;generalized complex structure;encoding;robustness;dependency grammar	Vision	57.897840866737546	-45.72096657069668	62756
db95c45a38ba8b4879324ca5844d93e304b9d55e	dynamic deformable models for enhanced haptic rendering in virtual environments	phantom haptic device dynamic deformable models enhanced haptic rendering virtual environments deformable model implementations geometric deformations realistic force feedback shape coverage haptic feedback global deformations force feedback shape class deformable superquadrics desuq compact geometric representation realistic haptic viscoelastic feedback deformable bodies lagrange equations ghost libraries;physics based modeling;haptic device;virtual reality;deformable models haptic interfaces force feedback shape solid modeling virtual environment viscosity elasticity lagrangian functions equations;deformable models;viscoelasticity;haptics;force feedback;haptic rendering;haptic feedback;virtual environment;haptic interfaces;rendering computer graphics;deformable model;interactive devices virtual reality rendering computer graphics haptic interfaces force feedback viscoelasticity;interactive devices	Currently there are no deformable model implementations that model a wide range of geometric deformations while providing realistic force feedback for use in virtual environments with haptics. The few models that exist are computationally very expensive, are limited in terms of shape coverage and do not provide proper haptic feedback. In this paper we use dynamic deformable models with local and global deformations governed by physical principles in order to provide e cient and true force feedback. We will extend the shape class of Deformable Superquadrics(DeSuq) to provide compact geometric representation using few parameters, while at the same time provide realistic haptic viscoelastic feedback. Dynamics associated with rigid and deformable bodies are modeled by the use of the Lagrange equations. Implementation of these is currently under progress using GHOST libraries on a PHANToM haptic device.	collision detection;haptic technology;immersion (virtual reality);lagrange multiplier;library (computing);simulation;superquadrics;surgery simulator;virtual reality	Rungun Ramanathan;Dimitris N. Metaxas	2000		10.1109/VR.2000.840360	computer vision;simulation;computer science;artificial intelligence;virtual reality;haptic technology;computer graphics (images)	Visualization	70.01602325176341	-47.18653438662484	62844
652e3b7e7695443a12a9cea6b1c62e63d34127bd	data-driven online decision making for autonomous manipulation	abt schaal	One of the main challenges in autonomous manipulation is to generate appropriate multi-modal reference trajectories that enable feedback controllers to compute control commands that compensate for unmodeled perturbations and therefore to achieve the task at hand. We propose a data-driven approach to incrementally acquire reference signals from experience and decide online when and to which successive behavior to switch, ensuring successful task execution. We reformulate this online decision making problem as a pair of related classification problems. Both process the current sensor readings, composed from multiple sensor modalities, in real-time (at 30 Hz). Our approach exploits that movement generation can dictate sensor feedback. Thus, enforcing stereotypical behavior will yield stereotypical sensory events which can be accumulated and stored along with the movement plan. Such movement primitives, augmented with sensor experience, are called Associative Skill Memories (ASMs). Sensor experience consists of (real) sensors, including haptic, auditory information and visual information, as well as additional (virtual) features. We show that our approach can be used to teach dexterous tasks, e.g. a bimanual manipulation task on a real platform that requires precise manipulation of relatively small objects. Task execution is robust against perturbation and sensor noise, because our method decides online whether or not to switch to alternative ASMs due to unexpected sensory signals.	autonomous robot;exploit (computer security);haptic technology;image noise;modal logic;perturbation theory;real-time clock;sensor	Daniel Kappler;Peter Pastor;Mrinal Kalakrishnan;Manuel Wüthrich;Stefan Schaal	2015		10.15607/RSS.2015.XI.044	computer science	Robotics	60.768315456388564	-28.300771364105668	62963
232cc32d023866c12acff736daa994786e97ac36	digi d ürer — a digital engraving system	curva;sistema experto;affichage;expert systems;visualizacion;curve evolution;imagen medio tinte;computer graphics;image demi teinte;bilevel display;evolucion;half tone image;courbe;intelligence artificielle;systeme numerique;grafismo;graphisme;curve;potential field;digital halftone;digital system;eikonal equation;display;graphism;sistema numerico;artificial intelligence;inteligencia artificial;systeme expert;affichage 2 niveaux;grafico computadora;infographie;evolution;expert system	A variety of halftone methods for reproducing gray-level images on bilevel display media have been proposed. The output of even the best of these falls far short of the quality achieved on similar resolution media in man-made engravings. We introduceDig i Dürer — a digital engraving/halftoning system. For a gray-level image input, the system produces a bilevel (black and white only) picture, which has the appearance of an engraving of the input. The system produces high-quality output, even when the graphic elements of the halftone are visible, and both the quality and style of the output can be improved or customized either by using further information on the image content or by interactive user intervention. The heart ofDig i Dürer is a curve evolution algorithm generating halftones by controlling the density of line elements, which are the level contours of a potential field induced by the image via an Eikonal equation. Since the basic version of the system produces rather rough results, further capabilities were added to allow for user intervention and the use of image content information. Extensions to graphic elements other than lines are also feasible.	algorithm;display advertising	Yachin Pnueli;Alfred M. Bruckstein	1994	The Visual Computer	10.1007/BF01901584	computer vision;simulation;eikonal equation;computer science;artificial intelligence;evolution;curve;computer graphics;expert system;algorithm;computer graphics (images)	Graphics	62.8518964098509	-48.05339215208101	62972
efe92c006dc29b2a9490947c79f11fc6f9cd6939	cepstral smoothing of separated signals for underdetermined speech separation	underdetermined speech separation;cepstral analysis smoothing methods cascading style sheets noise reduction blind source separation time frequency analysis speech coding filters speech enhancement distortion;speech signal;blind source separation;speech processing;time frequency;speech;time frequency mask;musical noise reduction method underdetermined speech separation blind source separation time frequency mask cepstral smoothing of spectral mask speech signal;musical noise reduction method;interference suppression;speech processing blind source separation cepstral analysis interference suppression;smoothing methods;cepstral analysis;noise reduction;cepstral smoothing of spectral mask;source separation;time frequency analysis;evaluation studies;noise	Musical noise is a typical problem with blind source separation using a time-frequency mask. Recently, the cepstral smoothing of spectral masks (CSM) was proposed. Based on the idea of smoothing in the cepstral domain, this paper proposes the cepstral smoothing of separated signals (CSS) on the assumption that a cepstral representation better reflects the characteristics of speech signals than those of masks (or filter gains). We also report a comparative evaluation study of CSM and CSS with other musical noise reduction methods. Our experimental results show that CSM is effective for musical noise reduction, but the target speech was relatively distorted. On the other hand, our proposed CSS produced less distorted target signals with the same musical noise reduction as CSM.	blind signal separation;cascading style sheets;cepstrum;community climate system model;noise reduction;signal-to-noise ratio;smoothing;source separation;unified extensible firmware interface	Yumi Ansa;Shoko Araki;Shoji Makino;Tomohiro Nakatani;Takeshi Yamada;Atsushi Nakamura;Nobuhiko Kitawaki	2010	Proceedings of 2010 IEEE International Symposium on Circuits and Systems	10.1109/ISCAS.2010.5537118	speech recognition;time–frequency analysis;computer science;pattern recognition;speech processing;quantum mechanics	EDA	82.68121194345923	-34.979274939370974	62973
78d362f2ab03cb2579a75497bace7117ced91508	developable polynomial surface approximation to smooth surfaces for fabrication parameters of a large curved shell plate by differential evolution	singly doubly curved shell plate;differential evolution;gaussian curvature;surface representation;optimization problem;process parameters;developable surface;roll bending process;surface approximation	This paper presents a simple and efficient method to approximate a developable surface to a compound design surface by a polynomial. It is required to predict a final shape of roll bending in the fabrication of a curved shell plate. The roll bending process usually makes the cylindrical or conical curvature from an initial flat plate. It means that the final shape is developable or the surface representation has zero Gaussian curvature. The fabrication shape is important in order to estimate process parameters of roller bending. An optimization problem is formulated to determine the polynomial surface which is in the closest proximity to the design surface or the given shell plate, which is subjected to developability. The results and the efficiency of this algorithm are verified and evaluated by applying it to some shell plates which are obtained from a real ship model. The predicted bending shape becomes fundamental information in determining more process parameters for the fabrication of a compound curved shell plate. © 2008 Elsevier Ltd. All rights reserved.	approximation algorithm;computation;differential evolution;mathematical optimization;optimization problem;polynomial	Jong Sung Yoon;Cheolho Ryu;Jang Hyun Lee	2008	Computer-Aided Design	10.1016/j.cad.2008.05.007	differential evolution;optimization problem;gaussian curvature;mathematical optimization;developable surface;bending of plates;mathematics;geometry;tangential developable;engineering drawing	Robotics	69.46348654227388	-38.039516859529854	63089
4debd86608c626dbf43c54d10b7bfadcc7925949	a polar initial alignment algorithm for unmanned underwater vehicles	grid frame;initial alignment;polar region;unmanned underwater vehicle	Due to its highly autonomy, the strapdown inertial navigation system (SINS) is widely used in unmanned underwater vehicles (UUV) navigation. Initial alignment is crucial because the initial alignment results will be used as the initial SINS value, which might affect the subsequent SINS results. Due to the rapid convergence of Earth meridians, there is a calculation overflow in conventional initial alignment algorithms, making conventional initial algorithms are invalid for polar UUV navigation. To overcome these problems, a polar initial alignment algorithm for UUV is proposed in this paper, which consists of coarse and fine alignment algorithms. Based on the principle of the conical slow drift of gravity, the coarse alignment algorithm is derived under the grid frame. By choosing the velocity and attitude as the measurement, the fine alignment with the Kalman filter (KF) is derived under the grid frame. Simulation and experiment are realized among polar, conventional and transversal initial alignment algorithms for polar UUV navigation. Results demonstrate that the proposed polar initial alignment algorithm can complete the initial alignment of UUV in the polar region rapidly and accurately.	alignment;cns disorder;choose (action);computer simulation;convergence (action);drug vehicle;experiment;inertial navigation system;kalman filter;meridians;motor vehicles;unmanned aerial vehicle;velocity (software development);algorithm	Zheping Yan;Lu Wang;Tongda Wang;Honghan Zhang;Xun Zhang;Xiangling Liu	2017		10.3390/s17122709	engineering;unmanned underwater vehicle;grid;inertial navigation system;kalman filter;polar;algorithm;computer vision;transversal (geometry);artificial intelligence	AI	55.0755250726695	-33.67125632368293	63180
48906e27224be495e0d6aed95df69acb8a236842	minimal solvers for 3d geometry from satellite imagery	minimal solvers 3d point triangulation image to object space mapping stereo correspondence problem 3d terrain 2d image coordinates satellite imagery processing 3d geometry;terrain mapping computational geometry computer vision geophysical image processing stereo image processing;satellites computational modeling three dimensional displays mathematical model cameras numerical models computer vision	We propose two novel minimal solvers which advance the state of the art in satellite imagery processing. Our methods are efficient and do not rely on the prior existence of complex inverse mapping functions to correlate 2D image coordinates and 3D terrain. Our first solver improves on the stereo correspondence problem for satellite imagery, in that we provide an exact image-to-object space mapping (where prior methods were inaccurate). Our second solver provides a novel mechanism for 3D point triangulation, which has improved robustness and accuracy over prior techniques. Given the usefulness and ubiquity of satellite imagery, our proposed methods allow for improved results in a variety of existing and future applications.	authorization;computer vision;correspondence problem;refinement (computing);solver;space mapping;tuple space	Enliang Zheng;Ke Wang;Enrique Dunn;Jan-Michael Frahm	2015	2015 IEEE International Conference on Computer Vision (ICCV)	10.1109/ICCV.2015.91	computer vision;computer graphics (images)	Vision	57.13212786186922	-46.44822546646937	63208
7b2583280c92d51977f7ed178decbf89b65e4a6a	space robotics-dlr's telerobotic concepts, lightweight arms and articulated hands	lightweight arms;multi fingered hands;robotersysteme;torque controlled robots;space robotics;present day;telerobotics;institut fur robotik und mechatronik bis 2012	"""The paper briefly outlines DLR's experience with real space robot missions (ROTEX and ETS VII). It then discusses forthcoming projects, e.g., free-flying systems in low or geostationary orbit and robot systems around the space station ISS, where the telerobotic system MARCO might represent a common baseline. Finally it describes our efforts in developing a new generation of """"mechatronic"""" ultra-light weight arms with multifingered hands. The third arm generation is operable now (approaching present-day technical limits). In a similar way DLR's four-fingered hand II was a big step towards higher reliability and yet better performance. Artificial robonauts for space are a central goal now for the Europeans as well as for NASA, and the first verification tests of DLR's joint components are supposed to fly already end of 93 on the space station."""	alveolar rhabdomyosarcoma;autonomy;baseline (configuration management);coat of arms;dynamic language runtime;enterprise test software;haptic device component;haptic technology;humans;low vision;mechatronics;multimodal interaction;obsolete - editstatus;online and offline;operability;outlines (document);relay device component;remote control;robot;robot (device);robotic spacecraft;robotics;round-trip engineering;satellite viruses;simulation;stereopsis;telerobotics;vii	Gerd Hirzinger;Bernhard Brunner;Klaus Landzettel;Norbert Sporer;Jörg Butterfaß;Markus Schedl	2003	Autonomous robots	10.1023/A:1022275518082	telerobotics;simulation;computer science;artificial intelligence	Robotics	64.16464919146397	-28.955417873903468	63232
8233d3d4f30e1784d0edcc95258274757bb8180d	touch sensing for humanoid robots	humanoid robot hands;human like touch sensing;robotic manipulation operations;collaboration;human like touch perception;manipulator dynamics;dynamic touch sensing technology human like touch sensing human like touch perception humanoid robot hands multifinger robot hand robotic manipulation operations static touch sensing technology;dexterous manipulators;humanoid robots;tactile sensors dexterous manipulators manipulator dynamics;robots;dynamic touch sensing technology;multifinger robot hand;tactile sensors;hman computer interaction;humanoid robots tactile sensors robots collaboration hman computer interaction;static touch sensing technology	A human-like touch and feel ability is still a major challenge yet to be solved in order to accelerate robot's transition from performing routine, preplanned, tasks in structured industrial environments to creatively performing tasks in unstructured environments such as nuclear stations, war zones, underwater, outer space, healthand elder-care, or telemedicine. Due to those unsolved challenges encountered in the development of a truly human-like touch sensing and perception capability for humanoid robot hands, considerable effort is still required before achieving the point of replicating the human hand's abilities by a multi-finger robot hand able to efficiently carry on dexterous robotic manipulation operations. All these challenges provide a strong incentive for using the bio-inspired approaches to develop efficient static and dynamic touch sensing technologies for the new generation of humanoid robots.	british informatics olympiad;humanoid robot	Thiago Eustaquio Alves de Oliveira;Ana-Maria Cretu;Vinicius Prado da Fonseca;Emil M. Petriu	2015	IEEE Instrumentation & Measurement Magazine	10.1109/MIM.2015.7271221	robot;computer vision;simulation;computer science;humanoid robot;artificial intelligence;tactile sensor;collaboration	Robotics	67.39841091799588	-27.216097035112377	63233
1dc5391aec49ffd5ce96081e44fee25db71d38f1	stable simulations of deformable objects using explicit integration	xfem physically based modeling explicit integration stability;stability;computational modeling stability analysis deformable models shape finite element analysis classification algorithms mathematical model;explicit integration;finite element analysis;mesh generation finite element analysis;mesh generation;xfem;physically based modeling;tetrahedralized cube deformable object simulation stability limit explicit integration schemes coarse tetrahedral mesh volumetric mesh triangular mesh object surface mesh rotational extended finite element method xfem	We present a new approach that deals with the stability limit of explicit integration schemes in simulations of deformable objects based on the finite element method. The underlying idea consists of using a large time step of a coarse tetrahedral mesh in any volumetric mesh that can be extracted from this initial mesh. This is performed by computing the intersection between two meshes: the volumetric mesh with a large time step (a tetrahedralized cube) and a triangular mesh that is the object to simulate. The mesh intersection is observed as cutting or dissecting the coarse mesh based on a given object's surface mesh. This task can be performed by the co rotational extended Finite Element Method (XFEM) in a stable manner. The XFEM handles the dissections as discontinuities while maintaining the original mesh intact. Hence, the magnitude order of the largest time step is preserved. Elements lying outside the surface mesh are treated as fixed and thus are not considered in the simulation. The intersection method is computed only once before starting the simulation. Our approach is suitable for interactive applications with/without topological changes. Furthermore, our approach can be directly switched to implicit solvers. The proposed method is an important contribution for designing simulations of deformable objects without meshing techniques.	complex systems;computer simulation;cube 2: sauerbraten;explicit and implicit methods;extended finite element method;graphics processing unit;haptic technology;intersection algorithm;polygon mesh;real-time clock	Luis F. Gutierrez Preciado;Felix Ramos	2013	2013 International Conference on Cyberworlds	10.1109/CW.2013.21	mesh generation;mathematical optimization;extended finite element method;stability;volume mesh;finite element method;mathematics;geometry;laplacian smoothing;t-vertices;statistics	Visualization	70.00503423807214	-46.46082687363612	63250
f0d3a8b57f7e0d5ce0313377ace2df3da7c7897f	directionally dependent light sources	photometry;support function;singular integral;rendering;global illumination;computer graphic	This paper deals with light sources in computer graphics. Different kinds of light sources and different types of solutions generally used are first described. Then, a new solution for directionally dependent light sources based on Nó e and Ṕeroche’s model[NP00] is proposed to avoid drawbacks of bilinear interpolation. The use of singular integrals with locally supported functions allows a fast and accurate reconstruction of goniometric diagrams. Application to point light sources is finally compared with some experimental results.	bilinear filtering;computer graphics;diagram;interpolation;light field	Stéphane Albin;Bernard Péroche	2003			optoelectronics;calculus;mathematics;optics	Graphics	72.31776500794496	-42.96861449136915	63262
75de35f793c2e0492e215e6114957ee8ba012841	rfid positioning robot: an indoor navigation system	radiofrequency identification robot kinematics robot sensing systems acoustics antennas;radiofrequency identification collision avoidance embedded systems infrared detectors mobile robots;mobile robots;embedded systems;collision avoidance;triangulation method rfid positioning robot indoor navigation system radio frequency identification rfid technology embedded system rfid reader mobile robot ultrasonic sensor ir sensor obstacle detection obstacle avoidance indoor guidance system;infrared detectors;radiofrequency identification	This paper describes a system to improve indoor navigation through use of radio frequency identification (RFID) technology. The terminal unit is an embedded system equipped with an RFID reader for localization, a mobile robot for navigation, and a combination of ultrasonic and IR sensors for obstacle detection and avoidance during navigation. To increase accuracy of an indoor guidance system, a triangulation method is proposed to accurately detect the location. While the proposed method can be verified by many methods, the accuracy is demonstrated through use of a mobile robot. It navigates to a designated location through continuously monitoring all RFID tags in the vicinity, localizing itself, and calculating the path to the destination.	embedded system;guidance system;internationalization and localization;mobile robot;radio frequency;radio-frequency identification;sensor	Brian Olszewski;Steven Fenton;Brian Tworek;Jiao Liang;Kumar Yelamarthi	2013	IEEE International Conference on Electro-Information Technology , EIT 2013	10.1109/EIT.2013.6632687	mobile robot;embedded system;computer vision;simulation;computer science;engineering;mobile robot navigation	Robotics	55.443882258734845	-34.09561090222318	63268
9b8b4e2c231b9dfe0c09ee8b8dc2c3cf5f86d47c	statistical geometry representation for efficient transmission and rendering	hierarchical partitioning;construccion arquitectura tecnologia ambiental;computacion informatica;large dataset;random sampling;point based rendering;grupo de excelencia;programmable gpu;statistical analysis;progressive transmission;ciencias basicas y experimentales;principal component analysis;probability distribution;quasi random numbers;tecnologias;random numbers;network graphics;view dependent rendering	Traditional geometry representations have focused on representing the details of the geometry in a deterministic fashion. In this article we propose a statistical representation of the geometry that leverages local coherence for very large datasets. We show how the statistical analysis of a densely sampled point model can be used to improve the geometry bandwidth bottleneck, both on the system bus and over the network as well as for randomized rendering, without sacrificing visual realism. Our statistical representation is built using a clustering-based hierarchical principal component analysis (PCA) of the point geometry. It gives us a hierarchical partitioning of the geometry into compact local nodes representing attributes such as spatial coordinates, normal, and color. We pack this information into a few bytes using classification and quantization. This allows our representation to directly render from compressed format for efficient remote as well as local rendering. Our representation supports both view-dependent and on-demand rendering. Our approach renders each node using quasi-random sampling utilizing the probability distribution derived from the PCA analysis. We show many benefits of our approach: (1) several-fold improvement in the storage and transmission complexity of point geometry; (2) direct rendering from compressed data; and (3) support for local and remote rendering on a variety of rendering platforms such as CPUs, GPUs, and PDAs.	byte;cache coherence;central processing unit;cluster analysis;data compression;deterministic algorithm;graphics processing unit;low-discrepancy sequence;personal digital assistant;principal component analysis;quantization (signal processing);randomized algorithm;rendering (computer graphics);sampling (signal processing);statistical classification;system bus	Aravind Kalaiah;Amitabh Varshney	2005	ACM Trans. Graph.	10.1145/1061347.1061356	probability distribution;sampling;simulation;rendering;computer science;theoretical computer science;mathematics;statistics;principal component analysis;computer graphics (images)	Graphics	67.72547254400067	-50.4047097585816	63298
b522ce3b8e8573c750fd09ff4a952753875ad913	"""retraction notice to: """"an autonomous all terrain robotic system for field demining missions"""" [robot. auton. syst. 70 (2015) 126-144]"""			auton;autonomous robot		2016	Robotics and Autonomous Systems	10.1016/j.robot.2015.11.005		Robotics	57.84357176495727	-30.00158308672586	63437
a7c3830ab3320f588a077ec87f4f6b79ded37191	optimal transportation for example-guided color transfer		I Let P = {pi}i∈[1,m] andQ = {qj}j∈[1,n] be the input and example set of color modes. I Let D = [dij] be a color distance matrix for each mode in P and Q: dij = ‖μi − μj‖2 + ‖σi − σj‖2. 1. We find the transport plan F = [fij] that minimizes ∑m i=1 ∑n j=1 fijdij. 2. For each input mode i = 1, ...,m, we compute a corresponding mapped color μ̂i = ∑n j=1 fijμ k j ∑n j=1 fij , where k = {a,b} are chroma channels in CIELAB color space. 3. The final color transfer is computed as a 3D thin plate splines interpolation of color correspondences Υ = { (μi ,μ b i ), (μ̂ a i , μ̂ b i ) } i=1,...,m. Semantic Constraints	artificial intelligence;color mapping;color space;distance matrix;interpolation;thin plate spline	Oriel Frigo;Neus Sabater;Vincent Demoulin;Pierre Hellier	2014		10.1007/978-3-319-16811-1_43	pattern recognition;computer vision;artificial intelligence;standard illuminant;computer science;structural similarity;color mapping;thin plate spline;chromatic adaptation;color constancy	Vision	73.95521126213552	-48.830873486828786	63524
c1b2de7ba04cda9ff943aa62cb882189b77f10af	a study on trunk stiffness and gait stability in quadrupedal locomotion using musculoskeletal robot	pneumatic actuator;elasticity;generators;motion control;hardware experiment trunk stiffness gait stability quadrupedal locomotion musculoskeletal robot gait pattern stability changeable body stiffness periodic leg motion rhyhmic motion body mechanism robot motion muscle tone changeable elasticity pneumatic actuator pace pattern;legged locomotion actuators dynamics joints generators pneumatic systems;legged locomotion;mechanical property;actuators;joints;stability;stability elastic constants elasticity legged locomotion motion control;elastic constants;feasibility study;dynamics;musculoskeletal robot;gait pattern stability;trunk stiffness;hardware experiment;body mechanism;robot motion muscle tone;quadrupedal locomotion;pneumatic systems;periodic leg motion;rhyhmic motion;changeable elasticity;changeable body stiffness;gait stability;pace pattern	In this study, a feasibility study on the stability of gait patterns with changeable body stiffness is reported. The periodic motions of the legs are generated as a rhyhmic motion. The stability of locomotion strongly depends on the mechanical properties of the body mechanism, especially the joint stiffness. In this report, the muscle tone of the robot motion at the trunk is changeable by using the changeable elasticity of the pneumatic actuators. The stability of quadruped locomotion in crawl, trot and pace patterns with changeable body stiffness was evaluated with hardware experiments.	elasticity (data store);experiment;robot;stiffness;trunk (software)	Katsuyoshi Tsujita;Kenji Miki	2011	2011 15th International Conference on Advanced Robotics (ICAR)	10.1109/ICAR.2011.6088641	control engineering;simulation;engineering;control theory	Robotics	67.82455272248255	-24.541869648633526	63543
1fc95be6f74b4f116605c5ce3b1342e5921ab920	orthogonal wall correction for visual motion estimation	inertial measurements;visual motion estimation;odometry;motion estimation;mobile robots;visual motion;robot vision;orthogonal wall correction;indoor environment;simultaneous localization and mapping;indoor environments;inertial measurements orthogonal wall correction visual motion estimation indoor environments odometry successive images matching;orientation estimation;robot vision mobile robots motion estimation;successive images matching;motion estimation simultaneous localization and mapping mobile robots indoor environments robot motion legged locomotion buildings motion measurement error correction measurement units	A good motion model is a prerequisite for many approaches to simultaneous localization and mapping. Without an absolute reference, it is however difficult to prevent drift when estimating motion. To prevent orientation drift, our approach exploits typical features of indoor environments: Straight walls that are parallel or orthogonal to each other. Our idea is to detect walls in monocular depth measurements and to correct odometry obtained from matching successive images and from inertial measurements, such that the observed walls are aligned with the main orientation estimated from the map that is being built. The experimental results indicate that orientation drift can be prevented and orientation uncertainty can be reduced greatly when applying the proposed orthogonal wall correction. This can make the difference between reliable mapping and failure.	closing (morphology);encoder;experiment;imperative programming;laser tracker;motion estimation;odometry;simultaneous localization and mapping;straight skeleton;visual odometry	Jörg Stückler;Sven Behnke	2008	2008 IEEE International Conference on Robotics and Automation	10.1109/ROBOT.2008.4543178	mobile robot;computer vision;simulation;computer science;artificial intelligence;motion estimation;odometry;optics;simultaneous localization and mapping	Robotics	54.78921026715846	-38.841785500240164	63551
48655ac8d879ae782c30b546d2488f7b716f55ef	dyadic and \sqrt 3 - subdivision for uniform powell-sabin splines	refined surface spl radic 3 subdivision dyadic subdivision powell sabin spline surfaces uniform triangulations vertex control points;cad;computational geometry;splines mathematics;polynomials tensile stress computer science refining packaging displays character generation piecewise linear techniques;computational geometry splines mathematics cad	We give two different possibilities for subdivision of Powell–Sabin spline surfaces on uniform triangulations. In the first case, dyadic subdivision, a new vertex is introduced on each edge between two old vertices. In the second case, p 3–subdivision, a new vertex is introduced in the center of each triangle of the triangulation. We give subdivision rules to find the new control points of the refined surface for both cases.	b-spline;dyadic transformation;powell's method;spline (mathematics);subdivision surface	Evelyne Vanraes;Joris Windmolders;Adhemar Bultheel;Paul Dierckx	2002		10.1109/IV.2002.1028842	mathematical optimization;combinatorics;mathematics;geometry	Theory	68.79985967973472	-41.80249007620946	63589
b81d7b4fcc5405b4b2f9883ea6b5cccda3021c73	unified model for omnidirectional vision using the conformal geometric algebra framework	algebra;computer vision;geometry;conformal geometric algebra framework;diverse catadioptric mirror handling;incidence algebra operations;omnidirectional vision	This work presents the application of the unified model for handling diverse catadioptric mirrors using the conformal geometric algebra framework. This framework is well equiped with incidence algebra operations (duality, meet and join) necessary for reflecting and projecting geometric entities of the visual space through the mirror to the camera. We show that our mathematical reduces the algebraic burden, as a result the development of algorithms for omnidirectional vision is easier and effective.	algorithm;conformal geometric algebra;entity;hyper cd-rom;incidence matrix;linear algebra;refinement (computing);unified model	Carlos López-Franco;Eduardo Bayro-Corrochano	2004	Proceedings of the 17th International Conference on Pattern Recognition, 2004. ICPR 2004.	10.1109/ICPR.2004.1333702	geometric algebra;computer vision;pure mathematics;unified model;mathematics;geometry	Robotics	62.89707894245802	-41.12779188004028	63600
528daf21a0166113d5e390545707984f3a9943ce	indoor mapping and localization for pedestrians using opportunistic sensing with smartphones		Indoor localization for pedestrians has gained increasing popularity among the rich body of literature for the last decade. In this paper, a low-cost indoor mapping and localization solution is proposed using the opportunistic signals from ambient indoor environments with a smartphone. It is composed of GraphSLAM-based offline mapping and Bayesian filtering-based online localization using generated signal maps. The GraphSLAM front-end is constructed by motion constraints from pedestrian dead-reckoning (PDR), loop-closure constraints identified by magnetic sequence matching with WiFi signal similarity validation, and observation constraints from opportunistic magnetic headings after error rejection. Globally consistent trajectories are created by graph optimization, after which signal maps (e.g., WiFi, magnetic fields, lights) are generated by Gaussian Processes Regression (GPR) for later localization. We propose to use the pseudo-wall constraints from the GPR variance map of magnetic fields and the lights measurements as observations for particle filtering. The proposed method is evaluated on several datasets collected from both the in-compass office buildings and outside public areas. Real-time localization is demonstrated on a smartphone in an office building covering 2000 square meters with the 50- and 90-percentile accuracies being 2.30 m and 3.41 m, respectively.		Qing Liang;Lujia Wang;Youfu Li;Ming Liu	2018	2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)	10.1109/IROS.2018.8594254	computer vision;ground-penetrating radar;computer science;filter (signal processing);pedestrian;artificial intelligence;particle filter;trajectory;gaussian process;simultaneous localization and mapping;bayesian probability	Robotics	56.087056834850365	-37.23597513973885	63601
