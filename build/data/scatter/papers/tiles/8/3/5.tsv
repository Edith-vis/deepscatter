id	title	keywords	abstract	entities	authors	year	journal	doi	fos	area	x	y	ix
553dbe2b0c9efe1a1c7e9057cefe574dadbb43fd	automatic optimization of stream programs via source program operator graph transformations	automatic tuning;code transformation;data intensive computing;stream processing;performance optimization	Distributed data stream processing is a data analysis paradigm where massive amounts of data produced by various sources are analyzed online within real-time constraints. Execution performance of a stream program/query executed on such middleware is largely dependent on the ability of the programmer to fine tune the program to match the topology of the stream processing system. However, manual fine tuning of a stream program is a very difficult, error prone process that demands huge amounts of programmer time and expertise which are expensive to obtain. We describe an automated process for stream program performance optimization that uses semantic preserving automatic code transformation to improve stream processing job performance. We first identify the structure of the input program and represent the program structure in a Directed Acyclic Graph. We transform the graph using the concepts of Tri-OP Transformation and Bi-Op Transformation. The resulting sample program space is pruned using both empirical as well as profiling information to obtain a ranked list of sample programs which have higher performance compared to their parent program. We successfully implemented this methodology on a prototype stream program performance optimization mechanism called Hirundo. The mechanism has been developed for optimizing SPADE programs which run on System S stream processing run-time. Using five real world applications (called VWAP, CDR, Twitter, Apnoea, and Bargain) we show the effectiveness of our approach. Hirundo was able to identify a 31.1 times higher performance version of the CDR application within seven minutes time on a cluster of 4 nodes.	algorithm;bargain buddy;cluster analysis;cognitive dimensions of notations;dataflow architecture;directed acyclic graph;glossary of computer graphics;graph rewriting;k-means clustering;mathematical optimization;middleware;operator overloading;optimization mechanism;optimizing compiler;performance prediction;performance tuning;profiling (computer programming);program transformation;programmer;programming paradigm;prototype;python;real-time clock;stream processing;structured programming;throughput;transformer;triangular function;xfig	Miyuru Dayarathna;Toyotaro Suzumura	2013	Distributed and Parallel Databases	10.1007/s10619-013-7130-x	program analysis;parallel computing;real-time computing;stream processing;computer science;theoretical computer science;operating system;data-intensive computing;database;data stream mining	PL	-16.342111940869547	37.44265947587283	13501
45c2128c5b13040d92f44092a66b1726a40a14ac	methods for parallelizing the probabilistic neural network on a beowulf cluster computer	parallel split training set;probability neural nets parallel processing pipeline processing;probability;neural nets;parallel split training set probabilistic neural network beowulf cluster computer parallel full training set;beowulf cluster computer;neural networks computer networks concurrent computing training data testing bayesian methods computational complexity application software computer architecture acoustical engineering;parallel full training set;beowulf cluster;probabilistic neural network;parallel processing;pipeline processing	In this paper, we present three different methods for implementing the probabilistic neural network on a Beowulf cluster computer. The three methods, parallel full training set (PFT-PNN), parallel split training set (PST-PNN) and the pipelined PNN (PPNN) all present different performance tradeoffs for different applications. We present implementations for all three architectures that are fully equivalent to the serial version and analyze the tradeoffs governing their potential use in actual engineering applications. Finally we provide performance results for all three methods on a Beowulf cluster.	artificial neural network;beowulf cluster;computer cluster;database;image scaling;load balancing (computing);overhead (computing);paging;parallel algorithm;parallel computing;pipeline (computing);planar separator theorem;probabilistic neural network;production system (computer science);program structure tree;speedup;test set	Jimmy Secretan;Michael Georgiopoulos;Ian Maidhof;Philip Shibly;Joshua Hecker	2006	The 2006 IEEE International Joint Conference on Neural Network Proceedings	10.1109/IJCNN.2006.247062	parallel processing;parallel computing;probabilistic neural network;computer science;theoretical computer science;machine learning;probability;artificial neural network	HPC	-11.551215235327938	42.02431331253187	13506
2a7ef24d2bc8dd8d603cc3b00bd723ac5dffb1f9	developments in firmware engineering		Publisher Summary   This chapter presents a survey of firmware engineering. The chapter discusses the use of microprogramming for implementing control units and emulating instruction sets. It has become commonplace and in fact has even become a topic of interest to systems and applications programmers as well as to computer architects and engineers. To emphasize the user interface of microprogramming, the term “firmware” has been coined as a synonym. They trace the key developments in firmware engineering and convey some of its intellectual content. In the past ten years, firmware engineering has emerged as a systematic discipline and its central problems have been essentially solved. The issue of formal verification, however, still remains controversial and yet it is of great importance in reasoning about the correctness of designs. The distinguishing characteristics of firmware are discussed: (1) its machine specificity, (2) the need for efficiency, (3) its place in the computer design process, and (4) the nature of its complexity.	embedded system;firmware	Subrata Dasgupta;Bruce D. Shriver	1985	Advances in Computers	10.1016/S0065-2458(08)60366-6	computer science	AI	-24.3240132600644	38.58588208611227	13523
57abb175d91a09092f349402bd44a39c89022261	a monitoring tool for a grid operation center	globus toolkit;cluster computing;virtual organization;resource broker	WorldGRID is an intercontinental testbed spanning E urope and the US integrating architecturally differ ent Grid implementations based on the Globus toolkit. The Wo rldGRID testbed has been successfully demonstrated during the WorldGRID demos at SuperComputing 2002 (Baltimore) and IST2002 (Copenhagen) where real HEP application jobs were transparently submitted from US and Europe using “n ative” mechanisms and run where resources were avai lable, independently of their location. To monitor the beh avior and performance of such testbed and spot prob lems as soon as they arise, DataTAG has developed the EDT-Monitor tool b ased on the Nagios package that allows for Virtual Organization centric views of the Grid through dynamic geographical maps . The tool has been used to spot several problems d uring the WorldGRID operations, such as malfunctioning Resource Brokers or Information Servers, sites not correctly config ured, job dispatching problems, etc. In this paper we give an overview of the package, its features and scalability solution s a d we report on the experience acquired and the benefit that a GRID ope ration center would gain from such a tool.	event dispatching thread;file spanning;heterogeneous element processor;map;microdot;nagios core;scalability;testbed;virtual organization (grid computing)	Sergio Andreozzi;Sergio Fantinel;David Rebatto;Luca Vaccarossa;Gennaro Tortone	2003	CoRR		parallel computing;simulation;computer cluster;computer science;operating system;database;distributed computing;world wide web	HPC	-29.83734600698647	52.17611295817988	13525
38b63d7331ae63c0ff163b918fe80e53a73b3d12	analysis of restart mechanisms in software systems	software reliability modeling;software failure;completion time;preventive maintenance;software preventive maintenance;web pages;software time out strategy analysis;software maintenance;efficient algorithm;time out;reliability modeling;software systems;online optimization;software fault tolerance;optimal restart strategy;fault tolerant system;system recovery;adaptive systems;fault tolerant systems;software reliability modeling software system restart mechanism analysis software preventive maintenance software rejuvenation software failure software time out strategy analysis optimal restart strategy fault tolerant system software performance modeling;adaptive system;randomized algorithm;system recovery software fault tolerance software maintenance;software systems internet failure analysis preventive maintenance software maintenance web pages software performance fault tolerant systems computer network reliability adaptive systems;performance and reliability modeling;software rejuvenation;restart;self management restart software rejuvenation time out fault tolerant systems performance and reliability modeling completion time adaptive systems;self management;software system restart mechanism analysis;software performance modeling	Restarts or retries are a common phenomenon in computing systems, for instance, in preventive maintenance, software rejuvenation, or when a failure is suspected. Typically, one sets a time-out to trigger the restart. We analyze and optimize time-out strategies for scenarios in which the expected required remaining time of a task is not always decreasing with the time invested in it. Examples of such tasks include the download of Web pages, randomized algorithms, distributed queries, and jobs subject to network or other failures. Assuming the independence of the completion time of successive tries, we derive computationally attractive expressions for the moments of the completion time, as well as for the probability that a task is able to meet a deadline. These expressions facilitate efficient algorithms to compute optimal restart strategies and are promising candidates for pragmatic online optimization of restart timers	approximation;authorization;computation;download;erlang (programming language);fm broadcasting;hard coding;hyper-threading;ieee xplore;job stream;mathematical optimization;online optimization;randomized algorithm;rate–distortion theory;software rejuvenation;software system;station hypo;time complexity;timeout (computing);timer;web page;xfig	Aad P. A. van Moorsel;Katinka Wolter	2006	IEEE Transactions on Software Engineering	10.1109/TSE.2006.73	reliability engineering;preventive maintenance;fault tolerance;real-time computing;computer science;adaptive system;operating system;software engineering;web page;distributed computing;randomized algorithm;software maintenance;software fault tolerance;software system	SE	-22.959301696450876	54.34554507634935	13532
8791036d81fc907dbbf235633ef58a09aa33e1be	a framework for high performance simulation of transactional data grid platforms	different data grid architecture;data grid;infinispan data grid;high performance simulation;root-sim parallel simulation engine;transactional data grid platform;large data grid model;differentiated data grid component;in-memory data maintenance;real measurement;data cache server;in-memory data grid system	One reason for the success of in-memory (transactional) data grids lies on their ability to fit elasticity requirements imposed by the cloud oriented pay-as-you-go cost model. In fact, by relying on in-memory data maintenance, these platforms can be dynamically resized by simply setting up (or shutting down) instances of so called data cache servers. However, defining the well suited amount of cache servers to be deployed, and the degree of in-memory replication of slices of data, in order to optimize reliability/availability and performance tradeoffs, is far from being a trivial task. To cope with this issue, in this article we present a framework for high performance simulation of in-memory data grid systems, which can be employed as a support for timely whatif analysis and exploration of the effects of reconfiguration strategies. The framework consists of a discrete event simulation library modeling differentiated data grid components in a modular fashion, which allows easy (re)-modeling of different data grid architectures (e.g. characterized by different concurrency control schemes). Also, the library has been designed to be layered on top of the open source ROOT-Sim parallel simulation engine, natively offering facilities for optimized resource usage in the context of model execution on top of multi-core and cluster based architectures. Finally, instances of data-grid models supported by the framework have been validated against real measurements obtained by deploying the Infinispan data grid onto Amazon EC2 virtual clusters, and running the well known TPC-C benchmark. By the experiments we demonstrate closeness of simulation outputs and real measurements, while jointly showing extreme scalability of the framework, in terms of speedup and ability to manage extremely large data grid models. ∗This work has been partially supported by the Cloud-TM project (co-financed by the European Commission through the contract no. 57784). The package has been released as part of this project deliverables, and is accessible at the URL https://github.com/cloudtm/cloudtm-autonomicmanager/tree/master/src/dags. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. SIMUTools 2013 March 5–8, Cannes, France. Copyright 2013 ACM 978-1-936968-00-8 ...$10.00.	amazon elastic compute cloud (ec2);analysis of algorithms;benchmark (computing);centrality;concurrency (computer science);concurrency control;dynamic data;elasticity (data store);experiment;ibm tivoli storage productivity center;in-memory database;infinispan;multi-core processor;open-source software;performance prediction;root;requirement;scalability;simulation;speedup;transaction processing;whole earth 'lectronic link	Pierangelo di Sanzo;Francesco Antonacci;Bruno Ciciani;Roberto Palmieri;Alessandro Pellegrini;Sebastiano Peluso;Francesco Quaglia;Diego Rughetti;Roberto Vitali	2013			parallel computing;real-time computing;simulation;computer science;operating system;distributed computing;computer network	HPC	-21.62526048014919	54.80004677955411	13534
79f4460ea3cea63343294664cff2ae0866d980d9	multiversion concurrency control for multidimensional index structures	index structure;search trees;indexation;concurrency control	Prevailing concurrency control mechanisms for multidimensional index structures, such as the Generalized Search Tree (GiST), are based on locking techniques. These approaches may cause significant overhead in settings where the indexed data is rarely updated and read access is highly concurrent. In this paper we present the Multiversion-GiST (MVGiST), which extends the GiST with Multiversion Concurrency Control. Beyond enabling lock-free read access, our approach provides readers a consistent view of the whole index structure, which is achieved through the creation of lightweight, read-only versions of the GiST that share unchanging nodes amongst themselves. Our evaluation confirms that for low update rates, the MVGiST significantly improves scalability w.r.t. the number of concurrent accesses when compared to a traditional, locking-based concurrency control mechanism.	multiversion concurrency control	Walter Binder;Samuel Spycher;Ion Constantinescu;Boi Faltings	2007		10.1007/978-3-540-74469-6_18	timestamp-based concurrency control;optimistic concurrency control;real-time computing;isolation;computer science;concurrency control;database;distributed computing;multiversion concurrency control;non-lock concurrency control;snapshot isolation;distributed concurrency control	DB	-21.368218542262035	49.13716202358488	13542
f54b6e2222fea11da7080ec4eedd5d89eb57640d	mobile ambients	mobile ambients;includ- ing movement through administrative domains. keywords: agents;abstract we introduce a calculus describing the movement of processes and devices;wide-area computation.;mobility;process calculi	We introduce a calculus describing the movement of processes and devices, including movement through administrative domains.	ambient calculus	Luca Cardelli;Andrew D. Gordon	1997	Electr. Notes Theor. Comput. Sci.	10.1016/S1571-0661(05)80699-1	real-time computing;computer science;theoretical computer science;algorithm	ECom	-29.539495809228065	32.94674492232974	13553
333b83e227e19b07cb13be4eb294bad6d44e8724	orchestrator: guarding against voltage emergencies in multithreaded applications	orchestrator single program and multiple data programming model multicore architectures voltage droops power activity domain wide destructive core interference multicore processors increase power capacity decrease feature size multithreaded applications voltage emergencies;interference;synchronization;message systems;multicore processing;pipelines;voltage emergencies ves multicore multithreaded application single program multiple data spmd;power aware computing multiprocessing programs multiprocessing systems multi threading;multicore processing instruction sets interference message systems synchronization pipelines;instruction sets	Voltage emergency (VE) has become a critical challenge with decreasing feature size and increasing power capacity. Destructive core interference is one main source of VE in multicore processors. We observed that the applications following single program and multiple data programming model tend to spark domain-wide destructive core interference because multiple threads exhibit similar power activity. We analyze and quantify this effect and propose one low-cost solution, Orchestrator, to avoid voltage droop synergy among cores. Orchestrator leverages the thread diversity to smooth voltage droops in multicore architectures based on thread scheduling. The thread migration impact on performance is also considered. Experimental results show that Orchestrator can significantly reduce VEs, thereby improving performance.	central processing unit;fail-safe;interaction;interference (communication);multi-core processor;multithreading (computer architecture);process migration;programming model;scheduling (computing);single-core;synergy;thread (computing)	Xing Hu;Guihai Yan;Yu Hu;Xiaowei Li	2014	IEEE Transactions on Very Large Scale Integration (VLSI) Systems	10.1109/TVLSI.2013.2296787	multi-core processor;embedded system;synchronization;electronic engineering;parallel computing;real-time computing;telecommunications;computer science;operating system;instruction set;interference;pipeline transport	Arch	-5.453276155711747	54.69602296265835	13555
5f8b72961a696649eefe2d1db3c4a12dea35e8ea	optimal recovery schemes for high-availability cluster and distributed computing	tolerancia falta;distributed system;metodo caso peor;high availability;evaluation performance;haute performance;systeme reparti;performance evaluation;fault tolerant;distribucion carga;availability;disponibilidad;evaluacion prestacion;reseau ordinateur;distributed computing;carga repartida;computer network;sistema repartido;fault tolerance;red ordenador;methode cas pire;alto rendimiento;distribution charge;load sharing;calculo repartido;charge repartie;load distribution;worst case method;high performance;disponibilite;calcul reparti;tolerance faute;distributed load	Clusters and distributed systems offer two important advantages, viz. fault tolerance and high performance through load sharing. When all computers are up and running, we would like the load to be evenly distributed among the computers. When one or more computers break down the load on these computers must be redistributed to other computers in the cluster. The redistribution is determined by the recovery scheme. The recovery scheme should keep the load as evenly distributed as possible even when the most unfavorable combinations of computers break down, i.e., we want to optimize the worst-case behavior. In this paper we define recovery schemes, which are optimal for a number of important cases. We also define a bound on the performance of the recovery schemes for any number of computers.	distributed computing;high-availability cluster	Lars Lundberg;Charlie Svahnberg	2001	J. Parallel Distrib. Comput.	10.1006/jpdc.2001.1760	embedded system;fault tolerance;parallel computing;real-time computing;computer science;distributed computing	HPC	-19.343924271777972	45.038734576176104	13625
ccbb92dd5607a98408a151ec1b39574a3cbb5167	pascal language extensions for parallel processing	programming environment;code generation;test bed;object oriented programming;liveness;deadlock;language extension;minimal;system architecture;petri net;strongly connected;parallel processing;discrete system;problem solving;trap;complete	Classes of problems amenable to parallel solution are differentiated over a wide range of distinct system architectures. In exploring applications of parallelism one has to work at two different levels: the problem-oriented or linguistic level and the run-time or architectural level. Predefined languages and fixed architectures can conceivably restrict the approach to problem solving and put a damper on both research and understanding. Dealing with the general problems of compiler development or with a large and extensible language of still limited availability such as ADA [1] serves to put a damper on experimentation with the linguistic and run-time issues.  Pascal still remains a language of choice for program illustration as a result of its general use in computer science instruction. The availability of Wirth's well-documented Pascal-S compiler [2] removes much of the effort needed to translate modifications of the language to useable object form. The authors are therefore using Pascal as a test bed for extensions needed for the solution of various parallel problems, discrete systems simulation, and object-oriented programming. Run-time issues are addressed through modifications of the stack machine to handle execution in both the strictly sequential computer environments available to everyone and the parallel environment of a laboratory-based system using Inmos Transputers [3]. The stack machines themselves are implemented in appropriate versions of C. A. parallel C compiler [4] for the Transputer conveniently handles the not insignificant problems of code generation, loading, and linking on the Transputer system.  The emphasis of the project is on an instructional programming environment. Languages such as Occam [5] and Simula [6] serve as conceptual starting points for defining the Pascal extensions. Available versions of Occam [7,8] tend to depart from the mainstream of user access, and the authors have frequently been perplexed by situations that beg for more information about behavior at the run-time implementation level. Simula's use of Algol-60 as its basis for definition gives a fair degree of compatibility with Pascal. Pascal in turn will give the student a familiar starting point and a fuller range of input and output capabilities for applications, debugging, and dynamic illustration of run-time behavior.	algol 60;ada;code generation (compiler);compiler;computer science;debugging;extensible programming;input/output;integrated development environment;limited availability;parallel computing;pascal;problem solving;simula;stack machine;systems simulation;testbed;transputer;unified parallel c (upc);usability;occam	Allen Brady;Mohammad Changi;Jiyu Yu	1989		10.1145/75427.1030266	complete;parallel processing;computer science;artificial intelligence;theoretical computer science;deadlock;software engineering;discrete system;database;programming language;object-oriented programming;trap;petri net;strongly connected component;algorithm;code generation;liveness;testbed	PL	-15.217587866441603	39.39007008887847	13639
2814fe0cc792388efee9918467cf05b1e233b8e4	power management for real-time tasks in wireless networked embedded systems	radio networks;energy management power system management real time systems embedded system energy consumption job shop scheduling processor scheduling dynamic voltage scaling frequency communication system security;real time;wireless network;dynamic voltage scaling;turn off;scheduling embedded systems power aware computing radio networks;wireless nodes;embedded systems power manament real time;embedded system;power management scheme;wireless communication;embedded systems;power aware computing;time factors;energy consumption;scheduling;power management;precedence constraint;schedules;network interface;real time application;radio sleep scheduling power management scheme real time tasks wireless networked embedded systems dynamic voltage scaling wireless nodes;wireless networked embedded systems;communication system security;real time tasks;radio sleep scheduling;real time systems;power manament	Power management is a key issue in designing real-time applications on wireless embedded systems, which makes dynamic voltage scaling on processors become popular. Meanwhile, the communication power practice is also important in that wireless nodes often turn off their network interfaces in a sleep schedule to reduce energy consumption. In this paper, we propose solutions to minimize network-wide energy consumption for real-time tasks with precedence constraints executing on wireless embedded systems. Our solutions take the radio sleep scheduling of wireless nodes into account when adjusting the execution modes of processors. The experiments show that our approach significantly reduces total energy consumption.	central processing unit;dynamic voltage scaling;embedded system;experiment;image scaling;power management;real-time clock;real-time web;scheduling (computing)	Zhaohui Yuan;Gaofeng Wang	2008	2008 International Conference on Computer Science and Software Engineering	10.1109/CSSE.2008.1245	embedded system;real-time computing;schedule;computer science;network interface;operating system;wireless network;distributed computing;key distribution in wireless sensor networks;scheduling;wireless	Embedded	-5.515621480811406	59.35946132013194	13668
602ea37fad3c066a5a9fd89793a1bad781bd5c53	integrated performance models for spmd applications and mimd architectures	synchronization overhead integrated performance models spmd applications mimd architectures queuing network models general purpose parallel architectures workstation clusters computation pattern communication pattern i o operations i o parallelism speedup surfaces processor relative influence hardware components software components measurable characteristics processor number disk number i o topology fork join queues mean value analysis parallel i o;queueing theory parallel architectures workstation clusters performance evaluation parallel machines parallel programming;performance evaluation;software components integrated performance models spmd applications single program multiple data multiple instruction multiple data mimd architectures queuing network models general purpose parallel architectures workstation clusters input output operations parallel programs;queueing theory;fork join queues;input output programs;software performance evaluation;mean value analysis mva;parallel programming;speedup surface;cluster of workstations;indexing terms;single program multiple data spmd;mean value analysis;performance analysis application software hardware queueing analysis parallel architectures workstations concurrent computing parallel processing software performance computer architecture;parallel architectures;performance analysis;software component;performance model;parallel machines;queuing network model;parallel i o;multiple instruction multiple data;queuing networks;workstation clusters;parallel architecture;multiple instruction multiple data mimd;synchronization overhead;parallel applications;input output programs software performance evaluation parallel architectures parallel programming queueing theory;computer architecture performance analysis application software hardware queueing analysis parallel architectures workstations concurrent computing parallel processing software performance;single program multiple data	This paper introduces queuing network models for the performance analysis of SPMD applications executed on generalpurpose parallel architectures such as MIMD and clusters of workstations. The models are based on the pattern of computation, communication, and I/O operations of typical parallel applications. Analysis of the models leads to the definition of speedup surfaces which capture the relative influence of processors and I/O parallelism and show the effects of different hardware and software components on the performance. Since the parameters of the models correspond to measurable program and hardware characteristics, the models can be used to anticipate the performance behavior of a parallel application as a function of the target architecture (i.e., number of processors, number of disks, I/O topology, etc).	analysis of algorithms;central processing unit;component-based software engineering;computation;computer multitasking;high-level programming language;image scaling;input/output;mimd;parallel computing;profiling (computer programming);programmer;resource contention;spmd;scheduling (computing);speedup;supercomputer;workstation	Paolo Cremonesi;Claudio Gennaro	2002	IEEE Trans. Parallel Distrib. Syst.	10.1109/TPDS.2002.1158268	mean value analysis;computer architecture;parallel computing;index term;mimd;computer science;component-based software engineering;operating system;distributed computing;queueing theory;spmd;statistics	HPC	-9.435939154642073	47.99671933428392	13695
1041d90b535a007e9b729132ec36daee15cf394c	process model and resource management in a distributed database	distributed database;process model	A deadlock-free resource management for a homogeneous distributed database system is proposed. Consistent database access is guaranteed in sections called transactions. Transactions consist of several processes of hier~chic~ structure. Transactions with read-and w~te-orations use a two-phase locking. The read-resources are locked as they are needed. The write-o~rations are buffered and executed at the end of a transaction. At this point the write-resources can be locked in a given order. Transactions which only read the database, do not lock the resources. It is only checked if these transactions can be serialized. Conflicts are resolved by resetting of transactions. No expensive recovery is needed. No physical controlling centre is used.	deadlock;distributed database;lock (computer science);serialization;two-phase commit protocol;two-phase locking	Werner Storz	1982	Inf. Syst.	10.1016/0306-4379(82)90014-X	real-time computing;scalability;database transaction;distributed transaction;computer science;process modeling;index locking;database;distributed computing;online transaction processing;compensating transaction;serializability;distributed database;acid	DB	-24.257799481475036	48.16083722902941	13707
2559ed3aac02abc5f64c9628aaadf64f1862a005	scalable computing with parallel tasks	hierarchical structure;multi core processor;interconnection network;loosely coupled applications;parallel machines;cloud computing;high throughput computing;many task computing	Recent and future parallel clusters and supercomputers use SMPs and multi-core processors as basic nodes, providing a huge amount of parallel resources. These systems often have hierarchically structured interconnection networks combining computing resources at different levels, starting with the interconnect within multi-core processors up to the interconnection network combining nodes of the cluster or supercomputer. The challenge for the programmer is that these computing resources should be utilized efficiently by exploiting the available degree of parallelism of the application programs and by structuring the application in a way which is sensitive to the heterogeneous interconnect.  In this article, we present an approach to structure the computations of an application as parallel tasks which can interact with other parallel tasks in communication phases. In particular, we consider how these parallel tasks can be mapped onto the computing resources provided by parallel clusters or supercomputers. We show that the scalability can be significantly improved by a suitable task-based organization and a corresponding structuring of the communication within tasks as well as between tasks. We evaluate the impact of different mappings of tasks to cores for different application programs on a variety of parallel machines.	central processing unit;computation;computer cluster;degree of parallelism;interconnection;multi-core processor;parallel computing;programmer;scalability;supercomputer	Jörg Dümmler;Thomas Rauber;Gudula Rünger	2009		10.1145/1646468.1646477	multi-core processor;parallel computing;embarrassingly parallel;cloud computing;computer science;theoretical computer science;operating system;massively parallel;data-intensive computing;distributed computing;data parallelism;utility computing;task parallelism	HPC	-7.538552208922548	44.24510058175041	13722
51c971b1478b763b8a7c0475e53f21e77d2e23c9	energy-oriented dynamic spm allocation based on time-slotted cache conflict graph	scanning probe microscopy;registers;system performance;memory management;optimization;embedded system;system on chip;graph theory;nonlinear programming;mathematical model;energy optimization;embedded systems;integer programming;resource management;soc	Energy consumption has always been considered as the key issue of the state-of-the-art SoCs. Implementing an on-chip Cache is one of the most promising solutions. However, traditional Cache may suffer from performance and energy penalties due to the Cache conflict. In order to deal with this problem, this paper firstly introduces a Time-Slotted Cache Conflict Graph to model the behavior of Data Cache conflict. Then, we implement an Integer Nonlinear Programming to select the most profitable data pages and employ Virtual Memory System to remap those data pages, which can cause severe Cache conflict within a time slot, to the on-chip Scratchpad Memory (SPM). In order to minimize the swapping overhead of dynamic SPM allocation, we introduce a novel SPM controller with a tightly coupled DMA to issue the swapping operations without CPU's intervention. The proposed method can optimize all of the data segments, including global data, heap and stack data in general, and reduce 24.83% energy consumption on average without any performance degradation.	cpu cache;cache (computing);central processing unit;direct memory access;elegant degradation;heap (data structure);nonlinear programming;openvms;overhead (computing);paging;scratchpad memory;super paper mario;system on a chip	Wang Huan;Zhang Yang;Mei Chen;Ling Ming	2010	2010 Design, Automation & Test in Europe Conference & Exhibition (DATE 2010)		bus sniffing;system on a chip;embedded system;cache-oblivious algorithm;parallel computing;real-time computing;cache coloring;page cache;integer programming;cpu cache;nonlinear programming;cache;computer science;write-once;graph theory;resource management;cache invalidation;operating system;smart cache;cache algorithms;cache pollution	EDA	-6.3399397828275506	54.889490255048536	13741
2884106dcb2c126e6e2d57e06cfa06106806333f	dyc: an expressive annotation-directed dynamic compiler for c	time constant;compilateur;langage c;optimizing compiler;compilateur annotation dirige;generation code;specialization;flot donnee;generacion codigo;code generation;dynamic compiler;run time code generation;dynamic compilation;annotation directed compiler;flujo datos;control flow graph;compiler;program optimization;dynamical system;systeme dynamique;c language;dataflow analysis;instruction set simulator;partial evaluation;optimisation programme;binding time analysis;sistema dinamico;data flow;constant folding;compilateur dynamique;data structure;compilador;lenguaje c;cycles per instruction;optimizacion programa	We present the design of DyC, a dynamic-compilation system for C based on run-time specialization. Directed by a few declarative user annotations that specify the variables and code on which dynamic compilation should take place, a binding-time analysis computes the set of run-time constants at each program point in the annotated procedure’s control-flow graph; the analysis supports programpoint-specific polyvariant division and specialization. The results of the analysis guide the construction of a run-time specializer for each dynamically compiled region; the specializer supports various caching strategies for managing dynamically generated code and mixes of speculative and demand-driven specialization of dynamic branch successors. Most of the key cost/benefit trade-offs in the binding-time analysis and the run-time specializer are open to user control through declarative policy annotations. DyC has been implemented in the context of an optimizing compiler, and initial results have been promising. The speedups we have obtained are good, and the dynamic-compilation overhead is among the lowest of any dynamic-compilation system, typically 20-200 cycles per instruction generated on a Digital Alpha 21164. The majority of DyC’s functionality has been used to dynamically compile an instruction-set simulator. Only three annotations were required, but a few other changes to the program had to be made due to DyC’s lack of support for static global variables. This deficiency and DyC’s rudimentary support for partially static data structures are the primary obstacles to making DyC easy to use.	angular defect;control flow graph;cycles per instruction;dec alpha;data structure;dynamic compilation;global variable;instruction set simulator;name binding;optimizing compiler;overhead (computing);partial template specialization;polyvariance;speculative execution;user interface	Brian Grant;Markus Mock;Matthai Philipose;Craig Chambers;Susan J. Eggers	2000	Theor. Comput. Sci.	10.1016/S0304-3975(00)00051-7	data flow diagram;compiler;parallel computing;real-time computing;dynamic compilation;data structure;computer science;dynamical system;program optimization;optimizing compiler;cycles per instruction;time constant;programming language;partial evaluation;constant folding;algorithm;code generation;control flow graph	PL	-19.091989200820493	36.029101507656726	13778
cc05fdb70b630138dd9b64a901eec9c36146c371	accelerating business analytics applications	analytical models;electronic mail;text analysis;data mining;acceleration;registers;simd hardware business text analytics applications data mining decision making processes regular expression processing total execution time network intrusion detection systems memory bus attached accelerators i o bus attached accelerators network attached accelerators;business data processing;decision making process;acceleration program processors business registers electronic mail analytical models twitter;business;text analysis business data processing data mining decision making security of data;twitter;network intrusion detection system;program processors;security of data;regular expression;analytical model;large data	Business text analytics applications have seen rapid growth, driven by the mining of data for various decision making processes. Regular expression processing is an important component of these applications, consuming as much as 50% of their total execution time. While prior work on accelerating regular expression processing has focused on Network Intrusion Detection Systems, business analytics applications impose different requirements on regular expression processing efficiency. We present an analytical model of accelerators for regular expression processing, which includes memory bus-, I/O bus-, and network-attached accelerators with a focus on business analytics applications. Based on this model, we advocate the use of vector-style processing for regular expressions in business analytics applications, leveraging the SIMD hardware available in many modern processors. In addition, we show how SIMD hardware can be enhanced to improve regular expression processing even further. We demonstrate a realized speedup better than 1.8 for the entire range of data sizes of interest. In comparison, the alternative strategies deliver only marginal improvement for large data sizes, while performing worse than the SIMD solution for small data sizes.	baseline (configuration management);business analytics;central processing unit;email;end-to-end principle;first-order predicate;general-purpose modeling;input/output;marginal model;memory bus;overhead (computing);processor register;regular expression;requirement;run time (program lifecycle phase);simd;speedup;text mining;vector processor	Valentina Salapura;Tejas Karkhanis;Priya Nagpurkar;José E. Moreira	2012	IEEE International Symposium on High-Performance Comp Architecture	10.1109/HPCA.2012.6169044	acceleration;decision-making;text mining;parallel computing;real-time computing;computer science;operating system;data mining;database;processor register;programming language;regular expression;computer network	Arch	-4.852975428304081	47.493680656216725	13779
bf9cc66b970d1b6c0458c43f9d61e750784b18ee	beyond batch computing on the wlcg grid	responsiveness;node protection;resource allocation;prototypes;job agent;task;data processing;grid distributed hep applications wlcg grid batch computing grid computing batch jobs grid technology private virtual cluster interactive grid cpu fairshare mechanism igrid machine data intensive parallel computing dynamic resource allocation remote data processing;tunneling data driven access grid interactivity job agent latency node protection responsiveness task;grid;middleware prototypes monitoring production grid computing data processing;monitoring;resource allocation batch processing computers grid computing interactive systems parallel processing;batch processing computers;interactivity;production;middleware;latency;grid computing;interactive systems;parallel processing;data driven access;tunneling	"""The traditional use of Grid computing consists in submitting batch jobs and waiting for results to be produced, without any prediction of the time at which a job will be effectively started at a selected site. This paper aims at widening the use of Grid technology for enabling a private virtual cluster on the WLCG Grid and running one's favorite software. We term such a system iGrid, interactive Grid, since a user can then """"interact"""" with Grid nodes right away. In addition, the Fairy CPU fairs hare mechanism allows users to get their fair iGrid machine share over a long period. We highlight important principles for introducing interactive capability to the Grid. We present a functioning prototype of iGrid running PROOF - a software for data intensive parallel computing - on top of it. Our prototype implementation scales to all 400 nodes we were granted. The experiment shows the performance of PROOF on iGrid sites and challenges many aspect of dynamic resource allocation and remote data processing. We identify bottlenecks that inhibit interactivity and outline opportunities and limitations for running interactive Grid-distributed HEP applications on the Grid."""	batch processing;central processing unit;data-intensive computing;glossary of computer graphics;grid computing;heterogeneous element processor;high-throughput computing;interactivity;loose coupling;microsoft outlook for mac;middleware;parallel computing;prototype;scalability;throughput;worldwide lhc computing grid	Marco Meoni	2011	2011 IEEE/ACM 12th International Conference on Grid Computing	10.1109/Grid.2011.34	parallel processing;latency;parallel computing;real-time computing;data processing;resource allocation;computer science;operating system;middleware;database;distributed computing;prototype;quantum tunnelling;interactivity;grid;grid computing	HPC	-25.954359404921657	55.02845313637918	13851
4596432085f997c7c0c413a9302423400d4ab844	a novel hot data identification mechanism for nand flash memory	false identification ratio nand flash memory hot data identification mechanism garbage collection wear leveling memory space overhead kernel density estimation read operations write operations kernel density function probability distribution;kernel;memory management;flash memory hot data identification kernel densityfunction multiple bloom filter hash function;radiation detectors;consumer electronics;density functional theory;estimation;probability flash memories nand circuits;flash memories memory management kernel radiation detectors consumer electronics density functional theory estimation;flash memories	Hot data identification plays a very important role in NAND flash memory because it can improve the efficiency of garbage collection and decrease the degree of wear leveling. Existing hot data identification mechanisms have drawbacks in terms of their memory-space overhead and the true identification of hot data. To address these problems, this paper proposes a novel hot data identification mechanism. This mechanism mainly consists of kernel density estimation and a hot degree function. The kernel density estimation is used to build the kernel density function of the read and write operations by monitoring them in the NAND flash memory. That is, the kernel density function can be used for preliminary estimation of the probability distribution of the hot and cold data in NAND flash memory. After preliminary estimation of the kernel density function, the hot degree function is introduced to accurately identify the hot data in the NAND flash memory. Experimental results show that the proposed mechanism performs better than existing hot data identification mechanisms in terms of the false identification ratio between hot data and memory-space overheads.	experiment;flash memory;garbage collection (computer science);identity document forgery;kernel (operating system);kernel density estimation;key derivation function;overhead (computing);wear leveling	Jun Liu;Shuyu Chen;Tianshu Wu;Hancui Zhang	2015	IEEE Transactions on Consumer Electronics	10.1109/TCE.2015.7389800	flash file system;estimation;parallel computing;kernel;real-time computing;computer hardware;computer science;particle detector;density functional theory;statistics;memory management	Security	-11.381307285508036	54.59493956091597	13873
da008b4d75a77f86bcd86a7138d9eb75b421e0a6	time matters: minimizing garbage collection overhead with minimal effort		Parameterization of garbage collectors can help improving the overall run time of programs, but finding the best parameter combination is a tedious task. We used a simple brute-force optimization algorithm for the Java Parallel GC to study the behavior of benchmarks with thousands of configurations. As a result of this study, we propose a practically usable strategy for finding a “good” parameter combination with a small number of experiments. Using this strategy, only 10 configurations need to be tested in order to reduce the garbage collection time down to 21% (56% on average). For the studied benchmarks, this results in an overall performance gain of up to 13%.	algorithm;benchmark (computing);experiment;garbage collection (computer science);java;mathematical optimization;run time (program lifecycle phase)	Günther Blaschek;Philipp Lengauer	2015	Softwaretechnik-Trends		parallel computing;computer science;garbage collection;distributed computing	PL	-17.373368847877494	37.439400475528025	13884
beb99063e0c724ba8da68d6ae07bcb5fbc1a81a9	the pet and dingo tools for deriving distributed implementations from estelle	modelo dinamico;modelizacion;distributed system;systeme reparti;protocole transmission;interface window;implementation;modelo osi;dynamic model;modele osi;modelisation;ejecucion;protocolo transmision;sistema repartido;modele dynamique;modeling;osi model;transmission protocol	Sijelmassi, R. and B. Strausser, The PET and DINGO tools for deriving distributed implementations from Estelle, Computer Networks and ISDN Systems 25 (1993) 841-851. The combination of the Portable Esteile Translator and the Distributed ImplementatioN GeneratOr tools produces distributed implementations from Estelle specifications. The resulting implementations run as one or more operating system processes distributed over several sites of a target distributed system. In addition, the tools generate elements of an X-Window interface which allows centralized or distributed monitoring of some or all of the running modules.	centralized computing;distributed computing;integrated services digital network;operating system;polyethylene terephthalate;x window system	Rachid Sijelmassi;Brett Strausser	1993	Computer Networks and ISDN Systems	10.1016/0169-7552(93)90051-5	embedded system;real-time computing;systems modeling;telecommunications;computer science;implementation;osi model;computer network	Networks	-28.444504424769946	41.52209753159691	13888
77ee477b0e6d0b6245eca5865ba95b55ed3db434	building workload-independent storage with vt-trees	small data item;file-system workloads;random-write workloads;workload-independent storage;concurrent access;current storage system;access pattern;storage system data structure;data size;novel workload-independent data structure;data access pattern	As the Internet and the amount of data grows, the variability of data sizes grows too—from small MP3 tags to large VM images. With applications using increasingly more complex queries and larger data-sets, data access patterns have become more complex and randomized. Current storage systems focus on optimizing for one band of workloads at the expense of other workloads due to limitations in existing storage system data structures. We designed a novel workload-independent data structure called the VT-tree which extends the LSM-tree to efficiently handle sequential and file-system workloads. We designed a system based solely on VT-trees which offers concurrent access to data via file system and database APIs, transactional guarantees, and consequently provides efficient and scalable access to both large and small data items regardless of the access pattern. Our evaluation shows that our user-level system has 2–6.6× better performance for random-write workloads and only a small average overhead for other workloads.	acid;cache (computing);computer data storage;concurrency control;data access;data structure;direction finding;fragmentation (computing);ibm notes;image stitching;live file system;log-structured merge-tree;mp3;online and offline;overhead (computing);plasma cleaning;randomized algorithm;scalability;spatial variability;throttling process (computing);throughput;user space	Pradeep Shetty;Richard P. Spillane;Ravikant Malpani;Binesh Andrews;Justin Seyster;Erez Zadok	2013			real-time computing;computer hardware;computer science;operating system;database	OS	-14.086076862991819	53.70782685689868	13912
ffbaa64406e9978ccbf1388875fad6fdc1f07cd1	real-time behavior of programs	programming language;parallel processes;real time;real time programming deadline scheduling guarded commands parallel processes process control;process control;process control computerized monitoring transformers aerospace electronics hardware state space methods application software automation missiles vehicles;present day;real time programming;guarded commands;parallel processing;deadline scheduling	Verification and compile-time checking of the behavior of programs in real time is an important issue in many applications, e.g., process control, lab automation, and monitoring of missiles and vehicles. Present day programming languages and compilers lack the facilities of calculating execution times of programs.	compile time;compiler;programming language;real-time transcription;verification and validation	Volkmar H. Haase	1981	IEEE Transactions on Software Engineering	10.1109/TSE.1981.231111	embedded system;parallel processing;parallel computing;real-time computing;computer science;operating system;process control;programming language	SE	-24.527363797214708	34.63893132120756	13972
9d2cdd25b090e12d71b721b6fdaa3be78f8a73ff	an efficient racetrack memory for l2 cache in gpgpus			cpu cache;general-purpose computing on graphics processing units;racetrack memory	Ehsan Atoofian;Ahsan Saghir	2017	Comput. Syst. Sci. Eng.		parallel computing;cpu cache;computer science;racetrack memory;distributed computing	DB	-9.523360007862758	43.51493477373371	13976
184e8cbb236d4c36fb340c9667fbbbf4ac1514fe	data driven scheduling approach for the multi-node multi-gpu cholesky decomposition	linear algebra;paper;heterogeneous systems;cuda;nvidia;cublas;tesla k20;computer science;task scheduling	Recently large scale scientific computation on heterogeneous supercomputers equipped with accelerators is receiving attraction. However, traditional static job execution methods and memory management methods are insufficient in order to harness heterogeneous computing resources including memory efficiently, since they introduce larger data movement costs and lower resource usage. This paper takes the Cholesky decomposition computation, which is an important linear algebra kernel, as the target for optimization. And we describe a scalable data-driven scheduling method and a heterogenous memory management method in order to improve resource utilization and reduce amount of data movement. Through the performance evaluation on TSUBAME2.5, which is a heterogenous supercomputer with NVIDIA GPUs, we demonstrate the efficiency of the proposed task scheduling method and data replacement strategies considering data reusability.	cholesky decomposition;computation;computational science;graphics processing unit;heterogeneous computing;linear algebra;mathematical optimization;memory management;performance evaluation;scalability;scheduling (computing);supercomputer	Yuki Tsujita;Toshio Endo	2015		10.1007/978-3-319-61756-5_4	parallel computing;computer science;theoretical computer science;operating system	HPC	-4.822818674108617	41.696814216895994	13995
254e21eeb2dd15612f890334aab069c8d5803480	correlation ratio based volume image registration on gpus	correlation ratio;gpu;histogram;image registration;conflict free	Volume image registration remains one of the best candidates for Graphics Processing Unit (GPU) acceleration because of its enormous computation time and plentiful data-level parallelism. However, an efficient GPU implementation for image registration is still challenging due to the heavy utilization of expensive atomic operations for similarity calculations. In this paper, we first propose five GPU-friendly Correlation Ratio (CR) based methods to accelerate the process of image registration. Compared to widely used Mutual Information (MI) based methods, the CR-based approaches require less resource for shadow histograms, a faster storage, such as the on-chip scratchpad memory, therefore can be fully exploited to achieve better performance. Second, we make design space exploration of the CR-based methods, and study the trade-off of introducing shadow histograms on different storage (shared memory, global memory) by computation units of different granularity (thread, warp, thread block). Third, we exhaustively test the proposed designs on GPUs of different generations (Fermi, Kepler and Maxwell) so that performance variations due to hardware migration are addressed. Finally, we evaluate the performance impact corresponding to the tuning of concurrency, algorithm settings as well as overheads incurred by preprocessing, smoothing and workload unbalancing. We highlight our last CR approach which completely avoids updating conflicts of histogram calculation, leading to substantial performance improvements (up to 55 speedup over naive CPU implementation). It reduces the registration time from 145 s to 2.6 s for two typical 256 256 160 volume images on a Kepler GPU. 2015 Elsevier B.V. All rights reserved.	algorithm;central processing unit;computation;concurrency (computer science);data parallelism;design space exploration;fermi (microarchitecture);graphics processing unit;image registration;kepler (microarchitecture);linearizability;maxwell (microarchitecture);mutual information;parallel computing;preprocessor;scratchpad memory;shared memory;smoothing;speedup;thread block;time complexity	Ang Li;Akash Kumar;Yajun Ha;Henk Corporaal	2015	Microprocessors and Microsystems - Embedded Hardware Design	10.1016/j.micpro.2015.04.002	embedded system;computer vision;parallel computing;correlation ratio;computer science;image registration;theoretical computer science;operating system;histogram;statistics;computer graphics (images)	HPC	-9.8159731213801	51.55884228493759	14000
369195255cd7a9107bbbcad8609880ad9cfde834	performance and scalability analysis of cray x1 vectorization and multistreaming optimization	workload;estensibilidad;computers;scientific application;programa paralelo;evaluation performance;largeur bande;streaming;processing;general and miscellaneous mathematics computing and information science;compilateur;performance evaluation;communications;machine unique;programacion automatica;parallel ocean program;vectorisation;generation code;transmision continua;evaluacion prestacion;boucle programme;performance;transformations;generacion codigo;code generation;optimizacion compiladora;traitement vectoriel;supercomputer;automatic programming;codigo bloque;compiler;vectorization;bucle programa;supercomputador;vectorisacion;transmission en continu;single machine;maquina unica;vectors;programa aplicacion;application program;programme application;compiler optimization;anchura banda;charge travail;computer codes;communication cost;bandwidth;program loop;code bloc;optimization;fortran;extensibilite;scalability;carga trabajo;programming;memory bandwidth;block code;parallel program;vector processing;optimisation compilateur;compilador;superordinateur;programmation automatique;programme parallele	Cray X1 Fortran and C/C++ compilers provide a number of loop transformations, notably vectorization and multistreaming, in order to exploit the multistreaming processor (MSP) hardware resources and its high memory bandwidth. A Cray X1 node is composed of four MSPs, which in turn are composed of four single streaming processors (SSP). Each SSP contains a superscalar processing unit and two vector processing units. Compiler vectorization provides loop level parallelization and uses the vector processing hardware. Multistreaming code generation by the compiler permits execution across the SSPs of an MSP on a block of code. In this paper, we analyze overall impact of loop-level compiler optimization on a scientific application called Parallel Ocean Program (POP). POP has been extensively optimized for X1 by instrumenting the code using X1 compiler directives. We compare and contrast automatic and manual optimization schemes available on X1 and analyze their impact on the code performance and scalability. Our results show that the addition of compiler directives increases the average vector length, thereby improving the single node performance significantly. However, this code scales at a slower rate as the local workload volume decreases and the communication costs increase.	analysis of algorithms;automatic vectorization;central processing unit;code generation (compiler);compatibility of c and c++;computation;cray x1;directive (programming);dummy variable (statistics);fortran;free license;high memory;image scaling;instrumentation (computer programming);loop optimization;mathematical optimization;max;memory bandwidth;optimizing compiler;parallel computing;scalability;supercomputer;superscalar processor;ut-vpn;vector graphics;vector processor	Sadaf R. Alam;Jeffrey S. Vetter	2005		10.1007/11428831_38	block code;transformation;programming;compiler;supercomputer;vector processor;parallel computing;real-time computing;scalability;performance;computer science;artificial intelligence;loop optimization;processing;theoretical computer science;operating system;vectorization;optimizing compiler;database;distributed computing;programming language;memory bandwidth;bandwidth;algorithm;code generation	HPC	-15.915964751647438	42.259991432818914	14012
ff18e9045f00e03d346922ccaffb03db1ea2021a	creating the virtual universe	digital simulation astronomy computing;software engineering simulation software astronomical multipurpose environment amuse astrophysics astrophysics simulations software development;software engineering;astronomical multipurpose environment;simulation software;computational modeling;graphics processing units;software development;astrophysics simulations;amuse;astrophysics;astronomy;multiphysics solver virtual universe simulation software astronomical multipurpose environment amuse;graphics processing units computational modeling software development astrophysics software engineering astronomy	Simulation software is important to our understanding of the universe. The intrinsic multiphysics aspects are spiced with a range of temporal scales and spatial scales, both of which cover more digits than are available in the standard hardware. This, together with the intrinsic chaotic nature of many physical processes, poses quite a challenge. To meet this challenge, researchers developed the Astronomical Multipurpose Environment (AMUSE). Instead of writing a suite of multiphysics solvers from scratch, AMUSE's developers coupled existing solvers for each physical ingredient. The result is a highly inhomogeneous collection of dedicated solvers with a homogeneous protocol that scales to supercomputers.	chaos theory;multiphysics;simulation software;spatial scale;supercomputer;virtual world	Simon Portegies Zwart;Jeroen Bédorf	2016	IEEE Software	10.1109/MS.2016.113	computational science;simulation;simulation software;computer science;engineering;software development;software engineering;software construction;computational model;computer graphics (images)	HPC	-7.58284439429148	36.618284522358536	14043
6ea51eb6912631d32ddee81f066692f7231d65d6	a cluster-m based mapping methodology	cluster m based mapping methodology;parallel algorithm;system graphs;high level machine independent parallel code;parallel programming;computer architecture concurrent computing parallel programming clustering algorithms parallel algorithms algorithm design and analysis topology writing portable computers information science;portable software;parallel programming parallel algorithms;parallel programming paradigm;cluster m specifications;parallel programs;high level constructs cluster m based mapping methodology parallel programming paradigm portable software cluster m specifications cluster m representations high level machine independent parallel code system graphs;high level constructs;cluster m representations;parallel algorithms	Cluster-M is a new parallel programming paradigm for designing portable software. The two main components of this paradigm are Cluster-M specifications and Cluster-M representations. Cluster-M specifications are high level machine independent parallel code which are mapped onto Cluster-M representations, system graphs representing the topologies of the underlying architectures. In this paper, an algorithm for generating Cluster-M representations is presented. Also, a set of high-level constructs essential for writing Cluster-M specifications are shown. Using these components, an efficient methodology is proposed t o map parallel algorithms onto architectures.	high- and low-level;high-level programming language;parallel algorithm;parallel computing;programming paradigm	Mary Mehrnoosh Eshaghian-Wilner;Muhammad E. Shaaban	1993		10.1109/IPPS.1993.262885	computer architecture;parallel computing;computer science;theoretical computer science;parallel algorithm;bulk synchronous parallel;cost efficiency;parallel programming model	HPC	-11.91287097705029	39.55282957026744	14116
176dc77381479f63dedc9546a926febd19a34637	an efficient on-line task allocation algorithm for qos and energy efficiency in multicore multimedia platforms	energy efficiency;cmos integrated circuits;decoding;next generation industrial multicore platform online task allocation algorithm qos energy efficiency multicore multimedia platform cmos multimedia platform core speed variability optimal task allocation cycle accurate virtual prototype;energy efficient;cycle accurate virtual prototype;resource manager;qos guarantee;resource management;multimedia application;qos;multicore multimedia platform;optimal task allocation;virtual prototyping;radio frequency;resource management energy consumption decoding radio frequency quality of service power demand multicore processing;energy consumption;next generation industrial multicore platform;cmos multimedia platform;multicore processing;multimedia communication;next generation;quality of service cmos integrated circuits microprocessor chips multimedia communication multiprocessing systems;energy budget;online task allocation algorithm;multiprocessing systems;quality of service;core speed variability;power demand;energy saving;microprocessor chips;task allocation;time constraint	The impact of variability on sub-45nm CMOS multimedia platforms makes hard to provide application QoS guarantees, as the speed variations across the cores may cause sub-optimal and sample-dependent utilization of the available resources and energy budget. These effects can be compensated by an efficient allocation of the workload at run-time. In the context of multimedia applications, a critical objective is to compensate core speed variability while matching time constraints without impacting the energy consumption. In this paper we present a new approach to compute optimal task allocations at run-time. The proposed strategy exploits an efficient and scalable implementation to find on-line the best possible solution in a tightly bounded time. Experimental results demonstrate the effectiveness of compensation both in terms of deadline miss rate and energy savings. Results have been compared with those obtained applying state-of-art techniques on a multithreaded MPEG2 decoder. The validation has been performed on a cycle-accurate virtual prototype of a next-generation industrial multicore platform that has been extended with process variability models.	algorithm;benchmark (computing);cmos;clock rate;heart rate variability;mpeg-2;mpsoc;multi-core processor;online and offline;overhead (computing);prototype;quality of service;run time (program lifecycle phase);scalability;thread (computing)	Francesco Paterna;Andrea Acquaviva;Alberto Caprara;Francesco Papariello;Giuseppe Desoli;Luca Benini	2011	2011 Design, Automation & Test in Europe	10.1109/DATE.2011.5763025	embedded system;parallel computing;real-time computing;quality of service;computer science;resource management;operating system;efficient energy use;computer network	EDA	-5.12780528588641	58.84185544009083	14134
04d59ad9806ad19246ff0b1fa2a29c4c1eb32ccf	dd-oceanvar: a domain decomposition fully parallel data assimilation software for the mediterranean forecasting system	domain decomposition;data assimilation	OceanVar is a Data Assimilation (DA) software which is being used in Italy within the Mediterranean Forecasting System (MFS) to combine observational data (Sea level anomaly, sea-surface temperatures, etc.) with backgrounds produced by computational models of ocean currents for the Mediterranean Sea (namely, the NEMO framework). OceanVAR is based on a three-dimensional variational approach. We describe computational efforts aimed to design a fully parallel OceanVar software, based on Domain Decomposition (DD), which involves modification of the variational scheme on each sub domain. Our approach aims to face to the ever greater multi-level parallelism and scalability of the current and of the next generation of leadership computing facility systems, while fulfilling the specific requirements of OceanVar within the MFS.	anomaly detection;computation;computational model;data assimilation;domain decomposition methods;linux mint;moose file system;next-generation network;parallel computing;requirement;scalability;variational principle	Luisa D'Amore;Rossella Arcucci;Luisa Carracciuolo;Almerico Murli	2013		10.1016/j.procs.2013.05.290	simulation;theoretical computer science;data mining	SE	-29.85360043149514	50.21651851733146	14148
68e6d8c611b4d646db7772b6e082d48d37d47e72	monitoring pvm programs using the dams approach	distributed system;eficacia sistema;architecture systeme;systeme reparti;multi agent system;performance evaluation;program visualization;programacion paralela;sistema informatico;performance systeme;parallel programming;computer system;system performance;development environment;sistema repartido;ornl;arquitectura sistema;systeme informatique;system architecture;programmation parallele	Monitoring tools are fundamental components of a development environment as they provide basic support for performance evaluation, debugging, and program visualization. We describe our experiments with several monitoring tools for PVM, namely XPVM, developed at ORNL, Tape/PVM, developed at IMAG Lab, and DAMS, developed at UNL. These tools are compared and their use is described to support instrumentation and monitoring of a high level distributed language, PVM-Prolog, an extension to Prolog that provides an interface to PVM. This language is being used for the implementation of multi-agent systems, and it provides support for heterogeneous programs, built from C and Prolog components that communicate using PVM.	attachments;debugger;debugging;distributed computing;experiment;heterogeneous computing;high-level programming language;message passing interface;multi-agent system;online and offline;parallel virtual machine;performance evaluation;prolog;universal networking language	José C. Cunha;Vítor Duarte	1998		10.1007/BFb0056585	embedded system;real-time computing;simulation;computer science;artificial intelligence;multi-agent system;distributed computing;development environment;computer performance;systems architecture	SE	-27.387458774343745	40.180024112557206	14213
0129fe41d388e04a2cc4f54a85218626667979ae	py_bvp: a universal python interface for bvp codes	cluster computing;numerical solution;ordinary differential equation;articulo;boundary value problem;scripting languages;scientific workflows;visualization;py_bvp a universal python interface for bvp codes;software package;fortran	Boundary-value problems (BVPs) for ordinary differential equations arise in many important applications, and over the last few decades a number of high-quality software packages for this problem class have been developed. Some of these solvers have been designed for use on high-performance computers, and there is potential for further development in this direction. Unfortunately these codes, typically written in languages like Fortran or C, require complicated parameter lists and user-written subroutines. Moreover, researchers often want to try more than one solver on a given problem, and doing so can be challenging because the different interfaces to each package require distinctly different code to be written to describe the problem to be solved. In this paper, we present a Python environment called py_bvp that is specifically designed for the numerical solution of BVPs. In addition to providing a uniform interface that allows multiple BVP codes to be conveniently accessed, several tools are provided to support researchers who want to try to use these codes. Furthermore, the py_bvp environment is designed to allow additional BVP codes and tools to be easily added. We discuss the design decisions made to ensure that py_bvp is both user-friendly and easily expandable and give examples to illustrate its use.	computer;fortran;numerical partial differential equations;python;qr code;solver;subroutine;supercomputer;usability	Jason J. Boisvert;Paul H. Muir;Raymond J. Spiteri	2010		10.1145/1878537.1878636	computational science;ordinary differential equation;visualization;computer cluster;boundary value problem;computer science;theoretical computer science;operating system;scripting language;programming language;algorithm	HPC	-9.87931738674105	36.10378713416036	14298
ad7cbb2d3d36d32edc31a08c2738fda4d8a3842d	reducing false aborts in stm systems	conflict detection;performance improvement;hash table;associative memory;concurrent programs;false positive;transactional memory	Transactional memory (TM) continues to be the most promising approach replacing locks in concurrent programming, but TM systems based on software (STM) still lack the desired performance when compared to fine-grained lock implementations. It is known that the critical operation in TM systems is to ensure the atomicity and isolation of concurrently executing threads. This task is known as the read/writeset validation. In attempt to make this process as fast as possible, STM systems usually use ownership tables to perform conflict detection, but this approach generates false positive occurrences, which result in false aborts. This paper shows the real impact of false aborts and how its relevance increases along with the number of concurrent threads, showing it is an essential factor for TM systems. We propose two different techniques to avoid false aborts, showing its benefits and limitations. The first is a collision list attached to the existing hash table. The second is a full associative memory mapping between the addresses and its version information. We achieved significant performance improvements in some STAMP benchmark programs, resulting in speedups up to 1.5x. We also show that speedups become higher when the number of parallel threads	atomicity (database systems);basic stamp;benchmark (computing);cpu cache;central processing unit;collision detection;concurrent computing;content-addressable memory;false sharing;file synchronization;hash table;lock (computer science);relevance;software transactional memory;speedup	Daniel Nicácio;Guido Araujo	2010		10.1007/978-3-642-13119-6_43	hash table;transactional memory;parallel computing;real-time computing;type i and type ii errors;computer science;operating system;distributed computing;programming language;computer security;algorithm	HPC	-14.689709800479037	48.92595412991759	14345
e75a1441c52e7c527104c0ae8ba7d9e9b8160764	ecological memory management in a continuation passing prolog engine	memory management;continuation passing style;garbage collection;functional language	Abst rac t . Starting from a simple 'ecological' metaphor, we introduce a new memory management scheme (heap-lifting) implemented in BinProlog, a continuation passing style variant of WAM. We discuss copying garbage collection mechanisms based on heap-lifting and an OR-parallel execution model. We point out some surprising similarities with related work on functional languages and the difficulties that arise in the context of nondeterministic execution. Finally, we describe the full implementation of two builtins: a recursive copy_terra and a very fast heap-lihing based f i n d a l l and we evaluate their impact on the performances of BinProlog.	continuation;continuation-passing style;functional programming;garbage collection (computer science);intrinsic function;lambda lifting;memory management;performance;prolog;recursion;warren abstract machine	Paul Tarau	1992		10.1007/BFb0017200	manual memory management;parallel computing;computer science;continuation-passing style;theoretical computer science;garbage collection;programming language;functional programming;memory management	PL	-17.515060140248437	33.621089746908005	14389
1cb5a6343e03c299fd9c877d07c077c85c2d012f	a compiler framework for speculative analysis and optimizations	lenguaje programacion;donnee experimentale;fiabilidad;reliability;compilateur;analyse speculative;programming language;redundancia;dato experimental;program transformation;ejecucion programa;tabla dato;optimizacion compiladora;register promotion;transformation programme;exactitude programme;compiler;program execution;partial redundancy elimination;analisis programa;linear functionals;data speculation;performance programme;transformacion programa;exactitud programa;redundancy;speculation;table donnee;execution programme;fiabilite;compiler optimization;speculative execution;langage programmation;speculative ssa form;eficacia programa;program analysis;program performance;data table;analyse programme;speculative weak update;instruction scheduling;open research compiler;especulacion;optimisation compilateur;compilador;redondance;program correctness	Speculative execution, such as control speculation and data speculation, is an effective way to improve program performance. Using edge/path profile information or simple heuristic rules, existing compiler frameworks can adequately incorporate and exploit control speculation. However, very little has been done so far to allow existing compiler frameworks to incorporate and exploit data speculation effectively in various program transformations beyond instruction scheduling. This paper proposes a speculative SSA form to incorporate information from alias profiling and/or heuristic rules for data speculation, thus allowing existing program analysis frameworks to be easily extended to support both control and data speculation. Such a general framework is very useful for EPIC architectures that provide checking (such as advanced load address table (ALAT) [10]) on data speculation to guarantee the correctness of program execution. We use SSAPRE [21] as one example to illustrate how to incorporate data speculation in those important compiler optimizations such as partial redundancy elimination (PRE), register promotion, strength reduction and linear function test replacement. Our extended framework allows both control and data speculation to be performed on top of SSAPRE and, thus, enables more aggressive speculative optimizations. The proposed framework has been implemented on Intel's Open Research Compiler (ORC). We present experimental data on some SPEC2000 benchmark programs to demonstrate the usefulness of this framework and how data speculation benefits partial redundancy elimination.	benchmark (computing);correctness (computer science);heuristic;instruction scheduling;linear function;open research;optimizing compiler;page table;partial redundancy elimination;program analysis;program transformation;scheduling (computing);speculative execution;static single assignment form;strength reduction	Jin Lin;Tong Chen;Wei-Chung Hsu;Pen-Chung Yew;Roy Dz-Ching Ju;Tin-Fook Ngai;Sun Chan	2003		10.1145/781131.781164	program analysis;compiler;speculation;parallel computing;real-time computing;computer science;table;reliability;optimizing compiler;instruction scheduling;redundancy;programming language;speculative execution;partial redundancy elimination	PL	-19.528249042654533	33.620016231811256	14398
39d8685dbbb4a5ed4187cf8303b17a2cb5189fe3	a batch of pnuts: experiences connecting cloud batch and serving systems	serving;hybrid;consistency model;large scale;low latency;file system;indexation;batch;batch process;hadoop;data management system;pnuts;reading and writing;bulk load;transaction level	Cloud data management systems are growing in prominence, particularly at large Internet companies like Google, Yahoo!, and Amazon, which prize them for their scalability and elasticity. Each of these systems trades off between low-latency serving performance and batch processing throughput. In this paper, we discuss our experience running batch-oriented Hadoop on top of Yahoo's serving-oriented PNUTS system instead of the standard HDFS file system. Though PNUTS is optimized for and primarily used for serving, a number of applications at Yahoo! must run batch-oriented jobs that read or write data that is stored in PNUTS.  Combining these systems reveals several key areas where the fundamental properties of each system are mismatched. We discuss our approaches to accommodating these mismatches, by either bending the batch and serving abstractions, or inventing new ones. Batch systems like Hadoop provide coarse task-level recovery, while serving systems like PNUTS provide finer record or transaction-level recovery. We combine both types to log record-level errors, while detecting and recovering from large-scale errors. Batch systems optimize for read and write throughput of large requests, while serving systems use indexing to provide low latency access to individual records. To improve latency-insensitive write throughput to PNUTS, we introduce a batch write path. The systems provide conflicting consistency models, and we discuss techniques to isolate them from one another.	apache hadoop;batch processing;cloud computing;consistency model;elasticity (data store);job stream;pnuts;read-only memory;scalability;sensor;snapshot (computer storage);snapshot algorithm;throughput;weatherstar	Adam Silberstein;Russell Sears;Wenchao Zhou;Brian F. Cooper	2011		10.1145/1989323.1989441	real-time computing;hybrid;computer science;consistency model;database;distributed computing;batch file;batch processing;low latency	OS	-14.250378163500299	52.82421249273634	14414
3f63a2362b1fabc83194d10d6b5a0b2a56c1799b	efficient execution of memory access phases using dataflow specialization	databases;databases hardware algebra acceleration;storage management data flow computing energy conservation energy consumption power aware computing;acceleration;algebra;hardware;dyser memory access phases dataflow specialization processor core dynamic regions address computation energy consumption energy efficiency in core accelerators memory access dataflow dataflow computation event condition action rules sse c cores npu	This paper identifies a new opportunity for improving the efficiency of a processor core: memory access phases of programs. These are dynamic regions of programs where most of the instructions are devoted to memory access or address computation. These occur naturally in programs because of workload properties, or when employing an in-core accelerator, we get induced phases where the code execution on the core is access code. We observe such code requires an OOO core's dataflow and dynamism to run fast and does not execute well on an in-order processor. However, an OOO core consumes much power, effectively increasing energy consumption and reducing the energy efficiency of in-core accelerators.  We develop an execution model called memory access dataflow (MAD) that encodes dataflow computation, event-condition-action rules, and explicit actions. Using it we build a specialized engine that provides an OOO core's performance but at a fraction of the power. Such an engine can serve as a general way for any accelerator to execute its respective induced phase, thus providing a common interface and implementation for current and future accelerators. We have designed and implemented MAD in RTL, and we demonstrate its generality and flexibility by integration with four diverse accelerators (SSE, DySER, NPU, and C-Cores). Our quantitative results show, relative to in-order, 2-wide OOO, and 4-wide OOO, MAD provides 2.4×, 1.4× and equivalent performance respectively. It provides 0.8×, 0.6× and 0.4× lower energy.	computation;dataflow;event condition action;mad;multi-core processor;network processor;object-oriented ontology;out-of-order execution;partial template specialization;reactive programming;streaming simd extensions	Chen-Han Ho;Sung Jin Kim;Karthikeyan Sankaralingam	2015	2015 ACM/IEEE 42nd Annual International Symposium on Computer Architecture (ISCA)	10.1145/2749469.2750390	acceleration;computer architecture;parallel computing;real-time computing;computer science;operating system;programming language	Arch	-6.312558558278744	47.44939590576882	14444
5dbef97bbf63df9e9fb5f92bf42e2d49c984575d	towards parallel machines for artificial intelligence: realization of the alice architecture by the l-components	artificial intelligent;parallel machines	This paper gives an outline of a realization of the ALICE architecture using the modular components on which the L-machine project is based. The ALICE architecture promises to provide an efficient method of parallel evaluating applicative languages and is also suited for parallel programming in logic. Up to now no hardware realization of the ALICE architecture is implemented.	alice;artificial intelligence	K. Aspetsberger	1985		10.1007/978-3-642-46552-9_13	artificial architecture;computer science;artificial intelligence;theoretical computer science;machine learning;artificial intelligence, situated approach	AI	-12.472778270477423	39.61863073231088	14451
54ccb96f19b33ad3f66ebf9af8d886cfa6fc16fc	limits of parallelism in hash join algorithms	tiempo respuesta;parallelisme;algoritmo paralelo;base donnee;parallel algorithm;critical study;performance evaluation;algorithm analysis;performance;limits of parallelism;database;base dato;limit;response time;etude critique;algorithme parallele;temps reponse;estudio critico;parallelism;jointure;paralelismo;database systems;parallel join algorithms;evaluation;analyse algorithme;evaluacion;rendimiento;limite;analisis algoritmo	The performance of parallel hash join algorithms is analyzed in an environment where several join queries are running concurrently. Analytical models for predicting the throughput and response time of join queries are developed. We consider two important parallel join algorithms: hybrid hash and Grace join. The effect of skew on the performance of these algorithms is examined. Results based on the analytical models, as well as simulation results, are presented. Some of the results obtained are quite unusual. For instance, in the case of the hybrid hash algorithm, we show that, under heavy load, the response time versus degree of parallelism curve can have two local minima. We establish a simple rule of thumb for choosing the degree of parallelism in order to maximize the throughput of the hybrid hash algorithm. In the case of Grace join, we derive asymptotic conditions on the amount of skew for a limit on parallelism to exist.	algorithm;hash join;join (sql)	Antoine N. Mourad;Robert J. T. Morris;Arun N. Swami;Honesty C. Young	1994	Perform. Eval.	10.1016/0166-5316(94)90019-1	hash join;double hashing;parallel computing;hash function;perfect hash function;primary clustering;performance;computer science;theoretical computer science;evaluation;limit;rolling hash;parallel algorithm;response time;algorithm;hash filter	DB	-17.2471219393824	45.14210691407872	14509
0592ee165b7baea73fecedf2c3499747624924f3	tscale: a contention-aware multithreaded framework for multicore multiprocessor systems		On the multicore and multiprocessor system, multithreaded applications which are kernel-intensive usually suffer from two kinds of performance issues, first one is frequent context switch between kernel/user mode. Another one is lock contention caused by non-scalable synchronization primitives (e.g., ticket spin lock) and may even result in performance degradation under heavy contention level. Unfortunately, current Linux threading model (i.e., NPTL) which adopts exception-based system call mechanism fails to reduce the excessive system call cost. Besides, conventional threading scheduler which is unconscious of lock contention also lacks the ability to limit the number of system-wide contending parallel threads. Both of them impede the application's throughput increment and may lead to the performance breakdown eventually. In this paper we propose a contention-aware threading framework to alleviate these two problems. Our proposed design is composed of two tightly contected components: system call batching via user-level thread library and a contention-aware scheduler based on non-work-conserving scheduling policy. The user-level threading library gathers multiple system call invocations transparently and deliverys these requests to the underlaying kernel working threads. Therefore, tScale improves application performance by reducing massive context switch cost. Then through continuing monitoring system-wide lock contention level and application's total throughput increment, tScale can quickly adjust the number of contending threads in order to sustain the maximum throughput. The prototype system is implemented on Linux 3.18.30 and Glibc 2.23. In microbenchmarks on a 32-core machine, experiment results show that our approach can not only improve the application throughput by up to 20% but also address the lock contention efficiently.	benchmark (computing);context switch;elegant degradation;gnu c library;kernel (operating system);linux;lock (computer science);maximum throughput scheduling;multi-core processor;multiprocessing;native posix thread library;prototype;regular expression;scalability;scheduling (computing);speedup;spinlock;system call;thread (computing);threaded code;user space	Miao Cai;Shenming Liu;Hao Huang	2017	2017 IEEE 23rd International Conference on Parallel and Distributed Systems (ICPADS)	10.1109/ICPADS.2017.00052	lock (computer science);context switch;real-time computing;scheduling (computing);system call;spin-½;multiprocessing;thread (computing);computer science;multi-core processor	HPC	-9.467968180733878	50.71887188663474	14551
1b4771c079829e71e0f61cc20a233863ef493897	design and implementation of a trader-based resource management system	information model;user interface;design and implementation;distributed computing system;distributed computing environment;resource management system;open distributed processing;directory service	Distributed computing systems are composed of various types and sizes of resources. Providing a reliable and e cient distributed computing environment largely depends on the effective management of these resources. ISO has begun work on a proposed standard for Open Distributed Processing (ODP).The ODP framework includes a mechanism called the Trader which provides a framework for exchanging services in an open distributed computing environment. This paper presents a design of Trader-Based Resource Management System (TBRMS) which employs and extends the ODP Trader concept to the management of general resources in distributed computing systems. We describe its architecture, information model, and user interface. We also present an implementation e ort of its prototype which uses the X.500 Directory Service as its resource information repository.	directory service;distributed computing environment;information model;information repository;management system;open road tolling;prototype;rm-odp;trader media east;traders;user interface;x.500	A. Warren Pratten;James Won-Ki Hong;J. Michael Bennett;Michael Anthony Bauer;Hanan Lutfiyya	1994		10.1145/782241	distributed algorithm;dce/rpc;directory service;information model;computer science;operating system;database;distributed computing;utility computing;distributed design patterns;user interface;world wide web;distributed computing environment;autonomic computing	HPC	-32.393240107168374	48.51001964047033	14622
c1341d7e4ee8c3aa20da1535b3950a05c233597b	on affinity based routing in multi-system data sharing	data sharing;database system;queueing model;concurrency control;communication delay;load balance;analytical modelling;trace driven simulation;integer linear program;analytical model	Multiple systems coupling incurs performance degradation due to inter-system (global) lock conlention and database buffer invalidation. At high transaction rates, the level of inter-syslem interference can have a severe hnpact on performance. In this paper, we propose a scheme for transaction routing lhat reduces inter-system interference while keeping load nearly balanced. The routing decision is based on affinity relations defined between transactions and databases. A methodology, employing an integer linear programming technique, is developed to classify incoming transactions into affinity groups based on their dotuba& call reference puffem. Based on traces from two of IBM’s high volume single system customers, we find that. at high lransaction rates, the proposed aflinily based routing significantly reduces the lock contention probability and leads to a substantial reduction in transaction response time. Further, the reduction in inter-system data contenlion, produces a large hnpact on the performance of optimislic type concurrency control.	affinity analysis;approximation algorithm;concurrency (computer science);concurrency control;database;elegant degradation;information management system (ims);integer programming;interference (communication);linear programming;lock (computer science);optimal control;processor affinity;response time (technology);routing;simulation;tracing (software)	Philip S. Yu;Douglas W. Cornell;Daniel M. Dias;Balakrishna R. Iyer	1986			real-time computing;computer science;load balancing;theoretical computer science;concurrency control;database;distributed computing	DB	-12.56582505215991	51.689094351224135	14649
4bf0de201b5fc9121bbc5c9378fecc016d127ab7	influence of infiniband fdr on the performance of remote gpu virtualization	virtualisation graphics processing units parallel architectures;virtualization;paper;rcuda framework infiniband fdr remote gpu virtualization high performance computing cluster interconnection network gpu accelerated application infini band qdr gigabit ethernet;cuda;computer architecture;parallel architectures;graphics processing units;comunicacion en congreso;nvidia;bandwidth;tesla k20;computer science;capitulo de libro;virtualisation;graphics processing units bandwidth virtualization servers throughput pipelines computer architecture	The use of GPUs to accelerate general-purpose scientific and engineering applications is mainstream today, but their adoption in current high-performance computing clusters is impaired primarily by acquisition costs and power consumption. Therefore, the benefits of sharing a reduced number of GPUs among all the nodes of a cluster can be remarkable for many applications. This approach, usually referred to as remote GPU virtualization, aims at reducing the number of GPUs present in a cluster, while increasing their utilization rate. The performance of the interconnection network is key to achieving reasonable performance results by means of remote GPU virtualization. To this end, several networking technologies with throughput comparable to that of PCI Express have appeared recently. In this paper we analyze the influence of InfiniBand FDR on the performance of remote GPU virtualization, comparing its impact on a variety of GPU-accelerated applications with other networking technologies, such as Infini-Band QDR and Gigabit Ethernet. Given the severe limitations of freely available remote GPU virtualization solutions, the rCUDA framework is used as the case study for this analysis. Results show that the new FDR interconnect, featuring higher bandwidth than its predecessors, allows the reduction of the overhead of using GPUs remotely, thus making this approach even more appealing.	bandwidth (signal processing);computation;computer data storage;data center;dhrystone;electrical connection;general-purpose markup language;gigabit;graphics processing unit;infiniband;interconnection;l band;overhead (computing);pci express;period-doubling bifurcation;quad data rate sram;server (computing);supercomputer;throughput;x86 virtualization;rcuda	Carlos Reaño;Rafael Mayo;Enrique S. Quintana-Ortí;Federico Silla;José Duato;Antonio J. Peña	2013	2013 IEEE International Conference on Cluster Computing (CLUSTER)	10.1109/CLUSTER.2013.6702662	embedded system;parallel computing;virtualization;computer science;operating system;computer network	HPC	-9.80945740734536	46.961348069887784	14672
832f6008cd3ec2c48bc6810b9ca574031fbea58b	maker as a service: moving hpc applications to jetstream cloud		As cloud resources become more available as an execution platform, the need to transition applications between HPC and the cloud becomes a necessity. However, because of the complex setup and system specific demands of these applications, transition is difficult and may not scale as desired. Jetstream is a NSF funded cloud service that is aiming to provide these services for users in a dynamical allocated nature. In this work we look at three key areas to focus on when transitioning between resources: providing a portable reproducible environment, scaling between local and remote resources, and using feedback to the user for informing configuration and runtime decisions. Building on the MAKER bioinformatic application, we have deployed WQ-MAKER on the Jetstream cloud platform, helping to annotate over 30 genomes and accelerating performance from days to hours and weeks to days.	bioinformatics;browser speed test;cloud computing;ibm notes;image scaling;meeting maker;message passing interface;parallel computing;scalability;software deployment;valkyria chronicles iii	Nicholas L. Hazekamp;Upendra Kumar Devisetty;Nirav Merchant;Douglas Thain	2018	2018 IEEE International Conference on Cloud Engineering (IC2E)	10.1109/IC2E.2018.00029	scalability;workflow;cloud computing;distributed computing;computer science	HPC	-28.33186920007497	53.29282851516877	14703
84bcb3e72aee77d69e7cadbf43b3d6026fb6f8f7	dudetm: building durable transactions with decoupling for persistent memory	storage systems;emerging memory technologies;transactional memory	Emerging non-volatile memory (NVM) offers non-volatility, byte-addressability and fast access at the same time. To make the best use of these properties, it has been shown by empirical evidence that programs should access NVM directly through CPU load and store instructions, so that the overhead of a traditional file system or database can be avoided. Thus, durable transactions become a common choice of applications for accessing persistent memory data in a crash consistent manner. However, existing durable transaction systems employ either undo logging, which requires a fence for every memory write, or redo logging, which requires intercepting all memory reads within transactions.  This paper presents DUDETM, a crash-consistent durable transaction system that avoids the drawbacks of both undo logging and redo logging. DUDETM uses shadow DRAM to decouple the execution of a durable transaction into three fully asynchronous steps. The advantage is that only minimal fences and no memory read instrumentation are required. This design also enables an out-of-the-box transactional memory (TM) to be used as an independent component in our system. The evaluation results show that DUDETM adds durability to a TM system with only 7.4 ~ 24.6% throughput degradation. Compared to the existing durable transaction systems, DUDETM provides 1.7times to 4.4times higher throughput. Moreover, DUDETM can be implemented with existing hardware TMs with minor hardware modifications, leading to a further 1.7times speedup.	byte;central processing unit;coupling (computer programming);durability (database systems);dynamic random-access memory;elegant degradation;non-volatile memory;out of the box (feature);overhead (computing);persistent memory;speedup;throughput;transactional memory;undo;volatile memory;volatility	Mengxing Liu;Mingxing Zhang;Kang Chen;Xuehai Qian;Yongwei Wu;Weimin Zheng;Jinglei Ren	2017		10.1145/3037697.3037714	uniform memory access;embedded system;interleaved memory;transactional memory;parallel computing;real-time computing;computer science;operating system;flat memory model;programming language;registered memory;memory management	Arch	-12.607413829274167	53.25832438313642	14778
362855ec18b3febbbb668a85221d59ff094ec1b2	the case for determinism in database systems	high availability;database system;deadlock detection;deadlock avoidance;distributed database system;concurrency control	Replication is a widely used method for achieving high availability in database systems. Due to the nondeterminism inherent in traditional concurrency control schemes, however, special care must be taken to ensure that replicas don’t diverge. Log shipping, eager commit protocols, and lazy synchronization protocols are well-understood methods for safely replicating databases, but each comes with its own cost in availability, performance, or consistency. In this paper, we propose a distributed database system which combines a simple deadlock avoidance technique with concurrency control schemes that guarantee equivalence to a predetermined serial ordering of transactions. This effectively removes all nondeterminism from typical OLTP workloads, allowing active replication with no synchronization overhead whatsoever. Further, our system eliminates the requirement for two-phase commit for any kind of distributed transaction, even across multiple nodes within the same replica. By eschewing deadlock detection and twophase commit, our system under many workloads outperforms traditional systems that allow nondeterministic transaction reordering.	concurrency (computer science);concurrency control;deadlock;distributed database;distributed transaction;high availability;lazy evaluation;log shipping;nondeterministic algorithm;online transaction processing;overhead (computing);synchronization (computer science);turing completeness;two-phase commit protocol	Alexander Thomson;Daniel J. Abadi	2010	PVLDB	10.14778/1920841.1920855	real-time computing;isolation;database transaction;distributed transaction;computer science;deadlock;concurrency control;database;distributed computing;high availability;serializability;acid;deadlock prevention algorithms;distributed concurrency control	DB	-22.304625078347083	48.33110831354183	14783
0e653e9f41b9a3f125fc00c64d525173b96dd92b	towards high-assurance multiprocessor virtualisation	theorem proving;critical system;work in progress	Virtualisation is increasingly being used in security-critical systems to provide isolation between system components. Being the foundation of any virtualised system, hypervisors need to provide a high degree of assurance with regards to correctness and isolation. Microkernels, such as seL4, can be used as hypervisors. Functional correctness of seL4’s uniprocessor C implementation has been formally verified. The framework employed to verify seL4 is tailored to facilitate reasoning about sequential programs. However, we want to be able to use the full power of multiprocessor/multicore systems, and at the same time, leverage the high assurance seL4 already gives us for uniprocessors. This work-in-progress paper explores possible multiprocessor designs of seL4 and their amenability to verification. For the chosen design, it contributes a formal multiprocessor execution model to lift seL4’s uniprocessor model and proofs into a multiprocessor context using only minor modifications. The theorems proving the validity of the lift operation are machine-checked in Isabelle/HOL and walked-through in the paper.	application binary interface;bootstrapping (compilers);central processing unit;concurrency (computer science);correctness (computer science);formal verification;hol (proof assistant);high- and low-level;hypervisor;isabelle;l4 microkernel family;multi-core processor;multikernel;multiprocessing;observable;parallel computing;refinement (computing);security bug;uniprocessor system	Michael von Tessin	2010			real-time computing;computer science;distributed computing;algorithm	Arch	-23.180812363505453	34.84852866659951	14801
3afcac7d20d5c4c61aa0445243bd8cea74237da4	random i/o scheduling in online tertiary storage systems	database system;storage system;content based analysis;teradata;user defined functions;parallel multimedia database;random access	New database applications that require the storage and retrieval of many terabytes of data are reaching the limits for disk-based storage systems, in terms of both cost and scalability. These limits provide a strong incentive for the development of databases that augment disk storage with technologies better suited to large volumes of data. In particular, the seamless incorporation of tape storage into database systems would be of great value. Tape storage is two orders of magnitude more efficient than disk in terms of cost per terabyte and physical volume per terabyte; however, a key problem is that the random access latency of tape is three to four orders of magnitude slower than disk. Thus, to incorporate a tape bulk store in an online storage system, the problem of tape access latency must be solved. One approach to reducing the latency is careful I/O scheduling. The focus of this paper is on efficient random I/O scheduling for tape drives that use a serpentine track layout, such as the Quantum DLT and the IBM 3480 and 3590. For serpentine tape, I/O scheduling is problematic because of the complex relationships between logical block numbers, their physical positions on tape, and the time required for tape positioning between these physical positions. The results in this paper show that our scheduling schemes provide a significant improvement in the latency of random access to serpentine tape.	computer data storage;dlt;database;disk storage;i/o scheduling;ibm 3590;input/output;logical volume management;magnetic tape data storage;quantum;random access;scalability;scheduling (computing);seamless3d;tape drive;terabyte	Bruce Hillyer;Abraham Silberschatz	1996		10.1145/233269.233332	embedded system;real-time computing;computer science;user-defined function;computer data storage;database;access method;random access;i/o scheduling	DB	-15.00968357450188	54.16774054064182	14805
4f4cc46a698962bf7f7e8ebfba47b1ee4609c363	main memory for user microprogram residence - an analysis	user microprogram residence;main memory;multiprogramming environment;microprogrammed computer organization;dynamic user microprogramming	Microprogrammed computer organizations are divided into three categories to analyze methods of allowing dynamic user microprogramming. Main memory is considered for user microprogram residence in a multiprogramming environment, and conclusions are drawn regarding such a scheme.	computer data storage;computer multitasking;microcode	Richard T. Thomas	1973		10.1145/800203.806229	parallel computing;real-time computing;computer hardware;computer science	Arch	-11.996354033564636	47.43387618731633	14807
8c6286bf0353cf2bd86abc74477087f9f12c763a	sprint: speculative prefetching of remote data	automatic;tool;caching;java programming;batching;prefetching;remote data;web service;compiler;run time system;speculation;data access;parallelization;run time	Remote data access latency is a significant performance bottleneck in many modern programs that use remote databases and web services. We present Sprint - a run-time system for optimizing such programs by prefetching and caching data from remote sources in parallel to the execution of the original program. Sprint separates the concerns of exposing potentially-independent data accesses from the mechanism for executing them efficiently in parallel or in a batch. In contrast to prior work, Sprint can efficiently prefetch data in the presence of irregular or input-dependent access patterns, while preserving the semantics of the original program.  We used Sprint to automatically improve the performance of several real-world Java programs that access remote databases (MySQL, DB2) and web services (Facebook, IBM's Yellow Pages). Sprint achieves speedups ranging 2.4x to 15.8x over sequential execution, which are comparable to those achieved by manually modifying the program for asynchronous and batch execution of data accesses. Sprint provides a simple interface that allows a programmer to plug in support for additional data sources without modifying the client program.	application programming interface;asynchronous i/o;batch processing;cpu cache;client (computing);data access;database;java;mysql;programmer;run time (program lifecycle phase);runtime system;scrum (software development);speculative execution;sprint (software development);web service	Arun Raman;Greta Yorsh;Martin T. Vechev;Eran Yahav	2011		10.1145/2048066.2048088	web service;data access;compiler;speculation;parallel computing;real-time computing;computer science;operating system;programming language;automatic transmission	PL	-18.937758515695066	37.76131532106949	14814
e80db84629f2941fb1a7646c9b2271261cb16903	analytic modeling and comparisons of striping strategies for replicated disk arrays	workload;modelizacion;processus ponctuel;magnetic disc storage;stochastic modeling;replication;disk arrays;base donnee;cluster;performance evaluation;queuing model;amas;availability;equations organizing availability databases analytical models queueing analysis delay stochastic processes transforms iterative methods;disponibilidad;queueing theory;transform method;point process;database;base dato;estrategia;data replication;failure mode;indexing terms;replicacion;strategy;modelisation;functional equation;point processes;stochastic processes;transform methods;chained declustering;dc clustering analytic modeling striping strategies replicated disk arrays data replication data availability database applications queries transactions skewed access pattern disk queuing policy m g 1 queuing model iterative functional equation query scan delay distribution simulations uniform striping strategies stable performance;performance evaluation replicated databases magnetic disc storage queueing theory stochastic processes distributed databases;policy design;charge travail;distributed databases;proceso puntual;m g 1 queues;monton;iterative functional equations;stochastic model;carga trabajo;modeling;strategie;disponibilite;modelo estocastico;replicated databases;modele stochastique;analytical model;disk array;mirrored disks	Data replication has ’been widely used as a means of increasing the data availability for critical applications in the event of disk failure. There are different ways of organizing the two copies of the data across a disk array. This paper compares strategies for striping data of the two copies in the context of database applications. By keeping both copies active, we explore strategies that can take advantage of the additional copy to improve not only availability, but also performance during both normal and failure modes. We consider the effects of small and large stripe sizes on the performance of disk arrays with two active copies of data under a mixed workload of queries and transactions with a skewed access pattern. We propose a dual (hybrid) striping strategy which uses different stripe sizes for the two copies and a disk queuing policy designed to exploit this organization for optimal performance. An analytical model is devised for this scheme, by treating the individual disks as independent, and applying an WG/1 queuing model. Disks on which a large query scan is running are modeled by a variation of the queue with permanent customers, which leads to an iterative functional equation for the query scan delay distribution. A solution for this equation is given. The results are validated against simulations and are shown to match well. Comparison with uniform striping strategies show that the dual striping scheme yields the most stable performance in a variety of workloads, out-performing the uniform striping strategy using either mirrored or chained declustering under both normal and failure mode operations.	data striping;disk array;failure cause;iterative method;organizing (structure);queueing theory;replication (computing);simulation	Arif Merchant;Philip S. Yu	1995	IEEE Trans. Computers	10.1109/12.372034	stochastic process;embedded system;parallel computing;real-time computing;data striping;disk array;telecommunications;computer science;operating system;database;point process;distributed computing;distributed database;algorithm;statistics;computer network	DB	-19.715032672441897	46.704195269573646	14862
bdf0018d33daf98c2b48ef366878368ba18434d4	planning your sql-on-hadoop deployment using a low-cost simulation-based approach	sql on hadoop;performance;simulation;deployment planning;simulator;big data;optimization;impala;modeling;systemc	"""The term """"SQL-on-Hadoop"""" has recently gained significant traction [19]. Impala represents a new emerging class of SQL-on-Hadoop systems that exploit a shared-nothing parallel database architecture over Hadoop. Impala was designed to close the gap of near real time data analytics on Hadoop stack and it has shown itself to be significantly more efficient than other SQL-on-Hadoop solutions [13]. However, it is not a trivial task to leverage Impala for handling queries with different business demands [12]. Improperly deploying an Impala cluster may not give you the expected performance you want. In this paper, we propose a novel Impala simulation framework to help IT professionals to understand its performance behavior. This would simplify the deployment planning work required to enable big data analytics on SQL-on-Hadoop systems. An Impala simulator models the behavior of a complete software stack and simulates the activities of cluster components such as storage, network, processors and memory. Moreover, the accuracy of the simulation remain high in response to both software configuration and hardware changes, it reflects the expected scaling trend with low cost overhead and fast simulation speed. The Impala simulator has been validated against various S/W and H/W configurations, using the well-known TPC-DS benchmark [15], and the simulation results are valid and expected. A use case is provided to show how one would use the simulator to solve their performance and deployment issues."""	algorithm;apache hadoop;benchmark (computing);big data;central processing unit;computer cluster;data compression;hash join;ibm tivoli storage productivity center;image scaling;multi-user;overhead (computing);parallel database;real-time computing;sql;shared nothing architecture;simulation;software deployment;total cost of ownership;traction teampage;whole earth 'lectronic link	Jun Liu;Bianny Bian;Samantika Subramaniam Sury	2016	2016 28th International Symposium on Computer Architecture and High Performance Computing (SBAC-PAD)	10.1109/SBAC-PAD.2016.31	parallel computing;real-time computing;simulation;systems modeling;big data;performance;computer science;operating system;database	Arch	-21.216869489868312	56.764003632444485	14876
6544be854da1c25121186f05d6bd8b6e3eb4fc3d	a fluid-structure-interaction tool by coupling of existing codes	fluid structure interaction;dynamic process management;partitioned approach	Fluid-Structure-Interaction (FSI), as a sub-discipline of computational mechanics, has been gaining relevance since the growth in clusters capacity has made it possible to simulate high resolution models. Although some commercial tools already present certain capabilities for coupled simulations, the lack of efficiency of these general purpose programs is still an issue. Moreover, the high cost of commercial licenses - on a per processor basis - hampers the computation of high resolution models for academic research. Instead, a coupled software solution that resorts to well established existent programs proves a good alternative to preserve the value of decades-long development and associated know-how. However, since such codes were mostly conceived for standalone run, an elegant software implementation is not easily achieved.  In this work our CFD code SPARC has been coupled with the open-source structural solver CalculiX by means of the in-house developed software packet FSiM. FSiM stands for Fluid-Structure-Interaction Simulation Manager and is in charge of the communication between the fluid and structure solver using the Dynamic Process Management of the MPI-2 standard. This approach facilitates that the parallelization strategies of both part-solvers be used with minimal modifications and no risk of mutual interference. Results of a simple two-dimensional test case of the panel flutter problem are presented to show the capabilities of the new coupling tool.	audio system measurements;charge-coupled device;code;computation;computational mechanics;image resolution;interference (communication);message passing interface;open-source software;parallel computing;relevance;sparc;simulation;solver;stanford university centers and institutes;test case	Pablo Mosquera Michaelsen;Balázs Pritz;Martin Gabi	2013		10.1145/2488551.2488575	simulation;computer science;theoretical computer science;engineering drawing	HPC	-6.938237062964491	37.55677469922276	14919
7402025aaeee7a4dbf35a667ea62cd2d5d7f897b	a network-aware distributed membership protocol for collaborative defense	software metrics;detectors;topology;protocols;dynamic enterprise environment;collaborative defense;software metrics internet invasive software;network aware;network topology;decentralized membership;collaborative defense scalability adaptivity decentralized membership network aware real world data;real world data;adaptivity;network aware distributed membership protocol;internet;grippers;invasive software;scalability;peer to peer computing;network malware;multiple system metrics;multiple system metrics network aware distributed membership protocol collaborative defense network malware dynamic enterprise environment;dynamic networks;protocols computer worms peer to peer computing costs international collaboration network topology detectors computer networks distributed computing power engineering computing	To counteract current trends in network malware, distributed solutions have been developed that harness the power of collaborative end-host sensors. While these systems greatly increase the ability to defend against attack, this comes at the cost of complexity due to the coordination of distributed hosts across the dynamic network. Many previous solutions for distributed membership maintenance are agnostic to network conditions and have high overhead, making them less than ideal in the dynamic enterprise environment. In this work, we propose a network-aware, distributed membership protocol, CLUSTER, which improves the performance of the overlay system by biasing neighbor selection towards beneficial nodes based on multiple system metrics and network social patterns (of devices and their users). We provide an extensible method for aggregating and comparing multiple, possibly unrelated metrics. We demonstrate the effectiveness and utility of our protocol through simulation using real-world data and topologies. As part of our results, we highlight our analysis of node churn statistics, offering a new distribution to accurately model enterprise churn.	biasing;computer cluster;dynamic enterprise;malware;overhead (computing);sensor;simulation	David Zage;Carl Livadas;Eve M. Schooler	2009	2009 International Conference on Computational Science and Engineering	10.1109/CSE.2009.173	communications protocol;detector;real-time computing;scalability;the internet;computer science;operating system;data mining;database;distributed computing;computer security;network topology;software metric;computer network	HPC	-24.5716272672274	53.62803625312275	14930
da92442bffc47ac89d7eb5e520b705681197a7b0	hips-lspp keynotes	software;biological system modeling;parallel programming;computational modeling;computational modeling adaptation models software biological system modeling parallel programming parallel processing;adaptation models;parallel processing	HIPS-LSPP Keynotes	labeled security protection profile	Torsten Hoefler;Laxmikant V. Kalé	2015	2015 IEEE International Parallel and Distributed Processing Symposium Workshop	10.1109/IPDPSW.2015.173	computational science;parallel processing;computer architecture;parallel computing;computer science;theoretical computer science;computational model	Embedded	-9.36002558153867	40.16359203019973	14949
572874a531bc403e276662d2999505878f05d28f	on the acceleration of wavefront applications using distributed many-core architectures	parallel algorithm;indexing terms;qa76 electronic computers computer science computer software;qa75 electronic computers computer science;high performance computer;performance model;nas parallel benchmarks;performance modelling	In this paper we investigate the use of distributed GPU-based architectures to accelerate pipelined wavefront applications – a ubiquitous class of parallel algorithm used for the solution of a number of scientific and engineering applications. Specifically, we employ a recently developed port of the LU solver (from the NAS Parallel Benchmark suite) to investigate the performance of these algorithms on high-performance computing solutions from NVIDIA (Tesla C1060 and C2050) as well as on traditional clusters (AMD/InfiniBand and IBM BlueGene/P). Benchmark results are presented for problem classes A to C and a recently developed performance model is used to provide projections for problem classes D and E, the latter of which represents a billion-cell problem. Our results demonstrate that while the theoretical performance of GPU solutions will far exceed those of many traditional technologies, the sustained application performance is currently comparable for scientific wavefront applications. Finally, a breakdown of the GPU solution is conducted, exposing PCIe overheads and decomposition constraints. A new k-blocking strategy is proposed to improve the future performance of this class of algorithm on GPU-based architectures.	benchmark (computing);blocking (computing);blue gene;central processing unit;code;computer hardware;gpu cluster;graphics processing unit;high- and low-level;infiniband;manycore processor;mathematical optimization;nas parallel benchmarks;nvidia tesla;pci express;parallel algorithm;parallel computing;performance per watt;petascale computing;programmer;scalability;solver;supercomputer;task parallelism	Simon J. Pennycook;Simon D. Hammond;Gihan R. Mudalige;Steven A. Wright;Stephen A. Jarvis	2012	Comput. J.	10.1093/comjnl/bxr073	computational science;parallel computing;index term;computer science;theoretical computer science;operating system;database;parallel algorithm	HPC	-6.027325934816818	40.46101458736979	14986
c1332bf39b90fc791dc7faaeb9ea42664c14cb2e	the design and implementation of a version server for computer-aided design	outil logiciel;concepcion asistida;interfase usuario;computer aided design;software tool;base donnee;user interface;estudio comparativo;database;base dato;systeme conversationnel;etude comparative;version server;design and implementation;interactive system;herramienta controlada por logicial;analyse performance;computer aided design databases;comparative study;performance analysis;sistema conversacional;conception assistee;interface utilisateur;systeme gestion base donnee;sistema gestion base datos;version and configuration management;database management system;analisis eficacia	Abstract#R##N##R##N#The Version Server is a system for managing the versions and configurations of design descriptions as they change over time. In this paper we focus on the design and implementation of such a system, which we have built at U.C. Berkeley. The data model supported and the browser application are introduced to illustrate the system's user and application interface. The design decisions and details of the internal architecture are described and the system's performance is evaluated. For structure-oriented queries, such as ‘traverse an entire chip's design hierarchy’, the Version Server is about five times as fast as comparable design management systems that store their design objects as files in a hierarchical file system.	computer-aided design	Ellis E. Chang;David Gedye;Randy H. Katz	1989	Softw., Pract. Exper.	10.1002/spe.4380190302	simulation;idef4;computer science;operating system;computer aided design;comparative research;database;user interface	EDA	-26.736208446223756	39.54136418975442	15016
23a07d34f1e6d514fba17f2538b1f4e892cf2917	extended timed petri nets for distributed multimedia presentation	control systems;petri nets multimedia systems communication system control control systems floors computer aided instruction mathematical model scheduling power system modeling stochastic processes;computer aided instruction;distributed multimedia;multimedia systems;time petri net;stochastic processes;scheduling;mathematical model;petri nets;power system modeling;communication system control;floors	Building a web-based distributed multimedia presentation system environment is a technical challenge .In this paper, we described how to present different multimedia objects on a web presentation system with floor control mechanism as a result of the distributed environment indispensably. The distributed approach is based on an extended timed Petri net model. Using characterization of extended time Petri net, we introduce the concepts of user interaction. The main goal of our system is to provide a feasible method to represent different multimedia objects with user interaction and floor control mode. In addition, users can dynamically request different kinds of conditions during the presentation. To verify the structural mechanism, we implement an algorithm using the Extend Time Petri net model. Futhremore, we consider the interactive facilities to support the distributed communication requirement. We specified a floor control algorithm based on Z notation, which provides four types of control (free access, equal control, group discussion, and direct contact). These control mechanisms are sufficient to the use of distance learning environment.	algorithm;control system;environment variable;petri net;web application;z notation	Timothy K. Shih;Huan-Chao Keh;Lawrence Y. Deng;Sheng-En Yeh;Chun-Hung Huang	2001	Proceedings 15th International Parallel and Distributed Processing Symposium. IPDPS 2001	10.1109/IPDPS.2001.925061	stochastic process;real-time computing;simulation;computer science;control system;operating system;mathematical model;distributed computing;process architecture;scheduling;petri net;statistics	SE	-33.04738633440735	35.399554865019	15037
b49bc4f4ce258cc3922659dbe8f43ab87f7e634e	message composition and its application to event- driven system construction				Alexander Colesnicov	1995	The Computer Science Journal of Moldova		mathematics;message broker;composition (visual arts);distributed computing	Logic	-32.17818690042706	34.93801573138349	15087
67cae545345e305ae878f22e3d959831371b21b5	set-dueling-controlled adaptive insertion for high-performance caching	insertion;analytical models;dynamic change;cache storage;storage management cache storage;lru replacement policy;optimized production technology;replacement;art;cache;memory intensive workloads;storage management;radiation detectors;presses;memory intensive workloads set dueling controlled adaptive insertion high performance caching lru replacement policy;hybrid power systems;set dueling;set dueling cache replacement thrashing insertion set sampling;set dueling controlled adaptive insertion;thrashing;electronics packaging;high performance caching;high performance;art data structures hardware cache storage system performance bridges filters proposals;set sampling;replacement policy	The commonly used LRU replacement policy causes thrashing for memory- intensive workloads. A simple mechanism that dynamically changes the insertion policy used by LRU replacement reduces cache misses by 21 percent and requires a total storage overhead of less than 2 bytes.	byte;cpu cache;cache (computing);insertion sort;overhead (computing);thrashing (computer science)	Moinuddin K. Qureshi;Aamer Jaleel;Yale N. Patt;Simon C. Steely;Joel S. Emer	2008	IEEE Micro	10.1109/MM.2008.14	insertion;parallel computing;real-time computing;thrashing;computer hardware;cache;computer science;operating system;adaptive replacement cache;electronic packaging;particle detector	Arch	-10.675941999819281	53.74221402684884	15107
7ce797e76683121b502182ef08a6d95e4264598c	optimizing i/o intensive domain handling in xen hypervisor for consolidated server environments		Consolidation of servers through virtualization, facilitated by the use of hypervisors, allows multiple servers to share a single hardware platform. Xen is a widely preferred hypervisor, mainly, due to its dual virtualization modes, virtual machine migration support and scalability. This paper involves an analysis of the virtual CPU (vCPU) scheduling algorithms in Xen, on the basis of their performance while handling compute intensive or I/O intensive domains in virtualized server environments. Based on this knowledge, the selection of CPU scheduler in a hypervisor can be aligned with the requirements of the hosted applications. We introduce a new credit-based vCPU scheduling strategy, which allows the vCPUs of I/O intensive domains to supersede other vCPUs, in order to favor the reduction of I/O bound domain response times and the subsequent bottleneck in the CPU run queue. The results indicate substantial improvement of I/O handling and fair resource allocation between the host and guest domains.	hypervisor;input/output;optimizing compiler	Venkataramanan Venkatesh;Amiya Nayak	2016		10.1007/978-3-319-39077-2_12	embedded system;real-time computing;storage hypervisor;operating system	Arch	-22.13326987436197	60.259492761471456	15108
ee3a2d2818182078052f6f665bf0ba8def5534f4	parallel computing applications and financial modelling	parallel computing;massively parallel systems;distributed array processor;parallel computer;portfolio optimisation;risk assessment;financial modelling	At Queen Mary, University of London, we have over twenty years of experience in Parallel Computing Applications, mostly on “massively parallel systems”, such as the Distributed Array Processors (DAPs). The applications in which we were involved included design of numerical subroutine libraries, Finite Element software, graphics tools, the physics of organic materials, medical imaging, computer vision and more recently, Financial modelling. Two of the projects related to the latter are described in this paper, namely Portfolio Optimisation and Financial Risk Assessment.		Heather M. Liddell;Dennis Parkinson;Graham S. Hodgson;Peter Dzwig	2004	Scientific Programming	10.1155/2004/404575	financial modeling;risk assessment;computational science;parallel computing;computer science;theoretical computer science;operating system;massively parallel;data-intensive computing	HPC	-7.740184805383914	37.45685869869559	15126
4892c91e93a1aaad9690266c2f505d80d47f2a4c	an optimizedworkload for failure data analysis of mobile p2p over bluetooth ad-hoc networks	p2p;wireless ad hoc network;ad hoc network;data analysis;network servers;data analysis bluetooth ad hoc networks peer to peer computing fires network servers laboratories ip networks large scale systems hardware;ad hoc networks;mobile ad hoc network;ip networks;bluetooth;peer to peer computing;fires;peer to peer;mobile internet;large scale systems;hardware	Mobile Peer-to-Peer (P2P) is a base paradigm for many new killer applications for mobile ad-hoc networks and the Mobile Internet. Currently, it is not well understood whether this paradigm is able to meet business and consumer dependability expectations. Dependability assessment of P2P applications can be achieved by field failure data analysis. The collection of failure data from wireless ad-hoc networks is a challenging task due to the intermittent usage and the mobility of users that do not allow to measure time-based dependability parameters. For this reason, we propose to deploy automated workloads on the actual peer nodes which have to operate continuously. Specifically, this paper formalizes the problem and presents the design of a workload for mobile P2P that aims to orchestrate the peers uniformly, letting the failure occurrence be independent of the network load. Simulation results and experimentation over an actual Bluetooth network demonstrate that the proposed workload meets the defined requirements.	bluetooth;dependability;hoc (programming language);killer application;peer-to-peer;programming paradigm;requirement;simulation	Gabriella Carrozza;Marcello Cinque;Fabio Cornevilli;Stefano Russo	2006	26th IEEE International Conference on Distributed Computing Systems Workshops (ICDCSW'06)	10.1109/ICDCSW.2006.18	wireless ad hoc network;computer science;distributed computing;world wide web;computer network	Mobile	-33.44971968047809	49.55291940195059	15160
3aa0dce7d31092a97954a31cc111d01762b59873	p-hase: an efficient synchronous pdes tool for creating scalable simulations		Synchronous, parallel discrete event simulation (PDES) is the simplest and lightweight approach to speedup large-scale simulations by scheduling as many events, of the same simulation cycle, to be executed concurrently. The scheduling technique to achieve perfect load balance and scalability is a key challenge for an efficient synchronous PDES. In this paper, we proposed a technique for balancing loads to fit the number of available processors on multicores. The technique has been implemented on a synchronous PDES tool called P-HASE (the Parallel - Hierarchical computer Architecture design and Simulation Environment) using the NET 4.0 concurrency runtime and OpenMP. Eight simulation models have been evaluated on 4-, 8-, and 16- core machines. The results show that the models using P-HASEare faster than HASE for 18 – 6.5 times; and maintain their performance when changing the numbers of processors. The results confirm that the simulation models created by using the P-HASE tool are highly scalable for multicore architecture.	computer simulation	Yanyong Mongkolsin;Worawan Marurngsith	2012		10.1007/978-3-642-34387-2_27	control engineering;discrete event simulation;simulation modeling;engineering;parallel computing;speedup;scalability;concurrency;architecture;multi-core processor;load balancing (computing)	EDA	-10.74970551501911	40.30511695798187	15164
049f9c6400a96b92d9e86d4d358d0ce698bd7c43	generating performance portable code using rewrite rules: from high-level functional expressions to high-performance opencl code	paper;algorithmic patterns;heterogeneous systems;ati radeon hd 7970;code generation;ati;gpu;compilers;nvidia geforce gtx 480;performance portability;rewrite rules;nvidia;computer science;opencl	Computers have become increasingly complex with the emergence of heterogeneous hardware combining multicore CPUs and GPUs. These parallel systems exhibit tremendous computational power at the cost of increased programming effort resulting in a tension between performance and code portability. Typically, code is either tuned in a low-level imperative language using hardware-specific optimizations to achieve maximum performance or is written in a high-level, possibly functional, language to achieve portability at the expense of performance. We propose a novel approach aiming to combine high-level programming, code portability, and high-performance. Starting from a high-level functional expression we apply a simple set of rewrite rules to transform it into a low-level functional representation, close to the OpenCL programming model, from which OpenCL code is generated. Our rewrite rules define a space of possible implementations which we automatically explore to generate hardware-specific OpenCL implementations. We formalize our system with a core dependently-typed lambda-calculus along with a denotational semantics which we use to prove the correctness of the rewrite rules. We test our design in practice by implementing a compiler which generates high performance imperative OpenCL code. Our experiments show that we can automatically derive hardware-specific implementations from simple functional high-level algorithmic expressions offering performance on a par with highly tuned code for multicore CPUs and GPUs written by experts.	central processing unit;compiler;correctness (computer science);denotational semantics;dependent type;emergence;experiment;function representation;functional programming;graphics processing unit;high- and low-level;high-level programming language;imperative programming;lambda calculus;multi-core processor;opencl api;programming model;rewrite (programming);rewriting;simple set;software portability	Michel Steuwer;Christian Fensch;Sam Lindley;Christophe Dubach	2015		10.1145/2784731.2784754	compiler;parallel computing;computer science;theoretical computer science;programming language;code generation	PL	-14.447419239914987	37.315777807385565	15201
e6ac93b4cbd71a55eada134683be3bd4db7af531	the aleph toolkit: support for scalable distributed shared objects	distributed application;eficacia sistema;distributed memory systems;sistema informatico;distributed computing;performance systeme;computer system;object oriented programming;system performance;data distribution;computer network;systeme memoire repartie;shared memory systems;reseau informatique;distribution pattern;systeme informatique;programmation orientee objet;systeme memoire partagee;object model	The shared object model is an appealing programming abstraction for distributed computing. By hiding the details of the network and data distribution, it allows the programmer to focus on higher-level concerns, and makes the program structure robust in the presence of changes in distribution patterns or environment. Nevertheless, it is not at all clear that the distributed shared object model can be adapted to the needs of modern large-scale distributed applications. The Aleph Toolkit is a collection of Java packages intended to support the construction of distributed shared objects in a way that addresses networking-related performance issues. This paper describes the design and rationale for the Aleph API, as well as our preliminary experience implementing a distributed shared object system in Java. This work is supported by AFOSR Agreement F30602-96-2-0228, DARPA Order D885.	application programming interface;design rationale;distributed computing;java package;library (computing);programmer;structured programming	Maurice Herlihy	1999		10.1007/10704826_10	distributed shared memory;parallel computing;object model;computer science;theoretical computer science;operating system;database;distributed computing;computer performance;distributed object;distributed design patterns;programming language;object-oriented programming	PL	-26.342590693017357	40.513901127525884	15239
4d193788bd91f6b11f5eced782bc3e2af0d83b82	teamwork: synchronizing threads globally to detect real deadlocks for multithreaded programs	thread scheduling;deadlock detection;object abstraction	This paper presents the aim of TeamWork, our ongoing effort to develop a comprehensive dynamic deadlock confirmation tool for multithreaded programs. It also presents a refined object abstraction algorithm that refines the existing stack hash abstraction.	algorithm;deadlock;thread (computing)	Yan Cai;Ke Zhai;Shangru Wu;Wing Kwong Chan	2013		10.1145/2442516.2442560	parallel computing;real-time computing;computer science;distributed computing;programming language;deadlock prevention algorithms	PL	-24.227179103697605	35.66491674174506	15253
7fac5d0f077466259bc8708b710293949258c66b	checkpointing in distributed computing systems	distributed system;algoritmo paralelo;systeme reparti;parallel algorithm;implementation;simulation;equilibrage charge;metric;simulacion;calculo automatico;state dependence;synchronous checkpointing;computing;algorithme parallele;performance metric;calcul automatique;ejecucion;sistema repartido;distributed computing system;analyse performance;performance analysis;performance model;load balancing;metrico;distributed computing environment;metrique;analisis eficacia	(and therefore a complete restart) increases with ever larger numbers of processors. Fault-tolerant techniques must be used to insure finishing times which are comparable with fault-free performance. One approach to providing higher reliability is to have each site periodically checkpoint by copying its system state to stable storage (e.g., disk). When a failure occurs, each site can resume computing after it restores its system state. The checkpoint frequency is an important design choice. Checkpointing too frequently in a highly reliable system results in unnecessary overhead, while checkpointing too infrequently in a highly unreliable system results in the loss of large quantities of work—work which must be repeated after recovery. In systems where the repair times are long, it may also be beneficial to provide a mechanism for resuming the computation on the remaining operational processors instead of waiting for the faulty processor to be repaired. This paper examines the performance of synchronous checkpointing of long-running, iterative algorithms in a distributed computing environment with and without load redistribution. Performance models are developed, and optimum checkpoint intervals are determined. The analysis significantly extends earlier work by allowing for multiple nodes, state-dependent checkpoint intervals, and a performance metric which is coupled to failure-free performance and speed-up functions associated with the implementation of parallel algorithms [3, 4]. The analytic results for (1) occupancy times, (2) failures from a Poisson process, and (3) failures only occur when a node is in the available state. Assumption 1 is unrealistic, but experimental results (discussed later) indicate that the run-time predicted by the model at the optimum checkpoint interval is robust and not significantly affected by this assumption. Assumption 2 is a typical failure model. Assumption 3 is reasonable when checkpoint and recovery times are small compared to the time that the node is available between such events [6]. The state transition-rate diagram and parameters for this Markov process are given in Fig. 1 and Table 1. After spending on average (f 1 a)21 time units in the available state (A), the system will enter the checkpoint state (C) with probability a/(f 1 a) or the recovery state (R) with probability f/(f 1 a). When the system enters the checkpointing state (C), it will spend on average b21 time units JOURNAL OF PARALLEL AND DISTRIBUTED COMPUTING 35, 67–75 (1996) ARTICLE NO. 0069	application checkpointing;central processing unit;computation;diagram;distributed computing environment;imperative programming;iteration;overhead (computing);parallel algorithm;population;stable storage;state transition table;synchronization (computer science);transaction processing system	Kenneth F. Wong;Mark A. Franklin	1996	J. Parallel Distrib. Comput.	10.1006/jpdc.1996.0069	computing;parallel computing;real-time computing;metric;computer science;load balancing;operating system;distributed computing;parallel algorithm;implementation;distributed computing environment	HPC	-18.86195817848794	46.564038767551494	15254
5d751ddf938d335d1865d0edfd50ef721998b6f1	using abstract state machines for the design of multi-level transaction schedulers	phase locking;model specification;formal specification;abstract state machine;transaction processing	Multi-level transactions have been suggested as an approach to increase transaction throughput in databases. The central idea is to enable some low-level conflicts to be ignored by taking higher-level application semantics into account. In this paper, we approach the formal specification of a multi-level transaction scheduler using Abstract State Machines. We are particularly interested in showing that concrete protocols for multi-level transaction processing arise as refinements of an abstract ground model specification. Furthermore, we are interested in the proof of desirable properties of such schedulers such as the correctness and if possible also completeness with respect to serialisability, and the recoverability of the accepted schedules. For this we investigate a two-phase locking and a hybrid protocol.	abstract state machines	Markus Kirchberg;Klaus-Dieter Schewe;Jane Zhao	2009		10.1007/978-3-642-11447-2_5	real-time computing;transaction processing;distributed transaction;computer science;database;distributed computing;online transaction processing;transaction processing system	EDA	-27.329968499343043	34.72477981195935	15374
6e3adc7855c03bac7458e41adb007557102bd52a	c++ exception handling for ia64	if ptr == 0 throw outofmemory;int result = foo2 * elements;void *ptr = mallocsize;/* do something else */ } int barint elements { resource object;/* do something else */ }	The C++ programming language offers a feature known as exception handling, which is used, for instance, to report error conditions. This technique can result in more robust software. On the other hand, it generally has a highly negative performance impact, even when exceptions are not actually thrown. This impact is especially important on an architecture such as the HP/Intel IA-64 processor, which is very sensitive to compiler optimizations. Hewlett-Packard implemented exception handling for IA-64 in a way that leaves the door open for optimizations, even in the presence of exceptions. 1. Overview of C++ Exception Handling Most software has to deal with exceptional conditions, such as insufÞcient resources, missing Þle or invalid user input. In C, such a condition is typically reported using special return codes from functions. For instance, the ubiquitous malloc function indicates an out-of-memory situation by returning a NULL pointer. Typical C code would test this situation as follows: void *ptr = malloc(1000000); if (ptr == NULL) fprintf(stderr, ÒSorry, out of memory\nÓ); C++ exceptions are a better way to report such a condition. A C++ function that detects an exceptional situation can throw an exception , which can be caught by any of the calling functions using an exception handler. For instance, the previous code could be written in a C++ program as follows (the error test is in bold): struct OutOfMemory {}; struct Resource { Resource(); // Ctor allocates resource ~Resource(); // Dtor frees resource }; int foo(int size) { void *ptr = malloc(size); if (ptr == 0) throw OutOfMemory(); /* Do something else */ } int bar(int elements) { Resource object; int result = foo(2 * elements); /* Do something else */ } int main() { int i; try { for (i = 0; i < 100; i++) bar(i); } catch (OutOfMemory) { /* Report out-of-memory condition*/ cerr << ÒOut of memory for i=Ó << i << endl; } catch (...) { /* Report other problems. */ } } If the anomalous situation is detected (in this case, malloc() returning zero), the function can report it by throwing an exception. Note that this would not even be necessary had the memory allocation been done the C++ way, since the C++ allocation operators normally report an out-of-memory condition by throwing a standard exception (std::bad_alloc ). Compared to the C error reporting method, the beneÞts are multiple: ¥ The exceptional situation is identiÞed by a speciÞc entity, an exception, rather than by a special return code. ¥ There is no need for intermediate functions, such as bar , to do anything to deal with the exceptions. ¥ In particular, objects with destructors such as object are properly destroyed when the block containing them is exited, whether normally or because of an exception. This makes resource management safer. ¥ The exception handling code (in main ) is easily identiÞed as such, and separate from normal processing. A catch block catching the exception type OutOfMemory is called an exception handler for OutOfMemory exceptions. Throwing an exception involves unwinding the call stack until an exception handler is found. This process is made more complex in the presence of C++ automatic objects, since these objects may have destructors. In that case, destructors have to be called as the stack is being unwound. 2. Performance Impact of Various Solutions Since exceptions occur infrequently, the performance of exception handling code is normally not critical. In addition, developers can easly control how their application uses exceptions, and avoid exceptions in performancecritical code. On the other hand, implementations of exception handling generally have a negative performance impact on the code that may throw an exception (the code inside a try block), whether this code actually ever throws an exception or not. Ideally, the code inside the try block should not be different than the same code outside a try block. In practice, however, the presence of a try block, or even the presence of an Òexceptions are enabledÓ option in general slows down the code and increases its size. The reasons are multiple and complex. We try to address some of them below. The performance of an exception-handling solution is therefore measured by its impact on the non-exceptional code when no exception is thrown; it should try to minimize the degradation of code speed and size for this ÒnormalÓ code. 2.1 Portable Exception Handling with setjmp The Þrst implementations of C++ exception handling used a mechanism based on the standard C setjmp and longjmp functions. The setmp function saves an execution context in a jmp_buf structure. The lonjmp function can later be used to perform a Ònon-local gotoÓ, transferring control to the place where setjmp was originally called, as long as the function containing the setjmp never returned. In ÒportableÓ exception handling, a try block is replaced with a setjmp call, and throwing an exception is replaced by a longjmp . A linked list of jmp_buf buffers will represent the dynamic list of enclosing try blocks. This same technique had been used routinely in C and C++ to simulate exceptions before exceptions became available as a standard language feature. The major difÞculty with this approach is to correctly destroy automatic objects (such as the Resource object in our example). This is typically solved by creating a linked list of the objects to be destroyed as you create them. This approach is relatively simple, and it works with a C++ compiler that generates C code, such as the original Cfront from AT&T Ñ this is the reason it is called ÒportableÓ. This scheme has been used quite widely, in particular by the Cfront-based C++ compiler from Hewlett-Packard [1]. On the other hand, the performance drawbacks are signiÞcant. ¥ The setjmp function must be called at the beginning of every try block, and the list of jmp_buf must be maintained. ¥ A linked list of objects on the stack must be maintained at all times, and kept in a consistent state with respect to the list of jmp_buf . ¥ All variables that are stored in registers and that are declared outside the try block have to be restored to their initial value when longjmp is invoked 1 . For instance, the value of i in the catch block in main must be the same value as when bar was called. This can be achieved either by spilling all variables to memory before calling setjmp , or by having setjmp itself save all registers. Both options are expensive on architectures with large register Þles such as RISC processors. This impact exists even if no exception is ever thrown, since the calls to setjmp and the management of the 1. Typically, setjmp will not save all registers in the jmp_buf it is given as an argument. This is why the documentation for these routines generally states something like: Ò Upon the return from a setjmp() call caused by a longjmp(), the values of any nonstatic local variables belonging to the routine from which setjmp() was called are undeÞned. Code which depends on such values is not guaranteed to be portable. Ó (from the HP-UX 10.20 man page for setjmp ). setjmp buffer local objects to destroy Figure 1. Setjmp based exception handling setjmp buffer try { f(1); Object X; g(2); } catch (...){ // Handler } int g(int) { Thing Y; throw 1; } Enclosing try block in calling function object stack have to be done each time a try block is entered or exited. 2.2 Table-Driven Exception Handling Another implementation of C++ exception handling uses tables generated by the compiler along with the machine code. When an exception is thrown, the C++ runtime library uses the tables to perform the appropriate actions. Conceptually, this process works as follows: ¥ A Þrst table is used to map the value of the program counter (PC) at the point where the exception is thrown to an action table. ¥ The action table is used to perform the various operations required for exception processing, such as invoking the destructors, adjusting the stack, or matching the exception type to the address of an exception handler. For example, there will be an action kind to indicate Òcall the destructor for object on the stack at stack offset N,Ó which will be used to invoke the destructor of the Resource object. ¥ Once an exception handler (a catch block corresponding to the type of the exception being thrown) is found, a new PC value is computed from the tables that corresponds to this handler, and control is transferred to the handler. This approach is signiÞcantly more efÞcient than the previous one. There is no longer the systematic cost of a setjmp function call for every try block. Similarly, the cost of maintaining linked lists even when exceptions are not thrown is also eliminated. Therefore, many C++ compilers switched to a table-driven exception-handling mechanism. The Hewlett-Packard aC++ compiler for PARISC uses this technique. On the other hand, there are still negative effects from a performance point of view: ¥ The runtime needs to be able to restore all variables that are declared outside the try block to their correct value before entering a catch block (for instance i in the catch block of main in the example above.) The impact of this on performance is quite subtle and has multiple aspects, which are discussed below. ¥ All objects that have destructors must have their address stored in a table. Therefore, they must reside in memory, and their address is implicitly exposed. ¥ All automatic objects that have their address exposed have to be committed to memory before any call. In practice, this is not often a signiÞcant constraint, since a C++ objectÕs address is exposed through the this pointer after any member function call (including the constructor.) On the other hand, this may impact the most performance-critical objects, whose member functions are all inlined. These objects could otherwise be promoted to registers. ¥ The tables themselves have to encode a lot of possible actions, including call to destructors	a/ux;ansi c;application binary interface;c dynamic memory allocation;call stack;central processing unit;cfront;constructor (object-oriented programming);decision table;destructor (computer programming);documentation;encode;elegant degradation;entry point;exception handling;exit status;function object;ia-64;input/output (c++);landing page;linked list;local variable;loop unrolling;machine code;mathematical optimization;method (computer programming);optimizing compiler;out of memory;pa-risc;pointer (computer programming);program counter;register file;robustness (computer science);runtime library;setjmp.h;simulation;struct (c programming language);the c++ programming language;unix;ac++ compiler	Christophe de Dinechin	2000				PL	-19.33124263213409	37.523662109306564	15395
7c02eff1b79a78639747d250532651d4c92089d0	improving hpc application performance in cloud through dynamic load balancing	virtual machines cloud high performance computing load balancing placement runtime system;performance evaluation;high performance computing;resource allocation;placement;cloud;interference;runtime;virtual machines;clouds;load management;load balancing;load management clouds interference cloud computing runtime benchmark testing radio access networks;load balance;runtime system;virtualisation cloud computing parallel processing performance evaluation resource allocation virtual machines;problem decomposition dynamic load balancing frequency pay as you go model cloud computing high performance computing applications interconnect performance heterogeneous environment virtual machines vm cpu utilization tightly coupled iterative hpc application performance improvement static hardware heterogeneity dynamic heterogeneity multitenancy periodic task distribution refinement cloud resources private cloud problem size computational granularity;parallel processing;benchmark testing;virtualisation;cloud computing;radio access networks	Driven by the benefits of elasticity and pay-as-you-go model, cloud computing is emerging as an attractive alternative and addition to in-house clusters and supercomputers for some High Performance Computing (HPC) applications. However, poor interconnect performance, heterogeneous and dynamic environment, and interference by other virtual machines (VMs) are some bottlenecks for efficient HPC in cloud. For tightly-coupled iterative applications, one slow processor slows down the entire application, resulting in poor CPU utilization. In this paper, we present a dynamic load balancer for tightly-coupled iterative HPC applications in cloud. It infers the static hardware heterogeneity in virtualized environments, and also adapts to the dynamic heterogeneity caused by the interference arising due to multi-tenancy. Through continuous live monitoring, instrumentation, and periodic refinement of task distribution to VMs, our load balancer adapts to the dynamic variations in cloud resources. Through experimental evaluation on a private cloud with 64 VMs using benchmarks and a real science application, we demonstrate performance benefits up to 45%. Finally, we analyze the effect of load balancing frequency, problem size, and computational granularity (problem decomposition) on the performance and scalability of our techniques.	analysis of algorithms;benchmark (computing);central processing unit;cloud computing;computation;elasticity (cloud computing);emulator;interference (communication);iteration;iterative method;load balancing (computing);multitenancy;product requirements document;refinement (computing);run time (program lifecycle phase);runtime system;scalability;supercomputer;virtual machine;web application	Abhishek Gupta;Osman Sarood;Laxmikant V. Kalé;Dejan S. Milojicic	2013	2013 13th IEEE/ACM International Symposium on Cluster, Cloud, and Grid Computing	10.1109/CCGrid.2013.65	parallel processing;parallel computing;real-time computing;cloud computing;computer science;load balancing;operating system;distributed computing	HPC	-20.726521512837373	59.29488376663287	15401
fe81a0c976d0d90e036575c9090fd5dec78e46ed	a novel optimal load distribution algorithm for divisible loads	and forward;communication computing model;parallel and distributed computing;communication model;divisible load theory;community computing;load assignment;linear model;load distribution;tree network	A new model for divisible load problem is introduced. Its characteristics are analyzed. Optimal load distribution algorithms on the new model are presented for the tree-network and linear network. Applications that fit our model are briefly described. We show that our model outperforms the existing model such as Cheng–Robertazzi model. We show that the linear model is equivalent to a single-level tree network if the intermediate processors do not follow the store-and-forward communication model, but they follow the store-and-bypass model. This paper introduces the concept of store-and-bypass for divisible load theory.	algorithm;central processing unit;computation;distributed computing;encryption;fits;front-end processor;human-readable medium;ising model;linear model;load balancing (computing);multi-level cell;store and forward;tree network	Hyoung Joong Kim	2003	Cluster Computing	10.1023/A:1020915000287	parallel computing;real-time computing;models of communication;computer science;weight distribution;linear model;distributed computing	DB	-12.954831697952269	42.97690292424886	15454
3e945f44e0bd4c76baf5152d76225700856dcfba	application aware scalable architecture for gpgpu		Abstract Modern General Purpose Graphic Processing Units (GPGPU) offer high throughput for parallel applications with their hundreds of integrated cores. However, there are applications that experience performance saturation and even degradation with increasing number of cores. At present the scheduler in the GPU hardware allocates all the available resources to maximize their utilization. We observed that applications have preference towards specific set of resources. The utilization of other redundant resources can reduce the throughput of the applications. To overcome this problem, in this paper we first classify the applications into two types; type-I that dominantly require processing cores and type-II that rely on the performance of the memory-system. We propose an Application aware Scalable Architecture (ApSA) for GPGPU based on classified applications which performs run-time tailoring of the GPU resources to present an optimal set of resources to the running application. The results are analyzed and compared in terms of instructions per cycle, bandwidth utilization and branch divergence. We found that if the application is identified to be of type-I with the proposed technique the average profiling overhead is 1.6%. Type-II applications experience average profiling overhead of 1.15%. The average power saved by clock-gating redundant resources in the case of type-II applications is 20.08%.	general-purpose computing on graphics processing units	Winnie Thomas;Rohin D. Daruwala	2018	Journal of Systems Architecture - Embedded Systems Design	10.1016/j.sysarc.2018.07.003	parallel computing;computer science;scalability;throughput;architecture;real-time computing;profiling (computer programming);general-purpose computing on graphics processing units;instructions per cycle	EDA	-5.797545679823964	52.11210801257754	15466
9400beb3612ecda9bc20301ad58082ab31974026	from verification to optimizations		Compilers perform static analysis prior to applying an optimization. The analysis results are typically not very precise, however, as a compiler operates with a strict time budget, which constrains reasoning. In this paper, we explore a new direction: using information gathered by external sound static analysis tools to augment the internal compiler reasoning, and investigate whether this leads to better optimization. One of the key problems to be solved is that of propagating the source-level information gathered by a static analyzer deeper into the optimization pipeline. We propose an approach to achieve this and demonstrate its feasibility through an implementation using the LLVM compiler infrastructure. We show how assertions obtained from the Frama-C static analysis tool are propagated through LLVM and are then used to substantially improve the effectiveness of several optimizations.	compiler;frama-c;llvm;mathematical optimization;static program analysis	Rigel Gjomemo;Kedar S. Namjoshi;Phu H. Phung;V. N. Venkatakrishnan;Lenore D. Zuck	2015		10.1007/978-3-662-46081-8_17	parallel computing;real-time computing;computer science;theoretical computer science;programming language	PL	-20.258452534543817	34.506593109591414	15493
11855a56f91a155aca8a539e6b2f8ad60deca2e8	the object-oriented development of a parallel application in polymer dynamics	object oriented;parallel applications	Without Abstract		Thomas Larsen;Wouter Joosen;John W. Perram	1994		10.1007/BFb0030162	computer science;object-oriented programming	HPC	-9.776518462923876	37.251893121329466	15523
a03799c2d8f461f84664c2f416d3471fb4c326bf	invariant consistency: a mechanism for inter-process ordering in distributed shared memory systems	distributed system;protocols;formal specification;shared memory;data integrity;message passing system;data consistency protocol invariant consistency inter process ordering distributed shared memory systems;programming profession access protocols concurrent computing multiprocessing systems counting circuits distributed computing multiprocessor interconnection networks message passing sufficient conditions contracts;distributed programming;distributed shared memory systems;middleware;data consistency;distributed shared memory;protocols distributed shared memory systems distributed programming data integrity	In a distributed shared memory (DSM) system, multiple copies of a shar ed variable may have to be maintained (in caches) to improve performance. Several notions of cons istency have been proposed to provide a consistent view of the shared memory. A consist e cy notion imposes constraints on the order in which updates to shared variables are made visible to various processes. A constraint may restrict the sequence in which updates from the same process ar e made visible to other processes. We classify such constraints as intra-process constraints and many existing consistency notions provide flexible mechanisms to specify such constraints . We may also need to specify inter-processconstraints to restrict the sequence in which updates issued by different p rocesses are made visible. In this paper, we propose the notion of invariant consistencythat allows specification of such inter-process constraints. For this propose, we allow a p rogrammer to label program operations and specify an invariant I constraining the execution of labeled operations at different processes. The implementation of invariant consistency ensures that the l bel d operations are made visible in an order that satisfies I . We show that invariant consistency simplifies programming as it eliminates application-level synchronization code to enforce inter-pr ocess constraints. We show that inter-process ordering can be done more efficiently via invariant cons iste cy as compared to application-level synchronization. We also give an implementation of in var ant consistency that involves a mechanical translation of invariants to synchronization code.	cognitive dimensions of notations;consistency model;cylinder-head-sector;decibel;distributed shared memory;machine translation;programmer;requirement;shared variables	Gurdip Singh	2002		10.1109/ICDCS.2002.1022285	distributed shared memory;shared memory;communications protocol;cache coherence;parallel computing;real-time computing;distributed memory;computer science;consistency model;operating system;middleware;data integrity;formal specification;database;distributed computing;data consistency;data diffusion machine	PL	-24.672651335038847	41.08205105899433	15617
b847459c44c92e3f411d60ea00725a3180edc8a5	puffin: an embedded domain-specific language for existing unstructured hydrodynamics codes	mathematics;high performance computing;framework for implementing parallel codes;computing;algorithm;particle simulation;and information science	In this paper, we present Puffin, a domain-specific language embedded in C++98 for incremental adoption in existing unstructured hydrodynamics codes. Because HPC systems with heterogeneous architectures (traditional CPUs, GPUs, Xeon Phis, etc.) are becoming increasingly common, developers of existing HPC software projects need performance across multiple architectures. While Puffin is not yet complete and only supports CPU execution so far, our aim for Puffin is to provide performance portability to existing unstructured hydrodynamics simulation projects. Our preliminary results focus on two topics. First, we show what the costs of using Puffin are. Adopting Puffin has a initial cost of rewriting existing code into Puffin. Using Puffin has the ongoing costs of increased compilation times (2-3X slower) and runtime overhead (0-11% slower). Second, we show the current benefits of using Puffin and mention the potential future benefits. We show how Puffin can gradually be adopted into an existing project, by doing so with the existing test application, LULESH 2.0. We show a reduction in code length by porting code to Puffin.	build automation;c++;central processing unit;code;compiler;domain-specific language;embedded system;graphics processing unit;overhead (computing);prototype;rewriting;simulation	Christopher Earl	2015		10.1145/2830018.2830021	computing;supercomputer;parallel computing;real-time computing;simulation;computer science;operating system;distributed computing;programming language	PL	-5.978344179249264	43.03218721595792	15627
4fe1c707a48869cbbdf3eb0384e526d1d294f7e2	maxdnn: an efficient convolution kernel for deep learning with maxwell gpus	paper;neural and evolutionary computing;nvidia geforce gtx 980;cuda;machine learning;package;nvidia;computer science	This paper describes maxDNN, a computationally efficient convolution kernel for deep learning with the NVIDIA Maxwell GPU. maxDNN reaches 96.3% computational efficiency on typical deep learning network architectures. The design combines ideas from cuda-convnet2 with the Maxas SGEMM assembly code. We only address forward propagation (FPROP) operation of the network, but we believe that the same techniques used here will be effective for backward propagation (BPROP) as well.	algorithmic efficiency;assembly language;blas;cuda;convolution;deep learning;graphics processing unit;maxwell (microarchitecture);software propagation	Andrew Lavin	2015	CoRR		computational science;parallel computing;computer science;theoretical computer science;machine learning;package	ML	-4.592731407503051	37.81252539289084	15651
0efe86ad1ac4b58ee5e4068f862a58c7a0fe85b4	application servers: one size fits all ... not?	application architecture;high availability;reliability;availability;user interface;performance;application server;j2ee;scaling up;net;client server;application servers	In the beginning there was machine language, followed by assembly language, formula translation, and eventually procedural programming, to organize the chaos. And then objects were introduced, to hide information. Soon Client/Server and multi-tier applications were conceived to separate data concerns from business logic concerns and user interface concerns. Later, these objects were distributed geographically to optimize hardware resources. And now, we have application servers, to simplify scaling up a system for large volumes, improved response times, impeccable reliability, and high availability. Application servers house the business logic, operating on data from a different server, and responding to requests from any source. But these Application Servers come in all shapes, flavors, and sizes. What is a developer to do? This panel will explore issues comparing application server technologies and questions about their appropriate use in different contexts.	application server;assembly language;business logic;fits;fortran;high availability;image scaling;machine code;multitier architecture;procedural programming;server (computing);user interface	Gail E. Harris;David Leibs;S. Jeromy Carrière;Fred Nagy;John Crupi;Martin Nally	2003		10.1145/949344.949414	real-time computing;computer science;operating system;database;programming language;application server;client–server model;server;server farm	PL	-28.281673426133203	50.79001557587568	15657
2b6b2d0992b9ac870f0330f2979b8ff042700d75	soft fault detection algorithms for multi-parallel data streams under the cloud computing				Hongbing Meng	2018	JACIII	10.20965/jaciii.2018.p1114	data stream;machine learning;computer science;artificial intelligence;data stream mining;cloud computing;distributed computing;fault detection and isolation	HPC	-30.802788779810733	46.648683422301	15663
2f49c717237bb1a5f594f86c544c57ed647de1fa	a client/server control architecture for robot navigation	navegacion;robot movil;distributed system;systeme commande;sistema control;systeme reparti;systeme client serveur;client server system;mobile robot;autonomous system;robot navigation;distributed programs;sistema autonomo;information sharing;navigation;control system;client server;sistema repartido;robot mobile;control architecture;mobile robot navigation;systeme autonome;autonomous navigation;navigation system;access control;information system;systeme information;moving robot;sistema informacion	We address the problem of task decomposition in a mobile robot navigation system. A typical robot navigation algorithm consists of a number of concurrent modules. In order to accomplish the common goal of the navigation task, they share resources on the robot. In such a system resource access control and information sharing must be properly managed. We approach these two issues by using a client/server distributed programming paradigm. Two types of server are defined : data server and hardware server. An indoor navigation system developed using the client/server model described above is presented.	client–server model;robotic mapping;server (computing)	Hansye S. Dulimart;Anil K. Jain	1996	Pattern Recognition	10.1016/0031-3203(96)00002-7	mobile robot;embedded system;navigation;simulation;computer science;autonomous system;control system;access control;distributed computing;server-side;fat client;mobile robot navigation;information system;client–server model;remote evaluation	Robotics	-29.614304550376062	43.11022598005881	15671
e8f2ffa701d0014cbe39d39ef2064f56c7ade322	parallel implementation of a simplified semi-physical wildland fire spread model using openmp		We present a parallel 2D version of a simplified semi-physical wildland fire spread model based on conservation equations, with convection and radiation as the main heat transfer mechanisms. This version includes some 3D effects. The OpenMP framework allows distributing the prediction operations among the available threads in a multicore architecture, thereby reducing the computational time and obtaining the prediction results much more quickly. The results from the experiments using data from a real fire in Galicia (Spain) confirm the benefits of using the parallel version.	openmp;semiconductor industry	D. Álvarez;D. Prieto Herráez;M. Isabel Asensio;José Manuel Cascón;Luis Ferragut	2017		10.1007/978-3-319-59650-1_22	heat transfer;parallel computing;convection;multi-core processor;architecture;thread (computing);radiation;computer science	HPC	-6.157203836562109	35.80813743407201	15698
d8fb6c5eb38a6a63fe9f7ab016b0f0d34c7c4dd0	task allocation in distributed database system design	distributed data;ioim;cpld;generic model;objective function;distributed database system;distributed computing system;parallel systems;emi;vme;task allocation	Task allocation in distributed database systems is an research problem. In DDBS systems Data & operation allocation are both closely interrelated & highly dependent on each other. Here it is represented along with model of allocation and development of such a model in general. Task allocation Models, Algorithms, Issues and Tools, General models and objective function explained in this paper. It can be treated as basic platform for research in this area of task allocation. The characteristics of DDBS like distributed data, distributed operations from query tree and result file are mentioned as tools to be taken in this field of research. An objective function can be derived by modifying the terms present in general model, which in turn depend on characteristics of the system concerned ex. Distributed computing system, distributed database system, parallel system & multiprocessors etc.	algorithm;distributed computing;distributed database;loss function;optimization problem;systems design	Gautam Borkar;Leena M. Borkar;Prashant Jawade	2010		10.1145/1741906.1742216	distributed algorithm;real-time computing;computer science;database;distributed computing;distributed design patterns;distributed database;replication;distributed concurrency control	DB	-19.522534871401803	42.31875974250475	15716
28560206d773fcfb2a4d435a6a82c77993be6000	probabilistic performance modelling of parallel numerical applications: a case study	shared memory;petri net;parallel computer	In this paper, three probabilistic performance modelling techniques are assessed on their usefulness for predicting the performance of a numerical application running on a shared-memory parallel computer: queueing networks, Petri nets and a hybrid technique combining both. The comparison is based on an LU factorisation algorithm as a case study. The reason for this choice is that the algorithm is simple, yet it contains several concurrency aspects that are interesting from a performance modelling point of view; moreover, it is well-documented and generally accepted as a benchmark (Linpack [3]), which makes it easier to relate our results to other work. 		Henk Jonkers	1993			parallel computing;theoretical computer science;computer science;probabilistic logic;petri net;shared memory;distributed computing	HPC	-12.67604227028666	41.83829059477219	15747
c7247e67ffb7d1d34a73a676f9c0156e49968d9d	distributed computing technologies and their application to drug discovery	drug discovery;distributed computing	Distributed Computing, the exploitation of idle cycles on pervasive desktop PC systems, offers the opportunity to increase the available computing power by orders of magnitude (10× to 1000×). Such large-scale resource sharing is a key part of the emerging Grid computing technologies being developed and pursued by a broad array of researchers, software vendors, and hardware vendors. However, for desktop PC distributed computing to be widely accepted within the enterprise, the systems must achieve high levels of robustness, security, scalability, unobtrusiveness, and manageability. In addition, as with any novel platform technology, the systems must also capture a critical mass of applications that make the platform valuable.	desktop computer;distributed computing;grid computing;pervasive informatics;scalability	Andrew A. Chien	2002		10.1109/CCGRID.2002.1017102	computer science;theoretical computer science;operating system;data mining;database;distributed computing;drug discovery	HPC	-27.230177985228863	55.959907774925405	15758
3ea694539bcc7ff06d3e24d575f1ee28aac4261c	distributed systems simulation	distributed system	Distributed systems are often defined as collections of (geographically-dispersed) interacting computing components (hardware or software). Collaborative Environments (e.g. games, e-learning), Agent-based systems, Distributed Transaction systems (e.g. Client-server, Distributed Databases), Mobile and Pervasive computing systems, Peer-to-Peer systems, Real Time and Embedded systems, Autonomic Computing Systems, the Internet, the Web and the Grid are all examples of distributed systems. Over the recent years, distributed systems have increasingly received considerable attention and a lot of effort is being invested in addressing the challenging problems they pose. Coordination and synchronisation, scalability (e.g. load balancing, data distribution), communication (e.g. protocols), security, failure handling (e.g. fault tolerance, deadlocks), heterogeneity (interoperability frameworks) and management (middleware) are some examples of these challenges. Concurrency, non-determinism and the lack of global states renders the design and analysis of distributed systems very challenging tasks. One approach to analyse a distributed system without a full-scale implementation, reason about its behaviour and evaluate its performance is simulation modeling. It has been the ambition of this special issue to provide a vehicle for reporting state-of-the-art developments in as many of the different aforementioned areas as possible. The focus of this special issue is on visionary approaches and original research results which advance the state of the art of designing efficient distributed systems and applications through simulation. The seven papers that have been finally selected after a rigorous review process, according to the practices of this Journal, provide a good sample of representative problems and work undertaken in this exciting field. Jang and Agha propose two service frameworks to reduce the amount of internode message passing in agent systems: dynamic agent distribution and search object-based middle agent services. They have implemented this framework in a Java-based tool and have used it to conduct simulations of up to 10,000 agents, where each agent represents a micro-UAV or a physical agent on the ground. In their experiments, the use of the dynamic agent distribution service reduces the execution time by 60% while the use of the search objectbased brokering service reduces it by 50%. Although the performance improvements will vary in different simulations, the authors conjecture is that in cases where an agent-based simulation is affected by the temporal communication locality between agents, and there is complex agent-environment interaction, the two services will considerably improve the overall performance of a simulation. Xu and Tropper propose an optimistic parallel and distributed logic simulator, XTW. In this simulator, a new event scheduling mechanism, XEQ, and a new rollback procedure, rb-messages, are proposed. XTW groups LPs into clusters, and makes use of a multi-level queue to schedule events in the cluster. XEQ has an O(1) event scheduling time complexity. The proposed rollback mechanism replaces the use of anti-messages by an rb-message, and eliminates the need for an output queue at each LP. Experimental comparisons with Clustered Time Warp reveal a superior performance on the part of XTW, while experimental results with large circuits demonstrate that XTW scales well with both the size of a circuit and the number of processors used in the simulation. The paper by Awan is concerned with the analysis of multiple threshold queues for congestion control of heterogeneous traffic streams. Using GE/GE/1/N approximation, a closed form cost-effective analytical solution is obtained using the principle of Maximum Entropy (ME). The forms of the joint, aggregate and marginal state probabilities, as well as basic performance measures such as state and blocking probabilities	advanced configuration and power interface;agent-based model;agent-based social simulation;aggregate data;approximation;autonomic computing;blocking (computing);central processing unit;computer cluster;deadlock;denotational semantics;distributed computing;distributed transaction;embedded system;experiment;fault tolerance;full scale;interaction;interoperability;java;load balancing (computing);locality of reference;logic simulation;marginal model;maximum entropy spectral estimation;message passing;middleware;network congestion;nondeterministic algorithm;object-based language;peer-to-peer;principle of maximum entropy;rendering (computer graphics);run time (program lifecycle phase);scalability;scheduling (computing);server (computing);systems simulation;time complexity;ubiquitous computing;unmanned aerial vehicle;web framework;world wide web;xojo	Helen D. Karatza;Georgios K. Theodoropoulos	2006	Simulation Modelling Practice and Theory	10.1016/j.simpat.2005.10.001	distributed algorithm;computer science;distributed computing;distributed design patterns;distributed concurrency control	HPC	-15.674346561638671	58.26962908397274	15759
44865db1220f7f21714e49b070532d313be53f1c	analysis of the effects of programming factors on programming effort	programming effort;average live variable;data communication;program construction;average nesting depth;programming factor;live variable;programming language feature;global variable;average variable	Programming effort appears to be related to choices of programming language features which we call programming factors. A series of experiments was conducted investigating program construction, comprehension, and modification. Ease of construction seemed related to average nesting depth, percentage of global variables used for data communication, average variables referenced, and average live variables per statement. Data communication and live variables were shown to be related to ease of modification as well.	experiment;global variable;list comprehension;programming language	Hubert E. Dunsmore;John D. Gannon	1980	Journal of Systems and Software	10.1016/0164-1212(79)90014-1	simulation;computer science;local variable;machine learning;algorithm	PL	-19.040951231357514	33.09104384838267	15785
935641ca92f4350166dab3fd9c51c423f5ced7ef	on selecting the right optimizations for virtual machine migration	migration time;virtual machine live migration;downtime;performance modeling of vm migration;live migration	To reduce the migration time of a virtual machine and network traffic generated during migration, existing works have proposed a number of optimizations to pre-copy live migration. These optimizations are delta compression, page skip, deduplication, and data compression. The cost-benefit analysis of these optimizations may preclude the use of certain optimizations in specific scenarios. However, no study has compared the performance & cost of these optimizations, and identified the impact of application behaviour on performance gain. Hence, it is not clear for a given migration scenario and an application, what is the best optimization that one must employ?  In this paper, we present a comprehensive empirical study using a large number of workloads to provide recommendations on selection of optimizations for pre-copy live migration. The empirical study reveals that page skip is an important optimization as it reduces network traffic by 20% with negligible additional CPU cost. Data compression yields impressive gains in reducing network traffic (37%) but at the cost of a significant increase in CPU consumption (5×). De-duplication needs to be applied with utmost care as the increase in CPU utilization might outweigh the benefits considerably. The combination of page skip and data compression works the best across workloads and results in a significant reduction in network traffic (40%).	central processing unit;data compression;data deduplication;delta encoding;mathematical optimization;network packet;network traffic control;virtual machine	Senthil Nathan;Umesh Bellur;Purushottam Kulkarni	2016		10.1145/2892242.2892247	parallel computing;real-time computing;computer science;operating system;downtime	HPC	-4.725113762965612	53.8192588330844	15787
43edc81c97bc4d9423b126bf422d1930a12fa885	fine-grain priority scheduling on multi-channel memory systems	random access memory;performance evaluation dram chips storage management scheduling;dram configurations;concurrent computing;performance evaluation;application software;processor scheduling;gang scheduling;storage management;fine grain priority scheduling;random access memory processor scheduling application software concurrent computing bandwidth delay computer science educational institutions resumes system performance;system performance;resumes;priority scheduling;performance improvement;scheduling;granularity dram memory fine grain priority scheduling multichannel memory systems workload independent configuration spec2000 programs direct rambus dram memory access scheduling;execution driven simulation;memory systems;bandwidth;computer science;and multi channel memory systems;dram chips;memory intensive applications	Configurations of contemporary DRAM memory systems become increasingly complex. A recent study [5] shows that application performance is highly sensitive to choices of configurations, and suggests that tuning burst sizes and channel configurations be an effective way to optimize the DRAM performance for a given memory-intensive workload. However, this approach is workload dependent. In this study we show that, by utilizing fine-grain priority access scheduling, we are able to find a workload independent configuration that achieves optimal performance on a multichannel memory system. Our approach can well utilize the available high concurrency and high bandwidth on such memory systems, and effectively reduce the memory stall time of memory-intensive applications. Conducting execution-driven simulation of a 4-way issue, 2 GHz processor, we show that the average performance improvement for fifteen memory-intensive SPEC2000 programs by using an optimized fine-grain priority scheduling is about 13% and 8% for a 2-channel and a 4-channel Direct Rambus DRAM memory systems, respectively, compared with gang scheduling. Compared with burst scheduling, the average performance improvement is 16% and 14% for the 2-channel and 4-channel memory systems, respectively.	benchmark (computing);best, worst and average case;burst error;cpu cache;channel memory;concurrency (computer science);dynamic priority scheduling;dynamic random-access memory;gang scheduling;parallel computing;parsing;precomputation;prefetch input queue;scheduling (computing);simulation;speculative execution	Zhichun Zhu;Zhao Zhang;Xiaodong Zhang	2002		10.1109/HPCA.2002.995702	uniform memory access;fair-share scheduling;shared memory;fixed-priority pre-emptive scheduling;embedded system;interleaved memory;application software;parallel computing;real-time computing;earliest deadline first scheduling;distributed memory;gang scheduling;concurrent computing;dynamic priority scheduling;computer science;rate-monotonic scheduling;operating system;two-level scheduling;flat memory model;round-robin scheduling;registered memory;scheduling;bandwidth;memory management	Arch	-8.756401863832087	51.00761114232767	15791
52c278bfe583d929ecaa3c85bd7d8e92fed8c535	a unified platform for exploring power management strategies		Power is quickly becoming a first class resource management concern in HPC. Upcoming HPC systems will likely be hardware over-provisioned, which will require enhanced power management subsystems to prevent service interruption. To advance the state of the art in HPC power management research, we are implementing SLURM plugins to explore a range of power-aware scheduling strategies. Our goal is to develop a coherent platform that allows for a direct comparison of various power-aware approaches on research as well as production clusters.	bsd;coherence (physics);experiment;first-class function;interrupt;open-source software;plug-in (computing);power management;scheduling (computing);slurm	Daniel A. Ellsworth;Tapasya Patki;Martin Schulz;Barry Rountree;Allen D. Malony	2016	2016 4th International Workshop on Energy Efficient Supercomputing (E2SC)		embedded system;parallel computing;real-time computing;engineering	HPC	-19.43460094733764	56.65297196046325	15859
58d76c4cf24e7806f1b19d57412a3ee4069396d6	an analysis of database workload performance on simultaneous multithreaded processors	database system;instruction cache;instruction throughput database workload performance simultaneous multithreaded processors architectural technique database systems smt processors oracle database management system memory system behavior online transaction processing decision support system software directed policies virtual to physical page mapping address offsetting d cache miss rates interthread instruction cache sharing;performance evaluation;database management systems;processor scheduling;on line transaction processing;data reuse;latency tolerance;decision support system;data cache;parallel architectures;performance evaluation parallel architectures database management systems processor scheduling;cache performance;memory systems;simultaneous multithreading;instruction scheduling;database management system;data analysis performance analysis surface mount technology database systems multithreading yarn transaction databases decision support systems simultaneous localization and mapping delay	"""Simultaneous multithreading (SMT) is an architectural technique in which the processor issues multiple instructions from multiple threads each cycle. While SMT has been shown to be effective on scientific workloads, its performance on database systems is still an open question. In particular, database systems have poor cache performance, and the addition of multithreading has the potential to exacerbate cache conflicts.This paper examines database performance on SMT processors using traces of the Oracle database management system. Our research makes three contributions. First, it characterizes the memory-system behavior of database systems running on-line transaction processing and decision support system workloads. Our data show that while DBMS workloads have large memory footprints, there is substantial data reuse in a small, cacheable """"critical"""" working set. Second, we show that the additional data cache conflicts caused by simultaneous multithreaded instruction scheduling can be nearly eliminated by the proper choice of software-directed policies for virtual-to-physical page mapping and per-process address offsetting. Our results demonstrate that with the best policy choices, D-cache miss rates on an 8-context SMT are roughly equivalent to those on a single-threaded superscalar. Multithreading also leads to better interthread instruction cache sharing, reducing I-cache miss rates by up to 35%. Third, we show that SMT's latency tolerance is highly effective for database applications. For example, using a memory-intensive OLTP workload, an 8-context SMT processor achieves a 3-fold increase in instruction throughput over a single-threaded superscalar with similar resources."""	cpu cache;central processing unit;decision support system;instruction scheduling;online and offline;online transaction processing;oracle database;relational database management system;scheduling (computing);simultaneous multithreading;superscalar processor;throughput;tracing (software);working set	Jack L. Lo;Luiz André Barroso;Susan J. Eggers;Kourosh Gharachorloo;Henry M. Levy;Sujay S. Parekh	1998		10.1145/279358.279367	computer architecture;parallel computing;real-time computing;decision support system;computer science;operating system;instruction scheduling;programming language;simultaneous multithreading	Arch	-12.005309348741992	51.4703270101809	15875
86631c26797de2f1ff5881fb02faa4d966cb20da	vine toolkit - grid-enabled portal solution for community driven computing workflows with meta-scheduling capabilities	wow2green;user interface;gria;vine;large scale;data center;grms;flowify;vine toolkit;middleware;load balance;grid security	In large scale production environments, the information sets to perform calculations on come from various sources. In particular, some computations may require the information obtained as a result of previous computations. Workflow description offers an attractive approach to formally deal with such complex processes. Vine Toolkit [1] solution addresses some major challenges here such as the synchronization of distributed workflows, establishing a community driven Grid environment for the seamless results sharing and collaboration. In order to accomplish these goals Vine Toolkit offers integration on different layers starting from rich user interface web components, integration with workflow engine and Grid security and ending up with a built-in meta-scheduling mechanisms, that allow IT administrators to perform load balancing automatically among computing clusters and data centers to meet peak demands. As a result of this particular project a complete solution has been developed and delivered.	meta-scheduling;scheduling (computing);vine toolkit	Dawid Szejnfeld;Piotr Domagalski;Piotr Dziubecki;Piotr Kopta;Michal Krysinski;Tomasz Kuczynski;Krzysztof Kurowski;Bogdan Ludwiczak;Jarek Nabrzyski;Tomasz Piontek;Dominik Tarnawczyk;Krzysztof Witkowski;Malgorzata Wolniewicz	2009		10.1007/978-3-642-14390-8_27	data center;parallel computing;computer science;load balancing;operating system;middleware;database;distributed computing;user interface;world wide web	HPC	-30.676908475805096	52.471978135501274	15905
ce2a4af567abe52f8b7d6adb54bf48259cf90461	parallel navier-stokes multi-block code to solve industrial aerodynamic design problems on high performance computers	viscous flow;navier stokes;large scale;high performance computer;parallel computer;block codes	Despite the major computing advances in recent years there has been a significant increase in the demand for more accurate, robust and reliable calculations of aerodynamic flows. New challenges are emerging that are pushing the limits of CFD calculations due to the complexity of the problems being proposed. Many of these problems are emerging from the aerospace industry and, in response to this, the UK has formed a new consortium that is focused on simulating challenges identified and driven by industrial aerospace needs. In this paper we analyse the performance of a helicopter rotor blade simulation code, developed by members of the consortium, on several largescale high-end computer architectures available in the UK. Finally we also benchmark the PMB (Parallel Multi-Block) code on the HPCx supercomputer.	benchmark (computing);block code;central processing unit;computer architecture;consortium;display resolution;hpcx;image scaling;message passing;navier–stokes equations;pmb;r.o.t.o.r.;simulation;supercomputer	V. Van Kemenade;Michel J. Daydé;J. B. Vos	1995		10.1007/BFb0046723	block code;parallel computing;simulation;computer science;theoretical computer science;statistics	HPC	-6.340392225355818	37.71379253914757	15909
66496ba3d1c7dafdda7ff115e837fec44d48a629	validation of systems of parallel processes	parallel processing			Andrew M. Lister	1974	Comput. J.	10.1093/comjnl/17.2.148	parallel processing;computer science	Logic	-9.496173048053498	42.31722951121487	15923
b9b9f3109367795f1f2fd982e1a37067e305f023	aspect-oriented programming of sparse matrix code	simulation ordinateur;calcul matriciel;rewrite rule;programacion paralela;parallel programming;parallel computation;calculo paralelo;matrice creuse;object oriented;aspect oriented programming;information dissemination;oriente objet;simulacion computadora;matrix calculus;sparse matrix;orientado objeto;calcul parallele;computer simulation;calculo de matrices;programmation parallele;matriz dispersa	the material is concerned, specifically the rights of translation, reprinting, re-use of illustrations, recitation, broadcasting, reproduction on microfilms or in any other way, and storage in data banks. Duplication of this publication in its current version, and permission for use must always be obtained from Springer-Verlag. Violations are liable for prosecution under the German Copyright Law. The expressiveness conferred by high-level and object-oriented languages is often impaired by concerns that cross-cut a program's basic functionality. Execution time, data representation, and numerical stability are three such concerns that are of great interest to numerical analysts. Using aspect-oriented programming we have created AML, a system for sparse matrix computation that deals with these concerns separately and explicitly while preserving the expressiveness of the original functional language. The resulting code maintains the efficiency of highly tuned low-level code, yet is ten times shorter	aspect-oriented programming;computation;data (computing);data deduplication;functional programming;high- and low-level;microform;numerical analysis;numerical linear algebra;numerical stability;sparse matrix;springer (tank)	John Irwin;Jean-Marc Loingtier;John R. Gilbert;Gregor Kiczales;John Lamping;Anurag Mendhekar;Tatiana Shpeisman	1997		10.1007/3-540-63827-X_68	computer simulation;aspect-oriented programming;sparse matrix;matrix calculus;separation of concerns;computer science;artificial intelligence;theoretical computer science;programming language;object-oriented programming;algorithm	PL	-10.145426501796646	35.64765090626438	15965
d79e6c784ec6684b4bb12a473b60504cdffb60b8	cross-tier application and data partitioning of web applications for hybrid cloud deployment		Hybrid cloud deployment offers flexibility in trade-offs between the cost-savings/scalability of the public cloud and control over data resources provided at a private premise. However, this flexibility comes at the expense of complexity in distributing a system over these two locations. For multi-tier web applications, this challenge manifests itself primarily in the partitioning of applicationand database-tiers. While there is existing research that focuses on either application-tier or data-tier partitioning, we show that optimized partitioning of web applications benefits from both tiers being considered simultaneously. We present our research on a new cross-tier partitioning approach to help developers make effective trade-offs between performance and cost in a hybrid cloud deployment. In two case studies the approach results in up to 54% reduction in monetary costs compared to a premise only deployment and 56% improvement in execution time compared to a näıve partitioning where application-tier is deployed in the cloud and data-tier is on private infrastructure.		Nima Kaviani;Eric Wohlstadter;Rodger Lea	2013		10.1007/978-3-642-45065-5_12	real-time computing;simulation;engineering;operations management	OS	-25.672448343131894	60.28934438424893	15974
c752e3d18225f3a2b15205f12717404b51e50709	adaptive task resources allocation in multi-agent systems	multi agent system;resource allocation;organization and social structure;organization self design;high performance;problem solving;task allocation;time constraint	In this paper, we present an adaptive organizational policy for multi-agent systems called \acro{trace}. \acro{trace} allows a collection of multi-agent organizations to dynamically allocate tasks and resources between themselves in order to efficiently process an incoming stream of task requests. \acro{trace} is intended to cope with environments in which tasks have time constraints, and environments that are subject to load variations. \acro{trace} is made up of two key elements: the task allocation protocol (\acro{tap}) and the resource allocation protocol (\acro{rap}). The \acro{tap} allows agents to cooperatively allocate their tasks to other agents with the capability and opportunity to successfully carry them out. As requests arrive arbitrarily, at any instant, some organizations could have surplus resources while others could become overloaded. In order to minimize the number of lost requests caused by an overload, the allocation of resources to organizations is changed dynamically by the resource allocation protocol (\acro{rap}), which uses ideas from computational market systems to allocate resources (in the form of problem solving agents) to organizations. We begin by formally defining the task allocation problem, and show that it is \acro{NP}-complete, and hence that centralized solutions to the problem are unlikely to be feasible. We then introduce the task and resource allocation protocols, focussing on the way in which resources are allocated by the \acro{rap}. We then present some experimental results, which show that \acro{trace} exhibits high performance despite unanticipated changes in the environment.	calculus of variations;centralized computing;function overloading;multi-agent system;problem solving	S. Shaheen Fatima;Michael Wooldridge	2001		10.1145/375735.376439	real-time computing;resource allocation;computer science;artificial intelligence;multi-agent system;distributed computing	AI	-26.723725038372432	48.53339046926719	16028
41a7bcf45dffd0153e52b7761c0c07ba07ff6744	high-speed lans: new environments for parallel and distributed applications	distributed application;distributed system;estacion trabajo;systeme reparti;red local;shared memory;high speed networks;memoria compartida;station travail;reseau ordinateur;computer network;local network;workstation;sistema repartido;grande vitesse;high performance computer;red ordenador;gran velocidad;systeme parallele;parallel system;reseau local;high speed;sistema paralelo;parallel simulation;memoire partagee	As the technology for high-speed networks has incredibly evolved this last decade, the interconnection of workstations at gigabits rates and low prices has become a reality. These clusters, based on regulars workstations (e.g. PCs), can now be used in place of traditional parallel computers with no possible comparison on the prices! In this article, 3 applications (high performance computing, distributed shared memory system and parallel simulation) that were traditionally executed on expensive parallel machines are ported on a Myrinet-based cluster of PCs. The results show that the performances of these new architectures can be very close to those obtained on state-of-the art parallel computers. 1 New technologies for parallel and distributed applications As soon as computers started to be used for problem solving tasks, this was a starting point for a never-ending quest towards more and more computational power. The availability of powerful computing environments began decades ago by putting several processing units in the same box and give them a way to communicate each other. The problem is that parallel machines were mainly built with proprietary and custom parts. Adding the high cost for software development , parallel computers could only be bought by large organizations. For a long time, parallel computers were the solution for people with high computation needs. Nowadays, there are still some applications where parallel computers are required but the demand has decreased dramatically as parallel computers are still highly expensive. If the processing units can now be taken from the commodity market, the interconnection networks and the softwares are still highly customized. While sequential computers have always seen a dramatic cut down in their prices every year, parallel computers took the opposite direction because of the decreasing demand. However, there are not so many solutions for having more computation power: one has to use several processors. The choice resides on how to make the parallel	central processing unit;computation;distributed computing;distributed shared memory;gigabit;interconnection;parallel computing;performance;personal computer;problem solving;simulation;software development;supercomputer;workstation	Patrick Geoffray;Laurent Lefèvre;CongDuc Pham;Loïc Prylli;Olivier Reymann;Bernard Tourancheau;Roland Westrelin	1999		10.1007/3-540-48311-X_89	local area network;shared memory;embedded system;parallel computing;workstation;computer science;operating system;distributed computing	HPC	-14.831247286879384	42.1742403124395	16052
d581be3a842cbc5f76d28a29a870e7087544bbb7	toward a standard benchmark format and suite for floating-point analysis		We introduce FPBench, a standard benchmark format for validation and optimization of numerical accuracy in floating-point computations. FPBench is a first step toward addressing an increasing need in our community for comparisons and combinations of tools from different application domains. To this end, FPBench provides a basic floatingpoint benchmark format and accuracy measures for comparing different tools. The FPBench format and measures allow comparing and composing different floating-point tools. We describe the FPBench format and measures and show that FPBench expresses benchmarks from recent papers in the literature, by building an initial benchmark suite drawn from these papers. We intend for FPBench to grow into a standard benchmark suite for the members of the floating-point tools research community.	benchmark (computing);compiler;computation;data structure;mathematical optimization;numerical analysis	Nasrine Damouche;Matthieu Martel;Pavel Panchekha;Chen Qiu;Alexander Sanchez-Stern;Zachary Tatlock	2016		10.1007/978-3-319-54292-8_6	theoretical computer science;abstract interpretation;imperative programming;computation;floating point;affine arithmetic;suite;computer science	PL	-14.21194547576247	35.18093748803682	16068
82a810e0e27c4b7296756a775e85cad35f1e0adb	load balancing for cpu-gpu coupling in computational fluid dynamics		This paper investigates static load balancing models for CPU-GPU coupling from a computational fluid dynamics perspective. While able to generate a benefit, traditional load balancing models are found to be too inaccurate to predict the runtime of a preconditioned conjugate gradient solver. Hence, an expanded model is derived that accounts for the multi-step nature of the solver, i.e. several communication barriers per iteration. It is able to predict the runtime to a margin of 5%, rendering CPU-GPU coupling better predictable so that load balancing can be improved substantially.	central processing unit;computational fluid dynamics;graphics processing unit;load balancing (computing)	Immo Huismann;Matthias Lieber;Jörg Stiller;Jochen Fröhlich	2017		10.1007/978-3-319-78024-5_30	parallel computing;rendering (computer graphics);symmetric multiprocessor system;distributed computing;coupling;conjugate gradient method;general-purpose computing on graphics processing units;computer science;load balancing (computing);computational fluid dynamics;solver	HPC	-4.826250429970691	39.21815304866903	16095
37618df61fc94e8f375fde8ba222c9dc3d2f3947	am++: a generalized active message framework	distributed memory;language use;active messages;parallel programming interfaces;transport layer;partitioned global address space;parallel graph algorithms;high performance computer;graph algorithm;parallel programs;generic programming	Active messages have proven to be an effective approach for certain communication problems in high performance computing. Many MPI implementations, as well as runtimes for Partitioned Global Address Space languages, use active messages in their low-level transport layers. However, most active message frameworks have low-level programming interfaces that require significant programming effort to use directly in applications and that also prevent optimization opportunities. In this paper we present AM++, a new user-level library for active messages based on generic programming techniques. Our library allows message handlers to be run in an explicit loop that can be optimized and vectorized by the compiler and that can also be executed in parallel on multicore architectures. Runtime optimizations, such as message combining and filtering, are also provided by the library, removing the need to implement that functionality at the application level. Evaluation of AM++ with distributed-memory graph algorithms shows the usability benefits provided by these library features, as well as their performance advantages.	active message;algorithm;compiler;distributed memory;generic programming;graph theory;high- and low-level;low-level programming language;mathematical optimization;multi-core processor;partitioned global address space;runtime system;supercomputer;usability;user space	Jeremiah Willcock;Torsten Hoefler;Nicholas Gerard Edmonds;Andrew Lumsdaine	2010	2010 19th International Conference on Parallel Architectures and Compilation Techniques (PACT)	10.1145/1854273.1854323	parallel computing;distributed memory;computer science;theoretical computer science;partitioned global address space;operating system;distributed computing;programming language;generic programming;transport layer	HPC	-12.034189184751796	41.456873421277756	16117
8aed6badac1a3ca6cc50bbda7f834ba763459ba0	a new approach for distributed symbolic software testing		This paper presents a new parallel algorithm for backward symbolic execution. We use a program modeling allowing an easy distributed symbolic execution and a scalable program testing. A program is divided into several parts assigned to different nodes. A particular node: the Coordinator allocates tasks to workers and collects final results.	parallel algorithm;predicate (mathematical logic);redundancy (engineering);scalability;software testing;symbolic execution	Nassima Aleb;Samir Kechid	2013		10.1007/978-3-642-39643-4_35	parallel computing;real-time computing;computer science;operating system;database;distributed computing;programming language;concolic testing	SE	-24.474354668327376	35.554240842848465	16136
adbe2e7f4c58d978cba63554def44f8f6e7d3b17	a new file system i/o mode for efficient user-level caching		A large number of cloud datastores have been developed to handle the cloud OLTP workload. Double caching problem where the same data resides both at the user buffer and the kernel buffer has been identified as one of the problems and has been largely solved by using direct I/O mode to bypass the kernel buffer. However, maintaining the caching layer only in user-level has the disadvantage that the user process may monopolize memory resources and that it is difficult to fully utilize the system memory due to the risks of the forced termination of the process or the unpredictable performance degradation in case of memory pressure. In this paper, we propose a new I/O mode, DBIO, to efficiently exploit OS kernel buffer as a victim cache for user-level file content cache, enjoying the strengths of kernel-level cache rather than just skipping it. DBIO provides the new file read/write function calls, which enable user programs to dynamically choose the right I/O behavior based on their context when issuing I/Os instead of when opening the file. On the cloud key-value store workloads and the traditional OLTP workloads with the modified version of MySQL/InnoDB, DBIO improves the in-memory cache hit ratio and the transaction performance compared to both buffered and direct I/O mode, fully utilizing the user buffer and the kernel buffer without double caching.	attribute–value pair;cpu cache;cache (computing);elegant degradation;hit (internet);ibm system i;in-memory database;innodb;input/output;kernel (operating system);key-value database;linux;multitier architecture;mysql;online transaction processing;operating system;page cache;random-access memory;user space	Jiwoong Park;Cheolgi Min;Heon Young Yeom	2017	2017 17th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing (CCGRID)		parallel computing;computer science;page cache;distributed computing;real-time computing;write buffer;cache;file system;smart cache;process management (computing);input/output;cache algorithms	OS	-13.486656235436637	53.42410640445485	16166
a09f2419775b1f6d74fcc5b0116e663d5287c9a4	cache balancer: access rate and pain based resource management for chip multiprocessors	memory management;chip multiprocessors;task mapping;cache memories	This paper presents a runtime resource management scheme named Cache Balancer that improves the utilization of on-chip shared caches and reduces access latencies in chip multiprocessor systems. Cache Balancer incorporates an access rate based memory allocator that improves utilization of on-chip cache resources resulting in up to 60% lower contention at cache banks. Furthermore, it uses information regarding the memory access characteristics of application tasks in order to obtain an optimal task mapping at runtime, and consequently achieves up to 22% lower execution times as compared to existing proposals.	cpu cache;multi-core processor;multiprocessing;run time (program lifecycle phase);slab allocation	Jurrien de Klerk;Sumeet S. Kumar;René van Leuken	2014	2014 Second International Symposium on Computing and Networking	10.1109/CANDAR.2014.81	bus sniffing;uniform memory access;cache-oblivious algorithm;snoopy cache;parallel computing;real-time computing;cache coloring;page cache;cpu cache;cache;computer science;write-once;cache invalidation;operating system;smart cache;mesi protocol;cache algorithms;cache pollution;mesif protocol;cache-only memory architecture;non-uniform memory access	Arch	-9.569959312239865	52.568716485179046	16168
b2699dd9d1705cc65ebc49d93150a210e313664b	deadline-aware programming and scheduling		Deadlines are the most important events in real-time systems. Realtime programs must therefore be aware of deadlines, and be able to identify and react to missed deadlines. Moreover, Earliest Deadline First (EDF) is the most widely studied optimal dynamic scheduling algorithm for uniprocessor real-time systems. In this paper we explore how a resource sharing protocol (called the DFP – Deadline Floor inheritance Protocol), which has been proposed for languages such as Ada, can be incorporated into the language’s definition. We also address the programming of systems that have mixed scheduling (e.g. fixed priority and EDF). The incorporation of the DFP into Ada requires some changes to the current predefined packages. These changes are also of use in supporting the programming of deadline-aware systems even when not scheduling by EDF.	ada;algorithm;context-aware pervasive systems;earliest deadline first scheduling;fifo (computing and electronics);preemption (computing);rapid refresh;real-time clock;real-time computing;round-robin scheduling;scheduling (computing);stack resource policy;two-level scheduling;uniprocessor system	Alan Burns;Andy J. Wellings	2014		10.1007/978-3-319-08311-7_9	fair-share scheduling;fixed-priority pre-emptive scheduling;earliest deadline first scheduling;flow shop scheduling;dynamic priority scheduling;rate-monotonic scheduling;two-level scheduling;deadline-monotonic scheduling;scheduling;round-robin scheduling	Embedded	-9.82632744632331	60.326295846759116	16253
277f11c42e606c8bf56bf961f0b00e26669de124	.net database programmability and extensibility in microsoft sql server	application development;extensibility;design principle;common language runtime;abstract data types;spatial index;abstract data type;data type;server programming;data access;value function	The integration of the .NET Common Language Runtime (CLR) into the SQL Server DBMS enables rich business logic written in modern .NET languages to run close to the data. Database application developers can write business logic as functions, stored procedures, and triggers. They can also extend the native capabilities of the DBMS by adding new scalar data types, and aggregates. A previous paper [2] described the architecture and design principles of the integration of the CLR inside SQL Server. Here we present new aspects of this work. First, we describe the extensibility contracts for user-defined types and aggregates in detail. Second, we present the advances to the CLR integration in SQL Server 2008 which significantly enhances the breath of applications supported by SQL Server. In particular, we describe the support for large (greater than 8000 byte) user-defined types and aggregates, multiple-input user-defined aggregates, and order-aware table valued functions. Third, we show how we leveraged scalar type extensibility to provide a hierarchical identifier data type that enables encoding of keys describing hierarchies as well as built-in support for spatial applications. This support includes both flat- and round-earth spatial types, as well as a spatial index. Fourth, we present how we use Language Integrated Query (LINQ) enhancements in .NET languages to improve developer productivity when creating routines that require data access. Finally, we present preliminary performance results showing the efficiency of streaming TVFs and aggregates relative to equivalent native features.	aggregate data;business logic;byte;canonical account;data access;database trigger;extensibility;identifier;language integrated query;list of cli languages;mathematical optimization;microsoft sql server;microsoft visual studio;overhead (computing);server (computing);spatial database;stored procedure	José A. Blakeley;Vineet Rao;Isaac Kunen;Adam Prout;Mat Henaire;Christian Kleinerman	2008		10.1145/1376616.1376725	data transformation services;business intelligence markup language;computer science;theoretical computer science;user-defined function;database;language integrated query;programming language;abstract data type	DB	-22.670648859380172	35.25562979018454	16261
67a9774585ce28611854e877eb0cc8606fb8736a	an efficient code update scheme for dsp applications in mobile embedded systems	sensibilidad contexto;informatica movil;traitement signal;red sin hilo;compilacion;satellite communication;cambio variable;incremental coalescing general offset assignment icgoa;context aware;mise a jour;informatique mobile;calculateur embarque;reseau sans fil;heuristic method;wireless network;metodo heuristico;telecomunicacion via satelite;telecommunication par satellite;coalescencia;embedded system;actualizacion;organizacion memoria;signal processing;codigo movil;changement variable;mobile code;boarded computer;organisation memoire;patch size;compilation;code binaire;algorithms;design;codigo binario;source code;incremental coalescing simple offset assignment icsoa;context unaware script;methode heuristique;memory organization;sensibilite contexte;mobile computing;satellite telecommunication;experimentation;procesamiento senal;context aware script;calculador embarque;binary code;variable transformation;code mobile;updating;coalescence	DSP processors usually provide dedicated address generation units (AGUs) to assist address computation. By carefully allocating variables in the memory, DSP compilers take advantage of AGUs and generate efficient code with compact size and improved performance. However, DSP applications running on mobile embedded systems often need to be updated after their initial releases. Studies showed that small changes at the source code level may significantly change the variable layout in the memory and thus the binary code, which causes large energy overheads to mobile embedded systems that patch through wireless or satellite communication, and often pecuniary burden to the users.  In this paper, we propose an update-conscious code update scheme to effectively reduce patch size. It first performs incremental offset assignment based on a recent variable coalescing heuristic, and then summarizes the code difference using two types of update primitives. Our experimental results showed that using update-conscious code update can greatly improve code similarity and thus reduce the update script sizes.	augmented assignment;binary code;central processing unit;communications satellite;compiler;computation;digital signal processor;embedded system;heuristic;money;run time (program lifecycle phase)	Weijia Li;Youtao Zhang	2010		10.1145/1755888.1755904	dead code;design;coalescence;binary code;parallel computing;real-time computing;telecommunications;computer science;operating system;wireless network;signal processing;redundant code;mobile computing;code generation;unreachable code;source code	EDA	-18.934176645681116	36.449308041478844	16304
4c097f6e0944bbe2de0284d46137d41d367a1a06	node reassignment in a dataflow system		Dataflow Protocol for Communication in Distributed Computer Systems, Proceedings of COMPCON 1980, Washington, D.C., September, 1980, pp 321-332 (V.P.Srini, and B.D.Shriver are the authors). Framework for Communication in Loosely Coupled Multiple Processor Systems, Proceedings of 1980 Parallel Processing Conference, Michigan, August, 1980, pp 49-52 (V.P.Srini, and B.D.Shriver are the authors). Programming Language Specification by using Three Forms, Proc. of CSC Conf., Detroit, February, 1978. The Class of Environment Operator Precedence Languages (EOPL'S), Proc. of CSC Conf., Atlanta, January, 1977.	algol 68;dataflow;essentials of programming languages;order of operations;programming language specification	Vason P. Srini	1984			distributed computing;dataflow;computer science	HPC	-27.73744105754018	36.46741194365694	16345
a35fb3a463104dee9a893ce338598ba30eb3c5ac	data mining analysis to validate performance tuning practices for hpl	hpl performance modeling data mining;support vector machines;niobium;software performance evaluation;data mining;data mining data analysis performance analysis application software guidelines benchmark testing analytical models thumb high performance computing niobium;system evaluation;computational modeling;tuning;application performance tuning;guidelines;application performance tuning data mining high performance linpack ranger system;performance model;hpl;ranger system;software performance evaluation data mining;performance modeling;high performance linpack;benchmark testing;performance tuning	Applications performance is a criterion for system evaluation, and hence performance tuning for these applications is of great interest. One such benchmark application is High Performance Linpack (HPL). Although guidelines exist for HPL tuning, validating these guidelines on various systems is a challenging task as a large number of configurations need to be tested. In this work, we use data mining analysis to reduce the number of configurations to be tested in validating the HPL tuning guidelines on the Ranger System. We validate that NB, P and Q are the three most important parameters to tune HPL, and that PMAP does not have a significant impact on HPL performance. We also validate the practice of tuning HPL at small N using data mining analysis. We find that the value of N selected for tuning should not be significantly smaller than the largest N that can fit into the system memory. Our results indicate that data mining could be further applied to application performance tuning.	benchmark (computing);data mining;flops;lunpack;naive bayes classifier;performance tuning;speedup;the proteolysis map;ranger	Tuan Zea Tan;Rick Siow Mong Goh;Verdi March;Simon See	2009	2009 IEEE International Conference on Cluster Computing and Workshops	10.1109/CLUSTR.2009.5289175	support vector machine;benchmark;niobium;real-time computing;computer science;data science;data mining;computational model	HPC	-4.799484472999076	45.48372735630383	16424
55b62ca5f3bf1771348c121be8024d288d015c0f	design of the trucluster multicomputer system for the digital unix environment	digital unix environment;trucluster multicomputer system	system for the Digital UNIX operating system was to develop a high-performance commercial database server environment running on a cluster of several nodes. Database applications often require computing power and I/O connectivity and bandwidth greater than that provided by most single systems. In addition, availability is a key requirement for enterprises that are dependent on database services for normal operations. These requirements led us to implement a cluster of computers that cooperate to provide services but fail independently. Thus, both performance and availability are addressed. We chose an industry-standard benchmark to gauge our success in meeting performance goals. The Transaction Processing Performance Council TPC-C benchmark is a widely accepted measurement of the capability of large servers. Our goal was to achieve industry-leading numbers in excess of 30,000 transactions per minute (tpmC) with a four-node TruCluster system. The TruCluster version 1.0 product provides reliable, shared access to large amounts of storage, distributed synchronization for applications, efficient cluster communication, and application failover. The focus on database servers does not mean that the TruCluster system is not suitable for other applications, but that the inevitable design decisions and trade-offs for the first product were made with this goal in mind. Although other aspects of providing a single-system view of a cluster are important, they are secondary objectives and will be phased into the product over time. This paper begins with a brief comparison of computer systems and presents the advantages of clustered computing. Next, it introduces the TruCluster product and describes the design of its key software components and their relationship to database applications. The paper then discusses the design of the MEMORY CHANNEL interconnect for cluster systems, along with the design of the low-level software foundation for cluster synchronization and communication. Finally, it addresses application failover and hardware configurations.	benchmark (computing);clustered file system;component-based software engineering;computer cluster;database server;failover;high- and low-level;ibm tivoli storage productivity center;input/output;offset binary;operating system;parallel computing;requirement;server (computing);transaction processing;tru64 unix;trucluster	Wayne M. Cardoza;Frederick S. Glover;William E. Snaman	1996	Digital Technical Journal		embedded system;parallel computing;computer science;operating system;database	OS	-17.81628643603332	51.111936293301426	16450
438a39f500aeeb5f394c1494e6acf169cb616b08	a large-scale malleable tsunami simulation realized on an elastic mpi infrastructure		Realization of resource awareness and elasticity in hardware and software is an answer to many problems and challenges we are facing in High Performance Computing (HPC) today. Resource utilization inefficiency is a real problem in current HPC systems due to the current static, inflexible resource assignment configuration. One way to resolve this problem is to change the static resource assignment setting---by introducing runtime resource elasticity, which requires both malleability in software implementation and support for runtime resource adaptation in the system infrastructure. In this paper, we show a successful implementation of a malleable tsunami simulation realized on an elastic MPI infrastructure we previously proposed. We also prove that introducing malleability to such a tightly coupled parallel application can be beneficial.	elasticity (data store);simulation	Ao Mo-Hellenbrand;Isaías A. Comprés Ureña;Oliver Meister;Hans-Joachim Bungartz;Michael Gerndt;Michael Bader	2017		10.1145/3075564.3075585	parallel computing;real-time computing;computer science;message passing;inefficiency;software;elasticity (economics);malleability;supercomputer;distributed computing;adaptive mesh refinement	HPC	-21.94155321430585	58.166052793552765	16461
d3245f6776ed6c0154550c65d7aff33247f565dc	extension of the amber molecular dynamics software to intel's many integrated core (mic) architecture	code optimization;molecular dynamics;acceleration;xeon phi;mic	We present an implementation of explicit solvent particle mesh Ewald (PME) classical molecular dynamics (MD) within the PMEMD molecular dynamics engine, that forms part of the AMBER v14 MD software package, that makes use of Intel Xeon Phi coprocessors by offloading portions of the PME direct summation and neighbor list build to the coprocessor. We refer to this implementation as  pmemd MIC offload    and in this paper present the technical details of the algorithm, including basic models for MPI and OpenMP configuration, and analyze the resultant performance. The algorithm provides the best performance improvement for large systems (  >     >       400,000 atoms), achieving a ∼35% performance improvement for satellite tobacco mosaic virus (1,067,095 atoms) when 2 Intel E5-2697 v2 processors (2 ×12 cores, 30M cache, 2.7 GHz) are coupled to an Intel Xeon Phi coprocessor (Model 7120P—1.238/1.333 GHz, 61 cores). The implementation utilizes a two-fold decomposition strategy: spatial decomposition using an MPI library and thread-based decomposition using OpenMP. We also present compiler optimization settings that improve the performance on Intel Xeon processors, while retaining simulation accuracy.	assisted model building with energy refinement (amber);molecular dynamics;xeon phi	Perri J. Needham;Ashraf Bhuiyan;Ross C. Walker	2016	Computer Physics Communications	10.1016/j.cpc.2015.12.025	acceleration;molecular dynamics;computer architecture;parallel computing;computer science;operating system;program optimization;xeon phi;hyper-threading;physics;quantum mechanics	Arch	-5.097100348288239	39.11590190626281	16512
3324dbcf685e1ef70f91de32b4d164071138fe18	guest editor introduction: special issue on high performance computing for high productivity environments	high performance computer	Rapid prototyping and application development environments are often the tool of choice for many developers and users. These environments and languages include MATLAB®, perl, python, R and Ruby. They are popular, in large part, because they make computing accessible to “accidental programmers” (scientists, statisticians, economists and others not specifically trained as programmers) and because they deliver on their promise of rapid prototyping to more seasoned programmers. Users of these systems often face a dilemma as their problems grow: live within the performance and resource constraints of these systems, or leave these comfortable environments behind and take up tools that are traditionally associated with high(er) performance computing (C/C++/FORTRAN, MPI, OpenMP). This special issue presents six projects aimed at resolving this dilemma in favor of remaining in the environment of choice, but augmenting it so that larger problems can be handled with relative ease (although, perhaps, not with absolutely optimal performance). The projects presented cover a good sampling of popular environments: MATLAB, python, R and Ruby, with a touch of Perl on the side. The enhancement strategies span a range of approaches: easy to use interfaces for accessing high performance libraries that were written the “old fashioned” way, parallel versions of apply/map functions, data parallel frameworks, cleanly wrapped RPC systems, and virtual shared memory. Some approaches are specific to one environment; others are applicable to many or most. Taken together, they are indicative of the interest in and the importance of creative responses to the challenge of making HPC accessible to a broad range of users. Sharma and Martin discuss parallel constructs for MATLAB, one of the most popular commercial systems in this area. They address two related challenges: (i) develop parallel functionality that fits well with the MATLAB computational model;	computational model;data parallelism;error-tolerant design;fits;library (computing);matlab;message passing interface;openmp;perl;programmer;python;r language;rapid prototyping;remote procedure call;ruby;sampling (signal processing);shared memory	Nicholas Carriero	2008	International Journal of Parallel Programming	10.1007/s10766-008-0090-5	computer science	HPC	-12.134069836947537	40.4868697986614	16585
83d544656ab76ae898073863cbb03d0a722696f6	enhancing the assertion-based verification of tlm designs with reentrancy	auxiliary variable;psl language;assertion based verification;psl modeling layer;simultaneous data processing;tlm design;time varying systems;semantics;reentrancy;abv methodology;pipelined behaviour;automatic generation;time domain analysis;formal verification;monitoring;syntactics;specification languages;simultaneous data processing assertion based verification tlm design reentrancy systemc transactional level modelling psl language abv methodology psl modeling layer auxiliary variable pipelined behaviour;transaction processing;switches;context;semantics monitoring syntactics context switches time domain analysis time varying systems;pipeline processing;transaction processing formal verification pipeline processing specification languages;systemc transactional level modelling;transaction level	In this paper, we focus on the assertion-based verification (ABV) of designs described using the SystemC transactional level (TLM). Assertions are expressed in the PSL language, and the verification that the system fulfils these properties is performed dynamically i.e., during simulation. We have previously reported our results about the development of a dedicated ABV methodology that makes use of automatically generated checkers and of ad hoc observation mechanisms. The technique has also been improved to support the PSL Modeling Layer which enables the use of (global) auxiliary variables in assertions. A prototype tool, called ISIS, implements all these features. However, supporting the notion of global variables in assertions is not sufficient in general, for instance when components have a pipelined behaviour, thus enabling the simultaneous processing of several data. We propose here yet another improvement of the method, that provides for considering reentrant assertions (i.e., assertions simultaneously evaluated for different data) through the use of multiple checker instances, with local variables. We extend the PSL syntax with an appropriate syntactical construct, we adapt the semantics accordingly, and we describe the implementation in our tool. Experimental results are also reported.	assertion (software development);global variable;hoc (programming language);isis;local variable;prototype;simulation;systemc;yet another	Laurence Pierre;Luca Ferro	2010	Eighth ACM/IEEE International Conference on Formal Methods and Models for Codesign (MEMOCODE 2010)	10.1109/MEMCOD.2010.5558642	reentrancy;parallel computing;real-time computing;transaction processing;formal verification;network switch;computer science;semantics;programming language	EDA	-33.21233299403394	33.07247706591815	16600
a0c5252e12c097b83aaa4bbea5036dc1e66279dd	necessity is the mother of invention: a simple grid computing system using commodity tools	xml rpc;calcul grille;systeme unix;apache;systeme grande taille;close coupling;sql;unix system;xml language;http;interrogation base donnee;distributed computing;interrogacion base datos;composant logiciel;langage java;large scale system;local system;protocole http;grid;large scale;large scale simulation;centre calcul;perl;rejilla;software component;grille;calculo repartido;lenguaje java;linux;sistema unix;computer center;protocolo http;grid computing;calcul reparti;database query;langage xml;lenguaje xml;unix;centro calculo;sistema gran escala;java language;java	Access to sufficient resources is a barrier to scientific progress for many researchers facing large computational problems. Gaining access to large-scale resources (i.e., university-wide or federally supported computer centers) can be difficult, given their limited availability, particular architectures, and request/review/approval cycles. Simultaneously, researchers often find themselves with access to workstations and older clusters overlooked by their owners in favor of newer hardware. Software to tie these resources into a coherent Grid, however, has been problematic. Here, we describe our experiences building a Grid computing system to conduct a large-scale simulation study using ‘‘borrowed’’ computing resources distributed over a wide area. Using standard software components, we have produced a Grid computing system capable of coupling several hundred processors spanning multiple continents and administrative domains. We believe that this system fills an important niche between a closely coupled local system and a heavyweight, highly customized wide area system. r 2003 Elsevier Science (USA). All rights reserved.	central processing unit;coherence (physics);component-based software engineering;computational problem;file spanning;grid computing;limited availability;niche blogging;simulation;workstation	Daniel S. Myers;Michael P. Cummings	2003	J. Parallel Distrib. Comput.	10.1016/S0743-7315(03)00004-2	hypertext transfer protocol;sql;parallel computing;xml-rpc;xml;telecommunications;computer science;component-based software engineering;operating system;database;distributed computing;utility computing;unix;programming language;grid;java;world wide web;linux kernel;local system;algorithm;grid computing	HPC	-27.386693904819847	43.431263809402495	16608
41924397a5c3a6176cf96731950102b6fbf38bfa	platform-as-a-service architecture for performance isolated multi-tenant applications	admission control time factors resource management delays generators throughput;software as a service platform as a service architecture performance isolated multitenant applications paas enhancement saas application;software performance evaluation cloud computing	Software-as-a-Service (SaaS) often shares one single application instance among different tenants to reduce costs. However, sharing potentially leads to undesired influence from one tenant onto the performance observed by the others. This is a significant problem as performance is one of the major obstacles for cloud customers. The application does intentionally not manage hardware resources, and the operating system is not aware of application level entities like tenants which makes the performance control a challenge. In case the SaaS is hosted on a Platform-as-a-Service (PaaS), the SaaS developer usually wants to control performance-related issues according to individual needs, and available information is even more limited. Thus, it is difficult to control the performance of different tenants to keep them isolated. Existing work focuses on concrete methods to provide performance isolation in systems where the whole stack is under control. In this paper we present a concrete PaaS enhancement which enables application developers to realize isolation methods for their hosted SaaS application. In a case study we evaluated the applicability and effectiveness of the enhancement in different environments.	algorithm;entity;multitenancy;operating system;overhead (computing);platform as a service;progressive enhancement;requirement;response time (technology);run time (program lifecycle phase);runtime system;software as a service	Rouven Krebs;Manuel Loesch;Samuel Kounev	2014	2014 IEEE 7th International Conference on Cloud Computing	10.1109/CLOUD.2014.125	real-time computing;simulation;operating system;computer security	HPC	-26.45128327474218	58.998270298480634	16618
2a3c48e6fe544a0a2ac5bb35c1780c41c7afacd7	concise server-wide causality management forźeventually consistent data stores	logical clocks;haslab haslab uminho;anti entropy;distributed systems;key value stores;eventual consistency;causality	Large scale distributed data stores rely on optimistic replication to scale and remain highly available in the face of network partitions. Managing data without coordination results in eventually consistent data stores that allow for concurrent data updates. These systems often use anti-entropy mechanisms (like Merkle Trees) to detect and repair divergent data versions across nodes. However, in practice hash-based data structures are too expensive for large amounts of data and create too many false conflicts. Another aspect of eventual consistency is detecting write conflicts. Logical clocks are often used to track data causality, necessary to detect causally concurrent writes on the same key. However, there is a nonnegligible metadata overhead per key, which also keeps growing with time, proportional with the node churn rate. Another challenge is deleting keys while respecting causality: while the values can be deleted, perkey metadata cannot be permanently removed without coordination. We introduce a new causality management framework for eventually consistent data stores, that leverages node logical clocks (Bitmapped Version Vectors) and a new key logical clock (Dotted Causal Container) to provides advantages on multiple fronts: 1) a new efficient and lightweight anti-entropy mechanism; 2) greatly reduced per-key causality metadata size; 3) accurate key deletes without permanent metadata.	64-bit computing;algorithm;bitmap;bitwise operation;causal consistency;causal filter;causality;data store;data structure;distributed computing;emoticon;eventual consistency;false sharing;identifier;least significant bit;logical clock;merkle tree;most significant bit;optimistic replication;overhead (computing);sensor;vector clock;version vector	Ricardo Gonçalves;Paulo Sérgio Almeida;Carlos Baquero;Victor Fonte	2015		10.1007/978-3-319-19129-4_6	logical clock;causality;computer science;operating system;data mining;database;distributed computing;eventual consistency	OS	-21.155179669845577	49.21532975756333	16631
1d90f1d5d058c42b9b997dbddfbb0e85cb2b2672	performance improvement of i/o intensive olap with dynamic control of file storing location	storage device;olap;dbms;filesystem	Large scale data intensive applications, such as Online analytical processing (OLAP) and Mining from Big Data are one of most important applications in recent years. For improving these performances, growing sequential I/O performance is essential because storage devices are accessed sequentially by these large scale data intensive applications. For improving sequential I/O performance, we have proposed two methods for file location optimization in ZBR HDDs. In this paper, we focus on these methods and OLAP, and investigate effectiveness of these methods for large scale data intensive applications. First, we introduce the methods for improving sequential I/O performance for large scale distributed filesystem and distributed processing. Second, we apply the method to a popular OLAP benchmark TPC-H and discuss applicability of the method to OLAP. We then demonstrate that the method can reduce time to process the query.	benchmark (computing);big data;clustered file system;data-intensive computing;distributed computing;ibm tivoli storage productivity center;mathematical optimization;online analytical processing;performance	Eita Fujishima;Kenji Nakashima;Saneyasu Yamaguchi	2017		10.1145/3022227.3022305	online analytical processing;computer science;operating system;data mining;database;world wide web	HPC	-16.793876549189747	54.146955237637805	16690
0c34762a9bf1d9cc870959ec4ab09493c5af643f	self-management grid services - a programmable network approach	ucl;discovery;theses;conference proceedings;digital web resources;ucl discovery;open access;grid service;ucl library;book chapters;open access repository;programmable networks;ucl research	Due to the complexity and size of service oriented GRIDs, it is essential that GRID systems should be autonomous i.e. a self-management system is needed. This paper identifies the requirements of such a self- management GRID system and the required supporting services. This paper suggests that these supporting services should be deployed in the form of software modules through programmable techniques. This paper presents a communication protocol for dynamic self-configuration in programmable GRIDs as an example for supporting new network services.	self-management (computer science)	Lawrence Cheng;Alex Galis;Arso Savanovic;Borka Jerman-Blazic;Janez Bester	2004		10.1007/978-3-540-24688-6_21	computer science;world wide web	HPC	-33.66341384015448	47.31414883756659	16705
3c79597f01e75dd4f066960969a1a06684339d09	paratrac: a fine-grained profiler for data-intensive workflows	profiling;data processing;tracing;file system;workflow;workflow management system	The realistic characteristics of data-intensive workflows are critical to optimal workflow orchestration and profiling is an effective approach to investigate the behaviors of such complex applications. ParaTrac is a fine-grained profiler for data-intensive workflows by using user-level file system and process tracing techniques. First, ParaTrac enables users to quickly understand the I/O characteristics of from entire application to specific processes or files by examining low-level I/O profiles. Second, ParaTrac automatically exploits fine-grained data-processes interactions in workflow to help users intuitively and quantitatively investigate realistic execution of data-intensive workflows. Experiments on thoroughly profiling Montage workflow demonstrate both the scalability and effectiveness of ParaTrac. The overhead of tracing thousands of processes is around 16%. We use low-level I/O profiles and informative workflow DAGs to illustrate the vantage of fine-grained profiling by helping users comprehensively understand the application behaviors and refine the scheduling for complex workflows. Our study also suggests that current workflow management systems may use fine-grained profiles to provide more flexible control for optimal workflow execution.	data-intensive computing;high- and low-level;information;input/output;interaction;montagejs;overhead (computing);profiling (computer programming);scalability;scheduling (computing);user space	Nan Dun;Kenjiro Taura;Akinori Yonezawa	2010		10.1145/1851476.1851482	workflow;real-time computing;tracing;data processing;computer science;operating system;database;profiling;windows workflow foundation;world wide web;workflow management system;workflow engine;workflow technology	HPC	-23.315877406031916	56.641126664673	16711
7978c6ee3e7261396c74944b7686581d04453467	a checkpointing algorithm for an sci based distributed shared memory system	distributed memory;shared memory;fault tolerant;parallel computer;message passing;rollback recovery;distributed shared memory	Distributed Shared Memory (DSM) systems combine the ease of programming of Shared Memory Parallel Computers and scalability of message passing multicomputers. IEEE has proposed an interface standard known as SCI standard to construct DSM systems. When the number of processors in a parallel computer increase it is imperative to build fault tolerance. This article presents an algorithm for checkpointing and rollback recovery of an SCI based DSM system using the provisions of the standard. It is shown that this checkpointing and rollback recovery procedure judiciously combines the features of both shared memory and message passing distributed memory system.	algorithm;application checkpointing;distributed shared memory	S. Kalaiselvi;V. Rajaraman	1999	Microprocessors and Microsystems - Embedded Hardware Design	10.1016/S0141-9331(98)00116-1	uniform memory access;distributed shared memory;shared memory;interleaved memory;fault tolerance;computer architecture;parallel computing;message passing;distributed memory;computer science;operating system;distributed computing;overlay;data diffusion machine;memory map;memory management;supercomputer architecture	EDA	-12.453501965430604	43.917441257118774	16776
4a7bbb5718449555f63eb45a1ab2c71fd212a75c	advanced compiler optimizations for supercomputers	computers;parallelisme;digital computers;computer program;calculo vectorial;optimisation;general and miscellaneous mathematics computing and information science;dato;compilateur;optimizacion;programming language;multiprocessor;executive codes;generation code;efficiency;data;generacion codigo;code generation;concurrent program;programming languages 990210 supercomputers 1987 1989;dependence;dependance;supercomputer;compiler;supercomputador;computer architecture;parallelism;paralelismo;donnee;vector calculus;array processors;compiler optimization;programa competidor;computer codes;programming 990200 mathematics computers;calcul vectoriel;optimization;fortran;multiprocesador;programming;vector processing;supercomputers;parallel processing;compilador;superordinateur;programming languages;dependencia;programme concurrent;multiprocesseur	Compilers for vector or multiprocessor computers must have certain optimization features to successfully generate parallel code.	compiler;computer;mathematical optimization;multiprocessing;parallel computing;supercomputer	David A. Padua;Michael Wolfe	1986	Commun. ACM	10.1145/7902.7904	parallel processing;programming;computer architecture;compiler;supercomputer;vector processor;parallel computing;multiprocessing;vector calculus;computer science;operating system;optimizing compiler;efficiency;programming language;algorithm;code generation;data	PL	-15.857187801962997	41.92468323248023	16807
57c1450ef144f742d226337bc57c2831870c4a4a	the case for sram main memory	replacement policy	The growing CPU-memory gap is resulting in increasingly large cache sizes. As cache sizes increase, associativity becomes less of a win. At the same time, since costs of going to DRAM increase, it becomes more valuable to be able to pin critical data in the cache---a problem if a cache is direct-mapped or has a low degree of associativity. Something else which is a problem for caches of low associativity is reducing misses by using a better replacement policy. This paper proposes that L2 cache sizes are now starting to reach the point where it makes more sense to manage them as the main memory of the computer, and relegate the traditional DRAM main memory to the role of a paging device. The paper details advantages of an SRAM main memory, as well as problems that need to be solved, in managing an extra level of virtual to physical translation.	cpu cache;central processing unit;computer data storage;dynamic random-access memory;paging;static random-access memory	Philip Machanick	1996	SIGARCH Computer Architecture News	10.1145/242694.242709	bus sniffing;parallel computing;real-time computing;thrashing;cache coloring;tag ram;computer hardware;cache;computer science;operating system;universal memory;cache algorithms;cache pollution	Arch	-8.392951791377882	53.59365833119361	16820
792c0939d4397800ac3ee23bd31ffdae6efe8dc4	enhancing performance in a parallel file system	parallelisme;optimisation;optimizacion;improvement;multiprogrammation;performance;multiprogramming;recherche;searching;parallelism;paralelismo;multiprogramacion;fichier parallele;systeme gestion fichier;amelioration;parallel file system;parallel files;mejoria;optimization;rendimiento;investigacion	As computer applications have become more sophisticated, they have become rather data intensive. Such applications suffer from inadequate use of parallelism for processing data stored on secondary storage devices. Devices such as database machines are useful in some applications, but many applications are too small or specialized to make use of database machine technology.#R##N##R##N#To bridge this gap, we have introduced a parallel file system. The parallel file system is capable of acting as either an SIMD machine or an MIMD machine depending on the file type.#R##N##R##N#In the present work, we describe two approaches to enhance performance in the parallel file system. First, we examine a strategy of initiating partial searches when full searches for concurrent file usage are not possible. As a second level, a relocation algorithm has been designed to move selected portions of files (subfiles) to improve the degree of parallelism in the multiprogramming environment. The relocation algorithm makes use of a cost function based on the level of sharing between files to determine the best place to relocate the subfiles.	clustered file system	Leslie L. Miller;S. R. Inglett	1994	Microprocessing and Microprogramming	10.1016/0165-6074(94)90134-1	self-certifying file system;parallel computing;torrent file;device file;computer file;computer multitasking;computer hardware;performance;computer science;stub file;versioning file system;operating system;unix file types;journaling file system;distributed computing;open;data file;programming language;file system fragmentation	HPC	-16.549960748799695	43.98165120115443	16860
a17334b66f5cbe5a05a89fc66921ee8b6f05ae71	performance modeling of nested transactions in database systems	phase locking;database system;performance evaluation;nested transaction;simulation;two phase locking;nested transactions;satisfiability;system performance;mobile database;workflow system;concurrency control;performance model;shape parameter;simulation model	The nested transaction model was introduced to satisfy the requirements of advanced database applications. Moreover, it is currently the basic transaction model for new databases like workflow systems, mobile databases, and objectrelational databases. Though there are several performance evaluation studies of different concurrency control mechanisms in nested transactions, effects of transaction parameters on the overall system performance have not received any attention. In this paper, we study the effects of transactions characteristics on system performance. We developed a detailed simulation model and conducted several experiments to measure the impact of transactions characteristics on the performance. First, the effect of the number of leaves on the performance of nested transactions is investigated under different shaping parameters. Also, effects of the depth of the transaction tree on the system performance are investigated.	concurrency (computer science);concurrency control;control system;database;experiment;nested transaction;noise shaping;performance evaluation;requirement;simulation;transaction processing	Hossam S. Hassanein;Mohamed E. El-Sharkawi	2000		10.1145/782034.782038	real-time computing;database transaction;distributed transaction;computer science;database;distributed computing;computer performance;online transaction processing;serializability;acid;transaction processing system;nested transaction;schedule	DB	-20.423088580078655	46.70518496996598	16895
caa3cbbd64df034a250dddd40e5788cb86c3371c	solving the cardiac bidomain equations using graphics processing units	cardiac modeling;multigrid method;graphics processing units;preconditioned conjugate gradient;bidomain equations	The computational modeling of the heart has been shown to be a very useful tool. The models, which become more realistic each day, provide a better understanding of the complex biophysical processes related to the electrical activity in the heart, e.g., in the case of cardiac arrhythmias. However, the increasing complexity of the models challenges high performance computing in many aspects. This work presents a cardiac simulator based on the bidomain equations that exploits the new parallel architecture of graphics processing units (GPUs). The initial results are promising. The use of the GPU accelerates the cardiac simulator by about 6 times compared to the best performance obtained in a general-purpose processor (CPU). In addition, the GPU implementation was compared to an efficient parallel implementation developed for cluster computing. A single desktop computer equipped with a GPU is shown to be 1.4 times faster than the parallel implementation of the bidomain equations running on a cluster composed of 16 processing cores.	computer graphics;graphics processing unit	Ronan M. Amorim;Rodrigo Weber dos Santos	2013	J. Comput. Science	10.1016/j.jocs.2012.06.007	computational science;computer hardware;computer science;mathematics;algorithm;multigrid method;computer graphics (images)	Theory	-5.595731559459407	36.882055961553704	16953
1cd7b4c3a93e3260c4c57efcecd3282e68f475f9	performance implications of dynamic memory allocators on transactional memory systems	performance evaluation;interdisciplinar;dynamic memory allocation;transactional memory	Although dynamic memory management accounts for a significant part of the execution time on many modern software systems, its impact on the performance of transactional memory systems has been mostly overlooked. In order to shed some light into this subject, this paper conducts a thorough investigation of the interplay between memory allocators and software transactional memory (STM) systems. We show that allocators can interfere with the way memory addresses are mapped to versioned locks on state-of-the-art software transactional memory implementations. Moreover, we observed that key aspects of allocators such as false sharing avoidance, scalability, and locality have a drastic impact on the final performance. For instance, we have detected performance differences of up to 171% in the STAMP applications when using distinct allocators. Moreover, we show that optimizations at the STM-level (such as caching transactional objects) are not effective when a modern allocator is already in use. All in all, our study highlights the importance of reporting the allocator utilized in the performance evaluation of transactional memory systems.	allocator (c++);basic stamp;benchmark (computing);best-effort delivery;blocking (computing);cache (computing);dhrystone;false sharing;graphic art software;interference (communication);locality of reference;lock (computer science);memory management;performance evaluation;run time (program lifecycle phase);scalability;sensor;software system;software transactional memory;software versioning	Alexandro Baldassin;Edson Borin;Guido Araujo	2015		10.1145/2688500.2688504	interleaved memory;transactional memory;parallel computing;real-time computing;computer science;static memory allocation;distributed computing;flat memory model;c dynamic memory allocation;programming language;memory map;memory management	Arch	-9.170809252450402	50.043903191709276	17044
91d28e48c2fca2682f6c554a699d63c6b2a207fd	a translation method from natural language specifications into formal specifications using contextual dependencies	algebraic specification;algebraic specifications;protocols;formal specification;protocol machine;natural language specifications;osi session protocol specification natural language specifications formal specifications contextual dependencies communication protocols algebraic specifications protocol machine;formal specifications;natural languages;data type;contextual dependencies;system recovery;telecommunications computing;specification of communication protocols;specification languages;natural language;safety;property a;protocol specification;communication protocol;natural languages formal specifications protocols context programming specification languages program processors parallel processing safety system recovery;osi session protocol specification;open systems;programming;program processors;context;communication protocols;parallel processing;telecommunications computing formal specification natural languages open systems protocols	This paper presents a method of translating natural language specifications of communication protocols into algebraic specifications. Such a natural language specification specifies action sequences performed by the protocol machine (program). Usually, a sentence implicitly specifies the state of the protocol machine at which the described actions should be performed. A method of analyzing the implicitly specified states of the protocol machine is proposed taking the OSI session protocol specification (265 sentences) as an example. The method uses the following properties: (a) syntactic properties of a natural language (English in this paper); (b) syntactic properties introduced by the target algebraic specifications, e.g., subtype relations; (c) properties of a data type, e.g., properties of timer. This paper also shows the result of applying this method to the main part of the OSI session protocol specification (29 paragraphs, 98 sentences). For 95 sentences, the translation system uniquely determines the states specified implicitly by those sentences, using only (a) and (b) described above. By using (c) in addition, each implicitly specified state in the remaining three sentences is uniquely determined.	algebraic specification;dictionary;emoticon;linear algebra;machine translation;natural language;osi model;parsing;programming language specification;rapid prototyping;requirement;sensor;timer	Yasunori Ishihara;Hiroyuki Seki;Tadao Kasami	1993		10.1109/ISRE.1993.324853	communications protocol;parallel processing;computer science;theoretical computer science;database;natural language;programming language;language of temporal ordering specification	SE	-31.71635202705571	32.38048814724844	17062
e9a14035f39355825ab65093fc21c53f32c8fbd9	thread migration and its applications in distributed shared memory systems	distributed system;virtual parallel machine;personal computer;mobile computer;thread migration;operating system;distributed computing system;tread migration;load sharing;load distribution;parallel machines;parallel programs;distributed shared memory	In this paper we describe the way thread migration can be carried in distributed shared memory (DSM) systems. We discuss the advantages of multi-threading in DSM systems and the importance of preempted dynamic thread migration. The proposed solution is implemented in MILLIPEDE: an environment for parallel programming over a network of (personal) computers. MILLIPEDE implements transparent computation migration mechanism: a mobile computation thread in a MILLIPEDE application can be suspended almost at every point during its lifetime and be resumed on another host. This mechanism can be used to better utilize system resources and improve performance by balancing the load and solving ping-pong situations of memory objects, and to provide user ownership on his workstation. We describe how some of these are implemented in the MILLIPEDE system. MILLIPEDE, including its thread migration module, is fully implemented in user-mode (currently on Windows-NT) using the standard operating system APIs.	distributed shared memory;process migration;thread pool	Ayal Itzkovitz;Assaf Schuster;Lea Shalev	1998	Journal of Systems and Software	10.1016/S0164-1212(98)00008-9	distributed shared memory;parallel computing;win32 thread information block;computer hardware;computer science;weight distribution;operating system;distributed computing;mobile computing	OS	-15.662943495942493	48.275020267543056	17084
249c6d4e73cc8bf6bf7a403c7c27e598942e8811	ndcouplinghdfs: a coupling architecture for a power-proportional hadoop distributed file system			apache hadoop;dce distributed file system	Hieu Hanh Le;Satoshi Hikida;Haruo Yokota	2014	IEICE Transactions		parallel computing;computer science;operating system;database	DB	-18.990787303425904	52.22828447218533	17117
01bcd68d640465f84dd6e12818751da5fe00ded7	assertion-based verification of rtos properties	embedded systems;instruction sets;operating systems (computers);program verification;specification languages;task analysis;ieee p1850 psl;rtos property;systemc;abstract rtos model;assertion-based verification;embedded real time systems;instruction set simulation;multiple software task allocation;property specification language;real time operating system;worst case timing analysis;psl;real-time operating systems;verification	Today, mobile and embedded real time systems have to cope with the migration and allocation of multiple software tasks running on top of a real time operating system (RTOS) residing on one or several processors. For scaling of each task set and processor configuration, instruction set simulation and worst case timing analysis are typically applied. This paper presents a complementary approach for the verification of RTOS properties based on an abstract RTOS-Model in SystemC. We apply IEEE P1850 PSL for which we present an approach and first experiences for the assertion-based verification of RTOS properties.	best, worst and average case;central processing unit;embedded system;image scaling;instruction set simulator;real-time operating system;simulation;static timing analysis;systemc	Marcio F. da S. Oliveira;Henning Zabel;Wolfgang Müller	2010	2010 Design, Automation & Test in Europe Conference & Exhibition (DATE 2010)		embedded system;synchronization;computer architecture;real-time computing;verification;real-time operating system;computer science;operating system;instruction set;task analysis;psl;static timing analysis;atom	Embedded	-8.062679457632896	59.11690021009974	17135
31b17bcb6fa8516ad97f16fdf984c7b53e3c60fd	random injection control of multiprogramming in virtual memory	virtual memory;virtual memory multiprogramming;multiprogramming;optimal control;simulation experiment;control systems throughput mathematical model predictive models optimal control computational modeling delay testing robust control control system synthesis;mathematical model	"""We propose a new method for the control of a multiprogrammed virtual memory computer system. A mathematical model solved by decomposition permits us to justify that the method avoids thrashing. Simulation experiments are used to test the robustness of the predictions of the mathematical model when certain simplifying assumptions are relaxed and when a slightly simpler control technique based on the same principle is used. Comparisons are given with the case where an """"optimal"""" control is used and with that with no control. We also provide a simulation evaluating the estimators used in an implementation of the control, as well as the responsiveness of the controlled system to transients in the workload."""	computer multitasking;experiment;mathematical model;numerical analysis;openvms;optimal control;overhead (computing);page fault;random graph;responsiveness;run time (program lifecycle phase);server (computing);simulation;steady state;thrashing (computer science);time-sharing;xfig	Erol Gelenbe;Alain Kurinckx	1976	IEEE Transactions on Software Engineering	10.1109/TSE.1978.231462	real-time computing;simulation;optimal control;computer multitasking;computer science;virtual memory;theoretical computer science;operating system;mathematical model	Visualization	-13.881356394103303	58.93738901089192	17163
384af94c3cce0001b2c6ddf8aaeafe60201ccae5	d2.4 report on the final prototype of programming abstractions for energy-efficient inter-process communication		Work package 2 (WP2) aims to develop libraries for energy-efficient inter-process communication and data sharing on the EXCESS platforms. The Deliverable D2.4 reports on the final prototype of programming abstractions for energy-efficient interprocess communication. Section 1 is the updated overview of the prototype of programming abstraction and devised power/energy models. The Section 2-6 contain the latest results of the four studies: • GreenBST, a energy-efficient and concurrent search tree (cf. Section 2) • Customization methodology for implementation of streaming aggregation in embedded systems (cf. Section 3) • Energy Model on CPU for Lock-free Data-structures in Dynamic Environments (cf. Section 4.10) • A General and Validated Energy Complexity Model for Multithreaded Algorithms (cf. Section 5) D2.4: Report on the final prototype of programming abstractions 5 Executive Summary Work package 2 (WP2) investigate and model the trade-offs between energy consumption and performance of data structures and algorithms for inter-process communication. WP2 also provides concurrent data structures and algorithms that support energy-efficient massive parallelism while minimizing inter-component communication. The main achievements of Deliverable D2.4 are summarized as follows. • We have described the cache-oblivious abstraction that is used in developing our energy-efficient and concurrent data structures. We also present in the same section a detailed description of GreenBST, an energy-efficient concurrent search tree that was briefly described in D2.3. Also in this deliverable, GreenBST is tested with new state-of-the-art concurrent search trees that are not included in D2.3. The latest experimental results showed that GreenBST is more energy efficient and has higher throughput for both the concurrent searchand updateintensive workloads than the state-of-the-art. We also have implemented GreenBST for Myriad2 platform and have conducted an experimental evaluation using the implementation. • We present a methodology for the customization of streaming aggregation implemented in modern low power embedded devices. The methodology is based on design space exploration and provides a set of customized implementations that can be used by developers to perform trade-offs between throughput, latency, memory and energy consumption. We compare the proposed embedded system implementations of the streaming aggregation operator with the corresponding HPC and GPGPU implementations in terms of performance per watt. Our results show that the implementations based on low power embedded systems provide up to 54 and 14 times higher performance per watt than the corresponding Intel Xeon and Radeon HD 6450 implementations, respectively. • We present an energy model on CPU for lock-free data-structures in dynamic environments. Lock-free data structures are based on retry loops and are called by application-specific routines. In D2.3, we illustrate the performance impacting factors and the model that we use to cover a subset of the lock-free structures that we consider here. In the former study, the analysis is built upon properties that arise only when the sizes of the retry loops and the application-specific work are constant. In this work, we introduce two new frameworks that can be used to the capture the performance of a wider set of lock-free data structures (i.e. the size of retry loops follow a probability distribution) in dynamic environments (i.e. the size of application specific follows a probability distribution). These analyses allow us to estimate the energy consumption of an extensive set of lock-free data structures that are used under various access patterns. • We introduces a new general energy model ICE for analyzing the energy complexity of a wide range of multi-threaded algorithms. Compared to the EPEM model reported in D2.4: Report on the final prototype of programming abstractions 6 D2.3, this model proposed using Ideal Cache memory model to compute I/O complexity of the algorithms. Besides a case study of SpMV to demonstrate how to apply the ICE model to find energy complexity of parallel algorithms, Deliverable D2.4 also reports a case study to apply the ICE model to Dense Matrix Multiplication (matmul). The model is then validated with both data-intensive (i.e., SpMV) and computationintensive (i.e., matmul) algorithms according to three aspects: different algorithms, different input types/sizes and different platforms. In order to make the reading flow easy to follow, we include in this report a complete study of ICE model along with latest results. D2.4: Report on the final prototype of programming abstractions 7	amd radeon rx 200 series;cpu cache;cache-oblivious algorithm;central processing unit;data structure;data-intensive computing;design space exploration;embedded system;general-purpose computing on graphics processing units;input/output;inter-process communication;library (computing);matrix multiplication;non-blocking algorithm;parallel algorithm;parallel computing;performance per watt;prototype;retry;search tree;streaming media;thread (computing);throughput	Phuong Hoai Ha;Vi Ngoc-Nha Tran;Ibrahim Umar;Aras Atalar;Anders Gidenstam;Paul Renaud-Goud;Philippas Tsigas;Ivan Walulya	2018	CoRR		distributed computing;work package;personalization;deliverable;efficient energy use;search tree;data sharing;computer science;inter-process communication;abstraction	HPC	-7.219621300759558	58.65539745656467	17175
2e0972ff64c30b10cbf33f873ab8737887e38b19	a parallel completion procedure for term rewriting systems	term rewrite system	We present a parallel completion procedure for term rewriting systems Despite an extensive literature concerning the well known sequential Knuth Bendix completion procedure little attention has been devoted to designing parallel com pletion procedures Because naive parallelizations of sequential procedures lead to over synchronization and poor performance we employ a transition based approach that enables more e ective parallelizations The approach begins with a formulation of the completion procedure as a set of transitions in the style of Bachmair Der showitz and Hsiang and proceeds to a highly tuned parallel implementation that runs on a shared memory multiprocessor The implementation performs well on a number of standard examples	knuth–bendix completion algorithm;multiprocessing;rewriting;shared memory;whole earth 'lectronic link	Katherine A. Yelick;Stephen J. Garland	1992		10.1007/3-540-55602-8_159	computer science;database;programming language;confluence;algorithm	AI	-16.26452920211815	34.05512735105677	17181
605f6a93cc650c37dcb00c27da4f5026724523bc	are clouds ready for large distributed applications?	distributed application;modelizacion;distributed system;sistema operativo;high availability;entreprise;systeme reparti;rich internet application;informatique dans les nuages;availability;disponibilidad;empresa;service web;hyperlink;multiplicite;distributed storage;abstraction;web service;abstraccion;modelisation;sistema repartido;operating system;algorithme reparti;firm;multiplicidad;systeme exploitation;algoritmo repartido;scalability;peer to peer;distributed algorithm;modeling;edge computing;disponibilite;multiplicity;computacion en nube;servicio web;cloud computing	Cloud computing carries the promise of providing powerful new models and abstractions that could transform the way IT services are delivered today. In order to establish the readiness of clouds to deliver meaningful enterprise-class IT services, we identify three key issues that ought to be addressed as first priority from the perspective of potential cloud users: how to deploy large-scale distributed services, how to deliver high availability services, and how to perform problem resolution on the cloud. We analyze multiple sources of publicly available data to establish cloud user expectations and compare against the current state of cloud offerings, with a focus on contrasting the different requirements from two classes of users -- the individual and the enterprise. Through this process, our initial findings indicate that while clouds are ready to support usage scenarios for individual users, there are still rich areas of future research to be explored to enable clouds to support large distributed applications such as those found in enterprise.	cloud computing;distributed computing;high availability;requirement	Kunwadee Sripanidkulchai;Sambit Sahu;Yaoping Ruan;Anees Shaikh;Chitra Dorai	2010	Operating Systems Review	10.1145/1773912.1773918	web service;distributed algorithm;availability;scalability;rich internet application;simulation;systems modeling;cloud computing;computer science;operating system;distributed computing;abstraction;hyperlink;multiplicity;high availability;world wide web;computer security	Networks	-28.583155544437123	43.60078634606354	17207
09109df625055422efd6f0f717bf2d5e43714a07	average-case performance analysis of online non-clairvoyant scheduling of parallel tasks with precedence constraints	graph theory;concurrent computing;approximation algorithms;processor scheduling;probability distributions;random variables;ll greedy algorithm;online nonclairvoyant scheduling algorithm;performance analysis scheduling algorithm processor scheduling optimal scheduling time factors approximation algorithms random variables concurrent computing probability distribution algorithm design and analysis;statistical distributions;scheduling algorithm;time factors;precedence constraints;computational complexity;optimal scheduling;probability distribution;statistical distributions computational complexity graph theory parallel processing processor scheduling;performance analysis;average case performance analysis;task graphs;ls algorithm average case performance analysis online nonclairvoyant scheduling algorithm parallel tasks precedence constraints approximation algorithms task graphs probability distributions ll greedy algorithm;ls algorithm;algorithm design and analysis;parallel processing;parallel tasks	We evaluate the average-case performance of three approximation algorithms for online non-clairvoyant scheduling of parallel tasks with precedence constraints. We show that for a class of wide task graphs, when task sizes are uniformly distributed in the range [1..C], the online non-clairvoyant scheduling algorithm LL-SIMPLE has an asymptotic average-case performance bound of M/(M-(3-(1+1/C)C+1)C-1), where M is the number of processors. For arbitrary probability distributions of task sizes, we present numerical and simulation data to demonstrate the accuracy of our general asymptotic average-case performance bound. We also report extensive experimental results on the average-case performance of online non-clairvoyant scheduling algorithms LL-GREEDY and LS. Algorithm LL-GREEDY has better performance than LL-SIMPLE by using an improved algorithm to schedule independent tasks in the same level. Algorithm LS produces even better schedules due to break of boundaries among levels.	approximation algorithm;best, worst and average case;c99;central processing unit;greedy algorithm;ll grammar;ll parser;least squares;numerical analysis;profiling (computer programming);scheduling (computing);semi-continuity;simulation;the computer journal	Keqin Li	2007	2007 IEEE International Parallel and Distributed Processing Symposium	10.1109/IPDPS.2007.370579	probability distribution;fair-share scheduling;parallel processing;parallel computing;concurrent computing;computer science;graph theory;theoretical computer science;distributed computing;statistics	Embedded	-13.130915769157243	60.1498258939619	17231
015559b28c47f2a182d5cd7a4d345a0212c2d040	a syntactic description of bc neliac	syntactic description;bc neliac	"""Editor's Note: The jbllo'~vin,9 description q/' NELIAC lan-9:~age is repT""""esen:a~b.'e (!fez 9rn~p q/"""" NELIAC compiler's'. As yet, lhe~:'e is not a stan do:'d NELi AC. Howet'er, at ~z. NELIAC User'.~ ('om'erence i, .lan.~a~'y, i363 the~'e u'a.~ <, ~ d¢-~cision to de~'elop such ct ~htm/ard.-~-.I.G. !~, l(.JSS: at the time of th(, tormati<)n ()~ an h~ternational :\io~<)rittmfic I~ang,da<,ge f(,r ('omputing Machines (sub-~,(t~t(~tly lmmed AL(;o~.), a project was started at the !. S. Naval Etectr()~fi('s Laboratory in San Diego to de-v~qoI) :~ translator for JAil.. ()vertaking the definition ~,ff()rt, tiler d(qined their own language, doing so with a i,arti<'~.aiar u()z~trol apt)li(:atiozl in mill(l. Thus, a problem-,,ri(,t~ted la,,~guage based on A[.(a)L was defined and trans-i:~t(,'s w(.re bttilt for a mlnA)er of computers (Sperry-l~:i~,], l)atatron, CI)C as,it [t.L\I. among others). The v{,s(~l~]~ language (named NELIAC) was Mgebraic in ~}mra('ter (like ALia)L} but niu('h simpler and straight-f,,rwar(l (ram (:{)ns('(iu('~t[y. nnM~ easier to lean~ al~d to ~s,,). i\[i~im~tm effort principles were used in the design: .i~(as. thi:~s that arc said fre(luel~tly can be said simply, :,.~t hist()riea] matt~enmtical ~otatiot~s are respected as i::~r as feasible. Using load-a~M-~o techniques, single-pass fast e()~npilation was possible (more than 5()00 object u, ~l(:ls per minute), arm fast-vmming programs were ,})tai1~(,(l, In l:tie f()ur years since Ell(, start of the activity, NELtAC ~ms ev()lved through sev(ral generations with improve-~(,~t of power, speed of compiling and speed of object t)rograms. Some versions permit nested parenthetical ('xpressions in statements, some generate relocatable bi-~mry ('odes aim some have elat)orate input and output for-""""~, ~,,""""~ and control capabilities. All \-ersions of NEr3AC are self-compiling; that is, ~heir tra~Mators are written in NELl:to. Due to fast compilation , changes to a~y N~.:LrAC program are always n~ade it~ source language. This gives the nontrivial advantage that documentatiolt is ahvays up to date. Also, with 15 si~tfificant characters per identifier, a NELIAC pr()gram is an easily readable do(.ument. The version described here (cMled BC NEL~AC) is a descendant of the IB2~[ 704-IBM 709-IBM 7090 NELIACS developed at Fort Huachucha, which thenlselves came fl'()m the N nLIAC for the ~.perry-I{and 3.[460 in San Diego. 5larry pe()ple were involved i~ this development. To This paper defines the reference language attd hardware representation for B(: N~:LIAC. The authors of this paper have made certaill additions t<) the original IB~I 704 NELtAC which make :it a more powerful, flexible and a more machine-independent language. Some of the features added are the following: …"""	artificial intelligence;computer;identifier;input/output;linear algebra;neliac;random-access memory;self-hosting;software development kit;source-to-source compiler;stan (fan)	Harry D. Huskey;Ralph Love;Niklaus Wirth	1963	Commun. ACM	10.1145/366663.366664	programming language;syntax;computer science	PL	-14.167451908554915	33.66011011739897	17237
3eef664c4d1a2a9777f45d443ca77dcbfa5cef47	prosa: a case for readable mechanized schedulability analysis	verification;real time;schedulability analysis;formally proven schedulability analyses readable mechanized schedulability analysis prosa open source foundation multiprocessor response time analysis parallel jobs release jitter;verification real time schedulability analysis;real time systems jitter redundancy cognition open source software libraries complexity theory;theorem proving formal verification multiprocessing systems scheduling system monitoring	Motivated by a string of recent errata, the paper argues that mechanized, yet readable schedulability proofs are desirable, feasible to create with current tools and with reasonable effort, and beneficial beyond the increase in confidence. To facilitate such mechanized analyses, PROSA, a new open-source foundation for formally proven schedulability analyses that prioritizes readability, is presented. The approach is demonstrated with a case study that mechanizes multiprocessor response-time analysis, including new variants for parallel jobs and release jitter.	confidentiality;correctness (computer science);druid;formal verification;human-readable medium;job stream;multiprocessing;open-source software;overhead (computing);parallel computing;real-time clock;real-time computing;requirement prioritization;revolution in military affairs;scheduling (computing);scheduling analysis real-time systems;windows rt	Felipe Cerqueira;Felix Stutz;Björn B. Brandenburg	2016	2016 28th Euromicro Conference on Real-Time Systems (ECRTS)	10.1109/ECRTS.2016.28	parallel computing;real-time computing;verification;computer science;operating system;distributed computing;programming language	Embedded	-20.339634998429307	39.64596184383477	17241
0a3479c4ba207030072a1a922529322bf6ba581c	characterizing mpi matching via trace-based simulation		With the increased scale expected on future leadership-class systems, detailed information about the resource usage and performance of MPI message matching provides important insights into how to maintain application performance on next-generation systems. However, obtaining MPI message matching performance data is often not possible without significant effort. A common approach is to instrument an MPI implementation to collect relevant statistics. While this approach can provide important data, collecting matching data at runtime perturbs the applicationu0027s execution, including its matching performance, and is highly dependent on the MPI libraryu0027s matchlist implementation. In this paper, we introduce a trace-based simulation approach to obtain detailed MPI message matching performance data for MPI applications without perturbing their execution. Using a number of key parallel workloads, we demonstrate that this simulator approach can rapidly and accurately characterize matching behavior. Specifically, we use our simulator to collect several important statistics about the operation of the MPI posted and unexpected queues. For example, we present data about search lengths and the duration that messages spend in the queues waiting to be matched. Data gathered using this simulation-based approach have significant potential to aid hardware designers in determining resource allocation for MPI matching functions and provide application and middleware developers with insight into the scalability issues associated with MPI message matching.	trace-based simulation	Kurt B. Ferreira;Scott Levy;Kevin T. Pedretti;Ryan E. Grant	2018	Parallel Computing	10.1016/j.parco.2018.05.005	parallel computing;message passing;computer science;scalability;middleware;resource allocation;queue;distributed computing;trace-based simulation	HPC	-16.95390708180625	48.1224117677072	17260
d48986fca2ce5fdbf1e47ac93b978db2ef8ef7ee	an early comparison of commercial and open-source cloud platforms for scientific environments	commercial closed;hypervisors;cloud computing;open source	Cloud computing promises efficient use of hardware resources through virtualization and elastic computing facilities. Various cloud computing solutions have emerged on the market from open-source communities and commercial vendors. In this paper we discuss criteria for feature comparison of private cloud platforms and compare several open-source and commercial products. We test performance of hypervisors used in these clouds with a set of benchmark suites containing tests for various aspects of the system. We discuss the results in the context of what is commonly described as a scientific workload. The described feature and performance differences can help make wiser platform choices.	benchmark (computing);central processing unit;cloud computing;elasticity (cloud computing);headroom (audio signal processing);hypervisor;open-source software;operating system;programming paradigm;thread (computing)	Ivan Voras;Marin Orlic;Branko Mihaljevic	2012		10.1007/978-3-642-30947-2_20	real-time computing;simulation;cloud computing;computer science;operating system;cloud testing;hypervisor	HPC	-22.424416160476913	59.78969948231451	17285
65565ec74172020f399a2951740cf604740e1e0f	a hybrid buffer design with stt-mram for on-chip interconnects	stt mram;network on chip;buffer storage;input buffer;input buffer network on chip stt mram router;sram chips buffer storage multiprocessing systems network on chip;random access memory system on a chip computer architecture power demand throughput switches magnetic tunneling;router;multiprocessing systems;many core architectures hybrid buffer design spin torque transfer magnetic ram stt mram sram on chip interconnects network on chip noc input buffers chip multiprocessor design dynamic power consumption data migration retention time write latency reduction technique intrarouter latency near zero leakage power communication delay;sram chips	As the chip multiprocessor (CMP) design moves toward many-core architectures, communication delay in Network-on-Chip (NoC) has been a major bottleneck in CMP systems. Using high-density memories in input buffers helps to reduce the bottleneck through increasing throughput. Spin-Torque Transfer Magnetic RAM (STT-MRAM) can be a suitable solution due to its nature of high density and near-zero leakage power. But its long latency and high power consumption in write operations still need to be addressed. We explore the design issues in using STT-MRAM for NoC input buffers. Motivated by short intra-router latency, we use the previously proposed write latency reduction technique sacrificing retention time. Then we propose a hybrid design of input buffers using both SRAM and STT-MRAM to hide the long write latency efficiently. Considering that simple data migration in the hybrid buffer consumes more dynamic power compared to SRAM, we provide a lazy migration scheme that reduces the dynamic power consumption of the hybrid buffer. Simulation results show that the proposed scheme enhances the throughput by 21% on average.	algorithm;benchmark (computing);data buffer;dhrystone;electrical connection;interconnection;lazy evaluation;magnetoresistive random-access memory;manycore processor;marginal model;multi-core processor;multiprocessing;network on a chip;router (computing);routing;simulation;spectral leakage;static random-access memory;throughput	Hyunjun Jang;Baik Song An;Nikhil Kulkarni;Ki Hwan Yum;Eun Jung Kim	2012	2012 IEEE/ACM Sixth International Symposium on Networks-on-Chip	10.1109/NOCS.2012.30	embedded system;parallel computing;real-time computing;computer science;write buffer;network on a chip;magnetoresistive random-access memory	Arch	-8.37717748130227	54.23070783781466	17304
03469fda1e42ce494c69b6bc89b2201054edeba7	collaborative query coordination in community-driven data grids	data intensive application;distributed database;query processing;data grids;data management;hot spot;science communication;distributed databases;high throughput;domain specificity;data grid	E-science communities face huge data management challenges due to large existing data sets and expected data rates from forthcoming projects. Community-driven data grids provide a scalable, high-throughput oriented data management solution for scientific federations by employing domain-specific partitioning schemes and parallelism. In this paper, we present how community-driven data grids can adapt their query coordination strategies in the face of different typical submission scenarios. We explore the impact of submitting queries uniformly or having submission hot spots. By an extensive evaluation of five strategies on simulated and distributed setups, we show that some coordination strategies are preferable to others, regardless of submission skew. Based on our results, we can improve the usability and scalability of community-driven data grids for data-intensive applications.	data-intensive computing;e-science;high-throughput computing;parallel computing;scalability;throughput;usability;ws-coordination	Tobias Scholl;Angelika Reiser;Alfons Kemper	2009		10.1145/1551609.1551641	high-throughput screening;science communication;parallel computing;computer science;operating system;data grid;data mining;database;distributed computing;world wide web;distributed database;hot spot	HPC	-21.14252183893856	52.98835903415773	17322
18b7ba2572bc9a4c2d20faedf87d62b87a434516	improving the efficiency of functional parallelism by means of hyper-scheduling	functional parallel programs;parallel processing processor scheduling concurrent computing grid computing testing mathematics computer science power system interconnection acceleration rendering computer graphics;parallel job queue;processor scheduling;grid computing environment;parallel programming;null;processor scheduling parallel programming;hyperscheduling;parallel job queue hyperscheduling functional parallel programs idle times;idle times;parallel programs	By means of a comprehensive test bench of 36000 test cases we evaluated the efficiency of functional parallel programs. For all the test cases schedules have been computed by various well known heuristics. We assumed a homogeneous target system (e.g. a compute cluster of equally powerful interconnected nodes) that can be part of a grid computing environment which supports the execution of parallel programs. Unfortunately, the efficiencies of the investigated schedules were pretty low. For this reason, we propose a new hyper-scheduling approach that reduces the amount of idle times by interweaving subsequent schedules from the parallel job queue. First results confirm that hyper-scheduling significantly improves efficiency	algorithm;directed acyclic graph;graph property;grid computing;heuristic (computer science);job queue;parallel computing;schedule (computer science);scheduling (computing);speedup;test bench;test case	Udo Hönig;Wolfram Schiffmann	2006	2006 International Conference on Parallel Processing Workshops (ICPPW'06)	10.1109/ICPPW.2006.42	parallel computing;real-time computing;embarrassingly parallel;computer science;operating system;massively parallel;distributed computing;cost efficiency;parallel programming model	HPC	-13.395444421475105	47.23385078694545	17332
f7bb287845308bcbc4bb58fffeb47745e9ca982d	supercomputer throughput benchmarks for the cray-1s and cyber 205 with estimates for class vii supercomputers	tratamiento paralelo;computers;software;computer program;general and miscellaneous mathematics computing and information science;traitement parallele;logiciel;multiprocessor;methode mesure;implementation;performance;metodo medida;supercomputer;supercomputador;ejecucion;simulation 990200 mathematics computers;array processors;computerized simulation;computer codes;logicial;rendimiento;measurement method;multiprocesador;programming;parallel processing;cray computers;superordinateur;multiprocesseur	A large set of codes is used to construct various throughput models of the overall performance of any supercomputer system. The model is described with re sults from runs on CRAY-1S and Cyber 205 Class VI su percomputers. A unique reference throughput is estab lished on a CRAY-1S with precise vector performance and CPU utilization. The sensitivity of the modeling to variations in the code mix is discussed. The performance of multiprocessor, parallel supercomputers is estimated.	cdc cyber;supercomputer;throughput;vii	Brendan McNamara	1989	IJHPCA	10.1177/109434208900300305	computational science;parallel processing;programming;computer architecture;supercomputer;parallel computing;multiprocessing;performance;computer science;operating system;programming language;implementation;algorithm	HPC	-7.902090081102822	40.005399454427675	17390
5a4c1c835d91d08d06f59119fb55121fe38acfe1	a bird's eye view of matrix distributed processing	cluster computing;parallel algorithm;distributed processing;discrete mathematics;differential equation;multi dimensional;high energy physics;mathematical software;automatic parallelization	We present Matrix Distributed Processing, a C++ library for fast development of efficient parallel algorithms. MDP is based on MPI and consists of a collection of C++ classes and functions such as lattice, site and field. Once an algorithm is written using these components the algorithm is automatically parallel and no explicit call to communication functions is required. MDP is particularly suitable for implementing parallel solvers for multi-dimensional differential equations and mesh-like problems.	bird's-eye view;c++ classes;computation;distributed computing;lattice qcd;message passing interface;numerical analysis;open-source software;parallel algorithm;quantum;real life;web page	Massimo Di Pierro	2003		10.1007/3-540-44839-X_110	distributed algorithm;parallel computing;computer science;theoretical computer science;operating system;distributed computing;parallel algorithm;programming language;differential equation;automatic parallelization	HPC	-8.810720969500187	37.892214914273126	17394
7709d65b7bee682f15961f05efb5c23850475e24	data placement in bubba	data intensive application;large scale;parallel systems;load balance;data placement	This paper examines the problem of data placement in Bubba, a highly-parallel system for data-intensive applications being developed at MCC. “Highly-parallel” implies that load balancing is a critical performance issue. “Data-intensive” means data is so large that operations should be executed where the data resides. As a result, data placement becomes a critical performance issue. In general, determining the optimal placement of data across processing nodes for performance is a difficult problem. We describe our heuristic approach to solving the data placement problem in Bubba. We then present experimental results using a specific workload to provide insight into the problem. Several researchers have argued the benefits of declustering (i e, spreading each base relation over many nodes). We show that as declustering is increased, load balancing continues to improve. However, for transactions involving complex joins, further declustering reduces throughput because of communications, startup and termination overhead. We argue that data placement, especially declustering, in a highly-parallel system must be considered early in the design, so that mechanisms can be included for supporting variable declustering, for minimizing the most significant overheads associated with large-scale declustering, and for gathering the required statistics.	data-intensive computing;heuristic;load balancing (computing);microelectronics and computer technology corporation;overhead (computing);relational algebra;throughput	George P. Copeland;William Alexander;Ellen E. Boughter;Tom W. Keller	1988		10.1145/50202.50213	parallel computing;real-time computing;computer science;load balancing;database;distributed computing	DB	-15.613545689331715	56.73072757004653	17479
8383b59216c5927bde7fcaf087d477a028f0ee84	recovering in large distributed systems with replicated data	data access times;analytical models;distributed system;large distributed systems;independent recovery;very large databases distributed databases system recovery transaction processing;failure events;waste materials;transaction based distributed systems;availability;uncertainty;independent recovery large distributed systems replicated data recovery transaction based distributed systems data access times failure events recovery protocols dependent recovery protocols;uncertainty voting waste materials distributed computing large scale systems costs access protocols analytical models performance analysis availability;distributed computing;recovery;recovery protocols;large scale;system recovery;voting;replicated data;performance analysis;data access;distributed databases;access protocols;very large databases;transaction processing;large scale systems;dependent recovery protocols	The problem of recovery in large-scale transaction-based distributed systems with replicated data is studied. In large distributed systems the cost of accessing data items may be considerably greater, because of the distances involved. It is thus important to exploit replication to reduce data-access times. Also, in large systems, failure events are much more frequent than in small systems. Therefore, executing costly recovery protocols, such as the ones needed to update stale, newly-recovered replicas or to resolve the uncertainty of recovering replicas, must be avoided. These protocols are called dependent recovery protocols, since they require a recovering site to consult other sites before it can be reintegrated into the distributed system. Independent recovery has been proved unattainable in one-copy systems. It is shown that independent recovery is possible in systems with replicated data by contributing such a protocol. Simulation and analytical studies of its performance and availability characteristics are reported. >	distributed computing	Peter Triantafillou	1993		10.1109/PDIS.1993.253074	real-time computing;computer science;database;distributed computing	DB	-22.15568304479034	49.11291175609055	17483
7170986aab1f22d1d2d6e0d4e01b9c965888cb3d	exploiting gpu hardware saturation for fast compiler optimization	gpgpu;iterative compilation;optimization;opencl	Graphics Processing Units (GPUs) are efficient devices capable of delivering high performance for general purpose computation. Realizing their full performance potential often requires extensive compiler tuning. This process is particularly expensive since it has to be repeated for each target program and platform.  In this paper we study the utilization of GPU hardware resources across multiple input sizes and compiler options. In this context we introduce the notion of hardware saturation. Saturation is reached when an application is executed with a number of threads large enough to fully utilize the available hardware resources. We give experimental evidence of hardware saturation and describe its properties using 16 OpenCL kernels on 3 GPUs from Nvidia and AMD. We show that input sizes that saturates the GPU show performance stability across compiler transformations.  Using the thread-coarsening transformation as an example, we show that compiler settings maintain their relative performance across input sizes within the saturation region. Leveraging these hardware and software properties we propose a technique to identify the input size at the lower bound of the saturation zone, we call it Minimum Saturation Point (MSP). By performing iterative compilation on the MSP input size we obtain results effectively applicable for much large input problems reducing the overhead of tuning by an order of magnitude on average.	blas;benchmark (computing);bottleneck (software);computation;extrapolation;fast fourier transform;graphics processing unit;information;iterative method;kepler;max;opencl api;optimizing compiler;overhead (computing);performance tuning;regional lockout;speedup;throughput	Alberto Magni;Christophe Dubach;Michael F. P. O'Boyle	2014		10.1145/2576779.2576791	parallel computing;real-time computing;computer science;theoretical computer science	Arch	-4.863114934454972	45.97644590738808	17536
ca3fa426be511357658a4ccbca380d28d503faa9	hybridizing and coalescing load value predictors	performance evaluation;resource allocation;resource allocation performance evaluation;specint95 load value predictors storage reduction techniques performance evaluations cycle accurate simulator;component analysis;delay computer science performance analysis registers	∗ now at Cornell University Abstract Most well -performing load value predictors are hybrids that combine multiple predictors into one. Such hybrids are often large. To reduce their size and to improve their performance, this paper presents two storage reduction techniques as well as a detailed analysis of the interaction between a hybrid’s components. We found that state sharing and simple value compression can shrink the size of a predictor by a factor of two without compromising the performance. Our component analysis revealed that combining well -performing predictors does not always yield a good hybrid, whereas sometimes a poor predictor can make an excellent complement to another predictor in a hybrid. Performance evaluations using a cycle-accurate simulator running SPECint95 show that hybridizing can improve non-hybrids by thirty to fifty percent over a wide range of sizes. With fifteen kilobytes of state, our coalesced-hybrid yields a harmonic mean speedup of twelve and fifteen percent with a re-fetch and a re-execute misprediction recovery mechanism, respectively, which is higher than the speedup of other predictors we evaluate, some of which are six times larger.	branch misprediction;branch predictor;central processing unit;computer architecture simulator;eff des cracker;kerrison predictor;kilobyte;linear predictor function;locality of reference;open research;performance evaluation;simulation;singular value decomposition;speedup;superscalar processor	Martin Burtscher;Benjamin G. Zorn	2000		10.1109/ICCD.2000.878272	real-time computing;simulation;resource allocation;engineering	Arch	-10.395051527834768	51.808207529831094	17543
bfd933ae5ab14026413b598b29669c75357fe5ab	principles of transactional grid deployment	distributed system;haute performance;systeme reparti;availability;disponibilidad;distributed computing;grid;sistema repartido;design and implementation;rejilla;alto rendimiento;grille;calculo repartido;high performance;disponibilite;calcul reparti	This paper examines the availability of grid infrastructures, describes the principles of transactional grid deployment, outlines the design and implementation of a transactional deployment system for the Grid-Ireland national grid infrastructure based on these principles, and estimates the resulting availability.	software deployment;system deployment	Brian A. Coghlan;John Walsh;Geoff Quigley;David O'Callaghan;Stephen Childs;Eamonn M. Kenny	2005		10.1007/11508380_11	embedded system;availability;simulation;computer science;distributed computing;grid	HPC	-28.124598934065922	43.35508542718434	17549
58a368c0150dea2d09be06bdc1fd71b8a2fc098a	a useful trace facility for microcomputers		Abstract   Recently a single-stepping debugging aid which could be used on 6800-based microprocessor systems provided that slight modifications are made to the hardware of the machines was described. This paper describes a more elaborate trace facility which does not require any modifications to the hardware but which uses the software interrupt facility in combination with an interpreter for branch instructions as the basic mechanism for single-stepping.	microcomputer	M. Howard Williams	1981	Microprocessors and Microsystems - Embedded Hardware Design	10.1016/0141-9331(81)90345-8	embedded system;parallel computing;real-time computing;computer science;operating system;programming language	EDA	-25.44396974677963	37.66740022505817	17554
a963702308d352b83c25ab91c01439a55e46152f	analyzing mpi-3.0 process-level shared memory: a case study with stencil computations	standards;shared memory systems message passing;resource management;heating;mpi 3 0;multicore;compiler optimizations process level shared memory stencil computations process level shared memory interface data structures multiple mpi processes;synchronization;multicore processing;multicore mpi 3 0 process shared memory intranode commu nication stencil;process shared memory;optimization;intranode commu nication;stencil;optimization heating resource management synchronization standards multicore processing partitioning algorithms;partitioning algorithms	The recently released MPI-3.0 standard introduced a process-level shared-memory interface which enables processes within the same node to have direct load/store access to each others' memory. Such an interface allows applications to declare data structures that are shared by multiple MPI processes on the node. In this paper, we study the capabilities and performance implications of using MPI-3.0 shared memory, in the context of a five-point stencil computation. Our analysis reveals that the use of MPI-3.0 shared memory has several unforeseen performance implications including disrupting certain compiler optimizations and incorrectly using suboptimal page sizes inside the OS. Based on this analysis, we propose several methodologies for working around these issues and improving communication performance by 40-85% compared to the current MPI-1.0 based approach.	computation;data structure;five-point stencil;mpich;operating system;optimizing compiler;page (computer memory);shared memory;stencil (numerical analysis)	Xiaomin Zhu;Junchao Zhang;Kazutomo Yoshii;Shigang Li;Yunquan Zhang;Pavan Balaji	2015	2015 15th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing	10.1109/CCGrid.2015.131	multi-core processor;uniform memory access;distributed shared memory;shared memory;computer architecture;parallel computing;real-time computing;distributed memory;computer science;resource management;operating system;data diffusion machine	Arch	-8.47083786988662	48.15593930634338	17568
7625779b4d12ae303c8a06a404ead75c1342b493	quest-v: a virtualized multikernel for high-confidence systems	organization and design;reliability;virtualization;multicore;design;technical report;fault isolation and recovery;operating systems	This paper outlines the design of ‘Quest-V’, which is implemented as a collection of separate kernels operating together as a distributed system on a chip. Quest-V uses virtualization techniques to isolate kernels and prevent local faults from affecting remote kernels. This leads to a high-confidence multikernel approach, where failures of system subcomponents do not render the entire system inoperable. A virtual machine monitor for each kernel keeps track of shadow page table mappings that control immutable memory access capabilities. This ensures a level of security and fault tolerance in situations where a service in one kernel fails, or is corrupted by a malicious attack. Communication is supported between kernels using shared memory regions for message passing. Similarly, device driver data structures are shareable between kernels to avoid the need for complex I/O virtualization, or communication with a dedicated kernel responsible for I/O. In Quest-V, device interrupts are delivered directly to a kernel, rather than via a monitor that determines the destination. Apart from bootstrapping each kernel, handling faults and managing shadow page tables, the monitors are not needed. This differs from conventional virtual machine systems in which a central monitor, or hypervisor, is responsible for scheduling and management of host resources amongst a set of guest kernels. In this paper we show how Quest-V can implement novel fault isolation and recovery techniques that are not possible with conventional systems. We also show how the costs of using virtualization for isolation of system services does not add undue overheads to the overall system performance.	booting;component-based software engineering;computer data storage;data structure;device driver;distributed computing;electrical connection;experiment;fault detection and isolation;fault tolerance;hardware performance counter;hardware virtualization;hypervisor;immutable object;input/output;interrupt;kernel (operating system);library (computing);linux;message passing;multi-core processor;multikernel;network packet;networking hardware;non-uniform memory access;operability;page table;real-time clock;reboot (computing);rich internet application;sandbox (computer security);scheduling (computing);shared memory;software verification;state (computer science);system integrity;system on a chip;systems design;virtual machine;x86 virtualization	Ye Li;Matthew Danish;Richard West	2011	CoRR		embedded system;design;real-time computing;virtualization;computer science;technical report;operating system;reliability;kernel preemption	OS	-24.409077366391195	51.03172564600037	17572
f50579f43affd90677c1647a169cfe0f10c7c00f	performance evaluation tools for parallel and distributed systems	performance evaluation tools			Cherri M. Pancake;Margaret L. Simmons;Jerry C. Yan	1995	IEEE Computer	10.1109/MC.1995.10120	distributed algorithm;computer science;distributed computing;distributed design patterns	Visualization	-29.26012427767167	46.75936486982643	17586
a44506e8a0553da6a67462f23986be88c77b36e3	dissemination of state information in distributed autonomous systems	parallel and distributed system;distributed system;formal model;autonomy;autonomic system;heterogeneous distributed system;information exchange;parallel and distributed systems;task scheduling;state dissemination	Many researchers are devising algorithms for task placement in distributed systems, but few are designing the necessary mechanisms to provide the information required by those algorithms. Fundamental to these mechanisms is an accurate means for information exchange between distributed systems. The messiahs project investigated the construction of a set of mechanisms to support task placement in autonomous, heterogeneous, distributed systems. In this paper we describe the semantics of the protocols used to exchange system state information within messiahs, and develop formal models to prove that the protocols accurately propagate system description information throughout the system.	algorithm;autonomous robot;autonomous system (internet);correctness (computer science);directed acyclic graph;distributed computing;information exchange;scheduling (computing);tree (data structure)	Steve J. Chapin;Eugene H. Spafford	1998	Computer Communications	10.1016/S0140-3664(98)00168-6	distributed algorithm;real-time computing;global information system;information exchange;failure semantics;computer science;theoretical computer science;distributed computing;autonomy;distributed design patterns	HPC	-25.55157721037574	44.55732935969095	17596
2b262c12327fa0d7cc89ddfa3f6b93d2d6e189b9	synchronized queueing networks: concepts, examples and evaluation techniques	queueing network	Synchronized queueing networks (SQN) are a new type of models, which allow the analysis of queueing systems subject to synchronization constraints. SQN-models originate from traditional queueing networks which have been enlarged by a new type of nodes. These nodes, called counters, can be viewed as synchronization primitives, which are used by the tasks moving through the network. Due to this combination of synchronization and queueing features SQN-models are a new approach towards the unified representation of areas which have been studied separately for a long time.		Bruno Müller-Clostermann;Günter Rosentreter	1987		10.1007/978-3-642-73016-0_12	g-network;real-time computing;computer science;theoretical computer science;layered queueing network;distributed computing	Metrics	-23.522795531846313	42.001270384944846	17628
fa31abc14ad8a895f52a7e521178d9e669dfe2dc	lowering the barrier to online malware detection through low frequency sampling of hpcs		As mobile phones become more ubiquitous in our daily lives, many malware creators have shifted their focus to these mobile platforms. While a plethora of work exists to try and detect malware as it is uploaded to app stores and when it is downloaded to user devices, malware still slips through. A lesser body of work has suggested that Hardware Performance Counters (HPCs) can provide an insight into detecting malware as it runs. While these works have been successful, they typically require thread-level sampling rates every tens of thousands of instructions and hundreds of KB/s to MB/s of bus bandwidth, resulting in high power overhead in battery constrained mobile devices. Unlike previous works, this paper proposes a coarser grained approach, requiring system-wide sampling rates in the hundreds of Hz and less than 10 KB/s of bandwidth, all while achieving similar accuracy to previous works and identification of zero-day attacks. The proposed method focuses purely on background detection, that is, detection of malware when its parent application is inactive. This technique relies upon a multi-layer neural network to extract the higher order dependencies between different HPCs as processes are executed on multiple cores. Experiments are conducted on a Motorola G4 platform, and classifiers are trained with multiple families of malware and a multitude of clean system states.	artificial neural network;data rate units;hardware performance counter;high-level programming language;kilobyte;layer (electronics);malware;mike lesser;mobile device;mobile phone;overhead (computing);power iteration;powerpc g4;sampling (signal processing);sensor	Patrick Cronin;Chengmo Yang	2018	2018 IEEE International Symposium on Hardware Oriented Security and Trust (HOST)	10.1109/HST.2018.8383910	real-time computing;sampling (statistics);artificial neural network;malware;computer science;mobile device;multi-core processor;low frequency;upload;bandwidth (signal processing)	Arch	-7.381431397685165	56.09538497338984	17656
18e1767e5533657d897da135a3bb3114498d8fa6	pmu-guided priority adjustment to guarantee thread performance on ibm power smt processor	cpu resource allocation pmu guided priority adjustment thread performance ibm power smt processor simultaneous multithreading superscalar cpu hardware multithreading user application hardware software integrated method thread priority control ibm power processor series monitoring unit;instruction sets hardware message systems monitoring phasor measurement units registers kernel;kernel;multi threading;monitoring;registers;message systems;multi threading microprocessor chips;phasor measurement units;microprocessor chips;instruction sets;hardware	Simultaneous-multithreading (SMT) is widely used to improve the overall efficiency of superscalar CPUs with hardware multi-threading. With SMT processors, it is challenging to guarantee the performance of each individual thread because resources are shared across the threads. In this paper, we study the scenario where user applications need to guarantee a certain level of performance for a primary thread. We present a hardware-software integrated method to control thread priority to achieve this objective. This method combines hardware thread priority control (which is currently available on IBM POWER processor series) and performance monitoring unit, and dynamically adjusts CPU resource allocations according to current thread workloads. Effectiveness of the proposed method is demonstrated through extensive experimental results.	central processing unit;code;https;ibm power microprocessors;library (computing);linux;multithreading (computer architecture);portland pattern repository;power management unit;real-time computing;real-time transcription;simultaneous multithreading;superscalar processor;thread (computing)	Zhengyu He;Bo Hong	2012	2012 IEEE 26th International Parallel and Distributed Processing Symposium Workshops & PhD Forum	10.1109/IPDPSW.2012.205	computer architecture;parallel computing;kernel;real-time computing;multithreading;computer science;operating system;instruction set;processor register;super-threading	Arch	-4.705795761927977	53.199682833597116	17691
a028915c9e875a64d4c78bdfa4096b8e0357b83c	laminar unsteady navier-stokes flow on multicore and gpu architectures			graphics processing unit;multi-core processor;navier–stokes equations	Bahareh Mostafazadeh Davani	2016				Arch	-6.3987957151870125	38.250786590328254	17693
3b3b5a43f5674f7e9c10dca8411a7da2473c614a	application on cloud computing in the future library	cloud computing libraries peer to peer computing computational modeling government servers;dynamic nodes data future library virtual node model cloud computing library virtualization data service similar node cluster data;computer network;virtual node;virtualisation cloud computing library automation;clustered data;library;virtualisation;library automation;cloud computing;virtual node cloud computing library	Cloud computing would be a developing tendency for computing network in the future, which had been widely used in many fields. Combing with the domestic and foreign relevant research and based on current situation of the library, virtual node model of cloud computing library was established in this study, then one method of realizing virtualization data service was discussed and virtual node of similar node cluster data was introduced, which would been more reaonalble distribution between dynamic nodes data. In the end, the changing of service mode of future library on cloude computing would be discussed.	cloud computing	Li Gao;Yinghui Zhao	2011	2011 IEEE International Conference on Cloud Computing and Intelligence Systems	10.1109/CCIS.2011.6045055	library;cloud computing;computer science;operating system;cloud testing;distributed computing;utility computing;world wide web;grid computing	HPC	-28.61533853252322	54.56529684032731	17700
21ea70bcd14a5c2172f81348c610607680da3049	design and test of the rt-nke task scheduling algorithm for multicore architectures		This paper presents the design and testing of a partitioned task-scheduling algorithm for the RT-NKE real-time operating system (RTOS). In this implementation, there is a scheduling queue for each core. The rate-monotonic (RM) scheduler already used in the single-core version of RT-NKE runs in each queue. The implementation of the algorithm was validated by porting the RT-NKE code to a BeagleBone board. To guarantee the quality of the test process, unitary tests were created using the GTEST library. As results of the work, we ported RT-NKE to the BeagleBone board and implemented the real-time task scheduling algorithm. Since RT-NKE only runs on single-core architectures, an environment was created that simulates the execution of the algorithm in a multi-core platform with the processor alternating the execution of the tasks in the different scheduling queues.	algorithm;beagleboard;multi-core processor;real-time clock;real-time operating system;scheduling (computing);single-core;windows rt	Renato Severo;Celso Maciel da Costa;Adriane Parraga;Debora Motta;I. L. Muller;Fabian Vargas	2018	2018 IEEE 19th Latin-American Test Symposium (LATS)	10.1109/LATW.2018.8349682	porting;parallel computing;scheduling (computing);real-time operating system;queue;multi-core processor;computer science	Embedded	-9.006890008689817	58.75219817999693	17707
118391e04c7552c637b84d22f08c6369bd3cd483	crash-only software	iron;software systems;embedded system;large scale;operating system;internet services;predictive coding;occam s razor	Crash-only programs crash safely and recover quickly. There is only one way to stop such software—by crashing it—and only one way to bring it up—by initiating recovery. Crash-only systems are built from crash-only components, and the use of transparent component-level retries hides intra-system component crashes from end users. In this paper we advocate a crash-only design for Internet systems, showing that it can lead to more reliable, predictable code and faster, more effective recovery. We present ideas on how to build such crash-only Internet services, taking successful techniques to their logical extreme. 1. Occam’s Razor and the Restart Potpourri There are many reasons to restart software, and many ways to do it. Studies have shown that a main source of downtime in large scale software systems is caused by intermittent or transient bugs [12, 20, 19, 1]. Most nonembedded systems have a variety of ways to stop; for example, an operating system can shut down cleanly, panic, hang, crash, lose power, etc. When shutting down programs cleanly, unavailability consists of the time to shut down and the time to come back up; when crash-rebooting, unavailability consists only of the time to recover. Ironically, shutting down and reinitializing can sometimes take longer than recovering from a crash. Table 1 illustrates a casual comparison of reboot times; no important data was lost in either of the experiments. System Clean reboot Crash reboot RedHat 8 (with ext3fs) 104 sec 75 sec JBoss 3.0 application server 47 sec 39 sec Windows XP 61 sec 48 sec Table 1. Duration of clean vs. crash reboots. It is impractical to build a system that is guaranteed to never crash, even in the case of carrier class phone switches or high end mainframe systems. Since crashes are unavoidable, software must be at least as well prepared for a crash as it is for a clean shutdown. But then—in the spirit of Occam’s Razor—if software is crash-safe, why support additional, non-crash mechanisms for shutting down? A frequent reason is the desire for higher performance. For example, to avoid slow synchronous disk writes, many UNIX file systems cache metadata updates in memory. As a result, when a UNIX workstation crashes, the file system reaches an inconsistent state that takes a lengthy fsck to repair, an inconvenience that could have been avoided by shutting down cleanly. This captures the design tradeoff that improves steady state performance at the expense of shutdown and recovery performance. In the face of inevitable crashes, such a file system turns out to be brittle: a crash can lose data and, in some cases, the post-crash inconsistency cannot even be repaired. Not only do such performance tradeoffs impact robustness, but they also lead to complexity by introducing multiple ways to manipulate state, more code, and more APIs. The code becomes harder to maintain and offers the potential for more bugs—a fine tradeoff, if the goal is to build fast systems, but a bad idea if the goal is to build highly available systems. If the cost of such performance enhancements is dependability, perhaps it’s time to reevaluate our design strategy. In earlier work, we used recursive microreboots to improve the availability of a soft-state system that was trivially crash-safe [3]. In this paper we advocate a crash-only design (i.e., crash safety + fast recovery) for Internet systems, a class distinguished by the following properties: large scale, stringent high availability requirements, built from many heterogenous components, accessed over standard requestreply protocols such as HTTP, serving workloads that consist of large numbers of relatively short tasks that frame state updates, and subjected to rapid and perpetual evolution. We restrict our attention to single installations that reside inside one data center and do not span administrative domains. In high level terms, a crash-only system is defined by the equations stop=crash and start=recover. In the rest of the paper, we describe the benefits of the crash-only design approach by analogy to physics, describe the internal properties of components in a crash-only system, the architectural properties governing the interaction of components, and a restart/retry architecture that exploits crash-only design, including our work to date on a prototype using J2EE. 2. Why Crash-Only Design ? Mature engineering disciplines rely on macroscopic descriptive physical laws to build and understand the behavior of physical systems. These sets of laws, such as Newtonian mechanics, capture in simple form an observed physical invariant. Software, however, is an abstraction with no	application server;backup;carrier grade;crash (computing);crash-only software;data center;dependability;downtime;experiment;fault model;high availability;high-level programming language;hypertext transfer protocol;invariant (computer science);java platform, enterprise edition;mainframe computer;microsoft windows;network switch;occam's razor;operating system;prototype;quantum number;reboot (computing);recursion;requirement;retry;server (computing);shutdown (computing);soft state;software bug;software system;steady state;unavailability;unix;wildfly;workstation;occam	George Candea;Armando Fox	2003			real-time computing;simulation;computer science;operating system;iron;computer security	OS	-23.053773522147583	50.547314833063226	17767
141c326abe74de317587ff6cc1571074ce7db7ee	parallel genetic algorithms: advances, computing trends, applications and perspectives	parallel computing;stress;parallel genetic algorithm;topology;data parallel;operating systems computers genetic algorithms parallel algorithms parallel architectures parallel programming;parallel algorithm;concurrent computing;programming paradigm;computer model;data parallelism;parallel programming;computer architectures;genetic algorithms computer applications concurrent computing parallel processing classification algorithms machinery stress computer architecture topology operating systems;genetics;computer applications;parallel libraries;computer architecture;parallel architectures;operating system;parallel systems;classification algorithms;parallel computer;parallel genetic algorithms;genetic algorithm;genetic algorithms;control parallelism;machinery;operating systems computers;parallel processing;parallel libraries parallel genetic algorithms data parallelism control parallelism parallel computing computer architectures operating systems;operating systems;parallel algorithms	Summary form only given. This article gives a brief overview of theoretical advances, computing trends, applications and future perspectives in parallel genetic algorithms. It explains basic terms and behavior of (parallel) genetic algorithms. Genetic algorithms are easily parallelized algorithms, therefore two kinds of possible parallelism, data parallelism and control parallelism, are mentioned and described towards them. Parallelism of genetic algorithms brings many advantages and gains. Classifications of these algorithms are often based on the type of computing model, a walk strategy and the used computing machinery. Afterwards significant milestones in the theory with latest advances are briefly mentioned. Then current trends in parallel computing with stress computer architectures of parallel systems, interconnection topologies, operating systems, parallel (genetic) libraries and programming paradigms are reviewed shortly. The sufficient space is devoted to the latest applications of parallel genetic algorithms. After the discussion section, perspectives of the algorithms are predicted till the year 2005. The information in the article is segregated into two periods before and after the year 2000 in all chapters. The second period is more interesting and of higher importance, because it highlights recent research efforts and gives some hints about possible future trends. That is why we devote much space to the second period. As there is no such an overview of the recent period of parallel genetic algorithms, our investigation could be appealing and useful in many aspects.	computer architecture;data parallelism;genetic algorithm;interconnection;library (computing);operating system;parallel computing;programming paradigm;task parallelism	Zdenek Konfrst	2004	18th International Parallel and Distributed Processing Symposium, 2004. Proceedings.	10.1109/IPDPS.2004.1303155	parallel processing;parallel computing;genetic algorithm;concurrent computing;computer science;theoretical computer science;distributed computing;parallel algorithm	HPC	-9.237551281820256	40.69607539252675	17790
3442633cbb946fb9e1dc12548d830bd17c16b33d	2-phase protocol: enhancing write performance in cooperative cache for pvfs			parallel virtual file system	In-Chul Hwang;Hanjo Jung;Seung Ryoul Maeng;Jung Wan Cho	2005			parallel computing;cache;smart cache;computer science	HPC	-12.67963708437671	50.044597999009994	17792
d40398f18f3e49d22e1196990950d86647811e3e	dracon: qos management for large-scale distributed real-time databases	quality of service;control structure;real time data;data replication;coupled cluster;feedback control;real time;electric power;decentralized control	The demand for real-time data services is increasing in many large-scale distributed real-time applications including advanced traffic control, global environment control, and the nation-wide electric power grid control. However, providing quality-of-service (QoS) for data services in such large-scale and geographically distributed environment is a challenging task. In particular, both unpredictable communicational delays and computational workloads of large-scale distributed systems can lead to large number of deadline misses. We have designed a distributed real-time database architecture called DRACON (Decentralized data Replication And CONtrol), which enables QoS guarantees for large-scale distributed real-time applications. DRACON couples cluster-based replica-sharing and a decentralized control structure to address communication and computational unpredictability, simultaneously. The cluster-based replica-sharing mechanism not only enables scalable and bounded-delay access to remote data with high probability, but also decouples clusters to have less interaction, allowing a decentralized, thus scalable, QoS control structure. The simulation study demonstrates that DRACON’s decentralized QoS control structure combined with a decentralized replica-sharing structure provides robust and predictable QoS guarantees in a highly scalable manner.	algorithm;baseline (configuration management);control flow;coupling (computer programming);database;distributed computing;distributed control system;global variable;interaction;quality of service;real-time clock;real-time data;real-time locating system;real-time transcription;replication (computing);scalability;simulation;with high probability	Woochul Kang;Sang Hyuk Son;John A. Stankovic	2009	JSW		coupled cluster;real-time data;real-time computing;electric power;quality of service;decentralised system;computer science;artificial intelligence;feedback;distributed computing;programming language;control flow;replication;computer network	Embedded	-25.68022801469459	52.660565377847064	17817
20832b00a105f2bef2f80d226b844ec7bae130f8	gpu array access auto-tuning		Graphics Processing Units (GPUs) have been used for years in compute intensive applications. Their massive parallel processing capabilities can speedup calculations significantly. However, to leverage this speedup it is necessary to rethink and develop new algorithms that allow parallel processing. These algorithms are only one piece to achieve high performance. Nearly as important as suitable algorithms is the actual implementation and the usage of special hardware features such as intra-warp communication, shared memory, caches, and memory access patterns. Optimizing these factors is usually a time consuming task that requires deep understanding of the algorithms and the underlying hardware. Unlike Central Processing Units (CPUs), the internal structure of GPUs has changed significantly and will likely change even more over the years. Therefore it does not suffice to optimize the code once during the development, but it has to be optimized for each new GPU generation that is released. To efficiently (re-)optimize code towards the underlying hardware, auto-tuning tools have been developed that perform these optimizations automatically, taking this burden from the programmer. In particular, NVIDIA – the leading manufacturer for GPUs today – applied significant changes to the memory hierarchy over the last four hardware generations. This makes the memory hierarchy an attractive objective for an auto-tuner. In this thesis we introduce the MATOG auto-tuner that automatically optimizes array access for NVIDIA CUDA applications. In order to achieve these optimizations, MATOG has to analyze the application to determine optimal parameter values. The analysis relies on empirical profiling combined with a prediction method and a data post-processing step. This allows to find nearly optimal parameter values in a minimal amount of time. Further, MATOG is able to automatically detect varying application workloads and can apply different optimization parameter settings at runtime. To show MATOG’s capabilities, we evaluated it on a variety of different applications, ranging from simple algorithms up to complex applications on the last four hardware generations, with a total of 14 GPUs. MATOG is able to achieve equal or even better performance than hand-optimized code. Further, it is able to provide performance portability across different GPU types (low-, mid-, high-end and HPC) and generations. In some cases it is able to exceed the performance of hand-crafted code that has been specifically optimized for the tested GPU by dynamically changing data layouts throughout the execution. III	algorithm;cpu cache;cuda;central processing unit;graphics processing unit;mathematical optimization;memory hierarchy;optimizing compiler;parallel computing;pitch correction;programmer;run time (program lifecycle phase);self-tuning;shared memory;software portability;speedup;tv tuner card;video post-processing	Nicolas Weber	2017			massively parallel;parallel computing;speedup;profiling (computer programming);software portability;memory hierarchy;programmer;cuda;shared memory;computer science	HPC	-4.945717376125193	45.316763765671354	17899
72a19fb376c3ef2028307709cbf0cf97c74dab6a	sealing os processes to improve dependability and safety	modelizacion;dynamique processus;sistema operativo;seguridad funcionamiento;evaluation performance;carga dinamica;surete fonctionnement;singularite;shared memory;performance evaluation;securite;redundancia;competitividad;memoria compartida;generation code;evaluacion prestacion;codigo tiempo;generacion codigo;code generation;run time code generation;time sharing;abstraction;interface programme application;systeme ouvert;program verification;dinamica proceso;charge dynamique;abstraccion;dynamic load;software engineering;analisis programa;software isolated process sip;sealed kernel;modelisation;verificacion programa;shared memory systems;redundancy;tiempo dividido;operating system;code temps;application program interfaces;dependability;sealed process architecture;safety;singularidad;competitiveness;genie logiciel;systeme exploitation;temps partage;program analysis;open process architecture;analyse programme;verification programme;open systems;sistema abierto;process dynamics;competitivite;seguridad;modeling;ingenieria informatica;time code;static program analysis;systeme memoire partagee;redondance;memoire partagee;dynamic code generation;singularity	In most modern operating systems, a process is a hardware-protected abstraction for isolating code and data. This protection, however, is selective. Many common mechanisms---dynamic code loading, run-time code generation, shared memory, and intrusive system APIs---make the barrier between processes very permeable. This paper argues that this traditional open process architecture exacerbates the dependability and security weaknesses of modern systems.  As a remedy, this paper proposes a sealed process architecture, which prohibits dynamic code loading, self-modifying code, shared memory, and limits the scope of the process API. This paper describes the implementation of the sealed process architecture in the Singularity operating system, discusses its merits and drawbacks, and evaluates its effectiveness. Some benefits of this sealed process architecture are: improved program analysis by tools, stronger security and safety guarantees, elimination of redundant overlaps between the OS and language runtimes, and improved software engineering.  Conventional wisdom says open processes are required for performance; our experience suggests otherwise. We present the first macrobenchmarks for a sealed-process operating system and applications. The benchmarks show that an experimental sealed-process system can achieve performance competitive with highly-tuned, commercial, open-process systems.	application programming interface;code generation (compiler);dependability;modern operating systems;operating system;process architecture;program analysis;record sealing;runtime system;self-modifying code;shared memory;singularity project;software engineering;the singularity	Galen C. Hunt;Mark Aiken;Manuel Fähndrich;Chris Hawblitzel;Orion Hodson;James R. Larus;Steven Levi;Bjarne Steensgaard;David Tarditi;Ted Wobber	2007		10.1145/1272996.1273032	program analysis;shared memory;embedded system;singularity;real-time computing;systems modeling;dynamic load testing;computer science;operating system;dependability;abstraction;redundancy;open system;programming language;time-sharing;code generation;static program analysis	OS	-21.094456896698254	34.09392231091953	17911
d7440ffe78e2ba9c61ca621d6a37e40e30b5b446	evolutionary migration of legacy systems to an object-based distributed environment	distributed system;electrical capacitance tomography;object oriented methods;object based distributed environment;application software;software maintenance;semiautomatic evolutionary migration methodology;object oriented component based distributed systems;isa;distributed computing;software systems;maintenance cost;client server systems;software engineering;legacy system migration;middleware technologies legacy system migration object based distributed environment software evolution software development paradigms object oriented component based distributed systems semiautomatic evolutionary migration methodology isa data cohesive hierarchical subsystem decomposition;data cohesive hierarchical subsystem decomposition;design recovery;software evolution;distributed environment;object oriented;software development;software development paradigms;costs electrical capacitance tomography instruction sets middleware computer science distributed computing application software hardware programming documentation;next generation;middleware;computer science;legacy system;programming;documentation;middleware technologies;object oriented paradigm;instruction sets;client server systems systems re engineering software maintenance object oriented methods;hardware;systems re engineering	There is an increasing interest in migrating legacy systems to new hardware platforms and to new software development paradigms. High maintenance costs and lack of documentation are among the challenges facing software engineers who wish to migrate such systems. The increasing emphasis on distributed systems and on the object-oriented paradigm suggests that object-oriented, component-based, distributed systems will represent a significant portion of the next generation of software systems. We present a semiautomatic, evolutionary migration methodology for legacy systems which produces an object-based distributed system. We use ISA which is a design recovery and subsystem classification technique that produces a data-cohesive hierarchical subsystem decomposition of the subject system. We adapt the subsystems to the object-oriented paradigm. We wrap and define interfaces of the subsystems in order to define components. Components are allocated to multiple sites. Finally, middleware technologies for distributed systems are used to implement the communication between components. The approach is suitable for the evolutionary migration of legacy systems since each component can be reengineered separately.	algorithm;component-based software engineering;distributed computing;documentation;heuristic (computer science);legacy system;mathematical optimization;memory management;middleware;object-based language;programming paradigm;software development;software engineer;software system;undocumented feature;wrapping (graphics)	Miguel A. Serrano;Carlos Montes de Oca;Doris L. Carver	1999		10.1109/ICSM.1999.792579	programming;software modernization;application software;real-time computing;documentation;computer science;software evolution;software development;operating system;software engineering;middleware;database;distributed computing;programming language;software maintenance;legacy system	SE	-33.522133556667704	44.11426382075662	17932
1ebed6d592ca38bc90d1588cf5eff54ad9fd54e6	experiments with a transputer-based parallel graph reduction machine	transputer-based parallel graph reduction	This paper is concerned with the implementation of functional languages on a parallel architecture, using graph reduction as a model of computation. Parallelism in such systems is automatically derived by the compiler but a major problem is the fine granularity, illustrated in Divide-and-Conquer problems at the leaves of the computational tree. The paper addresses this issue and proposes a method based on static analysis combined with run-time tests to remove the excess in parallelism. We report experiments on a prototype machine, simulated on several connected INMOS transputers. Performance figures show the benefits in adopting the method and the difficulty of automatically deriving the optimum partitioning due to differences among the problems.	compiler;experiment;functional programming;graph reduction machine;model of computation;offset binary;parallel computing;prototype;static program analysis;transputer	Fethi A. Rabhi;Gordon A. Manson	1991	Concurrency - Practice and Experience	10.1002/cpe.4330030417	computer architecture;parallel computing;distributed computing	PL	-14.415693169777025	38.616442011757584	17956
7602174a560de2e1b32ebe0eb125945b0983dd13	a comparative study on peer-to-peer failure rate estimation	distributed system;sample size;failure frequency based methods;estimation method;peer to peer systems;peer to peer computing robustness routing large scale systems scalability delay costs checkpointing computer science software engineering;peer to peer system;maximum likelihood estimation;large scale;system recovery;system recovery maximum likelihood estimation peer to peer computing;comparative study;failure rate;peer to peer computing;distributed systems;failure frequency based methods peer to peer failure rate estimation peer to peer systems distributed systems maximum likelihood method;peer to peer;maximum likelihood method;peer to peer failure rate estimation	The robustness of Peer-to-Peer systems is challenged by its highly dynamic nature. Frequent peer failure and departure events introduce uncertainty for which is considered exceptional in traditional distributed systems. The difficulty of monitoring such large scale networks is further exacerbated because it has to be done in a completely decentralized way for both scalability and reliability concerns. Some methods for estimating peer failure rate have been applied in Peer-to-Peer systems, however their comparative performance has not yet been reported in the literature. We simulate three different failure rate estimation methods and compare their accuracy and response time with respect to sample size, stabilization interval and neighbour set size. We conclude that the Maximum Likelihood Method introduced is better than the Failure Frequency based Methods commonly used in current Peer-to-Peer systems.	distributed computing;failure rate;parallel computing;process migration;response time (technology);scalability;simulation;social peer-to-peer processes;throughput;transaction processing system	Lei Ni;Aaron Harwood	2007	2007 International Conference on Parallel and Distributed Systems	10.1109/ICPADS.2007.4447815	real-time computing;computer science;theoretical computer science;distributed computing;maximum likelihood;statistics	HPC	-21.499149806659794	46.444110340211445	17969
15a3bb55c5838e10e68a98fdf4d5effc0c920738	system modeling and multicore simulation using transactions	multicore machine system modeling multicore simulation digital systems net introspection parallel simulation environment systemc communication channels module channels scheduling algorithms;synchronization semantics multicore processing scheduling algorithms complexity theory system on a chip programming;multiprocessing systems;parallel processing multiprocessing systems;parallel processing	With the increasing complexity of digital systems that are becoming more and more parallel, a better abstraction to describe such systems has become a necessity. This paper shows how, by using the powerful mechanism of transactions as a concurrency model, and by taking advantage of .NET introspection and attribute programming capabilities, we were able to develop a system-level modeling and parallel simulation environment. We kept the same concepts to describe the architecture of high-level models, such as modules and communication channels. However, unlike SystemC, the behaviour is no longer described as processes and events but as transactions. We implemented scheduling algorithms in order to enable simulating a transactional models in parallel by taking advantage of a multicore machine. These algorithms take into account the dependency between transactions and the number of cores of the simulation machine. We studied two synchronisation strategies: one using locking and the other using partitioning. An experiment made on a WiFi 802.11a transmitter achieved a speedup of about 1.9 using two threads. With 8 threads, although the workload of individual transactions was not significant, we could reach a 5.1 speedup. When the workload is significant the speedup can reach 6.3.	algorithm;assertion (software development);atomicity (database systems);concurrency (computer science);concurrent computing;digital electronics;formal verification;high- and low-level;high-level synthesis;introspection;lock (computer science);model checking;multi-core processor;natural deduction;principle of abstraction;programming paradigm;proof assistant;property specification language;refinement (computing);scheduling (computing);semantics (computer science);semiconductor industry;simulation;speedup;systemc;transmitter	Amine Anane;El Mostapha Aboulhamid;Yvon Savaria	2012	2012 International Conference on Embedded Computer Systems (SAMOS)	10.1109/SAMOS.2012.6404156	parallel computing;real-time computing;computer science;distributed computing	EDA	-15.679231152994047	38.96796179593129	17976
543c6ce5ca476d9c813a4e58c6a3450d3b556bf0	hoard: a scalable memory allocator for multithreaded applications	storage allocation;scientific application;programa paralelo;organization;evaluation performance;shared memory;performance evaluation;red www;multiprocessor;multiprocessor systems;gollete estrangulamiento;infinite medium;memoria compartida;evaluacion prestacion;database management;aplicacion cientifica;synchronisation;goulot etranglement;internet;synchronization;milieu infini;world wide web;application scientifique;reseau www;sincronizacion;systeme gestion base donnee;memory allocation;allocation memoire;multiprocesador;medio infinito;asignacion memoria;sistema gestion base datos;organisation;organizacion;database management system;bottleneck;parallel program;memoire partagee;programme parallele;multiprocesseur	Parallel, multithreaded C and C++ programs such as web servers, database managers, news servers, and scientific applications are becoming increasingly prevalent. For these applications, the memory allocator is often a bottleneck that severely limits program performance and scalability on multiprocessor systems. Previous allocators suffer from problems that include poor performance and scalability, and heap organizations that introduce false sharing. Worse, many allocators exhibit a dramatic increase in memory consumption when confronted with a producer-consumer pattern of object allocation and freeing. This increase in memory consumption can range from a factor of  P  (the number of processors) to unbounded memory consumption.This paper introduces Hoard, a fast, highly scalable allocator that largely avoids false sharing and is memory efficient. Hoard is the first allocator to simultaneously solve the above problems. Hoard combines one global heap and per-processor heaps with a novel discipline that provably bounds memory consumption and has very low synchronization costs in the common case. Our results on eleven programs demonstrate that Hoard yields low average fragmentation and improves overall program performance over the standard Solaris allocator by up to a factor of 60 on 14 processors, and up to a factor of 18 over the next best allocator we tested.	hoard;slab allocation;thread (computing)	Emery D. Berger;Kathryn S. McKinley;Robert D. Blumofe;Paul R. Wilson	2000		10.1145/356989.357000	synchronization;parallel computing;real-time computing;computer science;organization;operating system;distributed computing	Arch	-16.135599380134536	44.55076397580893	18018
5c546617617c7d484c9661ea02875bc513f3d66a	static global scheduling for optimal computer vision and image processing operations on distributed-memory multiprocessors	distributed memory;computer vision and image processing	In this paper, we develop a static global scheduling scheme for mapping computer vision and image processing (CVIP) operations on distributed-memory multiprocessors. Unlike most current parallel image processing research which focuses on parallelizing individual processing algorithms on a particular parallel architecture, our scheduler is for optimizing processor assignment and data partition for an entire image processing pipeline. The scheduler operates on task graphs speciied by conventional visual languages such as Khoros and Explorer. A task graph is assumed to be a linear chain of operations with any number of nested loops. The task chain is rst decomposed into simpler subchains; each a linear sequence of tasks without loops. The communication and computation costs of the component tasks in the subchains are determined by a taxon-omy of CVIP operations. Data redistribution overheads in between tasks can also be tabulated in advance for many popular data partitioning schemes. The scheduler then employs a shortest path algorithm to optimize the parallel time, taking into consideration possible variation in the task and resource parameters (such as the image size and number of processors used), and both the intra-operation and the inter-operation computation and communication times. In this paper, we present the scheduling scheme, and provide analyses and experimental results to verify our approach.	central processing unit;computation;computer vision;dijkstra's algorithm;distributed memory;image processing;image resolution;parallel computing;schedule (project management);scheduling (computing);shortest path problem	Cheolwhan Lee;Yuan-Fang Wang;Tao Yang	1995		10.1007/3-540-60268-2_403	parallel computing;real-time computing;distributed memory;computer science;machine learning;distributed computing	HPC	-8.693620475552098	46.98733271987333	18052
f7432bdfe6b22b5159d9ef1ebab4f88fdb1607d3	adaptive cache compression for non-volatile memories in embedded system	write endurance;non volatile memories;dynamic energy;cache compression	Cache compression has been studied to increase the effective cache size by storing the cache blocks in a compressed form in the cache. However, it also generates additional write operations during the compressing and compacting of cache blocks. Since increasing the write operations leads to a surging of dynamic energy consumption and a shortening of the lifetime of the cache in the Non-Volatile Memory (NVM) based Last-Level Cache (LLC), it is needed to balance the extra write operations against the performance improvement. In this paper, we identify that cache compression is not always efficient for NVM-based LLC. In light of the analysis, we propose Adaptive Cache Compression for NVM (ACCNVM) whose cache block is only compressed when cache compression is efficient. The result shows that our proposal achieves a 16.4% energy savings and a 19.1% lifetime extension with respect to the cache, which uses a state-of-the-art cache compression scheme.	cpu cache;embedded system;non-volatile memory;volatile memory	Ju Hee Choi;Jong Wook Kwak;Seong Tae Jhang;Chu Shik Jhon	2014		10.1145/2663761.2663764	bus sniffing;least frequently used;pipeline burst cache;cache-oblivious algorithm;snoopy cache;parallel computing;real-time computing;cache coloring;page cache;cpu cache;computer hardware;cache;computer science;write-once;cache invalidation;write buffer;smart cache;mesi protocol;cache algorithms;cache pollution;mesif protocol	Arch	-10.096883829865893	54.4189042816176	18075
940103eec8ae05022e1e14dd061d225a0edca36b	full configuration interaction algorithm on a massively parallel architecture: direct-list implementation	full configuration interaction;parallel computation;message passing		algorithm;full configuration interaction;parallel computing	Elda Rossi;Gian Luigi Bendazzoli;Stefano Evangelisti	1998	Journal of Computational Chemistry	10.1002/(SICI)1096-987X(19980430)19:6%3C658::AID-JCC7%3E3.0.CO;2-Q		HPC	-9.852904302365898	42.193702046873014	18079
b9a3d5dc5d0d54b00e5f31a82bb2e4950bd8fb35	towards practical incremental recomputation for scientists: an implementation for the python language	initial run;code edit;execution time;python language;subsequent run;towards practical incremental recomputation;maintainable code;high-level language;computational scientist;enhanced interpreter;python interpreter;extra code	Computational scientists often prototype data analysis scripts using high-level languages like Python. To speed up execution times, they manually refactor their scripts into stages (separate functions) and write extra code to save intermediate results to disk in order to avoid recomputing them in subsequent runs. To eliminate this burden, we enhanced the Python interpreter to automatically memoize (save) the results of long-running function executions to disk, manage dependencies between code edits and saved results, and re-use memoized results rather than re-executing those functions when guaranteed safe to do so. There is a ∼20% run-time slowdown during the initial run, but subsequent runs can speed up by several orders of magnitude. Using our enhanced interpreter, scientists can write simple and maintainable code that also runs fast after minor edits, without having to learn any new programming languages or constructs.	code refactoring;computation;high- and low-level;memoization;programming language;prototype;python	Philip J. Guo;Dawson R. Engler	2010			parallel computing;computer science;theoretical computer science;programming language	OS	-18.941294730344648	33.747916340583	18120
fce552c3c61cf69f213ae9dd9d7dab4d1dcf1432	fault tolerance in p2p-grid environments	software fault tolerance checkpointing grid computing peer to peer computing;detection algorithms;failure detection;peer to peer computing checkpointing fault tolerance fault tolerant systems detection algorithms computational modeling;software fault tolerance;checkpointing;computational modeling;failure recovery p2p grid fault tolerance failure detection;fault tolerant systems;fault tolerance;peer to peer computing;failure recovery;grid computing;p2p grid;high node departure fault tolerance p2p grid environments peer to peer network large scale distributed applications working nodes heterogeneous properties user decision common execution failures failure detection mechanisms checkpointing and recovery architecture fault recovery restart paradigm	P2P-Grid system provides a framework for converging Grid and peer-to-peer network to deploy large-scale distributed applications. However, working nodes with heterogeneous properties can freely join and leave in the middle of their computation. The nodes dynamic participation arbitrarily at any time according to user's decision can keep changing the topology of the network and also causing more common execution failures than in other systems. To this end, failure detection mechanisms and fault tolerance function typically as an integral part of P2P-Grid system have been well-studied. Our research aims to address the highly dynamic nature that arises in P2P-Grid systems by understanding nodes life time statistics in previous research. We are proposing a Check pointing-and-Recovery architecture for applications restarting as soon as possible on P2P-Grid systems. And failure-detection mechanism is a necessary prerequisite to fault tolerance and fault recovery in P2P-Grid system. We also investigate how the design of various failure detection algorithms affects their performance in node average failure detection time. The evaluation shows our check pointing and restart paradigm and failure detection algorithm enables high reliability and performance with high node departure.	algorithm;application checkpointing;computation;distributed computing;executable;fault tolerance;floor and ceiling functions;grid computing;peer-to-peer;programming paradigm	Wang Huan;Nakazato Hidenori	2012	2012 IEEE 26th International Parallel and Distributed Processing Symposium Workshops & PhD Forum	10.1109/IPDPSW.2012.308	fault tolerance;parallel computing;real-time computing;computer science;operating system;distributed computing;computational model;software fault tolerance;grid computing;computer network	HPC	-23.495230667131484	45.49758472282486	18129
bc7c4e6af6b9ad2d5dd7be57cc41b9eb08ccc455	a microservice architecture for the processing of large geospatial data in the cloud		With the growing number of devices that can collect spatiotemporal information, as well as the improving quality of sensors, the geospatial data volume increases constantly. Before the raw collected data can be used, it has to be processed. Currently, expert users are still relying on desktop-based Geographic Information Systems to perform processing workflows. However, the volume of geospatial data and the complexity of processing algorithms exceeds the capacities of their workstations. There is a paradigm shift from desktop solutions towards the Cloud, which offers virtually unlimited storage space and computational power, but developers of processing algorithms often have no background in computer science and hence no expertise in Cloud Computing.rnrnOur research hypothesis is that a microservice architecture and Domain-Specific Languages can be used to orchestrate existing geospatial processing algorithms, and to compose and execute geospatial workflows in a Cloud environment for efficient application development and enhanced stakeholder experience. We present a software architecture that contains extension points for processing algorithms (or microservices), a workflow management component for distributed service orchestration, and a workflow editor based on a Domain-Specific Language. The main aim is to provide both users and developers with the means to leverage the possibilities of the Cloud, without requiring them to have a deep knowledge of distributed computing. In order to conduct our research, we follow the Design Science Research Methodology. We perform an analysis of the problem domain and collect requirements as well as quality attributes for our architecture. To meet our research objectives, we design the architecture and develop approaches to workflow management and workflow modelling. We demonstrate the utility of our solution by applying it to two real-world use cases and evaluate the quality of our architecture based on defined scenarios. Finally, we critically discuss our results.rnrnOur contributions to the scientific community can be classified into three pillars. We present a scalable and modifiable microservice architecture for geospatial processing that supports distributed development and has a high availability. Further, we present novel approaches to service integration and orchestration in the Cloud as well as rule-based and dynamic workflow management without a priori design-time knowledge. For the workflow modelling we create a Domain-Specific Language that is based on a novel language design method.	cloud computing;microservices	Michel Krämer	2018			orchestration (computing);architecture;geospatial analysis;microservices;data mining;scalability;cloud computing;software architecture;workflow;computer science	HPC	-30.765254067403667	51.90264469580815	18134
7da5a47baf4ea5a83f274c4774fc574beb091fce	something old and something new: p-states can borrow microarchitecture techniques too	dynamic microarchitectural power saving;power saving;frequency scaling;turn off;power gating;p states;low power;power management;power reduction;voltage scaling;high performance;performance optimization;dynamic voltage and frequency scaling	The limited utility of voltage scaling in nano-scale technologies has led high-performance processors to rely increasingly on frequency scaling for power management. However, frequency scaling provides only a linear dynamic power reduction.  In this paper, we make a case for dynamically disabling performance optimizations, leveraging previously proposed low-power techniques, for more efficient power-performance trade-offs. By carefully selecting which optimizations to turn off, our lowest P-state consumes less than half the power achieved by frequency scaling, on average, for comparable performance. For all workloads, our approach performs as well or better than DVFS, demonstrating the effectiveness of our approach.	central processing unit;dynamic voltage scaling;frequency scaling;gnu nano;image scaling;low-power broadcasting;microarchitecture;power management	Yasuko Eckert;Srilatha Manne;Michael J. Schulte;David A. Wood	2012		10.1145/2333660.2333748	frequency scaling;electronic engineering;parallel computing;real-time computing;computer science;engineering	Arch	-4.791675870500621	55.55009917779406	18288
1f56659221a3f4902a74b7b76891c27ee8874a40	ecss experience: particle tracing reinvented	hdf5;particle tracing;load balance	This work describes an implementation of distributed particle tracking that provides a factor 10000x speedup over traditional schemes. While none of the techniques used to achieve this result are completely new, they have been used in combination to great effect in this project. The implementation includes parallel IO using HDF5, a flexible load balancing scheme, and dynamic buffering to achieve excellent performance at scale. The use of HDF5 decouples the size of the simulation generating the data from the particle tracing, providing a more flexible and efficient workflow. The load balancing scheme ensures that heterogeneous particle distributions do not result in a waste of computational resources by maintaining all the MPI tasks occupied at any given time. Dynamic buffering minimizes MPI exchanges across MPI tasks, a critical element in the performance improvements achieved.	computational resource;critical graph;hierarchical data format;load balancing (computing);simulation;speedup	Carlos Rosales;Robert T. McLay	2014		10.1145/2616498.2616527	parallel computing;real-time computing;computer science;distributed computing	HPC	-6.6159452826235645	40.943202652409525	18348
de148a2c05c66aa088c6e450e333eb3c647dee3d	analysis of multidimensional dsp specifications	tratamiento paralelo;traitement signal;traitement parallele;data flow graphs;cosic;flot donnee;multidimensional systems digital signal processing data analysis data structures data flow computing parallel processing memory management programming profession parallel machines page description languages;flujo datos;specification language;algorithme;grafo;algorithm;tratamiento numerico;data dependence;signal processing;graph;graphe;functional languages;data flow analysis;functional languages parallel languages data flow analysis signal processing data flow graphs;digital processing;lenguaje especificacion;data flow;procesamiento senal;parallel languages;silage language data flow languages dsp specifications multidimensional arrays data flow analysis techniques very fast running times data dependency checks functional languages data flow graph;langage specification;traitement numerique;parallel processing;algoritmo	Data flow languages are a natural and more formal way to describe the flow of computations in a DSP application. However, when the language contains extended array constructs, extra data dependency checks are needed. This correspondence describes a new model to represent multidimensional arrays and presents several data flow analysis techniques for multidimensional arrays. Results show very fast running times (<1 s) for problems of more than 100 nodes.	computation;data dependency;data-flow analysis;dataflow architecture;digital signal processor	Ingrid Verbauwhede;Chris J. Scheers;Jan M. Rabaey	1996	IEEE Trans. Signal Processing	10.1109/78.553544	data flow diagram;parallel processing;specification language;computer science;theoretical computer science;data-flow analysis;signal processing;graph;programming language;algorithm	Embedded	-15.145579935258606	37.47663923105263	18360
090c777b379185e650684df0effd4bd9d6af5e9b	low-latency memory-mapped i/o for data-intensive applications on fast storage devices	storage management;input output programs;storage management input output programs linux;mapping unmapping page overhead low latency memory mapped input output data intensive application fast storage device flash based ssd low latency device physical memory input output performance virtual memory subsystem linux virtual memory subsystem mmap input output path optimization policy cache hit ratio cache miss;linux	Thesedays, along with read()/write(), mmap() is used to file I/O in data-intensive applications as an alternative method of I/O on emerging low-latency device such as flash-based SSD. Although utilizing memory-mapped file I/O have many advantages, it does not produce much benefit when combined with large-scale data and fast storage devices. When the working set of an application accessing file with mmap() is larger than the size of physical memory, the I/O performance is severely degraded compared to the application with read/write(). This is mainly due to the virtual memory subsystem that does not reflect the performance feature of the underlying storage device. In this paper, we examined linux virtual memory subsystem and mmap() I/O path to figure out the influence of low-latency storage devices on the existing virtual memory subsystem. Also, we suggest some optimization policies to reduce the overheads of mmap() I/O and implement the prototype in a recent Linux kernel. Our solution guarantees that 1) memory-mapped I/O will be several times faster than read-write I/O when cache-hit ratio becomes high, and 2) the former will show at least the performance of the latter even when cache-miss frequently occurs and the overhead of mapping/unmapping pages becomes significant, which are not achievable by the existing virtual memory subsystem.	adobe flash;benchmark (computing);big data;cpu cache;computer data storage;data-intensive computing;expect;forward error correction;hit (internet);input/output;linux;mathematical optimization;memory-mapped i/o;mmap;nosql;overhead (computing);parallel computing;prototype;read-write memory;run time (program lifecycle phase);solid-state drive;synthetic data;thread (computing);vii;working set;write (system call);ycsb	Nae Young Song;Youngjin Yu;Woong Shin;Hyeonsang Eom;Heon Young Yeom	2012	2012 SC Companion: High Performance Computing, Networking Storage and Analysis	10.1109/SC.Companion.2012.105	input/output;parallel computing;real-time computing;computer hardware;computer science;physical address;virtual memory;memory-mapped i/o;operating system;mmap;distributed computing;computer memory;linux kernel;i/o scheduling;memory management	OS	-13.375914670993822	53.28588286534999	18392
54cd2dbb69dd6ca6b086439a735c864e1c1ddaa3	online deadline scheduling with bounded energy efficiency	online algorithm;energy efficient;energy eciency;on line algorithm;energy e ciency;competitive ratio	Existing work on scheduling with energy concern has focused on minimizing the energy for completing all jobs or achieving maximum throughput [19, 2, 7, 13, 14]. That is, energy usage is a secondary concern when compared to throughput and the schedules targeted may be very poor in energy efficiency. In this paper, we attempt to put energy efficiency as the primary concern and study how to maximize throughput subject to a user-defined threshold of energy efficiency. We first show that all deterministic online algorithms have a competitive ratio at least ∆, where ∆ is the max-min ratio of job size. Nevertheless, allowing the online algorithm to have a slightly poorer energy efficiency leads to constant (i.e., independent of ∆) competitive online algorithm. On the other hand, using randomization, we can reduce the competitive ratio to O(log ∆) without relaxing the efficiency threshold. Finally we consider a special case where no jobs are “demanding” and give a deterministic online algorithm with constant competitive ratio for this case.	competitive analysis (online algorithm);job stream;maxima and minima;maximum throughput scheduling;online algorithm;scheduling (computing)	Wun-Tat Chan;Tak Wah Lam;Kin-Sum Mak;Prudence W. H. Wong	2007		10.1007/978-3-540-72504-6_38	competitive analysis;online algorithm;mathematical optimization;real-time computing;computer science;efficient energy use	Theory	-5.848258649523555	59.47623137224425	18395
6ea02ac804cb47e9844591ca61de6522332632d8	a speculative technique for auto-memoization processor with multithreading	multi threading;yarn;multithread memoization multicore;indexing terms;data mining;iterative methods;multi threading iterative methods multiprocessing systems;multicore;registers;computer aided manufacturing;impedance matching;functions iteration speculative technique auto memoization processor loop iteration multicore processor speculative multi threading reuse test reuse target block spec cpu95 suite benchmark;multithread;multiprocessing systems;magnetic cores;memoization;parallel processing;multithreading microprocessors multicore processing yarn parallel processing testing clocks delay throughput distributed computing	We have proposed an auto-memoization processor. This processor automatically and dynamically memoizes both functions and loop iterations, and skips their execution by reusing their results. On the other hand, multi/many-core processors have come into wide use. The number of cores is expected to increase to a hundred or more. However, many programs do not have so much parallelism in them. Therefore it becomes very important to consider how to utilize many cores effectively. This paper describes a speedup technique for auto-memoization processor using speculative multi-threading. Two speculative threads will be forked on reuse test. The one assumes that the reuse test will succeed, and executes the following codes of the reuse target block speculatively. The other assumes that the reuse test will fail, and executes the reuse target block. These two threads conceal the overhead of auto-memoization processor. The result of the experiment with SPEC CPU95 suite benchmarks shows that proposing method improves the maximum speedup from 13.9% to 36.0%.	central processing unit;code;computation;iteration;manycore processor;memoization;overhead (computing);parallel computing;performance evaluation;simultaneous multithreading;speculative execution;speedup;thread (computing)	Yushi Kamiya;Tomoaki Tsumura;Hiroshi Matsuo;Yasuhiko Nakashima	2009	2009 International Conference on Parallel and Distributed Computing, Applications and Technologies	10.1109/PDCAT.2009.67	multi-core processor;parallel processing;impedance matching;computer architecture;parallel computing;real-time computing;memoization;index term;multithreading;computer science;operating system;distributed computing;iterative method;processor register;programming language	HPC	-7.163947033705766	50.329559464230066	18409
5dc7461a7802c0e29c658c1969c54e533f395858	manual parallelization versus state-of-the-art parallelization techniques: the spec cpu2006 as a case study		Being multiprocessors (both on-chip and/or off-chip), modern computer systems can automatically exploit the benefits of parallel programs, but their resources remain underutilized in executing still-Prevailing sequential applications. An obvious solution is in the parallelization of such applications. The first part overviews he broad issues in parallelization. Various parallelization approaches and contemporary software and hardware tools for extracting parallelism from sequential applications are studied. It also attempts to identify typical code patterns amenable for parallelization. The second part represents a case study where the SPEC CPU2006 suite-is considered as a representative collection of typical sequential applications. Following that, it discusses the possibilities and potentials of automatic parallelization and vectorization of the sequential C++ applications from the CPU2006 suite. Since these potentials are generally limited, it explores the issues in manual parallelization of these applications. After previously identified patterns are applied by source-to-source code modifications, the effects of paralllelization are evaluated by profiling and executing on two representative parallel machines. Finally, the presented results are carefully discussed.	automatic parallelization;parallel computing;spec#	Aleksandar Vitorovic;Milo Tomasevic;Veljko M. Milutinovic	2014	Advances in Computers	10.1016/B978-0-12-420232-0.00005-2	computer architecture;parallel computing;computer science;theoretical computer science;automatic parallelization	NLP	-7.333337021212564	47.516509875153815	18428
cf839a0b2b837a7b042e2ba2ecd83d267e5dcb4c	survey on energy-saving technologies for disk-based storage systems		The explosive growth of data from various research fields has led to increasing requirement and serious energy consumption of data storage in big data era. As a component of a data center, the storage system consumes almost 27% of the total energy. Therefore, increasing attention has been drawn to the research on energy conservation. In this paper, existing energy-saving methods for disk drives are summarized, which include disk power management, cache management, workload skew and RAID configuration. We find that power management is the basic strategy widely used in other models. Workload skew is efficient for energy saving although it could cause response delay due to the load concentration. Multiple models based on RAID are also developed for energy conservation. In the end, this paper forecasts the development of energy-saving technologies and come to the conclusion that a co-design scheme of hardware and software is necessary for the application-oriented system.	big data;computer data storage;data center;power management;raid	Ce Yu;Jianmei Wang;Chao Sun;Xiaoxiao Lu;Jian Xiao;Jizhou Sun	2017		10.1007/978-3-319-65482-9_64	computer science;distributed computing;raid;disk array;energy consumption;power management;data center;cache;computer data storage;energy conservation	OS	-10.920059910073345	55.569865225424216	18450
4aaad4cc5b0a207d27060069d2880a919a9fad76	a new architecture for concurrent lazy cyclic reference counting on multi-processor systems	reference counting;memory management;performance test;garbage collection;computer architecture;software development;concurrent programs;concurrent garbage collection	Multi-processor systems have become the standard in current computer architectures. Software developers have the possibility to take advantage of the additional computing power available to concurrent programs. This paper presents a way to automatically use additional processors, by performing memory management concurrently. A new architecture with little explicit synchronization for concurrent lazy cyclic reference counting is described. This architecture was implemented and preliminary performance tests point at significant efficiency improvements over the sequential counterpart.	algorithm;athlon;benchmark (computing);central processing unit;computer architecture;functional compiler;garbage collection (computer science);lazy evaluation;memory management;multiprocessing;parallel computing;random-access memory;reference counting;software developer;testbed;throughput	Andrei de Araújo Formiga;Rafael Dueire Lins	2007	J. UCS	10.3217/jucs-013-06-0817	computer architecture;reference counting;parallel computing;real-time computing;computer science;software development;operating system;garbage collection;programming language;memory management	Arch	-14.28207307599676	40.38870125897321	18495
6c7db5b65a4101fd5e45c7b9f87fc8c0019fbd03	an end-to-end dynamic trust framework for service-oriented architecture		Service-oriented architecture (SOA) is an architectural paradigm that advocates composition of loosely-coupled services in order to construct more complex applications. The agility and complexity of modern web services on one hand and the arbitrary interconnections among them on the other hand, make it difficult to maintain a sustainable trustworthiness in long-running SOA-based applications. Moreover, the chain of participating services in a specific SOA invocation may not be visible to the service consumers, which leads to a lack of accountability. To address these challenges in SOA, we propose the following contributions. First, we design a new dynamic and flexible trust model based on graph abstraction that uses multiple trust strategies to calculate trust across SOA. This trust model keeps track of three trust metrics: individual service trust, session trust, and composite trust. We further design a trust engine component that implements the proposed trust model and that continuously maintains the quantitative end-to-end trust based on processing actual execution of services. Second, to prove the practicality and usefulness of the proposed framework, we have implemented an adaptive and secure service composition engine (ASSC) which takes advantage of an efficient algorithm to generate service compositions with near-optimal trustworthiness under predefined QoS constraints. Finally, we have developed a tool that is able to automatically deploy SOA testbeds from arbitrary directed acyclic graphs (created in the GUI). This tool enables the researcher to study the dynamics of new trust algorithms and strategies under different scenarios (e.g., arbitrary SOA topologies and attacks). We have extensively studied the effectiveness and performance of the proposed solutions using testbeds in the Amazon EC2 cloud.	algorithm;amazon elastic compute cloud (ec2);attack (computing);directed acyclic graph;end-to-end principle;graphical user interface;open-source software;programming paradigm;service composability principle;service-oriented architecture;service-oriented device architecture;testbed;trust (emotion);trust metric;web service	Mehdi Azarmi;Bharat K. Bhargava	2017	2017 IEEE 10th International Conference on Cloud Computing (CLOUD)	10.1109/CLOUD.2017.78	quality of service;computer science;web service;distributed computing;network topology;service-oriented architecture;cloud computing;computational trust;directed acyclic graph;end-to-end principle	SE	-33.225954698571115	57.315154249412714	18511
af33fe2f8714a77ef0b5b100fdf50bc86ab6fe82	reducing overhead in the uintah framework to support short-lived tasks on gpu-heterogeneous architectures	heterogeneous systems;gpu;hybrid parallelism;parallel;optimization;stencil computation;uintah	The Uintah computational framework is used for the parallel solution of partial differential equations on adaptive mesh refinement grids using modern supercomputers. Uintah is structured with an application layer and a separate runtime system. The Uintah runtime system is based on a distributed directed acyclic graph (DAG) of computational tasks, with a task scheduler that efficiently schedules and execute these tasks on both CPU cores and on-node accelerators. The runtime system identifies task dependencies, creates a taskgraph prior to an iteration based on these dependencies, prepares data for tasks, automatically generates MPI message tags, and manages data after task computation. Managing tasks for accelerators pose significant challenges over their CPU task counterparts due to supporting more memory regions, API call latency, memory bandwidth concerns, and the added complexity of development. These challenges are greatest when tasks compute within a few milliseconds, especially those that have stencil based computations that involve halo data, have little reuse of data, and/or require many computational variables. Current and emerging heterogeneous architectures necessitate addressing these challenges within Uintah. This work is not designed to improve performance of existing tasks, but rather reduce runtime overhead to allow developers writing short-lived computational tasks to utilize Uintah in a heterogeneous environment. This work analyzes an initial approach for managing accelerator tasks alongside existing CPU tasks within Uintah. The principal contribution of this work is to identify and address inefficiencies that arise when mapping tasks onto the GPU, to implement new schemes to reduce runtime system overhead, to introduce new features that allow for more tasks to leverage on-node accelerators, and to show overhead reduction results from these improvements.	adaptive mesh refinement;application programming interface;central processing unit;computation;directed acyclic graph;graphics processing unit;iteration;memory bandwidth;message passing interface;overhead (computing);refinement (computing);runtime system;scheduling (computing);supercomputer;windows task scheduler	Brad Peterson;Harish Kumar Dasari;Alan Humphrey;James C. Sutherland;Tony Saad;Martin Berzins	2015		10.1145/2830018.2830023	parallel computing;real-time computing;stencil code;computer science;operating system;parallel;distributed computing;programming language	HPC	-5.5852202378362525	42.42167854842308	18540
49f99a1cc7e157b0515695debb6e6a847594894c	berkeley unix on 1000 workstations: athena changes to 4.3bsd	service management	4.3BSD UNIX as shipped is designed for use on individually-managed, networked timesharing systems. A large network of individual workstations and server machines, all managed centrally, has many important differences from such a model. This paper discusses some of the changes necessary for 4.3 in this new world, including the file system layout, configuration files, and software. The integration with Athena's authentica-tion system, name service, and service management system are also discussed. 1. Overview ''By 1988, create a new educational computing environment environment at MIT built around high-performance graphics workstations, high-speed networking, and servers of various types.'' This one-sentence statement is a high-level description of the technical goals of Project Athena. While the primary goals are to enhance education, attaining them has required a significant effort to engineer a software environment for use in a large network of workstations and servers. The Athena hardware environment currently consists of approximately 650 workstations and 65 dedicated server machines. There are two kinds of workstations: DEC Micro-VAX systems and IBM RT PC's. The servers are VAX 11/750's or dedicated workstations of either type. The operating system in use now is 4.3BSD UNIX on the VAX machines, and IBM's 4.3/RT UNIX for the RT PC systems. All systems include support for Sun Microsystem's Network File System (NFS). 1 The workstations and servers are connected to local-area Ethernet subnetworks, which are linked by a high-speed fiber optic † UNIX is a Trademark of Bell Laboratories. ''spine.'' At present, there are twelve such sub-networks. The problems of a distributed system are the scale of the operation and the role of the network as a fundamental component. UNIX systems have traditionally been managed on a ''one system , one wizard'' basis, but this is not acceptable at an eventual scale of 1000 workstations, 100 server machines, and 10,000 users. Two questions often asked are: ''Does it scale?'' and ''Is it well-behaved on the network?'' All too often, the answer to one or the other is ''No,'' and part of the system must be reworked to satisfy those constraints. This paper describes the goals and constraints faced by Athena, as well as many of the solutions devised in building such a system. In particular, the next two sections examine the goals and evolution of the computing system side of the Project. Next is a discussion of the base operating systems in use, such as 4.3BSD. This is followed by …	bsd;computer cluster;dedicated hosting service;directory service;distributed computing;graphics;high- and low-level;microvax;operating system;optical fiber;project athena;server (computing);tagged union;time-sharing;unix;vax;workstation	G. Winfield Treese	1988			computer systems research group;berkeley software distribution;operating system;workstation;unix architecture;computer science	OS	-27.560441139197014	51.04668509344435	18578
49b2ea5ab41d1090d82e32fe07f76482fe298943	the cloud storage model for manufacturing system in global factory automation	cloud computing manufacturing systems production facilities computational modeling servers data models;factory automation cloud computing cloud storage manufacturing system;factory automation;cloud storage model management server data exchange databases internet production rate global factory automation manufacturing system;manufacturing systems cloud computing database management systems factory automation;manufacturing system;cloud storage;cloud computing	There are many manufacturing systems in the factory. Furthermore the system engineer or user have to control and manage lots of data for the manufacturing system. There is, therefore, a need for an efficient management method or technique to handle the systems in their factory. The system managers who work in the main office or at a e location far from the factory also need to check the production rate and data of the manufacturing system in the factory. All of them need to manage the system data. Recently, cloud computing was introduced and thus allows a significant alternative to today's manufacturing system perspective. Therefore, this research aims to present a model to manage and share the data for the manufacturing system via the internet. For this purpose, the cloud storage for the manufacturing system in global factory automation was used. The proposed cloud storage model consists of four types of databases and one management server. The model interfaces the data exchange process between the manufacturing systems and each database. Through this model, the system manager, engineer, and user are all able to check and share the manufacturing system's data efficiently via the internet.	automation;cloud computing;cloud storage;database;internet;multiuser dos;server (computing);storage model;system manager (hp lx);systems engineering	Hwa-Young Jeong;Jong Hyuk Park;Jae Dong Lee	2014	2014 28th International Conference on Advanced Information Networking and Applications Workshops	10.1109/WAINA.2014.138	manufacturing execution system;integrated computer-aided manufacturing;process development execution system;cloud computing;computer science;operating system;automation;database;computer-integrated manufacturing	Robotics	-32.8416190373273	50.35871431519864	18610
b54812bf3fbe3dff52d8b0df1417e40746f0d6dd	contribution à l'élaboration d'ordonnanceurs de processus légers performants et portables pour architectures multiprocesseurs. (contribution to the design of portable and efficient threads schedulers for multiprocessors architectures)		Nowadays, threads are widely spread in computer science. Indeed, multithreading allows applications not only to fully exploit multiprocessor computers, but also to reveal its intrinsic parallelism. In the context of high performance computing, threads are commonly used to overlap computation with communication. They also allow various execution flows within the application to progress independently one from another. This is a mandatory functionality regarding the implementation of complex middleware such as MPI or CORBA. My work aims at providing an efficient threads library targeting a wide range of architectures (monoor multiprocessor computers, SMT technology, etc.) and able to fulfil the requirements of high performance computing programs. First, I have extended and implemented the Scheduler Activation model within the Linux kernel, so that user threads can be extremely reactive to hardware interruptions. Then, I did expend this mechanism to unify the management of interrupts and polling in multithreaded environments. Finally, I have designed new tracing mechanisms allowing to precisely rebuild the execution of multithreaded programs, even with a two-level scheduling. All these works have been implemented within the PM2 software suite. The Marcel library provides efficient multithreading on a large range of processors and systems. Marcel is flexible enough to allow an application to precisely manage its threads scheduling when needed. Applications can be traced in order to observe their precise behavior. The generated traces can be converted to the Pajé software format, so that application behavior can be graphically observed.		Vincent Danjean	2004				HPC	-11.398862078645106	40.811995085928196	18645
b4be542abfae69bd670bf06bdee1d6dd912881fe	distributed applications and interoperable systems		Graphs are at the core of many data processing problems, whether that is searching through billions of records for suspicious interactions, ranking the importance of web pages based on their connectivity, or identifying possible “missing” friends on a social network. This talk will discuss the challenges in building large, scalable, in-memory graph analytics systems. Many of these challenges come from the way that graph algorithms behave differently based on the structure of the input graph: a planar road network graph can produce a significantly different load on the machine’s memory system from a low-diameter social network graph. It can be necessary to select particular algorithms for these different cases, and to make contrasting decisions over how the machine’s resources are allocated. Finally, we face challenges simply from the scale at which we operate: making efficient use of the hardware in new SPARC machines with over 4000 threads. Speaker: Tim Harris leads the Oracle Labs group in Cambridge, UK. His research interests span multiple layers of the stack, including parallel programming, VMM/OS/runtime-system interaction, and opportunities for specialized architecture support for particular workloads. He has also worked on the implementation of software transactional memory for multi-core computers, and the design of programming language features based on it. Tim has a BA and PhD in computer science from Cambridge University Computer Laboratory. He was on the faculty at the Computer Laboratory from 2000–2004 where he led the department’s research on concurrent data structures and contributed to the Xen virtual machine monitor project. He was at Microsoft Research from 2004, and then joined Oracle Labs to found the Cambridge office in 2012.	algorithm;business architecture;collaboration graph;computer lab;computer science;data structure;graph theory;harris affine region detector;hypervisor;in-memory database;interaction;interoperability;microsoft research;multi-core processor;operating system;parallel computing;programming language;runtime system;sparc;scalability;social network;software transactional memory;virtual machine;weatherstar;web page	Márk Jelasity;Evangelia Kalyvianaki;Gerhard Goos;Juris Hartmanis;Jan van Leeuwen	2016		10.1007/978-3-319-39577-7		OS	-8.251464746838572	45.5013232215747	18662
78a95d1414b67992ea68890122b35665bebf1afb	towards resource disaggregation — memory scavenging for scientific workloads	protocols;memory management;resource management;servers;bandwidth;scalability;parallel processing	Compute clusters, consisting of many, uniformly built nodes, are used to run a large spectrum of different workloads, like tightly coupled (MPI) jobs, MapReduce, or graph-processing data-analytics applications, each of which with their own resource requirements. Many studies consistently highlight two types of under-utilized cluster resources: memory (up to 50%) and network. In this work, we take a step towards (software) resource disaggregation, and therefore increased resource utilization, by designing a memory scavenging technique that makes unused memory available to applications on other cluster nodes. We implement this technique in MemFSS, an in-memory distributed file system. The scavenging MemFSS extends its storage space by taking advantage of the unused memory and bandwidth of cluster nodes already running other tenants' applications. Our experiments show that our memory scavenging approach incurs negligible overhead (below 10%) for most tenant applications, while the compute resource comsumption of MemFSS applications is largely reduced (by 17%-74%).	clustered file system;computer cluster;experiment;graph (abstract data type);in-memory database;mapreduce;overhead (computing);requirement	Alexandru Uta;Ana-Maria Oprescu;Thilo Kielmann	2016	2016 IEEE International Conference on Cluster Computing (CLUSTER)	10.1109/CLUSTER.2016.18	communications protocol;parallel processing;parallel computing;real-time computing;scalability;computer science;resource management;operating system;distributed computing;bandwidth;server;computer network;memory management	HPC	-16.330462856631847	53.81084229239591	18702
dbc2f7ea1fefa214a1dd030844084f275f1b7f35	a conflict-resilient lock-free calendar queue for scalable share-everything pdes platforms		Emerging share-everything Parallel Discrete Event Simulation (PDES) platforms rely on worker threads fully sharing the workload of events to be processed. These platforms require efficient event pool data structures enabling high concurrency of extraction/insertion operations. Non-blocking event pool algorithms are raising as promising solutions for this problem. However, the classical non-blocking paradigm leads concurrent conflicting operations, acting on a same portion of the event pool data structure, to abort and then retry. In this article we present a conflict-resilient non-blocking calendar queue that enables conflicting dequeue operations, concurrently attempting to extract the minimum element, to survive, thus improving the level of scalability of accesses to the hot portion of the data structure---namely the bucket to which the current locality of the events to be processed is bound. We have integrated our solution within an open source share-everything PDES platform and report the results of an experimental analysis of the proposed concurrent data structure compared to some literature solutions.	blocking (computing);central processing unit;concurrency (computer science);concurrent computing;concurrent data structure;experiment;hot spare;locality of reference;non-blocking algorithm;open-source software;programming paradigm;retry;scalability;simulation;thread (computing)	Romolo Marotta;Mauro Ianni;Alessandro Pellegrini;Francesco Quaglia	2017		10.1145/3064911.3064926	cartography	DB	-13.976462445948023	48.44392455974823	18710
0e0f081cf26bdf6b064625b4d3dc017723ebcf90	energy efficient fault tolerance for high performance computing (hpc) in the cloud	energy efficient fault tolerance energy utilization cloud execution environment proactive process level migration approach ft algorithm hpc systems energy consumption haas model hardware as a service model computation intensive applications vm virtual machines cloud computing high performance computing;energy conservation;process level migrations;haas;software fault tolerance;proactive fault tolerance;power aware computing;hpc;computation intensive applications;energy consumption;monitoring hardware temperature sensors fault tolerance fault tolerant systems prediction algorithms cloud computing;process level migrations hpc cloud computing haas proactive fault tolerance computation intensive applications;software fault tolerance cloud computing energy conservation energy consumption parallel processing power aware computing;parallel processing;cloud computing	With cloud computing, a large number of Virtual Machines (VMs) can be provisioned to form high performance computing (HPC) to run computation-intensive applications using the Hardware as a Service (HaaS) model. Fault Tolerance (FT) for HPC in the cloud is increasingly a challenging issue, because any fault during the execution would result in re-running the application, which will cost time, money and energy. There has been a significant increase in energy consumption of HPC systems in cloud as a result of rerunning application and fault tolerance (e.g., redundant computing). In this paper we present energy efficient fault tolerance for HPC in the cloud. We develop a generic FT algorithm for HPC systems in the cloud. Our algorithm uses proactive processlevel migration approach, however it does not rely on a spare node or redundant computing prior to prediction of a failure. Our experimental results obtained from a real cloud execution environment show that the energy utilization for HPC in the cloud while providing fault tolerance can be reduced by as much as 30%.	algorithm;application checkpointing;cloud computing;computation;fault tolerance;mean time between failures;provisioning;research data archiving;supercomputer;virtual machine	Ifeanyi P. Egwutuoha;Shiping Chen	2013	2013 IEEE Sixth International Conference on Cloud Computing	10.1109/CLOUD.2013.69	embedded system;parallel processing;parallel computing;real-time computing;energy conservation;cloud computing;computer science;operating system;cloud testing;software fault tolerance	HPC	-21.074798269336984	58.864123367211775	18847
8e0cfc083663e1c8cc418c56212d5a9a24633abe	µ3l: an hll-risc processor for parallel execution of fp-language programs	functional programming language;parallel processing;user interface;programming language;tree structure;mathematical model;high level language	To eliminate the conceptual distance between the hardware instruction set and the user interface, some architects advocate High Level Language (HLL) machines. To obtain simple, fast and cheap machines, some architects advocate Reduced Instruction Set Computer (RISC) machines. This paper reconciles both views and presents an architecture which has both an HLL user interface and a RISC hardware. Each instance of this architecture is a module of an HLL multiprocessor system.  Functional programming languages offer a bridge between mathematical models of computation and multiprocessor system environments. We choose the language AFPL (A Functional Programming Language) as the HLL user interface. AFPL's direct execution model, based on a tree structured internal representation, takes advantage of the parallelism inherent in programs by decomposing them on the fly into tasks which can be performed concurrently.	functional programming;high-level programming language;mathematical model;model of computation;multiprocessing;on the fly;parallel computing;user interface	M. Castan;Elliott I. Organick	1982		10.1145/800048.801732	parallel processing;computer architecture;parallel computing;computer science;theoretical computer science;architecture;operating system;mathematical model;tree structure;programming language;user interface	Arch	-13.837574162830899	38.451503652594994	18920
2ef12a1520ca2bbccf730c0eb29fda2699dbe238	dpdns keynote	fault tolerant computing;message passing;cloud computing	The next challenges of the HPC community is to run successfully simulation applications in rather unstable environments: 1) at Exascale and 2) in Clouds. Instability of Exascale systems comes mainly from the scale of the system: 100 Millions of CPU cores. At that scale, the system can not be stable even with highly reliable components. The cloud environment instability is more related to the extensive use of inexpensive and less reliable components. Currently the community considers that the MTTI of an Exascale application will be between 1h and 1day. Some recent studies report similar MTTI for HPC applications run on Cloud with 100 to 1000 cores. Given these small MTTIs, both environments could be consider as hostile for HPC applications and the current fault tolerance approach used in supercomputing centers does not match such small MTTIs. In addition, while current fault tolerance techniques for HPC applications do not attempt to reduce energy consumption, this is an important concern for Exascale and Cloud environments. All together, this draws a new research filed on fault tolerance for HPC applications : there is a need for new fault tolerance approaches specifically designed for unstable environments, seeking a minimization of the power consumption. In this talk, we will explore some recent results concerning the execution of MPI applications on unstable environments. We will show that by extracting the fundamental characteristics of HPC application, we can design new fault tolerance approaches surpassing existing approaches. In particular, we will present a characterization of HPC applications and the design of a new family of fault tolerance protocols mixing the benefit of coordinated checkpointing and message logging protocols. Biography	application checkpointing;central processing unit;cloud computing;control theory;fault tolerance;instability;message passing interface;simulation;supercomputer	Franck Cappello	2011	2011 IEEE International Symposium on Parallel and Distributed Processing Workshops and Phd Forum	10.1109/IPDPS.2011.410	parallel computing;computer science;operating system;distributed computing	HPC	-16.63257091954736	50.43481480184866	18921
88f24c2ee2a96713b814cbd763abb250911bac7d	practical examples of gpu computing optimization principles	optimization principles;histograms;paper;shared memory;convolution;fermi cuda gpgpu optimization principles visual computing;joints;visual computing;cuda;gpgpu;directcompute;programming techniques;instruction sets histograms optimization graphics processing unit pixel joints convolution;signal processing;pixel;fermi;nvidia;optimization;computer science;graphics processing unit;opencl;instruction sets	In this paper, we provide examples to optimize signal processing or visual computing algorithms written for SIMT-based GPU architectures. These implementations demonstrate the optimizations for CUDA or its successors OpenCL and DirectCompute. We discuss the effect and optimization principles of memory coalescing, bandwidth reduction, processor occupancy, bank conflict reduction, local memory elimination and instruction optimization. The effect of the optimization steps are illustrated by state-of-the-art examples. A comparison with optimized and unoptimized algorithms is provided. A first example discusses the construction of joint histograms using shared memory, where optimizations lead to a significant speedup compared to the original implementation. A second example presents convolution and the acquired results.	algorithm;cuda;computer memory;convolution;directcompute;graphics processing unit;mathematical optimization;opencl api;programmer;run time (program lifecycle phase);shared memory;signal processing;single instruction, multiple threads;speedup;visual computing	Patrik Goorts;Sammy Rogmans;Steven Vanden Eynde;Philippe Bekaert	2010	2010 International Conference on Signal Processing and Multimedia Applications (SIGMAP)		shared memory;computer architecture;parallel computing;computer science;theoretical computer science;signal processing;fermi gamma-ray space telescope;instruction set;histogram;convolution;general-purpose computing on graphics processing units;pixel	EDA	-5.082497373458239	43.78548735443191	18937
d894dddcf29a1e2e05c5f6e909559ab34702578a	performance tests in data warehousing etlm process for detection of changes in data origin	gestion integrada;gestion integree;gestion entreprise;replication;tratamiento transaccion;base donnee;performance test;database;base dato;firm management;integrated management;almacen dato;securite donnee;replicacion;semistructured data;semi structured data;dato semi estructurado;file system;data warehousing;administracion empresa;materialized views;systeme gestion base donnee;synthetic data;entrepot donnee;data warehouse;transaction processing;security policy;sistema gestion base datos;database management system;security of data;traitement transaction;donnee semistructuree	In a data warehouse (DW) environment, when the operational environment does not posses or does not want to inform the data about the changes that occurred, controls have to be implemented to enable detection of these changes and to reflect them in the DW environment. The main scenarios are: i) the impossibility to instrument the DBMS (triggers, transaction log, stored procedures, replication, materialized views, old and new versions of data, etc) due to security policies, data property or performance issues; ii) the lack of instrumentation resources on the DBMS; iii) the use of legacy technologies such file systems or semi-structured data; iv) application proprietary databases and ERP systems. In another article [1], we presented the development and implementation of a technique that was derived for the comparison of database snapshots, where we use signatures to mark and detect changes. The technique is simple and can be applied to all four scenarios above. To prove the efficiency of our technique, in this article we do comparative performance tests between these approaches. We performed two benchmarks: the first one using synthetic data and the second one using the real data from a case study in the data warehouse project developed for Rio Sul Airlines, a regional aviation company belonging to the Brazil-based Varig group. We also describe the main approaches to solve the detection of changes in data origin.	benchmark (computing);database trigger;dreamwidth;erp;enterprise resource planning;legacy system;materialized view;semi-structured data;semiconductor industry;signature;stored procedure;synthetic data;transaction log;winsock	Rosana L. de B. A. Rocha;Leonardo Figueiredo Cardoso;Jano Moreira de Souza	2003		10.1007/978-3-540-45228-7_14	materialized view;replication;semi-structured data;transaction processing;computer science;security policy;operating system;data warehouse;data mining;database;computer security;synthetic data	DB	-26.52171862047539	43.98253853037663	18957
f1f80191d7d88d3e2bb389a6b429ac14dafee547	mul-t: a high-performance parallel lisp	user interface;product quality;high performance	Mul-T is a parallel Lisp system, based on Multilisp's future construct, that has been developed to run on an Encore Multimax multiprocessor. Mul-T is an extended version of the Yale T system and uses the T system's ORBIT compiler to achieve “production quality” performance on stock hardware — about 100 times faster than Multilisp. Mul-T shows that futures can be implemented cheaply enough to be useful in a production-quality system. Mul-T is fully operational, including a user interface that supports managing groups of parallel tasks.	compiler;encore computer;futures and promises;lisp;multilisp;multiprocessing;user interface	David A. Kranz;Robert H. Halstead;Eric Mohr	1989		10.1145/73141.74825	parallel computing;real-time computing;computer science;operating system;programming language;user interface	HPC	-11.17204698642543	41.319887528257524	18985
40531c8281efbfacda6d93cc8427968e64e5a8b4	a community authorization service for group collaboration	complex dynamic policies;electrical capacitance tomography;policy enforcement;groupware;authorization collaboration electrical capacitance tomography intrusion detection computer science mathematics collaborative software resource management identity based encryption prototypes;cluster computing;mathematics;identity based encryption;authorisation;resource allocation;policy maintenance;prototypes;data management community authorization service group collaboration computational grids collaboratories distributed communities resource providers resource consumers complex dynamic policies policy representation policy maintenance policy enforcement policy specification scalable mechanism authority delegation fine grained access control policies ultimate resource control prototype implementation;distributed communities;resource management;collaboration;data management;intrusion detection;policy specification;access control policy;dp management groupware authorisation distributed programming resource allocation;authority delegation;energy planning policy and economy;energy policy;group collaboration;distributed programming;prototype implementation;authorization;policy representation;ultimate resource control;computational grids;computer science;dp management;communities;resource consumers;collaboratories;interconnected power systems;community authorization service;scalable mechanism;collaborative software;resource providers;fine grained access control policies	In “Grids” and “collaboratories,” we find distributed communities of resource providers and resource consumers, within which often complex and dynamic policies govern who can use which resources for which purpose. We propose a new approach to the representation, maintenance, and enforcement of such policies that provides a scalable mechanism for specifying and enforcing these policies. Our approach allows resource providers to delegate some of the authority for maintaining fine-grained access control policies to communities, while still maintaining ultimate control over their resources. We also describe a prototype implementation of this approach and an application in a data management context.	access control;authorization;prototype;scalability	Laura Pearlman;Von Welch;Ian T. Foster;Carl Kesselman;Steven Tuecke	2002		10.1109/POLICY.2002.1011293	data management;computer science;knowledge management;resource management;database;distributed computing;authorization;computer security;collaborative software	Security	-33.22069857156273	56.153337398667034	18997
3c7f3d726968fccb7217cbab9f466da02831fbc5	methods of memory optimizations in streaming applications	streaming applications;performance evaluation;optimization methods yarn memory management random access memory streaming media technology management parallel programming multimedia systems performance analysis analytical models;storage management;parallel programming system;parallel programming;color based people tracking application;null;interactive multimedia applications;garbage collection;interactive multimedia;memory optimizations;multimedia computing;memory optimization;garbage collector;storage management multimedia computing parallel programming;people tracking;memory usage reduction;parallel programs;garbage identification problem;lower bound;oracle;distributed management;memory usage reduction memory optimizations streaming applications garbage collection garbage identification problem parallel programming system interactive multimedia applications oracle color based people tracking application performance evaluation	"""Streaming applications are often distributed, manage large quantities of data and, as a result, have large memory requirements. Therefore, efficient garbage collection (GC) is crucial for their performance. On the other hand, not all data items affect the application output due to differences in the processing rates of various application threads. In this paper we propose extending the definition of the garbage identification problem for streaming applications and include not only data items that are not """"reachable """" but also data items that have no effect on the final outcome of the application. We present four optimizations to an existing GC algorithm in Stampede, a parallel programming system to support interactive multimedia applications. We ask the question how far off these algorithms are from an ideal garbage collector, one in which the memory usage exactly equals the amount required for buffering only the relevant data items. This oracle, while unimplementable, serves as an empirical lower-bound for memory usage. We then propose optimizations that will help us get closer to this lower- bound. Using an elaborate measurement and post-mortem analysis infrastructure, we simulate the performance potential for these optimizations and implement the most promising ones. A color-based people tracking application is used for the performance evaluation. Our results show that these optimizations reduce the memory usage by up to 60%."""	admissible numbering;algorithm;color;data dependency;garbage (computer science);garbage collection (computer science);memory footprint;parallel computing;performance evaluation;requirement;runtime system;simulation;streaming media	Nissim Harel;Hasnain A. Mandviwala;Kathleen Knobe;Umakishore Ramachandran	2007	2007 International Conference on Parallel Processing (ICPP 2007)	10.1109/ICPP.2007.57	garbage;parallel computing;real-time computing;computer science;theoretical computer science;operating system;garbage collection;programming language	HPC	-11.204568732981617	50.22914656577789	19001
fed4992655da7175ac66dd0a51c58de9f4756f5e	d2stm: dependable distributed software transactional memory	databases;nonblocking distributed certification;software;distributed system;protocols;replication;certification;bloom filter;encoding dependable distributed software transactional memory dependability performance replicated stm nonblocking distributed certification bloom filter certification;dependable distributed software transactional memory;performance;data mining;bloom filters;bloom filters dependability software transactional memory replication;bloom filter certification;replicated stm;strong consistency;certification filters costs distributed computing software performance encoding programming profession transaction databases system recovery broadcasting;software transactional memory;distributed shared memory systems;dependability;information filters;encoding;software reliability;software reliability certification distributed shared memory systems encoding	At current date the problem of how to build distributed and replicated Software Transactional Memory (STM) to enhance both dependability and performance is still largely unexplored. This paper fills this gap by presenting D2STM, a replicated STM whose consistency is ensured in a transparent manner, even in the presence of failures. Strong consistency is enforced at transaction commit time by a non-blocking distributed certification scheme, which we name BFC (Bloom Filter Certification). BFC exploits a novel Bloom Filter-based encoding mechanism that permits to significantly reduce the overheads of replica coordination at the cost of a user tunable increase in the probability of transaction abort. Through an extensive experimental study based on standard STM benchmarks we show that the BFC scheme permits to achieve remarkable performance gains even for negligible (e.g. 1%) increases of the transaction abort rate.	base one foundation component library (bfc);blocking (computing);bloom filter;dependability;experiment;high availability;line code;non-blocking algorithm;overhead (computing);read-only memory;software transactional memory;strong consistency	Maria Couceiro;Paolo Romano;Nuno Carvalho;Luís E. T. Rodrigues	2009	2009 15th IEEE Pacific Rim International Symposium on Dependable Computing	10.1109/PRDC.2009.55	parallel computing;real-time computing;computer science;bloom filter;operating system;distributed computing;programming language;computer security;computer network	Arch	-22.542823316495966	49.382368040381465	19005
6bfb73881d3f465eef837e7a2afc21e807efb0b0	drive: using implicit caching hints to achieve disk i/o reduction in virtualized environments	trace based evaluation drive implicit caching hints disk i o reduction virtualized environments content similarity i o deduplication disk read access optimization;virtualization;memory management virtualization drives virtual machining runtime performance evaluation arrays;memory management;performance evaluation;virtual machining;runtime;drives;arrays;virtualisation cache storage input output programs optimisation	Co-hosting of virtualized applications results in similar content across multiple blocks on disk, which are fetched into memory (the host's page cache). Content similarity can be harnessed both to avoid duplicate disk I/O requests that fetch the same content repeatedly, as well as to prevent multiple occurrences of duplicate content in cache. Typically, caches store the most recently or frequently accessed blocks to reduce the number of disk read accesses. These caches are referenced by block number, and can not recognize content similarity across multiple blocks. Existing work in memory deduplication merges cache pages after multiple identical blocks have already been fetched from disk into cache, while existing work in I/O deduplication reserves a portion of the host-cache to be maintained as a content-aware cache. We propose a disk I/O reduction system for the virtualization environment that addresses the dual problems of duplicate I/O and duplicate content in the host-cache, without being invasive. We build a disk read-access optimization called DRIVE, that identifies content similarity across multiple blocks, and performs hint-based read I/O redirection to improve cache effectiveness, thus reducing the number of disk reads further. A metadata store is maintained based on the virtual machine's disk accesses and implicit caching hints are collected for future read I/O redirection. The read I/O redirection is performed from within the virtual block device in the virtualized system, to manipulate the entire host-cache as a content-deduplicated cache implicitly. Our trace-based evaluation using a custom simulator, reveals that DRIVE always performs equal to or better than the Vanilla system, achieving up to 20% better cache-hit ratios and reducing the number of disk reads by up to 80%. The results also indicate that our system is able to achieve up to 97% content deduplication in the host-cache.	cpu cache;cache (computing);data deduplication;hardware virtualization;input/output;mathematical optimization;page cache;rewriting;simulation;virtual machine	Sujesha Sudevalayam;Purushottam Kulkarni	2014	2014 21st International Conference on High Performance Computing (HiPC)	10.1109/HiPC.2014.7116877	parallel computing;real-time computing;virtualization;page cache;computer hardware;cache;computer science;disk array controller;operating system;disk buffer;direct memory access;distributed computing;logical disk;computer network;memory management	OS	-12.704800092729277	53.285625975354485	19114
008c3534090411a1af7f5762df3c674bb19a1d3e	operating system support for mitigating software scalability bottlenecks on asymmetric multicore processors	instruction set architecture;out of order;operating system;scheduling;asymmetric multicore;multicore processors;parallel applications;operating systems	Asymmetric multicore processors (AMP) promise higher performance per watt than their symmetric counterparts, and it is likely that future processors will integrate a few fast out-of-order cores, coupled with a large number of simpler, slow cores, all exposing the same instruction-set architecture (ISA). It is well known that one of the most effective ways to leverage the effectiveness of these systems is to use fast cores to accelerate sequential phases of parallel applications, and to use slow cores for running parallel phases. At the same time, we are not aware of any implementation of this parallelism-aware (PA) scheduling policy in an operating system. So the questions as to whether this policy can be delivered efficiently by the operating system to unmodified applications, and what the associated overheads are remain open. To answer these questions we created two different implementations of the PA policy in OpenSolaris and evaluated it on real hardware, where asymmetry was emulated via CPU frequency scaling. This paper reports our findings with regard to benefits and drawbacks of this scheduling policy.	advanced configuration and power interface;algorithm;busy waiting;central processing unit;emulator;floating-point unit;frequency scaling;image scaling;multi-core processor;opensolaris;operating system;parallel computing;performance per watt;scalability;scheduling (computing);serial digital video out;speedup;task parallelism;thread (computing)	Juan Carlos Saez;Alexandra Fedorova;Manuel Prieto;Hugo Vegas	2010		10.1145/1787275.1787281	computer architecture;parallel computing;real-time computing;computer science	Arch	-9.270177225325678	50.47984937241442	19131
a5c61e54c0a64f584b298502f0f3b0148bbbfe2c	energy and performance tradeoffs for matrix multiplication on multicore machines	energy conservation;system buses;power aware computing;memory architecture;system buses energy conservation matrix multiplication memory architecture multiprocessing systems power aware computing;energy consumption multicore processing clocks memory management time frequency analysis partitioning algorithms;matrix multiplication;multiprocessing systems;dynamic voltage scaling energy tradeoff performance tradeoff energy estimation bus based multicore processors dvs parallel matrix multiplication algorithms shared memory multicore machines l1 cache l2 cache bus voltage energy requirement reduction core voltage multiple element optimization multicore architectures performance requirements	In this paper, we propose a general methodology for energy estimation of bus-based multi-core processors assuming that DVS can be used for both buses and cores. Our formulation can provide tradeoffs between DVS setting for buses and cores. We examine this methodology using various parallel matrix multiplication algorithms that are suitable for shared memory multicore machines with L1 and L2 caches. Our simulation results show that the simultaneously changing the voltage of buses along with cores can result in 10 - 20% reduction in the overall energy requirements as compared to only changing the core voltages. This is under the assumption that sufficient slack is available for DVS to be able to work at lower voltages to save energy. The methods proposed in this paper demonstrate the usefulness of multiple element optimization in multicore architectures. The experiments show that a good understanding of the overall tradeoffs between the effect of these elements in the overall performance and energy requirements can lead to improved results in the energy requirements.	central processing unit;dynamic voltage scaling;experiment;mathematical optimization;matrix multiplication;multi-core processor;multiplication algorithm;requirement;shared memory;simulation;slack variable	Zhe Wang;Hengxing Tan;Sanjay Ranka	2012	2012 International Green Computing Conference (IGCC)	10.1109/IGCC.2012.6322295	computer architecture;parallel computing;real-time computing;computer science	HPC	-4.8530317277132395	56.551939775659164	19139
97dc1b226233b4591df41ad8633d1db91ca49406	majic: compiling matlab for speed and responsiveness	juste a temps;tiempo respuesta;lenguaje programacion;reponse temporelle;compilacion;compilateur;programming language;batch production;generation code;source ponctuelle;real time;fuente puntual;generacion codigo;code generation;procede discontinu;response time;compiler;macros;temps reponse;point source;produccion por lote;time response;temps reel;compiler optimization;production par lot;batch process;langage programmation;compilation;tiempo real;procedimiento discontinuo;just in time;justo en tiempo;generative programming;metaprogramming;respuesta temporal;matlab;compilador;java	This paper presents and evaluates techniques to improve the execution performance of MATLAB. Previous efforts concentrated on source to source translation and batch compilation; MaJIC provides an interactive frontend that looks like MATLAB and compiles/optimizes code behind the scenes in real time, employing a combination of just-in-time and speculative ahead-of-time compilation. Performance results show that the proper mixture of these two techniques can yield near-zero response time as well as performance gains previously achieved only by batch compilers.	ahead-of-time compilation;compiler;just-in-time compilation;matlab;response time (technology);responsiveness;speculative execution	George Almási;David A. Padua	2002		10.1145/512529.512564	metaprogramming;compiler;parallel computing;real-time computing;point source;computer science;macro;optimizing compiler;programming language;java;response time;algorithm;code generation;batch processing	PL	-18.414990889064708	38.131020193018585	19165
3baabc0db108b3271f38b6e3f47d614985a0f84d	design and analysis of a secure two-phase locking protocol	phase locking;protocols;performance evaluation;data integrity;database management systems;database security;covert channel;secure multiversion timestamp ordering secure two phase locking protocol consistency secure concurrency control algorithms covert channels data conflicts secure concurrency control higher access classes non interference property access class performance evaluation secure optimistic concurrency control;concurrency control;optimistic concurrency control;security of data data integrity concurrency control database management systems protocols;concurrency control transaction databases data security access protocols information security database systems timing computer science access control lamps;security of data	In addition to maintaining consistency of the database, secure concurrency control algorithms must be free from covert channels arising due to data conflicts between transactions. The existing secure concurrency control approaches are unfair to transactions at higher access classes. In this paper, a secure two-phase locking protocol is presented, which is correct and free from covert channels. The protocol uses three diferent types of locks to support non-intelference property and to provide reasonably fair execution of all transactions, regardless of their access class. The results of a pelformance evaluation of the protocol are provided, comparing it with secure optimistic concurrency control and secure multiversion timestamp ordering.	algorithm;best, worst and average case;concurrency (computer science);covert channel;database;fairness measure;lock (computer science);multilevel security;optimistic concurrency control;real-time clock;real-time computing;real-time transcription;requirement;response time (technology);simulation;throughput;timestamp-based concurrency control;two-phase locking	Sang H. Son;Rasikan David	1994		10.1109/CMPSAC.1994.342775	timestamp-based concurrency control;communications protocol;optimistic concurrency control;isolation;covert channel;computer science;concurrency control;data integrity;database;distributed computing;multiversion concurrency control;non-lock concurrency control;serializability;computer security;acid;distributed concurrency control	DB	-23.305595252988386	47.959036706764294	19190
4657cc93163f6efb819b536d4d4cdc3eb54d8d1a	conception et implémentation d'un langage de programmation concurrente modulaire. (design and implementation of a modular concurrent programming language)		Shared-memory concurrency is a classic concurrency model which, among other things, makes it possible to take advantage of multicore processors that are now widespread in personal computers. Concurrent programs are prone to deadlocks which are notoriously hard to predict and debug. Programs using mutexes, a very popular synchronization mechanism, are no exception. In this thesis we studied deadlock avoidance methods with the aim of making programming with mutexes easier. We first studied a method that uses a static analysis by means of a type and effect system, then a variation on this method in a dynamically typed language. We developed more the second method. It mixes deadlock prevention and avoidance to provide an easy-to-use and expressive deadlock-free locking function. We implemented it as a Hop (dialect of Scheme) library. This lead us to develop a starvation-free algorithm to simultaneously acquire an arbitrary number of mutexes, and to identify the concept of asymptotic deadlock. While doing so, we also developped an optimization of exceptions (finally blocks). Our performance tests seem to show that using our library has negligible impact on the performance of real-life applications. Most of our work could be applied to other structured programming languages such as Java.		Johan Grande	2015				PL	-20.536004176586	33.79566956676414	19200
80440fb15080413682905c8f5fde46aa1c72084b	using pvm 3.0 to run grand challenge applications on a heterogeneous network of parallel computers	parallel computer;heterogeneous network	This paper describes some recent research on PVM (Parallel Virtual Machine). One of the new features added in PVM 3.0 is multiprocessor integration. This is the ability to run PVM applications on the nodes of several diierent distributed memory multiprocessors as though they constitute one large parallel computer. We describe how multiprocessor integration is accomplished in PVM 3.0 and illustrate its use with examples using some of the parallel computers in ORNL's Center for Computational Science. Several computational Grand Challenge problems are being addressed at Oak Ridge National Laboratory. Two examples are the calculation of the electronic structure of solids from rst principles and groundwater transport. We will report on the use of PVM in the solution of these problems.	computation;computational science;computer;distributed memory;electronic structure;multiprocessing;parallel virtual machine;parallel computing	Jack J. Dongarra;Al Geist;Robert Manchek;Weicheng Jiang	1993			computer architecture;parallel computing;heterogeneous network;computer science;distributed computing	HPC	-7.709956755968449	38.50185627542382	19201
38bf988b9b8744e37b740425efa3e41cb4895ccc	*-box: towards reliability and consistency in dropbox-like file synchronization services	file system;synchronization client;consistent view;deeper knowledge;local file system;dropbox-like file synchronization service;actual state;cloud-based file synchronization service;correct data;local data corruption;file system activity	Cloud-based file synchronization services, such as Dropbox, have never been more popular. They provide excellent reliability and durability in their server-side storage, and can provide a consistent view of their synchronized files across multiple clients. However, the loose coupling of these services and the local file system may, in some cases, turn these benefits into drawbacks. In this paper, we show that these services can silently propagate both local data corruption and the results of inconsistent crash recovery, and cannot guarantee that the data they store reflects the actual state of the disk. We propose techniques to prevent and recover from these problems by reducing the separation between local file systems and synchronization clients, providing clients with deeper knowledge of file system activity and allowing the file system to take advantage of the correct data stored remotely.	dropbox;durability (database systems);file synchronization;loose coupling;microsoft sync framework;server-side	Yupu Zhang;Chris Dragga;Andrea C. Arpaci-Dusseau;Remzi H. Arpaci-Dusseau	2013			self-certifying file system;real-time computing;computer science;stub file;operating system;journaling file system;database;data synchronization;open;file synchronization;file system fragmentation;global namespace	OS	-23.42197493869562	50.969082113504946	19256
b2d8d01995485a8c5baf9e161e0c05b73d9e345b	global adaptation for energy efficiency in multicore architectures	energy efficiency;real time;mixed criticality	Today mixed-criticality systems are used in most industrial domains, because of their integration advantages. They are smaller, weigh less and reduce the idle time of previously dedicated hardware. However, these systems can still be improved. Since their hardware is now used more efficiently it automatically suffers more under the aging effects of heat created by all the simultaneous computations. Heat accelerates the aging process of hardware and increases failure rates. To prevent this the systems need to be cooled down by additional cooling devices like fans. In turn, these devices introduce new failure sources due to their movable parts. In this paper we propose a chip-wide approach to dynamically manage the system's computation and communication to optimize the energy-efficiency. By reducing the energy usage of the system we can reduce the additional hardware and therefore the weight of the whole system. Furthermore, we can prolong the system's lifetime as the available power resource lasts longer. We expand the current usage of tile-based energy management to a system wide scheme by implementing a meta-scheduler, which monitors the system state and changes the schedule if an optimization can be performed. This approach is shown to save up to 48% depending on the slack occurrence in an experimental setup.	algorithm;computation;computer cooling;criticality matrix;dynamical system;failure cause;mathematical optimization;meta-scheduling;mixed criticality;multi-core processor;real-time clock;real-time computing;routing;scheduling (computing);slack variable;vii	Alina Lenz;Tobias Pieper;Roman Obermaisser	2017	2017 25th Euromicro International Conference on Parallel, Distributed and Network-based Processing (PDP)	10.1109/PDP.2017.46	embedded system;parallel computing;real-time computing;simulation;computer science;operating system;distributed computing;efficient energy use	EDA	-5.99340852278062	58.17920029673081	19267
bf3d46d97274972774c1e1a4af9ad2dc3f728d20	high-level adaptive program optimization with adapt	lenguaje programacion;metodo adaptativo;description systeme;evaluation performance;system description;compilateur;performance evaluation;programming language;optimization technique;adaptive programming;perforation;estudio comparativo;evaluacion prestacion;heuristic method;adaptive optimization;dynamic compilation;metodo heuristico;dynamic system;methode adaptative;optimizacion compiladora;compiler;systeme adaptatif;distributed supercomputing;langage adapt;program optimization;langage dedie;etude comparative;timing optimization;clustered wide area systems;adaptive method;compiler optimization;comparative study;adaptive system;domain specific language;langage programmation;sistema adaptativo;optimisation programme;descripcion sistema;runtime system;methode heuristique;domain specic language;performance optimization;optimisation compilateur;compilador;lenguaje dedicado;java;optimizacion programa	Compile-time optimization is often limited by a lack of target machine and input data set knowledge. Without this information, compilers may be forced to make conservative assumptions to preserve correctness and to avoid performance degradation. In order to cope with this lack of information at compile-time, adaptive and dynamic systems can be used to perform optimization at runtime when complete knowledge of input and machine parameters is available. This paper presents a compiler-supported high-level adaptive optimization system. Users describe, in a domain specific language, optimizations performed by stand-alone optimization tools and backend compiler flags, as well as heuristics for applying these optimizations dynamically at runtime. The ADAPT compiler reads these descriptions and generates application-specific runtime systems to apply the heuristics. To facilitate the usage of existing tools and compilers, overheads are minimized by decoupling optimization from execution. Our system, ADAPT, supports a range of paradigms proposed recently, including dynamic compilation, parameterization and runtime sampling. We demonstrate our system by applying several optimization techniques to a suite of benchmarks on two target machines. ADAPT is shown to consistently outperform statically generated executables, improving performance by as much as 70%.	adaptive optimization;benchmark (computing);compile time;compiler;correctness (computer science);coupling (computer programming);domain-specific language;dynamic compilation;dynamical system;elegant degradation;executable;heuristic (computer science);high- and low-level;mathematical optimization;optimization problem;program optimization;run time (program lifecycle phase);sampling (signal processing)	Michael J. Voss;Rudolf Eigenmann	2001		10.1145/379539.379583	adaptive optimization;compiler;parallel computing;real-time computing;dynamic compilation;profile-guided optimization;computer science;domain-specific language;adaptive system;dynamical system;comparative research;program optimization;optimizing compiler;programming language;java;algorithm	PL	-18.928975379256375	36.389429449941666	19269
97e9114d944c881b47493c79dc7ef345b317c7b8	applying p2p strategies to scheduling in decentralized grid computing infrastructures	computational grid;measurement;processor scheduling;grid computing scheduling resource management;resource manager;resource management;load adaptive two tier job exchange strategy;scheduling processor scheduling program processors servers runtime measurement schedules;p2p;runtime;decentralized grid computing infrastructures;servers;large hpc centers p2p strategy decentralized grid computing infrastructures computational grids shaking g video files job scheduling load adaptive two tier job exchange strategy nongrid aware algorithms;scheduling;large hpc centers;schedules;video files;nongrid aware algorithms;computational grids;p2p networks;peer to peer computing;shaking g;grid computing;job scheduling;program processors;p2p strategy;scheduling grid computing peer to peer computing	In this paper, we propose a new algorithm for job interchange in Computational Grids that consist of autonomous and equitable HPC sites, called Shaking-G. Originally developed for balancing the sharing of video files in P2P networks, we conceptually transfer and adapt the algorithm to the domain of job scheduling in Grids, building an integrated, load-adaptive two-tier job exchange strategy. We evaluate the performance of Shaking-G with real workload data in different experimental scenarios and show that it outperforms traditional non-Grid aware algorithms in setups without job interchange, fostering the benefits of collaboration between large HPC centers.	algorithm;autonomous robot;central processing unit;centralized computing;computation;electroconvulsive therapy;grid computing;heuristic;job scheduler;job stream;meta-scheduling;multitier architecture;peer-to-peer;recursion;responsiveness;scheduling (computing);video file format;whole earth 'lectronic link	Christian Grimme;Joachim Lepping;Jonathan Moreno Picon;Alexander Papaspyrou	2010	2010 39th International Conference on Parallel Processing Workshops	10.1109/ICPPW.2010.47	parallel computing;real-time computing;schedule;computer science;resource management;job scheduler;operating system;peer-to-peer;distributed computing;scheduling;grid computing;server;measurement	HPC	-19.664042503680125	60.414764148386254	19271
cbadcc73ec06cd8aeaac755d9a5c0cf05400253d	a vectorization technique for prolog without explosion	perforation;intermediate language;logic programs;vector processor	Tbis paper describ四 a t�chnique for executing logic prog日mming languages such 回目。 log for the Cray-type vector proce騎O悶 Th国 民chnique, which we call the parnflel backtrack­ ing tuhnique, enables a kind of or-parallel ex ecution witho叫proc国s expl個ωn. The com piled intermediate language code for the par­ allel backtracking execution出the same 回tbe code presented in our previous paper. The corrト pilation is based on a kind of program trans­ f。町nation called or-vedorization. However, the interpretation of tbe intermediate code Îs ch&Ilged to enable the paraHel back色racking ex­ ec:ution. An execution simulator and a com­ piler pro凶ype were develope<l. We bave no色 yet imple官官nted出師同chnÎque to our n剖... code execution system, but we exp田t a. perfor. mance of創gbt tim四or more high町出a.n Sl:alar proc邑sing upon implementa.tion	automatic vectorization;backtracking;language code;prolog	Yasusi Kanada;Masahiro Sugaya	1989			computer architecture;vector processor;parallel computing;computer science;programming language;intermediate language	PL	-16.52586741682199	35.24847365666178	19353
9220eabfb5433cc4009d1314198ab7bc63bcc48f	energy efficient program updating for sensor nodes with flash memory	flash memory;resource constraint;energy efficient;wireless sensor network;operating system;sensor nodes;sensor operating systems;wireless sensor networks;energy efficient program updating	Updating sensor node programs is an essential task for maintaining stability and modifying the characteristics of wireless sensor networks. The updating mechanism must consider energy and memory efficiency, because of resource constraints of sensor nodes. In this paper, we propose a novel program updating mechanism, which considers resource constraints of sensor nodes. The proposed mechanism was designed for sensor nodes with the NOR flash memory. This is generally used to store program image. It was designed to minimize the number of flash write/erase operations, which consume a great deal of energy, and to provide wear-leveling for the NOR flash memory. We set a function as the basic unit of program updating, and partition a function into fixed-sized blocks that can be separately relocated in memory. Experimental results show that the proposed mechanism outperforms other mechanisms in terms of energy, memory and wear-leveling for flash memory.	executable;flash memory;sensor node;wear leveling	Junyoung Heo;Boncheol Gu;Sang Il Eo;Pankoo Kim;Gwangil Jeon	2010		10.1145/1774088.1774128	embedded system;interleaved memory;parallel computing;real-time computing;wireless sensor network;sensor node;computer science;operating system;key distribution in wireless sensor networks;mobile wireless sensor network	AI	-10.194192990673153	55.191601632519735	19430
109b2b66d2938d722ff6cc807cc261b9110245e5	efficient incremental garbage collection for client-server object database systems	client-server object database systems;efficient incremental garbage collection;fault tolerant;client server;garbage collection	We describe an eficient server-based algorithm for garbage collecting object-oriented databases in a client/server environment. The algorithm is incremental and runs concurrently with client transactions. Unlike previous algorithms, it does not hold any locks on data and does not require callbacks to clients. It is fault tolerant, but performs very little logging. The algorithm has been designed to be integrated into existing OODB systems, and therefore it works with standard implementation techniques such as two-phase locking and writeahead-logging. In addition, it supports client-server performance optimizations such as client caching and flexible management of client buffers. We describe an implementation of the algorithm in the EXODUS storage manager and present results from an initial performance study.	algorithm;callback (computer programming);client–server model;concurrency (computer science);database;exodus;fault tolerance;garbage collection (computer science);lock (computer science);server (computing);two-phase locking;write-ahead logging	Laurent Amsaleg;Michael J. Franklin;Olivier Gruber	1995			manual memory management;fault tolerance;database server;database tuning;computer science;operating system;database;distributed computing;garbage collection;programming language;database design;client–server model	DB	-20.715840295749892	48.05366208747521	19482
8c40dfbd645936d4743da10c8bb75db291e0657a	a scalable version control layer in p2p file system	p2p system;distributed system;sistema operativo;evaluation performance;crash failure;haute performance;systeme reparti;mise a jour;performance evaluation;peer to peer network;averia franca;gestion archivos;par a par;evaluacion prestacion;distributed computing;gestion fichier;p2p;file management;actualizacion;grid;resolucion problema;sistema repartido;poste a poste;operating system;rejilla;file system;alto rendimiento;grille;calculo repartido;systeme exploitation;panne franche;version control;peer to peer;high performance;calcul reparti;updating;problem solving;resolution probleme	Challenges revealed in constructing a peer-to-peer (P2P) file system are due to the difficulties of version control.There have appeared no P2P systems, which can solve these problems smoothly. In this paper we show our efforts towards solving the problems by developing a new application, SVCL (a Scalable Version Control Layer in P2P file system), in which version control servers are woven into a peer-to-peer network so that the system will not crash under single node failure. As a result, users can carry out both file updating and reading operations. Experiments have demonstrated the high performance of the proposed system.	version control	Xin Lin;Shanping Li;Wei Shi;Jie Teng	2005		10.1007/11590354_121	self-certifying file system;embedded system;torrent file;device file;computer science;revision control;stub file;versioning file system;operating system;unix file types;ssh file transfer protocol;journaling file system;peer-to-peer;distributed computing;open;distributed file system;file system fragmentation;grid;file control block	Robotics	-19.469956812373592	44.58308926220414	19521
86934c0be9472fb957334fd300e52aaf224b63b5	simulation of particle mixing by turbulent convective flows on the connection machine	flow simulation;parallel processing;partial differential equations;physics computing;turbulence;cm-200;cray;connection machine;chaotic flow fields;high-speed hippi channel;local memory;nonlinear system;partial differential equations;particle mixing simulation;time-dependent flow field;turbulent convective flows;turbulent thermal convection	Mixing of particles by chaotic jlow fields was simula(ed on (he Connection 14achine. We assigned each cell to the processor and kept [he coordinates ofpar(icles residing on the cell in the local memory of the processor. This approach implies the exchange between the local memories, when a particle moves from one cell (o another. Approximately I@ particles were injected iruo a time-dependenlflow jield obtained by solving the nonlinear system of PDEs, describing turbuleru thermal convection. The flow field was calculated on CRAY and data were transferred to CM-200 lhrough high-speed HIPP1 channel.	connection machine;nonlinear system;simulation;turbulence	Andrei V. Malevsky;David A. Yuen;Kirk E. Jordan	1992			turbulence;parallel computing;simulation;nonlinear system;computer science;theoretical computer science;partial differential equation	HPC	-6.0080606942138255	36.70600749412179	19567
857bd838e80e3dd02a6ee089ee98cf4b98e5a283	combining lattice boltzmann and discrete element methods on a graphics processor	scientific application;programming language;linear complexity;programming model;cuda;gpgpu;graphics processors;lattice boltzmann method;lbm;lattice boltzmann;discrete element method;dem	The current generation of graphics cards allows great flexibility in programming. With the introduction of general purpose programming languages for graphics cards, many fields of scientific application will benefit greatly from adapting to this new programming model. Due to the differences in the memory and execution models, not all algorithms can be applied. However, the lattice Boltzmann method can be used to great effect. It allows the simulation of fluids using basic arithmetic operations with a linear complexity, as will be demonstrated. Additionally, the discrete element method can also be adapted to the new model. After outlining the methods themselves and the integration of these two methods into a single simulation, this article will show a way to implement it on graphics cards using the CUDA platform.	graphics processing unit;lattice boltzmann methods	Andreas Monitzer	2012	IJHPCA	10.1177/1094342012442423	computational science;parallel computing;computer science;theoretical computer science;lattice boltzmann methods;programming language;general-purpose computing on graphics processing units	Theory	-6.7216668698093125	37.473778715939865	19578
8a07942bc1455e4963de45750a0ce8c616514d25	sky computing	internet;economies of scale;socio economic effects	Infrastructure-as-a-service (IaaS) cloud computing is revolutionizing how we approach computing. Compute resource consumers can eliminate the expense inherent in acquiring, managing, and operating IT infrastructure and instead lease resources on a pay-as-you-go basis. IT infrastructure providers can exploit economies of scale to mitigate the cost of buying and operating resources and avoid the complexity required to manage multiple customer-specific environments and applications. The authors describe the context in which cloud computing arose, discuss its current strengths and shortcomings, and point to an emerging computing pattern it enables that they call sky computing.	cloud computing	Katarzyna Keahey;Maurício O. Tsugawa;Andréa M. Matsunaga;José A. B. Fortes	2009	IEEE Internet Computing	10.1109/MIC.2009.94	the internet;simulation;computer science;economies of scale;end-user computing;database;distributed computing;management science;utility computing;law;world wide web;computer security	HPC	-28.976542210922272	58.37396696031259	19583
88f3effece3ad68787b025025071110c88c19bc6	parallelization of sequential gaussian, indicator and direct simulation algorithms	computadora;tratamiento datos;computers;maps;software;correlacion;geostatistique;geoestadistica;flow;probability;performance test;mapa;indicateur;ecoulement;logiciel;krigeage;sequential gaussian simulation;ordinateur;indicators;performance;simulacion numerica;suelo;fluid flow;data processing;geostatistics;estrategia;traitement donnee;correction;sol;carte;algorithme;strategy;corrections;simulation software;modelo;soils;parallel computer architecture;direct sequential simulation;inverse modelling;probabilidad;simulation numerique;sequential indicator simulation;probabilite;correccion;algorithms;computer application;source code;modele;performances;c programming language;correlation;polucion;kriging;strategie;high performance;models;parallel processing;digital simulation;open source;algoritmo;pollution	Improving the performance and robustness of algorithms on new high-performance parallel computing architectures is a key issue in efficiently performing 2D and 3D studies with large amount of data. In geostatistics, sequential simulation algorithms are good candidates for parallelization. When compared with other computational applications in geosciences (such as fluid flow simulators), sequential simulation software is not extremely computationally intensive, but parallelization can make it more efficient and creates alternatives for its integration in inverse modelling approaches. This paper describes the implementation and benchmarking of a parallel version of the three classic sequential simulation algorithms: direct sequential simulation (DSS), sequential indicator simulation (SIS) and sequential Gaussian simulation (SGS). For this purpose, the source used was GSLIB, but the entire code was extensively modified to take into account the parallelization approach and was also rewritten in the C programming language. The paper also explains in detail the parallelization strategy and the main modifications. Regarding the integration of secondary information, the DSS algorithm is able to perform simple kriging with local means, kriging with an external drift and collocated cokriging with both local and global correlations. SIS includes a local correction of probabilities. Finally, a brief comparison is presented of simulation results using one, two and four processors. All performance tests were carried out on 2D soil data samples. The source code is completely open source and easy to read. It should be noted that the code is only fully compatible with Microsoft Visual C and should be adapted for other systems/compilers. & 2010 Elsevier Ltd. All rights reserved.	3d modeling;algorithm;central processing unit;compiler;computation;dssim;direct numerical simulation;kriging;open-source software;parallel computing;pivot table;simulation software;speedup;strong generating set;the c programming language;time complexity	Ruben Nunes;José A. Almeida	2010	Computers & Geosciences	10.1016/j.cageo.2010.03.005	parallel processing;simulation;data processing;performance;computer science;theoretical computer science;machine learning;mathematics;algorithm;statistics;automatic parallelization;geostatistics	AI	-4.963758776088455	35.166024590979234	19586
b2e80afe089ecf4aa7e9391c960fd4db2bc4f578	the role of software architecture in configuring middleware: the scalagent experience	performance measure;distributed system;oriente message;systeme reparti;architecture description language;functional properties;logicial personalizado;customization;message oriented;personnalisation;orientado mensaje;intergiciel;message oriented middleware;software architecture;sistema repartido;lenguaje descripcion;personalizacion;middleware;information system;systeme information;architecture logiciel;langage description;sistema informacion;description language	Middleware has emerged as an important architectural component in modern distributed systems. It provides many solutions allowing to hide the management of the distribution of services and computations to the developers. However, its configuration becomes more and more complex, since it must fit application requirements, while adapting to the underlying system capacities. In this paper we propose a customization tool to automate the configuration of the ScalAgent messageoriented middleware. The tool uses the application description (into an Architecture Description Language) to determine and configure the set of middleware modules required to ensure non-functional properties required by the application. It is controlled by an algorithm that tries to minimize some non-functional property management costs. Our performance measurements clearly show the customization advantages. keywords: Middleware, architecture description languages, configuration, components.	algorithm;architecture description language;coherence (physics);component-based software engineering;computation;distributed computing;functional requirement;interdependence;message-oriented middleware;mobile device;non-functional requirement;server (computing);software architecture;software development	Vivien Quéma;Emmanuel Cecchet	2003		10.1007/978-3-540-27860-3_13	embedded system;software architecture;middleware;architecture description language;real-time computing;computer science;message oriented middleware;operating system;middleware;distributed computing;programming language;information system	SE	-28.932236955296343	42.30133088214702	19611
27548f04e01f84c7db8bdd6d6e490ad589abc06e	custom computer architectures for logic programming			computer architecture;logic programming	Andreas Kirkeby Fidjeland	2007				Arch	-10.42215140632653	33.9849659876243	19629
02a66c148057e4867691345a002875ba02ccc31e	a high performance inter-domain communication approach for virtual machines	inter vm communication;virtualization;overhead;journal;communication path	Highlights? Presented a novel inter-domain communication approach (IVCOM) for virtual machine. ? Using bypassing protocol stacks, shunning page flipping methods. ? IVCOM applies a direct communication channel between domain 0 and U. ? IVOCM can improve the latency and throughput in para-virtualized environment. ? IVCOM can greatly reduce the VM entry/exit operations. In virtualization technology field, researches mainly focus on strengthening the isolation barrier between virtual machines (VMs) that are co-resident within a single physical machine. At the same time, there are many kinds of distributed communication-intensive applications such as web services, transaction processing, graphics rendering and high performance grid applications, which need to communicate with other virtual machines at the same platform. Unfortunately, current inter-VM communication method cannot adequately satisfy the requirement of such applications. In this paper, we present the design and implementation of a high performance inter-VM communication method called IVCOM based on Xen virtual machine environment. In para-virtualization, IVCOM achieves high performance by bypassing some protocol stacks and privileged domain, shunning page flipping and providing a direct and high-performance communication path between VMs residing in the same physical machine. But in full-virtualization, IVCOM applies a direct communication channel between domain 0 and Hardware Virtualization based VM (HV2M) and can greatly reduce the VM entry/exit operations, which has improved the HV2M performance. In the evaluation of para-virtualization consisting of a few of benchmarks, we observe that IVCOM can reduce the inter-VM round trip latency by 70% and increase throughput by up to 3 times, which prove the efficiency of IVCOM in para-virtualized environment. In the full-virtualized one, IVCOM can reduce 90% VMX transition operations in the communication between domain 0 and HV2M.	inter-domain;inter-process communication;virtual machine	Yuebin Bai;Yao Ma;Cheng Luo;Duo Lv;Yuanfeng Peng	2013	Journal of Systems and Software	10.1016/j.jss.2012.08.054	embedded system;full virtualization;real-time computing;virtualization;computer science;virtual machine;operating system;hardware virtualization;overhead	OS	-16.759663128705878	51.37945814408946	19672
d78984bc52ee89f21ba479f7979038f1d86691da	service component architecture for vending machine system in cloud computing infrastructure	retail data processing;virtual software integration model;cloud computing service component architecture vending industry;software integration;component architectures cloud computing computer industry service oriented architecture application software ip networks computer architecture costs machinery production industries distributed computing;vending machines;resource allocation;service component architecture;integrable system;cloud computing infrastructure;loading;industries;vending industry;object oriented programming;innovative service establishment;scaling up;web services object oriented programming resource allocation retail data processing vending machines;smart store;system stability;servers;distributed environment;product optimization;web services;experiential shopping environment;location based shopping service;crawlers;vending machine system;retail domain;system scalability;development cost reduction;meteorology;service over loading;system scalability service component architecture vending machine system cloud computing infrastructure virtual software integration model vending industry development cost reduction innovative service establishment experiential shopping environment retail domain service over loading distributed environment smart store location based shopping service personal service product optimization system stability;personal service;cloud computing;component architectures	This paper proposes a software integration model of service component architecture in the vending industry. We use this architecture to rapidly integrate related services, substantially reduce development costs, establish innovative services, and provide consumers with a brand new experiential shopping environment in retail domain. Meanwhile, we apply a cloud computing technology to solve the following problem: service over loading in a distributed environment. We also discover many issues that will happen with system scaling up in smart store, such as virtual integration, location-based shopping service, personal services, and product optimization. Therefore we use cloud computing to solve these discussed issues. Finally, this paper gives two services as an example to be implemented in the vending industry. The research provides a cloud-based integration system that composes other services easily. The results of this research can increase development speed, and decrease poorly-done work over again and time consumption. It also makes allowance for system stability and scalability.	cloud computing;cloud-based integration;component-based software engineering;development speed;distributed shared memory;function overloading;image scaling;mathematical optimization;scalability;server (computing);service component architecture;system integration;web crawler	Feng-Cheng Lin;Yi-Shiou Lee;Chih Hao Hsu;Kuan Yu Chen;Tzu-Chun Weng	2009	2009 IEEE International Conference on e-Business Engineering	10.1109/ICEBE.2009.93	web service;embedded system;integrable system;simulation;cloud computing;resource allocation;computer science;marketing;operating system;software engineering;database;services computing;object-oriented programming;law;world wide web;computer security;server;distributed computing environment;system integration	Robotics	-33.325989303152085	54.78958392954674	19676
9bd7a5ddec5d570d97b9198550318e3b01768a4b	the r-link tree: a recoverable index structure for spatial data	spatial data;index structure	So far, R-trees have been investigated for use in the single-user environment. We use the link technique proposed by Kung and Lehman to support concurrent operations (search, insert, and delete) on an R-tree. We present algorithms for implementing these operations, and also discuss recovery issues in case of failure.	schedule (computer science)	Vincent T. Y. Ng;Tiko Kameda	1994		10.1007/3-540-58435-8_181	computer science;spatial analysis	DB	-20.1515726648729	47.62583609185158	19723
3f15f150ad36ab1c276c60b585547fef02d2aede	energy-efficient dynamic scheduling on parallel machines	energy efficient;energy requirement;worst case execution time;computing resource management;energy consumption;parallel machines;energy minimization;open framework;real time computing;dynamic scheduling	Energy consumption is a critical issue in parallel and distributedsystems. Workflows consist of a number of tasks that need to be executed tocomplete an application. These tasks typically have precedence relationshipsthat have to be observed during execution for correctness. DAGs (DirectedAcyclic Graphs) can be used to represent many such workflows. The staticalgorithms to schedule for energy minimization under the deadline constraintsare based on estimating worst case execution time for each task to guaranteethat the application completes by a given deadline. During execution, manytasks may complete earlier than expected during the actual execution. Thisallows for adjusting the schedule for the tasks that have not yet begun executionto incorporate the extra slack. This has to be done with the dual goal ofreducing the energy requirements while still meeting the deadline constraints. Inthis paper, we present a novel dynamic algorithm for remapping tasks forenergy efficient scheduling of DAG based applications for DVS enabledsystems. Our experimental results show that the combination of our dynamicassignment and dynamic slack allocation leads to significantly better energyminimization compared to not changing the static schedule and/or onlyperforming dynamic slack allocation. Furthermore, its execution timerequirements are small enough to be useful for a large number of applications.	algorithm;best, worst and average case;correctness (computer science);directed acyclic graph;dynamic problem (algorithms);dynamic voltage scaling;energy minimization;parallel computing;requirement;run time (program lifecycle phase);scheduling (computing);serializability;slack variable;worst-case execution time	Jaeyeon Kang;Sanjay Ranka	2008		10.1007/978-3-540-89894-8_21	parallel computing;real-time computing;dynamic priority scheduling;computer science;operating system;distributed computing;efficient energy use;least slack time scheduling;energy minimization;worst-case execution time	Embedded	-6.161248811392308	59.049832689478876	19727
3609a17555a6c6757f8ff0297fc046e6dc623a57	iorchestrator: improving the performance of multi-node i/o systems via inter-server coordination	file servers;kernel;electronic mail;storage system;input output programs;performance;and pvfs2;parallel programming;asynchronous requests;iorchestrator;hard disks;layout;usa councils;pvfs2 parallel file system;i o parallelism parallel file systems;program spatial locality;servers;multinode i o systems;synchronization;servers synchronization hard disks layout usa councils kernel electronic mail;parallel programming file servers input output programs;multinode storage systems;parallel file system;pvfs2 parallel file system iorchestrator multinode i o systems high throughput i o service parallel programs i o parallelism parallel file systems asynchronous requests program spatial locality multiple i o intensive programs multinode storage systems inter data server coordination;benchmarks;computer codes;high throughput i o service;cost effectiveness;synchronous requests;spatial locality;high throughput;inter data server coordination;parallel programs;programming;multiple i o intensive programs;parallel processing	A cluster of data servers and a parallel file system are often used to provide high-throughput I/O service to parallel programs running on a compute cluster. To exploit I/O parallelism parallel file systems stripe file data across the data servers. While this practice is effective in serving asynchronous requests, it may break individual program's spatial locality, which can seriously degrade I/O performance when the data servers concurrently serve synchronous requests from multiple I/O-intensive programs. In this paper we propose a scheme, IOrchestrator, to improve I/O performance of multi-node storage systems by orchestrating I/O services among programs when such inter-data-server coordination is dynamically determined to be cost effective. We have implemented IOrchestrator in the PVFS2 parallel file system. Our experiments with representative parallel benchmarks show that IOrchestrator can significantly improve I/O performance-- by up to a factor of 2.5--delivered by a cluster of data servers servicing concurrently-running parallel programs. Notably, we have not observed any scenarios in which the use of IOrchestrator causes substantial performance degradation.	clustered file system;data striping;elegant degradation;experiment;high-throughput computing;input/output;inter-server;locality of reference;parallel virtual file system;parallel computing;principle of locality;server (computing);throughput	Xuechen Zhang;Kei Davis;Song Jiang	2010	2010 ACM/IEEE International Conference for High Performance Computing, Networking, Storage and Analysis	10.1109/SC.2010.30	high-throughput screening;layout;file server;parallel processing;synchronization;programming;parallel computing;kernel;real-time computing;cost-effectiveness analysis;performance;computer science;operating system;distributed computing;server	HPC	-14.336853848500699	50.740805326562324	19746
9d780b2457f9d17a43bf399d958c8e4b8ddaaae3	survey of bigdata-as-a-service type	cyberspace;high performance computing;service type big data cloud computing big data as a service bdaas;cascading style sheets;service type;big data;safety;big data as a service bdaas;conferences high performance computing cyberspace safety security cascading style sheets embedded software;security;conferences;embedded software;cloud computing	Big Data is used to find new value and brings us several benefits, which we didn't know before. Various analytics has been studied in Big Data area for benefits. Moreover, to reduce analysis time and to support real-time service to user, distributed processing can be an alternative solution. Big Data also requires high performance resource for distributed analysis, for this reason, Big Data and Cloud Computing seem to be naturally combined-called Cloud-based Big Data. However, Cloud-based Big Data had no criteria to evaluation. Also, it is hard to decide which Cloud-based Big data is well designed and how much resource should be provided to provide qualitied Cloud-based Big data service. Hence, in this paper, we surveyed enterprises and their product and then, deduct criteria to classify and evaluate Cloud-based Big Data service.	big data;cloud computing;distributed computing;real-time clock	Yunkon Kim;Yong-Hyun Kim;Ga-Won Lee;Eui-nam Huh	2015	2015 IEEE 17th International Conference on High Performance Computing and Communications, 2015 IEEE 7th International Symposium on Cyberspace Safety and Security, and 2015 IEEE 12th International Conference on Embedded Software and Systems	10.1109/HPCC-CSS-ICESS.2015.279	cloud computing security;big data;embedded software;cloud computing;computer science;information security;operating system;database;internet privacy;cascading style sheets;world wide web;computer security	Embedded	-29.262555736931752	58.07208862450597	19779
59f694f81777df302530fc6856a3581aa9b0a296	scalable behavioral emulation of extreme-scale systems using structural simulation toolkit		With extremely large design spaces for algorithm and architecture to be explored, there is a need for fast and scalable performance modeling tools for preparing HPC application codes. Behavioral Emulation (BE) is a recent coarse-grained modeling and simulation methodology that has been proposed to solve this co-design problem. In this paper, we introduce a distributed parallel simulation library for Behavioral Emulation called BE-SST, integrated into the Structural Simulation Toolkit (SST). BE-SST provides simple interfaces and framework for development of coarse-grained BE models which can be extended to model new notional architectures. BE-SST also supports Monte Carlo simulations to generate meaningful distributions and summary statistics rather than a single datum for performance. In this paper, we present BE-SST simulations of two existing large DOE machines (Vulcan and Titan), which have been validated against actual testbed measurements and showed 5-10% error. These validated system models (up to 128k cores) are used to make blind predictions of application performance on systems larger than the current machines (up to 512k cores) - a crucial simulator feature for design-space exploration of notional systems. We further studied BE-SST in terms of scalability and performance, simulating up to a million cores, with BE-SST running on more than 2k parallel processes. BE-SST shows good scalability with a linear increase in memory usage and simulation time with increase in simulated system size, and a peak speedup of 7x over single process simulation. With ease of use and good scaling, we assert that BE-SST can significantly speed up design-space exploration.	algorithm;analysis of algorithms;code;computation;emulator;experiment;geodetic datum;ibm websphere extreme scale;image scaling;mathematical optimization;mean squared error;monte carlo method;moose file system;performance prediction;run time (program lifecycle phase);scalability;simulation;software transactional memory;speedup;symbolic regression;testbed;time complexity;titan;usability;dbase	Ajay Ramaswamy;Nalini Kumar;Aravind Neelakantan;Herman Lam;Greg Stitt	2018		10.1145/3225058.3225124	parallel computing;virtual prototyping;architecture;monte carlo method;speedup;scalability;process simulation;testbed;computer science;modeling and simulation	HPC	-5.299064687715087	45.09549996258573	19787
5b254780f88700b11bf6d1ee44f0fd0cce0f00c3	a sequentially consistent multiprocessor architecture for out-of-order retirement of instructions	multiprocessor interconnection networks;cache storage;registers retirement out of order multicore processing pipelines;sequential consistency;multiprocessor systems;processor scheduling;articulo;buffer storage;rob size sequentially consistent multiprocessor architecture instructions out of order retirement in flight instructions runtime scheduling head of line blocking effects reorder buffer instruction window strict memory model instruction execution memory latencies validation buffer architecture vb architecture out of order retirement multiprocessor sequential consistency memory hierarchy memory interconnection;out of order;out of order retirement;validation buffer;head of line;registers;memory architecture;multiprocessor architecture;multicore processing;pipelines;cost effectiveness;sequential consistency out of order retirement multicore processors validation buffer;multicore processors;memory hierarchy;retirement;processor scheduling buffer storage cache storage instruction sets memory architecture multiprocessor interconnection networks pipeline processing;pipeline processing;memory latency;instruction sets;memory model	Out-of-order retirement of instructions has been shown to be an effective technique to increase the number of in-flight instructions. This form of runtime scheduling can reduce pipeline stalls caused by head-of-line blocking effects in the reorder buffer (ROB). Expanding the width of the instruction window can be highly beneficial to multiprocessors that implement a strict memory model, especially when both loads and stores encounter long latencies due to cache misses, and whose stalls must be overlapped with instruction execution to overcome the memory latencies. Based on the Validation Buffer (VB) architecture (a previously proposed out-of-order retirement, checkpoint-free architecture for single processors), this paper proposes a cost-effective, scalable, out-of-order retirement multiprocessor, capable of enforcing sequential consistency without impacting the design of the memory hierarchy or interconnect. Our simulation results indicate that utilizing a VB can speed up both relaxed and sequentially consistent in-order retirement in future multiprocessor systems by between 3 and 20 percent, depending on the ROB size.	blocking (computing);cpu cache;central processing unit;centralized computing;coexist (image);instruction pipelining;instruction window;linear programming relaxation;memory hierarchy;memory model (programming);multiprocessing;operand;order by;pipeline (computing);re-order buffer;register file;register renaming;release consistency;scalability;scheduling (computing);sequential consistency;simulation;speaker wire;speculative execution;transaction processing system	Rafael Ubal;Julio Sahuquillo;Salvador Petit;Pedro López;David R. Kaeli	2012	IEEE Transactions on Parallel and Distributed Systems	10.1109/TPDS.2011.255	multi-core processor;computer architecture;parallel computing;real-time computing;computer science;operating system	Arch	-8.956384846270575	51.58432923976595	19792
5288484cd0f6689bedeebc87d0f2534e325e8c55	monitoring energy consumption with siox	monitoring;energy consumption;parallel i o;optimization;analysis	In the face of the growing complexity of HPC systems, their growing energy costs, and the increasing difficulty to run applications efficiently, a number of monitoring tools have been developed during the last years. SIOX  is one such endeavor, with a uniquely holistic approach: Not only does it aim to record a certain kind of data, but to make all relevant data available for analysis and optimization. Among other sources, this encompasses data from hardware energy counters and trace data from different hardware/software layers. However, not all data that can be recorded should be recorded. As such, SIOX  needs good heuristics to determine when and what data needs to be collected, and the energy consumption can provide an important signal about when the system is in a state that deserves closer attention. In this paper, we show that SIOX  can use Likwid to collect and report the energy consumption of applications, and present how this data can be visualized using SIOX’s web-interface. Furthermore, we outline how SIOX  can use this information to intelligently adjust the amount of data it collects, allowing it to reduce the monitoring overhead while still providing complete information about critical situations.	algorithm;heuristic (computer science);holism;mathematical optimization;overhead (computing);sim lock;supercomputer;system administrator;user interface	Julian M. Kunkel;Alvaro Aguilera;Nathanael Hübbe;Marc C. Wiedemann;Michaela Zimmer	2014	Computer Science - Research and Development	10.1007/s00450-014-0271-y	embedded system;mathematical optimization;real-time computing;computer science;operating system;analysis;data mining	HPC	-22.480686482597662	55.88238469232623	19878
05f472daf1c75420bb3f597a578280f7d047c753	towards a quality of service aware public computing utility	public information systems;p2p;client server systems;distributed shared memory systems;community based decentralized resource management system quality of service public computing utility shared public resources dedicated resources peer to peer computing grid computing utility based computing environment p2p overlay substrate;peer to peer computing;quality of service;open systems;peer to peer;grid computing;resource management system;distributed shared memory systems grid computing public information systems peer to peer computing client server systems quality of service open systems;quality of service grid computing computer architecture radio access networks peer to peer computing resource management distributed computing costs switches joining processes	This work describes a design for a quality of service aware public computing utility (PCU). The goal of the PCU is to utilize the idle capacity of the shared public resources and augment the capacity with dedicated resources as necessary, to provide high quality of service to the clients at the least cost. Our PCU design combines peer-to-peer (P2P) and grid computing ideas in a novel manner to construct a utility-based computing environment. In This work, we present the overall architecture and describe two major components: a P2P overlay substrate for connecting the resources in a global network and a community-based decentralized resource management system.	display resolution;global network;grid computing;peer-to-peer;programming paradigm;quality of service;trust management (information system);utility computing	Muthucumaru Maheswaran;Balasubramaneyam Maniymaran;Shah Asaduzzaman;Arindam Mitra	2004	Third IEEE International Symposium on Network Computing and Applications, 2004. (NCA 2004). Proceedings.	10.1109/NCA.2004.1347804	quality of service;cloud computing;computer science;end-user computing;peer-to-peer;database;distributed computing;utility computing;open system;world wide web;grid computing;computer network;autonomic computing	HPC	-26.298212276209004	56.99355991093874	19905
aec1bf64cacef66d178d3b49be9dbf115f55edf5	message-passing primitives for multimicroprocessor systems	microsystems;message passing;multiprocess structuring	Concurrent and distributed processing systems based on multiple microprocessors are both feasible and desirable. Processes residing on different processors execute in parallel while processes allocated on the same processor execute in a multiprogramming environment. These processes normally have to communicate and synchronize in order to achieve a common goal. Communication and synchronization are usually achieved by calling primitives supplied by a kernel. The paper describes a model of implementation for message-passing primitives which must be added to a single-processor kernel for communication and synchronization purposes in multimicroprocessor systems.		Kam-Wing Ng	1986	Microprocessors and Microsystems - Embedded Hardware Design	10.1016/0141-9331(86)90096-7	embedded system;parallel computing;message passing;real-time computing;computer science;microsystem;operating system;distributed computing;programming language	EDA	-31.6869878689153	38.25912442772426	19999
9b598eddc7edf81adc90a9fd150d22d1377160ae	event stream processing with multiple threads		Current runtime verification tools seldom make use of multi-threading to speed up the evaluation of a property on a large event trace. In this paper, we present an extension to the BeepBeep 3 event stream engine that allows the use of multiple threads during the evaluation of a query. Various parallelization strategies are presented and described on simple examples. The implementation of these strategies is then evaluated empirically on a sample of problems. Compared to the previous, single-threaded version of the BeepBeep engine, the allocation of just a few threads to specific portions of a query provides dramatic improvement in terms of running time.	event stream processing;parallel computing;runtime verification;thread (computing);time complexity	Sylvain Hallé;Raphaël Khoury;Sébastien Gaboury	2017		10.1007/978-3-319-67531-2_22	throughput;distributed computing;computer science;thread (computing);event stream processing	PL	-12.827335444487701	47.91981297827033	20003
576229cdded784a1fa188c5d3f01eebeef943bee	iteration aware prefetching for large multidimensional datasets	iteration aware prefetching;large multidimensional datasets		iteration;link prefetching	Philip J. Rhodes;Xuan Tang;R. Daniel Bergeron;Ted M. Sparr	2005			computer science;data mining	HPC	-14.61161629632483	54.371173044622566	20033
067b7f06fdaa1aceeb3fff534fd1f2649303922f	demand-driven alias analysis for c	developpement logiciel;lenguaje programacion;gestion memoire;demand driven analysis;reachability;compilateur;alias analysis;algorithm analysis;programming language;structure programme;pointer analysis;programming environment;storage management;interrogation base donnee;milisegundo;interrogacion base datos;program understanding tools;a la volee;compiler;desambiguisacion;milliseconde;medio ambiente programacion;integrated development environment;gestion memoria;marcador;estructura programa;pointer;cfl reachability;desarrollo logicial;asequibilidad;software development;disambiguation;memory disambiguation;on the fly;langage programmation;atteignabilite;pointeur;algorithms;analyse algorithme;technical report;al vuelo;computer science;desambiguisation;discriminacion;program structure;languages;database query;millisecond;analisis algoritmo;compilador;discrimination;environnement programmation;programming languages;points to analysis	This paper presents a demand-driven, flow-insensitive analysisalgorithm for answering may-alias queries. We formulate thecomputation of alias queries as a CFL-reachability problem, and use this formulation to derive a demand-driven analysis algorithm. The analysis uses a worklist algorithm that gradually explores the program structure and stops as soon as enough evidence is gathered to answer the query. Unlike existing techniques, our approach does not require building or intersecting points-to sets.  Experiments show that our technique is effective at answering alias queries accurately and efficiently in a demand-driven fashion. For a set of alias queries from the SPEC2000 benchmarks, an implementation of our analysis is able to accurately answer 96% of the queries in 0.5 milliseconds per query on average, using only 65 KB of memory. Compared to a demand-driven points-to analysis that constructs and intersects points-to sets on the fly, our alias analysis can achieve better accuracy while running more than 30 times faster. The low run-time cost and low memory demands of the analysis make it a very good candidate not only for compilers, but also for interactive tools, such as program understanding tools or integrated development environments (IDEs).	algorithm;alias analysis;compiler;courant–friedrichs–lewy condition;experiment;information retrieval;integrated development environment;on the fly;pointer analysis;program comprehension;reachability problem;structured programming	Xin Zheng;Radu Rugina	2008		10.1145/1328438.1328464	compiler;discrimination;pointer;alias analysis;millisecond;computer science;technical report;theoretical computer science;software development;database;programming language;reachability;pointer analysis;alias;algorithm	PL	-19.05405346380593	34.40486773377828	20091
f5df3bb908244aa6b3885ec10be6ef2e19a331e9	making the grid predictable through reservations and performance modelling	performance modelling	Unpredictable job execution environments pose a significant barrier to the widespread adoption of the Grid paradigm, because of the innate risk of jobs failing to execute at the time specified by the user. We demonstrate that predictability can be enhanced with a supporting infrastructure consisting of three parts: Performance modelling and monitoring, scheduling which exploits application structure and an advanced reservation resource management service. We prove theoretically that execution times using advanced reservations display less variance than those without. We also show that the costs of advanced reservations can be reduced by providing the system with more accurate performance models. Following the theoretical discussion, we describe the implementation of a fully functional workflow enactment framework that supports advanced reservations and performance modelling thereby providing predictable execution behavior. We further provide experimental results confirming our theoretical models.	exploit (computer security);failure;job stream;middleware;programming paradigm;runtime system;scheduling (computing);trinity	A. Stephen McGough;Ali Afzal;John Darlington;Nathalie Furmento;Anthony Edward Mayer;Laurie Robert Young	2005	Comput. J.	10.1093/comjnl/bxh091	real-time computing;simulation;computer science;operating system	HPC	-22.36388253372099	57.951868701427706	20100
b8385f5a9c90328d8f43a07d0e5cf31ef16d4731	addressing the challenges of future large-scale many-core architectures	operating system scheduler;adaptive thread scheduling;execution phases	Current processor trends show an increasing number of cores and a diversity of characteristics among them. Such processors offer a large potential for achieving high performance for different applications. Nevertheless, exploiting the characteristics of such processors is a challenge. In particular, considering all cores to be the same for scheduling tasks is not valid any longer. In this work we address three important characteristics for future many-core processors: (1) a many-core processor will include groups of different cores, (2) the latency to access off-chip memory will be larger for cores further from the on-chip memory controller and (3) as the number of cores per memory controller increases so does the pressure regarding the off-chip access bandwidth. To address these issues we propose a task assignment policy that monitors the demands of the application task and accordingly assigns the task to a better matching core if available. The assignment policy triggers, if needed, task migration in order to optimize both the execution time and the power consumption. In this paper we describe the assignment algorithm and how we will implement it on a many-core system.	algorithm;central processing unit;computer memory;manycore processor;memory controller;run time (program lifecycle phase);scheduling (computing)	Panayiotis Petrides;Pedro Trancoso	2013		10.1145/2482767.2482776	parallel computing;real-time computing;computer science;distributed computing	HPC	-5.829915037764604	53.54891105230066	20118
a3d9fa8aa4d9ff8985cd9e25e2538919d4daabd7	generic support for synchronization and consistency in arias	protocols;random access memory;management functions;distributed memory systems;entry consistency model;network operating systems;implementation examples arias distributed shared memory service synchronization consistency generic support persistent global address space consistency protocols general design data synchronization model zone management functions specialized consistency protocol modules entry consistency model;software engineering;synchronisation;protection;consistency model;persistent global address space;shared memory systems;general design;global address space;synchronization;generic support;data synchronization model;access protocols;object oriented modeling random access memory context aware services protection access protocols read write memory delay;zone;specialized consistency protocol modules;read write memory;operating systems computers distributed memory systems shared memory systems synchronisation virtual storage protocols software engineering network operating systems;distributed shared memory;operating systems computers;consistency protocols;object oriented modeling;consistency;virtual storage;context aware services;arias distributed shared memory service;implementation examples	In the context of Arias, a distributed shared memory service with a persistent global address space, we have designed a generic framework for consistency protocols. We motivate the general design of Arias and the specific approach to consistency, which is to allow applications to choose the consistency protocol adapted to their data synchronization model. A simple entity, the zone, is introduced, whose management functions constitute the base of a generic support for consistency protocols. This generic support layer is described, and particularly its interface with the specialized consistency protocol modules. We also illustrate the use of this generic support by describing implementation examples of the entry consistency model.	aix;adriana de barros;chunking (computing);computer memory;consistency model;data synchronization;distributed shared memory;generic programming;goto;operating system;partitioned global address space;powerpc 600;prototype;release consistency;synchronization model;unix	Elizabeth Pérez Cortés;Pascal Dechamboux;Jay Han	1995		10.1109/HOTOS.1995.513465	synchronization;weak consistency;real-time computing;computer science;consistency model;operating system;release consistency;database;distributed computing;eventual consistency;sequential consistency	OS	-25.889175408966885	41.901208722545014	20196
06b0ba4f2e26f5362a43f7824e788f9e083cb34c	affect-inspired resource management in dynamic, real-time environments		We describe a novel affect-inspired mechanism to improve the per- formance of computational systems operating in dynamic environments. In par- ticular, we designed a mechanism that is based on ideas from fear in humans to dynamically reallocate operating system-level resources to processes as they are needed to deal with time-critical events. We evaluated this system in MINIX and Linux in a simulated unmanned aerial vehicle (UAV) testbed. We found the affect-based system was not only able to react more rapidly to time-critical events as intended, but since the dynamic processes for handling these events did not need to use significant CPU when they were not in time-critical situa- tions, the simulated UAV was able to perform even non-emergency tasks at a higher level of efficiency and reactivity than was possible in the standard im- plementation.	real-time transcription	W. Scott Neal Reilly;Gerald Fry;Michael Reposa	2012		10.1007/978-3-642-34274-5_47	embedded system;real-time computing;simulation;engineering	Embedded	-27.796287525508845	37.689460890889244	20219
8788c9cc2714213ea9b16d3fd864114bdbdf534c	redundancy elimination in the presence of split class initialization		Virtual machines for mobile and embedded devices often use the romization technique when the VM is loaded from a preinitialized state, previously saved as an image. This way some of the initialization work can be avoided in a resource constrained environment. For Java, one of the initialization activities which can be moved from execution time to romization time is class initialization.  The preinitialized image can be optimized in different ways. For instance, redundancy elimination transformations, which include elimination of unused methods, fields, and classes, can be applied to reduce the static and the dynamic footprint of the image. We consider the problem of redundancy elimination in the presence of romization time class initialization.  There is a circular dependency between class initialization and method reachability analysis. On the one hand, class initialization reduces the set of reachable methods as the methods used solely for the initialization become unreachable. On the other hand, eager initialization of classes which are not used by the reachable methods can increase the size of the image by creating reachable but unused objects in the heap.  We propose a method reachability analysis algorithm which breaks this circular dependency by performing selective class initialization during the analysis. The algorithm keeps track of the classes which can be initialized by the reachable methods and initializes a subset of these classes. A simple heuristic is used to choose the classes which are safe to preinitialize.  We also found that elimination of initialized but unused reference fields in Java can affect finalization semantics. The elimination of a field might cause some objects to be collected by the GC, which can be observed by the application. We present an algorithm for elimination of unused fields which preserves finalization behavior.	algorithm;circular dependency;embedded system;heuristic;java;lazy initialization;mobile device;reachability;run time (program lifecycle phase);unreachable memory	Artur Pilipenko;Oleg Pliss	2018		10.1145/3237009.3237014	redundancy (engineering);real-time computing;initialization;virtual machine;heuristic;finalization;computer science;circular dependency;heap (data structure);java	PL	-20.529599380084335	35.16884952026196	20234
44483572d05e2ee60016986bb19efd61aef41c72	lustre lockahead: early experience and performance using optimized locking		SummaryrnRecent Cray-authored Lustre modifications known as Lustre Lockahead show significantly improved write performance for collective, shared-file I/O workloads. Initial tests show write performance improvements of more than 200% for small transfer sizes and over 100% for larger transfer sizes compared to traditional Lustre locking. Standard Lustre shared-file locking mechanisms limit scaling of shared-file I/O performance on modern high-performance Lustre servers. The new Lockahead feature provides a mechanism for applications (or libraries) with knowledge of their I/O patterns to overcome this limitation by explicitly requesting locks. MPI-IO is able to use this feature to dramatically improve shared-file collective I/O performance, achieving more than 80% of file per process performance. This paper discusses our early experience using Lockahead with applications. We also present application and synthetic performance results and discuss performance considerations for applications that benefit from Lockahead.	lock (computer science);lustre	Michael Moore;Patrick Farrell;Bob Cernohous	2018	Concurrency and Computation: Practice and Experience	10.1002/cpe.4332	parallel computing;distributed computing;computer science;weather research and forecasting model;server;lustre (mineralogy)	PL	-13.990766619562493	52.64123433464799	20240
4d64eee09c2710b91d87c335f31ec5c9565e17cd	towards synthesizing realistic workload traces for studying the hadoop ecosystem	analytical models;google;analytical models computational modeling google biological system modeling visualization memory management color;memory management;software performance modeling cloud computing performance analysis design optimization;hadoop system performance realistic workload traces hadoop ecosystem cloud computing cluster configuration networking characteristics google cloud workloads hadoop design hadoop job schedulers shared storage;color;computer model;biological system modeling;software performance evaluation;design optimization;software performance;visualization;computational modeling;software performance evaluation cloud computing;performance analysis;visual memory;analytical model;cloud computing;software performance modeling	Designing cloud computing setups is a challenging task. It involves understanding the impact of a plethora of parameters ranging from cluster configuration, partitioning, networking characteristics, and the targeted applications' behavior. The design space, and the scale of the clusters, make it cumbersome and error-prone to test different cluster configurations using real setups. Thus, the community is increasingly relying on simulations and models of cloud setups to infer system behavior and the impact of design choices. The accuracy of the results from such approaches depends on the accuracy and realistic nature of the workload traces employed. Unfortunately, few cloud workload traces are available (in the public domain). In this paper, we present the key steps towards analyzing the traces that have been made public, e.g., from Google, and inferring lessons that can be used to design realistic cloud workloads as well as enable thorough quantitative studies of Hadoop design. Moreover, we leverage the lessons learned from the traces to undertake two case studies: (i) Evaluating Hadoop job schedulers, and (ii) Quantifying the impact of shared storage on Hadoop system performance.	apache hadoop;cloud computing;cognitive dimensions of notations;computer cluster;digital footprint;distributed computing;ecosystem;job stream;locality of reference;scheduling (computing);simulation;tracing (software)	Guanying Wang;Ali Raza Butt;Henry M. Monti;Karan Gupta	2011	2011 IEEE 19th Annual International Symposium on Modelling, Analysis, and Simulation of Computer and Telecommunication Systems	10.1109/MASCOTS.2011.59	computer simulation;real-time computing;multidisciplinary design optimization;simulation;visualization;software performance testing;cloud computing;visual memory;computer science;operating system;computational model;memory management	Arch	-23.210759271557546	56.72161594759404	20286
c6278b3bd4e3db5fa976bc664e434df76f81a297	characterizing and detecting the set of global states seen by all observers of a distributed computation	distributed computing sufficient conditions;formal specification;observer independent property;unstable properties global states detection distributed computation monoprocessor system distributed execution common global state necessary and sufficient condition monitor based algorithm;distributed processing;distributed computing;consistent global state;concurrency;relevant event;distributed computation;unstable property detection;observation;formal specification distributed processing;common global state;precedence;causality	A consistent observation of a given distributed computation is a sequence of global states that could be produced by executing that computation on a monoprocessor system. Therefore a distributed execution generally accepts several consistent observations. This paper concentrates on what all these observations have in common. An abstraction called common global state is defined. A necessary and sufficient condition characterizing such states is given. A monitor-based algorithm that detects them is also presented and proved correct. Previous works on detection of unstable properties of distributed computations are revisited and explained with this abstraction. Moreover other uses of such particular states are sketched.	abstraction layer;advanced configuration and power interface;computation;concurrency (computer science);control theory;debugging;distributed computing;global serializability;global variable;greedy algorithm;modality (human–computer interaction);parallel computing;point of view (computer hardware company);sensor;transaction processing system	Eddy Fromentin;Michel Raynal	1995		10.1109/ICDCS.1995.500048	real-time computing;causality;concurrency;computer science;theoretical computer science;formal specification;distributed computing;observation	Logic	-23.823838297117366	42.84521208227959	20309
1ab9abb3c05c986f45487c8ebfe161fd66b4b765	consistency algorithms and protocols for distributed interactive applications	004 informatik	The Internet has a major impact not only on how people retrieve information but also on how they communicate. Distributed interactive applicationsupport the communication and collaboration of people through the sharing and manipulation of rich multimedia content via the Internet. Aside from shared text editors, meeting support systems, and distributed virtual environments, shared whiteboards are a prominent example of distributed interactive applications. They allow the presentation and joint editing of documents in video conferencing scenarios. The design of such a shared whiteboard application, the multimedia lecture board (mlb), is a main contribution of this thesis. Like many other distributed interactive applications, the mlb has a replicated architecture where each user runs an instance of the application. This has the distinct advantage that the application can be deployed in a lightweight fashion, without relying on a supporting server infrastructure. But at the same time, this peer-to-peer architecture raises a number of challenging problems: First, application data needs to be distributed among all instances. For this purpose, we present the network protocol RTP/I for the standardized communication of distributed interactive applications, and a novel applicationlevel multicast protocol that realizes efficient group communication while taking applicationlevel knowledge into account. Second, consistency control mechanisms are required to keep the replicated application data synchronized. We present the consistency control algorithms “local lag”, “timewarp”, and “state request”, show how they can be combined, and discuss how to provide visual feedback so that the session members are able to handle conflicting actions. Finally, late-joining participants need to be initialized with the current application state before they are able to participate in a collaborative session. We propose a novel late-join algorithm, which is both flexible and scalable. All algorithms and protocols presented in this dissertation solve the aforementioned problems in a generic way. We demonstrate how they can be employed for the mlb as well as for other distributed interactive applications.	algorithm;communications protocol;control system;internet;join (sql);multicast;peer-to-peer;scalability;server (computing);state (computer science);text editor;virtual reality	Jürgen Vogel	2004			computer science;distributed computing;multimedia;world wide web	HCI	-26.436817537174157	48.74124037760914	20368
ed14e3b8bd75795573075e096654505f13397278	a distributed geospatial information services sharing technology based on saas thought: in the application of biodiversity conservation	software;authorisation;service orientation;multiuser geospatial information distributed geospatial information services biodiversity saas software as a service web service distributed giservices sharing technology geoprocessing function internet geodata services role function resource based access control rbac model log management;particle size;web services authorisation geographic information systems geophysics computing information services;geoprocessing function;geospatial analysis;distributed giservices sharing technology;multi user;web service;biodiversity conservation;satisfiability;information services;r f rbac;rbac model;business model;role function resource based access control;collaborative environment;servers;internet;geophysics computing;geographic information systems;access control models;multiuser geospatial information;web services;mashup;the nature conservancy;software as a service;saas thought;log management;information service;information system;distributed geospatial information services;geospatial analysis servers software web services biodiversity;biodiversity;r f rbac distributed giservices sharing technology dgisst saas thought biodiversity conservation web service mashup;distributed giservices sharing technology dgisst;saas;geodata services	Biodiversity conservations are often comprehensive, dynamic and complex problem that require professionals to work in teams while dealing with large and decentralized of project areas. However, the varieties of scattered thematic geospatial information can not be used directly and effectively by users — it impedes rather facilitates collaboration, and increases the project cost. To solve this problems, an implementation method of providing distributed geospatial information services (GIServices) based on SaaS (Software as a Service) thought and the Service-oriented Web Service technology, which is called the Distributed GIServices Sharing Technology (DGISST), is presented as a key technology for the proposed scheme. This paper explores that develops a distributed GIServices sharing platform to provide users with a shared collaboration environment with the DGISST as the core technology. First of all, all the existing geoprocessing function applications, geospatial information data and specialized business models are published as Web services. Different from the traditional WebGIS, this platform not only provides geodata services but also focuses more on providing geoprocessing function services and model services, and offers powerful geoprocessing functions and specialized model functions. Therefore, it is very critical to help users in geodata manipulation online. Secondly, some important concepts such as perfect metainformation system and GIServices application mode are introduced. Therefore, the different particle sizes of GIServices can be called flexibly and simply via Internet. Particularly, it also permits users to mashup their private geodata services with the public geodata services. Then it allows users to combine geodata service and geoprocessing function service (or specialized model service) to meet the different needs. Thirdly, this platform is designed to allow geodata services to be distributed in the Internet and be accessible at client sites. Therefore, to ensure the security of information and data, a multi-user application model is presented as a core module in this platform. This model implements the R-F-RBAC (Role-Function-Resource Based Access Control) model by introducing Centralized Identity Authentication, the RBAC model and Log Management. Through the above work, this platform provides a multi-user geospatial information application environment to meet the needs of geodata manipulation and collaboration for teams. A prototype implementation has been developed to put into use in TNC (The Nature Conservancy) China, satisfying the demands of sharing geospatial information and the daily work.	authentication;biodiversity informatics;centralized computing;data center;distributed computing;geographic information system;geoprocessing;internet;log management;mashup (web application hybrid);multi-user;nist rbac model;prototype;role-based access control;service-oriented device architecture;service-oriented software engineering;software as a service;systems architecture;trusted network connect;web service	Xiaoxu Liu;Zhuowei Hu;Longzhu Wang;Wenji Zhao;Cheng Peng	2010	2010 18th International Conference on Geoinformatics	10.1109/GEOINFORMATICS.2010.5567782	computer science;knowledge management;database;world wide web	DB	-32.014976128357326	52.47229683100078	20375
a569ff944ae6a7aa77583c60ee86056898abb03c	value-based partial redundancy elimination	hachage;traitement flux donnee;redundancia;implementation;flot donnee;program transformation;flujo datos;optimizacion compiladora;program verification;transformation programme;partial redundancy elimination;analisis programa;verificacion programa;transformacion programa;hashing;redundancy;numerotation;data flow processing;compiler optimization;numbering;program analysis;numerotacion;analyse programme;data flow;implementacion;verification programme;optimisation compilateur;hybrid algorithm;redondance	Partial redundancy elimination (PRE) is a program transformation that identifies and eliminates expressions that are redundant on at least one (but not necessarily all) execution paths. Global value numbering (GVN) is a program analysis and transformation that identifies operations that compute the same value and eliminates operations that are redundant. A weakness of PRE is that it traditionally considers only expressions that are lexically equivalent. A weakness of GVN is that it traditionally considers only operations that are fully redundant. In this paper, we examine the work that has been done on PRE and GVN and present a hybrid algorithm that combines the strengths of each. The contributions of this work are a framework for thinking about expressions and values without source-level lexical constraints, a system of data-flow equations for determining insertion points, and a practical algorithm for extending a simple hash-based GVN for PRE. Our implementation subsumes GVN statically and, on most benchmarks, in terms of performance.	dataflow;global value numbering;hybrid algorithm;jikes;mathematical optimization;optimizing compiler;partial redundancy elimination;program analysis;program transformation;software engineering;static single assignment form	Thomas VanDrunen;Antony L. Hosking	2004		10.1007/978-3-540-24723-4_12	program analysis;data flow diagram;real-time computing;hash function;hybrid algorithm;computer science;theoretical computer science;optimizing compiler;redundancy;programming language;implementation;numbering;algorithm;partial redundancy elimination	PL	-19.32913273192279	33.293492234561455	20401
0b6e3e0300989ba85d99c560d058e8c146e5fac9	an architectural evaluation for scientific workflow service deployment in a virtual laboratory	collaboratabilit;performance;virtal laboratory;virtal laboratory workflow service data storage data security performance scalability collaboratabilit;data storage;workflow service;scalability;collaboration laboratories scalability data security memory software context;architectural evaluation service deployment decision making collaboration platform collaborative environment software architectural decision making complex scientific computation virtual laboratory scientific workflow service deployment;workflow management software computer mediated communication decision making groupware scientific information systems software architecture software performance evaluation;data security	Workflow is one of vital facilities in virtual laboratory for complex scientific computation. However, where to deploy a workflow service in a virtual laboratory is a challenging software architectural decision to make with tradeoff of requirements and resources. This paper presents an architectural evaluation for deploying a scientific workflow service in a collaborative environment. We evaluate three deployment options by comparing them against common scientific virtual laboratory requirements. While this case study is for a particular collaboration platform and application domain, the evaluation method, process and conclusion can be useful and reused in other service deployment decision making.	application domain;architectural decision;collaborative software;computation;computational science;requirement;software deployment	Shiping Chen;John Zic;Lingbo Jiang;Nerolie Oakes	2014	2014 IEEE International Conference on Services Computing	10.1109/SCC.2014.122	workflow;computer science;systems engineering;knowledge management;database;software deployment;workflow management system;workflow engine;workflow technology	HPC	-31.098414511239824	50.14263988471468	20411
3212369fe9f3479ff44917840e639f243ea7baa4	approximate data dependence graph generation using adaptive sampling	sampling methods data handling graph theory random processes;profiling;program analysis pin binary instrumentation data dependence analysis data flow analysis profiling;data dependence analysis;instruments pins runtime switches parallel processing kernel benchmark testing;data flow analysis;program analysis;pin;binary instrumentation;approximate data dependence graph generation instrumentation time polybench kernels pin binary instrumentation tools irregular memory accesses random sampling stability performance gain code instrumentation parallelisation process adaptive sampling	Identifying data dependence among loop iterations is a fundamental step in the parallelisation process. Generally, code instrumentation provides for such information at the expense of high runtime performance penalty. This paper proposes an efficient method that trades slight accuracy reduction with significant performance gain to generate an approximate dependence graph. The proposed method relies on replicating the loop under test, providing for instrumented and not instrumented code versions, and adaptively switching between them, as well as deciding on the analysis detail, depending on the stability of measured dependence distances. Moreover, the method utilises random sampling, decreasing the chances of missing dependent irregular memory accesses. An initial performance investigation of the method is conducted using the Pin binary instrumentation tools, results on selected PolyBench kernels shows up to 8.5× improvement in instrumentation time, with no missed dependencies in 14 kernels, and 45% missed dependencies in one kernel.	adaptive sampling;approximation algorithm;benchmark (computing);callback (computer programming);data dependency;dynamic data;iteration;kernel (operating system);monte carlo method;parallel computing;preprocessor;run time (program lifecycle phase);sampling (signal processing);speculative execution;speedup	Mostafa M. Abbas;Ahmed El-Mahdy	2016	2016 45th International Conference on Parallel Processing Workshops (ICPPW)	10.1109/ICPPW.2016.54	program analysis;parallel computing;real-time computing;computer science;theoretical computer science;operating system;data-flow analysis;profiling;programming language	HPC	-17.670490495683712	37.62773280382643	20452
dea46ecd2f807fead8e456b3d48e9b6f5a1de9e6	experience with active messages on the meiko cs-2	network communication co processors;active messages;low latency active messages meiko cs 2 parallel machines network communication co processors communication architecture;communication architecture;parallel machines message passing parallel architectures;performance improvement;low latency;parallel architectures;hardware delay coprocessors libraries space exploration workstations computer science parallel machines protocols programming profession;meiko cs 2;message passing;parallel machines;network interface	Active messages provide a low latency communication architecture which on modern parallel machines achieves more than an order of magnitude performance improvement over more traditional communication libraries. This paper discusses the experience we gained while implementing active messages on the Meiko CS-2, and discusses implementations for similar architectures. During our work we have identified that architectures which only support efficient remote write operations (or DMA transfers as in the case of the CS-2) make it difficult to transfer both data and control as required by active messages. Traditional network interfaces avoid this problem because they have a single point of entry which essentially acts as a queue. To efficiently support active messages on modern network communication co-processors, hardware primitives are required which support this queue behavior. We overcame this problem by producing specialized code which runs on the communications co-processor and supports the active messages protocol. Our implementation of active messages results in a one-way latency of 12:3 s and achieves up to 39 MB/s for bulk transfers. Both numbers are close to optimal for the current Meiko hardware and are competitive with performance of active messages on other hardware platforms.	active message;central processing unit;coprocessor;deadlock;direct memory access;error message;library (computing);mebibyte;memory address;network interface;next-generation network;one-way function;parallel computing;pointer (computer programming);queue (abstract data type);requirement;round-trip engineering;second generation multiplex plus	Klaus E. Schauser;Chris J. Scheiman	1995		10.1109/IPPS.1995.395925	parallel computing;real-time computing;computer science;distributed computing	Arch	-11.376073309139505	46.397470227685425	20501
1576f584ae805bb253d54cf2b7aa9045aefd622e	a comparison of windows driver model latency performance on windows nt and windows 98	sistema operativo;architecture systeme;personal computer;estudio comparativo;resource management;gestion fichier;file management;system performance;etude comparative;gestion recursos;operating system;scheduling;analyse performance;manejo archivos;comparative study;performance analysis;gestion ressources;arquitectura sistema;systeme exploitation;ordonamiento;system architecture;ordonnancement;analisis eficacia	Windows 98 and NT share a common driver model known as WDM (Windows Driver Model) and carefully designed drivers can be binary portable. We compare the performance of Windows 98 and Windows NT 4.0 under load from office, multimedia and engineering applications on a personal computer (PC) of modest power that is free of legacy hardware. We report our observations using a complementary pair of system performance measures, interrupt and thread latency, that capture the ability of the OS to support multimedia and real-time workloads in a way that traditional throughput-based performance measures miss. We use the measured latency distributions to evaluate the quality of service that a WDM driver can expect to receive on both OSs, irrespective of whether the driver uses thread-based or interrupt-based processing. We conclude that for real-time applications a driver on Windows NT 4.0 that uses high, real-time priority threads receives an order of magnitude better service than a similar WDM driver on Windows 98 that uses Deferred Procedure Calls, a form of interrupt processing. With the increase in multimedia and realtime processing on PCs the interrupt and thread latency metrics have become as important as the throughput metrics traditionally used to measure performance.	interrupt latency;microsoft windows 98;operating system;personal computer;quality of service;real-time clock;real-time transcription;throughput;wavelength-division multiplexing;windows driver model;windows nt 4.0	Erik Cota-Robles;James P. Held	1999		10.1145/296806.296823	embedded system;real-time computing;local procedure call;computer multitasking;computer science;group policy;resource management;server message block;operating system;hibernation;comparative research;computer performance;windows rally;commit charge;pse-36;scheduling;network access protection;systems architecture	OS	-18.41698965322968	45.07692668756765	20549
fa1753f9e2621d1c82a727de30add7dfc9e18211	supporting parameter sweep applications with synthesized grid services	scientific application;task performance;parametric model;service orientation;grid service;tool integration;experimental evaluation;system architecture;service oriented architecture;parallel programs	Specialized tools already provide support for creation and execution of parameter sweeps. In such applications many tasks perform similar computations for varying input parameters. So far however none of these existing tools integrates well into service-oriented architectures or allows parametric modeling directly at the service interface. We address exactly this gap and demonstrate practical applicability with a concrete system architecture and implementation. Moreover we extend our services with reduction operators well known from parallel programming that perform certain aggregations or selections over the result set from all tasks of a given parameter study. Our efforts are substantial extensions to previous work on the service synthesis tool the ’Otho Toolkit’ that allows smooth integration of scientific applications into service-oriented Grids. An experimental evaluation concludes our paper.	computation;embedded system;experiment;interaction;keyboard shortcut;parallel computing;parametric model;prototype;result set;scheduling (computing);service-oriented architecture;service-oriented device architecture;systems architecture	Jürgen Hofer;Thomas Fahringer	2008		10.1007/978-3-540-85451-7_4	parallel computing;simulation;parametric model;computer science;theoretical computer science;operating system;service-oriented architecture;database;distributed computing;programming language;statistics;systems architecture	HPC	-29.045417783505762	53.799752654565836	20564
8e1825bc9d2a92e4cfe5843951e9ec1e28213827	simulation of an ecs-based operating system	operating system	Extended Core Storage (ECS) for the Control Data 64/6600 System has been described in another paper. ECS is a large capacity, word-addressable core memory with block transfer times of from eight to ten words per microsecond after a transfer start-up time of approximately 2 microseconds. ECS memories range in size from 131K to over two million words, and can be shared by up to four 6000 systems. The cost per word of Extended Core Storage is about one-tenth that of Central Memory (CM).	core storage;flash memory;magnetic-core memory;operating system;simulation;uptime;word-addressable	M. H. MacDougall	1967		10.1145/1465482.1465601	parallel computing;computer hardware;computer science;operating system	Arch	-11.723856581174768	52.29733250356274	20616
27488a1c02941d086733c460eb6eb417674cd307	the mobile csound platform	electronic engineering;music	This article discusses the development of the Mobile Csound Platform (MCP), a group of related projects that aim to provide support for sound synthesis and processing under various new environments. Csound is itself an established computer music system, derived from the MUSIC N paradigm, which allows various uses and applications through its Application Programming Interface (API). In the article, we discuss these uses and introduce the three environments under which the MCP is being run. The projects designed for mobile operating systems, iOS and Android, are discussed from a technical point of view, exploring the development of the CsoundObj toolkit, which is built on top of the Csound host API. In addition to these, we also discuss a web deployment solution, which allows for Csound applications on desktop operating systems without prior installation. The article concludes with some notes on future developments.	android;application programming interface;csound;desktop computer;download;java web start;mobile device;mobile operating system;objective-c;programming idiom;programming paradigm;real-time transcription;software deployment;software development kit;sourceforge;technical documentation;ios	Steven Yi;Victor Lazzarini;Joseph Timoney;Damián Keller;Marcelo Soares Pimenta	2012			simulation;human–computer interaction;engineering;world wide web	HCI	-32.263087667414645	41.6549868943347	20619
6c4d8e64d53dd8092863e6bce9a83603d398654e	computational science and its applications — iccsa 2003			computation;computational science		2003		10.1007/3-540-44843-8		Theory	-7.688463565989599	37.57273748944108	20634
b86c818cec44eb646452d5e9c7f8983255619a24	status report on esprit project p7519 palace: parallelization of geant	status report;esprit project p7519 palace	We report on the status of the parallelization of GEANT, a MonteCarlo program used to simulate the effects of radiation in matter. After having implemented a Master/Slave model on a heterogeneous cluster of workstations, we have decomposed the problem into an arbitrary topology, consisting of a combination of Master/Slave and Server/Client models. This topology consists of a Master process, an Event Producer, a number of Workers, an Event Consumer and a few servers. Special care was given to the handling of the random number generator.	automatic parallelization;parallel computing	Carlino Casari;F. Fabbri;Mario Guanziroli;Michele Mazzeo;Graziano Meola;Sergio Punzi;Alan L. Scheinine;Paolo Stofella	1994		10.1007/3-540-57981-8_169	simulation	Logic	-8.592845085115826	39.239716513851256	20695
13311075ba146d37bfc68a3ac8c436614ee4551b	combining abstract interpretation with model checking for timing analysis of multicore software	analytical models;time division multiple access;ta combining abstract interpretation model checking multicore software timing analysis real time systems shared memory bus off chip memory timed automaton;computer engineering;frequency modulation;shared memory;low energy;combining abstract interpretation;real time;embedded real time systems;multicore processing analytical models delay automata frequency modulation time division multiple access;automatic generation;chip;automata;timed automaton;wcet;multicore;model checking;shared bus;multicore processing;multicore software timing analysis;datavetenskap datalogi;timing analysis;off chip memory;ta;timed automata;datorteknik;multiprocessing systems;shared memory bus;computer science;real time systems multiprocessing systems;abstract interpretation;high performance;shared bus abstract interpretation model checking wcet multicore;real time systems	It is predicted that multicores will be increasingly used in future embedded real-time systems for high performance and low energy consumption. The major obstacle is that we may not predict and provide any guarantee on real-time properties of software on such platforms. The shared memory bus is among the most critical resources, which severely degrade the timing predictability of multicore software due to the access contention between cores. In this paper, we study a multicore architecture where each core has a local L1 cache and all cores use a shared bus to access the off-chip memory. We use Abstract Interpretation (AI) to analyze the local cache behavior of a program running on a dedicated core. Based on the cache analysis, we construct a Timed Automaton (TA) to model when the programs access the memory bus. Then we model the shared bus also using timed automata. The TA models for the bus and programs will be explored using the UPPAAL model checker to find the WECTs for the respective programs. Based on the presented techniques, we have developed a tool for multicore timing analysis, which allows automatic generation of the TA models from binary code and WCET estimation for any given TA model of the shared bus. Extensive experiments have been conducted, showing that the combined approach can significantly tighten the estimations. As examples, we have studied the TDMA and FCFS buses, of which the WCET bounds can be tightened by up to 240% and 82% respectively, compared with the worst-case bounds estimated based on worst-case bus access delay.	abstract interpretation;access time;automata theory;best, worst and average case;binary code;cas latency;cpu cache;computer memory;embedded system;experiment;memory bus;model checking;multi-core processor;real-time clock;real-time computing;run time (program lifecycle phase);shared memory;static timing analysis;timed automaton;uppaal;worst-case execution time	Mingsong Lv;Wang Yi;Nan Guan;Ge Yu	2010	2010 31st IEEE Real-Time Systems Symposium	10.1109/RTSS.2010.30	bus sniffing;multi-core processor;embedded system;computer architecture;parallel computing;real-time computing;computer science;local bus;operating system;programming language	Embedded	-7.475433148293629	57.9524528473539	20714
2416fcf3ac86f15b30bf61e9768f2a90c8ff2d2e	distance-aware round-robin mapping for large nuca caches	cache storage;oceans;multiprogrammed workloads;cache access latency;radiation detectors;distance aware round robin mapping;on chip network traffic;parallel application distance aware round robin mapping nonuniform cache architecture many core architectures memory blocks physical mapping cache banks cache access latency on chip network traffic first touch mapping policy os managed policy gems simulator multiprogrammed workloads;nonuniform cache architecture;multiprogramming;system on a chip;physics computing;first touch mapping policy;chip;upper bound;computer architecture;telecommunication traffic;round robin;indexing;organizing;memory architecture;network traffic;indexation;physical mapping;gems simulator;os managed policy;informatics;tiles;magnetic cores;tiles delay telecommunication traffic proposals indexing organizing physics computing informatics computer architecture memory architecture;proposals;many core architectures;memory blocks;operating systems computers;physical map;parallel applications;parallel processing;parallel application;management policy;cache banks;parallel processing cache storage multiprogramming operating systems computers	In many-core architectures, memory blocks are commonly assigned to the banks of a NUCA cache by following a physical mapping. This mapping assigns blocks to cache banks in a round-robin fashion, thus neglecting the distance between the cores that most frequently access every block and the corresponding NUCA bank for the block. This issue impacts both cache access latency and the amount of on-chip network traffic generated. On the other hand, first-touch mapping policies, which take into account distance, can lead to an unbalanced utilization of cache banks, and consequently, to an increased number of expensive off-chip accesses. In this work, we propose the distance-aware round-robin mapping policy, an OS-managed policy which addresses the trade-off between cache access latency and number of off-chip accesses. Our policy tries to map the pages accessed by a core to its closest (local) bank, like in a first-touch policy. However, our policy also introduces an upper bound on the deviation of the distribution of memory pages among cache banks, which lessens the number of off-chip accesses. This tradeoff is addressed without requiring any extra hardware structure. We also show that the private cache indexing commonly used in many-core architectures is not the most appropriate for OS-managed distance-aware mapping policies, and propose to employ different bits for such indexing. Using GEMS simulator we show that our proposal obtains average improvements of 11% for parallel applications and 14% for multi-programmed workloads in terms of execution time, and significant reductions in network traffic, over a traditional physical mapping. Moreover, when compared to a first-touch mapping policy, our proposal improves average execution time by 5% for parallel applications and 6% for multi-programmed workloads, slightly increasing on-chip network traffic.	cpu cache;fast fourier transform;filter bank;informatics;manycore processor;network on a chip;network packet;network traffic control;operating system;round-robin dns;round-robin scheduling;run time (program lifecycle phase);tiling window manager;unbalanced circuit	Alberto Ros;Marcelo Cintra;Manuel E. Acacio;José M. García	2009	2009 International Conference on High Performance Computing (HiPC)	10.1109/HIPC.2009.5433220	chip;system on a chip;parallel processing;search engine indexing;cache-oblivious algorithm;parallel computing;real-time computing;cache coloring;page cache;computer multitasking;cache;computer science;cache invalidation;operating system;distributed computing;upper and lower bounds;programming language;particle detector;informatics;cache algorithms;cache pollution;computer network	HPC	-8.85413413635502	52.46993630848151	20718
5f4c39cb217ae7f8dc28e83e2c98aaf3e1909c74	an evaluation of staged run-time optimizations in dyc	compilacion;run time optimization;data compression;program tracing;program control flow;dynamic compilation;path profiling;ejecucion programa;optimizacion compiladora;program execution;performance programme;performance improvement;execution programme;timing optimization;compiler optimization;compilation;eficacia programa;program performance;dynamic program measurement;optimisation compilateur;systeme compilation dynamique dyc	Previous selective dynamic compilation systems have demonstrated that dynamic compilation can achieve performance improvements at low cost on small kernels, but they have had difficulty scaling to larger programs. To overcome this limitation, we developed DyC, a selective dynamic compilation system that includes more sophisticated and flexible analyses and transformations. DyC is able to achieve good performance improvements on programs that are much larger and more complex than the kernels. We analyze the individual optimizations of DyC and assess their impact on performance collectively and individually.	compiler;dynamic compilation;image scaling	Brian Grant;Matthai Philipose;Markus Mock;Craig Chambers;Susan J. Eggers	1999		10.1145/301618.301683	data compression;computer architecture;parallel computing;real-time computing;dynamic compilation;computer science;optimizing compiler;programming language	PL	-18.40701387412847	36.48386602025811	20787
5245955c40b29462e6f6b22a7a150c8e0d6a1f01	a framework for earth system model application monitoring	pop earth system model application monitoring global environmental evolution numerical approach esm applications earth system model oriented integrated developing environment esm application development flexible monitoring framework scalable monitoring framework ocean model;debugging;application monitoring;monitoring earth computational modeling instruments physics debugging numerical models;instruments;earth;system monitoring;software engineering;physics;computational modeling;numerical analysis;geophysics computing;monitoring;system monitoring earth geophysics computing numerical analysis oceanography software engineering;monitoring framework earth system models application monitoring;numerical models;earth system models;monitoring framework;oceanography	"""Earth System Model (ESM) is an important tool for the research on global environmental evolution using numerical approach. Here we present a monitoring method for ESM applications based on """"Earth System Model Oriented Integrated Developing Environment"""". As the existing tools cannot properly handle with the collections and analysis of the ESM applications' behaviors, we combine the monitor and development of ESM applications together by implementing a flexible and scalable monitoring framework. Our work reduces the difficulty of monitoring ESM applications significantly. Based on that, we implement a monitoring service for an ocean model called POP. And this job evaluates the effectiveness of the monitoring method."""	archive;earth system science;list of ocean circulation models;numerical analysis;ocean general circulation model;requirement;scalability	Ran Yan;JieQian Wu;Yibo Xie;You Meng;Depei Qian	2013	2013 IEEE 16th International Conference on Computational Science and Engineering	10.1109/CSE.2013.199	system monitoring;simulation;numerical analysis;computer science;earth;programming language;debugging;computational model	SE	-30.254594942907335	49.49998373985702	20817
e35a5630e532f9a92d17258d1db97b3c02dfcef1	a scalable cluster-based parallel simplifi cation framework for height fields				Valérie Gouranton;Sébastien Limet;Souley Madougou;Emmanuel Melin	2004				HPC	-9.227460993841358	33.717847727186964	20876
11935c80acfee08e19eb4e921a7565cbe6368901	exploiting in-memory processing capabilities for density functional theory applications		Processing-in-memory (PIM) is an approach to address the data transport challenge in future HPC architectures and various designs have been explored in the past. Despite, it remains unclear how scientific applications could efficiently exploit massively-parallel HPC architectures integrating PIM modules. In this paper we address this question for material science applications for which we ported relevant kernels to the Active Memory Cube architecture developed by IBM Research.	advanced mezzanine card;blue gene;central processing unit;compiler;cube;density functional theory;double-precision floating-point format;flops;finite difference;functional theories of grammar;ibm research;image scaling;in-memory database;in-memory processing;job control (unix);kernel (operating system);linear algebra;matrix multiplication;microcode;quantum turing machine;scalability;speedup	Paul F. Baumeister;Thorsten Hater;Dirk Pleiter;Hans Boettiger;Thilo Maurer;José R. Brunheroto	2016		10.1007/978-3-319-58943-5_60	parallel computing;porting;architecture;exploit;computer science;in-memory processing;density functional theory	HPC	-6.311068140446564	40.44691821220987	20878
104159548dc54ff96c8c93678d06b7c969b8b131	co-scheduling amdahl applications on cache-partitioned systems		Cache-partitioned architectures allow subsections of thernshared last-level cache (LLC) to be exclusively reserved for somernapplications. This technique dramatically limits interactions between applicationsrnthat are concurrently executing on a multi-core machine.rnConsider n applications that execute concurrently, with the objective to minimize the makespan,rndefined as the maximum completion time of the n applications.rnKey scheduling questions are: (i)rnwhich proportionrnof cache and (ii) how many processors should be given to each application? rnIn this paper, we provide answers to (i) and (ii) for Amdahl applications.rnEven though the problem is shown to be NP-complete, we give key elements to determinernthe subset of applications that should share the LLCrn(while remaining ones only use their smaller private cache). Building upon these results,rnwe design efficient heuristics for Amdahl applications. rnExtensive simulations demonstrate the usefulness of co-schedulingrnwhen our efficient cache partitioning strategies are deployed.	amdahl's law;cpu cache;cache (computing);central processing unit;concurrent computing;heuristic (computer science);interaction;key schedule;lunar lander challenge;makespan;multi-core processor;np-completeness;scheduling (computing);simulation	Guillaume Aupy;Anne Benoit;Sicheng Dai;Loïc Pottier;Padma Raghavan;Yves Robert;Manu Shantharam	2018	IJHPCA	10.1177/1094342017710806	amdahl's law;cache invalidation;parallel computing;cache coloring;computer science;cache;smart cache;cache-oblivious algorithm;cache algorithms;distributed computing;cache pollution	Arch	-13.959104745860117	57.80520800052766	20890
791451b2d50985961e793b13ee3846ff22de81c4	enhancing multi-model forest fire spread prediction by exploiting multi-core parallelism	efficiency;hpc;multi model;forest fire;prediction;multi core	The Two-Stage forest fire spread prediction methodology was developed to enhance forest fire evolution forecast by tackling the uncertainty of some environmental conditions. However, there are parameters, such as wind, that present a variation along terrain and time. In such cases, it is necessary to couple forest fire propagation models and complementary models, such as meteorological forecast and wind field models. This multi-model approach improves the accuracy of the predictions by introducing an overhead in the execution time. In this paper, different multi-model approaches are discussed and the results show that the propagation prediction is improved. Exploiting multi-core architectures of current processors, we can reduce the overhead introduced by complementary models.	central processing unit;experiment;multi-core processor;multi-model database;openmp;overhead (computing);parallel computing;population;run time (program lifecycle phase);software propagation;software release life cycle	Carlos Brun;Tomàs Margalef;Ana Carolina Castro Côrtes;Anna Sikora	2014	The Journal of Supercomputing	10.1007/s11227-014-1168-z	multi-core processor;supercomputer;parallel computing;simulation;prediction;computer science;operating system;efficiency;statistics	HPC	-5.956224270269077	33.481743015544865	20899
051bbf282c3474a46bc7a3c88ee258f55cc57aae	distributed quantum entanglement sharing model for high-performance real-time system	distributed system;fault identified;real time system;quantum entanglement;system dependability	Two processors jointly provide a real-time service which can be completed by exactly one processor. Assuming each processor is allowed to announce only a one-bit information in a distributed way to decide which one should process the job, inevitably some of the jobs will get lost if only classical resources are used. In this paper, we proposed the distributed quantum entanglement sharing (DQES) model to share quantum entanglement with processors. Assisted with DQES model, not only the system dependability can be enhanced, but the faulty processor can also be identified. We also presented some possible applications such like database consistency, job scheduling, system dependability, and reliable communication protocols.	quantum entanglement;real-time clock;real-time computing	Chi-Yuan Chen;Yao-Hsin Chou;Han-Chieh Chao	2012	Soft Comput.	10.1007/s00500-011-0727-y	real-time computing;real-time operating system;computer science;theoretical computer science;distributed computing;quantum entanglement	Embedded	-24.228488792593424	43.95768620509205	21020
d0faf52d88deca39ac365d7bab6ca2a70464b0cf	"""comments on """"the cost of selective recompilation and environment processing"""""""	ada tasking;static analysis;process algebra			Bevin R. Brett	1995	ACM Trans. Softw. Eng. Methodol.	10.1145/210134.210435	process calculus;parallel computing;real-time computing;computer science;programming language;static analysis	Graphics	-22.56034792204998	33.118115911405425	21040
5c8f4fa43fed377bedab9fa7c8251b3e2d40edd5	agent-based resource discovery and selection for dynamic grids	grid scheduling;filtering;protocols;computational grid;resource discovery;agent based;processor scheduling;resource allocation;grid scheduling process;contract net protocol;dynamic grid computing;resource management;telecommunication computing;contracts;agent based resource discovery;scheduling;resource management systems;ip networks;scheduling grid computing resource allocation;computer science;uniform resource locators;grid computing;resource management system;resource selection process;grid computing processor scheduling protocols filtering computer science telecommunication computing resource management ip networks uniform resource locators contracts;resource selection process agent based resource discovery dynamic grid computing grid scheduling process resource management systems	The massive amount of resources on computational grids raises the question of efficient resource discovery and selection. In this paper we present an agent-based approach to these two phases of a grid scheduling process. The approach is based on client agents which act on behalf of grid users, and search for resources in a network of resource representatives that are registries of resource characteristics. After potentially suitable resources are discovered, client agents carry out negotiations directly with agents representing local resource management systems. This selection process first determines the willing resources with a contract-net protocol and then uses current load information and a more accurate post-discovery search to determine the optimum set of resources for the task in hand	agent-based model;autonomous robot;client (computing);client honeypot;contract net protocol;jade;java;prototype;requirement;scheduling (computing);synergy	George Kakarontzas;Ilias K. Savvas	2006	15th IEEE International Workshops on Enabling Technologies: Infrastructure for Collaborative Enterprises (WETICE'06)	10.1109/WETICE.2006.18	filter;communications protocol;real-time computing;resource allocation;computer science;resource management;operating system;database;distributed computing;contract net protocol;scheduling;grid computing	HPC	-32.46960568876967	50.48350575171793	21049
7e1db212e2cfdb6aa6c3300932021293c037e20d	cmsm: an efficient and effective code management for software managed multicores	spm;smm architecture;correct management cost calculation;code management overhead;scratchpad memory;multi-core processor;explicit code;code;management cost calculation;storage management;local scratchpad memory;instruction;software managed multicore;cell spe;memory hierarchy;multiprocessing systems;effective code management;code mapping for software managed multicores;branch consideration;software managed multicores;code management;heuristic cmsm;embedded systems;local memory;data management;efficient code management execution;multi core processor	As we scale the number of cores in a multicore processor, scaling the memory hierarchy is a major challenge. Software Managed Multicore (SMM) architectures are one of the promising solutions. In an SMM architecture, there are no caches, and each core has only a local scratchpad memory. If all the code and data of the task mapped to a core do not fit on its local scratchpad memory, then explicit code and data management is required. In this paper, we solve the problem of efficiently managing code on an SMM architecture. We extend the state of the art by: i) correctly calculating the code management overhead, ii) even in the presence of branches in the task, and iii) developing a heuristic CMSM (Code Mapping for Software Managed multicores) that results in efficient code management execution on the local scratchpad memory. Our experimental results collected after executing applications from MiBench suite [1] on the Cell SPEs (Cell is an SMM architecture) [2], demonstrate that correct management cost calculation and branch consideration can improve performance by 12%. Our heuristic CMSM can reduce runtime in more than 80% of the cases, and by up to 20% on our set of benchmarks.	computer data storage;function object;heuristic;image scaling;memory hierarchy;multi-core processor;overhead (computing);scratchpad memory	Ke Bai;Jing Lu;Aviral Shrivastava;Bryce Holton	2013	2013 International Conference on Hardware/Software Codesign and System Synthesis (CODES+ISSS)		computer architecture;parallel computing;real-time computing;computer science	HPC	-5.87123557103652	50.04723225918107	21116
328b197b43b84e93b6725ed57bc41a97f5fbc663	hcube: a server-centric data center structure for similarity search	query identifier hcube server centric data center structure similarity search information society internet zettabytes zb big data bigtable mapreduce dynamo;query processing;servers vectors routing hamming distance reflective binary codes big data organizations;hamming similarity similarity search big data data center;computer centres;query processing computer centres internet;data center;internet;big data;hamming similarity;similarity search	The information society is facing a sharp increase in the amount of information driven by the plethora of new applications that sprouts all the time. The amount of data now circulating on the Internet is over zettabytes (ZB), resulting in a scenario defined in the literature as Big Data. In order to handle such challenging scenario, the deployed solutions rely not only on massive storage, memory and processing capacity installed in Data Centers (DC) maintained by big players all over the globe, but also on shrewd computational techniques, such as Big Table, MapReduce and Dynamo. In this context, this work presents a DC structure designed to support the similarity search. The proposed solution aims at concentrating similar data on servers physically close within a DC, accelerating the recovery of all data related to searches performed using a primitive get(k, sim), in which k represents the query identifier, i.e., the data used as reference, and sim a similarity level.	big data;computer data storage;cosine similarity;data center;data model;fault tolerance;file server;hamming distance;identifier;load balancing (computing);mapreduce;multipath routing;semantic similarity;server (computing);similarity search;space-filling curve;window function;yahoo! answers;zettabyte	Rodolfo da Silva Villaça;Rafael Pasquini;Luciano Bernardes de Paula;Maurício F. Magalhães	2013	2013 IEEE 27th International Conference on Advanced Information Networking and Applications (AINA)	10.1109/AINA.2013.139	data center;the internet;big data;computer science;operating system;data mining;database;law;world wide web;computer security	DB	-20.26782762682499	52.80200259953194	21136
b6026aea5fae53bb94da8dbcfb1f01c845e13c52	a new parallel graph reduction model and its machine architecture			graph reduction	Makoto Amamiya	1987			theoretical computer science;machine learning;distributed computing;parallel random-access machine	HPC	-10.12846456195848	42.441074032891535	21166
506fde1cf4f31ca0c369083cfebd956cff7d240a	static analysis meets distributed fault-tolerance: enabling state-machine replication with nondeterminism	compile-time static analysis;state-machine replication;preliminary evaluation;restores consistency;leverages application-level insight;second-hand source;lock-step synchronization;current performance overhead;nondeterministic checkpoint;new client request;inter-disciplinary approach	Midas is an inter-disciplinary approach to supporting state-machine replication for nondeterministic distributed applications. The approach exploits compile-time static analysis to identify both first-hand and second-hand sources of nondeterminism. Subsequent runtime compensation occurs through either the transfer of nondeterministic checkpoints or the reexecution of inserted code, and restores consistency among replicas before each new client request. The approach avoids the need for lock-step synchronization and leverages application-level insight to address only the nondeterminism that matters. Our preliminary evaluation demonstrates Midas’ feasibility and current performance overheads.	byzantine fault tolerance;callback (computer programming);compile time;compiler;concurrency (computer science);distributed computing;nondeterministic algorithm;run time (program lifecycle phase);state machine replication;static program analysis;synergy	Joseph G. Slember;Priya Narasimhan	2006			real-time computing;computer science;theoretical computer science;distributed computing	PL	-21.914197377674526	38.58625947134411	21226
44451171bc8446d6f6abe8122712d103cceb8109	multiprocessor virtual machine systems with special control unit organisation	thesis		control unit;multiprocessing;virtual machine	Theophilos Skevofilax	1977			computer architecture;parallel computing;real-time computing;computer science	HPC	-9.875883400804549	43.31475800549949	21254
cfe7480e8c996401832e87e0e2afdf34e0cf24e9	the algebra of connectors - structuring interaction in bip	algebraic formalization;binary fusion operator;component based systems;ports and harbors;and modeling;fusion reactions;interconnections;architecture real time and embedded systems system architectures integration and modeling systems specification methodology interconnections subsystems;interconnections subsystems;system architectures;object oriented programming;matrix algebra;set theory;integration;behavior interaction priority algebraic formalization connectors bip component framework binary fusion operator unary typing operator component model;connectors;equivalence relation;efficient implementation;algebra;synchronization;object oriented programming algebra;bip component framework;component model;integration and modeling;unary typing operator;system architecture;architecture;behavior interaction priority;systems specification methodology;information theory;real time and embedded systems	We provide an algebraic formalization of connectors in the BIP component framework. A connector relates a set of typed ports. Types are used to describe different modes of synchronization, in particular, rendezvous and broadcast. Connectors on a set of ports P are modeled as terms of the algebra AC(P), generated from P by using a binary fusion operator and a unary typing operator. Typing associates with terms (ports or connectors) synchronization types - trigger or synchron - that determine modes of synchronization. Broadcast interactions are initiated by triggers. Rendezvous is a maximal interaction of a connector that includes only synchrons. The semantics of AC(P) associates with a connector the set of its interactions. It induces on connectors an equivalence relation which is not a congruence as it is not stable for fusion. We provide a number of properties of AC(P) used to symbolically simplify and handle connectors. We provide examples illustrating applications of AC(P), including a general component model encompassing methods for incremental model decomposition and efficient implementation by using symbolic techniques.	linear programming	Simon Bliudze;Joseph Sifakis	2008	IEEE Trans. Computers	10.1109/TC.2008.26	embedded system;synchronization;parallel computing;real-time computing;information theory;computer science;theoretical computer science;architecture;equivalence relation;programming language;algorithm;set theory;algebra	Vision	-30.50531254555385	32.726549902010255	21319
e7f143bf35f183626eb0d8b65d5716532f59a43d	software fault tolerance in architectures with hierarchical protection levels	fault tolerance computer architecture protection hardware redundancy voting software testing programming profession control systems microprocessors;software reliability fault tolerant computing;fault tolerant;multiprocessor systems;software fault tolerance;fault tolerant computing;error propagation;error detection;software reliability;multiprocessor systems architectures hierarchical protection levels software fault tolerance hierarchical privilege levels rings descriptors memory protection separated virtual address spaces ring crossings energy points programming layer recovery layer process interactions recovery metaprogram rpm run time behavior application program error detection recovery reconfiguration privilege levels error propagation intel 80286	The effect on software fault tolerance of hardware features such as hierarchical privilege levels (rings), the use of descriptors for memory protection, separated virtual address spaces, and ring crossings that enforce specific energy points is considered. A strategy that uses a separate programming layer, the recovery layer, to handle fault-tolerant aspects of process interactions is discussed. The recovery metaprogram (RPM) which monitors the run-time behavior of the application program and coordinates error detection, recovery, and reconfiguration, is examined, focusing on privilege levels, which provide protection against error propagation, RMP implementation, and conversations. The intel 80286 has been used as a sample implementation vehicle, but most of the discussion applies to any machine with a similar range of features. Extension to multiprocessor systems is indicated.<<ETX>>	error detection and correction;interaction;memory protection;multiprocessing;propagation of uncertainty;protection ring;reference implementation;risk management plan;software fault tolerance;software propagation	Brenda M. Ozaki;Eduardo B. Fernández;Ehud Gudes	1988	IEEE Micro	10.1109/40.7770	embedded system;fault tolerance;parallel computing;real-time computing;error detection and correction;n-version programming;computer science;propagation of uncertainty;operating system;general protection fault;software quality;software fault tolerance	OS	-24.951605425287507	41.25222774186714	21327
ace8ec07ca041e7ae35ca1c3d6d5f3c30f4668ee	an approach to splitting atoms safely: extended abstract	observability;atomic action;granularity;concurrent programs	The intention of this paper is to make a contribution to (compositional) development methods for concurrent programs. The topics touched on include interference, atomicity, observability and granularity. The paper sets out some requirements for an approach to developing systems by “splitting atoms safely”.	atomicity (database systems);interference (communication);requirement	Cliff B. Jones	2006	Electr. Notes Theor. Comput. Sci.	10.1016/j.entcs.2005.11.051	real-time computing;observability;granularity;computer science;theoretical computer science;mathematics;distributed computing	Logic	-26.114877041238614	33.30519236055436	21347
1908d19b07b0706112912deb72e2a7a6b11b3652	viewbox: integrating local file systems with cloud storage services	viewbox detects;file system;view manager;cloud storage service;cloud helper;cloud copy;local file system;local corruption;automatic cloud;cloud-based file synchronization service;local file	Cloud-based file synchronization services have become enormously popular in recent years, both for their ability to synchronize files across multiple clients and for the automatic cloud backups they provide. However, despite the excellent reliability that the cloud back-end provides, the loose coupling of these services and the local file system makes synchronized data more vulnerable than users might believe. Local corruption may be propagated to the cloud, polluting all copies on other devices, and a crash or untimely shutdown may lead to inconsistency between a local file and its cloud copy. Even without these failures, these services cannot provide causal consistency. To address these problems, we present ViewBox, an integrated synchronization service and local file system that provides freedom from data corruption and inconsistency. ViewBox detects these problems using ext4-cksum, a modified version of ext4, and recovers from them using a user-level daemon, cloud helper, to fetch correct data from the cloud. To provide a stable basis for recovery,ViewBox employs the view manager on top of ext4-cksum. The view manager creates and exposes views, consistent inmemory snapshots of the file system, which the synchronization client then uploads. Our experiments show that ViewBox detects and recovers from both corruption and inconsistency, while incurring minimal overhead.	backup;causal consistency;cloud computing;cloud storage;daemon (computing);experiment;file synchronization;loose coupling;microsoft sync framework;overhead (computing);shutdown (computing);upload;user space	Yupu Zhang;Chris Dragga;Andrea C. Arpaci-Dusseau;Remzi H. Arpaci-Dusseau	2014			real-time computing;computer science;operating system;database;distributed computing;computer security	OS	-23.372619957191667	50.99296053698695	21371
54d5107b9ff52db488b9e4372373b365557e3c75	elastic stream processing in the cloud		Stream processing is a computing paradigm that has emerged from the necessity of handling high volumes of data in real time. In contrast to traditional databases, stream processing systems perform continuous queries and handle data on-the-fly. Today, a wide range of application areas relies on efficient pattern detection and queries over streams. The advent of Cloud computing fosters the development of elastic stream processing platforms which are able to dynamically adapt based on different cost-benefit tradeoffs. This article provides an overview of the historical evolution and the key concepts of stream processing, with special focus on adaptivity and Cloud-based elasticity. Copyright c © 2012 John Wiley & Sons, Ltd.	cloud computing;database;elasticity (cloud computing);john d. wiley;load shedding;operating environment;pattern recognition;privacy;programming paradigm;requirement;scalability;stream processing;traceability	Waldemar Hummer;Benjamin Satzger;Schahram Dustdar	2013	Wiley Interdiscip. Rev. Data Min. Knowl. Discov.	10.1002/widm.1100	real-time computing;computer science;data mining;database;distributed computing	DB	-28.28405445712764	60.02159126063933	21399
2f034649de5fb75bb3a8961e3d37a17ffc9872de	a framework for proactive fault tolerance	clustering proactive fault tolerance adaptation;fault tolerant;system application execution proactive fault tolerance policy checkpoint restart approach failure impact minimization modular architecture;checkpoint restart approach;proactive fault tolerance;proactive fault tolerance policy;system recovery;system recovery fault tolerance;clustering;adaptation;fault tolerance;system application execution;systems and applications;fault tolerance fault tolerant systems laboratories availability large scale systems monitoring prototypes computer applications communication system control national security;failure impact minimization;modular architecture	Fault tolerance is a major concern to guarantee availability of critical services as well as application execution. Traditional approaches for fault tolerance include checkpoint/restart or duplication. However it is also possible to anticipate failures and proactively take action before failures occur in order to minimize failure impact on the system and application execution. This document presents a proactive fault tolerance framework. This framework can use different proactive fault tolerance mechanisms, i.e., migration and pause/un-pause. The framework also allows the implementation of new proactive fault tolerance policies thanks to a modular architecture. A first proactive fault tolerance policy has been implemented and preliminary experimentations have been done based on system-level virtualization and compared with results obtained by simulation.	application checkpointing;fault tolerance;process migration;prototype;requirement;scalability;simulation;system monitor;transaction processing system	Geoffroy Vallée;Kulathep Charoenpornwattana;Christian Engelmann;Anand Tikotekar;Chokchai Leangsuksun;Thomas Naughton;Stephen L. Scott	2008	2008 Third International Conference on Availability, Reliability and Security	10.1109/ARES.2008.171	reliability engineering;real-time computing;engineering;distributed computing;software fault tolerance	HPC	-25.260430021094447	43.21045480817686	21401
0efc0d1ee8b322955a8fca76fd629ccb1c8adb87	scheduling of hybrid battery-supercapacitor control instructions for longevity in systems with power gating		The in-rush current due to wake-up of power gating (PG) components causes faster discharge of battery. This work introduces an instruction controlled hybrid battery-supercapacitor (B-SC) system for longer battery life in systems with instruction controlled PG. Two instructions have been introduced along with architectural support. The first instruction disconnects the battery from the PG components if the charge in the supercapacitor greater than or equal to the charge required by wake-up of PG components. The other instruction connects the battery to the PG components for recharging the supercapacitor. Disconnecting the battery during wake-up minimizes rate capacity effect (C-rate) for longer battery life. An algorithm is designed to schedule the proposed battery control instructions within a program having PG instructions. The efficacy of the proposed method is evaluated on MiBench and MediaBench benchmark programs. The proposed method reduces C-rate by an average of 14.25% at the cost of average performance loss of 6.87%.	algorithm;benchmark (computing);best, worst and average case;discharger;elegant degradation;embedded system;power gating;scheduling (computing)	Sumanta Pyne	2018		10.1145/3218603.3218609	real-time computing;battery (electricity);power gating;scheduling (computing);computer science;supercapacitor;inrush current	Arch	-5.5699772616468595	55.85945169205811	21408
b4af8ba1725365ef909257d8f8108a0558560411	the weakest failure detector for solving election problems in asynchronous distributed systems	distributed system;unreliable failure detector;crash failure;systeme reparti;averia franca;detection panne;failure detection;asynchronisation;resolucion problema;asynchronous system;captador medida;measurement sensor;sistema repartido;capteur mesure;asynchronism;failure detector;defaillance;asynchronous distributed system;failures;panne franche;deteccion falla;fallo;asincronia;problem solving;resolution probleme;consensus problem	This paper is about the weakest failure detector to solve the Election problem in asynchronous distributed systems. We first discuss the relationship between the Election problem and the Consensus problem in asynchronous distributed systems with unreliable failure detectors. Chandra and Toueg have stated that Consensus is solvable in asynchronous systems with unreliable failure detectors. But, in contrast to the Consensus problem, the Election problem is impossible to solve with unreliable failure detectors even with a single crash failure. More precisely, the weakest failure detector that is needed to solve this problem is a Perfect Failure Detector, which is strictly stronger than the weakest failure detector that is needed to solve Consensus.	distributed computing;failure detector	Sung-Hoon Park	2002		10.1007/3-540-36087-5_109	asynchronous system;real-time computing;consensus;computer science;distributed computing;chandra–toueg consensus algorithm;computer security;algorithm;failure detector	Theory	-21.93567900811548	43.898076870361905	21410
a09bf9d1acd37676712896fe5d5a09cc317f9d21	garbage collection for control systems	low priority;real time;garbage collection;control system;high priority;garbage collector;hard real time	This paper describes a scheme for garbage collection suitable for hard real-time applications. The approach supports both periodic high-priority processes and low-priority processes. Garbage collection work is done exclusively during execution of low-priority processes. A prototype garbage collector has been implemented for a C++ real-time kernel. The results confirms that high-priority processes can be guaranteed sub-millisecond response times and meet tight	c++;garbage collection (computer science);prototype;real-time clock;real-time computing	Boris Magnusson;Roger Henriksson	1995		10.1007/3-540-60368-9_32	manual memory management;garbage;real-time computing;computer science;control system;operating system;garbage collection;programming language	OS	-10.165630349633068	59.93671635513451	21421
022a4cabf4985fed91c154147ab3d20f42c13f8e	compiling fortran 8x array features for the connection machine computer system	common subexpression elimination	The Connection Machine® computer system supports a data parallel programming style, making it a natural target architecture for Fortran 8x array constructs. The Connection Machine Fortran compiler generates VAX code that performs scalar operations and directs the Connection Machine to perform array operations. The Connection Machine virtual processor mechanism supports elemental operations on very large arrays. Most array operators and intrinsic functions map into single instructions or short instruction sequences. Noncontiguous array sections, array-valued subscripts, and parallel constructs such as WHERE and FORALL are also readily accommodated on the Connection Machine. In addition to such customary optimizations as common subexpression elimination, the CM Fortran compiler minimizes data motion for aligning array operations, minimizes transfers between the Connection Machine and the VAX and minimizes context switching for masked computations.	cartesian closed category;common subexpression elimination;compiler;computation;computer;connection machine;context switch;data parallelism;elemental;fortran;inter-process communication;intrinsic function;parallel computing;programming style;supercomputer;triplet state;vax	Eugene Albert;Kathleen Knobe;Joan D. Lukas;Guy L. Steele	1988		10.1145/62115.62121	computer architecture;parallel computing;common subexpression elimination;computer science;array access analysis;programming language	HPC	-12.753391520646108	37.24738428113834	21515
c1558284c7a6fae87e132904c8f939fa25494ae7	a second opinion on data flow machines and languages	computers;computer languages;general and miscellaneous mathematics computing and information science;programming language;iterative algorithms;lan interconnection;counting circuits;programming profession;array processors;data flow processing;process control;arithmetic;programming 990200 mathematics computers;data flow computing;data flow;architecture;iterative algorithms hardware arithmetic computer languages data flow computing counting circuits process control lan interconnection programming profession;programming languages;hardware	Simultaneity is a key to high-speed computation. Assuming hardware components of a given speed, it is the only remaining consideration in achieving raw speed. Simultaneity can be shackled by dependences, however, and years of hardware and software work have been devoted to understanding the types of dependences and how they can be obeyed or removed from a computation. Dependence types. There are three types of depen-denceI: data, control, and resource. The first two arise in programs and the third in machines. Therefore, exact definitions depend on the type of language and machine under consideration, although many nearly universal dependences exist. We will discuss three types of data dependencel (see Kuck et al.2 for a fourth type): flow dependence, output dependence, and antidependence. Flow dependence exists from the computation to the use of a variable. Output dependence exists between two subsequent computations of the same variable. Antidependence exists from the use of a variable to its next computation. These three types ensure that the intended values are, in fact, used in a computation. Control dependence types vary from language to language. For example, loop dependences exist from a loop header to each statement inside the loop, conditional dependences exist from an IF to its THEN and ELSE parts, and GOTO dependences exist from a GOTO to its destination. Resource dependences arise when programs are compiled for and executed on a particular machine. For example , the existence of an adder and a multiplier that can be sequenced simultaneously by the control unit allows these two (but no more) arithmetic operations to be executed at once. A four-way interleaved memory allows simultaneous access to four words, but no more. A single program counter, a single arithmetic unit, and a single memory led to the so-called von Neumann machine, and these resource dependences were reflected in the definition of Fortran and other high-level programming languages. Dependence observation. Given a problem to solve on some machine, it is useful to observe dependences at five points in the selection, preparation, and execution of an algorithm. These are in (1) algorithm choice, (2) programming , (3) compiling, (4) instruction processing (control unit), and (5) instruction execution (processor, memory, interconnection). A given algorithm has certain built-in data dependences. For example, in certain iterative computations, an iterate must be computed before it can be used. However , other algorithms that solve the same problem might have less sequential …	adder (electronics);algorithm;arithmetic logic unit;canonical account;compiler;computation;control flow;control unit;dataflow architecture;dependence analysis;fortran;goto;high- and low-level;high-level programming language;interconnection;interleaved memory;iteration;iterative method;loop invariant;program counter;von neumann architecture	Daniel Gajski;David A. Padua;David J. Kuck;Robert H. Kuhn	1982	Computer	10.1109/MC.1982.1653942	computer science;artificial intelligence;theoretical computer science;architecture;operating system;software engineering;process control;programming language	Arch	-13.99465273559606	33.613422808342	21538
d021b8bcec02d09b43fa5c4fb16a0515f332d066	an object-based metasystem for distributed high performance simulation and product realization	high performance;physical simulation	 The Simulation Intranet/Product Database Operator (SI/PDO)is a cadre system which comprises one element of a multi-disciplinary distributedand distance computing initiative known as DisCom2at SandiaNational Laboratories. The SI/PDO is an architecture for satisfyingSandia's long term goal of providing integrated software services for highdelity full physics simulations in a high performance, distributed, anddistance computing environment. This paper presents the initial... 	meta-system;simulation	David J. Miller;Ruthe L. Vandewart	1999			real-time computing;simulation;computer engineering	HPC	-31.43338994723038	46.38257600598942	21540
2fe2304b79f19fd869cf9c612eb92c3a0f6e909c	data-driven tasks and their implementation	task performance;performance evaluation;processor scheduling;parallel programming;input constraint;scheduling algorithm;dataflow;task scheduling task parallelism dataflow;multicore platforms data driven tasks dynamic task parallelism many core processors runtime scheduler parallel programming model fork join structures task graph structures data driven futures dynamic single assignment rule scheduling algorithms put operation fine grain blocking delayed async;multiprocessing systems;task parallelism;task graphs;parallel programming model;task scheduling;coarse grained;processor scheduling multiprocessing systems parallel programming;parallel processing synchronization java runtime dynamic scheduling program processors containers;dynamic scheduling	Dynamic task parallelism has been identified as a prerequisite for improving productivity and performance on future many-core processors. In dynamic task parallelism, computations are created dynamically and the runtime scheduler is responsible for scheduling the computations across processor cores. The sets of task graphs that can be supported by a dynamic scheduler depend on the underlying task primitives in the parallel programming model, with various classes of fork-join structures used most often in practice. However, many researchers have advocated the benefits of more general task graph structures, and have shown that the use of these task graph structures can lead to improved performance. In this paper, we propose an extension to task parallelism called Data-Driven Tasks (DDTs) that can be used to create arbitrary task graph structures. Unlike a normal task that starts execution upon creation, a DDT specifies its input constraints in an await clause containing a list of Data-Driven Futures (DDFs). A DDF can be viewed as a container with a full/empty state that obeys a dynamic single-assignment rule. The runtime scheduler will then ensure that a task is only scheduled when all the DDFs in its await clause become available (full). There is no constraint on which task performs a put() operation on a DDF. We describe five scheduling algorithms (Coarse-Grain Blocking, Fine-Grain Blocking, Delayed Async, Rollback & Replay, Data-Driven) that can be used to implement DDTs, and include performance evaluations of these five algorithms on a variety of benchmark programs and multi-core platforms. Our results show that the Data-Driven scheduler is the best approach for implementing DDTs, both from the viewpoints of memory efficiency and scalable parallelism.	algorithm;benchmark (computing);blocking (computing);central processing unit;computation;disk data format;futures and promises;manycore processor;multi-core processor;parallel computing;parallel programming model;scalable parallelism;scheduling (computing);task parallelism	Sagnak Tasirlar;Vivek Sarkar	2011	2011 International Conference on Parallel Processing	10.1109/ICPP.2011.87	parallel computing;real-time computing;dynamic priority scheduling;computer science;operating system;dataflow;distributed computing;data parallelism;programming language;scheduling;task parallelism;parallel programming model	HPC	-6.772281858112778	48.440618821864355	21600
dff8eed4c5dc27cf1d6d4005d889e0a182befe4d	a generic prototype to benchmark algorithms and data structures for hierarchical hybrid grids			algorithm;benchmark (computing);prototype	Sebastian Kuckuk;Björn Gmeiner;Harald Köstler;Ulrich Rüde	2013		10.3233/978-1-61499-381-0-813	theoretical computer science;computer science;data structure	EDA	-9.360573873022748	33.88242632950718	21606
da73b6ad8c4f4dae8758fb0dc3ff0e28a72e8328	a minimal synchronization overhead affinity scheduling algorithm for shared-memory multiprocessors	affinity scheduling;independent parallel loop;scheduling algorithm;load balance;article;low synchronization;shared memory multiprocessor	In addition to load balancing and synchronization overhead, affinity is an important consideration for loop scheduling algorithms in modern multiprocessors. Algorithms based on affinity, like affinity scheduling (AFS), do perform better than dynamic algorithms, such as guided self-scheduling (GSS) and trapezoid self-scheduling (TSS). However, there is still room for improvement in affinity scheduling. This paper suggests a modification to AFS which combines the advantages of both GSS and AFS. Experimental results confirm the effectiveness of the proposed modification.		Yi-Min Wang;Ruei-Chuan Chang	1995	International Journal of High Speed Computing	10.1142/S0129053395000130	fair-share scheduling;parallel computing;real-time computing;dynamic priority scheduling;computer science;rate-monotonic scheduling;load balancing;operating system;two-level scheduling;distributed computing;scheduling	Arch	-14.1745218107803	47.007120441058554	21668
76d0fcb165aab46f1bc5e955be79851aafaa1a34	sequence pattern query processing over out-of-order event streams	query processing;probability density function;real time;partial order guarantee sequence pattern query processing out of order event streams complex event processing rfid tracking supply chain management real time intrusion detection aggressive strategy error compensation methods;intrusion detection;partial order guarantee;data mining;rfid tracking;out of order;books;aggressive strategy;time factors;error compensation methods;error compensation;complex event processing;radiofrequency identification query processing;real time intrusion detection;stream processing;process engineering;conservation strategies;out of order query processing delay robustness radiofrequency identification supply chain management intrusion detection data mining engines face detection;radiofrequency identification;supply chain management;out of order event streams;partial order;sequence pattern query processing	Complex event processing has become increasingly important in modern applications, ranging from RFID tracking for supply chain management to real-time intrusion detection. A key aspect of complex event processing is to extract patterns from event streams to make informed decisions in real-time. However, network latencies and machine failures may cause events to arrive out-of-order at the event processing engine. State-of-the-art event stream processing technology experiences significant challenges when faced with out-of-order data arrival including output blocking, huge system latencies, memory resource overflow, and incorrect result generation. To address these problems, we propose two alternate solutions: aggressive and conservative strategies respectively to process sequence pattern queries on out-of-order event streams. The aggressive strategy produces maximal output under the optimistic assumption that out-of-order event arrival is rare. In contrast, to tackle the unexpected occurrence of an out-of-order event and with it any premature erroneous result generation, appropriate error compensation methods are designed for the aggressive strategy. The conservative method works under the assumption that out-of-order data may be common, and thus produces output only when its correctness can be guaranteed. A partial order guarantee (POG) model is proposed under which such correctness can be guaranteed. For robustness under spiky workloads, both strategies are supplemented with persistent storage support and customized access policies. Our experimental study evaluates the robustness of each method, and compares their respective scope of applicability with state-of-art methods.	blocking (computing);complex event processing;correctness (computer science);event stream processing;experiment;intrusion detection system;list of object-relational mapping software;maximal set;persistence (computer science);radio-frequency identification;real-time clock;real-time transcription;robustness (computer science)	Mo Liu;Ming Li;Denis Golovnya;Elke A. Rundensteiner;Kajal T. Claypool	2009	2009 IEEE 25th International Conference on Data Engineering	10.1109/ICDE.2009.95	partially ordered set;intrusion detection system;probability density function;real-time computing;supply chain management;stream processing;computer science;out-of-order execution;complex event processing;data mining;database	DB	-23.38150625190811	48.60478509308949	21678
80b2ac1158dcf627f7df3f0333a166f0b7c68ca1	an empirical evaluation of high-level synthesis languages and tools for database acceleration	databases;hardware design languages;field programmable gate arrays fpga;database algorithm;software tools database management systems field programmable gate arrays high level languages high level synthesis;median operators;software developer;empirical analysis;sorting;systemverilog;hardware field programmable gate arrays sorting probes databases hardware design languages acceleration;probes;acceleration;high level synthesis;programmer experiences;high level synthesis languages hash joins median operator sorting database algorithms chisel legup altera opencl bluespec systemverilog dbms acceleration database management system acceleration software developers fpgas hls tools hls languages high level synthesis tools;conference report;database systems;empirical evaluations;field programmable gate arrays;hardware	High Level Synthesis (HLS) languages and tools are emerging as the most promising technique to make FPGAs more accessible to software developers. Nevertheless, picking the most suitable HLS for a certain class of algorithms depends on requirements such as area and throughput, as well as on programmer experience. In this paper, we explore the different trade-offs present when using a representative set of HLS tools in the context of Database Management Systems (DBMS) acceleration. More specifically, we conduct an empirical analysis of four representative frameworks (Bluespec SystemVerilog, Altera OpenCL, LegUp and Chisel) that we utilize to accelerate commonly-used database algorithms such as sorting, the median operator, and hash joins. Through our implementation experience and empirical results for database acceleration, we conclude that the selection of the most suitable HLS depends on a set of orthogonal characteristics, which we highlight for each HLS framework.	algorithm;benchmark (computing);download;expectation propagation;experiment;field-programmable gate array;functional programming;hardware acceleration;high-level synthesis;list of c-family programming languages;majority function;programmer;requirement;software developer;sorting;systemverilog;throughput;universal product code	Oriol Arcas;Geoffrey Ndu;Nehir Sönmez;Mohsen Ghasempour;Adrià Armejach;Javier Navaridas;Wei Song;John Mawer;Adrián Cristal;Mikel Luján	2014	2014 24th International Conference on Field Programmable Logic and Applications (FPL)	10.1109/FPL.2014.6927484	acceleration;embedded system;computer architecture;parallel computing;computer science;sorting;operating system;high-level synthesis;field-programmable gate array	DB	-5.324327109939494	45.83430144759041	21733
d3715c3eaaaeab303f76b640783a72518b55efec	a multithreaded compiler backend for high-level array programming	high performance computing;high-level parallel pro- gramming;array programming;compilers;parallel processing;image processing;data structure	Whenever large homogeneous data structures need to be processed in a non-trivial way, e.g. in computational sciences, image processing, or system simulation, high-level array programming in the style of A PL offers a far more concise and abstract approach than traditional scalar languages such as C/C++ or F ORTRAN-77. The same sort of applications often can also be characterized as performance critical and today represents the major domain for parallel processing. This paper reports on the development of a compiler backend which allows to implicitly generate multithreaded code from high-level array program specifications. On shared memory multiprocessor systems, this code can be executed in parallel without any additional programming effort. After sketching out basic compilation schemes, optimizations on the runtime system are addressed and, finally, experimental runtime figures are presented.	array programming;c++;central processing unit;compiler;computation;computational science;concurrency (computer science);data parallelism;data structure;high- and low-level;image processing;multiprocessing;parallel computing;runtime system;spmd;shared memory;simulation;symmetric multiprocessing;thread (computing)	Clemens Grelck	2003			compiler;parallel computing;runtime system;computer architecture;array programming;computer science;fortran;sort;multiprocessing;data structure;shared memory	HPC	-13.213171690864044	38.72034192741214	21760
72793315fb3a5636cc55c006e5fd29549a91128d	practically realizable efficient data allocation and replication strategies for distributed databases with buffer constraints	storage allocation;object replacement strategy;distributed database;dynamic window mechanism algorithm;caching;competitive algorithms;buffer storage;data replication strategy;data replication;data caching data allocation strategy data replication strategy distributed database system database buffer constraints read write request sequence dynamic window mechanism algorithm object replacement strategy;simulation experiment;distributed database system;database buffer constraints;object allocation;competitiveness;communication cost;competitive analysis;distributed databases costs database systems algorithm design and analysis data analysis buffer storage performance analysis availability communication system control system performance;data caching;buffer capacity;replicated databases;communication cost object allocation distributed database system competitiveness replacement algorithms caching;data allocation strategy;read write request sequence;replacement algorithms;storage allocation buffer storage competitive algorithms replicated databases	In this paper, we address the performance of distributed database systems with buffer constraints. Specifically, our objective is to design and analyze efficient data allocation and replication strategies to minimize the total servicing cost for an arbitrary read/write request sequence, under finite buffer constraints of the nodes in the system. When the available buffer space in a node is not enough to store a copy of an object, the decision has to be made on whether or not we should evict one or more objects in use to give room for the new object copy. In this paper, we design and analyze the data replication strategies with the model of dynamic window mechanism (DWM) algorithm jointly implemented with different types of object replacement strategies (no replacement, LRU, and LFU) commonly found in practice. We consider situations wherein the object sizes are identical as well as heterogeneous. We will show the impact on the performance of the allocation and replication strategies due to the limited local database buffer capacities. We analyze and quantify theoretically (using competitive analysis) the performances of all the proposed algorithms. Further, we perform rigorous simulation experiments to validate the findings with respect to several influencing parameters. Several useful conclusions are drawn based on the experimental results and we highlight the usefulness of the algorithms under different situations	algorithm;bandwidth (signal processing);cc system;central processing unit;competitive analysis (online algorithm);database storage structures;distributed database;dynamic data;experiment;fault tolerance;input/output;least frequently used;noise reduction;object copying;page replacement algorithm;performance;procedural generation;pseudo-lru;real life;replication (computing);simulation;translation lookaside buffer	Xin Gu;Wujuan Lin;Bharadwaj Veeravalli	2006	IEEE Transactions on Parallel and Distributed Systems	10.1109/TPDS.2006.127	competitive analysis;parallel computing;real-time computing;computer science;operating system;database;distributed computing;distributed database;replication	DB	-12.890152358586796	56.99844778300341	21788
77058877da04a8e45c89ef8cdac35fd88181a600	lcd: local combining on demand		Combining methods are highly effective for implementing concurrent queues and stacks. These data structures induce a heavy competition on one or two contention points. However, it was not known whether combining methods could be made effective for parallel scalable data structures that do not have a small number of contention points. In this paper, we introduce local combining on-demand, a new combining method for highly parallel data structures. The main idea is to apply combining locally for resources on which threads contend. We demonstrate the use of local combining on-demand on the common linkedlist data structure. Measurements show that the obtained linked-list induces a low overhead when contention is low and outperforms other known implementations by up to 40% when contention is high.	concurrent computing;data structure;linked list;overhead (computing);scalability;solution stack	Dana Drachsler-Cohen;Erez Petrank	2014		10.1007/978-3-319-14472-6_24	computer science;stack (abstract data type);distributed computing;thread (computing);synchronization;scalability;concurrent data structure;small number;queue;data structure	AI	-16.615165255136798	54.3534174850404	21796
428b2a5501575cdf6fe63096aa17eca1c02ef051	zgoubi: a startup guide for the complete beginner	websearch;hep	Zgoubi is a code which can be used to model accelerators and beam lines, comprised of magnetic and electrostatic elements. It has been extensively developed since the mid-1980s to include circular accelerators and related beam physics. It has been made freely available by its author on a code development site, including a Users' Guide, a data treatment/graphic interfacing tool, and many examples [1].	circular polarization	Annette Pressman;Kai Hock	2014	CoRR		physics	HPC	-8.42691547802865	34.42425584700399	21801
a82c548915a92a8ed912834bc5e3780ba13f8fc9	reducing the energy cost of computing through efficient co-scheduling of parallel workloads	multi-core system;increasing number;overall energy;energy consumption;efficient co-scheduling;future computing cluster;energy cost;multiple workloads;parallel workloads;novel multi-level technique;multi-core processor;energy efficiency;multicore processor;multicore processing;chip;instruction sets;multi core processor;radiation detectors;energy efficient;radiation detector;benchmark testing;measurement	Future computing clusters will prevalently run parallel workloads to take advantage of the increasing number of cores on chips. In tandem, there is a growing need to reduce energy consumption of computing. One promising method for improving energy efficiency is co-scheduling applications on compute nodes. Efficient consolidation for parallel workloads is a challenging task as a number of factors, such as scalability, inter-thread communication patterns, or memory access frequency of the applications affect the energy/performance tradeoffs. This paper evaluates the impact of co-scheduling parallel workloads on the energy consumed per useful work done on real-life servers. Based on this analysis, we propose a novel multi-level technique that selects the best policy to co-schedule multiple workloads on a multi-core processor. Our measurements demonstrate that the proposed multi-level co-scheduling method improves the overall energy per work savings of the multi-core system up to 22% compared to state-of-the-art techniques.	inter-process communication;multi-core processor;multi-level technique;real life;scalability;scheduling (computing);semiconductor consolidation	Can Hankendi;Ayse Kivilcim Coskun	2012	2012 Design, Automation & Test in Europe Conference & Exhibition (DATE)		multi-core processor;embedded system;parallel computing;real-time computing;computer science;operating system;particle detector	HPC	-5.133331178972402	54.37598654912731	21818
37a69350a63b7316b7b5e0d067a3e2236181355b	declarative programming for conventional mimd multiprocessors	declarative programming;distributed memory;data distribution;indexation	In this paper we demonstrate that declarative programming is a suitable vehicle for the programming of conventional distributed-memory multiprocessors. This is achieved by applying several transformations to the compiled declarative program to extract iteration-level parallelism. The transformations first group individual instructions into sequential light-weight processes, and then insert primitives to: (1) cause array allocation to be distributed over multiple processors, (2) cause computation to follow the data distribution by inserting an index filtering mechanism into a given loop and spawning a copy of it on all PEs; the filter causes each instance of that loop to operate on a different subrange of the index variable.	declarative programming;mimd	Lubomir F. Bic;John M. A. Roy;Mark Nagel	1992		10.1007/3-540-55599-4_111	computer architecture;parallel computing;declarative programming;mimd;reactive programming;computer science;programming paradigm;procedural programming;inductive programming;fifth-generation programming language;programming language	Arch	-13.941364751671975	38.392143970065085	21820
1bb26ea7d1b03257456cfe05c9c2ec463843c925	iopro: a parallel i/o profiling and visualization framework for high-performance storage systems	parallel file systems;hdf5;parallel netcdf;i o software stack;performance visualization;code instrumentation;mpi io	Efficient execution of large-scale scientific applications requires high-performance computing systems designed to meet the I/O requirements. To achieve high-performance, such data-intensive parallel applications use a multi-layer layer I/O software stack, which consists of high-level I/O libraries such as PnetCDF and HDF5, the MPI library, and parallel file systems. To design efficient parallel scientific applications, understanding the complicated flow of I/O operations and the involved interactions among the libraries is quintessential. Such comprehension helps identify I/O bottlenecks and thus exploits the potential performance in different layers of the storage hierarchy. To profile the performance of individual components in the I/O stack and to understand complex interactions among them, we have implemented a GUI-based integrated profiling and analysis framework, IOPro. IOPro automatically generates an instrumented I/O stack, runs applications on it, and visualizes detailed statistics based on the user-specified metrics of interest. We present experimental results from two different real-life applications and show how our framework can be used in practice. By generating an end-to-end trace of the whole I/O stack and pinpointing I/O interference, IOPro aids in understanding I/O behavior and improving the I/O performance significantly.	benchmark (computing);cognitive dimensions of notations;data-intensive computing;end-to-end principle;experiment;graphical user interface;hierarchical data format;high- and low-level;input/output;interaction;interference (communication);layer (electronics);library (computing);mathematical optimization;memory hierarchy;message passing interface;netcdf;overhead (computing);parallel i/o;real life;requirement;run time (program lifecycle phase);runtime system;supercomputer;throughput;transaction processing system	Seong Jo Kim;Yuanrui Zhang;Seung Woo Son;Mahmut T. Kandemir;Wei-keng Liao;Rajeev Thakur;Alok N. Choudhary	2014	The Journal of Supercomputing	10.1007/s11227-014-1329-0	instrumentation;parallel computing;computer science;theoretical computer science;operating system;distributed computing;programming language;hierarchical data format	HPC	-9.020452373860245	46.302737797382655	21821
7f3ad73b38bfeecb5ee0c8cc9ffc02ef8d1d34c4	new connectivity and msf algorithms for ultracomputer and pram			microsoft solutions framework;ultracomputer	Baruch Awerbuch;Tripurari Singh	1983			distributed computing;parallel computing;computer science	Theory	-10.110584071311669	42.38454244126996	21827
811f33cc6d0d9e963758b5d4ef6e73ac0928576c	designing and parameterizing a workflow for optimization: a case study in biomedical imaging	scientific application;workflow design;optimisation;workflow management;early experience;project management;resource management;knowledge management;runtime environment;biomedical imaging;compiler;design optimization;data analysis;large scale;design optimization biomedical imaging program processors runtime environment knowledge representation optimizing compilers environmental management knowledge management project management resource management;workflow manager workflow design workflow parameterization optimization biomedical imaging application program compiler knowledge representation;application program;program compilers biomedical imaging data analysis knowledge representation optimisation;workflow manager;optimization;resource availability;knowledge representation;program compilers;optimizing compilers;environmental management;program processors;workflow parameterization	This paper describes our experience to date employing the systematic mapping and optimization of large- scale scientific application workflows to current and future parallel platforms. The overall goal of the project is to integrate a set of system layers - application program, compiler, run-time environment, knowledge representation, optimization framework, and workflow manager - and through a systematic strategy for workflow mapping, our approach will exploit the vast machine resources available in such parallel platforms to dramatically increase the productivity of application programmers. In this paper, we describe the representation of a biomedical imaging application as a workflow, our early experiences in integrating the set of tools brought together for this project, and implications for future applications.	compiler;knowledge representation and reasoning;mathematical optimization;medical imaging;programmer;runtime system	Vijay S. Kumar;Mary W. Hall;Jihie Kim;Yolanda Gil;Tahsin M. Kurç;Ewa Deelman;Varun Ratnakar;Joel H. Saltz	2008	2008 IEEE International Symposium on Parallel and Distributed Processing	10.1109/IPDPS.2008.4536411	project management;workflow;compiler;multidisciplinary design optimization;computer science;knowledge management;resource management;database;windows workflow foundation;data analysis;workflow management system;workflow engine;workflow technology	HPC	-7.737993974407484	44.48843306680342	21837
7d2de7d6ada94d93f61f69edfd48ab9801b2b91c	matching database access patterns to storage characteristics	database system;device independence;robust performance	Today’s storage interfaces hide device-specific details, simplifying system development and device interoperability. However, they prevent database systems from exploiting devices’ unique performance characteristics. Abstract and device-independent annotations to existing storage interfaces can cleanly expose key device characteristics that improve performance and simplify manual tuning. By automatically matching access patterns to device strengths, a database storage manager can achieve robust performance even with workloads competing for the same storage resource. For example, disk-optimized accesses result in simultaneous improvement of up to 3x for DSS workloads and 7% for a competing OLTP workload. As another example, accesses to relational tables can take advantage of MEMS-based storage parallelism to achieve order of magnitude improvements in selective scans.	address space;computer data storage;database storage structures;flat memory model;interoperability;microelectromechanical systems;online transaction processing;parallel computing	Jiri Schindler	2003			real-time computing;computer science;data mining;database	DB	-18.056402110284576	53.302802147221634	21868
1032e28f9a015b1a55a8517688f3bbd1cd206c3d	massconf: automatic configuration tuning by leveraging user community information	configural processing;capacity planning;resource allocation;workload profiling;measurements;mapreduce;optimal algorithm;job scheduling	Configuring modern enterprise software can be extremely difficult because their behaviors often depend on large numbers of configuration parameters. Software vendors can simplify the configuration process for new users by collecting and using configuration information from existing users. In particular, we observe that (1) a 'good' configuration may work well for many different users, and (2) multiple configurations may work well for each user. We leverage these observations to design MassConf, a system that collects and uses existing configurations to automatically configure new software installations. Our evaluations with a case study confirm our observations and show that MassConf successfully reaches the targets of many more new installations than an existing efficient optimization algorithm.	algorithm;enterprise software;mathematical optimization;virtual community	Wei Zheng;Ricardo Bianchini;Thu D. Nguyen	2011		10.1145/1958746.1958786	real-time computing;resource allocation;computer science;job scheduler;data mining;database;management;measurement	OS	-23.814561523208262	56.59016171370017	21876
1a93e53ae3bda4b4e2c51791a9cc6cd307e3a9fc	performance evaluation of a parallel i/o architecture	performance evaluation;parallel i o;massively parallel processor;reading and writing	Presented are the resr.dts of a study conducted to evaluate the performance of parailel 1/0 on a massiveiy parallel processor (MPP). The network traversal and total processing times are calculated for [/0 reads and wriles whiie vaying the 1/0 and non-I/O request rates and the request size. A Iso studied is the performance impact of I/O and non-I/O traffic on each other. The resuits show that the system is scalable for I/O loads considered; however, the scalability is limited by 1/0 node saturation or considerable network contention.	division by zero;goodyear mpp;input/output;parallel i/o;parallel computing;performance evaluation;scalability	Sandra Johnson Baylor;Caroline Benveniste;Yarsun Hsu	1995		10.1145/224538.224645	computer architecture;parallel computing;distributed computing	HPC	-10.94425887879705	48.31445067974878	21921
9de105d105a2a98a073358b952ff754ff9bfd615	parallel real-time olap on multi-core processors	multi core olap;real time;parallel;index structures;processors	One of the most powerful and prominent technologies for knowledge discovery in decision support systems is online analytical processing (OLAP). Most of the traditional OLAP research, and most of the commercial systems, follow the static data cube approach proposed by Gray et.al. and materialize all or a subset of the cuboids of the data cube in order to ensure adequate query performance. Practitioners have called for some time for a real-time OLAP approach where the OLAP system gets updated instantaneously as new data arrives and always provides an up-to-date data warehouse for the decision support process. However, a major problem for realtime OLAP are significant performance issues with large scale data warehouses. The aim of our research is to address these problems through the use of efficient parallel computing methods. In this paper, we present a parallel real-time OLAP system for multi-core processors. To our knowledge, this is the first real-time OLAP system that has been parallelized and optimized for contemporary multi-core architectures. Our system allows for multiple insert and multiple query transactions to be executed in parallel and in real-time. We evaluated our method for a multitude of scenarios (different ratios of insert and query transactions, query transactions with different amounts of data aggregation, different database sizes, etc.), using the TPC-DS “Decision Support” benchmark data set. As multi-core test platforms, we used an Intel Sandy Bridge F. Dehne School of Computer Science, Carleton University, Ottawa, Canada. Faculty Fellow, IBM Center for Advanced Studies, Toronto, Canada. Tel.: +1-613-520-2600 ext. 1236 Fax: +1-613-520-4334 URL: www.dehne.net E-mail: frank@dehne.net H. Zaboli School of Computer Science, Carleton University, Ottawa, Canada. Tel.: +1613-520-2600 ext. 4588 Fax: +1613-520-4334 E-mail: hzaboli@connect.carleton.ca 2 F. Dehne & H. Zaboli processor with 4 cores (8 hardware supported threads) and an Intel Xeon Westmere processor with 20 cores (40 hardware supported threads). The tests demonstrate that, with increasing number of processor cores, our parallel system achieves close to linear speedup in transaction response time and transaction throughput. On the 20 core architecture we achieved, for a 100 GB database, a better than 0.25 second query response time for real-time OLAP queries that aggregate 25% of the database. Since hardware performance improvements are currently, and in the foreseeable future, achieved not by faster processors but by increasing the number of processor cores, our new parallel real-time OLAP method has the potential to enable OLAP systems that operate in real-time on large databases.	aggregate data;benchmark (computing);central processing unit;code segment;computer science;cuboid;data aggregation;data cube;database;decision support system;ext js javascript framework;fax;ibm tivoli storage productivity center;intel core (microarchitecture);like button;multi-core processor;online analytical processing;parallel computing;real-time clock;real-time computing;real-time operating system;real-time transcription;real-time web;response time (technology);sandy bridge;speedup;throughput;westmere (microarchitecture)	Frank Dehne;Hamidreza Zaboli	2015	IJDWM	10.4018/ijdwm.2015010102	parallel computing;online analytical processing;computer science;central processing unit;parallel;data mining;database	DB	-13.213958789961657	51.876935079780296	21950
1ec6ae5dcb20f236746dfe16629a4b79cc7ecc9d	model composition for scheduling analysis in platform design	compositional approach;analytical models;timing behavior;platform based design;global system timing properties;processor scheduling;scheduling analysis;resource management;schedulability analysis;embedded system;computer networks;platform design;optimal control;embedded systems;high level synthesis;integrated circuit design;formal verification;component behavior;scheduling;integrated circuit design formal verification scheduling timing embedded systems high level synthesis;performance analysis;formal analysis;abstract models scheduling analysis platform design compositional approach timing behavior event interfacing component behavior global system timing properties;event interfacing;embedded computing;model composition;timing processor scheduling performance analysis computer networks embedded computing embedded system optimal control resource management analytical models delay;timing;abstract models	We present a compositional approach to analyze timing behavior of complex platforms with different scheduling strategies. The approach uses event interfacing in order to couple previously incompatible analysis techniques which provide subsystem and component behavior. Based on these interfaces, event propagation using abstract models is used to derive global system timing properties.	event (computing);heuristic (computer science);preemption (computing);scheduling (computing);software propagation	Kai Richter;Dirk Ziegenbein;Marek Jersak;Rolf Ernst	2002		10.1145/513918.513993	embedded system;real-time computing;optimal control;formal verification;computer science;resource management;distributed computing;high-level synthesis;scheduling;integrated circuit design	Embedded	-7.876415209839082	60.06707999319251	22003
077bbe9430afe4d1f9072ef7bd09a31702676b26	conflict-tolerant real-time features	formal framework;verification;software;system verification;formal specification;composition;clocks;real time;controller;program verification;feature interaction;cost accounting;feature extraction;safety;vehicle crash testing;school of automation;computer science automation formerly;conflict tolerant real time features;real time systems;time constraint	This paper addresses the problem of detecting and resolving conflicts due to timing constraints imposed by features in real-time systems. We consider systems composed of a base system with multiple features or controllers, each of which independently advise the system on how to react to input events so as to conform to their individual specifications. We propose a methodology for developing such systems in a modular manner based on the notion of conflict tolerant features that are designed to continue offering advice even when their advice has been overridden in the past. We give a simple priority based scheme for composing such features. This guarantees the maximal use of each feature. We provide a formal framework for specifying such features, and a compositional technique for verifying systems developed in this framework.	maximal set;memory controller;real-time clock;real-time computing;real-time transcription;sensor;verification and validation	Deepak D'Souza;Madhu Gopinathan;S. Ramesh;Prahladavaradan Sampath	2008	2008 Fifth International Conference on Quantitative Evaluation of Systems	10.1109/QEST.2008.16	composition;real-time computing;verification;simulation;controller;feature extraction;computer science;formal specification;programming language;computer security;cost accounting	Embedded	-25.785762477034666	35.06594405456564	22013
a4b18119e6454f65b38b84e5aa618b9c53e76064	multi-grid, multi-user workflows in the p-grade grid portal	application development;globus toolkit;grid portal;school of no longer in use;electronics and computer science;workflow management;access grid;computational grid;collaborative work;multi user;large scale;collaborative environment;community building;collaborative problem solving;quality of service;grid computing;problem solving environment;grid system	Computational Grids connect resources and users in a complex way in order to deliver nontrivial qualities of services. According to the current trend various communities build their own Grids and due to the lack of generally accepted standards these Grids are usually not interoperable. As a result, large scale sharing of resources is prevented by the isolation of Grid systems. Similarly, people are isolated, because the collaborative work of Grid users is not supported by current environments. Each user accesses Grids as an individual person without having the possibility of organizing teams that could overcome the difficulties of application development and execution more easily. The paper describes a new workflow-oriented portal concept that solves both problems. It enables the interoperability of various Grids during the execution of workflow applications, and supports users to develop and run their Grid workflows in a collaborative way. The paper also introduces a classification model that can be used to identify workflow-oriented Grid portals based on two general features: Ability to access multiple Grids, and support for collaborative problem solving. Using the approach the different potential portal types are introduced, their unique features are discussed and the portals and Problem Solving Environments (PSE) of our days are classified. The P-GRADE Portal as a Globus-based implementation for the classification model is also presented.	communications satellite;geographic coordinate system;graphical user interface;grid computing;high- and low-level;interoperability;large hadron collider;middleware;multi-user;open grid services architecture;organizing (structure);p-grade portal;portals;problem solving;testbed;world wide web;worldwide lhc computing grid	Péter Kacsuk;Gergely Sipos	2005	Journal of Grid Computing	10.1007/s10723-005-9012-6	workflow;quality of service;computer science;database;distributed computing;community building;rapid application development;management;world wide web;grid computing	HPC	-31.190054960059523	52.00817172570392	22027
5ec1cc95a1954869024f38708d763b88c36d333d	parallelizing algorithms for symbolic computation using ||maple||	declarative programming;symbolic computation;parallel algorithm;computer algebra system;lines of code;logic programming;nonlinear equation;computer algebra systems;parallel architecture;logic programs;parallel programs;computer algebra	||MAPLE|| (speak: parallel Maple) is a portable system for parallel symbolic computation. The system is built as an interface between the parallel declarative programming language Strand and the sequential computer algebra system Maple, thus providing the elegance of Strand and the power of the existing sequential algorithms in Maple. The implementation of different parallel programming paradigms shows that it is fairly easy to parallelize even complex algebraic algorithms using this system. Sample applications (among them algorithms solving multivariate nonlinear equation systems) are implemented on various parallel architectures. For example a straightforward parallelization of the complex and important problem of real root isolation has been parallelized using a generic Strand program of fewer than 20 lines of code and a slight modification of 5 lines in the original sequential Maple source. Even with such a simple modification we gained a speed-up of 5 times, that is better than those reported by others in the literature.	algorithm;computer algebra system;declarative programming;maple;nonlinear system;parallel computing;programming language;programming paradigm;source lines of code;strand (programming language);symbolic computation	Kurt Siegl	1993		10.1145/155332.155351	symbolic computation;declarative programming;computer science;theoretical computer science;parallel algorithm;programming language;logic programming;source lines of code;algorithm;parallel programming model	PL	-11.902882127630932	36.002185280278	22086
7476081702fa81dd790f3f7087686fb1fd15066e	a cache-based hardware accelerator for memory data movements	hand held device;multi core processor;hardware accelerator;communication model;proof of concept;indexation;message passing	T his dissertation presents a hardware accelerator that is able to accelerate large (including non-parallel) memory data movements, in particular memory copies, performed traditionally by the processors. As today’s processors are tied with or have integrated caches with varying sizes (from several kilobytes in hand-held devices to many megabytes in desktop devices or large servers), it is only logical to assume that data to-be-copied by a memory copy is already present within the cache. This is especially true when considering that such data often must be processed first. This means that the presence of the caches can be utilized to significantly reduce the latencies associated with memory copies, when a “smarter” way to perform the memory copy operation is used. Therefore, the proposed accelerator for memory copies takes advantage of the presence of these caches and introduces a redirection mechanism that links the original data (in the cache) to the copied addresses (in a newly added indexing table). The proposed solutions avoid cache pollution and duplication of data, and efficiently schedule the access to the main memory, thus effectively reducing the latency associated with memory copies. Moreover, the proposed accelerator supports copies of cache line and word granularity, can be connected to a direct-mapped or a set-associative cache, and can efficiently reduce the memory copy bottleneck in single core processors and in multi-core processors that execute a message passing communication model. The proposed solutions have been implemented in a FPGA as a proof of concept and incorporated in a simulator running several benchmarks to determine the performance gains of the proposal. In particular, for the receiver side of the TCP/IP stack, the proposed solutions can reach speedups from 2.96 to 4.61 times and reduce the number of instructions executed by 26% to 44%.	benchmark (computing);cpu cache;cache pollution;central processing unit;computer data storage;desktop computer;field-programmable gate array;hardware acceleration;internet protocol suite;kilobyte;megabyte;message passing;mobile device;multi-core processor;simulation	Filipa Duarte	2008			bus sniffing;uniform memory access;shared memory;interleaved memory;semiconductor memory;parallel computing;real-time computing;cache coloring;distributed memory;cpu cache;computer hardware;computer science;computer memory;conventional memory;extended memory;registered memory;cache pollution;cache-only memory architecture;memory map;non-uniform memory access;memory management	Arch	-10.148220013498705	52.437275135788354	22092
a7ddd737490f1504e927a98ccafa57cc49ac75e0	a memory-efficient data redistribution algorithm	distributed application;limit distribution;madre;memory limited;redistribution;mpi;distributed	Many memory-bound distributed applications require frequent redistribution of data. Pinar and Hendrickson investigated two families of memory-limited redistribution algorithms. The first family has many advantages, but fails on certain inputs, and, if not implemented carefully, may lead to an explosion in the number of local data copies. The second family eliminates the possibility of failure at the expense of considerable additional overhead. We carefully analyze these algorithms and develop a modified method that potentially combines advantages of each. The resulting algorithm has been implemented in MADRE and experiments reveal its performance to be superior to that of other MADRE algorithms in most cases.	algorithm;computation;distributed computing;experiment;memory bound function;overhead (computing);thread (computing)	Stephen F. Siegel;Andrew R. Siegel	2009		10.1007/978-3-642-03770-2_28	computer science;theoretical computer science;distributed computing;algorithm	DB	-18.45336074728881	49.57908034471023	22094
2fd494899480dcb1ac7a56c2bb036c8dfdca507e	a grid resource broker with network bandwidth-aware job scheduling for computational grids	globus toolkit;computational grid;resource broker;job scheduling	This work presents a workflow-based computational resource broker whose main functions are matching available resources with user requests and considering network information statuses during matchmaking. The resource broker provides an interface for accessing available and appropriate resources via user credentials. We use the Ganglia and NWS tools to monitor resource status and network-related information, respectively. We also report on using the Globus Toolkit to construct a grid platform called the TIGER project that integrates the distributed resources of five universities in Taichung, Taiwan, where the resource broker was developed. The proposed broker provides secure, updated information about available resources and serves as a link to the diverse systems available in the Grid.	job scheduler;job shop scheduling;scheduling (computing)	Chao-Tung Yang;Sung-Yi Chen;Tsui-Ting Chen	2007		10.1007/978-3-540-72360-8_1	broker pattern;computer science;job scheduler;operating system;storage resource broker;database;distributed computing;world wide web	HPC	-30.676702501233308	52.209146748596936	22113
a21c972077f85d23f769c6ac4e4afa283d38de49	paraprox: pattern-based approximation for data parallel applications	data parallel;gpu;approximation;accuracy aware computing	Approximate computing is an approach where reduced accuracy of results is traded off for increased speed, throughput, or both. Loss of accuracy is not permissible in all computing domains, but there are a growing number of data-intensive domains where the output of programs need not be perfectly correct to provide useful results or even noticeable differences to the end user. These soft domains include multimedia processing, machine learning, and data mining/analysis. An important challenge with approximate computing is transparency to insulate both software and hardware developers from the time, cost, and difficulty of using approximation. This paper proposes a software-only system, Paraprox, for realizing transparent approximation of data-parallel programs that operates on commodity hardware systems. Paraprox starts with a data-parallel kernel implemented using OpenCL or CUDA and creates a parameterized approximate kernel that is tuned at runtime to maximize performance subject to a target output quality (TOQ) that is supplied by the user. Approximate kernels are created by recognizing common computation idioms found in data-parallel programs (e.g., Map, Scatter/Gather, Reduction, Scan, Stencil, and Partition) and substituting approximate implementations in their place. Across a set of 13 soft data-parallel applications with at most 10% quality degradation, Paraprox yields an average performance gain of 2.7x on a NVIDIA GTX 560 GPU and 2.5x on an Intel Core i7 quad-core processor compared to accurate execution on each platform.	approximate computing;approximation algorithm;best, worst and average case;cuda;commodity computing;computation;data mining;data parallelism;data-intensive computing;elegant degradation;geforce 500 series;graphics processing unit;kernel (operating system);machine learning;multi-core processor;opencl api;run time (program lifecycle phase);throughput	Mehrzad Samadi;Davoud Anoushe Jamshidi;Janghaeng Lee;Scott A. Mahlke	2014		10.1145/2541940.2541948	parallel computing;real-time computing;computer science;theoretical computer science;approximation;programming language	Arch	-4.719452708342377	45.58598581238269	22163
8d305b0f530eff4c742584361299f0077264c939	an engineering computation oriented grid project: design and implementation	distributed system;outil logiciel;globus toolkit;interfase usuario;interfaz grafica;software tool;systeme reparti;resource discovery;graphical interface;user interface;resource management;service web;web service;qualite service;service utilisateur;grid;gestion recursos;sistema repartido;design and implementation;rejilla;scheduling;grid service;pc cluster;utilisabilite;grille;gestion ressources;interface utilisateur;servicio usuario;usabilidad;quality of service;user service;usability;herramienta software;visual interfaces;interface graphique;service quality;ordonnancement;reglamento;servicio web;calidad servicio	This paper describes a Service-bAsed Grid project for Engineering computation, named SAGE. Based on the Globus toolkit, a grid-service-based architecture oriented to engineering computation is presented. To give grid users good usability, task definition and resource discovery are visually conducted. Whilst, a Quality of Service (QoS) driven user-centric scheduling strategy is proposed, two scheduling methods and steering-enabled visual interfaces are applied for different types of grid users. Result processing can be visualized in the aid of a PC-cluster and a stereopticon. The practices suggest that these mechanisms improve the convenience and QoS.	computation;computer cluster;quality of service;scheduling (computing);stereopticon;usability;while	Xianqing Wang;Qinhuai Zeng;Dingwu Feng;Changqin Huang	2005		10.1007/11428862_131	web service;quality of service;usability;computer science;resource management;operating system;graphical user interface;database;user interface;grid;scheduling;world wide web;service quality	HPC	-28.658999838185274	43.20603561015805	22164
269023e2189b93f2dedb77eba778be79f69af58f	connection bundling with http: supporting interactive applications through web browsers	telecontrol control engineering computing interactive systems internet java online front ends;software;web server application software distributed computing supercomputers joining processes workstations java communication system control world wide web concurrent computing;remote control;pediatrics;data mining;restrictive network environment remote interactive application support web browser distributed environment workstation cluster supercomputer grid computer remote computer transport mechanism java applet web server;online front ends;http channel bundling interactivity remote control remote steering;interactive application;internet;distributed environment;java applet;remote steering;interactivity;joining processes;telecontrol;control engineering computing;http channel bundling;web server;interactive systems;java	"""In a distributed environment, scientists using clusters, supercomputers, and the grid, may often find themselves in a place apart from the computing facilities. Therefore, controlling and steering interactive applications executing remotely requires a transport mechanism connecting the scientist's workstation with the remote computer. The concept presented in this paper only needs minimal prerequisites to fulfil this task. On the user side, a web browser executing a Java applet is sufficient, on the remote computer, a web server able to start the remote application is required. The """"connecting bundling'' method presented herein allows demanding remote interactive applications to be controlled even in a restrictive network environment."""	computer cluster;hypertext transfer protocol;ibm tivoli storage productivity center;java applet;product bundling;remote computer;server (computing);supercomputer;web server;workstation;x window system	Herbert Rosmanith;Jens Volkert	2009	2009 Eighth International Symposium on Parallel and Distributed Computing	10.1109/ISPDC.2009.12	the internet;computer science;operating system;distributed computing;interactivity;java;world wide web;web server;distributed computing environment;java applet;remote control	HPC	-33.390890958778435	48.391843456337654	22181
5389fccd8e6679331eb4042d34f53ca8af3b9f5e	translation-triggered prefetching	virtual memory;cache prefetching;dram	We propose translation-enabled memory prefetching optimizations or TEMPO, a low-overhead hardware mechanism to boost memory performance by exploiting the operating system's (OS) virtual memory subsystem. We are the first to make the following observations: (1) a substantial fraction (20-40%) of DRAM references in modern big- data workloads are devoted to accessing page tables; and (2) when memory references require page table lookups in DRAM, the vast majority of them (98%+) also look up DRAM for the subsequent data access. TEMPO exploits these observations to enable DRAM row-buffer and on-chip cache prefetching of the data that page tables point to. TEMPO requires trivial changes to the memory controller (under 3% additional area), no OS or application changes, and improves performance by 10-30% and energy by 1-14%.	amiga walker;big data;cpu cache;cache prefetching;critical path method;data access;dynamic random-access memory;link prefetching;memory controller;operating system;overhead (computing);page table;sparse matrix	Abhishek Bhattacharjee	2017		10.1145/3037697.3037705	interleaved memory;parallel computing;page fault;memory rank;static random-access memory;cas latency;computer hardware;computer science;virtual memory;operating system;memory controller;universal memory;registered memory;dram;memory map	Arch	-9.52682608954949	53.467013793739845	22241
bbf7dea6e1457412219dde7f0bf2638e356f5468	vector computer architecture and processing techniques	computer architecture	Publisher Summary   Vector- or array-processing computers are essentially designed to maximize the concurrent activities inside a computer and to match the bandwidth of data flow to the execution speed of various subsystems within a computer. This chapter reviews architectural advances in vector-processing computers. It describes the two major classes of vector machines—namely, the pipeline computers and array processors. Problems associated with designing pipeline computers are also presented with examples from the Texas Instruments Advanced Scientific Computer (TI-ASC), Control Data STring ARay (STAR-100) and CYBER-205 Computers, Cray Research CRAY-1, and Floating-Point Systems AP-120B. The chapter describes the architectures of recently developed SIMD array processors. Further, it examines the development experiences of the Burroughs Scientific Processor (BSP) and the Goodyear Aerospace Massively Parallel Processor (MPP). Recent research works on array and pipeline processors are also summarized. The chapter concludes with the evaluation of the performance of pipeline and array processors and explores various optimization techniques for vector operations. Hardware, software, and algorithmic issues of vector-processing systems and future trends of vector computers are also discussed.	computer architecture	Kai Hwang;Shun-Piao Su;Lionel M. Ni	1981	Advances in Computers	10.1016/S0065-2458(08)60497-0	computer architecture;vector processor;parallel computing;computer science;theoretical computer science;hybrid computer	Arch	-8.040787961122598	39.43487836928964	22252
0654c90ea5aadcfe297d800f86078902e694d365	more efficient network class loading through bundling	perforation	In this paper, we describe bundling, a technique for the transfer of files over a network. The goal of bundling is to group together files that tend to be needed in the same program execution and that are loaded close together. We describe an algorithm for dividing a collection of files into bundles based on profiles of file-loading behavior. Our motivation for bundling is to improve the performance of network class loading in Java. We examine other network class loading mechanisms and discuss their performance tradeoffs. Bundling is able to combine the strengths of both on-demand strategies and archivebased strategies. We present experimental results that show how bundling can perform well in a variety of network conditions.	algorithm;archive;classful network;dictionary;java;product bundling;test set	David Hovemeyer;William Pugh	2001			real-time computing;simulation;engineering;operations management	PL	-19.76331143996224	36.472610810615976	22284
7263f4c4fb26b22983f84a71f06c0225ec56ab1b	the improved delay time-based (idtb) algorithm to perform computation type application processes	delay time based dtb algorithm;power aware computing information systems parallel processing;energy aware distributed systems;improved delay time based idtb algorithm;servers;green it improved delay time based idtb algorithm delay time based dtb algorithm server cluster systems energy aware distributed systems;computational modeling;time factors;energy consumption;server cluster systems;total energy consumption reduction improved delay time based algorithm idtb algorithm computation type application processes high performance information systems server cluster systems electric energy improved dtb algorithm;clustering algorithms;green it;power demand;servers clustering algorithms energy consumption time factors power demand computational modeling delays;delays	In order to realize high performance information systems, server cluster systems are widely used. Here, since application processes are performed on multiple servers, the larger electric energy is consumed in a server cluster. The delay time-based (DTB) algorithm is discussed to select a server for each request process so that the total energy consumption of a server cluster to perform application processes can be reduced. However, in the DTB algorithm, if the average interarrival time of request processes is shorter than the minimum computation time of each process, the average response time of each process increases. This means, computation resources in a server cluster cannot be efficiently used in the DTB algorithm. In this paper, we propose an improved DTB (IDTB) algorithm to reduce the total energy consumption of a server cluster and more efficiently to use the computation resources for performing application processes in a server cluster even if the average interarrival time of request processes is shorter than the minimum computation time of each process. We evaluate the IDTB algorithm compared with the basic round-robin (RR), improved power consumption laxity-based (IPCLB), and DTB algorithms.	algorithm;clustered file system;computation;computer cluster;daisy digital talking book;information system;response time (technology);round-robin scheduling;server (computing);time complexity	Tomoya Enokido;Makoto Takizawa	2014	2014 17th International Conference on Network-Based Information Systems	10.1109/NBiS.2014.47	green computing;real-time computing;computer science;theoretical computer science;operating system;distributed computing;cluster analysis;computational model;server	Embedded	-17.80411176452688	59.282615047701285	22363
03fd9152659d926f05e59390225ca5697216e7e8	simulation factory: taming application configuration and workflow on high-end resources	databases;libraries;software;remote access;groupware;cluster computing;taming application configuration;open source license simulation factory computational science high performance computing resources batch queue systems taming application configuration;open source license;high performance computing;best practice;simulation factory;computational science;computational modeling;high performance computing resources;batch queue systems;queueing system;production facilities;high performance computer;source code;software computational modeling production facilities buildings high performance computing databases libraries;configuration management;buildings;groupware configuration management	Computational Science on large high performance computing resources is hampered by the complexity of these systems. Much of this complexity is due to low-level details on these resources that are exposed to the application and the end user. This includes (but is not limited to) mechanisms for remote access, configuring and building applications from source code, and managing simulations and their output files via batch queue systems.	computation;computational science;high- and low-level;job queue;simulation;supercomputer	Michael W. Thomas;Erik Schnetter	2010	2010 11th IEEE/ACM International Conference on Grid Computing	10.1109/GRID.2010.5698010	supercomputer;real-time computing;computer cluster;computer science;operating system;database;distributed computing;configuration management;management;computational model;best practice;source code	HPC	-29.59106267013397	51.54137530865108	22367
63a34631712dfd2ab37d38df37a440d220aca7b2	communication protocol negotiation in a composite data stream processing service		Data streaming services gain popularity but still only few works are focused on their composition and its detailed management, like communication protocol negotiation. In this paper, we describe a continued work on a platform for automated composition of distributed data stream processing services. With the platform a process of composite service building is simplified and negotiation among services automated. In the following sections we will present an overview of the platform, describe implemented negotiation approaches and their phases, and finally compare them in an experimental study.	communications protocol;stream processing	Pawel Stelmach;Pawel Swiatek;Patryk Schauer	2013		10.1007/978-3-319-01857-7_65	database;distributed computing;computer network	DB	-31.854542349560198	46.94276067358893	22370
10d43c933b290be75295c6c8501feeea8353edf2	customizable deployment, composition, and hosting of distributed java applications	distributed application;virtual machine;machine unique;java virtual machine;customization;personnalisation;langage java;machine virtuelle;single machine;maquina unica;personalizacion;middleware;lenguaje java;application repartie;maquina virtual;java language	Deploying and running Java applications on a single host is covered by standard approaches. However, when applications are dynamically deployed on distributed hosts, the situation is quite different. In this context, applications are likely to be composed of classes, located in remote repositories and possibly related to identical class names. Hence, the typical class loader approach is no longer feasible to resolve the right byte code. Moreover, the native Java Runtime Environment (JRE) has originally not been designed to host more than one application concurrently within a single Java Virtual Machine (JVM). Thus, there are also unresolved issues concerning hosting distributed applications. In this paper, we present a new approach for a customizable Java application middleware with respect to the topics of application deployment, composition and hosting. Finally, the application of the approach within a distributed middleware platform is presented, wherein applications are customizably deployed, dynamically composed and concurrently hosted.	byte;distributed computing;interceptor pattern;internet;java classloader;java virtual machine;middleware;name mangling;odin (firmware flashing software);on the fly;software deployment;tuple space	Stefan Paal;Reiner Kammüller;Bernd Freisleben	2002		10.1007/3-540-36124-3_56	embedded system;real-time computing;computer science;virtual machine;operating system;strictfp;middleware;database;distributed computing;real time java;programming language;java;java annotation	PL	-29.29609608762594	42.04853999559376	22433
c2597755e38acba6c18e6b1c84021eda99bea9a8	dynamic partitioning in a class of parallel systems	multiprocessor interconnection networks;concurrent computing;lattices;resource fragments;system dynamics;resource management;computer networks;parallel systems;dynamic partitioning;lattices power system modeling large scale systems computer science computer networks concurrent computing hardware costs multiprocessor interconnection networks resource management;computer science;lattice model dynamic partitioning parallel systems resource fragments;power system modeling;lattice model;parallel processing;large scale systems;hardware;partial order	Many parallel systems, such as PASM, can be partitioned into several independent subsystems. These systems have the capability to simultaneously execute tasks with various sizes and computation structures. When some tasks are completed, part of a system will become idle and should be properly reconfigured for new tasks. Inappropriate reconfiguration strategies may create many resource fragments, as the fragmentation problem in paging memory schemes, and may result in a loss of computation power. This problem can be alleviated by partitioning a parallel system dynamically, i.e., according to the instantaneous load changes of the system. Partitioning a parallel system includes two basic processes: splitting the system or a subsystem into smaller subsystems, and combining unallocated subsystems into larger subsystems. These two processes are investigated analytically based on a lattice model which uses a special partial ordering relation on a set. Complexities of these two processes are also analyzed. Any system which can be modeled by a lattice, in terms of the partitioning capabilities, can be dynamically partitioned based on the results presented here.	computation;fragmentation (computing);lattice model (physics);paging	Menkae Jeng;Howard Jay Siegel	1988		10.1109/DCS.1988.12497	partially ordered set;parallel processing;parallel computing;lattice model;concurrent computing;computer science;resource management;theoretical computer science;operating system;lattice;database;distributed computing;system dynamics	HPC	-12.158994876497973	48.38920871144108	22463
4d40abc5cfe292a937b85f6a51d1555250bf1a84	process migration in the galaxy distributed operating system	minimal residual dependencies;efficiency;operating systems computers distributed processing;distributed processing;distributed operating system;galaxy;minimal interference;transparency;robustness;process migration;process migration transparency galaxy distributed operating system minimal interference minimal residual dependencies efficiency robustness;operating systems computers;operating systems interference sprites computer information science robustness availability utility programs network topology	Transparency, minimal interference, minimal residual dependencies, efficiency and robustness are some of the features that are felt necessary for process migration mechanisms in distributed operating systems. None of the process migration mechanisms proposed so far possess all these features. In the paper the authors describe a process migration mechanism that possesses all the features mentioned above. This process migration mechanism has been developed as a part of the GALAXY distributed operating system. >	distributed operating system;process migration	Pradeep Kumar Sinha;Kyu Sung Park;Xiaohua Jia;Kentaro Shimizu;Mamoru Maekawa	1991		10.1109/IPPS.1991.153844	real-time computing;computer science;theoretical computer science;distributed computing	HPC	-25.14909976508173	46.02048146998984	22515
0510794661b8cbb58e1137774c7c8f1431f8320c	a preprocessing system of the eulash: an environment for efficient use of multiprocessors with local memory	preprocessing system;software;processor and memory architecture;shared memory	The EULASH environment is proposed for making the best use of a multiprocessor with a high speed local memory and slow shared memory. It consists of the preprocessing system, the kernel, and the library for management of variables and synchronization. On the EULASH, a program is written with light weight threads using only shared variables. The preprocessing system restructures the program in order to use both memory system efficiently without users’ optimization. By the optimization using the trial run, between 50% and 90% of shared variables are converted so as not to use the shared memory. From the result of evaluations, the execution time with optimization is about 13%–20% better than that without optimization on a switch connected multiprocessor.	compiler;kernel (operating system);library (computing);mathematical optimization;multiprocessing;preprocessor;run time (program lifecycle phase);shared variables;shared memory	Junji Yamamoto;D. Hattori;Jun-ichi Yamato;T. Tokuyoshi;Y. Yamaguchi;Hideharu Amano	1995			data diffusion machine;flat memory model;registered memory;conventional memory;distributed computing;parallel computing;memory map;computer science;cache-only memory architecture;interleaved memory;uniform memory access	Arch	-7.176753649353873	48.50880189870904	22525
a8c2ca452ee9e94766012cc1d7eb1fda3e1550ae	exploiting heterogeneous parallelism with the heterogeneous programming library	libraries;programmability;code generation;portability;parallelism;opencl;heterogeneity	While recognition of the advantages of heterogeneous computing is steadily growing, the issues of programmability and portability hinder its exploitation. The introduction of the OpenCL standard was a major step forward in that it provides code portability, but its interface is even more complex than that of other approaches. In this paper we present the Heterogeneous Programming Library (HPL), which permits the development of heterogeneous applications addressing both portability and programmability while not sacrificing high performance. This is achieved by means of an embedded language and data types provided by the library with which generic computations to be run in heterogeneous devices can be expressed. A comparison in terms of programmability and performance with OpenCL shows that both approaches offer very similar performance, while outlining the programmability advantages of HPL.	baseline (configuration management);c++;central processing unit;circuit rank;code generation (compiler);compile time;compiler;computation;distributed memory;embedded system;general-purpose markup language;graphics processing unit;handy board;heterogeneous system architecture;heterogeneous computing;kelly criterion;library (computing);memory management;metaprogramming;opencl api;overhead (computing);parallel computing;performance per watt;programmer;programming productivity;self-modifying code;software portability;topography	Moisés Viñas;Zeki Bozkus;Basilio B. Fraguela	2013	J. Parallel Distrib. Comput.	10.1016/j.jpdc.2013.07.013	computer architecture;parallel computing;computer science;heterogeneity;programming language;code generation	HPC	-5.858827795990719	43.94978780635578	22612
0bfe52c4e90fcb4f65d77cec9fc0e6840fa652df	a majority consensus approach to concurrency control for multiple copy databases	distribution;computers;networks;distributed database;clocks;solutions general;distributed computing;computations;multiprocess systems;update synchronization;data bases;computer networks;computer network;distributed computation;concurrency control;distributed databases;clock synchronization;algorithms;control;distributed data processing;distributed control;problem solving;synchronization electronics	A “majority consensus” algorithm which represents a new solution to the update synchronization problem for multiple copy databases is presented. The algorithm embodies distributed control and can function effectively in the presence of communication and database site outages. The correctness of the algorithm is demonstrated and the cost of using it is analyzed. Several examples that illustrate aspects of the algorithm operation are included in the Appendix.	algorithm;concurrency control;correctness (computer science);database;distributed control system	Robert H. Thomas	1979	ACM Trans. Database Syst.	10.1145/320071.320076	distribution;clock synchronization;real-time computing;computer science;theoretical computer science;concurrency control;computation;database;distributed computing;distributed database;scientific control	DB	-23.789586875551034	44.57389622664475	22706
ab2f4d4ca7191202aa81dfcfbef1a89a5f736383	distributed computing in the workstation environment	time-consuming algorithm;apl server;user application;idle workstations;unused processor time;large performance gain;workstation environment;local area network;distributed computing;object oriented programming;client server;distributed processing;expert systems	Exploiting unused processor time in workstation environments can result in large performance gains in user applications. A parallel each operator is shown which implements client-server based distributed processing. A time-consuming algorithm is sped up by using idle workstations in a local area network as APL servers.	apl;algorithm;client–server model;distributed computing;server (computing);workstation	Johann Mitlöhner	1993		10.1145/166197.166218	local area network;distributed algorithm;real-time computing;computer science;operating system;distributed computing;distributed object;distributed design patterns;object-oriented programming;expert system;client–server model	HPC	-13.512132276916539	43.86242444908518	22762
ffcbe42fbc0d931ce102d5e08e84b9cee9414869	parallel hompack: a case study in parallel mathematical software	mathematical software		mathematical software	Kashmira M. Irani;Calvin J. Ribbens;Layne T. Watson	1991			computational science;mathematical software;computer science	SE	-7.9439254877062755	37.507745313231254	22790
c62ab7751a188beec708bb78d27020bd86ac0d40	web-based decision-support system methodology for smart provision of adaptive digital energy services over cloud technologies	statistical analysis broadband networks cloud computing decision support systems digital subscriber lines energy measurement middleware open systems pattern clustering power engineering computing power system measurement smart power grids software agents;energy consultants;web interoperable technologies;cloud technologies;smart provision;web middleware;data management;adaptive digital energy services;hypercube topology;greek energy measurements;software agent based parallel analysis;distributed cloud architecture;internet;energy consumptions;clustering algorithms;energy information systems;greek energy measurements web based decision support system methodology smart provision adaptive digital energy services cloud technologies energy information systems energy consumptions internet energy consultants energy services web interoperable technologies distributed cloud architecture adsl broadband connections clustering algorithms web middleware hypercube topology data management software agent based parallel analysis;adsl broadband connections;web based decision support system methodology;energy services	Energy information systems, which manage energy consumptions over internet, have been evolving over the past decade and can be considered as a part of a specialised sequential decision process, regarding the provision of personalised energy services to the community. The aim of this study is to develop and present an innovative decision-support system and cloud computing software methodology that brings together energy consultants, consumers, energy services procedures and modern web interoperable technologies. The authors propose a web-based knowledge system, using distributed cloud architecture and metering grids over ADSL broadband connections. By using some clustering algorithms and a web middleware, energy profiles over time are analysed and observed. The resulting clusters and centroids are projected and statistically analysed over time, producing a centroid-locus. Hypercube topology was used for efficient data management and software agent-based parallel analysis. The system operates efficiently on a multi-tier cloud-based middleware that generates in real-time using various service software components to the end consumers. The case study on real Greek energy measurements, for the first time in Greece, indicated a compact and efficient distributed procedure that could analyse and produce adaptive personalised information services. www.ietdl.org	agent-based model;algorithm;asymmetric digital subscriber line;cloud computing;cluster analysis;component-based software engineering;decision support system;information system;internet;interoperability;knowledge-based systems;locus;middleware;multitier architecture;real-time transcription;software agent;web application	Vassilis Nikolopoulos;Giorgos Mpardis;Ioannis Giannoukos;Ioanna Lykourentzou;Vassilis Loumos	2011	IET Software	10.1049/iet-sen.2010.0008	middleware;real-time computing;the internet;simulation;data management;computer science;engineering;cluster analysis;world wide web	HPC	-31.842545082621843	51.00780540403454	22802
3b4bf8acc70b2d62cfdcb13c88cd9371b42d2371	geographical information system application of multiprocessor multidisk image servers	magnetic disc storage;distributed memory systems;image processing equipment;shared memory systems;geographic information systems;visualization parallelism	This contribution analyses the behavior of two kinds of multiprocessor multidisk storage server architectures for a data-intensive application, namely for spatial queries in geographical information systems (GIS). The two kinds of servers are :: (1) a workstation cluster architecture with multiple processors, multiple disks, and a shared-bus shared-memory architecture ; (2) a distributed-memory architecture, similar to the T9000 transputer-based architectures, where processing nodes and disk nodes are connected by a high-throughput crossbar switch. The GIS application under investigation is the map overlay with map at different scales and resolutions.	central processing unit;crossbar switch;data-intensive computing;file server;high-throughput computing;multiprocessing;server (computing);shared memory;throughput;transputer;workstation	Benoit A. Gennart;Roger D. Hersch	1995			shared disk architecture;uniform memory access;distributed shared memory;shared memory;parallel computing;real-time computing;distributed memory;computer science;operating system;distributed computing;geographic information system	Arch	-11.576795037355502	43.80451811124429	22810
76857488338424412ea56e17dd8b7c98703955ff	techniques for file system simulation	behavior modeling;performance;simulation;file system;file systems	Careful simulation-based evaluation plays an important role in the design of file and disk systems. We describe here a particular approach to such evaluations that combines techniques in workload synthesis, file system modeling, and detailed disk behavior modeling. Together, these make feasible the detailed simulation of I/O hardware and file system software. In particular, using the techniques described here is likely to make comparative file system studies more accurate. In addition to these specific contributions, the paper makes two broader points. First, it argues that detailed models are appropriate and necessary in many cases. Second, it demonstrates that detailed models need not be difficult or time consuming to construct or execute.	behavior model;input/output;simulation;systems modeling	Chandramohan A. Thekkath;John Wilkes;Edward D. Lazowska	1994	Softw., Pract. Exper.	10.1002/spe.4380241102	behavioral modeling;real-time computing;computer hardware;performance;computer science;operating system	Metrics	-17.62966424481292	46.35481855555302	22836
1ce655ef438778be1cc503cea005b65cca508612	using control theory for load shedding in data stream management	databases;control systems;control theory;load shedding;formal feedback control load shedding data stream management system database performance;system configuration;database management systems;resource allocation;data processing;drives;mechanical engineering;feedback;engineering management;formal feedback control;resource allocation control theory database management systems feedback;robustness;control theory delay feedback control databases robustness control systems environmental management engineering management mechanical engineering drives;environmental management;data stream management system;feedback control;database performance	Database performance can be greatly affected by environmental and internal dynamics such as workloads and system configurations. Existing strategies to maintain performance under such dynamics are often found to have poor robustness. To remedy this problem, we propose a systematic solution that takes advantages of formal feedback control techniques. In this demo, we show how the control-based solution derived from a dynamic DSMS model can be utilized to guide load shedding with the target of maintaining data processing delays.	control theory;database;feedback;load shedding	Yi-Cheng Tu;Song Liu;Sunil Prabhakar;Bin Yao;William Schroeder	2007	2007 IEEE 23rd International Conference on Data Engineering	10.1109/ICDE.2007.369048	real-time computing;data processing;computer science;feedback;database;distributed computing	DB	-24.670816630907456	48.673491356148176	22854
747966be8199a0feca4b701b6fbaf9e0a1d82116	mvs network file system server: performance considerations				Diana B. Husband	1993			computer network;appleshare;network file system;self-certifying file system;database;shared resource;computer science;file area network	OS	-18.718124673828264	51.95627604430294	22885
cd4f20b786b7be50557de8d7ce349b8dab6a40ab	balancing disk access times in raid5 disk arrays in degraded mode by conditionally prioritizing fork/join requests	repetition probability;lut look up table;crossover;partitioning level;chi square;frequency distribution;xor level	RAID5 disk arrays with rotated parities can tolerate single disk failures by reconstructing missing blocks on demand by XORing the contents of corresponding <i>K</i> blocks on surviving disks by a <i>K</i>-way <i>Fork/Join</i> (<i>F/J</i>) request, which is considered completed after the <i>K</i> disks are accessed. F/J accesses in RAID5 are processed concurrently with interfering disk accesses. The mean response time of F/J and independent/interfering requests: R<sup>F/J</sup>/<sub>K</sub> and R<sup>Ind</sup> and the mean delay from the completion of the first to the last F/J task, known as task dispersion time: T<sup>disp</sup>/<sub>K</sub>, are performance metrics of interest. Given R<sup>F/J</sup>/<sub>K</sub> > R<sup>Ind</sup> with FCFS scheduling, it is desirable to equalize disk access times, but giving a higher nonpreemptive priority to disk accesses due to F/J requests with respect to interfering disk accesses results in R<sup>Ind</sup> & R<sup>F/J</sup>/<sub>K</sub>. We propose a continuum of conditional priority methods based on the fraction F of F/J accesses completed with FCFS scheduling. F = ∞stands for FCFS and F = 0 stands for unconditional priorities. Simulation shows that F = 1/8 with K = 8 yields R<sup>F/J</sup>/<sub>K</sub> ≈ RInd for three distributions of disk requests and in the range of F/J and independent disk requests considered. F can be varied adaptively based on measurement results to balance disk access times.	degraded mode;disk array;fork (software development);response time (technology);scheduling (computing);simulation;standard raid levels;triune continuum paradigm	Alexander Thomasian;Bingxing Liu;Yuhui Deng	2014	SIGARCH Computer Architecture News	10.1145/2669594.2669598	crossover;parallel computing;real-time computing;frequency distribution;chi-square test;computer science;distributed computing	Metrics	-13.847291750246795	56.71950150560384	22913
2afba990524abf7e3724b3c611bba32aaca4b16a	enhancing multicore reliability through wear compensation in online assignment and scheduling	scheduling algorithm;full system reliability analysis;multicore reliability;online technique;optimizes system lifetime;system reliability;system lifetime;algorithm result;online assignment;dynamically-activated task assignment;four-core system;wear compensation;multicore system;benchmark testing;logic synthesis;multicore processing;reliability	System reliability is a crucial concern especially in multicore systems which tend to have high power density and hence temperature. Existing reliability-aware methods are either slow and non-adaptive (offline techniques) or do not use task assignment and scheduling to compensate for uneven core wear states (online techniques). In this article, we present a dynamically-activated task assignment and scheduling algorithm based on theoretical results that explicitly optimizes system lifetime. We also propose a data distillation method that dramatically reduces the size of the thermal profiles to make full system reliability analysis viable online. Simulation results show that our algorithm results in between 27--291% improvement to system lifetime compared to existing techniques for four-core systems.	algorithm;multi-core processor;online and offline;scheduling (computing);simulation	Thidapat Chantem;Xiang Yun;Xiaobo Sharon Hu;Robert P. Dick	2013	2013 Design, Automation & Test in Europe Conference & Exhibition (DATE)		embedded system;electronic engineering;parallel computing;logic synthesis;real-time computing;computer science;theoretical computer science;operating system	EDA	-5.18441994055704	57.53634454095072	22988
5371237cc104d843aa6dd995612e4d932855c485	automatic configuration generation for service high availability with load balancing	configuration generation;high availability;redundancy models;clustered systems;load balancing;availability management framework	The need for highly available services is ever increasing in various domains ranging from mission critical systems to transaction based ones such as banking. The Service Availability Forum (SAForum) has defined a set of services and related API specifications to address the growing need of commercial-off-the-shelf high availability solutions. Among these services, the Availability Management Framework (AMF) is the service responsible for managing the high availability of the application services by coordinating redundant application components deployed on the AMF cluster. To achieve this task, an AMF implementation requires a specific logical view of the organization of the application’s services and components, known as an AMF configuration. Any AMF configuration must be compliant to the concepts and constraints defined in the AMF specifications. Developing manually such a configuration is a complex error prone task that requires extensive domain knowledge. In this paper, we present an approach for the automatic generation of AMF compliant configurations from a set of requirements given by the configuration designer and the description of the software as provided by the vendor. The objective is to alleviate the need of configuration designers to acquire profound domain knowledge and deal with the complexity of handling large number of AMF entities and their relations. One important aspect of the AMF configuration is ranking the service units, when it is required by the redundancy model, for the assignment of the workload by AMF at runtime. Our approach includes a technique for generating these rankings in such a way that guarantees load balancing even after the occurrence of a failure.	action message format;application programming interface;autonegotiation;backup;cognitive dimensions of notations;component-based software engineering;entity;fifth generation computer;high availability;load balancing (computing);mission critical;requirement;run time (program lifecycle phase);software deployment;suicidegirls;superuser;top-down and bottom-up design;user requirements document	Ali Kanso;Ferhat Khendek;Maria Toeroe;Abdelwahab Hamou-Lhadj	2013	Concurrency and Computation: Practice and Experience	10.1002/cpe.2805	parallel computing;real-time computing;computer science;load balancing;operating system;database;distributed computing;high availability;computer security	SE	-30.87971567718201	55.41333067094342	22994
0ef90256dcb87254132dcb2dda035274f79cb4e9	worst-case performance analysis of parallel, communicating software processes	worst case performance analysis;communication behavior;concurrent computing;systemc models;design exploration;application software;system analysis and design;software performance evaluation;software systems;software performance evaluation systems analysis parallel programming;parallel programming;communicating software processes;fpga;software performance;parallel software processes worst case performance analysis static timing analysis systemc models worst case execution time analysis communication behavior worst case response time system design deadlocks data loss communicating software processes;parallel software processes;worst case execution time;system recovery;estimation;permission;systems analysis;system design;performance analysis;static timing analysis;worst case execution time analysis;data loss;worst case response time;deadlocks;community analysis;concurrent process;matlab;performance analysis software performance timing system recovery hardware concurrent computing software systems permission system analysis and design application software;software process;hardware;timing	In this paper we present a method to perform static timing analysis of SystemC models, that describe parallel, communicating software processes. The paper combines a worst-case execution time (WCET) analysis with an analysis of the communication behavior. The communication analysis allows the detection of points, where the program flow of two or more concurrent processes are synchronized. This knowledge allows the determination of the worst-case response time (WCRT). The method does not rely on restrictions on the system design to prevent deadlocks or data loss. Furthermore possible deadlocks and data loss can be detected during the analysis.	best, worst and average case;control flow;correctness (computer science);deadlock;earthbound;multiprocessing;profiling (computer programming);response time (technology);run time (program lifecycle phase);static timing analysis;systemc;systems design;worst-case execution time	Axel Siebenborn;Oliver Bringmann;Wolfgang Rosenstiel	2002		10.1145/774789.774798	parallel computing;real-time computing;computer science;distributed computing	SE	-7.298838250297059	59.53549571146966	22995
9fa4eb91deda95c2fa836a3e009136490124b6d1	a theory for nondeterminism, parallelism, communication, and concurrency	parallelisme;lenguaje de programacion;semantica denotacional;programming language;multiprogrammation;flot donnee;virgule fixe;concurrent program;flujo datos;systeme non deterministe;multiprogramming;coma fija;fixed point;non deterministic system;parallelism;semantique operationnelle;paralelismo;multiprogramacion;denotational semantics;programa competidor;langage programmation;sistema no determinista;data flow;semantique denotationnelle;programme concurrent	An applicative language is introduced for representing concurrent programs and communicating systems in the form of mutually recursive systems of nondeterministic equations for functions and streams. Mathematical semantics is defined by associating particular fixed points with such systems. These fixed points are chosen using a combination of several complete partial orderings. Operational semantics is described in the form of term rewriting rules, consistent with the mathematical semantics. It represents data-driven reduction semantics for usual expressions and data-driven data flow semantics in the case of recursive stream equations. So the language allows to treat the basic semantic notions of nondeterminism, parallelism, communication, and concurrency for multiprogramming in a completely formal, applicative framework. In particular, it provides a semantic theory for networks of loosely coupled, nondeterministic, communicating, stream processing functions. Finally, the relationship of the presented language to partial recursive functions and nonconventional computational models such as data flow and reduction machines is shown.	applicative programming language;computational model;computer multitasking;concurrency (computer science);concurrent computing;dataflow;denotational semantics;loose coupling;mutual recursion;nondeterministic algorithm;operational semantics;parallel computing;rewriting;stream processing	Manfred Broy	1986	Theor. Comput. Sci.	10.1016/0304-3975(86)90040-X	data flow diagram;combinatorics;computer multitasking;computer science;theoretical computer science;communicating sequential processes;unbounded nondeterminism;mathematics;fixed point;programming language;operational semantics;denotational semantics;algorithm	PL	-25.984207009934106	32.500860144507946	23063
716f1690c0ab057101700ca042e6fd89e18c0a6f	paraflow: a dataflow distributed data-computing system	distributed data;distributed system;systeme reparti;navegacion informacion;procesamiento informacion;adquisicion del conocimiento;heterogeneous computing;navigation information;information browsing;acquisition connaissance;data mining;sistema repartido;knowledge acquisition;information processing;data flow analysis;analyse flux donnee;information system;traitement information;parallel programs;high performance;systeme information;sistema informacion	We describe the P araflow system for connecting heterogeneous computing services together into a f lexible and ef ficient data-mining metacomputer . There are three le v ls of parallelism: a dataf low paradigm provides functional parallelism, connecting services by channels; each service may be a SPMD parallel program; and each node of the SPMD service may be multithreaded. Paraflow is easily integrated with web-computing, using MIME types, HTTP forms, a Ja v GUI for setting up the netw ork of services, and a simple API to allo w web servers to be utilized in the computation. Emphasis is on pro viding a bridge from straightforw ard, public, unauthenticated bro wsing of data to collaborati ve, highperformance data-computing. Modern high-performance computing and communication is capable of pro viding enormous processing speeds and high-speed data transfer between processing engines, while RAID disk and tape robots can store the v ast quantities of data that dri ve these systems. But ef f ctively using such hardware entails learning ho w to write or port code and ho w to submit jobs to a queue, as well as other mundane details such as what port number the FTP server runs on. Collaborating on a software project often in volves inventing a communication protocol at the byte le vel, then writing raw socket code. These problems are e xacerbated when the code must be portable between different machines. But to many people, computing means something quite dif ferent: a web-client machine at home which can browse remote databases, carry on a chat-group, or do wnload movie previews. Under the surface, comple x events occur that may in volve several machines, b ut these are hidden from the user , enabling him to think about an objecti ve rather than its implementation. W eb servers already provide much of the softw are infrastructure that mak es distributed computing easier: the MIME mechanism to deal with heterogeneous data types, HTML forms for data input, multithreading, and connecti vity to databases. But perhaps the most important adv antage of a web interface is the recognition of a web bro wser by a neoph yte user and the consequent feeling of control. The idea of Paraflow is to bring some of the ease of use of the commodity machine to the highperformance world, allowing scientists to think about their data, not about the computer . Such a system is in operation as a public, purely web-based bro wser for Earth-observation images, called the Synthetic Aperture Radar Atlas [1], and man y of the elements for P araflow are deri ved from this project. SARA is a collaboration with San Die go Supercomputing Center and the Uni versity	acm/ieee supercomputing conference;application programming interface;bro;browsing;byte;client (computing);communications protocol;computation;data mining;database;dataflow;distributed computing;form (html);graphical user interface;heterogeneous computing;hypertext transfer protocol;multithreading (computer architecture);ork;parallel computing;programming paradigm;raid;raw socket;robot;spmd;server (computing);software project management;supercomputer;thread (computing);usability;web application;web server	Roy Williams;Bruce Sears	1998		10.1007/BFb0037183	information processing;computer science;theoretical computer science;operating system;data-flow analysis;database;distributed computing;programming language;information system;symmetric multiprocessor system	HPC	-18.586004551215556	41.85740642457092	23112
41533cc17d35d7a81aa18483023e432186fea01d	reducing data transfer in service-oriented architectures: the circulate approach	engines computer architecture service oriented architecture local area networks data models distributed databases;scientific workflow environments data transfer reduction service oriented architectures centralized orchestration techniques standard orchestration model centralized engine workflow execution circulate central control orchestration model choreography model distributed data transport planetlab framework web service based implementation internet scale configurations;workflow optimization service oriented architecture orchestration choreography;workflow management software natural sciences computing service oriented architecture web services;computer architecture;engines;web services;distributed databases;workflow management software;natural sciences computing;service oriented architecture;choreography;local area networks;orchestration;data models;workflow optimization	As the number of services and the size of data involved in workflows increases, centralized orchestration techniques are reaching the limits of scalability. When relying on web services without third-party data transfer, a standard orchestration model needs to pass all data through a centralized engine, which results in unnecessary data transfer and the engine to become a bottleneck to the execution of a workflow. As a solution, this paper presents and evaluates Circulate, an alternative service-oriented architecture which facilitates an orchestration model of central control in combination with a choreography model of optimized distributed data transport. Extensive performance analysis through the PlanetLab framework is conducted on a web service-based implementation over a range of Internet-scale configurations which mirror scientific workflow environments. Performance analysis concludes that our architecture's optimized model of data transport speeds up the execution time of workflows, consistently outperforms standard orchestration and scales with data and node size. Furthermore, Circulate is a less-intrusive solution as individual services do not have to be reconfigured in order to take part in a workflow.	application programming interface;centralisation;centralized computing;load balancing (computing);message passing;montagejs;netbsd gzip / freebsd gzip;network topology;network traffic control;open-source software;orchestration (computing);parallel computing;planetlab;run time (program lifecycle phase);scalability;service-oriented architecture;shim (computing);software deployment;web service;workflow engine;workflow pattern	Adam Barker;Jon B. Weissman;Jano I. van Hemert	2012	IEEE Transactions on Services Computing	10.1109/TSC.2011.23	local area network;web service;data modeling;computer science;service-oriented architecture;database;distributed computing;orchestration;law;world wide web;choreography;distributed database;workflow technology	HPC	-25.20979256821435	55.211581764824444	23151
9f14902ba961ad5710ae8ee6f20fd477b75000fa	understanding co-running behaviors on integrated cpu/gpu architectures	computer architecture performance evaluation graphics processing units predictive models bandwidth kernel ports computers;kernel;workload characterization;performance evaluation;heterogeneous computing;computer architecture;heterogeneous computing integrated architecture performance prediction performance tuning workload characterization;graphics processing units;bandwidth;performance prediction;predictive models;ports computers;integrated architecture;performance tuning	Architecture designers tend to integrate both CPUs and GPUs on the same chip to deliver energy-efficient designs. It is still an open problem to effectively leverage the advantages of both CPUs and GPUs on integrated architectures. In this work, we port 42 programs in Rodinia, Parboil, and Polybench benchmark suites and analyze the co-running behaviors of these programs on both AMD and Intel integrated architectures. We find that co-running performance is not always better than running the program only with CPUs or GPUs. Among these programs, only eight programs can benefit from the co-running, while 24 programs only using GPUs and seven programs only using CPUs achieve the best performance. The remaining three programs show little performance preference for different devices. Through extensive workload characterization analysis, we find that architecture differences between CPUs and GPUs and limited shared memory bandwidth are two main factors affecting current co-running performance. Since not all the programs can benefit from integrated architectures, we build an automatic decision-tree-based model to help application developers predict the co-running performance for a given CPU-only or GPU-only program. Results show that our model correctly predicts 14 programs out of 15 for evaluated programs. For a co-run friendly program, we further propose a profiling-based method to predict the optimal workload partition ratio between CPUs and GPUs. Results show that our model can achieve 87.7 percent of the optimal performance relative to the best partition. The co-running programs acquired with our method outperform the original CPU-only and GPU-only programs by 34.5 and 20.9 percent respectively.	benchmark (computing);central processing unit;computation;data parallelism;decision tree;graphics processing unit;integrated development environment;memory bandwidth;parallel computing;performance prediction;profiling (computer programming);shared memory	Feng Zhang;Jidong Zhai;Beixin Julie He;Shuhao Zhang;Wenguang Chen	2017	IEEE Transactions on Parallel and Distributed Systems	10.1109/TPDS.2016.2586074	computer architecture;parallel computing;kernel;real-time computing;computer science;operating system;predictive modelling;bandwidth;symmetric multiprocessor system	Arch	-5.075593201178386	45.13467205868492	23169
6484268f63371444ea88ec405ead6b8becb948cc	conceptual level concurrency control of relational update transactions	model specification;relational database;semantic information;concurrency control;dynamic scheduling	We consider the main features of updates in databases. Recent results on updates are briefly described and used to raise various questions. It is argued that well-accepted query properties like safety and determinism should not be strictly enforced ...	concurrency control	Victor Vianu;Gottfried Vossen	1988		10.1007/3-540-50171-1_23	timestamp-based concurrency control;optimistic concurrency control;relational model;isolation;relational calculus;dynamic priority scheduling;relational database;computer science;concurrency control;database;distributed computing;multiversion concurrency control;non-lock concurrency control;programming language;serializability;specification;distributed concurrency control	DB	-23.96996219765862	46.97035967535655	23171
457178762beeacc0d151780698473eddcdcf04e0	parallel simulation of turbulent magneto-hydrodynamic flows	finite volume method;magnetic field;large eddy simulation les;direct numerical simulation dns;magnetohydrodynamics;parallel simulation	c © 2007 by John von Neumann Institute for Computing Permission to make digital or hard copies of portions of this work for personal or classroom use is granted provided that the copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. To copy otherwise requires prior specific permission by the publisher mentioned above.	algorithmic efficiency;computation;finite volume method;image resolution;large eddy simulation;network interface controller;numerical analysis;requirement;run time (program lifecycle phase);terabyte;test case;turbulence	Axelle Viré;Dmitry Krasnov;Bernard Knaepen;Thomas Boeck	2007			magnetohydrodynamics;simulation;magnetic field;computer science;finite volume method;large eddy simulation	Theory	-6.923801942249813	38.24402191573388	23248
8cd7a313b28ceb7621e8a3ecd9f417b0b07a91ff	effective kernel mapping for opencl applications in heterogeneous platforms	kernel graphics processing unit benchmark testing performance evaluation algorithm design and analysis cloning;kernel;performance evaluation;graphics processing units distributed processing;distributed processing;gpu;cloning;profiling information effective kernel mapping opencl applications heterogeneous platforms many core accelerators application mapping gpu mapping multikernel applications high data transfer overhead heterogeneous execution profiling based kernel mapping;heterogeneous;graphics processing units;mapping;graphics processing unit;opencl;algorithm design and analysis;benchmark testing;gpu heterogeneous opencl kernel mapping	Many core accelerators are being deployed in many systems to improve the processing capabilities. In such systems, application mapping need to be enhanced to maximize the utilization of the underlying architecture. Especially in GPUs mapping becomes critical for multi-kernel applications as kernels may exhibit different characteristics. While some of the kernels run faster on GPU, others may refer to stay in CPU due to the high data transfer overhead. Thus, heterogeneous execution may yield to improved performance compared to executing the application only on CPU or only on GPU. In this paper, we propose a novel profiling-based kernel mapping algorithm to assign each kernel of an application to the proper device to improve the overall performance of an application. We use profiling information of kernels on different devices and generate a map that identifies which kernel should run on where to improve the overall performance of an application. Initial experiments show that our approach can effectively map kernels on CPU and GPU, and outperforms to a CPU-only and GPU-only approach.	central processing unit;experiment;graphics processing unit;greedy algorithm;integer programming;kernel (operating system);linear programming;machine learning;maxima and minima;on the fly;opencl api;overhead (computing);profiling (computer programming)	Omer Erdil Albayrak;Ismail Akturk;Ozcan Ozturk	2012	2012 41st International Conference on Parallel Processing Workshops	10.1109/ICPPW.2012.14	algorithm design;benchmark;parallel computing;kernel;real-time computing;computer science;operating system;cloning;kernel preemption	HPC	-5.732078641523031	47.27366031774288	23279
04ccf4f8ab1b942712ce093e461ced386b9da452	multi-level feedback control for quality of service management	resource allocations;time varying;resource allocations multi level feedback control quality of service management power aware quality of service control soft real time embedded systems power scaling capabilities;soft real time embedded systems;processor scheduling;resource allocation;power aware quality of service control;multimedia application;data mining;soft real time;embedded system;feedback control quality of service quality management control systems switches power system management real time systems embedded system energy consumption resource management;embedded systems;power aware computing;feedback;multi level feedback control;control architecture;bandwidth;quality of service management;quality of service;quality of ser vice;feedback control;power scaling capabilities;resource allocation embedded systems feedback power aware computing quality of service;real time systems;timing;time constraint	We consider the problem of power-aware Quality of Service (QoS) control for soft real-time embedded systems. Applications can have time-varying and scarcely known resource requirements, and can be activated and terminated at any time. However, they have the capability to switch among a discrete set of operation modes with different QoS levels and resource requirements. In addition, the platform provides resources with power-scaling capabilities and may be subject to power constraints. We present a QoS control architecture achieving optimum trade-offs between overall QoS and power consumption of the system, based on two nested control loops. The external one decides dynamically the optimum configuration for the system, in terms of application QoS modes and resource power modes, while the internal one modulates the resource allocations on a job by job basis, so as to respect timing constraints. We demonstrate the effectiveness of the approach by extensive simulations with trace data of real multimedia applications.	aquosa;coexist (image);embedded system;feedback;image scaling;inner loop;isolation (database systems);middleware;quality of service;real-time clock;real-time computing;requirement;simulation	Tommaso Cucinotta;Giuseppe Lipari;Luigi Palopoli;Luca Abeni;Rodrigo M. Santos	2009	2009 IEEE Conference on Emerging Technologies & Factory Automation	10.1109/ETFA.2009.5347100	embedded system;real-time computing;mobile qos;resource allocation;computer science;engineering;feedback;distributed computing	Embedded	-6.073837460572247	59.809576441057516	23285
e7e6b579d294f2237e9c1640d5b77b849445c76a	a job scheduling method based on expected probability of completion of voting in volunteer computing	parallel computing;sabotage tolerance parallel computing desktop grids probabilistic method;probabilistic method;desktop grids;worker history information job scheduling method expected probability of completion epc volunteer computing vc;educational institutions computational modeling reliability processor scheduling error analysis resource management electronic mail;volunteer computing probability scheduling;sabotage tolerance	This paper addresses the problem of job scheduling in volunteer computing (VC) systems where each computation job is replicated and distributed to multiple participants (workers) to remove incorrect results. In the job scheduling of VC, the number of assigned workers to complete a job is an important factor for the system performance, however, it cannot be fixed because some of the workers may not return results in real VC. We propose a job scheduling method which considers the expected probability of completion (EPC) for each job based on the worker's history information. The key idea of the proposed method is to assign jobs so that EPC is always greater than a specified value (SPC). By setting SPC as a reasonable value, any job in the proposed method can be completed without excess allocations, which leads to the higher performance of VC systems. Simulation results show that the performance of the proposed method is up to 5 times higher than that of the conventional method, while keeping the error rate lower than a required value.	bit error rate;computation;electronic product code;job scheduler;job shop scheduling;offset binary;scheduling (computing);simulation;volunteer computing	Yuto Miyakoshi;Shinya Yasuda;Kan Watanabe;Masaru Fukushi;Yasuyuki Nogami	2014	2014 Second International Symposium on Computing and Networking	10.1109/CANDAR.2014.99	real-time computing;computer science;rate-monotonic scheduling;operations management;job stream;distributed computing	HPC	-15.12858805871302	60.201231716680674	23368
562d7b85d13007db19d1d4a70f430af1f3e37aa9	trace-based analysis and tuning for distributed parallel applications	integrated approach;performance analysis message passing information analysis clocks parallel programming computerized monitoring computer science application software timing analytical models;parallel programming;waiting time;performance analysis;message passing;local wait time trace based analysis tuning distributed parallel applications integrated approach timestamp consistency trace based performance analysis techniques trace generation facility message passing system events process dispatch trace driven analysis tools post execution analysis;parallel applications	We present an integrated approach to deal with timestamp consistency, and trace based performance analysis techniques for distributed parallel applications. Our trace generation facility captures message passing and system events such as process dispatch with minimal trace overhead. Trace driven analysis tools are developed for post execution analysis, reporting information such as the time stolen by other processes in each node, and the observed message passing time and local wait time for each message. We then present our techniques to reduce total elapsed times based on observed message passing times and local wait times.		Ching-Farn Eric Wu;Yew-Huey Liu;C. Benveniste;C.-L. Chen;W.-H. Chiang	1994		10.1109/ICPADS.1994.590449	parallel computing;message passing;real-time computing;computer science;operating system;database;distributed computing;programming language	HPC	-16.572233287627533	48.451062886222935	23395
224b3ba879bef13727aea194aeac987c6d600455	brief announcement: decoupled and consensus-free reconfiguration for fault-tolerant storage	new machine;system correctness;sufficient amount;faulty server;quorum system;system change;brief announcement;fault-tolerant storage;static set;system administrator;consensus-free reconfiguration	Quorum systems are constructions used to ensure consistency and availability of data stored in replicated servers. These systems usually comprise a static set of servers that provide a fault-tolerant read/write (r/w) register accessed by a set of clients. This approach is not adequate for long lived systems since, given a sufficient amount of time, there might be more faulty servers than the threshold tolerated, affecting the system correctness. Moreover, this approach does not allow a system administrator to deploy new machines or replace old ones at runtime and cannot be applied in many systems where, by their very nature, the set of processes that compose the system changes during its execution.		Eduardo Adílio Pelinson Alchieri;Alysson Neves Bessani;Fabíola Greve;Joni da Silva Fraga	2012		10.1007/978-3-642-33651-5_49	real-time computing;computer science;operating system;database;distributed computing;computer network	Robotics	-23.094656408125175	49.67415755588367	23408
076d7a9baaf4ab9aa0cbb0b15bd450b8370b6604	fluid petri nets for the performance evaluation of mapreduce and spark applications	spark;fluid petri nets;mapreduce;hadoop	Big Data applications allow to successfully analyze large amounts of data not necessarily structured, though at the same time they present new challenges. For example, predicting the performance of frameworks such as Hadoop and Spark can be a costly task, hence the necessity to provide models that can be a valuable support for designers and developers. Big Data systems are becoming a central force in society and the use of models can also enable the development of intelligent systems providing Quality of Service (QoS) guarantees to their users through runtime system reconfiguration. This paper provides a new contribution in studying a novel modeling approach based on fluid Petri nets to predict MapReduce and Spark applications execution time which is suitable for runtime performance prediction. Models have been validated by an extensive experimental campaign performed at CINECA, the Italian supercomputing center, and on the Microsoft Azure HDInsight data platform. Results have shown that the achieved accuracy is around 9.5% for Map Reduce and about 10% for Spark of the actual measurements on average.	apache hadoop;big data;data system;mapreduce;microsoft azure;performance evaluation;performance prediction;petri net;quality of service;run time (program lifecycle phase);runtime system;spark;supercomputer	Eugenio Gianniti;Alessandro Maria Rizzi;Enrico Barbierato;Marco Gribaudo;Danilo Ardagna	2017	SIGMETRICS Performance Evaluation Review	10.1145/3092819.3092824	real-time computing;spark;computer science;database;distributed computing	DB	-21.824102338030087	57.411770537173616	23433
1c7ad300aa19628e455628e2cff356f5983bf71e	dryadopt: branch-and-bound on distributed data-parallel execution engines	libraries;distributed data;optimal solution;data parallel;optimization algorithm;distributed execution;distributed data parallel execution engines;sequential code dryadopt branch and bound distributed data parallel execution engines optimization algorithm distributed execution;computer model;branch and bound algorithm;sequential code;engines parallel processing optimization workstations clustering algorithms libraries;dryadopt;search trees;engines;space use;workstations;parallel computer;clustering algorithms;optimization;load balance;tree searching;optimal algorithm;branch and bound;communication pattern;parallel processing;exhaustive search;workstation cluster	We introduce Dryad Opt, a library that enables massively parallel and distributed execution of optimization algorithms for solving hard problems. Dryad Opt performs an exhaustive search of the solution space using branch-and-bound, by recursively splitting the original problem into many simpler sub problems. It uses both parallelism (at the core level) and distributed execution (at the machine level). Dryad Opt provides a simple yet powerful interface to its users, who only need to implement sequential code to process individual sub problems (either by solving them in full or generating new sub problems). The parallelism and distribution are handled automatically by Dryad Opt, and are invisible to the user. The distinctive feature of our system is that it is implemented on top of Dryad LINQ, a distributed data-parallel execution engine similar to Hadoop and Map-Reduce. Despite the fact that these engines offer a constrained application model, with restricted communication patterns, our experiments show that careful design choices allow Dryad Opt to scale linearly with the number of machines, with very little overhead.	algorithm;apache hadoop;branch and bound;brute-force search;dryad;experiment;feasible region;language integrated query;mapreduce;mathematical optimization;overhead (computing);parallel computing;recursion	Mihai Budiu;Daniel Delling;Renato F. Werneck	2011	2011 IEEE International Parallel & Distributed Processing Symposium	10.1109/IPDPS.2011.121	parallel processing;parallel computing;computer science;theoretical computer science;operating system;distributed computing;programming language;branch and bound	Arch	-11.895635450327523	37.68240520331717	23442
4bd5fd92992b302dc2bf210cc20cd04207b0595f	performance improvement of multimedia kernels by alleviating overhead instructions on simd devices	performance improvement;register file;data level parallelism	SIMD extension is one of the most common and effective technique to exploit data-level parallelism in today’s processor designs. However, the performance of SIMD architectures is limited by some constraints such as mismatch between the storage and the computational formats and using data permutation instructions during vectorization. In our previous work we have proposed two architectural modifications, the extended subwords and the Matrix Register File (MRF) to alleviate the limitations. The extended subwords, uses four extra bits for every byte in a media register and it provides additional parallelism. The MRF allows flexible row-wise as well as column-wise access to the register file and it eliminates data permutation instructions. We have validated the combination of the proposed techniques by studying the performance of some multimedia kernels. In this paper, we analysis each proposed technique separately. In other words, we answer the following questions in this paper. How much of the performance gain is a result of the additional parallelism? and how much is due to the elimination of data permutation instructions? The results show that employing the MRF and extended subwords separately obtains the speedup less than 1 and 1.15, respectively. In other words, our results indicate that using either extended subwords or the MRF techniques is insufficient to eliminate most pack/unpack and rearrangement overhead instructions on SIMD processors. The combination of both techniques, on the other hand, yields much more performance benefits than each technique.	automatic vectorization;byte;central processing unit;data parallelism;mmx (instruction set);markov random field;multiprogram research facility;overhead (computing);parallel computing;register file;simd;speedup;the matrix	Asadollah Shahbahrami;Ben H. H. Juurlink	2009		10.1007/978-3-642-03644-6_31	parallel computing;computer hardware;computer science;theoretical computer science;operating system;database;distributed computing;data parallelism;programming language;register file	Arch	-10.728689748735249	52.14135305275982	23485
87d7ee8bfe9cffb9f05fd5b374b921e7e306704b	design considerations for a heterogeneous tightly-coupled multiprocessor system	multiprocessor systems;processor sharing;operating system	"""In a multiprocessor system, processors share main memory and a single copy of the operating system in shared main memory controls the entire system. Basically each processor can execute, any of the programs in the system. (This type of multiprocessor system is sometimes called a tightly-coupled multiprocessor system to distinguish from another type of multiprocessor system in which each processor has its own main memory and operating system. In this paper a """"multiprocessor system"""" means a """"tightly-coupled multiprocessor system"""" unless otherwise noted.) A multiprocessor system usually consists of identical processors, which have same computing speeds as well as the same functional characteristics. In this paper a more general type of multiprocessor system which consists of processors of different computing speeds are discussed. The component processors are equivalent in the hardware functions but have different performance characteristics. This type of multiprocessor system, a heterogeneous multiprocessor system, has the following merits as compared with a homogeneous multiprocessor."""	central processing unit;computer data storage;multiprocessing;operating system	Kenichiro Noguchi;Isao Ohnishi;Hiroshi Morita	1975		10.1145/1499949.1500062	real-time computing;simulation;distributed memory;advanced programmable interrupt controller;multiprocessor scheduling;symmetric multiprocessor system	Arch	-11.750877659466521	47.71151619257996	23494
1f1c9b78f5566351690cb341e7c5020923bef78b	correctness field testing of production and decommissioned high performance computing platforms at los alamos national laboratory	transient error cluster computing field testing high performance computing hpc cluster interconnect testing intermittent error linpack resilience silent data corruption soft error;cluster computing;parallel processing natural sciences computing;linpack;field testing;high performance computing;testing production transient analysis sdram data transfer computer architecture high performance computing;interconnect testing;transient error;silent data corruption;resilience;intermittent error;intermittent error mechanism correctness field testing production high performance computing platform decommissioned high performance computing platform los alamos national laboratory silent data corruption sdc scientific calculations hpc platforms transient error mechanism;soft error;hpc cluster	Silent Data Corruption (SDC) can threaten the integrity of scientific calculations performed on high performance computing (HPC) platforms and other systems. To characterize this issue, correctness field testing of HPC platforms at Los Alamos National Laboratory was performed. This work presents results for 12 platforms, including over 1,000 node-years of computation performed on over 8,750 compute nodes and over 260 petabytes of data transfers involving nearly 6,000 compute nodes, and relevant lessons learned. Incorrect results characteristic of transient errors and of intermittent errors were observed. These results are a key underpinning to resilience efforts as they provide signatures of incorrect results observed under field conditions. Five incorrect results consistent with a transient error mechanism were observed, suggesting that the effects of transient errors could be mitigated. However, the observed numbers of incorrect results consistent with an intermittent error mechanism suggest that intermittent errors could substantially effect computational correctness.	antivirus software;computation;correctness (computer science);petabyte;smart data compression;supercomputer	Sarah Ellen Michalak;William N. Rust;John T. Dal;Rew J. Dubois;David H. Dubois	2014	SC14: International Conference for High Performance Computing, Networking, Storage and Analysis	10.1109/SC.2014.55	parallel computing;real-time computing;soft error;computer cluster;computer science;operating system;distributed computing;psychological resilience	HPC	-17.675491175748245	49.32227349016676	23538
bbf70430b677deccd262c99dfb9026c813c0c0e3	slack-based resource arbitration for real-time networks-on-chip	temporal overhead networks on chip noc slack based resource arbitration real time systems traffic requirements hard real time transmissions global prioritization dynamic prioritization data streams overlay network scheduling unit logical transmissions hardware overhead;real time systems synchronization safety time factors dynamic scheduling hardware;real time systems network on chip overlay networks processor scheduling;time factors;synchronization;safety;dynamic scheduling;hardware;real time systems	Networks-on-Chip (NoCs) designed for real-time systems must efficiently deal with a broad diversity of traffic requirements. This requires providing latency guarantees for hard real-time transmissions with minimum impact on performance sensitive best-effort traffic. In this work, we present a novel mechanism which achieves this goal through a slack-based global and dynamic prioritization of data streams. This is performed using an overlay network and a scheduling unit combining local arbitration performed in routers with global scheduling of entire logical transmissions for end to end guarantees. Consequently, our approach allows to decrease both hardware and temporal overhead when compared with existing solutions and to achieve a performance improvement up to around 60%.	best-effort delivery;network on a chip;overhead (computing);overlay network;real-time clock;real-time computing;real-time transcription;requirement;scheduling (computing);slack variable;system on a chip	Adam Kostrzewa;Selma Saidi;Rolf Ernst	2016	2016 Design, Automation & Test in Europe Conference & Exhibition (DATE)	10.3850/9783981537079_0233	embedded system;synchronization;real-time computing;dynamic priority scheduling;computer science;operating system;least slack time scheduling;computer network	EDA	-8.637393975233659	58.60751706697882	23613
c90bc76bddb1307b3295567c4cba113a401d8aae	a practical scheduling scheme for non-uniform parallel loops on distributed memory parallel machines	distributed memory;software performance loop scheduling nonuniform parallel loops distributed memory parallel machines variable execution time parallel programming global distributed control scheme intel delta gdc;distributed memory systems;parallel machines processor scheduling dynamic scheduling runtime management information systems educational institutions distributed control process control load management testing;software performance evaluation scheduling parallel programming program control structures parallelising compilers distributed memory systems parallel machines resource allocation;resource allocation;program control structures;software performance evaluation;parallel programming;parallelising compilers;scheduling;parallel machines;distributed control	Loops without dependence8 among iterations are a rich source of paTalle&sm in many applications. Among these type8 of loops, non-uniform loops with vatiable execution times need eficient scheduling schemes to take advantages of the capabilities of parallel machines. In this paper, we present a global distributed control scheme (GDC) to schedule nonuniform loops on distributed memory parallel machines. GDC decentralizes scheduling controls among all processors with an attempt to keep heavily loaded processors being in charge of scheduling tasks. For comparative evaluation, GDC and other well-known scheduling schemes are implemented on a 512 proceasor Intel Delta parallel machine. Our experimental results show that GDC performs well on many applications with a’iflerent characteri&ics.	central processing unit;distributed control system;distributed memory;game developers conference;iteration;parallel computing;scheduling (computing)	Tong-Yee Lee;Cauligi S. Raghavendra;H. Sivaraman	1996		10.1109/HICSS.1996.495468	fair-share scheduling;parallel computing;real-time computing;distributed memory;dynamic priority scheduling;resource allocation;computer science;operating system;two-level scheduling;distributed computing;management;scheduling	HPC	-13.508841110170408	59.7688652574909	23724
bc9b04a33ded30ec6577e12aa7e2c6b95f493798	multi-source energy harvesting management and optimization for non-volatile processors	maximum power point trackers;energy harvesting optimization dc dc power converters maximum power point trackers mosfet yttrium embedded systems;energy harvesting;dc dc power converters;embedded systems;yttrium;power convertors embedded systems energy harvesting power aware computing;mosfet;optimization;converter parameter optimization techniques multisource energy harvesting management nonvolatile processors wearable embedded systems intermittent program execution stable power supply maximum power extraction	Due to size, longevity, safety, and recharging concerns, energy harvesting is becoming a better choice for many wearable embedded systems. However, harvested energy is intrinsically unstable. In order to overcome this drawback, nonvolatile processor (NVP) was proposed to bridge intermittent program execution. However, even with NVP, frequent power interruption will severely degrade system performance. In this paper, we will propose a multi-source energy harvesting system to combine multiple harvesting sources to provide a more stable power supply. Maximum power extraction and converter parameter optimization techniques will be discussed. Preliminary experimental results show the proposed architecture is very promising in providing a stable energy source for NVPs.	central processing unit;control theory;embedded system;interrupt;mathematical optimization;maximum power transfer theorem;multi-source;non-volatile memory;power supply;wearable computer	Soroush Heidari;Caiwen Ding;Yongpan Liu;Yanzhi Wang;Jingtong Hu	2015	2015 Sixth International Green and Sustainable Computing Conference (IGSC)	10.1109/IGCC.2015.7393721	embedded system;electronic engineering;real-time computing;engineering	EDA	-4.702895110355905	58.38773063492111	23812
5257c088024818622df57de44ca6a13cf1f8afdc	the crisp performance model for dynamic voltage and frequency scaling in a gpgpu	analytical models;kernel;clocks;radiation detectors;gpgpu;computational modeling;critical path;dvfs;load modeling;time frequency analysis	This paper presents CRISP, the first runtime analytical model of performance in the face of changing frequency in a GPGPU. It shows that prior models not targeted at a GPGPU fail to account for important characteristics of GPGPU execution, including the high degree of overlap between memory access and computation and the frequency of store-related stalls.  CRISP provides significantly greater accuracy than prior runtime performance models, being within 4% on average when scaling frequency by up to 7X. Using CRISP to drive a runtime energy efficiency controller yields a 10.7% improvement in energy-delay product, vs 6.2% attainable via the best prior performance model.	computation;cross industry standard process for data mining;dynamic frequency scaling;dynamic voltage scaling;general-purpose computing on graphics processing units;image scaling;run time (program lifecycle phase)	Rajib Nath;Dean M. Tullsen	2015	2015 48th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO)	10.1145/2830772.2830826	parallel computing;kernel;real-time computing;time–frequency analysis;computer hardware;computer science;operating system;critical path method;particle detector;computational model;general-purpose computing on graphics processing units	Arch	-5.030416518388436	54.87785861803487	23832
edf27c02c89a9b200240ebe4b81ff1c8f8def92f	assessing error detection coverage by simulated fault injection	seguridad funcionamiento;system reliability;fiabilite systeme;surete fonctionnement;client server architecture;architecture client serveur;computer model;sistema informatico;interface programme application;computer system;fiabilidad sistema;fault tolerant system;client server;coverage probability;application program interfaces;dependability;error handling;sistema tolerando faltas;transient fault;arquitectura cliente servidor;systeme tolerant les pannes;systeme informatique;error detection;fault injection	Server dependability is of increasing importance as more critical applications rely on the client-server computing model. As a consequence, complex fault/error handling mechanisms are becoming common features of today servers. This paper presents a new simulated fault injection method, which allows the assessment of the effectiveness of error detection mechanisms without using expensive test circuits. Fault injection was performed in two stages. First, physical fault injection was performed on a prototype server. Transient faults were injected in randomly selected signals. Traces of the signals sensitive to transients were captured. A complex protocol checker was devised for increasing error detection. The new detection circuitry was simulated in the second stage of the experiment. Signal traces, injected with transient faults, were used as inputs of the simulation. The error detection coverage and latency were derived. Fault injection also showed that coverage probability was a function of fault duration.	error detection and correction;fault injection	Cristian C Constantinescu	1999		10.1007/3-540-48254-7_12	computer simulation;reliability engineering;embedded system;real-time computing;fault coverage;fault indicator;computer science;stuck-at fault;operating system;distributed computing;computer security;client–server model	Robotics	-22.421340987529444	41.34650902775182	23833
09de6a2736fa2aac3803ce8fcac764f2b3b95df1	an adaptive, region-based allocator for java	clustering;garbage collector;adaptive system;type system	"""$ %'&)(+*-,.*0/21+&)354618759;:=< />(?,.3@,#9=,A*'48&)BC/#D 18/ E#&)7.3'FHG-,A(6/I9@,AJ)JK7L< ,A487.1 M 7.1ONC,IB#,5P $ %'/QG=,.(6&)<R&K9'/I,""""&)(S487?,.J)J)7L<I,A48/Q3=7.3'FH/ (6<I,A*=&)3=E+7.G;TU/ <>48( &)3VJK7L< ,.J518/ E#&)7#3'( D#WS%'&K< %"""",X18/ ,.J)J)7L<I,X48/I9"""",.3=9 M 18/ /I9Q&K3Q< 7.3.TY:'3=<>48&)7.3 WS&Z48%""""48%'/ &Z1[,A(6(67L< &K,A48/I9+(Y4 ,A<2\ M 1 ,.]+/>( P!^ _Q18/ J)/I,.(6&)3=ER]+/ ]+7A16_V,.(YF (67L<>&`,X48/I9+WS&)48%""""48%'/ (6/S(Y4 ,.< \ M 1 ,.]+/ ( DC48%'/SG=:'1 9;/ 3""""7.3""""48%=/ EC,X18G-,AE#/ <>7#J)J)/ <>487.1a&)(S18/ 9':=<>/I9 D;*07#(6(6&)G'J)_b18/ (6:=JZ48&)3=E &K3 M />W[/>1 < 7#J)J)/ <>48&)7#3'( P $ %'/b3'7XBC/ JZ4U_c7 M 7.:'1"""",.*=*;187C,A<2%d&)( 48%-,X4""""&Z4+9;7L/ (""""3'7.4 18/ e5:'&Z18/ (Y4 ,X48&)<b/ (6< ,.*0/f,.3=,.JZ_;(6&K( D!*;187#EA1 ,.]+]+/>1V,.3'3=7A4 ,A48&)7#3'( D!7.1Q(6*0/ < &K,.J 4g_;*0/a(Y_;(Y48/ ]+( P!$ %'/O,.*'*'187#,.< % &)([461 ,.3'(6*-,X18/ 3L4 487V48%'/ONC,IB.,Q*;187.F EA1 ,.]+]+/>1O,.3=9h18/>J`,X48&)BC/ JZ_i(6&K]+*'J)/Q487b,#9'9h487b,.3i/>j;&)(Y48&)3=EbN#kmlnP $ %'/o(Y_'(Y48/>]p(Y4 ,X1648(bGL_q,.(6(6:']+&K3'Er48%-,X4 ,AJ)Jm,.J)J)7L<I,A48/ 9s7.G;TU/ <>48( ,X18/hJ)7L<I,.JS487n48%'/ &Z1+(Y4 ,.< \c18/ E#&)7#3 DS,.3=9t48%'/ 3@< ,A48< %=/ (+/ (6< ,.*=&)3'E 7.G;TU/ <>48( B5&`,QW 18&)48/mG=,A1618&)/>18( P uv%=/>3w,.3b7#G5TY/ <24a&)(S<I,.:'E#%L4 / (6<I,A*'F &)3'E'D &Z48("""",.(6(67L<>&`,X48/I9q,AJ)JK7L< ,A48&)7#3@(6&)48/f&)( ]?,X18\C/I9r,A("""",h3=7.3'FHJ)7L<I,.J (6&Z48/#D (67h48%-,X4Q(6:=G=(6/ e5:'/ 3L4V,.J)J)7L<I,A48&)7#3'(""""WS&)JKJ G0/?*':'4V9'&Z18/ <>48JZ_x&K3 48%'/ E.JK7.G-,AJ 18/ E.&)7#3 P""""$ %5:=( Dy,.(m/>j;/ < :;48&)7#3x*;187L< / /I9;( Dy7.3=JZ_h48%=7.(6/ ,AJ)JK7L< ,A48&)7#3r(6&Z48/ ( 48%-,A4O,A18/VJK&)\C/>J)_h487?*;18759':=<>/ 3=7.3'FH/ (6<I,A*=&)3=E?7.G'F TU/ <>48( ,A18/R,AJKJ)7L<I,X48/I9 487 48%'/ &Z1 J)7L<I,AJy(Y4 ,A<2\?18/ E#&)7.3 P $ %'/h*-,A*0/>1f*'18/ (6/ 3L48(""""48%'/h7AB#/>1 ,.J)J &`9;/I,;D ,A3-9@48%'/ 3q*;187XB;&K9;/ ( 9;/>4 ,.&)J)(Q7 M , (6*0/>< &Zz-<?9'/>(6&KE.3c,.3=9x&)]+*=J)/ ]+/ 3L4 ,X48&K7.3 P+{g3x*=,A1648&)<>F :'JK,A1ID-W[/V*;18/ (6/ 3L4 , 18/ E#&)7#3;FHG-,.(6/ 9i,AJ)JK7L< ,A487.1m,.3-9 48%'/m3=/ <>/ (6(8,A16_ ]+759;&Zz-<I,X48&K7.3=(S7 M 48%'/RN#&)\C/ (S|ykOl}G-,.(6/>JK&)3'/VN.{Y$~,.3=9w, < 7.*5_;&)3=E <>7#J)J)/ <>487.1IP a:;1O/>j;*0/>18&)]+/ 3L4 ,.Jy(Y48:-9;_ / B.,.J):-,X48/ (a48%=/Q&K9'/I,?:=(6&)3'E 48%'/Q' [vN#kOlw#""""G0/ 3'<2%']?,A18\5( D;*=J):=(S7.3=/m7.48%'/>1 JK,A18E#/RG0/ 3'<2%;F ]?,X18\0Pyur/[(6%=7IWd48%-,A4 ,S18/ E#&)7#3;FHG-,.(6/ 9+,.J)J)7L<I,A487A1[&)( , 18/I,A(67#3-,AG=J)/ < %=7.&)< /#D-48%=,A4 7AB#/>18%=/I,.9'( <I,.3hG0/m\#/ *'4 J)7IWmD ,.3-9f48%-,A4 48%=/R,.9=,A*'F 48&)BC/ (Y_;(Y48/ ]&)( (6:=< <>/ (6( M :'J-,A4!z=3-9'&)3'EOJ)7L<I,.J;18/ E#&)7#3'( 48%=,A4 < 7#3L4 ,A&K3 3'7""""/ (6<I,A*=&)3=E+7.G;TU/ <>48( P Categories and Subject Descriptors VP 5P @ OX--X0xxy - 0y=='>?187L< / (6(67A18(Usn2 +¡.¢ £ """"¤.¥0¤ ¦L2 ?2¥=§a ̈¦C¤A¢ ©8¤I¦L""""a8¡#««K6a>§­¬¡A¥C® General Terms ̄ ,.3'E#:-,AE#/ ( D0 />1 M 7A18]?,.3=<>/#D-j;*0/>18&)]+/ 3L4 ,A48&)7#3 Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. ISMM’02, June 20-21, 2002, Berlin, Germany. Copyright 2002 ACM 1-58113-539-4/02/0006 ... ° 5.00. 1. INTRODUCTION $ %=/ NC,IB.,f ±X *;187#EA1 ,.]+]+&)3=ERJK,.3'E#:-,AE#/ &K]+*'J)&K<>&)48JZ_+:'(6/ ( ,mEC,X16F G-,AE#/+< 7.J)JK/><>487.1 ,.(R&Z48(R]+/ ]+7.16_h]?,A3-,AE#/>1IPb2O,X18G-,.E./?< 7#J)J)/ <>48&)7#3 %-,A(O48%=/+,.9'B.,.3L4 ,.E./ 7 M M 18/ />&K3'Ew]+/ ]+7A16_h(8, M / JZ_x,A3-9i7 M 48/>3x*'18/2F < &)(6/ JZ_LPd3a7IW[/ BC/>1ID!461 ,.<>&K3'Er,A3-9c< 7#J)J)/ <>48&)3'Ex7#G5TY/><>48(?,#9'9'( 7XBC/216F %=/ ,#9w487+48%=/R*'187.E.1 ,.]wD (67+18/I9;:=< &)3'E?48%'/ M 18/IeL:=/>3=<>_h7 M EC,A18G=,.E./ < 7.JKJ)/ <248&K7.3 ́<I,A3@G0/fG0/ 3=/2z-< &K,.J­Pq54 ,A<2\LFg,.J)J)7L<I,X48&K7.3q7 M 7#G5TY/><>48(+&)( 7#3'/o*'187#]+&)(6&)3=Er,.*=*;187C,A<2% ́487x18/ 9':=<>/o48%'/wW 7A18\@7 M ,rEC,A18G=,.E./ < 7.JKJ)/ <2487.1+ AP { M ,.3o7.G;TU/ <>4m9;7L/ (a3'7.4 / (6<I,A*0/"""",+]+/>48%=759 D-&Z4 <I,.3 G0/""""<>18/ ,A48/I9i7#3o48%=/""""(Y4 ,A<2\ M 1 ,.]+/""""&)3=(Y48/ ,#9n7 M &)3n48%'/ %'/I,.* P?aG'F TY/><>48(S7#3b48%'/O(Y4 ,.< \?<I,.3bG0/a18/ < JK,A&K]+/ 9fWS&Z48%=7.:'4S&)3L48/>18BC/ 3L48&)7#3bG5_ 48%=/aEC,A18G=,.E./Q<>7#J)J)/ <>487.1IP $ %=/218/ ,X18/S(6/ BC/>1 ,AJ=*07.48/>3548&K,AJ-7#G'(Y4 ,.< J)/ ( 487m*0/>1 M 7A18]+&K3'Em7#G5TY/ <24 (Y4 ,.< \LFg,.J)J)7L<I,A48&)7#3~&)3v,rN.kmlnP[!j;&)(Y48&)3=Ec(Y4 ,.< \LFg,.J)J)7L<I,A48&)7#3 ́48/><2%;F 3=&KeL:=/>( 18/IeL:=&Z18/R, (Y4 ,A48&)<f2μ2a8¤2¶' ¤.¥-¤#« £Aμ ¬·μO  ̧5D''D 1IoAD'WS%=&)<2%b:=(6:;F ,.J)JZ_s18/IeL:=&Z18/ (o,tWS%'7#J)/c*'187.E.1 ,A]»,.3-,AJZ_'(6&)(i,.3=91⁄4&)(o3=7A4o/I,.(6&)JZ_ ,.]+/>3-,.G'J)/w487c,cN#kml1⁄2WS&Z48%v9;_;3=,.]+&)<w< JK,.(6(bJ)7C,#9;&)3=Ed,.3=9 ́N#{U$ < 7.]+*=&)JK,A48&)7#3 P[3⁄4':'1648%=/21ID;,.( 9'&)(6< :'(6(6/I9bGL_b2O, _b,.3-9 548/ />3=(6EC,.,A1 9  ADL48%=/218/S,A18/ (6/ BC/21 ,.J'18/>(Y4618&K<248&K7.3=( 7#3 48%'/ \;&)3=9'(7 M 7.G;TU/ <>48( 48%-,A4 <I,A3wG0/m<>18/I,X48/I9 7#3b48%=/m(Y4 ,.< \0P[aG;TU/ <>48(SWS&)48% 3=7#3;F4618&KB5&K,.J'¿ ¥-¤#«ZÀ ¬KÁX ]+/248%=759'( ,A18/Q3=7A4O/I,A(6&)J)_o*'JK,.< /I9h7.3o48%'/V(Y4 ,A<2\0D ,X161 , _'(a]?,I_ G0/ 487L7QJK,A18E./#D-,A3-9+7#G5TY/><>48( <>18/I,X48/I9f&)3f,RJK7L7.*fWS&Z48%f7XBC/>18JK,.*'*=&)3=E J)& M />48&)]+/ ( ,A18/m3'7.4S(Y4 ,.< \.,.G=J)/#P $y7Q,#9'9;18/ (6( 48%=/ (6/ &K(6(6:'/ ( &)3f,VN.kmlnDLW / (6:=E.E#/ (Y4 ,.3b,#9=,A*'48&)BC/ 18/ E.&K7.3'FHG-,A(6/I9d,.J)J)7L<I,A487A1IPx{g3c7#:;1"""",A*=*'187#,.< %rW /?4618/I,A4VJ)7L<I,.J 18/2F E#&)7.3=(S,.( /2j;48/>3=(6&)7#3'( 7 M (Y4 ,A<2\ M 1 ,.]+/ ( P $ %5:'( D'(Y4 ,A<2\.,.G'J)/a7#G5TY/><>48( <I,A3 G0/[<218/I,A48/I9Q&)3V18/ E.&K7.3=(!&)3=(Y48/I,.9V7 M (Y4 ,.< \ M 1 ,A]+/ ( WS&Z48%=7#:;448%=/ ,.G07XBC/!18/ (Y4618&)<>48&)7#3'( P{ M , 18/ E.&K7.3V<>7#3L4 ,.&)3=( 7#3'J)_O3=7#3;FH/ (6<I,.*'&)3=ES7#G;F TY/><>48( D48%=/ 3nWS%=/ 3r&Z48(V,.(6(67L< &K,X48/I9c(Y4 ,.< \ M 1 ,A]+/+&)(V*07.*=*0/I9 D 48%=/ 18/ E.&K7.3o<I,.3oG0/Q9'/I,AJ)JK7L< ,A48/I9oGL_b18/>48:;183=&)3=E+&Z48( ,.(6(67L< &K,X48/I9n*=,.E#/>( 487 48%'/ M 18/ /RJ)&)(Y4 7 M 48%=/a%=/I,A* P ;&)3'< / W[/ WS&)(6%b487V,IBC7#&K9+*07.48/>3548&K,AJKJZ_?/>j;*0/ 3'(6&)BC/ (Y4 ,X48&)<m,.3=,.JZ_5F (6/ ( D W /V&)3=(Y48/I,.9h4 ,A\C/R48%=/V,.*=*;187C,A<2%i7 M ,.3o-Â =Ã ÄI`Å0w(Y461 ,A48/ EA_ WS%=&)< %d9;_;3-,A]+&)<I,.J)JZ_i<I,A48/ E.7.18&)Æ / ("""",.J)J)7L<I,A48&)7#3t(6&Z48/ (V,.(f«)¡Ia ¤.«y,A3-9 ¥0¡A¥-ÀH«)¡Ia ¤.« PO{U3'&Z48&`,AJ)J)_o7.G;TU/ <>48(m,X18/ ,A(6(6:=]+/I9w487?G0/?«)¡Ia8¤#«-,A3-9w48%=/ kml18/ J)&)/ ( 7#3OW 18&Z48/ G-,A1618&)/>18( 487 9'/>48/ <24 / (6<I,A*=&)3=ES7.G;TU/ <>48( P uv%'/ 3 ,.3n7#G5TY/ <24 / (6< ,.*0/ ( D 4gW 7h,A<>48&)7#3'(V,X18/""""4 ,.\C/>3 P?3⁄4 &Z18(Y4IDy48%'/""""< 7A1618/>F (6*07#3=9'&)3=Ef18/ E#&)7.3x&)(m]?,A18\C/ 9i,A(R9'&Z164U_LP 5/ < 7#3=9 D 48%=/ ,.J)J)7L<I,A48&)7.3 (6&Z48/[7 M 48%=/ / (6<I,A*=&)3=E 7#G5TY/ <24&)(<I,A48/ E.7.18&)Æ /I9V,.( 3'7#3;FgJ)7L<I,AJ­DC(67S48%-,A4 (6:=G'(6/IeL:=/ 3L4S,AJ)JK7L< ,A48&)7#3'( M 187#]Ç48%-,X4S(6&Z48/aWS&)JKJ G0/O*=:;4S9'&Z18/ <248J)_f&)3 ,""""E#J)7.G-,.J 18/ E#&)7.3 P È9'&Z164U_?18/ E.&K7.3h&)(a9;/I,.J)J)7L<I,A48/ 9oGL_b,.*'*0/ 3-9;&)3=E 48%=/?*=,.E#/>( ,A(6(67L< &K,A48/I9cWS&Z48%r48%-,A4Q18/ E.&K7.3c487w48%=/+E#J)7.G-,.J 18/>E#&)7#3 W ,A&Z48&K3'E M 7A1Q48%'/+3=/>j54RE#,A18G-,AE#/?< 7.JKJ)/ <248&K7.3 D WS%'&)JK/+48%'/""""*-,AE#/ (Q7 M ,+< J)/I,.3h18/ E.&)7#3o<I,.3oG0/m18/ < JK,A&K]+/ 9o&)]+]+/I9;&K,A48/ JZ_LPSÈ (a/>j;/ < :;48&)7#3 *'187L<>/ /I9'( D5]+7A18/S,.J)J)7L<I,A48&)7.3b(6&Z48/ ( <>18/I,A48&)3'Em/ (6<I,.*'&)3=ER7#G5TY/ <248( ,A18/ ]?,A18\#/I9+,.( 3'7#3;FgJ)7L<I,AJ­D=(67R48%-,X4 J)7L<I,.J018/ E.&)7#3=(S,X18/a]+7A18/ J)&)\C/ JZ_""""487 (Y4 , _ <>JK/ ,.3 P a:'1 ,A*=*'187#,.< % 18/IeL:=&Z18/ ( ,V18/ E.&)7#3'FHG=,.(6/I9h,AJKJ)7L<I,X487.1R,A( &Z48( G-,XF (6&)( P{U3qE./ 3=/21 ,.J­D %=/I,A*=(?7.18E#,.3=&)Æ / 9v,.(?*-,AE#/ ( X<2%5:=3'\5(f*;187XB;&K9;/ , -/>j;&)G=J)/ W , _c487r9'&)B5&K9'/b]+/ ]+7.16_c&)3L487o18/ E#&)7#3'( M 7.1f9;& />18/ 3L4 *':'18*07.(6/ ( D M 7A1m/>j',.]+*'JK/.D=18/ E.&K7.3=(""""Z1>'D!1I5D oA!7.1 48%'18/I,.9;FH(6*0/ < &Zz=< %'/I,.*'(S)1I±XP!3a7IW[/ BC/>1ID.48%=/ ]?,A&K3L48/ 3=,.3'< / 7 M 18/>E#&)7#3'([,A3-9V:'35:=(6/I9 (6*=,.< /Q7#3 *-,.E./ (a< ,.3hJ)/I,#9 487+/2j;461 ,V< 7#(Y48(a,.3-9b7AB#/>18%=/I,.9'(SWS%=/ 3 <>7#]+*-,X18/I9x487o, 0,X4 %'/I,.*c7A18EC,A3=&)ÆI,A48&)7.3 Pn$ %5:=( DW /?z=18(Y4Q7.:'46F J)&)3=/m48%'/R9'/ (6&)E#3h7 M , 18/ E#&)7.3'FHG-,A(6/I9h,.J)J)7L<I,A487A1m,A3-9bW[/Q(6%'7IW1⁄448%'/ G0/>%-,IB5&K7A1 7 M NC,IB., *'187.E.1 ,.]+(S7.3w*-,AE#/>FHG-,A(6/I9 %'/I,.*'( ­&­P /#P)D-%'/I,.*'( <>7#3=(6&)(Y48&)3=E?7 M ,""""(6/24a7 M <2%5:=3'\5( A*-,AE#/ ( 2PSa:'1 (Y48:-95_b(6%'7IWS( 48%-,X4 ]+7.(Y4,AJKJ)7L<I,X48&)7#3=(!<I,A3RG0/ (8,X48&K(Yz=/I9mWS&)48%Q&)3=/>j;*0/ 3'(6&)BC/ 7.*0/>1 ,A48&)7.3=( ,A3-9V48%=,A4!48%=/[< 7.1618/ <24[< %=7.&K<>/ 7 M *-,AE#/ (6&)Æ /SJ)/I,#9;( 487OJ)&Z4648J)/ W ,.(Y48/ 9 (6*=,.< /.P[$ %'&)( (6:=E#E./ (Y48( 48%-,X4 48%=/O*=,.E./>FHG-,.(6/ 9f%'/I,.*b7.18EC,A3=&)ÆI,X48&K7.3 &)( M /I,A(6&)G=J)/ M 7.1 NC,IB., kml ( P ux/a48%=/>3b(6%'7XW~%'7IWv487 G=:'&)J`9?48%=/a,#9=,A*'48&)BC/O(Y_;(Y48/ ] M 7.1 <I,X48/>F E.7.18&)Æ &)3=Ef,AJKJ)7L<I,X48&)7#3=(a&K3L487 48%'7#(6/mWS%=&)< %w(6%=7.:=JK9wG0/R,.J)J)7L<I,X48/I9h&K3 J)7L<I,AJ 18/ E#&)7.3=(+,A(6(67L< &K,A48/I9cWS&Z48%t(Y4 ,A<2\ M 1 ,A]+/ ( D ,.3=9x48%=7#(6/?48%-,X4 (6%'7#:'J`9 ́G0/n9'&Z18/ <248J)_ ́,.J)J)7L<I,A48/ 9s&)3 ́48%=/oE.JK7.G-,AJa18/ E#&)7.3 P {U3q48%'/ 9;/ (6&)E#3qW[/w<I,X18/ M :'JKJZ_@< 7#3'(6&K9'/>1?48%=/b7XBC/>18%=/ ,#9'( D G07.48%t&K3@(6*-,A< / ,A3-9d/>j5461 ,oW 18&Z48/bG-,A1618&)/>1?7XBC/218%=/I,.9 D[,.3-9cW /b*'187.*07#(6/ B.,A18&)7.:=( ,A*=*;187C,.< %=/>( M 7.1 \C/ / *'&)3=EV48%'/ (6/m7XBC/>18%'/I,#9;(S18/ ,.(67#3=,.G'J)_b(6]?,.J)J­P $ %'&)( *=,.*0/>1 ]?,A\C/ ( 48%=/ M 7#J)J)7IWS&)3=E?< 7#3L4618&)G=:;48&)7#3=(  1.P ur/ eL:-,.3L48&Z4 ,A48&)BC/>J)_w(Y4"""	a* search algorithm;flip-flop (electronics);java;keyhole markup language;nc (complexity)	Feng Qian;Laurie J. Hendren	2002		10.1145/773039.512446	stack trace;parallel computing;real-time computing;type system;region-based memory management;stack;computer science;virtual machine;adaptive system;operating system;interconnection;cluster analysis;garbage collection;programming language;static analysis	Vision	-24.34853597720505	38.22805124520001	23873
de8ddeb6dbc1fa73058ab13a973b0b189ac06f28	using the p-tosca model for energy efficient cloud	servers virtual machining clouds standards cooling cloud computing computational modeling;portability;virtual machines cloud computing energy conservation;eucalyptus cloud p tosca model energy efficient cloud computing topology and orchestration specification for cloud applications cloud application cloud architecture virtualized datacenters energy efficient management system virtual machine;green computing;cloud computing;portability cloud computing green computing	The Topology and Orchestration Specification for Cloud Applications (TOSCA) standard is used to describe a cloud application and cloud architecture in order to allow a portable deployment to other compatible cloud and multi-cloud applications. P-TOSCA is recently proposed model and proved concept, which is an extension of the TOSCA standard to improve the TOSCAs ambiguities and weaknesses. In this paper we use the P-TOSCA model for other issues that are also very important in virtualized datacenters and cloud computing, that is, to enlarge/extend the energy efficient management system. A prototype application that dynamically creates a target virtual machine on utilized physical compute node, ports the application(s) from a virtual machine hosted on an underutilized physical server to the target virtual machine in Eucalyptus cloud is presented, which is specified with P-TOSCA. After migration, the prototype application will shut down the underutilized empty physical node.	algorithm;cloud computing;computer cooling;data center;oasis tosca;planning;prototype;semiconductor consolidation;server (computing);software as a service;software deployment;universal instantiation;virtual machine	Bisera Ivanovska;Sasko Ristov;Magdalena Kostoska;Marjan Gusev	2015	2015 38th International Convention on Information and Communication Technology, Electronics and Microelectronics (MIPRO)	10.1109/MIPRO.2015.7160273	green computing;embedded system;real-time computing;single-chip cloud computer;cloud computing;computer science;operating system;cloud testing;utility computing	HPC	-30.55886805273533	55.45733405028087	23881
05e086f253149b55a09f37704156d0279e65718d	proactive service migration for long-running byzantine fault tolerant systems	tiempo respuesta;reponse temporelle;besoin de l utilisateur;fiabilidad;reliability;electronic data processing;software fault tolerance security of data;fault tolerant;temps service;availability;bepress selected works;disponibilidad;fault tolerant computing internet algorithms electronic data processing computer networks;proactive service;exigence usager;exigencia usuario;data processing;long term reliability;software fault tolerance;response time;necesidad usuario;inicializacion;tiempo servicio;vulnerability;service time;comportamiento bizantino;long terme;byzantine fault tolerant systems;vulnerability window byzantine fault tolerant systems proactive service migration proactive recovery scheme long term reliability continuous threats malicious adversaries;comportement arbitraire;long term;computer networks;computer network;temps reponse;byzantine behavior;vulnerabilite;malicious adversaries;fault tolerant system;fault tolerant computing;vulnerabilidad;sevicio proactivo;largo plazo;internet;digital communication;time response;user need;chemin critique;user requirement;critical path;fiabilite;retard;byzantine fault tolerant;sistema tolerando faltas;normal operator;vulnerability window;proactive recovery scheme;algorithms;systeme tolerant les pannes;continuous threats;system architecture;respuesta temporal;retraso;disponibilite;security of data;initialization;initialisation;recorrido critico;service proactif;proactive service migration	In this paper, we describe a proactive recovery scheme based on service migration for long-running Byzantine fault tolerant systems. Proactive recovery is an essential method for ensuring long term reliability of fault tolerant systems that are under continuous threats from malicious adversaries. The primary benefit of our proactive recovery scheme is a reduced vulnerability window under normal operation. This is achieved by two means. First, the time-consuming reboot step is removed from the critical path of proactive recovery. Second, the response time and the service migration latency are continuously profiled and an optimal service migration interval is dynamically determined during runtime based on the observed system load and the user-specified availability requirement.	byzantine fault tolerance;critical path method;load (computing);proactive parallel suite;response time (technology);vulnerability (computing)	Wenbing Zhao	2009	IET Software	10.1049/iet-sen.2008.0065	fault tolerance;real-time computing;data processing;computer science;engineering;distributed computing;programming language;computer security	HPC	-25.671429633483296	43.435787816217406	23903
c32531522ab59b900416fe4b4238d6169218cdc9	hmmsim: a simulator for hardware-software co-design of hybrid main memory	random access memory;memory management;radiation detectors;hidden markov models random access memory nonvolatile memory hardware memory management engines radiation detectors;hidden markov models;engines;nonvolatile memory;hardware software codesign digital simulation dram chips energy consumption;software managed hybrid memory hmmsim hardware software co design hybrid main memory nonvolatile memory nvm energy consumption reduction memory traffic data migration effective migration policy trace driven simulator memory hierarchy components memory architectures dram hardware cache;hardware	Due to scalability and energy consumption, the use of DRAM as the only main memory technology in modern computers is becoming increasingly less appealing. Researchers have proposed combining DRAM and non-volatile memory (NVM) in main memory to increase capacity and reduce energy consumption. Due to its architectural simplicity, software-managed hybrid memory is a promising way to incorporate NVM. However, there are significant performance issues caused by increased memory traffic due to data migration and a lack of effective migration policies. These issues can be addressed by carefully co-designing hardware-software mechanisms and migration policies. To aid in the development of new mechanisms and policies to incorporate NVM in main memory, we present HMMSim, a trace-driven simulator that allows for fast and flexible exploration of the hardware-software co-design space of hybrid main memory. HMMSim has a simple interface to connect memory hierarchy components that can be configured to simulate several memory architectures, including DRAM only, NVM only, DRAM hardware cache, and software-managed hybrid memory. We present two case studies that use HMMSim, and show that HMMSim is fast, flexible and scalable.	cache (computing);computer data storage;dynamic random-access memory;interference (communication);memory hierarchy;non-volatile memory;operating system;scalability;simulation;volatile memory	Santiago Bock;Bruce R. Childers;Rami G. Melhem;Daniel Mossé	2015	2015 IEEE Non-Volatile Memory System and Applications Symposium (NVMSA)	10.1109/NVMSA.2015.7304374	uniform memory access;shared memory;interleaved memory;semiconductor memory;parallel computing;real-time computing;memory rank;sense amplifier;memory refresh;computer hardware;computer science;computer memory;overlay;memory controller;non-volatile random-access memory;conventional memory;extended memory;flat memory model;registered memory;cache-only memory architecture;memory map;memory management	Arch	-8.139184183749462	54.29643270617335	23908
5079d7fd43faf6c1b5579561175d87050bde646e	the asynchronous bounded-cycle model	health research;uk clinical guidelines;biological patents;partially synchronous models;europe pubmed central;citation search;uk phd theses thesis;life sciences;vlsi;clock synchronization;fault tolerant distributed algorithms;uk research reports;medical journals;europe pmc;biomedical research;bioinformatics	This paper shows how synchrony conditions can be added to the purely asynchronous model in a way that avoids any reference to message delays and computing step times, as well as system-wide constraints on execution patterns and network topology. Our Asynchronous Bounded-Cycle (ABC) model just bounds the ratio of the number of forward- and backward-oriented messages in certain (“relevant”) cycles in the space?time diagram of an asynchronous execution. We show that clock synchronization and lock-step rounds can be implemented and proved correct in the ABC model, even in the presence of Byzantine failures. Furthermore, we prove that any algorithm working correctly in the partially synchronous ?-Model also works correctly in the ABC model. In our proof, we first apply a novel method for assigning certain message delays to asynchronous executions, which is based on a variant of Farkas? theorem of linear inequalities and a non-standard cycle space of graphs. Using methods from point-set topology, we then prove that the existence of this delay assignment implies model indistinguishability for time-free safety and liveness properties. We also introduce several weaker variants of the ABC model, and relate our model to the existing partially synchronous system models, in particular, the classic models of Dwork, Lynch and Stockmayer and the query?response model by Mostefaoui, Mourgaya, and Raynal. Finally, we discuss some aspects of the ABC model?s applicability in real systems, in particular, in the context of VLSI Systems-on-Chip.		Peter Robinson;Ulrich Schmid	2011	Theor. Comput. Sci.	10.1016/j.tcs.2010.08.001	clock synchronization;combinatorics;computer science;theoretical computer science;mathematics;distributed computing;very-large-scale integration;algorithm	ECom	-22.373040934957597	43.08050950787471	23924
bbe65ff79801630dcf8ed333014197bfa44756d0	implementation considerations of mapping lisp onto a cellular computer system	data locality;cellular system	Cellular Systems have been proposed as a new architecture to end the dominance of the conventional Von-Neumann machine. LISP as a suitable language for such systems is discussed in this paper. An implementation approach is also presented, thereby providing an insight into system realization, especially with regard to parallelism and data localization. This maximises the potential parallelism offered by cellular systems, while minimising the programming effort.	computer;lisp;parallel computing;realization (systems)	Jialun Shao;G. E. Quick	1985	SIGPLAN Notices	10.1145/988364.988373	computer architecture;computer science;cellular architecture;theoretical computer science;distributed computing;programming language	Arch	-14.624267014799097	41.176087389662804	24000
ab47d9160f8a0a322c7ccf74df8cab2be4558cfd	the instruction systolic array and its relation to other models of parallel computers	systolic array;parallel computer	In this paper we investigate the relationships between three different models of parallel computers based on mesh-connected arrays: the processor array (PA), which is an MIMD-array of independent processors, the instruction broadcasting array (IBA), where the instructions are broadcast to all the processors of a column and executed according to selector information which is broadcast to all the processors of a row, and the instruction systolic array (ISA), where the instructions are pumped through the array row by row and combined with selector information which is pumped through the array column by column. For every two of these models we determine tight bounds on the worst-case delay introduced by a transformation of a program on ene model into an equivalent program on the other. The results show that the ISA concept combines the advantages of standard systolic arrays with those of the MIMD concept. Since in addition the ISA architecture has smaller area requirements than a corresponding systofic array or MIMD machine it is of strong practical relevance.	best, worst and average case;central processing unit;computer;infiniband;mimd;parallel computing;processor array;relevance;requirement;systolic array	Manfred Kunde;Hans-Werner Lang;Manfred Schimmler;Hartmut Schmeck;Heiko Schröder	1988	Parallel Computing	10.1016/0167-8191(88)90095-6	hashed array tree;parallel array;computer architecture;array data structure;parallel computing;systolic array;computer science;theoretical computer science;operating system;misd;sparse array	HPC	-11.186414293209848	41.895545069642125	24017
b1d535205156ed9a0479d12f32a602a5bbd04fa9	networkit: a tool suite for large-scale complex network analysis		We introduce NetworKit, an open-source software package for analyzing the structure of large complex networks. Appropriate algorithmic solutions are required to handle increasingly common large graph data sets containing up to billions of connections. We describe the methodology applied to develop scalable solutions to network analysis problems, including techniques like parallelization, heuristics for computationally expensive problems, efficient data structures, and modular software architecture. Our goal for the software is to package results of our algorithm engineering efforts and put them into the hands of domain experts. NetworKit is implemented as a hybrid combining the kernels written in C++ with a Python frontend, enabling integration into the Python ecosystem of tested tools for data analysis and scientific computing. The package provides a wide range of functionality (including common and novel analytics algorithms and graph generators) and does so via a convenient interface. In an experimental comparison with related software, NetworKit shows the best performance on a range of typical analysis tasks.	algorithm engineering;analysis of algorithms;c++;complex network;computational science;data structure;ecosystem;heuristic (computer science);modular programming;open-source software;parallel computing;python;scalability;software architecture	Christian Staudt;Aleksejs Sazonovs;Henning Meyerhenke	2016	Network Science	10.1017/nws.2016.20	computational science;computer science;bioinformatics;package development process;theoretical computer science;machine learning;data mining	PL	-10.344841494376046	36.18848121819215	24025
e9aa5f2776a6ba6a9d844acb64f796d1888eb5f4	pass it on (passion): an adaptive online load-balancing algorithm for distributed range-query specialized systems	p2p system;range query;fault tolerant;data replication;distributed data structure;skewed distribution;data warehousing;data access;load balance;flash crowds	A basic requirement for every P2P system is fault-tolerance. Since the primary objective is resource location and sharing, we require that this basic operation takes place in a reliable manner. In a variety of situations with skewed data accesses (e.g., [1], etc) the demand for content can become overwhelming for certain serving peers, forcing them to reject connections. In many cases, these skewed distributions take extreme forms: Flash crowds, regularly documented surges in the popularity of certain content, are also known to cause severe congestion and degradation of service [2]. Data replication techniques is one commonly utilized solution to remedy these situations. Nevertheless, there are cases in which the requested resources cannot be arbitrarily replicated. Distributed data-structures that support range-queries is such an example: The keys are stored in the network nodes so that a natural order is preserved. These structures can be very useful in a variety of situations: On-line games, web servers, data-warehousing, etc. In such cases, adaptive and on-line load-balancing schemes must be employed in order to avoid resource unavailability and performance in a variety of workloads[3,4].	algorithm;load balancing (computing)	Ioannis Konstantinou;Dimitrios Tsoumakos;Nectarios Koziris	2008		10.1007/978-3-540-88875-8_2	real-time computing;computer science;database;distributed computing	HPC	-21.806509463680033	50.643585475870054	24204
7269bc078293addb4e907bbba6c1d58168a5c41e	enhancing the i/o system for virtual machines using high performance ssds	virtual machines parallel processing storage allocation;performance evaluation;cpu i o system virtual machines high performance ssd solid state drives vm environment hdd performance degradation fast storage devices i o stack vm storage devices;performance evaluation switches context instruction sets parallel processing delays;switches;context;parallel processing;delays;instruction sets	Storage I/O in VM (Virtual Machine) environments, which requires low latency, becomes problematic as the fast storage such as SSDs (Solid-State Drives) is currently in use. The low performance problem in the VM environment is caused by 1) the presence of additional software layer such as guest OS, 2) context switching between VM and host OS, and 3) scheduling delay for I/O process. These factors do not cause serious problems in the case of using HDD which leads to high latency batching. However, there will be significant performance degradation when fast storage devices are used. To address this problem, we have proposed the following methods to improve the performance of I/O stack in the VM environments by attempting to optimize the I/O stack: one is pipelined polling, and the other is multiple issues and multiple completions. We have found via experiments that our approach leads to increases in the performance of SSDs in a VM environment by up to 50% when multiple VM storage devices are used, and that it leads to improvements in the performance by more than 80% when a single VM storage device is used, with the CPU utilization reduced by up to 25%.	central processing unit;context switch;early completion;elegant degradation;experiment;hard disk drive;input/output;mathematical optimization;operating system;parallel computing;polling (computer science);random access;scheduling (computing);semiconductor industry;solid-state drive;vii;virtual machine;z/vm	Myoungwon Oh;Hyeonsang Eom;Heon Young Yeom	2014	2014 IEEE 33rd International Performance Computing and Communications Conference (IPCCC)	10.1109/PCCC.2014.7017096	parallel processing;parallel computing;real-time computing;computer hardware;network switch;computer science;operating system;instruction set	HPC	-12.314653979853805	52.691584473795444	24231
1ed139fb6bff6dbb3e280db8d46e429591394d70	a distributed vlsi architecture for efficient signal and data processing	tratamiento datos;software;high level languages;multiprocessor;vlsi computer architecture computerised signal processing distributed processing parallel processing signal processing equipment;very large scale integration;distributed processing;flot donnee;distributed computing;data processing;asynchronous execution;traitement donnee;flujo datos;allocation;signal processing equipment;data flow multiprocessor;computer architecture;architecture ordinateur;signal and data processor allocation asynchronous execution data flow multiprocessor distributed computing multiprocessor architecture;multiprocessor architecture;data flow principles signal processor scalable multiprocessor fault tolerant computer embedded computer distributed vlsi architecture hughes data flow multiprocessor programmable multicomputer weight size power consumption performance level reliability modularity;vlsi;arquitectura ordenador;high level languages very large scale integration computer architecture hardware software parallel processing throughput;multiprocesador;data flow;signal and data processor;traitement reparti;parallel processing;computerised signal processing;tratamiento repartido;throughput;hardware;vlsi architecture;multiprocesseur	The machine described, the Hughes Data-Flow Multiprocessor (HDFM), is a high-performance, scalable, fault-tolerant, highly programmable multicomputer designed for embedded signal and data processing applications. The architecture of the machine is described in detail, and the influences on the final design of various requirements such as weight, size, power consumption, performance level and reliability are shown. The processing elements have been designed to reduce the number of VLSI component types required and for modularity of the physical system. The modular nature of the architecture allows a range of throughput and reliability requirements to be met. The model of execution, derived from original data-flow principles, is presented, as well as the various software tools which give the system its high-level language programmability. Complex constructs (such as large structure handling) are demonstrated. The results of a deterministic simulation of the machine show that a 64-processing-element machine may provide real throughput of 64 million instructions per second (MIPS).	dataflow;embedded system;fault tolerance;high- and low-level;high-level programming language;multiprocessing;parallel computing;requirement;scalability;simulation;throughput;very-large-scale integration	Jean-Luc Gaudiot;Rex W. Vedder;George K. Tucker;Dennis Finn;Michael L. Campbell	1985	IEEE Transactions on Computers	10.1109/TC.1985.6312207	embedded system;parallel processing;computer architecture;parallel computing;real-time computing;data processing;computer science;operating system;very-large-scale integration	Arch	-14.110721831108721	43.11719128351495	24272
66de8cc5669c7d3f8ba4f9972088f05fec6f02c4	data-parallel programming on multicomputers	general relativity;data parallel;hypercubes parallel programming concurrent computing programming profession taxonomy functional programming message passing computer aided instruction process design ethernet networks;c programs;multicomputers;parallel programming;n cube 3200 multicomputer;compiler;c language;parallelism;mandelbrot set calculation;control structure;partial pivoting conventional parallel languages multicomputers c language compiler c programs hypercube multicomputer data parallel programs hand compiled c programs n cube 3200 multicomputer mandelbrot set calculation matrix multiplication parallelism control structure gaussian elimination;conventional parallel languages;partial pivoting;program compilers c language parallel machines parallel programming;gaussian elimination;parallel machines;mandelbrot set;matrix multiplication;hypercube multicomputer;program compilers;parallel languages;hand compiled c programs;data parallel programs	The inadequacies of conventional parallel languages for programming multicomputers are identified. The C* language is briefly reviewed, and a compiler that translates C* programs into C programs suitable for compilation and execution on a hypercube multicomputer is presented. Results illustrating the efficiency of executing data-parallel programs on a hypercube multicomputer are reported. They show the speedup achieved by three hand-compiled C* programs executing on an N-Cube 3200 multicomputer. The first two programs, Mandelbrot set calculation and matrix multiplication, have a high degree of parallelism and a simple control structure. The C* compiler can generate relatively straightforward code with performance comparable to hand-written C code. Results for a C* program that performs Gaussian elimination with partial pivoting are also presented and discussed.<<ETX>>	compiler;control flow;cube;degree of parallelism;distributed computing;gaussian elimination;mandelbrot set;matrix multiplication;parallel computing;pivot element;speedup	Michael J. Quinn;Philip J. Hatcher	1990	IEEE Software	10.1109/52.57894	gaussian elimination;computer architecture;compiler;parallel computing;matrix multiplication;computer science;theoretical computer science;general relativity;programming language;control flow;mandelbrot set;pivot element	PL	-12.390476090383471	37.42132298508651	24322
c8d75a9d9bc8cba5ad5222a15f31a022f45ec7d7	executing multi-workflow simulations on a mixed grid/cloud infrastructure using the shiwa and sci-bus technology			cloud computing;simulation	Péter Kacsuk;Gábor Terstyánszky;Ákos Balaskó;Krisztián Karóczkai;Zoltán Farkas	2012		10.3233/978-1-61499-322-3-141	grid;theoretical computer science;grid computing;workflow management system;computer science;cloud computing;utility computing;distributed computing;workflow	HPC	-29.95721093283491	48.01408034650845	24367
b289d21e065c42126732d9e6174028b91c196ff9	partitioning of vector-topological data for parallel gis operations: assessment and performance analysis	tratamiento datos;parallelisme;geologia;algoritmo paralelo;parallel algorithm;geographic information system;spatial data;geologie;data processing;traitement donnee;data partitioning;algorithme parallele;parallelism;paralelismo;geology;particion;analyse performance;performance analysis;partition;information system;systeme information;parallel processing;sistema informacion;analisis eficacia	Geographical Information Systems (GIS) are able to manipulate spatial data. Such spatial data can be available in a variety of formats, one of the most important of which is the vector-topological. This format retains the topological relationships between geographical features and is commonly used in a range of geographical data analyses. This paper describes the implementation and performance of a parallel data partitioning algorithm for the input of vector-topological data to parallel processes.	geographic information system;profiling (computer programming)	Terence M. Sloan;Michael J. Mineter;Steve Dowers;Connor Mulholland;Gordon Darling;Bruce M. Gittings	1999		10.1007/3-540-48311-X_97	partition;parallel processing;enterprise gis;parallel computing;data processing;computer science;theoretical computer science;database;spatial analysis;parallel algorithm;geographic information system;information system;algorithm	HPC	-15.32739023087557	42.49578404926978	24410
c6d59adcedf4e534a35a47162bc9e9fb211cdb62	design patterns for real-time distributed system	real time;distributed system;design pattern		distributed computing;real-time transcription	Yiqin Xu;Daisy F. Sang;Chang-Shyh Peng	2006			distributed algorithm;software design pattern;computer science;design pattern;distributed design patterns;distributed computing	Embedded	-29.61496665693469	46.43613416944842	24415
80f6e3d1f18f63639913c5600b5b6ddc4bc0adf1	the manchester dataflow machine	system performance;software development;model of computation	Abstract   A prototype dataflow computer system has been constructed by a research team at the University of Manchester. The hardware has been operational since October 1981, but has been steadily enhanced since that time. Store capacities and I/O bandwidth are approaching the state where realistically large applications programs can be used to evaluate system performance.  During the period of hardware enhancement, there have been parallel advances in the development of dataflow system software in the form of assemblers, compilers, debugging systems and sundry software tools. The software is also approaching readiness for application to large-scale benchmark programs.  The Manchester system implements a tagged-token dataflow model of computation. This model imposes a tag-field penalty on data values in order to maximise asynchronousness of instruction execution. It is important to know to what extent this overhead is necessary, and how to minimise it whilst maintaining acceptable asynchronousness. In comparison with more conventional architectures it is important that useful measures of cost and performance be developed. With emphasis on these issues, the paper describes the structure of the Manchester dataflow hardware and software, and outlines the system performance results so far obtained. Whilst this work is far from complete, it suggests new avenues for hardware and software development which are being followed at Manchester and elsewhere.	dataflow	John R. Gurd	1985	Future Generation Comp. Syst.	10.1016/0167-739X(85)90009-3	dataflow architecture;parallel computing;real-time computing;simulation;computer science;artificial intelligence;operating system;database;distributed computing;programming language;computer security	Arch	-16.385235160154732	39.29740694455091	24423
73a56cd573dfe11b57a2ae30c02a9b1ff6bdb185	a value-based scheduler capturing schedulability-reliability tradeoff in multiprocessor real-time systems		In real-time systems, tasks must meet their deadlines even in the presence of hardware/software faults. Fault-tolerance in real-time systems refers to the ability of the system to meet tasku0027s deadlines in the presence of faults, and is typically achieved by employing redundancy techniques. Redundancy often improves system reliability at the cost of reducing system schedulability. Therefore, there exists a tradeoff between schedulability and reliability. In this paper, we propose a value-based scheduler capturing this tradeoff in multiprocessor real-time systems. The key function of the scheduler is to select a suitable redundancy level for each task so as to improve performance index of the system, where IP is an integrated performance metric that captures this tradeoff. We have conducted extensive simulation studies to evaluate the effectiveness of the proposed scheduler and its variants for a wide range of system parameters. Our studies show that proposed schedulers maintain a high value-ratio for non-trivial tasks sets.	multiprocessing;real-time operating system;real-time transcription;scheduling (computing)	S. Swaminathan;G. Manimaran	2002	Scalable Computing: Practice and Experience		embedded system;parallel computing;real-time computing;computer science	Embedded	-8.745539339474544	60.2418338719322	24429
2defcceecc3bafa65c31e5973b104d1f54cef03b	concurrency control for distributed cooperative engineering applications	data sharing;long period;design and implementation;concurrency control;cooperative applications;persistent store;middleware;difference set;wide area network	Distributed cooperative engineering applications require consistent and long-term sharing of large volumes of data, which may cause conflicts due to concurrent read/write operations. Therefore designing concurrency control for underlying middleware systems is a difficult issue.Current transactional solutions, even if based on an optimistic approach, do not solve the problem because such applications access shared data for long periods of time performing a large number of read/write operations. Typically, a large set of modifications has to be discarded and this is unacceptable given the amount of work lost.In this paper, we describe the design and implementation of concurrency control mechanisms aimed at both reducing the amount of such conflicts and supporting the consistent long-term sharing of data. The mechanism of visibility depth allows the programmer to specify the consistency of shared data w.r.t. different sets of sites. We also provide other mechanisms: private-copy that allows data to be read/written without being considered as part of a transaction and reordering transaction history to avoid transaction aborts. We evaluate these techniques on a prototypical middleware system called PerDiS and show that: (i) the concurrency control mechanisms are well adapted to support long-lived data sharing in local or wide-area networks, and (ii) performance is acceptable.	concurrency (computer science);concurrency control;control system;middleware;parallel random-access machine;programmer	João Coelho Garcia;Paulo José Azevedo Vianna Ferreira	2002		10.1145/508791.508977	optimistic concurrency control;real-time computing;isolation;computer science;operating system;concurrency control;middleware;database;distributed computing;multiversion concurrency control;non-lock concurrency control;programming language;serializability;world wide web;computer security;difference set;distributed concurrency control	DB	-23.31769002740229	48.81742453794065	24436
9e45ab441f5509cc0d1d9d6544ce38f5bdb20787	performance analysis of a constrained resource sharing system	sistema fila espera;performance measure;systeme attente;sistema operativo;poisson process;exponential distribution;partage ressource;system performance;operating system;queueing system;analyse performance;resource sharing;performance analysis;particion recursos;performance measures;systeme exploitation;queueing models;operating systems;analisis eficacia	We consider a queueing system where the servers are arranged in a circle, and each arriving customer requires a pair of resources that is shared by its server with the respective neighbors on either side. If either resource is being used, the customer is denied service. Customers arrive at each server according to independent Poisson processes, and lengths of service times at each server have an exponential distribution. We derive a closed-form formula for the expected fraction of busy servers at any time in terms of the number of servers and the utilization factor (defined as the arrival rate times the mean service-time duration). This allows us to evaluate system performance when these parameters are varied, and to determine whether denying service to arrivals at alternate servers improves performance. We relate the system to Dijkstra’s dining philosophers problem, which is an abstraction for resource sharing in an operating system.	profiling (computer programming)	Deepinder P. Sidhu;Alexander L. Wijesinha	1998	Queueing Syst.	10.1023/A:1019192316079	shared resource;exponential distribution;real-time computing;simulation;poisson process;mathematics;computer performance;statistics	Metrics	-18.72225088157644	46.507676865718174	24457
91a260a33a57d466b7e6ef3a2dd9a9c7cab6bde7	achieving consistent sdn control with declarative applications	software defined networking;network control consistency	Software-defined networking enables applications act as blackboxes independently to control the network flexibly. However, these independent applications may generate conflicting control decisions. To reconcile applications automatically and dynamically, we implement control applications with Prolog, which enables applications to execute jointly to make consistent control decisions. When conflicts occur, we design a compromise algorithm by sacrificing a subset of applications to maximize the desired control objectives.	algorithm;black box;declarative programming;prolog;software-defined networking	Wen Wang;Cong Liu;Jinshu Su;Wenbo He	2016		10.1145/2934872.2959060	real-time computing;computer science;data mining;distributed computing;software-defined networking;computer network	OS	-24.507323813667494	39.61785063100736	24465
0a714abfcf37a2a37f2d533563b2eed19e8b801b	bluespec: a language for hardware design, simulation, synthesis and verification invited talk	hardware design	"""Bluespec has an execution model based on atomic actions.This model is quite different from traditional hardwaredescription languages like Verilog, VHDL and SystemC.Its also different from software languages like C andJava. Bluespec is based on research at MIT in using TermRewriting Systems (TRS) for hardware descriptions and wasdeveloped into an """"industrial strength"""" language and compilerby the Sandburst Corporation. Bluespec, because ofits execution model, strong typing, and object orientation,can raise the level of hardware design significantly withoutcompromising the ability to synthesize efficient hardware.In this talk I will outline how and why Bluespec improvesthe chip design process by giving examples from microprocessorand other complex chips."""	hardware description language;linearizability;simulation;vhdl;verilog	Arvind	2003			embedded system;parallel computing;real-time computing;computer science;operating system;software engineering;programming language	EDA	-22.793077745305723	34.53332080827871	24469
612657b8ac355379497681fc5c9418848e5d1c0b	furion: alleviating overheads for deep learning framework on single machine (work-in-progress)		Deep learning has been successful at solving many kinds of tasks. Hardware accelerators with high performance and parallelism have become mainstream to implement deep neural networks. In order to increase hardware utilization, multiple applications will share the same compute resource. However, different applications may use different deep learning frameworks and occupy different amounts of resources. If there are no scheduling platforms that are compatible with different frameworks, resources competition will result in longer response time, run out of memory, and other errors. When the resources of the system cannot satisfy all the applications at the same time, application switching overhead will be excessive without reasonable resource management strategy. In this paper, we propose Furion - a middleware alleviates overheads for deep learning framework on a single machine. Furion schedules tasks, overlaps the execution of different computing resource, and batches unknown inputs to increase the hardware accelerator utilization. It dynamically manages memory usage for each application to alleviate the overhead of application switching and make a complex model enable implement in a low-end GPU. Our experiment proved that Furion achieves 2.2x-2.7x speedup on the GTX1060.	deep learning	Lihui Jin;Chao Wang;Lei Gong;Chongchong Xu;Yahui Hu;Luchao Tan;Xuehai Zhou	2018			parallel computing;resource management;deep learning;scheduling (computing);artificial neural network;speedup;schedule;computer science;artificial intelligence;middleware;distributed computing;hardware acceleration	NLP	-10.376571213408022	57.155711363765555	24479
eb5045890d256ce7782c6b02e327505a479acdeb	tinkertoy parallel programming: complicated applications from simple tools		Developing parallel software for unstructured problems continues to be a diicult undertaking, particularly for distributed memory machines. Framework and library support are limited for non-standard applications and developers are often forced to code from scratch. This is particularly true for complex, unstructured applications. In this paper, we show that this needn't always be the case. We describe a set of simple primitives which can be combined to provide solutions to a variety of unstructured parallel computing problems. Speciically, we show how a small set of tools can yield eecient parallel algorithms for particle modeling, crash simulations and transferring data between two independent grids in multiphysics simulations. The use of such tools allows the application developer to program at a higher level without sacriicing performance.	distributed memory;multiphysics;parallel algorithm;parallel computing;simulation	Bruce Hendrickson;Steven J. Plimpton	2001			parallel computing;computer science	HPC	-11.102900745185368	37.09044477980753	24491
d6da285e00f5b3e8fdbc04326e0e0173510f3b37	automatic resource scaling for web applications in the cloud		Web applications play a major role in various enterprise and cloud services. With the popularity of social networks and with the speed at which information can be disseminate around the globe, online systems need to face ever-growing, unpredictable peak load events.		Ching-Chi Lin;Jan-Jan Wu;Pangfeng Liu;Jeng-An Lin;Li-Chung Song	2013		10.1007/978-3-642-38027-3_9	cloud testing	OS	-26.73516405016879	60.08443149171907	24535
5247b25c1a14b0a7d65f7d6b73f9bd0e9622fe5d	openmosix, openssi and kerrighed: a comparative study	single system image;open systems network operating systems workstation clusters;network operating systems;job shop scheduling operating systems containers file systems checkpointing memory management performance analysis kernel resource management dynamic scheduling;operating system;comparative study;ssi operating systems openmosix openssi kerrighed single system image operating system;workstation clusters;open systems	This paper presents a comparative study of Kerrighed, openMosix and OpenSSI, three single system image (SSI) operating systems for clusters. This experimental study gives an overview of SSI features offered by these SSI and evaluates performance of such features.	clusterknoppix;experiment;kerrighed;openssi;operating system;single system image	Renaud Lottiaux;Pascal Gallard;Geoffroy Vallée;Christine Morin;B. Boissinot	2005	CCGrid 2005. IEEE International Symposium on Cluster Computing and the Grid, 2005.	10.1109/CCGRID.2005.1558672	embedded system;real-time computing;computer science;operating system;comparative research;open system	Arch	-12.116152012250815	44.43828920912346	24548
e79d03f811972fb23e87d5c4d9871ffbf56f3f96	the construction of a reliable multipeer communication protocol for distributed virtual environments	distributed system;error recovery;systeme reparti;protocole transmission;multidestinatario;langage java;protocolo transmision;sistema repartido;design and implementation;distributed virtual environment;communication protocol;lenguaje java;multidestinataire;multicast;java language;transmission protocol	We present the design and implementation issues of a Reliable MultiPeer Protocol (RMPP). This protocol is suitable for applications in the area of distributed virtual environments and is written in Java. Motivation, protocol classification, design goals and the error recovery algorithm are discussed. This paper concludes by presenting a possible application of the RMPP.	algorithm;communications protocol;distributed computing;java;multicast;programming paradigm;virtual reality	Gunther Stuer;Frans Arickx;Jan Broeckhove	2002		10.1007/3-540-46080-2_71	communications protocol;real-time computing;multicast;computer science;operating system;distributed computing;computer network	Visualization	-25.726579261410702	41.99297565278365	24556
a4f06946c740ba0f14b9602f211f29a2f3814b8f	scalability studies and large grid computations for surface combatant using cfdship-iowa	ship hydrodynamics;free surface;scalability study;surface combatant;immersed boundary method;message passing interface;high performance computer;unsteady reynolds averaged navier stokes;turbulent flows;large grid computation;turbulent flow;detached eddy simulation;portable extensible toolkit for scientific computation;grid computing;memory bandwidth;free surface flow;flow pattern;central processing unit	Scalability studies and computations using the largest grids to date for free-surface flows are performed using message-passing interface (MPI)-based CFDShip-Iowa toolbox curvilinear (V4) and Cartesian (V6) grid solvers on Navy high-performance computing systems. Both solvers show good strong scalability up to 2048 processors, with V6 showing somewhat better performance than V4. V6 also outperforms V4 in terms of the memory requirements and central processing unit (CPU) time per time-step per grid point. The explicit solvers show better scalability than the implicit solvers, but the latter allows larger time-step sizes, resulting in a lower total CPU time. The multi-grid HYPRE solver shows better scalability than the portable, extensible toolkit for scientific computation solver. The main scalability bottleneck is identified to be the pressure Poisson solver. The memory bandwidth test suggests that further scalability improvements could be obtained by using hybrid MPI/open multi-processing (OpenMP) parallelization. V4-detached eddy simulation (DES) on a 300 M grid for the surface combatant model DTMB 5415 in the straight-ahead condition provides a plausible description of the vortical structures and mean flow patterns observed in the experiments. However, the vortex strengths are over predicted and the turbulence is not resolved. V4-DESs on up to 250 M grids for DTMB 5415 at 20 static drift angle significantly improve the forces and moment predictions compared to the coarse grid unsteady Reynolds averaged Navier–Stokes, due to the improved resolved turbulence predictions. The simulations provide detailed resolution of the free-surface and breaking pattern and vortical and turbulent structures, which will guide planned experiments. V6 simulations on up to 276 M grids for DTMB 5415 in the straight-ahead condition predict diffused vortical structures due to poor wall-layer predictions. This could be due to the limitations of the wall-function implementation for the immersed boundary method.	cartesian closed category;central processing unit;computation;computational science;experiment;explicit and implicit methods;hypre;immersed boundary method;measuring network throughput;memory bandwidth;message passing interface;multiprocessing;navier–stokes equations;openmp;parallel computing;requirement;scalability;simulation;solver;supercomputer;turbulence;vortex	Shanti Bhushan;Pablo Carrica;Jianming Yang;Frederick Stern	2011	IJHPCA	10.1177/1094342010394887	turbulence;parallel computing;simulation;computer science;message passing interface;theoretical computer science;operating system;central processing unit;free surface;thermodynamics;detached eddy simulation;memory bandwidth;grid computing;immersed boundary method	HPC	-5.428407588547999	38.23931142872093	24656
dcedcc233c1f113760e3c7e46128e04fd02901be	data centers in the cloud: a large scale performance study	focusing;file servers;virtualisation cloud computing computer centres economies of scale file servers;capacity planning;resource management;datacenter;servers resource management capacity planning time series analysis economics bandwidth focusing;computer centres;capacity planing datacenter performance analysis;servers;time series analysis;capacity planing;performance analysis;bandwidth;economics;economies of scale;data center server workload holistic characterization cloud virtualization technologies economies of scale data center availability workload demand interaction resource availability in production data center servers in depth analysis data center demand time evolution;virtualisation;cloud computing	With the advancement of virtualization technologies and the benefit of economies of scale, industries are seeking scalable IT solutions, such as data centers hosted either in-house or by a third party. Data center availability, often via a cloud setting, is ubiquitous. Nonetheless, little is known about the in-production performance of data centers, and especially the interaction of workload demands and resource availability. This study fills this gap by conducting a large scale survey of in-production data center servers within a time period that spans two years. We provide in-depth analysis on the time evolution of existing data center demands by providing a holistic characterization of typical data center server workloads, by focusing on their basic resource components, including CPU, memory, and storage systems. We especially focus on seasonality of resource demands and how this is affected by different geographical locations. This survey provides a glimpse on the evolution of data center workloads and provides a basis for an economics analysis that can be used for effective capacity planning of future data centers.	autocorrelation;central processing unit;cloud computing;data center;elasticity (data store);holism;network traffic control;scalability;seasonality;server (computing)	Robert Birke;Lydia Y. Chen;Evgenia Smirni	2012	2012 IEEE Fifth International Conference on Cloud Computing	10.1109/CLOUD.2012.87	file server;data center;real-time computing;simulation;data center services;cloud computing;computer science;economies of scale;resource management;operating system;time series;bandwidth;server	Metrics	-23.471415917275095	59.97627811950167	24679
589aee436c3c611338cbab3997f1e85e58a5b987	compositional sequentialization of periodic programs		We advance the state-of-the-art in verifying periodic programs – a commonly used form of real-time software that consists of a set of asynchronous tasks running periodically and being scheduled preemptively based on their priorities. We focus on an approach based on sequentialization (generating an equivalent sequential program) of a time-bounded periodic program. We present a new compositional form of sequentialization that improves on earlier work in terms of both scalability and completeness (i.e., false warnings) by leveraging temporal separation between jobs in the same hyper-period and across multiple hyper-periods. We also show how the new sequentialization can be further improved in the case of harmonic systems to generate sequential programs of asymptotically smaller size. Experiments indicate that our new sequentialization improves verification time by orders of magnitude compared to competing schemes.	application programming interface;assertion (software development);benchmark (computing);embedded system;experiment;hyper-heuristic;hyper-threading;race condition;real-time clock;real-time computing;robotics;scalability;verification and validation	Sagar Chaki;Arie Gurfinkel;Soonho Kong;Ofer Strichman	2013		10.1007/978-3-642-35873-9_31	real-time computing;distributed computing;algorithm	SE	-20.071801086261434	32.71059595044824	24698
94ae611ec94878a40e1e51b78108280045658196	integrating linux and the real-time erika os through the xen hypervisor	xen toolstack linux realtime erika os operating system xen hypervisor user interfaces safety critical control tasks single board dual os system erika enterprise operating system safety certification point of view;user interfaces linux safety critical software;operating systems virtual machine monitors real time systems linux user interfaces open source software;virtual machine monitors;linux;user interfaces;open source software;operating systems;real time systems	Modern user interfaces grow more and more complex and cannot be possibly handled by the same software components in charge of the timely execution of safety-critical control tasks. Evidence Srl recently proposed a single-board dual-OS system aimed at combining the flexibility of the Linux general-purpose operating system, which is able to produce any complex user interface, and the reliability of the automotive-grade ERIKA Enterprise operating system, a small-footprint real-time OS suitable for safety-critical control tasks and able to execute commands triggered by Linux. The operating systems run on dedicated cores and, for efficiency reasons, they share memory with limited support for memory protection: although the system allows running two operating systems, from a safety certification point of view it suffers from the fact that safety-critical and non-safety-critical components should be isolated from each other. In this paper we present, as an improvement to the initial implementation, again a double-OS system running, on a dual-core platform, ERIKA Enterprise and a full-featured Linux OS, but using the Xen hypervisor to run the two operating systems in two isolated domains. In the proposed setup, each of the domains runs on a dedicated core, assigned statically by the hypervisor. Linux runs as the control domain, and is therefore able to execute any of the components of the Xen toolstack; it is also able to grant to the real-time operating system access to any I/O-memory range needed for control tasks. The described system also provides a simple, safe communication mechanism between the two operating systems, based on Xen's inter-domain event notification primitives and explicit sharing of a dedicated set of memory pages by the real-time operating system.	arm architecture;component-based software engineering;erika enterprise;event (computing);general-purpose modeling;hypervisor;input/output;inter-domain;linux;memory protection;multi-core processor;open-source software;real-time clock;real-time operating system;real-time transcription;single-board microcontroller;software deployment;user interface;virtual machine;wiki	Arianna Avanzini;Paolo Valente;Dario Faggioli;Paolo Gai	2015	10th IEEE International Symposium on Industrial Embedded Systems (SIES)	10.1109/SIES.2015.7185063	embedded system;embedded operating system;real-time computing;gnu/linux;computer science;operating system;standard operating environment;process management;hypervisor;user interface;supercomputer operating systems;linux kernel	Embedded	-26.22275793310366	50.544738937726024	24719
549b4ed33ab0436742ad24e09de48b5434f7627b	1401 compatibility feature on the ibm system/360 model 30	ibm system;compatibility feature		ibm system/360	M. A. McCormack;T. T. Schansman;K. K. Womack	1965	Commun. ACM	10.1145/365691.365939	theoretical computer science;ibm;computer science;computational science;compatibility (mechanics)	Logic	-7.742827757673612	37.82369674404604	24758
1e0da85e0e65b116c13de06c6512f8847c6b21dc	a highly efficient implementation of i/o functions on gpu	libraries;debugging;kernel;graphics processing unit kernel message systems debugging coherence libraries instruction sets;mapped memory cuda i o functions;mapped memory;i o functions;cuda;real time debug method highly efficient implementation i o functions gpu api interfaces cuda applications read write file printf;parallel architectures;parallel architectures application program interfaces graphics processing units;message systems;graphics processing units;application program interfaces;coherence;graphics processing unit;instruction sets	The API interfaces provided by CUDA can help programmers develop CUDA applications and get high performance in GPU. However, many of the I/O operations are not supported in device codes. This paper has implemented most of the I/O functions through host's agent by using the characteristics of mapped memory in CUDA, such as read/write file and 'printf'. The methods that used to implement these I/O functions will not affect the performance of original applications, users' I/O requirements can be responded quickly, even more, the performance of 'printf' implemented in this paper is higher than that provided by CUDA. This paper supports easy and effective real-time debug method to GPU users, the research in this paper can improve productivity of converting legacy C/C++ codes to CUDA codes, and it is a valuable investigation for broadening CUDA's functions.	c++;cuda;code;compiler;graphics processing unit;input/output;printf format string;programmer;real-time clock;real-time transcription;requirement;scalability;server (computing);web server	Wei Wu;Feng Bin Qi;Wang Quan He;Shan-Shan Wang	2012	2012 IEEE 26th International Parallel and Distributed Processing Symposium Workshops & PhD Forum	10.1109/IPDPSW.2012.295	cuda pinned memory;computer architecture;parallel computing;kernel;coherence;computer hardware;computer science;operating system;instruction set;programming language;debugging	HPC	-6.182438293894007	43.22262609528761	24787
98a2ccb24aceeb872c593eb69b16379c739fe2d6	a performance evaluation on caching mechanisms for a persistent object system	performance evaluation;persistence;object oriented programming;operating system	This paper analizes the performance of caching mechanisms in a persistent object system. Techniques used in operating systems and developed by the author are investigated. Execution timings and analysis of results are presented.	cache (computing);operating system;performance evaluation	Christopher Burdorf	1993	OOPS Messenger	10.1145/165507.165526	persistence;real-time computing;simulation;computer science;distributed computing;programming language;object-oriented programming	Theory	-20.665490228244643	47.832363827288546	24814
2a2d5b58c392931163bf078fbb218895b5cf9027	a hybrid execution model for fine-grained languages on distributed memory multicomputers	sequential efficiency;fine-grained language;stack-based execution;poor execution effciency;parallel execution;parallel efficiency;low overhead parallel execution;dynamically adapts;memory multicomputers;hybrid execution model;parallel version;optimized sequential;concurrent computing;compiling;decoupled architecture;switches;quantitative analysis;performance;concurrency control;optimization;distributed computing;parallel processing;computer science;code optimization	While fine-grained concurrent languages can naturally capture concurrency in many irregular and dynamic problems, their flexibility has generally resulted in poor execution effciency. In such languages the computation consists of many small threads which are created dynamically and synchronized implicitly. In order to minimize the overhead of these operations, we propose a hybrid execution model which dynamically adapts to runtime data layout, providing both sequential efficiency and low overhead parallel execution. This model uses separately optimized sequential and parallel versions of code. Sequential efficiency is obtained by dynamically coalescing threads via stack-based execution and parallel efficiency through latency hiding and cheap synchronization using heap-allocated activation frames. Novel aspects of the stack mechanism include handling return values for futures and executing forwarded messages (the responsibility to reply is passed along, like call/cc in Scheme) on the stack. In addition, the hybrid execution model is expressed entirely in C, and therefore is easily portable to many systems. Experiments with function-call intensive programs show that this model achieves sequential efficiency comparable to C programs. Experiments with regular and irregular application kernels on the CM5 and T3D demonstrate that it can yield 1.5to 3 times better performance than code optimized for parallel execution alone.	distributed memory	John Plevyak;Vijay Karamcheti;Xingbin Zhang;Andrew A. Chien	1995		10.1109/SUPERC.1995.2	parallel processing;compiler;parallel computing;real-time computing;concurrent computing;performance;network switch;computer science;quantitative analysis;decoupled architecture;operating system;concurrency control;program optimization;distributed computing;programming language	HPC	-13.826431140599661	46.54388365272445	24819
15560a5884f6c4e5ee471d33090eb6f9067fbc35	the interplay of power management and fault recovery in real-time systems	power supplies;system reliability;reliability;fault tolerant;processor scheduling;frequency scaling;checkpointing;fault tolerant computing;system recovery;fault tolerant systems;energy consumption;power system management;fault tolerance;batteries;power management;system recovery processor scheduling real time systems power demand computer fault tolerance;real time system;power system reliability;power consumption;frequency;voltage scaling;defense advanced research project agency;fault recovery;energy saving;energy management;fault tolerant computing system recovery processor scheduling real time systems power consumption;uniform distribution;real time systems;system reliability power management fault recovery real time system checkpointing voltage scaling frequency scaling energy consumption	We describe how to exploit the scheduling slack in a real-time system to reduce energy consumption and achieve fault tolerance at the same time. During failure-free operation, a task takes checkpoints to enable recovery from failure. Additionally, the system exploits the slack to conserve energy by reducing the processor speed. If a task fails, it will restart from a saved checkpoint and execute at maximum speed to guarantee that the deadlines are met. We show that the number of checkpoints and their placements interact in subtle ways with the power management policy. We study two checkpoint placement policies for aperiodic tasks and analytically derive the optimal number of checkpoints to conserve energy under each. This optimal number allows the CPU speed to be slowed down to the level that yields minimum energy consumption, while still guaranteeing recoverability of tasks under each checkpointing policy. The results show that traditional periodic checkpointing is not the best policy for the combined purpose of conserving energy and guaranteeing recovery. Instead, better energy savings are possible through a nonuniform distribution of checkpoints that takes into account the energy consumption and reliability factors. Depending on the amount of slack and the checkpointing overhead, energy can be reduced by up to 68 percent under nonuniform checkpointing. We also demonstrate the applicability of these checkpoint placement policies to periodic tasks.	application checkpointing;bl (logic);central processing unit;clock rate;execution unit;fault tolerance;overhead (computing);power management;real-time clock;real-time computing;scheduling (computing);serializability;slack variable;transaction processing system	Rami G. Melhem;Daniel Mossé;E. N. Elnozahy	2004	IEEE Transactions on Computers	10.1109/TC.2004.1261830	embedded system;fault tolerance;parallel computing;real-time computing;real-time operating system;computer science;operating system;statistics	Embedded	-5.463605784950666	58.35010895447164	24839
69f0b92d73e5468cf596c2d6ee9f658dea04ff07	mixsl: an efficient transaction recovery model in flash-based dbms	flash memory;database;recovery;shadow page	With the development of flash technologies, flash disks have become an alternative to hard disk as external storage media. Because of the unique characteristics of flash disks such as fast random read access and out-place update, shadow paging technology can be adopted to support transaction recovery in flash-based DBMS. Inspired by shadow paging and logging, we propose a new transaction commit model named MixSL which can be used in databases built on MLC flash disks. Based on MixSL, we detail normal processing, garbage collection and recovery. For improving system performance and raising the utilization ratio of flash disks, we extend MixSL to support group commit. Our performance evaluation based on the TPC-C benchmark shows that MixSL outperforms the state-of-the-art recovery protocols.	adobe flash;benchmark (computing);concurrency (computer science);concurrency control;database;disk storage;external storage;flash memory;garbage collection (computer science);hard disk drive;ibm tivoli storage productivity center;multi-level cell;no-force;performance evaluation;random access;shadow paging;transaction processing system	Yulei Fan;Xiaofeng Meng	2013		10.1007/978-3-642-38562-9_40	flash file system;parallel computing;real-time computing;recovery;computer science;operating system;flash memory emulator;database	DB	-12.1695157878769	53.99099282403964	24851
97324bc9f94053fb9542e5e053d4276d3ffdf1bb	interactive exploration of the afs file system	afs;drill-down;filesystem;monitoring;visualization	Managing file systems of large organizations can present significant challenges in terms of the number of users, shared access to parts of the file system, and securing and monitoring critical parts of the file system. We present an interactive exploratory tool for monitoring and viewing the complex relationships within the Andrews File System (AFS). This tool is targeted as an aid to system administrators to manage users, applications and shared access. We tested our tool on UNC Charlotte’s Andrews File System (AFS) file system, which contains 4554 users, 556 user groups, and 2.2 million directories. Two types of visualizations are supported to explore file system relationships. In addition, drill-down features are provided to access the user file system and access control information of any directory within the system. All of the views are linked to facilitate easy navigation.	access control;data drilling;directory (computing);system administrator	Joshua Foster;Kalpathi R. Subramanian;Robert Herring;Gail-Joon Ahn	2004	IEEE Symposium on Information Visualization	10.1109/INFVIS.2004.40	self-certifying file system;visualization;device file;computer file;drill down;computer science;access control;operating system;unix file types;ssh file transfer protocol;journaling file system;data mining;database;open;distributed file system;everything is a file;global namespace;world wide web;design rule for camera file system;virtual file system	OS	-25.567903557650823	50.87427189999412	24865
987983d6c288930ea20f62e0b12d051d02c49e7b	storage fusion	tracking bias compensation;tracking bias;location systems;elp dll;eml dll	So far, the core component of the IT system was absolutely a server, and the storage was recognized as its peripheral. The recent evolution of device and network technologies has enabled storage consolidation, by which all the data and its related simple software codes can be placed in one place. Storage centric designs are being deployed into many enterprise systems. The role of the storage should be reconsidered. This paper presents activities of the Storage Fusion Project, a five-year research and development project. Storage Fusion is an idea of elegant deep collaboration between storage and database servers. Two substantial works are presented in this paper. First, the exploitation of query execution plans enables dynamically informed prefetching, accordingly boosting ad-hoc queries significantly. Second, the idea of putting autonomic database reorganization into the storage has the potential benefit of relieving the management burdens of database structural deterioration.	autonomic networking;cpu cache;code;database server;enterprise system;hoc (programming language);peripheral;semiconductor consolidation;server (computing)	Masaru Kitsuregawa;Kazuo Goda;Takashi Hoshino	2008		10.1145/1352793.1352852	embedded system;converged storage;telecommunications;operating system;data mining;database;information repository;world wide web;computer security	DB	-20.54917349583136	51.195802694420856	24880
3ec0fdc346d307375e5fd9828e9bb195b78aa272	automatic two way synchronization between server and multiple clients for hvac system	multiple instance;multi agent system;client server architecture;online file storage;economic efficiency;data synchronization;thick client;web service;embedded system;embedded systems;multi agent systems;hvac;operating system;hvac system	The authors study different two way synchronization methods between a server and distributed clients. Client-server architectures are used to control multiple instances from center. Hard-coded embedded controllers are replaced by embedded controllers based on general purpose operation systems. Authors aims to find the best synchronization method to exhange data between a HVAC system and a server. The synchronization is tested using different methods: online file storage, database, ftp, mail and web-service. The system based on online file storage was implemented in a city in Holland to control a HVAC system. The embedded controller receives data from the server to perform better control and increase economical efficiency of the HVAC system. All synchronization methods discussed in the paper can be implemented in other domains.	client–server model;database;embedded controller;embedded system;server (computing);synchronization (computer science);web service	Anton Tyukov;Adriaan Brebels;Maxim Shcherbakov	2011		10.1145/2095536.2095632	embedded system;real-time computing;computer science;distributed computing;data synchronization	Embedded	-31.768913935725006	42.430564890136814	24895
2bacaa96ea4b6942ee9a74477373bf24eff73c00	a tcp/ip network facsimile system built from publicly available software	tuple space;transputer;system development;ip networks;speculative processing;parallel lisp	A network desktop facsimile system was developed from inexpensive hardware and publicly available software. This system allows users on a TCP/IP network to develop documents and have them FAXed without printing out the document and using a manual FAX machine. The desktop facsimile system also receives FAXes. Schemes for electronic routing of incoming FAXes are outlined. The system is written in C and uses TCP/IP network protocols. Existing standards, system development and integration of publicly available software are discussed.	communications protocol;desktop computer;fax;internet protocol suite;printing;routing	Chane L. Fullmer;Brent Auernheimer;William L. Morris	1992		10.1145/131214.131281	embedded system;real-time computing;computer science;tuple space;operating system;database	Networks	-31.52027045061425	42.30549354222305	24909
1e0d9aeb8a8072d877809f97ce404e82134f4435	an energy-efficient parallel multi-core adas processor with robust visual attention and workload-prediction dvfs for real-time hd stereo stream	energy efficiency;throughput arrays optical arrays energy efficiency parallel processing logic gates;video streaming driver information systems microprocessor chips multiprocessing systems network on chip parallel processing power aware computing stereo image processing;arrays;logic gates;optical arrays;dynamic resource management advanced driver assistance system multiple granularity parallelism multi core architecture visual attention congestion avoiding network on chip;soc energy efficient parallel multicore adas processor robust visual attention workload prediction dvfs real time hd stereo stream advanced driver assistance system heterogeneous multicore processor 720p stereo video stream parallel simd mimd architecture visual attention network on chip computation cost network congestion data resource management processor workload prediction dynamic voltage and frequency scaling;parallel processing;throughput	A heterogeneous multicore processor is proposed to accelerate advanced driver assistance system (ADAS). To enable a real-time operation of ADAS functions with 720p stereo video stream, multiple granualrity parallel SIMD/MIMD architecture is proposed with precise visual attention and high throughput network-on-chip to reduce computation cost and network congestion, respectively. In addition, it employs a data resource management processor to control workload-prediction dynamic voltage and frequency scaling to reduce power consumption. As a result, the proposed SoC ahcieves 862GOPS/W energy efficiency and 31.4GOPS/mm2 area efficiency, which are 53% and 75% improvement over the state-of-the-art ADAS processor, respectively.	architecture design and assessment system;computation;dynamic frequency scaling;dynamic voltage scaling;image scaling;mimd;multi-core processor;network congestion;network on a chip;real-time clock;simd;streaming media;throughput	Kyuho Jason Lee;Kyeongryeol Bong;Changhyeon Kim;Junyoung Park;Hoi-Jun Yoo	2016	2016 IEEE Symposium in Low-Power and High-Speed Chips (COOL CHIPS XIX)	10.1109/CoolChips.2016.7503672	embedded system;parallel computing;real-time computing;computer science	Arch	-6.103538418188474	58.36140045053101	24918
469faab238738894fd04314466b20f120963962d	the fraunhofer virtual machine: a communication library and runtime system based on the rdma model	modelizacion;distributed system;virtual machine;systeme reparti;storage access;fraunhofer virtual machine;calculator cluster;real time;acceso directo;distributed computing;machine virtuelle;programming model;modelisation;biblioteca electronica;grappe calculateur;sistema repartido;acces direct;temps reel;acces memoire;direct access;acceso memoria;calculo repartido;rdma;tiempo real;electronic library;runtime system;maquina virtual;modeling;calcul reparti;communication pattern;parallel applications;bibliotheque electronique;racimo calculadora	The RDMA model provides an interesting basis for the creation of runtime systems and programming models targeting the development of parallel applications. There is a wide range of applications and algorithms that naturally fit the one-sided communication pattern presented by the RDMA model. In this paper we present the Fraunhofer Virtual Machine. The FVM is a communication library and runtime system for the development of real-time parallel applications that run on clusters of computers. It uses the Infiniband Architecture, as it supports the RDMA model, for the communication between the nodes. We provide an overview on the architecture and execution model of the Fraunhofer Virtual Machine along with the implemented functionality available to the programmer.	algorithm;application programming interface;computer cluster;gigabit;graphics processing unit;high- and low-level;infiniband;message passing interface;programmer;programming model;real-time clock;remote direct memory access;runtime system;virtual machine	Rui Machado;Carsten Lojewski	2009	Computer Science - Research and Development	10.1007/s00450-009-0088-2	embedded system;parallel computing;systems modeling;remote direct memory access;computer science;virtual machine;operating system;distributed computing;programming paradigm	HPC	-17.596796804358785	42.49615198479428	24962
b065de79d666d7cd158a6edcb5080e82bc99eeca	run-time object code compilation to hardware			compiler;object code	Ian Jason	2008				PL	-22.291033083333875	33.71074984726644	25001
610a6664d6ed02b2046d67f6ef69c2aea732a805	the synchronization treatment in implementing data-parallel programming languages on cpus	ssa data parallelism synchronization thread function splitting low level intermediate code;registers;synchronization;graphics processing units;transforms;switches;algorithm design and analysis;synchronization instruction sets graphics processing units transforms registers switches algorithm design and analysis;instruction sets	When implementing data-parallel programming languages such as CUDA, OpenCL on CPUs, synchronization must be simulated correctly. The basic method is thread-based, which means all thread must execute one instruction in turn before execute the next one. In this paper, we propose function splitting to treat synchronization in a co routine style but not just thread-based. It splits the data-parallel function presented by low-level intermediate representation into several parts by simulating synchronization. We evaluate our method in translating PTX kernels to multi-core CPUs, the result of which shows this method could promotes performance by 15% compared to thread-based method. Our main contribution is a generous synchronization treatment that performs on low-level intermediate code given by a control flow graph in SSA form.	cuda;central processing unit;control flow graph;coroutine;high- and low-level;intermediate representation;multi-core processor;opencl api;parallel computing;programming language;simulation;static single assignment form;thread (computing)	Feng Yue;Jianmin Pang;Rongcai Zhao;Chao Dai	2013	2013 IEEE 10th International Conference on High Performance Computing and Communications & 2013 IEEE International Conference on Embedded and Ubiquitous Computing	10.1109/HPCC.and.EUC.2013.275	algorithm design;synchronization;computer architecture;parallel computing;real-time computing;network switch;computer science;operating system;instruction set;distributed computing;data synchronization;processor register;synchronization	Robotics	-6.386944342992136	44.29151977690335	25032
33d7d2951c5fb585b21c7acdbf94456a71b52027	does query performance optimization lead to energy efficiency? a comparative analysis of energy efficiency of database operations under different workload scenarios		ABSTRACT With the continuous increase of online services as well as energy costs, energy consumption becomes a significant cost factor for the evaluation of data center operations. A significant contributor to that is the performance of database servers which are found to constitute the backbone of online services. From a software approach, while a set of novel data management technologies appear in the market e.g. key-value based or in-memory databases, classic relational database management systems (RDBMS) are still widely used. In addition from a hardware perspective, the majority of database servers is still using standard magnetic hard drives (HDDs) instead of solid state drives (SSDs) due to lower cost of storage per gigabyte, disregarding the performance boost that might be given due to high cost.	attribute–value pair;data center;database server;e-services;gigabyte;hard disk drive;in-memory database;internet backbone;mathematical optimization;qualitative comparative analysis;relational database management system;solid-state drive	Raik Niemann;Nikolaos Korfiatis;Roberto V. Zicari;Richard Göbel	2013	CoRR		real-time computing;computer science;data mining;database	DB	-14.497975863223802	53.641617637442096	25038
8d147ce8f5de61f1e939c994eb088663f6d24250	demo: reptor: enabling api virtualization on android for platform openness		This paper proposes a new technique that enables open innovation in mobile platforms. Our technique allows third-party developers to modify, instrument, or extend platform API calls and deploy their modifications seamlessly. The uniqueness of our technique is that it enables modifications completely at the app layer without requiring any platform-level changes. This allows practical openness---third parties can easily distribute their modifications for a platform without the need to update the entire platform. To demonstrate the benefits of our technique, we have developed a prototype on Android called Reptor and used it to instrument real-world apps with novel functionality. Our evaluation in realistic scenarios shows that Reptor has little overhead in performance and energy, and only modest overhead in memory usage that ranges from 0.6% to 10% for the observed worst cases.	android;application programming interface;class hierarchy;disk mirroring;openness;overhead (computing);play store;rewriting;type class	Taeyeon Ki;Alexander Simeonov;Chang Min Park;Karthik Dantu;Steven Y. Ko;Lukasz Ziarek	2017		10.1145/3081333.3089338	embedded system;uniqueness;virtualization;open innovation;computer science;android (operating system);operating system	Mobile	-26.620190974063615	55.76071284879371	25041
0791f5f5198346b7640a1611008be59a2cf86f0d	using csp languages to program parallel workstation systems	distributed application;programming environment;global computing;network of workstation;parallel applications	During the last decade one of the most relevant events in the computer market has been the large diffusion of workstations. In both industrial and research environments a huge amount of computing is done on personal workstations. Despite the rapid growth in networking technologies, however, a network of workstations cannot be easily seen as a global computational resource, although it represents a large amount of computing power. Moreover, its inherent parallelism is not accessible without a heavy effort to modify existing software and/or to develop new code. It is our belief that the CSP model is suitable to develop distributed applications for a particular class of such systems that can be defined Parallel Workstation Systems. This thesis has been tested in the course of the DISC project. In DISC, the language implementation of the CSP model tries to minimize the programming effort toward the development of parallel applications, and a friendly programming environment, integrated in the native workbench of workstations, is provided.	computational resource;computer cluster;disk storage;distributed computing;integrated development environment;parallel computing;workbench;workstation	Antonino Mazzeo;Stefano Russo;Giorgio Ventre	1992	Future Generation Comp. Syst.	10.1016/0167-739X(92)90036-B	computer architecture;parallel computing;computer science;operating system;database;distributed computing;programming language	HPC	-12.620413636348795	40.35381179664088	25048
dc34020de73708688a2f509f4e7a9f1beebec037	service-based global spatial data directory in spatial information grid	resource monitoring;reliability;spatial data query service based global spatial data directory spatial information grid security infrastructure distributed computing distributed spatial information resources global spatial data directory information tree organization spatial data resources spatial database spatial operation services synchronous mechanism resource monitoring discovery service digital raster graphics spatial metadata resource security level access control mechanism minimum bounding rectangle;spatial data;authorisation;distributed spatial information resources;access control mechanism;distributed processing;distributed computing;resource security level;spatial databases monitoring synchronization distributed databases access control reliability;spatial index;role based access control;sig;synchronous mechanism;spatial metadata;spatial database;sig data directory spatial database grid computing;information tree organization;globus toolkit 4;discovery service;spatial operation services;spatial data resources;monitoring;synchronization;indexation;spatial databases;digital raster graphics;visual databases authorisation distributed processing grid computing meta data;distributed databases;service based global spatial data directory;grid security infrastructure;meta data;access control;global spatial data directory;data directory;minimum bounding rectangle;grid computing;spatial information;spatial information grid security infrastructure;directory service;visual databases;spatial data query	Spatial Information Grid (SIG) is a spatial information infrastructure that has the capability of providing services on-demand. It provides a new distributed computing pattern for sharing and operating the massive distributed spatial information resources. The global spatial data directory is an information tree organization used to quickly locate spatial data resources and spatial database nodes in SIG and it is a key technology about quickly discovering, querying and locating spatial information resources. In this research, groups of spatial information services and spatial operation services are developed to support spatial data discovery and spatial applications. Spatial database distributed on scattered nodes. They are connected by the network and form a visual super global spatial database. Spatial database on proximity or logically associated nodes combined as a domain spatial database and a domain spatial data directory was built by the local spatial directory service. Directories in different domains build the global spatial data directory by the directory copy and synchronous mechanism. A resource monitoring and discovery service (MDS) was developed to discover new spatial resources and monitor resources' status. Spatial data resources such as layers and digital raster graphics (DRG) were registered to the directory as spatial metadata, and node information and resource security level are also contained in spatial metadata structure. A security spatial resources access control mechanism was implemented based on grid security infrastructure (GSI) and role based access control (RBAC). Global spatial indexes were built by layer type, role permission or minimum bounding rectangle (MBR) based on the global spatial data directory. Spatial data query and quickly locate were well supported by these indexes. Spatial database nodes' dynamic join and exit are also supported, and “Center-Based” global directory's single-point dependence problem was resolved. The Globus Toolkit 4.0 was used as the grid infrastructure in this research.	digital raster graphic;directory (computing);directory service;distributed computing;grid security infrastructure;minimum bounding rectangle;raster graphics;role-based access control;spatial database	Xincai Wu;Linbing Xia;Liang Wu	2010	2010 18th International Conference on Geoinformatics	10.1109/GEOINFORMATICS.2010.5567589	spatial data infrastructure;object-based spatial database;computer science;spatial reference system;data mining;database;world wide web;spatial database;spatial query	DB	-31.93354908673726	50.21520295656915	25063
063f62b0d59231fce08726b7ad9d25d08ed701da	checkpoints of gui-based applications	graphic user interface	We describe a new system, called guievict, that enables the graphical user interface (GUI) of any application to be transparently migrated to or replicated on another display without premeditative steps such as re-linking the application program binary or re-directing the application process’s window system communication through a proxy. Guievict is based on a small X window server extension that enables an application to retrieve itswindow session , a transportable representation of its GUI, from the window server and a library of GUI migration functionality that is injected in the application process at run time. We discuss the underlying technical issues: controlling and synchronizing the communication between the application and the window system, identifying and retrieving the GUI resources that form the window session, regenerating the window session in a new window system, and maintaining application transparency. We have implemented guievict for the XFree86 implementation of the X window system. The GUI migration performance of guievict is measurably but not perceptibly worse than that of a proxy-based system.	display server;graphical user interface;run time (program lifecycle phase);server (computing);x window system;x.org server	Victor C. Zandy;Barton P. Miller	2003			synchronizing;real-time computing;computer science;transparency (graphic);graphical user interface	OS	-31.981446184325915	41.03528374495252	25103
446d27bfb3d9f1cccb65b7574b20dd96bc90006a	partial evaluation applied to numerical computation	expressive power;partial evaluation;numerical computation;data abstraction;high performance;data structure	There have been many demonstrations that the expressive power of Lisp can greatly simplify the process of writing numerical programs, but at the cost of reduced performance.[10][16] I show that by coupling Lisp's abstract, expressive style of programming with a compiler that uses partial evaluation, data abstractions can be eliminated at compile time, producing extremely high-performance code. For an important class of numerical programs, partial evaluation achieves order-of-magnitude speed-ups over conventional Lisp compilation technology. This approach has proven to be especially effective when used in conjunction with schedulers for VLIW and highly pipelined architectures, because the elimination of data structures and procedural abstractions exposes the low-level parallelism inherent in a computation.		Andrew A. Berlin	1990		10.1145/91556.91612	parallel computing;data structure;computer science;fexpr;theoretical computer science;programming language;partial evaluation;preprocessor;expressive power	PL	-17.452231291294364	33.1976979392333	25112
41f978ac7891d6021242109e7f617ff433731eaa	the vega personal grid: a lightweight grid architecture	personal grid;vega;grid architecture;middleware;operating system;grid computing	Grid computing has emerged as a technology to solve the problem of sharing and cooperating of computational resources in wide area. In this paper, we propose a Grid architecture called Vega Personal Grid (the Vega PG). The key feature of the Vega PG is that it is a usercentered lightweight Grid architecture. We make a mapping between traditional computer systems and the Vega PG, which comprises Grid virtual hardware, Grid operating system and Grid User Environment. The Grid virtual hardware comprises various resources distributed in wide area. The Grid operating system (GOS) is a middleware based on the Grid virtual hardware and responsible for the management of the virtual hardware and the activities of the computations in a Grid. The Grid User Environment comprises several software tools enabling end users to utilize Grid resources conveniently. We also propose four important principles, which are Versatile Services, Enabling Intelligence, Global Uniformity and Autonomous Control, to evaluate the architecture design of the Vega PG.	access grid;circuit complexity;computation;computational resource;computer;geographical operations system;grid computing;map;middleware;open grid services architecture;operating system;user-centered design;virtual machine;web service	Wei Li;Zhiwei Xu;Bingchen Li;Yili Gong	2002			distributed computing;grid computing;grid;parallel computing;drmaa;architecture;vega;computer science;middleware	HPC	-31.63901214109383	51.34538669617439	25126
aa06d90f4da509c931d3f22ae4b292cc6afe0607	efficient key-value stores with ranged log-structured merge trees		The log-structured merge (LSM) tree is designed to provide efficient indexing for data that is frequently updated by using the log-structured approach. It defers merge operations for reordering data, propagating the index changes from a memory-resident component through one or more disk components. Thus, LSM-based storage engines can achieve good write performance. However, processing merge operations incurs high write amplification and memory consumption, ultimately having an adverse effect on system performance. In this paper, we propose the Ranged Log-Structured Merge (RLSM) tree to mitigate the problems of the LSM tree. To reduce the write amplification and memory overhead, RLSM simplifies the logical layout of storage and keeps data as an unsorted order. In addition, we prevent read performance from declining by partitioning data on the disk into multiple files with non-overlapping ranges. We implement our schemes on HBase, one of the most popular key-value storage engines, and evaluate our system by using YCSB benchmark. Our experimental results show that RLSM consequently reduces write amplification by a factor of 3, and memory consumption by up to 24%.	algorithm;amplifier;apache hbase;apache hadoop;attribute–value pair;benchmark (computing);binary space partitioning;data compaction;data structure;database engine;elegant degradation;merge sort;overhead (computing);random-access memory;throughput;tree (data structure);ycsb;zipf's law	Nae Young Song;Heon Young Yeom;Hyuck Han	2018	2018 IEEE 11th International Conference on Cloud Computing (CLOUD)	10.1109/CLOUD.2018.00090	throughput;real-time computing;memory management;merge (version control);computer science;search engine indexing;synchronization;data structure;write amplification;sorting	DB	-13.075153584601987	54.05755801848016	25143
8cc19cbbc013f96286083fdb6d19c1717570ccba	rescheduling co-allocation requests based on flexible advance reservations and processor remapping	schedules;estimation;resource management;resource allocation	Large-scale computing environments, such as TeraGrid, Distributed ASCI Supercomputer (DAS), and Gridpsila5000, have been using resource co-allocation to execute applications on multiple sites. Their schedulers work with requests that contain imprecise estimations provided by users. This lack of accuracy generates fragments inside the scheduling queues that can be filled by rescheduling both local and multi-site requests. Current resource co-allocation solutions rely on advance reservations to ensure that users can access all the resources at the same time. These coallocation requests cannot be rescheduled if they are based on rigid advance reservations. In this work, we investigate the impact of rescheduling co-allocation requests based on flexible advance reservations and processor remapping. The metascheduler can modify the start time of each job component and remap the number of processors they use in each site. The experimental results show that local jobs may not fill all the fragments in the scheduling queues and hence rescheduling co-allocation requests reduces response time of both local and multi-site jobs. Moreover, we have observed in some scenarios that processor remapping increases the chances of placing the tasks of multi-site jobs into a single cluster, thus eliminating the inter-cluster network overhead.	best, worst and average case;branch and bound;central processing unit;experiment;fork (software development);job stream;load (computing);mathematical optimization;meta-scheduling;overhead (computing);requirement;response time (technology);scheduling (computing);software deployment;supercomputer;teragrid	Marco Aurélio Stelmar Netto;Rajkumar Buyya	2008	2008 9th IEEE/ACM International Conference on Grid Computing		estimation;parallel computing;real-time computing;schedule;resource allocation;computer science;resource management;distributed computing;management	HPC	-16.456725378415342	60.23354110414632	25197
d3ced6531e27023f2994215853119aac2cad22be	simulating data processing for an advanced ion mobility mass spectrometer	field programmable gate arrays fpga;processing;mass spectrometer;general and miscellaneous mathematics computing and information science;dynamic partial reconfiguration;reconfigurable computing;mass spectrometry simulation;high performance computing;simulation;mass spectrometry;data processing;data capture;hybrid cpu fpga systems;ion mobility;signal processing;software component;algorithms;mass spectroscopy;process simulation;ion mobility spectrometry;pnnl;mass spectrometers;spectroscopy data intesive computing	We have designed and implemented a Cray XD 1-based simulation of data capture and signal processing for an advanced Ion Mobility mass spectrometer (Hadamard transform Ion Mobility). Our simulation is a hybrid application that uses both an FPGA component and a CPU-based software component to simulate Ion Mobility mass spectrometry data processing. The FPGA component includes data capture and accumulation, as well as a more sophisticated deconvolution algorithm based on a PNNL-developed enhancement to standard Hadamard transform Ion Mobility spectrometry. The software portion is in charge of streaming data to the FPGA and collecting results. We expect the computational and memory addressing logic of the FPGA component to be portable to an instrument-attached FPGA board that can be interfaced with a Hadamard transform Ion Mobility mass spectrometer.	algorithm;central processing unit;component-based software engineering;computation;deconvolution;field-programmable gate array;hadamard transform;memory address;nx bit;signal processing;simulation;streaming media;tree accumulation	Daniel G. Chavarría-Miranda;Brian Clowers;Gordon A. Anderson;Mikhail E. Belov	2007		10.1145/1328554.1328563	embedded system;electronic engineering;computer science;analytical chemistry	Embedded	-4.994154007152503	41.043478469779224	25202
46bfbf09f17df66bddd037dc950b3d748e21d180	modeling mpi communication performance on smp nodes: is it time to retire the ping pong test	parallel computing;benchmark;symmetric multiprocessor cluster;bandwidth saturation;multicore;performance model;ping pong;communication;multi core	"""The """"postal"""" model of communication [3, 8] T = α + βn, for sending n bytes of data between two processes with latency α and bandwidth 1/β, is perhaps the most commonly used communication performance model in parallel computing. This performance model is often used in developing and evaluating parallel algorithms in high-performance computing, and was an effective model when it was first proposed. Consequently, numerous tests of """"ping pong"""" communication have been developed in order to measure these parameters in the model. However, with the advent of multicore nodes connected to a single (or a few) network interfaces, the model has become a poor match to modern hardware. In this paper, we show a simple three-parameter model that better captures the behavior of current parallel computing systems, and demonstrate its accuracy on several systems. In support of this model, which we call the max-rate model, we have developed an open source benchmark1 that can be used to determine the model parameters."""	blue gene;blue waters;byte;multi-core processor;open-source software;oracle call interface;parallel algorithm;parallel computing;petascale computing;postal;supercomputer	William Gropp;Luke N. Olson;Philipp Samfass	2016		10.1145/2966884.2966919	parallel computing;real-time computing;computer science;distributed computing	HPC	-10.17838169377827	46.29543772361987	25237
c1083b8b378c0a6c8fc04d8fd6f97e552fd28329	generic support for remote memory access operations in score-p and otf2		Remote memory access (RMA) describes the ability of a process to access all or parts of the memory belonging to a remote process directly, without explicit participation of the remote side. There are a number of parallel programming models based on RMA operations that are relevant for High Performance Computing (HPC). On the one hand, Partitioned Global Address Space (PGAS) language extensions use RMA operations as underlying communication substrate, e.g. Co-Array Fortran and UPC. On the other hand, RMA programming APIs provide so called one-sided data transfer primitives as an alternative to the classic two-sided message passing. In this paper, we describe how Score-P, a scalable performance measurement infrastructure for parallel applications, is extended to support trace-based performance analyses of RMA parallelization models. Emphasis is given to the generic event model we designed to record RMA operations in the OTF2 trace format across a range of one-sided APIs and libraries.		Andreas Knüpfer;Robert Dietrich;Jens Doleschal;Markus Geimer;Marc-André Hermanns;Christian Rössel;Ronny Tschüter;Bert Wesarg;Felix Wolf	2012		10.1007/978-3-642-37349-7_5	uniform memory access;remote direct memory access;database	HPC	-12.648769885604091	41.535692167491604	25264
2a11452494ac24bb2ff5e0409c3c68372b10a1fd	protocols with exceptions, timeouts, and handlers: a uniform framework for monitoring fail-uncontrolled and ambient intelligence systems		This paper describes an approach for designing, formalizing and implementing sentinels that detect errors in fail-uncontrolled multiagent systems, and controllers that identify particular situations in ambient intelligence (AmI) systems. The formalism we use for representing the expected patterns of actions along with exceptions, timeouts, and their handlers, is that of constrained global types extended with features for dealing with these new constructs. We provide the syntax and semantics of the extended constrained global types and examples of their use, in the different contexts of fail-uncontrolled and AmI systems.	agent-based model;ambient intelligence;communications protocol;distributed computing;entity;exception handling;formal system;jade;jason;linear logic;linear temporal logic;multi-agent system;production (computer science);prolog;robot;run time (program lifecycle phase);runtime verification;semantics (computer science);simulation;timeout (computing);uncontrolled format string	Davide Ancona;Daniela Briola;Viviana Mascardi	2015			real-time computing;ambient intelligence;multi-agent system;engineering	AI	-30.815651485307512	33.61993133097974	25266
4b7c442086e51d0ea37dec355f3c26007e46198c	hand: highly available dynamic deployment infrastructure for globus toolkit 4	web services grid computing java;service level;dynamic grid computing;alternative data transfer protocol;web service;null;globus toolkit 4;dynamic environment;large scale;java web services;highly available dynamic deployment infrastructure;grid computing java web services availability large scale systems resource management problem solving performance analysis containers protocols;resource sharing;web services;alternative data transfer protocol highly available dynamic deployment infrastructure globus toolkit 4 dynamic grid computing java web services;grid computing;data transfer;problem solving;java	Grid computing is becoming more and more attractive for coordinating large-scale heterogeneous resource sharing and problem solving. Of particular interest for effective grid computing is a software provisioning mechanism. We propose a highly available dynamic deployment infrastructure, HAND, based on the Java Web services core of Globus toolkit 4. HAND provides capability, availability, and extensibility for dynamic deployment of Java Web services in dynamic grid environments. We identify the factors that have impact to dynamic deployment in static and dynamic environments. We also present the design, analysis, implementation, and evaluation of two different approaches to dynamic deployment (service level and container level), and examine the performance of alternative data transfer protocol for service implementations. Our results demonstrate that HAND can deliver significantly improved availability and performance relative to other approaches	apache tomcat;extensibility;grid computing;heterojunction;high availability;ibm notes;information system;letter-quality printer;non-maskable interrupt;problem solving;provisioning;requirement;software deployment;subroutine;user requirements document;web services metadata for java;web service	Li Qi;Hai Jin;Ian T. Foster;Jarek Gawor	2007	15th EUROMICRO International Conference on Parallel, Distributed and Network-Based Processing (PDP'07)	10.1109/PDP.2007.49	web service;computer science;operating system;database;world wide web	HPC	-31.35746429737505	51.90960191146759	25310
1c8a1f5ea40b3c3d99275a368b518c65166c3412	a hardware assisted high performance phk memory manager	garbage collection;memory allocation;programming language;memory management	Complex mechanisms for dynamic memory management and garbage collection are needed in modern imperative programming languages. Implementation of memory management functions efficiently both in terms of memory usage and execution performance becomes important for programs written in such languages. In this paper, we introduce a memory allocator that uses hardware assistance to improve the performance of a existing software allocator (PHK allocator). On average, our design reduces the execution time of memory management functions by 58.9%.	algorithm;allocator (c++);bitmap;buddy system;c dynamic memory allocation;critical path method;doug lea;field-programmable gate array;garbage collection (computer science);imperative programming;memory management;modern operating systems;operating system;paging;programming language;prototype;run time (program lifecycle phase);slab allocation	Wentong Li;Saraju P. Mohanty;Krishna M. Kavi	2006			computer hardware;memory management;conventional memory;flat memory model;memory map;real-time computing;interleaved memory;overlay;manual memory management;computer science;shared memory	PL	-7.268699915065857	48.787230739420224	25341
c2a47afcdfdbfd4d705f7a6e5761387093589023	us supercomputing receives multifaceted boost	shared memory;high power computing;supercomputer;hpc;funding;distributed shared memory systems;high performance computer;top end shared memory computers us supercomputing us based high performance computing public sector private sectors cluster interconnect technology;national electric code earth computational modeling computer simulation us government investments psychology supercomputers nasa computer architecture;openib project dsonline hpc high power computing funding supercomputer;parallel machines;open systems parallel machines workstation clusters distributed shared memory systems;private sector;workstation clusters;earth simulator;open systems;high performance;openib project;high power;dsonline	For several years, notably since Japan's NEC Earth Simulator earned the top spot on the list of the world's fastest computers, the US-based high-performance computing community has warned that the federal government's lagging interest and investment could cause serious long-term consequences for both the public and private sectors in the US. Apparently, those warnings haven't gone entirely unheeded. In November 2004, US-based supercomputing received both psychological and financial reinforcement. IBM's Blue Gene/L wrested the top spot on the global Top 500 supercomputer list (www.top500.org) from NEC with a performance rate of 70 teraflops per second. A second US-based computer, a cluster built by SGI and owned by NASA, took the second-place spot with 51 teraflops. In addition, federal officials demonstrated a willingness to invest across the range of high-performance architectures, from cluster interconnect technology to top-end shared-memory computers.	blue gene;computer;earth simulator;flops;fastest;mechatronics;shared memory;simulation;supercomputer;top500	Greg Goth	2005	IEEE Distributed Systems Online	10.1109/MDSO.2005.5	shared memory;supercomputer;parallel computing;computer hardware;computer science;operating system;distributed computing;open system;world wide web;computer security;private sector	HPC	-9.308554536451746	46.7594689894972	25349
3d739703e2e58a46b144647316a66ac3a24abed7	software architectures for flexible task-oriented program execution on multicore systems		The article addresses the challenges of software development for current and future parallel hardware architectures which will be dominated by multicore and manycore architectures in the near future. This will have the following effects: In several years desktop computers will provide many computing resources with more than 100 cores per processor. Using these multicore processors for cluster systems will create systems with thousands of cores and a deep memory hierarchy. A new generation of programming methodologies is needed for all software products to efficiently exploit the tremendous parallelism of these hardware platforms.	multi-core processor	Thomas Rauber;Gudula Rünger	2010		10.1007/978-3-642-15654-0_9	computer architecture;parallel computing;operating system	HPC	-7.5621118683563315	44.83125091325975	25353
628920d796919165564e0e0972d9f3dca2cfbfed	contents management in first-level multibanked data caches	content management;parallelisme;replication;banking;entrada salida;haute performance;distribution donnee;cache memory;gestion contenido;secteur bancaire;replicacion;design space;data distribution;antememoria;input output;antememoire;parallelism;data cache;paralelismo;gestion contenu;alto rendimiento;procesador oleoducto;processeur pipeline;high performance;distribucion dato;pipeline processor;entree sortie	High-performance processors will increasingly rely on multibanked first-level caches to meet frequency requirements. In this paper we introduce replication degree and data distribution as the main multibanking design axes. We sample this design space by selecting current data distribution policy proposals, measuring them on a detailed model of a deep pipelined processor and evaluating the trade-off introduced when the replication degree is taken into account. We find that the best design points use data address interleaving policies and several degrees of bank replication.	add-ons for firefox;cpu cache;cache-oblivious algorithm;central processing unit;content management system;dataflow;effective method;forward error correction;instruction pipelining;kilobyte;requirement	Enrique F. Torres;Pablo Ibáñez;Víctor Viñals;José María Llabería	2004		10.1007/978-3-540-27866-5_68	input/output;replication;parallel computing;real-time computing;cpu cache;content management;computer science;operating system;database	Arch	-17.098643390662268	45.73090826024074	25369
b5d8306cb9f648b5567b934124010849ba752816	reducing dram latency via charge-level-aware look-ahead partial restoration		Long DRAM access latency is a major bottleneck for system performance. In order to access data in DRAM, a memory controller (1) activates (i.e., opens) a row of DRAM cells in a cell array, (2) restores the charge in the activated cells back to their full level, (3) performs read and write operations to the activated row, and (4) precharges the cell array to prepare for the next activation. The restoration operation is responsible for a large portion (up to 43.6%) of the total DRAM access latency. We find two frequent cases where the restoration operations performed by DRAM do not need to fully restore the charge level of the activated DRAM cells, which we can exploit to reduce the restoration latency. First, DRAM rows are periodically refreshed (i.e., brought back to full charge) to avoid data loss due to charge leakage from the cell. The charge level of a DRAM row that will be refreshed soon needs to be only partially restored, providing just enough charge so that the refresh can correctly detect the cells' data values. Second, the charge level of a DRAM row that will be activated again soon can be only partially restored, providing just enough charge for the activation to correctly detect the data value. However, partial restoration needs to be done carefully: for a row that will be activated again soon, restoring to only the minimum possible charge level can undermine the benefits of complementary mechanisms that reduce the activation time of highly-charged rows. To enable effective latency reduction for both activation and restoration, we propose charge-level-aware look-ahead partial restoration (CAL). CAL consists of two key components. First, CAL accurately predicts the next access time, which is the time between the current restoration operation and the next activation of the same row. Second, CAL uses the predicted next access time and the next refresh time to reduce the restoration time, ensuring that the amount of partial charge restoration is enough to maintain the benefits of reducing the activation time of a highly-charged row. We implement CAL fully in the memory controller, without any changes to the DRAM module. Across a wide variety of applications, we find that CAL improves the average performance of an 8-core system by 14.7%, and reduces average DRAM energy consumption by 11.3%.		Yaohua Wang;Arash Tavakkol;Lois Orosa;Saugata Ghose;Nika Mansouri Ghiasi;Minesh Patel;Jeremie S. Kim;Hasan Hassan;Mohammad Sadrosadati;Onur Mutlu	2018	2018 51st Annual IEEE/ACM International Symposium on Microarchitecture (MICRO)	10.1109/MICRO.2018.00032	memory controller;access time;real-time computing;parallel computing;latency (engineering);computer science;row;data loss;dram;partial charge;bottleneck	Arch	-8.950431682910617	54.30660735117227	25406
2ec490f40efb00fa0a3b3a63306069d64630c340	fast and robust parallel sgd matrix factorization	matrix factorization;stochastic gradient descent	Matrix factorization is one of the fundamental techniques for analyzing latent relationship between two entities. Especially, it is used for recommendation for its high accuracy. Efficient parallel SGD matrix factorization algorithms have been developed for large matrices to speed up the convergence of factorization. However, most of them are designed for a shared-memory environment thus fail to factorize a large matrix that is too big to fit in memory, and their performances are also unreliable when the matrix is skewed.  This paper proposes a fast and robust parallel SGD matrix factorization algorithm, called MLGF-MF, which is robust to skewed matrices and runs efficiently on block-storage devices (e.g., SSD disks) as well as shared-memory. MLGF-MF uses Multi-Level Grid File (MLGF) for partitioning the matrix and minimizes the cost for scheduling parallel SGD updates on the partitioned regions by exploiting partial match queries processing}. Thereby, MLGF-MF produces reliable results efficiently even on skewed matrices. MLGF-MF is designed with asynchronous I/O permeated in the algorithm such that CPU keeps executing without waiting for I/O to complete. Thereby, MLGF-MF overlaps the CPU and I/O processing, which eventually offsets the I/O cost and maximizes the CPU utility. Recent flash SSD disks support high performance parallel I/O, thus are appropriate for executing the asynchronous I/O.  From our extensive evaluations, MLGF-MF significantly outperforms (or converges faster than) the state-of-the-art algorithms in both shared-memory and block-storage environments. In addition, the outputs of MLGF-MF is significantly more robust to skewed matrices. Our implementation of MLGF-MF is available at http://dm.postech.ac.kr/MLGF-MF as executable files.	algorithm;asynchronous i/o;block (data storage);central processing unit;computer data storage;entity;grid file;input/output;metafont;performance;robustness (computer science);scheduling (computing);shared memory;solid-state drive;the matrix	Jinoh Oh;Wook-Shin Han;Hwanjo Yu;Xiaoqian Jiang	2015		10.1145/2783258.2783322	parallel computing;computer science;theoretical computer science;machine learning;stochastic gradient descent;distributed computing;matrix decomposition	ML	-17.331059820362167	54.27694425826261	25408
02c7d219285f268047757412971d2cf58e77843a	a system-level optimization framework for high-performance networking	kernel benchmark testing throughput sockets optimization sensors tuning;optimisation local area networks memory architecture network interfaces;cpu power saving state management system level optimization high performance networking commodity high speed networking product 40 gigabit ethernet high speed data transfer streaming application kernel module setting network interface driver level setting kernel buffer size cpu core scheduling nonuniform memory access numa scheduling interrupt handling	Processing data in a streaming fashion is involved in many applications, including radar, electro-optical and infrared imaging, and other scenarios in which real-time data is acquired from sensors. While the difficulty of processing such data in real-time or in an otherwise timely fashion is the topic of much research, transferring the data between machines or devices is also a key challenge. This work investigates the utilization of commodity high-speed networking products - in particular, 40 gigabit Ethernet - for supporting high-speed data transfer in streaming applications. For such systems, optimizing the system configuration to support data transfers approaching line rate is critical. This work demonstrates the use of an optimization framework to explore the impact of various system-level optimization settings, including kernel module settings, network interface driver-level settings, kernel buffer sizes, thread and CPU core scheduling, non-uniform memory access (NUMA) scheduling, interrupt handling, and CPU power-saving state management.	central processing unit;gigabit;loadable kernel module;mathematical optimization;network interface controller;non-uniform memory access;radar;real-time clock;real-time data;real-time locating system;scheduling (computing);sensor;state management;streaming media;system configuration;uniform memory access	Thomas M. Benson	2014	2014 IEEE High Performance Extreme Computing Conference (HPEC)	10.1109/HPEC.2014.7040983	fair-share scheduling;embedded system;parallel computing;real-time computing;computer science	HPC	-5.828337320510943	48.003082864776175	25427
f5c576c6804f5b4b559b377d716e00eed49ddd2a	grouping memory consistency model for parallel-multithreaded shared-memory multiprocessor systems	grouping consistency model;performance evaluation;multiprocessor;consistency model;synchronization;multithread;group memory;article;memory consistency model;shared memory multiprocessor	In this paper, we propose a hardware-centric memory consistency model particularly for shared-memory multiprocessors with parallel-multithreaded processing elements. According to the behavior of critical sections and the feature of parallel-multithreaded processors, we extend the release consistency model to a more relaxed memory model. A release reference at the end of a critical section can be executed locally regardless of whether all of its previous ordinary references have performed. The requirement is that another thread on the same processor is waiting for the lock to be freed. Two new instructions and two additional macros are needed to properly label a program for our proposed model. Moreover, we use a table per processing element to determine if there are any threads waiting for a specific lock. We have used five benchmark programs in the SPLASH suite to evaluate the performance gain for the new model. According to the simulation results, our proposed model is superior to the release consistency model up to 25%.	consistency model;multiprocessing;shared memory;thread (computing)	Chao-Chin Wu;Cheng Chen	1999	International Journal of High Speed Computing	10.1142/S0129053399000041	memory model;synchronization;cache coherence;parallel computing;real-time computing;multiprocessing;distributed memory;computer science;consistency model;operating system;release consistency;pram consistency;memory coherence;sequential consistency	Arch	-14.251655602507167	46.746096975722516	25430
83684cc2fddbe64f8902d1ee5d5112bf95eaeffe	practical uses of synchronized clocks in distributed systems	distributed algorithms;distributed system;synchronized clocks;distributed computing;clock distribution;distributed algorithm	Synchronized clocks are interesting because they can be used to improve performance of a distributed system by reducing communications. Since they have only recently become a reality in distributed systems, their use in distributed algorithms has received relatively little attention. This paper discusses a number of distributed algorithms that make use of synchronized clocks and analyzes how clocks are used in these algorithms	distributed algorithm;distributed computing;synchronization (computer science)	Barbara Liskov	1993	Distributed Computing	10.1007/BF02242709	clock synchronization;distributed algorithm;real-time computing;computer science;theoretical computer science;distributed computing;master clock;matrix clock;distributed concurrency control	HPC	-23.336216450011683	43.15688310322363	25451
906b4b74e226752f4bb21936199ae24806889b0c	bar - where distributed computing meets game theory	game theory;distributed computing;control structure	This tutorial describes a general approach for building cooperative services that span multiple administrative domains (MADs). MAD systems are attractive because their diffused control structure may yield services that are potentially less costly and more democratic than their more centralized counterparts. Unfortunately, they are also particularly problematic from a dependability standpoint as they challenge the traditional distinction between correct and faulty nodes.	distributed computing;game theory	Lorenzo Alvisi	2007		10.1007/978-3-540-75294-3_19	embedded system;game theory;simulation;computer science;engineering;theoretical computer science;software engineering;database;distributed computing;programming language;control flow;computer security	Theory	-23.960260441271952	44.05776809660818	25468
31dd5e73ccde154162d44d1f64ad3ba43f275903	corona: a high performance publish-subscribe system for the world wide web	instant messaging;web pages;perforation;publish subscribe system;distributed optimization;large scale;coronae;publish subscribe;world wide web;technical report;computer science;high performance	Despite the abundance of frequently changing information, the Web lacks a publish-subscribe interface for delivering updates to clients. The use of naive polling for update detection leads to poor performance and limits scalability, as clients do not detect updates quickly and servers face high loads imposed by active polling. This paper describes Corona, a publish-subscribe system for the Web that provides high performance and scalability through optimal resource allocation. Users register interest in web pages through existing instant messaging services. Corona monitors the subscribed web pages, detects updates efficiently by allocating polling load among cooperating peers and disseminates them quickly to the clients. A distributed optimization engine ensures that Corona achieves the best update performance without exceeding load limits on content servers. Large scale simulations and measurements from Planet-Lab deployment, described in this paper, demonstrate that Corona achieves orders of magnitude improvement in update performance at a modest cost.	backward compatibility;bandwidth (signal processing);computer;distributed computing;ibm notes;instant messaging;mathematical optimization;overhead (computing);planetlab;polling (computer science);prototype;publish–subscribe pattern;real life;scalability;sensor;simulation;software deployment;sticky bit;web 2.0;web content;web index;web page;world wide web	Venugopalan Ramasubramanian;Ryan R. Peterson;Emin Gün Sirer	2006			real-time computing;computer science;technical report;operating system;web page;database;distributed computing;publish–subscribe pattern;world wide web;computer security;computer network	Networks	-24.148704695465838	54.85501969886544	25470
e4da0fff3b823dac1a1a988fe2464340669c4d25	page replacement in distributed virtual memory systems	distributed algorithms;microprocessors;virtual memory;local memory access trace driven simulation distributed virtual memory systems page replacement page out policies least recently brought global recently used rr round robin lan least active neighbor lln least loaded neighbor internode faults;distributed processing;resource management;space exploration;lln;lan;least active neighbor;distributed virtual memory systems;memory access;round robin;rr;fault tolerant systems;page replacement;page out policies;communications technology;global recently used;least loaded neighbor;virtual storage distributed processing;least recently brought;local memory access;trace driven simulation;least recently used;internode faults;virtual storage;local area networks;space exploration microprocessors communications technology resource management distributed algorithms fault tolerant systems round robin local area networks costs;replacement policy	The authors introduce three page replacement, and page out policies, in distributed virtual memory systems. Two of the replacement policies, the least recently brought and the global recently used or brought, are adapted versions of the least recently used policy, which is well known in conventional virtual memory systems. Trace driven simulation was used to evaluate the performance of the replacement policies and the RR (round robin), LAN (least active neighbor), and LLN (least loaded neighbor) page out policies. The results suggest that when the cost of internode faults is considerably higher than local memory access, global and remote policies are superior to the local one. When the cost of bringing a page from the immediate neighbor is considerably low compared to the cost of accessing the local memory, the local policy performs as well as the global and the remote. Among the page out policies, round robin is the least efficient. LLN generates lower cost than LAN when the size of the local memory is relatively large. Under high memory contention, LAN shows better performance. >	page replacement algorithm	Mohammed Malkawi;Deborah Knox;Mahmoud Abaza	1992		10.1109/SPDP.1992.242719	local area network;demand paging;parallel computing;real-time computing;page fault;page replacement algorithm;computer science;resource management;operating system;distributed computing;algorithm;computer network	HPC	-20.728423098417508	50.22580780116146	25473
3a220c285cf22313921ccbca36a1e87824c547b1	evaluating and improving performance of multimedia applications on simultaneous multi-threading	cache storage;similarity metric;multi threading;simultaneous multi threaded;processor scheduling;multimedia application;mutual prefetching multimedia applications simultaneous multithreading architecture memory bounded kernels computational bounded functions performance metric symmetric multiprocessor systems cache sharing cache locality cache conflicts cache size cache miss penalty thread scheduling;performance metric;multi threading cache storage multimedia computing processor scheduling;multimedia computing;surface mount technology decoding computer architecture pipelines microprocessors yarn delay multithreading kernel prefetching;simultaneous multithreading	This paper presents the study and results of running several core multimedia applications on a simultaneous multithreading (SMT) architecture, including some detailed analysis ranging from memory-bounded kernels to computational-bounded functions. A performance metric to evaluate effective SMT performance gain is introduced, and compared to similar metrics on symmetric multiprocessor (SMP) systems. In addition, we analyze and compare SMT versus SMP systems, and highlight the advantages in the studied applications. The results indicate that sharing the cache in SMT processors can provide better cache locality and thus better performance although sharing the cache can introduce cache conflicts and reduce the actual cache size available for each logical processor. We also propose “mutual prefetching” -a technique to schedule threads so that they prefetch data for each other in order to reduce cache miss penalty.	cpu cache;central processing unit;locality of reference;multithreading (computer architecture);simultaneous multithreading;symmetric multiprocessing	Yen-Kuang Chen;Eric Debes;Rainer Lienhart;Matthew J. Holliman;Minerva M. Yeung	2002		10.1109/ICPADS.2002.1183452	bus sniffing;pipeline burst cache;cache-oblivious algorithm;snoopy cache;parallel computing;real-time computing;cache coloring;page cache;multithreading;cpu cache;cache;computer science;write-once;cache invalidation;operating system;smart cache;mesi protocol;cache algorithms;cache pollution;simultaneous multithreading;mesif protocol	HPC	-9.477589789809242	50.46804744295309	25506
7b429c79c23e5808eb64bb1b16f1c41c5077b7e3	dynamic load balancing in parallel finite element simulations	simulation ordinateur;finite element simulation;dynamic load balancing;methode element fini;metodo elemento finito;programacion paralela;equilibrio de carga;equilibrage charge;parallel programming;finite element method;universiteitsbibliotheek;performance programme;load balancing;parallel computer;eficacia programa;simulacion computadora;program performance;computer simulation;parallel simulation;programmation parallele	In this paper we introduce a new method for parallelizing Finite Element simulations enabling the use of dynamic load balancing. A physical space partitioning is obtained by dividing the bounding cube into a large number of sub cubes. The cube mesh together with a workload attribute assigned to each cube is used to present an abstract view of the simulation. Based on this abstract view a dynamic load balancing process decides on a possible local repartitioning of the mesh. The dynamic load balancing process itself is diffusion based, that is cubes are migrated between neighboring partitions. A parallel simulation framework (P-CAM) is used to implement the dynamic load balancer.	computer simulation	Arjen Schoneveld;Martin Lees;Erwan Karyadi;Peter M. A. Sloot	1999		10.1007/BFb0100602	computer simulation;parallel computing;real-time computing;computer science;load balancing;finite element method;distributed computing	HPC	-6.464854472455465	40.17078828111745	25586
186f94a7280dbeb93064104a20fcff8420707f59	a distributed integrated fare collection and accounting system for metropolitan railway transit	databases;software;distributed system;railway engineering;replication;metropolitan railway transit;rail transportation;transportation accounts data processing distributed processing internet radiofrequency identification railway engineering smart cards;servers software satellite broadcasting databases frequency control faa rail transportation;train station application programs metropolitan railway transit smart devices ic card rfid token passenger transportation mrt development travel needs legacy systems web based distributed integrated fare collection and accounting system taipei rapid transit corporation program modules source code ifca system management ifca system engineering ifca system architecture ifca system maintenance train station databases;frequency control;distributed processing;fare collection;satellite broadcasting;accounting system;servers;internet;smart cards;transportation accounting system distributed system fare collection metropolitan railway transit replication system integration;system integration;transportation;accounts data processing;faa;radiofrequency identification	In the real world applications, the most widely used simple-and-small smart device is most likely the ticket of the metropolitan railway transit (MRT). Behind this simple-and-small device, IC-card or RFID token, very large and complicated system is required to facilitate such a smart device. MRT is typically of a distributed environment. MRT's primary purpose is transporting massive passengers, and thus, employs huge volume of distributed fare collections. Development (i.e., scale) of a MRT takes decades to mature, and due to different passes (tickets) may be offered for various travel needs, legacy systems may coexist for certain periods of time, and multiple fare collection methods may be utilized, such that integration of versatile vendors and applications becomes necessary. This paper presents a successful implementation of a web-based distributed integrated fare collection and accounting (IFCA) system in Taipei Rapid Transit Corporation. Such an IFCA system contains more than 1,200 program modules with million lines of source code. The architectural and engineering, as well as management and maintenance, issues will be addressed. The IFCA system replicates application programs and databases for each train station. It is proven robust, scalable, and lower cost. It may be served as a reference model for the existing and currently under building MRTs.	coexist (image);database;legacy system;reference model;robustness (computer science);scalability;smart card;smart device;web application	Pintsang Chang	2012	2012 9th International Conference on Ubiquitous Intelligence and Computing and 9th International Conference on Autonomic and Trusted Computing	10.1109/UIC-ATC.2012.147	embedded system;smart card;transport;replication;the internet;telecommunications;computer science;electrical engineering;operating system;railway engineering;automatic frequency control;accounting information system;computer security;server;computer network;system integration	EDA	-33.43105396640728	40.948483720568376	25601
2366a2c3c629bb20fdcb8f2b56136f3642a4edd6	grace: safe multithreaded programming for c/c++	estensibilidad;parallelisme;atomicidad;virtual memory;gestion memoire;fiabilidad;reliability;haute performance;race condition;langage c;virtualisacion proceso;storage management;performance;semantics;simultaneidad informatica;concurrent program;program verification;semantica;semantique;approche deterministe;deterministic approach;gestion memoria;verificacion programa;c language;parallelism;concurrency;col;paralelismo;process virtualization;atomicity;atomicite;reliability concurrency;fork join;fiabilite;programa competidor;enfoque determinista;memoire virtuelle;alto rendimiento;deadlock;multithread;interbloqueo;virtualisation processus;runtime system;extensibilite;scalability;multitâche;interblocage;sequential semantics;determinism;verification programme;simultaneite informatique;high performance;multitarea;memoria virtual;lenguaje c;programme concurrent;deterministic concurrency	The shift from single to multiple core architectures means that programmers must write concurrent, multithreaded programs in order to increase application performance. Unfortunately, multithreaded applications are susceptible to numerous errors, including deadlocks, race conditions, atomicity violations, and order violations. These errors are notoriously difficult for programmers to debug.  This paper presents Grace, a software-only runtime system that eliminates concurrency errors for a class of multithreaded programs: those based on fork-join parallelism. By turning threads into processes, leveraging virtual memory protection, and imposing a sequential commit protocol, Grace provides programmers with the appearance of deterministic, sequential execution, while taking advantage of available processing cores to run code concurrently and efficiently. Experimental results demonstrate Grace's effectiveness: with modest code changes across a suite of computationally-intensive benchmarks (1-16 lines), Grace can achieve high scalability and performance while preventing concurrency errors.	atomicity (database systems);benchmark (computing);c++;concurrency (computer science);deadlock;grace murray hopper award;memory protection;multithreading (computer architecture);parallel computing;programmer;race condition;runtime system;scalability;thread (computing);two-phase commit protocol	Emery D. Berger;Ting Yang;Tongping Liu;Gene Novark	2009		10.1145/1640089.1640096	parallel computing;real-time computing;scalability;concurrency;performance;computer science;virtual memory;deadlock;reliability;semantics;race condition;fork–join queue;programming language;deterministic system;atomicity;determinism	PL	-19.389931113298402	40.75912226541894	25617
18170bca0dd8c5fedaeff22292cccb0f853f176b	a multiport page-memory architecture and a multiport disk-cache system	shared memory;data processing;cache memory;memory architecture;parallel architecture;switching network	Everlasting demands for solutions to ever growing computation problems and demands for efficient means to manage and utilize sophisticated information have caused an increase in the amount of data necessary to handle a job, while drastic reduction in CPU prices is encouraging massive parallel architectures for gigantic data processing. These trends are increasing the importance of a large shared buffer memory with 103∼104 simultaneously accessible ports. This paper proposes a multiport page buffer architecture that allows 103∼104 concurrent accesses and causes no access conflict nor suspension. It consists of a set of memory banks and multistaged switching networks with controllers that control each row of the networks. Consecutive words in each page are stored orthogonally across banks. Memory interleaving may be applied to improve access rate in consecutive retrievals. When used as a disk cache memory, it decreases the number of disk accesses and increases both the page transfer rate and the maximum number of concurrent page accesses.	cpu cache;central processing unit;computation;disk buffer;forward error correction;interleaved memory;memory bank	Yuzuru Tanaka	1984	New Generation Computing	10.1007/BF03037059	uniform memory access;distributed shared memory;shared memory;demand paging;interleaved memory;semiconductor memory;parallel computing;real-time computing;page fault;page cache;memory management unit;cpu cache;data processing;computer hardware;computer science;computer memory;registered memory;cache-only memory architecture;memory map;non-uniform memory access	Arch	-9.686815082285447	52.82651756112749	25684
b2479d3ec727a7a4d3c0acad18c96d5063f7a470	a holistic approach to log data analysis in high-performance computing systems: the case of ibm blue gene/q	data science;predictive modeling;log data integration;correlation analysis;hpc system monitoring	The complexity and cost of managing high-performance computing infrastructures are on the rise. Automating management and repair through predictive models to minimize human interventions is an attempt to increase system availability and contain these costs. Building predictive models that are accurate enough to be useful in automatic management cannot be based on restricted log data from subsystems but requires a holistic approach to data analysis from disparate sources. Here we provide a detailed multi-scale characterization study based on four datasets reporting power consumption, temperature, workload, and hardware/software events for an IBM Blue Gene/Q installation. We show that the system runs a rich parallel workload, with low correlation among its components in terms of temperature and power, but higher correlation in terms of events. As expected, power and temperature correlate strongly, while events display negative correlations with load and power. Power and workload show moderate correlations, and only at the scale of components. The aim of the study is a systematic, integrated characterization of the computing infrastructure and discovery of correlation sources and levels to serve as basis for future predictive modeling efforts.	blue gene;holism;predictive modelling;supercomputer	Alina Sîrbu;Özalp Babaoglu	2015		10.1007/978-3-319-27308-2_51	predictive analytics;real-time computing;computer science;data science;operating system;data mining;database;distributed computing	HPC	-22.94484171349337	57.904682330687876	25694
3e856b550fbd1a53be709bb19140003f6ecf04e6	a popularity-aware cost-effective replication scheme for high data durability in cloud storage	google;servers;big data;bandwidth;time frequency analysis;delays;cloud computing	Cloud storage system usually experiences data loss, hindering data durability. Three-way random replication is commonly used to prevent data loss in cloud storage systems. However, it cannot effectively handle correlated machine failures. Although Copyset Replication and Tiered Replication can reduce data loss in correlated and independent failures and enhance data durability, they fail to leverage different data popularities to substantially reduce the storage cost and bandwidth cost caused by replication. To address these issues, we present a popularity-aware multi-failure resilient and cost-effective replication (PM-CR) scheme for high data durability in cloud storage. PMCR splits the cloud storage system into primary tier and backup tier, and classifies data into hot data, warm data and cold data based on data popularities. To handle both correlated and independent failures, PMCR stores the three replicas of the same data into one Copyset formed by two servers in the primary tier and one server in the backup tier. For the third replicas of warm data and cold data in the backup tier, PMCR uses the Similar Compression method for read-intensive data and uses the Delta Compression method for write-intensive data to reduce storage cost and bandwidth cost. As a result, these costs are reduced and data durability and availability are enhanced without compromising data request delay greatly. Extensive experiment results based on trace parameters show that PMCR achieves high data durability, low probability of data loss, and low storage cost and bandwidth cost compared to previous replication schemes.	backup;cloud storage;computer data storage;delta encoding;durability (database systems);fleet telematics system;ibm notes;microsoft research;multitier architecture;replication (computing);server (computing)	Jinwei Liu;Haiying Shen	2016	2016 IEEE International Conference on Big Data (Big Data)	10.1109/BigData.2016.7840627	real-time computing;computer science;database;world wide web	OS	-13.868606030416561	55.0883659601123	25724
2188257f5e63e9c886c943636e767e74c30da617	mashing up oil and water: combining heterogeneous services for diverse users	mashup interfaces heterogeneous services diverse users middleware user interface level mashup development environment service interface;interfase usuario;mashups;spreadsheet;end user development;user interface;heterogeneous services;lenguaje script;logicial personalizado;distributed computing;spreadsheets;service mashups mashups middleware end user development spreadsheets scripting;service mashups;diversity reception;service utilisateur;intergiciel;petroleum;development environment;mashup interfaces;internet;user interface level;user interfaces middleware;service interface;joining processes;calculo repartido;middleware;interface utilisateur;servicio usuario;mashups petroleum diversity reception middleware joining processes;mashup development environment;user service;diverse users;tableur;user interfaces;calcul reparti;scripting;scripting language;langage script	Connecting heterogeneous services is a complex endeavor that requires support at both the middleware and user-interface levels. Offering users a varied palette of mashup development environments and service interfaces lets users choose elements appropriate to their skill levels and their tasks. The authors discuss their experiences using various development paradigms, such as spreadsheets and high-level scripting, to mash up diverse services. They describe their middleware and service adapters, which abstract the difference between service interfaces, and compare several mashup interfaces aimed at different user groups.	high- and low-level;mash-1;mashup (web application hybrid);middleware;palette (computing);spreadsheet;user interface	Zeljko Obrenovic;Dragan Gasevic	2009	IEEE Internet Computing	10.1109/MIC.2009.97	human–computer interaction;computer science;operating system;database;scripting language;user interface;world wide web	HCI	-28.657896699587255	43.05948783835379	25748
4201103e3a88d1ad58ff3e0e58c7fb4d81f78f61	edge-tm: exploiting transactional memory for error tolerance and energy efficiency		Scaling of semiconductor devices has enabled higher levels of integration and performance improvements at the price of making devices more susceptible to the effects of static and dynamic variability. Adding safety margins (guardbands) on the operating frequency or supply voltage prevents timing errors, but has a negative impact on performance and energy consumption. We propose Edge-TM, an adaptive hardware/software error management policy that (i) optimistically scales the voltage beyond the edge of safe operation for better energy savings and (ii) works in combination with a Hardware Transactional Memory (HTM)-based error recovery mechanism. The policy applies dynamic voltage scaling (DVS) (while keeping frequency fixed) based on the feedback provided by HTM, which makes it simple and generally applicable. Experiments on an embedded platform show our technique capable of 57% energy improvement compared to using voltage guardbands and an extra 21-24% improvement over existing state-of-the-art error tolerance solutions, at a nominal area and time overhead.	clock rate;colour banding;dynamic voltage scaling;edge enhancement;embedded system;error-tolerant design;experiment;html;heart rate variability;image scaling;overhead (computing);playtoons;semiconductor device;shattered world;software bug;transactional memory;type safety	Dimitra Papagiannopoulou;Andrea Marongiu;Tali Moreshet;Maurice Herlihy;R. Iris Bahar	2017	ACM Trans. Embedded Comput. Syst.	10.1145/3126556	real-time computing;error management;parallel computing;voltage;scaling;software;computer science;energy consumption;efficient energy use;dynamic voltage scaling;transactional memory	Arch	-4.631780260597232	55.984796650709654	25762
8c270d482b77c7757f7d3c096e1a5599ac293411	data sharing in scientific simulations	c language;java;digital simulation;object-oriented programming;physics computing;software libraries;c++;java;python;component communication;computer science functions;data sharing;infrastructure;mathematical functions;physics processes;programming languages;scientific simulations;scientific software;simulation development;third-party libraries	"""Several physics processes modify the state of a scientific simulation over time. In fact, researchers often divide a simulation's development into areas - called packages - according to physics specialization. In this article, we use the word """"package"""" primarily to mean a portion of scientific software whose components communicate internally much more than they do with outside routines, but packages can take the form of third-party libraries for common mathematical or computer science functions. Most parts of a simulation refer to the """"infrastructure"""" portion of the state, so we can think of this portion as a package with lots of customers. How we share data within and between these packages is crucial to developer productivity. In this installment of Scientific Programming, we explore some of the pros and cons of the different ways to share data in C++ code."""	c++;computer science;library (computing);partial template specialization;simulation	Glenn P. Downing;Paul F. Dubois;Teresa L. Cottom	2004	Computing in Science & Engineering	10.1109/MCISE.2004.1289316	computational science;parallel computing;simulation;python;computer science;theoretical computer science;operating system;data mining;programming language;java	HPC	-12.412731318657967	38.02501534541877	25792
ee7dcb84b677a27d674693ecd7ae3ca389fded0b	performance evaluation of storage formats for sparse matrices in fortran	calcul matriciel;evaluation performance;haute performance;performance evaluation;evaluacion prestacion;distributed computing;sparse blas;sparse set;langage java;matrice creuse;jsa java sparse array;storage format;alto rendimiento;calculo repartido;lenguaje java;ensemble epars;fortran;matrix calculus;sparse matrix;high performance;calcul reparti;sparse matrices;calculo de matrices;matriz dispersa;java language	Many storage formats have been proposed to represent spa- rse matrices. This paper extends to Fortran 95 the performance evaluation of sparse storage formats in Java presented at ICCS 2005, [7]. These experiments have the same set up (almost 200 sparse matrices and matrix-vector multiplication), but now consider the Fortran 95 Sparse BLAS reference implementation.	fortran;performance evaluation;sparse matrix	Anila Usman;Mikel Luján;Len Freeman;John R. Gurd	2006		10.1007/11847366_17	parallel computing;sparse matrix;computer science;theoretical computer science;algorithm	HPC	-10.581707823254083	36.456823786290975	25853
3cf4b50b63832e75e4d12beba76eb3ae7a2c552a	hiérarchie mémoire dans les systèmes intégrés multiprocesseurs construits autour de réseaux sur puce. (memory hierarchy in embedded multiprocessor system built around networks on chip)			embedded system;memory hierarchy;multiprocessing	Hela Belhadj Amor	2017				EDA	-9.549853301082836	43.30516027875795	25863
0d4d4d4bc58661cdd0fcc2da82dcff23869dba94	optimal design of megabyte second-level caches for minimizing bus traffic in shared-memory shared-bus multiprocessors	shared memory;optimal design	As the design of shared-memory sharedbus multiprocessors is heading toward employing megabyte second-level caches, how to optimize the design of the second-level caches in order to minimize the traffic on the shared memory bus and thus improve system scalability is of great interest. This paper presents a comprehensive study on this issue through extensive trace-driven simulation. The simulation results show that a good cache design could mean a reduction of bus traffic by more than 80 percent or, equivalently, an increase of system scalability by more than five times. Furthermore, they show that a few simple design guidelines can be derived because the optimal choice of cache configuration metrics exhibits a high degree of invariance over system-conf,guration variations. This research was sponsored by the National Science Council of R.O.C. under grant NSC 79-0408-E-002-10. @ 1994 The USENIX Association, computing systems, vol. 7 . No. 3 . summer 1994 393	course (navigation);megabyte;memory bus;national supercomputer centre in sweden;optimal design;scalability;shared memory;simulation	Yen-Jen Oyang;Le-Chun Wu	1994	Computing Systems		bus sniffing;shared memory;computer architecture;parallel computing;real-time computing;computer science;optimal design;operating system	Arch	-9.733042313698803	48.68888263039258	25884
abff2f60ea2e7c48d56a8b8a08f8ef642c155e5d	on the use of the mmc language to utilize simd instruction set	programming language;multimedia application;support vector;performance improvement	This paper presents the use of the Multimedia C (MMC) language to develop multimedia applications. The MMC language was designed to support operations with multimedia extensions included in all modern microprocessors. Although the idea to extend high programming languages to support vector operations is not novel, we show that integration of multimedia extensions into C is valuable. This is specially true for idiomatic expressions which are difficult for a compiler to identify. The MMC language has been used to develop some of the most frequently used multimedia kernels. The presented experiments on these scientific and multimedia applications have yielded good performance improvements. Although this paper discuses the use of MMC, the key features of the MMC language and implementation of its compiler are also presented.	ansi c;application domain;c syntax;compiler;experiment;high- and low-level;high-level programming language;memory management controller;microprocessor;parallel computing;programmer;programming language;rewriting;simd;windows 3.0	Patricio Bulic;Veselko Gustin	2006		10.1007/978-3-540-71351-7_19	support vector machine;parallel computing;real-time computing;computer science;theoretical computer science;operating system;distributed computing;programming language	PL	-5.460872705854168	43.68857514444625	25928
87638512cd68079de726afd687bb2e72885a6089	case study: a portable parallel particle-in-cell code simulation	particle in cell		particle-in-cell;simulation	Sin Ming Loo;B. Earl Wells;Nagendra Singh;Edith P. Huang	1999			computer science;particle-in-cell;computer architecture;parallel computing	HPC	-6.69756266529924	38.23679133431767	25941
b85740931c232504674c84740b8f3ba8b9e6c4b3	towards the automated detection of unknown malware on live systems	t2 technology general műszaki tudomanyok altalaban;monitoring malware data structures program processors hardware virtualization virtual machine monitors;virtualisation computer network security invasive software;system call tracing method unknown malware live systems system monitoring framework automated malware detection hardware assisted virtualization capability cpu hypervisor layer	In this paper, we propose a new system monitoring framework that can serve as an enabler for automated malware detection on live systems. Our approach takes advantage of the increased availability of hardware assisted virtualization capabilities of modern CPUs, and its basic novelty consists in launching a hypervisor layer on the live system without stopping and restarting it. This hypervisor runs at a higher privilege level than the OS itself, thus, it can be used to observe the behavior of the analyzed system in a transparent manner. For this purpose, we also propose a novel system call tracing method that is designed to be configurable in terms of transparency and granularity.	64-bit computing;application programming interface;central processing unit;code injection;data structure;downtime;electromagnetically induced transparency;hardware-assisted virtualization;hypervisor;kernel (operating system);malware;microsoft windows;native api;operating system;privilege level;requirement;rootkit;sensor;system call;system monitoring	Gábor Pék;Levente Buttyán	2014	2014 IEEE International Conference on Communications (ICC)	10.1109/ICC.2014.6883425	embedded system;real-time computing;computer science;operating system	Embedded	-23.998518318945035	55.444540987475094	25947
6c6cbf161369aeb448855a9de21845fb710ff2f3	an experimentation platform for the automatic parallelization of r programs	r language;program interpreters authoring languages multiprocessing systems parallel processing;data parallelism;scripting languages;program interpreters;authoring languages;scripting language automatic parallelization analysis r program alchemy platform program execution parallelization analysis module code transformation module sequential r code parallelized r code multicore processor r interpreter multiprocessor performance parallel code;multicore processing vectors skeleton programming libraries bioinformatics hardware;parallel intermediate languages;multiprocessing systems;parallel intermediate languages automatic parallelization r language scripting languages data parallelism;parallel processing;automatic parallelization	We present our ALCHEMY platform that supports the automatic parallelization of R programs during execution. Parallelization occurs fully transparent to the user. Different parallelization techniques can be implemented as modules, linked into the platform, and combined with each other. The parallelization analysis modules and code transformation modules use a new intermediate representation for sequential and parallelized R code. Successfully parallelized parts of the R program are executed on a multicore processor, the results and the remaining sequential parts are fed back into the standard R interpreter and evaluated to completion. This way, an R user can benefit from multiprocessor performance without writing a single line of parallel code. At this stage of the research project, the main goal is to enable ample experimentation with different approaches to the automatic parallelization of scripting languages such as R.	automatic parallelization;boolean algebra;central processing unit;computation;data dependency;dependence analysis;dynamic programming;embarrassingly parallel;expect;experiment;input/output;intel array building blocks;intermediate representation;multi-core processor;multiprocessing;on the fly;parameter (computer programming);parsing;r language;recurrence relation;scheduling (computing);scripting language;speedup	Frank Padberg;Michael Mirold	2012	2012 19th Asia-Pacific Software Engineering Conference	10.1109/APSEC.2012.70	parallel processing;computer architecture;parallel computing;computer science;scripting language;data parallelism;programming language;automatic parallelization	PL	-13.907980751825622	37.18606934950349	25975
f05753937ce0a6a74521cf816dca39e49c4fb3ed	an investigation into improving the load balance for term-based partitioning	term frequency;skewed distribution;load balance	In Parallel (IR) systems the query response time is limited by the time of the slowest node in the system, thus distributing  the load equally across the nodes is very important issue. In this paper, we propose improving the load balance for term-based  partitioning by classifying the terms based on their length then distribute them equally across nodes. The motivation for  term length partitioning comes from the observation that the Excite-97 queries have a very skewed distribution of term lengths  with some predominant lengths. We also propose the term-frequency partitioning scheme in which the terms are classified based  on the total term frequency (F) and then distribute equally across the nodes.  	load balancing (computing)	Ahmad Abusukhon;Mohammad Talib;Michael P. Oakes	2008		10.1007/978-3-540-78942-0_38	skewness;computer science;load balancing;tf–idf	HPC	-17.469414955612542	58.26944761205743	26033
c835edd24c6ee8d254e8ccff0ca5afcc2889a01c	hardware transactional memory meets memory persistency		Abstract Persistent Memory (PM) and Hardware Transactional Memory (HTM) are two recent architectural developments whose joint usage promises to drastically accelerate the performance of concurrent, data-intensive applications. Unfortunately, combining these two mechanisms using existing architectural supports is far from being trivial. This paper presents NV-HTM, a system that allows the execution of transactions over PM using unmodified commodity HTM implementations. NV-HTM exploits a hardware–software co-design technique, which is based on three key ideas: (i) relying on software to persist transactional modifications after they have been committed via HTM; (ii) postponingthe externalization of commit events to applications until it is ensured, via software, that any data version produced and observed by committed transactions is first logged in PM; (ii) pruning the commit logs via checkpointing schemes that not only bound the log space and recovery time, but also implement wear leveling techniques to enhance PM’s endurance. By means of an extensive experimental evaluation, we show that NV-HTM can achieve up to 10 × speed-ups and up to 11.6 × reduced flush operations with respect to state of the art solutions, which, unlike NV-HTM, require custom modifications to existing HTM systems.	application checkpointing;cpu cache;computer architecture;data-intensive computing;html;l (complexity);login;nv network;persistent memory;throughput;transactional memory;wear leveling	Daniel Castro;Paolo Romano;João Pedro Barreto	2018	2018 IEEE International Parallel and Distributed Processing Symposium (IPDPS)	10.1109/IPDPS.2018.00046	transactional leadership;parallel computing;implementation;commit;operating system;computer science;software;exploit;wear leveling;transactional memory	Arch	-14.04764941480871	49.32000442367845	26061
0d45e56be38fd63f1ffb08a7339fee96388214ea	data-flow algorithms for parallel matrix computations	parallel calculus;computers;processing;general and miscellaneous mathematics computing and information science;parallel algorithm;traitement parallele;algorithm analysis;equation matricielle;systolic array;data processing;mathematical logic;flux information;information handling;synchronisation;information flow;lyapunov method;matrix computation;matrix equation;operating system;synchronization;array processors;resolucion de problema;communication protocol;programming 990200 mathematics computers;algorithms;analyse algorithme;sincronizacion;data flow;calcul parallele;logical process;parallel processing;problem solving;resolution probleme	In this article we develop some algorithms and tools for solving matrix problems on parallel processing computers. Operations are synchronized through data-flow alone, which makes global synchronization unnecessary and enables the algorithms to be implemented on machines with very simple operating systems and communication protocols. As examples, we present algorithms that form the main modules for solving Liapounov matrix equations. We compare this approach to wave front array processors and systolic arrays, and note its advantages in handling missized problems, in evaluating variations of algorithms or architectures, in moving algorithms from system to system, and in debugging parallel algorithms on sequential machines.	central processing unit;computer;dataflow;debugging;operating system;parallel algorithm;parallel computing;systolic array;tcp global synchronization	Dianne P. O'Leary;G. W. Stewart	1985	Commun. ACM	10.1145/4021.4025	randomized algorithms as zero-sum games;parallel processing;synchronization;probabilistic analysis of algorithms;data processing;computer science;theoretical computer science;operating system;analysis of parallel algorithms;mathematics;distributed computing;programming language;algorithm	HPC	-12.039318333208348	33.16043794011789	26079
6b97710a7a5d319fb41ddae0b5d36b196ca79a4f	automatic performance analysis of mpi applications based on event traces	interfase usuario;trace analysis;interfaz grafica;graphical interface;user interface;langage evolue;analisis automatico;automatic analysis;analyse performance;performance analysis;analyse automatique;arquitectura modular;interface utilisateur;lenguaje evolucionado;high level language;modular architecture;interface graphique;parallel applications;application mpi;architecture modulaire;analisis eficacia	This article presents a class library for detecting typical performance problems in event traces of MPI applications. The library is implemented using the powerful high-level trace analysis language EARL and is embedded in the extensible tool component EXPERT described in this paper. One essential feature of EXPERT is a flexible plug-in mechanism which allows the user to easily integrate performance problem descriptions specific to a distinct parallel application without modifying the tool component.	computer cluster;embedded system;graphical user interface;high- and low-level;java class library;library (computing);message passing interface;performance tuning;plug-in (computing);profiling (computer programming);programming paradigm;prototype;sensor;shared memory;stepwise regression;symmetric multiprocessing;tracing (software)	Felix Wolf;Bernd Mohr	2000		10.1007/3-540-44520-X_16	human–computer interaction;computer science;operating system;graphical user interface;programming language;user interface;high-level programming language	HPC	-18.068984378628382	41.46901439751585	26173
c625c58701559ea7128900468feb1a9ed45a339c	providing multi-tenant services with fpgas: case study on a key-value store		FPGAs can be used to speed up computation and data management tasks in various application domains. In cloud settings, however, high utilization is as important as high performance. In software it is common to co-locate different tenants' workloads on the same servers to increase utilization. Sharing an FPGA is more complex because applications take up physical space on the chip. Even though it is possible to physically partition the FPGA, tenants can have widely different requirements and their needs can also fluctuate over time. In this paper, we take a different approach and provide flexibility to the tenants who are interested in the same type of application but have different workloads and quality of service requirements. We demonstrate our approach of multi-tenant design using a key-value store service but the ideas generalize to other network-facing services as well. A key challenge of multi-tenancy is to efficiently share the underlying hardware while enforcing strict data and performance isolation between tenants. In this paper we demonstrate that, by following a single-pipeline design principle, it is possible to control each tenant's share of network bandwidth and computational resources even for complex, distributed operations. Furthermore, we show how state-machine based logic on the FPGA can be made tenant-aware without introducing significant context-switching overhead. Finally, our hardware design provides flexibility for changing per-tenant shares, allowing the same circuit to be used by one or multiple tenants without performance loss.		Zsolt István;Gustavo Alonso;Ankit Singla	2018	2018 28th International Conference on Field Programmable Logic and Applications (FPL)	10.1109/FPL.2018.00029	real-time computing;temporal isolation among virtual machines;data management;speedup;computer science;quality of service;software;data structure;cloud computing;server	DB	-21.59993753369599	53.582962592464206	26179
b33ad48b474168b969f0db205deefbbac8357b58	exploiting network locality in a decentralized read-write peer-to-peer file system	tolerancia falta;hachage;modelizacion;parallelisme;distributed system;sistema operativo;acceso multiple;groupware;entrada salida;acces multiple;systeme reparti;intelligent networks peer to peer computing file systems prototypes large scale systems data security fault tolerant systems authentication cryptography java;data integrity;localite;fault tolerant;distributed hash table;perforation;gestion archivos;par a par;authentication;gestion fichier;locality;integrite;langage java;integridad;file management;authoring systems fault tolerant computing message authentication data integrity cryptography java public domain software peer to peer computing groupware;multi user;oceanstore network locality decentralized peer to peer file system read write peer to peer file system multiuser peer to peer file system past distributed hash table fault tolerance consistency model authentication integrity cryptographic mechanism java freepastry open source implementation simulation nfs ivy;authoring systems;authentification;input output;modelisation;public domain software;consistency model;parallelism;fault tolerant computing;hashing;sistema repartido;autenticacion;integrity;paralelismo;poste a poste;operating system;consistencia soltada;file system;criptografia;cryptography;fault tolerance;logiciel libre;consistance relachee;cryptographie;software libre;systeme exploitation;lenguaje java;message authentication;relaxed consistency;peer to peer computing;multiple access;peer to peer;modeling;tolerance faute;open source software;java language;entree sortie;java;open source	We have developed a completely decentralized multiuser read-write peer-to-peer file system with good locality properties. In our system all data is contained in blocks stored using the Past distributed hash table (DHT), thus taking advantage of the fault tolerance and locality properties of Past and Pastry. We have also introduced a modification to the Past DHT which allows us to further increase performance when using a relaxed but nevertheless useful consistency model. Authentication and integrity are assured using standard cryptographic mechanisms. We have developed a prototype in order to evaluate the performance of our design. Our prototype is programmed in Java and uses the FreePastry open-source implementation of Past and Pastry. It allows applications to choose between two degrees of consistency. Preliminary results obtained through simulation suggest that our system is approximately twice as slow as NFS. In comparison, Ivy and Oceanstore are between two to three times slower than NFS.	apache ivy;authentication;concurrency (computer science);concurrency control;consistency model;cryptography;distributed hash table;fault tolerance;file synchronization;high-level programming language;image resolution;java;linearizability;locality of reference;lock (computer science);multi-user;open-source software;peer-to-peer;prototype;read-write memory;scalability;simulation;test case	Fabio Picconi;Jean-Michel Busca;Pierre Sens	2004	Proceedings. Tenth International Conference on Parallel and Distributed Systems, 2004. ICPADS 2004.	10.1109/ICPADS.2004.43	fault tolerance;parallel computing;computer science;operating system;authentication;database;distributed computing;programming language;computer security;computer network	HPC	-26.450559379467766	44.022139110461346	26202
606c8202dac8742cdfc4c6fc5401e892cb7b661d	tag overflow buffering: reducing total memory energy by reduced-tag matching	energy efficiency;cache storage tag overflow buffering reduced tag matching energy efficient cache architecture cache energy;cache storage;reduced tag matching;integrated circuit;energy efficient;tag overflow buffering;energy efficiency registers structural engineering energy measurement measurement standards memory architecture energy consumption embedded system circuits hardware;rendement energetique;cache memory;circuito integrado;valor medio;memory architecture cache memory low power;embedded system;antememoria;antememoire;low power;energy measurement;registers;energy consumption;memory architecture;structural engineering;rendimiento energetico;low power electronics;valeur moyenne;mean value;circuits;power consumption;consommation energie electrique;cache energy;measurement standards;energetic efficiency;electronique faible puissance;low power electronics cache storage;energy efficient cache architecture;circuit integre;energy saving;hardware	We propose a novel energy-efficient cache architecture based on a matching mechanism that uses a reduced number of tag bits. The idea behind the proposed architecture is based on moving a large subset of the tag bits from the cache into an external register (called the Tag Overflow Buffer) that serves as an identifier of the current locality of the memory references. Dynamic energy efficiency is achieved by accessing, for most of the memory references, a reduced-tag cache; furthermore, because of the reduced number of tag bits, leakage energy is also reduced as a by-product. We achieve average energy savings ranging from 16% to 40% (depending on different cache structural parameters) on total (i.e., static and dynamic) cache energy, and measured on a standard suite of embedded applications.	cpu cache;embedded system;identifier;locality of reference;spectral leakage;tagged architecture	Mirko Loghi;Paolo Azzoni;Massimo Poncino	2009	IEEE Transactions on Very Large Scale Integration (VLSI) Systems	10.1109/TVLSI.2009.2016720	embedded system;cache-oblivious algorithm;parallel computing;real-time computing;cache coloring;page cache;tag ram;cache;computer science;write-once;cache invalidation;operating system;efficient energy use;smart cache;cache algorithms;cache pollution	Arch	-5.9319694686026425	55.0642416195588	26213
870879387b8b7119e13e197e0bf066e0f7b97345	improving server applications with system transactions	system transactions;operating system;byzantine fault tolerant;high throughput	Server applications must process requests as quickly as possible. Because some requests depend on earlier requests, there is often a tension between increasing throughput and maintaining the proper semantics for dependent requests. Operating system transactions make it easier to write reliable, high-throughput server applications because they allow the application to execute non-interfering requests in parallel, even if the requests operate on OS state, such as file data.  By changing less than 200 lines of application code, we improve performance of a replicated Byzantine Fault Tolerant (BFT) system by up to 88% using server-side speculation, and we improve concurrent performance up to 80% for an IMAP email server by changing only 40 lines. Achieving these results requires substantial enhancements to system transactions, including the ability to pause and resume transactions, and an API to commit transactions in a pre-defined order.	application programming interface;byzantine fault tolerance;email;high-throughput computing;operating system;server (computing);server-side;throughput	Sangman Kim;Michael Z. Lee;Alan M. Dunn;Owen S. Hofmann;Xuan Wang;Emmett Witchel;Donald E. Porter	2012		10.1145/2168836.2168839	high-throughput screening;real-time computing;computer science;operating system;distributed computing	OS	-20.292970476501768	50.414518256868526	26226
123d0425c5a0fb8a02e80bcbb9e6491124b9e08e	eliminating barrier synchronization for compiler-parallelized codes on software dsms	distributed system;algoritmo paralelo;eficacia sistema;optimisation;systeme reparti;parallel algorithm;compilateur;systeme multiprocesseur memoire repartie;optimizacion;parallelizing compiler;parallelizing compilers;performance systeme;program transformation;eliminating barrier;paralelisacion;software dsm;ingenieria logiciel;transformation programme;lazy release consistency;compiler;software engineering;system performance;parallel computation;algorithme parallele;synchronisation;software distributed shared memory;transformacion programa;calculo paralelo;sistema repartido;synchronization;sistema multiprocesador memoria distribuida;parallelisation;nearest neighbor;parallelization;message passing;genie logiciel;optimization;sincronizacion;distributed memory multiprocessor system;communication;community analysis;calcul parallele;comunicacion;compilador	Software distributed-shared-memory (DSM) systems provide an appealing target for parallelizing compilers due to their flexibility. Previous studies demonstrate such systems can provide performance comparable to messagepassing compilers for dense-matrix kernels. However, synchronization and load imbalance are significant sources of overhead. In this paper, we investigate the impact of compilation techniques for eliminating barrier synchronization overhead in software DSMs. Our compile-time barrier elimination algorithm extends previous techniques in three ways: (1) we perform inexpensive communication analysis through local subscript analysis when using chunk iteration partitioning for parallel loops; (2) we exploit delayed updates in lazy-release-consistency DSMs to eliminate barriers guarding only anti-dependences; (3) when possible we replace barriers with customized nearest-neighbor synchronization. Experiments on an IBM SP-2 indicate these techniques can improve parallel performance by 20% on average and by up to 60% for some applications.	algorithm;automatic parallelization;barrier (computer science);compile time;compiler;distributed shared memory;iteration;lazy evaluation;overhead (computing);parallel computing;release consistency;sparse matrix	Hwansoo Han;Chau-Wen Tseng;Peter J. Keleher	1998	International Journal of Parallel Programming	10.1023/A:1018724631720	synchronization;parallel computing;real-time computing;computer science;operating system;computer performance;programming language;algorithm	HPC	-16.50793612973741	42.41655810632626	26247
72337154ea4d9da9ccad434e22a49fa9c93778ab	re-engineering compiler transformations to outperform database query optimizers		Traditionally, Query Optimization and Compiler Optimizations have been developed independently. Whereas Query Optimization aims at optimizing database queries to minimize the number of disk operations, Compiler Optimizations target to maximize performance of generic executable codes. While query optimizers were originally designed for systems that needed to process large volumes of data with little main memory, the size of computer main memory has increased significantly. As a result, techniques are now being considered in the database community that have been developed in the field of compiler optimization. In this paper, we demonstrate that the converse is much more lucrative: extend compiler transformations to also target query optimization. By doing so, advanced compiler optimizations are employed as the driving force in query optimization and database systems can be on par with future complex computer architectures.	compiler	Kristian F. D. Rietveld;Harry A. G. Wijshoff	2014		10.1007/978-3-319-17473-0_20	query optimization;parallel computing;optimizing compiler;database;programming language	PL	-18.270127893746817	34.86465604422623	26270
66e91e50d4f64a9ae5eeb283630ea28338461ae1	executing multiple pipelined data analysis operations in the grid	visualization application;scheduling algorithm;multiple pipelined data analysis;multiple data analysis operation;data analysis application;coarse grain data flow;pipelined chain;grid resource;data source;scheduling problem;resource management;data visualization;application software;data flow;data analysis;computer networks;san;mpi	Processing of data in many data analysis applications can be represented as an acyclic, coarse grain data flow, from data sources to the client. This paper is concerned with scheduling of multiple data analysis operations, each of which is represented as a pipelined chain of processing on data. We define the scheduling problem for effectively placing components onto Grid resources, and propose two scheduling algorithms. Experimental results are presented using a visualization application.	algorithm;dataflow;directed acyclic graph;scheduling (computing)	Matthew Spencer;Renato A. C. Ferreira;Michael D. Beynon;Tahsin M. Kurç;Ümit V. Çatalyürek;Alan Sussman;Joel H. Saltz	2002	ACM/IEEE SC 2002 Conference (SC'02)		fair-share scheduling;data flow diagram;application software;parallel computing;real-time computing;storage area network;computer science;message passing interface;resource management;operating system;distributed computing;data analysis;scheduling;data visualization	HPC	-12.0767541202959	43.76465276528383	26289
3090bf0a3cb3f38cb61f068b2fc6fdd289f9a134	thread-local concurrency: a technique to handle data race detection at programming model abstraction		With greater adoption of various high-level parallel programming models to harness on-node parallelism, accurate data race detection has become more crucial than ever. However, existing tools have great difficulty spotting data races through these high-level models, as they primarily target low-level concurrent execution models (e.g., concurrency expressed at the level of POSIX threads). In this paper, we propose a novel technique to accurately detect those data races that can occur at higher levels of concurrent execution. The core idea of our technique is to introduce the general concept of Thread-Local Concurrency (TLC) as a new way to translate the concurrency expressed by a high-level programming paradigm into the low execution level understood by the existing tools. Specifically, we extend the definition of vector clocks to allow the existing state-of-the-art race detectors to recognize those races that occur at the higher level of concurrency with minor modifications to these tools. Our evaluation with our prototype implemented within ThreadSanitizer shows that TLC can allow the existing tool to detect these races accurately with only small additional analysis overheads.	concurrency (computer science);high- and low-level;high-level programming language;multi-level cell;posix threads;parallel computing;programming model;prototype;race condition;sensor;thread-local storage;vector clock	Joachim Protze;Martin Schulz;Dong H. Ahn;Matthias S. Müller	2018		10.1145/3208040.3208056	vector clock;distributed computing;programming paradigm;concurrency;overhead (business);posix threads;thread (computing);computer science;abstraction	HPC	-20.90595415503496	39.3093904814255	26292
08937c92f31895e16af48de1c7d18eeceef11f6f	enabling highly-scalable remote memory access programming with mpi-3 one sided	message passing application program interfaces memory protocols;protocols synchronization programming libraries radiation detectors memory management hardware;tree saturation;performance;remote direct memory access highly scalable remote memory access programming mpi 3 one sided standard explicit message passing programming interface rdma networks scalable bufferless protocols memory consumption performance models fortran coarrays upc;reservation protocol;large scale networks;congestion control;congestion notification	Modern interconnects offer remote direct memory access (RDMA) features. Yet, most applications rely on explicit message passing for communications albeit their unwanted overheads. The MPI-3.0 standard defines a programming interface for exploiting RDMA networks directly, however, it's scalability and practicability has to be demonstrated in practice. In this work, we develop scalable bufferless protocols that implement the MPI-3.0 specification. Our protocols support scaling to millions of cores with negligible memory consumption while providing highest performance and minimal overheads. To arm programmers, we provide a spectrum of performance models for all critical functions and demonstrate the usability of our library and models with several application studies with up to half a million processes. We show that our design is comparable to, or better than UPC and Fortran Coarrays in terms of latency, bandwidth, and message rate. We also demonstrate application performance improvements with comparable programming complexity.	application programming interface;coarray fortran;electrical connection;image scaling;message passing interface;programmer;programming complexity;remote direct memory access;scalability;universal product code;usability	Robert Gerstenberger;Maciej Besta;Torsten Hoefler	2013	2013 SC - International Conference for High Performance Computing, Networking, Storage and Analysis (SC)	10.1145/2503210.2503286	parallel computing;real-time computing;performance;computer science;operating system;distributed computing;programming language;network congestion;computer network	HPC	-10.658193642340084	47.26479880572294	26306
8a1b3d2d4041fcf59e229e4e35209af00623cf31	byzantine fault-tolerant deferred update replication	simulation and modeling;data structures;computer science general;computer system implementation;operating systems	Replication is a well-established approach to increasing database availability. Many database replication protocols have been proposed for the crash-stop failure model, in which servers fail silently. Fewer database replication protocols have been proposed for the byzantine failure model, in which servers may fail arbitrarily. This paper considers deferred update replication, a popular database replication technique, under byzantine failures. The paper makes three contributions. First, it shows that making deferred update replication tolerate byzantine failures is quite simple. Second, the paper presents a byzantine-tolerant mechanism to execute read-only transactions at a single server. Third, we consider byzantine client attacks against deferred update replication and discuss effective countermeasures against these attacks.	byzantine fault tolerance;client honeypot;consensus (computer science);database;read-only memory;replication (computing);server (computing);windows update	Fernando Pedone;Nicolas Schiper	2011	2011 5th Latin-American Symposium on Dependable Computing	10.1007/s13173-012-0060-z	real-time computing;data structure;computer science;quantum byzantine agreement;operating system;state machine replication;database;distributed computing;programming language	OS	-21.98450254057241	48.99582045001508	26396
9ae7d8b39c78ce3708129eb910cded7072ac8103	a new job migration algorithm to improve data center efficiency	data center	The under exploitation of the available resources risks to be one of the main problems for a computing center. The growing demand of computational power necessarily entails more complex approaches in the management of the computing resources, with particular attention to the batch queue system scheduler. In a heterogeneous batch queue system, available for both serial single core processes and parallel multi core jobs, it may happen that one or more computational nodes composing the cluster are not fully occupied, running a number of jobs lower than their actual capability. A typical case is represented by more single core jobs running each one over a different multi core server, while more parallel jobs requiring all the available cores of a host are queued. A job rearrangement executed at runtime is able to free extra resources, in order to host new processes. We present an efficient method to improve the computing resources exploitation.	algorithm;computation;computer cluster;data center;exploit (computer security);information engineering;job queue;job stream;multi-core processor;parallel computing;performance per watt;requirement;run time (program lifecycle phase);scheduling (computing);server (computing)	Federico Calzolari;Silvia Volpe	2011	CoRR		data center;parallel computing;real-time computing;computer science;job scheduler;operating system;distributed computing;job queue	HPC	-21.28730676935726	59.45548541061807	26428
833da56175762daf644fe42b230917367264208c	linlogfs - a log-structured file system for linux			linux;log-structured file system	Christian Czezatke;M. Anton Ertl	2000				OS	-19.03724455128489	51.69102783875577	26436
2adcfd0f0d4a794ccd04373e282f978dc663dfaa	server consolidation: an approach to make data centers energy efficient and green	green house gases;emerging technology;data center;energy efficient	Data centers are the building blocks of IT business organizations providing the capabilities of centralized repository for storage, management, networking and dissemination of data. With the rapid increase in the capacity and size of data centers, there is a continuous increase in the demand for energy consumption. These data centers not only consume a tremendous amount of energy but are riddled with IT inefficiencies. All data center are plagued with thousands of servers as major components. These servers consume huge energy without performing useful work. In an average server environment, 30% of the servers are “dead” only consuming energy, without being properly utilized. Their utilization ratio is only 5 to 10 percent. This paper focuses on the use of an emerging technology called virtualization to achieve energy efficient data centers by providing a solution called server consolidation. It increases the utilization ratio up to 50% saving huge amount of energy. Server consolidation helps in implementing green data centers to ensure that IT infrastructure contributes as little as possible to the emission of green house gases, and helps to regain power and cooling capacity, recapture resilience and dramatically reducing energy costs and total cost of ownership. Index Terms Virtualization; Server Consolidation; Data centre; Green Technology; Carbon Footprints. — — —— — — — — — — — — —— — — — — —	categorization;centralized computing;computer cooling;cyber resilience;data center;hardware virtualization;list of code lyoko episodes;real-time clock;scalability;semiconductor consolidation;server (computing);software repository;total cost of ownership;watts humphrey	Mueen Uddin;Azizah Abdul Rahman	2010	CoRR		data center;greenhouse gas;simulation;computer science;engineering;operating system;efficient energy use;emerging technologies;computer security	OS	-26.248205258091375	59.79175345961958	26480
60224e4e6f3d4fa295922a91fa6433b5e763e6b2	design and implementation of bandwidth-aware memory placement and migration policies for heterogeneous memory systems		Heterogeneous memory systems that comprise memory nodes based on widely-different device technologies (e.g., DRAM and nonvolatile memory (NVM)) are emerging in various computing domains ranging from high-performance to embedded computing. Despite the extensive prior work on architectural and system software support for heterogeneous memory systems, relatively little work has been done to investigate the OS-level memory placement and migration policies that consider the bandwidth differences of heterogeneous memory nodes.  To bridge this gap, this work investigates the design and implementation of memory placement and migration policies for bandwidth-intensive applications on heterogeneous memory systems. Specifically, we propose three bandwidth-aware memory placement policies (i.e., bandwidth-aware interleave, random, and local policies) and a bandwidth-aware memory migration policy and implement the proposed policies in the Linux kernel. Through our quantitative evaluation based on real system software and hardware stacks, we demonstrate that the bandwidth-aware memory placement and migration policies achieve significantly higher performance than the conventional bandwidth-oblivious policies across a wide range of the DRAM-to-NVM bandwidth ratios when executing bandwidth-intensive workloads.	big data;cloud computing;dynamic random-access memory;embedded system;linux;mathematical optimization;non-volatile memory;nonvolatile bios memory;operating system;virtual machine manager	Seongdae Yu;Seongbeom Park;Woongki Baek	2017		10.1145/3079079.3079092	memory management;flat memory model;parallel computing;real-time computing;non-uniform memory access;computer science;distributed shared memory;uniform memory access;interleaved memory;computing with memory;shared memory	HPC	-8.729635111331593	49.94935659071716	26515
a77c933fd62cbacdb71cfea1a5f9a10cc49c3125	new architectures: performance highlights and new algorithms	massive parallelism;multigrid solution of pdes;computational efficiency;parallel computers;high-speed vectorization	Abstract   Parallel computers are having a profound impact on computational science. Recently highly parallel machines have taken the lead as the fastest supercomputers, a trend that is likely to accelerate in the future. We describe some of these new computers, and issues involved in using them. We present elliptic PDE solutions currently running at 3.8 gigaflops, and an atmospheric dynamics model running at 1.7 gigaflops, on a 65 536-processor computer.  One intrinsic disadvantage of a parallel machine is the need to perform inter-processor communication. It is important to ensure that such communication time is maintained at a small fraction of computation time. We analyze standard multigrid algorithms in two and three dimensions from this point of view, indicating that performance efficiencies in excess of 95% are attainable under suitable conditions on moderately parallel machines. We also demonstrate that such performance is not attainable for multigrid on massively parallel computers, as indicated by an example of poor multigrid efficiency on 65 536 processors. The fundamental difficulty is the inability to keep 65 536 processors busy when operating on very coarse grids.  Most algorithms used for implementing applications on parallel machines have been derived directly from algorithms designed for serial machines. The previously mentioned multigrid example indicates that such ‘parallelized’ algorithms may not always be optimal. Parallel machines open the possibility of finding totally new approaches to solving standard tasks—intrinsically parallel algorithms. In particular, we present a class of superconvergent multiple scale methods that were motivated directly by massevely parallel machines. These methods differ from standard multigrid methods in an intrinsic way, and allow all processors to be used at all times, even when processing on the coarsest grid levels. Their serial versions are not sensible algorithms. The idea that parallel hardware—the Connection Machine in this case—can lead to discovery of new mathematical algorithms was surprising for us.	algorithm	Oliver A. McBryan	1988	Parallel Computing	10.1016/0167-8191(88)90067-1	parallel computing;computer science;theoretical computer science;operating system;analysis of parallel algorithms;distributed computing;algorithm;cost efficiency	HPC	-4.570804835391118	39.42870951797258	26518
c69c685c70b368d068b7f3f5be322417b3b8deb0	a structured approach for developing concurrent programs in java	lenguaje programacion;java multi threated programming;programming language;java programming;simultaneidad informatica;langage java;concurrent program;safety properties;concurrency;programming theory;programa competidor;langage programmation;concurrent programs;invariante;theorie programmation;coarse grained;global invariant;simultaneite informatique;invariant;programme concurrent;java language	In recent years, concurrent programming has become the norm rather than the exception in many applications. In particular, popularity of the Java programming language has accelerated this trend. Most textbooks on Operating Systems and concurrent programming teach concurrent programming by demonstrating solutions for some well-known problems, such as the producer/consumer, readers/writers, and dining philosophers problems. A more systematic and formal approach to develop concurrent programs is presented in [1, 2]. In this approach, for a given problem, we first specify a global invariant that implies the safety property. Then, we develop a so-called coarse-grained solution using the two synchronization constructs: < await B → S > and < S >. Using Programming Logic, the global invariant is formally verified in the coarse-grained solution. Finally, the coarse-grained solution is mechanically translated to a fine-grained semaphore or monitor program that maintains the global invariant. This approach has many advantages. First, this is a formal approach that enables verification of programs being developed. Second, the most important activity in the programming process lies at a high level; namely, specifying global invariants. Once an appropriate global invariant is specified, much of the rest of the process is mechanical. Furthermore, global invariants and coarsegrained solutions are platform (synchronization primitive) independent. Thus, if the platform is switched from a semaphore-based to a monitor-based system, we only need to translate the existing coarse-grained solution to a monitor-based fine-grained program. The Java programming language encourages the use of multiple threads. Therefore, as Java’s popularity grows, concurrent programming using Java synchronization primitives will become more important. Java provides monitor-like synchronization primitives. However, these primitives have limitations. Each Java monitor object can only have one condition variable, which is associated with the object itself; all waits and signals (called notify in Java) refer to it. The translation	concurrent computing;dining philosophers problem;formal verification;global serializability;high-level programming language;java;monitor (synchronization);semaphore (programming);synchronization (computer science);waits	Masaaki Mizuno	1999	Inf. Process. Lett.	10.1016/S0020-0190(99)00020-4	parallel computing;real-time computing;concurrency;computer science;invariant;mathematics;real time java;programming language	PL	-23.426717791449708	32.75033354948876	26554
c341ce1db5daba8070fb7a5e8ea5f988537db474	euroserver: share-anything scale-out micro-server design	market research;electronic mail;memory management;publikationer;program processors servers memory management electronic mail hardware scalability market research;konferensbidrag;servers;artiklar;rapporter;scalability;virtualisation cloud computing file servers;program processors;virtualisation layer share anything scale out microserver design cloud markets euroserver fp7 project fundamental system compute unit design architecture chiplet nanotechnological integration everything close physical form factor;hardware	This paper provides a snapshot summary of the trends in the area of micro-server development and their application in the broader enterprise and cloud markets. Focusing on the technology aspects, we provide an understanding of these trends and specifically the differentiation and uniqueness of the approach being adopted by the EUROSERVER FP7 project. The unique technical contributions of EUROSERVER range from the fundamental system compute unit design architecture, through to the implementation approach both at the chiplet nanotechnological integration, and the everything-close physical form factor. Furthermore, we offer optimizations at the virtualisation layer to exploit the unique hardware features, and other framework optimizations, including exploiting the hardware capabilities at the run-time system and application layers.	automation;runtime system;scalability;server (computing);snapshot (computer storage);systems design	Manolis Marazakis;John Goodacre;Didier Fuin;Paul M. Carpenter;John Thomson;Emil Matús;Antimo Bruno;Per Stenström;Jérôme Martin;Yves Durand;Isabelle Dor	2016	2016 Design, Automation & Test in Europe Conference & Exhibition (DATE)	10.3850/9783981537079_1022	market research;embedded system;electronic engineering;parallel computing;real-time computing;scalability;computer science;operating system;distributed computing;server;memory management	EDA	-27.994291767771266	57.023037464694774	26578
57d6eb4998a97102af93b90a09fd134107d5aa6d	parallel visual data restoration on multi-gpgpus using stencil-reduce pattern	gaussian noise;image filtering;parallel patterns;image restoration;impulsive noise;gpgpus;structured parallel programming;mapreduce;iterative stencil;stencil reduce;skeletons	In this paper, a highly effective parallel filter for visual data restoration is presented. The filter is designed following a skeletal approach, using a newly proposed stencil-reduce, and has been implemented by way of the FastFlow parallel programming library. As a result of its high-level design, it is possible to run the filter seamlessly on a multicore machine, on multi-GPGPUs, or on both. The design and implementation of the filter are discussed, and an experimental evaluation is presented.	circuit restoration;general-purpose computing on graphics processing units;high- and low-level;level design;library (computing);multi-core processor;parallel computing;the filter	Marco Aldinucci;Guilherme Peretti Pezzi;Maurizio Drocco;Concetto Spampinato;Massimo Torquati	2015	IJHPCA	10.1177/1094342014567907	gaussian noise;image restoration;parallel computing;computer science;theoretical computer science;computer graphics (images)	Robotics	-6.052993826288704	42.695153120997254	26591
2c96a6d6ea1a7632dce886ad8d0f9ae3dbf6e061	a memory-driven scheduling scheme and optimization for concurrent execution in gpu		Concurrent execution of GPU tasks is available in modern GPU device. However, limited device memory is an obvious bottleneck in executing many GPU tasks. And the task priority and system performance are often ignored. To address these, a real-time GPU scheduling scheme is proposed in this paper. A reservation algorithm based on device memory(RBDM) is adopted to provide more opportunity for the High-priority task in the scheme. high priority first wake (HPFW) and small memory HPFW (SM-HPFW) are employed in the scheduling of waiting tasks to improve the priority response time and system performance. A CPU-based monitor is developed to check the GPU task execution. Experiments show the RBDM can work effectively. Compared with FIFO, HPFW can decrease overall priority response time significantly. Overall task completion time can be reduced by 20 % using the SM-HPFW while the distribution of device memory requirement of GPU tasks is even.	algorithm;asynchronous i/o;central processing unit;computer multitasking;concurrent computing;data-intensive computing;distributed computing;fifo (computing and electronics);graphics processing unit;input/output;mathematical optimization;pr/sm;real-time clock;real-time transcription;response time (technology);scheduling (computing)	Baoyu Xu;Wu Zhang;Xian-He Sun;Yang Wang	2016	Cluster Computing	10.1007/s10586-016-0656-8	parallel computing;real-time computing;computer hardware;computer science;operating system	HPC	-10.827167915621338	57.40256996908915	26597
6d8367fe1db7ce8be1250b770aaca1c581f6aeb2	object database benchmarks.		The need for performance measurement tools appeared soon after the emergence of the first Object-Oriented Database Management Systems (OODBMSs), and proved important for both designers and users (Atkinson & Maier, 1990). Performance evaluation is useful to designers to determine elements of architecture and more generally to validate or refute hypotheses regar ding the actual behavior of an OODBMS. Thus, performance evaluation is an essential component in the development process of well -designed and efficient systems. Users may also employ performance evaluation, either to compare the efficiency of different technologies before selecting an OODBMS or to tune a system. Performance evaluation by experimentation on a real system is generally referred to as benchmarking. It consists in performing a series of tests on a given OODBMS to estimate its performance in a given setting. Benchmarks are generally used to compare the global performance of OODBMSs, but they can also be exploited to illustrate the advantages of one system or another in a given situation, or to determine an optimal hardware configuration. Typically, a benchmark is constituted of two main elements: a workload model constituted of a database and a set of read and write operations to apply on this database, and a set of performance metrics.	benchmark (computing);emergence;management system;performance evaluation;software performance testing	Jérôme Darmont	2005		10.4018/978-1-59140-553-5.ch378	architecture;data mining;workload;database;benchmarking;object-relational database;performance measurement;computer science	DB	-17.728815511884648	46.892546685360166	26603
c1c4e6e8bdd00b7b8315b931b9dcec09393fb18a	strategies for improving connection management in a java-based, giop orb	rmi iiop orb;protocols;optimism ratio;multi threading;java yarn resource management protocols protection contracts subcontracting sun environmental management skeleton;yarn;multi threaded environments;soft real time environments;simple resource management algorithm;application server;resource manager;resource management;multi lock synchronization scheme;contracts;order of magnitude analysis connection management java based giop orb rmi iiop orb multi threaded environments soft real time environments java standard edition java enterprise edition platform application server vendors simple resource management algorithm multi lock synchronization scheme resource management aspects optimism ratio;soft real time;skeleton;distributed object management java multi threading remote procedure calls real time systems;protection;java enterprise edition platform;java based giop orb;java standard edition;application server vendors;distributed object management;sun;connection management;order of magnitude analysis;subcontracting;resource management aspects;environmental management;remote procedure calls;java;real time systems	In this study, we summarize an empirical investigation conducted in order to optimize connection management in the RMI-IIOP ORB, for highly multi-threaded environments. These environments can exist in soft real-time environments. The ORB has been released as a component in the Java TM Standard Edition and Java TM Enterprise Edition platforms. Several application server vendors have used this ORE3 as their RMI-IIOP core. This report focuses on the outcome of combining a rather simple resource management algorithm with a very effective multi-lock synchronization scheme. This paper emphasizes the resource management aspects. A simple model and the concept of optimism ratio are introduced. An order of magnitude analysis of the various approaches is given. Introduction The RMI-IIOP ORB supports the RMI model of programming, where the user defines distribution contracts in the RMVJava mode instead of defining such contracts in IDL [1,2]. This approach has been standardized by the OMG in the Java-to-IDL mapping [2]. The ORB is implemented in a multi-layer architecture: the generated stubs/skeletons, the subcontract layer, the GIOP layer and the transport layer. In the case of Java, the generated code layer has been specified to be portable among ORB implementations [3]. The subcontract layer manages the provisioning of distributed services such as distributed transactions and distributed security mechanisms. The next layer down is usually called the General Inter-ORB Protocol (GIOP) layer by ORB vendors [4]. It provides an implementation for the GIOP message semantics. From an organizational and conceptural point of view, GIOP messages have a structure very similar to a family of protocols that includes ones such as Simple Network Management Protocol (SNMP) [ 5 ] . Finally, the transport layer usually refers to the implementation required to dispatch GIOP messages. It is the “transport” layer of an ORB that deals with connection resource management. In performance evaluation of the current connection manager, we found that performance deteriorates rapidly when there are a large number of concurrent requests to the same endpoint. (For a fairly complete treatment of issues of concurrency in Java, see [6].) We concluded that the synchronization scheme and resource management mechanisms were the primary causes of the problem and we investigated two of the possible approaches to address the general problems. Original Synchronization Scheme used for Connection Management In the original scheme, a thread ready to dispatch a request would go into a wait state under the following conditions: 1 . The connection is not yet established 2. The connection is established but is used by another request These sorts of threads are usually programmed to w a i t ( ) on a synchronization object’s monitor [6]. 0-7695-1089-2/01 $10.00	algorithm;application server;artificial intelligence;communication endpoint;concurrency (computer science);distributed transaction;dynamic dispatch;general inter-orb protocol;java platform, enterprise edition;java concurrency;layer (electronics);performance evaluation;provisioning;rmi-iiop;real-time clock;real-time computing;server (computing);simple network management protocol;synchronization (computer science);thread (computing);wait state	Masood Mortazavi;Feng Hong	2001		10.1109/ISORC.2001.922821	embedded system;communications protocol;real-time computing;multithreading;computer science;resource management;operating system;software engineering;distributed computing;programming language;java;remote procedure call;skeleton;application server	OS	-32.52738752785411	43.82009547238033	26604
41175b2a8db988363258e1a091d882fa870d5706	efficacy and performance impact of value prediction	instruction level parallel;performance evaluation;hybrid predictor;hardware mechanism performance impact value prediction hybrid value predictor superscalar machine spec benchmarks;usefulness tracking;parallel architectures;computer aided instruction concurrent computing;data dependence;speculative execution;superscalar processor;instruction level parallelism;performance evaluation parallel architectures instruction sets;instruction sets;value prediction	Value prediction is a technique that bypasses inter-instruction data dependencies by speculating on the outcomes of producer instructions, thereby allowing dependent consumer instructions to execute in parallel. This work makes several contributions in value prediction research. A hybrid value predictor that achieves an overall prediction rate of up to 83% is presented. The design of a value-predicting eight-wide superscalar machine with its speculative execution core is described. This design is able to achieve 8.6% to 23% IPC improvements on the SPEC benchmarks. Furthermore, it is shown that prediction rate is not a good indicator of speedup because over 40% of predictions made may not be useful in enhancing performance, and a simple hardware mechanism that eliminates many of these useless predictions is introduced.	benchmark (computing);data dependency;kerrison predictor;speculative execution;speedup;superscalar processor	Bohuslav Rychlik;John Faistl;Bryon Krug;John Paul Shen	1998		10.1109/PACT.1998.727186	computer architecture;parallel computing;real-time computing;computer science;operating system;instruction set;instruction-level parallelism;speculative execution	Arch	-7.014891793519115	51.0727175520837	26612
f581ee1e3e83088fdce32f8816ce69f36b667401	cluster computing	software management;group and organization interfaces;schema and subschema;algorithms;design;intelligent agents;parallelism and concurrency;distributed systems;scheduling;experimentation;security;distributed networks;shared memory;miscellaneous;parallel programming;network communication;routing and layout;distributed debugging;interoperability;parallel i/o;reliability, availability, and serviceability;documentation;systems and software;system management;distributed programming;interconnection architectures;network topology;associative processors;wireless communication;web-based services;java;organization and design;modeling techniques;internet;graph algorithms;measurement;general;network communications;xml;distributed applications;data models;video;problem solving, control methods, and search;management;routing protocols;reliability;world wide web;theory;performance evaluation;file organization;heuristic methods;cluster computing;performance;performance attributes;real-time and embedded systems;packet-switching networks;distributed file systems;data communications;clustering	Cluster computing can be described as a fusion of the fields of parallel, high-performance, distributed, and high-availability computing. Cluster computing has become a hot topic of research among academic and industry community including system designers, network developers, language designers, standardizing forums, algorithm developers, graduate students and faculties. The use of clusters as computing platform is not just limited to scientific and engineering applications; there are many business applications that can benefit from the use of clusters. There are many exciting areas of development in cluster computing with new ideas as well as hybrids of old ones being deployed for production as well as research systems. The aim of this special issue is to bring together original and latest work from both academia and industry on various issues related to cluster computing. This research, and development, is being done in many areas but there are a few that are of special interest. The first one is, with no doubt, the network. Clusters are based on the communication between nodes and designing fast and low latency networks is a must for clusters to become the configuration of the future. Plenty of work being done in this are in	algorithm;computer cluster;high availability;software developer	Rajkumar Buyya;Hai Jin;Toni Cortes	2002	Future Generation Comp. Syst.	10.1016/S0167-739X(01)00053-X	simulation;computer science;theoretical computer science;distributed computing	HPC	-19.53132291295598	43.13969463424309	26631
7e454f4e89469099558aea03432364f1956602da	integrating task parallelism in data parallel languages for parallel programming on nows		A number of high-level parallel programming platforms for networks of workstations (NOWs) have been developed in recent times. Most of these platforms target the exploitation of data parallelism in applications. They do not allow expressibility of applications as a collection of tasks along with their precedence relationships. As a result, the control or task parallelism in an application cannot be expressed or exploited. The current work aims at integrating the notion of task parallelism and precedence relationships among constituting tasks to such high-level data parallel platforms for NOWs. Our model of integration provides for arbitrary nesting of data and task parallel modules. Also, the precedence relationships are clearly reflected from the program structure. The model relieves the programmer from the need to design applications for non-determinism in the order of completion of constituting tasks. The design of the runtime support as well as system-level book keeping is discussed. The model is general enough to be applied to a wide range of data parallel platforms. A specific case of integrating the model into anonymous remote computing (ARC), a data parallel programming platform, is presented. The performance related aspects are also discussed. Copyright  2000 John Wiley & Sons, Ltd.	cloud computing;data parallelism;high- and low-level;john d. wiley;nondeterministic algorithm;parallel computing;parallel programming model;programmer;structured programming;task parallelism;workstation	K. J. Binu;D. Janaki Ram	2000	Concurrency - Practice and Experience	10.1002/1096-9128(200011)12:13%3C1291::AID-CPE535%3E3.0.CO;2-%23	computer architecture;parallel computing;embarrassingly parallel;computer science;data-intensive computing;data parallelism;programming language;parallel extensions;implicit parallelism;task parallelism;parallel programming model	HPC	-13.379161481995485	39.377603246522405	26680
1ace07e590ef74a5b9d12c1a3757fae7921cb962	addressing cache/memory overheads in enterprise java cmp servers	cache storage;enterprise java cmp server;three dimensions;chip multiprocessor;architectural optimization;cache memory;microprocessor chips cache storage computer architecture electronic engineering computing java;data less cache line initialization;garbage collection;on socket dram cache;computer architecture;execution driven emulation cache memory overhead enterprise java cmp server chip multiprocessor architecture intel core 2 duo xeon platform architectural optimization data less cache line initialization hardware guided thread collocation on socket dram cache trace driven simulation;java random access memory yarn performance analysis memory architecture microprocessors hardware emulation current measurement frequency;memory architecture;cache memory overhead;chip multiprocessor architecture;electronic engineering computing;intel core 2 duo xeon platform;trace driven simulation;hardware guided thread collocation;microprocessor chips;java;execution driven emulation	As we enter the era of chip multiprocessor (CMP) architectures, it is important that we explore the scaling characteristics of mainstream server workloads on these platforms. In this paper, we analyze the performance of two significant enterprise Java workloads (SPECjAppServer2004 and SPECjbb2005) on CMP platforms -present and future. We start by characterizing the core, cache and memory behavior of these workloads on the newly released Intel core 2 Duo Xeon platform (dual-core, dual-socket). Our findings from these measurements indicate that these workloads have a significant performance dependence on cache and memory subsystems. In order to guide the evolution of future CMP platforms, we perform a detailed investigation of potential cache and memory architecture choices. This includes analyzing the effects of thread sharing and migration, object allocation and garbage collection. Based on the observed behavior, we propose architectural optimizations along three dimensions: (a) data-less cache line initialization (DCLI), (b) hardware-guided thread collocation (HGTC) and (c) on-socket DRAM caches (OSDC). In this paper, we will describe these optimizations in detail and validate their performance potential based on trace-driven simulations and execution-driven emulation. Overall, we expect that the findings in this paper will guide future CMP architectures for enterprise Java servers.	cpu cache;collocation;dynamic random-access memory;emoticon;emulator;garbage collection (computer science);image scaling;java platform, enterprise edition;limiter;multi-core processor;multiprocessing;server (computing);simulation;thread (computing)	Kumar Shiv;Ravi Iyer;Mahesh Bhat;Ramesh Illikkal;Michael Jones;Srihari Makineni;Jason Domer;Donald Newell	2007	2007 IEEE 10th International Symposium on Workload Characterization	10.1109/IISWC.2007.4362182	three-dimensional space;computer architecture;parallel computing;cache coloring;cpu cache;computer science;operating system;garbage collection;programming language;java	Arch	-8.485317145458284	50.09735342753545	26690
3501c0b41b493591e7ea58d62b0c1e5384977251	the impact of dynamic channels on functional topology skeletons	langage fonctionnel;parallelisme;communication process;programa paralelo;hierarchical system;topology;hypercube;evaluation performance;performance evaluation;esqueleto;gollete estrangulamiento;communication topologies;evaluacion prestacion;systeme hierarchise;topologie;lenguaje funcional;hombre;diferenciacion servicio;anneau;parallel functional programming;functional programming;skeleton;topologia;channel based communication;enfant;proceso comunicacion;sistema jerarquizado;processus communication;goulot etranglement;parallelism;paralelismo;nino;human;child;service differentiation;squelette;langage parallele;programmation fonctionnelle;ring;functional language;programacion funcional;parallel languages;bottleneck;parallel program;differenciation service;anillo;homme;topology skeletons;programme parallele;hipercubo	Parallel functional programs with implicit communication often generate purely hierarchical communication topologies during execution: communication only happens between parent and child processes. Messages between siblings must be passed via the parent. This causes inefficiencies that can be avoided by enabling direct communication between arbitrary processes. The Eden parallel functional language provides dynamic channels to implement arbitrary communication topologies. This paper analyses the impact of dynamic channels on Eden’s topology skeletons, i.e. skeletons which define process topologies such as rings, toroids, or hypercubes. We compare topology skeletons with and without dynamic channels with respect to the number of messages. Our case studies confirm that dynamic channels decrease the number of messages by up to 50% and substantially reduce runtime. Detailed analyses of Eden TV (trace viewer) execution profiles reveal a bottleneck in the root process when only hierarchical channel connections are used and a better overlap of communications with dynamic channels.	analysis of algorithms;beowulf cluster;bottleneck (software);computation;concurrency (computer science);functional programming;inter-process communication;network topology;run time (program lifecycle phase);runtime system	Jost Berthold;Rita Loogen	2008	Parallel Processing Letters	10.1142/S0129626408003259	parallel computing;el niño;computer science;operating system;distributed computing;hierarchical control system;programming language;functional programming;skeleton;algorithm;ring;hypercube	PL	-17.322223234664648	40.839252881936034	26694
4f3c78ad433a1f58f0f5c18899820cb3e30e46a0	adaptive intrusion detection in distributed environments: an ensemble-based approach			intrusion detection system	Alfredo Cuzzocrea;Gianluigi Folino;Pietro Sabatino	2016			machine learning;intrusion detection system;artificial intelligence;computer science	ML	-30.80789212714789	46.7096855778426	26727
a744f4505460436892ecbffa8571da600c58db71	performance evaluation of a c++ library based multithreaded system	dynamically weighted actor method call graphs;kernel;concurrent computing;performance evaluation;program visualization;c library based multithreaded system;concurrent computation;software libraries;object oriented design;multiprocessor systems;call graph;cad;complex parallel applications;software performance evaluation;parallel programming;object oriented programming;kernel support;visualization tools;runtime library;object oriented modeling multithreading computational modeling feedback visualization multiprocessing systems concurrent computing runtime library kernel statistics;program visualization performance evaluation c library based multithreaded system multiprocessor systems message driven model reactive model arriving message actor model concurrent computation empirical performance study kernel support propercad ii c class library parallel platforms object oriented design techniques real applications complex parallel applications performance feedback visualization tools dynamically weighted actor method call graphs method specific statistics;parallel platforms;visualization;c language;feedback;computational modeling;real applications;propercad ii c class library;object oriented design techniques;model integration;message driven model;statistics;message passing;arriving message;performance feedback;empirical performance study;cad software performance evaluation c language object oriented languages object oriented programming software libraries parallel programming message passing;multiprocessing systems;model of computation;reactive model;actor model;object oriented languages;object oriented modeling;parallel applications;method specific statistics;multithreading	One model of multithreading gaining popularity on multiprocessor systems is the message driven model of computation The message driven model is a reactive model in which an arriving message starts a block of computation to processthat message The advantage of programming in such a model is that the dependen cies are explicit messages are asynchronous and the resulting code is highly multithreaded The message driven model studie din this paper is the actor model of concurrent computation This pap er presents an empirical performance study of the runtime and ker nel supp ortof the Pr op erCADII C class library which supports the actor model The Pr operCAD II C class library facilitates the use of multithread ing on parallel platforms through object oriented de sign techniques The usefulness of the ProperCAD II is shown through the results of various large real appli cations In addition to providing a useful paradigm to program complex parallel applications we b elieve that the actor model integrates well with more advanced performance feedback and visualization tools Further feedback related to multithreading will be presented in the form of dynamically weighted actor method call graphs method speci c statistics and program visu alization	actor model;c++;concurrent computing;din connector;library (computing);method (computer programming);model of computation;multiprocessing;multithreading (computer architecture);parallel computing;performance evaluation;programming paradigm;thread (computing)	John G. Holm;Steven Parkes;Prithviraj Banerjee	1997		10.1109/HICSS.1997.667274	parallel computing;real-time computing;concurrent computing;computer science;operating system;database;distributed computing;programming language;object-oriented programming	HPC	-11.232477350741146	40.56500976448361	26784
396d7a86fe0007e2ec08bf21bb4d543ac4c361c1	a new class of cache memory cotnrollers	models;performance analysis;hit ratio;cache;program behav- ior;lru;fcrp;opt;fifo;memory replacement policies;cache memory;stochastic model	There is a lack of flexibility in a fixed page location system because every location within a page has a determined mapping within a page buffer. This causes the buffer to contain locations that are unlikely to be used. A more flexible system introduced in this paper, called variable page location, allows a page to begin at the first location needed so that the page buffer will be filled with sequential locations that are likely to be used. This is not easily accomplished or practical if a conventional replacement policy, such as FIFO or LRU, is used in a variable page location system; therefore, a new class of replacement policies, called location policies, is introduced. To see how well a location policy system compares to a conventional system, a performance model for each system is developed. Both models are a function of cache size, program size, and program behavior. As a preliminary step for performance modeling, a stochastic model of program behavior based on the difference between successive word references is presented.	buffer overflow;cpu cache;fifo (computing and electronics);performance prediction	Adnan Shaout;Larry Colagiovanni	2001	J. Inf. Sci. Eng.			Metrics	-12.912243841216902	56.38220882720145	26785
51a5cd00855ce6d3855d5265bdcf8725b75ff54f	mapping application performance to hpc architecture	benchmarking;high performance computing;performance analysis	A suite of application benchmarks, designed to be broadly representative of UK HPC usage, has been developed to stress a broad range of architectural features of large scale parallel HPC resources. A generic methodology to investigate application performance and scaling characteristics has been defined, resulting in a detailed understanding of the performance of these applications. This methodology is transferable to other applications and systems: it is of practical value to developers and users who are aiming for optimal utilisation of HPC resources. An understanding of the performance characteristics of a range of large-scale HPC resources has been obtained using low-level synthetic benchmarks. A relatively simple, qualitative mechanism to assess and predict application performance on current and future architectures using synthetic benchmark results together with application performance analysis results is explored.		Alan Gray;Iain Bethune;R. D. Kenway;Lorna Smith;Martyn F. Guest;Christine A. Kitchen;P. Calleja;A. Korzynski;S. Rankin;Mike Ashworth;A. Porter;Ilian T. Todorov;M. Plummer;E. Jones;L. Steenman-Clark;B. Ralston;Charles A. Laughton	2012	Computer Physics Communications	10.1016/j.cpc.2011.11.013	supercomputer;parallel computing;simulation;benchmarking	HPC	-5.627355854868768	45.51206674998397	26884
3246942507053f93167589bcbbadf0dc2814ad00	fault tolerant leader election in distributed systems		There are many distributed systems which use a leader in their logic. When such systems need to be fault tolerant and the current leader suffers a technical problem, it is necesary to apply a special algorithm in order to choose a new leader. In this paper I present a new fault tolerant algorithm which elects a new leader based on a random roulette wheel selection.	algorithm;byzantine fault tolerance;computer science;database;distributed computing;fault-tolerant computer system;fitness proportionate selection;leader election;transaction processing	Marius Rafailescu	2017	CoRR	10.5121/ijcsit.2017.9102	fitness proportionate selection;fault tolerance;computer science;leader election;distributed computing	Theory	-22.9251477948972	44.53279132828526	26920
a1c2e5e54fe2fc293fb375b279ab26c92d50ff5f	automatic parallelism through macro dataflow in high-level array languages	libraries;dataflow computation;runtime;arrays;mathematical model;c languages;task parallelism;matlab;parallel processing	Dataflow computation is a powerful paradigm for parallel computing that is especially attractive on modern machines with multiple avenues for parallelism. However, adopting this model has been challenging as neither hardware- nor language-based approaches have been successful, except, in specialized contexts. We argue that general-purpose array languages, such as MATLAB, are good candidates for automatic translation to macro dataflow-style execution, where each array operation naturally maps to a macro dataflow operation and the model can be efficiently executed on contemporary multicore architecture. We support our argument with a fully automatic compilation technique to translate MATLAB programs to dynamic dataflow graphs that are capable of handling unbounded structured control flow. These graphs can be executed on multicore machines in an event driven fashion with the help of a runtime system built on top of Intel's Threading Building Blocks (TBB). By letting each task itself be data parallel, we are able to leverage existing data-parallel libraries and utilize parallelism at multiple levels. Our experiments on a set of benchmarks show speedups of up to 18x using our approach, over the original data-parallel code on a machine with two 16-core processors.	central processing unit;compiler;computation;control flow;data parallelism;dataflow;experiment;general-purpose markup language;high- and low-level;library (computing);matlab;machine translation;map;multi-core processor;parallel computing;programming paradigm;reactive programming;runtime system;structured programming;threading building blocks	Pushkar Ratnalikar;Arun Chauhan	2014	2014 23rd International Conference on Parallel Architecture and Compilation (PACT)	10.1145/2628071.2628131	dataflow architecture;parallel processing;computer architecture;parallel computing;computer science;operating system;mathematical model;data parallelism;programming language;instruction-level parallelism;task parallelism	PL	-13.57165313477865	38.48697328826748	26924
b84c7c1bfe909d8e3f08df71222369a96ffa1285	a cost-effective approach of building multi-tenant oriented lightweight virtual hpc cluster		HPC are considered as increasingly importance but only a small set of large enterprises or governments have the capability to use this high performance approach. In order to deliver HPC service and solve software dependency problems which rigidly restrict the usage of HPC applications. Based on Fat-Tree network topology and the virtual HPC cluster model, this paper provides a cloud of HPC delivery model and solves the dependency of HPC application software stack without destroying the initial HPC environments. Extensive experiments are conducted and the results validate the feasibility and the efficiency of our approach.	computer cluster;coupling (computer programming);experiment;fat tree;multitenancy;network topology;quality of service;software repository;tree network	Rongzhen Li;Qingbo Wu;Yusong Tan;Jianfeng Zhang;Xiaoling Li;Jie Lin	2016	2016 7th International Conference on Cloud Computing and Big Data (CCBD)	10.1109/CCBD.2016.051	computer science;application software;real-time computing;network topology;distributed computing;software;cloud computing;restrict	HPC	-25.93860062296854	57.153132689010015	26949
ecb3c0a94cb98fe88aea05daa135aa2696ac9223	parallel image processing applications on a network of workstations	tratamiento paralelo;distributed memory;network of workstations;prediccion;estacion trabajo;image processing;traitement parallele;limiting factor;multiprocessor;binary image;programming environment;convolution;high speed networks;station travail;distributed computing;procesamiento imagen;convolucion;imagen nivel gris;traitement image;atm networks;algorithme;parallel imaging;algorithm;temps calcul;distributed memory multiprocessor;workstation;convolution algorithm;parallel image processing;image niveau gris;network of workstation;image binaire;parallel computer;imagen binaria;performance prediction;express;tiempo computacion;computation time;multiprocesador;experimental measurement;communication;grey level image;comunicacion;prediction;parallel processing;algoritmo;multiprocesseur	Concurrent computing on networks of distributed computers has gained tremendous attention and popularity in recent years. In this paper, we use this computing environment for the development of efficient parallel image convolution applications for grey-level images and binary images. Significant speedup was achieved using different image sizes, kernel sizes, and number of workstations. We also present a performance prediction model that agrees well with our experimental measurements and allows the highest speedup to be predicted from the knowledge of the ratio of the computation time to the communication time. The main limiting factor in our programming environment is the bandwidth of the network. Thus, it seems with emerging high-speed networks such as ATM networks, parallel computing on networks of distributed computers can be a very attractive alternative to traditional parallel computing on SIMD and MIMD multiprocessors in executing computationally intensive applications in general and image processing applications in particular.	atm turbo;algorithm;bandwidth (signal processing);binary image;byte;computation;computer cluster;concurrent computing;convolution;echo (command);emergence;fragmentation (computing);image processing;image resolution;integrated development environment;linear function;mimd;p (complexity);parallel computing;pattern matching;performance prediction;ps (unix);run time (program lifecycle phase);simd;speedup;time complexity;workstation;xfig	Chi-kin Lee;Mounir Hamdi	1995	Parallel Computing	10.1016/0167-8191(94)00068-L	parallel processing;parallel computing;multiprocessing;limiting factor;distributed memory;workstation;prediction;binary image;image processing;computer science;theoretical computer science;operating system;distributed computing;convolution	HPC	-15.936837471376023	43.27543759576565	26964
1f179b9b360f945cbad8a8f25b2ed97ed077f6d4	model checking of consensus algorit	verification;distributed algorithms;consensus;finite unbounded timestamp representation;fault tolerant;distributed computing state space methods computational modeling fault tolerant systems fault tolerance distributed algorithms algorithm design and analysis mathematical model formal verification power system modeling;computer model;distributed computing;asynchronous algorithm verification;fault tolerant distributed systems;standard model;asynchronous algorithm;formal verification;model checking;heard of model consensus algorithm model checking asynchronous algorithm verification fault tolerant distributed computing finite unbounded timestamp representation;state space;heard of model;formal verification distributed algorithms;fault tolerant distributed computing;consensus algorithm model checking;heard of ho model	We show for the first time that standard model checking allows one to completely verify asynchronous algorithms for solving consensus, a fundamental problem in fault-tolerant distributed computing. Model checking is a powerful verification methodology based on state exploration. However it has rarely been applied to consensus algorithms, because these algorithms induce huge, often infinite state spaces. Here we focus on consensus algorithms based on the Heard-Of model, a new computation model for distributed computing. By making use of the high abstraction level provided by this computation model and by devising a finite representation of unbounded timestamps, we develop a methodology for verifying consensus algorithms in every possible state by model checking.	abstraction layer;approximation algorithm;distributed computing;fault tolerance;model checking;model of computation;verification and validation	Tatsuhiro Tsuchiya;André Schiper	2007	2007 26th IEEE International Symposium on Reliable Distributed Systems (SRDS 2007)	10.1109/SRDS.2007.20	model checking;standard model;distributed algorithm;fault tolerance;real-time computing;verification;consensus;formal verification;computer science;state space;theoretical computer science;distributed computing;abstraction model checking	Logic	-22.416775961886337	43.05292266575023	26977
adbaa1a0b95877584db63f984b3281c92df41142	cluster and grid computing for solving large structural biology problems	structural biology;grid computing		computer cluster;grid computing	Dan C. Marinescu;Yongchang Ji;Gabriela M. Marinescu	2002	Sci. Ann. Cuza Univ.		grid computing;theoretical computer science;structural biology;computational science;computer science	HPC	-8.615156211049186	37.70905804418932	26995
8735162209a28eb27b8e8b0169c86278c41bdf7f	performance analysis of embedded software using implicit path enumeration	optimization;embedded computing;real time systems;embedded software;hardware;embedded processor;real time;application software;integer linear programming;embedded system;satisfiability	Embedded computer systems are characterized by the presence of a processor running application specific dedicated software. A large number of these systems must satisfy real-time constraints. This paper examines the problem of determining the extreme (best and worst) case bounds on the running time of a given program on a given processor. This has several applications in the design of embedded systems with real-time constraints. An important aspect of this problem is determining which paths in the program are exercised in the extreme cases. The state of the art solution here relies on an explicit enumeration of program paths. This runs out of steam rather quickly since the number of feasible program paths is typically exponential in the size of the program. We present a solution for this problem that does not require an explicit enumeration of program paths, i.e., the paths are considered implicitly. This solution is implemented in the program cinderella1 which currently targets a popular embedded processor --- the Intel i960. The preliminary results of using this tool are also presented here.	embedded software;profiling (computer programming)	Yau-Tsun Steven Li;Sharad Malik	1995		10.1145/216636.216666	embedded system;application software;parallel computing;real-time computing;integer programming;embedded software;computer science;operating system;distributed computing;programming language;satisfiability	EDA	-22.920188027250507	36.386955669205925	26998
36eacbc2e4588f588525952385146a9aa8ec4b9d	scalable real-time system design using preemption thresholds	preemptive scheduling;object oriented methods;multiprocessing programs;object oriented design;processor scheduling;task model;multiprocessing programs real time systems processor scheduling task analysis object oriented methods;real time systems runtime object oriented modeling system analysis and design timing design methodology job design switches control systems scalability;fixed priority;schedulability analysis;automatic implementation model synthesis scalable real time system design preemption thresholds schedulability analysis techniques fixed priority preemptive scheduling timing issues tasking architecture specification task execution time estimation preemptive multi tasking model fixed priority scheduling theory object oriented design methods concurrent jobs run time overhead minimization context switches memory savings nonpreemptive job groups shared stack space parametric control preemptability control priority based system schedulability scalability;task analysis;time use;fixed priority scheduling;real time systems	Thematurityof schedulabiltyanalysistechniquesfor fixed-prioritypreemptiveschedulinghasenabled the consider ation of timing issuesat designtime usinga specificationof the taskingarchitecture and estimatesof executiontimesfor tasks.While successful, this approach haslimitationssincethe preemptive multi-taskingmodeldoesnotscalewell for a largenumberof tasks,andthefixedpriority schedulingtheory doesnot work well with manyobject-orienteddesignmethods.In this paperwepresentan approach that usesa scalableimplementationarchitecturewhere designlevel tasksaregroupedinto a smallernumberof run-timethreadsduring implementation.Theschedulabilityanalysisfor this implementationarchitecture is basedon the preemptionthresholdschedulingmodel. We showthat our approach providessignificant advantagesoveroneusingfixed-priority preemptiveschedulingarchitecture. Thebenefitsincludehigher schedulabilityfor small numberof tasks,and lower run-timeoverheads, and hencebetterscalability. We developalgorithmsthat allow designtime consider ation of schedulability, and automaticsynthesisof an implementationmodelto minimizerun-timeoverheads.	preemption (computing);real-time operating system;real-time transcription;scheduling (computing)	Manas Saksena;Yun Wang	2000		10.1109/REAL.2000.895993	fair-share scheduling;fixed-priority pre-emptive scheduling;parallel computing;real-time computing;earliest deadline first scheduling;dynamic priority scheduling;computer science;rate-monotonic scheduling;operating system;object-oriented design;deadline-monotonic scheduling;task analysis;distributed computing;preemption	Embedded	-9.567589109268871	60.127173233863125	27008
8df96b169297f2eb284355c121ba451f5b38d24a	objnandsim: object-based nand flash device simulator	paged storage digital simulation flash memories;simulator portability object based nand flash device simulator objnandsim onfs system performance redundant software layers garbage collection overhead performance analysis algorithm modeling design verification hardware behaviors nand flash memories object based ftl functionalities object storage management physical page management code modularity simulator extendability;indexes prototypes emulation kernel lenses hardware flash memories	An object-based NAND flash storage system (ONFS) is proposed to overcome the architectural limitation of the existing block-based storage system. The ONFS can improve system performance by removing redundant software layers and reducing garbage collection overhead. However, the research progress of ONFS is significantly hindered due to lack of appropriate simulation tools. In this work, we present ObjNandsim - an object-based NAND flash device simulator that is developed to support various research needs of ONFS such as performance analysis, algorithm modeling, design verification, etc. ObjNandsim emulates hardware behaviors of NAND flash memories and implements object-based FTL functionalities, including object storage management, physical page management and garbage collection. In addition, ObjNandsim provides a well-defined interface and code modularity, ensuring simulator's extendability and portability. The results of some example experiments validate the capabilities and efficacy of ObjNandSim.	algorithm;benchmark (computing);computer data storage;debugging;emulator;experiment;extensibility;ftl: faster than light;flash memory;garbage collection (computer science);ibm notes;loadable kernel module;object storage;object-based language;overhead (computing);semiconductor device modeling;simulation;software portability;user space	Jie Guo;Chuhan Min;Tao Cai;Hai Li;Yiran Chen	2016	2016 5th Non-Volatile Memory Systems and Applications Symposium (NVMSA)	10.1109/NVMSA.2016.7547179	parallel computing;real-time computing;computer hardware;computer science	Embedded	-11.35793661351852	52.3563300703264	27018
5f95748ee1f6fac0ce584a3e1c7f85ac434fca69	research on service model of content delivery grid	computational grid;service orientation;distributed computing;orientado servicio;grid;service model;prospectiva;prospective;rejilla;system design;content delivery;grille;calculo repartido;oriente service;calcul reparti;service oriented	Content delivery grid is a new kind of service-oriented grid different from computational grid. We propose a novel service model of content delivery grid in this paper, and then describe the main components, key services, relationships and parameters of the modeled content delivery environment. These items make content delivery grid really stand out from other traditional content delivery models. Furthermore, this paper describes the delivery process of this model. As part of this study, this paper demonstrates a prototype system design based on this novel service model, and analyses the contractive experiment results obtained for the prototype system. At last, we analyze the prospective research direction and challenges.		ZhiHui Lv;Shiyong Zhang;YiPing Zhong	2004		10.1007/978-3-540-24655-8_35	simulation;computer science;operating system;service-oriented modeling;database;distributed computing;grid;world wide web;systems design	HPC	-29.144383707880138	43.552157302110984	27036
ef9b6f9925bc4c0ed0c15ea855f231b8d582e24a	vhdl vs. bluespec system verilog: a case study on a java embedded architecture	bluespec;embedded systems;datavetenskap datalogi;java processor	This paper compares two hardware design flows, based on the classic VHDL on one side and the relatively new Blue-spec System Verilog (BSV) on the other side. The comparison is based on a case study of a Java embedded architecture, comprising a Java native processor and a memory management unit. The processor is a micro-programmed, pipelined, Java-optimized processor (JOP), initially written in VHDL, and its BSV re-designed match BLUEJEP. Its memory management unit implements the bytecodes dealing with memory allocation, along with a mark-compact garbage collector. The two design flows are examined from several points of view, including both quantitative and qualitative measures. Based on this design experience, we conclude that the new high-abstraction level languages, such as BSV, offer in comparison to register-transfer (RT) level classic approaches roughly the same trade-offs that C++ offers vs. assembly language in the software world.	abstraction layer;assembly language;c++;computer performance;embedded system;fpga prototyping;field-programmable gate array;garbage collection (computer science);hardware description language;international federation for information processing;itanium;james hoe;java optimized processor;java processor;lecture notes in computer science;memory management unit;microarchitecture;pipeline (computing);real-time operating system;real-time transcription;spec#;springer (tank);systemc;systemverilog;vhdl;verilog;wunderlich (vacuum tube)	Flavius Gruian;Mark Westmijze	2008		10.1145/1363686.1364037	computer architecture;parallel computing;real-time computing;computer science;operating system;embedded java;programming language	Arch	-22.46615755384466	34.30439977457304	27069
aa4dfd27c58276831b4a153a0ebce13f80cee392	transaction scheduling using dynamic conflict avoidance	transaction scheduling;multiprocessor systems;concurrent programming;software transaction memory;interdisciplinar;atomic blocks;concurrent execution;computer programming;transaction throughput;scheduling;benchmark suites;pro active approach;java programming language;artigo;rate increase;conflict avoidance;transactional memory;improving systems;contention management;management;multi processor systems;management policy;managers	Software transaction memory (STM) systems have been used as an approach to improve performance, by allowing the concurrent execution of atomic blocks. However, under high-contention workloads, STM-based systems can considerably degrade performance, as transaction conflict rate increases. Contention management policies have been used as a way to select which transaction to abort when a conflict occurs. In general, contention managers are not capable of avoiding conflicts, as they can only select which transaction to abort and the moment it should restart. Since contention managers act only after a conflict is detected, it becomes harder to effectively increase transaction throughput. More proactive approaches have emerged, aiming at predicting when a transaction is likely to abort, postponing its execution. Nevertheless, most of the proposed proactive techniques are limited, as they do not replace the doomed transaction by another or, when they do, they rely on the operating system for that, having little or no control on which transaction to run. This article proposes LUTS, a lightweight user-level transaction scheduler. Unlike other techniques, LUTS provides the means for selecting another transaction to run in parallel, thus improving system throughput. We discuss LUTS design and propose a dynamic conflict-avoidance heuristic built around its scheduling capabilities. Experimental results, conducted with the STAMP and STMBench7 benchmark suites, running on TinySTM and SwissTM, show how our conflict-avoidance heuristic can effectively improve STM performance on high contention applications.	benchmark (computing);function overloading;heuristic (computer science);linearizability;operating system;overhead (computing);proactive parallel suite;run time (program lifecycle phase);scheduling (computing);software transactional memory;throughput;transaction processing;user space	Daniel Nicácio;Alexandro Baldassin;Guido Araujo	2012	International Journal of Parallel Programming	10.1007/s10766-012-0205-x	extreme transaction processing;transactional memory;parallel computing;real-time computing;concurrent computing;transaction processing;conflict avoidance;distributed transaction;computer science;operating system;x/open xa;computer programming;distributed computing;online transaction processing;programming language;scheduling	OS	-13.784882328446724	48.8591512502014	27077
863383466c0d78c7a733c6eb6d86d74697f11f0d	a resource-centric application classification approach		In this paper we present a resource-centric application classification approach that monitors data flow along the path from main memory to the cores to locate spots of high resource utilization and potential resource contention. We designate three application classes, i.e. streaming applications, last-level cache sensitive applications and applications that restrict their activity either within the cores or in the private levels of the memory hierarchy. Our classification scheme can form the basis for a number of preliminary prediction models that are capable of predicting application interference with high accuracy.	cpu cache;cellular automaton;computer data storage;dataflow;interference (communication);memory hierarchy;resource contention	Alexandros-Herodotos Haritatos;Konstantinos Nikas;Georgios I. Goumas;Nectarios Koziris	2016		10.14459/2016md1286948	parallel computing;computer science;theoretical computer science;multiclass classification	Metrics	-5.516624235458215	52.56935943825379	27078
091d09a257c46b1b38e98780444e5df813d8143b	pbddr: probe-based deadlock detection and recovery strategy for component-based systems	archstudio tool pbddr component based systems correctness software systems probe based deadlock detection and recovery cbs formal semantic model communicating sequential processes abstract interaction behavior statical deadlock analysis deadlock detection algorithm dda deadlock loops timeliness dlc deadlock recovery algorithm dra;object oriented programming;probe;based system;software architecture;communicating sequential processes;deadlock based system software architecture csp probe;concurrency control;deadlock;csp;software architecture communicating sequential processes concurrency control object oriented programming;system recovery connectors ports computers arrays semantics time factors vectors	Correctness is a critical requirement for software systems and one of the key factors in correctness is that the system be deadlock-free. In this paper, we present a Probe-Based Deadlock Detection and Recovery (PBDDR) strategy for Component-based System (CBS) which brings four contributions. First, we define a formal semantic model by using Communicating Sequential Processes (CSP) to abstract interaction behavior for statically analyzing deadlock. Second, we propose a Deadlock Detection Algorithm (DDA) to find deadlock loops in a CBS. Third, we consider two qualities of concern, Timeliness (i.e., response time) and DLC (i.e., How many deadlock loops that a component involved in). Then we give a Deadlock Recovery Algorithm (DRA) to evaluate and replace the component to solve the deadlock problem based on above quality concerns. Finally, we implement our approach using the Arch Studio tool. Experimental results show that our approach has reasonable performance.	algorithm;communicating sequential processes;correctness (computer science);deadlock;dynamic resolution adaptation;mean time between failures;response time (technology);software system;xml	Chen Li;Linpeng Huang;Luxi Chen;Weichao Luo;Xu Li	2012	2012 19th Asia-Pacific Software Engineering Conference	10.1109/APSEC.2012.33	real-time computing;wait-for graph;computer science;theoretical computer science;deadlock;concurrency control;communicating sequential processes;distributed computing;edge chasing;programming language;deadlock prevention algorithms	SE	-33.02493214255117	34.23506220175144	27109
b2d4dcc29be84c364da99b7b6900bcfb56b93c08	insights for exascale io apis from building a petascale io api	performance evaluation;cuda;gpgpu;xeon phi;swendsen wang multi cluster algorithm;many core processors;ising model;graph algorithms	Near the dawn of the petascale era, IO libraries had reached a stability in their function and data layout with only incremental changes being incorporated. The shift in technology, particularly the scale of parallel file systems and the number of compute processes, prompted revisiting best practices for optimal IO performance.  Among other efforts like PLFS, the project that led to ADIOS, the ADaptable IO System, was motivated by both the shift in technology and the historical requirement, for optimal IO performance, to change how simulations performed IO depending on the platform. To solve both issues, the ADIOS team, along with consultation with other leading IO experts, sought to build a new IO platform based on the assumptions inherent in the petascale hardware platforms.  This paper helps inform the design of future IO platforms with a discussion of lessons learned as part of the process of designing and building ADIOS.	application programming interface;best practice;library (computing);petascale computing;simulation	Jay F. Lofstead;Robert Ross	2013	2013 SC - International Conference for High Performance Computing, Networking, Storage and Analysis (SC)	10.1145/2503210.2503238	ising model;parallel computing;real-time computing;computer science;operating system;distributed computing;xeon phi;general-purpose computing on graphics processing units	HPC	-7.879818202194192	40.6389281006264	27149
e0a109eb85237621bfd3da3784cf21a983b7da72	a comparative analysis of performance of shared memory cluster computing interconnection systems		ion No abstraction Simple abstraction No abstraction Full abstraction Availability High Higher Less Same as that of physical cluster Architecture Communication on the fly Distributed data structure in linked base type Hierarchical memory Virtual machine monitor with virtual cluster Load balancing Centralized dynamic load balancing Distributed dynamic load balancing Hierarchical load balancing Virtual cluster server centralized dynamic load balancing Fault tolerance Shared memory checkpointing Time based coordinated checkpointing Hierarchical checkpointing Replicated and distributed checkpointing Scalability Limited scalability Highly scalable Hard to scale Good scalability Latency Lower Higher Low High Bandwidth Higher Lower High Low Programming Easier to program Easy to program Critical to program Hard to program End user Difficult to use Easier to use Hard to design and use Easy to use Execution Fastest Fast Faster Moderate fast Cost Cheapest Moderate Cheap High an independent programming language with a library of mathematical functions capable of treating complex problems. Figure 5 compares the four types of cluster architectures based on their execution times. The results infer that the distributed shared memory cluster has the highest scalability with fast execution. Figure 6 shows the comparison of load balancing in different types of shared memory clusters. We compare the number of tasks with response time in Figure 6. The shared memory cluster is found to be the best as compared to three others in terms of load balancing. Figure 7 shows the comparison of fault tolerance in different types of clusters.There, we compare the number of nodes with cluster availability. As shown in Figure 7, the distributed shared memory cluster provides the high availability. In virtual shared memory cluster, virtual machines may not handle the load when all physical nodes stop working at the same time. Hence, virtual shared memory cluster provides almost the same availability of the underlying physical cluster connected through the distributed sharedmemory cluster environment. Table 1 shows the summary of comparison of performance of the four types of shared memory clusters. 5. Conclusions In this paper, a comparative analysis of four different types of shared memory cluster computing systems is made. Our comparison mainly concentrates on the cluster architecture, load balancing, and fault tolerance aspects of the above said clusters. The important findings are presented. The hierarchical shared memory cluster is observed to support flexible form of communication through shared memory. It also performs much better and enjoys high availability. The distributed shared memory clusters intelligently balances the load among nodes with the work stealing approach. The virtual distributed shared memory clusters hide dynamic changes of physical hardware configuration of underlying distributed shared memory cluster. This architecture also allows better fault tolerance of the system. Conflict of Interests The authors declare that there is no conflict of interests regarding the publication of this paper. Journal of Computer Networks and Communications 9		Minakshi Tripathy;Chita Ranjan Tripathy	2014	Journal Comp. Netw. and Communic.	10.1155/2014/128438	shared disk architecture;uniform memory access;distributed shared memory;shared memory;parallel computing;real-time computing;distributed memory;computer science;distributed computing;computing with memory	HPC	-13.141900939778214	46.81948620509172	27170
7d5f01170e94c8873f86efd12407989abcb35917	active objects in tcoz	formal specification;real time object oriented specification active objects tcoz passive objects object z timed communicating object z timed csp process construct timing construct;temporal logic;electrical capacitance tomography object oriented modeling timing power system modeling information technology yarn control system synthesis sensor phenomena and characterization actuators cultural differences;object oriented programming;z notation;communicating sequential processes;object oriented;active objects;temporal logic formal specification object oriented programming communicating sequential processes real time systems;real time systems	Active objects have their own thread of control and passive objects are controlled by others. In Object-Z, all objects are modelled as passive objects. Timed Communicating Object Z (TCOZ) extends the Object-Z notation with Timed CSP’s process and timing constructs. The blending of the concepts of object and non-terminating process leads to the notion of active object in TCOZ. This paper considers the concept of active object, its role and implications in formal real-time object-oriented specification.	active galactic nucleus;active object;alpha compositing;divergence (computer science);newman's lemma;object-z;real-time clock;z notation	Jin Song Dong;Brendan P. Mahony	1998		10.1109/ICFEM.1998.730566	method;real-time computing;object model;computer science;object-oriented design;distributed computing;distributed object;programming language;object-oriented programming	Robotics	-32.01342072616036	34.16504587819776	27183
cc470b7fa5d0941cb972f763e0e244b2507af751	implementation of ccnugrid-based drug virtual screening applications using workflow techniques	drugs;biology computing;ccnugrid based drug virtual screening;chemistry computing;interactive tool ccnugrid based drug virtual screening workflow technique grid middleware web services authorization security quality of service visualization technology;grid middleware;web service;virtual screening;hmg coa reductase;interactive tool;web services;workflow technique;middleware;web services biology computing chemistry computing drugs grid computing middleware;authorization;quality of service;parallel programs;security;grid computing;drugs inhibitors pharmaceutical technology visualization packaging middleware web services authorization security quality of service;visualization technology	Grid-based virtual screening of new potential potent inhibitors has been able to be performed on Center China Normal University Grid (CCNUGrid), by joint of using workflow techniques and Dock 5.0 parallel program packages. The present grid middleware is designed by using Web services technologies and standards, which provides supports for authorization, workflow, security, quality of service aspects. In this work, one of the applications, the structure-based rational quest for potential novel inhibitors of human HMG-CoA reductase by virtual screening, is described. It includes a set of complete chain of tools necessary for entire process from defining an effective pharmacophore to finding more active hit compounds with pharmaceutical activation and visualization technology. The present workflow environment is utilized to implement the application for parameter setting, interactive tools, virtual screening from database and result visualization etc. It is concluded that the present workflow provides benefits to flexibility, reusability and scalability and is a more effective and convenient tools to grid-based virtual screening	authorization;computation;high-throughput satellite;middleware;parallel computing;pharmacophore;projection screen;quality of service;scalability;speedup;throughput;virtual screening;web service	Yanliang Ren;Qingye Zhang;Jian Wan;Xiangcheng Huang;Peng Xie;Guangfu Yang	2006	2006 Fifth International Conference on Grid and Cooperative Computing Workshops	10.1109/GCCW.2006.55	web service;computer science;information security;operating system;data mining;database;law;world wide web;workflow management system;workflow engine;workflow technology	HPC	-33.15171376125713	53.730541805863936	27194
2f6d28dc4667b5ea09dafb02746af96768478f6d	heterogeneous code cache: using scratchpad and main memory in dynamic binary translators	storage allocation;flash memory;cache storage;random access memory;scratchpad;storage allocation cache storage embedded systems program interpreters;software management;program interpreters;software caching;system on a chip;embedded system;heterogeneous code cache management;embedded systems;embedded system memory management scanning probe microscopy application software computer science program processors permission technology management buffer storage random access memory;software managed code cache;storage allocation heterogeneous code cache management scratchpad memory main memory dynamic binary translator embedded system software managed code cache;software caching dynamic binary translation scratchpad;dynamic binary translation;scratchpad memory;context;benchmark testing;main memory;management policy;dynamic binary translator	Dynamic binary translation (DBT) can be used to address important issues in embedded systems. DBT systems store translated code in a software-managed code cache. Unlike general-purpose systems, embedded systems often have specialized memory resources, such as a fast scratchpad memory, that can be used to mitigate DBT performance overhead. This paper presents the Heterogeneous Code Cache (HCC), a code cache split among scratchpad and main memory. We explore several HCC management policies and show that, on average, an HCC outperforms a code cache allocated only to scratchpad or only to main memory.	binary translation;cpu cache;computer data storage;embedded system;general-purpose markup language;human-centered computing;overhead (computing);scratchpad memory	José Baiocchi;Bruce R. Childers	2009	2009 46th ACM/IEEE Design Automation Conference	10.1145/1629911.1630103	system on a chip;embedded system;benchmark;parallel computing;real-time computing;cache coloring;page cache;cache;computer science;operating system;cache algorithms;cache pollution;cache-only memory architecture	EDA	-6.330448128610621	50.254120612413175	27198
4d5ae8ce744ca653d94874cdb70539cf1881370a	compiling c for the earth multithreaded architecture	program graph;remote access;high level c programs;eficacia sistema;earth yarn parallel processing computer architecture multithreading programming profession program processors delay communication system control high level languages;benchmark programs;high level languages;architecture systeme;yarn;acceso remoto;compilateur;compiling for parallel architectures;storage access;systeme multiprocesseur memoire repartie;langage c;programacion paralela;etude experimentale;generation code;earth;data locality;acces a distance;irregular parallelism;generacion codigo;performance systeme;code generation;parallel programming;ejecucion programa;program library;compiler;system performance;program execution;algorithme;algorithm;computer architecture;multithreaded execution model;c language;parallel architectures;graphe programme;programming profession;scheduling;execution programme;sistema multiprocesador memoria distribuida;multithreaded architecture;acces memoire;bibliotheque programme;earth multithreaded architecture;acceso memoria;irregular locality;benchmark programs earth multithreaded architecture irregular parallelism irregular locality multithreaded execution model compiler support high level c programs compiler;arquitectura sistema;ordonamiento;langage parallele;parallel language;distributed memory multiprocessor system;parallel architecture;communication system control;system architecture;program compilers;grafo programa;parallel languages;estudio experimental;program processors;parallel processing;ordonnancement;biblioteca programa;compiler support;compilador;lenguaje c;programmation parallele;multithreading;algoritmo	Multithreaded architectures provide an opportunity for efficiently executing programs with irregular parallelism and/or irregular locality. This paper presents a strategy that makes use of the multithreaded execution model without exposing multithreading to the programmer. Our approach is to design simple extensions to C, and to provide compiler support that automatically translates high-level C programs into lower-level threaded programs. In this paper we present EARTH-C our extended C language which contains simple constructs for specifying control parallelism, data locality, shared variables and atomic operations. Based on EARTH-C, we describe compiler techniques that are used for translating to lower-level Threaded-C programs for the EARTH multithreaded architecture. We demonstrate our approach with six benchmark programs. We show that even naive EARTH-C programs can lead to reasonable performance, and that more advanced EARTH-C programs can give performance very close to hand-coded threated-C programs.	benchmark (computing);compiler;high- and low-level;linearizability;locality of reference;multithreading (computer architecture);parallel computing;programmer;shared variables;task parallelism;thread (computing)	Laurie J. Hendren;Xinan Tang;Yingchun Zhu;Shereen Ghobrial;Guang R. Gao;Xun Xue;Haiying Cai;Pierre Ouellet	1997	International Journal of Parallel Programming	10.1007/BF02699905	parallel processing;computer architecture;compiler;parallel computing;multithreading;computer science;operating system;earth;programming language;scheduling;high-level programming language;code generation	Arch	-15.426892618369843	41.78972344050008	27227
35c1af16c95f805a81d8ac13841c79bf7644045d	cache-related preemption delay analysis for multi-level inclusive caches	control systems;memory management;cache analysis;interference;crpd analysis;upper bound;estimation;timing analysis;program processors;delays	Cache-related preemption delay (CRPD) analysis is crucial when designing embedded control systems that employ preemptive scheduling. CRPD analysis for single-level caches has been studied extensively based on useful cache blocks (UCBs). As high-performance embedded processors are increasingly used, which are often equipped with multi-level caches, CRPD analysis for cache hierarchies also needs to be investigated. Recently, an approach has been proposed to estimate CRPD for multi-level non-inclusive caches. Since multi-level inclusive caches are also commonly used, especially in some multi-core processors, it becomes important to study how to analyze CRPD for inclusive cache hierarchies. However, as shown in this paper, new challenges appear due to the strict inclusion enforcement in the multi-level inclusive caches, which make the traditional UCB concept hard to use. In this paper, we propose a new concept of useful positive references (UPRs) to replace the UCB concept. Based on UPRs, we propose an approach to bound the additional cache misses due to a preemption in a two-level inclusive cache hierarchy. We present theoretical analysis to show the approach is safe, and we evaluate the proposed approach on a set of benchmarks to demonstrate its effectiveness. To the best of our knowledge, this is the first attempt to analyze CRPD for multi-level inclusive caches.	baseline (configuration management);benchmark (computing);cpu cache;central processing unit;computation;control system;embedded system;instruction set simulator;multi-core processor;multi-level cell;overhead (computing);preemption (computing);scheduling (computing);simulation	Zhenkai Zhang;Xenofon D. Koutsoukos	2016	2016 International Conference on Embedded Software (EMSOFT)	10.1145/2968478.2968481	embedded system;estimation;parallel computing;real-time computing;computer science;control system;operating system;distributed computing;interference;upper and lower bounds;static timing analysis;statistics;memory management	Embedded	-7.279440227588397	57.93643724116554	27257
774d93a13073221d3fb3fe4a9993f181a87056e3	a low-overhead constant-time lowest-timestamp-first cpu scheduler for high-performance optimistic simulation platforms	cpu scheduling;parallel discrete event simulation;optimistic synchronization;performance optimization	An approach to high-performance discrete event simulation consists of exploiting parallelization techniques. These rely on partitioning the simulation model into multiple, interacting simulation objects, also known as Logical Processes (LPs), which concurrently execute events on different CPUs and/or multiple CPU-cores. However, despite the tendency towards high degree of hardware parallelism, for relatively large models, multi-programming schemes are still needed in order to share a single CPU-core across multiple LPs. Consequently, priority management and CPU-scheduling remain central issues for the effectiveness of any parallel simulation environment. This article focuses on the optimistic approach to parallelism, which is based on speculative processing and maintains event-causality across concurrent LPs via rollback techniques. Specifically, the article presents a low-overhead constant-time implementation of the well known Lowest-Timestamp-First algorithm for the identification of the next LP to be CPU-dispatched. This proposal is suited for contexts where the optimistic simulation system conforms to the best-practice of keeping separate event lists for the hosted LPs. The implementation has been integrated in the open source  ROOT-Sim  (ROme OpTimistic Simulator) package. The effectiveness of the presented proposal is assessed via an extended performance study, carried out by relying on the  game of life  as the test-bed application.	central processing unit;overhead (computing);scheduling (computing);simulation	Francesco Quaglia	2015	Simulation Modelling Practice and Theory	10.1016/j.simpat.2015.01.009	parallel computing;real-time computing;simulation;computer science;operating system;distributed computing;scheduling	OS	-14.853289288346007	47.982580852093065	27283
090ed7726f797c6c68b7f71c2427cb6e104327e1	pgas-fmm: implementing a distributed fast multipole method using the x10 programming language	active messages;fast multipole method;journal article;parallel programming models;scientific computing;partitioned global address space pgas	The fast multipole method (FMM) is a complex, multi-stage algorithm over a distributed tree data structure, with multiple levels of parallelism and inherent data locality. X10 is a modern partitioned global address space language with support for asynchronous activities. The parallel tasks comprising FMM may be expressed in X10 using a scalable pattern of activities. This paper demonstrates the use of X10 to implement FMM for simulation of electrostatic interactions between ions in a cyclotron resonance mass spectrometer.	algorithm;data structure;fast multipole method;interaction;locality of reference;parallel computing;partitioned global address space;programming language;resonance;scalability;simulation;tree (data structure);x10	Josh Milthorpe;Alistair P. Rendell;Thomas Huber	2014	Concurrency and Computation: Practice and Experience	10.1002/cpe.3039	parallel computing;fast multipole method;computer science;theoretical computer science;operating system;database;distributed computing;programming language	PL	-10.951852216134345	39.28858965060397	27300
3840b950c117e159e681815c1493f4877d7f87c2	history-based schemes and implicit path enumeration	branch prediction;longest path	The Implicit Path Enumeration Technique is often used to compute the WCET of control-intensive programs. This method does not consider execution paths as ordered sequences of basic blocks but instead as sets of basic blocks with their respective execution counts. This way of describing an execution path is adequate to compute its execution time, provided that safe individual WCETs for the blocks are known. Implicit path enumeration has also been used to analyze hardware schemes like instructions caches or branch predictors the behavior of which depends on the execution history. However, implicit paths do not completely capture the execution history since they do not express the order in which the basic blocks are executed. Then the estimated longest path might not be feasible and the estimated WCET might be overly pessimistic. This problem has been raised for cache analysis. In this paper, we show that it arises more acutely for branch prediction and we propose a solution to tighten the estimation of the misprediction counts.	basic block;branch misprediction;branch predictor;cpu cache;integer programming;kerrison predictor;linear programming;longest path problem;run time (program lifecycle phase);worst-case execution time	Claire Maiza;Christine Rochange	2006			parallel computing;real-time computing;longest path problem;computer science;algorithm;branch predictor	Arch	-6.211458897235639	51.90598295240118	27319
09aff6848c284797adda3bdb38bbb1278641cef9	poster: pay as you go in the cloud: one watt at a time		Advancements in virtualization have led to the construction of large data centers that host thousands of servers and to the selling of virtual machines (VMs) to consumers under a per-hour rate. This current pricing scheme employed by cloud computing providers ignores the disparities in consumer usage and in its related infrastructural costs of providing the service to different users. We thus propose a new pricing model based on the liable power consumption of the VM, which we correlate to the VM's proportion of CPU and disk I/O usage. In the poster, we evaluate the fairness and practicality of our accountable power consumption model on various machines and storage types. We then demonstrate the benefits of the proposed pricing model by looking four consumer cases. Our work is undergoing further experimentation and we hope to expand our testing using cloud services.	central processing unit;cloud computing;data center;fairness measure;virtual machine	Kayo Teramoto;H. Howie Huang	2012	2012 SC Companion: High Performance Computing, Networking Storage and Analysis	10.1109/SC.Companion.2012.319	parallel computing;real-time computing;simulation;operating system;distributed computing;computer security;computer network	HPC	-25.14761446100287	60.141960059375386	27370
82be8926e3e8f9512bda4eafb1c9367faf1e53ad	concurrency control scheme for key-value stores based on infiniband	key value store;infiniband;rdma;nosql	Using InfiniBand technologies, the performance of key-value stores can be greatly improved because of RDMA features and the ultra-low latency of InfiniBand. However, maximizing the benefits of InfiniBand for key-value stores is still challenging because of the data consistency problem between RDMAs and CPU-aware memory accesses. In this paper, we propose a concurrency control scheme to utilize the RDMA features of InfiniBand in key-value stores. The proposed scheme efficiently handles the race conditions among GET and PUT operations on the key-value store.	attribute–value pair;central processing unit;concurrency (computer science);concurrency control;infiniband;key-value database;race condition;remote direct memory access	Joonhyouk Jang;Yookun Cho;Jinman Jung;Sanghee Yoon	2014		10.1145/2663761.2664239	parallel computing;real-time computing;computer science;operating system;sockets direct protocol	DB	-12.092248198199663	52.546831641116036	27385
2db613afb64da01dd87bc410325409752f99f9ef	data block prefetching and caching in a hierarchical storage model	storage models;storage hierarchies;performance improvement;data prefetching;evolutionary algorithm;prefetching and caching;analytical model	Storage subsystems have become one of the most important components in computer systems nowadays and have been expanded to include all three levels of memory hierarchy, namely the cache, the secondary and the tertiary storage. This paper presents a study of data block prefetching and caching over the two upper storage levels in a hierarchical storage model, by proposing techniques for data amortization from tertiary to secondary and from secondary to cache levels. Each level reserves a speci®c area for data prefetching and an evolutionary algorithm is proposed for identifying the data blocks to be prefetched in each of the two upper storage levels. An analytic model is proposed such that the cache, the secondary and the tertiary storage are appropriately parameterized in order to analyse the expected performance improvement due to prefetching. The data object prefetching approach is experimented under certain workload of requests referring to all storage levels and has shown signi®cant performance improvement with respect to request service times, as well as cache and secondary storage hit ratios. Ó 2000 Elsevier Science Inc. All rights reserved.	auxiliary memory;byte;cpu cache;cache (computing);computer data storage;evolutionary algorithm;glossary of computer graphics;hierarchical storage management;loss function;memory hierarchy;norm (social);optimization problem;requirement;simulation;software release life cycle;storage model	Athena Vakali	2000	Inf. Sci.	10.1016/S0020-0255(00)00045-1	parallel computing;real-time computing;computer science;artificial intelligence;machine learning;evolutionary algorithm;database	HPC	-16.874244427243596	45.19211130656878	27419
79e56c34993a3149b05fba038097f9d92fd29e06	the prim system: an alternative architecture for emulator development and use	sharable system;modern general-purpose computing system;prim approach;pdp-10 service;tenex timesharing system;emulator microcode;dec pdp-10;tenex file system;alternative architecture;emulator development;prim-like system;prim system;shared memory;software component	The architecture of PRIM is unique in coupling a powerful microprogrammable machine (the Standard Computer Corporation MLP-900) to a modern general-purpose computing system (the DEC PDP-10). The TENEX timesharing system running in the PDP-10 is responsible for scheduling use of the MLP-900. Emulator microcode runs in the MLP-900 under the control of a small resident executive that swaps its users and mediates references to PDP-10 services and shared memory. The PRIM system in the PDP-10 (also running under control of TENEX) provides emulators with access to the TENEX file system and peripherals. PRIM also permits on-line user control of an emulation and supports interactive symbolic debugging of both emulator microcode and target code for the various emulated machines. The resulting sharable system, accessible via the ARPANET to users anywhere, supports both emulator developers and users. This architecture has allowed the development of a more powerful and convenient tool with less effort than would have been possible on a stand-alone microprogrammable host. The hardware and software components of the PRIM system are described and the operation of PRIM is outlined from the user's viewpoint. Requirements for creating PRIM-like systems are discussed, and the PRIM approach is compared with other, more conventional approaches.	component-based software engineering;debug symbol;debugging;emulator;general-purpose markup language;microcode;online and offline;pdp-10;peripheral;prim's algorithm;requirement;scheduling (computing);shared memory;tops-20;time-sharing;user interface	Joel Goldberg;Alvin S. Cooperband;Louis Gallenson	1977			shared memory;embedded system;parallel computing;computer science;component-based software engineering;operating system;programming language	OS	-26.424079839708472	38.36505802410322	27425
89c74d950cfab42c9858a1391e85b0ca1d69115d	edge-computing-aware deployment of stream processing tasks based on topology-external information: model, algorithms, and a storm-based prototype	deployment;iot;topology big data storms internet of things optimization servers databases;apache storm edge computing aware deployment stream processing framework spf topology external information data exchange cloud centric big data processing;latency;stream processing;parallel processing big data cloud computing electronic data interchange;deployment stream processing iot latency	Stream Processing Frameworks (SPF, e.g., Apache Storm) are solutions that facilitate and manage the execution of processing topologies that consist of multiple parallelizable steps (or tasks) and involve continuous data exchange among these tasks. Stemming from the world of Cloud-centric Big Data processing, SPFs often fail to address certain requirements of Internet-of-Things systems. For example, existing deployment solutions ignore the fact that topology tasks can also be involved in other interactions and data-intensive communication flows, which are not taking place between the tasks, but between a task and another Internet-of-things entity, such as an actuator, a database, or a user. This paper describes SPF extensions for taking these interactions into account. The extensions are described both generically and as extensions of Apache Storm. In a simple evaluation upon a topology which involves topology-external interactions, we demonstrate how our solution can eliminate latency requirements violations and reduce Cloud-to-edge bandwidth consumption to 1/3 compared to Apache Storm.	algorithm;apache storm;big data;data-intensive computing;database;distributed computing;edge computing;entity;interaction;prototype;requirement;sender policy framework;software deployment;stemming;stream processing	Apostolos Papageorgiou;Ehsan Poormohammady;Bin Cheng	2016	2016 IEEE International Congress on Big Data (BigData Congress)	10.1109/BigDataCongress.2016.40	real-time computing;computer science;database;world wide web	DB	-20.880497732826555	54.807111126587515	27426
bb0642120cf8d45de16c08282ceaa3a838d14928	tachyon common lisp: an efficient and portable implementation of cltl2	technology development;optimization technique;code generation	Tachyon Common Lisp is an efficient and portable implementation of Common Lisp 2nd Edition. The design objective of Tachyon is to apply both advanced optimization technology developed for RISC processors and Lisp optimization techniques. The compiler generates very fast codes comparable to, and sometimes faster than the code generated by UNIX C compiler. Comparing with the most widely used commercial Common Lisp, Tachyon Common Lisp compiled code is 2 times faster and the interpreter is 6 times faster than the Lisp in Gabriel benchmark suit. Tachyon Common Lisp is the fastest among the Lisp systems known to the authors.	benchmark (computing);central processing unit;code;common lisp;compiler;fastest;mathematical optimization;unix	Atsushi Nagasaka;Yoshihiro Shintani;Tanji Ito;Hiroshi Gomi;Junichi Takahashi	1992		10.1145/141471.141561	read–eval–print loop;parallel computing;interpreter;computer science;fexpr;theoretical computer science;lisp;programming language;preprocessor;code generation	PL	-13.971820589299469	36.0171641024841	27447
32c5fa43cb6845cdeebf1dc7fed4ce965f678d97	virtual-cpu scheduling in the quest operating system	sporadic server;cpu scheduling;software execution predictability;quest operating system;cpu scheduling overhead virtual cpu scheduling quest operating system software execution safety software execution predictability software execution efficiency task integrated management i o event i o processing priority inheritance bandwidth preserving server policy pibs i o management sporadic server i o transfer vcpu scheduling infrastructure;cpu scheduling overhead;processor scheduling;radiation detectors;input output programs;real time operating system;software execution safety;virtual machines input output programs processor scheduling;servers;operating system;virtual machines;i o processing;scheduling;task integrated management;multicore processing;bandwidth preserving servers;hybrid system;time use;vcpu scheduling infrastructure;real time operating systems;priority inheritance bandwidth preserving server policy;bandwidth preserving servers real time operating systems scheduling;bandwidth;software execution efficiency;pibs i o management;i o transfer;technical report;virtual cpu scheduling;i o event;servers bandwidth instruction sets real time systems multicore processing radiation detectors operating systems;operating systems;instruction sets;real time systems	"""This paper describes the scheduling framework for a new operating system called """"Quest"""". The three main goals of Quest are to ensure safety, predictability and efficiency of software execution. For this paper, we focus on one aspect of predictability, involving the integrated management of tasks and I/O events such as interrupts. Quest's scheduling infrastructure is based around the concept of a virtual CPU (VCPU). Using both Main and I/O VCPUs, we are able to separate the CPU bandwidth consumed by tasks from that used to complete I/O processing. We introduce a priority-inheritance bandwidth-preserving server policy for I/O management, called PIBS. We show how PIBS operates with lower cost and higher throughput than a comparable Sporadic Server for managing I/O transfers that require small bursts of CPU time. Using a hybrid system of Sporadic Servers for Main VCPUs, and PIBS for I/O VCPUs, we show how to maintain temporal isolation between multiple tasks and I/O transfers from different devices. We believe Quest's VCPU scheduling infrastructure is scalable enough to operate on systems supporting large numbers of threads. For a system of 24 Main VCPUs, we observe a CPU scheduling overhead of approximately 0.3% when VCPU budget is managed in 1ms units."""	bus contention;cache (computing);central processing unit;entity;fragmentation (computing);hybrid system;input/output;interrupt;memory bus;multi-core processor;naive bayes classifier;operating system;overhead (computing);posix;priority inheritance;scalability;scheduling (computing);server (computing);temporal isolation;throughput	Matthew Danish;Ye Li;Richard West	2011	2011 17th IEEE Real-Time and Embedded Technology and Applications Symposium	10.1109/RTAS.2011.24	embedded system;parallel computing;real-time computing;real-time operating system;computer science;operating system;scheduling;i/o scheduling	Embedded	-9.916644801590147	56.95611943671051	27485
815285392b4c9f7f213381b64f60dc71cadf87c6	an analyzable memory controller for hard real-time cmps	wcet estimation;analyzable memory controller;ddrx sdram;shared hardware resources;hard real time cmp;memory access time predictability analyzable memory controller hard real time cmp multicore processors real time systems wcet estimation shared hardware resources jedec compliant ddrx sdram memory controller;microprocessor chips dram chips;jedec compliant ddrx sdram memory controller;memory access;worst case execution time;hard real time system;estimation;memory controller;memory access time predictability;worst case execution time wcet;multicore processors;cmp;worst case execution time wcet cmp ddrx sdram hard real time memory controller;article;program processors;dram chips;interference sdram multicore processing embedded system real time systems random access memory performance analysis hardware timing control system analysis;sdram;hard real time;microprocessor chips;real time systems	Multicore processors (CMPs) represent a good solution to provide the performance required by current and future hard real-time systems. However, it is difficult to compute a tight WCET estimation for CMPs due to interferences that tasks suffer when accessing shared hardware resources. We propose an analyzable JEDEC-compliant DDRx SDRAM memory controller (AMC) for hard real-time CMPs, that reduces the impact of memory interferences caused by other tasks on WCET estimation, providing a predictable memory access time and allowing the computation of tight WCET estimations.	access time;advanced mezzanine card;cas latency;central processing unit;computation;dynamic random-access memory;gddr sdram;memory controller;multi-core processor;real-time clock;real-time computing;real-time transcription;worst-case execution time	Marco Paolieri;Eduardo Quiñones;Francisco J. Cazorla;Mateo Valero	2009	IEEE Embedded Systems Letters	10.1109/LES.2010.2041634	multi-core processor;estimation;parallel computing;real-time computing;computer hardware;computer science;operating system;memory controller;worst-case execution time	Embedded	-8.431047884097419	58.53957420278364	27525
badce2b99e0f34886ce24af0165d3593305d7213	a porting and optimization of search for neighbour-particle in mps method for gpu by using openacc		"""Moving Particle Semi-implicit (MPS) method is a particle method used in fields such as computational fluid dynamics. It is classified as a particle method. Target fluids and objects are divided up into particles, and each particle interacts with its neighbour-particle. The search for neighbour-particle is the main bottleneck of the MPS method. In this paper, we port and optimize """"search for neighbour-particle"""" part in MPS method for GPU by using OpenACC. It accounted for 56% of all the processing time. We present three different optimizations and evaluated them with three different data sets; 25,704, 224,910 and 2,247,750 particles. We also use four different GPUs; NVIDIA K20c, GTX1080, P100(PCIe) and P100(NVlink). As a result, P100(NVlink) GPU achieves 41.5 times speed-up compared with 24 MPI process CPU version when the number of particles is 2,247,750."""	central processing unit;computational fluid dynamics;geforce;graphics processing unit;mathematical optimization;message passing interface;openacc	Takaaki Miyajima;Kenichi Kubota;Naoyuki Fujita	2017		10.1145/3120895.3120903	parallel computing;porting;internal medicine;pci express;cardiology;computational fluid dynamics;bottleneck;particle;medicine;particle number	HPC	-5.344462261194789	38.60641216850147	27574
902eb8ff329aac36b732ba00988eb2929fce1eb4	closed user groups in internet service centres	internet service centre;closed user group;security;access control;middleware;corba;authorisation	The paper presents a model for end-user directed access cont rol t services in Internet service centres that, beside the classical Inte rne services (e.g., e-mail), offer a multitude of new services (e.g., on-line conferencing and uctioning) over the Internet. The model is based on the concept of closed user groups. The ma in idea is that at creation time each service instance and its components are a ssigned to a user group previously formed by a subset of the end-users, and access co ntrol is performed for access attempts through checking the group assignment of th e accessed resource against the group memberships of the authenticated accessing end-u ser. Access control is directed c 1999 IFIP. Published in the Proceedings of the DAIS’99 Confe rence. Research partly funded by Swisscom Corporate Technology as well as partly funded by the Swiss National Science Foundation (SNSF) as part of the Swiss Priority Prog ramme Information and Communications Structures (SPP-ICS) under project numbers 5003-045364 an d 5003-054575.	access control;authentication;authorization;common object request broker architecture;computer programming;cryptography;denial-of-service attack;distributed computing;email;graphical user interface;international federation for information processing;internet;java;middleware;multicast;online and offline;programmer;scalability;self-propelled particles;switzerland;transaction processing;www	Sebastian Staamann;Levente Buttyán;Allan Coignet;Ernesto Ruggiano;Uwe G. Wilhelm;Marc Zweiacker	1999			computer science;information security;access control;operating system;common object request broker architecture;middleware;database;distributed computing;authorization;world wide web;computer security;computer network	Security	-33.21992766335034	52.534270704400754	27596
2992e804a3e1173c74c3487176c38d1de40c9ad4	modelling dynamic load-sharing in a distributed computing system	distributed computing system;dynamic loading		distributed computing	David Finkel	1990	Comput. Syst. Sci. Eng.		computer science;distributed design patterns	DB	-29.38294649190277	46.787929202072924	27640
d42871e7ac5a2f656ee118c2f1f89527c2adf091	an agent-based deadlock detection/resolution algorithm for the and model	distributed data;control systems;memory management;detection algorithms;agent based;deadlock detection;resource management;probes;imaging phantoms;system recovery;system recovery detection algorithms safety computer science proposals probes imaging phantoms resource management control systems memory management;safety;computer science;proposals	Previous edge-chasing Deadlock Detection algorithms for Distributed Data Base systems (DDBS) have the n steps time limitation to detect a deadlock cycle of size n in the wait-for graph (WFG). This paper proposes an agent based edge-chasing algorithm to speed up the detection process. The blocked nodes in our algorithm know their predecessors and successors simultaneously, enables they find the cycle of size 2 locally and the cycle of size n in n-2 (n\ge2) steps. The detection agents are assigned the originator’s priority to decrease the detection overhead, and they are forwarded or discarded momentarily to avoid the false detection. Our algorithm is built on an AND model, a retreat-inform scheme is adopted to deal with the cycle overlap problem. The correctness of the algorithm is formally proven by the invariant verification technique.	agent-based model;algorithm;correctness (computer science);deadlock;distributed database;edge chasing;overhead (computing);verification and validation;wait-for graph	Xin Cheng;Xiaozong Yang;Feng Jin	2005	Sixth International Conference on Parallel and Distributed Computing Applications and Technologies (PDCAT'05)	10.1109/PDCAT.2005.68	parallel computing;real-time computing;simulation;computer science;resource management;deadlock;operating system;database;distributed computing;edge chasing;programming language;computer security;deadlock prevention algorithms;algorithm;memory management	EDA	-22.750402382572773	46.62772533837222	27666
4d91addef1140fb620ddf1acb23b20b2b505b807	a portable and adaptable fault tolerance solution for heterogeneous applications	heterogeneous systems;portability;checkpointing;fault tolerance;opencl	Heterogeneous systems have increased their popularity in recent years due to the high performance and reduced energy consumption capabilities provided by using devices such as GPUs or Xeon Phi accelerators. This paper proposes a checkpoint-based fault tolerance solution for heterogeneous applications, allowing them to survive fail-stop failures in the host CPU or in any of the accelerators used. Besides, applications can be restarted changing the host CPU and/or the accelerator device architecture, and adapting the computation to the number of devices available during recovery. The proposed solution is built combining CPPC (ComPiler for Portable Checkpointing), an application-level checkpointing tool, and HPL (Heterogeneous Programming Library), a library that facilitates the development of OpenCL-based applications. Experimental results show the low overhead introduced by the proposal and prove its portability and adaptability benefits.	application checkpointing;central processing unit;computation;fail-stop;fault tolerance;graphics processing unit;heterogeneous computing;linpack benchmarks;opencl api;overhead (computing);software portability;transaction processing system;xeon phi	Nuria Losada;Basilio B. Fraguela;Patricia González;María J. Martín	2017	J. Parallel Distrib. Comput.	10.1016/j.jpdc.2017.01.020	fault tolerance;parallel computing;real-time computing;computer science;operating system;distributed computing	HPC	-9.797272477897875	45.93569163096375	27715
c82f3ba2f1b61d027312286286da69346405392d	knowledge-based support of network management tasks using active information resource	knowledge management resource management information resources computer network management intelligent systems intelligent networks technology management computerized monitoring collaboration prototypes;multiagent system;agent based simulation;knowledge based systems information networks;intelligent facilities;network system;knowledge based support method;support system;knowledge based support method knowledge based support network management tasks active information resource complex system large system network system network administrators intelligent facilities;network management tasks;information networks;complex system;large system;active information resource;network management;scalability;distributed systems;networked systems;network administrators;knowledge based systems;knowledge based support;bioinformatics;knowledge base	A network system is a kind of large and complex systems and the network administrators are required exhaustive work to maintain the quality and functions of the network system. To reduce the load of administrators, systematic and intelligent facilities for the network management tasks should be realized and provided for administrators. In this paper, we propose a knowledge-based support method of the network management tasks using the active information resource (AIR) which has knowledges and functions for its information resource. Furthermore, a novel network management support system based on this method, called AIR-NMS, is also proposed by using the agent-based computing technologies. In the AIR-NMS, a lot of AIRs are defined and utilized in order to monitor and collect the status information of the network automatically. The AIRs are collaborated each other and inspect the behavior of the network. The network administrator can obtain useful supports for management in responses of AIR-NMS. Moreover, a prototype system is implemented to demonstrate and evaluate the essential functions of the AIR-NMS.	agent-based model;complex systems;no man's sky;prototype	Susumu Konno;Sameera Abar;Yukio Iwaya;Toru Abe;Tetsuo Kinoshita	2006	2006 IEEE/WIC/ACM International Conference on Intelligent Agent Technology	10.1109/IAT.2006.84	organizational network analysis;out-of-band management;element management system;intelligent computer network;network architecture;network management station;computer science;systems engineering;knowledge management;network security;data mining;network simulation;network management application;structure of management information	Robotics	-31.9571239281584	48.04459804967604	27721
861a94e142b043be5c61471903695cd9c7ff367b	a design to reduce write amplification in object-based nand flash devices	random access memory;write amplification;memory management;metadata;nand flash memories;system analysis and design;resource management;indexes	Write amplification is a major cause of performance and endurance degradations in NAND flash based storage systems. In an object-based NAND flash device, two causes of write amplification are onode partial update and cascading update. Updating one onode, a kind of small-sized object metadata, invokes partial page update (i.e., onode partial update) that incurs unnecessary migration of the un-updated data. An cascading update denotes that object metadata is updated in a cascading manner due to erase-before-program property of NAND flash memory. In this work, we propose a system design to alleviate onode partial update and cascading update. The proposed system design includes: 1) A multi-level garbage collection technique to minimize unnecessary data migration incurred by onode partial update; 2) A B+ table tree and selective cache design to reduce the write operations associated with cascading update; and 3) A power failure handling technique to guarantee system consistency. Experiment results show that our proposed design can achieve up to 20% write reduction compared to the best state-of-the-art.	amplifier;flash memory;garbage collection (computer science);object-based language;page table;systems design;tree (data structure);update (sql)	Jie Guo;Chuhan Min;Tao Cai;Yiran Chen	2016	2016 International Conference on Hardware/Software Codesign and System Synthesis (CODES+ISSS)	10.1145/2968456.2968465	parallel computing;real-time computing;computer science;database	EDA	-11.922760820202626	54.47789570421228	27772
57673644ddbb8cfe1cb9d81a56e2485390b8860d	rapid parallel systems deployment: techniques for overnight clustering	high availability;parallel systems;configuration management	Automated system deployment frameworks and configuration management systems have been in wide use for a number of years. However, due to increasing pressures to maintain high availability, coupled with the price effects of commodity servers, administrators may be required to deploy large numbers of systems in shorter time frames than is normally possible with available staff. In this paper, we describe a straightforward procedure using commonly-available infrastructure to enable rapid simultaneous deployment of hundreds of machines by temporary staff. As an example of the efficacy of this approach, we present a case study in rapid systems deployment at Purdue University. On May 5th, we deployed Purdue’s ‘‘Steele’’ cluster, installing over 500 compute nodes in a single business day.	configuration management;high availability;software deployment;system deployment	Donna Cumberland;Randy Herban;Rick Irvine;Michael Shuey;Mathieu Luisier	2008			simulation;computer science;operations management;configuration management;high availability;computer security	OS	-26.92877971038806	52.7638781594926	27837
e8248927b7aed5bc4942de21711a374deecdc8b9	a distributed application execution system for an infrastructure with dynamically configured networks	computers;pattern clustering;virtualization;monitoring containers ip networks virtualization resource management computers customer relationship management;customer relationship management;resource allocation;resource management;monitoring;middleware;ip networks;stackable file system technology distributed application execution system dynamically configured networks middleware suite gridars computing resources network resources resource allocation multisite administration heterogeneity application configuration information dynamic determination distributed resource monitoring asymmetric network reachability conventional computing cluster system wide area network environment slice construction application invocation contextualization information os level virtualization;virtualisation file organisation grid computing middleware operating systems computers pattern clustering resource allocation;grid computing;operating systems computers;containers;virtualisation;file organisation	We have been developing a middleware suite called GridARS that enables co-allocation of computing and network resources from multiple administration sites. In such middleware, it is important to provide each user application with a slice which is a set of dynamically allocated resources distributed across sites. However, there are the following issues in constructing such a slice automatically: 1) multi-site administration heterogeneity, 2) dynamic determination of application configuration information, 3) distributed resource monitoring, and 4) asymmetric network reachability. We design and implement an application execution system that provides each application with a slice, that mimics a conventional computing cluster system over the dynamically allocated resources. From the demonstration of the proposed system on an emulated wide area network environment, we confirmed that: first, the proposed system can fully automate resource allocation, slice construction, application invocation, and resource monitoring, in coordination with GridARS. Second, the proposed system can setup a slice quickly, even if the allocated resources are widely distributed and their communication latencies are high. This is because the overhead for gathering and distributing contextualization information is small, and OS-level virtualization and stackable file system technologies accelerate the contextualization process at each node.	accessibility;computer cluster;distributed computing;emulator;interoperability;job stream;memory management;middleware;open cloud computing interface;operating system;operating-system-level virtualization;oracle c++ call interface;overhead (computing);performance evaluation;reachability;stackable switch	Ryousei Takano;Hidemoto Nakada;Atsuko Takefusa;Tomohiro Kudoh	2012	4th IEEE International Conference on Cloud Computing Technology and Science Proceedings	10.1109/CloudCom.2012.6427503	real-time computing;virtualization;computer science;resource management;operating system;distributed computing	HPC	-29.88054178509712	53.66610283256407	27838
e9346e5d21ab6b5bd9c997010ea2f86390ef9d1b	a performance evaluation methodology in virtual environments	virtual machine;performance evaluation;performance evaluation methodology;virtual machine performance evaluation methodology virtual environments system virtualization;software performance evaluation;virtual environments;performance characterization;virtual machines;virtual environment application virtualization web server measurement internet file servers concurrent computing telecommunication computing virtual machining information technology;virtual environment;system virtualization;virtual machines software performance evaluation	System virtualization come into the spotlight again with the emerging virtual machine (VM) technologies (e.g., Parallels, VMware and Xen). With these market trends toward virtual environments, many research groups are developing evaluation tools to check the performance of virtual systems and their overheads. However, the performance characterization in virtual environments has not been established yet for many challenging issues. In this paper, we categorize four virtualization models for characterizing the performance of virtual environments and present an efficient evolution methodology to compare the performance of virtualized versus non-virtualized systems.	benchmark (computing);categorization;dbpedia;enterprise modelling;hardware virtualization;httperf;iozone;parallels desktop for mac;performance evaluation;virtual machine;virtual reality	Jiyong Jang;Saeyoung Han;Jinseok Kim;Sungyong Park;Seungjo Bae;Young Choon Woo	2007	7th IEEE International Conference on Computer and Information Technology (CIT 2007)	10.1109/CIT.2007.179	sysfs;embedded system;full virtualization;real-time computing;virtualization;temporal isolation among virtual machines;computer science;virtual machine;operating system;hardware virtualization	Visualization	-26.27049024797984	55.446203416713125	27884
2a3526a92a3765cffcb20f8a786fb2148190674f	high performance linear algebra package lapack90	linear algebra;lenguaje programacion;distributed system;interfase usuario;systeme reparti;programming language;ordinateur parallele;user interface;reseau ordinateur;program library;parallel computation;computer network;programme utilitaire;calculo paralelo;sistema repartido;utility program;algebre lineaire;ordenador paralelo;red ordenador;parallel computer;bibliotheque programme;langage programmation;algebra lineal;interface utilisateur;fortran;high performance;calcul parallele;biblioteca programa;programa utilitario	LAPACK90 is a set of LAPACK90 subroutines which interfaces FORTRAN90 with LAPACK. All LAPACK driver subroutines (including expert drivers) and some LAPACK computationals have both generic LAPACK90 interfaces and generic LAPACK77 interfaces. The remaining computationals have only generic LAPACK77 interfaces. In both types of interfaces no distinction is made between single and double precision or between real and complex data types.	double-precision floating-point format;lapack;linear algebra;subroutine	Jack J. Dongarra;Jerzy Wasniewski	1998		10.1007/3-540-64359-1_712	computer science;theoretical computer science;linear algebra;programming language;user interface;algorithm	Visualization	-17.284968564284362	41.40929192631423	27886
664983d8d5257ccaedb47865f649c0f06c902856	transparent deployment of scientific workflows across clouds - kubernetes approach		We present an end-to-end solution for automation of scientific workflow deployment and execution on distributed computing infrastructures. The solution integrates de-facto standard and widely adopted tools, including Terraform and Kubernetes, with our HyperFlow workflow management system. In such a solution, infrastructure providers have abstracted away thanks to generic Kubernetes layer. However, we also support other computing infrastructures, both containerized such as Kubernetes or Amazon ECS, and non-containerized, e.g. Amazon Lambda, in a single unified approach. The resulting solution enables execution of hybrid workflows that utilize multiple computing infrastructures and significantly lowers the complexity related to management of repeatable infrastructures for the execution of scientific workflows and conducting scientific workflow research.		Michal Orzechowski;Bartosz Balis;Krystian Pawlik;Maciej Pawlik;Maciej Malawski	2018	2018 IEEE/ACM International Conference on Utility and Cloud Computing Companion (UCC Companion)	10.1109/UCC-Companion.2018.00020	cloud computing;software deployment;automation;workflow management system;task analysis;workflow;distributed computing;computer science	HPC	-30.12201466473314	55.236606147544464	27937
eb192808fc847a98d695d193b1ca08a6184d4c9b	qos-aware fault-tolerant scheduling for real-time tasks on heterogeneous clusters	parallel and distributed system;resource utilization;heuristic;system reliability;real time systems fault tolerance fault tolerant systems quality of service scheduling algorithm heuristic algorithms;fault tolerant;qos aware fault tolerant scheduling;heterogeneous cluster;scheduling fault tolerant computing quality of service;real time;realtime task scheduling;heterogeneous clusters;passive execution scheme qos aware fault tolerant scheduling quality of service realtime task scheduling heterogeneous clusters parallel systems distributed systems;heuristic heterogeneous clusters real time scheduling fault tolerance quality of service qos;scheduling algorithm;fault tolerant system;fault tolerant computing;fault tolerant systems;parallel systems;scheduling;heuristic algorithms;real time scheduling;fault tolerance;quality of service qos;quality of service;distributed systems;passive execution scheme;heuristic algorithm;real time systems	Fault-tolerant scheduling plays a significant role in improving system reliability of clusters. Although extensive fault-tolerant scheduling algorithms have been proposed for real-time tasks in parallel and distributed systems, quality of service (QoS) requirements of tasks have not been taken into account. This paper presents a fault-tolerant scheduling algorithm called QAFT that can tolerate one node's permanent failures at one time instant for real-time tasks with QoS needs on heterogeneous clusters. In order to improve system flexibility, reliability, schedulability, and resource utilization, QAFT strives to either advance the start time of primary copies and delay the start time of backup copies in order to help backup copies adopt the passive execution scheme, or to decrease the simultaneous execution time of the primary and backup copies of a task as much as possible to improve resource utilization. QAFT is capable of adaptively adjusting the QoS levels of tasks and the execution schemes of backup copies to attain high system flexibility. Furthermore, we employ the overlapping technology of backup copies. The latest start time of backup copies and their constraints are analyzed and discussed. We conduct extensive experiments to compare our QAFT with two existing schemes-NOQAFT and DYFARS. Experimental results show that QAFT significantly improves the scheduling quality of NOQAFT and DYFARS.	algorithm;backup;computer cluster;computer data storage;distributed computing;experiment;fault tolerance;load (computing);quality of service;real-time clock;real-time computing;real-time transcription;requirement;run time (program lifecycle phase);scheduling (computing);simulation	Xiaomin Zhu;Xiao Qin;Meikang Qiu	2011	IEEE Transactions on Computers	10.1109/TC.2011.68	fault tolerance;parallel computing;real-time computing;heuristic;computer science;operating system;distributed computing	Embedded	-11.638683386395474	59.99639383663055	27993
dabebdd5d8adec535dc401131fc63cc6bc857d05	a failure detection system for large scale distributed systems	biomedical monitoring;distributed system;detectors;decentralized failure detector;topology;hierarchical structure;protocols;pattern clustering;reliability;system orchestration;fault tolerant;computer crashes;building block;failure detection;distributed processing;gossiping;large scale systems detectors fault tolerant systems computer crashes fault detection condition monitoring heart beat scalability intelligent structures competitive intelligence;gossiping distributed systems failure detection scalability;gossip based algorithm;application flow;fault tolerant computing;monitoring;quality of service distributed processing fault tolerant computing pattern clustering;large scale distributed system;clustering;failure detection system;reliability failure detection system large scale distributed system fault tolerance adaptive failure detector decentralized failure detector application flow clustering gossip based algorithm hierarchical structure traffic qos requirement system orchestration;failure detector;fault tolerance;traffic;scalability;large scale distributed systems;quality of service;distributed systems;qos requirement;heart beat;adaptive failure detector	Failure detection is a fundamental building block for ensuring fault tolerance in large scale distributed systems. In this paper we present an innovative solution to this problem. The approach is based on adaptive, decentralized failure detectors, capable of working asynchronous and independent on the application flow. The proposed failure detectors are based on clustering, the use of a gossip-based algorithm for detection at local level and the use of a hierarchical structure among clusters of detectors along which traffic is channeled. In this we present result proving that the system is able to scale to a large number of nodes, while still considering the QoS requirements of both applications and resources, and it includes the fault tolerance and system orchestration mechanisms, added in order to asses the reliability and availability of distributed systems in an autonomic manner.	distributed computing	Andrei Lavinia;Ciprian Dobre;Florin Pop;Valentin Cristea	2010		10.1109/CISIS.2010.29	embedded system;real-time computing;engineering;distributed computing;failure detector	EDA	-25.00000152546082	53.33698167973103	28027
612c34d781bcde27312468813ce6704dd67bd655	ab-ftl: an alternative block flash translation layer using locality-aware technique	policy making;flash memory;performance evaluation;garbage collection;flash translation layer;lbn ab ftl alternative block flash translation layer locality aware technique flash memory file system erase operation performance degradation flash translation layers ftl software layer garbage collection logical block number;locality aware;file system;ssd;ftl;ssd ftl flash memory locality aware split operation storage;split operation;performance evaluation file organisation flash memories;storage;flash memory switches degradation random access memory file systems distributed databases;life span;flash memories;file organisation	Since flash memory has useful characteristics, it has been used in a variety of areas recently. However, it has a critical weakness known as “erase-before-write”, which means that whenever receiving a write request to the preoccupied place from a file system, an erase operation must be preceded. If such a frequent request is generated in succession, this policy makes systems have experienced serious performance degradation. Many efforts have been actively made to solve this problem, and the activities are moved to utilize Flash Translation Layers (FTL). The software layer also manages garbage collection and wear leveling strategies to extend the life span and prevent malfunction. In this paper, we propose a novel flash memory management scheme named AB-FTL using an alternative block which plays a role to collect the data with the same LBN (Logical Block Number) and the new operation named split operation to decrease many erase operations created by a number of full merge operations. Moreover, alternative blocks depend on the characteristics of locality to manage update requests more efficiently. Our experimental results show that AB-FTL is an outstanding FTL algorithm of reducing the full merge cost generated by full merge operations over the implemented FTLs.	algorithm;elegant degradation;ftl: faster than light;flash file system;flash memory controller;garbage collection (computer science);locality of reference;memory management;overhead (computing);succession;wear leveling	Hyuk-In Kwon;Rize Jin;Tae-Sun Chung	2011	2011 IEEE 2nd International Conference on Networked Embedded Systems for Enterprise Applications	10.1109/NESEA.2011.6144952	parallel computing;computer hardware;computer science;operating system	Embedded	-11.989557140970847	53.998442360639444	28039
cac93990155fcdf56541fc8134f8f344cef73048	contribution to goodenough's and gerhart's theory of software testing and verification: relation between strong compiler test and compiler implementation verification	software testing;programming language;distributed programs;time constraint	 this paper we are mainly interested in sequential programming languages of usual informationprocessing. These languages are opposed to process languages with their constructsfor concurrent and distributed programming with communications and timing constraints.The languages we are studying here shall be especially appropriate for compiler writingwhat is done in sequential languages even if process languages are translated.2.1 Programming Languages, Syntax, Semantics, Transformation 	compiler;formal verification;software testing	Hans Langmaack	1997		10.1007/BFb0052101	computer architecture;compiler;verification and validation;compiler correctness;software verification;computer science;theoretical computer science;software development;compiler construction;software construction;software testing;programming language;functional compiler	Logic	-23.482655751248956	32.38755941789675	28040
ef8087fb62eb1eddb49bb0959d81aaa739b86de0	poster: towards highly accurate large-scale ab initio calculations using fragment molecular method in gamess	applications	One of the major challenges of modern quantum chemistry (QC) is to apply it to large systems with thousands of correlated electrons and basis functions. The availability of supercomputers and development of novel methods are necessary to realize this challenge. In particular, we employ linear scaling Fragment Molecular Orbital (FMO) method which decompose the large system into smaller, localized fragments which can be treated with high-level QC method like MP2. FMO is inherently scalable since the individual fragment calculations can be carried out simultaneously on separate processor groups. It is implemented in GAMESS, a popular ab-initio QC program. We present the scalability and performance of FMO on Intrepid (Blue Gene/P) and Blue Gene/Q systems at ALCF.	basis function;blue gene;flexible macroblock ordering;fragment molecular orbital;gamess (us);high- and low-level;image scaling;møller–plesset perturbation theory;scalability;supercomputer	Maricris L. Mayes;Graham D. Fletcher;Mark S. Gordon	2012	2012 SC Companion: High Performance Computing, Networking Storage and Analysis	10.1109/SC.Companion.2012.171	parallel computing;computer science;theoretical computer science;fragment molecular orbital	HPC	-4.6015585823197345	37.933066518094144	28199
72647643aef1c7ff49aaf2d4cc0c30945c73d5b0	request window: an approach to improve throughput of rdbms-based data integration system by utilizing data sharing across concurrent distributed queries	data sharing;data integrity;data transfer	This paper focuses on the problem of improving distributed query throughput of the RDBMS-based data integration system that has to inherit the query execution model of the underlying RDBMS: execute each query independently and utilize a global buffer pool mechanism to provide disk page sharing across concurrent query execution processes. However, this model is not suitable for processing concurrent distributed queries because the foundation, the memory-disk hierarchy, does not exist for data provided by remote sources. Therefore, the query engine cannot exploit any data sharing so that each process will have to interact with data sources independently: issue data requests and fetch data over the network. This paper presents Request Window, a novel DQP mechanism that can detect and employ data sharing opportunities across concurrent distributed queries. By combining multiple similar data requests issued to the same data source to a common data request, Request Window allows concurrent query executing processes to share the common result data. With the benefits of reduced source burdens and data transfers, the throughput of query engine can be significantly improved. This paper also introduces the IGNITE system, an extended PostgreSQL with DQP support. Our experimental results show that Request Window makes IGNITE achieve a 1.7x speedup over a commercial data integration system when running a workload of distributed TPC-H queries.	global variable;ibm tivoli storage productivity center;oracle database;page cache;postgresql;query throughput;relational database management system;speedup	Rubao Lee;Minghong Zhou;Huaming Liao	2007			computer science;data integrity;data mining;database;world wide web	DB	-21.2503650645497	50.51652450577693	28246
747ee43f3fa546155e1d3675097bd3e9dddb7eb5	actor classification using actor machines	computers;ports computers computational modeling educational institutions testing computers abstracts schedules;testing;computational modeling;abstracts;schedules;datavetenskap datalogi;ports computers	Program analysis is an important tool in software development, both for verifying desired properties and for enabling optimizations. For dataflow programs, properties such as determinacy and static schedulability are important for verifying correctness and creating efficient implementations. In this paper we develop an analyzer for dataflow actors, the computational units of a dataflow program, that classifies actors based on these properties. The analysis is performed on a language independent model for dataflow actors called actor machine.	actor model;compiler;correctness (computer science);data structure;dataflow programming;indeterminacy in concurrent computation;program analysis;scheduling (computing);software development;synchronous data flow;verification and validation	Gustav Cedersjö;Jörn W. Janneck	2013	2013 Asilomar Conference on Signals, Systems and Computers	10.1109/ACSSC.2013.6810612	real-time computing;computer science;theoretical computer science;distributed computing	SE	-25.330804547575003	34.010688076935004	28279
ea843e41baee78b1fc3d425b4c33ebb3f9c80d91	an integrated parallel/distributed environment for high performance computing			supercomputer	Fredy Joao Valente	1995				HPC	-7.848716536223013	38.248363871248074	28386
8faaf762922a57b24e7087d2bdb46673d89f46be	object-oriented parallelisation of java desktop programs	parallel computing;developpement logiciel;modelizacion;interfase usuario;threading model;concurrent computing;parallel programming graphical user interfaces java;user interface;gui aware concept object oriented parallelization java desktop program desktop application structure threading model;instruction sets graphical user interfaces object oriented modeling java parallel processing runtime concurrent computing;event dispatch thread parallel computing desktop applications object oriented programming graphical user interface;object oriented parallelization;parallel programming;langage java;graphical user interface;paralelisacion;object oriented programming;runtime;desktop applications;modelisation;event dispatch thread;desktop application structure;graphical user interfaces;desktop program;object oriented;desarrollo logicial;parallelisation;software development;parallelization;oriente objet;lenguaje java;interface utilisateur;modeling;orientado objeto;object oriented modeling;parallel processing;java language;instruction sets;java;gui aware concept	This article explores desktop applicationsu0027 structure and the threading modelu0027s limitations while examining the parallelization of a desktop application using object-oriented and GUI-aware concepts.	desktop computer;graphical user interface;java desktop system;parallel computing;threaded code	Nasser Giacaman;Oliver Sinnen	2011	IEEE Software	10.1109/MS.2010.135	parallel processing;computer architecture;parallel computing;concurrent computing;computer science;graphical user interface;programming language;object-oriented programming	Visualization	-17.963562307882796	41.26421627228166	28452
2d144c45446d189c061771aa90505c88bf63e69e	coarse-grain parallel programming in jade	cholesky factorization;run time system;data dependence;sparse matrix;coarse grained;parallel programs	Coarse-Grain Parallel Programming Monica S. Lam and Martin C. Rinard Computer Systems Laboratory Stanford University, CA 94305 This paper presents Jade, a language which allows a programmer to easily express dynamic coarse-grain parallelism. Starting with a sequential program, a programmer augments those sections of code to be parallelized with abstract data usage information. The compiler and run-time system use this information to concurrently execute the program while respecting the progmm’s data dependence constraints. Using Jade can significantly reduce the time and effort required to develop and maintain a parallel version of an imperative application with serial semantics. The paper introduces the basic principles of the language, compares Jade with other existing lrmguages, and presents the performance of a sparse matrix Cholesky factorization algorithm implemented in Jade.	algorithm;cholesky decomposition;compiler;data dependency;hardware description language;imperative programming;jade;lam/mpi;monica s. lam;parallel computing;programmer;runtime system;sparse matrix	Monica S. Lam;Martin C. Rinard	1991		10.1145/109625.109636	parallel computing;sparse matrix;computer science;theoretical computer science;distributed computing;minimum degree algorithm;cholesky decomposition	PL	-12.617432629303648	38.13388698758308	28461
8e4b9fb51eea5e37ef6129bd820a2d98b0531da5	embracing distance learning using middleware-based architecture	middleware;distance learning		middleware	Yeong-Tae Song	2003			theoretical computer science;middleware (distributed applications);distributed computing;architecture;computer science;distance education;middleware	Vision	-32.61651601018731	46.805011919277675	28516
262810e31eb54791c9304ef8db652d6adb9751d5	an infrastructure for profile-driven dynamic recompilation	optimising compilers;computer program;programmer feedback profile driven dynamic recompilation infrastructure computer programs dynamic optimization profile driven optimization code optimization code regeneration active procedures low overhead edge count profiling strategy profiling instrumentation graphical data display;programming profession instruments cost function frequency computer science application specific integrated circuits application software dynamic range feedback program processors;basic block reordering;instruments;cost function;code optimization;application software;programmer feedback;edge count profiling;run time code generation;dynamic compilation;computer programs;visual programming;profile driven optimization;feedback;application specific integrated circuits;profiling instrumentation;programming profession;dynamic range;on the fly;low overhead edge count profiling strategy;profile driven dynamic recompilation infrastructure;computer science;graphical data display;frequency;visual programming optimising compilers;program processors;active procedures;dynamic optimization;code regeneration	Dynamic optimization of computer programs can dramatically improve their performance on a variety of applications. This paper presents an efficient infrastructure for dynamic recompilation that can support a wide range of dynamic optimizations including profile-driven optimizations. The infrastructure allows any section of code to be optimized and regenerated on-the-fly, even code for currently active procedures. The infrastructure incorporates a low-overhead edge-count profiling strategy that supports first-class continuations and reinstrumentation of active procedures. Profiling instrumentation can be added and removed dynamically, and the data can be displayed graphically in terms of the original source to provide useful feedback to the programmer.	algorithm;basic block;binary recompiler;code segment;compile time;compiler;computer program;continuation;data-flow analysis;dynamic recompilation;even code;garbage collection (computer science);graphical user interface;high- and low-level;inline expansion;java;mathematical optimization;overhead (computing);program counter;programmer;register allocation;scheme;smalltalk	Robert G. Burger;R. Kent Dybvig	1998		10.1109/ICCL.1998.674174	computer architecture;dynamic range;application software;real-time computing;dynamic compilation;computer science;operating system;frequency;program optimization;feedback;application-specific integrated circuit;visual programming language;programming language	PL	-18.409389639481013	36.11554109169728	28525
824c12cad961f3b3697fd0d2931c1a144216f65e	pascal, modula-2 and multi-tasking kernel implementation	interrupts pascal modula 2 multi tasking kernel high level language microprocessor system software engineering sequential language language run time support portability;multi tasking kernel;pascal modula multiprogramming;software engineering;portability;sequential language;interrupts;pascal;modula 2;microprocessor system;high level language;language run time support	This paper presents a comparison of Pascal and Modula-2 based on the implementation of the basic components of a multi-tasking kernel. The major issues involved in high-level language implementation of a stand-alone multi-tasking kernel on a microprocessor system are the transportation of the language support system and what may be termed software engineering considerations. The merits of Pascal and Modula-2 with respect to these issues are compared. Standard Pascal is a sequential language, and the development of the multi-tasking features of the kernal has to take place outside the scope of the language. The Modula-2 language (nucleus), however, allows the kernal to be built entirely using high-level constructs. Issues of language run-time support and portability are also covered. These topics and the high-level handling of interrupts have received little attention in the literature on Modula-2. The Modula-2 kernel also provides a possible implementation of the ‘MODULE processes’.	computer multitasking;kernel (operating system);modula-2;pascal	S. Ayandeh;E. L. Morris	1987	Software Engineering Journal	10.1049/sej.1987.0027	modula-2;parallel computing;real-time computing;pascal;computer science;interrupt;programming language;high-level programming language	SE	-15.949340250914487	39.36075518374802	28541
421c8485c640efb84437ea0adbc094adf527af6e	a novel analysis space for pointer analysis and its application for bug finding	bug finding;pointer analysis;summary based analysis;computer science;static analysis;reading and writing	The size of today’s programs continues to grow, as does the number of bugs they contain. Testing alone is rarely able to flush out all bugs, and many lurk in difficult-to-test corner cases. An important alternative is static analysis, in which correctness properties of a program are checked without running it. While it cannot catch all errors, static analysis can catch many subtle problems that testing would miss. We propose a new space of abstractions for pointer analysis—an important component of static analysis for C and similar languages. We identify two main components of any abstraction—how tomodel statement order and how tomodel conditionals, then present a newmodel of programs that enables us to explore different abstractions in this space. Our assign-fetch graph represents reads and writes to memory instead of traditional pointsto relations and leads to concise function summaries that can be used in any context. Its flexibility supports many new analysis techniques with different trade-offs between precision and speed. We present the details of our abstraction space, explain where existing algorithms fit, describe a variety of new analysis algorithms based on our assign-fetch graphs, and finally present experimental results that show our flow-aware abstraction for statement ordering both runs faster and produces more precise results than traditional flow-insensitive analysis. © 2009 Elsevier B.V. All rights reserved.	algorithm;allocate-on-flush;bottom-up proteomics;corner case;correctness (computer science);data-flow analysis;dataflow;dereference operator;directed acyclic graph;for loop;java;on the fly;pointer (computer programming);pointer analysis;program transformation;software bug;static program analysis;top-down and bottom-up design	Marcio Buss;Daniel Brand;Vugranam C. Sreedhar;Stephen A. Edwards	2010	Sci. Comput. Program.	10.1016/j.scico.2009.08.002	computer science;theoretical computer science;shape analysis;programming language;pointer analysis;static analysis;algorithm	PL	-18.418854449881085	32.65698422386839	28634
7ee5a967d21c9af456b56c4fbf021401a15d8132	guide automatic vectorization by means of machine learning: a case study of tensor contraction kernels		Modern optimizing compilers tend to be conservative and often fail to vectorize programs that would have benefited from it. In this paper, we propose a way to predict the relevant command-line options of the compiler so that it chooses the most profitable vectorization strategy. Machine learning has proven to be a relevant approach for this matter: fed with features that describe the software to the compiler, a machine learning device is trained to predict an appropriate optimization strategy. The related work relies on the control and data flow graphs as software features. In this article, we consider tensor contraction programs, useful in various scientific simulations, especially chemistry. Depending on how they access the memory, different tensor contraction kernels may yield very different performance figures. However, they exhibit identical control and data flow graphs, making them completely out of reach of the related work. In this paper, we propose an original set of software features that capture the important properties of the tensor contraction kernels. Considering the Intel Merom processor architecture with the Intel Compiler, we model the problem as a classification problem and we solve it using a support vector machine. Our technique predicts the best suited vectorization options of the compiler with a cross-validation accuracy of 93.4%, leading to up to a 3-times speedup compared to the default behavior of the Intel Compiler. This article ends with an original qualitative discussion on the performance of software metrics by means of visualization. All our measurements are made available for the sake of reproducibility. key words: automatic vectorization, machine learning, software optimization	automatic vectorization;command-line interface;cross-validation (statistics);dataflow;machine learning;mathematical optimization;optimizing compiler;program optimization;simulation;software metric;speedup;support vector machine	Antoine Trouvé;Arnaldo J. Cruz;Kazuaki Murakami;Masaki Arai;Tadashi Nakahira;Eiji Yamanaka	2016	IEICE Transactions		computer science;theoretical computer science;machine learning;program optimization;programming language	AI	-5.083436271268374	44.99269255407978	28734
f37e6f1054aa281bd612ce5b9b1c52defa6f88b2	superpas: a parallel architectural skeleton model supporting extensibility and skeleton composition	estensibilidad;application development;modelizacion;parallelisme;algoritmo paralelo;parallel algorithm;esqueleto;programming environment;reutilizacion;communicating process;programacion basada sobre modelo;distributed computing;paralelisacion;reuse;skeleton;algorithme parallele;proceso comunicante;modelisation;medio ambiente programacion;parallelism;lenguaje descripcion;paralelismo;programmation base sur modele;envoi message;parallelisation;processus communicant;parallel computer;parallelization;message passing;squelette;calculo repartido;model based programming;extensibilite;scalability;parallel architecture;parallel programming model;parallel programs;modeling;calcul reparti;langage description;environnement programmation;reutilisation;description language	Application of pattern-based approaches to parallel programming is an active area of research today. The main objective of pattern-based approaches to parallel programming is to facilitate the reuse of frequently occurring structures for parallelism whereby a user supplies mostly the application specific code-components and the programming environment generates most of the code for parallelization. Parallel Architectural Skeleton (PAS) is such a pattern-based parallel programming model and environment. The PAS model provides a generic way of describing the architectural/structural aspects of patterns in message-passing parallel computing. Application development using PAS ishierarchical, similar to conventional parallel programming using MPI, however with the added benefit of reusability and high level patterns. Like most other pattern-based parallel programming models, the benefits of PAS were offset by some of its drawbacks such as difficulty in: (1) extending PAS and (2) skeleton composition. SuperPAS is an extension of PAS that addresses these issues. SuperPAS provides a skeleton description language for the generic PAS. Using SuperPAS, a skeleton developer can extend PAS by adding new skeletons to the repository (i.e., extensibility). SuperPAS also makes the PAS system more flexible by defining composition of skeletons. In this paper, we describe SuperPAS and elaborate its use through examples.	extensibility	Mohammad Mursalin Akon;Dhrubajyoti Goswami;Hon Fung Li	2004		10.1007/978-3-540-30566-8_112	parallel computing;message passing;scalability;systems modeling;computer science;theoretical computer science;operating system;reuse;parallel algorithm;rapid application development;skeleton;algorithm;parallel programming model	NLP	-17.766913815093087	41.65015345981177	28744
589824fc671d2152eff247b807392f98b9739b00	a generic qos infrastructure for grid web services	web service level agreement;medical simulation;web and internet services;grid applications;qos guarantee;biomedical imaging;contracts;web service;time factors;web services quality of service medical simulation delay contracts simple object access protocol grid computing time factors web and internet services biomedical imaging;web services;grid service;quality of service;simple object access protocol;grid computing;parallel applications	QoS support to ensure timeliness of results is a key requirement for applications that rely on Grid services for computationally demanding tasks. In this paper we present a generic Grid infrastructure based on standard Web Services which provides flexible application-level QoS support, addressing the special requirements of time-critical Grid applications. We describe the provision of parallel applications as QoS-aware Grid services, which are capable of dynamically negotiating with clients QoS guarantees for response time and price in the form of Web Service Level Agreements. The presented techniques have been implemented within the Vienna Grid Environment and utilized in the context of the EU project GEMSS for the development of Grid-enabled medical simulation services.	generalized environmental modeling system for surfacewaters;grid computing;middleware;quality of service;requirement;response time (technology);service-level agreement;simulation;testbed;web service;window of opportunity	Siegfried Benkner;Gerhard Engelbrecht	2006	Advanced Int'l Conference on Telecommunications and Int'l Conference on Internet and Web Applications and Services (AICT-ICIW'06)	10.1109/AICT-ICIW.2006.16	web service;medical simulation;semantic grid;computer science;database;distributed computing;law;world wide web;grid computing	HPC	-26.496629350085783	58.070624855821194	28775
a079322a7950aaee3ecc03d06f3f39e3a830255e	preserving the benefit of strict 2-phase locking with parallel multidatabase transactions			two-phase locking	Jérôme Besancenot;Michèle Cart;Jean Ferrié;Claire Morpain;Jean-François Pons;Philippe Pucheral	1995			database;computer science;two-phase locking	DB	-23.278706301519733	47.70851851356843	28791
bc2d7b813a1b577f22d9ff876dd49a8b8b3c8490	fault-tolerant disk storage and file systems using reflective memory	distributed system;high availability;magnetic disc storage;standard computers;massively parallel systems;storage system;concurrent computing;storage systems;measurement;fault tolerant;replicated storage;fault tolerant systems file systems hardware concurrent computing computer architecture availability scalability large scale systems emulation measurement;high availability replicated file and storage systems;availability;massively parallel system;distributed storage;emulation;software fault tolerance;large scale i o intensive applications;software oriented approach;computer architecture;large scale;shared memory systems;file services fault tolerant disk storage file systems reflective memory replicated storage software oriented approach fault tolerance standard computers massively parallel system high availability replicated file and storage systems storage systems large scale i o intensive applications stable storage dasd subsystem performance measurements distributed storage;performance measurements;fault tolerant disk storage;fault tolerant systems;file system;fault tolerance;reflective memory;distributed databases;magnetic disc storage shared memory systems replicated databases distributed databases software fault tolerance;scalability;file services;replicated databases;stable storage dasd subsystem;file systems;large scale systems;hardware	Most replicated storage and file systems either take a specialized hardware approach or a sofhuare-oriented approach to fault tolerance. This paper describes a fault-tolerant disk storage and file system that falls in between the hardware and software categories. The system uses Reflective Memory to interconnect an array of standard computers comprising a massively parallel system. This architecture provides the basis for highavailability replicated file and storage systems with the pelformance and low overhead expected from specialized hardware while offering the modularity and scalability of a distributed system. In this paper, we describe the implementation of the fault-tolerant file and storage system to run large scale IJO-intensive applications, such as emulation of a stable storage DASD subsystem. Preliminary perfarmance measurements indicate that selectively broadcasting regions of Reflective Memory allows for virtually no overhead over conventional systems for supporting replicated, distributed storage andfile services.	clustered file system;computation;computer data storage;disk storage;distributed computing;downtime;emulator;fault tolerance;input/output;overhead (computing);parallel computing;reflective memory;scalability;software categories;stable storage	Nicos Vekiarides	1995		10.1109/HICSS.1995.375404	flash file system;self-certifying file system;file server;fault tolerance;parallel computing;storage area network;concurrent computing;memory-mapped file;device file;computer file;object storage;computer science;stub file;versioning file system;operating system;unix file types;journaling file system;database;distributed computing;open;distributed file system;file system fragmentation;file control block;virtual file system	OS	-18.321215683956893	51.607636472947135	28875
984250da0a78dbc6f47ce5624a98cfd6a4dc0aae	compiler-controlled extraction of computation-communication overlap in mpi applications	distributed application;optimising compilers;computation communication overlap;early experience;dominator trees;optimizing compiler;mpi applications;performance improvement;real world application;ibm xl series;application program interfaces;compiler optimization;compiler controlled extraction;message passing;programming profession optimizing compilers distributed computing application specific integrated circuits algorithm design and analysis performance gain performance loss;compiler optimization computation communication overlap;optimising compilers application program interfaces message passing;nas parallel benchmarks;ssa based use def analyses;parallel applications;aggressive inlining;nas parallel benchmarks compiler controlled extraction computation communication overlap mpi applications optimizing compiler ibm xl series aggressive inlining dominator trees ssa based use def analyses parallel applications	Exploiting computation-communication overlap is a well- known requirement to speed up distributed applications. However, efforts till now use programmer expertise, rather than any automatic tool to do this. In our work we propose the use of an aggressive optimizing compiler (IBM's xl series) to automatically extract opportunities for computation communication overlap. We depend on aggressive inlining, dominator trees and SSA based use-def analyses provided by the compiler framework for exploiting such overlap. Our target is MPI applications. In such applications, we try to automatically move mpi_waits as well as split blocking mpi_send/recv to create more opportunities for overlap. Our objective is two-fold: firstly, our tool should relieve the programmer from the burden of hunting for overlap manually as much as possible, and secondly, it should aid in converging on parallel applications which benefit from such overlap quickly. These are necessary as MPI applications are quickly becoming complex and huge and manual overlap extraction is becoming cumbersome. Our early experience shows that it is not necessary that exploiting an overlap always leads to performance improvement. This corroborates with the fact that if we have an automatic tool, then, we can quickly discard such applications (or certain configurations of such applications) without spending person-hours to manually rewrite MPI applications for introducing non-blocking calls. Our initial experiments with the industry-standard NAS parallel benchmarks show that we can get small-to-moderate improvements by utilizing overlap even in such highly tuned benchmarks. This augurs well for real-world applications that do not exploit overlap optimally.	blocking (computing);central processing unit;computation;distributed computing;dominator (graph theory);experiment;fold (higher-order function);inline expansion;message passing interface;nas parallel benchmarks;non-blocking algorithm;optimizing compiler;programmer;rewrite (programming);transmitter power output	Dibyendu Das;Manish Gupta;Rajan Ravindran;W. Shivani;P. Sivakeshava;Rishabh Uppal	2008	2008 IEEE International Symposium on Parallel and Distributed Processing	10.1109/IPDPS.2008.4536193	computer architecture;parallel computing;computer science;operating system;optimizing compiler;distributed computing;programming language	HPC	-15.446099522600708	36.5434605240308	28915
54d6af976be92a522fa73354a75e2143a25328b7	a lightweight, scalable grid computing framework for parallel bioinformatics applications	biology computing;grid computing bioinformatics power engineering computing concurrent computing power engineering and energy computer networks distributed computing large scale systems java hardware;computational grid;concurrent computing;macromolecules grid computing biology computing;distributed computing;rna folding;parallel and distributed computing;computer networks;power engineering and energy;large scale;origin of life;power engineering computing;rna;software development;macromolecules;ad hoc grid;grid computing;loosely coupled parallel bioinformatics;large scale systems;rna grid computing loosely coupled parallel bioinformatics java ad hoc grid;hardware;java;bioinformatics	In recent years our society has witnessed an unprecedented growth in computing power available to tackle important problems in science, engineering and medicine. For example, the SHARCNET network links large computing resources in 11 leading academic institutions in South Central Ontario, thus providing access to thousands of compute processors. It is a continuous challenge to develop efficient and scalable algorithms and methods for solving large scientific and engineering problems on such parallel and distributed computers. If the computing power available in such computational grids can be unleashed effectively in a scalable way, large scientific problems can be solved that would otherwise be hard to solve using the machines available in a stand-alone way. This paper describes techniques and software developed that allow to apply the power of computational grids to large-scale, loosely coupled parallel bioinformatics problems. Our approach is based on decentralization and implemented in Java, leading to a flexible, portable and scalable software solution for parallel bioinformatics. We discuss advantages and disadvantages of this approach, and demonstrate seamless performance on an ad-hoc grid composed of a wide variety of hardware for a real-life parallel bioinformatics problem. The bioinformatics problem described consists of virtual experiments in RNA folding executed on hundreds of compute processors concurrently, which may establish one of the missing links in the chain events that led to the origin of life.	algorithm;bioinformatics;central processing unit;computer;experiment;grid computing;hoc (programming language);java;loose coupling;real life;scalability;seamless3d;the sims	Hans De Sterck;Rob S. Markel;Rob Knight	2005	19th International Symposium on High Performance Computing Systems and Applications (HPCS'05)	10.1109/HPCS.2005.7	macromolecule;computational science;parallel computing;rna;concurrent computing;abiogenesis;computer science;theoretical computer science;software development;operating system;distributed computing;programming language;java;grid computing	HPC	-29.252695911194063	50.58826713903471	28973
53aa92db96f9f6ebf32dc4784abf560db060fbe8	an asynchronous branch and bound skeleton for heterogeneous clusters	parallelisme;distributed system;virtual machine;interfase usuario;systeme reparti;esqueleto;heterogeneous cluster;user interface;communicating process;linux cluster;machine virtuelle;skeleton;proceso comunicante;optimisation combinatoire;parallelism;branch and bound method;sistema repartido;paralelismo;metodo branch and bound;envoi message;processus communicant;message passing;squelette;interface utilisateur;methode separation et evaluation;combinatorial optimization;branch and bound;maquina virtual;optimizacion combinatoria	This work presents a parallel skeleton for the Branch and Bound technique. The main contribution of the proposed skeleton is that it is fully distributed. The implementation has been written in MPI. The user interface is the same as the one provided by the combinatorial optimization library MaLLBa. Computational results for a heterogeneous Linux cluster of PC are presented.	branch and bound	Juan R. González;Coromoto León;Casiano Rodríguez	2004		10.1007/978-3-540-30218-6_30	parallel computing;message passing;combinatorial optimization;computer cluster;computer science;virtual machine;operating system;distributed computing;programming language;user interface;skeleton;branch and bound;algorithm	Arch	-17.684244287829113	42.11703253860654	29019
3d540a420a8582a9ecfec867e1a37b78fc536b36	object life-cycle management in a highly flexible middleware system	modelo dinamico;lenguaje programacion;distributed system;fine grain structure;adaptability;adaptabilite;durabilite;ciclo desarrollo;systeme reparti;life cycle;programming language;life cycle management;estructura grano fino;dynamic model;durabilidad;logicial personalizado;adaptabilidad;intergiciel;sistema repartido;durability;modele dynamique;cycle developpement;langage programmation;middleware;distribution dynamics;structure grain fin	This paper describes the object life-cycle management in the Dinopolis middleware system. Advanced object composition is used to support adaptability and extensibility of the running system. Such a high degree of flexibility requires mechanisms to keep objects and the entire system in a consistent state. We show that a fine-grained definition of the object life-cycle helps controlling objects in a highly flexible fashion. Moreover, we discuss how the life-cycle of composed objects can be exploited to model different dynamic scenarios found in distributed, dynamically changing environments.	compiler;component-based software engineering;destructor (computer programming);distributed computing;dynamical system;extensibility;java;method overriding;middleware;object composition;openjava;preprocessor;programmer;prototype;requirement;run time (program lifecycle phase);type system	Karl Blümlinger;Christof Dallermassl;Heimo Haub;Philipp Zambelli	2003		10.1007/978-3-540-45213-3_14	biological life cycle;method;adaptability;simulation;computer science;operating system;object-oriented design;durability;middleware;database;distributed object;programming language;product life-cycle management	Robotics	-28.546999729046842	42.38425903449522	29027
c1e2937f8494979b3a2e23ec15ab75d77b53417d	optimizing cost of continuous overlapping queries over data streams by filter adaption	query execution cost continuous overlapping queries data streams filter adaption cost management optimization filter evaluation shared strategy data item characteristics query execution plan filter ordering;electronic mail;query processing;monitoring optimization streaming media multimedia communication query processing electronic mail probabilistic logic;filter adaption;data streams;overlapping queries;monitoring;cost optimization;streaming media;multimedia communication;optimization;probabilistic logic;query processing information filtering optimisation;article;data streams overlapping queries cost optimization filter adaption	The problem we aim to address is the optimization of cost management for executing multiple continuous queries on data streams, where each query is defined by several filters, each of which monitors certain status of the data stream. Specially, the filter can be shared by different queries and expensive to evaluate. The conventional objective for such a problem is to minimize the overall execution cost to solve all queries, by planning the order of filter evaluation in shared strategy. However, in the streaming scenario, the characteristics of data items may change in process, which can bring some uncertainty to the outcome of individual filter evaluation, and affect the plan of query execution as well as the overall execution cost. In our work, considering the influence of the uncertain variation of data characteristics, we propose a framework to deal with the dynamic adjustment of filter ordering for query execution on data stream, and focus on the issues of cost management. By incrementally monitoring and analyzing the results of filter evaluation, our proposed approach can be effectively adaptive to the varied stream behavior and adjust the optimal ordering of filter evaluation, so as to optimize the execution cost. In order to achieve satisfactory performance and efficiency, we also discuss the trade-off between the adaptivity of our framework and the overhead incurred by filter adaption. The experimental results on synthetic and two real data sets (traffic and multimedia) show that our framework can effectively reduce and balance the overall query execution cost and keep high adaptivity in streaming scenario.	mathematical optimization;optimizing compiler;overhead (computing);synthetic data	Qing Xie;Xiangliang Zhang;Zhixu Li;Xiaofang Zhou	2016	IEEE Transactions on Knowledge and Data Engineering	10.1109/TKDE.2016.2516541	real-time computing;computer science;data mining;database;data stream mining;probabilistic logic	DB	-19.544610448345235	55.708343197417115	29028
418b904d836bff77a25143723de01e4c85f2e352	an approach to scalable molecular dynamics simulation using supercomputing adaptive processing elements	processing element;reconfigurable hardware scalable molecular dynamics simulation supercomputing adaptive processing element floating point;supercomputing adaptive processing element;reconfigurable architectures molecular dynamics method floating point arithmetic;reconfigurable architectures;molecular dynamic simulation;molecular dynamics method;molecular dynamic;floating point;floating point arithmetic;scalable molecular dynamics simulation;reconfigurable hardware;computational modeling kernel hardware supercomputers application software computational efficiency acceleration space exploration computer science numerical simulation	We implement and report performance numbers of an entire molecular dynamics application in floating point on reconfigurable hardware achieving sustainable speedup and scaling with a novel technique based on adaptive processing elements.	field-programmable gate array;image scaling;molecular dynamics;scalability;simulation;speedup;supercomputer	Luis E. Cordova;Duncan A. Buell	2005	International Conference on Field Programmable Logic and Applications, 2005.	10.1109/FPL.2005.1515820	computational science;molecular dynamics;parallel computing;computer science;floating point;theoretical computer science;operating system	HPC	-5.495758718057044	37.925627914756966	29037
fc62d11655fe06edee1a848c4f48d7d619b4e850	a novel tag access scheme for low power l2 cache	cache storage;random access memory;low power electronics cache storage content addressable storage;radiation detectors power demand energy consumption accuracy random access memory estimation clocks;bloom filter;clocks;cache power consumption;radiation detectors;radiation detector;tag access scheme;low power l2 cache;accuracy;per way cache miss detection;serial tag data access tag access scheme low power l2 cache cache power consumption highly associative cache partial tag enhanced bloom filter tag comparison per way cache miss detection cache data classification hot data cold data spec2000 spec2006;low power;estimation;cold data;energy consumption;low power electronics;data access;hot data;cache data classification;spec2006;tag comparison;partial tag enhanced bloom filter;power consumption;content addressable storage;power demand;serial tag data access;highly associative cache;spec2000	Tag comparisons occupy a significant portion of cache power consumption in the highly associative cache such as L2 cache. In our work, we propose a novel tag access scheme which applies a partial tag-enhanced Bloom filter to reduce tag comparisons by detecting per-way cache misses. The proposed scheme also classifies cache data into hot and cold data and the tags of hot data are compared earlier than those of cold data exploiting the fact that most of cache hits go to hot data. In addition, the power consumption of each tag comparison can be further reduced by dividing the tag comparison into two micro-steps where a partial tag comparison is performed first and, only if the partial tag comparison gives a partial hit, then the remaining tag bits are compared. We applied the proposed scheme to an L2 cache with 10 programs from SPEC2000 and SPEC2006. Experimental results show average 23.69% and 8.58% reduction in cache energy consumption compared with the conventional serial tag-data access and the other existing methods, respectively.	bloom filter;cpu cache;data access;goto;sensor;tagged architecture	Hyunsun Park;Sungjoo Yoo;Sunggu Lee	2011	2011 Design, Automation & Test in Europe	10.1109/DATE.2011.5763108	cache-oblivious algorithm;parallel computing;real-time computing;cache coloring;page cache;tag ram;computer hardware;cache;computer science;cache invalidation;particle detector;cache algorithms;statistics	HPC	-7.617270886489615	54.49387046391254	29136
06b6093385787899ff33b93b2449eadbe9944d5f	performability evaluation of networked storage systems using n-spek	benchmarking;network operating systems storage area networks benchmark testing performance evaluation;storage system;performance evaluation;performability;network operating systems;performance evaluation computer networks grid computing;spectrum;storage area networks;file system;fault injection;san components performability evaluation networked storage system benchmark tool storage area network fault injection modules file system configurable storage workload;high performance;block level access;networked storage;benchmark testing	This paper introduces a new benchmark tool for evaluating performance and availability (performability) of networked storage systems, specifically storage area network (SAN) that is intended for providing block-level data storage with high performance and availability. The new benchmark tool, named N-SPEK (Networked-Storage Performability Evaluation Kernel module), consists of a controller, several workers, one or more probers, and several fault injection modules. N-SPEK is highly accurate and efficient since it runs at kernel level and eliminates skews and overheads caused by file systems. It allows a SAN architect to generate configurable storage workloads to the SAN under test and to inject different faults into various SAN components such as network devices, storage devices, and controllers. Available performances under different workloads and failure conditions are dynamically collected and recorded in the N-SPEK over a spectrum of time. To demonstrate its functionality, we apply N-SPEK to evaluate the performability of a specific iSCSI-based SAN under Linux environment. Our experiments show that N-SPEK not only efficiently generates quantitative performability results but also reveals a few optimization opportunities for future iSCSI implementations.	benchmark (computing);byzantine fault tolerance;communications protocol;computer data storage;experiment;fault injection;iscsi;linux;linux;loadable kernel module;mathematical optimization;operating system;performance;prototype;storage area network	Ming Zhang;Qing Yang;Xubin He	2003		10.1109/CCGRID.2003.1199441	embedded system;spectrum;benchmark;real-time computing;storage area network;computer science;operating system;database;distributed computing;benchmarking	OS	-18.137809389171178	51.43418984417783	29192
974ecb21c3a5cd45148fe319c737757ecf5a6d8a	performance of interconnection network in multithreaded architectures	integrable model;multiprocessor systems;network performance;interconnection network;multithreaded architecture;queuing networks	In this paper, we analyze the performance of interconnection networks in a multithreaded multiprocessor using a closed queuing network model. Proposed integrated model of the multiprocessor system captures the interaction among subsystems faithfully. Our study reveals a strong relationship of workload parameters to the network performance and brings out a feedback effect of network response on message rate to the network.	interconnection;thread (computing)	Shashank S. Nemawarkar;Renganayaki Govindarajan;Guang R. Gao;Vinod K. Agarwal	1994		10.1007/3-540-58184-7_166	computer architecture;parallel computing;real-time computing;network architecture	Arch	-10.044751165762786	47.36356859115242	29193
707999561ff3d7531594a95c2dd3311369976c1b	coordination models and facilities could be parallel software accelerators	distributed memory systems;formal specification;programacion paralela;sistema informatico;parallel programming;computer system;software engineering;specification formelle;especificacion formal;systeme memoire repartie;shared memory systems;datavetenskap datalogi;systeme informatique;computer science;programvaruteknik;parallel programs;coordination model;distributed shared memory;systeme memoire partagee;programmation parallele	A new coordination model is constructed for distributed shared memory parallel programs. It exploits typing of shared resources and formal specification of a priori known synchronization constraints.		Anatoly E. Doroshenko;Lars-Erik Thorelli;Vladimir Vlassov	1999		10.1007/BFb0100694	distributed shared memory;computer architecture;parallel computing;computer science;formal specification;programming language	SE	-16.98466496164901	40.845167535232704	29212
96ccb14c8ea9a35e36cc70367350b2305ea10b5e	game-theoretic incentive model for improving mobile code offloading adaptability		Due to the limited computational capabilities of the mobile device they usually need to delegate resource intensive tasks to the cloud. Code offloading is one of the techniques used for such purposes. In Code offloading, the mobile application is partitioned to identify resource intensive tasks which are then transferred to the server for remote processing. Various techniques have been in use for performing code offloading but none of them is economically viable due to which this model is not frequently used in the industry. In this paper, we tried to address the issues which make code offloading expensive and came up with code offloading model that can make the process economically viable. We developed a game theoretic model that provides incentive to mobile users to open their devices for offloading. Simulations have been done to validate the mathematical model and a prototype has also been developed to see how the framework behaves in the real world scenario.		Talha Mahin Mir;Satish Narayana Srirama	2018	2018 IEEE International Conference on Cloud Computing Technology and Science (CloudCom)	10.1109/CloudCom2018.2018.00040	real-time computing;game theory;cloud computing;adaptability;delegate;mobile device;computer science;distributed computing;incentive;mobile code	Robotics	-25.42612143716785	59.87772958550424	29294
1f089598fa1f2d334c749d6640f29962187d693b	fddi performance evaluation based on lotos formal description tecnique	performance evaluation		performance evaluation	Antonio Martínez Maz;Carlos Miguel;Eliany Perez;Angel Fernández	1994			fiber distributed data interface;computer architecture;computer science	Vision	-29.77788107541164	34.88334152796867	29356
12ca32a3e764130716fefa7258cbc9d0222bbf5a	a methodology for co-location aware application performance modeling in multicore computing	benchmarking;degradation;multicore processing predictive models degradation radiation detectors interference data models mathematical model;application co location;radiation detectors;resource management;interference;parallel architectures memory architecture multiprocessing systems;multicore processing;mathematical model;multicore processors performance modeling resource management memory interference application co location benchmarking;memory interference;predictive models;multicore processors;intel xeon multicore processor colocation aware application multicore computing multicore processor architecture parallel computing system distributed computing system memory interference performance modeling;performance modeling;data models	As multicore processor architectures are now prevalent in server nodes of parallel and distributed computing systems, it has become important to characterize the performance of applications run on these architectures. This study investigates the performance degradation an application experiences from memory interference due to other applications colocated on cores of the same multicore processor. We propose a methodology for designing models that are capable of utilizing varying amounts of information relating to an application and its co-located applications to predict the application's execution time performance degradation due to co-location. We evaluate the models sing several application co-location scenarios based on real world test data from two scientific benchmark suites on two server class Intel Xeon multicore processors.	artificial neural network;benchmark (computing);cache manifest in html5;central processing unit;colocation centre;computer data storage;distributed computing;elegant degradation;energy modeling;hp multi-programming executive;interference (communication);linear model;machine learning;multi-core processor;parallel computing;principle of good enough;run time (program lifecycle phase);scheduling (computing);server (computing);test data;vii	Daniel Dauwe;Eric Jonardi;Ryan Friese;Sudeep Pasricha;Anthony A. Maciejewski;David A. Bader;Howard Jay Siegel	2015	2015 IEEE International Parallel and Distributed Processing Symposium Workshop	10.1109/IPDPSW.2015.38	multi-core processor;computer architecture;parallel computing;real-time computing;computer science;resource management;operating system	HPC	-8.590460343593012	48.39433822216487	29409
085e9af9bb57332f47fd4593a33a0865a27aae61	power and energy-aware processor scheduling (abstracts only)	kronecker products;power estimation;optimization of iterative methods;numerical methods;power consumption;job scheduling	"""Power consumption is a critical consideration in high computing systems. We propose a novel job scheduler that optimizes power and energy consumed by clusters when running parallel benchmarks with minimal impact on performance. We construct accurate models for estimating power consumption. These models are based on measurements of power consumption on benchmarks with different characteristics and on systems with processors using different microarchitectures. We show the power estimation models achieve less than 2% error versus actual measurements. We show a job scheduler can be enhanced to make it """"power-aware"""" and to optimize power consumption of jobs with similar performance characteristics. The enhanced scheduler can estimate the power consumed by a particular job using the power estimation model, configure the nodes in the cluster via suitably adjusting processor frequency on each of the nodes to maximize performance, minimize power, or minimize energy with a predictable impact on power, energy and performance."""	benchmark (computing);central processing unit;job scheduler;job stream;microarchitecture;scheduling (computing);windows nt processor scheduling	Luigi Brochard;Raj Panda;Don DeSota;Francois Thomas;Robert H. Bell	2011	SIGMETRICS Performance Evaluation Review	10.1145/2160803.2160828	parallel computing;real-time computing;numerical analysis;computer science;job scheduler;operating system	HPC	-5.114009079412695	55.33572833636214	29421
df75d33bf39dcf0fbaf3cc40f7dc95c27920e0e1	awakening decentralised real-time collaboration: re-engineering apache wave into a general-purpose federated and collaborative platform		Real-time collaboration is being offered by plenty of libraries and APIs (Google Drive Real-time API, Microsoft Real-Time Communications API, TogetherJS, ShareJS), rapidly becoming a mainstream option for web-services developers. However, they are offered as centralised services running in a single server, regardless if they are free/open source or proprietary software. After re-engineering Apache Wave (former Google Wave), we can now provide the first decentralised and federated free/open source alternative. The new API allows to develop new real-time collaborative web applications in both JavaScript and Java environments.	apache wave;application programming interface;centralisation;general-purpose markup language;google drive;java;javascript;library (computing);open-source software;real-time transcription;real-time web;server (computing);web application	Pablo Ojanguren-Menendez;Antonio Tenorio-Fornes;Samer Hassan	2015		10.1007/978-3-319-19638-1_31	simulation;world wide web;computer security	SE	-32.662853729416305	42.250616642323536	29439
0cd54e310cdc58c3a374e4df76be933dc347f462	efficient index lookup for de-duplication backup system	data structures;memory index lookup structure;workload-aware index partitioning;fingerprint management overhead;file chunking latency;deduplication backup system;servers;data structure;indexes;redundancy;fingerprint recognition;indexation	We minimizes fingerprint management overhead (index lookup and index insert) via introducing main memory index lookup structure and workload-aware index partitioning of the index file in the storage. Backup server maintains three data structures for redundancy elimination: Header files, chunk files and fingerprint tables. These data structures altogether enables PRUNE to effectively eliminate redundancy and to perform efficient backup. We perform various experiment to measure the overhead of each tasks in backup operation and to examine the efficiency of redundancy elimination. Incremental modulo-K reduces the file chunking latency by approximately 60%. With filter based in-memory index data structure and index partitioning, PRUNE eliminates 99.4% of disk accesses involved in fingerprint management.	backup;computer data storage;data structure;database index;fingerprint;in-memory database;lookup table;modulo operation;overhead (computing);server (computing);shallow parsing;test template framework	Youjip Won;Jongmyeong Ban;Jaehong Min;Jungpil Hur;Sangkyu Oh;Jangsun Lee	2008	2008 IEEE International Symposium on Modeling, Analysis and Simulation of Computers and Telecommunication Systems		database index;parallel computing;real-time computing;data structure;computer science;operating system;database;redundancy;fingerprint recognition;server	OS	-13.61257631560221	53.834364009854546	29499
df40a82970552cee731bf230d75220045ebdd0e3	exploiting intra-request slack to improve ssd performance	scheduling;ssd;intra request slack	With Solid State Disks (SSDs) offering high degrees of parallelism, SSD controllers place data and direct requests to exploit the maximum offered hardware parallelism. In the quest to maximize parallelism and utilization, sub-requests of a request that are directed to different flash chips by the scheduler can experience differential wait times since their individual queues are not coordinated and load balanced at all times. Since the macro request is considered complete only when its last sub-request completes, some of its sub-requests that complete earlier have to necessarily wait for this last sub-request. This paper opens the door to a new class of schedulers to leverage such slack between sub-requests in order to improve response times. Specifically, the paper presents the design and implementation of a slack-enabled re-ordering scheduler, called Slacker, for sub-requests issued to each flash chip. Layered under a modern SSD request scheduler, Slacker estimates the slack of each incoming sub-request to a flash chip and allows them to jump ahead of existing sub-requests with sufficient slack so as to not detrimentally impact their response times. Slacker is simple to implement and imposes only marginal additions to the hardware. Using a spectrum of 21 workloads with diverse read-write characteristics, we show that Slacker provides as much as 19.5%, 13% and 14.5% improvement in response times, with average improvements of 12%, 6.5% and 8.5%, for write-intensive, read-intensive and read-write balanced workloads, respectively.	flash memory;floppy disk;marginal model;parallel computing;read-write memory;scheduling (computing);slack variable;solid-state drive	Nima Elyasi;Mohammad Arjomand;Anand Sivasubramaniam;Mahmut T. Kandemir;Chita R. Das;Myoungsoo Jung	2017		10.1145/3037697.3037728	parallel computing;real-time computing;computer science;operating system;scheduling	Arch	-9.428749073883038	53.031493142168415	29512
226d39140716cafb8aa2b875ce3e37535a3a603f	impact of i/o coordination on a nfs-based parallel file system with dynamic reconfiguration	distributed data;available bandwidth;file servers;software architecture file servers input output programs network operating systems reconfigurable architectures;dnfsp file system;dynamic reconfiguration;reconfigurable architectures;network operating systems;nfs based parallel file system;input output programs;computer architecture;reconfiguration mechanism;software architecture;servers;multicore system;file system;parallel file system;bandwidth;cluster architecture;i o server;parallel architecture;multicore system nfs based parallel file system upc application i o server reconfiguration mechanism dnfsp file system cluster architecture parallel architecture;benchmark testing;file systems;data models;upc application;servers bandwidth benchmark testing file systems computer architecture delay data models	The large gap between processing and I/O speed makes the storage infrastructure of a cluster a great bottleneck for HPC applications. Parallel File Systems propose a solution to this issue by distributing data onto several servers, dividing the load of I/O operations and increasing the available bandwidth. However, most parallel file systems use a fixed number of I/O servers defined during initialization and do not support addition of new resources as applications’ demands grow. With the execution of different applications at the same time, the concurrent access to these resources can impact the performance and aggravate the existing bottleneck. The dNFSp File System proposes a reconfiguration mechanism that aims to include new I/O resources as application’s demands grow. These resources are standard cluster nodes and are dedicated to a single application. This paper presents a study of the I/O performance of this reconfiguration mechanism under two circunstances: the use of several independent processes on a multi-core system or of a single centralized I/O process that coordinates the requests from all instances on a node. We show that the use of coordination can improve performance of applications with regular intervals between I/O phases. For applications with no such intervals, on the other hand, uncoordinated I/O presents better performance.	bottleneck (engineering);centralized computing;clustered file system;computer cluster;concurrency control;fairness measure;forward secrecy;i/o bound;input/output;multi-core processor;relocation (computing);server (computing);throughput	Rodrigo Kassick;Francieli Zanon Boito;Philippe Olivier Alexandre Navaux	2010	2010 22nd International Symposium on Computer Architecture and High Performance Computing	10.1109/SBAC-PAD.2010.32	data modeling;file server;benchmark;software architecture;parallel computing;real-time computing;computer science;operating system;multipath i/o;bandwidth;i/o scheduling;server	HPC	-20.532889168393254	51.24812650568922	29551
7c8b8c1eec518958b0fd4914a865ff52238ca313	real-time reconfigurable scheduling of sporadic tasks		This book chapter deals with the problem of scheduling multiprocessor real-time tasks by an optimal EDF-based scheduling algorithm. Two forms of automatic reconfigurations which are assumed to be applied at run-time: Addition-Removal of tasks or just modifications of their temporal parameters: WCET and/or deadlines. Nevertheless, when such a scenario is applied to save the system at the occurrence of hardware-software faults, or to improve its performance, some real-time properties can be violated at run-time. We define an Intelligent Agent that automatically checks the system’s feasibility after any reconfiguration scenario was applied on a multiprocessor embedded system. Indeed, if the system is unfeasible, then the Intelligent Agent dynamically provides precious technical solutions for users to send sporadic tasks to idle times, by modifying the deadlines of tasks, the worst case execution times (WCETs), the activation time, by tolerating some non critical tasks, by sending some tasks from their current processors to be scheduled in other processors, or in the worst case by removing some soft tasks according to predefined heuristic. We implement the agent to support these services.	real-time transcription;scheduling (computing)	Hamza Gharsellaoui;Samir Ben Ahmed	2013		10.1007/978-3-662-44920-2_2	fixed-priority pre-emptive scheduling	Robotics	-9.735948433414757	59.671903029931116	29578
3942a79e2878ed8d3c339dde395ea52019f50656	spacecraft plasma environment analysis via large scale 3d plasma particle simulation	large scale simulation;spacecraft model;spacecraft plasma environment analysis;plasma particle simulation code;realistic physical model;geospace environment;space plasma;3-dimensional full-particle electromagnetic simulation;spacecraft environment;kinetic environment;geospace environment simulator	Geospace environment simulator (GES) has started as one of the advanced computing research projects at the Earth Simulator Center in Japan Marine Science and Technology Center since 2002: [1]. By using this computing resource, a large scale simulation which reproduces a realistic physical model can be utilized not only for studying the geospace environment but also for various human activities in space. GES project aims to reproduce fully kinetic environment around a spacecraft by using the 3-dimensional full-particle electromagnetic simulation code which could include spacecraft model inside (NuSPACE). NuSPACE can model interaction between space plasma and a spacecraft by the unstructuredgrid 3D plasma particle simulation code embedded in the NuSPACE.We will report current status of the project and our concept of achieving the spacecraft environment in conjunction with the space weather.	simulation	Masaki Okada;Hideyuki Usui;Yoshiharu Omura;Hiroko O. Ueda;Takeshi Murata;Tooru Sugiyama	2005		10.1007/978-3-540-77704-5_36	space simulator;simulation	HPC	-6.763522262657911	35.84499475932064	29584
cb341eddcb2f896cebc102fdad607a8498587b20	javasymphony: a programming and execution environment for parallel and distributed many-core architectures	multi core processor;shared memory;distributed programs;programming model;execution environment;software development;parallel computer;load balance	Today, software developers face the challenge of re-engineering their applications to exploit the full power of the new emerging many-core processors. However, a uniform high-level programming model and interface for parallelising Java applications is still missing.#R##N##R##N#In this paper, we propose a new Java-based programming model for shared memory many-core parallel computers as an extension to the JavaSymphony distributed programming environment. The concept of dynamic virtual architecture allows modelling of hierarchical resource topologies ranging from individual cores and multi-core processors to more complex parallel computers and distributed Grid infrastructures. On top of this virtual architecture, objects can be explicitly distributed, migrated, and invoked, enabling high-level user control of parallelism, locality, and load balancing.#R##N##R##N#We evaluate the JavaSymphony programming model and the new shared memory run-time environment for six real applications and benchmarks on a modern multi-core parallel computer. We report scalability analysis results that demonstrate that JavaSymphony outperforms pure Java implementations, as well as other alternative related solutions.	manycore processor	Muhammad Aleem;Radu Prodan;Thomas Fahringer	2010		10.1007/978-3-642-15291-7_15	multi-core processor;shared memory;computer architecture;parallel computing;computer science;load balancing;software development;operating system;distributed computing;programming paradigm;programming language	HPC	-7.503074685894253	43.720089466425556	29595
b7a2bd2ca28b66a681fa4a77256d9f73fc91f5c5	the initium rjs screensaver: part 1, ms windows	selected works;bepress	This paper describes a Java-based screensaver technology for the Initium Remote Job Submission (RJS) system running on Microsoft Windows. Initium RJS is a Java Web Start (JAWS) technology that enables Java-based grid computing. The Initium RJS system uses screensavers to enable CPU scavenging. A screensaver is a program that activates during a period of user-computer quiescence. Detection of this quiet time enables the use of otherwise wasted CPU cycles. When the period of user-computer quiescence ceases, the screensaver terminates any currently running compute jobs, releasing the computer back for general use. Such a program constitutes a first step toward utilizing otherwise idle compute resources in a grid computing system. We are motivated to study screen-savers because they represent a minimally invasive technology for volunteering CPU services. Typically, computers are used between 40 and 60 hours out of a 168-hour week. This represents approximately 35% utilization. Screen-saver based cycle scavenging improves this number dramatically. We are motivated to provide a Java-based environment in order to capitalize on Java's inherent heterogeneity. This makes a larger universe of grid-compute servers available, without requiring changes to the computational program. This paper is part 1 of a 5 part series on Java-based screensavers. Part 1 addresses the creation of screensavers on MS Windows platform systems. Parts 2 and 3 address the Linux and Macintosh-based screensavers. Part 4 addresses the automatic deployment and installation of the screensavers. Part 5 speaks to the problem of integration of the screensavers with the Initium RJS system.	central processing unit;computation;computer;grid computing;java web start;job stream;linux;microsoft windows;quiescence search;screensaver;software deployment	Douglas A. Lyon	2006	Journal of Object Technology	10.5381/jot.2006.5.4.c1	computer science	HPC	-27.899238312425133	52.85927332761482	29635
42b954edcce30e97c47b08e23c34154b3cb5e524	integrating behavioural and performance analysis with topology information	multiprocessor interconnection networks;graph theory;naming services;naming;graph theory communicating sequential processes naming services parallel processing computational linguistics stochastic processes software performance evaluation;stochastic π calculus;axioms;csp like stochastic process algebra;software performance evaluation;system allocations;expected performance topology information performance analysis behavioural analysis spl pi calculus concurrent process model naming probabilistic information csp like stochastic process algebra stochastic spl pi calculus semantic language description axioms language distributed systems system allocations fixed network architecture;stochastic calculus;semantic language description;topology information;network topology;communicating sequential processes;probabilistic information;system recovery;stochastic processes;algebra;stochastic process algebra;calculus;carbon capture and storage;behavioural analysis;performance analysis;network architecture;concurrent process model;computational linguistics;π calculus;language;distributed systems;performance analysis algebra stochastic processes information analysis delay calculus network topology carbon capture and storage system recovery multiprocessor interconnection networks;information analysis;concurrent process;parallel processing;expected performance;fixed network architecture	Weconsider -calculus, a model of concurrent processes based on the notion of naming, extended with probabilistic information. The new language is an evolution of CSP like stochastic process algebra that we call stochastic calculus. Furthermore, we integrate the semantic description of the language with topology information expressed through axioms. The new formalism is suitable to study behavioural and performance property of distributed systems. In particular, we can compare different allocations of systems on a fixed network architecture with respect to expected performance.	algorithm;concurrency (computer science);distributed computing;interconnection;interpolation;network architecture;network topology;process calculus;profiling (computer programming);semantics (computer science);stochastic process	Corrado Priami	1996		10.1109/HICSS.1996.495500	parallel processing;stochastic calculus;network architecture;carbon capture and storage;π-calculus;computer science;graph theory;theoretical computer science;computational linguistics;communicating sequential processes;database;distributed computing;language;axiom;data analysis;programming language;network topology	Logic	-30.639516003494087	32.40721695937015	29676
d8c72e7f3af03d2678a22ff4ec55bafc9a682b36	towards the reproduction of selected dynamic loop scheduling experiments using simgrid-simdag		Modern computing architectures exhibit increasing parallelism. Therefore, dynamic loop scheduling (DLS) plays an increasing role in the performance optimization of parallel applications executing on the modern computing architectures. In the previous decades, there was a large body of research concerning DLS techniques. Reproduction of the DLS experiments is significant for ensuring the trustworthiness of the DLS techniques implementation in modern scheduling tools or within new scientific applications. The results of executing the implemented DLS techniques are expected to be in agreement with the results reported in earlier work. The present work is a step towards the reproduction of the experiments that introduced the well-known DLS technique named factoring (FAC). Studying scheduling techniques via simulation is favorable compared to native execution to have control over all the factors that may affect the performance. The use of simulation in this work is essential for the reproduction of the scheduling experiments performed on computing systems that no longer exist. This work shows that the self scheduling technique with matrix multiplication kernel has a significantly poorer performance on the modern system considered in this study than on the past system.	centralized computing;computation;computer architecture;dls format;experiment;fly-by-wire;integer factorization;iteration;kernel (operating system);loop scheduling;machine code;mathematical optimization;matrix multiplication;parallel computing;scheduling (computing);shared memory;simgrid;simulation;the matrix;trust (emotion);whole earth 'lectronic link	Ali Mohammed;Ahmed Eleliemy;Florina M. Ciorba	2017	2017 IEEE 19th International Conference on High Performance Computing and Communications; IEEE 15th International Conference on Smart City; IEEE 3rd International Conference on Data Science and Systems (HPCC/SmartCity/DSS)	10.1109/HPCC-SmartCity-DSS.2017.85	trustworthiness;distributed computing;loop scheduling;scheduling (computing);matrix multiplication;computer science	HPC	-8.247588327030849	46.55745734850066	29691
ae0d1dc3ea678bb830d7beeaf887087df2ceefc5	trace-based load characterization for gernerating performance software models	developpement logiciel;modelizacion;distributed system;workload characterization;architecture systeme;systeme reparti;formal specification;software traces;community development;design and development;program design;reseau ordinateur;software performance evaluation;system monitoring;conception programme;analytic performance models;ingenieria logiciel;software engineering;software performance;computer network;character generation software performance delay software design queueing analysis operating systems telephony failure analysis risk analysis performance analysis;specification formelle;algorithme;modelisation;early warning;algorithm;especificacion formal;performance engineering;layered queuing;sistema repartido;software life cycle performance models software designs trace based load characterization resource saturation excessive delay angiotrace executable design automated model development concurrent software distributed software synchronous communication layered queuing network model asynchronous interactions synchronous interactions asynchronous messages telephony software;monitoring;desarrollo logicial;scheduling;analyse performance;software development;performance analysis;performance model;red ordenador;genie logiciel;arquitectura sistema;ordonamiento;software life cycle;queuing networks;performance prototyping;monitorage;software design;system architecture;system monitoring software performance evaluation computer telephony integration;monitoreo;communication;modeling;comunicacion;ordonnancement;concepcion programa;computer telephony integration;algoritmo;analisis eficacia	Performance models of software designs can give early warnings of problems such as resource saturation or excessive delays. However models are seldom used because of the considerable effort needed to construct them. The ANGIOTRACE/sup TM/ was developed to gather the necessary information from an executable design and develop a model in an automated fashion. It applies to distributed and concurrent software with synchronous (send-reply or RPC) communications, developing a layered queuing network model. The trace-based load characterization (TLC) technique presented here extends the ANGIOTRACE/sup TM/ to handle software with both synchronous and asynchronous interactions. TLC also detects interactions which are effectively synchronous or partly-synchronous (forwarding) but are built up from asynchronous messages. These patterns occur in telephony software and in other systems. The TLC technique can be applied throughout the software life-cycle, even after deployment.		Curtis E. Hrischuk;C. Murray Woodside;Jerome A. Rolia;Rod Iversen	1999	IEEE Trans. Software Eng.	10.1109/32.748921	embedded system;system monitoring;community development;real-time computing;systems modeling;software performance testing;performance engineering;computer science;software design;software development;operating system;software engineering;warning system;formal specification;program design language;scheduling;software development process	SE	-25.879945213205584	41.09779535674508	29696
5aa0805d55bad6c40baa2bc7239a3b2838ffde84	an example of the use of public health grid (phgrid) technology during the 2009 h1n1 influenza pandemic	gestion integrada;trust;distributed system;gestion integree;record format;confiance;haute performance;architecture systeme;systeme reparti;confidencialidad;distributed database;service oriented framework and middleware;public health grid;surveillance;network security;format enregistrement;salud publica;opportunistic networks;securite informatique;logicial personalizado;distributed computing;base repartida dato;timely data exchange;hombre;integrated management;h1n1 influenza pandemic;indice aptitud;administration publique;orientado servicio;confidentiality;intergiciel;flu pandemic;grid;computer security;vida privada;indice aptitude;confidentialite;confidence;vigilancia;sistema repartido;private life;monitoring;base de donnees repartie;confianza;capability index;rejilla;seguridad informatica;human;distributed databases;alto rendimiento;grille;calculo repartido;sante publique;vie privee;middleware;arquitectura sistema;civil service;oriente service;monitorage;formato grabacion;administracion publica;system architecture;service oriented framework;usa;monitoreo;security;grid computing;high performance;calcul reparti;privacy and trust;privacy;public health;public health surveillance;service oriented;homme;decentralised information	Historically, public health surveillance systems in the USA have been designed as registries targeting specific public health issues that collect data from certain population groups to answer particular questions. This resulted in disparate public health information systems that can rarely address new needs without extensive redesign. Such a design limits the ability of public health professionals to address emerging public health threats when data need to be collected from different areas of public health practice; the 2009 H1N1 influenza pandemic posed such a challenge. The US Centers for Disease Control and Prevention’s Public Health Informatics and Technology Program Office (CDC/PHITPO) and its partners explored a decentralised information architecture using the Public Health Grid (PHGrid). Through the exploration of PHGrid capabilities, CDC/PHITPO developed a pilot project to demonstrate a method for secure and timely data exchange using simulated data in aggregate format.	aggregate data;informatics;information architecture;information system;threat (computer)	Terry Boyd;Brian Lee;Thomas G. Savel;John Stinn;Gautam Kesarinath	2011	IJGUC	10.1504/IJGUC.2011.040602	health policy;public health informatics;simulation;international health;confidentiality;telecommunications;process capability index;computer science;middleware;confidence;trustworthy computing;grid;privacy;distributed database;computer security;grid computing	HCI	-27.93513550033794	43.66746799336426	29702
406fef895ecdbdcf0fa259894b65b22d99093c74	ithreads: a threading library for parallel incremental computation	incremental computation;concurrent dynamic dependence graph cddg;self adjusting computation;shared memory multithreading;release consistency rc memory model;memoization	Incremental computation strives for efficient successive runs of applications by re-executing only those parts of the computation that are affected by a given input change instead of recomputing everything from scratch. To realize these benefits automatically, we describe iThreads, a threading library for parallel incremental computation. iThreads supports unmodified shared-memory multithreaded programs: it can be used as a replacement for pthreads by a simple exchange of dynamically linked libraries, without even recompiling the application code. To enable such an interface, we designed algorithms and an implementation to operate at the compiled binary code level by leveraging MMU-assisted memory access tracking and process-based thread isolation. Our evaluation on a multicore platform using applications from the PARSEC and Phoenix benchmarks and two case-studies shows significant performance gains.	algorithm;benchmark (computing);binary code;compiler;computation;dynamic problem (algorithms);dynamic-link library;incremental computing;library (computing);memory management unit;multi-core processor;parsec;posix threads;shared memory;thread (computing)	Pramod Bhatotia;Pedro Fonseca;Umut A. Acar;Björn B. Brandenburg;Rodrigo Rodrigues	2015		10.1145/2694344.2694371	parallel computing;real-time computing;memoization;computer science;theoretical computer science;programming language	Arch	-13.398257825281716	47.768524617434345	29731
b6cbda19a1a0904046719632d3466c20547af23f	service-oriented middleware for financial monte carlo simulations on the cell broadband engine	monte carlo simulation;phastgrid middleware;financial monte carlo simulation;completion time;huge impact;huge interest;job completion time;simulation result;single simulation;workload distribution;service-oriented middleware;cell broadband engine;financial monte carlo simulation	Financial Monte Carlo simulations are computationally intensive applications that must meet tight deadlines in terms of job completion times. The completion time might have a huge impact on the financial profits made from decisions derived from the simulation results. Naturally, there is a huge interest in being able to simulate as fast as possible. While single simulations can be done on one machine, decisions often depend on portfolios of simulations. Distributing the workload among resources is crucial to achieve low latency. In this article we present a combination of a middleware with a high-performance implementation of an Asian options evaluation code on the Cell Broadband Engine (CBE). We handle workload distribution with our PHASTGrid middleware and provide users with a web service interface to the whole infrastructure. The CBE is particularly suitable for Monte Carlo simulations. We implemented a well-known algorithm on both the CBE and the Intel x86 multicore architectures. Both codes are integrated in our middleware, allowing a direct comparison of the performance and scalability. In addition to the Monte Carlo simulation, we also use different applications and compare our middleware with Globus. Copyright © 2009 John Wiley & Sons, Ltd.	algorithm;amazon elastic compute cloud (ec2);cell (microprocessor);code;concurrency control;disk staging;exploit (computer security);john d. wiley;monte carlo method;multi-core processor;parallel computing;processor design;requirement;runtime system;scalability;service-oriented device architecture;service-oriented middleware;simulation;test case;throughput;value (ethics);web service;x86	Tiberiu Rotaru;Mathias Dalheimer;Franz-Josef Pfreundt	2010	Concurrency and Computation: Practice and Experience	10.1002/cpe.1529	parallel computing;real-time computing;simulation;computer science;operating system;service-oriented architecture;middleware;database;distributed computing;grid computing;monte carlo method;low latency	HPC	-21.69159961117633	58.46113481851471	29759
40ef73d81f79de79c8871966361dfebb6c2878f7	implementation and performance evaluation for a computation-intensive climate simulation application			climate model;computation;performance evaluation;simulation	Hao Wang;G. M. Prabhu;E. S. Takle;R. Todi	1999			theoretical computer science;computer science;computation	HPC	-7.458323019611746	38.45241729366264	29771
7641b78b00ac83ce13c7fddf1e0de7acddafec96	xml schema based faultset definition to improve faults injection tools interoperability	gui based application xml schema based faultset definition faults injection tools interoperability formalization approach software implemented fault injection swifi tools;xml schema;swifi;software fault tolerance;xml faultset;tool interoperability;software implemented fault injection;formalization approach;experimental dependability;experience management;engineering and technology;graphical user interfaces;teknik och teknologier;annan teknik;xml schema based faultset definition;other engineering and technologies;xml;swifi tools;gui based application;floating point;xml fault diagnosis graphical user interfaces open systems software fault tolerance;xml faultset swifi fault injection experimental dependability;fault injection;open systems;fault diagnosis;faults injection tools interoperability	This paper describes an XML schema formalization approach for the definition of basic fault sets which specify memory and/or register value corruption in microprocessor-based systems. SWIFI (software implemented fault injection) tools use fault injectors to carry out the fault injection campaign defined in a GUI-based application. However, the communication between the fault injector and the application is defined in an ad-hoc manner. Through this proposed XML schema definition different injectors could be used to carry out the same fault set injection. To validate this approach floating point register and memory corruptions with temporal triggers and routine interception mechanisms to carry out argument and return value, corruption has been considered. Moreover, an experimental tool called Exhaustifreg, consisting of a GUI Java application for defining the fault sets and injection policies and two injectors for SPARC and i386 architectures under RTEMS, has been developed. The XML-based approach improves the interoperability between SWIFI tools by uncoupling the injectors from the experiment manager in charge of the fault campaign.	bos/360;daemon (computing);data structure;experiment;fault injection;graphical user interface;hoc (programming language);interoperability;java;markup language;microprocessor;operating system;rtems;return statement;sparc;vocabulary;xml schema	Antonio Dasilva;José-Fernán Martínez;Lourdes López-Santidrián;Ana Belén García;Vicente Hernández	2008	2008 Third International Conference on Dependability of Computer Systems DepCoS-RELCOMEX	10.1109/DepCoS-RELCOMEX.2008.26	computer science;database;programming language;world wide web	SE	-33.450918156964256	39.79816693169641	29775
6d7920c00f7ec19d7c044de81e6d78dd0f66f4d6	trends in virtualized user environments		Virtualized environments can make forensics investigation more difficult. Technological advances in virtualization tools essentially make removable media a PC that can be carried around in a pocket or around a neck. Running operating systems and applications this way leaves very little trace on the host system. This paper will explore all the newest methods for virtualized environments and the implications they have on the world of forensics. It will begin by describing and differentiating between software and hardware virtualization. It will then move on to explain the various methods used for server and desktop virtualization. Next, it will explain how virtualization affects the basic forensic process. Finally, it will describe the common methods to find virtualization artifacts and identify virtual activities that affect the examination process of certain virtualized user environments.	desktop virtualization;hardware virtualization;operating system;personal computer;removable media;server (computing)	Diane Barrett	2008	JDFSL		embedded system;full virtualization;real-time computing;virtualization;thin provisioning;application virtualization;computer science;virtual machine;data virtualization;operating system;hardware virtualization;service virtualization;storage virtualization	HCI	-28.79049699586112	55.88555598733724	29810
3d735363af5737ffb84a81c93905fec50514cc3b	irm: integrated file replication and consistency maintenance in p2p systems	p2p system;peer to peer file sharing systems;time varying;distributed hash table;approximation algorithms;routing;peer to peer computing maintenance internet large scale systems computer science high performance computing telephony system performance costs character generation;replicator dynamic;maintenance engineering;system performance;additives;peer to peer computing file organisation;time varying file query;integrated file replication;time varying file query integrated file replication consistency maintenance p2p systems peer to peer file sharing systems update polling;file sharing;consistency maintenance;peer to peer computing;dynamic adaptation;peer to peer;high efficiency;time frequency analysis;p2p systems;update polling;file organisation	In peer-to-peer file sharing systems, file replication and consistency maintenance are widely used techniques for high system performance. Despite significant interdependencies between them, these two issues are typically addressed separately. Most file replication methods rigidly specify replica nodes, leading to low replica utilization, unnecessary replicas and hence extra consistency maintenance overhead. Most consistency maintenance methods propagate update messages based on message spreading or a structure without considering file replication dynamism, leading to inefficient file update and hence high possibility of outdated file response. This paper presents an Integrated file Replication and consistency Maintenance mechanism (IRM) that integrates the two techniques in a systematic and harmonized manner. It achieves high efficiency in file replication and consistency maintenance at a significantly low cost. Instead of passively accepting replicas and updates, each node determines file replication and update polling by dynamically adapting to time-varying file query and update rates, which avoids unnecessary file replications and updates. Simulation results demonstrate the effectiveness of IRM in comparison with other approaches. It dramatically reduces overhead and yields significant improvements on the efficiency of both file replication and consistency maintenance approaches.	consistency model;information rights management;interdependence;overhead (computing);peer-to-peer file sharing;simulation	Haiying Shen	2008	2008 Proceedings of 17th International Conference on Computer Communications and Networks	10.1109/ICCCN.2008.ECP.62	maintenance engineering;self-certifying file system;routing;real-time computing;time–frequency analysis;food additive;computer science;chord;operating system;journaling file system;database;distributed computing;file system fragmentation;global namespace;file sharing;replication;computer network	DB	-22.046367874889825	49.47172415764848	29858
be7d8bc0a4f668084318ba81ec1fdc1865df7b1d	authorisation in grid computing	grid applications;qa 76 software;computer programming;global grid forum;grid computing	This paper briefly surveys how authorisation in Grid computing has evolved during the last few years, and presents the latest developments in which Grid applications can utilise a policy controlled authorisation infrastructure to make decisions about which users are allowed to perform which actions on which Grid resources. The paper describes the Global Grid Forum SAML interface for connecting policy based authorisation infrastructures to Grid applications, and then describes the PERMIS authorisation infrastructure which has implemented this interface. The paper concludes with suggestions about how this work will evolve in the future. 2005 Elsevier Ltd. All rights reserved.	authorization;grid computing;permis;security assertion markup language	David Chadwick	2005	Inf. Sec. Techn. Report	10.1016/j.istr.2004.11.004	semantic grid;computer science;data mining;computer programming;database;world wide web;drmaa;grid computing	HPC	-32.86435698963129	52.897840290355745	29916
f80c560b352560ee7cf03be822fa9f2a8a73ae57	air: adaptive index replacement in hadoop	indexing clustering algorithms prediction algorithms adaptation models atmospheric modeling;algorithm leb 2 hadoop distributed filesystem de facto standard large dataset data management system hadoop mapreduce hive stratosphere indexing technique aggressive indexing hdfs replica multiple clustered index adaptive indexing query processing natural redundancy space constraint adaptive index replacement problem online air problem leastexpectedbenefit k online index selection algorithm;query processing database indexing distributed databases parallel processing	The Hadoop Distributed Filesystem has become the de-facto standard for storing large datasets in data management systems such as Hadoop MapReduce, Hive, and Stratosphere. Though HDFS was originally designed to support scan-oriented operations, recently several techniques for HDFS have been developed to allow for efficient indexing. One of these indexing techniques is aggressive indexing, i.e. HDFS replicas are immediately indexed at upload time before touching any disk - creating multiple clustered indexes almost for free on the way. A second technique is adaptive indexing, i.e. HDFS blocks are only indexed on demand as a side effect of query processing. Though these techniques provide impressive speed-ups in terms of query processing, they totally ignored the costs involved with storing a large number of replicas of a particular dataset. The HDFS-variants of adaptive indexing were already designed to leverage the natural redundancy that comes with HDFS, typically storing a dataset three times anyway. However, it is questionable whether storing an unlimited number of replicas for a dataset is a practical solution. Therefore, this paper is the first to analyze adaptive indexing under a space constraint, i.e. we assume that indexes are adaptively created and deleted. We coin this problem the Adaptive Index Replacement problem. We present a new algorithm to solve the online AIR problem called LeastExpectedBenefit-K and compare it with several existing state-of-the-art online Index Selection algorithms. We present a comprehensive study evaluating ten different algorithms. Our results show that our algorithm LEB-2 is efficient and robust and a good choice in practice.	analysis of algorithms;apache hadoop;apache hive;bcjr algorithm;computer data storage;database;input/output;mapreduce;selection algorithm;selectivity (electronic);upload	Stefan Schuh;Jens Dittrich	2015	2015 31st IEEE International Conference on Data Engineering Workshops	10.1109/ICDEW.2015.7129539	computer science;theoretical computer science;data mining;database	DB	-13.956621173707232	54.088044934827636	29948
1bb22cae9fe800532234a6cc6b0fb7335f617783	achieving performance consistency in heterogeneous clusters	distributed system;load balancing algorithm heterogeneous clusters hash based randomization distributed system load management shared disk cluster adaptive nonuniform randomization virtual processor workload configuration cluster configuration;heterogeneous cluster;resource allocation;load management scalability hardware computer science clustering algorithms table lookup computer architecture buildings large scale systems high performance computing;grid computing resource allocation workstation clusters virtual storage;anu;load balance;workstation clusters;grid computing;virtual storage;uniform distribution	Hash-based randomization is a powerful technique used in clusters and distributed systems for load management. It offers uniform distribution, efficient addressing, little shared state, and scalability. However, simple hash-based randomization is unable to deal with skew and heterogeneity and, therefore, cannot achieve load balance in many environments. Virtual processors have been proposed as a solution to simple randomization's problem. We evaluate an alternative load management scheme for heterogeneous, shared-disk clusters. Our scheme directly tunes hash-based randomized load placement using a technique called adaptive, nonuniform (ANU) randomization [2003] and compares favorably to the virtual processor approach. It provides the load balancing benefits of virtual processors with less shared state. It also automatically adapts to workload and cluster configuration changes, such as failure and recovery and adding or removing servers, without human involvement. Experimental results show that our scheme outperforms virtual processors and performs comparably to prescient load-balancing algorithms. They also show that our system maintains consistent performance across all servers while moving a minimal amount of load.	address space layout randomization;central processing unit;computer cluster;distributed computing;load balancing (computing);load management;map;randomized algorithm;scalability;self-replicating machine;server (computing);system configuration;table (database)	Changxun Wu;Randal C. Burns	2004	Proceedings. 13th IEEE International Symposium on High performance Distributed Computing, 2004.	10.1109/HPDC.2004.1	parallel computing;real-time computing;resource allocation;computer science;load balancing;operating system;distributed computing;uniform distribution;grid computing	HPC	-20.87561232348204	52.0340714631217	29957
1e89ec2f2ab642ff1382de044ce216bfff8a03c7	virtual dcs and specification	text;simulation software;ml;management layer;automation and control;distributed control	In considering advancements in distributed control systems (DCS), this research is directed to design and develop an application level software tool for distributed automation. The study defines specification, methodology, and prototype design of an application tool that is capable of providing services to the proposed management layer (ML). The ML integrates simulation platform, a top-level ware, by using which distributed control network (DCN) design can be achieved. The developed platform utilises the benefit of object oriented and client-server approach, respectively.	client–server model;content-control software;control function (econometrics);distributed control system;dynamic circuit network;java virtual machine;programming tool;prototype;requirement;server (computing);simulation;warez	Sanjat Mishra;Nitaigour Mahalik	2011	IJICT	10.1504/IJICT.2011.043629	embedded system;real-time computing;simulation;simulation software;computer science;operating system;distributed design patterns;computer security;computer network	Embedded	-28.732777122366585	41.37903079562067	29988
f17dbca05103ae2740c1762d4c56663f8da62f92	cloud federation to elastically increase mapreduce processing resources		MapReduce is a programming model that allows users the parallel processing of large data sets into a cluster. One of its major implementation is the Apache Hadoop framework that couples both big data storage and processing features. In this paper, we aim to make Hadoop Cloud-like and more resilient adding a further level of paral- lelization by means of cooperation of federated Clouds. Such an approach allows Cloud providers to elastically scale up/down the system used for parallel job processing. More specifically, we present a system prototype integrating the Hadoop framework and CLEVER, a Message Oriented Middleware supporting federated Cloud environments. In addition, in or- der to minimize overhead of data transmission among federated Clouds, we considered a shared memory system based on the Amazon S3 Cloud Storage Provider.Experimental results highlight the major factors in- volved for job deployment in a federated Cloud environment.	mapreduce	Alfonso Panarello;Maria Fazio;Antonio Celesti;Antonio Puliafito;Massimo Villari	2014		10.1007/978-3-319-14313-2_9	parallel computing;computer science;operating system;database;distributed computing;world wide web	Arch	-19.16230533656543	52.74160593386043	30038
db34b6dca375db617174c89291d9bc953953d36f	software based fault tolerance against byzantine failures	byzantine failures;fault tolerant;process monitoring;byzantine fault tolerant;transient fault;computer application;byzantine faults;software design;state transition	The proposed software technique is a very low cost and an effective solution towards designing Byzantine fault tolerant computing application systems that are not so safety critical. It does not rely on multiple versions of software running simultaneously on multiple machines. The proposed software approach is to mask various hardware random errors on adopting the so-called, ESVP (an enhanced single -version program) scheme, while an application is being executed. It is not intended to eliminate software design bugs. In other words, it is assumed that code is correct and the faulty behavior is only due to transient or Byzantine faults affecting an application system. Implementation of this approach is also easy. A test program's present state is compared with its pre-computed state also in order to detect state transition fault also. ESVP is intended to be suitable for a computerbased process monitoring system.	byzantine fault tolerance;microprocessor;overhead (computing);precomputation;software bug;software design;state transition table	Goutam Kumar Saha	2006	CLEI Electron. J.		fault tolerance;real-time computing;computer science;engineering;quantum byzantine agreement;software design;distributed computing;byzantine fault tolerance;computer security;software fault tolerance	SE	-22.999665377156564	41.06675565935766	30061
c35f6751e4bc773e1550702ddb2fa0d0d3d66cb5	a microprogrammed storage management system for a paged stack machine	programming language;storage management;instruction generator;macro generation;address control;microprogramming;architecture	The development of a storage management scheme for MEMBERS, an emulated stack machine incorporating a virtual store and paging, is described. The approach used employs an anologue of the 'working set' concept of Denning. Information contained in the activation stack for each process is used to identify a 'Top Stack Set' for the process. The set of all the top stack sets defines the pages that are held in main storage.  The architecture of the MEMBERS machine incorporates an activation stack in which pointers can be distinguished from other data. The basic programming language for the machine is designed to encourage a modular structure for programs, so the activation records in the stack for the recently entered procedures contain pointers to an approximation of the working set. A descriptor-based addressing structure enables address mapping to be performed without the use of a page table, so no further gains can be obtained through the use of associative page-register hardware.  The use of microprogramming for the implementation of the storage management system is discussed and some preliminary estimates of its performance are given.	approximation;basic programming;computer data storage;dorothy e. denning;emulator;hierarchical storage management;microcode;online shopping;page table;paging;programming language;stack overflow;stack machine;working set	Panos Macres;George Coulouris	1974		10.1145/800118.803851	stack trace;parallel computing;call stack;computer hardware;stack;computer science;architecture;operating system;stack register;database;programming language	OS	-26.648935191956976	37.14771596117433	30083
0d04db954be019ef2970d87c3dc614cb838a52c9	eager meets lazy: the impact of write-buffering on hardware transactional memory	content management;multicores;prefetches;relative performance;structure optimization;multicores hardware transactional memory;execution time;detailed modeling;storage management;sound designs;hardware transactional memory;storage management microprocessor chips multiprocessing systems parallel processing;structural optimization;chip;workload characteristics;buffering mechanism write buffering optimization hardware transactional memory system speculative versioning policy contention management policy chip multiprocessing system eager conflict resolution mechanism lazy conflict resolution mechanism parallel architecture latency hiding effect prefetch effect abort effect;sound design;parallel architectures;chip multiprocessing;interfacial structures;coherence protocols prefetching optimization tiles hardware;processor cores;design points;multiprocessing systems;memory hierarchy;parallel architecture;versioning;transactional memory;conflict resolution;structural design;parallel processing;storage allocation computer;management policy;microprocessor chips	Hardware transactional memory (HTM) systems have been studied extensively along the dimensions of speculative versioning and contention management policies. The relative performance of several designs policies has been discussed at length in prior work within the framework of scalable chip-multiprocessing systems. Yet, the impact of simple structural optimizations like write-buffering has not been investigated and performance deviations due to the presence or absence of these optimizations remains unclear. This lack of insight into the effective use and impact of these interfacial structures between the processor core and the coherent memory hierarchy forms the crux of the problem we study in this paper. Through detailed modeling of various write-buffering configurations we show that they play a major role in determining the overall performance of a practical HTM system. Our study of both eager and lazy conflict resolution mechanisms in a scalable parallel architecture notes a remarkable convergence of the performance of these two diametrically opposite design points when write buffers are introduced and used well to support the common case. Mitigation of redundant actions, fewer invalidations on abort, latency-hiding and prefetch effects contribute towards reducing execution times for transactions. Shorter transaction durations also imply a lower contention probability, thereby amplifying gains even further. The insights, related to the interplay between buffering mechanisms, system policies and workload characteristics, contained in this paper clearly distinguish gains in performance to be had from write-buffering from those that can be ascribed to HTM policy. We believe that this information would facilitate sound design decisions when incorporating HTMs into parallel architectures.	coherence (physics);copy-on-write;data buffer;downgrade;dynamic data;elegant degradation;html;lazy evaluation;memory coherence;memory hierarchy;multi-core processor;multiprocessing;parallel computing;scalability;software transactional memory;speculative execution;throughput;transaction processing;transactional memory;write buffer	Anurag Negi;J. Rubén Titos Gil;Manuel E. Acacio;José M. García;Per Stenström	2011	2011 International Conference on Parallel Processing	10.1109/ICPP.2011.63	sound design;parallel processing;transactional memory;parallel computing;real-time computing;computer science;operating system;conflict resolution;distributed computing	HPC	-11.016812198608408	50.95114516569426	30096
1117447413e1ea10798add80b83d85b7375a3af8	experience with a software-defined machine architecture	lenguaje programacion;titan;machine language;interfase usuario;optimisation;lenguaje maquina;architecture systeme;compilateur;optimizacion;programming language;profiling;register allocation;user interface;interprocedural;sistema informatico;langage evolue;graph coloring;computer system;compiler;abstract machine;information gathering;intermediate language;register windows;target language;time use;risc;langage programmation;arquitectura sistema;interface utilisateur;lenguaje evolucionado;optimization;systeme informatique;system architecture;instruction scheduling;high level language;langage machine;compilador;pipeline scheduling	We have built a system in which the compiler back end and the linker work together to present an abstract machine at a considerably higher level than the actual machine. The intermediate language translated by the back end is the target language of all high-level compilers and is also the only assembly language generally available. This lets us do intermodule register allocation, which would be harder if some of the code in the program had come from a traditional assembler, out of sight of the optimizer. We do intermodule register allocation and pipeline instruction scheduling at link time, using information gathered by the compiler back end. The mechanism for analyzing and modifying the program at link time is also useful in a wide array of instrumentation tools.	abstract machine;assembly language;compiler;high- and low-level;instruction scheduling;link time;linker (computing);mathematical optimization;register allocation;scheduling (computing)	David W. Wall	1992	ACM Trans. Program. Lang. Syst.	10.1145/129393.129395	reduced instruction set computing;compiler;parallel computing;real-time computing;machine code;computer science;graph coloring;abstract machine;profiling;instruction scheduling;programming language;intermediate language;user interface;register allocation;high-level programming language;titan	PL	-19.110048054496936	36.607140651884926	30111
5af15599f881dca25e4e069c1427daa2102db196	a fast implementation and performance analysis of collisionless n-body code based on gpgpu	optimization;gpgpu	Abstract We have implemented a fast collisionless N -body code which runs on GPU, the peak performance of the code reaches 767 GFLOPS (corresponds to 74% of theoretical peak performance for our measurement environment) under an assumption of computational cost is 26 ﬂoating-point operations per interaction. Our implementation is 1.7 times faster than CUDA SDK in maximum case (for low N region) due to our proposal algorithm of force accumulation without synchronization. Detailed performance analysis clariﬁes that the performance metrics of collisionless N -body simulations on GPU are only two quantities: ﬁrst one is the number of running streaming multiprocessors and another is the clock cycle ratio of latency to access global memory and operations to calculate gravitational interaction.	general-purpose computing on graphics processing units;profiling (computer programming)	Yohei Miki;Daisuke Takahashi;Masao Mori	2012		10.1016/j.procs.2012.04.011	parallel computing;real-time computing;computer science;theoretical computer science;operating system	HPC	-5.187348019125638	39.5571030401409	30139
da3f88f9291948e92c18c28e0ea04148171bc58b	decoupled value prediction on trace processors	performance evaluation;parallel architectures;performance value prediction trace processors superscalar architectures trace processor instruction fetch stage hybrid predictor dynamic classification execution driven simulation;data dependence;computer science hardware performance gain electronic switching systems parallel processing registers clocks decoding;execution driven simulation;performance evaluation parallel architectures;value prediction	Value prediction is a technique that breaks true data dependences by predicting the outcome of an instruction, and executes speculatively its data-dependent instructions based on the predicted outcome. In this paper, we address several implementation issues for value prediction which are important on wide-issue superscalar architectures, and present a value prediction scheme based on the trace processor [18]. The scheme decouples the value prediction from the instruction fetch stage and use a hybrid predictor with dynamic classification. We use execution-driven simulation to study the performance of such a scheme using SPECint95 benchmarks.	baseline (configuration management);benchmark (computing);cpu cache;central processing unit;critical path method;data dependency;kerrison predictor;specint;simulation;speedup;superscalar processor;wide-issue	Sang Jeong Lee;Yuan Wang;Pen-Chung Yew	2000		10.1109/HPCA.2000.824353	computer architecture;parallel computing;real-time computing;computer science;operating system	Arch	-7.179859717950365	50.84269771026886	30156
90b2e3db0f9a2d783382e6cfe69c927c56efc82d	characterizing and evaluating a key-value store application on heterogeneous cpu-gpu systems	databases;simd;cache storage;memory access pattern;kernel;paper;server;memory management;heterogeneous systems;key value store;high performance computing;server gpgpu simd opencl key value store;ati;supercomputer;physical hardware;memory access;gpgpu;key value look up handler heterogeneous cpu gpu system graphics processing unit supercomputer high performance computing hpc parallelism server workload control flow memory access pattern key value store middleware application memcached heterogeneous hardware gpu simulator opencl physical hardware;servers;parallelism;hpc;graphics processing unit payloads servers hardware memory management kernel;ati radeon hd 6310;graphics processing units;control flow;high performance computer;memcached;heterogeneous hardware;gpu simulator;ati radeon hd 6550;graphic processing unit;middleware;payloads;table lookup cache storage graphics processing units middleware parallel processing;key value store middleware application;computer science;heterogeneous cpu gpu system;graphics processing unit;opencl;table lookup;ati radeon hd 5870;server workload;key value look up handler;parallel processing;hardware	The recent use of graphics processing units (GPUs) in several top supercomputers demonstrate their ability to consistently deliver positive results in high-performance computing (HPC). GPU support for significant amounts of parallelism would seem to make them strong candidates for non-HPC applications as well. Server workloads are inherently parallel; however, at first glance they may not seem suitable to run on GPUs due to their irregular control flow and memory access patterns. In this work, we evaluate the performance of a widely used key-value store middleware application, Memcached, on recent integrated and discrete CPU+GPU heterogeneous hardware and characterize the resulting performance. To gain greater insight, we also evaluate Memcached's performance on a GPU simulator. This work explores the challenges in porting Memcached to OpenCL and provides a detailed analysis into Memcached's behavior on a GPU to better explain the performance results observed on physical hardware. On the integrated CPU+GPU systems, we observe up to 7.5X performance increase compared to the CPU when executing the key-value look-up handler on the GPU.	attribute–value pair;central processing unit;computer graphics;control flow;discrete system;general-purpose computing on graphics processing units;graphics processing unit;key-value database;list of amd accelerated processing unit microprocessors;lookup table;memcached;middleware;opencl api;parallel computing;server (computing);supercomputer	Tayler H. Hetherington;Timothy G. Rogers;Lisa Hsu;Mike O'Connor;Tor M. Aamodt	2012	2012 IEEE International Symposium on Performance Analysis of Systems & Software	10.1109/ISPASS.2012.6189209	computer architecture;supercomputer;parallel computing;computer hardware;computer science;operating system;server	Arch	-5.508965753294045	46.44949225499196	30192
fcfb312b600fe6c6c1b381de2ec9c3e320660ca9	distributed execution of functional programs using serial combinators	parallel calculus;sequential machines computer architecture distributed processing multiprocessing programs program compilers;sequential machines;multiprocessing programs;parallel computing combinators distributed computing functional programming graph reduction lambda calculus load balancing multiprocessing;multiprocessor;distributed processing;lambda calculus;functional programming;computer architecture;parallel processing calculus program processors computer architecture complexity theory computational modeling optimization;programmation fonctionnelle;combinateur;program compilers;lambda calcul;calcul parallele;traitement reparti;program transformation technique distributed execution data flow machine digital simulation functional programs serial combinators automatically decomposing dynamically distributing parallel execution multiprocessor architectures reduction machine research compiler technology sequential machines;multiprocesseur	A general strategy for automatically decomposing and dynamically distributing a functional program is discussed. The strategy is suitable for parallel execution on multiprocessor architectures with no shared memory. It borrows ideas from data flow and reduction machine research on the one hand, and from conventional compiler technology for sequential machines on the other. One of the more troublesome issues in such a system is choosing the right granularity for the parallel tasks. As a solution, the authors describe a program transformation technique based on serial combinators that offers in some sense just the right granularity for this style of computing, and that can be fine-tuned for particular multiprocessor architectures. Simulation demonstrates the success of this approach.	combinatory logic;compiler;dataflow;functional programming;multiprocessing;program transformation;shared memory;simulation	Paul Hudak;Benjamin Goldberg	1985	IEEE Transactions on Computers	10.1109/TC.1985.6312191	embedded system;computer architecture;parallel computing;multiprocessing;computer science;operating system;lambda calculus;programming language;functional programming;algorithm	Arch	-13.409731338634893	38.77244371581295	30200
5f60d6337d21f6931c85fab6f35fee43eafba147	the distributed asci supercomputer project	distributed application;parallelisme;lenguaje programacion;distributed system;cluster computing;systeme reparti;programming language;cooperative environments;programacion paralela;parallel programming;partial order relations;recherche developpement;supercomputer;universiteitsbibliotheek;wide area distributed system;supercomputador;article letter to editor;parallelism;research and development;distributed objects;sistema repartido;paralelismo;investigacion desarrollo;scheduling;langage programmation;ordonamiento;causal relations of actions;parallel languages;parallel applications;ordonnancement;superordinateur;programmation parallele	The Distributed ASCI Supercomputer (DAS) is a homogeneous wide-area distributed system consisting of four cluster computers at different locations. DAS has been used for research on communication software, parallel languages and programming systems, schedulers, parallel applications, and distributed applications. The paper gives a preview of the most interesting research results obtained so far in the DAS project.	computer;distributed computing;parallel computing;scheduling (computing);supercomputer	Henri E. Bal;Raoul Bhoedjang;Rutger F. H. Hofman;Ceriel J. H. Jacobs;Thilo Kielmann;Jason Maassen;Rob van Nieuwpoort;John Romain;Luc Renambot;Tim Rühl;Ronald Veldema;Kees Verstoep;Aline Baggio;Gerco Ballintijn;Ihor Kuz;Guillaume Pierre;Maarten van Steen;Andrew S. Tanenbaum;Gerben Doornbos	2000	Operating Systems Review	10.1145/506106.506115	supercomputer;parallel computing;computer cluster;computer science;theoretical computer science;operating system;distributed computing;programming language;scheduling	HPC	-17.953541111860215	42.1038353526607	30222
4bea12253b1533d156ba7c5078ed50efd0c67c08	parallel hash join algorithms for dynamic load balancing in a shared disks cluster	distributed system;algoritmo paralelo;carga dinamica;cluster computing;dynamic load balancing;systeme reparti;distributed database;parallel algorithm;shared disks;availability;disponibilidad;equilibrio de carga;equilibrage charge;base repartida dato;charge dynamique;dynamic load;algorithme parallele;sistema repartido;base de donnees repartie;load balancing;load balance;modele amas;cluster model;disponibilite;simulation model;hash join;geographic distribution	Most of previous parallel join algorithms assume a shared nothing (SN) cluster, where each database partition is owned by a single processing node. While SN cluster can interconnect a large number of nodes and support a geographically distributed environment, it may suffer from poor facility for load balancing and system availability compared to a shared disks sharing (SD) cluster. In this paper, we first propose a dynamic load balancing strategy by exploiting the characteristics of SD cluster. Then we parallelize conventional hash join algorithms using the dynamic load balancing strategy. We also explore the performance of parallel join algorithms using a simulation model of SD cluster. The experiment results show that the proposed parallel join algorithms can achieve higher potential for dynamic load balancing with the inherent flexibility of SD cluster.	clustered file system;floppy disk;hash join;join (sql);load balancing (computing)	Aekyung Moon;Haengrae Cho	2006		10.1007/11751649_23	parallel computing;real-time computing;computer science;load balancing;operating system;distributed computing;distributed database;computer security	DB	-18.35920455626811	44.9702434694175	30226
0e6acd998f4c4d929359b2438fd54017dfca9fc1	how to efficiently process 100 list variations		Variational execution offers an avenue of efficiently analyzing configurable systems, but data structures like lists require special consideration. We implement automatic substitution of a more efficient list representation in a variational execution framework and evaluate its performance in micro-benchmarks. The results suggest that the substitution may offer substantial performance improvements to programs involving highly variational lists.	data structure;variational principle	Lukas Lazarek	2017		10.1145/3135932.3135951	computer science;theoretical computer science;distributed computing;data structure	PL	-12.192123107099887	37.50337021519898	30251
a49451cc27168d6a5e7c94f2d4dbea3971ed38aa	a dynamic evaluation of the precision of static heap abstractions	verification;analyse statique;measurement;java programming;analisis dinamica;abstraction;simultaneidad informatica;langage java;ejecucion programa;program verification;abstraccion;program execution;analisis estatica;analisis programa;refinement method;verificacion programa;concurrency;execution programme;analyse dynamique;lenguaje java;program analysis;methode raffinement;analyse programme;heap abstractions;static analysis;experimentation;verification programme;simultaneite informatique;metodo afinamiento;dynamic analysis;java language	The quality of a static analysis of heap-manipulating programs is largely determined by its heap abstraction. Object allocation sites are a commonly-used abstraction, but are too coarse for some clients. The goal of this paper is to investigate how various refinements of allocation sites can improve precision. In particular, we consider abstractions that use call stack, object recency, and heap connectivity information. We measure the precision of these abstractions dynamically for four different clients motivated by concurrency and on nine Java programs chosen from the DaCapo benchmark suite. Our dynamic results shed new light on aspects of heap abstractions that matter for precision, which allows us to more effectively navigate the large space of possible heap abstractions	benchmark (computing);call stack;concurrency (computer science);dacapo;java;static program analysis	Percy Liang;Omer Tripp;Mayur Naik;Shmuel Sagiv	2010		10.1145/1869459.1869494	program analysis;real-time computing;verification;concurrency;computer science;binary heap;dynamic program analysis;abstraction;programming language;static analysis;algorithm;measurement	PL	-19.948901616002367	35.1837120824048	30272
a877f79c624f18db1bc8129b6b73570b6a47d498	process synchronization and ipc	process synchronization	Process synchronization (also referred to as process coordination) is a fundamental problem in operating system design and implementation whenever two or more processes must coordinate their activities based upon a condition. A specific problem of synchronization is mutual exclusion, which requires that two or more concurrent activities do not simultaneously access a shared resource. This resource may be shared data among a set of processes where the instructions that access these shared data form a critical region (also referred to as a critical section). Processes involved in synchronization become indirectly aware of each other by waiting on a condition that is set by another process. Processes can also communicate directly with each other through interprocess communication (IPC). IPC causes communication to be sent between two or more processes. A common form of IPC is message passing.	critical section;inter-process communication;message passing;mutual exclusion;operating system;synchronization (computer science);systems design	Craig E. Wills	1996	ACM Comput. Surv.	10.1145/234313.234401	theoretical computer science;synchronization (computer science);computer science	Embedded	-23.589638472442203	42.4062916305576	30276
2fee3eeccdc44f1447615812309c1cc57fb26138	an efficient parallel mixed method for flow simulations in heterogeneous geological media	65n30;parallel computing;parallel algorithm;fluid flow;triangular mesh;linear system;mixed finite element;numerical modelling;mixed method;geological media;parallel computer;mixed finite element method;76s05;76d99;flow simulation;68n15;68w10	An efficient parallel mixed method for flow simulations in heterogeneous geological media Hussein Mustapha a b , Abir Ghorayeb c , Kassem Mustapha d & Pierre Saramito e a Department of Mining and Materials Engineering , McGill University , Montreal, Canada b Reservoir Engineering Reseach Institute , Palo Alto, USA c Department of Computer Sciences , LMC Laboratory University , Grenoble, France d Department of Mathematical Sciences , King Fahd University of Petroleum and Minerals , Dhahran, Saudi Arabia e CNRS, LJK-IMAG , Grenoble, France Published online: 29 Sep 2008.	distributed object;image scaling;little man computer;numerical analysis;numerical weather prediction;palo;parallel algorithm;parallel computing;run time (program lifecycle phase);simulation;structural analysis	Hussein Mustapha;Abir Ghorayeb;Kassem Mustapha;Pierre Saramito	2010	Int. J. Comput. Math.	10.1080/00207160802158728	mathematical optimization;simulation;computer science;theoretical computer science;triangle mesh;parallel algorithm;linear system;mixed finite element method;fluid dynamics	HPC	-7.257785758717854	38.08354957152263	30283
73d41e3cb1613f4fbbe00a4aad9adec54294bf8d	abstracting asynchronous multi-valued networks		ing Asynchronous Multi-Valued Networks		L. Jason Steggles	2011	Sci. Ann. Comp. Sci.		asynchronous communication;computer science;distributed computing	AI	-28.77851304923637	34.503044989640436	30285
33c1f933eb64ccef045236897f4604e09b7920a4	multimedia: towards an electronic performance support system	pram;shared memories;parallelism;vlsi;electronic performance support system			Ann Rockley	1994	SIGARCH Computer Architecture News	10.1145/192537.192542	real-time computing;computer science;theoretical computer science;very-large-scale integration;electronic performance support systems	Arch	-9.963311641109856	43.039049159910405	30287
a7075b5b8fe3dbcec3b0a2c4868154af968fae94	vectorization and parallelization of transport monte carlo simulation codes	monte carlo methods;cosmic ray showers and bursts;digital simulation;parallel programming;transport processes;egs4;cascade shower simulation code;coding methodology;parallelization;performance;shared-memory parallel processors;transport monte carlo simulation;vector supercomputers;vectorization	This paper discusses the computa t iona l techniques , the coding methodology and the pe r fo rmance for the t ranspor t Monte Carlo s imula t ion on the vec tor supercomputers and on the s h a r e d m e m o r y paral lel processors . A cascade shower s imula t ion code EGS4 has been taken as an example. As for vec to r processing, more than 10 t imes of pe r fo rmance has been obta ined by t r ea t ing the problem in a d i f fe ren t manner f rom the convent ional sequent ia l processing in such a way as to exploit the vec to r a rch i t ec tu re of current supe r computers . As for parallel processing, more than 25 t imes pe r fo rmance has been obtained over sequent ia l process ing by using 29 processors . This paper also discusses a new analyt ical pe r fo rmance model for parallel processing, new issues in paral lel process ing the t ranspor t Monte Carlo codes, and compar isons be tween vec to r and parallel approaches.	automatic vectorization;central processing unit;code;computer;field electron emission;monte carlo method;parallel computing;simulation;supercomputer;tor messenger;ical	Kenichi Miura	1990			computational science;parallel processing;parallel computing;concurrent computing;computer science;theoretical computer science;statistics;monte carlo method	AI	-6.835603273926745	37.41733405791965	30319
4e800427408d7b6df756d808ea5f12c7834cf121	towards service collaboration model in grid-based zero latency data stream warehouse (gzldswh)	dynamic workflow execution service collaboration model grid based zero latency data stream warehouse data stream processing automated event based reaction knowledge base;resource limitation;groupware;resource allocation;data stream;dynamic workflow execution;collaboration delay grid computing collaborative work software tools automation data analysis computer networks telecommunication computing memory;groupware grid computing data warehouses resource allocation knowledge based systems;data streams processing;grids based zero latency dwh;grid service;near real time;data warehouses;grid computing;knowledge based systems;knowledge base	"""A grid-based zero-latency data stream warehouse (GZLDSWH), built upon a set of OGSI-based grid services and GT3 toolkit, overcomes the resource limitation issue for data stream processing without using traditional approximate approaches. However, due to its """"automated event-based reaction"""" characteristic, the GZLDSWH requires a mechanism which allows the grid services to be able to work together to fulfill the common tasks. This paper describes the collaboration model for the grid services which enables the automation of the GZLDSWH in capturing and storing continuous data streams, making analytical processing, and reacting autonomously in near real time with some kinds of events based on well-established knowledge base."""	approximation algorithm;knowledge base;open grid services infrastructure;real-time computing;stream processing	Tho Manh Nguyen;A Min Tjoa;Guenter Kickinger;Peter Brezany	2004	IEEE International Conference onServices Computing, 2004. (SCC 2004). Proceedings. 2004	10.1109/SCC.2004.1358025	grid file;real-time computing;semantic grid;computer science;data grid;data mining;database	Robotics	-31.582718473378197	50.78984823790682	30348
ee1e42cb053e67050b592a6a7bc686f2a259a946	scalable and leaderless byzantine consensus in cloud computing environments	consensus;gossip;byzantine fault tolerance;cloud computing	Traditional Byzantine consensus in distributed systems requires n ≥ 3f + 1, where n is the number of nodes. In this paper, we present a scalable and leaderless Byzantine consensus implementation based on gossip, requiring only n ≥ 2f + 1 nodes. Unlike conventional distributed systems, the network topology of cloud computing systems is often not fully connected, but loosely coupled and layered. Hence, we revisit the Byzantine consensus problem in cloud computing environments, in which each node maintains some number of neighbors, called local view. The message complexity of our Byzantine consensus scheme is O(n), instead of O(n2). Experimental results and correctness proof show that our Byzantine consensus scheme can solve the Byzantine consensus problem safely in a scalable way without a bottleneck and a leader in cloud computing environments.	byzantine fault tolerance;cloud computing;consensus (computer science);correctness (computer science);distributed computing;like button;loose coupling;network topology;reliability engineering;scalability;scheme;single point of failure	JongBeom Lim;Taeweon Suh;Joon-Min Gil;Heon-Chang Yu	2014	Information Systems Frontiers	10.1007/s10796-013-9460-7	gossip;consensus;cloud computing;computer science;quantum byzantine agreement;uniform consensus;distributed computing;byzantine fault tolerance;computer security;computer network	OS	-22.54864972240885	45.72048457068863	30356
794a8c17ae4b799a6bda4f348db77fd5a4f4cb63	performance evaluation of openmp and cuda on multicore systems	parallel programming;auto parallel;cuda;multicore;openmp	Nowadays, not only CPU but also GPU goes along the trend of multi-core processors. Parallel processing presents not only an opportunity but also a challenge at the same time. To explicitly parallelize the software by programmers or compilers is the key for enhancing the performance on multi-core chip. In this paper, we first introduce some of the automatic parallel tools based OpenMP, which could save the time to rewrite codes for parallel processing on multicore system. Then we focus on ROSE and explore it in depth. And we also implement an interface to reduce its complexity of use and use some automatic parallelization for CUDA.	cuda;multi-core processor;openmp;performance evaluation	Chao-Tung Yang;Tzu-Chieh Chang;Kuan-Lung Huang;Jung-Chun Liu;Chih-Hung Chang	2012		10.1007/978-3-642-33065-0_25	multi-core processor;computer architecture;parallel computing;computer science;operating system	HPC	-5.982566734175485	44.24638916873427	30382
7eff4ce517a5661479ca1896cc70ce2f452b7c72	describing the immune system using enhanced mobile membranes	membrane system;immune system;structural properties	We investigate the enhanced mobile membranes, a new class of mobile membrane system in which new rules are introduced. The contextual evolution rules describe how an object from a membrane can evolve only in some context. The other rules describe the objective endocytosis and exocytosis. We use the class of enhanced mobile membrane system to model some evolutions in the immune system.	ambient calculus;computation;p system;timer	Bogdan Aman;Gabriel Ciobanu	2008	Electr. Notes Theor. Comput. Sci.	10.1016/j.entcs.2007.12.003	immune system	Mobile	-30.200665284340975	33.501302378273444	30402
19d9fb03cc0e9747b1208535cbe2751749b39dac	orthogonal serialisation for haskell	parallel haskell;lazy functional language;runtime support;orthogonal serialisation;haskell function;haskell data structure;real-world programming language;higher-order function;serialisation process;data serialisation	Data serialisation is a crucial feature of real-world programming languages, often provided by standard libraries or even built-in to the language. However, a number of questions arise when the language in question uses demand-driven evaluation and supports higher-order functions, as is the case for the lazy functional language Haskell. To date, solutions to serialisation for Haskell generally do not support higher-order functions and introduce additional strictness. This paper investigates a novel approach to serialisation of Haskell data structures with a high degree of flexibility, based on runtime support for parallel Haskell on distributed memory platforms. This serialisation has highly desirable and so-far unrivalled properties: it is truly orthogonal to evaluation and also does not require any type class mechanisms. Especially, (almost) any kind of value can be serialised, including functions and IO actions. We outline the runtime support on which our serialisation is based, and present an API of Haskell functions and types which ensure dynamic type safety of the serialisation process. Furthermore, we explore and exemplify potential application areas for orthogonal serialisation.	application checkpointing;application programming interface;checksum;computation;continuation;data structure;distributed memory;error message;exemplification;functional programming;goto;haskell;higher-order function;iterative method;lazy evaluation;library (computing);memoization;monad (functional programming);network packet;programming language;run time (program lifecycle phase);serialization;set packing;standard library;strand (programming language);type class;type safety;type system	Jost Berthold	2010		10.1007/978-3-642-24276-2_3	parallel computing;computer science;programming language;algorithm	PL	-18.252948887956084	32.39108509891998	30459
7959a54935f9ae3e6604dd6ad4f9f62b3e0ebb45	high performance computing and networking	high performance computing	Following the common use of of commodity hardware to build clusters, we argue that commodity software should be harnessed in a similar way to support Scientific and Engineering work. Problem Solving Environments (PSE) provide the arena where commodity software technology can modernise the development and execution environment. We describe a PSE prototype based on the standard software infrastructure of Java Beans and CORBA that illustrates this idea and provides advanced PSE functionality at minimum effort for medium sized heterogeneus platforms.	commodity computing;common object request broker architecture;java platform, enterprise edition;problem solving;prototype	Stephen Pickles;Fumie Costen;J. Brooke;Edgar Gabriel;Matthias Müller;Michael Resch;Stephen M. Ord	2000		10.1007/3-540-45492-6	active networking;delay-tolerant networking;software-defined networking	HPC	-32.565214755415525	49.68417398763314	30463
a8bf49a54a6425fae0a843c0286b0324c6b30b9c	implementing split-mode barriers in openshmem	split mode;openshmem;barrier	Barriers synchronize the state of many processing elements working in parallel. No worker may leave a barrier before all the others have arrived. High performance applications hide latency by keeping a large number of operations in progress asynchronously. Since barriers synchronize all these operations, maximum performance requires that barriers have as little overhead as possible. When some workers arrive at a barrier much later than others, the early arrivers must sit idle waiting for them. Split-mode barriers provide barrier semantics while also allowing the early arrivers to make progress on other tasks. In this paper we describe the process and several challenges in developing split-mode barriers in the OpenSHMEM programming environment.		Michael A. Raymond	2014		10.1007/978-3-319-05215-1_14	embedded system;real-time computing;engineering;operations management	HPC	-8.481216230403435	51.546754575482474	30508
ade1de00c38e6e78796fcbaed526ab06abb7c12c	memory footprint reduction for embedded systems	flash memory;binary rewriting;software engineering;embedded system;technology and engineering;operating system;linkers;code size;power consumption;diablo;optimalisation;component based design;embedded software	The memory footprint is considered an important constraint for embedded systems. This is especially important in the context of increasing sophistication of embedded software, and the increasing use of modern software engineering techniques like component-based design. Since reusability is the major motivation for using components, most components are not optimized for the (limited) functionality they have to realize in an embedded system. All this leads to an increasing amount of code and data that might not be needed for a given functionality.   The memory footprint of an embedded system consists of 2 parts: the footprint of the application and the footprint of the operating system. In this keynote talk, I will focus on the memory footprint reduction of application as well as the Linux kernel. I will report memory footprint reductions that have been obtained by the Diablo binary rewriter, which has been used to substantially reduce the memory footprint of both applications and of the system software.   For the applications, the optimizer is capable of reducing the code size of programs compiled with two proprietary ARM tool chains (ADS 1.1 and RVCT 2.1) with on average 16% for statically linked ARM programs, while making them 12.8% faster. Execution of the rewritten programs also consumes on average 10.7% less energy.   For the system software, we specialize the kernel both for the system calls that are actually occurring in the application program, and for the boot parameters of the kernel. We also assume that the hardware is fixed so that part of the bootstrap process is completely deterministic and can be optimized based on actual trace information.   Finally, we compress frozen code, and we swap cold code to flash memory. All combined, these compaction techniques on the kernel can reduce the kernel's RAM footprint with up to 48% for the Linux kernel. The slowdown was limited to 1--2%.   This proves that binary rewriting can help in substantially reducing the memory footprint of both the application and the system software. The nice thing is that it can be done automatically, and that it also reduces the execution time and the power consumption.	embedded system;memory footprint	Koen De Bosschere	2008		10.1145/1361096.1361102	memory footprint;embedded system;parallel computing;real-time computing;embedded software;computer science;component-based software engineering;operating system;overlay;programming language	EDA	-20.768816095130656	36.65785852077904	30513
76008df9a79c2d8e79f984a65cf2ae906c1b07fa	parallel execution optimization of gpu-aware components in embedded systems		Many embedded systems process huge amount of data that comes from the interaction with the environment. The Graphics Processing Unit (GPU) is a modern embedded solution that tackles the efficiency challenge when processing a lot of data. GPU may improve even more the system performance by allowing multiple activities to be executed in a parallel manner. In a complex component-based application, the challenge is to decide the components to be executed in parallel on GPU when considering different system factors (e.g., GPU memory, GPU computation power). In the context of component-based CPU-GPU embedded systems, we propose an automatic method that provides parallel execution schemes of components with GPU capabilities. The introduced method considers hardware (e.g., available GPU memory), software properties (e.g., required GPU memory) and communication pattern. Moreover, the method optimizes the overall system performance based on component execution times and system architecture (i.e., communication pattern). The validation uses an underwater robot example to describe the feasibility of our proposed method. Keywords—CBD, component-based development, CPU-GPU, embedded systems, GPU-aware component, GPU component, parallel component execution, optimization	central processing unit;component-based software engineering;computation;embedded system;flash memory;graphics processing unit;heuristic;mathematical optimization;np-hardness;parallel computing;robot;run time (program lifecycle phase);series and parallel circuits;systems architecture	Gabriel Campeanu	2017		10.18293/SEKE2017-137	parallel computing;computer science	EDA	-5.011237575089115	46.376598457029964	30536
28155dae90fd1d8c241138b2b5b5836384727e42	rapid fpga prototyping of a dab test data generator using protocol compiler	prototipificacion rapida;eficacia sistema;field programmable gate array;digital audio broadcast;hierarchical structure;architecture systeme;domain specific modeling;data stream;sistema informatico;design flow;performance systeme;test data generation;computer system;red puerta programable;system performance;design quality;reseau porte programmable;rapid prototyping;design and implementation;digital audio broadcasting;radiodiffusion sonore numerique;arquitectura sistema;systeme informatique;system architecture;prototypage rapide	Rapid FPGA Prototyping of a DAB Test Data Generator using Protocol Compiler Klaus Feske, Michael Scholz, Günther Döring, Mark Langer FhG IIS Erlangen Department EAS Dresden Zeunerstr. 38, D-01069 Dresden, Germany, e-mail: feske@eas.iis.fhg.de 1 Motivation Conventionally, the controller design for structured data stream processing is not well supported by tools [SHM-96]. So, we are faced with a bottleneck in the design process especially for telecommunication applications. Therefore we checked the qualification of domain specific high level synthesis approaches [Sea-94, Syn-98, HoB-98] to improve the design productivity (Fig. 1). The paper deals with the design of a Digital Au Broadcasting (DAB) Test Data Generator (TDG) using an extended FPGA prototyping d flow. The TDG produces hierarchical structured data streams according to the DAB pro Based on this previous work [FRK-98] and first experiences in utilizing the Protocol Com [SDF-99] we outline high level modelling principles and related synthesis solutions in ord enhance efficiency in controller design and according to the requirements of the DAB test ronment. 2 Requirements of our Digital Audio Broadcasting (DAB) Test Environment The digital radio system DAB is a broadband system, which transmits multiple programs common program block: the ensemble transport interface ETI (Fig. 2a). Digitized and pr cessed audio signals and data services are put together using a multiplexer (Fig. 2b). domain specific reuse	bottleneck (engineering);compiler;domain-specific language;email;fpga prototyping;field-programmable gate array;high-level programming language;high-level synthesis;internet information services;multiplexer;object-relational database;requirement;stream processing;test bench;test data;xfig	Klaus Feske;Michael Scholz;Günther Döring;Denis Nareike	1999		10.1007/978-3-540-48302-1_25	embedded system;test data generation;real-time computing;computer science;design flow;operating system;computer performance;field-programmable gate array;systems architecture	EDA	-29.93159383936425	35.06707146052429	30558
7a2048b0b8d59f3df76f05db9050932333b85261	automatic translation of mpi source into a latency-tolerant, data-driven form	data driven execution;source to source translator;task dependency graph;mathematics and computing automatic communication hiding;automatic communication hiding	Hiding communication behind useful computation is an important performance programming technique but remains an inscrutable programming exercise even for the expert. We present Bamboo, a code transformation framework that can realize communication overlap in applications written in MPI without the need to intrusively modify the source code. We reformulate MPI source into a task dependency graph representation, which partially orders the tasks, enabling the program to execute in a data-driven fashion under the control of an external runtime system. Experimental results demonstrate that Bamboo significantly reduces communication delays while requiring only modest amounts of programmer annotation for a variety of applications and platforms, including those employing co-processors and accelerators. Moreover, Bamboos performance meets or exceeds that of labor-intensive hand coding. The translator is more than a means of hiding communication costs automatically; it demonstrates the utility of semantic level optimization against a well-known library. Bamboo is a translator that can reformulate MPI source into a task graph form.Bamboo supports both point-to-point and collective communication.Bamboo supports GPUs, hiding communication among GPUs and between hosts and GPUs.Bamboo speeds up applications containing elaborate data and control structures.		Tan Nguyen;Pietro Cicotti;Eric J. Bylaska;Dan Quinlan;Scott B. Baden	2017	J. Parallel Distrib. Comput.	10.1016/j.jpdc.2017.02.009	distributed computing;runtime system;hand coding;parallel computing;latency (engineering);computation;dependency graph;source code;computer science;programmer;annotation	HPC	-13.01010675982737	36.3083471337613	30565
4c295de6a8fe9e07fe914e727065eeb37d70c5f1	linux alighted: down to earth clusters	silicon;personal computer;analytical modeling;pricing;earth;linux cluster;automatic analysis;business;cache performance;linux;memory hierarchy;high end computing;linux earth costs business silicon graphics pricing;graphics	Sky high costs and through the roof servicing of traditional specialized supercomputing has put immense pressure for earth-bound pricing and clustering solutions. Vectors and scalable UNIX-based solutions are not going to disappear, but over time Linux clusters will likely do for supercomputing what the Apple II did for personal computing: bring down costs, ease use, and make high-end computing power commercially viable and consumer available. This movement is in its adolescence, but maturity is rapidly approaching. This talk will discuss what is being done to integrate today's real solutions with tomorrow's promise.	capability maturity model;cluster analysis;linux;personal computer;scalability;supercomputer;unix	Beau Vrolyk	1999		10.1109/PACT.1999.807555	pricing;embedded system;parallel computing;simulation;computer cluster;computer science;graphics;operating system;linux unified key setup;earth;silicon;linux kernel	HPC	-27.665932158975938	54.23030636584871	30601
7a4ffbc5c38ffe75fc054aa5565f1f0bd9540a56	the wisdom of virtual crowds: mining datacenter telemetry to collaboratively debug performance	data analytics;cloud storage	"""Explaining the (mis)behavior of virtual machines in large-scale cloud environments presents a number of challenges with respect to both scale and making sense of torrents of datacenter telemetry emanating from multiple levels of the stack. In this paper we leverage VM-similarity to explain the behavior or performance of a VM using its cohort as a reference (or by contrasting it against groups of VMs outside of its cohort). The key insight is that virtual machines (VMs) running the same application (components or workloads), or VMs colocated within the same (logical) tier of a complex application exhibit similar telemetry patterns.  The power of similarity relationships stems from the additional context that similarity provides. The quantitative or qualitative """"distance"""" between a VM and its expected cohort could be used to explain or diagnose any discrepancy. Similarly, the distance between a VM and one in another cohort can be used to explain why the VMs are dissimilar. As an example we apply our data-mining techniques to debugging ViewPlanner performance. ViewPlanner is a tool used to emulate and evaluate large-scale deployments of virtual desktops. Using a ViewPlanner deployment of 175 VMs we collect ~ 300 metrics-per-VM, sampled at 20-second frequency over multiple 1 hour epochs, from the PerformanceManager [4] on ESX and automatically filter (using entropy measures [2]) and cluster them using K-means [1]. We use the median value of each metric within an epoch to summarize the VM's behavior during that epoch.  We introduce spread/diffusion metrics to explain the difference between VMs. Spread metrics are those such that the expected value of the order statistic (in our case the median) of a metric, <i>m</i>, <i>E</i>[<i>m</i>] differs between two clusters, i.e., the expected value is conditioned on the cluster, <i>E</i>[<i>m</i><sub><i>i</i></sub>|<i>clusterA</i>] ≠ <i>E</i>[<i>m</i><sub><i>i</i></sub>|<i>clusterB</i>]. Within a cluster of VMs, differences in the distribution of a particular metric, <i>m</i><sub><i>i</i></sub>, may be explained by conditioning <i>m</i><sub><i>i</i></sub> on other metrics, {<i>c</i><sub>0</sub>, ..., <i>c</i><sub><i>n</i></sub>}, where <i>E</i>[<i>m</i><sub><i>i</i></sub>] ≠ <i>E</i>[<i>m</i><sub><i>i</i></sub>|<i>c</i><sub>0</sub>, ..., <i>c</i><sub><i>n</i></sub>]. We automatically find potentially interesting <i>m</i><sub><i>i</i></sub>'s using Silverman's test [3] for multi-modality and we use Mutual Information [2] to find associated <i>c</i><sub><i>i</i></sub>'s."""	colocation centre;data center;data mining;debugging;discrepancy function;k-means clustering;metric;modality (human–computer interaction);multitier architecture;mutual information;singular value decomposition;software deployment;virtual desktop;virtual machine;z/vm	Dragos Ionescu;Rean Griffith	2013		10.1145/2523616.2525941	embedded system;real-time computing;simulation;telecommunications;computer science;engineering;operating system;data mining;data analysis;statistics;computer network	OS	-23.342518120151084	57.13363860979268	30642
fdc07e9c88f852a647de1f63a060d0a861ca0ee6	portability and code reuse in parallel applications	ease of use	This paper reports on the development of a library of reusable code modules for parallel applications. We illustrate the need for a variety of levels of abstraction, in which modules provide different levels of support, trading off ease of use for potential reuse. We also discuss the conflict between code reuse and high performance in this context.	code reuse;principle of abstraction;software portability;usability	R. A. Fletcher;N. B. MacDonald	1993			code reuse;parallel computing;computer architecture;computer science;usability;software portability	HPC	-15.007220173766795	40.366069680381024	30650
159a381905ef7574a8c8dcd7f25c08fa3c147fde	real time distributed control systems using rtai	networked control systems real time distributed control systems real time application interface linux middleware layer;distributed control system;real time;complex network;operating systems computers real time systems application program interfaces;real time systems distributed control application software linux costs computer interfaces distributed computing high performance computing middleware computer network management;control system;design and implementation;application program interfaces;middleware;high performance;off the shelf;real time application;operating systems computers;real time systems	The paper outlines the design and implementation of the Real Time Application Interface (RTAI) for Linux, as used for high performance local/distributed control systems implemented on low cost off the shelf general purpose computers. Its native lean real time middleware layer is described along with its use in an advanced tool to easily manage and monitor complex networked control systems.	distributed control system;rtai	Lorenzo Dozio;Paolo Mantegazza	2003		10.1109/ISORC.2003.1199229	embedded system;middleware;real-time computing;service interface for real time information;computer science;control system;operating system;middleware;distributed control system;complex network	Robotics	-32.534986816432635	39.13523824947293	30651
a015dcbaf17e586c4e5299b75e60c1e1167bef7f	interoperability in large scale cyber-physical systems	cloud network large scale cyber physical systems design foundation software platforms interoperability infrastructure optimisation computational capabilities storage capabilities physical resources software building blocks client devices cloud iaas layers iaas paas paas saas;optimisation cloud computing large scale systems;optimisation;interoperability cloud computing occi osgi;large scale systems;cloud computing	While the capability for growing on demand is the design foundation of the new generation of software platforms, physical systems always have limited resources. Therefore, there is a need to optimise the existing infrastructures and evolving them building on interoperability. The optimisation of the infrastructure entails not only addressing the computational and storage capabilities but also the network, its associated intelligence and the exchanged information. Therefore, the interoperability requirement in a large scale cyber-system spans from the lowest layers, interfacing with the physical resources, to the software building blocks, client devices and handled data. In this paper, several initiatives addressing interoperability among cloud IaaS layers, IaaS-PaaS, PaaS-SaaS, Cloud-Network and data are presented.	cloud computing;cyber-physical system;emergence;interoperability;mathematical optimization;next-generation network;platform as a service;requirement;software as a service;software deployment;vergence	Jesús Bermejo Muñoz;Sebastian García Galán;L. R. Lopez;Rocío Pérez de Prado;J. Enrique Muñoz Expósito;Terje Grimstad;Diego R. Lopez	2012	Proceedings of 2012 IEEE 17th International Conference on Emerging Technologies & Factory Automation (ETFA 2012)	10.1109/ETFA.2012.6489788	cloud computing;computer science;engineering;operating system;database;distributed computing;world wide web	EDA	-29.835052185834826	57.119664415835956	30657
f51927e2a606dca708322221b4a7cf261033e540	parallel programming approaches for an agent-based simulation of concurrent pandemic and seasonal influenza outbreaks	simulation;cuda;pandemic outbreak;openmp	In this paper we propose parallelized versions of an agent-based simulation for concurrent pandemic and seasonal influenza outbreaks. The objective of the implementations is to significantly reduce the replication time and allow faster evaluation of mitigation strategies during an ongoing emergency. The simulation was initially parallelized using the g++ OpenMP library. We simulated the outbreak in a population of 1,000,000 individuals to evaluate algorithm performance and results. In addition to the OpenMP parallelization, a proposed CUDA implementation is also presented.	parallel computing;simulation	Milton Soto-Ferrari;Peter Holvenstot;Diana Prieto;Elise de Doncker;John A. Kapenga	2013		10.1016/j.procs.2013.05.389	computational science;parallel computing;simulation;computer science	HPC	-6.26142734404737	34.61370049559927	30741
77032ed28886119ed85f948b7a6d55fdf66c8712	duang: fast and lightweight page migration in asymmetric memory systems	shared row buffer architecture duang page migration asymmetric memory systems resistive memory architecture migrating memory pages memory access patterns asymmetric memory architecture;phase change materials memory architecture random access memory memory management runtime resistance;memory architecture buffer storage	Main memory systems have gone through dramatic increases in bandwidth and capacity. At the same time, their random access latency has remained relatively constant. For given memory technology, optimizing the latency typically requires sacrificing the density (i.e., cost per bit), which is one of the most critical concerns for memory industry. Recent studies have proposed memory architectures comprised of asymmetric (fast/low-density and slow/high-density) regions to optimize between overall latency and negative impact on density. Such memory architectures attempt to cost-effectively offer both high capacity and high performance. Yet they present a unique challenge, requiring direct placements of hot memory pages1 in the fast region and/or expensive runtime page migrations. In this paper, we propose a novel resistive memory architecture sharing a set of row buffers between a pair of neighboring banks. It enables two attractive techniques: (1) migrating memory pages between slow and fast banks with little performance overhead and (2) adaptively allocating more row buffers to busier banks based on memory access patterns. For an asymmetric memory architecture with both slow/high-density and fast/low-density banks, our shared row-buffer architecture can capture 87-93% of the performance of a memory architecture with only fast banks.	computer data storage;memory architecture;overhead (computing);page (computer memory);random access	Hao Wang;Jie Zhang;Sharmila Shridhar;Gieseo Park;Myoungsoo Jung;Nam Sung Kim	2016	2016 IEEE International Symposium on High Performance Computer Architecture (HPCA)	10.1109/HPCA.2016.7446088	uniform memory access;distributed shared memory;shared memory;interleaved memory;semiconductor memory;parallel computing;real-time computing;memory refresh;computer hardware;computer science;physical address;computer memory;overlay;conventional memory;extended memory;flat memory model;registered memory;cache-only memory architecture;memory map;non-uniform memory access;memory management	Arch	-9.589681841127973	53.750796086490574	30946
fc3a0ddf86d9eb6180acf4cf284a2cb86b0f033a	optimization of execution time under power consumption constraints in a heterogeneous parallel system with gpus and cpus	parallel computing;heterogeneous environments;performance;gpgpu;power consumption;opencl	The paper proposes an approach for parallelization of computations across a collection of clusters with heterogeneous nodes with both GPUs and CPUs. The proposed system partitions input data into chunks and assigns to particular devices for processing using OpenCL kernels defined by the user. The system is able to minimize the execution time of the application while maintaining the power consumption of the utilized GPUs and CPUs below a given threshold. We present real measurements regarding performance and power consumption of various GPUs and CPUs used in a modern parallel system. Furthermore we show, for a parallel application for breaking MD5 passwords, how the execution time of the real application changes with various upper bounds on the power consumption.	central processing unit;graphics processing unit;optimizing compiler	Pawel Czarnul;Pawel Rosciszewski	2014		10.1007/978-3-642-45249-9_5	computer architecture;parallel computing;real-time computing;performance;computer science;operating system;general-purpose computing on graphics processing units	HPC	-5.797935101649673	52.61772639606738	30959
a5abf71f75d1281329e5f2ef37dee3337d40bfa6	co-scheduling parallel electronic structure calculations in smp cluster environments	quantum chemistry chemistry computing distributed processing electronic structure;electronic structure calculation;integrable model;chemistry computing;distributed processing;parallel electronic structure;distributed symmetric multiprocessor;network information conveyer and application notification;atomic electronic structure system;molecular electronic structure system;molecular electronics;distributed symmetric multiprocessor parallel electronic structure atomic electronic structure system molecular electronic structure system ab initio molecular quantum chemistry network information conveyer and application notification;electronic structure;peer to peer computing games scheduling algorithm chemistry throughput middleware quantum computing processor scheduling molecular electronics high performance computing;quantum chemistry;smp cluster;ab initio molecular quantum chemistry	The general atomic and molecular electronic structure system (GAMESS) is a program for ab initio molecular quantum chemistry calculations. This work presents a modification to the integration model of network information conveyer and application notification (NICAN) into GAMESS for the concurrent execution of sequential GAMESS jobs. In the work presented here, NICAN acts as an application-level co-scheduler in distributed SMP environments. The primary goal of such a co-scheduler is to increase throughput of parallel GAMESS calculations	ab initio quantum chemistry methods;electronic structure;gamess (us);scheduling (computing);symmetric multiprocessing;throughput	Nurzhan Ustemirov;Masha Sosonkina	2005	2005 IEEE International Conference on Cluster Computing	10.1109/CLUSTR.2005.347014	parallel computing;molecular electronics;computer science;theoretical computer science;distributed computing;quantum chemistry;electronic structure	HPC	-9.08511992442558	40.59524781484298	30981
5995dbfc53ab5ff404e4a4a8bfd2faca1e839841	virtual machine co-migration for out-of-band remote management	vm migration;iaas clouds;virtual machines;remote management	In Infrastructure-as-a-Service (IaaS) clouds, users manage the systems in virtual machines (VMs) called user VMs through remote management systems (RMSes). To allow users to manage their VMs during failures inside the VMs, IaaS usually provides out-of-band remote management. This management is performed indirectly via an RMS server in a privileged VM called the management VM. However, it is discontinued when a user VM is migrated. This is because an RMS server in the management VM at the source host is terminated on VM migration. Even worse, pending data is lost between an RMS client and a user VM. In this paper, we propose D-MORE for continuing outof-band remote management across VM migration. D-MORE provides a privileged and migratable VM called DomR and performs out-of-band remote management of a user VM via DomR. During VM migration, it synchronously comigrates DomR and its target VM and transparently maintains the connections between an RMS client, DomR, and its target VM. We have implemented D-MORE in Xen and confirmed that a remote user could manage his VM via DomR after the VM has been migrated. Our experiments showed that input data was not lost during VM migration and the overhead of D-MORE was acceptable.	cloud computing;downtime;elegant degradation;experiment;information processing;memory footprint;operating system;out-of-band agreement;overhead (computing);server (computing);virtual machine manager;z/vm	Sho Kawahara;Kenichi Kourai	2016	JIP	10.2197/ipsjjip.24.669	real-time computing;computer science;virtual machine;operating system;distributed computing	Security	-23.23602073267009	51.16139247161675	31008
480f91f624131cdfcde28599e87de115ec878ed3	the development of a tri-use cluster for general computer education, high performance computing education, and computationally intensive research	clusters;cluster computing;high performance computing;computational science;computer science education;operating system;high performance computer;parallel computer;computer education;scientific research;open source	This paper describes the construction of a tri-use computer cluster for general computer science education, instruction in parallel high performance computing, and computationally intensive scientific research. While many schools today are starting to include parallel computing in their curriculum, a large number of smaller institutions lack the resources to devote a significant amount of their equipment budget exclusively to computers for parallel computing. Similarly, many schools would like to have computational facilities for scientific research, but cannot afford to designate machines solely for this purpose. Our system allows for one set of systems to be easily shared between pedagogical and research tasks. The system described herein utilizes standard hardware components and a combination of open-source Linux and commercial software. In addition, the development of a software program to selectively boot between operating systems is described.	commercial software;computation;computer cluster;computer program;computer science;general computer corporation;linux;open-source software;operating system;parallel computing;supercomputer;triangular function	Andrew J. Pounds;Rajeev Nalluri;Bennie L. Coleman	2005		10.1145/1167350.1167446	computational science;computing;simulation;computer science;data-intensive computing;utility computing;computer engineering	HPC	-11.738177388684395	39.516271451448404	31023
4ae32eb2d6dbae1161a2cbca6f80e5857b390715	parallelisation of nonequilibrium molecular dynamics code for polymer melts using openmp	swinburne;loop fusion;performance improvement;molecular dynamic	The parallelisation of a sequential nonequilibrium molecular dynamics (NEMD) code for simulating polymer melts is presented. The issues impacting the efficiency of the parallel executable are probed. Various techniques, such as loop interchange, loop fusion and code restructure, have been applied to the incremental OpenMP parallelisation. Significant performance improvement and speed up are achieved for large sized systems when the parallelized code is compared to the existing sequential code. The parallelised code has successfully been applied to simulate the shear rheology of a polymer melt system.	molecular dynamics;openmp;parallel computing;polymer	Zhongwu Zhou;Billy D. Todd;Peter J. Daivis	2003		10.1007/3-540-44863-2_28	loop fusion;computational science;molecular dynamics;parallel computing;computer science;theoretical computer science	HPC	-5.344626962387501	36.71205242537555	31044
32ff49ead0a33d89613e3802ccaa37aadce85e38	selecting checkpoints along the time line: a novel temporal checkpoint selection strategy for monitoring a batch of parallel business processes	business process;on-time completion;parallel business;time line;challenging issue;checkpoint selection strategy;novel temporal checkpoint selection;brand new idea;satisfactory on-time completion rate;parallel business process;temporal checkpoint selection;individual business process;selecting checkpoint;new definition;throughput;system monitoring;cloud computing;exception handling;parallel processing;business	Nowadays, most business processes are running in a parallel, distributed and time-constrained manner. How to guarantee their on-time completion is a challenging issue. In the past few years, temporal checkpoint selection which selects a subset of workflow activities for verification of temporal consistency has been proved to be very successful in monitoring single, complex and large size scientific workflows. An intuitive approach is to apply those strategies to individual business processes. However, in such a case, the total number of checkpoints will be enormous, namely the cost for system monitoring and exception handling could be excessive. To address such an issue, we propose a brand new idea which selects time points along the workflow execution time line as checkpoints to monitor a batch of parallel business processes simultaneously instead of individually. Based on such an idea, a set of new definitions as well as a time-point based checkpoint selection strategy are presented in this paper. Our preliminary results demonstrate that it can achieve an order of magnitude reduction in the number of checkpoints while maintaining satisfactory on-time completion rates compared with the state-of-the-art activity-point based checkpoint selection strategy.	business process;exception handling;parallel computing;run time (program lifecycle phase);system monitor;timeline;transaction processing system	Xiao Qiao Liu;Yun Yang;Dahai Cao;Dong Yuan	2013	2013 35th International Conference on Software Engineering (ICSE)		exception handling;parallel processing;system monitoring;real-time computing;computer science;operating system;database;distributed computing;programming language	SE	-20.200966451889908	55.997410396600024	31310
15ad98d48e735ebfc681e686ff66ed1e0f545524	fast parallel i/o on cluster computers	cluster computing;communication system;production system;linux cluster;quantum chromodynamics;large scale;lattice qcd;file system;gigabit ethernet;parallel file system;parallel i o;open source	Today’s cluster computers suffer from slow I/O, which slows down I/O-intensive applications. We show that fast disk I/O can be achieved by operating a parallel file system over fast networks such as Myrinet or Gigabit Ethernet. In this paper, we demonstrate how the ParaStation3 communication system helps speed-up the performance of parallel I/O on clusters using the open source parallel virtual file system (PVFS) as testbed and production system. We will describe the set-up of PVFS on the Alpha-Linux-Cluster-Engine (ALiCE) located at Wuppertal University, Germany. Benchmarks on ALiCE achieve write-performances of up to 1 GB/s from a 32-processor compute-partition to a 32-processor PVFS I/Opartition, outperforming known benchmark results for PVFS on the same network by more than a factor of 2. Read-performance from buffer-cache reaches up to 2.2 GB/s. Our benchmarks are giant, I/O-intensive eigenmode problems from lattice quantum chromodynamics, demonstrating stability and performance of PVFS over Parastation in large-scale production runs.	benchmark (computing);central processing unit;clustered file system;computation;computer cluster;data-intensive computing;gigabit;gigabyte;hard disk drive;input/output;lattice qcd;linux;normal mode;open-source software;page cache;parallel i/o;parallel virtual file system;performance;production system (computer science);testbed;throughput	Thomas Düssel;Norbert Eicker;Florin Isaila;Thomas Lippert;Thomas Moschny;Hartmut Neff;Klaus Schilling;Walter F. Tichy	2003	CoRR		parallel computing;computer cluster;computer science;operating system;distributed computing;quantum chromodynamics	HPC	-10.578070551895703	45.672972178364326	31312
31a0e5754f4878c3bcc640b877c7517033a760a9	on submesh allocation for mesh multicomputers: a best-fit allocation and a virtual submesh allocation for faulty meshes	submesh allocation;multiprocessor interconnection networks;multitasking computer society topology multiprocessing systems computer architecture concurrent computing prototypes character recognition computer science;best fit;free submesh list;multiprocessor systems;faulty submesh;fault tolerant computing;fault tolerant computing multiprocessor interconnection networks;best fit submesh submesh allocation mesh multicomputers best fit allocation faulty meshes virtual submesh allocation;faulty mesh;reservation;mesh multicomputer;fragmentation;virtual submesh	The submesh allocation problem is to recognize and locate a free submesh that can accommodate a request for a submesh of a specified size. In this paper, we propose a new best-fit submesh allocation strategy for mesh-connected multiprocessor systems. The proposed strategy maintains and uses a free submesh list for an efficient allocation. For an allocation request, the strategy selects the best-fit submesh which causes the least amount of potential processor fragmentation. As many large free submeshes as possible are preserved for later allocations. For this purpose, we introduce a novel function quantifying the degree of potential fragmentation of submeshes. The proposed strategy has the capability of recognizing a complete submesh. We also propose an allocation strategy for faulty meshes which can maintain and allocate virtual submeshes derived from faulty submeshes. Extensive simulation is carried out to compare the proposed strategy with previous strategies. The proposed strategy has the best performance: a 6-50 percent improvement over the previous best strategy.	polygon mesh	Geunmo Kim;Hyunsoo Yoon	1998	IEEE Trans. Parallel Distrib. Syst.	10.1109/71.663881	parallel computing;real-time computing;computer science;operating system;distributed computing;fragmentation;statistics;curve fitting	HPC	-13.09848284611782	58.68879870169292	31321
6702ac28306a9940fa946dc07e6daf05a6eb7252	prefetching and memory system behavior of the spec95 benchmark suite	simulation ordinateur;memory layout;evaluation performance;storage system;performance evaluation;evaluacion prestacion;cache memory;antememoria;algorithme;algorithm;organizacion memoria;antememoire;systeme memoire;organisation memoire;memory systems;simulacion computadora;sistema memoria;computer simulation;algoritmo	"""sulte This paper presents instruction and data cache miss rates for the SPEC95"""" benchmark suite. We have simulated the instruction and data traffic resulting from 500 million instructions of each of the 18 programs. Simulation results show that only a few of the applications place more than modest demands on the memory system. This was noticed for instruction caches, where only a few workloads required more than a 32Kb cache to achieve miss rates of less than one miss every 1000 instructions. We also analyze two prefetching algorithms using the SPEC95 workload: next-sequential prefetching and shadow-directory prefetching. Each prefetching algorithm is evaluated using three performance metrics: coverage, accuracy, and traffic. Variations in each prefetching algorithm involve the use of a confirmation mechanism that receives feedback information about the quality of each prefetch. With confirmation, the prefetching algorithm is able to enhance the accuracy of prefetching decisions. The results show that shadow-directory prefetching averages miss coverage about ten percent higher than next-sequential prefetching when used in prefetching instructions (about 60 percent coverage for next-sequential prefetching versus 70 percent for shadow-directory prefetching). The prefetching accuracy for both algorithms is more than 90 percent when a confirmation mechanism is used. In general, data prefetching is shown to be less accurate and to provide less coverage than instruction prefetching. Shadow-directory prefetching averaged about a 40 percent miss coverage versus a 25 percent miss coverage for next-sequential prefetching. Prefetching accuracy is over 70 percent when confirmation is applied."""	algorithm;benchmark (computing);cpu cache;directory (computing);link prefetching;simulation	Mark J. Charney;Thomas R. Puzak	1997	IBM Journal of Research and Development	10.1147/rd.413.0265	computer simulation;parallel computing;real-time computing;cpu cache;computer science;operating system	Metrics	-16.32950737250644	44.82879278410277	31326
112b7b7e31ee43e80aeca4a2979c60bf04a708be	autocsd: automatic cloud system deployment in data centers	reliability;deployment server;cloud computing system;data center;load balance	It is a huge challenge to deploy a cloud computing system in large-scale data centers. In order to help resolve this issue, we propose an automatic cloud system deployment approach with the characteristics of reliability, availability, and load balance. Specifically, we use workflow to deal with the dependencies among the automatic deployment processes of a cloud system. We also design a failover mechanism to avoid the single point failure of the deployment server. Besides, we adopt a load balancing algorithm to solve the bottleneck problem of deploying a cloud system.#R##N##R##N#We implement a prototype, and evaluate it with 16 physical nodes as well as a virtualized environment with 160 virtual machines. Experimental results show that the average deployment time under our approach is lower than that with traditional deployment methods. In addition, it achieves a cloud system deployment success ratio of up to 90i¾?%, even in the high-concurrency environment.	software deployment;system deployment	Tao Xie;Haibao Chen	2015		10.1007/978-3-319-28430-9_6	embedded system;data center;real-time computing;deployment diagram;computer science;load balancing;operating system;reliability;distributed computing	Networks	-23.736103089178993	59.94857798686282	31347
2a5d9ff64cdde1cb9a2019d0fc2d2491e4ef6cf4	characterizing, modeling, and generating workload spikes for stateful services	workload spikes;workoad characterization;internet services;data hotspots;spatial locality;workload synthesis;stress testing;cloud computing	Evaluating the resiliency of stateful Internet services to significant workload spikes and data hotspots requires realistic workload traces that are usually very difficult to obtain. A popular approach is to create a workload model and generate synthetic workload, however, there exists no characterization and model of stateful spikes. In this paper we analyze five workload and data spikes and find that they vary significantly in many important aspects such as steepness, magnitude, duration, and spatial locality. We propose and validate a model of stateful spikes that allows us to synthesize volume and data spikes and could thus be used by both cloud computing users and providers to stress-test their infrastructure.	cloud computing;locality of reference;principle of locality;state (computer science);stateful firewall;stress testing;synthetic intelligence;tracing (software)	Peter Bodík;Armando Fox;Michael J. Franklin;Michael I. Jordan;David A. Patterson	2010		10.1145/1807128.1807166	real-time computing;cloud computing;computer science;operating system;distributed computing;stress testing	Metrics	-23.452380589101722	57.22831375288495	31355
5697643c04dd4fbcada7985e70f53de229e8be21	experience with multi-transputer ada		The transputer is one of the most cost-effective multicomputer components to buy, but still one of the hardest to program. Even if the parts of a program that are destined for individual transputers are programmed in a familiar high-level language (Ada or Fortran or C), users are forced to be aware of occam when connecting transputers together with harnesses. Moreover, the design of parallel and distributed algorithms is in itself a challenging field. This paper describes experience with using the Alsys Ada compiler on single and multiple transputer configurations, and considers whether Ada makes it any easier to gain access to the power of multi-transputers. Early performance figures indicate that Ada running on transputer arrays compares favourably with the speed of other languages. An assessment of the impact of the proposed Ada 9X support for distribution is made.	ada;transputer	Judith Bishop;Ken S. Thomas	1993	Concurrency - Practice and Experience	10.1002/cpe.4330050204	distributed computing;parallel computing;computer science;compiler;distributed algorithm;transputer;occam;fortran	SE	-12.807515754760905	40.54200829017231	31365
8ccdc3eb36ed701d4b07d5b4727425dbc87e48fa	enterprise javabeans - developing enterprise java components: covers ejb 2.1 and ejb 2.0 (4. ed)	enterprise javabean		enterprise javabeans;java platform, enterprise edition	Richard Monson-Haefel;Bill Burke;Sacha Labourey	2004			computer science;operating system;software engineering;database	PL	-33.39861556917983	42.82440466636215	31482
1d6aa5b77c8f8da43ec19dc859ddd651f1202eb9	tempo, a program specializer for c (panel session)	dynamic compilation;emulation;interpretation	dynamic compilation;emulation;interpretation		Ron Cytron;Renaud Marlet	2000		10.1145/351397.351424	emulation;computer architecture;parallel computing;dynamic compilation;interpretation;computer science;programming language	PL	-22.631476554620154	33.74756623671472	31491
6aa7427f9dcd89ed9aba1c8433b43ea5741c0816	time-based transactional memory with scalable time bases	websearch;software transactional memory;data access;transactional memory;bibliotheque numerique rero doc	Time-based transactional memories use time to reason about the consistency of data accessed by transactions and about the order in which transactions commit. They avoid the large read overhead of transactional memories that always check consistency when a new object is accessed, while still guaranteeing consistency at all times--in contrast to transactional memories that only check consistency on transaction commit.  Current implementations of time-based transactional memories use a single global clock that is incremented by the commit operation for each update transaction that commits. In large systems with frequent commits, the contention on this global counter can thus become a major bottleneck.  We present a scalable replacement for this global counter and describe how the Lazy Snapshot Algorithm (LSA), which forms the basis for our LSA-STM time-based software transactional memory, has to be changed to support these new time bases. In particular, we show how the global counter can be replaced (1) by an external or physical clock that can be accessed efficiently, and (2) by multiple synchronized physical clocks.	clock synchronization;database transaction;global serializability;lazy evaluation;overhead (computing);parallel computing;real-time clock;real-time computing;real-time transcription;scalability;snapshot (computer storage);snapshot algorithm;software transactional memory;vector clock	Torvald Riegel;Christof Fetzer;Pascal Felber	2007		10.1145/1248377.1248415	data access;transactional memory;parallel computing;real-time computing;computer science;software transactional memory;database;programming language	PL	-20.11372172954933	48.87951890675587	31495
5ae020fae8f0cbf882f6db1ffbbf5dfee6c931c9	memory reuse optimizations in the r-stream compiler	compiler optimziation;cuda;gpgpu;polyhedral model;parallelization;automatic translation	We propose a new set of automated techniques to optimize memory reuse in programs with explicitly managed memory. Our techniques are inspired by hand-tuned seismic kernels on GPUs. The solutions we develop reduce the cost of transferring data across multiple memories with different bandwidth, latency and addressability properties. They result in reduction of communication volumes from main memory and faster execution speeds, comparable to hand-tuned implementations, for out-of-place stencils. We discuss various steps of our source-to-source compiler infrastructure and focus on specific optimizations which comprise: flexible generation of different granularities of communications with respect to computations, reduction of redundant transfers, reuse of data across processing elements using a globally addressable local memory and reuse of data within the same processing elements using a local private memory. The models of memory we consider in our techniques support the GPU model with device, shared and register memories. The techniques we derive are generally applicable and their formulation within our compiler can be extended to other types of architectures.	computation;computer data storage;graphics processing unit;intel hd and iris graphics;memory address;source-to-source compiler	Nicolas Vasilache;Muthu Manikandan Baskaran;Benoît Meister;Richard Lethin	2013		10.1145/2458523.2458528	cuda pinned memory;uniform memory access;distributed shared memory;shared memory;memory model;computer architecture;parallel computing;computer science;theoretical computer science;flat memory model;cache-only memory architecture;memory map;memory management;memory ordering	PL	-6.789455953812572	48.280216055172815	31500
2ea668eb286333431ee9065b0d8e997d01640680	adaptive sampling for efficient mpsoc architecture simulation	modern micro architecture simulators;logic design;mpsoc architecture simulation;acceleration;computer architecture;computational modeling;adaptation model;multiprocessor architectures;sampling technique;system on chip logic design multiprocessing systems;system on chip;multiprocessor architecture;sampling methods computational modeling space exploration estimation error computer architecture acceleration hardware computer simulation irrigation computer aided instruction;adaptive sampling;multiprocessing systems;design space exploration;estimation error;program processors;benchmark testing;design space exploration adaptive sampling mpsoc architecture simulation modern micro architecture simulators multiprocessor architectures	Modern micro-architecture simulators are many orders of magnitude slower than the hardware they simulate. The use of multiprocessor architectures for supporting future mobile and embedded applications will exacerbate this slowness. In this paper, we focus on the usage of the sampling technique for simulation acceleration, in the case of design space exploration (DSE), considering MPSoC. Among the addressed issue is the formation of sampling intervals that are executed simultaneously by the different processors. We propose a technique that dynamically adjusts the size for simulation samples for multiprocessor activities overlaps. Experimental results show that with our method, the simulation can be speedup by a factor of up to 800 with a relatively small estimation error.	adaptive sampling;central processing unit;design space exploration;embedded system;mpsoc;microarchitecture;multiprocessing;sampling (signal processing);simulation;spatial variability;speedup	Melhem Tawk;Khaled Z. Ibrahim;Smaïl Niar	2007	2007 15th International Symposium on Modeling, Analysis, and Simulation of Computer and Telecommunication Systems	10.1109/MASCOTS.2007.6	acceleration;system on a chip;benchmark;sampling;computer architecture;parallel computing;logic synthesis;real-time computing;computer science;operating system;computational model	Arch	-5.140653454504994	51.65146639163394	31507
48a7179eff058d6347d2ec8f25c2052b78522ffe	power-aware bus encoding techniques for i/o and data buses in an embedded system	flash memory;power aware;lcd controller;bus encoding;mobile computer;embedded system;operating system;file system;power reduction;power consumption;liquid crystal;device driver;palette assignment	Microprocessors with built-in Liquid Crystal Device (LCD) controllers and equipped with Flash ROM are common in mobile computing applications. In the first part of the paper, a software-only encoding technique is proposed to reduce the power consumption of the processor-memory bus when displaying an image on the LCD. Based on the translation mechanism of the LCD controller, the approach of this paper is to start with the palette as a coding table for the pixel buffer and then reassign the codes according to the image characteristics. Experimental results prove the efficacy of this approach; power reduction reaches 29% for text-based and 17% for graphics-based images. In the second part of the paper, another software-only encoding technique is presented to reduce the transitions on the processor-CompactFlash bus. The device driver in a Linux operating system is modified to perform Bus-Invert encoding when the data is read from or written to a Compact Flash file system. With minimal software overhead, the transitions on the bus are reduced by up to 25%.	bus encoding;code;compactflash;device driver;embedded system;flash file system;flash memory;graphics;input/output;linux;liquid-crystal display;memory bus;microprocessor;mobile computing;operating system;overhead (computing);palette (computing);pixel buffer;read-only memory;text-based (computing)	Wei-Chung Cheng;Massoud Pedram	2002	Journal of Circuits, Systems, and Computers	10.1142/S0218126602000501	flash file system;embedded system;real-time computing;liquid crystal;computer hardware;computer science;local bus;operating system;system bus;control bus;mobile computing	EDA	-10.850434607010026	53.96399067738173	31577
02d6877ed98920d9fe23faca730c1f6d951c0971	simulating materials with strong correlations on bluegene/l.	distributed memory;model system;degree of freedom;local density approximation;quantum spin system;memory access;non perturbative;lanczos method;quantum computer;ground state;kinetic energy;dynamic properties	c © 2007 by John von Neumann Institute for Computing Permission to make digital or hard copies of portions of this work for personal or classroom use is granted provided that the copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. To copy otherwise requires prior specific permission by the publisher mentioned above.	blue gene	Andreas Dolfen;Yuan Lung Luo;Erik Koch	2007			distributed memory;local-density approximation;kinetic energy;ground state;degrees of freedom;quantum computer;non-perturbative	Theory	-4.664868846515175	34.48647729552548	31599
6d032b29ea516031a0c22b42865c3a5c85c1f031	sleep scheduling for energy-savings in multi-core processors	energy aware scheduling;real time scheduling theory;processor idle durations sleep scheduling multicore processors transistor geometries static leakage power power consumption frequency scaling processor gating system clock gating partitioned fixed priority scheduling periodic real time task scheduling energy saving rate harmonized scheduling es rhs energy saving rate monotonic scheduling es rms lowest power deep sleep state max syncsleep partitioning technique synchronous deep sleep duration;processor scheduling multiprocessing systems power aware computing;real time scheduling theory energy aware scheduling;program processors multicore processing processor scheduling real time systems context dynamic scheduling	As transistor geometries get smaller, static leakage power dominates the power consumption in modern processors. This phenomenon diminishes the ability of frequency scaling-based techniques to save energy. Modern processors also provide sleep states which minimize leakage power by gating portions of the processor and/or the system clock. This paper presents partitioned fixed-priority scheduling solutions for utilizing these sleep states to efficiently schedule periodic real-time tasks, and maximize energy savings on multi-core processors. The techniques presented rely on an Enhanced Version of Energy-Saving Rate-Harmonized Scheduling (ES-RHS), and our newly proposed Energy-Saving Rate-Monotonic Scheduling (ES-RMS) policy to maximize the time the processor spends in the lowest-power deep sleep state. In some modern multi-core processors, all cores need to transition synchronously into deep sleep. For this class of processors, we present a partitioning technique called Max-SyncSleep which utilizes a priori task information, to maximize the synchronous deep sleep duration across all processing cores. The performance of Max-SyncSleep is compared to the classical Worst-Fit Decreasing load balancing heuristic. We also illustrate the benefits of using ES-RMS over ES-RHS for this class of processors. For processors which allow cores to individually transition into deep sleep, we prove that, while utilizing ES-RHS on each core, any feasible partition can optimally utilize all of the processor's idle durations to put it into deep sleep. Experimental evaluations indicate that the proposed techniques can provide significant energy savings.	approximation algorithm;cma-es;central processing unit;es evm;fixed-priority pre-emptive scheduling;frequency scaling;heuristic;image scaling;load balancing (computing);multi-core processor;opengl es;rate-monotonic scheduling;real-time clock;scheduling (computing);spectral leakage;transistor;uniprocessor system	Sandeep D'Souza;Anand Bhat;Ragunathan Rajkumar	2016	2016 28th Euromicro Conference on Real-Time Systems (ECRTS)	10.1109/ECRTS.2016.16	fair-share scheduling;generalized processor sharing;fixed-priority pre-emptive scheduling;embedded system;parallel computing;real-time computing;earliest deadline first scheduling;flow shop scheduling;dynamic priority scheduling;computer science;rate-monotonic scheduling;two-level scheduling;stride scheduling;gain scheduling;least slack time scheduling;round-robin scheduling;multiprocessor scheduling;i/o scheduling;proportionally fair	EDA	-5.70941060555752	58.68280155150363	31641
8d062cb02827deca7bb3da926ad8b5193a80cf36	an empirical study for evaluating the performance of multi-cloud apis		Abstract The massive use of cloud APIs for workload orchestration and the increased adoption of multiple cloud platforms prompted the rise of multi-cloud APIs. Multi-cloud APIs abstract cloud differences and provide a single interface regardless of the target cloud platform. Identifying whether the performance of multi-cloud APIs differs significantly from platform-specific APIs is central for driving technological decisions on cloud applications that require maximum performance when using multiple clouds. This study aims to evaluate the performance of multi-cloud APIs when compared to platform-specific APIs. We carried out three rigorous quasi-experiments to measure the performance ( dependent variable ) of cloud APIs ( independent variable ) regarding CPU time, memory consumption and response time. jclouds and Libcloud were the two multi-cloud APIs used ( experimental treatment ). Their performance were compared to platform-specific APIs ( control treatment ) provided by Amazon Web Services and Microsoft Azure. These APIs were used for uploading and downloading ( tasks ) 39 722 files in five different sizes to/from storage services during five days ( trials ). Whereas jclouds performed significantly worse than platform-specific APIs for all performance indicators on both cloud platforms and operations for all five file sizes, Libcloud outperformed platform-specific APIs in most tests ( p -value not exceeding 0.00125, A -statistic greater than 0.64). Once confirmed by independent replications, our results suggest that jclouds developers should review the API design to ensure minimal overhead whereas jclouds users should evaluate the extent to which this trade-off affect the performance of their applications. Multi-cloud users should carefully evaluate what quality attribute is more important when selecting a cloud API.		Reginaldo Ré;Rômulo Manciola Meloca;Douglas Nassif Junior;Marcelo Alexandre da Cruz Ismael;Gabriel Costa Silva	2018	Future Generation Comp. Syst.	10.1016/j.future.2017.09.003	web service;cpu time;workload;orchestration (computing);performance indicator;real-time computing;operating system;computer science;cloud computing;response time;database;upload	Arch	-23.957882891902646	59.48100302214351	31687
a4826463631134f28db7b5f3a8353231d80e5957	development of a farm-oriented benchmark tool for distributed filesystem	nfs filesystem farm oriented benchmark tool development distributed filesystem infn cnaf tier1 computing center italian institute of nuclear physics farming departments storage departments network departments infrastructure departments hardware performance measurements storage devices real production data access pattern hardware solution production environment throughput measurement input output operation software synchronization method ad hoc library mpi real physical analysis job data access pattern tuning parameters visualization program gpfs filesystem;benchmark testing databases hardware bandwidth monitoring synchronization data models;storage management distributed databases program visualisation	The INFN CNAF Tier1 is the main computing center of Italian Institute of Nuclear Physics. Here there are several teams that cooperate with each other in order to grant proper operation of the entire center. In our organization these groups are: the farming, the storage, the network and the infrastructure departments. In each teams one of the most important necessity is to measure the performance of the hardware in use. In addition, defining what performance measurements are significant in the context and how to measure them is not an obvious task. Our work is focused on the storage devices and the goal of this project is to understand how we can measure the performance of a filesystem with a real production data access pattern in order to compare different hardware solution for the production environment. Currently there are other tools that can help to measure the throughput through bandwidth or the Input/Output Operation per second (iops) of a filesystem, but they cant simulate a real production environment data access pattern. Effectively these tools work only with limited number of concurrent multiple processes or they haven't enough flexibility to simulate a real pattern. Furthermore, they must be synchronized via barriers (i.e. software synchronization method) or via ad hoc library as MPI. The tool presented in this paper can simulate a real physical analysis job data access pattern starting from a real job and replicate the simulation without heavy synchronization between nodes or without a heavy environment set up. The data are collected from each node and lossless stored into a remote database. It, also, include the possibility to indicate opportune tuning parameters for better suiting to several scenarios, e.g. it is possible to decide the sampling times during the test or the duration that a test can take in order to use a scheduled time windows arrange with other team. It is also possible to represent the data in a graphic way, using the appropriate analysis and visualization program. In addition, the data could be processed in various ways and the sampling times could be aggregated for a better visualization. Initially the tool has been developed for measuring GPFS and NFS filesystem but it has a modular implementation and therefore it is ready to analyze other types of filesystem simply developing the correct module for each.	barrier (computer science);benchmark (computing);clustered file system;data access;deployment environment;hoc (programming language);ibm gpfs;input/output;job stream;lossless compression;message passing interface;microsoft windows;performance tuning;petabyte;remote database access;sampling (signal processing);self-replicating machine;simulation;throughput	Matteo Favaro;Pier Paolo Ricci;Daniele Gregori	2014	2014 International Conference on High Performance Computing & Simulation (HPCS)	10.1109/HPCSim.2014.6903806	parallel computing;real-time computing;computer science;operating system;database;distributed computing;programming language	HPC	-20.295101641803	52.06037294919712	31688
89f6916e0b2ba4c42696763608ad44fbeb0aa081	energy efficient resource allocation strategy for cloud data centres		Cloud computing data centres are emerging as new candidates for replacing traditional data centres. Cloud data centres are growing rapidly in both number and capacity to meet the increasing demands for highly-responsive computing and massive storage. Making the data centre more energy efficient is a necessary task. In this paper, we focus on the organisation’s internal Infrastructure as a Service (IaaS) data centre type. An internal IaaS cloud data centre has many distinguished features with heterogeneous hardware, single application, stable load distribution, lived load migration and highly automated administration. This paper will propose a way of saving energy for IaaS cloud data centre considering all stated constraints. The basic idea is rearranging the allocation in a way that saving energy. The simulation results show the efficiency of the method.	algorithm;cloud computing;computer hardware;data center;heuristic;load balancing (computing);semiconductor consolidation;server (computing);simulation	Dang Minh Quan;Robert Basmadjian;Hermann de Meer;Ricardo Lent;Toktam Mahmoodi;Domenico Sannelli;Federico Mezza;Luigi Telesca;Corentin Dupont	2011		10.1007/978-1-4471-2155-8_16	resource allocation;environmental resource management;computer network	HPC	-25.838488461785598	60.3836187240615	31810
e5e09d5e5385c1cf0c12dcd84b3df9d399e585b8	two implementations of a concurrent simulation environment	programming language;parallel computer;technical report;simulation environment	This paper discusses the design of a concurrent simulation environment hosted on the Ada programming language at the Laboratory for Software Research at Texas A & M University. This environment was first implemented on a VAX 11/750 single processor system and then ported to a Sequent Balance 8000 parallel computer system with ten processors. Two run-time Ada systems were available on the Sequent: one for sequential and one for parallel. This paper reports our experiences in porting the original software to these new environments.	ada;central processing unit;computer;parallel computing;programming language;sequent calculus;simulation;vax	Carolyn Hughes;Usha Chandra;Sallie V. Sheppard	1987		10.1145/318371.318673	computer architecture;parallel computing;computer science;technical report;programming language;world wide web	HPC	-10.606579870984346	40.80957596458445	31831
4de514893ed7c3249ed61fdbd83d82d184ec6354	unison, canon, and sluggish clocks in networks controlled by a synchronizer	distributed networks;linear time	The effect of using a simple synchronizer on the performance of a directed, strongly connected, distributed network, is analysed. In this paper we assume that the time of message transmission is positive but negligible. It is shown that the synchronizer is sufficient to assure that a full rate of computation is achieved in networks with a global clock, in spite of the absence of a global start-up signal. In fact,unison is reached within linear time. A similar phenomenon occurs if there is no global clock, but all local clocks have the same rate. In case the local clocks do not have the same rate, it is shown that the computational rate is not slower than anysluggish clock; i.e., a clock such that between any two of its ticks, every local clock ticks at least once.	computation;computer performance;full rate;strongly connected component;synchronizer (algorithm);time complexity;unison	Shimon Even;Sergio Rajsbaum	1995	Mathematical systems theory	10.1007/BF01185865	time complexity;clock synchronization;real-time computing;telecommunications;clock domain crossing;clock hypothesis;computer science;mathematics;distributed computing;timing failure;clock drift;algorithm	Embedded	-21.110539320617328	44.03496633056949	31876
263cbd7a73320128bea00df99ff7dec809aa26fe	a framework for the dynamic evolution of highly-available dataflow programs	consensus;multicore;message passing;scalability	"""Many distributed applications deployed on the Internet must operate continuously with no noticeable interruption of service. Such 24/7 availability requirements make the maintenance of these application difficult because fixing bugs or adding new functionality necessitates the online replacement of the software version by the new one, i.e., a """"live update"""". Support for """"live update"""" is therefore essential to allow software evolution of critical services. While the problem of live update has been widely studied and several techniques have been proposed (e.g., using group communication and replication), we propose in this paper an original approach for the dataflow-based programming model (FBP). An interesting property of FBP is its seamless support for multi-and many-core architectures, which have become the norm in recent generation of servers and Cloud infrastructures. We introduce a framework and new algorithms for implementing coordinated non-blocking updates, which do not only support the replacement of individual software components, but also modifications of structural aspects of the applications independently of the underlying execution infrastructure. These algorithms allow us to transparently orchestrate live updates without halting the executing program. We illustrate and evaluate our approach on a web server application. We present experimental evidence that our live update algorithms are scalable and have negligible impact on availability and performance."""	blocking (computing);cloud computing;component-based software engineering;dataflow programming;distributed computing;flow-based programming;internet;interrupt;manycore processor;non-blocking algorithm;programming model;requirement;scalability;seamless3d;server (computing);software bug;software evolution;software versioning;web server	Sebastian Ertel;Pascal Felber	2014		10.1145/2663165.2663320	real-time computing;computer science;theoretical computer science;distributed computing	OS	-24.667735545531496	54.05348270006144	31879
f13a2dfc48a0d645134b2411873933bfeae0a3b9	execution history guided instruction prefetching	instruction cache;performance improvement;cache performance;hardware prefetching;instruction prefetching;memory latency	The increasing gap in performance between processors and main memory has made effective instructions prefetching techniques more important than ever. A major deficiency of existing prefetching methods is that most of them require an extra port to I-cache. A recent study by Rivers et al. [19] shows that this factor alone explains why most modern microprocessors do not use such hardware-based I-cache prefetch schemes. The contribution of this paper is two-fold. First, we present a method that does not require an extra port to I-cache. Second, the performance improvement for our method is greater than the best competing method BHGP [23] even disregarding the improvement from not having an extra port. The three key features of our method that prevent the above deficiencies are as follows. First, late prefetching is prevented by correlating misses to dynamically preceding instructions. For example, if the I-cache miss latency is 12 cycles, then the instruction that was fetched 12 cycles prior to the miss is used as the prefetch trigger. Second, the miss history table is kept to a reasonable size by grouping contiguous cache misses together and associated them with one preceding instruction, and therefore, one table entry. Third, the extra I-cache port is avoided through efficient prefetch filtering methods. Experiments show that for our benchmarks, chosen for their poor I-cache performance, an average improvement of 9.2% in runtime is achieved versus the BHGP methods [23], while the hardware cost is also reduced. The improvement will be greater if the runtime impact of avoiding an extra port is considered. When compared to the original machine without prefetching, our method improves performance by about 35% for our benchmarks.	angular defect;benchmark (computing);cpu cache;cache (computing);central processing unit;computer data storage;mhtml;microprocessor	Yi Zhang;Steve Haga;Rajeev Barua	2004	The Journal of Supercomputing	10.1023/B:SUPE.0000009319.31230.a9	parallel computing;real-time computing;cas latency;computer hardware;computer science;operating system	HPC	-9.773887437201948	53.09969881335693	31919
9cb4489c20675d927a5bfcc9c6b7a6c0d7300ace	modeling and evaluation of a new message-passing system for parallel multiprocessor systems	modelizacion;parallelisme;evaluation performance;performance evaluation;systeme passage message;multiprocessor systems;message passing system;evaluacion prestacion;multiprocesseur memoire repartie;transputer;modelisation;distributed memory multiprocessor;parallelism;paralelismo;reseau transputer;parallel implementation;implantation parallele;modeling;transputer network	Abstract   As parallel implementation of complex applications is becoming popular, the need for a high performance interprocessor communication system becomes imminent, especially in loosely coupled distributed-memory multiprocessor networks. An important factor in the efficiency of these networks is the effectiveness of the message-passing system which manages the data exchanges among the processors of the network. This paper presents the modeling and performance evaluation of a new Message-Passing System (MPS) for distributed multiprocessor networks without shared-memory and where the processors or Processing Elements (PEs) are connected to each other by point-to-point communication links. For maximum performance, the MPS manages the communication and the synchronization between the different tasks of an application by means of three approaches. One is an asynchronous send/receive approach which handles efficiently server like tasks, the second is a synchronous send/receive approach which handles efficiently streaming communication mode and the third is a virtual channel approach which minimizes the overhead of the synchronization mechanism, efficiently handling the burst mode of heavy communication between tasks. The developed models of the MPS approaches enable the determination of analytical expressions for different performances and a comparison between analytical and experimental performances reveals that the models predict the MPS performance with high accuracy. The MPS written in Parallel ANSI C, is studied on a mesh topology network of 16 transputers T800. The MPS performances for each approach are studied and presented in terms of communication latency, throughput, computation efficiency and memory consumption.	message passing;multiprocessing	Helnye Azaria;Yuval Elovici	1993	Parallel Computing	10.1016/0167-8191(93)90012-A	parallel computing;real-time computing;systems modeling;computer science;operating system;distributed computing	HPC	-17.87603117950523	43.19612626939015	31929
f4c217923ceebd709e8eb106b1f7d25fd5d088c2	loggp: incorporating long messages into the logp model for parallel computation	latencia;prediccion;eficacia sistema;largeur bande;processing;general and miscellaneous mathematics computing and information science;parallel algorithm;image processing;systeme multiprocesseur memoire repartie;long message;time complexity;latence;analytical solution;transformations;performance systeme;teleinformatica;short message;transmission message;mathematical logic;system performance;message transmission;parallel computation;computer architecture;teleinformatique;message court;complexite temps;calculo paralelo;parallel image processing;sistema multiprocesador memoria distribuida;array processors;anchura banda;linear model;parallel computer;bandwidth;algorithms;parallel machines;mapping;message long;latency;distributed memory multiprocessor system;complejidad tiempo;programming 990210 supercomputers 1987 1989;algoritmo optimo;real time image processing;algorithme optimal;optimal algorithm;analytic solution;calcul parallele;remote data processing;prediction;algorithm design;logical process;parallel processing;transmision mensaje	We present a new model of parallel computation—the LogGP model—and use it to analyze a number of algorithms, most notably, the single node scatter (one-to-all personalized broadcast). The LogGP model is an extension of the LogP model for parallel computation which abstracts the communication of fixed-sized short messages through the use of four parameters: the communication latency (L), overhead (o), bandwidth ( g), and the number of processors ( P). As evidenced by experimental data, the LogP model can accurately predict communication performance when only short messages are sent (as on the CM-5). However, many existing parallel machines have special support for long messages and achieve a much higher bandwidth for long messages than for short messages (e.g., IBM SP-2, Paragon, Meiko CS-2, Ncube/ 2). We extend the basic LogP model with a linear model for long messages. This combination, which we call the LogGP model of parallel computation, has one additional parameter,G, which captures the bandwidth obtained for long messages. Experimental data collected on the Meiko CS-2 shows that this simple extension of the LogP model can quite accurately predict communication performance for both short and long messages. This paper discusses algorithm design and analysis under the new model. We also examine, in more detail, the single node scatter problem under LogGP. We derive solutions for this problem which are qualitatively different from those obtained under the simpler LogP model, reflecting the importance of capturing long messages in a model. © 1997 Academic Press	algorithm design;central processing unit;computation;connection machine;linear model;logp machine;overhead (computing);parallel computing;personalization	Albert D. Alexandrov;Mihai F. Ionescu;Klaus E. Schauser;Chris J. Scheiman	1997	J. Parallel Distrib. Comput.	10.1006/jpdc.1997.1346	parallel processing;closed-form expression;feature detection;parallel computing;telecommunications;image processing;computer science;theoretical computer science;operating system;digital image processing;distributed computing;numerical linear algebra;programming language;algorithm;statistics	HPC	-15.501350741416507	43.50549249401548	31962
5721a2b3e585dd0dbec5385132d987d966327db5	realization of the low cost and high performance mysql cloud database		MySQL is a low cost, high performance, good reliability and open source database product, widely used in many Internet companies. For example, there are thousands of MySQL servers being used in Taobao. Although NoSQL developed very quickly in past two years, and new products emerged in endlessly, but in the actual business application of NoSQL, the requirements to developers are relatively high. Moreover, MySQL has many more mature middleware, maintenance tools and a benign ecological circle, so from this perspective, MySQL dominates in the whole situation, while NoSQL is as a supplement. We (the core system database team of Taobao) have done a lot of work in the filed of MySQL hosting platform, designed and implemented a UMP (Unified MySQL Platform) system, to provide a low cost and high performance MySQL cloud database service.	business software;cloud database;middleware;mysql;nosql;open-source software;requirement;taobao marketplace	Wei Cao;Feng Yu;Jiasen Xie	2014	PVLDB	10.14778/2733004.2733077	data mining;database;world wide web	DB	-27.961482104575943	54.23267104071261	31970
fd8d2d2d0fa63d2ebc4dfd7d2678a5214bb77982	maintaining temporal consistency: pessimistic vs. optimitic concurrency control	phase locking;systeme temps reel;herencia;evaluation performance;protocols;fijacion;concurrency control algorithms;computer society;verrouillage;optimistic algorithms;algorithm performance;lock based concurrency control temporal consistency optimistic concurrency control concurrency control algorithms shared data hard real time systems periodic tasks update transactions real time transactions temporally consistent data multiversion data two phase locking optimistic algorithms rate monotonic earliest deadline first scheduling algorithms priority inheritance stack based protocols;performance evaluation;data integrity;connectionism;gestion labor;conexionismo;heritage;data temporal consistency;earliest deadline first;real time;evaluacion prestacion;temporally consistent data;stack;multiversion data;real time transactions;locking;priorite;two phase locking;scheduling real time systems concurrency control data integrity software performance evaluation;concurrency control scheduling algorithm real time systems navigation computer society protocols performance evaluation remotely operated vehicles mobile robots process control;software performance evaluation;simultaneidad informatica;pila;mobile robots;remotely operated vehicles;periodicite;consistencia;periodicity;connexionnisme;navigation;scheduling algorithm;concurrency;periodicidad;earliest deadline first scheduling algorithms;gestion tâche;hard real time system;shared data;stack based protocols;periodic tasks;resultado algoritmo;temporal consistency;scheduling;real time scheduling;indexation;consistance;concurrency control;process control;performance algorithme;optimistic concurrency control;periodic job model;lock based concurrency control;ordonamiento;real time system;priority inheritance;sistema tiempo real;controle concurrence;control concurrencia;multiversion concurrency control;task scheduling;inheritance;priority;prioridad;simultaneite informatique;pile memoire;update transactions;rate monotonic;consistency	{ We study the performance of concurrency control algorithms in maintaining temporal consistency of shared data in hard real-time systems. In our model, a hard real-time system consists of periodic tasks which are either write-only, read-only or update transactions. Transactions may share data. Data objects are temporally inconsistent when their ages and dispersions are greater than the absolute and relative thresholds allowed by the application. Real-time transactions must read temporally consistent data in order to deliver correct results. Based on this model, we have evaluated the performance of two well-known classes of concurrency control algorithms that handle multiversion data: the two-phase locking and the optimistic algorithms, as well as the rate-monotonic and earliest-deadline-rst scheduling algorithms. The eeects of using the priority inheritance and stack-based protocols with lock-based concurrency control are also studied.	algorithm;concurrency control;earliest deadline first scheduling;lock (computer science);priority inheritance;read-only memory;real-time computing;real-time locating system;real-time transcription;scheduling (computing);stack-oriented programming language;temporal logic;two-phase locking;write-only documentation	Xiohui Song;Jane W.-S. Liu	1995	IEEE Trans. Knowl. Data Eng.	10.1109/69.469820	timestamp-based concurrency control;connectionism;optimistic concurrency control;parallel computing;real-time computing;isolation;computer science;process control;database;distributed computing;multiversion concurrency control;serializability;scheduling;distributed concurrency control	DB	-23.63035729820312	48.05055212317464	31992
c806e288fd878814f2f739b29bebba69554199a0	deadlock detection for actor-based coroutines		The actor-based language studied in this paper features asynchronous method calls and supports coroutines which allow for the cooperative scheduling of the method invocations belonging to an actor. We model the local behavior of an actor as a well-structured transition system by means of predicate abstraction and derive the decidability of the occurrence of deadlocks caused by the coroutine mode of method execution.	actor model;automated theorem proving;computer multitasking;coroutine;deadlock;key;predicate abstraction;reachability;scheduling (computing);sensor;well-structured transition system	Keyvan Azadbakht;Frank S. de Boer;Erik P. de Vink	2018		10.1007/978-3-319-95582-7_3	predicate abstraction;transition system;theoretical computer science;scheduling (computing);asynchronous method invocation;deadlock;computer science;deadlock prevention algorithms;decidability;coroutine	AI	-27.796666034873883	33.41868329662585	32005
9a7e961710b01b3e78b32f9696881fd57730439a	numa aware iterative stencil computations on many-core systems	cache storage;affinity;kernel;4 socket oct core system nonuniform memory access aware iterative stencil computation many core system tiling scheme contradicting goal spatio temporal data locality regular memory access pattern independent task data to core affinity numa aware data distribution cache coherent nonuniform memory access temporal blocking algorithm cache aware scheme cache oblivious scheme numa aware variant tiling strategy parallelization strategy 8 socket dual core system;numa aware data distribution;tiles instruction sets bandwidth synchronization kernel scalability cats;temporal blocking;multiprocessing systems cache storage iterative methods;cache aware;iterative methods;synchronization;bandwidth;parallelism and locality;tiles;scalability;multiprocessing systems;stencil computation;cats;parallelism and locality stencil computation temporal blocking numa aware data distribution affinity cache oblivious cache aware;instruction sets;cache oblivious	Temporal blocking in iterative stencil computations allows to surpass the performance of peak system bandwidth that holds for a single stencil computation. However, the effectiveness of temporal blocking depends strongly on the tiling scheme, which must account for the contradicting goals of spatio-temporal data locality, regular memory access patterns, parallelization into many independent tasks, and datato-core affinity for NUMA-aware data distribution. Despite the prevalence of cache coherent non-uniform memory access (ccNUMA) in todays many-core systems, this latter aspect has been largely ignored in the development of temporal blocking algorithms. Building upon previous cache-aware [1] and cacheoblivious [2] schemes, this paper develops their NUMA-aware variants, explaining why the incorporation of data-to-core affinity as an equally important goal necessitates also new tiling and parallelization strategies. Results are presented on an 8 socket dual-core and a 4 socket oct-core systems and compared against an optimized naive scheme, various peak performance characteristics, and related schemes from literature.	algorithm;blocking (computing);cache coherence;coherence (physics);computation;image scaling;iterative method;locality of reference;manycore processor;multi-core processor;non-uniform memory access;octal;parallel computing;processor affinity;requirement;scalability;stencil (numerical analysis);tiling window manager;uniform memory access	Mohammed Shaheen;Robert Strzodka	2012	2012 IEEE 26th International Parallel and Distributed Processing Symposium	10.1109/IPDPS.2012.50	synchronization;cache-oblivious algorithm;parallel computing;kernel;real-time computing;scalability;stencil code;computer science;theoretical computer science;operating system;instruction set;iterative method;bandwidth	HPC	-8.160848579146842	48.03873898495431	32014
540f711164908f47c65621cda74d0f3eee0342af	impact of variable privatization on extracting synchronization-free slices for multi-core computers		Variable Privatization is an important technique that has been used by compilers to parallelize loops by eliminating storage-related dependences. In this paper, we present an approach that combines extracting synchronization-free slices available in program loops with variable privatization. This permits us to reduce the number of dependence relations and as a consequence to reduce the time complexity of algorithms aimed at extracting synchronization-free slices. This leads to enlarging the scope of the applicability of those algorithms and reducing the time required to parallelize loops. The scope of the applicability of the approach is illustrated by means of the NAS Parallel Benchmark suite. Results of a performance analysis for parallelized loops executed on a multi-core computer are presented. Received results are compared with those obtained by other loop parallelization techniques. The future work is outlined.	multi-core processor	Marek Palkowski	2012		10.1007/978-3-642-35893-7_7	simulation;computer science;operations management;theoretical computer science	NLP	-7.055840036747807	47.42484268024233	32036
16cd0b1873ce707bc8d2dbfc136af51f9072611c	a transparent distributed shared memory for clustered symmetric multiprocessors	workload;reconfiguration;symmetric configuration;parallelisme;distributed system;virtual memory;interfase usuario;cluster computing;distribution donnee;systeme reparti;shared memory;symmetric multiprocessor;multiprocessor;user interface;racimo calculadura;memoria compartida;configuration symetrique;memoria virtualmente compartida;distributed computing;processus leger logiciel;supercomputer;system performance;data distribution;thread architecture;memoire virtuellement partagee;supercomputador;proceso ligero logicial;configuracion simetrica;grappe calculateur;parallelism;shared memory systems;sistema repartido;paralelismo;charge travail;memoire virtuelle;thread software;calculo repartido;interface utilisateur;multiprocesador;carga trabajo;shared memory system;distributed shared memory;distribucion dato;calcul reparti;memoria virtual;systeme memoire partagee;superordinateur;memoire partagee;multiprocesseur	A transparent distributed shared memory (DSM) system must achieve complete transparency in data distribution, workload distribution, and reconfiguration respectively. The transparency of data distribution allows programmers to be able to access and allocate shared data using the same user interface as is used in shared-memory systems. The transparency of workload distribution and reconfiguration can optimize the parallelism at both the user-level and the kernel-level, and also improve the efficiency of run-time reconfiguration. In this paper, a transparent DSM system referred to as Teamster is proposed and is implemented for clustered symmetric multiprocessors. With the transparency provided by Teamster, programmers can exploit all the computing power of the clustered SMP nodes in a transparent way as they do in single SMP computer. Compared with the results of previous researches, Teamster can realize the transparency of cluster computing and obtain satisfactory system performance.	computational science;computer cluster;distributed shared memory;global microbial identifier;internetworking;parallel computing;process migration;programmer;thread (computing);user space	Jyh-Biau Chang;Ce-Kuen Shieh;Tyng-Yeu Liang	2006	The Journal of Supercomputing	10.1007/s11227-006-5483-x	distributed shared memory;shared memory;embedded system;supercomputer;parallel computing;multiprocessing;computer cluster;computer science;virtual memory;control reconfiguration;operating system;distributed computing;user interface	HPC	-17.440709904778497	43.08766649099782	32076
8d181ccff96ed9100521c10327624eaa5b1a41e2	exploiting reference idempotency to reduce speculative storage overflow	lenguaje programacion;arquitectura circuito;overflow computer arithmetics;compilateur;storage access;programming language;data stream;storage structure;metodo formal;methode formelle;circuit architecture;stockage donnee;buffer system;compiler;capacite stockage;compilers;formal method;sistema amortiguador;data storage;speculation;data dependence;multiple instruction stream;capacidad almacenaje;necessary and sufficient condition;storage capacity;theory;multithreaded architecture;acces memoire;speculative execution;architecture circuit;life sciences;rebasamiento capacidad;health science;idempotent references;langage programmation;hierarchie memoire;acceso memoria;multithread;almacenamiento datos;multiple data stream processors;algorithms;depassement capacite;estructura memoria;structure memoire;multitâche;memory hierarchy;systeme tampon;jerarquia memoria;multitarea;especulacion;compilador;compiler assisted speculative execution	Recent proposals for multithreaded architectures employ speculative execution to allow threads with unknown dependences to execute speculatively in parallel. The architectures use hardware speculative storage to buffer speculative data, track data dependences and correct incorrect executions through roll-backs. Because all memory references access the speculative storage, current proposals implement speculative storage using small memory structures to achieve fast access. The limited capacity of the speculative storage causes considerable performance loss due to speculative storage overflow whenever a thread's speculative state exceeds the speculative storage capacity. Larger threads exacerbate the overflow problem but are preferable to smaller threads, as larger threads uncover more parallelism.In this article, we discover a new program property called memory reference idempotency. Idempotent references are guaranteed to be eventually corrected, though the references may be temporarily incorrect in the process of speculation. Therefore, idempotent references, even from nonparallelizable program sections, need not be tracked in the speculative storage, and instead can directly access nonspeculative storage (i.e., conventional memory hierarchy). Thus, we reduce the demand for speculative storage space in large threads. We define a formal framework for reference idempotency and present a novel compiler-assisted speculative execution model. We prove the necessary and sufficient conditions for reference idempotency using our model. We present a compiler algorithm to label idempotent memory references for the hardware. Experimental results show that for our benchmarks, over 60% of the references in nonparallelizable program sections are idempotent.	algorithm;benchmark (computing);compiler;idempotence;memory hierarchy;parallel computing;speculative execution;thread (computing)	Seon Wook Kim;Chong-liang Ooi;Rudolf Eigenmann;Babak Falsafi;T. N. Vijaykumar	2006	ACM Trans. Program. Lang. Syst.	10.1145/1152649.1152653	compiler;parallel computing;real-time computing;formal methods;computer science;programming language;speculative multithreading;algorithm	PL	-15.967010850040596	44.27623790382723	32080
14e458a294eac4102cc8eb7db7ddf56b8f611cce	storm: using p2p to make the desktop part of the web	dangling links;storage system;p2p;content addressable network;location independent identifiers;content addressable networks;peer to peer technology;peer to peer	We present Storm, a storage system which unifies the desktop and the public network, making Web links between desktop documents more practical. Storm assigns each document a permanent unique URI when it is created. Using peer-to-peer technology, we can locate documents even though our URIs do not include location information. Links continue to work unchanged when documents are emailed or published on the network. We have extended KDE to understand Storm URIs. Other systems such as GNU Emacs are able to use Storm through an HTTP gateway.	computer data storage;desktop computer;email;gnu emacs;hypertext transfer protocol;peer-to-peer;uniform resource identifier	Benja Fallenstein;Tuomas J. Lukka;Hermanni Hyytiälä;Toni Alatalo	2003		10.1145/900051.900084	content addressable network;computer science;peer-to-peer;database;internet privacy;world wide web	Web+IR	-22.02069071246771	51.86469839394257	32092
cf77275893f299065c6a5e06f69ef09630441739	the inner most loop iteration counter: a new dimension in branch history	energy efficiency;history;radiation detectors;tracking loops;correlators;fine grained phase prediction;monitoring;heterogeneous processors;correlation;hardware	The most efficient branch predictors proposed in academic literature exploit both global branch history and local branch history. However, local history branch predictor components introduce major design challenges, particularly for the management of speculative histories. Therefore, most effective hardware designs use only global history components and very limited forms of local histories such as a loop predictor.  The wormhole (WH) branch predictor was recently introduced to exploit branch outcome correlation in multidimensional loops. For some branches encapsulated in a multidimensional loop, their outcomes are correlated with those of the same branch in neighbor iterations, but in the previous outer loop iteration. Unfortunately, the practical implementation of the WH predictor is even more challenging than the implementation of local history predictors.  In this paper, we introduce practical predictor components to exploit this branch outcome correlation in multidimensional loops: the IMLI-based predictor components. The iteration index of the inner most loop in an application can be efficiently monitored at instruction fetch time using the Inner Most Loop Iteration (IMLI) counter. The outcomes of some branches are strongly correlated with the value of this IMLI counter. A single PC+IMLI counter indexed table, the IMLI-SIC table, added to a neural component of any recent predictor (TAGE-based or perceptron-inspired) captures this correlation. Moreover, using the IMLI counter, one can efficiently manage the very long local histories of branches that are targeted by the WH predictor. A second IMLI-based component, IMLI-OH, allows for tracking the same set of hard-to-predict branches as WH.  Managing the speculative states of the IMLI-based predictor components is quite simple. Our experiments show that augmenting a state-of-the-art global history predictor with IMLI components outperforms previous state-of-the-art academic predictors leveraging local and global history at much lower hardware complexity (i.e., smaller storage budget, smaller number of tables and simpler management of speculative states).	branch predictor;experiment;iteration;kerrison predictor;mehrotra predictor–corrector method;perceptron;ring counter;simplified instructional computer;speculative execution;strongly correlated material	André Seznec;Joshua San Miguel;Jorge Albericio	2015	2015 48th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO)	10.1145/2830772.2830831	parallel computing;real-time computing;simulation;branch target predictor;computer science;theoretical computer science;operating system;efficient energy use;particle detector;correlation	Arch	-6.0633151276963115	52.14650891004049	32107
8bf3827ad3d1c1ccaee25a0d9fc643aeb3bf3df4	runtime locality optimizations of distributed java applications	performance measure;distributed system;virtual machine;cluster;optimal virtual machine;distributed processing;individual object;optimal virtual machine runtime locality optimization distributed java application javaparty parallel java application;javaparty;java distributed processing;runtime locality optimization;dynamic locality optimization;java virtual machining runtime environment yarn performance gain programming profession dynamic programming parallel programming workstations parallel processing;runtime performance measurement dynamic locality optimization distributed java applications cluster;parallel java application;runtime performance measurement;parallel applications;distributed java applications;java;distributed java application	In distributed Java environments, locality of objects and threads is crucial for the performance of parallel applications. We introduce dynamic locality optimizations in the context of JavaParty, a programming and runtime environment for parallel Java applications. Until now, an optimal distribution of the individual objects of an application has to be found manually, which has several drawbacks. Based on a former static approach, we develop a dynamic methodology for automatic locality optimizations. By measuring processing and communication times of remote method calls at runtime, a placement strategy can be computed that maps each object of the distributed system to its optimal virtual machine. Objects then are migrated between the processing nodes in order to realize this placement strategy. We evaluate our approach by comparing the performance of two benchmark applications with manually distributed versions. It is shown that our approach is particularly suitable for dynamic applications where the optimal object distribution varies at runtime.	benchmark (computing);central processing unit;distributed algorithm;distributed computing;java;locality of reference;numerical analysis;overhead (computing);run time (program lifecycle phase);runtime system;thread (computing);virtual machine	Christian Hütter;Thomas Moschny	2008	16th Euromicro Conference on Parallel, Distributed and Network-Based Processing (PDP 2008)	10.1109/PDP.2008.76	parallel computing;real-time computing;computer science;virtual machine;operating system;distributed computing;programming language;java;cluster	HPC	-14.862926606329761	59.03389327140144	32116
6cc5f88c19f63578c7265af7c414697362ead16f	parallel ray tracing using processor farming model	libraries;ray tracing algorithm;parallel algorithm;concurrent computing;parallel ray tracing;distributed task;photorealistic rendering;distributed task processor farming ray tracing algorithm photorealistic rendering scalability load balancing parallel ray tracing;distributed computing;parallel programming;computational modeling;parallel programming ray tracing rendering computer graphics;parallel systems;processor farming;ray tracing;load management;load balancing;load balance;scalability;rendering computer graphics;parallel processing;ray tracing rendering computer graphics parallel processing concurrent computing parallel algorithms libraries computational modeling scalability load management distributed computing;parallel algorithms	The ray tracing algorithm is one of many photorealistic rendering techniques. It requires heavy computational processing to synthesize images. Parallel processing can be used to reduce the computational processing time. A parallel algorithm for ray tracing has been implemented using a processor farming model with the MPI parallel library. The implemented parallel ray tracing has been executed to simulate various images on an IBM SP system. Since each image is divided and distributed to each farming processor; the scalability of the parallel system and load balancing are achieved simultaneously in the proposed algorithm. Eficiency of the parallel ray tracing of up to eighty-seven percent of the ideal speedup is obtained for I5 processors. However; the best size of a distributed task is much higher in simple images due to the lower computational requirement for each pixel. Eficiency degradation is observed for small granularity tasks because of relatively increased communication overhead. The processor farming model programming is evaluated excellently in both programming easiness and its eficiency.	central processing unit;data degradation;elegant degradation;load balancing (computing);overhead (computing);parallel algorithm;parallel processing (dsp implementation);pixel;ray tracing (graphics);scalability;simulation;speedup;unbiased rendering	Hyo Jong Lee;B. H. Lim	2001		10.1109/ICPPW.2001.951851	parallel processing;parallel computing;real-time computing;concurrent computing;computer science;load balancing;parallel algorithm;computer graphics (images)	HPC	-6.821038752277062	41.193574279014534	32146
68d759190ad9fd762eb6c13c0707526d1295c464	a hybrid load balancing policy underlying grid computing environment	dynamic load balancing;grid computing environment;information technology;distributed computing;large scale;load balancing;load balance;distributed computing environment;grid computing	Network bandwidth and hardware technology are developing rapidly, resulting in the vigorous development of the Internet. A concept, cloud computing, uses low-power hosts to achieve high usability. The cloud computing refers to a class of systems and applications that employ distributed resources to perform a function in a decentralized manner. Cloud computing is to utilize the computing resources (service nodes) on the network to facilitate the execution of complicated tasks that require large-scale computation. Thus, the selecting nodes for executing a task in the cloud computing must be considered. However, in this study, a hybrid load balancing policy, which integrated static, and dynamic load balancing technologies to assist in the selection for effective nodes. In addition, if any selected node can no longer provide resources, it can be promptly identified and replaced with a substitutive node to maintain the execution performance and the load balancing of the system. Key-Words: Cloud computing, Distributed computing, Load balancing	cloud computing;computation;distributed computing;grid computing;internet;load balancing (computing);low-power broadcasting;usability	Kuo-Qin Yan;Shu-Chin Wang;Chiu-Ping Chang;J. S. Lin	2007	Computer Standards & Interfaces	10.1016/j.csi.2006.03.003	parallel computing;real-time computing;computer science;load balancing;distributed computing;utility computing;information technology;computer security;grid computing;autonomic computing	HPC	-20.028332038188175	58.58577692181419	32177
96406b84be276bf1001f82ad3cad802cec979d4f	the anatomy of the register file in a multiscalar processor	compiler support register file multiscalar processor multiscalar architecture logically centralized register file decentralized register file queues control logic storage communication synchronization instruction level parallelism;program compilers parallel architectures instruction sets synchronisation;synchronisation;automatic instruction set design;compile time optimization;parallel architectures;logic synthesis;anatomy registers computer architecture communication system control permission centralized control logic engines parallel processing distributed computing;register file;program compilers;programmable logic;general purpose microarchitectures;instruction sets	This paper presents the operation of the register file in the Multiscalar architecture. The register file provides the appearance of a logically centralized register file, yet is implemented as physically decentralized register files, queues, and control logic in a Multiscalar processor. We address the key issues of storage, communication, and synchronization required for successful design and discuss the complications that arise in the face of speculation. In particular, the hardware required to implement the register file is detailed, and software support to streamline the operation of the register file is described. Illustrative examples detailing important aspects of the operation of the register file and an evaluation of its effectiveness are provided.	adobe streamline;benchmark (computing);centralized computing;computer architecture;computer graphics;ibm notes;register file;speculative execution	Scott E. Breach;T. N. Vijaykumar;Gurindar S. Sohi	1994		10.1145/192724.192750	self-certifying file system;synchronization;computer architecture;parallel computing;logic synthesis;real-time computing;register window;computer file;control register;computer science;operating system;programmable logic device;register renaming;stack register;instruction set;instruction register;index register;open;processor register;flags register;programming language;register file;status register;memory data register;memory address register	Arch	-10.55825406801933	49.015607011085706	32212
5e5d77ade733e1ea0e2f4ae5f55b6e715875b809	software fault-tolerance with off-the-shelf sql servers	tolerancia falta;developpement logiciel;extraction information;mascara;seguridad funcionamiento;tratamiento transaccion;base donnee repartie;base donnee;surete fonctionnement;distributed database;tolerance aux pannes logiciel;fault tolerant;information extraction;cout developpement;redundancia;sql;development cost;interrogation base donnee;database;base repartida dato;interrogacion base datos;base dato;simultaneidad informatica;software fault tolerance;envolvero;base dato multiple;concurrency;redundancy;desarrollo logicial;enveloppeur;fault tolerance;dependability;software development;multiple database;replique;masque;transaction processing;simultaneite informatique;off the shelf;mask;multibase;database query;extraccion informacion;replica;tolerance faute;traitement transaction;redondance;wrapper	With off-the-shelf software, software fault tolerance is almost the only means available for assuring better dependability than the off-the-shelf software offers, without the much higher costs of bespoke development or extra V&V. We report our experience with an experimental setup we have developed with off-theshelf SQL database servers. First, we describe the use of a protective wrapper to mask the effects of a bug in one of the servers, without depending on an adequate fix from the vendors. We then discuss how to combine the diverse off-the-shelf servers into a diverse modular redundant configuration (N-version software or Nself-checking software). A wrapper guarantees the consistency between the diverse replicas of the database, serving multiple clients, by restricting the concurrency between the client transactions We thus show that diverse modular redundancy with protective wrapping is a viable way of achieving fault-tolerance with even complex off-the-shelf components, like database servers.	bespoke;component-based software engineering;concurrency (computer science);database server;dependability;microsoft sql server;prototype;sql;scalability;server (computing);software bug;software fault tolerance;software reliability testing;test case;trustworthy computing;wrapper library;wrapping (graphics)	Peter T. Popov;Lorenzo Strigini;A. Kostov;V. Mollov;D. Selensky	2004		10.1007/978-3-540-24645-9_23	fault tolerance;real-time computing;computer science;operating system;database;distributed computing;programming language;distributed database;computer security;information extraction;server	OS	-26.91030931459178	42.794028010035724	32216
048f8ac95294ec7464b2d46a6da1569d6ad74be3	hierarchical parallel processing of large scale data clustering on a pc cluster with gpu co-processing	tratamiento paralelo;tratamiento datos;general purpose computation on gpu gpgpu;distributed system;data transmission;methode diviser pour regner;data parallel;κ means data clustering;systeme reparti;paper;programmable graphics processing unit gpu;traitement parallele;base donnee tres grande;calculator cluster;k means;distributed computing;metodo dividir para vencer;data processing;traitement donnee;supercomputer;data mining;paralelismo masivo;supercomputador;data clustering;unite traitement graphique programmable;large scale;grappe calculateur;sistema repartido;fouille donnee;transmission donnee;divide and conquer method;pc cluster;message passing;graphic processing unit;calculo repartido;the divide and conquer approach;nearest neighbor search;computer science;very large databases;coarse grained;computational efficiency;parallelisme massif;busca dato;calcul reparti;divide and conquer;massive parallelism;k means data clustering;parallel processing;transmision datos;data transfer;superordinateur	This paper presents an effective scheme for clustering a huge data set using a PC cluster system, in which each PC is equipped with a commodity programmable graphics processing unit (GPU). The proposed scheme is devised to achieve three-level hierarchical parallel processing of massive data clustering. The divide-and-conquer approach to parallel data clustering is employed to perform the coarse-grain parallel processing by multiple PCs with a message passing mechanism. By taking advantage of the GPU’s parallel processing capability, moreover, the proposed scheme can exploit two types of the fine-grain data parallelism at the different levels in the nearest neighbor search, which is the most computationally-intensive part of the data-clustering process. The performance of our scheme is discussed in comparison with that of the implementation entirely running on CPU. Experimental results clearly show that the proposed hierarchial parallel processing can remarkably accelerate the data clustering task. Especially, GPU co-processing is quite effective to improve the computational efficiency of parallel data clustering on a PC cluster. Although data-transfer from GPU to CPU is generally costly, acceleration by GPU co-processing is significant to save the total execution time of data-clustering.	central processing unit;cluster analysis;computer cluster;computer graphics;data parallelism;graphics processing unit;message passing;nearest neighbor search;parallel computing;run time (program lifecycle phase)	Hiroyuki Takizawa;Hiroaki Kobayashi	2006	The Journal of Supercomputing	10.1007/s11227-006-8294-1	parallel processing;supercomputer;parallel computing;data processing;computer science;theoretical computer science;operating system;distributed computing;data transmission	HPC	-16.1715365229972	42.669795083475876	32221
9739a513589f4bdc35718dc5c307a3c1e1bcedcb	log-based directory resolution in the coda file system	log size;high availability;file servers;electronic mail;constraint optimization;2 mb;optimistic replication;availability;2 mb coda file system optimistic replication semantic knowledge concurrent updates multiple partitions partitioned updates unix file systems file traces log size;coda file system;file organization computer science;computer programs;side effect;file system;concurrent updates;semantic knowledge;unix file organisation;merging;bandwidth;distributed file system;multiple partitions;computer science;file traces;usability;partitioned updates;unix;unix file system;unix file systems;file systems;file systems availability computer science constraint optimization radio access networks usability merging electronic mail bandwidth file servers;radio access networks;file organisation	Optimistic replication is an important technique for achieving high availability in distributed file systems. A key problem in optimistic replication is using semantic knowledge of objects to resolve concurrent updates from multiple partitions. In this paper, we describe how the Coda File System resolves partitioned updates to directories. The central result of our work is that logging of updates is a simple yet efficient and powerful technique for directory resolution in Unix file systems. Measurements from our implementation show that the time for resolution is typically within 10% of the time for performing the original set of partitioned updates. Analysis based on file traces from our environment indicate that a log size of 2 MB per hour of partition should be ample for typical servers. This work was sponsored by the Avionics Laboratory, Wright Research and Development Center, Aeronautical Systems Division (AFSC), U.S. Air Force, Wright-Patterson AFB, Ohio 45433-6543 under Contract F33615-90-C-1465, ARPA Order No. 7597, the National Science Foundation PYI Award No. CCR 8657907 and NSF Grant No. ECD 8907068, an IBM Corporation Research Initiation Grant, a Digital Equipment Corporation External Research Project Grant, a Bellcore Information Networking Research Grant and the General Electric Company. The views and conclusions contained in this document are those of the authors and should not be interpreted as representing the official policies, either expressed or implied, of DARPA, the NSF, the IBM Corporation, the Digital Equipment Corporation, Bellcore, General Electric Company, or the U.S. government.	avionics;coda;directory (computing);energy citations database;high availability;ibm notes;megabyte;optimistic replication;tracing (software);unix	Puneet Kumar;Mahadev Satyanarayanan	1993		10.1109/PDIS.1993.253092	self-certifying file system;parallel computing;computer science;versioning file system;operating system;fstab;unix file types;journaling file system;database;working directory	OS	-26.395481354594324	51.428018689520584	32230
799c70f0c5b406c47e483a4bb8da729784ecb1d2	on the performance and convergence of distributed stream processing via approximate fault tolerance		Fault tolerance is critical for distributed stream processing systems, yet achieving error-free fault tolerance often incurs substantial performance overhead. We present AF-Stream, a distributed stream processing system that addresses the trade-off between performance and accuracy in fault tolerance. AF-Stream builds on a notion called approximate fault tolerance, whose idea is to mitigate backup overhead by adaptively issuing backups, while ensuring that the errors upon failures are bounded with theoretical guarantees. Our AFStream design provides an extensible programming model for incorporating general streaming algorithms as well as exports only few threshold parameters for configuring approximation fault tolerance. Furthermore, we formally prove that AF-Stream preserves high algorithm-specific accuracy of streaming algorithms, and in particular the convergence guarantees of online learning. Experiments show that AF-Stream maintains high performance (compared to no fault tolerance) and high accuracy after multiple failures (compared to no failures) under various streaming algorithms.	anisotropic filtering;approximation algorithm;backup;extensible programming;fault tolerance;online machine learning;overhead (computing);performance;programming model;stream processing;streaming algorithm	Zhinan Cheng;Qun Huang;Patrick P. C. Lee	2018	CoRR			DB	-23.41792141107009	53.72014015941682	32250
ab218e682fa65e6572a7588665ca1600a425415e	efficient code deployment for heterogeneous distributed data sources	distributed data;distributed system;unfolding;base donnee repartie;systeme reparti;distributed database;deploiement;maintenance;despliegue;base repartida dato;query optimization;data type;intergiciel;heterogeneous information;software architecture;sistema repartido;design and implementation;heterogeneidad;mantenimiento;middleware;information system;data flow;systeme information;architecture logiciel;heterogeneity;heterogeneite;dynamic loading;sistema informacion	Middleware systems have received significant attention for supporting distributed heterogeneous information systems. A few research groups study both the deployment of application specific functionality into middleware systems and query optimization based on reduction of data movement. Such extensions relieve system administrators and developers from tedious tasks on manual installation, consistency and maintenance of user specific codes. In this paper, we present the design and implementation details of a middleware system, which aims to enhance query optimization based on data movement by involving the data flow from the system to the client side. It is also aimed to provide an efficient code-shipping model for automatic code deployment by using a simple data type model. In order to support portability and efficient dynamic loading capability, the project was implemented using Java and XML.	software deployment	Deniz Demir;Haluk Topcuoglu;Ergun Kavukcu	2002		10.1007/3-540-36077-8_42	data flow diagram;software architecture;middleware;query optimization;real-time computing;data type;computer science;heterogeneity;operating system;middleware;database;distributed computing;distributed database;computer security;information system	HPC	-28.91211514811535	42.681052756303636	32257
5753dbf1efb81900440c253022dd4d8e720bb5d1	distributed programming in argus	lenguaje programacion;distributed system;evaluation performance;fiabilidad;reliability;systeme reparti;performance evaluation;argus;programming language;implementation;evaluacion prestacion;sistema informatico;distributed programs;concurrent program;computer system;ejecucion;sistema repartido;fiabilite;programa competidor;gestion transmission;communications managing;langage programmation;systeme informatique;gestion transmision;programme concurrent	Argus—a programming language and system developed to support the implementation and execution of distributed programs—provides mechanisms that help programmers cope with the special problems that arise in distributed programs, such as network partitions and crashes of remote nodes.	apl;crash (computing);distributed computing;programmer;programming language	Barbara Liskov	1988	Commun. ACM	10.1145/42392.42399	embedded system;real-time computing;simulation;computer science;reliability;distributed object;distributed design patterns;programming language;implementation	PL	-19.278342126438947	42.073607421371996	32310
fd8ce704645a44038d4a0a83aeb8076c23c43abe	exploring complex networks with failure-prone agents		Distributed data-collection and synchronization is essential in sensor networks and the Internet of Things (IoT), as well as for datareplication in server farms, clusters and clouds. Generally, such systems consist of a set of interconnected components, which cooperate and coordinate to achieve a collective task, while acting locally and being failureprone. An important challenge is hence to define efficient and robust algorithms for data collection and synchronisation in large-scale, distributed and failure-prone platforms. This paper studies the performance and robustness of different multi-agent algorithms in complex networks with different topologies (Lattice, Small-world, Community and Scalefree) and different agent failure rates. Agents proceed from random locations and explore the network to collect local data hosted in each node. Their exploration algorithm determines how fast they cover unexplored nodes to collect new data, and how often they meet other agents to exchange complementary data and speed-up the process. Two exploration algorithms are studied: one random and one using a stigmergy model (that we propose). Experimental results show how network topologies and agent failure-rates impact data-collection and synchronization, and how a stigmergy-based approach can improve performance and success rates across most scenarios. We believe these results offer key insights into the suitability of various decentralised algorithms in different networked environments, which are increasingly at the core of modern information and communication technology (ICT) systems.	algorithm;complex network;internet of things;multi-agent system;network topology;server (computing);server farm;stigmergy	Arles Rodríguez;Jonatan Gómez;Ada Diaconescu	2016		10.1007/978-3-319-62428-0_7	machine learning;data collection;robustness (computer science);wireless sensor network;complex network;artificial intelligence;server farm;synchronization;network topology;stigmergy;computer science;distributed computing	ML	-25.748883346474926	53.23975241423997	32316
21c07dac9ed45028ce98c0634ae2fa58a59a87a5	advise: performance evaluation of parallel vhdl simulation	digital simulation hardware description languages performance evaluation parallel algorithms;parallel algorithm;performance evaluation;programming language;hardware description languages;partitioning;vhdl simulation;optimistic simulation;multiprocessor architecture;parallel and distributed algorithms;vhdl compilation;signal processing circuit simulation partitioning algorithms hardware design languages distributed algorithms parallel algorithms digital systems throughput memory architecture engines;simulation environment parallel vhdl simulation advise performance evaluation optimistic distributed algorithms vhdl simulation;multiprocessor simulation;hardware description language;distributed simulation;distributed algorithm;simulation environment;digital simulation;parallel algorithms	VHDL is one of the most important and widely used hardware description languages at this time. Applications written in VHDL are increasing in size and complexity, which prompts the use of parallel algorithms to obtain acceptable simulation performance. We have investigated the use of optimistic distributed algorithms with VHDL simulation. Optimistic simulation algorithms have been shown to deliver the highest performance of the currently available simulation strategies. It is however a difficult algorithm to implement, especially for VHDL which has all the characteristics of a high level programming language. With our simulation environment, ADVISE, we obtain speedups of around four for a medium-sized benchmark. The amount of speedup depends on the type of multiprocessor architecture used, partitioning algorithm, and optimizations. Further optimization of the simulation and partitioning algorithms within ADVISE, the use of more advanced compilation strategies, and larger benchmarks should lead to higher speedups, which makes it worthwhile to investigate this approach further.	performance evaluation;simulation;vhdl	Wilco Van Hoogstraeten;Henk Corporaal	1997		10.1109/SIMSYM.1997.586510	distributed algorithm;computer architecture;parallel computing;computer science;theoretical computer science;parallel algorithm;hardware description language;programming language	HPC	-7.909265370688233	41.702632115388695	32343
76fac6a13a7b0642682996cc2d6fee60f0902af1	comparative study on edge detection algorithms using openacc and openmpi on multicore systems		In this paper, we present a comparative study on parallel edge detection algorithms upon high-resolution satellite images, implemented on OpenACC, Hybrid OpenMP/MPI, OpenMP, and MPI models on which the Sobel, Prewitt and Canny algorithms were developed using C++ language and OpenCV. The performance of these computing models were measured in terms of speedup and execution time by implementing the edge detection algorithms using various sized images and programming constructs. The program implementations using OpenACC display the largest speedup in CPU time, which is followed by the Hybrid OpenMP/MPI model. The parallel detection algorithms using OpenACC obtain the greatest speedup of around 6.5 over OpenMP model. The parallel Sobel and Prewitt algorithms are relatively 2 times faster than the Canny in all respects.	algorithm;c++;canny edge detector;central processing unit;edge detection;image resolution;multi-core processor;open mpi;openacc;opencv;openmp;prewitt operator;run time (program lifecycle phase);sobel operator;speedup	Aakashdeep Goyal;Zuqing Li;Haklin Kimm	2017	2017 IEEE 11th International Symposium on Embedded Multicore/Many-core Systems-on-Chip (MCSoC)	10.1109/MCSoC.2017.16	speedup;cpu time;algorithm;multi-core processor;edge detection;computer science;sobel operator;prewitt operator	Arch	-5.808045117915174	42.029996176009384	32354
502827fa563a156520d32d31f4dee0b310f774c9	programming abstractions and toolchain for dataflow multithreading architectures	kernel;multi threading;yarn;frequency modulation;multicore systems;dataflow multithreading architectures;data mining;compiler directives dataflow preprocessing;computer architecture;program compilers data flow computing multiprocessing systems multi threading;dataflow;multithreading program processors programming profession yarn parallel programming computer architecture distributed computing computer science data engineering parallel processing;multithreaded architecture;compiler directives;data flow computing;programming abstractions;dta architectures;multiprocessing systems;preprocessing;program compilers;program processors;parallel processing;dta architectures programming abstractions dataflow multithreading architectures multicore systems parallel processing tflux architectures;tflux architectures;multithreading	The need to exploit multi-core systems for parallel processing has revived the concept of dataflow. In particular, the Dataflow Multithreading architectures have proven to be good candidates for these systems. In this work we propose an abstraction layer that enables compiling and running a program written for an abstract Dataflow Multithreading architecture on different implementations. More specifically, we present a set of compiler directives that provide the programmer with the means to express most types of dependencies between code segments. In addition, we present the corresponding toolchain that transforms this code into a form that can be compiled for different implementations of the model. As a case study for this work, we present the usage of the toolchain for the TFlux and DTA architectures.	abstraction layer;code segment;compiler;dataflow architecture;digital television adapter;directive (programming);multi-core processor;multithreading (computer architecture);parallel computing;programmer;simultaneous multithreading;thread (computing);toolchain	Kyriakos Stavrou;Demos Pavlou;Marios Nikolaides;Panayiotis Petrides;Paraskevas Evripidou;Pedro Trancoso;Zdravko Popovic;Roberto Giorgi	2009	2009 Eighth International Symposium on Parallel and Distributed Computing	10.1109/ISPDC.2009.35	dataflow architecture;parallel processing;computer architecture;parallel computing;multithreading;computer science;operating system;temporal multithreading;programming language	Arch	-14.763543305125895	37.32959632844021	32364
1babda81ab47c52266328a918bd210583d3557fa	safe-for-space threads in standard ml	continuations;standard ml;coroutines;threads;space safety	Threads can easily be implemented using first-class continuations, but the straightforward approaches for doing so lead to space leaks, especially in a language with exceptions like Standard ML. We show how these space leaks arise and give a new implementation for threads that is safe for space.	byte;continuation;experiment;functional programming;hypertext transfer protocol;memory leak;server (computing);standard ml;world-system	Edoardo Biagioni;Kenneth Cline;Peter Lee;Chris Okasaki;Christopher A. Stone	1998	Higher-Order and Symbolic Computation	10.1023/A:1010016600604	thread;real-time computing;computer science;continuation;coroutine;programming language;algorithm	PL	-22.111062916767345	32.379677048770574	32370
6abc160cb265b54c98a488381d8b3a1c6562766e	a class of loop self-scheduling for heterogeneous clusters	distributed system;cluster computing;concurrent computing;heterogeneous systems;application software;heterogeneous cluster;multiprocessor systems;heterogeneous computing;processor scheduling;distributed computing concurrent computing processor scheduling computer science system testing load management application software computer applications parallel processing dynamic scheduling;distributed computing;computer applications;distributed scheduling;loop scheduling;distributed computing system;heterogeneous distributed system;load management;load balancing;parallel computer;concurrent programs;system testing;load balance;computer science;parallel processing;dynamic scheduling	Distributed Computing Systems are a viable and less expensive alternative to parallel computers. However, a serious difficulty in concurrent programming of a distributed system is how to deal with scheduling and load balancing of such a system which may consist of heterogeneous computers. Distributed scheduling schemes suitable for parallel loops with independent iterations on heterogeneous computer clusters have been designed in the past. In this work we consider a class of Self-Scheduling schemes for parallel loops with independent iterations which have been applied to multiprocessor systems. We extend this type of schemes to heterogeneous distributed systems. We present tests that the distributed versions of these schemes maintain load balanced execution on heterogeneous systems.	computer cluster;concurrent computing;dartmouth time-sharing system;distributed computing;iteration;load balancing (computing);multiprocessing;parallel computing;scheduling (computing);workstation	Anthony T. Chronopoulos;Manuel Benche;Daniel Grosu;Razvan Andonie	2001	Proceedings 42nd IEEE Symposium on Foundations of Computer Science	10.1109/CLUSTR.2001.959989	parallel processing;parallel computing;real-time computing;concurrent computing;computer science;load balancing;operating system;distributed computing	HPC	-13.104670495881708	43.620059930669655	32405
23e9e23bd898b42dd04bdcc66f36209e2b719920	control dependencies in interpretive systems		Interpreters and just-in-time (JIT) compilers are ubiquitous in modern computer systems, making it important to have good program analyses for reasoning about such systems. Control dependence, which plays a fundamental role in a number of program analyses, is an important contender in this regard. Existing algorithms for (dynamic) control dependence analysis do not take into account some important runtime characteristics of interpretive computations, and as a result produce results that may be imprecise and/or unsound. This paper describes a new notion of control dependence and analysis algorithm for interpretive systems. This significantly improves dynamic control dependence information, with corresponding improvements in client analyses such as dynamic program slicing and reverse engineering. To the best of our knowledge, this is the first proposal to reason about low-level dynamic control dependencies in interpretive systems in the presence of dynamic code generation and optimization.	algorithm;code generation (compiler);compiler;computation;dependence analysis;high- and low-level;interpreter (computing);just-in-time compilation;mathematical optimization;program analysis;program slicing;reverse engineering;self-modifying code	Babak Yadegari;Saumya Debray	2017		10.1007/978-3-319-67531-2_19	program slicing;theoretical computer science;compiler;dependence analysis;reverse engineering;computation;computer science;code generation;interpreter	PL	-18.743433002052974	34.09194456029413	32456
0e8a3fd321526fff587e8ca910c57f050a95aa9c	optimizing the parallel execution time of homogeneous random workloads			optimizing compiler	Emile Haddad	1991			distributed computing;parallel computing;computer science;homogeneous	HPC	-9.042918470533708	44.02993460203324	32458
a56f8aa276cc2067761e9790370669ade5ef86c2	accelerating climate and weather simulations through hybrid computing	libraries;computers;microprocessors;parallel processing climate mitigation message passing multiprocessing systems natural sciences computing;climate;climate models;weather;ib sockets direct protocol hybrid computing climate acceleration weather simulations multicore processors many core processors parallel computers message passing interface dynamic application virtualization software intel blades ibm qs22 cell be blades infiniband 1 gigabit ethernet solar radiation model component compute intensive calculations ip protocol;parallel programming;acceleration;hybrid computing;computer architecture;protocol computers;sockets direct protocol;multiprocessing computers;message passing interface;gigabit ethernet;acceleration computational modeling blades concurrent computing protocols computer interfaces message passing joining processes application virtualization software prototyping;hybrid system;parallel computer;message passing;solar radiation;blades;climate mitigation;parallel computers;load balance;multiprocessing systems;hybrid computing acceleration climate weather;natural sciences computing;meteorology;program processors;parallel processing	Unconventional multiand many-core processors (e.g. IBM Cell B.E.TM and NVIDIA GPU) have emerged as effective accelerators in trial climate and weather simulations. Yet these climate and weather models typically run on parallel computers with conventional processors (e.g. Intel , AMD , and IBM) using Message Passing Interface. To address challenges involved in efficiently and easily connecting accelerators to parallel computers, we investigated using IBM’s Dynamic Application VirtualizationTM (IBM DAV) software in a prototype hybrid computing system with representative climate and weather model components. The hybrid system comprises two Intel blades and two IBM QS22 Cell B.E. blades, connected with both InfiniBand (IB) and 1-Gigabit Ethernet. The system significantly accelerates a solar radiation model component by offloading compute-intensive calculations to the Cell blades. Systematic tests show that IBM DAV can seamlessly offload compute-intensive calculations from Intel blades to Cell B.E. blades in a scalable, load-balanced manner. However, noticeable communication overhead was observed, mainly due to IP over the IB protocol. Full utilization of IB Sockets Direct Protocol and the lower latency production version of IBM DAV will reduce this overhead. Copyright 2011 John Wiley & Sons, Ltd.	cell (microprocessor);central processing unit;computer simulation;concurrency control;graphics processing unit;hybrid system;ibm bladecenter;infiniband;john d. wiley;load balancing (computing);manycore processor;message passing interface;numerical weather prediction;overhead (computing);parallel computing;programming model;prototype;scalability;sockets direct protocol;usability;webdav	Shujia Zhou;Carlos A. Cruz;Daniel C. Duffy;Robert Tucker;Mark Purcell	2010		10.1109/CCGRID.2010.75	climate;embedded system;parallel processing;parallel computing;real-time computing;computer science;operating system;database;distributed computing	HPC	-7.65786829123716	41.36019334298205	32467
92fe1cbfb65f6318622508eeec4b76e4485005ec	proactive data placement for surveillance video processing in heterogeneous cluster	video surveillance;media;computational modeling;streaming media;sparks;distributed databases	Large-scale surveillance video analytic is a kind of typical big data application. The Spark framework combined with Hadoop Distributed File System (HDFS) is a promising solution for the efficient surveillance video processing. However, the current HDFS distributes data to multiple nodes according to the disk space availability, and this data placement mode will lead to the serious skew of the video task completion time and the performance degradation of the distributed video processing in the heterogeneous Spark cluster. In this paper, we firstly design a distributed surveillance video processing platform architecture which supports the seamless integration with the standard video surveillance system. Our platform uses the Spark computing framework over the data stored in HDFS. Then, we propose a novel proactive video data placement strategy to schedule the input video data into the appropriate cluster node adaptively. Our strategy adopts a novel Computing Time Prediction Model (CTPM) which can accurately estimate the execution time of the video processing task by incorporating the several important video task features. In our strategy, an Initial Data Placement Algorithm (IDPA) is used to place the data needed by the video processing jobs on the appropriate cluster node in the process of the initial data loading, and then a Data Rebalance Algorithm (DRA) is further used to schedule the data for the workload balancing during the process of the job execution. Finally, we build a distributed surveillance video processing system according to the proposed platform architecture and conduct the extensive experiments. The experimental results verify the accuracy of CTPM and show that our system can reduce the overhead of the data transferring and improve the job execution efficiency compared with the current widely used methods.	algorithm;apache hadoop;apache spark;big data;closed-circuit television;dce distributed file system;disk space;dynamic resolution adaptation;elegant degradation;entity;experiment;overhead (computing);proactive parallel suite;run time (program lifecycle phase);seamless3d;self-balancing binary search tree;video processing	Haitao Zhang;Bin Xu;Jin Yan;Lujie Liu;Huadong Ma	2016	2016 IEEE International Conference on Cloud Computing Technology and Science (CloudCom)	10.1109/CloudCom.2016.0044	embedded system;real-time computing;media;computer science;operating system;video tracking;computational model;distributed database	DB	-17.22295219814657	57.53040061608477	32470
89e020603b909ebdab4508ec3d8f87551cc2ca76	self-tuning, bandwidth-aware monitoring for dynamic data streams	dynamic data streams;monitoring bandwidth costs aggregates resilience prototypes arithmetic filtering channel allocation performance evaluation;temporal imprecision;query precision;pediatrics;query processing;network monitoring;bandwidth allocation;data stream;distributed stream processing systems;data mining;data streams;dhts;accuracy;monitoring system;dynamic data;temporal imprecision data streams self tuning monitoring bandwidth aware query precision dhts arithmetic filtering temporal batching arithmetic imprecision;monitoring;arithmetic filtering;aggregates;bandwidth aware monitoring;self tuning monitoring;temporal batching;arithmetic filtering bandwidth aware monitoring dynamic data streams distributed stream processing systems temporal batching;bandwidth;artificial intelligence;optimal algorithm;bandwidth aware;arithmetic imprecision;query processing bandwidth allocation	We present SMART, a self-tuning, bandwidth-aware monitoring system that maximizes result precision of continuous aggregate queries over dynamic data streams. While prior approaches minimize bandwidth cost under fixed precision constraints, they may still overload a monitoring system during traffic bursts. To facilitate practical deployment of monitoring systems, SMART therefore bounds the worst-case bandwidth cost for overload resilience. The primary challenge for SMART is how to dynamically select updates at each node to maximize query precision while keeping per-node monitoring bandwidth below a specified budget. To address this challenge, SMART’s hierarchical algorithm (1) allocates bandwidth budgets in an ear-optimal manner to maximize global precision and (2) selftunes bandwidth settings to improve precision under dynamic workloads. Our prototype implementation of SMART provides key solutions to (a) prioritize pending updates for multi-attribute queries, (b) build bounded fan-in, load-aware aggregation trees to improve accuracy, and (c) combine temporal batching with arithmetic filtering to reduce load and to quantify result staleness. Our evaluation using simulations and a network monitoring application shows that SMART incurs low overheads, improves accuracy by up to an order of magnitude compared to uniform bandwidth allocation, and performs close to the optimal algorithm under modest bandwidth budgets.	aggregate data;algorithm;best, worst and average case;data security;dynamic data;emoticon;fan-in;fixed-point arithmetic;internet access;prototype;smart;scalability;self-tuning;simulation;software deployment	Navendu Jain;Praveen Yalagandula;Michael Dahlin;Yin Zhang	2009	2009 IEEE 25th International Conference on Data Engineering	10.1109/ICDE.2009.134	real-time computing;dynamic data;computer science;data mining;database;distributed computing;accuracy and precision;data stream mining;network monitoring;bandwidth;dynamic bandwidth allocation;bandwidth allocation	DB	-20.096327346724348	55.6842647395802	32627
81c143a1e376dd8e8f34dc19c7fd761dbb4ab170	the system for evolutionary computing on the computational grid.	parallel simulated annealing;computational grid;grid middleware;genetics;grid computing;evolutionary computing	ThecomputationalGrid canoffer userstremendouscomputer resources. Many research ers are developing the Grid middleware and the typical resultsare Grid RPCs. However, application modelsare restrictedto use when Grid RPCsare applied. In this paper , we proposedthe ”EVOLVE/G” systemfor developerto construct evolutionary computation (EC) systemon the computationalgrid. The EVOLVE/G hasa treetopology of datacommunication. In theEVOLVE/G, thereareAgentandsomeWorkers. Sincethe datacanbe transferred betweenAgent and Worker, any logical model of EC can be implemented by the EVOLVE/G. Furthermore, it has mechanismof clusteringnodes. Therefore, the effective model can be constructed on the Grid environment. In this paper , the Gridcalculationmodel of ParallelSimulatedAnnealingusing the GeneticCrossover (PSA/GAc) is built using the EVOLVE/G andpresentedthe experimentalresultsin the realGrid environment. Consequently, it is shown that the examinationof thecalculationmodel usingtheEVOLVE/G is effective.	evolutionary computation;grid computing;middleware;polar surface area;simulation	Yusuke Tanimura;Tomoyuki Hiroyasu;Mitsunori Miki;K. Aoi	2002			computational science;computer science;theoretical computer science;distributed computing;grid computing;evolutionary computation	HPC	-30.779742329788736	49.41695840536853	32675
22138aa8e690179eb3e1f942623be7def1fa75f5	distributed simulation of large-scale and detailed models	simulation ordinateur;modelizacion;distributed system;scale model;red sin hilo;evaluation performance;large scale models;wireless networks;systeme reparti;performance evaluation;modele reduit;reseau sans fil;dynamic reconfiguration;scaling law;equilibrio de carga;evaluacion prestacion;wireless network;simulation;equilibrage charge;distributed computing;systeme ouvert;simulator;modelisation;modelo reducido;large scale;sistema repartido;commercial off the shelf;simulador;ley escala;communication overhead;load balancing;simulateur;calculo repartido;cost effectiveness;load balance;detailed models;simulacion computadora;loi echelle;distributed simulation;open systems;sistema abierto;modeling;computer simulation;calcul reparti	In this paper, we present a new approach for the distributed simulation of large scale and detailed models. Our approach, based on the migration of simulated entities, enhances the s imulator speed jointly addressing two main problems of distributed simulation: the reduction of the communication ov erhead and the load-balancing in the distributed execution architecture. The proposed method dynamically rec onfigures the simulation, taking care of the performance of each part of the execution architecture and dealing with the unpredictable fluctuations of the available computation power and the communication load of each execution unit. In this way, low-cost commercial-off-the-shelf hardware can be used to run fast and cost-effective distributed simula tions. A fine-grained model of the 802.11 DCF protocol has been used for the performance evaluation of the propos ed approach. The results demonstrate that it is feasible for the detailed simulation of very large scale models such as wirele ss networks.	care-of address;computation;design rule for camera file system;entity;execution unit;load balancing (computing);performance evaluation;simula;simulation	Gabriele D'Angelo;Michele Bracuto	2009	IJSPM	10.1504/IJSPM.2009.028625	computer simulation;embedded system;real-time computing;simulation;computer science;engineering;load balancing;wireless network	HPC	-18.4763433629307	43.20149240763013	32689
6aa4ab6333fc2c2439fa954ef4105b6bf1e2722b	the os faces a brave new world	jeos;virtual machine;virtualization;application virtualization;internet browser;virtual machines internet operating systems computers;jeos term;jeos operating systems virtualization cloud computing application development framework;cloud based software;servers;internet;operating system;virtual machines;just enough operating system virtualization cloud computing application development framework operating system server host virtual machine internet browser cloud based software jeos term;just enough operating system;application development framework;new world;operating systems computers;server host;cloud computing;operating systems;hardware;operating systems application software application virtualization cloud computing web server virtual machining internet packaging	"""Increasingly popular approaches such as virtualization, cloud computing, and application development frameworks are changing the importance of the traditional operating system. Virtualization lets a single server host slices of multiple operating systems, each of which can run different applications within virtual machines. This makes the installation of any single full-featured OS instance a choice rather than a necessity. Cloud computing features applications that run on servers spread across the Internet. Cloud providers push these applications to users' browsers. Users of cloud based software thus don't need an OS to do more than run the browser. Developers are increasingly using frameworks that enable the faster building of applications that work with multiple OSs, again making the use of a specific operating system less important. The just enough operating system (JeOS, pronounced """"juice"""") movement focuses on packaging an application with only the parts of an OS necessary for it to work. Over time, these developments could affect what constitutes an operating system, what its roles and responsibilities will be, and how it will be installed and used."""	cloud computing;hardware virtualization;internet;just enough operating system;server (computing);virtual machine	David Geer	2009	Computer	10.1109/MC.2009.333	embedded system;real-time computing;computer science;virtual machine;operating system	OS	-29.348639573996856	55.59734428440335	32807
4ff82707353191e2eadcc40af6a9f4b74720b8d4	optimizing multiple distributed stream queries using hierarchical network partitions	costs partitioning algorithms query processing runtime network topology educational institutions computer networks distributed computing algorithm design and analysis virtual prototyping;optimal solution;bottom up;distributed data stream system;query processing;search space;top down;data stream;continuous query;hierarchical networks;hierarchical network partition;query optimization;null;emulab multiple distributed stream query optimization hierarchical network partition distributed data stream system;distributed databases;multiple distributed stream query optimization;formal analysis;query processing distributed databases;emulab	We consider the problem of query optimization in distributed data stream systems where multiple continuous queries may be executing simultaneously. In order to achieve the best performance, query planning (such as join ordering) must be considered in conjunction with deployment planning (e.g., assigning operators to physical nodes with optimal ordering). However, such a combination involves not only a large number of network nodes but also many query operators, resulting in an extremely large search space for optimal solutions. Our paper aims at addressing this problem by utilizing hierarchical network partitions. We propose two algorithms - top-down and bottom-up which utilize hierarchical network partitions to provide scalable query optimization. Formal analysis is presented to establish the bounds on the search-space and to show the sub-optimality of our algorithms. Through simulations and experiments using a prototype deployed on Emulab we demonstrate the effectiveness of our algorithms.	algorithm;bottom-up parsing;experiment;mathematical optimization;network topology;optimization problem;optimizing compiler;prototype;query optimization;query plan;scalability;simulation;software deployment;top-down and bottom-up design;tree network	Sangeetha Seshadri;Vibhore Kumar;Brian F. Cooper;Ling Liu	2007	2007 IEEE International Parallel and Distributed Processing Symposium	10.1109/IPDPS.2007.370281	query optimization;computer science;theoretical computer science;top-down and bottom-up design;database;distributed computing;distributed database	DB	-20.200376826770448	55.501608680459356	32819
3753a499584c91b41f9d40c9c97483b712ab468c	performability analysis of i/o bound application on container-based server virtualization cluster	container based operating systems;server virtualization;virtualization availability servers time factors protocols operating systems throughput;performability;virtualisation cache storage file servers internet operating systems computers;performability analysis web cache service container based operating system virtualization environment file system web cache server container based server virtualization cluster i o bound application;performability server virtualization container based operating systems	Use of server virtualization for providing applications produces overloads that degrade the performance of provided systems. The use of container-based virtualization enabled a narrowing of this overload. On this work, we go a step forward and demonstrate how a broad tuning combination of several performance factors concerning to web cache server - the I/O bound application analysed - to file system and to operating system, led to a higher performance of proposed cluster, when it is executed on a container-based operating system virtualization environment. Availability and performance similarity of web cache service, under non-virtualized and virtualized systems, were evaluated when submitted to proposed web workload. Results reveal that web cache service provided under virtual environment, without unresponsiveness fails due to overload, i. e., with high availability, presents a 6% higher hit ratio and a 21.4% lower response time than those observed on non-virtualized environments.	1:1 pixel mapping;baseline (configuration management);cos;central processing unit;computer data storage;deployment environment;disk space;full virtualization;hardware virtualization;high availability;high- and low-level;hit (internet);hypervisor;i/o bound;input/output;mathematical optimization;oprofile;openvms;operating system;overhead (computing);performance tuning;response time (technology);server (computing);throughput;valgrind;virtual machine;virtual private server;virtual reality;web cache;x86 virtualization	Erico A. C. Guedes;Luis E. T. Silva;Paulo Romero Martins Maciel	2014	2014 IEEE Symposium on Computers and Communications (ISCC)	10.1109/ISCC.2014.6912556	embedded system;full virtualization;virtualization;application virtualization;computer science;virtual machine;operating system;hardware virtualization;storage virtualization;application server;computer network	OS	-23.507530100979405	57.81656570781729	32829
7a7dbb31b8f57068a1c74de55f91a5f18c0acbd1	low-latency java communication devices on rdma-enabled networks	remote direct memory access rdma;message passing in java mpj;java communication middleware;parallel systems;rdma enabled networks	Providing high-performance inter-node communication is a key capability for running High Performance Computing (HPC) applications efficiently on parallel architectures. In fact, current systems deployments are aggregating a significant number of cores interconnected via advanced networking hardware with Remote Direct Memory Access (RDMA) mechanisms, that enable zero-copy and kernel-bypass features. The use of Java for parallel programming is becoming more promising thanks to some useful characteristics of this language, particularly its built-in multithreading support, portability, easy-to-learn properties and high productivity, along with the continuous increase in the performance of the Java Virtual Machine (JVM). However, current parallel Java applications generally suffer from inefficient communication middleware, mainly based on protocols with high communication overhead that do not take full advantage of RDMAenabled networks. This paper presents efficient low-level Java communication devices that overcome these constraints by fully exploiting the underlying RDMA hardware, providing low-latency and high-bandwidth communications for parallel Java applications. The performance evaluation conducted on representative RDMA networks and parallel systems has shown significant point-to-point performance increases compared with previous Java communication middleware, allowing to obtain up to 40% improvement in applicationlevel performance on 4096 cores of a Cray XE6 supercomputer. Copyright c © 0000 John Wiley & Sons, Ltd.	central processing unit;code;concurrency control;cray xe6;data rate units;floating-point unit;hp utility data center;high- and low-level;infiniband;inter-process communication;java virtual machine;john d. wiley;message passing interface;middleware;multi-core processor;multithreading (computer architecture);networking hardware;open mpi;overhead (computing);parallel computing;performance evaluation;point-to-point protocol;remote direct memory access;scalability;software portability;supercomputer;top500;thread (computing);unavailability;year 10,000 problem;zero-copy	Roberto R. Expósito;Guillermo L. Taboada;Sabela Ramos;Juan Touriño;Ramón Doallo	2015	Concurrency and Computation: Practice and Experience	10.1002/cpe.3473	parallel computing;java concurrency;computer science;operating system;strictfp;embedded java;distributed computing;real time java;java	HPC	-10.038308048464923	46.0855196613907	32842
16ce90115e7413f8ee753e036abb8b53c171f345	executing nested parallel loops on shared-memory multiprocessors	shared memory;cache coherence;parallel processing;cost effectiveness	Cache-coherent, bus-based shared-memory multiprocessors are a cost-e ective platform for parallel processing. In scienti c parallel applications, most of the computation involves processing of large multidimensional data structures which results in a high degree of data parallelism. This parallelism can be exploited in the form of nested parallel loops. Most existing shared memory multiprocessors exploit this multi-level parallelism at only one level. In this paper, we explore e cient algorithms and models for executing nested parallel loops and present a simulation based performance comparison of di erent techniques using real application traces. We show that it is possible to exploit the parallelism in nested parallel loops with the use of good scheduling and synchronization algorithms.	algorithm;cache coherence;coherence (physics);computation;data parallelism;data structure;parallel computing;scheduling (computing);shared memory;simulation;tracing (software)	Sadun Anik;Wen-mei W. Hwu	1992			data diffusion machine;parallel computing;distributed computing;supercomputer architecture;cache-only memory architecture;distributed memory;computer science;distributed shared memory;bus sniffing;uniform memory access;shared memory	HPC	-10.770109339449256	43.46449204022618	32895
c2df96d9adf1c3f498e18494567b1e1d764ba2ed	how to use google app engine for free computing	google;economic and other policies;master worker model free computing google app engine cloud service task queue api;search engines;web sites application program interfaces cloud computing;search engines google cloud computing monte carlo methods servers monitoring;servers;internet computing;monitoring;distributed programming;application program interfaces;web sites;monte carlo methods;internet computing distributed programming cloud computing economic and other policies;cloud computing	Can the Google App Engine cloud service be used, free of charge, to execute parameter study problems? That question drove this research, which is founded on the App Engine's newly developed Task Queue API. The authors created a simple and extensible framework implementing the master-worker model to enable usage of the App Engine application servers as computational nodes. This article presents and discusses the results of the feasibility study, as well as compares the solution with EC2, Amazon's free cloud offering.	application programming interface;application server;cloud computing;google app engine	Maciej Malawski;Maciej Kuzniar;Piotr Wójcik;Marian Bubak	2013	IEEE Internet Computing	10.1109/MIC.2011.143	simulation;cloud computing;computer science;operating system;cloud testing;database;distributed computing;utility computing;world wide web;server;monte carlo method	HPC	-30.806185209428822	54.105437527952105	32920
add111b707e22fb66788d1a9f5ddbc239f6a26af	measuring i/o performance in xen paravirtualization virtual machines		This report summarizes the results obtained with measurements of I/O performance in Xen paravirtualized machines. Focus was put on the performance differences between storage virtualized on a file system as opposed to directly based on a native partition. The experiments are structured in a repeatable and controlled way. Some important notions are also discussed about hard disks geometry and measurement units.	backup;experiment;hard disk drive;iscsi;infiniband;input/output;lvm;overhead (computing);roberto busa;storage virtualization	Giovanni Giacobbi;Tullio Vardanega	2011			hypervisor	OS	-16.311564763559407	51.80951278082237	32929
c10c1493a5207c16cb62a3311bb21401baafa3b7	applying hyperthreading technology for evaluating the performance of http server for stored audio/video retrieval.	audio streaming;multi threading;yarn;video streaming;audio video;video retrieval;data mining;servers;time factors;client server;internet;streaming media;performance analysis;audio streaming hyperthreading technology http server evaluation audio video retrieval web servers threading modules http streaming protocol client server interface video streaming;program processors;video streaming audio streaming internet multi threading video retrieval;web server streaming media performance analysis prototypes network servers yarn testing writing protocols stress measurement	This paper discusses the proposed system that analyses the performance of the prototypes of threaded HTTP servers on Hyper-Threading as well as non-HyperThreading platforms. Once the performance benefits for the prototype HTTP servers are recorded, these would be helpful in building various client-server interfaces over the network. This paper aims at writing HTTP Web-Servers for the 4 basic Threading models. These models are analysed for stored audio and video streaming on Hyper-Threading enabled and HyperThreading disabled platform. The differences in performance analysis are recorded and studied. The benefits of Hyper-Threading platform are emphasized. The system consists of the following modules: HTTP server modules for the 4 basic Threading modules: Non-threaded server and simple client. Single thread of the server and multiple simple clients. Single thread per simple client request. Threaded serverr module and multiple simple clients. All the above threading modules are used for the purpose of stored audio and video streaming. The server stays resident on the Hyper-Threading enabled machine, the client machine could have any basic configuration or the client and the server could be on the same machine. The audio and video retrieval is based on HTTP streaming protocol, HTTP itself is capable of the streaming effect. The server response is measured under the audio and video workload stress. Hyper-Threading benefits are analysed for the applications. Forming suitable test cases for analysing the client server interface is an important aspect of the analysis. The test cases would be further analysed to prove and explain the benefit levels of Hyper-Threading Technology.	client (computing);client–server model;hyper-threading;hypertext transfer protocol;profiling (computer programming);prototype;server (computing);streaming media;test case;thread (computing);threaded code;web server	A. Madhura V. Phatak;B. Rakhi Dongaonkar	2009	2009 Second International Conference on Emerging Trends in Engineering & Technology	10.1109/ICETET.2009.39	client;real-time computing;computer science;operating system;world wide web;server farm	Metrics	-33.50718522103123	46.04999503399643	32945
19fc42e6557bf609e7a674c8b43b92d4171f44ff	d-stampede: distributed programming system for ubiquitous computing	dynamic programming;platform heterogeneity;heterogeneous computing;interactive application class;data stream;pervasive computing;storage management;automatic distributed garbage collection;application level dynamism;stream oriented application class;distributed computing;distributed programs;ubiquitous computing distributed computing pervasive computing hardware space technology dynamic programming parallel processing middleware educational institutions drives;dynamic application class;drives;garbage collection;temporal data stream correlation;language heterogeneity;storage management distributed programming;temporal data stream indexing;distributed programming;indexation;hardware parallelism;ubiquitous computing;middleware;programming support;space technology;computational abstractions;application level dynamism ubiquitous computing programming support distributed heterogeneous computing elements interactive application class dynamic application class stream oriented application class computational abstractions d stampede distributed programming system temporal data stream indexing temporal data stream correlation automatic distributed garbage collection high performance hardware parallelism platform heterogeneity language heterogeneity;high performance;parallel processing;hardware;d stampede distributed programming system;distributed heterogeneous computing elements	We focus on an important problem in the space of ubiquitous computing, namely, programming support for the distributed heterogeneous computing elements that make up this environment. We address the interactive, dynamic, and stream-oriented nature of this application class and develop appropriate computational abstractions in the D-Stampede distributed programming system. The key features of DStampede include indexing data streams temporally, correlating different data streams temporally, performing automatic distributed garbage collection of unnecessary stream data, supporting high performance by exploiting hardware parallelism where available, supporting platform and language heterogeneity, and dealing with application level dynamism. We discuss the features of D-Stampede, the programming ease it affords, and its performance.	admissible numbering;cache stampede;computation;computational model;distributed computing;distributed garbage collection;garbage collection (computer science);heterogeneous computing;parallel computing;privacy;runtime library;ubiquitous computing	Sameer Adhikari;Arnab Paul;Umakishore Ramachandran	2002		10.1109/ICDCS.2002.1022258	parallel computing;real-time computing;reactive programming;computer science;operating system;dynamic programming;middleware;database;distributed computing;space technology;garbage collection;programming language;ubiquitous computing;symmetric multiprocessor system	HPC	-14.43487611283639	40.91694102219662	32968
8ac50e3904cf8e8f7209be6feef15cc7f43aba1b	an efficient equi-semi-join algorithm for distributed architectures	estensibilidad;modelizacion;base relacional dato;algoritmo paralelo;approximation asymptotique;base donnee repartie;distributed database;parallel algorithm;algorithm performance;asymptotic optimality;equilibrio de carga;equilibrage charge;base repartida dato;relational database;algorithme parallele;modelisation;resultado algoritmo;algorithme reparti;performance algorithme;load balancing;base donnee relationnelle;algoritmo repartido;load balance;extensibilite;scalability;asymptotic approximation;distributed algorithm;modeling;cost model;distributed architecture;aproximacion asintotica	Semi-joins is the most used technique to optimize the treatment of complex relational queries on distributed architectures. However the overcost related to semi-joins computation can be very high due to data skew and to the high cost of communication in distributed architectures. In this paper we present a parallel equi-semi-join algorithm for shared nothing machines. The performance of this algorithm is analyzed using the BSP cost model and is proved to have asymptotic optimal complexity and perfect load balancing even for highly skewed data. This guarantees unlimited scalability in all situations for this key algorithm.	algorithm;join (sql);semiconductor industry	Mostafa Bamha;Gaétan Hains	2005		10.1007/11428848_97	distributed algorithm;parallel computing;computer science;load balancing;theoretical computer science;database;distributed computing;distributed database	ML	-18.217119733140027	44.68379034791183	33024
0210943ad8df357b035537e5b1dfdd85c25c00b6	visualisation of allocated and unallocated data blocks in digital forensics		The ability to visualise blocks within file systems as allocated or unallocated is part of many existing forensic tools, for example the ‘Disk’ view in EnCase. However, analysis of the file system or partitioning of a disk is only one level of analysis that can occur as part of a digital investigation. Analysis of the structure within individual files can also be useful, however, there are limited examples of visualising file based data structures. This paper provides a discussion of the development of a prototype visualisation tool that could be used for examining application or operating system files that themselves contain allocated and unallocated blocks. An example is provided that visualises the Windows Registry and demonstrates how a visualisation could assist in identifying areas that are unallocated and therefore may contain deleted data of interest. This approach has potential applications in teaching the binary structure of files and also for data recovery in situations where code exists to process the live data from a file format, but data carving strategies for that format have not yet been developed.	data recovery;data structure;encase;microsoft windows;operating system;prototype	Christopher James Hargreaves	2013			computer hardware;computer science;database;data file;world wide web	OS	-26.031611245883685	38.50132458891132	33056
4c3be1d6aaca08541bc833372bbf9374d83d1a9c	real-time support for software transactional memory	libraries;heuristic;deadline violations;multicore systems;processor scheduling;real time;scheduling real time software transactional memory multicore;real time operating system;real time systems job shop scheduling partitioning algorithms multicore processing operating systems transaction databases computer applications embedded computing application software collaborative software;soft real time;real time operating system multicore systems real time software transactional memory concurrent soft real time transaction scheduling heuristic conflict resolution deadline violations;research and development;multicore;software transactional memory;scheduling;real time scheduling;concurrency control;transaction processing concurrency control operating systems computers real time systems scheduling;linux;transaction processing;transactional memory;conflict resolution;real time software transactional memory;concurrent soft real time transaction scheduling;program processors;operating systems computers;real time systems	Transactional memory is currently a hot research topic, having attracted the focus of both academic researchers and development groups at companies. Indeed, the concept of transactional memory has recently attracted much interest for multicore systems as it eases programming and avoids the problems of lock-based methods. However, up to now, the scheduling of real-time transactions within software transactional memories has not been studied. To address this issue, we present in this paper a real-time software transactional memory, namely RT-STM. We focus on the scheduling of concurrent soft real-time transactions. In particular, we explore a new heuristic for conflict resolution that reduces the number of deadline violations when scheduling soft real-time transactions. After having discussed the scalability of various classical STMs under a real-time operating system, we present experimental results that show that RT-STM can improve the performance of transactional memory-based applications on multicore platforms.	heuristic;multi-core processor;real-time clock;real-time computing;real-time operating system;real-time transcription;scalability;scheduling (computing);software transactional memory	Toufik Sarni;Audrey Queudet;Patrick Valduriez	2009	2009 15th IEEE International Conference on Embedded and Real-Time Computing Systems and Applications	10.1109/RTCSA.2009.57	multi-core processor;transactional memory;parallel computing;real-time computing;real-time operating system;heuristic;commitment ordering;transaction processing;computer science;operating system;concurrency control;conflict resolution;software transactional memory;distributed computing;scheduling;linux kernel	Embedded	-11.301460101952474	58.53136891672846	33066
1182dc6fe96a9713e9073076d0f0fcfc954a5617	the limits of instruction level parallelism in spec95 applications	instruction level parallel	"""This paper examines the limits to instruction level parallelism that can be found in programs, in particular the SPEC95 benchmark suite. Apart from using a more recent version of the SPEC benchmark suite, it di ers from earlier studies in removing non-essential true dependencies that occur as a result of the compiler employing a stack for subroutine linkage. This is a subtle limitation to parallelism that is not readily evident as it appears as a true dependency on the stack pointer. Other methods can be used that do not employ a stack to remove this dependency. In this paper we show that its removal exposes far more parallelism than has been seen previously. We refer to this type of parallelism as \parallelism at a distance"""" because it requires impossibly large instruction windows for detection. We conclude with two observations: 1) that a single instruction window characteristic of superscalar machines is inadequate for detecting parallelism at a distance; and 2) in order to take advantage of this parallelism the compiler must be involved, or separate threads must be explicitly programmed."""	benchmark (computing);call stack;compiler;instruction window;instruction-level parallelism;linkage (software);microsoft windows;parallel computing;pointer (computer programming);sensor;stack-based memory allocation;subroutine;superscalar processor	Matt Postiff;David A. Greene;Gary S. Tyson;Trevor N. Mudge	1999	SIGARCH Computer Architecture News	10.1145/309758.309771	computer science;minimal instruction set computer;instruction set;data parallelism;instruction-level parallelism;explicitly parallel instruction computing;implicit parallelism;task parallelism	Arch	-17.711018208730348	35.86786371489095	33069
bc744805873250348420366c2cc94263408db4b8	fluctuations in the defect creation by ion beam irradiation	programacion paralela;simulacion numerica;solid state physics;ion beam;parallel programming;analisis programa;program optimization;decomposition method;performance programme;monte carlo method;simulation numerique;parallel computer;eficacia programa;optimisation programme;program analysis;program performance;analyse programme;fisica solido;physique solide;programmation parallele;numerical simulation;optimizacion programa	Variance behaviour and correlation structures in ion beam induced cascades have been studied by Monte Carlo method. It was found that the number of defects created in an infinite medium has an over-Poisson variance due to fluctuations in the electronic losses. The defect fluctuations are enhanced in the case of a slab geometry due fluctuations of escaping particles and their loss of progeny. The structure of the vacancy depth correlations supports the variance results and indicates clustering effects in an individual cascade. The algorithm is suitable for parallelization by particle decomposition method. Linear speed-up is easily achieved. The usage of MPI library makes the code portable to parallel computers with different architectures (Cray T3E, IBM SP, SGI Origin 2000). However optimization and code modifications are needed to obtain comparable performance results.	ion beam;software bug	R. Chakarova;Imre Pázsit	1998		10.1007/BFb0095319	program analysis;computer simulation;solid-state physics;parallel computing;simulation;decomposition method;computer science;theoretical computer science;program optimization;programming language;algorithm;ion beam;monte carlo method	Robotics	-5.256440901480979	36.49880008627371	33131
f4c9b77cc5d3306791ead13ccfb168cf200abe54	sharing multimedia applications among heterogeneous workstations	multimedia application		workstation	Thomas Gutekunst;Bernhard Plattner	1993			database;distributed computing;multimedia	HPC	-28.534939161116363	47.82195044024281	33167
affbdf55928bcce5897a831eaa64e1c2b3cdc6e1	mostly-strongly-timed programming in lc		Due to its synchronous behaviour, a strongly-timed program can suffer from the temporary suspension of realtime DSP in the presence of a time-consuming task. In this paper, we propose mostly-strongly-timed programming, which extends strongly-timed programming with the explicit switch between synchronous context and asynchronous context. If a thread is in asynchronous context, the underlying scheduler is allowed to preempt it without the explicit advance of logical time. Timeconsuming tasks can be executed asynchronously, without causing the temporary suspension of real-time DSP. We also discuss how the concept is integrated in LC, a new computer music programming language we prototyped, together with the discussion on implementation issues.	digital signal processor;list of audio programming languages;programming language;real-time clock;scheduling (computing)	Hiroki Nishino;Ryohei Nakatsu	2014			asynchronous communication;real-time computing;thread (computing);computer music;digital signal processing;computer science	EDA	-24.148043253403475	34.581933202067574	33176
60db970c3cdd44920535038995d36ecb62ccee44	implicit intermittent fault detection in distributed systems	distributed processing;fault detection principle implicit intermittent fault detection distributed systems unavoidable transient faults permanent faults fault diagnosis precautionary measures;equations fault detection transient analysis mathematical model vectors runtime reliability;software reliability distributed processing fault diagnosis;software reliability;fault diagnosis	This paper presents a novel approach to detect resources in distributed systems with an increased occurrence of intermittent faults that exceed the amount of unavoidable transient faults caused by environmental phenomena. Intermittent faults occur due to stressed resources and often are a precursor of permanent faults. The proposed early fault detection and diagnosis allows the use of precautionary measures before the permanent failure of a component in a distributed system occurs. In this paper, we present four methods that can implicitly detect intermittent faults by taking the distributed applications and their dependencies into account. Thus, explicit tests are not required which would lead to additional costs and resource load. On the other hand, the implicit approach may considerably reduce the number of plausibility tests compared to the conservative solution with one test per resource. We analyzed and evaluated implementations of the proposed fault detection principle. The experimental results give evidence of the feasibility of our approach and show a comparison of the implemented methods in terms of runtime and detection rate.	distributed computing;fault detection and isolation;intermittent fault;plausibility structure	Peter Waszecki;Matthias Kauer;Martin Lukasiewycz;Samarjit Chakraborty	2014	2014 19th Asia and South Pacific Design Automation Conference (ASP-DAC)	10.1109/ASPDAC.2014.6742964	reliability engineering;fault;real-time computing;fault indicator;computer science;stuck-at fault;fault model;distributed computing;software quality;software fault tolerance	EDA	-24.343859547820873	45.062778878727684	33189
baa70ef21dbc4d962734486fed9eede51e4a8cf6	using time warp for computer network simulations on transputers	discrete event simulation;computational modeling;concurrent computing;computer network;computer networks;computer simulation;protocols;computer architecture;simulation model	Using Time Warp for Computer Network Simulations on Transputers Fannie Tallieu, Frank Verboven Brussels Free University W B Pleinlaan 2 B1050 Brussels Belgium email: fdtallie@info.vub.ac.be In thispaper t . 2 implementation 0 i Time Warp simulation frame is examined on a multitransputer machine. As computer networks can be considered as an integratedpart of machine architecture, reliable evaluation tools for the development and study of protocols are a necessity. Simulation constitutes the only possible tool to obtain detailed information in this domain. The complexity of computer networks makes their simulation computational complex and also very slow. That is why it is interesting to consider distributed simulation approaches. A major goal of this work is to determine whether the optimistic Time Warp algorithm is advantageous for the simulation of computer networks. The results presented indicate that the eficiency of the Time Warp technique seems to depend heavily on the characteristics of the simulation model. Introduction. Simulations of large and complex systems are among the most expensive of all computational tasks. To speed up simulations, the use of parallelism appears to be a promising approach. It is possible toexploit their potential concurrency, if the simulation programs are structured in a way that they exhibit this potential concurrency. In parallel simulation, the research is concentrated on mechanisms that decompose simulations into objects and treat events as atomic actions, which can be executed concurrently. The problem with discrete event simulations is that, to be sure to execute events in increasing simulation time order, logical processes must be prepared to block, before processing an event message, until they can be sure they will never receive another event message with a lower simulation time [Mis86]. In the first section of the paper the basic Time Warp mechanism is described. The next section emphasises our implementation of the algorithm in OCCAM [Occ88]. A number of results, obtained by the introduction of a simple computer network model in the Time Warp frame, are presented in the third section, followed by some optimization proposals. Finally a few conclusions and the future work is outlined.	algorithm;complex systems;computer simulation;concurrency (computer science);distributed computing;dynamic time warping;email;linearizability;mathematical optimization;network model;parallel computing;occam	Fannie Tallieu;Frank Verboven	1991		10.1145/306792.306848	computer simulation;communications protocol;real-time computing;simulation;concurrent computing;computer science;theoretical computer science;discrete event simulation;simulation modeling;distributed computing;computational complexity theory;computational model;computer network	Metrics	-13.337178599082604	42.47295549034691	33231
152108f0877b78ff26dc7a822a154773319ea8ad	animating operating systems algorithms with xtango	libraries;multimedia;parallel programming;software engineering;operating system	In operating systems courses, students study the major algorithms used in operating systems to manage the various objects and resources in a computing system: processes, files, buffer space, processors, messages, main memory, semaphores, and disk storage. Various classical synchronization problems such as the dining philosophers, the readers and writers, and the producers and consumers with bounded buffer are also analyzed. Even though the computing systems being studied are getting more and more powerful, these algorithms and classical problems are usually analyzed using blackboard, chalk, pencil, and paper. This paper describes an X-windows based package called xtango that was used to animate some of the algorithms and classical problems studied in operating systems. One animation typical of those that have been developed is presented. Students can use these animations during study outside the classroom for a better understanding of the algorithms. Instructors can use the animations to facilitate the presentation of the algorithms in the classroom.	algorithm;central processing unit;computer data storage;dining philosophers problem;disk storage;microsoft windows;operating system;process (computing);semaphore (programming);x window system	Stephen J. Hartley	1994		10.1145/191029.191164	embedded operating system;simulation;computer science;theoretical computer science;operating system;software engineering;multimedia;programming language	Theory	-25.24785480153961	38.742022992942275	33237
eb0339308c735a4ea189a13f6c2309ce79185a02	parallelization techniques for heterogeneous multicores with applications			automatic parallelization;parallel computing	Wasuwee Sodsong	2017				OS	-9.110179299163626	42.812934619840846	33296
1eeea3ef3cd2ff02c494e767dc1c94e69bbf5328	emulation of cloud-scale environments for scalability testing	software;protocols;performance;virtual machining;swinburne;emulation;testing;program testing cloud computing;servers;engines;program testing;service virtualisation;scalability;servers emulation scalability protocols software virtual machining engines;performance scalability testing emulation cloud computing service virtualisation;cloud computing;endpoint systems cloud scale environments scalability testing cloud computing software applications it management applications emulation approach kaluta unmodified application under test emulation engine cloud hosted application ca identity minder as a service	"""Cloud computing increases the level of connectivity between software applications. IT management applications delivered as a service may need to connect to tens of thousands of endpoint systems. In order to validate the application's reliability and performance at these very large scales, its scalability needs to be tested before being deployed in the cloud. We use an emulation approach, whereby endpoints are modelled and then executed in an emulation environment, which we call """"Kaluta"""". The key aspect is to balance the modelling of the endpoint systems such that it is rich enough to """"fool"""" an unmodified application-under-test into thinking that it is talking to real systems, but light-weight enough such that tens of thousands of instances of model systems can be executed simultaneously in the emulation engine. We present an industry case study - CA Identity Minder™ -as-a-Service - to demonstrate the effectiveness of using emulation to validate the scalability of a cloud hosted application."""	cloud computing;communication endpoint;emulator;scalability testing	Steven Versteeg;Cameron M. Hine;Jean-Guy Schneider;Jun Han	2012	2012 12th International Conference on Quality Software	10.1109/QSIC.2012.57	communications protocol;emulation;real-time computing;scalability;simulation;cloud computing;performance;computer science;operating system;software testing;server;hardware emulation	HPC	-28.64214731905257	55.92368311117116	33311
a36f52a2d28151777c27e9796c201dc47d8a3c69	effectiveness of data dependence analysis	compilacion;gestion memoire;dato;metodologia;analisis datos;ilpp system;storage management;data;analizador;boucle programme;paralelisacion;dependence;dependance;methodologie;bucle programa;dynamical system;systeme dynamique;data analysis;gestion memoria;affine memory disambiguation;donnee;data dependence;parallelisation;defaillance;parallelization;compilation;program loop;analyse donnee;failures;sistema dinamico;analyzer;methodology;translators;fallo;analyseur;parallel processing;dependencia;mathematics computers information science management law miscellaneous	Data dependence testing is the basic step in detecting loop level parallelism in numerical programs. The problem is undecidable in the general case. Therefore, work has been concentrated on a simplified problem, affine memory disambiguation. In this simpler domain, array references and loops bounds are assumed to be linear integer functions of loop variables. Dataflow information is ignored. For this domain, we have shown that in practice the problem can be solved accurately and efficiently.(1) This paper studies empirically the effectiveness of this domain restriction, how many real references are affine and flow insensitive. We use Larus's llpp system(2) to find all the data dependences dynamically. We compare these to the results given by our affine memory disambiguation system. This system is exact for all the cases we see in practice. We show that while the affine approximation is reasonable, memory disambiguation is not a sufficient approximation for data dependence analysis. We propose extensions to improve the analysis.	data dependency;data parallelism;dataflow;dependence analysis;linear approximation;loop-level parallelism;numerical analysis;parallel computing;sensor;undecidable problem;word-sense disambiguation	Dror E. Maydan;John L. Hennessy;Monica S. Lam	1995	International Journal of Parallel Programming	10.1007/BF02577784	parallel processing;parallel computing;spectrum analyzer;computer science;theoretical computer science;operating system;dynamical system;methodology;data analysis;algorithm;data	HPC	-17.74793060598509	34.578211297405915	33343
825ffb97ceeec3d0b06692ef2609f86d15bfaa3d	fast cache access with full-map block directory	logic arrays art pipelines process design;cache storage;logic arrays;tpc c benchmark;art;performance evaluation;tag array;fault tolerant computing cache storage performance evaluation;full map block directory;system performance;fast cache access;data array;process design;fault tolerant computing;spec92 benchmark suite;pipelines;cache performance;spatial locality;system performance fast cache access full map block directory data array tag array cache performance spatial locality tpc c benchmark spec92 benchmark suite	There are two concurrent paths in a typical cache access — one through the data array and the other through the tag array. In most cases, the path through the tag array is signif icantly longer than that through the data array. In this pape r, we propose a new scheme that exploits this imbalance in the tag and data paths to improve overall cache performance. Under this scheme, an additional tag directory, the Full-Ma p Block Directory, is used to provide an alternate tag path to speed up cache access for almost all the memory requests. This scheme is based on the observation that spatial localit y exists on a cache line basis i.e. cache lines near one another tend to be referenced together. Performance evaluation using the TPC-C benchmark and the SPEC92 benchmark suite demonstrates that this scheme has the potential to improve overall system performance by more than 20%.	benchmark (computing);cpu cache;cache (computing);directory (computing);ibm tivoli storage productivity center;performance evaluation;tag cloud;wilhelm pape	Jih-Kwon Peir;Windsor W. Hsu	1997		10.1109/ICCD.1997.628924	array data type;bus sniffing;process design;least frequently used;cache-oblivious algorithm;parallel computing;real-time computing;cache coloring;page cache;tag ram;cache;computer science;write-once;cache invalidation;operating system;pipeline transport;computer performance;smart cache;mesi protocol;cache algorithms;cache pollution	Arch	-8.646513915785107	52.305361484207246	33348
cdbb382890587d38662885b8e80abd873531f0e0	distributed scheduler of workflows with deadlines in a p2p desktop grid	two phase reservation protocol;resource availability information;processor scheduling peer to peer computing scalability availability distributed computing computational modeling concurrent computing resource management time factors computer science;availability;routing;distributed global scheduler;processor scheduling;resource management;distributed computing;p2p;large scale system;two phase reservation protocol distributed task workflow scheduler p2p desktop grid deadlines distributed computing scalable scheduler tree based p2p overlay decentralized architecture resource availability information distributed management distributed global scheduler;p2p desktop grid deadlines;decentralized architecture;distributed task workflow scheduler;distributed scheduling;computational modeling;scheduling;processor scheduling grid computing peer to peer computing;resource availability;peer to peer computing;large scale systems scheduling distributed computing;tree based p2p overlay;grid computing;scalable scheduler;large scale systems;distributed management	Scheduling large amounts of tasks in distributed computing platforms composed of millions of nodes is a challenging goal, even more in a fully decentralized way and with low overhead. Thus, we propose a new scalable scheduler for task workflows with deadlines following a completely decentralized architecture. It's built upon a tree-based P2P overlay that supports efficient and fast aggregation of resource availability information. Constraints for deadlines and the correct timing of tasks in workflows are guaranteed with a suitable distributed management of availability time intervals of resources. A local scheduler in each node provides its available time intervals to the distributed global scheduler, which summarizes them in the aggregation process. A two phase reservation protocol looks for suitable resources that comply with workflow structure and deadline. Experimental results, from simulations of a system composed of one million nodes, show scalable fast scheduling with low overhead that can allow a high dynamic usage of computational resources.	computational resource;distributed computing;global serializability;overhead (computing);peer-to-peer;scalability;scheduling (computing);simulation	Javier Celaya;Unai Arronategui	2010	2010 18th Euromicro Conference on Parallel, Distributed and Network-based Processing	10.1109/PDP.2010.41	availability;routing;parallel computing;real-time computing;computer science;resource management;operating system;peer-to-peer;distributed computing;computational model;scheduling;grid computing	HPC	-19.0360474515143	59.025467048056996	33367
75df22e424d76ca230cc8e95f952784eb789d3df	the intrinsic bandwidth requirements of ordinary programs	eficacia sistema;largeur bande;gestion memoire;entrada salida;hierarchy;programacion entera;memory management;data stream;storage management;bandwidth spectrum;program design;simulacion numerica;performance systeme;cache memory;conception programme;spectrum;system performance;programmation en nombres entiers;antememoria;input output;memory access;gestion memoria;antememoire;particion;integer programming;calcul numerique;numerical computation;simulation numerique;anchura banda;jerarquia;calculo numerico;partition;bandwidth;floating point;coma flotante;point of view;hierarchie;quantitative method;i o traffic;lower bound;concepcion programa;stream;entree sortie;numerical simulation;virgule flottante	While there has been an abundance of recent papers on hardware and software approaches to improving the performance of memory accesses, few papers have addressed the problem from the program's point of view. There is a general notion that certain programs have larger working sets than others. However, there is no quantitative method for evaluating and comparing the memory requirements of programs.This paper introduces the bandwidth spectrum for characterizing the memory requirements of a program's instruction and data stream. The bandwidth spectrum measures the average bandwidth requirement of a program as a function of available local memory. These measurements are performed under the most idealized conditions of perfect knowledge and perfect memory management. As such, they represent the lower bounds on the memory requirements of programs. We present the bandwidth spectrums for a set of 22 benchmarks and show how they can be used in the comparison of memory requirements and I/O requirement. The bandwidth spectrums also offer a convenient method to weigh the trade-off amongst instruction issue rate, local memory capacity and bandwidth into local memory.Using the bandwidth spectrum, we show that at issue rates of four or less, bandwidth usually scales linearly with the issue rate. At higher issue rates, bandwidth can often scale superlinearly with respect to issue rate. Finally, we also investigate the effects of varying the input sets on the bandwidth spectrums.	input/output;memory management;requirement	Andrew S. Huang;John Paul Shen	1996		10.1145/237090.237163	partition;input/output;spectrum;simulation;integer programming;cpu cache;quantitative research;computer science;floating point;theoretical computer science;operating system;program design language;computer performance;upper and lower bounds;stream;bandwidth;algorithm;hierarchy;dynamic bandwidth allocation;memory management	Arch	-15.26333731128864	43.76508014424238	33407
be94c5051438209816397be214ee8c1bdda94165	self-adjusting computation: (an overview)	computer program;continuations;self adjusting computation;design and development;performance;compilers;asymptotic complexity;dynamic data;parallel computer;continuous dependence;change propagation;frame of reference;incremental modification;language design;dependence graphs	Many applications need to respond to incremental modifications to data. Being incremental, such modification often require incremental modifications to the output, making it possible to respond to them asymptotically faster than recomputing from scratch. In many cases, taking advantage of incrementality therefore dramatically improves performance, especially as the input size increases. As a frame of reference, note that in parallel computing speedups are bounded by the number of processors, often a (small) constant.  Designing and developing applications that respond to incremental modifications, however, is challenging: it often involves developing highly specific, complex algorithms. Self-adjusting computation offers a linguistic approach to this problem. In self-adjusting computation, programs respond automatically and efficiently to modifications to their data by tracking the dynamic data dependences of the computation and incrementally updating their output as needed. In this invited talk, I present an overview of self-adjusting computation and briefly discuss the progress in developing the approach and present some recent advances.	algorithm;central processing unit;computation;dynamic data;information;parallel computing	Umut A. Acar	2009		10.1145/1480945.1480946	frame of reference;compiler;dynamic data;performance;computer science;theoretical computer science;continuation;programming language;algorithm	PL	-11.173305090867602	36.947727970694395	33432
480aaa925808ce2c07053084b1f1057168fe3ab7	detecting unsafe error recovery schedules	tolerancia falta;systeme temps reel;modelizacion;asynchronous real time systems unsafe error recovery schedules modeling timing precedence data consistency constraints concurrently executing processes galileo spacecraft;concurrently executing processes;error recovery;fault tolerant;securite;asynchrone;correction erreur;data consistency constraints;sistema informatico;recubrimiento;simultaneidad informatica;overlay;computer system;ingenieria logiciel;indexing terms;recouvrement;software engineering;asynchronous system;modelisation;asynchronous real time systems;fault tolerant computing;concurrency;galileo spacecraft;hard real time system;aerospace computing;scheduling;error correction;fault tolerance;safety;genie logiciel;real time system;systeme informatique;sistema tiempo real;unsafe error recovery schedules;correccion error;space vehicles timing testing scheduling algorithm safety software tools software algorithms interleaved codes computer science hardware;modeling timing;scheduling aerospace computing fault tolerant computing real time systems;seguridad;modeling;simultaneite informatique;tolerance faute;precedence;asincrono;asynchronous;real time systems;timing;time constraint	This paper presents a mechanism for modeling timing, precedence, and data-consistency constraints on concurrently executing processes. The model allows durations and intervals between events to be speciied. An algorithm is provided to detect schedules which may be unsafe with respect to the constraints. This work, motivated by the design and validation of autonomous error-recovery strategies on the Galileo spacecraft, appears to be applicable to a variety of asynchronous real-time systems.	algorithm;autonomous robot;galileo (satellite navigation);real-time clock;real-time computing;schedule (computer science)	Robyn R. Lutz;Johnny S. Wong	1992	IEEE Trans. Software Eng.	10.1109/32.153384	embedded system;fault tolerance;real-time computing;real-time operating system;computer science;operating system;distributed computing	Embedded	-24.631055811416942	34.138635599201784	33472
c173932643c1fcc1cfa5a072f17fda531485a0aa	evaluating the impacts of code-level performance tunings on power efficiency	random access memory;sorting;tuning;scalability;power demand;supercomputers;benchmark testing	As the power consumption of HPC systems will be a primary constraint for exascale computing, a main objective in HPC communities is recently becoming to maximize power efficiency (i.e., performance per watt) rather than performance. Although programmers have spent a considerable effort to improve performance by tuning HPC programs at a code level, tunings for improving power efficiency is now required. In this work, we select two representative HPC programs (Graph500 and SDPARA) and evaluate how traditional code-level performance tunings applied to these programs affect power efficiency. We also investigate the impacts of the tunings on power efficiency at various operating frequencies of CPUs and/or GPUs. The results show that the tunings significantly improve power efficiency, and different types of tunings exhibit different trends in power efficiency by varying CPU frequency. Finally, the scalability and power efficiency of state-of-the-art Graph500 implementations are explored on both a single-node platform and a 960-node supercomputer. With their high scalability, they achieve 27.43 MTEPS/Watt with 129.76 GTEPS on the single-node system and 4.39 MTEPS/Watt with 1,085.24 GTEPS on the supercomputer.	central processing unit;cholesky decomposition;computer performance;graph500;graphics processing unit;performance per watt;programmer;scalability;supercomputer	Satoshi Imamura;Keitarou Oka;Yuichiro Yasui;Yuichi Inadomi;Katsuki Fujisawa;Toshio Endo;Koji Ueno;Keiichiro Fukazawa;Nozomi Hata;Yuta Kakibuka;Koji Inoue;Takatsugu Ono	2016	2016 IEEE International Conference on Big Data (Big Data)	10.1109/BigData.2016.7840624	parallel computing;real-time computing;computer hardware;computer science	HPC	-4.643010344011278	53.945761124777114	33498
967df02fd825f14052f8c7a2d57c4e8d2a6e131c	concept and implementation of an efficient communication network for distributed parallel computing				Peter Kohler	1997		10.3929/ethz-a-001859452	distributed algorithm;parallel computing;theoretical computer science;data-intensive computing;distributed computing;distributed design patterns	HPC	-29.18914444911009	46.80893672137351	33529
114801eccb5eb0831fd1848f351a138253a42f15	pres: probabilistic replay with execution sketching on multiprocessors	replay;partial information;concurrency bug;graduate student	"""Bug reproduction is critically important for diagnosing a production-run failure. Unfortunately, reproducing a concurrency bug on multi-processors (e.g., multi-core) is challenging. Previous techniques either incur large overhead or require new non-trivial hardware extensions.  This paper proposes a novel technique called PRES (probabilistic replay via execution sketching) to help reproduce concurrency bugs on multi-processors. It relaxes the past (perhaps idealistic) objective of """"reproducing the bug on the first replay attempt"""" to significantly lower production-run recording overhead. This is achieved by (1) recording only partial execution information (referred to as """"sketches"""") during the production run, and (2) relying on an intelligent replayer during diagnosis time (when performance is less critical) to systematically explore the unrecorded non-deterministic space and reproduce the bug. With only partial information, our replayer may require more than one coordinated replay run to reproduce a bug. However, after a bug is reproduced once, PRES can reproduce it every time.  We implemented PRES along with five different execution sketching mechanisms. We evaluated them with 11 representative applications, including 4 servers, 3 desktop/client applications, and 4 scientific/graphics applications, with 13 real-world concurrency bugs of different types, including atomicity violations, order violations and deadlocks. PRES (with synchronization or system call sketching) significantly lowered the production-run recording overhead of previous approaches (by up to 4416 times), while still reproducing most tested bugs in fewer than 10 replay attempts. Moreover, PRES scaled well with the number of processors; PRES's feedback generation from unsuccessful replays is critical in bug reproduction."""	atomicity (database systems);central processing unit;concurrency (computer science);dspace;deadlock;desktop computer;graphics;multi-core processor;overhead (computing);software bug;system call	Soyeon Park;Yuanyuan Zhou;Weiwei Xiong;Zuoning Yin;Rini T. Kaushik;Kyu H. Lee;Shan Lu	2009		10.1145/1629575.1629593	real-time computing;computer science;theoretical computer science;operating system;distributed computing	OS	-20.729231068094986	38.70619496070892	33582
3bf53e42cafec688082033dc77cc55c5ae7d4b1f	implement of item-based recommendation on gpu	real time service item based recommendation gpu high speed parallel processor business recommender system online recommend part offline calculation part;graphics processing units recommender systems kernel instruction sets real time systems prediction algorithms algorithm design and analysis;graphics processing units;efficiency recommender system off line calculation gpu;recommender systems;recommender systems graphics processing units	Recommemder System is becoming more and more important for getting information in recent 20 years. But recommender system has the weakness of extreed large scale that makes it delayable for recommendation, which making it cannot offer real-time service. Business recommender system is general divided into two parts, the on-line recommend part and the off-line calculation part. It precomputes the off-line part to get quicker recommendation when needed. Pretended real-time recommendation is a compromise with the growing and changing system. We propose the better way to get better real-time service by processing the off-line calculation on GPU, which is a high-speed parallel processor, to speed up the first part of recommender system to get more real-time service. Our experiments show, the off-line part can speed up 19 times when using GPU, and the larger of the data scale, the better it can improve.	cold start;computer performance;experiment;graphics processing unit;ibm websphere extreme scale;online and offline;parallel computing;real-time clock;real-time locating system;real-time transcription;recommender system;speedup	Zhanchun Gao;Yuying Liang;Yanjun Jiang	2012	2012 IEEE 2nd International Conference on Cloud Computing and Intelligence Systems	10.1109/CCIS.2012.6664242	computer science;theoretical computer science;operating system;multimedia;world wide web;recommender system	Robotics	-13.582200249919106	52.191297124713245	33636
3ebae4472aa2543191ca529aeb33123bd2e09e30	scheduling deadline constrained scientific workflows on dynamically provisioned cloud resources	cloud resources;deadline constrained;scientific workflows;scheduling	Commercial cloud computing resources are rapidly becoming the target platform on which to perform scientific computation, due to the massive leverage possible and elastic pay-as-you-go pricing model. The cloud allows researchers and institutions to only provision compute when required, and to scale seamlessly as needed. The cloud computing paradigm therefore presents a low capital, low barrier to operating dedicated HPC eScience infrastructure. However, there are still significant technical hurdles associated with obtaining sufficient execution performance while limiting the financial cost, in particular, a naive scheduling algorithm may increase the cost of computation to the point that using cloud resources is no longer a viable option.#R##N##R##N#The work in this article concentrates on the problem of scheduling deadline constrained scientific workloads on dynamically provisioned cloud resources, while reducing the cost of computation. Specifically we present two algorithms, Proportional Deadline Constrained (PDC) and Deadline Constrained Critical Path (DCCP) that address the workflow scheduling problem on such dynamically provisioned cloud resources. These algorithms are additionally extended to refine their operation in task prioritization and backfilling respectively. The results in this article indicate that both PDC and DCCP algorithms achieve higher cost efficiencies and success rates when compared to existing algorithms.	scheduling (computing)	Vahid Arabnejad;Kris Bubendorfer;Bryan Ng	2017	Future Generation Comp. Syst.	10.1016/j.future.2017.01.002	critical path method;job shop scheduling;real-time computing;scheduling (computing);cost efficiency;cloud computing;distributed computing;earliest deadline first scheduling;workflow;provisioning;computer science	HPC	-21.385034165471712	58.754307999634214	33658
44ed197987fec7aa6ab12aa9618277c32ff87f05	deriving message passing protocols from collective behavior	collective behavior;deriving message passing protocols;message passing	Many embedded systems applications involve distributed co-operating components. For cost reasons, they must be designed to use computational and communication resources as sparingly as possible. To achieve this, carefully hand-optimized solutions are often used. However, reasoning about such solutions at the implementation level using deductive techniques is like trying to verify the object code produced by an optimizing compiler: much of the structure and abstractions present at the high level of design have been lost. Recovering abstractions can be quite expensive, necessitating the formulation and verification of large strengthening invariants.	message passing	Pertti Kellomäki	2000			real-time computing;computer science;theoretical computer science;distributed computing	Vision	-27.42885174372867	33.31593669635914	33775
0804f5f172c675285fb49b87cb4cb64d53ed9fa8	parallel in sequence - towards the architecture of an elementary cortical processor	elementary cortical processor	F i r s t , a s h o r t e v a l u t i o n o f t h e r e c e n t p r o g r e s s on t h e q u e s t i o n o f how t h e b r a i n w o r k s i s g i v e n and e v i d e n c e s u b m i t t e d f o r t h e n e e d o f l a r g e s c a l e c o m p u t a t i o n a l a p p r o a c h e s t o n e u r a l c o m p u t i n g w h i c h a r e a s t i g h t l y a s p o s s i b l e r e l a t e d to t h e known d e t a i l s o f n e u r a l h a r d w a r e and f u n c t i o n . The c r u c i a l r o l e o f t h e f i r m w a r e l e v e l ( m o d u l a r ) o r g a n i z a t i o n o f n e u r a l m a s s f o r u n d e r s t a n d i n g t h e f l e x i b i l i t y o f n e u r a l c o m p u t i n g i s s t r e s s e d . B a s e d on b o t h t h e a n a t o m y o f a n e o c o r t i c a l c o l u m n and a n a p p r o a c h to t h e i n t e r p r e t a t i o n o f c o m p l e x s c e n e s by t h e v i s u a l c o r t e x , a f u n c t i o n a l a r c h i t e c t u r e o f a c o r t i c a l p r o c e s s o r i s p r o p o s e d w i t h s p e c i a l e m p h a s i s on t h e d y n a m i c s o f s e l f c o n t r o l . i. Hardware Does Matter Recently, with the advent of massively parallel computers the interest in understanding the algorithms behind the brains' function resurged, since these new computing environments need a new software approach. Neurocybernetics has put from the beginning emphasis to parallel architectures. Parallelism is more than gain in speed of computing only ; i t e n a b l e s a q u a l i t a t i v e l y d i f f e r e n t k i n d o f a l g o r i t h m s f o r i n t e l l i g e n t o p p e r a t i o n s . H o w e v e r , t h e r e i s n o t y e t a c o m p r e h e n s i v e b r a i n t h e o r y , b u t in m o s t c a s e s e i t h e r a b s t r a c t c o m p u t a t i o n a l a p p r o a c h e s o r d e s c r i p t i o n s on t h e l e v e l o f c e l l u l a r c o n n e c t i v i t y . C u r r e n t l y e f f o r t s a r e u n d e r way f o r a more i n t e r a c t i v e a p p r o a c h . The b r a i n was n o t p r o g r a m m e d b u t e v o l v e d i n f u n c t i o n . Why t h i s s e n s o r y m o t o r c o n t r o l s y s tem d e v e l o p e d i n t e l l i g e n t b e h a v i o r i s a m a t t e r o f b o t h t h e s o c a l l e d m i c r o s t r u e t u r e o f c o g n i t i o n and t h e c o o r d i n a t i v e c o n t r o l in t h e c o m p l e x s y s t e m ( t h a t m e a n s n o t t h e e m e r g e d a l g o r i t h m s b u t t h e u n d e r l y i n g p r o c e s s e s and i t s c o n t r o l a r e t h e s o u r c e o f i n t e l l i g e n c e ) . W i t h t h e c o n s t r a i n t s o f t i m e and r e s o u r c e s u n d e r t h e s e l e c t i v e p r e s s u r e o f e v o l u t i o n , o n l y c e r t a i n c o m b i n a t i o n s o f t h e t r i p l e < h a r d w a r e , s o f t w a r e , e n v i r o n m e n t > may g i v e e n o u g h p e r f o r m a n c e [ 2 7 ] , t h e y a r e s t r o n g l y i n t e r r e l a t e d , s p e c i f i c . T h e r e f o r e , a m o r e r a p i d p r o g r e s s i n u n d e r s t a n d i n g t h i s s o f t w a r e i s e x p e c t e d o n l y i f l a r g e s c a l e c o m p u t a t i o n a l t h e o r i e s c a n be c o n s t r u c t e d i n c l o s e i n t e r a c t i o n w i t h a l l t h e d e t a i l s o f s t r u c t u r e and f u n c t i o n w h i c h a r e o f f e r e d by e x p e r i m e n t a l n e u r o b i o l o g y a n d 1) B i o h o l o n i c s R e s e a r c h P r o j e c t , R e s e a r c h D e v e l o p m e n t C o r p o r a t i o n o f J a p a n , N i s s h o B l d g . , 5F, 1 4 2 4 K o i s h i k a w a 4 c h o m e , B u n k y o k u , Tokyo 112 , J a p a n 2) F a c u l t y o f P h a r m a c e u t i c a l S c i e n c e s , D e p a r t m e n t o f B i o p h y s i c s , U n i v e r s i t y o f T o k y o , H o n g o , B u n k y o k u , T o k y o I 1 3 , J a p a n 3) P r e s e n t a d d r e s s : The I l m e n a u I n s t i t u t e o f T e c h n o l o g y , Dep . o f E n g n g . and B i o m e d i c a l C y b e r n e t i c s , PF 3 2 7 , GDR-6300 I i m e n a u	algorithm;artificial intelligence;computer;emoticon;neurocybernetics;parallel computing	Edgar Körner;T. Tsuda;Hiroyuki Shimizu	1987		10.1007/3-540-18099-0_27	real-time computing;computer science;theoretical computer science	AI	-9.292229766106717	41.13334959222994	33788
05d63daaec7b427da7822de6bae1020a23b56495	performance analysis of parallel programs via message-passing graph traversal	graph theory;program diagnostics;message passing graph traversal;perforation;parallel programming;perturbation techniques;data distribution;interconnection network;message passing interface;operating system;interconnection network layer performance analysis parallel programs message passing graph traversal operating system;performance analysis;message passing;message passing graph;performance analysis concurrent computing delay distributed computing application software operating systems multiprocessor interconnection networks runtime predictive models extrapolation;program diagnostics parallel programming message passing graph theory perturbation techniques operating systems computers;technical report;interconnection network layer;parallel programs;operating systems computers	The ability to understand the factors contributing to parallel program performance are vital for understanding the impact of machine parameters on the performance of specific applications. We propose a methodology for analyzing the performance characteristics of parallel programs based, on message-passing traces of their execution on a set of processors. Using this methodology, we explore how perturbations in both single processor performance and the messaging layer impact the performance of the traced run. This analysis provides a quantitative description of the sensitivity of applications to a variety of performance parameters to better understand the range of systems upon which an application can be expected to perform well. These performance parameters include operating system, interference and variability in message latencies within the interconnection network layer.	central processing unit;graph traversal;heart rate variability;interconnection;interference (communication);message passing;operating system;perturbation theory;profiling (computer programming);tracing (software);tree traversal	Matthew J. Sottile;Vaddadi P. Chandu;David A. Bader	2006	Proceedings 20th IEEE International Parallel & Distributed Processing Symposium	10.1109/IPDPS.2006.1639321	parallel computing;message passing;computer science;technical report;graph theory;message passing interface;theoretical computer science;operating system;distributed computing	Arch	-9.28738757532756	47.82886315631203	33815
5192f6819d2dbd28ccd2b83fd673078fc3c5a240	scads: scale-independent storage for social computing applications	query language;cluster computing;social computing;scaling up;machine learning;relaxed consistency;utility computing	Collaborative web applications such as Facebook, Flickr and Yelp present new challenges for storing and querying large amounts of data. As users and developers are focused more on performance than single copy consistency or the ability to perform ad-hoc queries, there exists an opportunity for a highly-scalable system tailored specifically for relaxed consistency and pre-computed queries. The Web 2.0 development model demands the ability to both rapidly deploy new features and automatically scale with the number of users. There have been many successful distributed keyvalue stores, but so far none provide as rich a query language as SQL. We propose a new architecture, SCADS, that allows the developer to declaratively state application specific consistency requirements, takes advantage of utility computing to provide cost effective scale-up and scale-down, and will use machine learning models to introspectively anticipate performance problems and predict the resource requirements of new queries before execution.	flickr;hoc (programming language);machine learning;precomputation;query language;requirement;sql;scalability;social computing;utility computing;web 2.0;web application;world wide web	Michael Armbrust;Armando Fox;David A. Patterson;Nick Lanham;Beth Trushkowsky;Jesse Trutna;Haruki Oh	2009	CoRR		computer cluster;computer science;data mining;database;utility computing;programming language;world wide web;social computing;query language	OS	-23.247475397927495	52.35181334802043	33856
43f403d7cbdaeea11b7e95a86216d56e401a5344	plugging anti and output dependence removal techniques into loop parallelization algorithm	parallel algorithm;loop parallelization algorithm;anti dependence;loop transformation;output dependence;dependence removal	In this paper we shortly survey some loop transformation techniques which break anti or output dependence& or artificial cycles involving such ‘false’ dependences. These false dependences are removed through the introduction of temporary buffer arrays. Next we show how to plug these techniques into loop parallelization algorithms (such as Allen and Kennedy’s algorithm). The goal is to extract as many parallel loops as the intrinsic degree of parallelism of the nest authorizes, while avoiding a full memory expansion. We try to reduce the number of temporary arrays that we introduce, as well as their dimension.	algorithm;automatic parallelization;degree of parallelism;dependence analysis;loop optimization;parallel computing	Pierre-Yves Calland;Alain Darte;Yves Robert;Frédéric Vivien	1997	Parallel Computing	10.1016/S0167-8191(96)00108-1	parallel computing;loop dependence analysis;computer science;loop nest optimization;theoretical computer science;mathematics;distributed computing;parallel algorithm	PL	-9.958615175849332	33.00331741614522	33897
89b6df684a0fbc81d3eb6174cf18ffa005899b7e	self-synchronization of concurrent processes	concurrent processes;multiprocessing programs;communicating action refinement operations;steps self synchronization operation concurrent processes concurrent transitions parallel synchronization operations communicating action refinement operations unsynchronized noncommunicating operations fully abstract process semantics action multisets;fully abstract process semantics;synchronisation;computer science carbon capture and storage communication standards algebra equations;algebra;self synchronization operation;carbon capture and storage;communication standards;communicative action;steps;formal logic;action multisets;parallel synchronization operations;concurrent transitions;multiprocessing systems;synchronisation formal logic multiprocessing programs multiprocessing systems;computer science;unsynchronized noncommunicating operations;concurrent process	"""We introduce a unary \self-synchronization"""" operation on concurrent processes that synchronizes concurrent transitions within a process. Standard parallel synchronization and communicating action reene-ment operations can be reduced to simple combinations of self-synchronization and unsynchronized non-communicating operations. We show that modifying familiar fully abstract process semantics so that actions are replaced by action multi-sets (steps) typically yields semantics which are fully abstract for processes with self-synchronization."""		Lalita Jategaonkar Albert R. Meyer	1993		10.1109/LICS.1993.287567	synchronization;real-time computing;carbon capture and storage;computer science;theoretical computer science;distributed computing;programming language;logic;algorithm	Logic	-26.742868018872272	33.10502372528653	33909
b1d14e2b28759afd361d50e14744224b654e205e	internally deterministic parallel algorithms can be fast	geometry algorithms;parallel algorithm;programming paradigm;sorting;string processing;benchmark problem;dependence graph;commutative operations;parallel programming;deterministic parallelism;graph algorithm;parallel programs;graph algorithms;data structure;parallel algorithms	The virtues of deterministic parallelism have been argued for decades and many forms of deterministic parallelism have been described and analyzed. Here we are concerned with one of the strongest forms, requiring that for any input there is a unique dependence graph representing a trace of the computation annotated with every operation and value. This has been referred to as internal determinism, and implies a sequential semantics---i.e., considering any sequential traversal of the dependence graph is sufficient for analyzing the correctness of the code. In addition to returning deterministic results, internal determinism has many advantages including ease of reasoning about the code, ease of verifying correctness, ease of debugging, ease of defining invariants, ease of defining good coverage for testing, and ease of formally, informally and experimentally reasoning about performance. On the other hand one needs to consider the possible downsides of determinism, which might include making algorithms (i) more complicated, unnatural or special purpose and/or (ii) slower or less scalable.  In this paper we study the effectiveness of this strong form of determinism through a broad set of benchmark problems. Our main contribution is to demonstrate that for this wide body of problems, there exist efficient internally deterministic algorithms, and moreover that these algorithms are natural to reason about and not complicated to code. We leverage an approach to determinism suggested by Steele (1990), which is to use nested parallelism with commutative operations. Our algorithms apply several diverse programming paradigms that fit within the model including (i) a strict functional style (no shared state among concurrent operations), (ii) an approach we refer to as deterministic reservations, and (iii) the use of commutative, linearizable operations on data structures. We describe algorithms for the benchmark problems that use these deterministic approaches and present performance results on a 32-core machine. Perhaps surprisingly, for all problems, our internally deterministic algorithms achieve good speedup and good performance even relative to prior nondeterministic solutions.	benchmark (computing);computation;correctness (computer science);data structure;debugging;existential quantification;experiment;linearizability;non-deterministic turing machine;parallel algorithm;parallel computing;programming paradigm;scalability;speedup;tree traversal;verification and validation	Guy E. Blelloch;Jeremy T. Fineman;Phillip B. Gibbons;Julian Shun	2012		10.1145/2145816.2145840	parallel computing;data structure;computer science;deterministic algorithm;theoretical computer science;distributed computing;parallel algorithm;programming language;algorithm	PL	-12.477001787664433	33.47863327737959	33931
30d1424eb91d7b230f4929b9cb4bdc1ddbad876a	a review paper on microprocessor based controller programming		Designing of microprocessor based controllers requires specific hardware as well as software programming. Programming depends upon type of the software whether operating software or application software. Programming requires knowledge of system configuration and controller specific programming. Programs are always in digital form so microprocessor can control directly at digital level called Direct Digital Control (DDC).	computer programming;controller (computing);microprocessor;operating system;system configuration	Jaswinder Singh Dilawari;Gurpreet Singh Sandhu	2012	CoRR		control engineering;computer architecture;real-time computing;n-version programming;reactive programming;functional reactive programming;computer science;component-based software engineering;signal programming;computer programming;event-driven programming;procedural programming;inversion of control;inductive programming;system programming;software system	Arch	-27.751098685909145	38.15994079425877	33959
500260d6c83d61b130b5fffb7be30bb317393c81	autonomics for grid systems and applications	grid system application management;application management;pervasive computing;engineering system;autonomic computing;grid system	Emerging pervasive computing and information environments, such as Grids and CDNs, are enabling a new generation of applications, which are based on seamless aggregation and interactions of resources, services and data. However the extreme scale, dynamism and uncertainty of these environments and applications present significant development, configuration and management challenges. Autonomic computing has the potential to fundamentally address these challenges. The goal of autonomic computing is to design and engineer systems that are capable of running themselves, adapting their resources and operations to current workloads and anticipating the needs their users, all with minimal involvement from the users. In this talk, I will introduce autonomic computing and describe how it can be potentially used to address the challenges for Grids and CDNs. I will then introduce relevant solutions being developed as part of the NSF Center for Autonomic Computing.	autonomic computing;ibm notes;ibm websphere extreme scale;interaction;seamless3d;ubiquitous computing	Manish Parashar	2008		10.1145/1384209.1384211	context-aware pervasive systems;simulation;computer science;theoretical computer science;end-user computing;distributed computing;utility computing;application lifecycle management;management;grid computing;autonomic computing	HPC	-29.843116614815894	53.23521607730098	33971
07a42501dca5a83c8b36633012646b31ba407da0	evaluating multiple server dbms in general purpors operating system environments	operating system		operating system	Theo Härder;Peter Peinl	1984			embedded system;embedded operating system;computer science;operating system;standard operating environment;database	ML	-31.04712714485973	42.271460712415895	33975
6fd9b70e3328b65ffc41516f0760b6af881489cf	combined on-line lifetime-energy optimization for asymmetric multicores	reliability;asymmetric multicores;lifetime reliability;energy consumption;multicore processing;mathematical model;optimization;quality of service	In this paper we present an architectural and on-line resource management solution to optimize lifetime reliability of asymmetric multicores while minimizing the system energy consumption, targeting both single nodes (multicores) as well as multiple ones (cluster of multicores). The solution exploits the different characteristics of the computing resources to achieve the desired performance while optimizing the lifetime/energy trade-off. The experimental results show that a combined optimization of energy and lifetime allows for achieving an extended lifetime (similar to the one pursued by lifetime-only optimization solutions) with a marginal energy consumption detriment (less than 2%) with respect to energy-aware but aging-unaware systems.		Cristiana Bolchini;Matteo Carminati;Tulika Mitra;Thannirmalai Somu Muthukaruppan	2016	2016 IEEE International Symposium on Defect and Fault Tolerance in VLSI and Nanotechnology Systems (DFT)	10.1109/DFT.2016.7684066	multi-core processor;embedded system;parallel computing;real-time computing;quality of service;computer science;engineering;mathematical model;reliability;statistics	Embedded	-4.923792991297362	57.0230922373769	34149
a13c50b75d0b3650dd0a36066a8de162835f41ac	performance expectations and guidelines for mpi derived datatypes	relevant optimizations;performance improvement;mpi implementers;performance expectation;performance portability;self-consistent guideline;enforced self-consistent guideline;self-consistent performance guideline;mpi communication;mpi implementation	MPI’s derived datatypes provide a powerful mechanism for concisely describing arbitrary, noncontiguous layouts of user data for use in MPI communication. This paper formulates self-consistent performance guidelines for derived datatypes. Such guidelines make performance expectations for derived datatypes explicit and suggest relevant optimizations to MPI implementers. We also identify self-consistent guidelines that are too strict to enforce, because they entail NP-hard optimization problems. Enforced self-consistent guidelines assure the user that certain manual datatype optimizations cannot lead to performance improvements, which in turn contributes to performance portability between MPI implementations that behave in accordance with the guidelines. We present results of tests with several MPI implementations, which indicate that many of them violate the guidelines.	benchmark (computing);experiment;library (computing);mathematical optimization;message passing interface;np-hardness	William Gropp;Torsten Hoefler;Rajeev Thakur;Jesper Larsson Träff	2011		10.1007/978-3-642-24449-0_18	parallel computing;real-time computing;computer science;theoretical computer science	HPC	-12.006443873947905	40.97842219796895	34151
e156076768136fc4c386046f60a2d548cf7d22a1	wake-up logic optimizations through selective match and wakeup range limitation	estensibilidad;wakeup logic instruction scheduler issue window wakeup locality;wakeup locality;optimisation;random access memory;issue window;memoria acceso directo;selective match;optimizacion;integrated circuit;logic design;source tags;logic processor scheduling energy consumption dynamic scheduling delay computer aided manufacturing cadcam clocks pipeline processing scalability;grant lines;circuito integrado;wakeup locality wake up logic optimizations selective match instructions per cycle loss dynamic instruction schedulers power consumption wakeup latency source tags redundant matches grant lines;random access storage circuit optimisation logic design;wake up logic optimizations;redundant matches;memoire acces direct;wakeup logic;random access storage;optimization;extensibilite;scalability;reactivation;power consumption;reactivacion;consommation energie electrique;circuit optimisation;dynamic instruction schedulers;instruction scheduling;instructions per cycle loss;instruction scheduler;wakeup latency;circuit integre;instructions per cycle	This paper presents two effective wakeup designs that improve the speed, power, area, and scalability without instructions per cycle (IPC) loss for dynamic instruction schedulers. First, a wakeup design is proposed to aim at reducing the power consumption and wakeup latency. This design removes the read of the destination tags from the wakeup path by matching the source tags directly with the grant lines. Moreover, this design eliminates the redundant matches during the wakeup operations by matching the source tags with only the selected grant lines. Next, the second design explores a metric called wakeup locality to further reduce the area cost of the wakeup logic. By limiting the wakeup ranges for the instructions in the issue window, this design not only reduces the area requirement but also improves the scalability. The experimental results show that this range-limited-wakeup design saves 76%-94% of the power consumption and reduces 29%-77% in the wakeup latency compared to the conventional CAM-based scheme with only 5%-44% of the area cost in a traditional RAM-based scheme. The results also show that this design scales well with the increase of both the issue width and the window size	bitmap;central processing unit;elegant degradation;instructions per cycle;locality of reference;random-access memory;scalability;speedup	K.-S. Hsiao;C.-H. Chen	2006	IEEE Transactions on Very Large Scale Integration (VLSI) Systems	10.1109/TVLSI.2006.884150	embedded system;parallel computing;logic synthesis;real-time computing;scalability;computer science;operating system;integrated circuit;instruction scheduling;instructions per cycle	EDA	-7.449600791591336	53.53694767234353	34153
39744bf71651ee803a69c1ba536253fa1f8f7c47	vm data spaces and esa/xc facilities	virtual machine;data sharing;architecture systeme;machine virtuelle;addressing;monitoring system;programme moniteur;operating system;almacenamiento;stockage;adressage;programa monitor;arquitectura sistema;enterprise system;direccionamiento;system architecture;maquina virtual;monitor program;storage	Release 1.1 of the Virtual Machine/Enterprise Systems Architecture™ (VM/ESA™) operating system introduces a new function called VM Data Spaces, provided through a new virtual-machine architecture called Enterprise Systems Architecture/Extended Configuration (ESA/XC). ESA/XC is the strategic VM/ESA virtual-machine environment for Conversational Monitor System (CMS) users and service virtual machines requiring large amounts of storage or advanced data-sharing capabilities. ESA/XC includes all of the facilities of System/370 Extended Architecture (370-XA) that are used by CMS or server programs and is therefore upward compatible for CMS or server programs currently running in 370-XA virtual machines. To this 370-XA base, ESA/XC adds the data space and access-register addressing capabilities previously available only under the Multiple Virtual Storage/Enterprise Systems Architecture (MVS/ESA™) operating system. These addressing extensions can be used to make additional storage available to large, storage-constrained applications and can also be used by servers as an efficient way of sharing data between service virtual machines and the users that access those servers. As an introduction to the VM Data Spaces function, this paper describes the ESA/XC virtual-machine architecture and presents an overview of the VM/ESA services provided in support of the ESA/XC architecture.	dataspaces;esa;spaces	Joseph M. Gdaniec;James P. Hennessy	1991	IBM Systems Journal	10.1147/sj.301.0014	embedded system;enterprise system;real-time computing;addressing mode;computer science;engineering;virtual machine;operating system;systems architecture	DB	-30.624193688701425	42.52228281783019	34334
61751add720a960a5e019aac705aa890a8a2dc29	non-uniform power access in large caches with low-swing wires	silicon;cache storage;interbank network nonuniform power access low swing wires processor power uniform cache access onchip network cache access power energy consumption minimization;processor power;cache access power;wires wiring program processors technological innovation energy dissipation navigation proposals energy consumption energy measurement computer architecture;interbank network;wires;chip;arrays;nonuniform power access;energy consumption;energy consumption minimization;uniform cache access;low swing wires;program processors;pipeline processing;energy saving;onchip network	Modern processors dedicate more than half their chip area to large L2 and L3 caches and these caches contribute significantly to the total processor power. A large cache is typically split into multiple banks and these banks are either connected through a bus (uniform cache access — UCA) or an on-chip network (non-uniform cache access — NUCA). Irrespective of the cache model (NUCA or UCA), the complex interconnects that must be navigated within large caches are found to be the dominant part of cache access power. While there have been a number of proposals to minimize energy consumption in the inter-bank network, very little attention has been paid to the optimization of intra-bank network power that contributes more than 50% of the total cache dynamic power in large cache banks. In this work we study various mechanisms that introduce low-swing wires inside cache banks as energy saving measures. We propose a novel non-uniform power access design, which when coupled with simple architectural mechanisms, provides the best power-performance tradeoff. The proposed mechanisms reduce cache bank energy by 42% while incurring a minor 1% drop in performance.	cpu cache;central processing unit;h tree;low-power broadcasting;mathematical optimization;network on a chip;pipeline (computing);speaker wire;unicode collation algorithm	Aniruddha N. Udipi;Naveen Muralimanohar;Rajeev Balasubramonian	2009	2009 International Conference on High Performance Computing (HiPC)	10.1109/HIPC.2009.5433222	chip;bus sniffing;embedded system;pipeline burst cache;parallel computing;real-time computing;cache coloring;page cache;cpu cache;cache;write-once;cache invalidation;operating system;smart cache;silicon;cache algorithms;cache pollution	Arch	-6.798351144085303	54.01500474504708	34339
319bf128a8aa15a4719049af0869bb7ce45d07ee	efficient dir0b cache coherency for many-core cmps	cache coherence	Directory-based cache coherency is commonly accepted as the design of choice to provide high performance and scalability in coherency maintenance for many-core CMPs. However, the on-chip area overhead required to encode sharer sets may compromise their success as core count increases. In this work, we propose the Express COherence NOtification (ECONO) protocol, a simple and efficient Dir0B cache coherence protocol that does not require sharer sets encoding while approaching performance of a conventional directory-based protocol. To accomplish that, ECONO relies on express coherence notifications which are broadcast atomically over a dedicated lightweight on-chip network leveraging state-of-the-art technology. Detailed full-system simulation using a representative set of benchmarks corroborates our statement.	cache coherence;computer architecture simulator;directory (computing);encode;manycore processor;network on a chip;overhead (computing);scalability;simulation	José L. Abellán;Alberto Ros;Juan Fernández Peinador;Manuel E. Acacio	2013		10.1016/j.procs.2013.05.437	parallel computing;mesi protocol;mesif protocol	Arch	-10.121146161542647	50.85870339063324	34404
bbcf4a13d81de59a4143c4d37c033ac4c45a08d0	algorithm level fault tolerance for molecular dynamic applications	kernel;matrix vector multiplication algorithm level fault tolerance molecular dynamic applications soft error handling high performance computing;force;fault tolerant systems;dynamics;heuristic algorithms;fault tolerance;mathematical model;heuristic algorithms kernel fault tolerance fault tolerant systems force dynamics mathematical model;vectors error handling matrix multiplication molecular dynamics method parallel processing software fault tolerance	Handling soft errors have recently emerged as an important topic in high performance computing. Though there has been a significant amount of work on algorithm-level fault tolerance (ABFT) solutions, they have been applied to linear algebra problems only. Molecular dynamics represents a popular class of computational applications that are susceptible to soft errors because of their long running nature, and yet there has been no ABFT solution for them. This paper develops such a solution. We show how we are able to map the key computational kernel of molecular dynamic to a matrix vector multiplication (MVM), in which the matrix holds the intermediate data, the vector comprises the coordinate of the atoms, and the final force is the matrix vector product. We adapt existing MVM based solutions to this problem, though additional optimizations are required for efficiency. Our effectiveness evaluation shows that our method can always achieve an F-score of over 0.9, provided an appropriate tolerance threshold is chosen. The overall overhead of detection and recovery is also always less than 10%.	algorithm;application checkpointing;computation;f1 score;fault tolerance;full scale;kernel (operating system);linear algebra;matrix multiplication;molecular dynamics;overhead (computing);soft error;supercomputer;the matrix	Jiaqi Liu;Gagan Agrawal	2015	2015 IEEE 22nd International Conference on High Performance Computing (HiPC)	10.1109/HiPC.2015.53	dynamics;fault tolerance;parallel computing;kernel;real-time computing;computer science;theoretical computer science;mathematical model;distributed computing;force;quantum mechanics	HPC	-18.208986060735445	48.63268398573858	34416
05734ec36b0838e4b4f89897010143cfaf0b935d	non-uniform replication		Replication is a key technique in the design of efficient and reliable distributed systems. As information grows, it becomes difficult or even impossible to store all information at every replica. A common approach to deal with this problem is to rely on partial replication, where each replica maintains only a part of the total system information. As a consequence, a remote replica might need to be contacted for computing the reply to some given query, which leads to high latency costs particularly in geo-replicated settings. In this work, we introduce the concept of nonuniform replication, where each replica stores only part of the information, but where all replicas store enough information to answer every query. We apply this concept to eventual consistency and conflict-free replicated data types. We show that this model can address useful problems and present two data types that solve such problems. Our evaluation shows that non-uniform replication is more efficient than traditional replication, using less storage space and network bandwidth. 1998 ACM Subject Classification C.2.4 Distributed Systems	conflict-free replicated data type;distributed computing;eventual consistency;system information (windows)	Gonçalo Cabrita;Nuno M. Preguiça	2017		10.4230/LIPIcs.OPODIS.2017.24	replica;latency (engineering);real-time computing;computer science;control of chromosome duplication;semiconservative replication;distributed computing;dna replication factor cdt1;eventual consistency;minichromosome maintenance;pre-replication complex	HPC	-22.278404595615797	49.23228164178079	34421
03ff37a2b968a40a7f3d59434b4763a1ca72c46c	efficient shared-memory support for parallel graph reduction	cache organisation;shared memory;simulation;interconnection network;declarative languages;cache coherence;simulation study;parallel implementation;spatial locality;functional programming language	This paper presents the results of a simulation study of cache coherency issues in parallel implementations of functional programming languages. Parallel graph reduction uses a heap shared between processors for all synchronisation and communication. We show that a high degree of spatial locality is often present and that the rate of synchronisation is much greater than for imperative programs. We propose a modiied coherency protocol with static cache line ownership and show that this allows locality to be exploited to at least the level of a conventional protocol, but without the unnecessary serialisation and network transactions this usually causes. The new protocol avoids false sharing, and makes it possible to reduce the number of messages exchanged, but relies on increasing the size of the cache lines exchanged to do so. It is therefore of most beneet with a high-bandwidth interconnection network with relatively high communication latencies or message handling overheads.	cache (computing);cache coherence;central processing unit;false sharing;functional programming;graph reduction;imperative programming;interconnection;locality of reference;principle of locality;programming language;serialization;shared memory;simulation	Andrew J. Bennett;Paul H. J. Kelly	1997	Future Generation Comp. Syst.	10.1016/S0167-739X(96)00019-2	locality of reference;shared memory;cache coherence;parallel computing;real-time computing;cache coloring;cache;computer science;write-once;cache invalidation;operating system;database;distributed computing;programming language;functional programming;mesi protocol;cache algorithms;cache pollution;moesi protocol;mesif protocol	Arch	-12.218414936623118	49.258168393683576	34427
8f92214668991cf6d19684e562eb2186f2c65a8c	ft-offload: a scalable fault-tolerance programing model on mic cluster		Massively heterogeneous architectures are popular for modern petascale and future exascale systems. Fault-tolerance is key to the increased number of components and the complexity of these heterogeneous systems. However, standard offload programming models have traditionally been developed for supporting high performance rather than reliability. Naive fault-tolerance protocols are incapable of serving distributed MPI applications that tuned for CPU-MIC heterogeneous clusters. To address these problems, we design and implement a framework of fault tolerance programming model (FT-Offload). This enhances the reliability of heterogeneous supercomputers and retains the convenient of popular Intel Offload programming model. The effectiveness of the framework is demonstrated via numerical analysis and by porting both benchmarks and real-world applications to large-scale CPU-MIC nodes on the Tianhe-2 supercomputer. Our experimental results show that the current solution, which involves checkpoints, can efficiently strength the long running and reduce checkpointing overhead.	fault tolerance	Cheng Chen;Yunfei Du;Zhen Xu;Canqun Yang	2015		10.1007/978-3-319-27140-8_1	parallel computing	NLP	-9.657205522796213	45.98290936703869	34428
687c66d1e9d706085d7f9d4bd4d8b5393a56328c	sacrificing true distribution for gaining access efficiency of replicated shared objects	distributed algorithms;second chance protocol access efficiency replicated shared objects replicated shared object management heterogeneous networks truly distributed algorithms true distribution property replication control scheme;voting availability costs access protocols workstations lattices microcomputers network servers mirrors power supplies;distributed algorithm;heterogeneous network	1 Introduction Grid-based replication control schemes are very popular in the replication research community due to very high operation availabilities and extremely low operation costs. Representatives of grid-based protocols are the classic Grid Protocol (Grid) 1], the Hierarchical Grid Protocol (HGrid) 3], and the Triangular Lattice Protocol (TLP) 9]. Among other replication control schemes, grid-based protocols generally exhibit a property called true distribution. The term was rst introduced by Maekawa 5] in the scope of solving the distributed mutual exclusion problem. Informally, a protocol is truly distributed if no site participating in the execution of the protocol bears more responsibility than another one. Through a truly distributed protocol , it is guaranteed that no site can constitute an availability or performance bottleneck. We propose a new replication control scheme called Second Chance Protocol, which sacriices true distribution. The motivation for doing so stems from the following observations: Distributed networking environments of today do not consist of homogeneous components with identical characteristics. The opposite is the case: high-performance multiprocessor workstations coexist with ordinary workstations and even low-budget personal computers. In such an environment , having a proper system administration, high-performance server machines can process a bigger portion of the workload than others without becoming a performance bottleneck. Furthermore, server machines can be regarded being higher available than other machines: either they are equipped with special components like mirror disks and uninterruptable power supplies, or their mean time to repair is shorter and their mean time between failures is longer due to better administration and maintenance. 2 The new protocol We construct the Second Chance Protocol (SCP) as a multi-level replication control scheme with priorities by combining the Logarithmic Protocol (LP) 2] and the Majority Consensus Strategy (MCS) 8]. The LP is a protocol with low read and write access costs as well as a high read operation availability. Unfortunately, the write operation availability is poor. The MCS, on	coexist (image);distributed networking;file system permissions;maekawa's algorithm;mean time between failures;mean time to repair;multi categories security;multiprocessing;mutual exclusion;personal computer;server (computing);system administrator;task parallelism;uninterruptible power supply;workstation	Henning Pagnia;Oliver E. Theel	1998		10.1109/HICSS.1998.649259	distributed algorithm;real-time computing;heterogeneous network;computer science;theoretical computer science;operating system;database;distributed computing	Networks	-22.015352273680044	50.352762340977094	34443
1e72f684a684647daee2a82286fb0960ad1f279a	vi architecture communication features and performance on the giganet cluster lan	cluster computing;communication system;performance evaluation;virtual interface;satisfiability;system area network;low latency;critical path;giganet clan;vi architecture;high throughput;hardware implementation;data transfer	The virtual interface (VI) architecture standard was developed to satisfy the need for a high throughput, low latency communication system required for cluster computing. VI architecture aims to close the performance gap between the bandwidths and latencies provided by the communication hardware and visible to the application, respectively, by minimizing the software overhead on the critical path of the communication. This paper presents the results of a performance study of one VI architecture hardware implementation, the Giganet cLAN (cluster LAN). The focus of the study is to assess and compare the performance of different VI architecture data transfer modes and specific features that are available to higher-level communication software like MPI in order to aid the implementor to decide which VI architecture options to employ for various communication scenarios. Examples of such options include the use of send/receive vs. RDMA data transfers, polling vs. blocking to check completion of communication operations, multiple VIs, completion queues and scatter capabilities of VI architecture. © 2002 Elsevier Science B.V. All rights reserved.	bandwidth (signal processing);benchmark (computing);blocking (computing);computer cluster;conjunctive query;context switch;copy-on-write;critical path method;expansion card;explicit and implicit methods;interrupt;linux;maximum throughput scheduling;message passing interface;overhead (computing);polling (computer science);remote direct memory access;throughput;visual instruction set;windows nt	Hermann Hellwagner;Matthias Ohlenroth	2002	Future Generation Comp. Syst.	10.1016/S0167-739X(01)00060-7	high-throughput screening;parallel computing;real-time computing;computer cluster;computer science;operating system;critical path method;database;distributed computing;computer security;communications system;satisfiability;low latency	Arch	-11.752397064946864	45.805017080698626	34449
18757bfb32685a147c05ae3f75e18edace5cb86c	teaching distributed computing with workqueue (abstract only)	parallel computing;distributed computing;workqueue;mapreduce	"""With the recent emphasis on Parallel and Distributed Computing topics in the Computer Science Curricula 2013, instructors are increasingly incorporating these topics into their undergraduate courses. Unfortunately, many universities lack the dedicated computing resources to provide hands-on experiences in this area. This workshop guides attendees through the open source WorkQueue software to teach parallel and distributed computing principles to undergraduate students. WorkQueue is a distributed master worker framework developed by the Cooperative Computing Lab at the University of Notre Dame. WorkQueue is well-suited for inclusion in undergraduate courses due to the ease of use and deployment on a wide range of computer systems, low administrative overhead, and scalability. WorkQueue can be deployed on any system, from a small Raspberry Pi cluster to a high-performance grid computing environment. This workshop walks attendees through the use of WorkQueue with three demonstrations: a """"live demo"""" such as would be used to engage students in the classroom with a hands-on introduction to distributed computing principles, and a guided """"tour"""" through two lab assignments. The first lab assignment will give attendees a hands-on example of a simple distributed computing problem from implementation to deployment. The second lab will demonstrate WorkQueue MapReduce, a simple framework that can be used to introduce the MapReduce programming model without the overhead of a Hadoop cluster or equivalent. A laptop is required to participate in the workshop; the presenters will provide a pre-configured Linux VirtualBox virtual machine to facilitate software setup, or attendees can use their own Linux installations."""	apache hadoop;computer science;distributed computing;experience;grid computing;hands-on computing;laptop;linux;mapreduce;open-source software;overhead (computing);programming model;raspberry pi 3 model b (latest version);scalability;software deployment;usability;virtual machine;virtualbox	Aaron Dingler;Peter Bui	2017		10.1145/3017680.3017838	simulation;computer science;operating system;software engineering;data-intensive computing;distributed computing;utility computing;grid computing	HPC	-29.084037175787294	52.11254003826436	34515
24404b71d9263f2e8417db09526e755d90697f99	processing recursive queries on transputers		There is a perceived need within the database community to extend the traditional relational database systems so as to accommodate applications which are deductive in nature. One major problem involved in such an extension is the efficient processing of recursive queries. To this end, parallel processing is expected to play an important role. While substantial work has been done in devising strategies for processing recursive queries in parallel, it is perhaps surprising that little has been reported on the implementation and the run-time performance of these strategies. In the paper we report our experience of implementing a pipelined evaluation strategy on transputers. A wide range of queries, database structures and architectural configurations are considered as benchmarks in this study. The performance is studied in terms of both speed-up factors and communication costs. The experimental results show the potential of processing recursive queries in parallel, and provide insight into the usefulness of using transputers for such applications.	hierarchical and recursive queries in sql;recursion;transputer	Jialun Shao;David A. Bell;M. Elizabeth C. Hull	1995	Concurrency - Practice and Experience	10.1002/cpe.4330070202	theoretical computer science;database;distributed computing	DB	-15.071422002642766	38.255415779876785	34535
bfbf3f5585b91a9daad3add844cf3bb1c5f68b47	advanced hybrid branch predictors for high-performance cpus	hybrid branch prediction;dynamic branch prediction;instruction level parallelism;high performance		branch predictor;central processing unit	Venkata S. Yerasi;Wei-Ming Lin	2006			computer architecture;parallel computing;real-time computing;computer science;instruction-level parallelism;branch predictor	Arch	-9.21422756645987	43.33010756795663	34633
c7bfe9299f187950378fb60da35265016cff13f0	an effective algorithm for parallelizing hash joins in the presence of data skew	heuristic optimization algorithm;optimisation;processor scheduling;prototypes;heuristic programming;data skew;zipf like distribution;hierarchical hashing;algorithm;scheduling algorithm;scheduling;heuristic algorithms;database systems;heuristic optimization;load management;load balancing;scheduling phase;robustness;load balance;relational databases;load balancing algorithm parallelizing hash joins data skew hierarchical hashing scheduling phase heuristic optimization algorithm zipf like distribution;parallelizing hash joins;partitioning algorithms scheduling algorithm processor scheduling relational databases heuristic algorithms load management robustness database systems proposals prototypes;scheduling file organisation heuristic programming optimisation;proposals;partitioning algorithms;file organisation	As relations grow larger and queries become more complex processing queries in parallel becomes more important. However, the presence of data skew can cause load imbalances among the various processors, significantly reducing the speedup available from conventional parallel join algorithms. The presence of even one large skew element can cause a processor to become overloaded. This paper presents a parallel hash join algorithm based o n the concept of hierarchical hashing to address the problem of data skew. I'he proposed algorithm adds an extra scheduling phase to the usual hash and join phases. During the scheduling phase, a heuristic optimization algorithm, using the output of the hash phase, attempb to balance the load across the multiple processors in the subsequent join phase. The algorithm naturally identifies the hash partitions with the largest skew elements, splits them up, and assigns each of them to an optimal number of processors. Assuming a Zipf-like distribution of the elements in the join column, the algorithm is shown to achieve good load balancing for the join phase in a CPU-bound environment, and is shown to he fairly robust relative to the degree of data skew and the total number of processors. We cornpare the overall speedup due to this algorithm with conventional parallel hash join methods and we show the considerable advantage of the proposed method even when the additional scheduling phase is taken into account.	algorithm;amdahl's law;central processing unit;function overloading;hash join;heuristic;join (sql);load balancing (computing);mathematical optimization;parallel computing;scheduling (computing);speedup;zipf's law	Joel L. Wolf;Daniel M. Dias;Philip S. Yu;John Turek	1991		10.1109/ICDE.1991.131467	hash join;hash table;double hashing;parallel computing;hash function;linear hashing;perfect hash function;dynamic perfect hashing;primary clustering;computer science;load balancing;theoretical computer science;operating system;block nested loop;database;k-independent hashing;distributed computing;rolling hash;scheduling;swifft;hash tree;hash filter	DB	-16.36096880095091	55.889051858050614	34651
127875b4344e6fa7ff4b01cb7bc073a7355a26d7	performance analysis of dynamic finite versioning for concurrency transaction and query processing	trace analysis;instruction cache;query processing;trace generation;performance analysis;cache simulation;analytical model;renewal process	In this paper, we analyze the performance of dynamic finite versioning (DFV) schemes for concurrent transaction and query processing, where a finite number of consistent snapshots can be derived for query access. We develop analytical models based on a renewal process approximation to evaluate the performance of DFV using M ≥ 2 snapshots. The storage overhead and obsolescence faced by queries are measured. Simulation is used to validate the analytical models and to evaluate the trade-offs between various starategies for advancing snapshots when M > 2. The results show that (1) the analytical models match closely with simulation; 2) both the storage overhead and obsolescence are sensitive to the snapshot-advancing strategies, especially for M > 2 snapshots; and (3) generally speaking, increasing the number of snapshots demonstrates a trade-off between storage overhead and query obsolescence. For cases with skewed access or low update rates, a moderate increase in the number of snapshots beyond 2 can substantially reduce the obsolescence, while the storage overhead may increase only slightly, or even decrease in some cases. Moreover, for very low update rates, a large number of snapshots demonstrates a trade-off between storage overhead and query obsolescence. For cases with skewed access or low update rates, a moderate increase in the number of snapshots beyond 2 can substantially reduce the obsolescence, while the storage overhead may increase only slightly, or even decrease in some cases. Moreover, for very low update rates, a large number of snapshots can be used to reduce the obsolescence to almost zero without increasing the storage overhead.	approximation;database;overhead (computing);profiling (computer programming);simulation;snapshot (computer storage)	Arif Merchant;Kun-Lung Wu;Philip S. Yu;Ming-Syan Chen	1992		10.1145/133057.133094	renewal theory;parallel computing;real-time computing;computer science;operating system;database;statistics	Metrics	-20.760669941786006	48.65928006914759	34706
0c7defe10c372f1a8a24ec4f840a5bc1870eea3e	adaptive cache bypassing for inclusive last level caches	cache storage;performance evaluation;adaptive cache bypassing hardware implementation cost reduction cache bypassing algorithm usage information upper level caches cache lines bypass buffer llc performance enhancement last level cache performance enhancement high performance caches cache replacement cache hierarchy design inclusive last level caches;last level cache;cost reduction;inclusion property last level cache cache bypassing cache replacement policy;benchmark testing algorithm design and analysis hardware resource management buffer storage art coherence;performance evaluation cache storage cost reduction memory architecture;inclusion property;cache bypassing;memory architecture;cache replacement policy	Cache hierarchy designs, including bypassing, replacement, and the inclusion property, have significant performance impact. Recent works on high performance caches have shown that cache bypassing is an effective technique to enhance the last level cache (LLC) performance. However, commonly used inclusive cache hierarchy cannot benefit from this technique because bypassing inherently breaks the inclusion property. This paper presents a solution to enabling cache bypassing for inclusive caches. We introduce a bypass buffer to an LLC. Bypassed cache lines skip the LLC while their tags are stored in this bypass buffer. When a tag is evicted from the bypass buffer, it invalidates the corresponding cache lines in upper level caches to ensure the inclusion property. Our key insight is that the lifetime of a bypassed line, assuming a well-designed bypassing algorithm, should be short in upper level caches and is most likely dead when its tag is evicted from the bypass buffer. Therefore, a small bypass buffer is sufficient to maintain the inclusion property and to reap most performance benefits of bypassing. Furthermore, the bypass buffer facilitates bypassing algorithms by providing the usage information of bypassed lines. We show that a top performing cache bypassing algorithm, which is originally designed for non-inclusive caches, performs comparably for inclusive caches equipped with our bypass buffer. The usage information collected from the bypass buffer also significantly reduces the cost of hardware implementation compared to the original design.	algorithm;cpu cache;cache (computing);lunar lander challenge;page replacement algorithm;prefetcher	Saurabh Gupta;Hongliang Gao;Huiyang Zhou	2013	2013 IEEE 27th International Symposium on Parallel and Distributed Processing	10.1109/IPDPS.2013.16	bus sniffing;pipeline burst cache;cache coherence;cache-oblivious algorithm;snoopy cache;parallel computing;real-time computing;cache coloring;page cache;cpu cache;tag ram;computer hardware;cache;computer science;write-once;cache invalidation;adaptive replacement cache;write buffer;smart cache;mesi protocol;cache algorithms;cache pollution;mesif protocol	Arch	-10.39959842064484	53.50018838325652	34730
e6c310c0d42ef90ea65b664de8aab5c351624703	performance and optimization abstractions for large scale heterogeneous systems in the cactus/chemora framework	finite difference methods;astronomy;data structures;parallel processing	We describe a set of lower-level abstractions to improve performance on modern large scale heterogeneous systems. These provide portable access to system- and hardware dependent features, automatically apply dynamic optimizations at run time, and target stencil-based codes used in finite differencing, finite volume, or block-structured adaptive mesh refinement codes. These abstractions include a novel data structure to manage refinement information for block-structured adaptive mesh refinement, an iterator mechanism to efficiently traverse multidimensional arrays in stencil-based codes, and a portable API and implementation for explicit SIMD vectorization. These abstractions can either be employed manually, or be targeted by automated code generation, or be used via support libraries by compilers during code generation. The implementations described below are available in the Cactus framework, and are used e.g. in the Einstein Toolkit for relativistic astrophysics simulations.	adaptive mesh refinement;automatic programming;automatic vectorization;autoregressive integrated moving average;blue waters;c++;cactus framework;code generation (compiler);compiler;data structure;epr paradox;finite volume method;high- and low-level;ibm notes;iterator;library (computing);marek karpinski;mathematical optimization;national center for supercomputing applications;network interface controller;performance application programming interface;perimeter;program optimization;refinement (computing);run time (program lifecycle phase);simd;simulation;system information (windows);traverse	Erik Schnetter	2013	2013 Extreme Scaling Workshop (xsw 2013)		parallel processing;parallel computing;real-time computing;stencil code;data structure;computer science;finite difference method;theoretical computer science;operating system;distributed computing;programming language;algorithm	HPC	-7.1622271543242375	39.32684158318359	34826
fc5b5863bfa0df8f65be477f1abda964aa769751	compatibility in a multi-component environment		A distributed environment where many components interact may be functioning in a suboptimal manner due to two main factors: message loss and deadlocks. Message loss occurs when a component is not ready to receive as input a message sent to it. In the case of a deadlock, a system is indefinitely waiting for a message that never arrives. In Carmona and Cortadella (2002) [12] a theory has been presented for characterizing when a pair of systems is compatible in the sense that they can engage in a dialog free from these two problems. The theory developedwas restricted to only two components, a particular mode of synchronization and a closed environment. In this paper we lift all these assumptions to define a general notion of compatibility in a multi-component environment. For the extended definition of compatibility, we use team automata as a modeling formalism which allows arbitrary synchronization strategies and iterative/hierarchical composition. Moreover, it is shown how the general definition of compatibility presented in this paper can be used to determine the compatibility problems that arise in a team automaton built on the basis of an arbitrary synchronization strategy. © 2013 Elsevier B.V. All rights reserved.	automaton;deadlock;formal system;iterative method;regular expression;dialog	Josep Carmona;Jetty Kleijn	2013	Theor. Comput. Sci.	10.1016/j.tcs.2013.03.006	simulation;computer science;distributed computing;algorithm	Logic	-30.198455160826178	32.67871000446815	34896
bbbacbaf23c9af31a08b7a03416db0f143ab6c53	semmo: a scalable engine for massively multiplayer online games	game semantics;virtual environments;massively multiplayer online game;large scale;games;scalability;virtual environment;system architecture	We propose to demonstrate SEMMO, a consistency server for MMOs. The key features of SEMMO are its novel distributed consistency protocol and system architecture. The distributed nature of the engine allows the clients to perform all computations locally; the only computation that the central server performs is to determine the serialization order of game actions.  We will demo SEMMO through a game called Manhattan Pals, and show how we can exploit game semantics in order to support large-scale MMOs. In the demo, avatars of the audience will be able to play Manhattan Pals and thus experience various scalability and consistency effects of an MMO.	computation;game semantics;scalability;serialization;server (computing);systems architecture	Nitin Gupta;Alan J. Demers;Johannes Gehrke	2008		10.1145/1376616.1376743	first playable demo;game design;games;scalability;simulation;computer science;virtual machine;game semantics;database;distributed computing;multimedia;systems architecture	OS	-27.402386331007786	49.47858597298653	34981
2562400498eed45ca89fc54fec05e323a08d586e	parallel verilog simulation: architecture and circuit partition	optimistic asynchronous;communication cost;parallel verilog simulation architecture;partition algorithm;promising speedup;parallel verilog simulation;pre-simulation partition algorithm;circuit partition;mpi library;parallel simulation algorithm;novel efficient module-based partition;algorithm design and analysis;canonical form;kernel;very large scale integration;logic synthesis	This paper presents parallel Verilog simulation architecture bases on optimistic asynchronous parallel simulation algorithm and MPI library, and proposes a novel efficient module-based partition algorithm combined with pre-simulation partition algorithm. With the presented architecture and partition algorithm, parallel Verilog simulation can get promising speedup, as well as distributed workload and communication cost across processors.	algorithm;central processing unit;simulation;speedup;verilog	Tun Li;Yang Guo;Sikun Li;Fujiang Ao;Gongjie Li	2004	ASP-DAC 2004: Asia and South Pacific Design Automation Conference 2004 (IEEE Cat. No.04EX753)	10.1145/1015090.1015265	embedded system;algorithm design;canonical form;computer architecture;parallel computing;kernel;logic synthesis;computer science;theoretical computer science;operating system;very-large-scale integration;programming language	EDA	-8.519171122593947	42.2218325879218	35073
1dc1cb2f7e21f4caca1db6011a03c5863ad0af2d	achieving high availability at the application level in the cloud	configuration generation;ha as a service cloud computing telecommunication grade requirements high availability requirement ha requirement dynamic incorporation;state aware applications high availability ha cloud middleware runtime upgrade configuration generation ha as a service rest architecture;middleware availability monitoring redundancy virtualization unified modeling language;runtime upgrade;ha as a service;cloud middleware;rest architecture;high availability ha;state aware applications;cloud computing	Cloud computing is an emerging paradigm that is gaining more attention by the day. Even with the increased number of applications that are being deployed in the Cloud, the question remains, is the Cloud ready to host applications adhering to telecommunication-grade requirements? In this paper we target the issue of the high-availability (HA) requirement in the Cloud from an application perspective. We present an approach that enables the dynamic incorporation of HA features into the deployed applications, which raises the discussion about the feasibility of having HA-as-a-Service, per application, in the Cloud.	agile software development;application checkpointing;cloud computing;high availability;middleware;programming paradigm;quality of service;representational state transfer;requirement;state (computer science);stepping level	Ali Kanso;Yves Lemieux	2013	2013 IEEE Sixth International Conference on Cloud Computing	10.1109/CLOUD.2013.24	embedded system;real-time computing;cloud computing;computer science;operating system;cloud testing;distributed computing	Visualization	-29.89345021129253	56.07298511138183	35103
78af8e7b0e66e98d2b1c1a88ccb9769d20d28d37	the organization of networks in plan 9	user interface;distributed system	In a distributed system networks are of paramount importance. This paper describes the implementation, design philosophy, and organization of network support in Plan 9. Topics include network requirements for distributed systems, our kernel implementation, network naming, user interfaces, and performance. We also observe that much of this organiza­ tion is relevant to current systems.	central processing unit;coupling (computer programming);distributed computing;endianness;plan 9 from bell labs;programmer;requirement;server (computing);user interface	David L. Presotto;Phil Winterbottom	1993			human–computer interaction;distributed computing;computer science;user interface	OS	-27.92474786766919	39.87434210176818	35169
9edbd80ada5cec84254e1815d45c4d02d17412c0	foregraph: exploring large-scale graph processing on multi-fpga architecture	large scale graph processing;multi fpga architecture	The performance of large-scale graph processing suffers from challenges including poor locality, lack of scalability, random access pattern, and heavy data conflicts. Some characteristics of FPGA make it a promising solution to accelerate various applications. For example, on-chip block RAMs can provide high throughput for random data access. However, large-scale processing on a single FPGA chip is constrained by limited on-chip memory resources and off-chip bandwidth. Using a multi-FPGA architecture may alleviate these problems to some extent, while the data partitioning and communication schemes should be considered to ensure the locality and reduce data conflicts. In this paper, we propose ForeGraph, a large-scale graph processing framework based on the multi-FPGA architecture. In ForeGraph, each FPGA board only stores a partition of the entire graph in off-chip memory. Communication over partitions is reduced. Vertices and edges are sequentially loaded onto the FPGA chip and processed. Under our scheduling scheme, each FPGA chip performs graph processing in parallel without conflicts. We also analyze the impact of system parameters on the performance of ForeGraph. Our experimental results on Xilinx Virtex UltraScale XCVU190 chip show ForeGraph outperforms state-of-the-art FPGA-based large-scale graph processing systems by 4.54x when executing PageRank on the Twitter graph (1.4 billion edges). The average throughput is over 900 MTEPS in our design and 2.03x larger than previous work.	computer memory;data access;field-programmable gate array;graph (abstract data type);locality of reference;pagerank;random access;randomness;scalability;scheduling (computing);throughput;virtex (fpga)	Guohao Dai;Tianhao Huang;Yuze Chi;Ningyi Xu;Yu Wang;Huazhong Yang	2017		10.1145/3020078.3021739	embedded system;parallel computing;computer science;theoretical computer science;operating system;distributed computing	HPC	-5.391027455588898	49.04277566883756	35175
ac35455b128baf4e280f2571160c242b67b3f85e	can seqlocks get along with programming language memory models?	read modify write;programming language;fences;sequence numbers;seqlocks;reader writer locks;data races;atomic operations;cache coherence;c;critical section;java;memory model	"""Seqlocks are an important synchronization mechanism and represent a significant improvement over conventional reader-writer locks in some contexts. They avoid the need to update a synchronization variable during a reader critical section, and hence improve performance by avoiding cache coherence misses on the lock object itself. Unfortunately, they rely on speculative racing loads inside the critical section. This makes them an interesting problem case for programming-language-level memory models that emphasize data-race-free programming. We analyze a variety of implementation alternatives within the C++11 memory model, and briefly address the corresponding issue in Java. In the process, we observe that there may be a use for """"read-dont-modify-write"""" operations, i. e. read-modify-write operations that atomically write back the original value, without modifying it, solely for the memory model consequences, and that it may be useful for compilers to optimize such operations."""	c++11;cache coherence;compiler;critical section;java;lock (computer science);memory model (programming);programming language;race condition;read-modify-write;seqlock;speculative execution	Helene Böhm	2012		10.1145/2247684.2247688	parallel computing;real-time computing;memory barrier;computer science;distributed computing	PL	-20.115472833286812	34.58398465664627	35200
55f027894a56cb60b2e43cd92c373a685f37c0d9	a stepwise approach to developing staged applications	staged events;event driven;concurrency;threads	The staged event-driven architecture (SEDA) can be seen as a milestone as regards integration of threads and events in a single model. By decomposing applications into sets of multi-threaded stages connected by event queues, SEDA allows for the use of each concurrency model where most appropriate. Inside each SEDA stage, the number and scheduling policy of threads can be adjusted to enhance performance. SEDA lends itself to parallelization on multi-cores and is well suited for many high-volume data stream processing systems and highly concurrent event processing systems. In this paper, we propose an extension to the staged model that decouples application design from specific execution environments, encouraging a stepwise approach for designing concurrent applications, similar to Foster’s PCAM methodology. We also present Leda, a platform that implements this extended model. In Leda, stages are defined purely by their role in application logic, with no concern for locality of execution, and are bound together through asynchronous communication channels, called connectors, to form a directed graph representing the flow of events inside the application. Decisions about the configuration of the application at execution time are delayed to later phases of the implementation process. Stages in the application graph can then be grouped to form clusters, and each cluster is mapped to an exclusive OS process, running on an arbitrary host. Finally, we discuss two example applications which we developed to evaluate the Leda platform.	business logic;complex event processing;concurrency (computer science);concurrent computing;directed graph;library of efficient data types and algorithms;locality of reference;operating system;parallel computing;scheduling (computing);staged event-driven architecture;stepwise regression;stream processing;thread (computing)	Tiago Salmito;Ana Lúcia de Moura;Noemi de La Rocque Rodriguez	2014	The Journal of Supercomputing	10.1007/s11227-014-1110-4	thread;parallel computing;real-time computing;concurrency;computer science;operating system;distributed computing;event-driven programming;programming language	HPC	-31.427401380962603	35.52526520907029	35243
de549fa2f12344649dff6440cb8d865050a14228	adaptive implementation selection in the skepu skeleton programming library	adaptive offline learning;gpu programming;skeleton programming;implementation selection;datavetenskap datalogi;computer science;automated performance tuning	In earlier work, we have developed the SkePU skeleton programming library for modern multicore systems equipped with one or more programmable GPUs. The library internally provides four types of implementations (implementation variants) for each skeleton: serial C++, OpenMP, CUDA and OpenCL targeting either CPU or GPU execution respectively. Deciding which implementation would run faster for a given skeleton call depends upon the computation, problem size(s), system architecture and data locality. In this paper, we present our work on automatic selection between these implementation variants by an offline machine learning method which generates a compact decision tree with low training overhead. The proposed selection mechanism is flexible yet high-level allowing a skeleton programmer to control different training choices at a higher abstraction level. We have evaluated our optimization strategy with 9 applications/kernels ported to our skeleton library and achieve on average more than 94% (90%) accuracy with just 0.53% (0.58%) training space exploration on two systems. Moreover, we discuss one application scenario where local optimization considering a single skeleton call can prove sub-optimal, and propose a heuristic for bulk implementation selection considering more than one skeleton call to address such application scenarios.	abstraction layer;adaptive algorithm;c++;cuda;central processing unit;computation;computational problem;decision tree;graphics processing unit;heuristic;high- and low-level;library (computing);locality of reference;machine learning;mathematical optimization;multi-core processor;online and offline;opencl api;openmp;overhead (computing);programmer;recursion;self-tuning;software portability;systems architecture	Usman Dastgeer;Lu Li;Christoph W. Kessler	2013		10.1007/978-3-642-45293-2_13	real-time computing;simulation;computer science;theoretical computer science	HPC	-5.607202358458748	45.6190067708619	35262
4bb67aa983e0a3bfcdee865694ddf1dac4f2968a	model driven advanced hybrid cloud services for big data: paradigm and practice		Advanced hybrid cloud services aim to serve big data applications by bridging multi-provider high performance cloud resources including direct connects, hypervisor bypassing VM interfaces, on premise clusters, parallel storage and high speed inter-cloud networks. We present a new “full-stack model driven orchestration” paradigm to integrate these diverse resources through semantic modeling and provide complex highend services through dynamic orchestrated workflows. We also present architectural design of a real-world orchestration system, VersaStack, that implements the paradigm as well as a case study for providing full-scale advanced hybrid cloud services in practice.	big data;bridging (networking);cloud computing;data-intensive computing;full scale;hypervisor;on-premises software;orchestration (computing);programming paradigm;semantic web;world-system	Xi Yang;Tom Lehman	2016	2016 Seventh International Workshop on Data-Intensive Computing in the Clouds (DataCloud)		real-time computing;computer science;distributed computing;world wide web	HPC	-28.82973497515493	56.93415880778253	35350
221f4059451deaf01e6d2acd52908a4e037154d9	temporal query processing and optimization in multiprocessor database machines	query processing;query optimization;temporal pattern;parallel processing	In this paper, we discuss issues involving temporal data fragmentation, temporal query processing, and query optimization in multiprocessor database machines. We propose parallel processing strategies, which are based on partitioning of temporal relations on timestamp values, for multi-way joins (e.g., complex temporal pattern queries) and optimization alternatives. We analyze the proposed schemes quantitatively, and show their advantages in computing complex temporal joins.	database;fragmentation (computing);mathematical optimization;multiprocessing;parallel computing	T. Y. Cliff Leung;Richard R. Muntz	1992			parallel processing;sargable;query optimization;query expansion;computer science;theoretical computer science;database;programming language;web search query;query language;spatial query	DB	-11.71098810909855	50.879235321137244	35422
2b3957c7acd894329c1fbc349a4ccbcaed4f2573	the information structure of indulgent consensus	distributed system;detectors;indulgent algorithm;computational complexity distributed processing fault tolerant computing;unreliable failure detector;information structure;crash failure;consensus;random number generator;fault tolerant;computer crashes;generic algorithm;distributed processing;random number generation;distributed computing;indexing terms;leader oracle;distributed abstraction;distributed computing computer fault tolerance complexity theory;fault tolerant computing;system recovery;resilience;fault tolerant systems;computational complexity;failure detector;fault detection;fault tolerance;safety;indulgent consensus algorithm;random oracle;asynchronous distributed system;modularity;algorithm design and analysis;lower bound;unreliable failure detector random number generator indulgent consensus algorithm distributed abstraction information structure asynchronous distributed system crash failure fault tolerance leader oracle modularity random oracle	"""To solve consensus, distributed systems have to be equipped with oracles such as a failure detector, a leader capability, or a random number generator. For each oracle, various consensus algorithms have been devised. Some of these algorithms are indulgent toward their oracle in the sense that they never violate consensus safety, no matter how the underlying oracle behaves. We present a simple and generic indulgent consensus algorithm that can be instantiated with any specific oracle and be as efficient as any ad hoc consensus algorithm initially devised with that oracle in mind. The key to combining genericity and efficiency is to factor out the information structure of indulgent consensus executions within a new distributed abstraction, which we call """"Lambda"""". Interestingly, identifying this information structure also promotes a fine-grained study of the inherent complexity of indulgent consensus. We show that instantiations of our generic algorithm with specific oracles, or combinations of them, match lower bounds on oracle-efficiency, zero-degradation, and one-step-decision. We show, however, that no leader or failure detector-based consensus algorithm can be, at the same time, zero-degrading and configuration-efficient. Moreover, we show that leader-based consensus algorithms that are oracle-efficient are inherently zero-degrading, but some failure detector-based consensus algorithms can be both oracle-efficient and configuration-efficient. These results highlight some of the fundamental trade offs underlying each oracle."""	chandra–toueg consensus algorithm;consensus (computer science);distributed computing;elegant degradation;failure detector;generic programming;hoc (programming language);oracle database;oracle machine;random number generation	Rachid Guerraoui;Michel Raynal	2004	IEEE Transactions on Computers	10.1109/TC.2004.1268403	fault tolerance;parallel computing;real-time computing;computer science;theoretical computer science;uniform consensus;distributed computing;chandra–toueg consensus algorithm;algorithm;psychological resilience	Theory	-22.759676876083326	44.62494460389623	35462
e9e3c56080b8354efb689a83c5003eda00817a23	towards automatic hbm allocation using llvm: a case study with knights landing		In this paper, we introduce a new LLVM analysis, called Bandwidth-Critical Data Analysis (BCDA), to decide when it is beneficial to allocate data in High-Bandwidth Memory (HBM) and then transform allocation calls into specific HBM allocation calls, for increased performance in parallel systems. High-Bandwidth Memory (HBM) is a new memory technology that features stacked 3D chips on processor dies.The well-known SSA-based compilation infrastructure for sequential and parallel languages LLVM will be used to detect frequently used data and patterns of memory accesses in order to decide on which level to allocate the data: HBM or DDR. BCDA core analysis counts the number of data uses and detects irregular and simultaneous accesses, generating a priority value for every variable. Using this priority value information, LLVM will generate memkind_alloc function calls, to transform mallocs to HBM allocations if HBM is present and a sufficient size of HBM is available.As a use case for validating our approach, we show how the Conjugate Gradient (CG) benchmark from the NAS Parallel suite can be optimized for the use of MCDRAM, as the HBM on the Knights Landing Xeon Phi processors is called. We implement BCDA in the LLVM compiler and apply it on CG to detect when it is beneficial to allocate data in the HBM. Then, we allocate the data in the MCDRAM using hbwmalloc library calls. Using the priority generated by BCDA, we achieved a 2.29× performance improvement using the LLVM compiler and 2.33× using Intel's compiler compared to the DDR version of CG.	benchmark (computing);central processing unit;coefficient;compiler;conjugate gradient method;convex conjugate;experiment;high bandwidth memory;knights;llvm;mcdram;profiling (computer programming);recursion (computer science);speedup;whole earth 'lectronic link;xeon phi	Dounia Khaldi;Barbara M. Chapman	2016	2016 Third Workshop on the LLVM Compiler Infrastructure in HPC (LLVM-HPC)		embedded system;parallel computing;real-time computing;computer science	HPC	-6.491792756075761	48.15725329793252	35504
ed2286cb1f43a49f153b8e9bbf06ac30fe3ce3f7	seeking time-composable partitions of tasks for cots multicore processors	real processor boards seeking time composable partitions cots multicore processors timing verification real time single core systems timing analysis execution time bound etb schedulability analysis step interference effects hardware shared resources circular dependence space domain;time composability task allocation in multicores cots multicores;processor scheduling;task allocation in multicores;resource management;cots multicores;multiprocessing systems formal verification;scheduling;multicore processing;program processors multicore processing timing processor scheduling hardware resource management scheduling;time composability;program processors;conference lecture;hardware;timing	The timing verification of real-time single core systems involves a timing analysis step that yields an Execution Time Bound (ETB) for each task, followed by a schedulability analysis step, where the scheduling attributes of the individual tasks, including the ETB, are studied from the system level perspective. The transition between those two steps involves accounting for the interference effects that arise when tasks contend for access to shared resource. The advent of multicore processors challenges the viability of this two-step approach because several complex contention effects at the processor level arise that cause tasks to be unable to make progress while actually holding the CPU, which are very difficult to tightly capture by simply inflating the tasks' ETB. In this paper we show how contention on access to hardware shared resources creates a circular dependence between the determination of tasks' ETB and their scheduling at runtime. To help loosen this knot we present an approach that acknowledges different flavors of time compos ability, examining in detail the variant intended for partitioned scheduling, which we evaluate on two real processor boards used in the space domain.	central processing unit;cobham's thesis;interference (communication);multi-core processor;ptc integrity;real-time clock;response time (technology);run time (program lifecycle phase);scheduling (computing);scheduling analysis real-time systems;serialization;static timing analysis	Gabriel Fernandez;Jaume Abella;Eduardo Quiñones;Luca Fossati;Marco Zulianello;Tullio Vardanega;Francisco J. Cazorla	2015	2015 IEEE 18th International Symposium on Real-Time Distributed Computing	10.1109/ISORC.2015.43	multi-core processor;embedded system;parallel computing;real-time computing;computer science;resource management;operating system;distributed computing;scheduling	Embedded	-8.990657528727276	59.05720582180372	35507
4c643c67b71bf2a27685d9eb6c14ee3842983ba6	an approach to formalization and analysis of message passing libraries	formal model;point to point;distributed programs;formal semantics;model checking;message passing interface;high performance computer;partial order reduction;message passing;reference standard	Message passing using libraries implementing the Message Passing Interface (MPI) standard is the dominant communication mechanism in high performance computing (HPC) applications. Yet, the lack of an implementation independent formal semantics for MPI is a huge void that must be filled, especially given the fact that MPI will be implemented on novel hardware platforms in the near future. To help reason about programs that use MPI for communication, we have developed a formal TLA+ semantic definition of the point to point communication operations to augment the existing standard. The proposed semantics includes 42 MPI functions, including all 35 point to point operations, many of which have not been formally modeled previously. We also present a framework to extract models from SPMD-style C programs, so that designers may understand the semantics of MPI by exercising short, yet pithy, communication scenarios written in C/MPI. In this paper, we describe (i) the TLA+ MPI model features, such as handling the explicit memory for each process to facilitate the modeling of C pointers, and some of the widely used MPI operations, (ii) the model extraction framework and the abstraction based simplifications made to the model that help facilitate explicit-state model checking of formal semantic definitions, (iii) a customized model checker for MPI that performs much faster model checking, and features a dynamic partial order reduction algorithm whose correctness is directly based on the formal semantics, and (iv) an error trail replay facility in the Visual Studio environment. Our effort has helped identify a few omissions in the MPI reference standard document. These benefits suggest that a formal semantic definition and exploration approach as described here must accompany every future effort in creating parallel and distributed programming libraries.	algorithm;correctness (computer science);distributed computing;lam/mpi;library (computing);message passing interface;microsoft visual studio;model checking;partial order reduction;point-to-point (telecommunications);spmd;semantics (computer science);supercomputer;tla+	Robert Palmer;Michael Delisi;Ganesh Gopalakrishnan;Robert Michael Kirby	2007		10.1007/978-3-540-79707-4_13	model checking;partial order reduction;message passing;point-to-point;computer science;message passing interface;theoretical computer science;formal semantics;distributed computing;programming language;algorithm	HPC	-13.095078416486418	34.073037056171145	35535
e122fb4f9386404fd3d91ddd757d4e9f3a8d61a4	performance evaluation of concurrency control algorithms in the sabre database computer	concurrency control	This paper compares the performances of two concurrency control algorithms: two-phase locking and timestamp ordering. This is achieved by solving analytically a queuing network which gives response times of the SABRE data base machine. It is shown that locking is better than timestamp ordering when there is a high probability of conflict between transactions. However, if the mean number of requests per transaction is high then timestamp ordering is the better technique; this is improved when the frequency of small transactions increases (i.e. number of requests having a geometrical distribution law).	algorithm;concurrency control;performance evaluation	Jacques Madelaine	1983			timestamp-based concurrency control;optimistic concurrency control;real-time computing;isolation;computer science;database;distributed computing;distributed concurrency control	DB	-20.024911730453493	46.833543220089126	35541
23620ed93a399b8889d4bf5185f8f6cf086eb9a6	elastic process optimization and scheduling in the cloud		Business processes in today’s industry are getting more complex and resource-intensive from day to day. Cloud computing offers methods and technologies that can help managing this steadily increase of complexity in the business process executions. A new class of Business Process Management Systems (BPMS), called elastic BPMS (eBPMS), is using Cloud computing resources for the enactment of so-called Elastic Processes (EP). Those eBPMS are combining traditional BPMS with Cloud controllers and are thus able to use Cloud resources for the EP enactment in an ad hoc manner. This paper focuses on our current work on a research eBPMS called ViePEP and discusses open research questions in the field of eBPMS.	amazon elastic compute cloud (ec2);business process;cloud computing;expectation propagation;hoc (programming language);open research;process optimization;scheduling (computing)	Philipp Waibel	2016			systems engineering;cloud computing;scheduling (computing);process optimization;distributed computing;computer science	HCI	-27.570344855848287	59.92359766152136	35548
0103a18b3d682c5338e61fc965c218e1e91e895e	mobility in distributed systems		Mobile agents are programs with the additional capability to move  between computers across a network connection. Movement implies that the  running program that constitutes an agent moves from one system to  another, taking with the agent the code that constitutes the agent as  well as the state information of the agent. The movement of agents may  be user-directed or self-directed (i.e. autonomous). In the case of  user-directed movement, agents are configured with an itinerary that  dictates the movement of the agents. In the case of self-directed  movement, agents may move in order to better optimize their operation.  Mobility may also be a combination of user- and self-directedness.  Mobile agents provide three basic capabilities: mobile code, mobile  computation, and mobile state. These three capabilities are shown in the  figure below. Each of the capabilities is an evolution of previously  well-established notions in distributed and networked systems.           Mobile computation involves moving a computation from one system to  another. This capability is an evolution of remote computation, which  allows a system to tap into the computational resources of another  system over a network connection. One of the original mechanisms for  remote computation was Remote Procedure Call (RPC). Java Remote Method  Invocation (RMI) is another example of remote computation as are  servlets and stored procedures.  The difference between mobile and remote computation is that mobile  computation supports network disconnection. In a traditional remote  computation model, the system requesting the service (the client) must  remain connected to the system providing the service (the server) for  the duration of the remote computation operation. Additionally,  depending on the interface exposed by the server, an interaction can  require an arbitrary number of messages between client and server. If  network connectivity is lost, the remote computation will become an  orphaned computation that will either be terminated or whose results  will be discarded. A mobile computation, on the other hand, is an  autonomous entity. Once the computation moves from the first system  (which may nominally be called the client) to the second system (the  server), the computation continues to execute on the server even if the  client becomes disconnected. The agent returns to the client with the  results of the computation when (and if) the connectivity is recovered.  Mobile Code is the ability to move code from one system to another. The  code may be either source code that is compiled or interpreted or binary  code. Binary code may further be either machine dependent or be some  intermediate, machine-independent form.  Mobile code is used in other contexts besides mobile agents. For  example, system administrators use mobile code in order to remotely  install or upgrade software on client systems. Similarly, a web browser  uses mobile code to pull an applet or script to execute as part of a web  page.  Code may be mobile in two different ways: push and pull. In the push  model, the system sending the code originates the code transfer  operation whereas in the pull model, the system receiving the code  originates the code transfer operation. An example of the pull model is a  Web browser downloading components such as applets or scripts. Remote  installation is an example of the push model. Mobile agent systems use  the push model of code mobility.  Pull mobility is often considered to be more secure and trustworthy  because the host receiving the code is the one that requested the code.  Usually, the origin of the request lies in some action carried out by a  user of the system and hence pull mobility is superficially more secure.  Push mobility on the other hand allows a system to send code to the  receiving system at unexpected or unmonitored times. Hence push mobility  is less trustworthy from a user’s point of view. In practice the  overwhelming majority of security exploits encountered in distributed  systems originates in careless user actions such as running mail  attachments.  Mobile code allows systems to be extremely flexible. New capabilities  can be downloaded to systems on the fly thereby dynamically adding  features or upgrading existing features. Moreover, if capabilities can  be downloaded on demand, temporarily unused capabilities can also be  discarded. Swapping capabilities on an as-needed basis allows systems to  support small memory constrained devices. Discarding capabilities after  use can also help improve system security.  Mobile state is an evolution of state capture, which allows the  execution state of a process to be captured. State capture has been  traditionally used for checkpointing systems to protect against  unexpected system failure. In the event of a failure, the execution of a  process can be restarted from the last checkpointed state thereby not  wasting time by starting from the very beginning. Checkpointing is thus  very useful for long-running processes. Operating system research has  investigate capturing entire process states, a variant of checkpointing,  for load balancing purposes in the early 1980s, but that avenue of  research proved to be a dead-end due to coarse granularity of process  and semantics problem due to the impossibility of capturing operating  system resources such as open file descriptors.  Mobile state allows the movement of the execution state of an agent to  another system for continued execution. The key advantage provided by  mobile state is that the execution of the agent does not need to restart  after the agent moves to a new host. Instead, the execution continues  at the very next instruction in the agent.  Not all mobile agent systems provide support for state mobility. The  term strong mobility is used to describe systems that can capture and  move execution state with the agent. Operationally, strong mobility  guarantees that all variables will have identical values and the program  counter will be at the same position. Weakly mobile-agent systems, on  the other hand, usually support the capture of most of a program’s data,  but restart the program from a predefined program point and thus  require some programmer involvement at each migration. The advantage of  strong mobility is that the result of migrating is well defined and  easier to understand, but its disadvantage is that it is much more  complex to implement efficiently.  The most important advantage provided by strong mobility is the ability  to support external asynchronous migration requests (also known as  forced mobility). This allows entities other than the agent (such as  other system components, an administrator, or the owner) to request that  an agent be moved. Forced mobility is useful for survivability,  load-balancing, forced isolation, and replication for fault-tolerance,  and is an important aspect of the agile computing approach.  For some applications, the technical issues of software mobility are  dwarfed by security issues. Despite fits and starts, mobile agents  herald emerging technological solutions. This special issue provides a  good sampling of this frontier. It is our hope and desire that the  software industry embrace the capabilities offered by mobile agents. In  the future, we hope to see general purpose programming languages that  support mobility as well as large scale development platforms and  toolkits.  Niranjan Suri  Institute of Human and Machine Cognition  Henry Hexmoor  Sourthern Illinois University		Niranjan Suri;Henry Hexmoor	2006	Scalable Computing: Practice and Experience	10.12694/scpe.v7i4.381	real-time computing;mobile search;simulation;computer science;mobile agent;distributed computing;code mobility;remote evaluation	HPC	-33.13621932225746	41.48125813755297	35589
68f29355c1be24cf229967e70898942958cffebb	the least-dirty-first cache replacement policy for phase-change memory	last level cache;cache architecture;phase change memory;replacement policy	Phase-change memory (PCM) is a promising non-volatile memory technology that is anticipated to be used as main memory of computer systems in the not too far future. However, PCM has relatively long write latency and limited write endurance compared to DRAM. To mitigate these limitations of PCM, this paper presents a new last-level cache replacement policy that reduces the write traffic to PCM memory by considering the dirtiness of cache blocks when making a replacement decision. Specifically, the proposed policy tracks the dirtiness of a block at the granularity of a sub-block (i.e., cache line) and replaces a block with the least number of dirty sub-blocks among blocks not recently used. Experimental results with various workloads show that the proposed policy reduces the amount of data written to PCM by 26% and 17% on average and up to 52% and 33% compared to NRU and RRIP, respectively, without performance degradations. It also extends the lifespan of PCM by 31% and reduces the energy consumption of PCM by 19% on average.	cpu cache;computer data storage;dynamic random-access memory;non-volatile memory;page replacement algorithm;phase-change memory;volatile memory	Seunghoon Yoo;Eunji Lee;Hyokyung Bahn	2014		10.1145/2554850.2555023	least frequently used;parallel computing;real-time computing;cache coloring;page cache;cpu cache;phase-change memory;computer hardware;cache;computer science;write-once;cache algorithms;cache pollution;cache-only memory architecture	Arch	-9.72344840083992	54.29397098566589	35592
858f83da66c3025ee0d3dea342f8803049a05c0e	using metrics to optimize a high performance intelligent image processing code	level 2;multi core processor;pcid;shared memory;image processing;performance;multi code;fft;hpc;system design;intelligent system;heuristic evaluation;optimization;latency;high performance	Optimizing the execution of intelligent codes on high performance computer's (HPC's) has become more challenging as the numbers of processors increases. Single processors in many HPC's have been replaced with dual processors, and more recently multiprocessors. This, combined with the inherent complexities of multi-core processors, has made the processing of intelligent codes even more complex on the latest HPC's. The coming availability of thousands of processors in more affordable medium sized HPC's offers the potential for improved performance for codes that can scale sufficiently to take advantage of hundreds of teraflops. Additionally, techniques for harnessing the performance potential of multi-code processors require the appropriate location of data in shared memories, or even shared level-2 caches, and can afford additional orders of magnitude performance increases. The key to designing code that uses the available teraflops wisely is an understanding of the application's behavior. For intelligent systems, whose behavior may depend on heuristics evaluated at runtime, measurements and profiling runs provide the basis for system design decisions, regarding distribution of data and processing. This paper focuses on the metrics needed to optimize intelligent codes, and how a specific image processing code was instrumented to produce the required metrics.	central processing unit;code;computational photography;flops;heuristic (computer science);image processing;multi-core processor;optimizing compiler;profiling (computer programming);run time (program lifecycle phase);supercomputer;systems design	Scott E. Spetka;Susan Emeny;George O. Ramseyer;Richard W. Linderman	2008		10.1145/1774674.1774695	parallel computing;real-time computing;computer hardware;computer science	HPC	-6.836017131621362	46.85441125952159	35593
00c8e444697fb8efba41d7a6ad6b22ee6e05e14f	evaluating the performance and energy efficiency of n-body codes on multi-core cpus and gpus	energy efficiency;n body simulations astronomical;multi threading;gpus;paper;n body simulation performance energy efficiency multi core cpus gpus hyper threading;performance;niobium;n body simulation;software performance evaluation;tesla k20c performance evaluation energy efficiency n body codes multicore cpus multicore gpus n body simulations computation intensive applications scientific fields parallel n body implementations xeon e5620 cpu hyper threading energy usage reduction gpu based acceleration;energy efficiency graphics processing units niobium runtime energy consumption force instruction sets;software performance evaluation graphics processing units multiprocessing systems multi threading n body simulations astronomical power aware computing;runtime;force;nvidia geforce gtx 480;cuda;power aware computing;energy consumption;graphics processing units;nvidia;multiprocessing systems;computer science;hyper threading;multi core cpus;instruction sets	N-body simulations are computation-intensive applications that calculate the motion of a large number of bodies under pair-wise forces. Although different versions of n-body codes have been widely used in many scientific fields, the performance and energy efficiency of various n-body codes have not been comprehensively studied, especially when they are running on newly released multi-core CPUs and GPUs (e.g., Tesla K20). In this paper, we evaluate the performance and energy efficiency of five parallel n-body implementations on two different multi-core CPU systems and on two different types of GPUs. Our experimental results show that up to 71% of the energy can be saved by using all cores of a Xeon E5620 CPU instead of only one. We find hyper-threading to be able to further reduce the energy usage and runtime, but not by as much as adding more cores does. Finally, our experiments illustrate that GPU-based acceleration using a Tesla K20c can boost the performance and energy efficiency by orders of magnitude.	central processing unit;code;computation;experiment;graphics processing unit;hyper-threading;multi-core processor;simulation;thread (computing);xeon phi	Ivan Zecena;Martin Burtscher;Tongdan Jin;Ziliang Zong	2013	2013 IEEE 32nd International Performance Computing and Communications Conference (IPCCC)	10.1109/PCCC.2013.6742789	niobium;computer architecture;parallel computing;multithreading;computer hardware;performance;computer science;operating system;n-body simulation;instruction set;efficient energy use;hyper-threading;force	HPC	-4.759045666054571	43.6663051750157	35609
42725af7cdd3c597ed8acc5c2c4fa4799cc3b891	part: a partitioning tool for efficient use of distributed systems	processor performance;multiprocessor interconnection networks;distributed system;performance evaluation;decomposition tool;execution time;finite element analysis computational complexity simulated annealing computer networks performance evaluation;part;high speed networks;performance;distributed computing;power system interconnection;geographically distributed supercomputers interconnection;partitioning tool;simulated annealing;interconnection network;computer networks;large scale;computational modeling;computational complexity;finite element based problems;execution time part partitioning tool distributed systems geographically distributed supercomputers interconnection high speed networks processor performance wide area network decomposition tool performance computational complexity simulated annealing finite element based problems;finite element analysis;distributed systems;power system interconnection supercomputers high speed networks computer networks distributed computing large scale systems multiprocessor interconnection networks wide area networks computational complexity computational modeling;supercomputers;wide area network;geographic distribution;wide area networks;large scale systems	The interconnection of geographically distributed supercomputers via high-speed networks allows users to access the needed compute power for large-scale, complex applications. For efficient use of such systems, the variance in processor performance and network (i.e., interconnection network versus wide area network) performance must be considered. In this paper, we present a decomposition tool, called PART, for distributed systems. PART takes into consideration the variance in performance of the networks and processors as well as the computational complexity of the application. This is achieved via the parameters used in the objective function of simulated annealing. The initial version of PART focuses on finite element based problems. The results of using PART demonstrate a 30% reduction in execution time as compared to using conventional schemes that partition the problem domain into equal-sized subdomains.	distributed computing	Jian Chen;Valerie E. Taylor	1997		10.1109/ASAP.1997.606838	computer architecture;parallel computing;simulated annealing;performance;computer science;theoretical computer science;finite element method;distributed computing;computational complexity theory;computational model	EDA	-6.610276908321746	40.2984258452568	35635
2a4cfb32e9f2f6b1b3ed08671dbc5f933b062825	the ifs model: a parallel production weather code	spectral transform;atmospheric general circulation modeling;semi lagrangian transport;message passing;weather prediction;shared memory parallel computing	Abstract   The integrated Forecasting System (IFS) of the European Centre for Medium-range Weather Forecasts (ECMWF) is a spectral weather forecasting model, which daily produces weather forecasts on up to 16 processors of a CRAY C90. This paper describes the shared-memory implementation of the code and the subsequent development that has been carried out in order to generate a parallel version, suitable for a scalable distributed-memory architecture with many processors. Performance results presented for several vector and parallel systems indicate that the parallelization effort has been successful in achieving good performance and high efficiency.		Saulo R. M. Barros;David Dent;Lars Isaksen;G. Mozdzynski;Fritz Georg Wollenweber	1995	Parallel Computing	10.1016/0167-8191(96)80002-0	parallel computing;message passing;simulation;computer science;programming language;weather research and forecasting model	HPC	-6.560441763892846	35.4199146341763	35673
f561fbc2488559f3a850c5705339c1064758eee7	free atomic consistency in storage class memory with software based write-aside persistence	in memory database;stream processing;social media	"""This paper describes a lightweight software library to solve the challenges [5, 3, 1, 4, 2] of programming storage class memory (SCM). It provides primitives to demarcate failure-atomic code regions. SCM loads and stores within each de-marcated code region (called a """"wrap"""") are routed through the library, which buffers updates and transmits them to SCM locations asynchronously while allowing their speedy propagation from writers to readers through CPU caches."""	c syntax;cpu cache;central processing unit;library (computing);persistence (computer science);routing;software propagation	Ellis Giles;Kshitij Doshi;Peter J. Varman	2015		10.1145/2742854.2742902	parallel computing;real-time computing;computer science;database	OS	-13.010009689172934	47.5303592810295	35720
a70a7f60d3d3dadb9c2c4e0ff5ef840ab0011a8b	java embedded real-time systems: an overview of existing solutions	software portability;programming language;software portability embedded systems java reviews;execution environment java embedded real time systems overview platform independence dynamic loading distributed systems;real time;embedded real time systems;garbage collection;embedded systems;scheduling;embedded;java real time systems nist packaging software maintenance proposals computer languages dynamic programming art software systems;reviews;java;real time and embedded systems	Java is a programming language with features not found in traditional languages such as platform independence and dynamic loading. Because of this, Java is extending and beginning to be used in many new environments. In particular, the advantages that Java provides make it a good candidate for distributed, real-time and embedded systems. However, Java presents some problems regarding its use in embedded and real-time environments. In this paper, we examine the state-of-the-art in the development of embedded realtime systems using Java. We analyze the limits that the Java language and its execution environment present to develop real-time and embedded systems, and we present current research in this area aimed at solving these limits.	apl;application programming interface;compiler;dynamic loading;embedded system;garbage collection (computer science);http 404;high- and low-level;java classloader;just-in-time compilation;multithreading (computer architecture);programming language;real time java;real-time clock;real-time computing;real-time locating system;real-time operating system;real-time transcription;thread (computing)	M. Teresa Higuera-Toledano;Valérie Issarny	2000		10.1109/ISORC.2000.839556	software portability;embedded operating system;java card;real-time computing;jsr 94;java concurrency;computer science;operating system;strictfp;embedded java;real time java;garbage collection;programming language;java;scheduling;scala;java annotation	Embedded	-28.847099220656823	37.51739857912183	35777
7fdb458328695931458c71058b1725c15f5ee39b	a gpu-based heart simulator with mass-spring systems and cellular automaton	mass spring systems;gpu;cuda;heart simulation;cellular automata	This work proposes an electro-mechanical simulator of the cardiac tissue, so that its main feature is the low computational cost. This is necessary to run real-time simulations and on the fly applications. In order to achieve this, we used cellular automata and mass-spring systems to model the cardiac behavior, and furthermore parallelize the code to run in graphics processing unit (GPU) with compute unified device architecture. Sequentially, our simulator was quite faster than traditional partial differential equations simulators. In addition, we performed different load tests to evaluate our code behavior in GPUs, and spotted its potentials and bottlenecks.	algorithmic efficiency;analysis of algorithms;automata theory;bottleneck (software);cuda;cellular automaton;computation;computer graphics;experiment;graphics processing unit;on the fly;real-time clock;real-time computing;real-time transcription;simulation;software propagation;time complexity	Ricardo Silva Campos;Marcelo Lobosco;Rodrigo Weber dos Santos	2014	The Journal of Supercomputing	10.1007/s11227-014-1199-5	cellular automaton;computational science;parallel computing;simulation;computer science;theoretical computer science;operating system;algorithm	Robotics	-5.8239898069721185	36.60270911898685	35794
395faf7827ce6fbb20d894a6e0e6f4be839aebcb	store vulnerability window (svw): re-execution filtering for enhanced load optimization	cache storage;optimisation;multi threading;store vulnerability window;bloom filter;processor scheduling;queueing theory;storage management;pipelines buffer storage information filtering information filters information science computer architecture engines retirement costs yarn;cache storage processor scheduling dynamic scheduling storage management optimisation queueing theory multi threading;svw implementation store vulnerability window re execution filtering enhanced load optimization load store unit dynamically scheduled processor load optimizations load queue scalability intra thread memory ordering inter thread memory ordering store queue scalability redundant loads cache bandwidth monotonic store sequence numbering bloom filtering;dynamic scheduling;dynamically scheduled processors	The load-store unit is a performance critical component of a dynamically-scheduled processor. It is also a complex and non-scalable component. Several recently proposed techniques use some form of speculation to simplify the load-store unit and check this speculation by re-executing some of the loads prior to commit. We call such techniques load optimizations. One recent load optimization improves load queue (LQ) scalability by using re-execution rather than associative search to check speculative intra- and inter- thread memory ordering. A second technique improves store queue (SQ) scalability by speculatively filtering some load accesses and some store entries from it and re-executing loads to check that speculation. A third technique speculatively removes redundant loads from the execution engine; re-execution detects false eliminations. Unfortunately, the benefits of a load optimization are often mitigated by re-execution itself. Re-execution contends for cache bandwidth with store commit, and serializes load re-execution with subsequent store commit. If a given load optimization requires a sufficient number of load re-executions, the aggregate re-execution cost may overwhelm the benefits of the technique entirely and even cause drastic slowdowns. Store Vulnerability Window (SVW) is a new mechanism that significantly reduces the re-execution requirements of a given load optimization. SVW is based on monotonic store sequence numbering and an adaptation of Bloom filtering. The cost of a typical SVW implementation is a 1KB buffer and a 16-bit field per LQ entry. Across the three optimizations we study, SVW reduces re-executions by an average of 85%. This reduction relieves cache port contention and removes many of the dynamic serialization events that contribute the bulk of re-executionýs cost, allows these load optimizations to perform up to their full potential. For the speculative SQ, this means the chance to perform at all, as without SVW it posts significant slowdowns.	16-bit;aggregate data;application checkpointing;auto-tune;bloom;central processing unit;data dependency;david ceperley;entity–relationship model;han unification;ia-64;ibm notes;ieee micro;instruction scheduling;instruction window;interrupt latency;kilobyte;letter-quality printer;load/store architecture;locality of reference;mathematical optimization;memory dependence prediction;memory ordering;microarchitecture;microprocessor;ocean observatories initiative;project milo;r10000;realms of the haunting;register file;requirement;scalability;scheduling (computing);serialization;sound quality;speculative execution;superscalar processor;very-large-scale integration;vulnerability (computing);window function;word-sense disambiguation	Amir Roth	2005	32nd International Symposium on Computer Architecture (ISCA'05)	10.1109/ISCA.2005.48	computer architecture;parallel computing;real-time computing;multithreading;dynamic priority scheduling;computer science;bloom filter;operating system;distributed computing;programming language;queueing theory;load/store architecture	Arch	-14.650392521175556	49.78329281075085	35806
b9e79fd4131d6cbd0fdd47b7f1cd36bb219d9b11	linear array with a reconfigurable pipeline bus system - concepts and applications				Yi Pan;Keqin Li	1996			computer science;parallel computing;distributed computing	EDA	-9.663303616645182	42.7054377009469	35835
145174de8676bc094896b5c3d9fa7f77d8804fab	efficient management of complex striped files in active storage	scientific application;general and miscellaneous mathematics computing and information science;memory management;performance;complex data;network traffic;file system;memory devices active storage parallel filesystems necdf;data base management;supercomputers	Active Storage provides an opportunity for reducing the bandwidth requirements between the storage and compute elements of current supercomputing systems, and leveraging the processing power of the storage nodes used by some modern file systems. To achieve both objectives, Active Storage allows certain processing tasks to be performed directly on the storage nodes, near the data they manage. However, Active Storage must also support key requirements of scientific applications. In particular, Active Storage must be able to support striped files and files with complex formats (e.g., netCDF). In this paper, we describe how these important requirements can be addressed. The experimental results on a Lustre file system not only show that our proposal can reduce the network traffic to near zero and scale the performance with the number of storage nodes, but also that it provides an efficient treatment of striped files and can manage files with complex data structures.	data structure;lustre;netcdf;network packet;requirement;supercomputer;usability	Juan Piernas;Jarek Nieplocha	2008		10.1007/978-3-540-85451-7_72	parallel computing;storage area network;converged storage;computer hardware;performance;object storage;computer science;operating system;database;distributed computing;programming language;information repository;complex data type;memory management	OS	-19.40559360771856	52.78857525280182	35865
de599b86f32402b9d5eeb84da2b263111145f22b	tools for scalable parallel program analysis - vampir vng and dewiz	tracing;program analysis;scalability;performance tuning;debugging;near real time;distributed computing	Large scale high-performance computing systems pose a tough obstacle for todays program analysis tools. Their demands in computational performance and memory capacity for processing program analysis data exceed the capabilities of standard workstations and traditional analysis tools. The sophisticated approaches of Vampir NG (VNG) and the Debugging Wizard DeWiz intend to provide novel ideas for scalable parallel program analysis. While VNG exploits the power of cluster architectures for near real-time performance analysis, DeWiz utilizes distributed computing infrastructures for distinct analysis activities. A comparison of these two complimentary approaches delivers some promising ideas for future solutions in the area of parallel and distributed program analysis.	debugging;distributed computing;parallel computing;program analysis;real-time clock;real-time computing;scalability;supercomputer;workstation	Holger Brunst;Dieter Kranzlmüller;Wolfgang E. Nagel	2004			parallel computing;program analysis;performance tuning;scalability;computer science	HPC	-7.804715434491643	45.412679893971955	35919
26f1ed27f484cda8f1f19a0418bfc61696c238da	automated benchmarking of functional data structures	decision tree;structure programme;ingenieria logiciel;software engineering;functional programming;analisis programa;estructura programa;estructura datos;genie logiciel;structure donnee;functional data;programmation fonctionnelle;program analysis;analyse programme;programacion funcional;program structure;data structure;random access	"""Despite a lot of recent interest in purely functional data structures, for example Ada93, Oka95, BO96, Oka96, OB97, Erw97], few have been benchmarked. Of these, even fewer have their performance qualiied by how they are used. But how a data structure is used can signiicantly aaect performance. This paper makes three original contributions. (1) We present an algorithm for generating a benchmark according to a given use of data structure. (2) We compare use of an automated tool based on this algorithm, with the traditional technique of hand-picked benchmarks, by benchmarking six implementations of random-access list using both methods. (3) We use the results of this benchmarking to present a decision tree for the choice of random-access list implementation, according to how the list will be used. 1 Motivation Recent years have seen renewed interest in purely functional data structures: sets Ada93], random-access lists Oka95], priority queues BO96], arrays OB97], graphs Erw97], and so on. But, empirical performance receives little attention, and is usually based on a few hand-picked benchmarks. Furthermore, the performance of a data structure usually varies according to how it is used, yet this is mostly overlooked. For example, Okasaki Oka95] uses ve simple benchmarks to measure the performance of diierent implementations of a list providing random access. He points out that three of the benchmarks use random access, and two do not. However, all the benchmarks are single-threaded. How do the data structures perform under non-single-threaded use? We simply do not know. Okasaki presents many new data structures in his thesis Oka96], but without measurements of practical performance. He writes in a section on future work: \The theory and practice of benchmarking functional] data structures is still in its infancy."""" How can we make benchmarking easier and more reliable? A major problem is nding a range of benchmarks that we know use the data structure in diierent ways. If we could generate a benchmark according to a well-deened use of the data structure, we could easily make a table listing performance against a range of uses."""	access control list;algorithm;benchmark (computing);decision tree;priority queue;purely functional data structure;random access;thread (computing)	Graeme E. Moss;Colin Runciman	1999		10.1007/3-540-49201-1_1	program analysis;data structure;computer science;decision tree;data mining;database;programming language;functional programming;algorithm;random access	Metrics	-16.835934397363438	33.88781698877309	35986
f6a02a055a5473b4f4d66bfb4a7aeabf3ee32560	towards deployment-time dynamic analysis of server applications	partial dynamic analysis;conference paper;n version execution	Bug-finding tools based on dynamic analysis (DA), such as Valgrind or the compiler sanitizers provided by Clang and GCC, have become ubiquitous during software development. These analyses are precise but incur a large performance overhead (often several times slower than native execution), which makes them prohibitively expensive to use in production. In this work, we investigate the exciting possibility of deploying such dynamic analyses in production code, using a multi-version execution approach.	clang;dynamic program analysis;gnu compiler collection;machine code;overhead (computing);server (computing);software deployment;software development;valgrind	Luís Pina;Cristian Cadar	2015		10.1145/2823363.2823372	real-time computing;computer science;operating system;database	SE	-21.670133668633447	37.05013397305397	36020
e66f3584f71efad5fe4c130da85b5a734dd30238	interfacing wide-area network computing and cluster management software: condor, dqs and pbs via punch	condor;collision mitigation;management system;access point;portable batch system;network operating systems;network operating systems wide area networks workstation clusters internetworking computer network management;wide area network computing;resource management;traffic control;pbs;computer networks;telecommunication traffic;wan wide area network computing cluster management software condor dqs distributed queueing service pbs portable batch system transparent interfacing punch purdue university network computing hubs;distributed queueing service;transparent interfacing;wan;purdue university network computing hubs;engineering management;computer network management;internetworking;writing;cluster management software;workstation clusters;punch;dqs;computer interfaces;wide area network;network computing;computer interfaces computer networks computer network management telecommunication traffic traffic control collision mitigation resource management engineering management hardware writing;wide area networks;hardware	Software: Condor, DQS and PBS via PUNCH Sumalatha Adabala Nirav H. Kapadia Jos e A. B. Fortes School of Electrical and Computer Engineering, Purdue University fadabala, kapadia, fortesg@purdue.edu Abstract This paper outlines the issues that must be addressed in order to allow cluster management systems such as Condor, DQS, and PBS to be transparently used via a wide-area network-computing system such as PUNCH.	cluster manager;computer engineering;network computing system;punched card	Sumalatha Adabala;Nirav H. Kapadia;José A. B. Fortes	2000		10.1109/HPDC.2000.868670	embedded system;parallel computing;real-time computing;computer science;resource management;operating system;portable batch system;management system;distributed computing;management;writing;computer network	DB	-27.60979961478565	50.88772026858182	36082
62f5f426693eca47d11c4b9f38715383bb7ab7d6	a flexible hybrid concurrency control model for collaborative applications in large scale settings	collaborative work;collaborative application;large scale;concurrency control	"""Large-scale collaborative applications are difficult to build because of their high concurrency control needs and the heterogeneity of the underlying architecture. Due to these difficulties, only a few large-scale applications have been developed, such as Usenet or irc. To facilitate the realisation of such applications, we propose a more precise definition of the application's needs, in order to provide a good """"quality"""" of cooperation when it is needed, and cheaper cooperation when it is acceptable. The model of LaSCoW (Large Scale Collaborative Work) allows the applications to be partitioned into separate consistency domains, each domain implementing its own collaboration policy."""	concurrency (computer science);concurrency control;internet relay chat;usenet	Guillaume Pierre;Clive K. Liu	1996		10.1145/504450.504498	real-time computing;computer science;database;distributed computing	DB	-26.37948228486527	49.34601344403104	36107
6ca1d8753164d67e8c600296cba3ea02991133d8	the low latency fault tolerance system	bepress selected works;software fault tolerance;leader follower replication;strong replica consistency;distributed systems;message ordering;membership;virtual synchrony	The Low Latency Fault Tolerance (LLFT) system provides fault tolerance for distributed applications within a local-area network, using a leader-follower replication strategy. LLFT provides application-transparent replication, with strong replica consistency, for applications that involve multiple interacting processes or threads. Its novel system model enables LLFT to maintain a single consistent infinite computation, despite faults and asynchronous communication. The LLFT Messaging Protocol provides reliable, totally-ordered message delivery by employing a group multicast, where the message ordering is determined by the primary replica in the destination group. The Leader-Determined Membership Protocol provides reconfiguration and recovery when a replica becomes faulty and when a replica joins or leaves a group, where the membership of the group is determined by the primary replica. The Virtual Determinizer Framework captures the ordering information at the primary replica and enforces the same ordering of non-deterministic operations at the backup replicas. LLFT does not employ a majority-based, multiple-round consensus algorithm and, thus, it can operate in the common industrial case where there is a primary replica and only one backup replica. The LLFT system achieves low latency message delivery during normal operation and low latency reconfiguration and recovery when a fault occurs.	backup;byzantine fault tolerance;chandra–toueg consensus algorithm;computation;distributed computing;interaction;interrupt latency;multicast	Wenbing Zhao;P. M. Melliar-Smith;Louise E. Moser	2010	Comput. J.	10.1093/comjnl/bxs131	parallel computing;real-time computing;computer science;operating system;database;distributed computing;virtual synchrony;software fault tolerance	Networks	-23.043521871172683	45.79040710839782	36116
651022b61907695400e2e6c13aeb5c5184cf1228	energy-aware flash memory management in virtual memory system	index terms—embedded systems;energy-efficient;nand flash memory;virtual memory.	The traditional virtual memory system is designed for decades assuming a magnetic disk as the secondary storage. Recently, flash memory becomes a popular storage alternative for many portable devices with the continuing improvements on its capacity, reliability and much lower power consumption than mechanical hard drives. The characteristics of flash memory are quite different from a magnetic disk. Therefore, in this paper, we revisit virtual memory system design considering limitations imposed by flash memory. In particular, we focus on the energy efficient aspect since power is the first-order design consideration for embedded systems. Due to the write-once feature of flash memory, frequent writes incur frequent garbage collection thereby introducing significant energy overhead. Therefore, in this paper, we propose three methods to reduce writes to flash memory. The HotCache scheme adds an SRAM cache to buffer frequent writes. The subpaging technique partitions a page into subunits, and only dirty subpages are written to flash memory. The duplication-aware garbage collection method exploits data redundancy between the main memory and flash memory to reduce writes incurred by garbage collection. We also identify one type of data locality that is inherent in accesses to flash memory in the virtual memory system, intrapage locality. Intrapage locality needs to be carefully maintained for data allocation in flash memory. Destroying intrapage locality causes noticeable increases in energy consumption. Experimental results show that the average energy reduction of combined subpaging, HotCache, and duplication-aware garbage collection techniques is 42.2%.	auxiliary memory;computer data storage;computer multitasking;data redundancy;embedded system;first-order predicate;flash memory;garbage collection (computer science);hard disk drive;locality of reference;magnetic storage;memory management;mobile device;openvms;overhead (computing);page (computer memory);page fault;paging;static random-access memory;subpage;systems design	Han-Lin Li;Chia-Lin Yang;Hung-Wei Tseng	2008	IEEE Transactions on Very Large Scale Integration (VLSI) Systems	10.1109/TVLSI.2008.2000517	flash file system;embedded system;interleaved memory;semiconductor memory;parallel computing;thrashing;index term;static random-access memory;cpu cache;logic gate;memory refresh;computer hardware;computer science;virtual memory;operating system;integrated circuit;flash memory emulator;first-order logic;computer data storage;reliability;volatile memory;computer memory;overlay;universal memory;efficient energy use;extended memory;flat memory model;garbage collection;registered memory;low-power electronics;memory map;mean;systems design;memory management	Embedded	-9.496222903209445	54.81174847701479	36179
266707348233ceb3e381a7337dfe89d4809cc813	combining contracts and exemplar-based programming for class hiding and customization	customized class;library implementation;combining contract;exemplar-based class factory;object-oriented library;service class selection;wrong class;class hiding;exemplar-based programming;multiple service class;similar service class;service implementation;implementation strategy;virtual machines;real time;object oriented;database system	For performance reasons, client applications often need to influence the implementation strategies of libraries whose services they use. If an object-oriented library contains multiple service classes customized for different usage patterns, applications can influence service implementations by instantiating the customized classes that match their needs. However, with many similar service classes, it can be difficult for applications to determine which classes to instantiate. Choosing the wrong class can result in very subtle errors since a customized class might use optimizations that work only over a restricted domain. In this paper, we show how client-side software contracts and exemplar-based class factories can be used to construct customized server objects. By expressing priorities and requirements in contracts, clients can delegate service class selection to the library and thereby avoid implicit dependencies on the library implementation. We have used this approach in the implementation of a real-time database system.	abstract factory pattern;client-side;compiler;database;design by contract;factory method pattern;library (computing);naruto shippuden: clash of ninja revolution 3;organizing (structure);real-time clock;real-time operating system;requirement;server (computing);tree (data structure)	Victor B. Lortz;Kang G. Shin	1994		10.1145/191080.191150	real-time computing;computer science;virtual machine;database;programming language;object-oriented programming	PL	-26.332830492821756	39.73484514487203	36191
550caeea3d541c5d43be01e10016c907dc83d05b	compiler-assisted overlapping of communication and computation in mpi applications	analytical models;bayes methods;runtime;computational modeling;optimization;time frequency analysis;benchmark testing	The performance of distributed-memory applications, many of which are written in MPI, critically depends on how well the applications can ameliorate the long latency of data movement by overlapping them with ongoing computations, thereby minimizing wait time. This paper presents a study of the various optimization techniques to enable such overlapping in large MPI applications and presents a framework that uses an analytical performance model and an optimizing compiler to systematically enable a majority of such optimizations. In particular, we first generate an analytical performance model of the application execution flow to automatically identify potential communication hot spots that may induce long wait time. Next, for each communication hot spot, we search the execution flow graph to find surrounding loops that include sufficient local computation to overlap with the communication. Then, blocking MPI communications are decoupled into non-blocking operations when necessary, and their surrounding loop is transformed to hide the communication latencies behind local computations. We evaluated our framework using 7 MPI applications from the NAS benchmark suite. Our optimizations can attain 3% to 72% speedup over the original implementations.	analytical performance modeling;benchmark (computing);blocking (computing);computation;distributed memory;erp;mathematical optimization;message passing interface;non-blocking algorithm;optimizing compiler;performance prediction;software portability;speedup	Jichi Guo;Qing Yi;Jiayuan Meng;Junchao Zhang;Pavan Balaji	2016	2016 IEEE International Conference on Cluster Computing (CLUSTER)	10.1109/CLUSTER.2016.62	benchmark;parallel computing;real-time computing;time–frequency analysis;computer science;theoretical computer science;operating system;computational model	HPC	-8.483254686554261	47.9374595646197	36227
e3c65890263583b6861a9ee3bbee5a26a45e21b2	a novel parallel fdtd algorithm on non-uniform memory access multiprocessors	finite difference time domain fdtd;time domain analysis;acceleration;computer architecture;inverted f antenna ifa finite difference time domain fdtd non uniform memory access numa;parallel algorithms finite difference methods multiprocessing systems;message systems;non uniform memory access numa;application threads affinity parallel fdtd algorithm finite difference time domain algorithm nonuniform memory access multiprocessors numa architecture workstation;inverted f antenna ifa;program processors;finite difference methods;finite difference methods time domain analysis computer architecture acceleration program processors message systems	It is critical to Choose a good threads and data distribution scheme to the performance of data-parallel applications on Non-Uniform Memory Access (NUMA) architecture workstation. In this paper, we introduce a novel parallel finite-difference time-domain (FDTD) algorithm by optimize application threads affinity on NUMA architecture workstation. The algorithm has achieved the excellent performance through an ideal test case and an inverted-F antenna example.	algorithm;finite-difference time-domain method;inverted-f antenna;non-uniform memory access;processor affinity;test case;uniform memory access;workstation	Xiaomei Guo	2016	2016 IEEE/ACIS 15th International Conference on Computer and Information Science (ICIS)	10.1109/ICIS.2016.7550921	acceleration;uniform memory access;parallel computing;real-time computing;computer hardware;computer science;finite difference method;operating system;non-uniform memory access	HPC	-6.504941325457357	41.81718497483791	36376
0a954f76158d0b0c9894892983b644d61e0839b0	a practice for the certification of minimum flight crew workload		Although FAR/CCAR25.1523 addressed the accessibility and ease of operation of necessary controls in addition to individual workload, the methods of evaluating workload are far less straightforward, and usually dominate the determination of the minimum flight crew.		Hongmei Liu;Xianchao Ma;Yinbo Zhang;Zhefeng Jin;Dayong Dong	2017		10.1007/978-3-319-58750-9_47	simulation;cockpit;workload;computer science;certification;crew;real-time computing	Robotics	-12.128429190089737	57.947169923463704	36386
0a1b072ec6763b7ac25e5b86a7d00159822429ef	trgen: a traffic generation system for interconnection network simulators	parallel and distributed system;multiprocessor interconnection networks;joomla;concurrent computing;application software;telecommunication traffic multiprocessor interconnection networks parallel architectures virtual machines;traffic control;telecommunication traffic traffic control multiprocessor interconnection networks computational modeling application software intelligent networks computer architecture concurrent computing assembly proposals;interconnection network;traffic generation system;assembly;computer architecture;execution driven simulation trgen traffic generation system interconnection network simulators parallel systems distributed systems network traffic;telecommunication traffic;complete system simulation;computational modeling;parallel architectures;virtual machines;parallel systems;network traffic;interconnection network simulators;execution driven simulation;trgen;intelligent networks;distributed systems;proposals	In this paper we introduce TrGen, a traffic generation environment specifically designed to interact with simulators of interconnection networks for parallel and distributed systems. This environment is able to generate synthetic traffic, and actual traffic taken from traces (of previous program runs). It can also cooperate with complete-system simulators to assemble a complete execution-driven simulation arrangement.	adobe flash lite;central processing unit;distributed computing;experiment;interconnection;interoperability;simics;simulation;synthetic intelligence;tracing (software);www	Francisco Javier Ridruejo Perez;A. Gonzalez;José Miguel-Alonso	2005	2005 International Conference on Parallel Processing Workshops (ICPPW'05)	10.1109/ICPPW.2005.86	embedded system;intelligent network;application software;parallel computing;real-time computing;concurrent computing;computer science;virtual machine;operating system;assembly;distributed computing;computational model;computer network	HPC	-12.52497938411879	43.10776304450886	36440
ce73443d36436f4ed9a82ae8039fd63e6b1e6aca	python for unix and linux system administration - efficient problem-solving with python	problem solving			Noah Gift;Jeremy M. Jones	2008			single unix specification;unix architecture;computational science;python;operating system;unix;programming language	Security	-9.427850179980432	37.070725819307135	36455
37e1035f8b843fbd3b163977bd48262e835edc9f	gpgpu acceleration using opencl for a spotlight sar simulator		In this paper, OpenCL is used to target a general purpose graphics processing unit (GPGPU) for acceleration of 2 modules used in a synthetic aperture radar (SAR) simulator. Two of the most computationally complex modules, the Back Projection and Generate Return modules, are targeted to an AMD FirePro M5100 GPGPU. The resulting speedup is 3X over multi-threaded C++ implementations of those algorithms running on an 4-core Intel I7 2.8GHz processor, 4X and 7X over single-threaded C++ implementations, and 19X and 29X over native MATLAB implementations, respectively.	amd firepro;algorithm;c++;computer graphics;dbpedia;dhrystone;general-purpose computing on graphics processing units;graphics processing unit;matlab;opencl api;simulation;speedup;thread (computing)	Eric J. Balster;Marc P. Hoffman;Jon P. Skeans;David Fan	2017		10.1145/3078155.3078157	embedded system;parallel computing;computer graphics (images)	Arch	-5.23855171105202	42.275980343105005	36478
54ee2faf68b50669b60a299f09734b567109045f	how hard is it to take a snapshot?	space complexity;distributed computing;lower bound	The snapshot object is an important and well-studied primitive in distributed computing. This paper will present some implementations of snapshots from registers, in both asycnhronous and synchronous systems, and discuss known lower bounds on the time and space complexity of this problem.	dspace;distributed computing;hagit attiya;processor register;randomized algorithm;snapshot (computer storage);snapshot isolation	Faith Ellen	2005		10.1007/978-3-540-30577-4_3	real-time computing;computer science;theoretical computer science;distributed computing	Theory	-15.692315858947225	46.49930877312616	36479
1c77dbf175cdf45c5998bed61da3a9d2172f52a8	towards bounded wait-free pasis		The PASIS read/write protocol implements a Byzantine fault-tolerant erasure-coded atomic register. The prototype PASIS storage system implementation provides excellent best-case performance. Writes require two round trips and contentionand failure-free reads require one. Unfortunately, even though writes and reads are wait-free in PASIS, Byzantine components can induce correct clients to perform an unbounded amount of work. This unbounded amount of work can take one of two forms: an unbounded number of protocol steps to complete a read or arbitrarily-sized timestamps. Correct clients may have to read back in logical time to complete a read that is concurrent to a write; Byzantine components can induce a correct client to perform this protocol step an unbounded number of times. A correct client advances logical time by a single unit with every write. A Byzantine component can advance logical time by an arbitrary amount, thus creating an arbitrarily-sized timestamp. Such timestamps require every read and write to perform an unbounded amount of work. In this extended abstract, we enumerate the avenues by which Byzantine servers and clients can induce correct clients to perform an unbounded amount of work in PASIS. We sketch extensions to the PASIS protocol [1] and Lazy Verification [2] that bound the amount of work Byzantine components can induce correct clients to perform. We present the extensions necessary to constrain Byzantine servers separately from those necessary to constrain Byzantine clients. We believe that the extensions providebounded wait-free [3] reads and writes. As with (unbounded wait-free) PASIS, we assume an unbounded amount of server storage space. We also	best, worst and average case;byzantine fault tolerance;computer data storage;enumerated type;lazy evaluation;non-blocking algorithm;prototype;server (computing)	Michael Abd-El-Malek;Gregory R. Ganger;Garth R. Goodson;Michael K. Reiter;Jay J. Wylie	2006			trips architecture;sketch;bounded function;computer science;server;distributed computing;computer data storage	Theory	-21.770199687871234	45.16452379393703	36520
1a98bf1f950d824773af27d32d3da8db4169451b	modeling the impact of checkpoints on next-generation systems	lightweight storage architectures;general and miscellaneous mathematics computing and information science;performance monitoring;storage system;information systems;massive scale in production doe systems;fault tolerant;petaflop system;performance;overlay networks;next generation systems;application driven periodic checkpoint operations;checkpointing;capability class mpp systems;parallel processing checkpointing memory architecture;monitoring;mathematical models;massively parallel processing systems;memory architecture;next generation;mathematical model;overlay network;mathematical modeling;overlay networks next generation systems massively parallel processing systems capability class mpp systems application driven periodic checkpoint operations mathematical modeling massive scale in production doe systems petaflop system lightweight storage architectures;memory devices;supercomputers;parallel processing;lower bound;laboratories us department of energy computer networks bandwidth contracts delay parallel processing fault tolerance large scale systems fault tolerant systems;massively parallel processing	"""The next generation of capability-class, massively parallel processing (MPP) systems is expected to have hundreds of thousands of processors. For application-driven, periodic checkpoint operations, the state-of-the-art does not provide a solution that scales to next-generation systems. We demonstrate this by using mathematical modeling to compute a lower bound of the impact of these approaches on the performance of applications executed on three massive-scale, in-production, DOE systems and a theoretical petaflop system. We also adapt the model to investigate a proposed optimization that makes use of """"lightweight"""" storage architectures and overlay networks to overcome the storage system bottleneck. Our results indicate that (1) as we approach the scale of next-generation systems, traditional checkpoint/restart approaches will increasingly impact application performance, accounting for over 50% of total application execution time; (2) although our alternative approach improves performance, it has limitations of its own; and (3) there is a critical need for new approaches to fault tolerance that allow continuous computing with minimal impact on application scalability."""	application checkpointing;approximation algorithm;central processing unit;clustered file system;computer data storage;experiment;flops;fault tolerance;goodyear mpp;list of toolkits;mathematical model;mathematical optimization;next-generation network;overhead (computing);overlay network;parallel computing;run time (program lifecycle phase);scalability;transaction processing system	Ron Oldfield;Sarala Arunagiri;Patricia J. Teller;Seetharami R. Seelam;Maria Ruiz Varela;Rolf Riesen;Philip C. Roth	2007	24th IEEE Conference on Mass Storage Systems and Technologies (MSST 2007)	10.1109/MSST.2007.24	parallel computing;real-time computing;computer science;distributed computing	HPC	-16.84165703342579	50.708614456509665	36522
319de76a2b81db503cbfba55d3aae3f1c23433d7	systematic development of parallel programs using skeletons				Holger Bischof	2005				HPC	-10.155434790028696	40.802933588053506	36526
bf97e8c9d4d29263781b45931d216ba0d9407c14	pdc-nh: popular data concentration on nand flash and hard disk drive	energy conservation;flash memory;cache storage;write cache;popular data concentration technique;disc drives;nand flash;network server architecture;write caching;network server;energy efficient;hard disks;data mining;simulator;arrays;servers;performance improvement;solid state drive;low power;hard disks network servers energy consumption energy efficiency energy conservation web server performance gain computer science data engineering power engineering and energy;clustering;nand flash drive;network server architecture nand flash drive hard disk drive popular data concentration technique solid state drive file placement policy write caching power consumption reduction;power consumption;correlation;hard disk drive;trace driven simulation;power consumption reduction;power consumption cache storage disc drives flash memories;flash memories;file placement policy;energy saving;disk array;reading and writing;clustering nand flash energy conservation write cache simulator	In this paper, we present a network server architecture which concentrates popular data on both HDD and NAND flash. Popular Data Concentration (PDC) is a well known technique to reduce the power consumption of disk arrays. We extended PDC by adding NAND flash based Solid State Drive (SSD) and achieved better performance and energy savings. We developed a novel file placement policy which places popular files on either one of flash disk or hard disk based on their size, popularity and access characteristics. Our placement policy places large and sequential read files on HDD and small and random read files on SSD. This placement takes advantage of the benefits of each medium and hides their shortcomings. To boost the HDD's performance, we further clustered correlated files and placed them on the HDD in a sequential manner. This reduces seek counts hence leading to a performance improvement. And we reserved some space of HDD to use it for write caching. By this, all the requests including reads and writes are concentrated on a designated hard disk and flash disk letting other disks to stay longer in low-power mode. We evaluated our architecture with trace driven simulator and the results show that our architecture is more energy efficient and performance effective compared with existing energy efficient architectures.	cpu cache;cache (computing);cluster analysis;computer cluster;disk array;disk storage;flash memory;hard disk drive;low-power broadcasting;nethack;peripheral dma controller;power supply;programme delivery control;random access;randomness;sequential access;server (computing);simulation;solid-state drive;solid-state electronics;usb flash drive	DongKyu Lee;Kern Koh	2009	2009 10th IEEE/ACM International Conference on Grid Computing	10.1109/GRID.2009.5353061	parallel computing;real-time computing;computer hardware;computer science;operating system;server	Arch	-10.674232420113924	54.44752357483048	36551
748f12a5c3328abb8e921babe4b6ad64d9eef450	preemptibility in real-time operating systems	analytical models;scheduling decisions;oceans;multimedia;average response time;perforation;processor scheduling;task set priority information scheduling decisions small integers deadline times preferred order priority inversion high priority job nonpreemptible code sections critical sections critical regions soft real time operating system average response time performance metric time constrained jobs multimedia;critical regions;nonpreemptible code sections;real time operating system;multimedia systems;soft real time;performance metric;scheduling operating systems computers real time systems;high priority job;task set;operating system;high priority;programming profession;scheduling;time constrained jobs;priority information;soft real time operating system;small integers;critical sections;deadline times;computer science;real time systems operating systems delay computer science processor scheduling analytical models multimedia systems programming profession hardware oceans;critical section;operating systems computers;priority inversion;preferred order;analytical model;operating systems;hardware;real time systems	Real-time operating systems generally depend on some form of priority information for making scheduling decisions. Priorities may take the form of small integers or deadline times, for example, and the priorities indicate the preferred order for execution of the jobs. Unfortunately, most systems suffer from some degree of priority inversion where a high priority job must wait for a lower priority job to execute. We consider the nature of the non-preemptible code sections, called critical sections or critical regions, which give rise to this priority inversion in the context of a soft real-time operating system where average response time for different priority classes is the primary performance metric. An analytical model is described which is used to illustrate how critical regions may affect the timeconstrained jobs in a multimedia (soft real-time) task set.	critical section;job stream;lazy evaluation;preemption (computing);priority inversion;real-time clock;real-time computing;real-time operating system;real-time transcription;response time (technology);scheduling (computing);software design;the void (virtual reality)	Clifford W. Mercer;Hideyuki Tokuda	1992		10.1109/REAL.1992.242674	priority inversion;priority inheritance;embedded system;real-time computing;earliest deadline first scheduling;simulation;real-time operating system;priority call;dynamic priority scheduling;computer science;rate-monotonic scheduling;operating system;deadline-monotonic scheduling;distributed computing;critical section;priority ceiling protocol	Embedded	-11.499481910610678	59.76435942673898	36565
ee33f087148eecc85e423a3eb40e55c4932503c3	a novel approach to real-time rti based distributed simulation system	middleware digital simulation open systems real time systems;real time rti end system real time rti based distributed simulation system dod high level architecture large scale distributed interactive simulation systems simulation component reusability simulation component interoperability real time simulation application hla specification real time implementation specification hla run time infrastructure;hla;distributed interactive simulation hla rti real time multi threads scheduling;real time;real time simulation;multi threads;scheduling;run time infrastructure;middleware;real time implementation;distributed interactive simulation;distributed simulation;open systems;high level architecture;real time application;digital simulation;rti;real time systems	HLA, a DoD high level architecture, is emerging as a standard platform for large-scale distributed interactive simulation systems. It mainly emphasizes on the reusability and interoperability of different simulation components. HLA was well designed and has been proved to have the ability to guarantee the desirable properties of reusability and the interoperability in distributed simulation systems from several aspects. However, HLA shows an apparent weakness when it comes to real-time simulation applications. Indeed, there are no specific rules provided with respect to real-time applications in HLA specifications. Therefore, there has not been any widely accepted real-time implementation specification for the HLA Run-Time Infrastructure (HLA-RTI). In this paper, we propose a novel real-time RTI architecture which addresses the weakness of HLA/RTI in terms of real-time applications. We discuss our design and the implementation of our real-time RTI architecture with an emphasis on the real-time RTI end-system.	distributed interactive simulation;high-level architecture;interoperability;real-time clock;real-time transcription;run-time infrastructure (simulation)	Azzedine Boukerche;Kaiyuan Lu	2005	38th Annual Simulation Symposium	10.1109/ANSS.2005.9	embedded system;real-time computing;computer science;operating system	Embedded	-33.655428267553376	44.81158852964663	36676
79a8aad5d96388368ca6cfeb15659acda5fcc310	local-area and wide-area computing: architectures and tools	protocols;computer architecture concurrent computing computer networks workstations distributed computing parallel processing local area networks high performance computing grid computing network servers;parallel and distributed computing;interconnection network;computer architecture;protocols local area networks wide area networks;network of workstation;cost efficiency;parallel computer;optimized protocol system architectures wide area computing local area computing clusters of servers workstations pcs parallel computing multicomputer systems locally organized clusters local area computing wide area multiclusters hyperclusters clusters of clusters high speed interconnection networks;high throughput;system architecture;high speed;local area networks;wide area networks;workstation cluster	In this contribution, recent architectural approaches and tools for local-area and wide-area computing using clusters of servers, workstations, and PCs as multicomputers (i.e. parallel computing in workstation clusters) are classified and described. The goal of such systems is to concentrate available computing resources to solve computing problems. A special focus of this contribution is a description of recent research in the field of cost-efficient parallel computing with standard component multicomputer systems, concentrating on locally organized clusters for local-area computing and on widearea multiclusters (hyperclusters or clusters of clusters) for widearea computing. Selected examples are given demonstrating the improvement through high-speed interconnection networks and optimizedprotocol system architectures in local-area systems and optimized organizations in wide-area systems.	computer cluster;cost efficiency;interconnection;parallel computing;workstation	Djamshid Tavangarian	2001		10.1109/EMPDP.2001.905006	fabric computing;computer architecture;parallel computing;computer science;end-user computing;data-intensive computing;distributed computing;utility computing;grid computing;unconventional computing;autonomic computing	HPC	-12.373228672371237	43.87917761693415	36710
c790a4d82c67deeac3a48cba9fefc0eb9e802237	the eftos voting farm: a software tool for fault masking in message passing parallel environments	system recovery message passing fault tolerant computing c language real time systems;recovery techniques eftos voting farm software tool fault masking message passing parallel environments c functions distributed software voting mechanism epx eftos framework embedded fault tolerant supercomputing dependability user application modular redundancy systems n replicated voters structural design goals fault transparency replication transparency;eftos voting farm;software tool;user application;fault tolerant;application software;message passing parallel environments;nuclear magnetic resonance;structural design goals;replication transparency;modular redundancy systems;fault masking;ease of use;eftos framework;c language;fault tolerant computing;system recovery;redundancy;epx;voting;recovery techniques;pipelines;fault tolerance;dependability;message passing;embedded fault tolerant supercomputing;software tools;fault transparency;n replicated voters;structural design;embedded software;c functions;voting software tools message passing nuclear magnetic resonance redundancy pipelines embedded software fault tolerance application software hardware;hardware;distributed software voting mechanism;real time systems	"""IV' present ct set of C: . fienetions implementing (i di.stributed software voting mecharri.sm fi)r Ep,V orsimilar mcssa,ge passing environments, and we place it within the l;l""""T0S fi'arrtewnrk (Embe(Ided Fault-Tolerant .4u1)c'rr'onrlu1ti17g) gf'saftwarc) tools for enhancing the dependability of cr user application . The described ntechanam can he ased . f )r instance to implerr,E,'t7t r""""E.'.SIO7""""Ir7,:y o1gar1s r .e_ N_ Modular redundancy systems with N-replicated voters. We show that, besidc~s structural design goals likE' .fatrlt tran .sparencti"""" this tool achieves replication t!'un.spcrreru;t', a high dc~ree gf;f1E'.ribilily and ease-c)f-u se"""", good he """" r fornlarrce, as hell as the possibility 10 e0mbfne , fault masking with recovc7'l' techn que~s . ;379 2. If we consider a pipeline of such systems, then a failing voter in one stage of the pipeline can be simply regarded as a corrupted input for the next stage, where it will be restored . The resulting system is easily recognizable to be more robust than plain NMR, for it does no """"lore exhibit single points of failures . Dependability analysts confirms intuition . Property 2. in particular explains why such systems are also known as """"restoring organs"""" 112] . From the point of view ofsoftware engineering, this system though has two major drawbacks : Each module in the VMR """"rust he aware of and responsible for interacting with the whole set of voters, """" 'file complexity of these interactions, which is a function increasing quodratically with N. the cardinaliiy of the voting farm, burdens cacti module in the NMR. As a consequence, it first appeared difficult to us to design a software rnechanistn which, besides reaching design goals like fault transparency (i .e ., fault masking) and efficiency, were also able to achieve replication transparency, case of use, and flexibility . In order to reach the full set of these requirements, we slightly modified the design of (lie system as described in Fig.' : Now each module only has to interact with, and be aware of one voter, regardless the value of N. Moreover, the complexity of such a task is fully shifted to the voter. We adopted this approach during the design and development of the voting faun n)echanism, a class of C functions which is part of the FI TOS Framework (Embedded Faultfolcrant Supercomputing, (:SPRIT-CV Project 21012) . In this paper we briefly draw a picture of FFTOS and place the voting faint into it, then we describe the design of the voting farm and show how such tool proved to Fulfill the"""	acm/ieee supercomputing conference;algorithm;c standard library;cc system;compile farm;computer engineering;database;dependability;directshow;embedded system;fault tolerance;interaction;internet backbone;message passing;point of view (computer hardware company);programming paradigm;redundancy (engineering);requirement;rust;single point of failure;windows nt	Vincenzo De Florio;Geert Deconinck;Rudy Lauwereins	1998		10.1109/EURMIC.1998.711830	fault tolerance;parallel computing;real-time computing;computer science;operating system;distributed computing	EDA	-24.948330793866457	41.461339967800875	36726
e1214fbc6a1ea4a0636b941b0448989b071c9712	blue gene: a vision for protein science using a petaflop supercomputer	parallel computer;novel idea;protein folding;ibm research;petaflop supercomputer;parallel machine;novel machine architecture;protein science;novel platform;parallel machine architecture;blue gene project;biomolecular phenomenon	by the IBM Blue Gene team: F. Allen, G. Almasi, W. Andreoni, D. Beece, B. J. Berne, A. Bright, J. Brunheroto, C. Cascaval, J. Castanos, P. Coteus, P. Crumley, A. Curioni, M. Denneau, W. Donath, M. Eleftheriou, B. Fitch, B. Fleischer, C. J. Georgiou, R. Germain, M. Giampapa, D. Gresh, M. Gupta, R. Haring, H. Ho, P. Hochschild, S. Hummel, T. Jonas, D. Lieber, G. Martyna, K. Maturu, J. Moreira, D. Newns, M. Newton, R. Philhower, T. Picunko, J. Pitera, M. Pitman, R. Rand, A. Royyuru, V. Salapura, A. Sanomiya, R. Shah, Y. Sham, S. Singh, M. Snir, F. Suits, R. Swetz, W. C. Swope, N. Vishnumurthy, T. J. C. Ward, H. Warren, R. Zhou	blue gene;flops;fitch notation;jonas;kohn–sham equations;newton;supercomputer;warren abstract machine	Frances E. Allen;George Almási;Wanda Andreoni;Daniel K. Beece;Bruce J. Berne;Arthur A. Bright;José R. Brunheroto;Calin Cascaval;José G. Castaños;Paul Coteus;Paul Crumley;Alessandro Curioni;Monty Denneau;Wilm E. Donath;Maria Eleftheriou;Blake G. Fitch;Bruce M. Fleischer;Christos J. Georgiou	2001	IBM Systems Journal	10.1147/sj.402.0310	computational science;simulation;computer science;engineering;electrical engineering;operating system;software engineering;database	Theory	-7.986758609127239	37.38819975453195	36736
05839dc8971066a8dbd1b67e67255e1dc0e4a958	memory-efficient optimization of gyrokinetic particle-to-grid interpolation for multicore processors	particle deposition;parallel algorithm;parallel algorithms circuit optimisation interpolation memory architecture mesh generation multiprocessing systems;kernel methods;gpu;space filling curves;high performance pic simulation code memory efficient optimization gyrokinetic particle to grid interpolation multicore processor multicore parallelization strategies gyrokinetic toroidal code 3d particle in cell pic application magnetic confinement fusion device 3d toroidal mesh parallel algorithm gtc charge deposition kernel multicore platform grid size particle larmor radius variation architectural feature;gram matrices;affinity propagation;multicore processors;particle in cell;high performance;sparse matrices;gyrokinetic toroidal code	We present multicore parallelization strategies for the particle-to-grid interpolation step in the Gyrokinetic Toroidal Code (GTC), a 3D particle-in-cell (PIC) application to study turbulent transport in magnetic-confinement fusion devices. Particle-grid interpolation is a known performance bottleneck in several PIC applications. In GTC, this step involves particles depositing charges to a 3D toroidal mesh, and multiple particles may contribute to the charge at a grid point. We design new parallel algorithms for the GTC charge deposition kernel, and analyze their performance on three leading multicore platforms. We implement thirteen different variants for this kernel and identify the best-performing ones given typical PIC parameters such as the grid size, number of particles per cell, and the GTC-specific particle Larmor radius variation. We find that our best strategies can be 2x faster than the reference optimized MPI implementation, and our analysis provides insight into desirable architectural features for high-performance PIC simulation codes.	central processing unit;chemical vapor deposition;code;extensible authentication protocol;interpolation;kernel (operating system);mathematical optimization;multi-core processor;parallel algorithm;parallel computing;particle-in-cell;simulation;toroidal graph;turbulence	Kamesh Madduri;Samuel Williams;Stéphane Ethier;Leonid Oliker;John Shalf;Erich Strohmaier;Katherine A. Yelick	2009	Proceedings of the Conference on High Performance Computing Networking, Storage and Analysis	10.1145/1654059.1654108	multi-core processor;kernel method;particle-in-cell;parallel computing;sparse matrix;computer hardware;computer science;theoretical computer science;parallel algorithm;particle deposition;affinity propagation	HPC	-5.12230757867169	38.735444011686766	36754
2be3744faff87c14ece361ed9fe867185f72d803	a dynamic weighted data replication strategy in data grids	distributed data;bandwidth resource management history computer science data engineering system performance distributed computing grid computing delay file servers;information retrieval;data grids;optorsim dynamic weighted data replication strategy data grids distributed data sets latest access largest weight data access record;data replication;system performance;information retrieval data analysis grid computing;data analysis;dynamic data;load balance data grids data replication;reference value;latest access largest weight;data access;data access record;load balance;grid computing;data grid;optorsim;dynamic weighted data replication strategy;distributed data sets	Data grids deal with a huge amount of data regularly. It is a fundamental challenge to ensure efficient accesses to such widely distributed data sets. Creating replicas to a suitable site by data replication strategy can increase the system performance. It shortens the data access time and reduces bandwidth consumption. In this paper, a dynamic data replication mechanism is proposed, which is called Latest Access Largest Weight (LALW). LALW selects a popular file for replication and calculates a suitable number of copies and grid sites for replication. By setting a different weight for each data access record, the importance of each record is differentiated. The data access records in the nearer past have higher weight. It indicates that these records have higher value of references. In other words, the data access records in the long past have lower reference values. A Grid simulator OptorSim is used to evaluate the performance of this dynamic replication strategy. The simulation results show that LAHW successfully increases the effective network usage. It means that the LALW replication strategy can find out a popular file and replicates it to a suitable site.	access time;algorithm;data access;dynamic data;exponential time hypothesis;least frequently used;load (computing);load balancing (computing);mathematical optimization;national supercomputer centre in sweden;replication (computing);run time (program lifecycle phase);simulation;time complexity	Ruay-Shiung Chang;Hui-Ping Chang;Yun-Ting Wang	2008	2008 IEEE/ACS International Conference on Computer Systems and Applications	10.1109/AICCSA.2008.4493567	data access;dynamic data;computer science;load balancing;operating system;data grid;data mining;database;distributed computing;computer performance;data analysis;grid computing;replication;computer network	HPC	-17.805531303341066	58.83874052731782	36853
778238926ac3ab265221152900a2c6f2125a9d80	an interactive simulator generating system for small computers	interactive simulation	This paper is concerned with a novel idea for the use of an interactive computer system. The system, called an Interactive Simulator Generator, is designed primarily for a student interested in learning about the structure of a computer. This is achieved through the use of design configuration in a simulation process. The Interactive Simulator Generator asks questions about the structure of the target machine the user wants and provides him finally with a simulator for his machine. It also provides a list of pseudo micro-operations that help the user to specify and develop assembly instructions and programs. Modest diagnostic and debugging aids are provided. Measurements such as frequency of use and average execution time, etc., are also available for comparing different computer configurations. The simulation of a subset of the PDP-8 Computer is illustrated. The system is programmed in System 360/APL.	computer;debugging;micro-operation;pdp-8;run time (program lifecycle phase);simulation	Joel L. Brame;C. V. Ramamoorthy	1971		10.1145/1478786.1478848	computer architecture simulator;simulation;computer science;theoretical computer science;power system simulator for engineering;computer graphics (images)	Graphics	-26.02702058529809	37.93179429170665	36877
4812bc7d92fed779a80faaec99caf00a7d6dfa4b	deploying livewn grids in the greek school network	scavenging;grid computing;remote management;open source	A determinant factor for the introduction of grid technologies in production domains of scale can be the design of easy, fast and, from an operational point of view, realizable deployment procedures. Remote system management technologies, typically used to monitor and manage IT environments, are designed to offer remote software installation functionality that exhibits the aforementioned characteristics; however, previous work has shown that even valuable systems can fail to perform in heterogeneous, geographically distributed environments, especially if they are maintained by organizations affiliated to the public sector. The deployment of grid technologies throughout the Greek School Network can be achieved by combining OpenRSM, a novel open source solution capable to support usable, configurable, infrastructure management use cases in heterogeneous environments and LiveWN, a grid scavenging solution that integrates live technologies with gLite grids.	booting;code signing;combinational logic;computer form factor;desktop computer;download;full scale;grid network;hippi;live cd;open-source software;operating system;point of view (computer hardware company);prospective search;remote desktop software;scalability;software deployment;systems management;virtual machine;workstation;glite	Michael N. Kalochristianakis;Fotis Georgatos;Vasileios Gkamas;Giannis Kouretis;Emmanouel A. Varvarigos	2012	Journal of Grid Computing	10.1007/s10723-012-9203-x	embedded system;simulation;computer science;scavenger;operating system;database;distributed computing;computer security;grid computing	HPC	-32.180810212699086	53.01256231240768	36906
876f77a69769784986a103f0855e7dcafcb24aa7	usenet nuggets		As it stands, the tool only does it for code, not data; for many programs, code impact on paging and TLB is much less than data impacts--or in some cases, the code impact is horrible, but there's nothing in the world that can be done about it except to have huge caches, and even better, fast cache refill. (Consider the kind of program that's 200 Mbytes o f code, much of it in a giant single loop, leading to a high 1-cache miss rate.)	paging;translation lookaside buffer;usenet	Mark Thorson	1991	SIGARCH Computer Architecture News	10.1145/122576.773554	computer science;graph theory;parallel computing;real-time computing;hypercube;synchronization;multiprocessing;multithreading;cache coherence;mimd;floating-point unit	Arch	-8.44393893319163	51.2137811111439	36914
caa45b610988aa5f75c2121945c64955a0a7358b	ultra-low power data storage for sensor networks	energy efficiency;flash memory;ultra low power;storage system;measurement;fault tolerant;sensors;energy efficient;performance;sensor network;embedded systems;data storage;file system;indexation;design;objects;experimentation	Local storage is required in many sensor network applications, both for archival of detailed event information, as well as to overcome sensor platform memory constraints. Recent gains in energy efficiency of new-generation NAND flash storage have strengthened the case for in-network storage by data-centric sensor network applications. We argue that current storage solutions offering a simple file system abstraction are inadequate for sensor applications to exploit storage. Instead, we propose Capsule—a rich, flexible and portable object storage abstraction that offers stream, file, array, queue and index storage objects for data storage and retrieval. Further, Capsule supports checkpointing and rollback of object state for fault tolerance. Our experiments demonstrate that Capsule provides platform independence, greater functionality and greater energy efficiency than existing storage solutions.	abstraction layer;application checkpointing;array data structure;computer data storage;experiment;fault tolerance;flash memory;hardware abstraction;image sensor;nand gate;object storage;portable object (computing);queue (abstract data type);rollback (data management);streams;serial peripheral interface bus;visual sensor network	Gaurav Mathur;Peter Desnoyers;Paul Chukiu;Deepak Ganesan;Prashant J. Shenoy	2009	TOSN	10.1145/1614379.1614385	embedded system;real-time computing;storage area network;data striping;converged storage;computer hardware;computer science;computer data storage;emc invista;storage violation;efficient energy use;information repository	OS	-9.483932628732797	55.73380094558108	36928
de7ada38151931291f4af2da78e6848bf80df59b	community-based load balancing for massively multi-agent systems.	mobile agents;fault tolerance and dependability;scalability and performance issues robustness	Recently, large-scale distributed multiagent systems consisting of one million of agents have been developed. When agents are distributed among multiple servers, both the computational and interaction cost of servers must be considered when optimizing the performance of the entire system. Multiagent systems reflect the structure of social communities and artificial networks such as the Internet. Since the networks possess characteristics common to the `small world' phenomenon, networks of agents on the systems can be considered as small worlds. In that case, communities, which are the sets of agents that frequently interact with each other, exist in the network. Most previous works evaluate agents one by one to select the most appropriate agent to be moved to a different server. If the networks of agents are highly clustered, previous works divide the communities when moving agents. Since agents in the same community often interact with each other, this division of communities increases the interaction cost among servers. We propose community-based load balancing (CLB), which evaluates the communities to select the most appropriate set of agents to be moved. We conducted simulations to evaluate our proposed method according to the network of agents. Our simulations show that when the clustering coefficient is close to 1.0, the interaction cost with CLB can be approximately 30% lower than that with previous works.		Naoki Miyata;Toru Ishida	2006		10.1007/978-3-540-85449-4_3	real-time computing;simulation;computer science;distributed computing	AI	-19.57488376262139	58.41884953129465	36945
c9ae9df2ac7a203241cb039081720c74c88f1dee	translating openmp device constructs to opencl using unnecessary data transfer elimination		In this paper, we propose a framework that translates OpenMP 4.0 accelerator directives to OpenCL. By translating an OpenMP program to an OpenCL program, the program can be executed on any hardware platform that supports OpenCL. We also propose a run-time optimization technique that automatically eliminates unnecessary data transfers between the host and the target accelerator. It exploits the page-fault mechanism to detect if a copy of the memory object already resides in the accelerator and the copy has not been modified by the host. To evaluate the framework, we develop 17 OpenMP 4.0 benchmark applications in two versions: basic and hand-tuned. By evaluating them on three different GPUs with the original OpenCL and OpenMP programs, we show the effectiveness of the framework. To show the practicality of the framework, we compare the performance of generated OpenCL programs with that of equivalent OpenACC programs compiled by the commercial PGI compiler.	benchmark (computing);care-of address;compiler;graphics processing unit;mathematical optimization;open-source software;openacc;opencl api;openmp;page fault;programmer;programming complexity;run time (program lifecycle phase)	Junghyun Kim;Yong-Jun Lee;Jung-Ho Park;Jaejin Lee	2016	SC16: International Conference for High Performance Computing, Networking, Storage and Analysis		parallel processing;programming;computer architecture;parallel computing;software performance testing;computer science;operating system;computer performance;programming language;code generation;benchmarking	HPC	-17.04045431835947	36.394756699603285	37008
47c308e9fc5bc4d722f3ba1df48569061a0a4e91	a concurrent dynamic task graph	multifrontal method;shared memory;gestion labor;multiprocessor;memoria compartida;concurrent program;lu factorisation;grafo;factorization;matrice creuse;gestion tâche;dynamic task graph;factorizacion;shared memory multiprocessors;graph;graphe;estructura datos;programa competidor;factorisation;on the fly;task graph scheduling;structure donnee;task graphs;sparse matrix;task scheduling;multiprocesador;data structure;lu factorization;sparse matrices;memoire partagee;programme concurrent;matriz dispersa;shared memory multiprocessor;multiprocesseur	Task graphs are used for scheduling tasks on parallel processors when the tasks have dependencies. If the execution of the program is known ahead of time, then the tasks can be statically and optimally allocated to the processors. If the tasks and task dependencies aren't known ahead of time (the case in some analysts-factor sparse matrix algorithms), then task scheduling must be performed on the fly. We present simple algorithms for a concurrent dynamic-task graph. A processor that needs to execute a new task can query the task graph for a new task, and new tasks can be added to the task graph on the fly. We present several alternatives for allocating tasks for processors and compare their performance.	algorithm;central processing unit;computation;concurrent data structure;lu decomposition;on the fly;parallel computing;qr decomposition;scheduling (computing);sparse matrix	Theodore Johnson;Timothy A. Davis;Steven M. Hadfield	1993	1993 International Conference on Parallel Processing - ICPP'93	10.1016/0167-8191(95)00061-5	parallel computing;real-time computing;data structure;sparse matrix;computer science;operating system;distributed computing;factorization;algebra	HPC	-5.707011853547347	47.34541678626353	37009
8cf9e252c8314e26f20b619acb6392d52abac647	ross: a high-performance, low memory, modular time warp system	algorithme rapide;algoritmo paralelo;time warp;driving force;haute performance;systeme evenement discret;parallel algorithm;simulation systeme;reverse computation;systeme grande taille;systeme multiprocesseur memoire repartie;telecommunication sans fil;gauchissement;systeme modulaire;time warps reverse computation;telecommunication network;sistema modular;large scale system;network simulator;algorithme parallele;sistema acontecimiento discreto;large scale;discrete event system;simulation time warp;red telecomunicacion;telecomunicacion sin hilo;fast algorithm;sistema multiprocesador memoria distribuida;modular system;network model;torcimiento;reseau telecommunication;alto rendimiento;distributed memory multiprocessor system;time warp simulation;system simulation;high performance;simulacion sistema;simulation model;algoritmo rapido;warping;parallel simulation;sistema gran escala;discrete event simulation;shared memory multiprocessor;wireless telecommunication	In this paper, we introduce a new Time Warp system called ROSS: Rensselaer’s optimistic simulation system. ROSS is an extremely modular kernel that is capable of achieving event rates as high as 1,250,000 events per second when simulating a wireless telephone network model (PCS) on a quad processor PC server. In a head-to-head comparison, we observe that ROSS out performs the Georgia Tech Time Warp (GTW) system by up to 180% on a quad processor PC server and up to 200% on the SGI Origin 2000. ROSS only requires a small constant amount of memory buffers greater than the amount needed by the sequential simulation for a constant number of processors. ROSS demonstrates for the first time that stable, highly efficient execution using little memory above what the sequential model would require is possible for low-event granularity simulation models. The driving force behind these high-performance and low-memory utilization results is the coupling of an efficient pointerbased implementation framework, Fujimoto’s fast GVT algorithm for shared memory multiprocessors, reverse computation and the introduction of kernel processes ðKPsÞ: KPs lower fossil collection overheads by aggregating processed event lists. This aspect allows fossil collection to be done with greater frequency, thus lowering the overall memory necessary to sustain stable, efficient parallel execution. These characteristics make ROSS an ideal system for use in large-scale networking simulation models. The principle conclusion drawn from this study is that the performance of an optimistic simulator is largely determined by its memory usage. r 2002 Published by Elsevier Science (USA).	algorithm;central processing unit;dynamic time warping;fossil;i. michael ross;loadable kernel module;network model;reverse computation;server (computing);shared memory;simulation;x86 virtualization	Christopher D. Carothers;David W. Bauer;Shawn Pearce	2000	J. Parallel Distrib. Comput.	10.1016/S0743-7315(02)00004-7	image warping;embedded system;parallel computing;real-time computing;simulation;telecommunications;computer science;discrete event simulation;operating system;network model;simulation modeling;network simulation;distributed computing;parallel algorithm;algorithm;telecommunications network	Arch	-17.9444893425914	43.45362054484057	37013
1e6351753c76491518f3a98b25798a5153c0a91d	the proset-linda approach to prototyping parallel systems	parallel algorithm;parallel programming language;parallel systems;software development;parallel programs;parallel applications	Parallel programming is conceptually harder to undertake and to understand than sequential programming, because a programmer often has to manage the coexistence and coordination of multiple parallel activities. Prototyping is used to explore the essential features of a proposed system through practical experimentation before its actual implementation to make the correct design choices early in the process of software development. Approaches to prototyping parallel algorithms with very high-level parallel programming languages intend to alleviate the development of parallel algorithms. To make parallel programming easier, early experimentation with alternate algorithm choices or problem decompositions for parallel applications is suggested. This paper presents the ProSet-Linda approach which has been designed for prototyping parallel systems.	carlo ghezzi;coexist (image);computer vision;concurrent computing;field electron emission;high- and low-level;high-level programming language;instruction cycle;linda (coordination language);parallel algorithm;parallel computing;proset;programmer;programming language;prototype;requirement;requirements analysis;server (computing);software development;software engineer;waterfall model	Wilhelm Hasselbring	1998	Journal of Systems and Software	10.1016/S0164-1212(98)10032-8	parallel computing;computer science;theoretical computer science;software development;parallel rendering;analysis of parallel algorithms;distributed computing;parallel algorithm;programming language;parallel programming model	SE	-14.079502963741499	39.79202385033166	37030
2e4a63f3d9bb4a8d42dda180dcf1a7f963d2a0b2	supernova: super-peers based architecture for decentralized online social networks	cluster computing;service provider;dynamic system;drntu engineering computer science and engineering;pragmatic design supernova super peer based architecture decentralized online social networks open source communities brotherly service providers data replication user machine;information network;conference paper;self organizing system;public domain software;social networking online public domain software;peer to peer computing availability social network services artificial neural networks synchronization communities computer architecture;super peers;social networking online;self organization system architecture super peers storage;self organization;user behavior;online social network;system architecture;storage;open source	Recent years have seen several earnest initiatives from both academic researchers as well as open source communities to implement and deploy decentralized online social networks (DOSNs). The primary motivations for DOSNs are privacy and autonomy from big brotherly service providers. However decentralization introduces many challenges. One of the principal problems is to guarantee availability of data even when the data owner is not online, so that others can access the said data even when a node is offline or down. Intuitively this can be solved by replicating the data on other users' machines. Existing DOSN proposals try to solve this problem using heuristics which are agnostic to the various kinds of heterogeneity both in terms of end user resources as well as end user behaviors in such a system. In this paper, we argue that a pragmatic design needs to explicitly allow for and leverage on system heterogeneity, and provide incentives for the resource rich participants in the system to contribute such resources. To that end we introduce SuperNova - a super-peer based DOSN architecture. Super-peers can help (i) bootstrap new peers who are yet to have/find any friends by either providing them storage space, (ii) maintaining a directory of users, so that users can find friends in the network by name or interests, (iii) help peers find other peers to store their content in case they don't have adequate friends to do so, or if their friends are already overloaded. Users may want to become super-peers out of altruism (they want DOSNs to succeed), for the sake of the reputation (e.g., being an influential member for an interest based community) as well as potentially to monetize their special roles (e.g., run advertisements). While proposing the SuperNova architecture, we envision a dynamic system driven by incentives and reputation, however, investigation of such incentives and reputation, and its effect on determining peer behaviors is a subject of our future study. In this paper we instead investigate the efficacy of a super-peer based system at any time point (a snap-shot of the envisioned dynamic system), that is to say, we try to quantify the performance of SuperNova system given any (fixed) mix of peer population and strategies.	autonomy;dynamical system;heuristic (computer science);monetization;network interface device;online and offline;open-source software;population;privacy;refinement (computing);residential gateway;social network;systems design;universal quantification	Rajesh Sharma;Anwitaman Datta	2012	2012 Fourth International Conference on Communication Systems and Networks (COMSNETS 2012)	10.1109/COMSNETS.2012.6151349	service provider;self-organization;simulation;computer cluster;computer science;dynamical system;internet privacy;public domain software;world wide web;systems architecture	Mobile	-31.14208027649349	60.155868043965434	37077
8318fa48ed23f9e8b9909385d3560f029c623171	implementing linearizability at large scale and low latency		Linearizability is the strongest form of consistency for concurrent systems, but most large-scale storage systems settle for weaker forms of consistency. RIFL provides a general-purpose mechanism for converting at-least-once RPC semantics to exactly-once semantics, thereby making it easy to turn non-linearizable operations into linearizable ones. RIFL is designed for large-scale systems and is lightweight enough to be used in low-latency environments. RIFL handles data migration by associating linearizability metadata with objects in the underlying store and migrating metadata with the corresponding objects. It uses a lease mechanism to implement garbage collection for metadata. We have implemented RIFL in the RAMCloud storage system and used it to make basic operations such as writes and atomic increments linearizable; RIFL adds only 530 ns to the 13.5 μs base latency for durable writes. We also used RIFL to construct a new multi-object transaction mechanism in RAMCloud; RIFL's facilities significantly simplified the transaction implementation. The transaction mechanism can commit simple distributed transactions in about 20 μs and it outperforms the H-Store main-memory database system for the TPC-C benchmark.	benchmark (computing);computer data storage;concurrency (computer science);distributed transaction;garbage collection (computer science);general-purpose markup language;h-store;ibm tivoli storage productivity center;in-memory database;linearizability;remote procedure call;source lines of code;whetstone (benchmark)	Collin Lee;Seo Jin Park;Ankita Kejriwal;Satoshi Matsushita;John K. Ousterhout	2015		10.1145/2815400.2815416	real-time computing;computer science;operating system;database;distributed computing	OS	-15.07386580162658	47.68922846210993	37108
4c8aebed9fd2d991c13cbe59a250152c50774d60	addressing energy challenges in filter caches		Filter caches and way-predictors are common approaches to improve the efficiency and/or performance of first-level caches. Filter caches use a small L0 to provide more efficient and faster access to a small subset of the data, and work well for programs with high locality. Way-predictors improve efficiency by accessing only the way predicted, which alleviates the need to read all ways in parallel without increasing latency, but hurts performance due to mispredictions.In this work we examine how SRAM layout constraints (h-trees and data mapping inside the cache) affect way-predictors and filter caches. We show that accessing the smaller L0 array can be significantly more energy efficient than attempting to read fewer ways from a larger L1 cache; and that the main source of energy inefficiency in filter caches comes from L0 and L1 misses. We propose a filter cache optimization that shares the tag array between the L0 and the L1, which incurs the overhead of reading the larger tag array on every access, but in return allows us to directly access the correct L1 way on each L0 miss. This optimization does not add any extra latency and counter-intuitively, improves the filter caches overall energy efficiency beyond that of the way-predictor.By combining the low power benefits of a physically smaller L0 with the reduction in miss energy by reading L1 tags upfront in parallel with L0 data, we show that the optimized filter cache reduces the dynamic cache energy compared to a traditional filter cache by 26% while providing the same performance advantage. Compared to a way-predictor, the optimized cache improves performance by 6% and energy by 2%.	cpu cache;filter bank;hit (internet);kerrison predictor;locality of reference;mathematical optimization;overhead (computing);static random-access memory	Ricardo Alves;Nikos Nikoleris;Stefanos Kaxiras;David Black-Schaffer	2017	2017 29th International Symposium on Computer Architecture and High Performance Computing (SBAC-PAD)	10.1109/SBAC-PAD.2017.14	computer science;real-time computing;parallel computing;cache invalidation;cpu cache;cache coherence;cache;bus sniffing;cache algorithms;cache pollution;tag ram	Arch	-8.82223967223252	53.48372863296345	37115
310ac1337cc92e75976b81c37df65378d269e521	return instruction analysis and optimization in dynamic binary translation	cache storage;program instrumentation;optimisation;software maintenance;program interpreters;binary codes;instruction sets runtime performance analysis instruments cloning acceleration computer science sun binary codes protocols;return cache scheme return instruction analysis dynamic binary translation legacy binary code support program instrumentation spec cpu2000 int benchmarks;dynamic binary translation;source code;software maintenance binary codes cache storage instruction sets optimisation program interpreters;instruction sets	Dynamic Binary Translation (DBT) is widely re-searched and used to support legacy binary code, pro-vide program instrumentation, improve code performance, and so on. The performance of a DBT system is always an essential issue. And a major source of over-head is the execution of the indirect branch in source code, because it requires extra instructions to resolve the target address. In this paper, we present an improved return cache scheme with relative low overhead to handle the return instruction, the most important form of indirect branch. On dealing with the source return instruction, the overhead caused by our method is only 1%~4% to the native execution for most SPEC CPU2000 INT benchmarks (2.5% on average), which is acceptable in a DBT system.	binary translation;return statement	Tingtao Sun;Yindong Yang;Hongbo Yang;Haibing Guan;Alei Liang	2009		10.1109/FCST.2009.35	embedded system;binary code;computer architecture;parallel computing;real-time computing;computer science;operating system;instruction set;database;programming language;software maintenance;source code	EDA	-6.240039765183663	50.15219870795631	37126
047beca8784aadb85df773391a9031083ff78542	principles of optimally placing data in tertiary storage libraries	optic disk;large scale;scheduling algorithm;uct;data placement;disk array	Recently, technological advances have resulted in the wide availability of commercial products offering near-line, robot-based, tertiary storage libraries. Thus, such libraries have become a crucial component of modern largescale storage servers, given the very large storage requirements of modern applications. Although the subject of optimal data placement (ODP) strategies has received considerable attention for other storage devices (such as magnetic and optical disks and disk arrays), the issue of optimal data placement in tertiary libraries has been neglected. The latter issue is more critical since tertiary storage remains three orders of magnitude slower than secondary storage. In this paper, we address this issue by deriving such optimal placement algorithms. First, we study the ODP problem in disk libraries (jukeboxes) and subsequently, in tape libraries. In our studies, we consider different scheduling algorithms, different configurations of disk libraries and different tape library technologies (reflecting different existing commercial products) and show how these impact on the ODP strategy. *Support for this work was provided by the European Community through the ESPRIT Long Term Research Project HERMES no. 9141. Permission to copy without fee all OT part of this material is granted provided that the copies are not made OT distributed JOT direct commercial advantage, the VLDB copyright notice and the title of the publication and its date appear, and notice is given that copying is by permission of the VeTy Large Data Base Endowment. To copy otherwise, OT to republish, requires a Jee and/or special permission from the Endowment. Proceedings of the 23rd VLDB Conference Athens, Greece, 1997	algorithm;auxiliary memory;computer data storage;database;disk array;disk storage;java platform, enterprise edition;library (computing);rm-odp;requirement;robot;scheduling (computing);tape library;vldb	Stavros Christodoulakis;Peter Triantafillou;Fenia Zioga	1997			real-time computing;disk array;computer hardware;computer science;distributed computing;scheduling	DB	-15.813918373985329	55.472861450507715	37137
576623306885353fc163c37ba1ce1177b247a67e	a new i/o architecture for improving the performance in large scale clusters	distributed data;clusters;distributed system;sistema operativo;algoritmo paralelo;parallel file systems;evaluation performance;entrada salida;haute performance;systeme reparti;storage system;parallel algorithm;performance evaluation;gollete estrangulamiento;high performance computing;gestion archivos;evaluacion prestacion;serveur informatique;distributed computing;gestion fichier;file management;supercomputer;algorithme parallele;input output;supercomputador;flash io;large scale;goulot etranglement;sistema repartido;operating system;systeme memoire;parallel file system;high performance computer;mpi io;alto rendimiento;calculo repartido;servidor informatico;systeme exploitation;parallel i o;sistema memoria;high performance;bottleneck;calcul reparti;superordinateur;entree sortie;computer server	BEDFORD, Mass. – June 28, 2004 – Voltaire, a leading provider of interconnect solutions for high performance grid computing, today introduced its next generation Fibre Channel and IP routers and the industry’s first true network boot solution that offer high performance I/O and resource virtualization for large InfiniBand clusters and grids. The products, which feature new enterprise-class security, traffic manipulation, and management capabilities, integrate with Voltaire’s InfiniBand switches to deliver even greater performance and manageability to large scale clusters and grids.	fibre channel;grid computing;infiniband;input/output;network switch	Luis Miguel Sánchez;Florin Isaila;Félix García Carballeira;Jesús Carretero;Rolf Rabenseifner;Panagiotis A. Adamidis	2006		10.1007/11751649_12	input/output;embedded system;supercomputer;parallel computing;computer science;operating system;database;distributed computing;parallel algorithm;i/o scheduling;server	HPC	-18.77685919685395	44.363611508008674	37153
7e8348f39f019817d4cf5389111974bc0e31245f	efficient state-based crdts by delta-mutation	haslab haslab uminho	CRDTs are distributed data types that make eventual consistency of a distributed object possible and non ad-hoc. Specifically, state-based CRDTs ensure convergence through disseminating the entire state, that may be large, and merging it to other replicas; whereas operation-based CRDTs disseminate operations (i.e., small states) assuming an exactly-once reliable dissemination layer. We introduce Delta State Conflict-Free Replicated Datatypes (δ-CRDT) that can achieve the best of both worlds: small messages with an incremental nature, disseminated over unreliable communication channels. This is achieved by defining δ-mutators to return a delta-state, typically with a much smaller size than the full state, that is joined to both: local and remote states. We introduce the δ-CRDT framework, and we explain it through establishing a correspondence to current state-based CRDTs. In addition, we present an anti-entropy algorithm that ensures causal consistency, and two δ-CRDT specifications of well-known replicated datatypes.	algorithm;causal consistency;distributed object;eventual consistency;hoc (programming language);idempotence;local variable;overhead (computing);replication (computing)	Paulo Sérgio Almeida;Ali Shoker;Carlos Baquero	2015		10.1007/978-3-319-26850-7_5	parallel computing;real-time computing;computer science;distributed computing;algorithm	PL	-23.234095099297637	45.86441022573943	37190
392d89dc68957f8efc3479c74abfb63f2b17c973	"""pyclaw: accessible, extensible, scalable tools for wave propagation problems """""""	generalized hyperbolic;compressible flow;65m08;35l65;65y05;ease of use;python;shallow water;65y15;parallel computer;clawpack;fortran;hyperbolic pde;weighted essentially non oscillatory;hyperbolic pdes;wave propagation;scientific software	Development of scientific software involves tradeoffs between ease of use, generality, and performance. We describe the design of a general hyperbolic PDE solver that can be operated with the convenience of MATLAB yet achieves efficiency near that of hand-coded Fortran and scales to the largest supercomputers. This is achieved by using Python for most of the code while employing automatically wrapped Fortran kernels for computationally intensive routines, and using Python bindings to interface with a parallel computing library and other numerical packages. The software described here is PyClaw, a Python-based structured grid solver for general systems of hyperbolic PDEs [K. T. Mandli et al., PyClaw Software, Version 1.0, http://numerics.kaust.edu.sa/pyclaw/ (2011)]. PyClaw provides a powerful and intuitive interface to the algorithms of the existing Fortran codes Clawpack and SharpClaw, simplifying code development and use while providing massive parallelism and scalable solvers via the PETSc library. The package is further augmented by use of PyWENO for generation of efficient high-order weighted essentially nonoscillatory reconstruction code. The simplicity, capability, and performance of this approach are demonstrated through application to example problems in shallow water flow, compressible flow, and elasticity.	algorithm;code;computer performance;elasticity (data store);fortran;matlab;numerical analysis;petsc;parallel computing;python;regular grid;scalability;software propagation;solver;supercomputer;usability	David I. Ketcheson;Kyle T. Mandli;Aron J. Ahmadia;Amal Alghamdi;Manuel Quezada de Luna;Matteo Parsani;Matthew G. Knepley;Matthew Emmett	2012	SIAM J. Scientific Computing	10.1137/110856976	computational science;mathematical optimization;parallel computing;compressible flow;python;wave propagation;computer science;theoretical computer science;thermodynamics	HPC	-9.512813150664769	36.11896330486777	37195
10d46c494d0d491b0535a5ade64e7504a803b788	the influence of different workload descriptions on a heuristic load balancing scheme	informatica;system response;software;distributed system;optimisation;heuristic load balancing scheme;optimizacion;logiciel;executable workload;helium;processor scheduling;reponse systeme;workload descriptions;distributed computing;conception;task scheduler;indexing terms;learning automata;system call rate heuristic load balancing scheme task scheduler stochastic learning automation unix workstations executable workload workload descriptions one dimensional workload descriptors 1 min load average run queue;unix workstations;learning systems;unix learning systems microcomputer applications scheduling stochastic processes;stochastic processes;scheduling;workstations;load management;diseno;logicial;load distribution;design;informatique;optimization;load management processor scheduling distributed computing delay costs learning automata stochastic processes workstations stochastic systems helium;load balance;computer science;stochastic learning automation;stochastic systems;one dimensional workload descriptors;task scheduling;1 min load average;microcomputer applications;system call rate;run queue;unix;respuesta sistema	A task scheduler based on the concept of a stochastic learning automation, implemented on a network of Unix workstations, is described. Creating an artificial, executable workload, a number of experiments were conducted to determine the effect of different workload descriptions. These workload descriptions characterize the load at one host and determine whether a newly created task is to be executed locally or remotely. Six one-dimensional workload descriptors are examined. Two workload descriptions that are more complex are also considered. It is shown that the best single workload descriptor is the number of tasks in the run queue. The use of the worst workload descriptor, the 1-min load average, resulted in an increase of the mean response time of over 32%, compared to the best descriptor. The two best workload descriptors, the number of tasks in the run queue and the system call rate, are combined to measure a host's load. Experimental results indicate that no performance improvements over the scheduler versions using a one-dimensional workload descriptor can be obtained. >	heuristic;load balancing (computing)	Thomas Kunz	1991	IEEE Trans. Software Eng.	10.1109/32.83908	stochastic process;design;parallel computing;real-time computing;computer science;operating system;distributed computing;run queue;helium;unix;scheduling	SE	-14.230346359193462	59.11738416509413	37230
008e34aa995625eeaa75e74a41597debc0eac8cd	list processing primitives for parallel computation	traitement liste;programacion paralela;tratamiento lista;parallel programming;functional programming;qa76 electronic computers computer science computer software;data structures;estructura datos;parallel computer;structure donnee;programmation fonctionnelle;parallel programs;programacion funcional;high performance;data structure;list processing;programmation parallele	A new model of list processing is proposed which is more suitable as a basic data structure for architecture-independent programming languages than the traditional model of lists. Its main primitive functions are: concatenate, which concatenates two lists; split, which partitions a list into two parts; and length, which gives the number of elements in a list. This model contains a degree of non-determinism which allows greater freedom to the implementation to achieve high performance on both parallel and serial architectures.	computation;concatenation;data structure;functional programming;haskell;lisp;miranda;nondeterministic algorithm;parallel computing;programmer;programming language	Tom Axford;Mike Joy	1993	Comput. Lang.	10.1016/0096-0551(93)90036-Z	list update problem;linked list;parallel computing;difference list;data structure;list;association list;computer science;theoretical computer science;self-organizing list;programming language;algorithm	PL	-14.758189150137921	37.83994518054107	37238
61a6e12e916ac3af04d248baf7bcc0b42c22ab60	on the online fault-tolerant server consolidation problem	server consolidation;online bin packing;competitive analysis	In the server consolidation problem, the goal is to minimize the number of servers needed to host a set of clients. The clients appear in an online manner and each of them has a certain load. The servers have uniform capacity and the total load of clients assigned to a server must not exceed this capacity. Additionally, to have a fault-tolerant solution, the load of each client should be distributed between at least two different servers so that failure of one server avoids service interruption by migrating the load to the other servers hosting the respective second loads. In a simple setting, upon receiving a client, an online algorithm needs to select two servers and assign half of the load of the client to each server. We analyze the problem in the framework of competitive analysis. First, we provide upper and lower bounds for the competitive ratio of two well known heuristics which are introduced in the context of tenant placement in the cloud. In particular, we show their competitive ratios are no better than 2. We then present a new algorithm called Horizontal Harmonic and show that it has an improved competitive ratio which converges to 1.59. The simplicity of this algorithm makes it a good choice for use by cloud service providers. Finally, we prove a general lower bound that shows any online algorithm for the online fault-tolerant server consolidation problem has a competitive ratio of at least 1.42.	cloud computing;competitive analysis (online algorithm);fault tolerance;heuristic (computer science);interrupt;online algorithm;semiconductor consolidation;server (computing)	Khuzaima Daudjee;Shahin Kamali;Alejandro López-Ortiz	2014		10.1145/2612669.2612686	round-robin dns;competitive analysis;mathematical optimization;real-time computing;computer science;operating system;distributed computing;k-server problem;world wide web;client–server model;server	Theory	-18.61941878271374	59.82542932476283	37300
580f6c344c4973259bd235db89fd14f8339bd89e	why bother with catocs?	sistema operativo;total order;sistema informatico;software systems;computer system;operating system;causalite;systeme exploitation;systeme informatique;communication;comunicacion;ordre causal;causality;causalidad;causal order	In their paper Understanding the Limitations of Causally and Totally Ordered Communication [CS93], David Cheriton (Stanford University) and Dale Skeen (Teknekron Software Systems, Inc.) identify several potential problems in using causally and totally ordered communication support (CATOCS), and conclude that such support is of limited merit at best. This is a remarkable statement, given that, first, many well-known researchers are advocating a CATOCS model, and second, several projects have used CATOCS support successfully.[CS93] lists four limitations. They recognize that the third limitation is only a generalization of the second, so that there are really only three. However, in the course of the paper they state an additional two. For convenience, we combine overhead and scalability concerns. In total, therefore, the paper actually does contain four limitations. These are:&bull; Lamport's event ordering cannot always be recognized in a system, and therefore correct causal delivery cannot always be enforced.&bull; CATOCS delivery is not sufficient to guarantee the consistency of user-level state. The mechanisms that do guarantee such consistency obviate the need for CATOCS.&bull; CATOCS events, even if atomic, are not durable, that is, they may be lost after delivery.&bull; CATOCS presents unacceptable overhead, and does not scale.They conclude that CATOCS is at best very narrowly applicable. These limitations are stated without proof or experimental verification. Here, we undertake to refute their conclusion by showing their examples and proof incorrect. We assume familiarity with the contents of [CS93], and, for the sake of brevity, do not repeat their examples.	causal filter;overhead (computing);scalability;software system;user space	Robbert van Renesse	1994	Operating Systems Review	10.1145/164853.164859	causality;computer science;artificial intelligence;operating system;computer security;total order;algorithm;software system	OS	-21.58887730303589	43.25994673679784	37304
93c61c737000a98899588cceb1c23716263827d8	real-time performance analysis of multiprocessor systems with shared memory	time dependent;shared memory;multiprocessor systems;real time;performance analysis;multiprocessor system on chip;multiprocessor performance analysis;multiple access;real time systems;local time	Predicting timing behavior is key to reliable real-time system design and verification, but becomes increasingly difficult for current multiprocessor systems on chip. The integration of formerly separate functionality into a single multicore system introduces new intercore timing dependencies resulting from the common use of the now shared resources. This feedback of system timing on local timing makes traditional performance analysis approaches inappropriate.  This article presents a general methodology to model the shared resource traffic and consider its effect on the local task execution. The aggregate busy time captures the timing of multiple accesses to a shared memory far better than the traditional models that focus on the timing of individual events. An iterative approach is proposed to tackle the analysis dependencies that exist in systems with event-driven task activation and dynamic resource arbitration.	aggregate data;event-driven programming;iterative method;profiling (computer programming);real-time clock;real-time computing;real-time transcription;shared memory;symmetric multiprocessing;system on a chip;systems design	Simon Schliecker;Rolf Ernst	2010	ACM Trans. Embedded Comput. Syst.	10.1145/1880050.1880058	shared memory;embedded system;computer architecture;parallel computing;real-time computing;distributed memory;computer science;operating system;local time	Embedded	-7.646945436997473	59.91691549558735	37359
93c7ff126a0bf20e9b2f6527a14e70c84a44eab2	an opencl implementation of sketch-based network traffic change detection on gpu	sketch;kernel graphics processing units computational modeling radiation detectors parallel processing programming data structures;change detection;computer network security;telecommunication traffic computer network security data structures graphics processing units parallel architectures parallel programming;simd stream architecture open computing language estimate operation hash computation radeon hd 5870 gpu global memory opencl execution model sketch data structure mapping opencl parallel programming framework sketch based network traffic change detection application design space packet processing applications;parallel programming;gpu;telecommunication traffic;parallel architectures;data structures;graphics processing units;gpu sketch change detection opencl;opencl	GPU and other SIMD stream architecture have been used for accelerating packet processing applications. This paper explores the design space on GPU for sketch-based network traffic change detection application by using OpenCL parallel programming framework. Due to the parallel nature of sketch data structure, the computations can be mapped to OpenCL execution model on GPU efficiently. The sketch data structure is mapped to buffer object in device's global memory, and work-items are executed on the sketch in parallel. Compared to the sequential CPU implementation, the experiment results on Radeon HD 5870 GPU show that the hash computation and ESTIMATE operation achieved about 15 times and 9 times speedup, respectively.	amd radeon rx 200 series;automatic vectorization;central processing unit;computation;data buffer;data structure;field-programmable gate array;graphics processing unit;mathematical optimization;multiple buffering;network packet;opencl api;parallel computing;simd;singlet fission;sketch;sorting;speedup;time complexity;x86	Theophilus Wellem;Yu-Kuen Lai	2012	2012 Fifth International Symposium on Parallel Architectures, Algorithms and Programming	10.1109/PAAP.2012.46	computer architecture;parallel computing;computer science;theoretical computer science;general-purpose computing on graphics processing units	Arch	-5.618297127661982	46.3153232419478	37369
7fb313770532cc3c1b83cc6a9f1931c3001665c1	dynamic schemes for speculative execution of code	microprocessors;simulations dynamic schemes speculative code execution pipeline processors execution path branch executions pipelining stochastic analyses;instruction sets pipeline processing parallel programming performance evaluation;optimized production technology;dynamic schemes;performance evaluation;stochastic analyses;branch executions;execution path;parallel programming;runtime;pipeline processors;runtime optimized production technology radio access networks pipelines throughput algorithm design and analysis microprocessors computer interfaces hardware;pipelines;speculative execution;pipelining;computer interfaces;speculative code execution;algorithm design and analysis;pipeline processing;instruction sets;throughput;radio access networks;hardware	"""pipe length is the maximal number of conditional branches that can be simultaneously in the pipe at any time. This length can take values in the range 4–20. We used a synthetic predictor for which we could tune the prediction probability in each branch; the percentage of conditional branches was set based on the required prediction probability and program structure model; Unless otherwise indicated, the average prediction probability used for each program was 0.94 (where the average is over all branches – conditional as well as unconditional). The prediction probability of hard branches was set to 0:65, and for easy branches 0:95. In Figures 1-3 we present the main results of our experiments. Figure 1 compares the performance of the MP schemes to the SP scheme for varying pipe lengths and a structured program; we present the results obtained for the case densisty = 1. Note, that the MP schemes (DEE and HYB) improve on SP's performance for longer pipelines; e.g., for pipe length 20, MP schemes can increase the processor throughput by about 5%. In Figure 2 we compare the performance of the various schemes in the RANDOM model, for high prediction probabilities and varying pipe lengths. We also plotted the expected runtime of SP, given by (3) where ^ p is the average prediction probability of the program. Indeed, due to the high prediction probabilities and the fact that there are no large regions of hard branches, DEE is not eager for most of the branches. Thus, in this model, DEE and SP are almost identical with an average runtime as computed in (3). In contrast, the HYB scheme, that becomes """" wasteful """" whenever a hard branch is encountered, yields a longer runtime of the program. In Figure 3 we examine the performance in the RANDOM model for short pipelines and varying prediction probabilities. We conclude, that when the average prediction probability is low, HYB and DEE are similar and achieve higher throughput, compared to SP (HYB becomes less wasteful, since there is a greater chance for large regions of hard branches). A comparison study of the three schemes, using a Two Level Adaptive Branch Predictor (as implemented, e.g., on the Pentium Pro [6]), showed that the RANDOM model can provide a close approximation to the distribution of branches in real programs. Acknowledgments The second author would like to thank Oded Lem-pel and Ilan Spillinger for many …"""	speculative execution	Prabhakar Raghavan;Hadas Shachnai;Mira Yaniv	1998		10.1109/MASCOT.1998.693711	algorithm design;throughput;computer architecture;parallel computing;real-time computing;computer science;operating system;instruction set;pipeline transport;pipeline;speculative multithreading;speculative execution	Arch	-6.776040176120635	50.97573376016335	37456
913be921bc9ebf12027f79aa26a33a4c0f56b3ab	g-system: a functionally-based communication system model for parallel processing	communication system;parallel processing		parallel processing (dsp implementation)	Myuhng Joo Kim;Chu Shik Jhon;Tetsuo Ida	1992			parallel communication	HPC	-9.806879920866782	42.274287354304846	37499
7660bb97522e1cd56e662131f589f9511d974f98	engineering a production code generator	encapsulation;extensibility;high level languages;register allocation;product code;efficiency;code generation;machine code;compilers;assemblers;inline code;draft international standard	This paper describes the structure of a code generator formed by merging the best aspects of three code generation techniques: Graham-Glanville parser-driven code generation [G] [GG] [GR] [HG], the register allocation/spill mechanism from the Portable C Compiler [J], and a code template expander [W]. The Graham-Glanville method was modified to use a standard LALR parser and table builder, and the register allocation method was extended in several significant ways in order to make optimal use of a machine with characterized registers.  This code generator is a part of the Pascal-86 compiler developed by Intel Corporation as one of several compilers supporting its iAPX-86 (8086) microprocessor family. The language supported by the compiler is an extension of the Draft International Standard Pascal, level 0. Object code generated by this method compares favorably to code produced by other compilers for the 8086, as well as Pascal compilers for other machines. Since its release in March 1981, the code generator has proved to be quite reliable and easy to maintain.	code generation (compiler);display resolution;gadu-gadu;graham scan;lalr parser;microprocessor;object code;pascal;portable c compiler;register allocation;software bug;software quality	John Crawford	1982		10.1145/800230.806996	dead code;self-modifying code;computer architecture;compiler;code bloat;parallel computing;loop-invariant code motion;machine code;encapsulation;object code;extensibility;computer science;dead code elimination;redundant code;inline function;universal product code;efficiency;programming language;register allocation;high-level programming language;code generation;assembly language;threaded code;unreachable code;source code	PL	-22.870869086259408	33.351619592121814	37514
0e342b64c553be06920ce73efc5bc57564b9f540	the first international workshop on dependability of clouds, data centers and virtual computing environments	availability;resource manager;resource management;computer architecture;data center;conferences cloud computing security resource management computer architecture availability;cloud computing conferences security resource management computer architecture availability;security;conferences;cloud computing	Cloud computing can be characterized as the culmination of the integration of computing and data infrastructures to provide a scalable, agile and cost-effective approach to support the ever-growing critical IT needs (in terms of computation and storage) of both enterprises and the general public. Cloud computing introduces a paradigm shift in computing where the ownership of computing resources is no more necessary for businesses and individuals to provide services to their end-users over the Internet. Cloud computing relieves its users from the burdens of provisioning and managing their own data centers and allows them to pay for resources only when they are actually needed and used. However, a shared cloud infrastructure introduces a number of new dependability challenges both for the cloud providers and users. Indeed all the data gets created, stored, shared and manipulated within the cloud.	data center;dependability	Jogesh K. Muppala;Matti A. Hiltunen;Robert J. Stroud;Ji Wang	2011		10.1109/DSN.2011.5958232	cloud computing security;availability;data center;cloud computing;computer science;resource management;operating system;end-user computing;cloud testing;database;distributed computing;utility computing;world wide web;computer security	HPC	-29.094673741314267	58.00313352497408	37537
f0927f537b2594c758908fc19a2b513cbe9e65d4	storage solutions ii - global data sharing: addressing the challenge of data locality	resource scheduling;data sharing;data locality;complex data;file system;data access;scientific applications;data intensive computing;overlapping communication and computation;performance modeling;wide area network	"""YottaYotta provides a summary of its Global Data Sharing project at the Data Intensive Computing Environment (DICE). DICE provides a multi-agency environment aimed at reducing the time-to-solution for complex data intensive problems in a diverse geographical setting over real-world wide area networks.One of the serious barriers to global data sharing is the challenge of data locality. In order to ensure optimal utilization of globally distributed IT resources, data must be both """"local"""" and """"global"""" at the same time. Users must ensure that their data is """"local"""" so that processing at any given site can progress without the delays of remote I/O or file transfer. However, at the same time, the data must be """"global"""" so that it remains consistent, while offering coherency of data access between sites. YottaYotta presents a new architecture that leverages clustered file systems and enables site agnostic resource scheduling across wide area heterogeneous storage environments."""	clustered file system;data access;data-intensive computing;file transfer;input/output;locality of reference;scheduling (computing)	Wayne Karpoff	2006		10.1145/1188455.1188729	data access;parallel computing;data quality;computer science;operating system;data-intensive computing;data mining;database;distributed computing;data efficiency;programming language;complex data type	HPC	-20.90575884117793	52.8696281619876	37550
1e8e082a027512a58cedcf9948dc91c65ec74d17	real-time database scheduling: design, implementation, and performance evaluation	performance evaluation;real time	A reaI-time database system has timing constraints associated with transactions and the database. To ensure that a real-time database system completes as many transactions as possible without violating their timing constraints, its scheduling strategy should be dynamic and use information about the timing constraints associated with transactions and the database. This paper presents an intelligent dynamic scheduling algorithm for transactions in real-time database syslcms. The scheduling algorithm uses timing informaLion about transactions and the database to enhance the system’s ability to meet transaction dcadIincs. The scheduling algorithm is implcmcntcd in a simulated puke detection system, and its pcrformancc is dcmonslratcd by a series of expcrimcnts.	algorithm;database;performance evaluation;real-time clock;real-time transcription;scheduling (computing)	Sang Hyuk Son;Prasad Wagle;Seog Park	1991			computer architecture;real-time computing;computer science;operating system	DB	-10.264842558938197	60.124833779562785	37568
8cc75007f182c5233f762d5b7f4f1c70b9fb4c51	red storm io performance analysis	high performance computing application;red storm parallel io performance analysis;disk storage;storage management disc storage parallel processing;disc storage;storage management;limiting;testing;system performance;computer architecture;storms;monitoring;aggregates;sandia national laboratories;bandwidth testing storms aggregates computer architecture limiting monitoring;high performance computer;performance analysis;bandwidth;access method;disk storage red storm parallel io performance analysis sandia national laboratories high performance computing application;parallel processing	This paper will summarize an IO performance analysis effort performed on Sandia National Laboratories Red Storm platform. Our goal was to examine the IO system performance and identify problems or bottle-necks in any aspect of the IO sub-system. Our process examined the entire IO path from application to disk both in segments and as a whole. Our final analysis was performed at scale employing parallel IO access methods typically used in high performance computing applications.	profiling (computer programming);red storm (computing);supercomputer	James H. Laros;Lee Ward;Ruth Klundt;Sue Kelly;James L. Tomkins;Brian R. Kellogg	2007	2007 IEEE International Conference on Cluster Computing	10.1109/CLUSTR.2007.4629216	embedded system;parallel processing;parallel computing;computer hardware;computer science;operating system;software testing;storm;access method;bandwidth;limiting	HPC	-15.308554480817055	50.02131509784503	37597
f71bccdb3d61d10ad511a398b3b6cec27bebeede	mastering freebsd and openbsd security - building, securing, and maintaining bsd systems		FreeBSD and OpenBSD are rife with security “building blocks” that you can put to use, and Mastering FreeBSD and OpenBSD Security shows you how. Both operating systems have kernel options and filesystem features that go well beyond traditional Unix permissions and controls. This power and flexibility is valuable, but the colossal range of possibilities creates a need for stepby-step instructions. This book walks you through the installation of a hardened operating system, the installation and configuration of critical services, and the ongoing maintenance of your FreeBSD and OpenBSD systems.	bsd;bus mastering;freebsd;openbsd;operating system;rife;unix	Yanek Korff;Paco Hope;Bruce Potter	2005			embedded system;engineering;operating system;computer security	OS	-27.035974967986743	50.70013354320098	37613
59259b6dae3f548106ac51d9c422e30b33e3b45e	on reducing energy management delays in disks	disk energy management;spin up delay reduction disk energy management peer memory sharing;peer memory sharing;spin up delay reduction	Enterprise computing systems consume a large amount of energy, the cost of which contributes significantly to the operating budget. Consequently, dynamic energy management techniques are prevalent. Unfortunately, dynamic energymanagement for disks impose delays associatedwith powering up the disks from a low-power state. Systems designers face a critical trade-off: saving energy reduces operating costs but may increase delays; conversely, reduced access latency makes the systems more responsive but may preclude energy management. In this paper, we propose a System-wide Alternative Retrieval of Data (SARD) scheme. SARD exploits the similarity in software deployment and configuration in enterprise computers to retrieve binaries transparently from other nodes, thus avoiding access delays when the local disk is in a low-power state. SARD uses a software-based approach to reduce spin-up delays while eliminating custom buffering, shared memory infrastructure, or the need for major changes in the operating system. SARD achieves over 71% reduction in delays on trace-driven simulations and in an actual implementation. This will encourage users to utilize energy management techniques more frequently. SARD also achieves an additional 5.1% average reduction in energy consumption for typical desktop applications compared to the widely-used timeout-based disk energy management. © 2013 Elsevier Inc. All rights reserved.	algorithm;binary file;desktop computer;low-power broadcasting;operating system;shared memory;simulation;software deployment	R. K. KrishK.;Guanying Wang;Puranjoy Bhattacharjee;Ali Raza Butt;Chris Gniady	2013	J. Parallel Distrib. Comput.	10.1016/j.jpdc.2013.02.011	embedded system;parallel computing;real-time computing;telecommunications;computer science;operating system;distributed computing;computer network	OS	-8.610662194130947	55.35661156674905	37629
017fc40263f8bee8e4732076874dca9bf2e27aa4	nvcr: a transparent checkpoint-restart library for nvidia cuda	parallel architectures application program interfaces checkpointing computer graphic equipment coprocessors message passing;computer graphic equipment;coprocessors;checkpointing;hpl nvcr transparent checkpoint restart library nvidia cuda de facto standard programming framework graphics processing units gpu accelerated system node allocation slot allocation memory chunk memory related api calls cuda runtime api cuda driver api mpi;parallel architectures;application program interfaces;message passing;graphics processing unit libraries checkpointing context databases instruction sets arrays	Today, CUDA is the de facto standard programming framework to exploit the computational power of graphics processing units (GPUs) to accelerate various kinds of applications. For efficient use of a large GPU-accelerated system, one important mechanism is checkpoint-restart that can be used not only to improve fault tolerance but also to optimize node/slot allocation by suspending a job on one node and migrating the job to another node. Although several checkpoint-restart implementations have been developed so far, they do not support CUDA applications or have some severe limitations for CUDA support. Hence, we present a checkpoint-restart library for CUDA that first deletes all CUDA resources before check pointing and then restores them right after check pointing. It is necessary to restore each memory chunk at the same memory address. To this end, we propose a novel technique that replays memory related API calls. The library supports both CUDA runtime API and CUDA driver API. Moreover, the library is transparent to applications, it is not necessary to recompile the applications for check pointing. This paper demonstrates that the proposed library can achieve checkpoint-restart of various applications at acceptable overheads, and the library also works for MPI applications such as HPL.	application checkpointing;application programming interface;cuda;chunking (computing);computer graphics;fault tolerance;graphics processing unit;linpack benchmarks;memory address;message passing interface;transaction processing system	Akira Nukada;Hiroyuki Takizawa;Satoshi Matsuoka	2011	2011 IEEE International Symposium on Parallel and Distributed Processing Workshops and Phd Forum	10.1109/IPDPS.2011.131	cuda pinned memory;computer architecture;parallel computing;message passing;computer science;operating system;distributed computing;programming language;general-purpose computing on graphics processing units;coprocessor	HPC	-15.870222323065553	50.207967453771374	37657
40511ffb8d195cabb962305a2569eb7e640c8379	online mapping of mpi-2 dynamic tasks to processes and threads	parallelisme;distributed memory;dynamique processus;high performance systems;distributed system;algoritmo paralelo;haute performance;systeme reparti;parallel algorithm;programming environment;equilibrio de carga;memoria compartida;communicating process;equilibrage charge;distributed computing;parallel programming;dinamica proceso;algorithme parallele;proceso comunicante;medio ambiente programacion;parallelism;sistema repartido;paralelismo;message passing interface;envoi message;processus communicant;task mapping;load balancing;message passing;alto rendimiento;calculo repartido;multithread;mpi;multitâche;threads;memoire repartie;process dynamics;high performance;calcul reparti;multitarea;dynamic programs;environnement programmation;multithreaded programming	In recent years, distributed platforms became largely used on HPC, and most of these architectures have different levels of parallelism. Hence, one of the key design stages in parallel programming is task mapping which attempts to maximise processor utilisation and minimise communication cost. However, this depends on a programming environment with efficient mapping scheme. This paper presents a library to MPI-2 (libSpawn) that implements a scheme to map tasks between processes and threads in order to minimise communications and task creation costs. We evaluated the libSpawn with two dynamic MPI programs: Fibonacci and Mergesort. Our experiments demonstrate that the mapping scheme offers significant performance improvements.	compile time;compiler;computer cluster;experiment;integrated development environment;merge sort;message passing interface;parallel computing;programmer;synthetic data;testbed	João V. F. Lima;Nicolas Maillard	2009	IJHPSA	10.1504/IJHPSA.2009.032025	thread;parallel computing;real-time computing;computer science;message passing interface;operating system;distributed computing	HPC	-17.15047728328002	42.71095250233431	37682
6ec79b7094975956c56b4fdb68382474b9b88079	prophesy: an infrastructure for performance analysis and modeling of parallel and grid applications	modeling technique;experimental analysis;grid applications;performance analysis;performance model;model development;grid systems;performance modeling;parallel applications;grid system	Performance is an important issue with any application, especially grid applications. Efficient execution of applications requires insight into how the system features impact the performance of the applications. This insight generally results from significant experimental analysis and possibly the development of performance models. This paper present the Prophesy system, for which the novel component is the model development. In particular, this paper discusses the use of our coupling parameter (i.e., a metric that attempts to quantify the interaction between kernels that compose an application) to develop application models. We discuss how this modeling technique can be used in the analysis of grid applications.	blueprint;computation;eurographics;gnu octave;grid computing;j. c. p. miller;parallel computing;profiling (computer programming);software development	Valerie E. Taylor;Xingfu Wu;Rick L. Stevens	2003	SIGMETRICS Performance Evaluation Review	10.1145/773056.773060	computational science;simulation;computer science;theoretical computer science;experimental analysis of behavior	HPC	-9.789336016313857	39.685903633941614	37703
3de9e1830cac6fccec19cc3746175a2a3cae1eb3	practical verification of high-level dataraces in transactional memory programs	verification;automatic verification;java programming;anomaly detection;testing;concurrency;software transactional memory;static analysis;transactional memory	In this paper we present MoTh, a tool that uses static analysis to enable the automatic verification of concurrency anomalies in Transactional Memory Java programs. Currently MoTh detects high-level dataraces and stale-value errors, but it is extendable by plugging-in sensors, each sensor implementing an anomaly detecting algorithm. We validate and benchmark MoTh by applying it to a set of well known concurrent buggy programs and by close comparison of the results with other similar tools. The results achieved so far are very promising, yielding good accuracy while triggering only a very limited number of false warnings.	algorithm;anomaly detection;benchmark (computing);concurrency (computer science);extensibility;high- and low-level;java;sensor;static program analysis;transactional memory	Vasco Pessanha;Ricardo J. Dias;João Lourenço;Eitan Farchi;Diogo Sousa	2011		10.1145/2002962.2002968	optimistic concurrency control;transactional memory;parallel computing;real-time computing;computer science;programming language	PL	-21.402010285042614	37.96270635217073	37734
5b3a623a001d77839964f41a2c20000d2699ba5f	the cache complexity of multithreaded cache oblivious algorithms	work stealing;shared memory;stencil computations;cache oblivious algorithms;parallel machines;matrix multiplication;multithreading	We present a technique for analyzing the number of cache misses incurred by multithreaded cache oblivious algorithms on an idealized parallel machine in which each processor has a private cache. We specialize this technique to computations executed by the Cilk work-stealing scheduler on a machine with dag-consistent shared memory. We show that a multithreaded cache oblivious matrix multiplication incurs <i>O</i>(<i>n</i><sup>3</sup>/√<i>Z</i> + (<i>Pn</i>)<sup>1/3</sup><i>n</i><sup>2</sup>) cache misses when executed by the Cilk scheduler on a machine with <i>P</i> processors, each with a cache of size <i>Z</i>, with high probability. This bound is tighter than previously published bounds. We also present a new multithreaded cache oblivious algorithm for 1D stencil computations, which incurs <i>O</i>(<i>n</i><sup>2</sup>/<i>Z</i>+<i>n</i>+√<i>Pn</i><sup>3</sup>+<sup>ε</sup>) cache misses with high probability.	cpu cache;cache-oblivious algorithm;central processing unit;cilk plus;computation;directed acyclic graph;matrix multiplication;parallel computing;scheduling (computing);shared memory;thread (computing);with high probability;work stealing	Matteo Frigo;Volker Strumpen	2006	Theory of Computing Systems	10.1007/s00224-007-9098-2	bus sniffing;shared memory;pipeline burst cache;cache-oblivious algorithm;snoopy cache;parallel computing;cache coloring;page cache;multithreading;cpu cache;matrix multiplication;cache;computer science;write-once;theoretical computer science;cache invalidation;distributed computing;smart cache;mesi protocol;cache algorithms;cache pollution;mesif protocol	Arch	-11.166536610286087	50.08528336103296	37742
1a6e3d2c5f9dff9dccafa53e9bb28b64f2c38335	towards automatic translation of openmp to mpi	distributed memory;shared memory;performance;compiler techniques;software distributed shared memory;high performance fortran;cluster system;message passing;openmp;mpi;nas parallel benchmarks;parallel applications;commodity clusters	We present compiler techniques for translating OpenMP shared-memory parallel applications into MPI message-passing programs for execution on distributed memory systems. This translation aims to extend the ease of creating parallel applications with OpenMP to a wider variety of platforms, such as commodity cluster systems. We present key concepts and describe techniques to analyze and efficiently handle both regular and irregular accesses to shared data.We evaluate the performance achieved by our translation scheme on seven representative OpenMP applications, two from SPEC OMPM2001 and five from the NAS Parallel Benchmarks suite, on two different platforms. The average scalability (execution time relative to the serial version) achieved is within 12% of that achieved by corresponding hand-tuned MPI applications. We also compare our programs with versions deployed for a Software Distributed Shared Memory (SDSM) system and find that the direct translation to MPI achieves up to 30% higher scalability. A comparison with High Performance Fortran (HPF) versions of two NAS benchmarks indicates that our translated OpenMP versions achieve 12% to 89% better performance than the HPF versions.	beowulf cluster;clustered file system;compiler;distributed memory;distributed shared memory;high performance fortran;machine translation;message passing interface;nas parallel benchmarks;openmp;run time (program lifecycle phase);scalability;syntax-directed translation	Ayon Basumallik;Rudolf Eigenmann	2005		10.1145/1088149.1088174	shared memory;computer architecture;parallel computing;message passing;distributed memory;performance;computer science;message passing interface;operating system;spmd	HPC	-6.759606487369568	43.392677728354286	37747
0068aa2fb735142c06c559eec453136c9cdd334c	multi-core architectures: complexities of performance prediction and the impact of cache topology	performance prediction	The balance metric is a simple approach to estimate the performance of bandwidth-limited loop kernels. However, applying the method to in-cache situations and modern multi-core architectures yields unsatisfactory results. This paper analyzes the influence of cache hierarchy design on performance predictions for bandwidth-limited loop kernels on current mainstream processors. We present a diagnostic model with improved predictive power, correcting the limitations of the simple balance metric. The importance of code execution overhead even in bandwidth-bound situations is emphasized. Finally we analyze the impact of synchronization overhead on multi-threaded performance with a special emphasis on the influence of cache topology. J. Treibig · G. Hager · G. Wellein Regionales Rechenzentrum Erlangen, Friedrich-Alexander Universität Erlangen-Nürnberg, Martensstr. 1, D-91058 Erlangen, Germany e-mail: {jan.treibig,georg.hager,gerhard.wellein}@rrze.uni-erlangen.de 1 ar X iv :0 91 0. 48 65 v1 [ cs .P F] 2 6 O ct 2 00 9	cpu cache;central processing unit;code;email;forward error correction;image scaling;jacobi method;memory hierarchy;microarchitecture;microsoft outlook for mac;multi-core processor;nehalem (microarchitecture);network topology;overhead (computing);performance prediction;solver;synchronization (computer science);thread (computing)	Jan Treibig;Georg Hager;Gerhard Wellein	2009	CoRR		real-time computing;simulation;computer science;theoretical computer science;operating system;cache algorithms	HPC	-8.189951265803725	47.90010628960189	37765
d2b9a892b3a91d8390f8afded0fdee06cba97a3f	fusion of multispectral satellite imagery using a cluster of graphics processing unit		The paper presents a parallel implementation of existing image fusion methods on a graphical cluster. Parallel implementations of methods based on discrete wavelet transformation (Haar’s and Daubechie’s discrete wavelet transform) are developed. Experiments were performed on a cluster using GPU and CPU and performance gains were estimated for the use of the developed parallel implementations to process satellite images from satellite Landsat 7. The implementation on a graphic cluster provides performance improvement from 2 to 18 times. The quality of the considered methods was evaluated by ERGAS and QNR metrics. The results show performance gains and retaining of quality with the cluster of GPU compared to the results obtained by the authors and other researchers for a CPU and single GPU.	central processing unit;computer graphics;discrete wavelet transform;graphics processing unit;haar wavelet;image fusion;multispectral image;software system	Anas M. Al-Oraiqat;Evgeniy A. Bashkov;V. Babkov;C. Titarenko	2018	CoRR		embedded system;simulation;computer science;computer graphics (images)	HPC	-5.607653587978736	41.8855421554954	37771
671a085dd7db379bfd69e86d839ee01d1910eac4	identifying dynamic data structures by learning evolving patterns in memory	program comprehension;pointer programs;dynamic data structures;machine learning;pattern recognition	We investigate whether dynamic data structures in pointer programs can be identified by analysing program executions only. This paper describes a first step towards solving this problem by applying machine learning and pattern recognition techniques to analyse executions of C programs. By searching for repeating temporal patterns in memory caused by multiple invocations of data-structure operations, we are able to first locate and then identify these operations. Applying a prototypic tool implementing our approach to pointer programs that employ, e.g., lists, queues and stacks, we show that the identified operations can accurately determine the data structures used.	data structure;dynamic data;dynamization;machine learning;object code;pattern recognition;pointer (computer programming);program comprehension;prototype;recursion;reverse engineering;static program analysis;tail call	David H. White;Gerald Lüttgen	2013		10.1007/978-3-642-36742-7_25	computer science;theoretical computer science;data mining;programming language;algorithm	SE	-18.620804013049902	34.79910278135721	37782
1b7c52bddc3b9a4bc1dbb3cd39c96f95ef85bd66	evaluation of compound system calls in the linux kernel	runtime analysis;virtual machine;controlled experiment;statistical significance;virtual environment	The overhead caused by system calls in many applications has motivated research works focusing on reducing their execution costs. In this work we implement different types of compound system calls, and evaluate them taking into account their execution time in a multicore computer. The experimental plan is conducted for both physical and virtual machine environments. The execution time dataset obtained through experiments statistically controlled is analysed and we show that all proposed compound calls present statistically significant performance gains when compared to their conventional counterparts, for both physical and virtual machine environments.	experiment;linux;multi-core processor;overhead (computing);run time (program lifecycle phase);system call;virtual machine	Elder Vicente;Rivalino Matias;Lucio Borges de Araujo;Autran Macedo	2011	2011 Brazilian Symposium on Computing System Engineering	10.1145/2146382.2146394	real-time computing;simulation;computer science;virtual machine;operating system;virtual finite-state machine	OS	-8.686660087911003	49.438992965183274	37793
72f2a414ca1045f3ede6f1bd59d53250dad4db79	brief announcement: monotonic stabilization	fault tolerant;locality;self stabilization;fault tolerance	In this brief announcement, we discuss the trade-off between the locality of information and the optimality of convergence for self-stabilization. We define the optimality of convergence, called monotonic stabilization, and propose a new metrics for the locality of information to achieve monotonic stabilization. Then, we examine the locality of many well-known distributed problems.	locality of reference;non-monotonic logic;self-stabilization;vergence	Yukiko Yamauchi;Sébastien Tixeuil	2010		10.1145/1835698.1835794	fault tolerance;real-time computing;computer science;theoretical computer science;mathematics;distributed computing	AI	-22.142849928070987	45.42138607260374	37836
dfbbf0abf157b8fe8679819b814859d6b98b2379	hydra: a c++11 framework for data analysis in massively parallel platforms		Hydra is a header-only, templated and C++11-compliant framework designed to perform the typical bottleneck calculations found in common HEP data analyses on massively parallel platforms. The framework is implemented on top of the C++11 Standard Library and a variadic version of the Thrust library and is designed to run on Linux systems, using OpenMP, CUDA and TBB enabled devices. This contribution summarizes the main features of Hydra. A basic description of the overall design, functionality and user interface is provided, along with some code examples and measurements of performance.		A. A. Alves;Michael D. Sokoloff	2017	CoRR		parallel computing;computer science;computer architecture;massively parallel;lernaean hydra;cuda;multiprocessing;user interface;mathematical software	SE	-8.917534366420398	40.33832021387598	37850
0d2991ef78be38789097a2e2f1283339ba3a850e	improving data management in a distributed environment		AbstrAct: Users of distributed systems often detect performance problems of different types and sources which can sometimes be difficult to trace down to a specific cause due to the complex structure of distributed systems. However, determining the source of the performance problem is highly critical in finding an efficient solution. Managing data fragments on different nodes is one of the major sources of such a problem and is considered as a big challenge facing system developers and designers in a distributed environment. This paper contributes in deciding on the most efficient possible allocation alternatives for data partitions in a distributed environment based on the access patterns and the cost data manipulation.	crossover (genetic algorithm);distributed computing;genetic algorithm;mathematical optimization;simulated annealing;software release life cycle	Hassan Ismail Abdalla	2011	JDIM		data mining;data management;distributed computing environment;computer science	HPC	-20.145093593207605	57.48225663098376	37863
ea318cc70d85264bf0786202a23bb1a298e4f025	mariane: using mapreduce in hpc environments	data intensive;scientific computing;mapreduce;hadoop	MapReduce is increasingly becoming a popular programming model. However, the widely used implementation, Apache Hadoop, uses the Hadoop Distributed File System (HDFS), which is currently not directly applicable to a majority of existing HPC environments such as Teragrid and NERSC that support other distributed file systems. On such resourceful High Performance Computing (HPC) infrastructures, the MapReduce model can rarely make use of full resources, as special circumstances must be created for its adoption, or simply limited resources must be isolated to the same end. This paper not only presents a MapReduce implementation directly suitable for such environments, but also exposes the design choices for better performance gains in those settings. By leveraging inherent distributed file systems’ functions, and abstracting them away from its MapReduce framework, MARIANE (MApReduce Implementation Adapted for HPC Environments) not only allows for the use of the model in an expanding number of HPC environments, but also shows better performance in such settings. This paper identifies the components and trade-offs necessary for this model, and quantifies the performance gains exhibited by our approach in HPC environments over Apache Hadoop in a data intensive setting at the National Energy Research Scientific Computing Center (NERSC).	mapreduce	Zacharia Fadika;Elif Dede;Madhusudhan Govindaraju;Lavanya Ramakrishnan	2014	Future Generation Comp. Syst.	10.1016/j.future.2013.12.007	parallel computing;computer science;operating system;database;world wide web	HPC	-5.056106268118328	45.57962877147768	37914
4416268a6e0f600f222d4f872d37181d4bbe2561	memory bank predictors	clustered microarchitectures;cache storage;cache memory;null;parallel architectures cache storage;memory access;history microarchitecture pipelines cache memory clocks wire delay effects hardware table lookup shift registers;data cache;parallel architectures;conference report;distributed cache design cache memories multiple memory banks data cache bank clustered microprocessors cache bank predictors communication latency memory accesses clustered microarchitecture;superscalar processor;memory bank prediction	Cache memories are commonly implemented through multiple memory banks to improve bandwidth and latency. The early knowledge of the data cache bank that an instruction will access can help to improve the performance in several ways. One scenario that is likely to become increasingly important is clustered microprocessors with a distributed cache. This work presents a study of different cache bank predictors. We show that effective bank predictors can be implemented with relatively low cost. For instance, a predictor of approximately 4 Kbytes is shown to achieve an average hit rate of 78% for SPECint2000 when used to predict accesses to an 8-bank cache memory in a contemporary superscalar processor. We also show how a predictor can be used to reduce the communication latency caused by memory accesses in a clustered microarchitecture with a distributed cache design.	cpu cache;distributed cache;filter bank;kerrison predictor;kilobyte;memory bank;microarchitecture;microprocessor;superscalar processor	Stefan Bieschewski;Joan-Manuel Parcerisa;Antonio González	2005	2005 International Conference on Computer Design	10.1109/ICCD.2005.73	bus sniffing;uniform memory access;least frequently used;pipeline burst cache;computer architecture;cache-oblivious algorithm;snoopy cache;parallel computing;real-time computing;cache coloring;page cache;cpu cache;cache;computer science;write-once;cache invalidation;operating system;smart cache;memory organisation;mesi protocol;cache algorithms;cache pollution;mesif protocol;cache-only memory architecture;non-uniform memory access	Arch	-8.233233309299443	52.40900570859982	37927
20c57ecc77a498fcc3552e82ba3af2cefeb7da30	scalable verification techniques for data-parallel programs	benchmarking;paper;thesis or dissertation;nvidia geforce gtx 570;tesla m2050;cuda;thesis;package;nvidia;arm;computer science;opencl	This thesis is about scalable formal verification techniques for software. A verification technique is scalable if it is able to scale to reasoning about real (rather than synthetic or toy) programs. Scalable verification techniques are essential for practical program verifiers. In this work, we consider three key characteristics of scalability: precision, performance and automation. We explore trade-offs between these factors by developing verification techniques in the context of data-parallel programs, as exemplified by graphics processing unit (GPU) programs (called kernels). This thesis makes three original contributions to the field of program verification: • An empirical study of candidate-based invariant generation that explores the tradeoffs between precision and performance. An invariant is a property that captures program behaviours by expressing a fact that always holds at a particular program point. The generation of invariants is critical for automatic and precise verification. Over a benchmark suite comprising 356 GPU kernels, we find that candidate-based invariant generation allows precise reasoning for 256 (72%) kernels. • Barrier invariants: a new abstraction for precise and scalable reasoning about datadependent GPU kernels, an important class of kernel beyond the scope of existing techniques. Our evaluation shows that barrier invariants enable us to capture a functional specification for three distinct prefix sum implementations for problem sizes using hundreds of threads and race-freedom for a real-world stream compaction example. • The interval of summations: a new abstraction for precise and scalable reasoning for parallel prefix sums, an important data-parallel primitive. We give theoretical results showing that the interval of summations is, surprisingly, both sound and complete. That is, all correct prefix sums can be precisely captured by this abstraction. Our evaluation shows that the interval of summations allow us to automatically prove full functional correctness of four distinct prefix sum implementations for all powerof-two problem sizes up to 220.	benchmark (computing);computer graphics;computer performance;correctness (computer science);data compaction;formal verification;functional specification;graphics processing unit;invariant (computer science);parallax barrier;prefix sum;scalability;synthetic intelligence;toy program	Nathan Chong	2014			computational science;computer architecture;parallel computing;computer science	PL	-14.217956558058816	34.919151817213574	37933
fbc893391732149db2eb9fc5485001957a747484	a thread behavior-based memory management framework on multi-core smartphone	libraries;androids;memory management;storage management android operating system multiprocessing systems smart phones;resource management;instruction sets memory management androids humanoid robots resource management libraries multicore processing;android;humanoid robots;multicore processing;thread;smartphone;smartphone android thread memory management behaviors;multicore architecture thread behavior based memory management framework memory management systems multicore smartphone systems smartphone operating systems global buddy system fcfs first come first served principle memory allocation memory external fragmentation android applications android buddy system memory management based on thread behaviors mmbtb;behaviors;instruction sets	Memory management systems have significantly affected the overall performance of modern multi-core smartphone systems. Android, as one of the most popular smartphone operating systems, adopts a global buddy system with the FCFS (first come, first served) principle for memory allocation, and releases requests to manage external fragmentations and maintain the memory allocation efficiency. However, extensive experimental study on thread behaviors indicates that memory external fragmentation is no longer the crucial bottleneck in most Android applications. Specifically, a thread usually allocates or releases memory in bursts, resulting in serious memory locks and inefficient memory allocation. Furthermore, the pattern of such bursting behaviors varies throughout the life cycle of a thread. The conventional FCFS policy of Android buddy system fails to adapt to such variations and thus suffers from performance degradation. In this paper, we propose a novel memory management framework, called Memory Management Based on Thread Behaviors (MMBTB), for multi-core smartphone systems. It adapts to various thread behaviors through targeted optimizations to provide efficient memory allocation. The efficiency and effectiveness of this new memory management scheme on multicore architecture is proved by a theoretical emulation model. Our experimental studies on the real Android system show that MMBTB can improve the efficiency of memory allocation by 12%-20%, confirming the theoretical analysis results.	android;buddy system;elegant degradation;emulator;experiment;fork (software development);fragmentation (computing);lock (computer science);mathematical optimization;memory management;mobile operating system;multi-core processor;smartphone	Zongwei Zhu;Xi Li;Hengchang Liu;Cheng Ji;Yuan Xu;Xuehai Zhou;Beilei Sun	2014	2014 19th International Conference on Engineering of Complex Computer Systems	10.1109/ICECCS.2014.21	uniform memory access;distributed shared memory;shared memory;embedded system;thread;real-time computing;distributed memory;computer hardware;computer science;virtual memory;resource management;operating system;memory protection;overlay;extended memory;flat memory model;cache-only memory architecture;android;non-uniform memory access;memory management	DB	-9.35266539608207	50.5819040231123	37951
79b5bc002efb1795e0e8244b833816abe09870c4	from mpi to mpi+openacc: conversion of a legacy fortran pcg solver for the spherical laplace equation		A real-world example of adding OpenACC to a legacy MPI FORTRAN Preconditioned Conjugate Gradient code is described, and timing results for multi-node multi-GPU runs are shown. The code is used to obtain three-dimensional spherical solutions to the Laplace equation. Its application is finding potential field solutions of the solar corona, a useful tool in space weather modeling. We highlight key tips, strategies, and challenges faced when adding OpenACC. Performance results are shown for running the code with MPI-only on multiple CPUs, and with MPI+OpenACC on multiple GPUs and CPUs.	avx-512;central processing unit;computation;computer;conjugate gradient method;fortran;graphics processing unit;haswell (microarchitecture);ibm notes;image scaling;legacy code;message passing interface;openacc;pc²;phrase structure grammar;preconditioner;programmable sound generator;server (computing);solver;workstation	Ronald M. Caplan;Zoran Mikic;Jon A. Linker	2017	CoRR		laplace's equation;parallel computing;multi-core processor;conjugate gradient method;fortran;software portability;computational science;cuda;mathematical software;computer science;solver	HPC	-6.745677156722274	38.366854824201496	37982
4d83036e752c0be3fadbd02e0fa20bb6180cdae8	a polyhedral modeling based source-to-source code optimization framework for gpgpu	optimisation;gpu;graphics processing unit instruction sets optimization parallel processing programming vectors arrays;cuda;arrays;gpgpu;c language;parallelism;vectors;graphics processing units;optimisation affine transforms c language graphics processing units;nvidia handcrafted cublas polyhedral modeling based source to source code optimization framework general purpose computing on graphics processing units polyhedral loop transformation theory reformulation actual memory transactions performance metric gpgpu specific optimization problems affine transformations initial parallelized solution input c c code gpgpu compiler;affine transforms;optimization;polyhedral;graphics processing unit;programming;parallel processing;source to source optimization;source to source optimization gpu gpgpu polyhedral cuda parallelism;instruction sets	In this paper, we propose a source-to-source code optimization framework for general purpose computing on graphics processing units (GPGPU). Our framework is based on a re-formulation of the polyhedral loop transformation theory under the context of GPGPU. We prove that the number of actual memory transactions can be used as a performance metric to guide the code optimization process. In addition, we show how to analytically derive such a metric from a GPU program's polyhedral model. We also develop formations of GPGPU-specific optimization problems and propose corresponding affine transformations, which can be applied to an initial parallelized solution derived from input C/C++ code. The experiment results demonstrate the effectiveness of our work. On average, the code generated by our work outperforms a leading GPGPU compiler and NVIDIA handcrafted CUBLAS 4.0 by 20% and 17%, respectively.	c++;compiler;computer graphics;general-purpose computing on graphics processing units;graphics processing unit;loop optimization;mathematical optimization;parallel computing;polyhedral;polytope model;program optimization;software transactional memory;transformation theory	Chenxi Wang;Kang Kang;Maohua Zhu;Yangdong Deng	2012	2012 IEEE 26th International Parallel and Distributed Processing Symposium Workshops & PhD Forum	10.1109/IPDPSW.2012.256	parallel processing;programming;computer architecture;parallel computing;computer science;theoretical computer science;operating system;instruction set;general-purpose computing on graphics processing units;polyhedron	EDA	-6.319409936790685	47.12147616904406	38006
9ba5693d9ae8b15ada1f3e296e0a29c34d51bb55	fatman: cost-saving and reliable archival storage based on volunteer resources		We present Fatman, an enterprise-scale archival storage based on volunteer contribution resources from underutilized web servers, usually deployed on thousands of nodes with spare storage capacity. Fatman is specifically designed for enhancing the utilization of existing storage resources and cutting down the hardware purchase cost. Two major concerned issues of the system design are maximizing the resource utilization of volunteer nodes without violating Service Level Objectives (SLOs) and minimizing the cost without reducing the availability of archival system. Fatman has been widely deployed on tens of thousands of server nodes across several datacenters, provided more than 100PB storage capacity and served dozens of internal massdata applications. The system realizes an efficient storage quota consolidation by strong isolation and budget limitation, to maximally support resources contribution without any degradation on host-level SLOs. It firstly improves data reliability by applying disk failure prediction to minish failure recovery cost, named fault-aware data management, dramatically reduces the MTTR by 76.3% and decreases file crash ratio by 35% on real-life product workload.	archive;elegant degradation;mean time to recovery;real life;replication (computing);semiconductor consolidation;server (computing);service-level agreement;systems design;the legend of zelda: the minish cap;web server	An Qin;Dianming Hu;Jun Liu;Wenjun Yang;Dai Tan	2014	PVLDB	10.14778/2733004.2733078	real-time computing;database;computer security	OS	-21.991376588415697	53.738114706995255	38066
d54805a7ac44719e8573ab71c0e57589ec942452	system-level performance and power optimization for mpsoc: a memory access-aware approach	power gating;memory scheduling;mpsoc	As the number of IPs in a multimedia Multi-Processor System-on-Chip (MPSoC) continues to increase, concurrent memory accesses from different IPs increasingly stress memory systems, which presents both opportunities and challenges for future MPSoC design. The impact of such requirements on the system-level design for MPSoC is twofold. First, contention among IPs prolongs memory access time, which exacerbates the persisting memory wall problem. Second, longer memory accesses lead to longer IP stall time, which results in unnecessary leakage waste. In this article, we propose two memory access-aware system-level design approaches for performance and leakage optimization. To alleviate the memory wall problem, we propose a Hierarchical Memory Scheduling (HMS) policy that schedules memory requests from the same IP and application consecutively to reduce interference among memory accesses from different IPs with a fairness guarantee. To reduce IP leakage waste due to long memory access, we propose a memory access-aware power-gating policy. A straightforward power-gating approach is to power gate an IP when it needs to fetch data from memory. However, due to the response time variation among memory accesses, aggressively power gating an IP whenever a memory request occurs may result in incorrect power-gating decisions. The proposed memory access-aware power-gating policy makes these decisions judiciously, based on the predicted memory latency of an individual IP and its energy breakeven time. The experimental results show that the proposed HMS memory scheduling policy improves system throughput by 42% compared to First-Come-First-Serve (FCFS) and by 21% compared to First-Ready First-Come-First-Serve (FR-FCFS) on an MPSoC for mobile phones. For the improvement of fairness, HMS improves fairness by 1.52× compared to FCFS and by 1.23× compared to FRFCFS. In the aspect of leakage optimization, our memory access-aware power-gating mechanism improves energy savings by 3.88× and reduces the performance penalty by 70% compared to conventional timeout-based power gating. We further demonstrate that our HMS memory scheduler can regulate memory access orders, thereby reducing memory response time variation. This leads to more accurate power-down decisions for both conventional timeout power gating and the proposed memory access- aware power gating.	ap computer science principles;access time;cas latency;central processing unit;electronic system-level design and verification;elegant degradation;fairness measure;health management system;interference (communication);level design;mpsoc;mathematical optimization;mem (computing);mobile phone;multiprocessing;power management unit;power gating;power optimization (eda);program optimization;random-access memory;requirement;response time (technology);scheduling (computing);spectral leakage;system bus;system on a chip;throughput;timeout (computing)	Ye-Jyun Lin;Chia-Lin Yang;Jiao-Wei Huang;Tay-Jyi Lin;Chih-Wen Hsueh;Naehyuck Chang	2015	ACM Trans. Embedded Comput. Syst.	10.1145/2656339	uniform memory access;shared memory;embedded system;interleaved memory;parallel computing;real-time computing;distributed memory;computer science;operating system;flat memory model;registered memory;computing with memory;cache-only memory architecture;memory management	EDA	-6.298622375642855	55.70051171712494	38078
05d2acfe58593fc8d601efd623d55c3f5828fa48	efficient means of achieving composability using object based semantics in transactional memory systems		Composing together the individual atomic methods of concurrent datastructures (cds) pose multiple design and consistency challenges. In this context composition provided by transactions in software transaction memory (STM) can be handy. However, most of the STMs offer read/write primitives to access shared cds. These read/write primitives result in unnecessary aborts. Instead, semantically rich higher-level methods of the underlying cds like lookup, insert or delete (in case of hash-table or lists) aid in ignoring unimportant lower level read/write conflicts and allow better concurrency. In this paper, we adapt transaction tree model in databases to propose OSTM which enables efficient composition in cds. We extend the traditional notion of conflicts and legality to higher level methods of cds using STMs and lay down detailed correctness proof to show that it is co-opaque. We implement OSTM with concurrent closed addressed hash-table (HT-OSTM) and list (list-OSTM) which exports the higher-level operations as transaction interface. In our experiments with varying workloads and randomly generated transaction operations, HT-OSTM shows speedup of 3 to 6 times and w.r.t aborts HT-OSTM is 3 to 7 times better than ESTM and read/write based STM, respectively. Where as, list-OSTM outperforms state of the art lock-free transactional list, NOrec STM list and boosted list by 30% to 80% across all workloads and scenarios. Further, list-OSTM incurred negligible aborts in comparison to other techniques considered in the paper.	boolean algebra;compact discs;composability;concurrency (computer science);concurrent chemoradiotherapy;conflict (psychology);correctness (computer science);data structure;eighty;experiment;hl7publishingsubsection <operations>;handy board;hash table;hyper-threading;hypertensive disease;lookup table;marijuana abuse;memory disorders;non-blocking algorithm;numerous;object-based language;procedural generation;published database;software transactional memory;speedup;theory;triglyceride storage disease with ichthyosis;workload	Sathya Peri;Ajay Singh;Archit Somani	2018		10.1007/978-3-030-05529-5_11	software transactional memory;programming language;semantics;concurrent data structure;composability;software;concurrency;database transaction;computer science;transactional memory	PL	-21.053519745387508	48.09638632828786	38136
49af2a74106212799241a55b4fc8a2d2809437ab	a prioritized petri net model and its application in distributed multimedia systems	multimedia;application software;distributed multimedia system;distributed processing;distance learning;distributed multimedia;distributed computing;multimedia systems;petri net model;distributed computer systems;synchronisation;distributed object composition petri net;computational modeling;distributed objects;distributed environment;extended ocpn;synchronization;prioritized petri net;systeme informatique reparti;humans;petri nets synchronisation multimedia systems distributed processing;computer science;multimedia systems power system modeling petri nets application software distributed computing computational modeling computer science conductors distance learning humans;petri nets;power system modeling;distributed environment prioritized petri net distributed multimedia petri net model distributed object composition petri net object composition petri net media synchronization extended ocpn;ocpn;media synchronization;petri net;object composition petri net;article;reseau petri;conductors	The achievement of media synchronization has been dealt with in the Object Composition Petri Net (OCPN) model and the extended OCPN (XOCPN) model. Yet these two models are not enough for synchronization of computers in a distributed environment. This paper proposes a new Petri Net model—Prioritized Petri Net (Pnet). The modeling power and properties of P-nets are analyzed. We apply the P-net model to distributed multimedia synchronization, using our version of Distributed Object Composition Petri Net (DOCPN) model. Using the DOCPN model, we can coordinate operations among distributed computer sites. The scenario is like a conductor conducting an orchestra to perform a symphony.	asynchronous i/o;computer;distributed computing;distributed control system;distributed object;object composition;petri net;real-time clock;scheduling (computing);simulation;software architecture;symphony;turing machine	Steven Guan;Hsiao-Yeh Yu;Jen-Shun Yang	1998	IEEE Trans. Computers	10.1109/12.675716	synchronization;real-time computing;stochastic petri net;computer science;theoretical computer science;distributed computing;distributed object;petri net	Robotics	-32.92652672216148	35.19323880706334	38182
4f87b9039b5799de0dfc8424db55cc5eeb4b0792	load balancing in distributed systems	distributed system;load management distributed computing cost function system performance power system reliability computational modeling distributed processing process control processor scheduling jacobian matrices;computer model;distributed processing;distributed programs;system performance;computer networks;computer network;distributed computing system;optimal scheduling;indexation;decision theory;performance analysis;load balance;performance analysis computer networks distributed processing optimal scheduling	In a distributed computing system made up of different types of processors each processor in the system may have different performance and reliability characteristics. In order to take advantage of this diversity of processing power, a modular distributed program should have its modules assigned in such a way that the applicable system performance index, such as execution time or cost, is optimized. This paper describes an algorithm for making an optimal module to processor assignment for a given performance criteria. We first propose a computational model to characterize distributed programs, consisting of tasks and an operational precedence relationship. This model alows us to describe probabilistic branching as well as concurrent execution in a distributed program. The computational model along with a set of seven program descriptors completely specifies a model for dynamic execution of a program on a distributed system. The optimal task to processor assignment is found by an algorithm based on results in Markov decision theory. The algorithm given in this paper is completely general and applicable to N-processor systems.	algorithm;approximation;central processing unit;clock rate;compiler;computation;computational model;computer;decision theory;distributed computing;load balancing (computing);markov chain;microsoft windows;out-of-order execution;run time (program lifecycle phase);scheduling (computing);spatial variability;time complexity;transaction processing system;turing reduction	Timothy C. K. Chou;Jacob A. Abraham	1982	IEEE Transactions on Software Engineering	10.1109/TSE.1982.235574	self-stabilization;distributed algorithm;parallel computing;real-time computing;distributed memory;decision theory;computer science;load balancing;concurrency control;distributed computing;computer performance;distributed design patterns;replication;distributed concurrency control	HPC	-14.030840964964012	59.620248596484274	38188
5b09fc2403507383e4000139ab845c67cf549675	bringing virtualization to the x86 architecture with the original vmware workstation	virtualization;x86;virtual machine monitors;vmm;dynamic binary translation;hypervisors	This article describes the historical context, technical challenges, and main implementation techniques used by VMware Workstation to bring virtualization to the x86 architecture in 1999. Although virtual machine monitors (VMMs) had been around for decades, they were traditionally designed as part of monolithic, single-vendor architectures with explicit support for virtualization. In contrast, the x86 architecture lacked virtualization support, and the industry around it had disaggregated into an ecosystem, with different vendors controlling the computers, CPUs, peripherals, operating systems, and applications, none of them asking for virtualization. We chose to build our solution independently of these vendors.  As a result, VMware Workstation had to deal with new challenges associated with (i) the lack of virtualization support in the x86 architecture, (ii) the daunting complexity of the architecture itself, (iii) the need to support a broad combination of peripherals, and (iv) the need to offer a simple user experience within existing environments. These new challenges led us to a novel combination of well-known virtualization techniques, techniques from other domains, and new techniques.  VMware Workstation combined a hosted architecture with a VMM. The hosted architecture enabled a simple user experience and offered broad hardware compatibility. Rather than exposing I/O diversity to the virtual machines, VMware Workstation also relied on software emulation of I/O devices. The VMM combined a trap-and-emulate direct execution engine with a system-level dynamic binary translator to efficiently virtualize the x86 architecture and support most commodity operating systems. By relying on x86 hardware segmentation as a protection mechanism, the binary translator could execute translated code at near hardware speeds. The binary translator also relied on partial evaluation and adaptive retranslation to reduce the overall overheads of virtualization.  Written with the benefit of hindsight, this article shares the key lessons we learned from building the original system and from its later evolution.	binary translation;cpu modes;central processing unit;commodity computing;computer;data center;device driver;ecosystem;emulator;encapsulation (networking);exception handling;hardware virtualization;hypervisor;input/output;interaction;laptop;machine translation;mainframe computer;mobile device;operating system;partial evaluation;peripheral;protection mechanism;user experience;virtual machine manager;workstation;x86	Edouard Bugnion;Scott Devine;Mendel Rosenblum;Jeremy Sugerman;Edward Y. Wang	2012	ACM Trans. Comput. Syst.	10.1145/2382553.2382554	embedded system;full virtualization;real-time computing;virtualization;computer science;virtual machine;x86;operating system;hardware virtualization;distributed computing;hypervisor;programming language;computer network	OS	-28.960932032833167	55.42609743331089	38263
0e821fc86adb922236a9657b1703f0ee74e2d88d	sm-prof: a tool to visualise and find cache coherence performance bottlenecks in multiprocessor programs	datorsystem;computer systems;performance improvement;performance analysis;data access;cache coherence;matrix multiplication;source code	Cache misses due to coherence actions are often the major source for performance degradation in cache coherent multiprocessors. It is often difficult for the programmer to take cache coherence into account when writing the program since the resulting access pattern is not apparent until the program is executed.SM-prof is a performance analysis tool that addresses this problem by visualising the shared data access pattern in a diagram with links to the source code lines causing performance degrading access patterns. The execution of a program is divided into time slots and each data block is classified based on the accesses made to the block during a time slot. This enables the programmer to follow the execution over time and it is possible to track the exact position responsible for accesses causing many cache misses related to coherence actions.Matrix multiplication and the MP3D application from SPLASH are used to illustrate the use of SM-prof. For MP3D, SM-prof revealed performance limitations that resulted in a performance improvement of over 75%.The current implementation is based on program-driven simulation in order to achieve non-intrusive profiling. If a small perturbation of the program execution is acceptable, it is also possible to use software tracing techniques given that a data address can be related to the originating instruction.	cache coherence;coherence (physics);data access;diagram;elegant degradation;matrix multiplication;multiprocessing;profiling (computer programming);programmer;simulation;tracing (software)	Mats Brorsson	1995		10.1145/223587.223607	bus sniffing;data access;cache coherence;cache-oblivious algorithm;parallel computing;real-time computing;cache coloring;page cache;computer hardware;matrix multiplication;cache;computer science;cache invalidation;operating system;smart cache;mesi protocol;cache algorithms;cache pollution;mesif protocol;source code	HPC	-9.974533759646452	49.08057415567639	38277
26ba98160228eb1b4a8ae50e2c122a959ac709d3	a 3d-java tool to visualize loop-carried dependences	program visualizing;iteration space;loop transformation;timing analysis;data flow;nested loops;three dimensional	The interactive tool presented allows programmers to visualize and manipulate the three-dimensional iteration space dependence graph (ISDG). Constructed from the runtime analysis, it reveals the potential parallelism and permits the programmer to find suitable loop transformations which maximize the speedup. The tool manipulates it with a number of graphical operations such as rotations, zooms, cutting planes and projections. Once the runtime trace of the program is generated, the new iteration space of a unimodular or non-singular transformation can be constructed without having to rewrite and execute the transformed program. In addition the temporal behavior of the program is revealed by a stepby-step traversal animating the iterations presently executed as well as the past and the future iterations in either data-flow, loop-wise or plane-wise order. From the ISDG, a dependence distance matrix is derived for both uniform dependence and non-uniform dependence problems. It has been used to speedup a real-life computational fluid dynamics(CFD) program which is hard to parallelize with traditional compiler.	analysis of algorithms;compiler;computational fluid dynamics;dataflow;distance matrix;graphical user interface;integrated development environment;iteration;java;parallel computing;parameterized complexity;programmer;real life;rewrite (programming);speedup;tree traversal;unimodular polynomial matrix	Yijun Yu	1999			three-dimensional space;data flow diagram;real-time computing;nested loop join;computer science;theoretical computer science;distributed computing;static timing analysis	HPC	-17.41142332027338	34.258669066850494	38292
155d910ee8dece12aec9a6f200329ea990070d82	formal analysis of load balancing in microservices with scenario calculus		Load balancing plays a crucial role in realising the benefits of microservices, especially to achieve elastic scalability and performance optimisation. However, it is different from load balancing for virtual machines, because workloads on microservices are harder to predict and the number of services in the systems is large. In this paper, we formalise load balance as an emergent property of the microservices ecosystem, and employ scenario calculus to formally analyse the impact of scheduling on service capability and scalability. We discovered that elastic round robin scheduling is highly scalable but the service capability is limited by the slowest microservice instance. In contrast, shortest waiting queue scheduling is less scalable, but the service capability is higher.	ecosystem;emergence;load balancing (computing);mathematical optimization;microservices;round-robin scheduling;scalability;scheduling (computing);virtual machine	Hong Zhu;Hongbo Wang;Ian Bayley	2018	2018 IEEE 11th International Conference on Cloud Computing (CLOUD)	10.1109/CLOUD.2018.00133	computer science;real-time computing;microservices;job shop scheduling;scalability;scheduling (computing);round-robin scheduling;calculus;load balancing (computing);virtual machine;load management;distributed computing	HPC	-27.319299045158683	59.9448531306086	38308
21a1a7efc892c3c94d1c7b552035b289c2545ff9	a local-view array library for partitioned global address space c++ programs	just in time compilation;data parallelism;tracing;r	Multidimensional arrays are an important data structure in many scientific applications. Unfortunately, built-in support for such arrays is inadequate in C++, particularly in the distributed setting where bulk communication operations are required for good performance. In this paper, we present a multidimensional library for partitioned global address space (PGAS) programs, supporting the one-sided remote access and bulk operations of the PGAS model. The library is based on Titanium arrays, which have proven to provide good productivity and performance. These arrays provide a local view of data, where each rank constructs its own portion of a global data structure, matching the local view of execution common to PGAS programs and providing maximum flexibility in structuring global data. Unlike Titanium, which has its own compiler with array-specific analyses, optimizations, and code generation, we implement multidimensional arrays solely through a C++ library. The main goal of this effort is to provide a library-based implementation that can match the productivity and performance of a compiler-based approach. We implement the array library as an extension to UPC++, a C++ library for PGAS programs, and we extend Titanium arrays with specializations to improve performance. We evaluate the array library by porting four Titanium benchmarks to UPC++, demonstrating that it can achieve up to 25% better performance than Titanium without a significant increase in programmer effort.	acm/ieee supercomputing conference;array data structure;bsd;benchmark (computing);c++;carlson's theorem;chamberlain group, inc. v. skylink technologies, inc.;chapel;code generation (compiler);compiler;computation;computer;experiment;heterogeneous computing;ibm research;international parallel and distributed processing symposium;java;parallel computing;partitioned global address space;pike;programmer;programming language;spmd;software engineering;static program analysis;universal product code;x10;zpl	Amir Kamil;Yili Zheng;Katherine A. Yelick	2014		10.1145/2627373.2627378	computer architecture;parallel computing;real-time computing;computer science;partitioned global address space	PL	-12.935723808973345	36.97629896574831	38353
27c9c37df0c1e74321a12bc55ee54aa248871e7b	link performance model for system level simulations of filter bank multicarrier-based systems in pmr networks				Alexandra Oborina;Christian Ibars;Lorenza Giupponi;Faouzi Bader	2013			real-time computing;telecommunications	Metrics	-10.020444982561209	44.28023543551672	38364
e9c961ee227794ebf7a8644a9cbd392c65a87806	column-selection-enabled 8t sram array with ∼1r/1w multi-port operation for dvfs-enabled processors	sram chips;cache storage;microprocessor chips;power aware computing;two-port networks;dvfs-enabled processors;ipc enhancement;column selection enabled 8t sram array;instructions per cycle;multiport operation;multiway cache;one read-one write dual port;size 45 nm;write-back operation;8t sram;cache memory;dvfs;low-power	In this work, we propose a new multi-port 8T SRAM architecture suitable for DVFS enabled processors. With multi-way caches using 8T SRAM, write-back operations are required to support column selection. While conventional write-back schemes may not have the 1R/1W dual port advantage of 8T SRAM, our proposed local write-back scheme preserves both ports with only minimal limitations. Simulation results show significant IPC enhancements with the proposed cache. Implementation in 45nm technology demonstrates wide-range DVFS (from 120MHZ@0.48V to 710MHz@1V) for the proposed SRAM array.	cpu cache;cache (computing);central processing unit;dynamic voltage scaling;selection (user interface);simulation;static random-access memory	Sang Phill Park;Soo Youn Kim;Dongsoo Lee;Jae-Joon Kim;W. Paul Griffin;Kaushik Roy	2011	IEEE/ACM International Symposium on Low Power Electronics and Design			Arch	-9.284702167269467	53.50329537668667	38435
1957982f36b8dfaee5df7c9adadac408966e4c26	adaptive scheduling with parallelism feedback	data parallel;multiprocessor scheduling;parallel job scheduling;instantaneous parallelism;processor allocation;multiprocessing;parallelism feedback;multiprogramming;parallel computation;greedy scheduling;trim analysis;critical path;high performance fortran;work;two level scheduling;data parallel computing;parallel computer;adaptive scheduling;space sharing;adversary;task scheduling;job scheduling	"""Multiprocessor scheduling in a shared multiprogramming environment is often structured as two-level scheduling, where a kernel-level job scheduler allots processors to jobs and a user-level task scheduler schedules the work of a job on the allotted processors. In this context, the number of processors allotted to a particular job may vary during the job's execution, and the task scheduler must adapt to these changes in processor resources. For overall system efficiency, the task scheduler should also provide parallelism feedback to the job scheduler to avoid the situation where a job is allotted processors that it cannot use productively.We present an adaptive task scheduler for multitasked jobs with dependencies that provides continual parallelism feedback to the job scheduler in the form of requests for processors. Our scheduler guarantees that a job completes near optimally while utilizing at least a constant fraction of the allotted processor cycles. Our scheduler can be applied to schedule data-parallel programs, such as those written in High Performance Fortran (HPF), *Lisp, C*, NESL, and ZPL.Our analysis models the job scheduler as the task scheduler's adversary, challenging the task scheduler to be robust to the system environment and the job scheduler's administrative policies. For example, the job scheduler can make available a huge number of processors exactly when the job has little use for them. To analyze the performance of our adaptive task scheduler under this stringent adversarial assumption, we introduce a new technique called """"trim analysis,"""" which allows us to prove that our task scheduler performs poorly on at most a small number of time steps, exhibiting near-optimal behavior on the vast majority.To be precise, suppose that a job has work <i>T</i><inf>1</inf> and critical-path length <i>T</i><inf>∞</inf> and is running on a machine with <i>P</i> processors. Using trim analysis, we prove that our scheduler completes the job in <i>O</i>(<i>T</i><inf>1</inf>/<i>P</i> + <i>T</i><inf>∞</inf> + <i>L</i>lg <i>P</i>) time steps, where <i>L</i> is the length of a scheduling quantum and <i>P</i> denotes the <i>O</i>(<i>T</i><inf>∞</inf> + <i>L</i> lg <i>P</i>)-trimmed availability. This quantity is the average of the processor availability over all time steps excluding the <i>O</i>(<i>T</i><inf>∞</inf> + <i>L</i> lg <i>P</i>) time steps with the highest processor availability. When <i>T</i><inf>1</inf>/<i>T</i><inf>∞</inf> >> <i>P</i> (the job's parallelism dominates the <i>O</i>(<i>T</i><inf>∞</inf> + <i>L</i> lg <i>P</i>)-trimmed availability), the job achieves nearly perfect linear speedup. Conversely, when <i>T</i><inf>1</inf>/<i>T</i><inf>∞</inf> << <i>P</i>, the asymptotic running time of the job is nearly the length of its critical path."""	*lisp (starlisp);adversary (cryptography);central processing unit;computer multitasking;critical path method;environment variable;high performance fortran;job scheduler;job stream;lisp;multiprocessing;multiprocessor scheduling;nesl;parallel computing;scheduling (computing);speedup;time complexity;two-level scheduling;user space;windows task scheduler	Kunal Agrawal;Yuxiong He;Wen-Jing Hsu;Charles E. Leiserson	2006	2007 IEEE International Parallel and Distributed Processing Symposium	10.1145/1122971.1122988	fixed-priority pre-emptive scheduling;scheduler activations;parallel computing;real-time computing;multiprocessing;computer science;adversary;job scheduler;operating system;deadline scheduler;distributed computing;job queue;work;scheduling;multiprocessor scheduling	Theory	-17.559654428569967	56.58935434938455	38455
6cdc4f469f1b03a14eb9984b91839d514931db3b	colored petri net model with automatic parallelization on real-time multicore architectures	colored petri net cpn;期刊论文;task scheduling;model based design;multiprocessor system on chip mpsoc	This paper proposes a novel Colored Petri Net (CPN) based dynamic scheduling scheme, which aims at scheduling real-time tasks on multiprocessor system-on-chip (MPSoC) platforms. Our CPN based scheme addresses two key issues on task scheduling problems, dependence detecting and task dispatching. We model inter-task dependences using CPN, including true-dependences, output-dependences, anti-dependences and structural dependences. The dependences can be detected automatically during model execution. Additionally, the proposed model takes the checking of real-time constraints into consideration. We evaluated the scheduling scheme on the state-of-art FPGA based multiprocessor hardware system and modeled the system behavior using CPN tools. Simulations and state space analyses are conducted on the model. Experimental results demonstrate that our scheme can achieve 98.9% of the ideal speedup on a real FPGA based hardware prototype. 2013 Elsevier B.V. All rights reserved.	algorithm;automatic parallelization;central processing unit;coloured petri net;computer simulation;effective method;field-programmable gate array;integrated circuit;mpsoc;multi-core processor;multiprocessing;out-of-order execution;parallel computing;prototype;real-time clock;reconfigurable computing;scheduling (computing);scoreboarding;sensor;speedup;state space	Chao Wang;Xiaojing Feng;Xi Li;Xuehai Zhou;Peng Chen	2014	Journal of Systems Architecture - Embedded Systems Design	10.1016/j.sysarc.2013.08.016	embedded system;parallel computing;real-time computing;computer science;operating system;distributed computing;model-based design	Embedded	-7.5791172948942425	58.47405743852031	38488
1566fa6ca14f3a8e68c17def62fa994520eddd77	a probabilistic scheduling framework for mixed-criticality systems	mixed criticality scheduling;probabilistic logic processor scheduling timing real time systems switches program processors time factors;processor scheduling;time factors;probabilistic analysis;probabilistic analysis mixed criticality scheduling real time systems;probabilistic logic;switches;program processors;shared resource probabilistic scheduling framework mixed criticality systems;scheduling probability;real time systems;timing	We propose a probabilistic scheduling framework for the design and development of mixed-criticality systems, i.e., where tasks with different levels of criticality need to be scheduled on a shared resource. Whereas highly critical tasks normally require hard real-time guarantees, less or non-critical ones may be degraded or even temporarily discarded at runtime. We hence propose giving probabilistic (instead of deterministic) real-time guarantees on low-criticality tasks. This simplifies the analysis and reduces conservativeness on the one hand. On the other hand, probabilistic guarantees can be tuned by the designer to reach a desired level of assurance. We illustrate these and other benefits of our framework based on extensive simulations.	criticality matrix;mixed criticality;real-time clock;real-time computing;run time (program lifecycle phase);scheduling (computing);self-organized criticality;simulation	Alejandro Masrur	2016	2016 53nd ACM/EDAC/IEEE Design Automation Conference (DAC)	10.1145/2897937.2897971	fair-share scheduling;fixed-priority pre-emptive scheduling;parallel computing;probabilistic analysis of algorithms;real-time computing;earliest deadline first scheduling;dynamic priority scheduling;network switch;computer science;rate-monotonic scheduling;two-level scheduling;distributed computing;probabilistic logic;lottery scheduling	EDA	-9.276987176800517	60.10067348824543	38532
d200dc47663e47dd41921e116760e5a9089d77e6	architectural ccs	multiprocessors;ccs;distributed systems	In this article, we discuss the effect of architectures on behaviours and the notions of equivalence for CCS terms. Two types of architectures are considered viz, shared memory systems and distributed memory systems. Processes can be logically migrated in shared memory systems while in distributed memory systems, processes are bound to a location and require explicit migration. Communication in shared memory systems can follow the CCS principle. A complete equational characterisation of the bisimulation equivalence induced by the execution on multiprocessors requires an extended syntax; which captures the process of compiling and loading. To permit a realistic description of communication in distributed systems, asynchronous actions are required. Due to this the complete axiomatisation for the bisimulation equivalence is more sensitive to the causal structure of the processes. A practical interpretation to the complete axiomatisation of the bisimulation equivalence is also given.	axiomatic system;bisimulation;calculus of communicating systems;causal filter;central processing unit;compiler;distributed computing;distributed memory;hayes microcomputer products;hayes command set;multiprocessing;operational semantics;parallel computing;process migration;production (computer science);routing;shared memory;turing completeness;viz: the computer game	Padmanabhan Krishnan	1996	Formal Aspects of Computing	10.1007/BF01214555		Logic	-26.58526369629332	33.3494436384225	38535
84b975647055d5f464f23466241c9436fd1bdf7a	implementation of fine-grained algorithms on graphical processing unit	probabilistic cellular automata;graphic processing unit	In this paper we solve the problem of mapping of fine- grained algorithm to graphical processing unit (GPU). Synchronous, asynchronous, block-synchronous and probabilistic cellular automata and explicit scheme of PDE are used as examples. Different implementation variants and their performances are presented.	algorithm;graphics processing unit	Konstantin Kalgin	2009		10.1007/978-3-642-03275-2_21	stochastic cellular automaton;parallel computing;computer science;theoretical computer science;distributed computing	ML	-10.306148962119442	39.55180482227561	38616
c418f5f331eb0ef48a2f645fabf2b801edc97d7b	bounding loop iterations for timing analysis	real time;parallel programming;timing electronic mail counting circuits pipeline processing optimizing compilers optimization methods application software parallel processing real time systems computer science;timing analysis predictions bounding loop iterations static timing analyzers real time program accurate timing predictions loop invariant variables minimum values maximum values execution time prediction counter variables outer level loops caching pipelining;wcet;parallel programming real time systems pipeline processing;timing analysis;static analysis;pipeline processing;real time systems	Static timing analyzer s need to know the minimum and maximum number of iterations associated with eac h loop in a real-time pr ogram so accurate timing pr edictions can be obtained.This paper describes three complementary methods to support timing analysis by bounding the number of loop iter ations. First, an algorithm is pr esented that determines the minimum and maximum number of iterations of loops with multiple e xits. Second, the loopinvariant variables on whic h the number of loop iter ations depends ar e identified for whic h the user can pr ovide minimum and maximum values. Finally, a method is given to tightly predict the execution time of loops whose number of iterations is dependent on counter variables of outer level loops. These methods have been successfully integrated in an existing timing analyzer that predicts the per formance for optimized code on a machine that e xploits caching and pipelining. The result is tighter timing analysis predictions and less work for the user.	algorithm;iteration;need to know;pipeline (computing);real-time clock;run time (program lifecycle phase);static timing analysis	Christopher A. Healy;Mikael Sjödin;Viresh Rustagi;David B. Whalley	1998		10.1109/RTTAS.1998.683183	embedded system;parallel computing;real-time computing;computer science;theoretical computer science;operating system;loop counter;static timing analysis;static analysis	EDA	-7.4023631125254745	57.486681604714434	38637
6714168d80b16069573b49d8cf7ef58f2939a5c6	algorithms for data placement, reconfiguration and monitoring in storage networks	computer science algorithms for data placement;srinivas raaghav;college park samir khuller kashyap;dissertation;reconfiguration and monitoring in storage networks university of maryland	Title of dissertation: ALGORITHMS FOR DATA PLACEMENT, RECONFIGURATION AND MONITORING IN STORAGE NETWORKS Srinivas Raaghav Kashyap Doctor of Philosophy, 2007 Dissertation directed by: Professor Samir Khuller Department of Computer Science In this thesis we address three problems related to self-management of storage networks data placement, data reconfiguration and data monitoring. Examples of such storage networks include centrally managed systems like Storage Area Networks and Network Attached Storage devices, or even highly distributed systems like a P2P network or a Sensor Network. One of the crucial functions of a storage system is that of deciding the placement of data within the system. This data placement is dependent on the demand pattern for the data and subject to constraints of the storage system. For instance, if a particular data item is very popular the storage system might want to host it on a disk with high bandwidth or make multiple copies of the item. We present new results for some of these data placement problems. As the demand pattern changes over time, the storage system will have to modify its placement accordingly. Such a modification in placement will typically involve movement of data items from one set of disks to another or changing the number of copies of a data item in the system. For such a modification to be effective, it should be computed and applied quickly since the system is running inefficiently during this reconfiguration. We propose new schemes to reconfigure the data placement to deal with changing demand. To re-compute data placement periodically and to reconfigure the data placement, we need to continuously track of the demand distribution in the storage system and also be able to answer aggregate queries about the demand distribution. The data monitoring portion of the thesis deals with such problems that arise in the context of distributed data management applications. A monitoring system for such a scenario would need to process large amounts of data from a widely distributed set of data sources. The thesis presents new schemes that improve communicationefficiency of existing methods that address these problems.	aggregate data;algorithm;computer data storage;data item;distributed computing;information retrieval;network-attached storage;peer-to-peer;samir khuller;self-management (computer science);storage area network	Srinivas R. Kashyap	2007			real-time computing;computer science;database;distributed computing;data efficiency;information repository	DB	-20.57459231817051	53.2020452303938	38650
a4699c22ad3c704a9b9b62d1b3a0d935337b4082	a software-based hardware fault tolerance scheme for multicomputers.	error recovery;shared memory;fault tolerant;interactive application;high performance;high speed	A hardware fault tolerance scheme for large multicomputers executing time-consuming non-interactive applications is described. Error detection and recovery are done mostly by software with little hardware support. The scheme is based on simultaneous execution of identical copies of the application on two subnetworks of the system. Normal system operation is periodically suspended and the logical states of the two subnetworks are synchronized. Errors are detected by comparing the ‘‘frozen’’ synchronized states of the two subnetworks while they are being saved as ‘‘checkpoints’’ for possible subsequent use for error recovery. Algorithms for error detection and recovery using this scheme are discussed.	algorithm;computation;converge;distributed computing;error detection and correction;fail-safe;fault tolerance;general material designation;interactivity;overhead (computing);requirement;sensor	Yuval Tamir;Eli Gafni	1987			shared memory;fault tolerance;parallel computing;real-time computing;computer science;operating system;distributed computing;software fault tolerance	OS	-19.518939024419232	47.909392027816686	38787
f6269f1a435a699e4b2f686c333693a161911670	fundamental limitations on the use of prefetching and stream buffers for scientific applications	scientific application;high performance computing;prefetching;supercomputer;computer architecture;high performance computer;memory systems;memory hierarchy;stream buffers;vector processor	Many researchers have noted that scientific codes perform poorly on computer architectures involving a memory hierarchy. At the same time, there have been numerous papers discussing the Memory Wall (for example the Workshop on Solving the Memory Wall Problem to be held in conjunction with the 27th International Symposium on Computer Architecture [ISCA 27]). One commonly discussed solution to the problem is using some combination of prefetching and stream buffers. However, there are significant practical limitations to this approach. When taken to the extreme, one will be essentially reinventing the CDC CYBER 205, a vector processor that streamed data directly between main memory and the vector units and was far less successful than the Cray X-MP. Some of those limitations will be discussed in this paper. Furthermore, it will be proposed that the combination of coding changes (primarily at the implementation level), large caches, prefetching/stream buffers, and a welldesigned memory system can overcome many of those limitations. † SAC 2001, Las Vegas, NV ISBN 1-58113-324-3/01/02 * This work was partially funded by a grant from the DOD High Performance Computing Modernization Office (CHSSI project CFD-6). Furthermore, it received grants of computer time at the ARL-MSRC, NAVO-MSRC, TARDEC-DC, NRL-DC, and the SSCSD. All items bolded are defined in the glossary.	cdc cyber;cpu cache;code;computer data storage;cray x-mp;glossary;input/output (c++);international standard book number;international symposium on computer architecture;memory hierarchy;nv network;random-access memory;streaming media;vector processor	Daniel M. Pressel	2001		10.1145/372202.372460	computer architecture;supercomputer;vector processor;parallel computing;computer science;operating system	Arch	-10.498931412140726	48.18364841151907	38798
1e7f634ad63ceef8da03d7eb6c3e93f20d58362f	dynamic memory interval test vs. interprocedural pointer analysis in multimedia applications	multimedia;pointer analysis;multimedia application;vliw;memory access;memory disambiguation;it evaluation	Techniques to detect aliasing between access patterns of array elements are quite effective for many numeric applications. However, although multimedia codes usually follow very regular memory access patterns, current commercial compilers remain unsuccessful in disambiguating them due mainly to complex pointer references. The Dynamic Memory Interval Test is a runtime memory disambiguation technique that takes advantage of the specific behavior of multimedia memory access patterns. It evaluates whether or not the full loop is disambiguated by analyzing the region domain of each load or store before each invocation of the loop.This paper provides a detailed evaluation of the approach, compares it against an advanced interprocedural pointer analysis framework, and analyzes the possibility of using both techniques at the same time. Both techniques achieve similar speedups separately (1.25X in average for a 8-issue width architecture). Furthermore, they can be used together to improve performance (reaching an average speed-up of 1.32X). Results also confirm that memory disambiguation is a key optimization to exploit the available parallelism in multimedia codes, especially for wide-issue architectures (1.50X average speed-up when scaling from 4- to 12-issue width in contrast to a low 1.10X for the baseline compiler).	aliasing;baseline (configuration management);code;compiler;image scaling;internationalized domain name;mathematical optimization;memory disambiguation;memory management;parallel computing;pointer (computer programming);pointer analysis;wide-issue;word-sense disambiguation	Esther Salamí;Mateo Valero	2005	TACO	10.1145/1071604.1071608	uniform memory access;interleaved memory;parallel computing;real-time computing;computer science;very long instruction word;operating system;programming language;pointer analysis;memory map;memory management	HPC	-7.727977024699455	52.05549376798835	38811
52bb4b7f6a3862009030892419b19d93ff12ebb7	adaptive object code compression	compression algorithm;instruction cache;embedded system;timing optimization;control flow;code size;code compaction;data structure;code size reduction;code compression;partial order	Previous object code compression schemes have employed static and semiadaptive compression algorithms to reduce the size of instruction memory in embedded systems. The suggestion by a number of researchers that adaptive compression techniques are unlikely to yield satisfactory results for code compression has resulted in virtually no investigation of their application to that domain. This paper presents a new adaptive approach to code compression which operates at the granularity of a program's cache lines, where the context for compression is determined by an analysis of control flow in the code being compressed. We introduce a novel data structure, the compulsory miss tree, that is used to identify a partial order in which compulsory misses will have occurred in an instruction cache whenever a cache miss occurs. This tree is used as a basis for dynamically building and maintaining an LZW dictionary for compression/decompression of individual instruction cache lines. We applied our technique to eight benchmarks taken from the MiBench and MediaBench suites, which were compiled with size optimization and subsequently compacted using a link-time optimizer prior to compression.Results from our experiments demonstrate object code size elimination averaging between 7.7% and 18.3% of the original linked code size, depending on the cache line length under inspection.	adaptive compression;algorithm;cpu cache;cache (computing);compiler;control flow;data compression;data structure;dictionary;embedded system;experiment;lempel–ziv–welch;linker (computing);mathematical optimization;object code	John Gilbert;David M. Abrahamson	2006		10.1145/1176760.1176795	data compression;partially ordered set;dead code;self-modifying code;embedded system;parallel computing;real-time computing;data structure;computer science;theoretical computer science;operating system;dead code elimination;redundant code;lossless compression;programming language;control flow;cache algorithms;unreachable code	PL	-18.41760862422486	36.139085650608045	38816
384096cd30358c5e5cbdd641d3a7f6a4ce230c17	the algorithmics of write optimization		Write-optimized dictionaries (WODs), such as LSM trees and B^epsilon trees, are increasingly used in databases and file systems. Such data structures support very fast insertions without sacrificing lookup performance. This talk explains how WODs can substantially reduce the I/O cost of many workloads, enabling some applications to scale by orders of magnitude. In contrast, traditional data structures, such as B-trees, are often I/O bound on these workloads. The talk explores write-optimization from the perspective of foundational theory, parallelization, and applications.	algorithmics;b-tree;data structure;database;dictionary;input/output;lookup table;mathematical optimization;parallel computing	Michael A. Bender	2018	2018 IEEE International Parallel and Distributed Processing Symposium (IPDPS)	10.1109/IPDPS.2018.00010	computer science;distributed computing;orders of magnitude (numbers);distributed database;data structure;algorithmics	Arch	-12.354101871136853	51.39787513759567	38825
7d2a8d2a3100db235e4542f740a2024097eb1c03	air pollution modelling using a graphics processing unit with cuda	parallel computing;video card;air pollution modelling;transport phenomena;compute unified device architecture;cuda;point source;parallel computer architecture;air pollution;parallel computer;graphic processing unit;parallel implementation;parallel architecture;particle modeling;environmental application	a r t i c l e i n f o a b s t r a c t The Graphics Processing Unit (GPU) is a powerful tool for parallel computing. In the past years the performance and capabilities of GPUs have increased, and the Compute Unified Device Architecture (CUDA) – a parallel computing architecture – has been developed by NVIDIA to utilize this performance in general purpose computations. Here we show for the first time a possible application of GPU for environmental studies serving as a basement for decision making strategies. A stochastic Lagrangian particle model has been developed on CUDA to estimate the transport and the transformation of the radionuclides from a single point source during an accidental release. Our results show that parallel implementation achieves typical acceleration values in the order of 80–120 times compared to CPU using a single-threaded implementation on a 2.33 GHz desktop computer. Only very small differences have been found between the results obtained from GPU and CPU simulations, which are comparable with the effect of stochastic transport phenomena in atmosphere. The relatively high speedup with no additional costs to maintain this parallel architecture could result in a wide usage of GPU for diversified environmental applications in the near future.	atmospheric dispersion modeling;cuda;central processing unit;computation;computer architecture;computer simulation;cost efficiency;decision support system;desktop computer;error-tolerant design;general-purpose computing on graphics processing units;graphics processing unit;numerical analysis;parallel computing;speedup;thread (computing);turbulence	F. Molnár;T. Szakály;Róbert Mészáros;István Lagzi	2010	Computer Physics Communications	10.1016/j.cpc.2009.09.008	cuda pinned memory;parallel computing;point source;computer science;theoretical computer science;transport phenomena;general-purpose computing on graphics processing units;physics;air pollution;computer graphics (images)	HPC	-5.564328015346308	36.624885674091836	38848
83edbf07409d83fdecc5b48a4e646b2bf5939fc0	dynamic load balancing mechanisms for a parallel operating system kernel	dynamic load balancing;genetics;simulation experiment;operating system;parallel systems;load balance;parallel programs;task allocation	In this paper, we present the task allocation tool for the PAROS PARallel Operating System. Such a tool becomes necessary in case of highly parallel systems where load balancing is a key feature for performances enhancement. PAROS tasks allocation tool achieves load balancing through three cooperating components. First, a parallel static allocation algorithm (this is based on an original parallel genetic approach) is used to map parallel programs on available processors of the target architecture. Second, a dynamic allocation algorithm allocates run-time created tasks. Finally, a task migration mechanism is used for fine tuning system load balance situations when mere allocation strategies are not sufficient. Some simulation experiments are presented to evaluate the performances of the proposed allocation tool.	load balancing (computing);operating system	A. Elleuch;Rushed Kanawati;Traian Muntean;El-Ghazali Talbi	1994		10.1007/3-540-58430-7_75	parallel computing;real-time computing;distributed computing	HPC	-14.764505012689728	59.41615953774476	38851
2b01111f33085a3855c01d14c7af4d157beb0ebf	an algorithm for entering mathematical functions as input to a fortran program	fortran	An algorithm which emulates the function of an HP45 calculator is presented to input mathematical functions as data into a compiled FORTRAN program. This algorithm obviates the need to reprogram and recompile subroutines containing functions which frequently need to be changed. INTRODUCTION In a number of programming applications it is frequently necessary to make modifications to a program and recompile it because some functions are being changed in one of the subroutines. For example, in performing nonlinear least squares calculations one is frequently faced with the annoying prospect of having to make changes in the Jacobian subroutines because a new model function is to be fit to the experimental data. Or, in many sophisticated plotting routines one has to write and compile a separate subroutine to supply the function of interest to the graphics routines. In our research in the area of gas phase electron diffraction we too have frequently been confronted with this problem, and we have often desired a technique which would permit one to enter mathematical functions as input to a compiled version of a program at execution time. We devised a relatively simple algorithm which performs this operation in much the same manner as a Hewlett Packard calculator using Reverse Polish Notation (RPN). What we wanted was an algorithm which could parse a functional expression and evaluate it at execution time. It would have been desirable to enter the mathematical expressions in algebraic notation with nested parentheses, but this approach was too complex to program easily. So, instead, we decided to write a parsing algorithm which would emulate an HP 45 calculator using X, y, z and t registers and RPN. The resulting algorithm is relatively easy to use, and with a little practice even large and complex functions can be routinely entered as data. Since we have developed the original algorithm we have discovered numerous uses for it in our research. We routinely use it in performing Cartesian coordinate calculations (Hilderbrandt, 1969) where we employ complex functions to transform from one set of structural parameters to a set of input parameters which are used by our model builder routine. We also use it to specify the form of multiparameter multidimensional potential functions (and their derivatives) for large amplitude motions (Tamagawa & Hilderbrandt, 1983). Other possible applications would be specifying the equations for energy functions in molecular tAuthor to whom correspondence should be addressed. mechanics calculations (Hilderbrandt, 1977), or perhaps inputting functional forms for molecular orbital surface plotting programs. THE ALGORITHM The FORTRAN function subroutine called HUEY (Hewlett Packard HP45 emulator) is shown in Listing I. The subroutine has only one call parameter, the number of the function to be evaluated. All of the rest of the information needed by the routine is passed through the common block PAR. In all of our applications the same set of parameters are used in many function evaluations so it was convenient to read in a parameters list separately and then refer to the parameters by number in the RPN function expressions. Two singly dimensioned arrays are used to pass the parameter names (RNAME) and the parameter values (PR) to the subroutine. HUEY does not use the parameter names but they are used in other parts of the application program. The character strings corresponding to the functions themselves are passed in the two dimensional array IFUNC. The version of the subroutine shown in the listing allows for up to 20 function definitions consisting of up to 80 characters each, but this is easily modified. Note also that not all of the parameters have to be input parameters; it is frequently convenient to pass parameters to the routine which are being calculated internally in the program such as the independent variables in a plotting routine. As with the HP45 calculator the parameters in the function to be evaluated are entered into the x register which is at the top of the stack. The contents of each of the n, y and z registers are then pushed down on the stack with the old value of x going into they register, etc. When a unary operation is performed, such as sin, square root, COS, etc. the operation is applied to the contents of the x register and the contents of the x register is replaced with the result. When binary operations such as +, -, / or * are performed, they are applied to the contents of both the x and y registers. The result of a binary operation is placed in the x register, and the stack moves up with the old contents of the z register replacing the contents of the y register, and the old contents of the t register replacing the contents of the I register. Each function	algorithm;cos;cartesian closed category;compiler;electron diffraction;emulator;fortran;graphics;jacobian matrix and determinant;linear algebra;molecular orbital;non-linear least squares;parsing;reverse polish notation;run time (program lifecycle phase);subroutine;unary operation	J. R. Kingsley;R. L. Hilderbrandt	1985	Computers & Chemistry	10.1016/0097-8485(85)85006-3	biology;computational science;chemistry;computer science;programming language	PL	-12.333708444364241	34.63546620695768	38880
8bfc7a26da85c8761b2abcb29eacf56f1b912485	stapl: an adaptive, generic parallel c++ library	parallelisme;distributed memory;lenguaje programacion;stl format;metodo adaptativo;library design;modele geometrique;lien hypertexte;methode particulaire;sequential consistency;compilateur;programming language;geometrie algorithmique;enlace hipertexto;standard template adaptive parallel library;memoria compartida;memoria virtualmente compartida;quimica matematica;chainage donnee;computational geometry;distributed computing;molecular dynamics;hyperlink;mathematical chemistry;metodo particula;ejecucion programa;methode adaptative;compiler;dynamic linking;program execution;dynamique moleculaire;memoire virtuellement partagee;particle method;molecular dynamics method;mouvement particule;parallelism;paralelismo;standard template library;transporte particula;particle motion;execution programme;movimiento particula;estructura datos;adaptive method;data link;graph algorithm;langage programmation;calculo repartido;molecular dynamic;format stl;geometria computacional;structure donnee;functionality;geometric model;methode dynamique moleculaire;fonctionnalite;dinamica molecular;memoire repartie;distributed shared memory;transport particule;data structure;calcul reparti;particle transport;funcionalidad;compilador;stl;chimie mathematique;geometrical model;metodo dinamico molecular;modelo geometrico;ligazon datos	The Standard Template Adaptive Parallel Library (STAPL) is a parallel library designed as a superset of the ANSI C++ Standard Template Library (STL). It is sequentially consistent for functions with the same name, and executes on unior multi-processor systems that utilize shared or distributed memory. STAPL is implemented using simple parallel extensions of C++ that currently provide a SPMD model of parallelism, and supports nested parallelism. The library is intended to be general purpose, but emphasizes irregular programs to allow the exploitation of parallelism in areas such as particle transport calculations, molecular dynamics, geometric modeling, and graph algorithms, which use dynamically linked data structures. STAPL provides several different algorithms for some library routines, and selects among them adaptively at run-time. STAPL can replace STL automatically by invoking a preprocessing translation phase. The performance of translated code is close to the results obtained using STAPL directly (less than 5% performance deterioration). However, STAPL also provides functionality to allow the user to further optimize the code and achieve additional performance gains. We present results obtained using STAPL for a molecular dynamics code and a particle transport code.	ansi c;algorithm;c++;central processing unit;compiler;cylinder-head-sector;data structure;distributed memory;experiment;foreign function interface;geometric modeling;graph theory;iterator;library (computing);linked data;machine translation;memory management;molecular dynamics;multiprocessing;parallel extensions;parallel computing;preprocessor;recursion;runtime system;spmd;scalability;semiconductor industry;speedup;standard template library;stapl	Ping An;Alin Jula;Silvius Rus;Steven Saunders;Timmie G. Smith;Ilie Gabriel Tanase;Nathan E Thomas;Nancy M. Amato;Lawrence Rauchwerger	2001		10.1007/3-540-35767-X_13	distributed shared memory;molecular dynamics;compiler;parallel computing;standard template library;distributed memory;data link;computer science;theoretical computer science;geometric modeling;hyperlink;programming language;magnetosphere particle motion;sequential consistency;algorithm	HPC	-16.558647735493555	41.95310106903792	38913
734e7a3168fa8f9d4e4870aa75e803de35d1bd43	beehive: simple distributed programming in software-defined networks	openflow;distributed control platforms;programming abstraction;software defined networking	In this paper, we present the design and implementation of Beehive, a distributed control platform with a simple programming model. In Beehive, control applications are centralized asynchronous message handlers that optionally store their state in dictionaries. Beehive's control platform automatically infers the keys required to process a message, and guarantees that each key is only handled by one light-weight thread of execution (i.e., bee) among all controllers (i.e., hives) in the platform. With that, Beehive transforms a centralized application into a distributed system, while preserving the application's intended behavior. Beehive replicates the dictionaries of control applications consistently through mini-quorums (i.e., colonies), instruments applications at runtime, and dynamically changes the placement of control applications (i.e., live migrates bees) to optimize the control plane. Our implementation of Beehive is open source, high-throughput and capable of fast failovers. We have implemented an SDN controller on top of Beehive that can handle 200K of OpenFlow messages per machine, while persisting and replicating the state of control applications. We also demonstrate that, not only can Beehive tolerate faults, but also it is capable of optimizing control applications after a failure or a change in the workload.	centralized computing;control plane;dictionary;distributed computing;distributed control system;high-throughput computing;light-weight process;open-source software;openflow;programming model;run time (program lifecycle phase);software-defined networking;thread (computing);throughput;user error	Soheil Hassas Yeganeh;Yashar Ganjali	2016		10.1145/2890955.2890958	embedded system;real-time computing;engineering;distributed computing	Networks	-24.03307505251454	51.57263444225441	38932
7bebc706688166831c610352cb9acc23523c4928	the design of the paclib kernel for parallel algebraic computation	parallel algorithm;shared memory;efficient implementation	This paper describes the runtime kernel of Paclib, a new system for parallel algebraic computation on shared memory computers. Paclib has been developed as a professional tool for the simple design and eecient implementation of parallel algorithms in computer algebra and related areas. It provides concurrency, shared memory communication , non-determinism, speculative parallelism, streams and a paralleli-zed garbage collection. We explain the main design decisions as motivated by the special demands of algebraic computation and give several benchmarks that demonstrate the performance of the system. Paclib has been implemented on a Sequent Symmetry multiprocessor and is portable to other shared memory machines and workstations.	application programming interface;benchmark (computing);central processing unit;computer;concurrency (computer science);garbage collection (computer science);kernel (operating system);linear algebra;linear equation;multiprocessing;nondeterministic algorithm;parallel algorithm;parallel computing;resultant;streams;shared memory;speculative execution;symbolic computation;workstation	Wolfgang Schreiner;Hoon Hong	1993		10.1007/3-540-57314-3_17	computer architecture;parallel computing;theoretical computer science;parallel algorithm;cost efficiency	Arch	-10.415059546472701	40.824461462673824	39003
07b2fed50ceaf0ff40e7cc89dede09e10d35c5e0	p∗: a model of pilot-abstractions	analytical models;kernel;processor scheduling;resource allocation;pilot api implementation pilot abstractions model distributed resource utilization production distributed cyberinfrastructures conceptual model pilot job implementations interoperability extensibility p model pilot job frameworks;computational modeling;abstracts;application program interfaces;distributed databases;computational modeling data models kernel processor scheduling analytical models abstracts distributed databases;resource allocation application program interfaces open systems parallel processing;open systems;parallel processing;data models	Pilot-Jobs support effective distributed resource utilization, and are arguably one of the most widely-used distributed computing abstractions - as measured by the number and types of applications that use them, as well as the number of production distributed cyberinfrastructures that support them. In spite of broad uptake, there does not exist a well-defined, unifying conceptual model of Pilot-Jobs which can be used to define, compare and contrast different implementations. Often Pilot-Job implementations are strongly coupled to the distributed cyber-infrastructure they were originally designed for. These factors present a barrier to extensibility and interoperability. This paper is an attempt to (i) provide a minimal but complete model (P*) of Pilot-Jobs, (ii) establish the generality of the P* Model by mapping various existing and well known Pilot-Job frameworks such as Condor and DIANE to P*, (iii) derive an interoperable and extensible API for the P* Model (Pilot-API), (iv) validate the implementation of the Pilot-API by concurrently using multiple distinct Pilot-Job frameworks on distinct production distributed cyberinfrastructures, and (v) apply the P* Model to Pilot-Data.	application programming interface;distributed computing;emoticon;extensibility;interoperability;pilot job	André Luckow;Mark Santcroos;Ole Weidner;André Merzky;Pradeep Kumar Mantha;Shantenu Jha	2012	2012 IEEE 8th International Conference on E-Science	10.1109/eScience.2012.6404423	data modeling;parallel processing;parallel computing;kernel;real-time computing;resource allocation;computer science;operating system;database;distributed computing;open system;programming language;computational model	DB	-29.04081440536045	51.309523084135485	39023
ee03d7cb18c66095bf0490d95655bfc2064dd9ff	throughput calculation for basic stochastic rendezvous networks	tratamiento paralelo;file attente;modelizacion;distributed system;evaluation performance;systeme reparti;performance evaluation;traitement parallele;red petri;evaluacion prestacion;sistema informatico;reseau ordinateur;queue;concurrent program;computer system;computer network;modelisation;sistema repartido;programa competidor;red ordenador;systeme informatique;petri net;modeling;fila espera;parallel processing;reseau petri;programme concurrent	Distributed computer programs using rendezvous for intertask communication have performance effects due to tasks waiting for rendezvous. Tasks have a dual nature as being both servers of requests and customers in making requests of other tasks. In a previous paper, such tasks have been termed ‘active servers’. In this paper, a distributed program is modelled as a stochastic network of tasks related by their rendezvous requests. For purposes of defining the throughput, the tasks are assumed to have maximum concurrency as if each task were executed on its own processor. For small networks, exact throughput values can be found by translating them into equivalent times Petri nets, and the translation procedure is given as an algorithm. An approximation suitable for larger networks, which was found to be accurate to within a few percent in most of the cases tested, is also given.	throughput	C. Murray Woodside	1989	Perform. Eval.	10.1016/0166-5316(89)90039-4	parallel processing;real-time computing;simulation;systems modeling;computer science;distributed computing;petri net;queue;computer network	ML	-18.629020724115765	46.379625323959125	39044
bdbe5d02479b9f7c375cb545007343ce7b3ba795	languages and compilers for parallel computing: 20th international workshop, lcpc 2007, urbana, il, usa, october 11-13, 2007, revised selected papers	parallel computer	Reliability.- Compiler-Enhanced Incremental Checkpointing.- Techniques for Efficient Software Checking.- Languages.- Revisiting SIMD Programming.- Multidimensional Blocking in UPC.- An Experimental Evaluation of the New OpenMP Tasking Model.- Language Extensions in Support of Compiler Parallelization.- Parallel Compiler Technology I.- Concurrency Analysis for Shared Memory Programs with Textually Unaligned Barriers.- Iteration Disambiguation for Parallelism Identification in Time-Sliced Applications.- A Novel Asynchronous Software Cache Implementation for the Cell-BE Processor.- Pillar: A Parallel Implementation Language.- Associative Parallel Containers in STAPL.- Explicit Dependence Metadata in an Active Visual Effects Library.- Supporting Huge Address Spaces in a Virtual Machine for Java on a Cluster.- Modeling Relations between Inputs and Dynamic Behavior for General Programs.- Evaluation of RDMA Opportunities in an Object-Oriented DSM.- Automatic Communication Performance Debugging in PGAS Languages.- Parallel Compiler Technology II.- Exploiting SIMD Parallelism with the CGiS Compiler Framework.- Critical Block Scheduling: A Thread-Level Parallelizing Mechanism for a Heterogeneous Chip Multiprocessor Architecture.- Languages II.- Capsules: Expressing Composable Computations in a Parallel Programming Model.- Communicating Multiprocessor-Tasks.- An Effective Automated Approach to Specialization of Code.- Flow-Sensitive Loop-Variant Variable Classification in Linear Time.- Using ZBDDs in Points-to Analysis.		Vikram S. Adve;María Jesús Garzarán;Paul M. Petersen	2007		10.1007/978-3-540-85261-2	computer architecture;parallel computing;compiler construction;compiled language;programming language	HPC	-27.66683956917083	36.3505808731925	39058
0027aa55e4aa3a2963e0306fb942b8069af8197a	cost and performance analysis of a distributed computing environment	distributed computing environment		distributed computing environment;profiling (computer programming)	Toby Olberding	1989			autonomic computing;distributed algorithm;grid computing;distributed concurrency control;utility computing;distributed computing environment;computer science;distributed design patterns;distributed computing	HPC	-29.31944275681921	46.95247468520158	39061
3d61d8e89c11910049fba2283afb8d8541978057	ompio: a modular software architecture for mpi i/o	o architecture;arbitrary number;smaller unit;high-end machine;new parallel;o functionality;external parameter;large scale parallel application;modular software architecture;modular approach;customized selection criterion	I/O is probably the most limiting factor on high-end machines for large scale parallel applications as of today. This paper introduces OMPIO, a new parallel I/O architecture for OpenMPI. OMPIO provides a highly modular approach to parallel I/O by separating I/O functionality into smaller units (frameworks) and an arbitrary number of modules in each framework. Furthermore, each framework has a customized selection criteria that determines which module to use depending on the functionality of the framework as well as external parameters.	asynchronous i/o;foremost;input/output;lustre;modular programming;non-blocking algorithm;open mpi;parallel i/o;parallel virtual file system;software architecture;usability	Mohamad Chaarawi;Edgar Gabriel;Rainer Keller;Richard L. Graham;George Bosilca;Jack J. Dongarra	2011		10.1007/978-3-642-24449-0_11	computer architecture;computer science;theoretical computer science;distributed computing	HPC	-11.630467700059098	44.32954834330683	39064
142472f34028d13747ea688ef414e4d446a4605a	parallel algorithms for two processors precedence constraint scheduling			parallel algorithm;scheduling (computing)	Maria J. Serna	2016		10.1007/978-1-4939-2864-4_279	parallel computing;parallel algorithm;scheduling (computing);analysis of parallel algorithms;computer science	AI	-9.792882842182038	42.58093366244535	39066
39e2cde7f7bd89aa089b08965ed516f7fc00c787	latency hiding in dynamic partitioning and load balancing of grid computing applications	data transmission;latency hiding;parallel distributed processing;information power grid;parallel processing resource allocation security of data wide area networks software performance evaluation;adaptive mesh;resource allocation;large scale distributed computations;performance;simulation;heterogeneous environment;distributed computing;software performance evaluation;dynamic loads;power system dynamics;latency tolerance;latency tolerant partitioning scheme;interconnection network;large scale;synchronism;globus environment;unsteady adaptive mesh application;high speed asynchronous interconnection network;processor workload balancing;dynamic partitioning;load management;balancing;load balancing;parallel processing computers;load balance;high speed asynchronous interconnection network latency hiding dynamic partitioning load balancing grid computing information power grid nasa metacomputing large scale distributed computations data security latency tolerant partitioning scheme processor workload balancing unsteady adaptive mesh application wide area network performance globus environment parallel distributed processing experimental results;computational grids;power grids;metacomputing;delay load management power system dynamics power grids nasa metacomputing large scale systems distributed computing grid computing data security;experimental results;nasa;grid computing;high speed;security of data;parallel processing;wide area network;wide area networks;heterogeneity;large scale systems;data security	The b_formation Power Grid (IPG) concept developed by NASA is aimed to provide a metacomputing platform for large-scale distributed computations, by hiding the intricacies of a highly heterogeneous environment and yet maintaining adequate security. In this paper, we propose a latency-tolerant partitioning scheme that dynamically balances processor workloads on the !PG, and minimizes data movement and runtime communication. By simulating an unsteady adaptive mesh application on a wide area network, we study the performance of our load balancer under the Globus environment. The number of IPG nodes, the number of processors per node, attd the interconnect speeds are paramelerized to derive conditions under which the IPG would be suitable for parallel distributed processing of such applications. Experimental results demonstrate that effective solutions are achieved when the 1PG nodes are connected by a high-speed asynchronous interconnec!i.o, _:et,;'ork.	central processing unit;computation;connectionism;distributed computing;grid computing;interrupt latency;load balancing (computing);metacomputing;simulation	Sajal K. Das;Daniel J. Harvey;Rupak Biswas	2001		10.1109/CCGRID.2001.923212	parallel processing;parallel computing;real-time computing;computer science;load balancing;operating system;distributed computing	HPC	-12.338955039163757	47.311239110574704	39142
0a3ebad7f91f35c81fd40201b51cd78257d9f45f	using an automated planner to control an organic middleware	automated planning;distributed system;optimisation;middleware automated planning organic computing;organic manager organic middleware organic computing systems self organizing techniques distributed systems self configuration self healing self optimization;organic computing;optimisation fault tolerant computing middleware;fault tolerant computing;self organization;middleware;planning middleware numerical models monitoring computer architecture load modeling connectors	Organic Computing Systems feature self-organizing techniques to manage the rising complexity of distributed systems. This paper introduces an implementation of self-configuration, self-healing and self-optimization by means of an Organic Manager. The Organic Manager is based on an automated planner and integrated in a middleware. The Organic Manager unites formerly distributed self-x features to use synergetic effects. An evaluation with four scenarios compares the behavior of the system under two different planning models. We show that an automated planner can lead to an optimized system quickly and reliably.	automated planning and scheduling;distributed computing;mathematical optimization;middleware;organic computing;organizing (structure);self-organization;synergetics (fuller)	Julia Schmitt;Michael Roth;Rolf Kiefhaber;Florian Kluge;Theo Ungerer	2011	2011 IEEE Fifth International Conference on Self-Adaptive and Self-Organizing Systems	10.1109/SASO.2011.18	embedded system;middleware;real-time computing;self-organization;computer science;artificial intelligence;operating system;middleware;distributed computing	Robotics	-31.255656764147002	47.8744871247395	39146
c5b3f0caeba42a532a48adc80e6932c35bb26ac4	the case for gpgpu spatial multitasking	kernel;multiprogramming graphics processing units multiprocessing systems;transform coding;multiprogramming;graphics hardware;graphics processing units;multitasking;graphic processing unit;bandwidth;multiprocessing systems;gpu stream multiprocessors gpgpu spatial multitasking technique set top portable device market graphics processing units general purpose computations graphics hardware cooperative multitasking preemptive multitasking general purpose gpu application;graphics processing unit;encoding;graphics processing unit multitasking kernel instruction sets bandwidth transform coding encoding;parallel applications;instruction sets	The set-top and portable device market continues to grow, as does the demand for more performance under increasing cost, power, and thermal constraints. The integration of Graphics Processing Units (GPUs) into these devices and the emergence of general-purpose computations on graphics hardware enable a new set of highly parallel applications. In this paper, we propose and make the case for a GPU multitasking technique called spatial multitasking. Traditional GPU multitasking techniques, such as cooperative and preemptive multitasking, partition GPU time among applications, while spatial multitasking allows GPU resources to be partitioned among multiple applications simultaneously. We demonstrate the potential benefits of spatial multitasking with an analysis and characterization of General-Purpose GPU (GPGPU) applications. We find that many GPGPU applications fail to utilize available GPU resources fully, which suggests the potential for significant performance benefits using spatial multitasking instead of, or in combination with, preemptive or cooperative multitasking. We then implement spatial multitasking and compare it to cooperative multitasking using simulation. We evaluate several heuristics for partitioning GPU stream multiprocessors (SMs) among applications and find spatial multitasking shows an average speedup of up to 1.19 over cooperative multitasking when two applications are sharing the GPU. Speedups are even higher when more than two applications are sharing the GPU.	computation;cooperative multitasking;emergence;general-purpose computing on graphics processing units;general-purpose markup language;graphics hardware;graphics processing unit;heuristic (computer science);ibm notes;mobile device;multiplexing;preemption (computing);scheduling (computing);simulation;speedup;unbalanced circuit;user experience	Jacob Adriaens;Katherine Compton;Nam Sung Kim;Michael J. Schulte	2012	IEEE International Symposium on High-Performance Comp Architecture	10.1109/HPCA.2012.6168946	computer architecture;parallel computing;kernel;transform coding;human multitasking;computer multitasking;computer hardware;computer science;operating system;instruction set;graphics hardware;bandwidth;encoding	Arch	-5.146250483911963	47.54532944547779	39159
069a80883759e70c6ca79c358268931ef7ce1802	autonomic fine-grained replication and migration at component level on multicloud		Although migration and replication of applications in a distributed environment have been discussed by many researchers, the implementations of these features are rarely focused when deployed in the cloud. The cloud enterprises usually have to migrate or replicate partly or fully their services because of economical or disaster preventing reasons. Because the cost of copying the whole virtual machines is too high due to their big size, the replication at application level is a possible approach. This work proposes an autonomic replication and migration mechanism integrated in an implementation of a fine-grained deployment framework which enables ability to migrate and replicate-service components on the clouds. We formulate the deployment problem of replicated components to optimize the system performance as a quadratic program. Our proposed framework ensures the high availability and scalability of services, and complies with the service-oriented architecture. Our experiments conducted in real scenarios of elastic demands demonstrate that the proposed fine-grained migration and replication is more efficient than the coarse-grained ones when an autonomic system responds to fluctuation of webapp’s workload. We also show the influence of adding servers and upgrading server connections on the system performance.	autonomic computing;cloud computing;digital subscriber line;experiment;high availability;legacy system;multicloud;numerical analysis;overhead (computing);quadratic programming;quantum fluctuation;scalability;self-replicating machine;semiconductor consolidation;server (computing);service-oriented architecture;service-oriented device architecture;software deployment;virtual machine;web application	Linh Manh Pham;Tuan-Minh Pham	2016	Vietnam Journal of Computer Science	10.1007/s40595-016-0074-0	real-time computing;simulation;computer security	HPC	-26.394244207277122	59.09147493039342	39180
1ae454453d2794bc7e286f3e34a4e15838fa93ca	opamp: evaluation framework for optimal page allocation of hybrid main memory architecture	energy efficiency;pram;memory management;dynamic random access memory opamp evaluation framework optimal page allocation hybrid main memory architecture dram memory nonvolatile memory energy consumption time delay np complete pram;memory management pram energy efficiency;phase change random access memory resource management energy consumption memory management equations mathematical model;computational complexity;dram chips computational complexity;dram chips	Main memory as a hybrid between DRAM and nonvolatile memory is rapidly considered as a basic building block of computing systems. Despite widely-performed researches no one can confirm whether hybrid memory is at its full performance in terms of energy consumption, time delay or both. The main problem is that evaluating their performance in comparison with the optimal performance is challenging since deriving the optimal value is NP-complete. In this paper, we design and implement an evaluation framework termed OPAMP, which calculates optimal performance of the hybrid memory environment. This system gathers workload, specification of DRAM and PRAM, and environmental parameters of the hybrid main memory. After that, it calculates the maximum performance under the corresponding conditions. We suggest the way of deriving the optimal value by profiling instead of page migration which is the mainstream of recent researches on hybrid main memory system. Also, proportion of DRAM's size to PRAM's and proportion of DRAM's usage space to PRAM's are impactive factors. While designing hybrid main memory, those two variables must be determined carefully and OPAMP gives the guideline to the researchers.	broadcast delay;computer data storage;dynamic random-access memory;embedded system;memory architecture;np-completeness;nonvolatile bios memory;operational amplifier;optimization problem;profiling (computer programming)	Jong Hun Choi;Seong-Min Kim;Chulmin Kim;Ki-Woong Park;Kyu Ho Park	2012	2012 IEEE 18th International Conference on Parallel and Distributed Systems	10.1109/ICPADS.2012.89	uniform memory access;interleaved memory;semiconductor memory;parallel computing;real-time computing;memory rank;static random-access memory;memory refresh;computer hardware;computer science;physical address;operating system;static memory allocation;universal memory;efficient energy use;extended memory;flat memory model;computational complexity theory;registered memory;algorithm;cache-only memory architecture;memory management	EDA	-5.526741267530043	56.71330666886775	39183
3a71f032f5ff9bbfb315c66754044dcd2d14befe	remote load-sensitive caching for multi-server database systems	multi server database systems;cache storage;database system;paged storage;server cluster remote load sensitive caching multi server database systems clusters of workstations scalable database servers large aggregate memory capacities global memory buffer management algorithms database clusters data placement standard client server page replacement algorithms global lru page replacement policy shore database system rls caching distributed memory management;distributed memory systems;memory management;personal communication networks;large aggregate memory capacities;rls caching;storage management;client server systems;technology management;server cluster;network servers;standard client server page replacement algorithms;aggregates;clusters of workstations;workstations;database systems;distributed databases;clustering algorithms;scalable database servers;buffer management algorithms;database systems memory management clustering algorithms technology management hardware aggregates costs workstations personal communication networks network servers;global memory;distributed memory management;microcomputer applications;database clusters;shore database system;remote load sensitive caching;data placement;global lru page replacement policy;hardware	Project Summary This project's goal is to study the impact of the new capabilities of high -speed networks on the design and performance of data management protocols. In particular, the focus is on high-speed wide -area networks (WANs) where the propagation latency is the dominant communication cost, the migration of large amounts of data is not an issue, and efficient multicasting and guarantees on network Quality of Service (QoS) parameters are available. In this project, existing concurrency control, commit and recovery protocols are being evaluated with respect to performance scalability under the new network assumptions. Further, new protocols are being developed that utilize the huge bandwidth and minimize the number of sequential phases of messages exploiting the multicasting capability and the provision of QoS guarantees such as bounded end-to-end packet delay and packet loss. At the same time, because of the need to scale to thousands of clients and servers, not all of which may be operational at any given time, the new WAN data management protocols are designed to achieve higher site autonomy in a cooperative manner, reducing global synchronization and supporting disconnected operations. The various protocols are empirically evaluated using computer simulation under different scenarios. The results of this research are expected to provide a better insight into the synergy between database and network technologies. This, in turn, will facilitate the deployment of future high performance WAN data server systems, which are part of the necessary infrastructure that will support important nationand world-wide applications such as electronic commerce. Finally, we believe that several of the principles developed in this project are applicable in mobile as well as peer-to-peer computing environments.	cache (computing);commit (data management);computer simulation;concurrency (computer science);concurrency control;e-commerce;end-to-end principle;multicast;network packet;peer-to-peer;quality of service;scalability;server (computing);software deployment;software propagation;synergy;tcp global synchronization	Shivakumar Venkataraman;Jeffrey F. Naughton;Miron Livny	1998		10.1109/ICDE.1998.655814	parallel computing;workstation;computer cluster;computer science;technology management;operating system;database;cluster analysis;distributed database;memory management	DB	-20.646251670512324	51.145337107812175	39195
255b2f8fad3cc9f59a0c4334506854a1e626452f	vord: a versatile on-the-fly race detection tool in openmp programs	rdc;ecps;on the fly race detection;intel thread checker;openmp;parallel programs	Shared-memory based parallel programming with OpenMP and Posix-thread APIs becomes more common to fully take advantage of multiprocessor computing environments. One of the critical risks in multithreaded programming is data races that are hard to debug and greatly damaging to parallel applications if they are uncaught. Although ample effort has been made in building specialized data race detection techniques, the state of art tools such as the Intel Thread Checker still have various functionality and performance problems. In this paper, we present a Versatile On-the-fly Race Detection (VORD) tool that provides an agile, efficient, and scalable race detection environment for various parallel programming models. VORD can automatically construct an empirically optimal set of race engines by utilizing classification and adaptation mechanisms. A Race-Detection Classification (RDC) table is created to categorize adequate engines in the aspect of labeling, detecting, and filtering. An Engine Code Property Selector (ECPS) uses the RDC table to adapt optimal engines for the given target programming models. In addition to RDC and ECPS, we have also implemented an OpenMP parser and a source instrumentor. The functionality and efficiency of VORD were compared with those of the Intel Thread Checker by using a set of OpenMP based kernel programs. The experimental results show that VORD can detect data races in more challenging programming models such as nested thread and synchronization models, and can achieve a couple of orders of a magnitude faster processing time than the Intel Thread Checker in the large parallel programs.	agile software development;categorization;exception handling;multiprocessing;openmp;posix;parallel computing;race condition;scalability;sensor;shared memory;simulation;thread (computing)	Young-Joo Kim;Sejun Song;Yong-Kee Jun	2013	International Journal of Parallel Programming	10.1007/s10766-013-0257-6	computer architecture;parallel computing;computer hardware;computer science;operating system;programming language;algorithm	HPC	-15.743459489951537	37.48397728041549	39231
d55fec29fb06dce9ff594d43dc8c886ea7b9cb08	preserving virtual memory by mitigating the address translation wall		The concept of virtual memory is one of the classic computer science abstractions and has long enabled systems that are easy to program and that operate quickly. Today, however, virtual memory faces challenges that pose a threat to the continued progress of computing. This article discusses these threats and presents some promising ways to counter them.		Abhishek Bhattacharjee	2017	IEEE Micro	10.1109/MM.2017.3711640	computer science;parallel computing;flat memory model;overlay;distributed memory;abstraction;memory management;theoretical computer science;virtual memory;memory protection	Arch	-13.590968215542587	49.115208431612864	39240
003d93108ad0eba164b7ec98cff8860cf7bea673	new scheduling strategies for randomized incremental algorithms in the context of speculative parallelization	load balancing and task assignment;computational complexity randomized incremental algorithm speculative parallelization meseta fixed size chunking scheduling strategy;scheduling computational complexity parallel algorithms randomised algorithms;speculative parallelization;randomised algorithms;geometrical problems and computations;fixed size chunking;computational complexity;scheduling and task partitioning;scheduling;scheduling strategy;geometrical problems and computations parallelism and concurrency load balancing and task assignment scheduling and task partitioning;load balance;task assignment;incremental algorithm;randomized incremental algorithm;parallelism and concurrency;automatic parallelization;meseta;parallel algorithms	In this work, we address the problem of scheduling loops with dependences in the context of speculative parallelization. We show that the scheduling alternatives are highly influenced by the dependence violation pattern the code presents. We center our analysis in those algorithms where dependences are less likely to appear as the execution proceeds. Particularly, we focus on randomized incremental algorithms, widely used as a much more efficient solution to many problems than their deterministic counterparts. These important algorithms are, in general, hard to parallelize by hand and represent a challenge for any automatic parallelization scheme. Our analysis led us to the development of MESETA, a new scheduling strategy that takes into account the probability of a dependence violation to determine the number of iterations being scheduled. MESETA is compared with existing techniques, including fixed-size chunking (FSC), the only scheduling alternative used so far in the context of speculative parallelization. Our experimental results show a 5.5 percent to 36.25 percent speedup improvement over FSC, leading to a better extraction of the parallelism inherent to randomized incremental algorithms. Moreover, when the cost of dependence violations is too high to obtain speedups, MESETA curves the performance degradation	approximation algorithm;automatic parallelization;elegant degradation;iteration;randomized algorithm;scheduling (computing);shallow parsing;speculative execution;speedup	Diego R. Llanos Ferraris;David Orden;Belén Palop	2007	IEEE Transactions on Computers	10.1109/TC.2007.1030	parallel computing;real-time computing;computer science;load balancing;operating system;distributed computing;parallel algorithm;computational complexity theory;scheduling;automatic parallelization	HPC	-13.372639288940155	48.03914312797139	39278
82f2b00848c43b5dba54c63d18d89bab95e82a36	finding the right level of abstraction for minimizing operational expenditure	programming language;total cost of ownership;abstraction;tco;levels of abstraction;static and dynamic analysis;cost	In this paper we are examining the impact of modern programming language abstractions on total cost of ownership (TCO) of a financial computing operation. Our analysis is based on static and dynamic analysis of example financial software, based on our loop-flow graph (LFG) concept and our custom dynamic hotspot tool called MaxSpot. Our results show that, if the required throughput of an application is high enough, then operational expenditure is minimized by minimizing runtime and not programming effort.	computational finance;lexical functional grammar;programming language;throughput;total cost of ownership	Oskar Mencer;Erik Vynckier;James Spooner;Stephen Girdlestone;Oliver Charlesworth	2011		10.1145/2088256.2088262	real-time computing;simulation;computer science;abstraction;programming language	PL	-18.692790637872672	39.06548478174065	39286
3d886409fd8dc74220d29bc2baff26e9e2321130	load balancing for network based multi-threaded applications	distributed system;eficacia sistema;systeme reparti;management system;programacion paralela;equilibrio de carga;sistema informatico;equilibrage charge;performance systeme;parallel programming;cluster of workstations;computer system;test bed;system performance;process management;transparent adaptation;sistema repartido;operating system;load balancing;message passing;systeme informatique;load balance;programmation parallele	In this paper we present Lbs, a load-management-system for network based concurrent computing. The system is built on Pt-Pvm, a library based on the PVM system. Pt-Pvm provides message passing and process management facilities at thread and process level for a cluster of workstations running the UNIX operating system. The presented system is realized as an open library which can be easily used to implement new load-balancing algorithms. In addition to that, the unit of load which has to be distributed (either data or lightweight processes) can be transparently adapted to application needs. Therefore the system serves as an ideal test-bed for comparing different load-balancing methods.	algorithm;computer cluster;concurrent computing;load balancing (computing);load management;location-based service;message passing;operating system;parallel virtual machine;testbed;thread (computing);unix;workstation	Oliver Krone;Martin Raab;Béat Hirsbrunner	1998		10.1007/BFb0056577	embedded system;real-time computing;computer science;load balancing;operating system;computer performance;computer security	HPC	-18.29022447486146	42.88606709493681	39298
16c52a3cdde525971e10e4221e393fea9147cdbe	a process logic for distributed system synthesis	algebraic specification;distributed system;concurrent behavior;concurrent computing;computability;satisfiability;interleaved codes;ds algebra;algebra;carbon capture and storage;process logic;logic functions;interleaving behavior;computability process algebra concurrency theory algebraic specification;sp logic process logic distributed system synthesis process algebra satisfiability concurrent behavior interleaving behavior ds algebra;process algebra;distributed system synthesis;sp logic;algebra concurrent computing logic functions interleaved codes carbon capture and storage laboratories;concurrency theory	In this paper, we define a process algebra DS@ to formally describe distributed systems and a process logic SP@ to formally describe their specifications. Then, we present a method to synthesize a distributed system (described in DS@) from given specifications (described in SP@). The main contribution of this paper is to show how to check the satisfiability of process logics in which concurrent behavior is distinct from interleaving behavior (i.e. considering true concurrency).	algorithm;boolean satisfiability problem;concurrency (computer science);distributed computing;forward error correction;process calculus;synchronization (computer science)	Yoshinao Isobe;Kazuhito Ohmaki	2000		10.1109/APSEC.2000.896684	process calculus;carbon capture and storage;concurrent computing;computer science;theoretical computer science;computability;programming language;algorithm;satisfiability	PL	-31.001543857953674	32.48139203568798	39300
e1df756ff2c5e9d6fc5bfeeef22c6c1fdf46d018	a novel disk layout optimization for networked storage systems	networked storage system;energy conservation;storage system;delay cost function energy storage measurement computer science throughput energy conservation sun heuristic algorithms energy consumption;storage management;raid;sea strategy disk storage layout optimization networked storage system energy saving data placement striping based energy aware strategy raid structured storage system;response time;raid data placement energy conservation response time;storage area networks;energy saving data placement;sea strategy;disk storage layout optimization;storage management raid storage area networks;quick response;data placement;raid structured storage system;energy saving;striping based energy aware strategy	To achieve energy-conservation and prompt responses simultaneously, in this paper we propose a novel energy-saving data placement strategy, called striping-based energy-aware (SEA), which can be applied to RAID-structured storage systems to noticeably save energy while providing quick responses. Further, to illustrate the effectiveness of SEA, we implement two SEA-powered RAID-based data placement algorithms, SEA0 and SEA5, by incorporating the SEA strategy into RAID-0 and RAID-5, respectively. Extensive experimental results demonstrate that compared with three well-known data placement algorithms greedy, SP, and HP, SEAO and SEA5 reduce mean response time on average at least 52.15% and 48.04% while saving energy on average no less than 10.12% and 9.35%, respectively.	algorithmic efficiency;data striping;disk storage;elegant degradation;fault tolerance;greedy algorithm;hard disk drive;nosql;overhead (computing);program optimization;response time (technology);rise time;standard raid levels	Tao Xie;Yao Sun	2007	2007 16th International Conference on Computer Communications and Networks	10.1109/ICCCN.2007.4317922	embedded system;real-time computing;storage area network;energy conservation;computer hardware;computer science;operating system;response time;raid	DB	-10.743534947922456	55.31876274703959	39305
48e57d5dad9d2f79116ea7c0af92dbc7ab7afd40	heapo: heap-based persistent object store	persistent objects;persistent heap;nonvolatile memory	In this work, we developed a Heap-Based Persistent Object Store (HEAPO) to manage persistent objects in byte-addressable Nonvolatile RAM (NVRAM). HEAPO defines its own persistent heap layout, the persistent object format, name space organization, object sharing and protection mechanism, and undo-only log-based crash recovery, all of which are effectively tailored for NVRAM. We put our effort into developing a lightweight and flexible layer to exploit the DRAM-like access latency of NVRAM. To address this objective, we developed (i) a native management layer for NVRAM to eliminate redundancy between in-core and on-disk copies of the metadata, (ii) an expandable object format, (iii) a burst trie-based global name space with local name space caching, (iv) static address binding, and (v) minimal logging for undo-only crash recovery. We implemented HEAPO at commodity OS (Linux 2.6.32) and measured the performance. By eliminating metadata redundancy, HEAPO improved the speed of creating, attaching, and expanding an object by 1.3×, 4.5×, and 3.8×, respectively, compared to memory-mapped file-based persistent object store. Burst trie-based name space organization of HEAPO yielded 7.6× better lookup performance compared to hashed B-tree-based name space of EXT4. We modified memcachedb to use HEAPO in maintaining its search structure. For hash table update, HEAPO-based memcachedb yielded 3.4× performance improvement against original memcachedb implementation which uses mmap() over ramdisk approach to maintain the key-value store in memory.	attribute–value pair;b-tree;byte addressing;dynamic random-access memory;emoticon;hash table;key-value database;linux;lookup table;memcachedb;mmap;non-volatile random-access memory;object file;operating system;persistent object store;protection mechanism;trie;undo	Taeho Hwang;Jaemin Jung;Youjip Won	2014	TOS	10.1145/2629619	real-time computing;non-volatile memory;computer science;operating system;database;distributed computing	DB	-12.698701870844683	53.566974056320994	39312
6cc0da25cb3c0c08a77514ce68446a7038b3a58e	a component system for spontaneous virtual networks	libraries;measurement;overlay composition;overlay networks;libraries measurement optimization xml indexes overlay networks runtime;004 informatik;computer networks component system spontaneous virtual networks network services sharing components publish subscribe functionalities service composition;middleware computer networks message passing;runtime;component system;computer networks;indexes;automatic composer overlay composition component system;xml;message passing;middleware;optimization;automatic composer	In this paper, we propose a framework and a component system, which can be used to dynamically create modularized network services. A composer can automatically compose such services from a library of available components, taking into account dependencies among components and the possibility of sharing components by different services. In addition to group communication and publish/subscribe functionalities, which are implemented as components already, it is very easy to extend the library with third-party components or own implementations. The framework performs the calculation of a suitable service composition and its deployment among all participating nodes. Each composition can take into account different application requirements or incorporate new components without changing the host application. Since the system is also highly modularized itself, it allows to flexibly choose alternative composition or deployment algorithms, or develop new ones.	algorithm;functional requirement;graphics processing unit;microsoft outlook for mac;non-functional requirement;overlay network;peer-to-peer;publish–subscribe pattern;service composability principle;software deployment;spontaneous order	Philipp Schaber;Wolfgang Effelsberg	2013	2013 Conference on Networked Systems	10.1109/NetSys.2013.22	computer science;database;distributed computing;world wide web	HPC	-31.414723856037085	53.084152221094776	39313
95d9459c01a0e3e6af97daf2ef0daf159428743f	objectstore's virtual memory mapping architecture			objectstore	Rüdiger Wirth	1993	Datenbank Rundbrief		database;architecture;computer science;virtual memory	Arch	-10.574775078927969	43.87256423180186	39318
83a8b2224f6fe38b43388a2813b3dbf923a028de	linear algebra software on a vector computer	linear algebra	Abstract   Mathematical software libraries (IMSL, NAG) supply subprograms for the solution of a broad class of frequently occurring numerical problems. Therefore, the library routines are normally used as building blocks in more complex computer codes. Users taking advantage of this approach can simplify code development and introduce expertise to their codes. The acceptance of mathematical software libraries is strongly related to the quality of their components. Results on the performance and accuracy of library subroutines for matrix multiplication, the solution of linear equations and eigenvalue problems on a CRAY X-MP are reported.	linear algebra;vector processor	Jürgen-Friedrich Hake;Willi Homberg	1989	Parallel Computing	10.1016/0167-8191(89)90078-1	computational science;parallel computing;computer science;theoretical computer science;linear algebra;operating system;basic linear algebra subprograms;mathematics;programming language;algorithm;algebra	HPC	-11.39839781830798	35.22521655598028	39332
b265958037597d0a3d499ce89700e24017427384	piton: a manycore processor for multitenant clouds	energy efficiency;computer architecture;bandwidth;multiprocessing systems;large scale systems;cloud computing;data centers	The shared cloud-based computing paradigm has experienced enormous growth. Multitenant clouds are conventionally built atop datacenters that utilize commodity hardware connected hierarchically with standard network protocols. Piton is a 25-core manycore processor that takes a different perspective, rethinking the architecture of datacenters and specializing processor architecture for Infrastructure as a Service (IaaS) clouds. The tile-based manycore processor is designed not only as a single chip, but as a large-scale system. Up to 8,192 chips (204,800 cores) can be seamlessly connected in a flat topology, maintaining a packet-switched network fabric both on and off chip. Shared memory is supported across arbitrary cores in the system, both intrachip and interchip, enabling flexibility and fine-grained resource allocation in shared systems. Piton also targets energy efficiency, critical to datacenters, using a modified multithreaded OpenSPARC T1 core enhanced with an energy-efficient drafting mode. To further facilitate sharing and increase utility for IaaS users and providers, a novel memory traffic shaper partitions bandwidth among cores or applications. Piton reimagines the datacenter architecture, breaking down barriers between chips, nodes, and racks, and enables flexibility, performance, and energy efficiency at scale. Piton has also been open sourced as a research platform called OpenPiton to enable practical full-system manycore research.	cloud computing;commodity computing;communications protocol;data center;manycore processor;multitenancy;network packet;open-source software;opensparc;packet switching;programming paradigm;shared memory;tag cloud;thread (computing);traffic shaping	Michael McKeown;Yaosheng Fu;Tri M. Nguyen;Yanqi Zhou;Jonathan Balkind;Alexey Lavrov;Mohammad Shahrad;Samuel Payne;David Wentzlaff	2017	IEEE Micro	10.1109/MM.2017.36	embedded system;data center;computer architecture;parallel computing;real-time computing;cloud computing;computer science;operating system;efficient energy use;bandwidth	Arch	-28.155712967543053	57.00639222374072	39352
5fe5bc52d0ca95dddb93fc5ef23fe6de4c3b279e	parallelization of lattice boltzmann method using mpi domain decomposition technology for a drop impact on a wetted solid wall	domain decomposition;hpc;lattice boltzmann method;mpi;drop impact;two phase flow	Lattice Boltzmann method (LBM) is a new attractive computational approach for simulating isothermal multi-phase flows in computational fluid dynamics (CFD). It is based on the kinetic theory and easy to be parallelized. This study aims to analyze the performance of parallel LBM programming for the incompressible two-phase flows at high density and viscosity ratio. For this purpose, a liquid drop impact on a wetted wall with a pre-existing thin film of the same liquid is simulated by using the parallel LBM code. During the simulations, the domain decomposition, data communication and parallelization of the LBM code using the message passing interface (MPI) library have been investigated. The computational results show that the parallel LBM code exhibits a good high performance computing (HPC) on the parallel speed-up.	automatic parallelization;domain decomposition methods;lattice boltzmann methods;message passing interface;parallel computing	Zhi Shang;Ming Cheng;Jing Lou	2014	IJMSSC	10.1142/S1793962313500244	computational science;supercomputer;parallel computing;computer science;message passing interface;theoretical computer science;lattice boltzmann methods;domain decomposition methods;two-phase flow	HPC	-5.7794709124068815	36.98107232549982	39355
657de33036a0d2cb7d4d14640c97101c8b63158f	easy pram-based high-performance parallel programming with ice		Parallel machines have become more widely used. Unfortunately parallel programming technologies have advanced at a much slower pace except for regular programs. For irregular programs, this advancement is inhibited by high synchronization costs, non-loop parallelism, non-array data structures, recursively expressed parallelism and parallelism that is too fine-grained to be exploitable. We present ICE, a new parallel programming language that is easy-to-program, since: (i) ICE is a synchronous, lock-step language so there is no need for programmer-specified synchronization; (ii) for a PRAM algorithm its ICE program amounts to directly transcribing it; and (iii) the PRAM algorithmic theory offers unique wealth of parallel algorithms and techniques. We propose ICE to be a part of an ecosystem consisting of the XMT architecture, the PRAM algorithmic model, and ICE itself, that together deliver on the twin goal of easy programming and efficient parallelization of irregular programs. The XMT architecture, developed at UMD, can exploit fine-grained parallelism in irregular programs. We have built the ICE compiler which translates the ICE language into the multithreaded XMTC language; the significance of this is that multi-threading is a feature shared by practically all current scalable parallel programming languages thus providing a method to compile ICE code. As one indication of ease of programming, we observed a reduction in code size in 11 out of 16 benchmarks as compared to hand-optimized XMTC. For these programs, the average reduction in number of lines of code was 35.5 percent. The remaining 5 benchmarks had almost the same code size for both ICE and hand-optimized XMTC. Our main result is perhaps surprising: The run-time was comparable to XMTC with a 0.53 percent average gain for ICE across all benchmarks.	parallel computing	Fady Ghanim;Uzi Vishkin;Rajeev Barua	2018	IEEE Trans. Parallel Distrib. Syst.	10.1109/TPDS.2017.2754376	computer science;parallel computing;compiler;real-time computing;architecture;distributed computing;parallel algorithm;instruction set;source lines of code;data structure;parallel programming model;technical report	HPC	-7.016987828296821	42.83175295464766	39421
7b0e1a86947a65021649ebc21a7f1b966f83df5a	modeling the effects of node heterogeneity on the performance of grid applications	analytical models;order statistics;queueing network;order statistic;grid applications;queueing theory;speed up;partitioning;endnotes;real grid application;node heterogeneity;synchronisation;computer architecture;order statistics node heterogeneity real grid application grid systems parallel tasks synchronization overhead grid nodes queueing network based performance model grid architectures resource heterogeneity network latency grid computing;computational modeling;statistical analysis;synchronization;network contention;resource heterogeneity;performance analysis;single photon emission computed tomography;performance model;statistics;performance analysis benchmark testing grid computing queueing analysis delay computer architecture statistics analytical models stochastic systems petri nets;grid architectures;grid systems;pubications;grid nodes;petri nets;stochastic systems;task scheduling;partitioning grid computing synchronization overhead order statistics performance model speed up;network latency;synchronization overhead;grid computing;synchronisation grid computing queueing theory statistical analysis;parallel applications;benchmark testing;local area networks;parallel tasks;grid system;queueing analysis;queueing network based performance model	The performance benefit when using Grid systems comes from different strategies, among which partitioning the applications into parallel tasks is the most important. However, in most cases the enhancement coming from partitioning is smoothed by the effect of the synchronization overhead, mainly due to the high variability of completion times of the different tasks, which, in turn, is due to the large heterogeneity of Grid nodes. For this reason, it is important to have models which capture the performance of such systems. In this paper we describe a queueing-network-based performance model able to accurately analyze Grid architectures, and we use the model to study a real parallel application executed in a Grid. The proposed model improves the classical modelling techniques and highlights the impact of resource heterogeneity and network latency on the application performance.		Paolo Cremonesi;Roberto Turrin;Vassil N. Alexandrov	2009	JNW	10.4304/jnw.4.9.837-854	synchronization;parallel computing;real-time computing;order statistic;computer science;operating system;distributed computing;statistics	HPC	-15.560400700144513	58.40015062670956	39428
829e354508c34d5f37f726d1402ba641319b9bc9	linux in practice: an overview of applications	linux military computing sensor systems and applications high speed networks publishing workstations control system synthesis europe south america real time systems;computerised control;military computing unix operating systems computers real time systems publishing oceanography computerised control;south america;high speed networks;publishing;soft real time;control system;beowulf cluster;operating systems computers;oceanography;unix;weather simulation linux oceanographic lab remote sensors high speed network publishing company workstations real time control system military contractor embedded applications beowulf cluster computer supercomputing;military computing;real time systems	"""The article discusses several interesting applications of Linux, in a wide variety of environments. These include an oceanographic lab running remote and inaccessible sensors, the development of a high-speed network on a shoestring budget, a publishing company that evolved from two people and a Unix box to 15 people on Linux workstations, the development of """"soft real-time"""" control systems in Europe and South America, a military contractor building complex real-time embedded applications, and the use of a Beowulf cluster computer for supercomputing tasks such as weather simulation."""	linux	Terry Bollinger	1999	IEEE Software	10.1109/52.744572	embedded system;simulation;computer science;engineering;control system;operating system;software engineering;publishing;unix	Visualization	-31.382623205780096	38.7164716775685	39453
15a80c22e9d71397ec36ab98c9c9fd7338149ad5	an efficient abortable-locking protocol for multi-level numa systems	mcs lock;timeout lock;synchronization;queuing lock;hierarchical lock;numa;spin lock;abortable lock	The popularity of Non-Uniform Memory Access (NUMA) architectures has led to numerous locality-preserving hierarchical lock designs, such as HCLH, HMCS, and cohort locks. Locality-preserving locks trade fairness for higher throughput. Hence, some instances of acquisitions can incur long latencies, which may be intolerable for certain applications. Few locks admit a waiting thread to abandon its protocol on a timeout. State-of-the-art abortable locks are not fully locality aware, introduce high overheads, and unsuitable for frequent aborts. Enhancing locality-aware locks with lightweight timeout capability is critical for their adoption. In this paper, we design and evaluate the HMCS-T lock, a Hierarchical MCS (HMCS) lock variant that admits a timeout. HMCS-T maintains the locality benefits of HMCS while ensuring aborts to be lightweight. HMCS-T offers the progress guarantee missing in most abortable queuing locks. Our evaluations show that HMCS-T offers the timeout feature at a moderate overhead over its HMCS analog. HMCS-T, used in an MPI runtime lock, mitigated the poor scalability of an MPI+OpenMP BFS code and resulted in 4.3x superior scaling.	access time;concurrency (computer science);fairness measure;image scaling;locality of reference;lock (computer science);manycore processor;non-uniform memory access;overhead (computing);scalability;throughput;time complexity;timeout (computing);uniform memory access	Milind Chabbi;Abdelhalim Amer;Shasha Wen;Xu Liu	2017		10.1145/3018743.3018768	lock;synchronization;parallel computing;real-time computing;spinlock;computer science;operating system;lock convoy;non-uniform memory access	OS	-10.382102206218589	50.93349202657513	39539
b951b732c1400162ddd6da6c40d1eb1047d3b979	extending the archc language for automatic generation of assemblers	program assemblers;instruction set architecture;automatic programming;automatic generation;assembly encoding computer architecture libraries computer aided instruction laboratories ground penetrating radar geophysical measurement techniques process design instruction sets;assembly language;elf object file archc language automatic assembler generation assembly language operand encoding instruction set architecture gnu assembler library binutils library mips i architecture sparc v8 architecture mibench benchmark;instruction sets program assemblers assembly language automatic programming;instruction sets	In this paper, we extend the ArchC language with new constructs to describe the assembly language syntax and operand encoding of an instruction set architecture. Based on the extended language we have created a tool which can automatically generate assemblers. Our tool uses the GNU Binutils framework in order to produce the assembler, generating the architecture dependent files necessary to retarget the GNU assembler and the Binutils libraries. We have generated assemblers for the MIPS-I and SPARC-V8 architectures based on ArchC models using our tool. The assemblers generated for both architectures were compared with the default gas assemblers for a set of files taken from the MiBench benchmark, and the ELF object files generated by each pair of assemblers were equivalent in both cases.	assembly language;benchmark (computing);central processing unit;data segment;debugger;disassembler;gnu assembler;gnu binutils;gnu linker;home page;international symposium on computer architecture;library (computing);machine-dependent software;object file;operand;pic16x84;powerpc;relocation (computing);sparc;simulation;synthetic intelligence;turing completeness	Alexandro Baldassin;Paulo Centoducatte;Sandro Rigo	2005	17th International Symposium on Computer Architecture and High Performance Computing (SBAC-PAD'05)	10.1109/CAHPC.2005.25	computer architecture;parallel computing;computer science;operating system;instruction set;programming language;assembly language	Arch	-14.113429794920316	36.12215889054332	39586
3e6c3166e1d0a84f87279ab8268eb86b6357bb84	accelerating big data processing on modern clusters	acceleration;hpc;big data	Modern clusters are having multi-/many-core architectures, high-performance rdma-enabled interconnects and SSD-based storage devices. Hadoop framework is extensively being used these days for Big Data processing. Spark framework is emerging for real-time analytics. Similarly, Memcached is being used in data centers with Web 2.0 environment. This talk will provide an overview of challenges in accelerating Hadoop, Spark and Memcached on modern clusters. An overview of RDMA-based designs for multiple components of Hadoop (HDFS, MapReduce, RPC and HBase), Spark and Memcached will be presented. Performance benefits of these designs on various cluster configurations will be shown. The talk will also address the need for designing benchmarks using a multi-layered and systematic approach, which can be used to evaluate the performance of these middleware.	apache hbase;apache hadoop;apache spark;benchmark (computing);big data;data center;electrical connection;mapreduce;memcached;middleware;real-time clock;remote direct memory access;remote procedure call;solid-state drive;web 2.0	Dhabaleswar K. Panda	2015		10.1145/2694730.2694733	parallel computing;computer science;operating system;database	OS	-18.712954303956298	52.6913400343607	39618
8867f88d1ccf336c3f32db999f630125eb104ba5	fv encoding for low-power data i/o	low power data bus;switching activity;i o pin capacitance;process variation;pins;system buses low power electronics encoding;clocked timing elements;encoding data buses pins capacitance circuits permission computer science central processing unit;system buses;low power;permission;energy consumption;data buses;low power electronics;frequent value encoding;circuits;capacitance;computer science;cpu;voltage scaling;switching activity low power data bus cpu i o pin capacitance frequent value encoding;encoding;central processing unit	The power consumed by I/O pins of a CPU is signi cant due to high capacitances associated with the pins. While highly e ective techniques for reducing address bus switching exist [1], similarly e ective techniques for data bus have not been developed. We have discovered a characteristic of values transmitted over the data bus according to which a small number of distinct values, called frequent values, account for 58-68% of transmissions over the external data bus. To exploit this characteristic we have developed a method for dynamic identi cation of frequent values and their use in encoding data values using FV (frequent value) encoding scheme. Our experiments show that FV encoding of 32 frequent values yields an average reduction of 42.7% (with onchip data cache) and 67.63% (without on-chip data cache) in data bus switching activity for SPEC95 benchmarks.	1-bit architecture;adaptive coding;address bus;bus (computing);cpu cache;central processing unit;experiment;farmville;input/output;line code;low-power broadcasting	Jun Yang;Rajiv Gupta	2001		10.1145/383082.383100	embedded system;electronic engineering;parallel computing;computer hardware;computer science;operating system;central processing unit	Arch	-6.6017324651106835	53.76600305425444	39635
5ba061ac80893c44a0492b83da2c0b27bed027e1	partial rollback-based scheduling on in-memory transactional data grids	synchronisation concurrency control grid computing public domain software relational databases scheduling sql;transactional throughput improvement partial rollback based scheduling in memory transactional data grids nosql data grids data intensive applications concurrency control model distributed transactional memory lock based distributed synchronization multiversioning model multiple object mv transactional memory write transaction concurrency transactional scheduler partial rollback based transactional scheduler pts multiversioned dtm model multiple object versions read only transaction concurrency object level backoff times conflicting transactions partially rolled back transaction open source transactional in memory data store red hat infinispan;partial transmit sequences delays concurrent computing scalability concurrency control protocols synchronization	In-memory transactional data girds, often referred to as NoSQL data grids demand high concurrency for scalability and high performance in data-intensive applications. As an alternative concurrency control model, distributed transactional memory (DTM) promises to alleviate the difficulties of lock-based distributed synchronization. We consider the multi-versioning (MV) model of using multiple object versions in DTM to avoid unnecessary aborts. MV transactional memory inherently guarantees commits of read-only transactions, but limits concurrency of write transactions. We present a transactional scheduler, called partial rollback-based transactional scheduler (or PTS), for a multi-versioned DTM model. The model supports multiple object versions to exploit concurrency of read-only transactions, and detects conflicts of write transactions at an object level. Instead of aborting a transaction, PTS assigns backoff times for conflicting transactions, and the transaction is rolled-back partially. Our implementation, integrated with a popular open-source transactional in-memory data store (i.e., Red Hat's Infinispan) reveals that PTS improves transactional throughput over MV DTM without PTS by as much as 2.4×.	dynamic data;in-memory database;scheduling (computing)	Junwhan Kim	2014		10.1109/BigData.2014.7004216	optimistic concurrency control;transactional memory;parallel computing;real-time computing;commitment ordering;computer science;software transactional memory;database;multiversion concurrency control;non-lock concurrency control;serializability	DB	-21.740714268268906	48.7331298012805	39648
5d5c42e4a58bc4bc490215d8951368e75cb01eda	modular adaptive query processing for service-based grids	modular adaptive query processing;service-based grids;adaptive query processor;adaptive behaviour;query plan;heterogeneous environment;data access;query evaluator;possible adaptive strategy;query runtime;adaptive dqp system;query processor;adaptive systems;computer science;fluctuations;feedback loop;data analysis;software systems	Distributed and heterogeneous environments present significant challenges to complex software systems, which must operate in the context of continuously changing loads, with partial or out-of-date information on resource capabilities. A distributed query processor (DQP) can be used to access and integrate data from distributed sources, as well as for combining data access with data analysis. However in heterogeneous environments, statically constructed query plans may commit a query evaluator to following significantly suboptimal strategies. As such, there is considerable interest in using adaptive query processors (AQPs) in such settings to provide self-optimizing behaviour. However, with many possible adaptive strategies available, it is important that AQPs can be constructed in a systematic and efficient manner. This paper outlines an approach to the development of AQPs in which adaptive behaviour is implemented using cooperating monitoring, assessment and response components. It is shown how this decomposition has been applied in the development of an adaptive DQP system for service-based grids, which reallocates load at query runtime, thereby supporting self-optimization.	adaptive behavior;central processing unit;data access;interpreter (computing);mathematical optimization;software system	Anastasios Gounaris;Norman W. Paton;Rizos Sakellariou;Alvaro A. A. Fernandes;Jim Smith;Paul Watson	2006	2006 IEEE International Conference on Autonomic Computing		query optimization;telecommunications;computer science;artificial intelligence;adaptive system;feedback loop;data analysis;software system	HPC	-20.296018240550726	55.219223389581295	39675
7e4921a43378b2b7b9cf950604fe434e4b07da58	slik: scalable low-latency indexes for a key-value store		Many large-scale key-value storage systems sacrifice features like secondary indexing and/or consistency in favor of scalability or performance. This limits the ease and efficiency of application development on such systems. Implementing secondary indexing in a large-scale memory based system is challenging because the goals for low latency, high scalability, consistency and high availability often conflict with each other. This paper shows how a large-scale key-value storage system can be extended to provide secondary indexes while meeting those goals. The architecture, called SLIK, enables multiple secondary indexes for each table. SLIK represents index B+ trees using objects in the underlying key-value store. It allows indexes to be partitioned and distributed independently of the data in tables while providing reasonable consistency guarantees using a lightweight ordered write approach. Our implementation of this design on RAMCloud (a main memory key-value store) performs indexed reads in 11 μs and writes in 30 μs. The architecture supports indexes spanning thousands of nodes, and provides linear scalability for throughput.	attribute–value pair;computer data storage;computer performance;file spanning;high availability;interrupt latency;key-value database;scalability;throughput;usb flash drive	Ankita Kejriwal;Arjun Gopalan;Ashish Gupta;Zhihao Jia;Stephen Yang;John K. Ousterhout	2016			computer science;throughput;real-time computing;architecture;latency (engineering);scalability;high availability;search engine indexing;associative array;computer data storage	OS	-14.926463319564135	54.016574347885644	39722
78e778e9210e825ca5ec59752500fe241f79d083	hybrid hdfs: decreasing energy consumption and speeding up hadoop using ssds	hd;performance;hybrid;energy consumption;ssd;hadoop;hdfs	Apache Hadoop has evolved significantly over the last years, with more than 60 releases bringing new features. By implementing the MapReduce programming paradigm and leveraging HDFS, its distributed file system, Hadoop has become a reliable and fault tolerant middleware for parallel and distributed computing over large datasets. Nevertheless, Hadoop may struggle under certain workloads, resulting in poor performance and high energy consumption. Users increasingly demand that high performance computing solutions being to address sustainability and limit power consumption. In this paper, we introduce HDFSH , a hybrid storage mechanism for HDFS, which uses a combination of Hard Disks and Solid-State Disks to achieve higher performance while saving power in Hadoop computations. HDFSH brings to middleware the best from HDs (affordable cost per GB and high storage capacity) and SSDs (high throughput and low energy consumption) in a configurable fashion, using dedicated storage zones for each storage device type. We implemented our mechanism as a block placement policy for HDFS, and assessed it over six recent releases of the Hadoop project, representing different designs of the Hadoop middleware. Results indicate that our approach increases overall job performance while decreasing the energy consumption under most hybrid configurations evaluated. Our results also showed that in many cases storing only part of the data in SSDs results in significant energy savings and execution speedups.	apache hadoop;cloud computing;clustered file system;computation;dce distributed file system;distributed computing;fault tolerance;floppy disk;hard disk drive;mapreduce;middleware;programming paradigm;solid-state drive;supercomputer;throughput	Ivanilton Polato;Denilson Barbosa;Abram Hindle;Fabio Kon	2015	PeerJ PrePrints	10.7287/peerj.preprints.1320v1	biology;hybrid;performance;ecology	HPC	-15.932049733531887	53.70072642634785	39746
0880d254ab4ccd2b3f0609785bd04b0bcd70ba69	an mpi tool to measure application sensitivity to variation in communication parameters	distributed system;algoritmo paralelo;systeme reparti;parallel algorithm;communicating process;algorithme parallele;proceso comunicante;sistema repartido;envoi message;processus communicant;message passing;parallel applications	This work describes an apparatus which can be used to vary communication performance parameters for MPI applications, and provides a tool to analyze the impact of communication performance on parallel applications. Our tool is based on Myrinet (along with GM). We use an extension of the LogP model to allow greater flexibility in determining the parameter(s) to which parallel applications may be sensitive. We show that individual communication parameters can be independently controlled within a small percentage error. We also present the results of using our tool on a suite of parallel benchmarks.	computer science;requirement	Edgar A. León;Arthur B. Maccabe;Ron Brightwell	2003		10.1007/978-3-540-39924-7_18	parallel computing;message passing;computer science;theoretical computer science;operating system;distributed computing;parallel algorithm;programming language	Logic	-16.814928696424328	43.178590928776885	39748
a43d7f58efc90980050a5d3addf4253e0b33a9e7	a scalability-aware kernel executive for many-core operating systems		Number, variety, and organization of the on-chip processing elements of many-core processors demand a radical rethink in operating systems design. One may come from a multitude of allocatable units that bestows every execution thread its own core: single-threaded cores will be usual, multi-threaded cores will be unusual. The paper presents a scalability-aware kernel executive, Sake, that is currently designed against such background targeting at large-scale heterogeneous manycore systems. Benchmarks on a 48-core machine motivate custom system software and special purpose systems for such modern machines.	abstract machine;benchmark (computing);blocking (computing);comefrom;central processing unit;experiment;general-purpose markup language;join-pattern;linux;manycore processor;multi-core processor;multithreading (computer architecture);operating system;parallel computing;partial template specialization;run to completion scheduling;scalability;static program analysis;systems design;thread (computing);way to go	Gabor Drescher;Timo Hönig;Sebastian Maier;Benjamin Oechslein;Wolfgang Schröder-Preikschat	2013		10.1007/978-3-642-54420-0_80	embedded system;parallel computing;real-time computing;computer hardware;operating system;database;distributed computing	OS	-8.924918190725755	44.96540575072924	39818
2eb7ae49eb567fc5f8d466417a95f8fbba4cf4ce	collective communication on architectures that support simultaneous communication over multiple links	collective communication;parallel architecture;lower bound	Traditional collective communication algorithms are designed with the assumption that a node can communicate with only one other node at a time. On new parallel architectures such as the IBM Blue Gene/L, a node can communicate with multiple nodes simultaneously. We have redesigned and reimplemented many of the MPI collective communication algorithms to take advantage of this ability to send simultaneously, including broadcast, reduce(-to-one), scatter, gather, allgather, reduce-scatter, and allreduce. We show that these new algorithms have lower expected costs than the previously known lower bounds based on old models of parallel computation. Results are included comparing their performance to the default implementations in IBM's MPI.	algorithm;blue gene;computation;message passing interface;parallel computing	Ernie Chan;Robert A. van de Geijn;William Gropp;Rajeev Thakur	2006		10.1145/1122971.1122975	parallel computing;computer science;theoretical computer science;operating system;distributed computing;upper and lower bounds	Theory	-10.996361770286397	46.113118733480306	39842
15010afff58a59f6eaacf6a5457e62f390705f95	improving application concurrency on gpus by managing implicit and explicit synchronizations	software api shared computing environments gpu software stacks runtime components concurrent applications application concurrency implicit synchronization explicit synchronization runtime mechanism design memory management scheme synchronization avoidance mechanisms gpu resource utilization system throughput gpu virtualization runtime sync free gpu multitenancy;graphics processing units runtime kernel context concurrent computing hardware;virtualisation application program interfaces concurrency computers graphics processing units resource allocation storage management synchronisation virtual machines	Originally designed to be used as dedicated coprocessors, GPUs have progressively become part of shared computing environments, such as HPC servers and clusters. Commonly used GPU software stacks (e.g., CUDA and OpenCL), however, are designed for the dedicated use of GPUs by a single application, possibly leading to resource underutilization when multiple applications share the GPU resources. In recent years, several node-level runtime components have been proposed to target this problem and allow the efficient sharing of GPUs among concurrent applications. The concurrency enabled by these systems, however, is limited by synchronizations embedded in the applications or implicitly introduced by the GPU software stack. This work targets this problem. We first analyze the effect of explicit and implicit synchronizations on application concurrency and GPU utilization. We then design runtime mechanisms to bypass these synchronizations, along with a memory management scheme that can be integrated with these synchronization avoidance mechanisms to improve GPU utilization and system throughput. We integrate these mechanisms into a recently proposed GPU virtualization runtime named Sync-Free GPU (SF-GPU), thus removing unnecessary blockages caused by multitenancy, ensuring any two applications running on the same device experience limited to no interference, maximizing the level of concurrency supported. We also release our mechanisms in the form of a software API that can be used by programmers to improve the performance of their applications without modifying their code. Finally, we evaluate the impact of our proposed mechanisms on applications run in isolation and concurrently.	application programming interface;cuda;computer cluster;concurrency (computer science);coprocessor;embedded system;glossary of computer graphics;graphics processing unit;grid computing;interference (communication);memory management;multitenancy;multithreading (computer architecture);opencl api;programmer;runtime system;thread (computing);throughput;vii;x86 virtualization	Michael Butler;Kittisak Sajjapongse;Michela Becchi	2015	2015 IEEE 21st International Conference on Parallel and Distributed Systems (ICPADS)	10.1109/ICPADS.2015.73	parallel computing;real-time computing;computer science;operating system;database;distributed computing;programming language	HPC	-12.80070474428514	48.97102645146854	39862
887bb1f7e703f22e12462ea79642c165afdcf3f7	design and performance evaluation of a software framework for multi-physics simulations on heterogeneous supercomputers	paper;lattice boltzmann model;heterogeneous systems;tesla m2050;gpu cluster;cuda;thesis;nvidia;fluid dynamics;mpi;tesla m2070;numerical simulation	Despite the experience of several decades the numerical simulation of computational fluid dynamics is still an enormously challenging and active research field. Most simulation tasks of scientific and industrial relevance require the modeling of multiple physical effects, complex numerical algorithms, and have to be executed on supercomputers due to their high computational demands. Facing these complexities, the reimplementation of the entire functionality for each simulation task, forced by inflexible, non-maintainable, and non-extendable implementations is not feasible and bound to fail. The requirements to solve the involved research objectives can only be met in an interdisciplinary effort and by a clean and structured software development process leading to usable, maintainable, and efficient software designs on all levels of the resulting software framework. The major scientific contribution of this thesis is the thorough design and implementation of the software framework WaLBerla that is suitable for the simulation of multi-physics simulation tasks centered around the lattice Boltzmann method. The design goal of WaLBerla is to be usable, maintainable, and extendable as well as to enable efficient and scalable implementations on massively parallel supercomputers. In addition, a performance analysis of lattice Boltzmann simulations has been conducted on heterogeneous supercomputers using a MPI, a hybrid, and a heterogeneous parallelization approach and over 1000 GPUs. With the help of a performance model for the communication overhead the parallel performance has been accurately estimated, understood, and optimized. It is shown that WaLBerla introduces no significant performance overhead and that efficient hardware-aware implementations are possible in WaLBerla. Furthermore, the applicability and flexibility of WaLBerla is demonstrated in simulations of particle flows and nano fluids on CPU-GPU clusters. By the successful application of WaLBerla in various simulation tasks, and the analysis of the performance and the software quality with help of quality criteria, it is shown that the design goals of WaLBerla have been fulfilled.	algorithm;central processing unit;computation;computational fluid dynamics;computer simulation;dynamical simulation;extensibility;gnu nano;graphics processing unit;lattice boltzmann methods;message passing interface;numerical analysis;numerical weather prediction;overhead (computing);parallel computing;performance evaluation;relevance;requirement;scalability;software development process;software framework;software quality;supercomputer	Christian Feichtinger	2012			computational science;parallel computing;computer science;theoretical computer science	HPC	-9.678611822058865	38.17982748394059	39949
78367025f094f36f621dd5b956cca406725e1613	prototyping dbs3, a shared-memory parallel database system	database system;project management;single user queries;concurrent computing;shared memory;performance evaluation;shared memory parallel database system;prototypes;pipelined parallelism;parallel database system;concurrent execution;satellite broadcasting;computer architecture;compile time optimization;timing optimization;database systems;parallel dataflow execution model;concurrency control;prototypes database systems satellite broadcasting parallel processing delay scalability computer architecture concurrent computing volcanoes project management;parallel machines;relational databases;scalability;response times;relational databases concurrency control parallel machines parallel processing;parallel processing;data declustering;volcanoes;scalability shared memory parallel database system dbs3 extended relational capabilities shared memory multiprocessor performance evaluation parallel dataflow execution model data declustering compile time optimization pipelined parallelism concurrent execution single user queries response times;dbs3;shared memory multiprocessor;extended relational capabilities	DBS3 is a database system with extended relational capabilities designed for a shared-memory multiprocessor. This paper presents the design choices, architecture and performance evaluation of the current DBS3 prototype. The major contributions of DBS3 are: a parallel dataflow execution model based on data declustering, the compile-time optimization of both independent and pipelined parallelism, and the exploitation of shared-memory for efficient concurrent execution. The current DBS3 prototype runs on a shared-memory, commercially available multiprocessor. The initial performance experiments for single-user queries are promising and show excellent response times and scalability. >	parallel database;shared memory	Björn Bergsten;Michel Couprie;Patrick Valduriez	1991		10.1109/PDIS.1991.183107	parallel computing;real-time computing;computer science;distributed computing	DB	-13.025986728968304	47.53833658794126	39980
1264db22a6dab250483e4ae75935d0156d78b275	friendly barriers: efficient work-stealing with return barriers	work stealing;managed languages;scheduling task parallelism;conference paper;scheduling;x10;task parallelism	This paper addresses the problem of efficiently supporting parallelism within a managed runtime. A popular approach for exploiting software parallelism on parallel hardware is task parallelism, where the programmer explicitly identifies potential parallelism and the runtime then schedules the work. Work-stealing is a promising scheduling strategy that a runtime may use to keep otherwise idle hardware busy while relieving overloaded hardware of its burden. However, work-stealing comes with substantial overheads. Recent work identified sequential overheads of work-stealing, those that occur even when no stealing takes place, as a significant source of overhead. That work was able to reduce sequential overheads to just 15%.  In this work, we turn to dynamic overheads, those that occur each time a steal takes place. We show that the dynamic overhead is dominated by introspection of the victim's stack when a steal takes place. We exploit the idea of a low overhead return barrier to reduce the dynamic overhead by approximately half, resulting in total performance improvements of as much as 20%. Because, unlike prior work, we attack the overheads directly due to stealing and therefore attack the overheads that grow as parallelism grows, we improve the scalability of work-stealing applications. This result is complementary to recent work addressing the sequential overheads of work-stealing. This work therefore substantially relieves work-stealing of the increasing pressure due to increasing intra-node hardware parallelism.	introspection;overhead (computing);parallel computing;programmer;scalability;scheduling (computing);task parallelism;work stealing	Vivek Kumar;Stephen M. Blackburn;David Grove	2014		10.1145/2576195.2576207	parallel computing;real-time computing;computer science;operating system;distributed computing;data parallelism;scheduling;instruction-level parallelism;task parallelism	PL	-13.153608110030127	48.223871725480855	39985
fdc67c469901332c0cab07fcf47d1808fcea71e3	a new architecture of online trading platform based on cloud computing	distributed data;knowledge grid online trading platform cloud computing;concurrent computing;virtual machining;wearable computers;distributed computing;knowledge grid;computer architecture;servers;business;computer architecture cloud computing grid computing distributed computing concurrent computing wearable computers parallel processing computer science virtual machining large scale systems;computer science;theoretical foundation;grid computing;meteorology;parallel processing;online trading platform;large scale systems;cloud computing	Along with the development of grid computing and cloud computing, finite computing resources supplied by stand-alone server usually become the bottleneck in the process of system implementation of online trading platform. Moreover, It is difficult to reuse algorithm module and the system also becomes more complicated to achieve. Traditional online trading framework can not preferably solve the problem listed above. Thus, we propose a framework of online trading platform based on cloud computing. It is feasible to establish a high-complexity online trading platform using infinite virtual computing capability provided by cloud computing. Simultaneously, this framework can realize the sharing of data sets after the integration of heterogeneous and distributed data based on layered thoughtway, and supply theoretical foundation and framework support for setting up a unified, open, distributed, and parallel online trading platform.	algorithm;cloud computing;grid computing;server (computing)	Xiujuan Zhang;Guoqing Dong	2010	2010 Asia-Pacific Conference on Wearable Computing Systems	10.1109/APWCS.2010.15	parallel processing;real-time computing;concurrent computing;wearable computer;cloud computing;computer science;theoretical computer science;operating system;database;distributed computing;utility computing;grid computing;server	HPC	-33.21320347184956	54.74827614065096	40028
1c776d0dbc9913608b9c8e24ae4ca0ebcbe6b2ce	advances in grid and pervasive computing, second international conference, gpc 2007, paris, france, may 2-4, 2007, proceedings	computer communication networks;algorithm analysis;pervasive computing;software engineering;operating system;problem complexity;information system	Grid computing and pervasive computing have rapidly emerged and affirmed respectively as the paradigm for high performance computing and the      paradigm for user-friendly computing. The conjunction of such paradigms are now generating a new one, the Pervasive Grid Computing, which aims at extending      classic grids with characteristics of pervasive computing like spontaneous and transparent integration of mobile devices, context-awareness, proactivity, and      so on. In this paper, we present mechanisms and a software infrastructure for executing tasks in a pervasive grid. In particular, the proposed solution,      which provides an implementation of the Utility Computing model, enables users to submit tasks and to pick up results without concerning on requiring and      handling hardware resources.	computer;ubiquitous computing		2007		10.1007/978-3-540-72360-8	computing;context-aware pervasive systems;computer science;theoretical computer science;end-user computing;distributed computing;grid computing;unconventional computing;computer engineering;autonomic computing	HPC	-30.90435983449289	48.71032856479268	40037
1d2e763a75eb7170ef3d7db8176a0dce5c3daef5	problems in modern high performance parallel i/o systems	scientific application;cluster computing;scientific data;parallel i o;high performance	0.1 Abstract In the past couple of decades, the computational abilities of supercomput-ers have increased tremendously. Leadership scale supercomputers now are capable of petaflops. Likewise, the problem size targeted by applications running on such computers has also scaled. These large applications have I/O throughput requirements on the order of tens of gigabytes per second. For a variety of reasons, the I/O subsystems of such computers have not kept pace with the computational increases, and the time required for I/O in an application has become one of the dominant bottlenecks. Also troublesome is the fact that scientific applications do not attain near the peak theoretical bandwidth of the I/O subsystems. In addressing the two prior issues, one must also question the nature of the data itself; one can ask whether contemporary practices of data dumping and analysis are optimal and whether they will continue to be applicable as computers continue to scale. These three topics, the I/O subsystem, the nature of scientific data output, and future possible optimizations are discussed in this report.	analysis of algorithms;application checkpointing;application programming interface;asynchronous i/o;bottleneck (software);clustered file system;computation;computer;computer science;disk staging;flops;gigabyte;indirection;input/output;library (computing);modernpascal;multi-storey car park;posix;parallel i/o;requirement;supercomputer;throughput;tweaking;xml	Robert Louis Cloud	2011	CoRR		parallel computing;simulation;computer cluster;computer science;theoretical computer science;operating system;distributed computing;algorithm;data	HPC	-16.38333894432296	50.53533452666584	40042
1eec574880337cd18b9d0ec8bc2b300a924cc698	sigops (paper session)	system designer;information analyst;business information systems;systems approach	An algorithm is presented which dynamically clusters pages of a problem program based on its past program behavior (i.e. reference string patterns) in a demand paged virtual memory environment. The objective of this algorithm is to minimize the number of page faults during execution, while at the same time use memory page frames efficiently. Dynamic clusters of time and reference related pages are built during a program's execution time.  Whenever a page fault for the i-th page occurs in this time evolving environment, the pages of the cluster associated with the i-th page is compared to the pages currently in real (physical) memory. Thus during this current page fault, the demanded page, and any associated clustered pages not currently in physical memory are placed into memory. Page frames holding pages not in the current cluster are returned to the memory management system. Thus the physical amount of memory allocated to a processing program is dependent upon the size of the associated cluster at that time.  Simulation results of program behavior operating under this dynamic clustering strategy indicates that significant improvements in page faults and in the space time product may be achieved. The algorithm requires fewer real page frames per executed instruction than most currently implemented algorithms that utilize a fixed number of page frames per problem programs (i.e. fixed allocated partition or region).  The algorithm, MLMM (Modified Locality Matrix Model), an extension of work by Hedges and Pooch [12] is used to determine inherent program locality to predict independent dynamic program behavior, separating instruction from data references. Furthermore, strength coefficients between weakly or loosely coupled clusters are used to refine the cluster population, identify cluster transitions, as well as indicate the behavior of the cluster formations.	algorithm;cluster analysis;coefficient;computer data storage;locality of reference;loose coupling;memory management;page fault;paging;run time (program lifecycle phase);simulation	Udo W. Pooch;David M. Burris;Patrice Burgevin;Jacques Leroudier;Errol H. Pollnow;H. F. Tibbals;Anita K. Jones	1976		10.1145/800191.805611	simulation;computer science;database;world wide web	Arch	-6.5551845806443065	52.010796159182284	40049
06c9045abda6da99c8ad88ea91611f156f4215aa	a parallelizable approach for mining likely invariants		A relevant aspect in design analysis and verification is monitoring how logic relations among different variables change at run time. Current static approaches suffer from scalability problems that prevent their adoption on large designs. On the contrary, dynamic techniques scale better from the memory-consumption point of view. However, to achieve a high accuracy, they require to analyse a huge number of (long) execution traces, which results in time-consuming phases. In this paper, we present a new efficient approach to automatically infer logic relations among the variables of a design implementation. Both a sequential and a GPU-oriented parallel implementation are proposed to dynamically extract likely invariants from execution traces on different time windows. Execution traces composed of millions of simulation instants can be efficiently analysed.	graphics processing unit;invariant (computer science);microsoft windows;point of view (computer hardware company);run time (program lifecycle phase);scalability;simulation;tracing (software)	Alessandro Danese;Luca Piccolboni;Graziano Pravadelli	2015	2015 International Conference on Hardware/Software Codesign and System Synthesis (CODES+ISSS)		parallel computing;real-time computing;computer science;theoretical computer science	EDA	-20.718904619274078	39.53142570104504	40064
d29a6747750cb21b2611f381e2fb5c0ccb4eacab	performance evaluation of barrier techniques for distributed tracing garbage collectors	garbage collector;garbage collection;performance;clusters;mechanism design;evaluation;embedded systems;distributed computing;software engineering	Currently, software engineering is becoming even more complex due to distributed computing. In this new context, portability is one of the key issues and hence a cluster-aware Java Virtual Machine (JVM) that can transparently execute Java applications in a distributed fashion on nodes of a cluster, while providing the programmer with the single system image of a classical JVM, is really desirable. This way multi-threaded server applications can take advantage of cluster resources without increasing their programming complexity. However, such kind of JVM is not easy to design. Moreover, one of the most challenging tasks in its design is the development of an efficient, scalable and automatic dynamic memory manager. Inside this manager, one important module is the automatic recycling mechanism or garbage collector. This collector is a module with very intensive processing demands that must concurrently run with user’s application. It can consume a very significant portion of the total execution time spent inside JVM in uniprocessor systems, and its overhead increases in distributed garbage collection because of the update of changing references in different nodes. Hence, the garbage collector is a very critical part in distributed designs of JVMs, both for performance and energy. In this paper our contribution to automatic distributed garbage collection is two-fold. First, we have analyzed the barrier mechanism design space for the study of tracing-based distributed garbage collectors. Second, we have evaluated the impact of the most significative barrier strategies as main bottlenecks in global performance. Our preliminary results show that the choice of the specific technique used in barrier mechanisms produces significant differences both in performance and internodes messaging overhead.	computer recycling;distributed computing;distributed garbage collection;garbage collection (computer science);item unique identification;java virtual machine;memory barrier;memory management;overhead (computing);parallax barrier;performance evaluation;programmer;programming complexity;run time (program lifecycle phase);scalability;server (computing);single system image;software engineering;software portability;thread (computing);uniprocessor system	José Manuel Velasco;David Atienza;Katzalin Olcoz;Francky Catthoor	2005				PL	-15.329688039517492	48.50718794916212	40096
29b544464d1a6e85654df2993cc79258ec208da1	formal verification of a power controller using the real-time model checker uppaal	systeme temps reel;remote control;architecture systeme;control systems design;program verification computers;real time;sistema informatico;systems engineering;audio video;computer system;proving;protocol computers;formal verification;electronic control;controllers;commande puissance;verification formelle;arquitectura sistema;real time system;systeme informatique;sistema tiempo real;control potencia;system architecture;real time operation;hard real time;new products;real time systems;power control	A real-time system for power-down control in audio/video components is modeled and verified using the real-time model checker UPPAAL. The system is supposed to reside in an audio/video component and control (read from and write to) links to neighbor audio/video components such as TV, VCR and remote–control. In particular, the system is responsible for the powering up and down of the component in between the arrival of data, and in order to do so in a safe way without loss of data, it is essential that no link interrupts are lost. Hence, a component system is a multitasking system with hard real-time requirements, and we present techniques for modeling time consumption in such a multitasked, prioritized system. The work has been carried out in a collaboration between Aalborg University and the audio/video company B&O. By modeling the system, 3 design errors were identified and corrected, and the following verification confirmed the validity of the design but also revealed the necessity for an upper limit of the interrupt frequency. The resulting design has been implemented and it is going to be incorporated as part of a new product line.	automata theory;avengers: age of ultron;computer multitasking;dspace;formal verification;graphical user interface;information;interrupt;logic programming;model checking;natural language;real-time cmix;real-time clock;real-time computing;real-time transcription;requirement;scheduling (computing);simulation;software bug;state transition table;television;temporal logic;timed automaton;timed event system;uppaal;version control;videocassette recorder;window of opportunity	Klaus Havelund;Kim G. Larsen;Arne Skou	1999		10.1007/3-540-48778-6_17	embedded system;real-time computing;simulation;real-time operating system;formal verification;power control;computer science;remote control;systems architecture	Embedded	-25.508038649906386	34.8234112970364	40109
c383cb4228f6fc6c8611f551f8301894256f8444	hierarchical multicore thread mapping via estimation of remote communication	multicore;thread mapping;cache hierarchy;data sharing;data reuse;inter- and intra-thread communication cost	Affinity-aware thread mapping is a method to effectively exploit cache resources in multicore processors. We propose an affinity- and architecture-aware thread mapping technique which maximizes data reuse and minimizes remote communications and cache coherency costs of multi-threaded applications. It consists of three main components: Data Sharing Estimator, Affine Mapping Finder and Maximum Speedup Predictor. Data Sharing Estimator creates application-specific data dependency signatures used by Affine Mapping Finder to determine the appropriate thread mapping of application for a given architecture. To prevent excessive thread migration, Maximum Speedup Predictor estimates the speedup of the obtained mapping and ignores it if it causes no significant performance improvement. The proposed framework is evaluated using Phoenix benchmark suite on two different multicore architectures. The proposed thread mapping approach gives 25% improvement in performance compared to default Linux scheduler. We also elucidate that affinity-based thread mapping approaches, which only consider the number of shared blocks, are not appropriate enough to accurately estimate data dependency between threads and determine the proper thread mapping.	benchmark (computing);cpu cache;cache coherence;central processing unit;data dependency;electronic signature;experiment;graph partition;linux;multi-core processor;process migration;processor affinity;run time (program lifecycle phase);scheduling (computing);speedup;symmetric multiprocessing;thread (computing)	Hamidreza Khaleghzadeh;Hossein Deldari;Ravi Reddy;Alexey L. Lastovetsky	2017	The Journal of Supercomputing	10.1007/s11227-017-2176-6	computer science;distributed computing;parallel computing;data dependency;architecture;real-time computing;cache coherence;cache;speedup;multi-core processor;thread (computing);affine transformation	HPC	-9.654324771991885	51.57974671757282	40115
35e6633e04046929e89d1316d9a360a43885cd4c	the common instrument middleware architecture: overview of goals and implementation	instruments middleware grid computing computer architecture computer networks computer science web services humans informatics laboratories;network accessible instruments;data processing;actuators;storage resources;sensor network;instrument design;grid computing actuators scientific research common instrument middleware architecture network accessible instruments network accessible sensors network transport data transport storage resources networking resources data acquisition data processing;computer network;data transport;network transport;network accessible sensors;middleware;common instrument middleware architecture;computerised instrumentation;high throughput;natural sciences computing;natural sciences computing computerised instrumentation data acquisition grid computing middleware;grid computing;scientific research;data acquisition;networking resources	Instruments and sensors and their accompanying actuators are essential to the conduct of scientific research. In many cases they provide observations in electronic format and can be connected to computer networks with varying degrees of remote interactivity. These devices vary in their architectures and type of data they capture and may generate data at various rates. In this paper we present an overview of the design goals and initial implementation of the common instrument middleware architecture (CIMA), a framework for making instruments and sensors network accessible in a standards-based, uniform way, and for interacting remotely with instruments and the data they produce. Some of the issues CIMA addresses include: flexibility in network transport, efficient and high throughput data transport, the availability (or lack of) computational, storage and networking resources at the instrument or sensor platform, evolution of instrument design, and reuse of data acquisition and processing codes	cima: the enemy;code;data acquisition;interaction;interactivity;middleware;requirement;sensor;throughput	Tharaka Devadithya;Kenneth Chiu;Kianosh Huffman;Donald F. McMullen	2005	First International Conference on e-Science and Grid Computing (e-Science'05)	10.1109/E-SCIENCE.2005.77	high-throughput screening;embedded system;scientific method;wireless sensor network;data processing;computer science;operating system;middleware;database;distributed computing;data acquisition;world wide web;grid computing;actuator	HPC	-31.03123780125255	49.94828075258417	40136
c3cdc6dddc1328a8e96dba6fdef4707e14c924df	global-edf scheduling of multimode real-time systems considering mode independent tasks	multicores;protocols;difference operator;multiprocessor systems;processor scheduling;realtime systems;embedded real time systems;multiprocessors;time window;software structure;protocols schedules real time systems processor scheduling multicore processing program processors scheduling;embedded system;chip;embedded systems;scheduling;task analysis;multicore processing;real time scheduling;real time scheduling mode change multiprocessors multicores real time systems;task analysis embedded systems processor scheduling;schedules;multicore processors;mode change;mode specific task scheduling global edf scheduling multimode real time system mode independent tasks embedded real time system aircraft taxiing cruise flight software structure single chip multicore processor multiprocessor system mode independent task scheduling;article;program processors;real time systems	Embedded real-time systems often have to support the embedding system in very different and changing application scenarios. An aircraft taxiing, taking off and in cruise flight is one example. The different application scenarios are reflected in the software structure with a changing task set and thus different operational modes. At the same time there is a strong push for integrating previously isolated functionalities in single-chip multicore processors. On such multicores the behavior of the system during a mode change, when the systems transitions from one mode to another, is complex but crucial to get right. In the past we have investigated mode change in multiprocessor systems where a mode change requires a complete change of task set. Now, we present the first analysis which considers mode changes in multicore systems, which use global EDF to schedule a set of mode independent (MI) and mode specific (MS) tasks. In such systems, only the set of MS tasks has to be replaced during mode changes, without jeopardizing the schedulability of the MI tasks. Of prime concern is that the mode change is safe and efficient: i.e. the mode change needs to be performed in a predefined time window and no deadlines may be missed as a function of the mode change.	central processing unit;earliest deadline first scheduling;embedded system;multi-core processor;multidisciplinary design optimization;multiprocessing;pdf/a;real-time clock;real-time computing;real-time operating system;scheduling (computing);scheduling analysis real-time systems	Vincent Nélis;Björn Andersson;José Marinho;Stefan M. Petters	2011	2011 23rd Euromicro Conference on Real-Time Systems	10.1109/ECRTS.2011.27	multi-core processor;embedded system;parallel computing;real-time computing;computer science;operating system;real mode	Embedded	-8.163154283024907	58.540988182048864	40152
7b46f26e8560120cfd0525afddfac00a957f194b	using interceptors to enhance corba	distributed computing;distributed object management;distributed object computing;protocols distributed computing communication standards file systems computerized monitoring runtime computer architecture application software tcpip internet;common object request broker architecture;application behavior modification distributed computing object model distributed object computing multiple computers common object request broker architecture corba interceptors nonapplication components;object model	T he integration of distributed computing and the object model leads to distributed object computing, in which objects rather than processes are distributed across multiple computers. A well-established standard for distributed object computing is the Common Object Request Broker Architecture (CORBA).1 Distributed object frameworks like CORBA have many attractive features but provide little support for alternative protocols, profiling and monitoring, security, or reliability. Previously, you would have had to create—and enable the application to use—the components that provide such additional capabilities. Even if the components that provide these capabilities already exist, using them requires substantial effort, as well as specialized knowledge and understanding of problems outside the application domain. With the advent of interceptors—nonapplication components that can alter application behavior—you can enhance CORBA applications at runtime with components whose operation is transparent to both the application and the CORBA framework; this means that you can modify application behavior without having to modify the application or the CORBA framework. The Object Management Group—the CORBA standards body—recognizes the value of interceptors.2 Other distributed object computing standards, such as Microsoft’s Distributed Component Object Model (DCOM), provide for interceptor-like components through custom marshaling mechanisms,3 which enable an application to bypass the standard communication mechanisms and to use custom ones. Interceptors can also allow you to chain together multiple components (each with its own functionality) to achieve new functionality transparently. Over the past few years, we have developed a system—called Eternal—that exploits interceptors transparently.4-6 The Eternal system enhances unmodified CORBA applications with reliability by using an interceptor to chain together protocol, monitoring, scheduling, and replication management components at runtime.	application domain;common object request broker architecture;computer;distributed component object model;distributed computing;distributed object;interceptor pattern;run time (program lifecycle phase);scheduling (computing)	Priya Narasimhan;Louise E. Moser;P. M. Melliar-Smith	1999	IEEE Computer	10.1109/2.774920	distributed objects everywhere;interoperable object reference;common data representation;general inter-orb protocol;distributed algorithm;method;real-time computing;object model;computer science;object request broker;object;csiv2;dynamic invocation interface;common object request broker architecture;database;distributed computing;distributed object;distributed design patterns;programming language;portable object	HPC	-33.25390271576597	43.80496857081576	40185
6ff591a0cf1840b14905f44ce44d50ea32c89b68	research and design of a middleware for supporting wide-area distributed applications	distributed application;virtual enterprises;application software;middleware scalability large scale systems distributed computing computer architecture computer network reliability application software virtual enterprises internet communication system security;distributed computing;computer architecture;internet;middleware;scalability;large scale distributed systems;large scale systems;communication system security;computer network reliability	As the platform for wide-area distributed applications, the middleware architecture should support adaptability, scalability, mobility, reliability and security. However, current middleware solutions cannot meet these requirements. The middleware architecture, called MSWADA, is presented in this paper. It is designed for large-scale distributed systems. We focus especially on how MSWADA supports adaptability, scalability and mobility.	distributed computing;java;legacy system;middleware;prototype;requirement;scalability	Dong Zhao;Shaowen Yao;Mingtian Zhou	2002		10.1109/IPDPS.2002.1016627	middleware;space-based architecture;application software;real-time computing;scalability;the internet;computer science;object request broker;message oriented middleware;operating system;middleware;database;distributed computing;distributed system security architecture;distributed design patterns	HPC	-33.267761904583196	47.47070701076549	40211
5b54fb8864dc540e07562f07575a712cbb2d643f	a distributed resource broker for spatial middleware using adaptive space-filling curve	spatial middleware;geographic information system;hilbert space filling curve;hilbert space;geographic information systems;cyberinfrastructure;resource broker;overlay network;self organization;middleware;space filling curve;spatial analysis;high performance;resource brokering	Spatial middleware serves as a glue for high-performance and distributed GIS services to harness the computational capabilities of cyberinfrastructure. This paper focuses on the development of an important component of spatial middleware -- a distributed resource broker that matches computation tasks of GIS and spatial analysis to appropriate cyberinfrastructure resources to solve computationally intensive GIS and spatial analysis problems. This distributed resource broker is built on computational intensity estimations and a self-organized grouping (SOG) framework. Specifically, we use computational intensity information to enable cyberinfrastructure resource brokering for spatial middleware by exploiting spatial characteristics; and adapt the SOG framework to enhance resource brokering performance through the use of a space filling curve. A new overlay network is designed to inherit the good performance and distributed self-organizing nature of SOG while the use of computational intensity information enhances computational performance of resource brokering for GIS and spatial analysis applications.	computation;cyberinfrastructure;distributed gis;geographic information system;middleware;organizing (structure);overlay network;self-organization;space-filling curve;spatial analysis	Anand Padmanabhan;Shaowen Wang	2010		10.1145/1869692.1869697	computer science;data mining;database;distributed computing	HPC	-30.79012139877825	50.07664935296302	40236
a0bb810314cb01d5c0be177d27bb197aa6cef5ce	{sc}*ecs: a class of modular and hierarchical cooperating systems	cooperative systems;asynchronous communication	We introduce a new class of Place/Transition net systems, {SC}*ECS, a generalisation of Equal Conflict systems [13] and Deterministic Systems of Sequential Processes [7, 11, 9, 10, 6]. {SC}*ECS are modular and hierarchical by definition: An {SC}*ECS is made up of a set of {SC}*ECS modules that asynchronously communicate through buffers in a restricted way.		Laura Recalde;Enrique Teruel;Manuel Silva Suárez	1996		10.1007/3-540-61363-3_24	embedded system;real-time computing;computer science;asynchronous communication;distributed computing	Logic	-28.75410444293304	33.794974322693726	40245
f1c3c1d5ce8f003f6bde86f79f357743797afb51	general-purpose optimization methods for parallelization of digital terrain analysis based on cellular automata	parallel computing;slope of aspect;message passing interface;digital terrain analysis;cellular automata	Solving traditional spatial analysis problems benefits from high performance geo-computation powered by parallel computing. Digital Terrain Analysis (DTA) is a typical example of data and computationally intensive spatial analysis problems and can be improved by parallelization technologies. Previous work on this topic has mainly focused on applying optimization schemes for specific DTA case studies. The task addressed in this paper, in contrast, is to find optimization methods that are generally applicable to the parallelization of DTA. By modeling a complex DTA problem with Cellular Automata (CA), we developed a temporal model that can describe the time cost of the solution. Three methods for optimizing different components in the temporal model are proposed: (1) a parallel loading/writing method that can improve the IO efficiency; (2) a best cell division method that can minimize the communication time among processes; and (3) a communication evolution overlapping method that can reduce the total time of evolutions and communications. The feasibilities and practical efficiencies of the proposed methods have been verified by comparative experiments conducted on an elevation dataset from North America using the Slope of Aspect (SOA) as an example of a general DTA problem. The results showed that the parallel performance of the SOA can be improved by applying the proposed methods individually or in an integrated fashion.	automata theory;cellular automaton;general-purpose markup language;mathematical optimization;parallel computing	Guo Cheng;Lu Liu;Ning Jing;Luo Chen;Wei Xiong	2012	Computers & Geosciences	10.1016/j.cageo.2012.03.009	cellular automaton;simulation;computer science;message passing interface;theoretical computer science;machine learning;database;mathematics;algorithm	Logic	-5.391389976548395	34.142193073142074	40246
939a9ebdc984fe26d3349a0ecc814d261b5014a6	extending a j2ee™ server with dynamic and flexible resource management	developpement logiciel;sistema operativo;virtual machine;evaluation performance;entreprise;base donnee;performance evaluation;java programming;evaluacion prestacion;resource manager;empresa;resource management;logicial personalizado;database;base dato;langage java;spectrum;machine virtuelle;j2ee;intergiciel;gestion recursos;operating system;desarrollo logicial;firm;software development;gestion ressources;middleware;systeme exploitation;lenguaje java;java 2 enterprise edition;maquina virtual;java language	The JavaTM 2 Platform, Enterprise Edition (J2EETM) is the standard platform for hosting enterprise applications written in the Java programming language. A single J2EE server can support multiple applications much like a traditional operating system, but performance levels can be difficult to control, due to the absence of resource management facilities in the Java platform. The Resource Management (RM) interface addresses this problem by providing a flexible and extensible framework for managing resources that is applicable across a broad spectrum, from low-level resources like CPU time to higherlevel resources such as database connections. RM has been implemented in the Multi-tasking Virtual Machine (MVM), a scalable operating environment for multiple applications based on the concept of isolated computations. This paper describes the application of MVM and RM to the management of resources in a J2EE Server and shows that application performance can be controlled flexibly and easily with low overhead and minimal intrusion.	application programming interface;application server;central processing unit;computation;computer multitasking;enterprise javabeans;enterprise software;high- and low-level;jdbc;java community process;java hotspot virtual machine;java management extensions;java message service;java platform, enterprise edition;java platform, standard edition;java servlet;java version history;java virtual machine;javaserver pages;load balancing (computing);machine code;operating environment;operating system;overhead (computing);programming language;prototype;provisioning;resource management (computing);runtime system;sparc;scalability;server (computing);shell script	Mick J. Jordan;Grzegorz Czajkowski;Kirill Kouklinski;Glenn Skinner	2004		10.1007/978-3-540-30229-2_23	embedded system;spectrum;computer science;virtual machine;resource management;software development;operating system;middleware;database;distributed computing;programming language;computer security;application server	OS	-27.949298258420825	42.80811587792692	40278
0cf02436f05ae8ad9cdd9e7ee60da5b849595b3a	a temporal programming model with atomic blocks based on projection temporal logic	verification;temporal logic programming;framing;semantics temporal logic programming verification framing atomic blocks;semantics;atomic blocks;xiaoxiao yang yu zhang ming fu xinyu feng 编程模型 时序逻辑 子块 时间 投影 语言结构 并行编程 ptl a temporal programming model with atomic blocks based on projection temporal logic	Atomic blocks, a high-level language construct that allows programmers to explicitly specify the atomicity of operations without worrying about the implementations, are a promising approach that simplifies concurrent programming. On the other hand, temporal logic is a successful model in logic programming and concurrency verification, but none of existing temporal programming models supports concurrent programming with atomic blocks yet. In this paper, we propose a temporal programming model (αPTL) which extends the projection temporal logic (PTL) to support concurrent programming with atomic blocks. The novel construct that formulates atomic execution of code blocks, which we call atomic interval formulas, is always interpreted over two consecutive states, with the internal states of the block being abstracted away. We show that the framing mechanism in projection temporal logic also works in the new model, which consequently supports our development of an executive language. The language supports concurrency by introducing a loose interleaving semantics which tracks only the mutual exclusion between atomic blocks. We demonstrate the usage of αPTL by modeling and verifying both the fine-grained and coarse-grained concurrency.	atomicity (database systems);code::blocks;concurrency (computer science);concurrency control;concurrent computing;forward error correction;framing (world wide web);high- and low-level;high-level programming language;interval arithmetic;language construct;logic programming;mutual exclusion;pass transistor logic;programmer;programming model;temporal logic;verification and validation	Xiaoxiao Yang;Yu Zhang;Ming Fu;Xinyu Feng	2014	Frontiers of Computer Science	10.1007/s11704-014-3342-0	framing;linear temporal logic;verification;concurrency;interval temporal logic;computation tree logic;computer science;artificial intelligence;theoretical computer science;operating system;machine learning;database;semantics;programming paradigm;inductive programming;programming language;logic programming;algorithm;concurrent object-oriented programming;temporal logic of actions	PL	-25.965657240697194	33.268489907382985	40342
17b075c429d6c125eae1f505a20cf5ef6723de0d	declarative tracepoints: a programmable and application independent debugging system for wireless sensor networks	sensor network;wireless sensor network;system evaluation;declarative tracepoints;operating system;embedded debugging;source code;use case;wireless sensor networks	Effective debugging usually involves watching program state to diagnose bugs. When debugging sensor network applications, this approach is often time-consuming and errorprone, not only because of the lack of visibility into system state, but also because of the difficulty to watch the right variables at the right time. In this paper, we present declarative tracepoints, a debugging system that allows the user to insert a group of action-associated checkpoints, or tracepoints, to applications being debugged at runtime. Tracepoints do not require modifying application source code. Instead, they are written in a declarative, SQL-like language called TraceSQL independently. By triggering the associated actions when these checkpoints are reached, this system automates the debugging process by removing the human from the loop. We show that declarative tracepoints are able to express the core functionality of a range of previously isolated debugging techniques, such as EnviroLog, NodeMD, Sympathy, and StackGuard. We describe the design and implementation of the declarative tracepoints system, evaluate its overhead in terms of CPU slowdown, illustrate its expressiveness through the aforementioned debugging techniques, and finally demonstrate that it can be used to detect real bugs using case studies of three bugs based on the development of the LiteOS operating system.	buffer overflow protection;cns;central processing unit;debugging;declarative programming;ibm notes;liteos;operating system;overhead (computing);programming language;run time (program lifecycle phase);sql;software bug;state (computer science);ftrace	Qing Cao;Tarek F. Abdelzaher;John A. Stankovic;Kamin Whitehouse;Liqian Luo	2008		10.1145/1460412.1460422	embedded system;real-time computing;wireless sensor network;computer science;distributed computing;algorithmic program debugging	Mobile	-22.142013872246306	36.26325806110249	40350
71009b7d6aef1c9a2ea812f4707bf46256683059	compositional refinement of interactive systems modelled by relations	distributed system;interactive system;mathematical model	We introduce a mathematical model of components that can be used for the description of both hardware and software units forming distributed interactive systems. As part of a distributed system a component interacts with its environment by exchanging messages in a time frame. The interaction is performed by accepting input and by producing output messages on named channels. We describe forms of composition and three forms of refinement, namely property refinement, glass box refinement, and interaction refinement. Finally, we prove the compositionality of the mathematical model with respect to the introduced refinement relations.	ccir system a;distributed computing;mathematical model;refinement (computing);white box (software engineering)	Manfred Broy	1997		10.1007/3-540-49213-5_6	computer science;theoretical computer science;algorithm	Logic	-32.3195322013368	34.2224979281003	40358
4f13075cc8c06aa3e3411ecd567745a9243ba48c	approximate mva solutions with fixed throughput classes	modelizacion;evaluation performance;approximate algorithm;performance evaluation;evaluacion prestacion;sistema informatico;computer system;valor medio;red cola espera;algorithme;modelisation;algorithm;multiclass queueing network;reseau file attente;valeur moyenne;mean value;queuing network;systeme informatique;modeling;algoritmo	Transaction (open) type workloads are often used in approximating computer system workloads which are actually closed because open workloads provide reasonable estimates in many cases and their solutions are straight-forward. We have found that their use can distort the results for many workloads in a multiclass queueing network model of a computer system. We have replaced transaction workloads with what we call fixed class workloads. We present an approximate algorithm based on MVA that represents a class with a given throughput by a corresponding terminal or batch class, which we call a fixed class workload. We solve for the closed population required to deliver the requested throughput. We also present techniques for overcoming problems encountered in the solution of some fixed class models.	approximation algorithm;distortion;model–view–adapter;network model;queueing theory;throughput	Arnold O. Allen;Gary Hynes	1990	SIGMETRICS Performance Evaluation Review	10.1145/101320.101321	real-time computing;simulation;systems modeling;computer science;operating system;statistics;mean	Metrics	-13.113070658942988	56.9027538245309	40367
de8a53699106ba9177b31616e4315bf28df0cbd8	towards archiving-as-a-service: a distributed index for the cost-effective access to replicated multi-version data	replication;archiving as a service;multi version index;data archiving;multi version data management	With the advent of data Clouds that come with nearly unlimited storage capacity combined with low storage costs, the well-established update-in-place paradigm for data management is more and more replaced by a multi-version approach. Especially in a Cloud environment with several geographically distributed data centers that act as replica sites, this allows to keep old versions of data and thus to provide a rich set of read operations with different semantics (e.g., read most recent version, read version not older than, read data as of, etc.). A combination of multi-version data management, replication, and partitioning allows to redundantly store several or even all versions of data items without significantly impacting each single site. However, in order to avoid that single sites in such partially replicated data Clouds are overloaded when processing archive queries that access old versions, query optimization has to jointly consider version selection and load balancing (site selection). In this paper, we introduce ARCTIC, a novel cost-aware index for version and site selection for a broad range of query types including both fresh data and archive data. We describe in detail the interplay between the different parts of the index and their implementation. Moreover, we present the results of the evaluation of the combined version and replica index in a Cloud environment that shows a significant gain in query throughput compared to a monolithic index.	archive;cloud computing;data center;in-place algorithm;load balancing (computing);mathematical optimization;programming paradigm;query optimization;query throughput;whole earth 'lectronic link	Filip-Martin Brinkmann;Heiko Schuldt	2015		10.1145/2790755.2790770	replication;computer science;data mining;database;world wide web	DB	-15.356061847727585	53.370280112756504	40397
9a5f2ecfe786cb9bba23dd79b5d79baf2a1d88ba	parallel programming and code selection in fortress	scientific application;design principle;programming language;java programming;diskless clusters;high productivity computing systems;data distribution;large scale;parallel computing education;tools for developing parallel or distributed software;high performance computing education;polymorphism;language development;scientific computing;source language;parallel computing environments;parallel machines;performance analysis of parallel or distributed software;parallel programs;flow analysis;type system	As part of the DARPA program for High Productivity Computing Systems, the Programming Language Research Group at Sun Microsystems Laboratories is developing Fortress, a language intended to support large-scale scientific computation with the same level of portability that the Java programming language provided for multithreaded commercial applications. One of the design principles of Fortress is that parallelism be encouraged everywhere; for example, it is intentionally just a little bit harder to write a sequential loop than a parallel loop. Another is to have rich mechanisms for encapsulation and abstraction; the idea is to have a fairly complicated language for library writers that enables them to write libraries that present a relatively simple set of interfaces to the application programmer. Thus Fortress is as much a framework for language developers as it is a language for coding scientific applications. We will discuss ideas for using a rich parameterized polymorphic type system to organize multithreading and data distribution on large parallel machines. The net result is similar in some ways to data distribution facilities in other languages such as HPF and Chapel, but more open-ended, because in Fortress the facilities are defined by user-replaceable and -extendable libraries rather than wired into the compiler. A sufficiently rich type system can take the place of certain kinds of flow analysis to guide certain kinds of code selection and optimization, again moving policymaking out of the compiler and into libraries coded in the Fortress source language.	chapel;compiler;computation;computational science;data parallelism;data-flow analysis;encapsulation (networking);fortress;high performance fortran;high productivity computing systems;java;library (computing);mathematical optimization;multithreading (computer architecture);nonlinear gameplay;parallel computing;programmer;programming language theory;simple set;software portability;thread (computing);type system	Guy L. Steele	2006		10.1145/1122971.1122972	polymorphism;parallel computing;type system;computer science;theoretical computer science;operating system;data-flow analysis;programming language	PL	-13.062378011927771	39.10785748579413	40401
bf9a14cd4033584882bb211ee826fcad4c037b89	scheduling or-parallelism in yapor and thor on multi-core machines	libraries;prolog implementation scheduling strategies parallelism;processor scheduling multiprocessing systems parallel processing;topmost dispatching or parallelism scheduling yapor thor multicore machine or scheduling strategy or parallel system;processor scheduling;parallelism;prolog implementation;logic programming;data structures;instruction sets dispatching parallel processing data structures search problems libraries logic programming;search problems;multiprocessing systems;scheduling strategies;parallel processing;dispatching;instruction sets	In this work we perform a detailed study of different or-scheduling strategies varying several parameters in two or-parallel systems, YapOr and ThOr, running on multi-core machines. Our results show that some kinds of applications are sensitive to the choice of scheduling strategy adopted. In particular, the choice of scheduling parameters mostly affect applications that have short execution times, which, despite having speedups, have their performance significantly affected. Our results also show that topmost dispatching can be more advantageous than bottommost dispatching, a finding that contradicts previous works in this area. One last finding is that YapOr and ThOr are affected differently by changes in scheduling with ThOr performing significantly better than YapOr in several applications.	central processing unit;event dispatching thread;multi-core processor;parallel computing;prolog;schedule (project management);scheduling (computing)	Inês de Castro Dutra;Ricardo Rocha;Vítor Santos Costa;Fernando M. A. Silva;João Santos	2012	2012 IEEE 26th International Parallel and Distributed Processing Symposium Workshops & PhD Forum	10.1109/IPDPSW.2012.199	parallel processing;computer architecture;parallel computing;real-time computing;computer science;operating system;instruction set;distributed computing;programming language;logic programming	Arch	-13.141939155790968	48.16282826254459	40440
c6006207465f87b177af983e5e525cb9bc16d540	quality-based synchronization methods of multimedia objects	concurrency control;quality of service	It is critical for applications to obtain enough quality of service (QoS) from multimedia objects. Not only states but also QoS of objects are changed by methods. The objects are manipulated by multiple transactions. Here, the objects are required to be consistent. We discuss new types of consistency of multimedia objects with respect to QoS. Since it takes a longer time to perform a method on multimedia objects, the throughput of the system is decreased if objects are exclusively locked in traditional concurrently control. We separate a concurrency control mechanism to two orthogonal ones, one for serializing transactions and the other for mutually exclusive access to objects. The timestamp ordering protocol is adopted for the former one and the locking protocol for the latter.		Naokazu Nemoto;Katsuya Tanaka;Makoto Takizawa	2002	Inf. Sci.	10.1016/S0020-0255(01)00192-X	real-time computing;chain-of-responsibility pattern;quality of service;computer science;concurrency control;database;distributed computing	DB	-23.856572566571177	47.70554169022458	40446
768fab865dad7f11bb8a4933c4b0e76e1a33b079	agentless cloud-wide streaming of guest file system updates	virtual machine;vmi;agentless;virtual machines cloud computing file organisation;ds vmi mechanism agentless cloud wide streaming guest file system updates virtual machine vm monitoring cloud computing guest file update monitoring vm instances central design principle introspected disk sector writes;monitoring;agentless virtual machine virtual machine introspection vmi cloud computing monitoring;monitoring gamma rays real time systems crawlers reactive power servers linux;virtual machine introspection;cloud computing	We propose a non-intrusive approach for monitoring virtual machines (VMs) in the cloud. At the core of this approach is a mechanism for selective real-time monitoring of guest file updates within VM instances. This mechanism is agentless, requiring no guest VM support. It has low virtual I/O overhead, low latency for emitting file updates, and a scalable design. Its central design principle is distributed streaming of file updates inferred from introspected disk sector writes. The mechanism, called DS-VMI, enables many system administration tasks that involve monitoring files to be performed outside VMs.	cloud computing;disk sector;entity–relationship model;ibm notes;nintendo ds and 3ds storage devices;open-source software;operating system;overhead (computing);read-only memory;real-time clock;real-time computing;scalability;software engineering institute;system administrator;virtual machine	Wolfgang Richter;Canturk Isci;Benjamin Gilbert;Jan Harkes;Vasanth Bala;Mahadev Satyanarayanan	2014	2014 IEEE International Conference on Cloud Engineering	10.1109/IC2E.2014.36	embedded system;real-time computing;computer science;operating system	DB	-21.66739899736137	52.55353483075011	40470
6e4c510be00d2971d703659d430bb6285ae1ad04	a distributed cooperative coevolutionary algorithm for multiobjective optimization	workload;parallelisme;distributed system;evolutionary computation distributed computing computer networks concurrent computing computational modeling sorting genetic algorithms parallel processing runtime application software;methode diviser pour regner;multiobjective programming;optimum pareto;programmation multiobjectif;optimisation;pareto optimisation;networked computers distributed cooperative coevolutionary algorithm multiobjective optimization evolutionary algorithms divide and conquer approach pareto optimization concurrent processing;systeme reparti;evolutionary computation;optimizacion;pareto front;multiple solution;distributed computing;metodo dividir para vencer;archive;coevolution;divide and conquer methods;multiobjective optimization coevolution distributed computing evolutionary algorithms;parallelism;sistema repartido;paralelismo;archivo;solution multiple;algorithme reparti;divide and conquer method;charge travail;pareto optimisation divide and conquer methods evolutionary computation;evolutionary algorithms;calculo repartido;algorithme evolutionniste;multiobjective optimization;algoritmo repartido;algoritmo evolucionista;optimization;evolutionary algorithm;carga trabajo;pareto optimum;solucion multiple;distributed algorithm;computer simulation;coevolucion;concurrent process;optimo pareto;calcul reparti;divide and conquer;cooperative coevolution;network computing;programacion multiobjetivo	Recent advances in evolutionary algorithms show that coevolutionary architectures are effective ways to broaden the use of traditional evolutionary algorithms. This paper presents a cooperative coevolutionary algorithm (CCEA) for multiobjective optimization, which applies the divide-and-conquer approach to decompose decision vectors into smaller components and evolves multiple solutions in the form of cooperative subpopulations. Incorporated with various features like archiving, dynamic sharing, and extending operator, the CCEA is capable of maintaining archive diversity in the evolution and distributing the solutions uniformly along the Pareto front. Exploiting the inherent parallelism of cooperative coevolution, the CCEA can be formulated into a distributed cooperative coevolutionary algorithm (DCCEA) suitable for concurrent processing that allows inter-communication of subpopulations residing in networked computers, and hence expedites the computational speed by sharing the workload among multiple computers. Simulation results show that the CCEA is competitive in finding the tradeoff solutions, and the DCCEA can effectively reduce the simulation runtime without sacrificing the performance of CCEA as the number of peers is increased	archive;benchmark (computing);computer multitasking;cooperative mimo;cooperative coevolution;evolutionary algorithm;genetic algorithm;mathematical optimization;multi-objective optimization;parallel computing;pareto efficiency;programming paradigm;simulation	Kay Chen Tan;Y. J. Yang;Chi Keong Goh	2006	IEEE Transactions on Evolutionary Computation	10.1109/TEVC.2005.860762	mathematical optimization;computer science;theoretical computer science;multi-objective optimization;machine learning;evolutionary algorithm	AI	-17.2298428360987	43.69680214909593	40471
5b0cb35478ec9b25150e460376aa2e074490cb74	the ibm diskette and diskette drive		The diskette and diskette drive have had a major influence on data processing. They provide a low-cost, compact, highperformance solution to the need for a reusable magnetic medium and have largely replaced the punched card in many applications. Early applications were simple program-load functions. Today these have expanded to a wide range of medium exchange, information storage, and data processing applications. This paper examines the history of the development of these products within IBM. The discussion includes some of the alternatives considered and some of the problems encountered during these developments.	a new kind of science;computer data storage;floppy disk;magnetic storage;punched card	James T. Engh	1981	IBM Journal of Research and Development	10.1147/rd.255.0701	computer hardware;engineering;electrical engineering;operating system	DB	-19.683317743184414	43.850575646581035	40478
158efaa09a3c6d696c17575af09f0052a529ee1c	efficiently storing virtual machine backups	storage cost;virtual machine backup;logical consistency;logical backup;physical level backup;deduplicating storage;physical backup;data-driven approach;good backup performance;logical backup model	Physical level backups offer increased performance in terms of throughput and scalability as compared to logical backup models, while still maintaining logical consistency [2]. As the trend toward virtualization grows, virtual machine backups (a form of physical backup) are even more important, while becoming easier to perform. The downside is that physical backup generally requires more storage, because of file system meta-data and unallocated blocks. Deduplication is becoming widely accepted and many believe that it will favor logical backup, but this has not been well studied and the relative cost of physical vs. logical on deduplicating storage is not known. In this paper, we take a data-driven approach using user data to quantify the storage costs and contributing factors of physical backups over numerous generations. Based on our analysis, we show how physical backups can be as storage efficient as logical backups, while also giving good backup performance.	backup;central processing unit;data deduplication;delta encoding;disk image;fred (chatterbot);media foundation;netbsd gzip / freebsd gzip;optimizing compiler;scalability;shallow parsing;shim (computing);throughput;virtual machine;workstation;zfs	Stephen Smaldone;Grant Wallace;Windsor W. Hsu	2013			backup software;real-time computing;data loss;incremental backup;computer science;database;distributed computing;enterprise storage	OS	-15.740745130241192	53.9260883386344	40492
0fca220343f411c7dac67b1f5fc1bcf5790cc030	high performance dynamic lock-free hash tables and list-based sets	processor architecture;memory management;building block;sliding windows;data streams;hash table;robust performance;distributed;high performance;data structure;waves	Lock-free (non-blocking) shared data structures promise more robust performance and reliability than conventional lock-based implementations. However, all prior lock-free algorithms for sets and hash tables suffer from serious drawbacks that prevent or limit their use in practice. These drawbacks include size inflexibility, dependence on atomic primitives not supported on any current processor architecture, and dependence on highly-inefficient or blocking memory management techniques.Building on the results of prior researchers, this paper presents the first CAS-based lock-free list-based set algorithm that is compatible with all lock-free memory management methods. We use it as a building block of an algorithm for lock-free hash tables. In addition to being lock-free, the new algorithm is dynamic, linearizable, and space-efficient.Our experimental results show that the new algorithm outperforms the best known lock-free as well as lock-based hash table implementations by significant margins, and indicate that it is the algorithm of choice for implementing shared hash tables.	blocking (computing);boolean algebra;data structure;free list;hash table;linearizability;memory management;non-blocking algorithm	Maged M. Michael	2002		10.1145/564870.564881	waves;hash table;double hashing;parallel computing;real-time computing;hash function;perfect hash function;dynamic perfect hashing;merkle tree;data structure;primary clustering;quadratic probing;microarchitecture;sha-2;computer science;theoretical computer science;operating system;hash chain;distributed computing;hash list;rolling hash;programming language;algorithm;cryptographic hash function;hash tree;hash filter;hat-trie;memory management	OS	-14.672914352425702	49.144741650947296	40510
6762e07e9e9f3fed6feeadf5cb01e16a66b20016	reducing impact of cache miss stalls in embedded systems by extracting guaranteed independent instructions	compiler assisted hardware;embedded system;pipeline stalls;out of order execution;data cache;data dependence;embedded processors;embedded processor;memory latency	Today, embedded processors are expected to be able to run complex, algorithm-heavy, memory-intensive applications that were originally designed and coded for general-purpose processors. As such, the impact of memory latencies on the execution time increasingly becomes evident. All the while, it is also expected that embedded processors be power-conscientious as well as of minimal area impact. As a result, traditional methods for addressing performance and memory latencies, such as multiple issue, out-of-order execution and large, associative caches, are not aptly suited for the embedded domain due to the significant area and power overhead. This paper explores a novel approach to mitigating execution delays caused by memory latencies that would otherwise not be possible in a regular in-order, single-issue embedded processor without large, power-hungry constructs like a Reorder Buffer (ROB). The concept relies on both compile-time and run-time information to safely allow non-data-dependent instructions to continue executing while a memory stall has occurred. The simulation results show significant improvement in execution throughput of approximately 11%, while having a minimal impact on area overhead and power.	algorithm;buffer overflow;cpu cache;central processing unit;compile time;compiler;data dependency;embedded system;general-purpose modeling;out-of-order execution;overhead (computing);re-order buffer;run time (program lifecycle phase);simulation;throughput	Garo Bournoutian;Alex Orailoglu	2009		10.1145/1629395.1629413	embedded system;parallel computing;real-time computing;cas latency;computer hardware;computer science;out-of-order execution;operating system	EDA	-7.301241548123381	52.522915783014476	40536
96a3f00cc51b2c69a2cc4192e85d2e479207a4c1	development of an interpreter for lrt using the exact real number paradigm		The exact real number representation can grow arbitrarily so it does not truncate or rounds up as opposed to oating point number representation. The advantage of this representation is that not rounding errors are generated and any operation can be achieved with the desired accuracy. The LRT is a proposal that implements exact real number. This paper develops an interpreter for LRT using this paradigm whose operational semantics is based on sixteen rules so the programs based on LRT libraries are less complicated to debug. One of the main problems in implementing LRT has been memory consumption. The main contribution of this work is that LRT has its own administrator for in nite lists as well as its own lazy evaluation. The performance of programs written in LRT interpreter is shown to be superior to the libraries of functions in both execution time and use of memory.	lazy evaluation;library (computing);long-running transaction;operational semantics;programming paradigm;round-off error;rounding;run time (program lifecycle phase);truncation	J. Leonardo González-Ruiz;José Antonio Hernández Servín;José Raymundo Marcial-Romero	2015	Research in Computing Science		computer science;theoretical computer science;programming language;algorithm	Logic	-17.153358156678458	33.352373209600735	40646
c861a17a4e45e55aaec50a6863d2ccc047f1375e	rethinking multicast for massive-scale platforms	multicast protocols distributed computing internet cloud computing waste materials web services biographies computer science magnetic heads mashups;routing protocols;mashups;waste materials;magnetic heads;biographies;distributed computing;data mining;internet;multicast protocols;fault tolerance;web services;computer science;atmospheric modeling;security;cloud computing	A dramatic scale-up of distributed computing platforms is underway. Internet routers can contain hundreds or thousands of line cards. Cloud computing platforms may contain tens or even hundreds of thousands of machines. What is gluing all of this together? Multicast to support data replication, event streams, and coordination. Yet yesterday’s multicast protocols are poorly matched to this new generation of uses; so much so that many cloud platforms refuse to deploy multicast as such, and have instead resorted to clumsy alternatives, mapping multicast to TCP or even web services method invocations. This talk will explore inadequacies of existing protocols, early progress towards better ones, and the longer term research agenda. Biography Ken Birman [http://www.cs.cornell.edu] is The N. Rama Rao Professor of Computer Science at Cornell University. He heads Cornell’s Live Information Objects project, which is developing new ways to create client-side mashups that blend hosted content with P2P multicast protocols. Multicast has been a theme of his work for nearly thirty years, used for such purposes as fault-tolerance, data and service replication, locking, and end-to-end security. Birman’s work has been widely adopted in industry. His Isis Toolkit, which introduced the virtual synchrony model, is central to the French air traffic control system and US Navy AEGIS, and operated the New York Stock exchange for more than a decade. Technologies Birman helped design and implement are used by Amazon.com, IBM and Microsoft to operate their largest clustered platforms and products. The author of several books and more than 200 journal and conference papers, Dr. Birman was Editor in Chief of ACM Transactions on Computer Systems from 1993-1998 and is a Fellow of the ACM. 2009 29th IEEE International Conference on Distributed Computing Systems 1063-6927/09 $25.00 © 2009 IEEE DOI 10.1109/ICDCS.2009.84 1	acm transactions on computer systems;book;client-side;cloud computing;computer science;control system;distributed computing;end-to-end principle;fault tolerance;icdcs;isis;internet;lock (computer science);multicast;replication (computing);virtual synchrony;web service	Kenneth P. Birman	2009	2009 29th IEEE International Conference on Distributed Computing Systems	10.1109/ICDCS.2009.84	web service;atmospheric model;fault tolerance;the internet;cloud computing;telecommunications;computer science;information security;operating system;database;distributed computing;routing protocol;law;world wide web;computer security;mashup;computer network	Visualization	-27.45882925070157	51.68250732119915	40655
929733311dc23de3989b71d22fd0ac8c7e27d376	ilias : a sequential language for parallel matrix computations	data distribution;matrix computation;matrix multiplication	The ILIAS system consists of a. sequential language for matrix computations, a compiler translating a. source program into ILIAS pseudo code and a parallel interpreter for this code. The pseudo code is independent of a target architecturej it merely specifies scalar and matrix computations. We present the ILIAS language and discuss its implementation on a square torus network of transputers. Subscription of matrices causes data-alignment problems, which are solved by redistributions. To reduce redistribution overhead we use a new data distribution called the grid-base distribution. Furthermore, we develop several run-time heuristics that, together with the grid.base distribution, efficiently implement matrix subscription. The feasibility and scalability of the ILIAS system is demonstrated by timing results for two example ILIAS programs, an L U decomposition and a Strassen matrix multiplication, on transputer networks up to 400 processors.		L. D. J. C. Loyens;Jean R. Moonen	1993		10.1007/3-540-58184-7_106	parallel computing;sparse matrix;single-entry matrix;theoretical computer science;band matrix;commutation matrix;vectorization;logical matrix;state-transition matrix;block matrix	HPC	-12.282753596661182	37.005227736666384	40716
10f9d33a295b1f3975f568a8d10b84f148bd7468	architecture of the atlas chip-multiprocessor: dynamically parallelizing irregular applications	chip multiprocessor;parallel programming multiprocessing systems parallel architectures;parallel programming;parallel architectures;multiprocessing systems;thread level parallelism atlas chip multiprocessor architecture dynamic parallelization irregular applications single chip multiprocessor aggressive speculation techniques irregular sequential binaries thread speculation data value prediction dynamic thread partitioning mem slicing aggressive correlated value predictor inter thread dependency management simulations sequential programs specint95 speedup;automatic parallelization;yarn application software microprocessors delay registers computer architecture concurrent computing microarchitecture parallel processing energy consumption;value prediction	Single-chip multiprocessors are an important research direction for future microprocessors. The stigma of this approach is that many important applications cannot be automatically parallelized. This paper presents a single-chip multiprocessor that engages aggressive speculation techniques to enable dynamic parallelization of irregular, sequential binaries. Thread speculation (multiscalar execution) and data value prediction are combined to enable the processor to execute dependent threads in parallel. The architecture performs a novel form of dynamic thread partitioning and includes an aggressive correlated value predictor. Several new microarchitectural structures manage inter-thread dependencies. On an eight processor system, simulated execution of SPECint95 binaries delivers a speedup of 3.4 over uniprocessor performance. This improvement is due entirely to the exploitation of dynamically extracted thread level parallelism.	automatic parallelization;kerrison predictor;microarchitecture;microprocessor;multi-core processor;multiprocessing;parallel computing;speedup;task parallelism;uniprocessor system	Lucian Codrescu;D. Scott Wills	1999		10.1109/ICCD.1999.808577	embedded system;computer architecture;parallel computing;real-time computing;computer science;operating system;speculative multithreading;automatic parallelization	Arch	-7.041393218890075	49.93550773221661	40762
257b6045e6907e16892fcf94d79cb1eecbdfbd8a	green streams for data-intensive software	software;green streams linear programming constraint based inference parallel processing environment dvfs dynamic voltage and frequency scaling stream programming model data processing components energy consumption energy efficiency data intensive software;green products;data processing;parallel programming;inference mechanisms;software engineering;power aware computing;energy consumption;programming software green products linear programming abstracts energy consumption data processing;abstracts;software engineering green computing inference mechanisms linear programming parallel programming power aware computing;linear programming;programming;green computing	This paper introduces GREEN STREAMS, a novel solution to address a critical but often overlooked property of data-intensive software: energy efficiency. GREEN STREAMS is built around two key insights into data-intensive software. First, energy consumption of data-intensive software is strongly correlated to data volume and data processing, both of which are naturally abstracted in the stream programming paradigm; Second, energy efficiency can be improved if the data processing components of a stream program coordinate in a “balanced” way, much like an assembly line that runs most efficiently when participating workers coordinate their pace. GREEN STREAMS adopts a standard stream programming model, and applies Dynamic Voltage and Frequency Scaling (DVFS) to coordinate the pace of data processing among components, ultimately achieving energy efficiency without degrading performance in a parallel processing environment. At the core of GREEN STREAMS is a novel constraint-based inference to abstract the intrinsic relationships of data flow rates inside a stream program, that uses linear programming to minimize the frequencies – hence the energy consumption – for processing components while still maintaining the maximum output data flow rate. The core algorithm of GREEN STREAMS is formalized, and its optimality is established. The effectiveness of GREEN STREAMS is evaluated on top of the StreamIt framework, and preliminary results show the approach can save CPU energy by an average of 28% with a 7% performance improvement.	algorithm;central processing unit;data-intensive computing;dataflow;dynamic frequency scaling;dynamic voltage scaling;linear programming;online and offline;parallel computing;programming model;programming paradigm;requirement;standard streams;stream processing	Thomas Bartenstein;Yu David Liu	2013	2013 35th International Conference on Software Engineering (ICSE)	10.1109/ICSE.2013.6606599	green computing;programming;parallel computing;real-time computing;n-version programming;data processing;reactive programming;computer science;linear programming;theoretical computer science;operating system;software engineering;programming language;management	SE	-6.897802772854371	56.5686381146562	40817
712d56d28736a087f96cc869148c8acaae35fb21	an object-oriented programming framework for parallel finite element analysis with application: liquid composite molding	application development;parallel finite element analysis;finite element methods;programming environments;concurrent computing;application software;resin transfer molding;interface tools object oriented programming framework parallel finite element analysis liquid composite molding software reuse data file parsing equation solving post processing research codes graphical user interfaces compose generic visualization;generic visualization;interface tools;liquid composite molding;object oriented programming;finite element method;functional programming;finite element;production engineering computing;transfer moulding finite element analysis object oriented programming programming environments parallelising compilers production engineering computing graphical user interfaces program visualisation;manufacturing processes;graphical user interfaces;data file parsing;parallelising compilers;research codes;software development;data visualization;transfer moulding;object oriented programming framework;graphic user interface;finite element analysis;equation solving;object oriented programming finite element methods application software graphical user interfaces concurrent computing functional programming manufacturing processes laboratories equations data visualization;compose;software reuse;program visualisation;parallel processing;post processing	The use of object-oriented programming techniques in development of parallel, finite element analysis software enhances software reuse and makes application development more efficient. In this paper, an object-oriented programming framework for developing parallel finite element software is described. All required steps, from data file parsing and equation solving to post processing and graphical user interfaces, are discussed. After development of the framework, a sample parallel finite element code, namely COMPOSE, is taken from its original functional programming paradigm and implemented in the new framework. Besides ease of development, the use of generic visualization and interface tools for software utilizing the framework speeds delivery of research codes to end users.	c++;code reuse;computer data storage;domain decomposition methods;equation solving;finite element method;functional programming;graphical user interface;kinetics internet protocol;multiple inheritance;parallel algorithm;parallel computing;parsing;programmer;programming paradigm;refinement (computing);resin;software development;solver;sparse matrix;swift (programming language)	Brian J. Henz;Dale R. Shires	2003		10.1109/IPDPS.2003.1213459	parallel processing;parallel computing;concurrent computing;functional reactive programming;computer science;theoretical computer science;software framework;software development;operating system;finite element method;database;distributed computing;programming language;functional programming;software development process;data visualization	HPC	-9.720705693901229	36.82461906973834	40846
a594118c6a743e99b36c7ee3de684e97957f9109	on microprocessors: a platform for true program portability with examples from microcobal			microprocessor	A. D'Agapayeff	1979				Logic	-8.54710284000983	43.7182124308628	40867
f1728af622d45aa97d83bc790854cbc7e221d92c	cloud service of analyzing virus data: a case study for norovirus	virus analysis;service oriented architecture bioinformatics cloud computing microorganisms;virtualization;phylogeny;virtual machining;computer architecture;cloud computing phylogeny bioinformatics virtualization computer architecture virtual machining;remote computing resources cloud service virus data analysis norovirus internet based development software services bioinformatics tools biologists local system bioinformatics as a service cloud computing biocomputing services virus analysis service;service oriented architecture;virus analysis cloud computing bioinformatics;microorganisms;cloud computing;bioinformatics	Cloud computing, an emerging Internet-based development provides various platform and software services has become a significant issue. Many bioinformatics tools developed based on the Internet for biologists without reconstructing the whole software in the local system. Therefore, bioinformatics as a service is a new significant demand of cloud computing that integrates the bioinformatics tools to cloud platform to provide more efficient bio-computing services. In this paper, we propose a virus analysis service on the cloud. Norovirus is used as case study for this service. The result demonstrates that the proposed cloud service is able to be easily used to analyze virus data by using remote computing resources.	bioinformatics;british informatics olympiad;cloud computing;internet	Che-Lun Hung;Chun-Yuan Lin	2012	4th IEEE International Conference on Cloud Computing Technology and Science Proceedings	10.1109/CloudCom.2012.6427594	virtualization;cloud computing;computer science;bioinformatics;operating system;service-oriented architecture;cloud testing;distributed computing;utility computing;microorganism;data as a service;world wide web;phylogenetics	HPC	-33.11023620491125	53.76969998832803	40925
a3ee431d5ba16d823457e848d0794cfb5b502820	organization of an instruction scheduling and token storage unit in a tagged token dataflow machine	instruction scheduling		dataflow;instruction scheduling	Stephen A. Brobst	1987			distributed computing;instruction scheduling;parallel computing;security token;dataflow;two-level scheduling;computer science	Arch	-10.188417007650362	44.11211857251127	40933
ae03090c044c8fefe2be4daefadc0adfcebc0fb6	abstraction of transaction demarcation in component-oriented platforms	distributed system;tratamiento transaccion;systeme reparti;enterprise javabeans;componente logicial;componente ejb;logicial personalizado;distributed computing;abstraction;composant logiciel;corba;systeme ouvert;abstraccion;intergiciel;sistema repartido;software component;calculo repartido;middleware;transaction processing;open systems;sistema abierto;common object request broker architecture;composant ejb;calcul reparti;traitement transaction	ion of Transaction Demarcation in Component-Oriented Platforms Romain Rouvoy and Philippe Merle INRIA Jacquard Project, Laboratoire d’Informatique Fondamentale de Lille, UPRESA 8022 CNRS – U.F.R. I.E.E.A. – Bâtiment M3, Université des Sciences et Technologies de Lille, 59655 Villeneuve d’Ascq Cedex, France, rouvoy, merle @lifl.fr Abstract. Component-oriented middleware becomes the privileged substrate for distributed computing in heterogeneous and open environments. Technically they promote the notion of container as structure to host application components. They transparently take charge of a large set of technical or non-functional services like security or transactions. The transaction service is integrated using a set of transaction demarcation (TD) policies. Nevertheless, they are strongly linked to a specific transactional monitor and they are not often isolated. The main contribution of this paper is to propose a component-based framework to deal with TD policies. Thus, this framework allows one to instantiate several configurations of TD policies with different platforms like EJB, CCM, OSGi, WebServices and several transactional monitors like JTS, OTS, WS-T, BTP, etc. It proposes an extensible abstraction of TD policies. This framework shows that no performance degradation is introduced by the refactoring process. Component-oriented middleware becomes the privileged substrate for distributed computing in heterogeneous and open environments. Technically they promote the notion of container as structure to host application components. They transparently take charge of a large set of technical or non-functional services like security or transactions. The transaction service is integrated using a set of transaction demarcation (TD) policies. Nevertheless, they are strongly linked to a specific transactional monitor and they are not often isolated. The main contribution of this paper is to propose a component-based framework to deal with TD policies. Thus, this framework allows one to instantiate several configurations of TD policies with different platforms like EJB, CCM, OSGi, WebServices and several transactional monitors like JTS, OTS, WS-T, BTP, etc. It proposes an extensible abstraction of TD policies. This framework shows that no performance degradation is introduced by the refactoring process.	code refactoring;component-based software engineering;computer monitor;database transaction;demarcation point;distributed computing;elegant degradation;enterprise javabeans;intel mcs-48;java topology suite (jts);middleware;osgi;smart-m3;web service	Romain Rouvoy;Philippe Merle	2003		10.1007/3-540-44892-6_16	real-time computing;computer science;operating system;common object request broker architecture;database;distributed computing;computer security	PL	-28.713596006519936	42.31993252240859	41073
99506fff44ab41f7df9a958d62fdb61b35a388f9	towards universal cloud service for distributed large scale scientific data	cloud computing computer architecture virtual machining servers throughput containers;universal cloud service infrastructure distributed large scale scientific data resources pool container distributed heterogeneous scientific resources integration distributed heterogeneous scientific resources continuous expansion scalable architecture application virtualization back end transparent resources pool open interface;virtualisation cloud computing distributed databases scientific information systems;cloud service cloud computing e science;distributed databases;scientific information systems;virtualisation;cloud computing	Integrating heterogeneous scientific dataset and providing universal collaborative services is an important goal for e-Science project of Chinese Academy of Sciences (CAS). In this paper, we present a universal cloud service for scientific dataset applications. We firstly design a resources pool container to support distributed heterogeneous scientific resources integration and continuous expansion. We then provide a scalable architecture to support application virtualization, which aims to support cloud service invocation applying back-end transparent resources pool. Finally an open interface is presented for third-party to develop customized applications. We give the experiments on the cloud service infrastructure of its performance, which shows our approach achieves considerable efficiency.	academy;application virtualization;big memory;cloud computing;clustered file system;e-science;experiment;nikon cx format;open interface;scalability;throughput	Jianjun Xie;Junling Huang;Fang Qian;Jianjun Yu	2012	2012 IEEE 2nd International Conference on Cloud Computing and Intelligence Systems	10.1109/CCIS.2012.6664421	cloud computing security;cloud computing;computer science;operating system;cloud testing;database;distributed computing;utility computing;world wide web;distributed database	HPC	-31.12262183466293	53.475833606148775	41079
4508ac69f39b8235225c664c7260a394e7848795	a comparison of four microcomputer operating systems	real time operating system;spectrum;development environment;operating system;real time application;process control system;real time systems	This article describes a comparative study of four operating systems for IBM-PC compatible microcomputers. The assessment concentrated on the suitability of the operating systems for use in real-time applications, and on their use as development environments for real-time systems. The study evaluated the predictability and the performance of the operating systems in several areas critical in real-time systems by using comparative benchmarks. In addition, a small-scale simulation of a process control system was developed for each of the systems. The operating systems that were studied were UNIX, OS/2, QNX and FlexOS. These operating systems represent a broad spectrum of systems from general purpose operating systems to small, specialized real-time operating systems. The details of the evaluation process are given and a summary of the results is presented.	distributed control system;flexos;ibm pc compatible;ibm personal computer;microcomputer;os/2;qnx;real-time clock;real-time computing;real-time operating system;real-time transcription;simulation;unix	George Wells	1993	Real-Time Systems	10.1007/BF01088835	embedded system;spectrum;embedded operating system;real-time computing;real-time operating system;computer science;operating system;process control;development environment	Embedded	-28.3765842756569	39.647621681182216	41101
28f40413b48fc43c9d72348d93d9c54951fbdab0	fixed-priority preemptive multiprocessor scheduling: to partition or not to partition	multiprocessor scheduling;preemptive scheduling;algorithm performance;fixed priority preemptive multiprocessor scheduling;availability;processor scheduling;multiprocessors;partitioning;software performance evaluation;migration costs fixed priority preemptive multiprocessor scheduling multiprocessor real time scheduling task set partitioning uniprocessor scheduling periodically arriving tasks algorithm performance preemption costs;fixed priority;migration costs;runtime;resumes;non partitioned method;processor scheduling partitioning algorithms costs computer architecture runtime resumes multiprocessing systems availability design methodology modems;software performance evaluation processor scheduling real time systems;dynamic binding;computer architecture;shared memory multiprocessors;real time scheduling;global scheduling;modems;multiprocessing systems;fixed priority scheduling;bin packing algorithms;periodically arriving tasks;task set partitioning;uniprocessor scheduling;partitioning algorithms;multiprocessor real time scheduling;real time systems;design methodology;preemption costs	Traditional multiprocessor real-time scheduling partitions a task set and applies uniprocessor scheduling on each processor. For architectures where the penalty of migration is low, such as uniform-memory access shared-memory multiprocessors, the non-partitioned method becomes a viable alternative. By allowing a task to resume on another processor than the task was preempted on, some task sets can be scheduled where the partitioned method fails. We address fixed-priority scheduling of periodically arriving tasks onm equally powerful processors having a non-partitioned ready queue. We propose a new priorityassignment scheme for the non-partitioned method. Using an extensive simulation study, we show that the priorityassignment scheme has equivalent performance to the best existing partitioning algorithms, and outperforms existing fixed-priority assignment schemes for the non-partitioned method. We also propose a dispatcher for the nonpartitioned method which reduces the number of preemptions to levels below the best partitioning schemes.	algorithm;central processing unit;context switch;fixed-priority pre-emptive scheduling;multiprocessing;multiprocessor scheduling;network switch;preemption (computing);process state;random-access memory;real-time clock;scheduling (computing);shared memory;simulation;uniform memory access;uniprocessor system	Björn Andersson;Jan Jonsson	2000		10.1109/RTCSA.2000.896409	fixed-priority pre-emptive scheduling;availability;parallel computing;real-time computing;design methods;computer science;operating system;distributed computing;preemption;multiprocessor scheduling	Embedded	-12.199189612555905	59.983770294518415	41146
12091cf2291037200d704c3ad595969f76a9e6fe	synchronizers for local computations	synchronisateur;transformacion grafo;rewrite rule;graph transformation;synchronisation;transformation graphe;synchronization;local computation;sincronizacion;synchronizer;sincronizador	A synchronizer is intended to allow synchronous algorithms to be executed on asynchronous networks. It is useful because designing synchronous algorithms is generally much easier than designing asynchronous ones. In this paper, we provide synchronization protocols described as local computations. We obtain a general and an unified approach for handling synchrony in the framework of local computations.	algorithm;asynchronous i/o;computation;synchronization (computer science);synchronizer (algorithm)	Yves Métivier;Mohamed Mosbah;Rodrigue Ossamy;Afif Sellami	2004		10.1007/978-3-540-30203-2_20	synchronization;real-time computing;computer science;theoretical computer science;distributed computing;algorithm;synchronizer	Theory	-22.651045751411047	42.77125192346476	41185
5466651ba8f11e62477567ef5770c16a49e86fbe	a performance tuning methodology with compiler support	openuh compiler;mpi performance problem;performance result;scalable performance measurement;performance measurement;performance view;compiler technology;popular performance tool;performance tuning;acceptable level;compiler support;compiler optimizations	We have developed an environment, based upon robust, existing, open source software, for tuning applications written using MPI, OpenMP or both. The goal of this effort, which integrates the OpenUH compiler and several popular performance tools, is to increase user productivity by providing an automated, scalable performance measurement and optimization system. In this paper we describe our environment, show how these complementary tools can work together, and illustrate the synergies possible by exploiting their individual strengths and combined interactions. We also present a methodology for performance tuning that is enabled by this environment. One of the benefits of using compiler technology in this context is that it can direct the performance measurements to capture events at different levels of granularity and help assess their importance, which we have shown to significantly reduce the measurement overheads. The compiler can also help when attempting to understand the performance results: it can supply information on how a code was translated and whether optimizations were applied. Our methodology combines two performance views of the application to find bottlenecks. The first is a high level view that focuses on OpenMP/MPI performance problems such as synchronization cost and load imbalances; the second is a low level view that focuses on hardware counter analysis with derived metrics that assess the efficiency of the code. Our experiments have shown that our approach can significantly reduce overheads for both profiling and tracing to acceptable levels and limit the number of times the application needs to be run with selected hardware counters. In this paper, we demonstrate the workings of this methodology by illustrating its use with selected NAS Parallel Benchmarks and a cloud resolving code.	compiler;performance tuning	Oscar R. Hernandez;Barbara M. Chapman;Haoqiang Jin	2008	Scientific Programming	10.3233/SPR-2008-0253	computer architecture;parallel computing;real-time computing;computer science;operating system;optimizing compiler;programming language	HPC	-16.909467761911607	47.71465962721371	41205
5e23995e2b523e09c6cb8772957efc845d061d52	a high availability and disaster recovery system	databases;disaster recovery;high availability;cluster;banking industry;performance evaluation;recovery disaster;disaster recovery system;availability;performance comparison;relational database;availability transaction databases computer science information technology production systems disaster management protection switches computer industry data security;servers;system recovery;design and implementation;unix security of data system recovery;business;cluster structure;production;performance comparison high availability recovery disaster cluster;disaster recovered structure;security of data;unix;relational database disaster recovery system cluster structure data security disaster recovered structure unix;file systems;data security	In this paper, we present the design and implementation of cluster structure and disaster recovered system that can be used in the bank, industry and enterprise. It is capable of storing great capacity data. This toolkit is targeted at data security business which want to achieve high availability and disaster recovered structure and to compare their structure with others. The comparison functions can be used to find structure differences between two performance level, especially in data safeguard. The system is developed in Unix and the great capacity data is stored in a relational database.	computer data storage;data security;disaster recovery;high availability;relational database;requirement;unix	Qin Zhang;Hong A Xu	2008	2008 IEEE Conference on Robotics, Automation and Mechatronics	10.1109/RAMECH.2008.4681437	availability;relational database;computer science;engineering;data mining;database;data security;high availability;unix;computer security;disaster recovery;server;cluster	DB	-24.425960017367533	50.28365978831746	41214
2b972d2891715c459d285b0ec349461a2b1369a6	optimisation of application execution on dynamic systems	fourier transform;dynamic system;fftw;quality of information;on the fly;performance optimisation;application steering;performance prediction;dynamic performance prediction;grid system;performance modelling	In this paper, we demonstrate the impact of using a dynamic (on-the-fly) performance prediction tool-set, PACE, for optimising application execution on dynamic systems. The need for steering the application execution arises from the ever-growing use of distributed and GRID systems. The unquestionable aim to overcome bottleneck problems, allocation, and performance degradation due to shared CPU time has prompted many investigations into the best way in which the performance of an application can be enhanced. In this work, we present a novel approach to dynamically optimise the performance of an application. An example application, the FFTW (the fastest Fourier transform in the west), is used to illustrate the approach which itself is a novel method that optimises the execution of an FFT. It is shown that performance prediction can provide the same quality of information as a measurement process for application optimisation but in a fraction of the time and thus improving the overall application performance. © 2001 Elsevier Science B.V. All rights reserved.	central processing unit;computation;dynamical system;elegant degradation;executable;fftw;fast fourier transform;fastest;grid computing;mathematical optimization;performance prediction;scheduling (computing)	A. M. Alkindi;Darren J. Kerbyson;Efstathios Papaefstathiou;Graham R. Nudd	2001	Future Generation Comp. Syst.	10.1016/S0167-739X(01)00036-X	embedded system;fourier transform;parallel computing;real-time computing;simulation;computer science;operating system;dynamical system;information quality	HPC	-7.511675302928699	46.09652952493275	41217
e7bf8bad8d5ca95b68bf143987d2e650d75aa757	the solo operating system: processes, monitors, and classes	operator communication;resource scheduling;concurrent;processes;hierarchical program design;abstract data types;monitors;input output;process monitoring;solo operating system;program testing;operating system;file system;classes;message buffers;concurrent programs;pascal;concurrent process;independent component	DATA TYPES Each program layer consists of one or more abstract data types (monitors and classes). Resource management A fifo class implements a first-in, first-out queue that is used to maintain multiprocess queues and message buffers. A resource monitor gives processes exclusive access to a computer resource. It is used to control disk access. A typewriter resource monitor gives processes exclusive access to a console and tells them whether they need to identify themselves to the operator. Console management A typewriter class transmits a single line between a process and a console (but does not give a process exclusive access to it). A terminal class gives a process the illusion that it has its own private console by giving it exclusive access to the operator for input or output of a single line. A terminal stream makes a terminal look character oriented. Disk management A disk class can access a page anywhere on disk (but does not give a process exclusive access to it). It uses a terminal to report disk failure. A disk file can access any page belonging to a particular file. The file pages, which may be scattered on disk, are addressed indirectly through a page map. The disk address of the page map identifies the file. It uses a disk to access the map and its pages. A disk table class makes a disk catalog of files look like an array of entries, some of which describe files, and some of which are empty. The entries are identified by numeric indices. It uses a disk file to access the catalog page by page. A disk catalog monitor can look up files in a disk catalog by means of their names. It uses a resource to get exclusive acess to the disk and a disk table to scan the catalog. A data file class gives a process access to a named disk file. It uses a resource, a disk catalog, and a disk file to access the disk. SOLO: PROCESSES, MONITORS AND CLASSES 5 Program management A program file class can load a named disk file into core when a process wishes to execute it. It uses a resource, a disk catalog, and a disk file to do this. A program stack monitor keeps track of nested program calls within a process. Buffer management The buffer monitors transmit various kinds of messages between processes: arguments (scalars or identifiers), lines, and pages. The following defines the purpose, specification, and implementation of each of these abstract data types.	abstract data type;computer program;fifo (computing and electronics);floppy disk;identifier;indirect branch;logical disk manager;operating system;page view;resource management (computing);solo	Per Brinch Hansen	1976	Softw., Pract. Exper.	10.1002/spe.4380060204	input/output;embedded system;real-time computing;pascal;computer science;operating system;class;programming language;abstract data type	OS	-25.898618172842422	38.380954482877165	41271
151ca857efe6f484b39afea1f1a63fc5b32dcdbc	dynamic load balancing for the simulation of granular materials	dynamic load balancing;granular material	We discuss the simulation of granular materials and the problems encountered when parallelizing these simulations. The main problem of inadequately balanced loads can be mitigated via the use of a dynamic load balancing procedure. We discuss a mapping of this procedure onto a deterministic cellular automaton and show that the time needed for convergence from an initially unbalanced state grows like T cc P“, with P being the number of processors and ~ = (),0t3$J+ 0.009. THs convergence time can be considered “fast”, enabling t hk algorithm to track fluctuations in the particle density as the simulation progresses. We then discuss the implementation of this algorithm on a Paragon XP/S 10 and a CRAY T3D.	algorithm;cellular automaton;central processing unit;cray t3d;load balancing (computing);parallel computing;simulation;unbalanced circuit	R. Knecht;Gregory Allen Kohring	1995		10.1145/224538.224556	granular material;computer science	HPC	-6.08003643400578	37.12820602452786	41302
b03c16f2b33108299127ef65b014de4865f4a54f	integrated semantics of intermediate-language c and macro-assembler for pervasive formal verification of operating systems and hypervisors from verisoftxt	c function;macro-assembler code execution;pervasive verification context;pervasive formal verification;pervasive operating system;integrated semantics;formal correctness;gate-level hardware model;intermediate-language c;integrated operational small-step semantics;hypervisor verification;formal verification	Pervasive formal verification of operating systems and hypervisors is, due to their safety-critical aspects, a highly relevant area of research. Many implementations consist of both assembler and C functions. Formal verification of their correctness must consider the correct interaction of code written in these languages, which is, in practice, ensured by using matching application binary interfaces (ABIs). Also, these programs must be able to interact with hardware. We present an integrated operational small-step semantics model of intermediatelanguage C and Macro-Assembler code execution for pervasive operating systems and hypervisor verification. Our semantics is based on a compiler calling convention that defines calleeand caller-save registers. We sketch a theory connecting this semantic layer with an ISA-model executing the compiled code for use in a pervasive verification context. This forms a basis for soundness proofs of tools used in the VerisoftXT project and is a crucial step towards arguing formal correctness of execution of the verified code on a gate-level hardware model.	ansi escape code;assembly language;c standard library;call stack;calling convention;compiler;correctness (computer science);formal verification;high- and low-level;hypervisor;intermediate representation;microsoft macro assembler;operating system;operational semantics	Sabine Schmaltz;Andrey Shadrin	2012		10.1007/978-3-642-27705-4_3	formal verification;computer science;theoretical computer science;database;programming language	PL	-21.655713329606996	32.59787184033059	41328
4ce795cc102abe9eff1df27b731cd90e369cb36a	software coherence management on non-coherent cache multi-cores	8 core noncache coherent texas instruments processor tms320c6678 software coherence management noncoherent cache multicores design complexity power consumption hardware cache coherence logic skipping coherence dma instructions parallel programming program transformations runtime library data race free multithreaded programs byte granularity private write notice multithreaded signal processing benchmarks;multi core processor;software coherence management;software managed multicores software coherence management scratchpad memory multi core processor;software managed multicores;software libraries cache storage multi threading;coherence software multicore processing hardware memory management synchronization;scratchpad memory	The design complexity and power consumption of hardware cache coherence logic increase considerably with the increase in number of cores. Although skipping coherence can simplify hardware and make it more power-efficient, programming becomes more challenging as programmers have to manually insert DMA instructions to ensure that there is coherence of shared data between cores. To reduce the burden of parallel programming, we propose program transformations and a runtime library that will enable correct execution of data-race-free multi-threaded programs. Our scheme manages coherence at byte granularity rather than conventional page-granularity. We further optimize the performance by introducing the concept of private write notice for each core and combining write notices in our coherence implementation. Experimental results of running multi-threaded signal processing benchmarks on the 8-core non-cache coherent Texas Instruments processor TMS320C6678 demonstrates that our technique achieves 12X performance improvement over naive scheme of disabling caches, and 2X performance improvement over the state-of-art technique.	byte;cache (computing);cache coherence;coherence (physics);direct memory access;parallel computing;program transformation;programmer;race condition;runtime library;signal processing;thread (computing)	Jian Cai;Aviral Shrivastava	2016	2016 29th International Conference on VLSI Design and 2016 15th International Conference on Embedded Systems (VLSID)	10.1109/VLSID.2016.70	bus sniffing;multi-core processor;embedded system;computer architecture;parallel computing;real-time computing;computer science;operating system;programming language;mesi protocol	EDA	-8.510221582326215	50.29390811899657	41349
f3a6d07dabf8513101ec4cee666ce6bf5790a506	unimodularity and the prallelization of loops	parallelizing compiler;systolic array;unimodularity;space time transformation	The parallelization of loops can be made formal by basing it on an algebraic theory of loop transformations. In this theory, the concept of unimodularity arises. We discuss the pros and cons of insisting on unimodularity.		Michael Barnett;Christian Lengauer	1992	Parallel Processing Letters	10.1142/S0129626492000416	parallel computing;systolic array;computer science;theoretical computer science;programming language	HPC	-11.32462203768834	33.47552277985161	41374
46d65b446a03f7872a2509ba787c8ab29f70657e	improving message passing over ethernet with i/oat copy offload in open-mx	libraries;i oat copy offload;generic ethernet stack;linux kernel;open mx;linux kernel message passing generic ethernet stack i oat copy offload open mx;receivers;engines;local community;message passing;driver circuits;linux;message passing linux local area networks;ethernet networks;local area networks;throughput;hardware;hardware ethernet networks driver circuits receivers throughput engines libraries	Open-MX is a new message passing layer implemented on top of the generic Ethernet stack of the Linux kernel. Open-MX works on all Ethernet hardware, but it suffers from expensive memory copy requirements on the receiver side due to the hardwarepsilas inability to deposit messages directly in the target application buffers.	i/o acceleration technology;linux;message passing;requirement	Brice Goglin	2008	2008 IEEE International Conference on Cluster Computing	10.1109/CLUSTR.2008.4663775	embedded system;parallel computing;rdma over converged ethernet;ethernet flow control;computer science;ata over ethernet;jumbo frame;operating system;ethernet global data protocol;network interface controller;ethernet;linux kernel;computer network	Visualization	-11.211032563335397	46.51599359963936	41448
fda87c93b75633caa0f78b6e7f9384e8e775d3f1	triple-h: a hybrid approach to accelerate hdfs on hpc clusters with heterogeneous storage architecture	random access memory;performance evaluation;big data hdfs heterogeneous storage hpc;heterogeneous storage;puma triple h hdfs hpc clusters heterogeneous storage architecture hadoop distributed file system data locality big data applications io bottlenecks trireplicated data blocks high performance computing data placement policies parallel file system fault tolerance sort benchmark lustre cloudburst application sequencecount grep;servers;hpc;engines;big data;fault tolerant systems;fault tolerance;parallel processing big data distributed databases fault tolerant computing;random access memory fault tolerance fault tolerant systems servers performance evaluation engines file systems;file systems;hdfs	HDFS (Hadoop Distributed File System) is the primary storage of Hadoop. Even though data locality offered by HDFS is important for Big Data applications, HDFS suffers from huge I/O bottlenecks due to the tri-replicated data blocks and cannot efficiently utilize the available storage devices in an HPC (High Performance Computing) cluster. Moreover, due to the limitation of local storage space, it is challenging to deploy HDFS in HPC environments. In this paper, we present a hybrid design (Triple-H) that can minimize the I/O bottlenecks in HDFS and ensure efficient utilization of the heterogeneous storage devices (e.g. RAM, SSD, and HDD) available on HPC clusters. We also propose effective data placement policies to speed up Triple-H. Our design integrated with parallel file system (e.g. Lustre) can lead to significant storage space savings and guarantee fault-tolerance. Performance evaluations show that Triple-H can improve the write and read throughputs of HDFS by up to 7x and 2x, respectively. The execution times of data generation benchmarks are reduced by up to 3x. Our design also improves the execution time of the Sort benchmark by up to 40% over default HDFS and 54% over Lustre. The alignment phase of the Cloudburst application is accelerated by 19%. Triple-H also benefits the performance of SequenceCount and Grep in PUMA [15] over both default HDFS and Lustre.	apache hadoop;benchmark (computing);big data;clustered file system;computer cluster;computer data storage;dce distributed file system;disk staging;fault tolerance;hard disk drive;input/output;locality of reference;lustre;non-volatile random-access memory;page cache;random-access memory;run time (program lifecycle phase);solid-state drive;supercomputer;thread-local storage;triangular function	Nusrat S. Islam;Xiaoyi Lu;Md. Wasi-ur-Rahman;Dipti Shankar;Dhabaleswar K. Panda	2015	2015 15th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing	10.1109/CCGrid.2015.161	fault tolerance;parallel computing;real-time computing;big data;computer science;operating system;database;server	HPC	-13.964706517064457	52.68947671362693	41508
5d232f9aeeba1431195e81218c39a35cd46510da	an automata-based monitoring technique for commitment-based multi-agent systems	multi agent system;linear temporal logic;open multi agent systems	In open multi-agent systems (MASs) we cannot assume agents to be developed in a centralized fashion. Recent proposals of commitmentbased communication frameworks aim at increasing such openness. Interaction with agents whose behavior does not follow a universal standard raises the need for some means of protection for each agent. In this work we propose an automata-based monitoring module that continuously supports an agent during its life in a MAS. Such module includes a Word Composer that observes exchanged messages and keeps track of significant past interactions to express an agent’s input in the form of time-stamped words, and a Word Analyzer that processes such words and matches them against some properties expressed in linear temporal logic which are supposed to hold throughout the interactions.	aggregate function;automata theory;automaton;centralized computing;composer;data aggregation;interaction;linear temporal logic;location-based service;microsoft word for mac;model checking;multi-agent system;openness;web service	Paola Spoletini;Mario Verdicchio	2008		10.1007/978-3-642-00443-8_12	real-time computing;simulation;engineering;artificial intelligence	AI	-30.724613393276254	33.6546986556443	41517
210afee18a5c5a5185ab721ce6cf4a60fa5b2a6e	online anomaly detection in case of limited feedback with accurate distribution learning		We propose a high-performance algorithm for se­quential anomaly detection. The proposed algorithm sequentially runs over data streams, accurately estimates the nominal distribu­tion using exponential family and then declares an anomaly when the assigned likelihood of the current observation is less than a threshold. We use the estimated nominal distribution to assign a likelihood to the current observation and employ limited feedback from the end user to adjust the threshold. The high performance of our algorithm is due to accurate estimation of the nominal distribution, where we achieve this by preventing anomalous data to corrupt the update process. Our method is generic in the sense that it can operate successfully over a wide range of data distributions. We demonstrate the performance of our algorithm with respect to the state-of-the-art over time varying distributions.	algorithm;anomaly detection;feedback;level of measurement;nominal type system;time complexity	Iman Marivani;Dariush Kari;Ali Emirhan Kurt;Eren Manis	2017	2017 25th Signal Processing and Communications Applications Conference (SIU)	10.1109/SIU.2017.7960595	anomaly detection;end user;artificial intelligence;pattern recognition;computer science;real-time computing;data stream mining;ac power;exponential family	ML	-22.96046124725525	55.72842391567264	41536
49a52924c2f20ed0e65cbaa8f1ae4e222656858a	a unifying approach to performance analysis in the java environment	virtual machine;data collection;java virtual machine;group communication;data model;complex data;performance analysis	In general, performance analysis tools deal with large volumes of highly complex data of varying types and at varying levels of granularity. The result is that it is common for there to be many different tools and components that implement performance data collection, recording, and reporting in an analysis environment. This variety complicates communication within a group and makes cross-group communication about specific performance findings even more difficult. The analysis of the performance of Java virtual machines and Java applications introduces additional complexity. We describe an approach that unifies the recording and reporting components of performance analysis into a single data model and standard set of reports. We have employed this model with significant success in the analysis of IBM’s Developer Kits for the Java virtual machine.	data model;java virtual machine;profiling (computer programming)	William P. Alexander;Robert F. Berry;Frank E. Levine;Robert J. Urquhart	2000	IBM Systems Journal	10.1147/sj.391.0118	real-time computing;java concurrency;data model;communication in small groups;computer science;virtual machine;operating system;software engineering;strictfp;data mining;database;real time java;programming language;java annotation;complex data type;data collection	HPC	-16.441845608098518	48.97617923779252	41537
b7dd26331783771ad62612728cacab20c3eff2cf	interfacing scmsweb with condor-g – a joint pragma-condor effort	distributed computing grid computing;joint pragma condor effort;electronic mail;sdsc;grid monitoring system;condor g;collaboration;distributed computing;scmsweb condor interface development;thaigrid;intelligent grid level scheduling services;probes;university of wisconsin;processor scheduling grid computing international collaboration supercomputers monitoring job shop scheduling middleware collaborative work computer industry usa councils;intelligent grid level scheduling services scmsweb condor g joint pragma condor effort scmsweb condor interface development thaigrid kisti sdsc grid monitoring system;monitoring system;monitoring;user interfaces grid computing middleware;kisti;scmsweb;middleware;organizations;grid computing;user interfaces;throughput	SCMSWeb-Condor interface development is an international collaborative effort among some PRAGMA member institutions (ThaiGrid, Thailand; KISTI, Korea; SDSC, USA) and Condor team at University of Wisconsin. It aims at utilizing the rich information collected by the grid monitoring system - SCMSWeb, to enable Condor-G to provide more intelligent grid-level scheduling services. This paper addresses the motivations, practices, benefits and issues of this collaboration; illustrates the design, development and implementation of the SCMSWeb-Condor interface; describes the experiences, test results and discussions driven by running applications thru the SCMSWeb-Condor interface.	directive (programming);san diego supercomputer center;scheduling (computing)	Somsak Sriprayoonsakul;Putchong Uthayopas;Jysoo Lee;Cindy Zheng;Miron Livny;Jaime Frey	2008	2008 IEEE Fourth International Conference on eScience	10.1109/eScience.2008.32	real-time computing;computer science;operating system;database	Robotics	-31.400307722863992	48.55377813484111	41569
81acbc64ea0a5608459978fb8f706cd2d02c79ab	a scalable and reconfigurable shared-memory graphics architecture	shared memory;terrain rendering;virtual environments;conference paper;computer science;collaborative environments	Current scalable high-performance graphics systems are either constructed using special purpose graphics acceleration hardware or built as a cluster of commodity components with a software infrastructure that exploits multiple graphics cards [Humphreys et al. 2002]. Both these solutions are used in application domains where computational demand cannot be met by a single commodity graphics card e.g., large-scale scientific visualisation. The former approach tends to provide the highest performance but is expensive because it requires frequent redesign of the special purpose graphics acceleration hardware in order to maintain a performance advantage over the commodity graphics hardware used in the cluster approach. The latter approach, while more affordable and scalable, has intrinsic performance drawbacks due to computationally expensive communication between the individual graphics pipelines.	analysis of algorithms;application domain;blitter;computation;graphics hardware;graphics processing unit;hardware acceleration;pipeline (computing);reconfigurable computing;scalability;scientific visualization;shared memory;video card	Michael Manzke;Ross Brennan;Keith O'Conor;John Dingliana;Carol O'Sullivan	2006		10.1145/1179849.1180077	shared memory;terrain rendering;human–computer interaction;computer science;operating system;multimedia;software rendering;computer graphics (images)	HPC	-29.839892040640862	40.08597792393977	41584
1315ea1bf8f92bc1773556f727af0f85605cb677	exploring datavortex systems for irregular applications		Emerging applications for data analytics and knowledge discovery typically have irregular or unpredictable communication patterns that do not scale well on parallel systems designed for traditional bulk-synchronous HPC applications. New network architectures that focus on minimizing (short) message latencies, rather than maximizing (large) transfer bandwidths, are emerging as possible alternatives to better support those applications with irregular communication patterns. We explore a system based upon one such novel network architecture, the Data Vortex interconnection network, and examine how this system performs by running benchmark code written for the Data Vortex network, as well as a reference MPI-over- Infiniband implementation, on the same cluster. Simple communication primitives (ping-pong and barrier synchronization), a few common communication kernels (distributed 1D Fast Fourier Transform, breadth-first search, Giga-Updates Per Second) and three prototype applications (a proxy application for simulating neutron transport-”SNAP”, a finite difference simulation for computing incompressible fluid flow, and an implementation of the heat equation) were all implemented for both network models. The results were compared and analyzed to determine what characteristics make an application a good candidate for porting to a Data Vortex system, and to what extent applications could potentially benefit from this new architecture.	aggregate data;barrier (computer science);benchmark (computing);breadth-first search;data buffer;fast fourier transform;finite difference;giga-updates per second;graph500;infiniband;interconnection;network architecture;prototype;simulation;supercomputer;vortex	Roberto Gioiosa;Antonino Tumeo;Jian Yin;Thomas Warfel;David J. Haglin;Santiago Betelú	2017	2017 IEEE International Parallel and Distributed Processing Symposium (IPDPS)	10.1109/IPDPS.2017.121	distributed computing;computer science;porting;knowledge extraction;network model;parallel computing;network architecture;architecture;synchronization;infiniband;data analysis	HPC	-6.860300231820384	40.44666108654178	41599
055e3b351099e180aa0e5e6c3336157de6e36069	on multisystem coupling through function request shipping	data sharing;mirrors;multiprocessor;multiprocessor systems;routing;database management systems;estudio comparativo;simulation;locking;partitioning;telecommunication network;simulacion;approximate analysis multisystem coupling function request shipping database system data sharing remote function calls mirror transaction setups multisystem two phase commits simulation;partage ressource;etude comparative;particion;data base management system;red telecomunicacion;database systems;analyse performance;resource sharing;comparative study;performance analysis;particion recursos;reseau telecommunication;partition;linear programming;mirrors couplings database systems routing linear programming load modeling;systeme gestion base donnee;couplings;multiprocesador;load modeling;sistema gestion base datos;performance analysis database systems data sharing locking multiprocessor systems partitioning;analisis eficacia;multiprocesseur	In a multisystem database system with a function request shipping approach, the databases are partitioned among the multiple systems and a facility is provided to support the shipping of database requests among the systems. This is in contrast to a data sharing multisystem approach in which all systems have direct access to the shared database. The performance of the two approaches is compared, emphasizing generic issues that affect the function shipping approach. A methodology is presented for partitioning the databases and routing transactions among the systems so as to minimize the fraction of remote function calls, while balancing the load among systems. Estimates of the resulting remote function calls, mirror transaction setups, and multisystem two-phase commits are obtained. Results of simulation and approximate analysis are presented.	approximation algorithm;central processing unit;computer performance;database;digital footprint;emoticon;flat file database;information management system (ims);input/output;line level;load balancing (computing);lock (computer science);overhead (computing);random access;response time (technology);resultant;routing;simulation;tracing (software);two-phase commit protocol;xfig	Douglas W. Cornell;Daniel M. Dias;Philip S. Yu	1986	IEEE Transactions on Software Engineering	10.1109/TSE.1986.6313017	partition;shared resource;routing;real-time computing;multiprocessing;computer science;linear programming;operating system;comparative research;database;distributed computing;coupling;telecommunications network	DB	-19.64284105172381	46.37945819069529	41650
48bd463455f059cedde18a787460ae609fc97a61	auto-tuning methodology to represent landform attributes on multicore and multi-gpu systems	parallel computing;auto tuning;landform representation;performance estimation;multi gpu;multicore	Auto-Tuning techniques have been used in the design of routines in recent years. The goal is to develop routines which automatically adapt to the conditions of the computational system, in such a way that efficient executions are obtained independently of the end-user experience. This paper aims to explore programming routines that can be automatically adapted to the computational system conditions, making possible to use Auto-Tuning methodology to represent landform attributes on multicores and multi-GPU systems.	auto-tune;graphics processing unit;multi-core processor;user experience	Murilo Boratto;Pedro Alonso;Domingo Giménez;Marcos Barreto;Karolyne Oliveira	2012	2012 13th Symposium on Computer Systems	10.1145/2442992.2443006	real-time computing;simulation;computer science;theoretical computer science	Arch	-5.799011812008751	45.08066792175861	41697
06f6b0e95e23e5ce54ee6ef14b5f3389eb5b22ee	a fault-tolerant protocol for generating sequence numbers for total ordering group communication in distributed systems	quorum;total order;fault-tolerance;sequence number;coterie;mutual exclusion;group communication;fault tolerant;distributed system	In this paper, we propose a fault-tolerant scheme for generating global sequence numbers for total ordering in group communication. Our method is based on the notion of quorums, which have been used mostly to solve the mutual exclusion problem. In our scheme, each process in the group may initiate the generation of sequence numbers independently for messages emitted by itself. For the sake of enhancing fault tolerance, the information about the sequence numbers is maintained by all the members of a quorum at all times. We show that the sequence numbers generated by our scheme are unique, consecutive natural numbers. Our mechanism only incurs a moderate amount of communication traffic. The message complexity is on the order of the size of a quorum. Failure handling and crash recovery are also addressed in the paper.	distributed computing;fault tolerance;microsequencer;multicast;mutual exclusion	Chih-Ming Hsiao;Ge-Ming Chiu	2006	J. Inf. Sci. Eng.			DB	-22.450223319647968	45.5135985845982	41702
28d3bc0f74e1cc825bfbc076a16a061d9bf99a77	scalability and performance of computational structures for real-time order promising	real time;index structure;large scale simulation;tree structure	This paper analyzes the scalability and performance of computational structures used in an order promising method designed for discrete build-to-order environments facing dynamic order arrivals. Main-memory database technology and supporting index structures are exploited to improve scalability of this data-intensive procedure so that orders can be promised in real time for industrial-sized systems. Two index structures, a linear structure and a tree structure, are compared. The tree structure improves response times and also has higher scalability at the expense of larger memory requirements compared to the linear structure. Performance of the method is evaluated under two manufacturing scenarios: a tandem line and an assembly shop. Computational results obtained from large-scale simulation studies of realistic systems with 60 resources show the method to be robust. Accuracy of the method in terms of median absolute lateness surpasses that of due date assignment methods previously examined in the literature.	benchmark (computing);clock rate;computation;data-intensive computing;in-memory database;load profile;real-time clock;requirement;response time (technology);robustness (computer science);scalability;simulation;time complexity;tree structure	Andres J. Lucas;Scott A. Moses	2005	J. Intelligent Manufacturing	10.1007/s10845-005-4821-9	mathematical optimization;real-time computing;simulation;computer science;tree structure	Robotics	-16.48880335925336	58.23851804517853	41735
182cd5dcdb7940fbe12abb6fee9168eb541cb010	a comparison of three commodity-level parallel architectures: multi-core cpu, cell be and gpu	heat equation;graphic processing unit;mandelbrot set;parallel architecture	We explore three commodity parallel architectures: multi-core CPUs, the Cell BE processor, and graphics processing units. We have implemented four algorithms on these three architectures: solving the heat equation, inpainting using the heat equation, computing the Mandelbrot set, and MJPEG movie compression. We use these four algorithms to exemplify the benefits and drawbacks of each parallel architecture.		André Rigland Brodtkorb;Trond Runar Hagen	2008		10.1007/978-3-642-11620-9_6	computer architecture;parallel computing;computer science;theoretical computer science	HPC	-6.519589739275762	42.33377186764118	41754
780f4c9298df43b47dbb30dbd0a95b4616815d92	comparison and evaluation of design choices for implementing the virtual interface architecture (via)	eficacia sistema;distributed memory systems;architecture systeme;sistema informatico;performance systeme;computer system;system performance;interface ordinateur;computer network;interfaces computer;systeme memoire repartie;low latency;parallel architectures;architecture parallele;reseau informatique;arquitectura sistema;systeme informatique;system architecture;network interface;software implementation;virtual interface architecture	The Virtual Interface Architecture (VIA) specication has been developed to standardize user-level network interfaces that provide low latency, high bandwidth communications. Few hardware and soft- ware implementations of VIA exist. Since the VIA specication is flexi- ble, dierent choices exist for implementing various components of VIA such as doorbells, address translation methods, and completion queues. Although previous studies have evaluated the overall performance of dif- ferent VIA implementations, there has not been a comparative study on the performance of VIA components. In this paper, we evaluate and compare the performance of dierent implementations of essential VIA components. We discuss the pros and cons of each design approach and describe the required support for implementing each of them. As a user application, we use the NAS Parallel Benchmarks to study the eect of caching the address translation tables on the NIC and to study de- sign issues involved in implementing completion queues. As a hardware platform we use the IBM Netnity SP cluster running the NT 4.0 oper- ating system and a Myrinet connected cluster of PCs running the Linux operating system.		Mohammad Banikazemi;Bülent Abali;Dhabaleswar K. Panda	2000		10.1007/10720115_11	embedded system;real-time computing;computer science;network interface;operating system;computer performance;systems architecture;low latency	Arch	-12.060730582942819	45.71003692269883	41788
26cbb5feff89cad57281b2749d1cffff6bef886f	supervising agent team in an agent-based grid resource brokering system -- initial solution	protocols;mirrors;monitoring computer crashes graphical user interfaces time factors mirrors testing lead;computer crashes;supervising agent team agent team based infrastructure resource brokering grid system;agent based;software agent;resource management;software systems;agent teams grid software agents agent systems grid middleware resource brokering;contracts;grid middleware;testing;software agents;grid;multi agent systems;time factors;graphical user interfaces;supervising agent team;monitoring;agent teams;lead;agent team based infrastructure;intelligent agent;resource broker;agent systems;competitive intelligence;grid computing;programming;resource brokering;parallel processing;software development management;grid system;software agents grid computing multi agent systems	Currently, we are developing an agent-team based infrastructure for resource brokering and management in Grids. In this note we consider how team is supervised and how mirroring can be applied to improve chances of its long-term persistence.	agent-based model;disk mirroring;persistence (computer science);supervised learning	Wojciech Kuranowski;Maria Ganzha;Marcin Paprzycki;Ivan Lirkov	2008	2008 International Conference on Complex, Intelligent and Software Intensive Systems	10.1109/CISIS.2008.113	simulation;knowledge management;distributed computing;business	Robotics	-31.663119855376785	48.119612203542694	41821
1e71d4031932bb0dd9cee77afe85a6a5a8fad93a	toward supporting data parallel programming on clusters of symmetric multiprocessors	data parallel;multi threading;shared memory;collective communication;multi threading multiprocessing systems message passing shared memory systems;sun ultrasparc ii workstations data parallel programming symmetric multiprocessor clusters runtime library smp clusters design algorithms hybrid methodology hierarchical memory system programming methodologies shared memory programming smp node message passing hybrid approach collective communication prototype library standard interfaces pthread mpi;hybrid approach;shared memory systems;parallel programming workstations concurrent computing clustering algorithms computer science message passing sun high performance computing application software hardware;message passing;memory systems;multiprocessing systems;smp cluster	This paper reports the design of a runtime library for data-parallel programming on clusters of symmetric multiprocessors (SMP clusters). Our design algorithms exploit a hybrid methodology which maps directly to the underlying hierarical memory system in SMP clusters, by combining two styles of programming methodologies – threads (shared memory programming) within a SMP node and message passing between SMP nodes. This hybrid approach has been used in the implementation of a library for collective communications. The prototype library is implemented based on standard interfaces for threads (pthread) and message passing (MPI). Experimental results on a cluster of Sun UltraSparc-II workstations are reported.	algorithm;data parallelism;inter-process communication;mathematical optimization;message passing;posix threads;parallel computing;prototype;runtime library;shared memory;symmetric multiprocessing;tiling window manager;ultrasparc t1;workstation	C.-L. Chiang;J.-J. Wu;N.-W. Lin	1998		10.1109/ICPADS.1998.741143	distributed shared memory;shared memory;computer architecture;parallel computing;message passing;multithreading;computer science;operating system;distributed computing	HPC	-11.137554158568982	44.89804695577313	41868
05fb2dc509099b3c45c2df3d8b5d0f75a0c66976	a local parallel communication algorithm for polydisperse rigid body dynamics		The simulation of large ensembles of particles is usually parallelized by partitioning the domain spatially and using message passing to communicate between the processes handling neighboring subdomains. The particles are represented as individual geometric objects and are assigned to the subdomains. Handling collisions and migrating particles between subdomains, as required for proper parallel execution, requires a complex communication protocol. Typically, the parallelization is restricted to handling only particles that are smaller than a subdomain. In many applications, however, particle sizes may vary drastically with some of them being larger than a subdomain. In this article we propose a new communication and synchronization algorithm that can handle the parallelization without size restrictions on the particles. Despite the additional complexity and extended functionality, the new algorithm introduces only minimal overhead. We demonstrate the scalability of the previous and the new communication algorithms up to almost two million parallel processes and for handling ten billion (1010) geometrically resolved particles on a state-of-theart petascale supercomputer. Different scenarios are presented to analyze the performance of the new algorithm and to demonstrate its capability to simulate polydisperse scenarios, where large individual particles can extend across several subdomains. ∗Corresponding author Email address: sebastian.eibl@fau.de (Sebastian Eibl) Preprint submitted to Parallel Computing August 3, 2018 ar X iv :1 80 2. 02 76 5v 2 [ cs .D C ] 2 A ug 2 01 8		Sebastian Eibl;Ulrich Rüde	2018	Parallel Computing	10.1016/j.parco.2018.10.002	parallel computing;message passing;communications protocol;petascale computing;scalability;computer science;synchronization;particle;algorithm;parallel communication;supercomputer	HPC	-5.673309982698758	41.17639762297555	41887
174782755d995d94467fe28ed7b2f96c90c2a5d0	specification of performance problems in mpi programs with asl	working group;performance evaluation;bottlenecks performance problems mpi programs asl performance critical applications performance property specification language mpi applications performance analysis;specification languages performance evaluation;specification languages;performance analysis programming profession data analysis specification languages object oriented modeling software performance computer science application software automatic control process control;performance analysis;property specification language;object model	Performance analysis is an important step in tuning performance critical applications. It is a cyclic process of measuring and analyzing performance data which is driven by the programmers hypotheses on potential performance problems. Currently this process is controlled manually by the programmer. The implicit knowledge applied in this cyclic process must be formalized in order to be reused in the automation of performance analysis tools. This article describes the performance property specification language ASL developed in the APART Esprit IV working group. ASL allows the specification of performance data via an object model and of performance properties via a specially designed notation. Performance bottlenecks can then be identified based on the specification since bottlenecks are viewed as performance properties with a huge negative impact. We present the ASL language in the context of MPI applications.		Thomas Fahringer;Michael Gerndt;Graham D. Riley;Jesper Larsson Träff	2000		10.1109/ICPP.2000.876072	parallel computing;real-time computing;working group;object model;specification language;computer science;operating system;programming language;language of temporal ordering specification	HPC	-32.08964156303363	32.75680136349062	41893
c8b4adfac3b2ebf5bb601dd722f6714b026f1f33	session guarantees to achieve pram consistency of replicated shared objects	distributed system;systeme reparti;data centric;centre donnee;centrado dato;consistency model;sistema repartido;contexto;contexte;modele donnee;context;data models	In this paper we discuss relationships between client-centric consistency models (known as session guarantees), and data-centric consistency models. Appropriate models are formally defined in the context of replicated shared objects using a consistent notation. We prove that PRAM consistency model may be achieved as a proper combination of different session guarantees.	pram consistency	Jerzy Brzezinski;Cezary Sobaniec;Dariusz Wawrzyniak	2003		10.1007/978-3-540-24669-5_1	data modeling;real-time computing;database-centric architecture;computer science;consistency model;operating system;database;distributed computing	PL	-25.078868263213625	41.90762297318734	41963
276dc2c8d2d7ea52e59f82533dbc08b3afe06fad	system managed storage perspectives	system management		hierarchical storage management	Thomas J. Meehan	1989	CMG Transactions			DB	-19.561377737904614	51.7165286834271	41964
ab9909e037eed282407404c986d57fc08e807ba0	an image processing-based test bench for performance evaluation in hybrid clouds	image processing;software performance evaluation;data processing;test bench;hybrid clouds;computational modeling;statistical analysis;monitoring;distributed image processing hybrid clouds test bench;statistics image processing based test bench performance evaluation hybrid clouds public clouds community clouds private clouds cloud bursting deployment models cpu intensive scientific data processing;communities;statistical analysis benchmark testing cloud computing image processing software performance evaluation;algorithm design and analysis;cloud computing image processing data processing computational modeling algorithm design and analysis monitoring communities;benchmark testing;distributed image processing;cloud computing	"""Hybrid clouds are combinations of private, community and/or public clouds, and allow the creation of """"cloud bursting"""" deployment models, in which part of the data processing is done in a private cloud and resources from public clouds are used when needed. This model is particularly interesting for CPU-intensive scientific data processing. In order to help determine in which conditions part of the whole of a large data processing task must be sent to a public or private cloud, dynamic benchmarks are required. In this paper we propose an image processing-based test bench that monitors the performance of the clouds resources to gather useful statistics and to determine which resource should be used for a specific task, in order to reduce costs and running time."""	benchmark (computing);central processing unit;cloud computing;hybrid drive;image processing;performance evaluation;software deployment;test bench;time complexity	Rafael D. C. Santos;Bernady O. Apduhan	2013	2013 13th International Conference on Computational Science and Its Applications	10.1109/ICCSA.2013.54	algorithm design;benchmark;simulation;data processing;cloud computing;image processing;computer science;data science;theoretical computer science;operating system;computational model	HPC	-18.50045491246323	58.76348338059485	41999
efb8a9cc40b90360b5677d4c61bc24bcb4023d70	valid application of evt in timing analysis by randomising execution time measurements		Intrinsic timing uncertainties present in modern hardware platforms have motivated the use of Extreme Value Theory (EVT) to timing analysis, however, the timing behaviour of a task may not entirely fulfil the necessary assumptions. To deal with this difficulty, randomisation at the hardware level has been proposed as a means of facilitating the use of statistical timing analysis. However, it has been shown that hardware randomisation does not solve all the analysis problems and importantly some projects may not wish to change the hardware that is used to support timing analysis. This paper presents an innovative approach, which does not require hardware randomisation or any special system feature, named Indirect Estimation in Statistical Time Analysis (IESTA). The main difference is that randomised hardware is performed before software instructions actually executes and is applied to parameters (e.g. cache state) only indirectly linked to timing. In contrast, IESTA adds its randomisation directly to the timing measures without affecting the way the software is executed. The IESTA approach is evaluated by experiments on two real case studies for which execution time measurements are taken from an embedded platform and from a Rolls-Royce Full Authority Digital Engine Controller.	embedded system;experiment;extreme value theory;fadec;fallout;run time (program lifecycle phase);static timing analysis;winston w. royce	George Lima;Iain Bate	2017	2017 IEEE Real-Time and Embedded Technology and Applications Symposium (RTAS)	10.1109/RTAS.2017.17	extreme value theory;real-time computing;cache;control theory;software;computer science;static timing analysis	Embedded	-23.791938181436446	37.172837551198704	42008
668d06eb4b48c53cc73253002daf83dd34fd0408	introduction of virtualization technology to multi-process model checking	technology utilization;channels data transmission;virtual memory systems;software engineering;computer networks;mathematical models;java programming language;architecture computers;operating systems computers	Model checkers find failures in software by exploring every possible execution schedule. Java PathFinder (JPF), a Java model checker, has been extended recently to cover networked applications by caching data transferred in a communication channel. A target process is executed by JPF, whereas its peer process runs on a regular virtual machine outside. However, non-deterministic target programs may produce different output data in each schedule, causing the cache to restart the peer process to handle the different set of data. Virtualization tools could help us restore previous states of peers, eliminating peer restart. This paper proposes the application of virtualization technology to networked model checking, concentrating on JPF.	channel (communications);java pathfinder;model checking;virtual machine;x86 virtualization	Watcharin Leungwattanakit;Cyrille Artho;Masami Hagiya;Yoshinori Tanabe;Mitsuharu Yamamoto	2009			computer architecture;computing;virtualization;computer science;virtual machine;theoretical computer science;software engineering;mathematical model;real time java;programming language;computer engineering	SE	-24.930525535484147	39.226623013154224	42064
0f2d2efa260377dd8b8a171fa83e2c9938324bca	design and optimization of a big data computing framework based on cpu/gpu cluster	graphics processing units optimization programming java kernel computer architecture data processing;kernel;data processing;computer architecture;graphics processing units;optimization;programming;java	Big data processing is receiving significant amount of interest as an important technology to reveal the information behind the data, such as trends, characteristics, etc. MapReduce is one of the most popular distributed parallel data processing framework. However, some high-end applications, especially some scientific analyses have both data-intensive and computation intensive features. Therefore, we have designed and implemented a high performance big data process framework called Lit, which leverages the power of Hadoop and GPUs. In this paper, we presented the basic design and architecture of Lit. More importantly, we spent a lot of effort on optimizing the communications between CPU and GPU. Lit integrated GPU with Hadoop to improve the computational power of each node in the cluster. To simplify the parallel programming, Lit provided an annotation based approach to automatically generate CUDA codes from Hadoop codes. Lit hid the complexity of programming on CPU/GPU cluster by providing extended compiler and optimizer. To utilize the simplified programming, scalability and fault tolerance benefits of Hadoop and combine them with the high performance computation power of GPU, Lit extended the Hadoop by applying a GPUClassloader to detect the GPU, generate and compile CUDA codes, and invoke the shared library. For all CPU-GPU co-processing systems, the communication with the GPU is the well-known performance bottleneck. We introduced data flow optimization approach to reduce unnecessary memory copies. Our experimental results show that Lit can achieve an average speedup of 1× to 3× on three typical applications over Hadoop, and the data flow optimization approach for the Lit can achieve about 16% performance gain.	algorithm;apache hadoop;big data;cuda;central processing unit;code;computation;data-intensive computing;dataflow;directive (programming);fault tolerance;gpu cluster;graphics processing unit;instruction scheduling;java compiler;library (computing);mapreduce;mathematical optimization;overhead (computing);parallel computing;program optimization;programmer;requirement;scalability;scheduling (computing);speedup;time complexity;whole earth 'lectronic link	Yanlong Zhai;Ying Guo;Qiurui Chen;Kai Yang;Emmanuel Mbarushimana	2013	2013 IEEE 10th International Conference on High Performance Computing and Communications & 2013 IEEE International Conference on Embedded and Ubiquitous Computing	10.1109/HPCC.and.EUC.2013.147	programming;computer architecture;parallel computing;kernel;data processing;computer science;operating system;distributed computing;programming language;java	HPC	-5.72927343286661	43.961680493483634	42081
72a14aec23269f129e8369eb6277fd99c364ec5b	algorithm 561: fortran implementation of heap programs for efficient table maintenance [z]	fortran	"""In many computat ional problems one has a collection of entit ies whose t ime history is being studied. T h e calculation proceeds by creating, destroying, and generally processing these entities, hencefor th called nodes. Often the node to be processed is tha t one which is """"most impor tan t"""" in some problem-dependent sense. Examples of such calculations occur in particle following for accelerator problems and adaptive quadrature , to name bu t two [3, 4, 6]. In such problems the t ime spent maintaining the nodes is significant, and it is impor tan t to implement this efficiently. An organization of nodes based on """"most impor tan t in, first out"""" (i.e., where every deletion removes the most impor tan t node) is called a priori ty queue [5]. T h e computer implementa t ion of such queues can vary considerably. An unordered table of nodes is the simplest a r rangement bu t requires an expensive search for the most impor tan t node. Maintaining an ordered table allows easy access to the most impor tan t node, but then insertions become slow. A """"heap"""" [1] is a data s t ructure tha t implements a priori ty queue in an efficient way, being equally fast for bo th insertions and deletions. Here we present a suite of For t ran programs of l ibrary quali ty for heaps. These programs are of modes t length and can easily be included in o ther packages. Similar programs were used in [6] but they were not found to be general enough for l ibrary use. In this paper we do not describe any of the detailed propert ies of heaps since these have been well documented [1, 7]. Ra the r we give only enough information about t hem so tha t the use of the programs can be quickly understood. Th e last section contains two simple examples."""	accessibility;adaptive quadrature;algorithm;call of duty: black ops;entity;fortran;http 404;heap (data structure);os-tan;ordered pair;transaction authentication number	David K. Kahaner	1980	ACM Trans. Math. Softw.	10.1145/355900.355918	computer architecture;parallel computing;mathematics;programming language	Theory	-10.639881154913297	34.9617701549031	42090
773be05845717aa0f96d642b9d632bff65647b70	supporting distributed collaborative work with multi-versioning	groupware;multi version;real time;distributed processing;distributed collaborative work multiversion approach synchronous groupware system asynchronous groupware system real time group editor;multiversion approach;distributed collaborative work;synchronous groupware system;asynchronous groupware system;distributed collaboration;configuration management;groupware multi version coordination;text editing;coordination;real time group editor;collaborative work distributed computing australia collaborative software ip networks humans delay effects internet database systems collaboration;text editing configuration management distributed processing groupware	The multi-version approach is useful in both synchronous and asynchronous groupware systems. This paper discusses the implementation of a real-time group editor that embodies our approaches and algorithms based on multi-versioning, which can preserve individual users' concurrent conflicting intentions in a consistent way. To highlight the distinct contributions of our work, we also present a detailed description of some novel features of the system	algorithm;asynchronous circuit;collaborative software;correctness (computer science);experiment;prototype;real-time transcription;systems architecture;usability	Mehmet A. Orgun;Liyin Xue;Zhangang Han	2006	2006 10th International Conference on Computer Supported Cooperative Work in Design	10.1109/CSCWD.2006.253140	human–computer interaction;computer science;database;distributed computing;configuration management;management;world wide web	Robotics	-25.668683339682506	47.441281072563925	42159
a5ebabc524360c2ecc1460c6878b9aea68e78252	clam: a framework for audio and music application development	application development;development framework;software libraries;audio processing algorithm repository;abstract model;music application development;platform;data type;multimedia systems;software libraries c language multimedia systems;audio processing;c language;rapid prototyping;media processing;application software music graphical user interfaces java software tools web pages middleware software systems software libraries xml;process development;audio application development;audio processing development framework platform;abstract model audio application development music application development c library for audio and music development framework audio processing algorithm repository;c library for audio and music development framework;open source	The CLAM (C++ Library for Audio and Music) development framework offers a complete R&D platform for the audio and music domain. Winner of the 2006 ACM Open Source Multimedia Software Competition, CLAM originated in an effort to organize a repository of audio-processing algorithms. Today it includes an abstract model for audio systems, a repository of processing algorithms and data types, and several tools and stand-alone applications. Developers can exploit all these features to build cross-platform applications or rapid prototypes for testing signal- and media-processing algorithms and systems	algorithm;c++;open-source software	Xavier Amatriain	2007	IEEE Software	10.1109/MS.2007.8	process development execution system;data type;audio signal processing;computer science;multimedia;programming language;platform;rapid application development;world wide web	SE	-33.64742373898103	41.95693004195932	42161
184d8b53487c0d4ff2d144df605eb4995efc38d0	scalability terminology: farms, clones, partitions, packs, racs and raps	cluster computing	3 Why and how to Scale ? § why u Server systems must be able to start small • Small-size company (garage-scale) v.s. international company (kingdom-scale) u System should be able to grow as demand grows e.g. • eCommerce made system growth more rapid & dynamic • ASP also need dynamic growth § how u Scale up expanding a system by incrementally adding more devices to an existing node – CPUs, discs, NICS, etc. • inherently limited u Scale Out – expanding the system by adding more nodes – convenient (computing capacity can be purchased incrementally), no theoretical scalability limit	central processing unit;e-commerce;ibm pc compatible;scalability	Bill Devlin;Jim Gray;Bill Laing;George Spix	1999	CoRR		simulation;computer cluster;computer science;engineering;operating system;database	Arch	-27.80696116491912	54.10965160100147	42166
92fd6bf920ac934218253085be239ce77b4aa3c4	fast and precise symbolic analysis of concurrency bugs in device drivers (t)	kernel;concurrent computing programming linux computer bugs kernel instruction sets context;concurrent computing;concurrency bugs data races device drivers whoop automated approach symbolic pairwise lockset analysis statical analysis data races all thread interleavings race freedom guarantees partial order reduction corral industrial strength bug finder concurrent programs concurrent errors debugging linux 4 0 kernel;linux;computer bugs;programming;symbol manipulation concurrency computers device drivers linux program debugging;context;instruction sets	Concurrency errors, such as data races, make device drivers notoriously hard to develop and debug without automated tool support. We present Whoop, a new automated approach that statically analyzes drivers for data races. Whoop is empowered by symbolic pairwise lockset analysis, a novel analysis that can soundly detect all potential races in a driver. Our analysis avoids reasoning about thread interleavings and thus scales well. Exploiting the race-freedom guarantees provided by Whoop, we achieve a sound partial-order reduction that significantly accelerates Corral, an industrial-strength bug-finder for concurrent programs. Using the combination of Whoop and Corral, we analyzed 16 drivers from the Linux 4.0 kernel, achieving 1.5 -- 20× speedups over standalone Corral.	approximation;code coverage;concurrency (computer science);device driver;linux;partial order reduction;race condition;scalability;sensor;software bug	Pantazis Deligiannis;Alastair F. Donaldson;Zvonimir Rakamaric	2015	2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)	10.1109/ASE.2015.30	programming;parallel computing;kernel;real-time computing;software bug;concurrent computing;computer science;operating system;instruction set;programming language;linux kernel	SE	-21.28563438463133	38.39212388091968	42170
12dd6aa9ea1a3d8b07bbcc2a7ce51d1c6a269ba8	programming with intervals	data races;control flow;parallel programs	Intervals are a new, higher-level primitive for parallel programming with which programmers directly construct the program schedule. Programs using intervals can be statically analyzed to ensure that they do not deadlock or contain data races. In this paper, we demonstrate the flexibility of intervals by showing how to use them to emulate common parallel control-flow constructs like barriers and signals, as well as higher-level patterns such as bounded-buffer producer-consumer. We have implemented intervals as a publicly available library for Java and Scala.	barrier (computer science);compiler;concurrent computing;control flow;deadlock;declarative programming;java;parallel computing;producer–consumer problem;programmer;scala;structured programming	Nicholas D. Matsakis;Thomas R. Gross	2009		10.1007/978-3-642-13374-9_14	parallel computing;real-time computing;computer science;programming language;control flow	PL	-21.60792537842457	34.09940690589652	42189
