id	title	keywords	abstract	entities	authors	year	journal	doi	fos	area	x	y	ix
d57ef7586cce1df6c7084cf02e4d751cb3ef5cb2	cloud gaming onward: research opportunities and outlook	quality of experience cloud computing computer games;dynamic adaptation startup companies public cloud gaming services cloud gaming research wide spectrum distributed systems video codecs virtualization human computer interaction quality of experience resource allocation;servers;networked systems computer games cloud computing interactive applications performance optimization;games servers graphics processing units cloud computing rendering computer graphics mobile communication delays;graphics processing units;games;mobile communication;computer games;networked systems;rendering computer graphics;performance optimization;interactive applications;delays;cloud computing	Cloud gaming has become increasingly more popular in the academia and the industry, evident by the large numbers of related research papers and startup companies. Some public cloud gaming services have attracted hundreds of thousands subscribers, demonstrating the initial success of cloud gaming services. Pushing the cloud gaming services forward, however, faces various challenges, which open up many research opportunities. In this paper, we share our views on the future cloud gaming research, and point out several research problems spanning over a wide spectrum of different directions: including distributed systems, video codecs, virtualization, human-computer interaction, quality of experience, resource allocation, and dynamic adaptation. Solving these research problems will allow service providers to offer high-quality cloud gaming services yet remain profitable, which in turn results in even more successful cloud gaming eco-environment. In addition, we believe there will be many more novel ideas to capitalize the abundant and elastic cloud resources for better gaming experience, and we will see these ideas and associated challenges in the years to come.	algorithm;cloud computing;cloud gaming;codec;distributed computing;file spanning;graphics processing unit;human–computer interaction;microsoft outlook for mac;mobile device;server (computing);user experience;x86 virtualization	Kuan-Ta Chen;Chun-Ying Huang;Cheng-Hsin Hsu	2014	2014 IEEE International Conference on Multimedia and Expo Workshops (ICMEW)	10.1109/ICMEW.2014.6890683	cloud computing security;games;simulation;mobile telephony;single-chip cloud computer;cloud computing;computer science;operating system;cloud testing;distributed computing;multimedia;server	HPC	-19.620356375439805	74.34860365512667	23293
424567b2a7263f2d3a00290dae9e082867a0e0b0	ros and buzz: consensus-based behaviors for heterogeneous teams		This paper address the challenges encountered by developers when deploying a distributed decision-making behavior on heterogeneous robotic systems. Many applications benefit from the use of multiple robots, but their scalability and applicability are fundamentally limited if relying on a central control station. Getting beyond the centralized approach can increase the complexity of the embedded intelligence, the sensitivity to the network topology, and render the deployment on physical robots tedious and error-prone. By integrating the swarm-oriented programming language Buzz with the standard environment of ROS, this work demonstrates that behaviors requiring distributed consensus can be successfully deployed in practice. From simulation to the field, the behavioral script stays untouched and applicable to heterogeneous robot teams. We present the software structure of our solution as well as the swarm-oriented paradigms required from Buzz to implement a robust generic consensus strategy. We show the applicability of our solution with simulations and experiments with heterogeneous ground-and-air robotic teams.	basic programming;centralized computing;cognitive dimensions of notations;computer simulation;consensus (computer science);directed acyclic graph;embedded system;experiment;network packet;network topology;programming language;robot;robot operating system;scalability;simulation;software deployment;swarm;swarm intelligence;virtual machine	David St-Onge;Vivek Shankar Varadharajan;Guannan Li;Ivan Svogor;Giovanni Beltrame	2017	CoRR		robot;engineering;software deployment;software;scalability;embedded intelligence;network topology;marketing buzz;distributed computing;consensus	Robotics	-16.931568621992078	78.89293556278467	23313
14d929b4068919afbba5c4333d1c7904c9d19ca2	from nonpreemptive to preemptive scheduling: from single-processor to multi-processor?	preemptive scheduling;task model;schedulability analysis;timed automata;multi processor;rate monotonic;decidability	The use of automata for specifying patterns of task generation has broaden the perspective of schedulability analysis; scheduling has moved from periodic or rate-monotonic to aperiodic and non-uniform tasks. The question of schedulability in this setting, however, is not always decidable; with a preemptive scheduler, it is shown to be decidable for very restricted task models, e.g., when a task is modeled merely as a fixed computation time. In this paper, we consider the possibility of specifying tasks using timed automata. We show that, in this more complex setting, decidability holds not only for non-preemptive schedulers but also for preemptive schedulers if a minimum delay is assumed between consecutive preemptions. In practice, this minimum can be a multiple of the CPU clock speed. We show further how to extend from a single processor to multi-processor models with shared and/or separate queues.	automata theory;central processing unit;clock rate;computation;computer multitasking;multiprocessing;preemption (computing);scheduling (computing);scheduling analysis real-time systems;time complexity;timed automaton	Mohammad Mahdi Jaghoori	2011		10.1145/1982185.1982342	decidability;fixed-priority pre-emptive scheduling;parallel computing;real-time computing;computer science;distributed computing;preemption	Embedded	-9.995704221881716	60.86270727029415	23417
4da798429a79dfcf528445ac6ea1787bf55eaffc	blockchain-based security architecture for distributed cloud storage		With the development of ICT industry, the volume of produced data is experiencing tremendous growth, which motivates more demands of storage capacity. Because of the limited storage capacity of users' terminals, more and more applications prefer to upload data to cloud platforms. However, it is well known that security should not be neglected in existing cloud storage architectures. Motivated by the increasing popularity of emerging blockchain technology, we propose a blockchain-based security architecture for distributed cloud storage. Moreover, we customize a genetic algorithm to solve the file block replica placement problem between multiple users and multiple data centers in the distributed cloud storage environment. Numerical experimental results show that the proposed architecture outperforms the traditional cloud storage architectures in terms of security, with acceptable network transmission delay.	bitcoin;cloud storage;computer security;data center;genetic algorithm;mega man network transmission;multi-user;network performance;scheduling (computing);simulation;transmitter;upload	Jiaxing Li;Zhusong Liu;Long Chen;Pinghua Chen;Wu Jigang	2017	2017 IEEE International Symposium on Parallel and Distributed Processing with Applications and 2017 IEEE International Conference on Ubiquitous Computing and Communications (ISPA/IUCC)	10.1109/ISPA/IUCC.2017.00065	enterprise information security architecture;computer security;the internet;cloud storage;cloud computing;software;audit;data sharing;computer data storage;computer science	HPC	-32.169181714437954	61.444702910878895	23430
ec71b3fde3d88220d566d823241a969d8463997e	economic analysis of class 5 migration to ims	economic analysis	Telecommunication providers are increasingly choosing Internet Protocol Multimedia Subsystem (IMS) infrastructure. However, they often have substantial investment in the existing time division multiplexing (TDM) switches. The question arises: Should they cap but maintain existing TDM infrastructure and provision broadband subscribers on an Internet Protocol (IP) network, or should they consolidate the TDM network and proactively migrate their existing plain old telephone service (POTS) subscribers to IMS? In the former case, one has to maintain two networks and incur the operating expenses and the pertinent complexities. In the latter case, the cost of public switched telephone network (PSTN) replacement and earlier investment in IMS must be weighed against potential operations savings and possible incremental revenue. In this paper we provide an economic analysis of these two options. We find that consolidation and operational expense (OpEx) savings in the proactive migration to IMS are not enough to offset the costs of migration unless there are new revenue opportunities due to the new services that the PSTN replacement subscribers are willing to adopt. © 2007 Alcatel-Lucent.	closing (morphology);internet protocol suite;multiplexing;network switch;pots codec;relevance;semiconductor consolidation;toad data modeler	Subramanian Prakash;Abdol Saleh;Salman Shaikh;David Tsay	2007	Bell Labs Technical Journal	10.1002/bltj.20218	telecommunications;computer science;engineering;operating system;computer security;computer network	Networks	-9.981052250096822	86.12044065779442	23460
349680d8a9d71d9eb0143e7381f85bff4e2fa7e0	an i/o scheduling algorithm for soft real-time services oriented iscsi storage system	i/o scheduling;iscsi;multi-objective optimization;soft real-time;i o scheduling;multi objective optimization	iSCSI storage system is the most widely used network storage system, and soft real-time services are the most common type of business. However, the traditional I/O scheduling algorithms canu0027t work very well for iSCSI storage system oriented soft real-time services. In this paper, the mathematical model of I/O scheduling in iSCSI storage system for soft real-time services is analyzed and discussed, and it proves that this is a multi-objective optimization problem. HB-SCHED is proposed in this paper, which is a heuristic I/O scheduling algorithm for soft real-time services oriented iSCSI storage system. The simulation results show that HB-SCHED not only has better quality in terms of real time than SCAN and can gain higher disk throughput than EDF, but also can adjust the weights between real time and disk throughput by changing the parameter value. HB-SCHED can be well adopted in soft real-time services oriented iSCSI storage system.	algorithm;i/o scheduling;iscsi;input/output;real-time operating system;real-time transcription;scheduling (computing)	Qiwen Zha;Wu Zhang;Xuewen Zeng;Xiuyan Guo	2013	JSW		iscsi;distributed computing;multi-objective optimization;real-time computing;i/o scheduling;throughput;hyperscsi;scheduling (computing);computer science;computer data storage;optimization problem	Embedded	-18.137124120886114	62.82029987822075	23465
5f1b23a4f4ac627734ab174a543e3ae60221479c	message-efficient service management schemes for mom-based upnp networks	protocols heart beat peer to peer computing ip networks complexity theory computer architecture unicast;protocols;complexity theory;industry specific standards optimization of services systems web services communication protocols;computer architecture;optimization of services systems;ip networks;peer to peer computing;industry specific standards;unicast;heart beat;web services communication protocols	The use of message-oriented middleware (MOM) in pervasive systems has increased noticeably because of its flexible and failure-tolerant nature. Meanwhile, decentralized service management protocols such as UPnP are believed to be more suitable for administrating applications in small-scale pervasive environments such as smart homes. However, administering MOM-based pervasive systems by UPnP often suffers from network flood problems due to the replications of too many unnecessary messages. This paper presents several traffic reduction schemes, namely, decomposing the multicast traffic, service-based node searching, heartbeat by decomposing the multicast traffic, and on-demand heartbeat, which reduce the replications of unnecessary messages in MOM-based UPnP networks. The analytical predictions agree well with the simulated and experimental results, which show that the message counts of presence and leave announcements, node searching, and heartbeat can be greatly reduced.	denial-of-service attack;digital monetary trust;downtime;experiment;home automation;message-oriented middleware;multicast;pervasive informatics;prototype;simulation;ubiquitous computing;universal plug and play	Chun-Feng Liao;Hsin-Chih Chang;Li-Chen Fu	2013	IEEE Transactions on Services Computing	10.1109/TSC.2011.43	communications protocol;real-time computing;computer science;operating system;database;distributed computing;computer security;computer network;unicast	HPC	-21.341037637130327	69.71068745441005	23522
2528bfec12301305834bd8dcc55187a1b04d46f8	a heuristic algorithm for multi-site computation offloading in mobile cloud computing		Due to limitation of mobile device in terms of battery life and processing power, Mobile Cloud Computing (MCC) has become an attractive choice to leverage this shortcoming as the mobile computation could be offloaded to the cloud, which is so-called mobile computation offloading. Existing research on mobile computation offloading considers offloading a mobile computation to a single cloud. However, in the real world a computation service could be provided by multiple clouds and each computation service. Thus, a new and interesting research problem in mobile computation offloading is how to select a computation service for each of the computation tasks of a mobile computation such that the computation time of the mobile computation, the energy consumption of the mobile device and the cost of using the computation services are minimized. This is so called multi-site computation offloading in mobile cloud computing. In this paper we formulate the multi-site computation offloading problem, propose a heuristic algorithm for the multi-site computation offloading problem and evaluate the heuristic algorithm.	algorithm;computation offloading;heuristic (computer science);mobile cloud computing;mobile device;time complexity	Nur Idawati Md Enzai;Maolin Tang	2016		10.1016/j.procs.2016.05.490	model of computation;real-time computing;computer science;theoretical computer science;distributed computing	Mobile	-22.161569430066827	67.04088554541293	23523
2fc843356cbdce32beb3764b181ba50cb15b2d2c	balancing streaming and demand accesses in a network based storage environment	storage system;research outputs;research publications;satisfiability;analytical model	The usage of network-based applications is increasing, as network speeds increase. Also, the use of streaming applications, e.g BBC I-Player, Youtube etc, over the network is becoming commonplace. These applications access data sequentially. However, as processor speed and the amount of memory available increase, the rate at which streaming applications access data is much faster than the rate at which the blocks can be fetched consecutively from the network storage. Therefore, there is a need to analyse prefetching and clustering techniques for network-based storage systems. In addition to sequential access, the system also needs to satisfy demand misses.#R##N#In this paper, we attempt to develop an analytical model which will be used to investigate the operational boundaries under which streaming applications can run without jitter and demand misses can be satisfied in reasonable time.		Dhawal N. Thakker;Glenford E. Mapp;Orhan Gemikonakli	2008		10.1007/978-90-481-3662-9_69	real-time computing;simulation;telecommunications;computer science;theoretical computer science;operating system;computer security;computer network;satisfiability	HPC	-15.121224797711251	71.54661820321523	23534
7f3c9b5e103f595cb005c8ed5848764f3f43e650	a new approach for achieving traffic-exchange localization in p2p-based content distribution	resource utilization;service provider;application layer traffic optimization alto p2p applications traffic localization;isp;probability density function;application layer traffic optimization alto;resource management;tellurium;traffic control;p2p;data mining;autonomic system;distance measurement;telecommunication traffic;internet traffic;internet;content distribution;p2p service providers;p2p applications;interautonomous system traffic;traffic exchange localization;p2p based content distribution;locality based peer selection;bandwidth;telecommunication traffic internet peer to peer computing;ip networks;web server;peer to peer computing;telecommunication traffic traffic control internet peer to peer computing web server bandwidth costs ip networks tellurium resource management;inter as p2p traffic;intraautonomous system traffic;traffic localization;intraautonomous system traffic traffic exchange localization p2p based content distribution internet traffic inter as p2p traffic isp p2p service providers resource utilization locality based peer selection interautonomous system traffic	Due to the fact that P2P applications have dominantly accounted for the entire Internet traffic, how to efficiently manage P2P traffic has become increasingly important. It has been recently proposed that the underlying network information can be shared between ISPs and P2P service providers in order to achieve efficient resource utilization, with the locality-based peer selection being a specific example. Based on such collaboration, we propose a proportional traffic-exchange localization scheme for making efficient use of network resources. Our approach employs locality information in order to regulate the volume of traffic exchange between peers according to their physical distance between peers. The key objective of our approach is to further reduce both intra- and inter-autonomous system (AS) traffic compared with basic locality-based peer selection solutions. Our simulation-based results have shown that this approach is not only able to reduce a significant of inter-AS P2P traffic, but also to balance the network utilization in comparison to existing approaches.	algorithm;autonomous system (internet);digital distribution;locality of reference;peer-to-peer;simulation;traffic exchange	Chaojiong Wang;Ning Wang;Michael P. Howarth	2009	2009 International Conference on Telecommunications	10.1109/ICTEL.2009.5158619	service provider;probability density function;in situ resource utilization;the internet;internet traffic;computer science;resource management;peer-to-peer;tellurium;world wide web;computer security;bandwidth;web server;statistics;computer network	HPC	-14.430068789819888	76.34147026049803	23536
9e695873cf7eb6cd586569b8d29aef569108adf6	modelling the power consumption and trade-offs of virtualised cloud radio access networks	communication systems;article;power measurement	In large-scale computing centres, the advancement of knowledge in regards to the predicted power consumption (PC) and concerns of host servers that run virtual machines (VMs) could improve the capacity planning and networks’ Energy Efficiency (EE). In this paper, a parameterised power model is proposed to explore the individual components within the virtualisation based cloud-radio access network (vC-RAN). The model evaluates the PC and trade-offs of a server undergoing virtualisation. After, cooling and total PC for C-RAN architecture with and without virtualisation have been compared using differentiated parameters, such as varying number of bare-metal base band units (BBUs), VMs and system’s resource blocks (RBs) share/bandwidth. The results show dramatic decrease in the total PC via virtualising the core network (CN). In addition, the degraded performance of each virtualised server is demonstrated via modelling the execution time and overhead costs. These costs have been resulted from increasing the number of hosted VMs and utilised RBs by each VM.	bare machine;baseband;c-ran;computer cooling;overhead (computing);radio access network;run time (program lifecycle phase);server (computing);virtual machine	Raad S. Alhumaima;Hamed S. Al-Raweshidy	2017	IET Communications	10.1049/iet-com.2016.1396	telecommunications;computer science;communications system;computer network	Mobile	-21.40760427059721	61.325421208782295	23601
bb23d6e7f3b752712aa376dd3530a71e2264fe97	an open-source platform for distributed linux software routers	distributed router architecture;sw router;open source software	In this paper, our main objective is to explore how Linux Software Routers (SRs) can deploy advanced and flexible paradigms for supporting novel control-plane functionalities and applications. To this end, we investigate and study a new open-source software (SW) framework: the Distributed SW ROuter Project (DROP), which aims to develop and enable a novel cooperative middleware for distributed IP-router control and management. DROP allows logical network nodes to be built through the aggregation of multiple SRs based on the Linux operating system and commodity hardware, which can be devoted to packet forwarding or control operations. In addition to the original ForCES design, DROP aims to extend router distribution and aggregation concepts by moving them to a network-wide scale to enable and support value-added services for nextgeneration networks.	autonomous robot;commodity computing;fast path;linux;middleware;network packet;open-source software;operating system;performance evaluation;router (computing);shattered world	Raffaele Bolla;Roberto Bruschi	2013	Computer Communications	10.1016/j.comcom.2012.11.002	core router;embedded system;computer science;operating system;one-armed router;computer network	OS	-16.403186702886227	83.15764709177479	23608
78956cd762457957d5dcd39aed363c70581ff86c	finding critical traffic matrices	network design;approximate algorithm;capacity planning;clustering based approximation algorithm ip network network survivability analysis traffic engineering critical traffic matrices selection problem;communication complexity;north american;matrix algebra;approximation theory;network survivability;telecommunication traffic;telecommunication traffic ip networks clustering algorithms acoustical engineering capacity planning reliability engineering design engineering computer networks bridges approximation algorithms;approximation theory ip networks telecommunication traffic communication complexity matrix algebra;ip networks;traffic engineered;traffic matrix	"""A traffic matrix represents the amount of traffic between origin and destination in a network. It has tremendous potential utility for many IP network engineering applications, such as network survivability analysis, traffic engineering, and capacity planning. Recent advances in traffic matrix estimation have enabled ISPs to measure traffic matrices continuously. Yet a major challenge remains towards achieving the full potential of traffic matrices. In practical networking applications, it is often inconvenient (if not infeasible) to deal with hundreds or thousands of measured traffic matrices. So it is highly desirable to be able to extract a small number of """"critical"""" traffic matrices. Unfortunately, we are not aware of any good existing solutions to this problem (other than a few ad hoc heuristics). This seriously limits the applicability of traffic matrices. To bridge the gap between the measurement and the actual application of traffic matrices, we study the critical traffic matrices selection (CritMat) problem in this paper. We developed a mathematical problem formalization after identifying the key requirements and properties of CritMat in the context of network design and analysis. Our complexity analysis showed that CritMat is NP-hard. We then developed several clustering-based approximation algorithms to CritMat. We evaluated these algorithms using a large collection of real traffic matrices collected in AT&T's North American backbone network. Our results demonstrated that these algorithms are very effective and that a small number (e.g., 12) of critical traffic matrices suffice to yield satisfactory performance."""	analysis of algorithms;approximation algorithm;best, worst and average case;cluster analysis;heuristic (computer science);hoc (programming language);internet backbone;mathematical optimization;np-hardness;network planning and design;requirement;traffic exchange	Yin Zhang;Zihui Ge	2005	2005 International Conference on Dependable Systems and Networks (DSN'05)	10.1109/DSN.2005.51	traffic generation model;network planning and design;network traffic control;computer science;theoretical computer science;communication complexity;distributed computing;traffic shaping;computer security;internet traffic engineering;computer network;network traffic simulation;approximation theory	Metrics	-7.66248892241424	79.61252851576224	23648
00bb701f76be21a3d2720bf67042e691cc758436	termite: emulation testbed for encounter networks	debug;openstack;cloudstack;virtualization;emulation;android;wifi direct;emulator	Cutting-edge mobile devices like smartphones and tablets are equipped with various infrastructureless wireless interfaces, such as WiFi Direct and Bluetooth. Such technologies allow for novel mobile applications that take advantage of casual encounters between co-located users. However, the need to mimic the behavior of real-world encounter networks makes testing and debugging of such applications hard tasks. We present Termite, an emulation testbed for encounter networks. Our system allows developers to run their applications on a virtual encounter network emulated by software. Developers can model arbitrary encounter networks and specify user interactions on the emulated virtual devices. To facilitate testing and debugging, developers can place breakpoints, inspect the runtime state of virtual nodes, and run experiments in a stepwise fashion. Termite defines its own Petri Net variant to model the dynamically changing topology and synthesize user interactions with virtual devices. The system is designed to efficiently multiplex an underlying emulation hosting infrastructure across multiple developers, and to support heterogeneous mobile platforms. Our current system implementation supports virtual Android devices communicating over WiFi Direct networks and runs on top of a local cloud infrastructure. We evaluated our system using emulator network traces, and found that Termite is expressive and performs well.	android;bluetooth;breakpoint;cloud computing;colocation centre;debugging;emulator;experiment;interaction;mobile app;mobile device;multiplexing;petri net;prototype;scalability;simulation;smartphone;stepwise regression;testbed;tracing (software)	Rodrigo Bruno;Nuno Santos;Paulo José Azevedo Vianna Ferreira	2015	ICST Trans. Ambient Systems	10.4108/eai.22-7-2015.2260069	embedded system;emulation;real-time computing;virtualization;simulation;telecommunications;computer science;operating system;computer security;android;computer network	Mobile	-16.675962173299688	80.77764371181645	23670
c6f5d7cc4f4c4db7fcc66e9dc938e7cc2936fae9	a reliable fault-tolerant scheduling algorithm for real time embedded systems		In this paper, we propose a fault-tolerant scheduling for realtime embedded systems. Our scheduling algorithm is dedicated to multibus heterogeneous architectures, which take as input a given system description and a given fault hypothesis. It is based on a data fragmentation and passive redundancy, which allow fast fault detection/retransmission and efficient use of buses. Our scheduling approach consist of a list scheduling heuristic based on a Global System Failure Rate (GSFR). In order to maximize the reliability of the system, the size of each fragmented data depends on GSFR and the bus failure rates. variable fragment size allows reliable communication and to maximize the reliability of the system. Finally, simulation results show the performance of our approach when using data fragmentation with a variable fragment size.	application-level gateway;autonomous robot;backup;bus (computing);critical path method;distributed algorithm;embedded system;failure rate;fault detection and isolation;fault tolerance;fault-tolerant computer system;fragmentation (computing);heuristic;list scheduling;multibus;real-time operating system;retransmission (data networks);scheduling (computing);simulation	Chafik Arar;Hamoudi Kalla;Salim Kalla;Hocine Riadh	2013			fair-share scheduling;fixed-priority pre-emptive scheduling;embedded system;parallel computing;real-time computing;earliest deadline first scheduling;flow shop scheduling;dynamic priority scheduling;computer science;rate-monotonic scheduling;genetic algorithm scheduling;two-level scheduling;distributed computing;least slack time scheduling;lottery scheduling;round-robin scheduling;proportionally fair	Embedded	-8.374677572904071	62.53721499031062	23763
9db5aed0df916588c8480233e414921b95bb5fa7	interconnection of broadband local area networks		Interconnection of multiple broadband local area networks to form an integrated packet transport system presents several challenges. To take full advantage of broadband systems, assignment of nodes to channels must be dynamic, leading to the use of a flat address space. Combined with the desire to avoid reliance on a central server or complex routing in packet forwarders, this addressing scheme leads to adoption of a controlled flooding technique to “discover” the best path to a destination node. This discovery procedure sets up a path through internetwork forwarders for use by subsequent packets to the same destination. This paper describes the design and implementation of such a technique in Sytek's LocalNet(TM) systems along with several refinements which increase performance and keep the worst case load for route discovery below a few percent of network capacity.	address space;addressing scheme;best, worst and average case;flat memory model;interconnection;internetworking;library (computing);network packet;routing;server (computing)	Carl A. Sunshine;D. Kaufman;Gregory Ennis;K. Biba	1983		10.1145/800034.800897	local area network;real-time computing;telecommunications;computer science;packet forwarding;computer network	Arch	-7.539502211795732	86.18844512807482	23781
5bdc9ba8ad3f3841c231c16c0b25c68b4d84c7cd	refundable service through cloud brokerage	cloud computing pricing computational modeling radio frequency conferences degradation;service level agreement sla;refundable service;cloud broker;pricing;cloud broker refundable service service level agreement sla service estimation pricing;contracts;service estimation;quality of service;quality of service cloud computing contracts pricing;cloud computing;service quality degradation refundable service cloud brokerage cloud computing pricing fairness cloud computing environment pricing model customer appreciation customer satisfaction propose cloud service provider anxiety third party cloud broker	As we know, cloud computing has already become a dominant computing paradigm with its significant impact on the distribution of computing resources and business attribution. However, due to the lack of fairness in pricing and SLA violation during the service in cloud computing, customers are dissatisfied with the existing pricing model of current cloud computing environment, and there have an immense chance to lose those discontented customers. Moreover, the cloud service provider's total business can be obstructed in the long run. Therefore, we wish to provide a solution that can preserve customers' appreciation by refundable service. In this paper, we propose a unique technique that can boost up customer satisfaction and diminish cloud service provider anxiety for continuing their business. Basically, we applied a third party cloud broker that can handle all of the business procedure instead of cloud service provider. Our method offers refunding in case of unutilized resource as well service quality degradation that is service level agreement (SLA) violation. The experiment results demonstrate different refund amount for cloud consumers' considering with several attribute.	cloud computing;elegant degradation;fairness measure;programming paradigm;service-level agreement	Al Amin Hossain;Eui-nam Huh	2013	2013 IEEE Sixth International Conference on Cloud Computing	10.1109/CLOUD.2013.115	service provider;pricing;cloud computing security;service level requirement;service level objective;quality of service;cloud computing;differentiated service;computer science;service delivery framework;operating system;utility computing;data as a service	HPC	-23.89254083778956	64.60757903595997	23888
44cb65037463d8951cb0cd30e15e81d88ccd313c	an efficient load-balancing mechanism for heterogeneous range-queriable cloud storage		The rising popularity of big data processing for semantically rich applications such as social networks and IoT (Internet of Things) has made the range-queriable cloud storage increasingly important. To support range queries, the data locality is preserved strictly, which makes the load balancing among nodes a challenging task. Currently, most of the range-queriable cloud storage adopts the combination of neighbor item exchange and neighbor migration methods, which incurs large overhead, and suffers from slow convergence. In this work, we present a novel virtual node based decentralized load-balancing method for range-queriable cloud storage. In our method, each physical node is partitioned into multiple virtual nodes, and all the virtual nodes are organized with range-queriable P2P network. Load balancing is conducted in both overlay level (between neighboring virtual nodes) without global knowledge and physical level (among physical nodes) with limited global knowledge. Both theoretical analysis and simulations show that our method can significantly reduce the overhead and shorten the convergence time. © 2017 Elsevier B.V. All rights reserved.	big data;cloud storage;internet of things;load balancing (computing);locality of reference;overhead (computing);peer-to-peer;range query (data structures);simulation;social network	Xun Shao;Masahiro Jibiki;Yuuichi Teranishi;Nozomu Nishinaga	2018	Future Generation Comp. Syst.	10.1016/j.future.2017.07.053	real-time computing;cloud storage;range query (data structures);big data;distributed computing;computer network;overlay;computer science;associative array;load balancing (computing);convergence (routing);internet of things	HPC	-13.317874109485036	72.59870479217388	23944
2a7ed0216675cb841dc4336dd14083b7be66df8f	hyper-heuristic based resource scheduling in grid environment	resource scheduling;grid computing resource scheduling heuristic methods;resource allocation;scheduling scheduling algorithms heuristic algorithms grid computing computational modeling algorithm design and analysis;cost reduction;heuristic methods;computational complexity;scheduling;scheduling computational complexity cost reduction grid computing resource allocation;grid computing;hyperheuristic based resource scheduling make span minimization cost minimization gridsim toolkit job scheduling np complete problem computational grid grid resources scheduling grid computing resource management grid environment	An efficient management of the resources in Grid computing crucially depends on the efficient mapping of the jobs to resources according to the user's requirements. Grid resources scheduling has become a challenge in the computational Grid. The mapping of the jobs to appropriate resources for execution of the application in Grid computing is an NP-Complete problem. In this paper, hyper-heuristic based resource scheduling algorithm is designed to effectively schedule the jobs on available resources in a Grid environment. The performance of the proposed algorithm is evaluated using the GridSim toolkit. Empirical results illustrate that our algorithm outperformed the existing algorithm by minimizing cost and make span of user's submitted applications.	algorithm;grid computing;heuristic (computer science);hyper-heuristic;job shop scheduling;makespan;np-completeness;requirement;scheduling (computing);tabu search	Rajni Aron;Inderveer Chana;Ajith Abraham	2013	2013 IEEE International Conference on Systems, Man, and Cybernetics	10.1109/SMC.2013.187	fair-share scheduling;fixed-priority pre-emptive scheduling;parallel computing;real-time computing;earliest deadline first scheduling;flow shop scheduling;dynamic priority scheduling;resource allocation;computer science;rate-monotonic scheduling;genetic algorithm scheduling;two-level scheduling;distributed computing;scheduling;lottery scheduling;computational complexity theory;round-robin scheduling;scheduling;grid computing	HPC	-18.32694105491142	62.99339432002902	23945
06e04a7a24100dbc0f72f22bc8e6dde4b2a27d8b	hyparview: a membership protocol for reliable gossip-based broadcast	resilient reliable broadcast primitives;protocols;gossip based broadcast;hyparview;gossip;degree distribution;gossip protocol hyparview membership protocol gossip based broadcast resilient reliable broadcast primitives;report;gossip protocol;fault tolerance;membership protocol;broadcasting peer to peer computing maintenance power system reliability clustering algorithms transport protocols scalability redundancy costs sampling methods;computer science;gossip protocols;membership protocols;article;reliable broadcast;groupcomm	Gossip, or epidemic, protocols have emerged as a powerful strategy to implement highly scalable and resilient reliable broadcast primitives. Due to scalability reasons, each participant in a gossip protocol maintains a partial view of the system. The reliability of the gossip protocol depends upon some critical properties of these views, such as degree distribution and clustering coefficient. Several algorithms have been proposed to maintain partial views for gossip protocols. In this paper, we show that under a high number of faults, these algorithms take a long time to restore the desirable view properties. To address this problem, we present HyParView, a new membership protocol to support gossip-based broadcast that ensures high levels of reliability even in the presence of high rates of node failure. The HyParView protocol is based on a novel approach that relies in the use of two distinct partial views, which are maintained with different goals by different strategies.	algorithm;clustering coefficient;communications protocol;degree distribution;directed graph;emergence;fan-out;fault tolerance;gossip protocol;network packet;overhead (computing);planetlab;scalability	João Leitão;José Orlando Pereira;Luís E. T. Rodrigues	2007	37th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN'07)	10.1109/DSN.2007.56	gossip protocol;computer science;distributed computing;computer security;computer network	HPC	-8.048918242641081	72.14467964384836	23981
c85e8479748636a6879d5f476f3d43174237615f	a timed petri-net model for fine-grain loop scheduling	partially ordered set;polynomial time;petri net;partial order	Efficient execution of loops is one of the most important obstacles facing high-performance computer architectures. Loop scheduling involves handling a partially ordered set of operations which are to be performed repetitively over a number of iterations.In this paper we study loop scheduling using Petri nets, due to their unique power for modeling both partial orders and cycles. The behavior of loops can be modeled by constructing, at compile time, a Petri-net . From a cyclic frustum, a time-optimal schedule for the corresponding loop can be derived. A polynomial time bound for such a cyclic frustum to occur has been established. Simulation results on a number of Livermore loops, both with and without loop-carried dependences, have demonstrated the feasibility of determining the cyclic frustum at compile time.	loop scheduling;petri net;scheduling (computing)	Guang R. Gao;Yue-Bong Wong;Qi Ning	1991		10.1145/962140	loop fusion;real-time computing;simulation;computer science;distributed computing	Robotics	-10.131667774382604	61.8947058703679	24006
732c89b3558cd025481016c3a41f7868bc1e4542	information exchange protocol: a new approch for future network management			information exchange	Deh-Min Wu	1995				Networks	-20.161836226680276	87.02405640812786	24026
eb60284c0c9ad6c09e8ab735e343f0a1dc0ef9e1	on a balanced neighbor selection strategy for tracker-based peer-to-peer networks	graph theory;probability;file sharing process balanced neighbor selection strategy tracker based peer to peer networks uniform load distribution balanced multiple choice algorithm overlay topology maximum graph degree graph diameter probability randomized upload policy block distribution neighbor selection strategy constant factor upper bound improvement bittorrent networks peersim simulation framework;telecommunication network topology computational complexity graph theory overlay networks peer to peer computing probability;overlay networks;computational complexity;peer to peer computing overlay networks topology network topology routing algorithm design and analysis conferences;peer to peer computing;telecommunication network topology	In this paper we introduce a novel neighbor selection strategy for tracker-based peer-to-peer systems like BitTorrent that can uniformly distribute the load among peers in the network. Our method is based on a balanced multiple choice algorithm which takes into account not only the actual load of a peer, but the possibility as well that it will be selected in the future. We first analyze the properties of the constructed overlay topology theoretically, proving that, the maximum degree in the constructed graph is O(1) while the diameter remains O(ln n), with high probability, where n is the number of nodes. Considering a randomized upload policy, we show that the full distribution of b blocks on the network generated by our neighbor selection strategy takes O(b + ln n) phases only, with high probability, which is optimal up to a constant factor. This result improves the previous upper bound of O(b+(ln n)2) by Arthur and Panigrahy (SODA'06). In order to adapt our algorithm in real BitTorrent networks only a slight modification of the tracker is necessary without any change in the clients. Besides theoretical analysis, thorough simulations have been done to validate our algorithm and show its applicability in real BitTorrent networks. To this end, we have extended the BitTorrent implementation of the PeerSim simulation framework with a new tracker using our balanced neighbor selection strategy and demonstrated that it can speed up the file-sharing process in heavy loaded situations.	bittorrent;file sharing;graph property;network topology;peer-to-peer;randomized algorithm;routing;simulation;upload;verlet list;with high probability	Sándor Laki;Tamás Lukovszki	2013	IEEE P2P 2013 Proceedings	10.1109/P2P.2013.6688706	overlay network;computer science;graph theory;theoretical computer science;probability;distributed computing;computational complexity theory;world wide web;statistics;computer network	Theory	-9.651017065683543	73.8105197837815	24050
66654dfef7ffe723a4e2fac63e40b824515d07af	a distributed task assignment algorithm with the fcfs policy in a ring			algorithm	Atsushi Sasaki	2004			distributed computing;computer science	EDA	-11.63427887153092	62.730399071651696	24094
b0aa08a4c838f0ed329296ffd2acf86083467cb3	flying communication server in case of a largescale disaster	uav;disaster;single board computer;information sharing flying communication server large scale disaster drone unmanned aerial vehicle uav single board computer wi fi base station web server webrtc server private smart devices smart phones video sharing text chat asynchronous exchange real time video communication communication layers architecture wi fi standard technologies web technologies wi fi distance video stream distribution frame rate concurrent user connection number;websocket;drone;servers ieee 802 11 standard streaming media smart devices cameras smart phones computers;webrtc;disaster drone uav single board computer communication server websocket webrtc;communication server;wireless lan autonomous aerial vehicles disasters electronic messaging emergency management file servers internet peer to peer computing smart phones telecommunication networks video communication video streaming	We have developed a Flying Communication Server, which is a drone, unmanned aerial vehicle (UAV), equipped with a single board computer implemented in a Wi-Fi base station, a Web server and a WebRTC server. With this system, even in situations in which the cellular telephony network/public wireless network have been collapsed due to a large-scale disaster, users who have their own private smart devices such as smart phones will be able to share the video of an affected area from the sky, exchange the text chat asynchronously, and execute the real-time video communication. In order to make it possible, we proposed three communication layers architecture based on Wi-Fi standard technologies and Web technologies. In this study, we have checked a range of connectivity of the Flying Communication Server such as Wi-Fi distance, frame rate to distribute video stream, and concurrent connection user numbers. We have also evaluated the text chat and the real-time video communication availability. Then, we have confirmed the effectiveness of the Flying Communication Server concerning to information sharing and asynchronous/realtime communication in case of a large-scale disaster.	aerial photography;computer performance;continuous operation;game server;online chat;prototype;real-time clock;real-time transcription;requirement;server (computing);single-board computer;smart device;smartphone;streaming media;unmanned aerial vehicle;web server;webrtc;world wide web	Toru Kobayashi;Hiroaki Matsuoka;Shouta Betsumiya	2016	2016 IEEE 40th Annual Computer Software and Applications Conference (COMPSAC)	10.1109/COMPSAC.2016.117	embedded system;drone;disaster;computer science;operating system;communications server;computer security;computer network;server farm	Mobile	-21.791984310211046	77.60121704930434	24109
0ba8064728463d0dee8618d081b5c394e13b8a82	lipsin: line speed publish/subscribe inter-networking	bloom filter;energy efficient;scaling up;bloom filters;large scale;publish subscribe;internet application;forwarding;multicast	A large fraction of today's Internet applications are internally publish/subscribe in nature; the current architecture makes it cumbersome and inept to support them. In essence, supporting efficient publish/subscribe requires data-oriented naming, efficient multicast, and in-network caching. Deployment of native IP-based multicast has failed, and overlay-based multicast systems are inherently inefficient. We surmise that scalable and efficient publish/subscribe will require substantial architectural changes, such as moving from endpoint-oriented systems to information-centric architectures.  In this paper, we propose a novel multicast forwarding fabric, suitable for large-scale topic-based publish/subscribe. Due to very simple forwarding decisions and small forwarding tables, the fabric may be more energy efficient than the currently used ones. To understand the limitations and potential, we provide efficiency and scalability analysis via simulations and early measurements from our two implementations. We show that the system scales up to metropolitan WAN sizes, and we discuss how to interconnect separate networks.	cache (computing);communication endpoint;multicast;publish–subscribe pattern;scalability;simulation;software deployment	Petri Jokela;András Zahemszky;Christian Esteve Rothenberg;Somaya Arianfar;Pekka Nikander	2009		10.1145/1592568.1592592	real-time computing;multicast;protocol independent multicast;computer science;bloom filter;distributed computing;source-specific multicast;xcast;computer network	Networks	-10.283577761638016	80.24953391775546	24310
aa510b95a810c1b21f6a00ef32cae5c7320b4237	fast and efficient bandwidth reservation algorithms for dynamic network provisioning	bandwidth scheduling;high performance networks;dedicated network	Large-scale collaborative e-science requires fast and reliable data transfer with guaranteed performance, which is made possible by reserving bandwidth as needed in advance in high-performance networks. In scientific applications, users typically know the data size, the data available time, and the deadline to finish the data transfer, and they always wish to achieve the earliest possible finish time or the minimum time duration for the data transfer. On the other hand, the network service provider wishes to serve as many users’ bandwidth reservation requests (BRRs) as possible to maximize the network resource utilization without compromising their deadlines. Such multi-objective requirements and high system throughput call for a fast and efficient bandwidth reservation strategy that can quickly discover various reservation options in a time-varying network environment. We propose two bandwidth reservation algorithms with rigorous optimality proofs to compute the reservation options with the earliest completion time and with the shortest duration for a local BRR. Our algorithms aim to achieve the balanced resource utilization for the network system. Extensive simulation results demonstrate the superiority of the proposed algorithms in terms of execution time, success ratio, success ratio of BRRs with different priorities and searched complexity of BRRs in comparison with similar scheduling algorithms.	algorithm;business readiness rating;e-science;network service provider;provisioning;requirement;run time (program lifecycle phase);scheduling (computing);simulation;throughput;time-varying network	Liudong Zuo;Mengxia Zhu;Chase Qishi Wu	2013	Journal of Network and Systems Management	10.1007/s10922-013-9294-0	real-time computing;computer science;distributed computing;computer network	HPC	-18.343276429034148	61.96007060717797	24318
141eaa54cc8f8403a6977a860604f592f0d563f8	a technique to reduce preemption overhead in real-time multiprocessor task scheduling	multiprocessor scheduling;multiprocessor;processor scheduling;real time;fair scheduling;preempcion;deadline;equite;equidad;computer architecture;reglamento edf;equity;architecture ordinateur;optimal scheduling;real time scheduling;ordonnancement edf;preemption;edf;arquitectura ordenador;ordonnancement processeur;task scheduling;multiprocesador;date limite;algoritmo optimo;algorithme optimal;fechas ultimas;optimal algorithm;multiprocesseur	Partitioning and global scheduling are two approaches for scheduling real-time tasks in multiprocessor environments. Partitioning is the more favored approach, although it is sub-optimal. This is mainly due to the fact that popular uniprocessor real-time scheduling algorithms, such as EDF and RM, can be applied to the partitioning approach with low scheduling overhead. In recent years, much research has been done on global real-time multiprocessor scheduling algorithms based on the concept of “proportionate fairness”. Proportionate fair (Pfair) scheduling [5],[6] is the only known optimal algorithm for scheduling real-time tasks on multiprocessor. However, frequent preemptions caused by the small quantum length for providing optimal scheduling in the Pfair scheduling make it impractical. Deadline Fair Scheduling (DFS) [1] based on Pfair scheduling tried to reduce preemption-related overhead by means of extending quantum length and sharing a quantum among tasks. But extending quantum length causes a mis-estimation problem for eligibility of tasks and a non-work-conserving problem.#R##N##R##N#In this paper, we propose the Enhanced Deadline Fair Scheduling (E-DFS) algorithm to reduce preemption-related overhead. We show that E-DFS allows us to decrease quantum length by reducing overhead and save wasted CPU time that is caused by preemption-related overhead and miss-estimation of eligibility.	multiprocessing;preemption (computing);real-time transcription;schedule (project management);scheduling (computing)	Kyong Jung;Chanik Park	2005		10.1007/11572961_46	fair-share scheduling;nurse scheduling problem;fixed-priority pre-emptive scheduling;parallel computing;real-time computing;earliest deadline first scheduling;multiprocessing;gang scheduling;flow shop scheduling;dynamic priority scheduling;computer science;rate-monotonic scheduling;genetic algorithm scheduling;operating system;two-level scheduling;deadline-monotonic scheduling;stride scheduling;distributed computing;preemption;least slack time scheduling;lottery scheduling;round-robin scheduling;equity;multiprocessor scheduling;proportionally fair	Embedded	-11.495142169538338	60.94859660142182	24355
8c494294cd24d4ab0c6f38c6aff8edc5c33c1c76	analysis and classification of service interactions for the scalability of the internet of things		Scalability is an important concern for Internet of Things (IoT) applications since the amount of service interactions may become overwhelming, due to the huge number of interconnected nodes. In this paper, we present an IoT scenario for real-time Electrocardiogram (ECG) monitoring, in order to analyze how well different kinds of service interactions can fulfill the scalability requirements of IoT applications.	computation;control flow;event-driven architecture;experiment;interaction;internet of things;network performance;real-time clock;requirement;scalability;throughput	Damian Arellanes;Kung-Kiu Lau	2018	2018 IEEE International Congress on Internet of Things (ICIOT)	10.1109/ICIOT.2018.00018	computer network;computer science;scalability;internet of things	Embedded	-19.568427001133625	79.9690409255631	24412
488d4eb3b41e3c488db00d466ece2115ce5e3561	reliable communication in the presence of agent mobility	channel endpoint;communication reliability;telecommunication network reliability;mobile agent systems;mobile agents;distributed computing;telecommunication computing;transport layer;transport protocols;mobile agent system;reliable communication;internet;local community;sprites computer;mobile radio;mobile agents mobile communication communication channels transport protocols logic devices internet distributed computing telecommunication network reliability proposals sprites computer;mobile communication;transport layer protocol;channel endpoint communication reliability mobile agent systems transport layer protocol;transport protocols mobile agents mobile radio telecommunication computing telecommunication network reliability;communication channels;proposals;logic devices	Although mainly resorting to local communication, all mobile agent systems also provide some kind of remote communication facility. This introduces issues not addressed in the protocols provided by the transport layer, such as TCP, nor in its extensions to cope with physical mobility. The problem consists of tracking the agent to which the channel must be established, and providing support for the migration of any of the channel's endpoints. In this paper, we propose a model that solves both problems, transparently to the application, by resorting to sophisticated interaction with a naming service and by featuring a protocol to support the migration of both the connection's endpoints.	bottleneck (engineering);byte;cache (computing);centralized computing;channel (communications);communications protocol;handshaking;identifier;mobile agent;network congestion;overhead (computing);scalability;unique key	Hervé Paulino	2007	2007 12th IEEE Symposium on Computers and Communications	10.1109/ISCC.2007.4381559	telecommunications;computer science;computer security;transport layer;computer network	Mobile	-11.453219452771084	87.9375282876036	24438
7449faa8dcec05f53549a8fee72faf7e0ca6bacd	a new rule scheduling approach based on estimation of rule execution probability in active database	estimation of rule execution probability;active database system;management system;active database;standard deviation;rule scheduling;active database management systems;evaluation criteria	Active database systems (ADBS) can, automatically, react to the occurrence of predefined events by definition a collection of active rules. One of the most important modules of ADBS is the rule scheduler, which has considerable impact on performance and efficiency of ADBS. Rule scheduler selects a rule to execute in each time through the rules, which are ready for execution. We have already evaluated and compared the existing rule scheduling approaches in a laboratorial environment based on three tier architecture. Five evaluation criteria were, formally, recognized and defined for evaluation and comparison of rule scheduling approaches including: Average Response Time, Response Time Standard Deviation, Throughput, Time Overhead per Transaction and CPU Utilization. At last, we introduced the most effective approach. In this paper, we propose a new approach to improve the rule scheduling based on improvement of Rule Execution Probability Estimation. Then, we compare it with the most effective existing approach in the framework mentioned. Results of experiments show that the new method improves the rule scheduling.	active database;algorithm;casio exilim;central processing unit;event condition action;experiment;multitier architecture;responsiveness;rule 184;scheduling (computing);throughput	Abbas Rasoolzadegan Barforoush;Rohollah Alesheykh;Ahmad Abdollahzadeh Barforoush	2008	JCIT		database tuning;computer science;data mining;management system;database;standard deviation;management;database testing;statistics	DB	-17.579653832581478	61.20978352624976	24482
dd198e5976e689cd47acaa6cd49d05377442d08d	a comprehensive study of wide area data movement at a scientific computing facility		Wide-area data transfer is central to distributed science. Network capacity, data movement infrastructure, and tools in science environments continuously evolve to meet the requirements of distributed-science applications. Research and education (R&E) networks such as the U.S. Department of Energy’s Energy Sciences network and Internet2 provide multiple 100 Gbps backbone networks. Large scientific facilities and research institutions have 100 Gbps wide-area network connectivity, and 10 Gbps wide-area network connectivity is common for a lot of R&E institutions. Many of these institutions employ Science DMZs, dedicated data transfer node(s), and high performance data movement tools to improve wide area data transfer performance. Large facilities may use 10 or more dedicated data transfer nodes to meet the needs of their users. In this work, we analyze various logs pertaining to wide area data transfers in and out of a large scientific facility to obtain insights on data transfer characteristics and behavior. We also show some of the inefficiencies in the state-of-the-art data movement tool and discuss approaches to address these inefficiencies.	computational science;data rate units;internet backbone;requirement	Zhengchun Liu;Rajkumar Kettimuthu;Ian T. Foster;Yuanlai Liu	2018	2018 IEEE 38th International Conference on Distributed Computing Systems (ICDCS)	10.1109/ICDCS.2018.00180	distributed computing;data transmission;computer science	HPC	-21.192670082926284	78.83456495288699	24517
aabd3ff837a740cbb555845f79ed5a18fd7c9a86	self-organizing strategies for resource management in cloud computing: state-of-the-art and challenges	open research issues cloud computing resource management self organizing strategies;resource management monitoring biomedical monitoring servers virtual machining protocols biochemistry;cloud providers self organizing strategies resource management cloud computing distributed solutions bio inspired computing multiagent systems evolutionary techniques self organizing solutions;self organising feature maps cloud computing resource allocation	Due to the growth of Cloud Computing, the supporting infrastructure has become more complex, and the centralized solutions suffer resource management difficulties due to the large scale and the dynamicity of the scenario. Consequently, distributed solutions have been proposed in the literature and the self-organizing ones have attracted particular interest due to their robustness and adaptability characteristics. Techniques, such as bio-inspired computing, multi-agent systems, and evolutionary techniques are used to manage resources. The main goal of this paper is to present a start study about how self-organizing solutions are applied in resource management of Cloud providers, as well as to highlight the main research challenges in this area.	bio-inspired computing;centralized computing;cloud computing;multi-agent system;organizing (structure);self-organization	Patricia Takako Endo;Marcelo Santos Batista;Glauco Estacio Gonçalves;Moisés Rodrigues;Djamel Fawzi Hadj Sadok;Judith Kelner;Azimeh Sefidcon;Fetahi Zebenigus Wuhib	2013	2nd IEEE Latin American Conference on Cloud Computing and Communications	10.1109/LatinCloud.2013.6842215	cloud computing;computer science;knowledge management;cloud testing;distributed computing;management science	HPC	-30.620567622433935	61.26424279863626	24528
1c7aed5dca38752fb047c39b445670da811c7161	a multi-objective optimization approach for joint channel assignment and multicast routing in multi-radio multi-channel wireless mesh networks	multicast tree;non dominated sorting genetic algorithm nsga ii;wireless mesh networks;channel assignment	Multicast routing is an effective mechanism for delivering data to a group of receivers. Due to intrinsic property of air medium in wireless mesh networks (WMN), interference is an important issue in determining the data rate for multicast services. Interference reduction is handled by assigning multiple orthogonal channels to multiple radios in multi-radio multi-channel WMNs. Channel assignment is known to be a NP-complete problem. Most prior methods have solved multicast routing and channel assignment problems sequentially and have not considered the interplay between these two problems. Focusing on this issue, we address joint channel assignment and routing problem for multicast applications. In this paper, a novel technique based on a multi-objective genetic algorithm is proposed to build a delay constrained minimum cost multicast tree with minimum interference. We have examined the proposed algorithm on different network configurations. Experimental results demonstrate that our method finds better trees in terms of cost, delay, and interference compared to prior methods.	mesh networking;multi-objective optimization;multicast;routing;wireless mesh network	Elaheh Vaezpour;Mehdi Dehghan	2014	Wireless Personal Communications	10.1007/s11277-013-1554-5	multicast;telecommunications;protocol independent multicast;computer science;distributed computing;distance vector multicast routing protocol;source-specific multicast;xcast;computer network	Mobile	-4.594739761122458	83.09466423456654	24630
9e6ab5f7f7740c4cda8649ed96e4442dbd424078	energy-aware migration of groups of virtual machines in distributed data centers	topology;virtual machining;network topology;servers;energy consumption;distributed databases;algorithm design and analysis	This paper proposes the Topology-aware Virtual Machine Selection (TAVMS) algorithm to choose sets of communicating groups of virtual machines (VMs) to be migrated to other data centers, aiming at global energy savings. It considers the migration of groups of VMs as well as the data center network topology, selecting VM groups with network proximity in order to increase the potential number of equipments to be switched off. Results obtained show that relevant energy savings can be achieved by using the proposed algorithm in the allocation of servers to the migration of virtual machines in a distributed data center scenario.	algorithm;data center;internet backbone;network switch;network topology;selection algorithm;virtual machine	Rodrigo A. C. da Silva;Nelson Luis Saldanha da Fonseca	2016	2016 IEEE Global Communications Conference (GLOBECOM)	10.1109/GLOCOM.2016.7841803	algorithm design;real-time computing;computer science;operating system;distributed computing;distributed database;network topology;server;computer network	HPC	-17.70607245655221	64.78642720901212	24683
84e3498db0afe968b32a4b566b8d1c7e3ce00f6c	an enhanced router topology discovery model	anonymous routers topology discovery router topology traceroute router alias resolution;topology;telecommunication network topology computer networks telecommunication network routing;research needs;topology discovery;data mining;probes;computer networks;anonymous router processing enhanced router topology discovery model computer network router alias resolution;computer network;network topology;computational modeling;router alias resolution;internet;telecommunication network routing;traceroute;anonymous router processing;ip networks;enhanced router topology discovery model;telecommunication network topology;network topology probes databases communication networks computer networks visualization data analysis information analysis;router topology;anonymous routers	Router topology discovery is indispensable in the research of computer network, but existing models based on collected traces have several shortages, resulting in that the accuracy and completeness of the generated topologies can not meet the further research needs. This paper presents an enhanced topology discovery model-ETDM, which solves some of the problems by new techniques and leads to better results, such as router alias resolution by ‘Neighbors-Subnet’ resolution, anonymous router processing by ‘the largest resolution of anonymous routers’, and so on. Compared with the existing models, lower time consumption, fewer probes, and wider discovery range can be seen in ETDM after plenty of experiments.	experiment;network topology;router (computing);subnetwork;tracing (software)	Peidong Zhu;Huai-Zhou Shi;Xin Liu	2009	2009 Seventh Annual Communication Networks and Services Research Conference	10.1109/CNSR.2009.75	core router;traceroute;the internet;computer science;distributed computing;computational model;world wide web;network topology;computer network	DB	-8.193547449301567	79.29501164937739	24701
843ad9641ff75c5eb7bab93a7e59ee9b128e5312	evaluating performance of containerized iot services for clustered devices at the network edge		The constant and fast increase in the number of heterogeneous Internet of Things (IoT) devices that populate everyday life environments brings new challenges to the full exploitation of the computation, memory, sensing, and actuation resources associated to them. In this context, device virtualization solutions and platforms may definitely play a key role in enabling the desired tradeoff between flexibility and performance. This paper focuses on lightweight virtualization technologies for IoT devices, suitably thought to effectively deploy new integrated applications and to create a novel distributed and virtualized ecosystem. Two different frameworks for container-based IoT service provisioning are compared, the one based on a direct interaction between two cooperating devices and the other based on the presence of a manager supervising the operations between cooperating devices forming a cluster. In the latter case, accounting for the growing impetus to move intelligence toward the edge of the network, management features are implemented at the network access point to provide short latency responses. We also introduce the outcomes of a thorough performance evaluation campaign conducted via a real IoT testbed. The measurements, performed by accounting for the constraints of typical IoT nodes, shed light on the actual feasibility of container-based IoT frameworks.	abstraction layer;access network;computation;ecosystem;interaction;internet of things;network access point;overhead (computing);performance evaluation;population;provisioning;scalability;testbed;wireless access point;x86 virtualization	Roberto Morabito;Ivan Farris;Antonio Iera;Tarik Taleb	2017	IEEE Internet of Things Journal	10.1109/JIOT.2017.2714638	virtualization;network access point;distributed computing;computer network;latency (engineering);edge device;cloud computing;computer science;testbed;provisioning;edge computing	Mobile	-16.762293419407523	85.3805726321574	24859
00b7a23cf50bad3c0e0c5e2ff6bdc2832f41ccad	dpdk open vswitch performance validation with mirroring feature	virtualisation cloud computing computer centres linux public domain software software defined networking telecommunication computing telecommunication network management virtual machines;kernel throughput ports computers hardware linux standards;kernel;standards;port flow mirroring open vswitch ovdk nfv sdn;linux;ports computers;dpdk open vswitch performance validation virtualized network architecture flow forwarding port mirroring flow mirroring ovdk data plane development kit linux distributions open source software ovs network management forwarding functions virtual switches data center virtualization technology virtual machine vnf virtual network functions cloud computing software based network architecture hardware based network architecture sdn software defined network nfv network function visualization;throughput;hardware	Network Function Visualization (NFV) and Software Defined Network (SDN) currently play a key role to transform the network architecture from hardware-based to software-based. Along with cloud computing, NFV and SDN are moving network functions from dedicated hardware to software implementation (Virtual Network Functions - VNF), on Virtual Machine (VM) or other virtualization technology such as containers, on top of a virtualized platform in the Cloud. To connect the VNFs, hosted in the same Data Center (DC) or across multiple DCs, virtual switches are required. Besides forwarding functions, virtual switches can be configured to mirror traffics for network management needs. Among the existing virtual switch solutions, Open vSwitch (OVS) is the most known and used. OVS is open source, and included in most of the existing Linux distributions. However, OVS performance in terms of throughput for smaller packets is very smaller than of line rate of the interface. To overcome this limitation, OVS was ported to Data Plane Development Kit (DPDK), namely OVDK. The latter achieves an impressive line rate throughput across physical interfaces. In this paper, we present the result of OVDK performance test when flow and port mirroring are activated, which was not tested so far. The performance test focuses on two parameters, throughput and latency in OVDK; allowing to validate the use of OVDK for flow forwarding and network management in the envisioned virtualized network architecture.	algorithm;cloud computing;dpdk / dpdk.org;data center;disk mirroring;forwarding plane;hardware virtualization;linux;network architecture;network function virtualization;network switch;open platform for nfv;open vswitch;open-source software;performance;real-time operating system;real-time transcription;software-defined networking;throughput;virtual machine;x86 virtualization	Sivasothy Shanmugalingam;Adlen Ksentini;Philippe Bertin	2016	2016 23rd International Conference on Telecommunications (ICT)	10.1109/ICT.2016.7500387	embedded system;throughput;kernel;computer science;operating system;linux kernel;computer network	Networks	-14.86192650372831	82.5926568529723	24867
c3f6059efe4e8e1628fc272aa840979413c92f00	a novel task scheduling algorithm based on dynamic critical path and effective duplication for pervasive computing environment	pervasive computing;task scheduling;dynamic critical path;effective task duplication	In order to effectively utilize massive heterogeneous resources and provide transparent computing capability to upper applications, task scheduling as the key issue of pervasive computing system becomes significantly important. Previous proposed priority and duplication based task scheduling algorithms, which can be applied in pervasive computing environment, usually have following limitations: critical path cannot be calculated accurately while neglecting the effect of resource availability in scheduling; in duplication based resource allocation stage, duplications without restriction would lead to some negative effects on final schedule length (SL). For the purpose of solving these problems, a novel task scheduling algorithm based on dynamic critical path (DCP) and effective duplication, called DCPED, is presented in this paper. In DCPED, a more accurate DCP calculation method which takes resource availability into account is introduced. Meanwhile an effective task duplication strategy is proposed to eliminate ineffective duplications and make an optimized schedule result by using space compression technique and dynamic critical path length (DCPL) based evaluation technique respectively. Finally, simulation results show that DCPED can outperform previous algorithms significantly in NSL and speedup rate metrics. Especially, it is very effective for utilizing computing resources and scheduling the fine-grain and large-scale workflow applications in pervasive computing system. Copyright © 2008 John Wiley & Sons, Ltd.	algorithm;critical path method;scheduling (computing);ubiquitous computing	Junzhou Luo;Fang Dong;Jiuxin Cao;Aibo Song	2010	Wireless Communications and Mobile Computing	10.1002/wcm.717	workflow;availability;real-time computing;simulation;metric;dynamic priority scheduling;resource allocation;computer science;operating system;critical path method;distributed computing;scheduling;ubiquitous computing;gene duplication	EDA	-14.82686040214462	60.99743241846327	24932
5af04736a521eb22372fb6baaa895709dcffc1a0	partial path protection for wdm networks: end-to-end recovery using local failure information	greedy approach partial path protection wdm networks end to end recovery local failure information end to end backup paths restoration path network failures protection path dynamic call by call model blocking probability performance metric capacity efficiency measurement batch call arrivals shortest path routing primary paths;probability wavelength division multiplexing optical fibre networks telecommunication network reliability;wdm network;probability;telecommunication network reliability;protection wdm networks laboratories electronic mail wavelength measurement wavelength routing telecommunication traffic traffic control capacity planning costs;performance metric;shortest path routing;optical fibre networks;link failure;efficiency measurement;wavelength division multiplexing	In this paper, we propose a new protection scheme, which we term partial path protection (PPP), to select endto-end backup paths using local information about network failures. PPP designates a different restoration path for every link failure on each primary path. PPP also allows reuse of operational segments of the original primary path in the protection path. A novel approach used in this paper is that of a dynamic call-by-call model with blocking probability as the performance metric, this model is in contrast with traditional capacity-efficiency measurement for batch call arrivals. Additionally, we show that a simple method based on shortest path routing for which primary paths are selected first is more effective than a greedy approach that minimizes, for each call arrival, the number of wavelengths used by the primary and backup path jointly.	backup;blocking (computing);circuit restoration;end-to-end principle;erlang (unit);greedy algorithm;path protection;routing;shortest path problem;wavelength-division multiplexing	Hungjen Wang;Eytan Modiano;Muriel Médard	2002		10.1109/ISCC.2002.1021753	private network-to-network interface;constrained shortest path first;any-angle path planning;telecommunications;average path length;probability;distributed computing;wavelength-division multiplexing;statistics;computer network	Metrics	-7.3974671610934175	81.31220522817057	24958
c8bcf651b89e46cb4a496783c0cf0cd1cae18d46	fog server deployment considering network topology and flow state in local area networks		Fog computing can reduce service response time and dramatically reduce network traffic. To take advantage of fog computing, a fog server must be deployed on the network device near the user to handle the service. However, there has been little research on where to deploy the fog server. In fact, there are so many things to consider in deploying fog servers. In this paper, we analyze the challenges when IoT and fog computing are combined. Then, we describe the fog server deployment algorithm considering the data movement distance and computing resource in fog computing environment, and see how it is deployed by simple example. Finally, we verified through experiment that the proposed fog server deployment algorithm can reduce service response time and overall network traffic.	algorithm;fog computing;network topology;network traffic control;networking hardware;response time (technology);server (computing);software deployment	Jung-Hoon Lee;Sang-Hwa Chung;Won-Suk Kim	2017	2017 Ninth International Conference on Ubiquitous and Future Networks (ICUFN)	10.1109/ICUFN.2017.7993872	local area network;networking hardware;computer network;software deployment;computer science;distributed computing;network topology;server;response time;internet of things	HPC	-15.856306732276952	80.93127103293135	24967
32ade9a917d59c4e1cecd605686d87e3e91e9c92	ibgp confederation provisioning	autonomous system;large scale confederation;traditional ibgp topology;physical topology;bgp network;ibgp confederation provisioning;optimal design;effective methodology;large scale confederation deployment;appropriate confederation design;large scale	This paper proposes an optimization method for the design of large scale confederation based BGP networks. We propose a graph based model and an associated metric to evaluate the reliability of large scale autonomous systems. We propose and validate an effective methodology to find the optimal design for a given physical topology. According to our experiments, we consider that replacing the traditional IBGP topology by an appropriate confederation design could increase at the same time the scalability and the reliability into the domain. Our work might be a step further towards a large scale confederation deployment.	autonomous system (internet);border gateway protocol;cyber resilience;experiment;mathematical optimization;optimal design;provisioning;randomized algorithm;scalability;semantic network;software deployment	Mohamed Nassar;Radu State;Olivier Festor	2007			network management;simulation;computer science;optimal design;computer security;computer network	EDA	-9.216431383285009	78.87963239424853	24981
c600f82b46e4dfd6cf7d164bb023a83f35d436ec	supporting storage configuration for i/o intensive workflows	distributed storage systems;performance prediction	System provisioning, resource allocation, and system configuration decisions for I/O-intensive workflow applications are complex even for expert users. Users face choices at multiple levels: allocating resources to individual sub-systems (e.g., the application layer, the storage layer) and configuring each of these optimally (e.g., replication level, chunk size, caching policies in case of storage) all having a large impact on overall application performance. This paper presents our progress on addressing the problem of supporting these provisioning, allocation and configuration decisions for workflow applications. To enable selecting a good choice in a reasonable time, we propose an approach that accelerates the exploration of the configuration space based on a low-cost performance predictor that estimates total execution time of a workflow application in a given setup. Our evaluation shows that: (i) the predictor is effective in identifying the desired system configuration, (ii) it can scale to model a workflow application run on an entire cluster, while (iii) using over 2000x less resources (machines x time) than running the actual application.	input/output;kerrison predictor;osi model;provisioning;run time (program lifecycle phase);system configuration	Lauro Beltrão Costa;Samer Al-Kiswany;Hao Yang;Matei Ripeanu	2014		10.1145/2597652.2597679	parallel computing;real-time computing;simulation;computer science;operating system;distributed computing;workflow management system	HPC	-22.29218388588874	60.52393099441541	25009
48b38f50a017b56632a451788099c94f45c8f63b	sip as a universal communication bus: a methodology and an experimental study	pervasive computing protocols telephony joining processes zigbee middleware streaming media temperature measurement payloads communications society;ubiquitous computing personal area networks signalling protocols system buses;pervasive computing;native sip entities sip protocol universal communication bus pervasive computing serial based sensors zigbee devices x10 devices pda;system buses;software component;ubiquitous computing;personal area networks;signalling protocols	This paper describes a methodology and a programming support that use the SIP protocol as a universal communication bus in pervasive computing environments. In doing so, our work enables homogeneous communications between heterogeneous distributed entities. We present a classification of a wide variety of entities in terms of features, capabilities and network connectors. Based on this classification, a methodology and a programming support are described for connecting entities on the SIP communication bus. This work has been validated by applications using the SIP communication bus to coordinate widely varying entities, including serial-based sensors (RS232, 1-Wire), ZigBee devices, X10 devices, PDA, native SIP entities, and software components.	1-wire;border gateway protocol;bus (computing);component-based software engineering;entity;experiment;home automation;personal digital assistant;rs-232;sensor;ubiquitous computing;x10	Benjamin Bertran;Charles Consel;Wilfried Jouve;Hongyu Guan;Patrice Kadionik	2010	2010 IEEE International Conference on Communications	10.1109/ICC.2010.5502591	embedded system;sip trunking;computer science;component-based software engineering;operating system;distributed computing;ubiquitous computing;computer network	Robotics	-24.915872497389348	84.34753097261404	25129
cbb539358691e17071e74f2481113e051826c05e	named data networking for software defined vehicular networks		Named data networking and software defined networking share mutual courage in changing legacy networking architectures. In the case of NDN, IP-based communication has been tackled by naming the data or content itself, while SDN proposes to decouple the control and data planes to make various services manageable without physical interference with switches and routers. Both NDN and SDN also support communication via heterogeneous interfaces and have been recently investigated for vehicular networks. Na�ve VNs are based on the IP-based legacy, which is prone to several issues due to the dynamic network topology among other factors. In this article, we first see both SDN and NDN enabled VNs from a bird's eye view, and for the very first time, we present an architecture that combines SDN functionalities within VNs to retrieve the required content using NDN. Moreover, we discuss a number of current research challenges and provide a precise roadmap that can be considered for the research community to jointly address such challenges.	bird's-eye view;interference (communication);network switch;network topology;numerical aperture;software-defined networking	Syed Hassan Ahmed;Safdar Hussain Bouk;Dongkyun Kim;Danda B. Rawat;Houbing Song	2017	IEEE Communications Magazine	10.1109/MCOM.2017.1601137	networking hardware;computer network;vehicular ad hoc network;distributed computing;architecture;wireless;software;computer science;dynamic network analysis;delay-tolerant networking;software-defined networking	Mobile	-13.975119083865838	85.23302493141452	25185
33baec7311974b244bae84739667a719355924b8	a modular correctness proof of ieee 802.11i and tls	access point;wireless network;protocol composition logic;group communication;security proof;mutual authentication;tls;ieee 802 11i;proof of correctness;failure recovery;correctness proof	The IEEE 802.11i wireless networking protocol provides mutual authentication between a network access point and user devices prior to user connectivity. The protocol consists of several parts, including an 802.1X authentication phase using TLS over EAP, the 4-Way Handshake to establish a fresh session key, and an optional Group Key Handshake for group communications. Motivated by previous vulnerabilities in related wireless protocols and changes in 802.11i to provide better security, we carry out a formal proof of correctness using a Protocol Composition Logic previously used for other protocols. The proof is modular, comprising a separate proof for each protocol section and providing insight into the networking environment in which each section can be reliably used. Further, the proof holds for a variety of failure recovery strategies and other implementation and configuration options. Since SSL/TLS is widely used apart from 802.11i, the security proof for SSL/TLS has independent interest.	access network;communications protocol;correctness (computer science);formal proof;group key;ieee 802.11i-2004;ieee 802.1x;modular programming;mutual authentication;network access point;protocol composition logic;provable security;session key;transport layer security;wireless access point	Changhua He;Mukund Sundararajan;Anupam Datta;Ante Derek;John C. Mitchell	2005		10.1145/1102120.1102124	yak;communication in small groups;computer science;authentication protocol;wireless network;distributed computing;transport layer security;computer security;computer network	Security	-23.28840477779125	86.7387070773629	25285
431968fb3593e182d019f1561064f1f9bd49a803	dsa keys and sigs in the domain name system (dns)	domain name system;resource record	Internet-Drafts are draft documents valid for a maximum of six months. Internet-Drafts may be updated, replaced, or obsoleted by other documents at any time. It is not appropriate to use Internet-Drafts as reference material or to cite them other than as a ''working draft'' or ''work in progress.'' To learn the current status of any Internet-Draft, please check the 1id-abstracts.txt listing contained in the Internet-Drafts Shadow Directories on ds.internic.net (East USA), ftp.isi.edu (West USA), Abstract A standard method for storing US Government Digital Signature Algorithm keys and signatures in the Domain Name System is described which utilizes DNS KEY and SIG resource records.	algorithm;digital signature;document;type signature	Donald E. Eastlake	1999	RFC	10.17487/RFC2536	root name server;wildcard dns record;naptr record;cname record;fully qualified domain name;computer science;dns spoofing;dns zone;internet privacy;zone file;name server;world wide web;computer security;nsupdate;domain name system	Security	-26.543450540282485	88.33226303307794	25291
9bf7d821a1b47436fc9ef524686438da1d4bf1f3	experimental responsiveness evaluation of decentralized service discovery	location service;loss measurement;protocols;domain name system;ad hoc wireless network;domain name system experimental responsiveness evaluation decentralized service discovery ad hoc scenarios ad hoc wireless networks autoconfiguring service networks zeroconf technologies;delay analytical models computer networks publishing time factors wireless networks performance evaluation domain name system mobile communication mobile computing;autoconfiguring service networks;software performance evaluation distributed processing;experimental responsiveness evaluation;packet loss;distributed processing;software performance evaluation;zeroconf technologies;bridges;ad hoc scenarios;decentralized service discovery;ad hoc networks;linux;ip networks;ad hoc wireless networks;service discovery;unicast	Service discovery is a fundamental concept in service networks. It provides networks with the capability to publish, browse and locate service instances. Service discovery is thus the precondition for a service network to operate correctly and for the services to be available. In the last decade, decentralized service discovery mechanisms have become increasingly popular. Especially in ad-hoc scenarios - such as ad-hoc wireless networks - they are an integral part of auto-configuring service networks. Albeit the fact that auto-configuring networks are increasingly used in application domains where dependability is a major issue, these environments are inherently unreliable. In this paper, we examine the dependability of decentralized service discovery. We simulate service networks that are automatically configured by Zeroconf technologies. Since discovery is a time-critical operation, we evaluate responsiveness - the probability to perform some action on time even in the presence of faults - of domain name system (DNS) based service discovery under influence of packet loss. We show that responsiveness decreases significantly already with moderate packet loss and becomes practicably unacceptable with higher packet loss.	application domain;browsing;client (computing);dependability;enumerated type;floor and ceiling functions;hoc (programming language);mathematical optimization;network packet;precondition;real life;responsiveness;service discovery;simulation;time complexity;window of opportunity;zero-configuration networking	Andreas Dittrich;Felix Salfner	2010	2010 IEEE International Symposium on Parallel & Distributed Processing, Workshops and Phd Forum (IPDPSW)	10.1109/IPDPSW.2010.5470861	computer science;distributed computing;service discovery;computer security;computer network	Metrics	-12.491827272304414	77.04753402570898	25300
092661b7ce6b54abd75f5626fe9b703968f9b3a1	a framework for self-management of hybrid wireless networks using autonomic computing principles	evolution methods;self optimization;biology computing;optimisation;wireless networks;biological system;network design;communication system;service provisioning strain;ad hoc multihop routing;high data rate service;adaptive wireless network architecture;routing;cellular radio;self management approach;wireless network;cellular system;high data rate;autonomic computing principle;cellular networks;multimedia application;ad hoc network;computer networks;fuzzy logic;multimedia computing;computer architecture;spread spectrum communication;self optimization autonomic computing principle mobile subscriber service provisioning strain multimedia application high data rate service adaptive wireless network architecture cellular network ad hoc multihop routing radio resource heterogeneity biological system self management approach;telecommunication network routing;adaptive systems;base station;wireless networks computer networks land mobile radio cellular systems computer architecture cellular networks routing biology computing capacitive sensors adaptive systems spread spectrum communication;mobile subscriber;subscriber loops;radio resource heterogeneity;cellular network;biological systems;ad hoc networks;genetic algorithm;land mobile radio cellular systems;autonomic computing;service provision;capacitive sensors;core network;neural network;telecommunication network management;subscriber loops telecommunication network routing cellular radio ad hoc networks telecommunication network management optimisation multimedia computing adaptive systems	The dramatic increase in the number of mobile subscribers has put a significant resource and service provisioning strain on current cellular networks in particular in terms of multimedia and high-data rate service provision. Hybrid wireless networks, which is a novel scalable and adaptive wireless network architecture utilizing a mixture of cellular and ad hoc multi-hop routing, facilitates cellular network design with small cell systems without having to wire a large number of base stations into a core network. However, this new network design has drawbacks in terms of routing complexity, radio resource heterogeneity and network infrastructure design growth. Traditional centralised system administration methods become too inflexible to result in a manageable cellular system. A recently introduced concept-autonomic computing, based on stimulation from biological systems, may provide a remedy to the state of unmanageability. The Autonomic computing paradigm, recently coined autonomic communications, when applied to communication systems and networks, enables self-management, which is composed of self-protecting, self-healing, self-configuring and self-optimizing components. This self-management is not necessarily novel as technologies such as neural networks, fuzzy logic, genetic algorithms and evolutional methods have already been proposed to facilitate limited self-configuration and self-optimization when embedded with cellular and ad hoc networks. However, a structure or framework has been lacking so far. In this paper we propose an architecture for a framework of autonomic computing based on policies for a hybrid wireless network and investigate the merits of each of its functions.	ac (complexity);artificial neural network;autonomic computing;biological system;broadcast relay station;centralisation;data rate units;embedded system;fuzzy logic;genetic algorithm;hoc (programming language);hybrid system;mathematical optimization;network architecture;network planning and design;programming paradigm;provisioning;radio resource management;requirement;routing;scalability;self-management (computer science);system administrator;test-driven development;testbed	Chong Shen;Dirk Pesch;James Irvine	2005	3rd Annual Communication Networks and Services Research Conference (CNSR'05)	10.1109/CNSR.2005.8	multi-frequency network;wireless ad hoc network;cellular network;wireless wan;heterogeneous network;telecommunications;computer science;radio resource management;wireless network;distributed computing;computer network;autonomic computing	Mobile	-13.801243699750158	87.89480284471976	25311
d4cf1aff0f64a03dbea5d515844b4a07c3edb4f8	a min-cover based controller placement approach to build reliable control network in sdn	network manageability min cover based controller placement approach sdn software defined network centralized control plane multiple distributed controllers control network reliability propagation delay;telecommunication network reliability;min cover sdn controller placement problem network reliability;propagation delay;software defined networking computer network reliability;switches telecommunication network reliability delays propagation delay;switches;delays	Software defined network (SDN) develops a centralized control plane to manage the whole network. If the scale of the network is large, it is necessary to deploy multiple distributed controllers. In SDN, a switch can only work by relying on flow tables received from its controller. Therefore, controller placement is an important problem to keep the switches working efficiently and improve the reliability of the control network, which consists of controllers, switches and the communication paths between them. However, the existing controller placement approaches are not effective or do not consider the network reliability and the required delay between switches and controllers at the same time. In order to ensure the reliability of the control network and meet the required propagation delay, a min-cover based controller placement approach is proposed. Two metrics are proposed to measure the reliability of a control network, and the definitions of neighborhood and min-cover are provided, based on which the approach try to use less controllers to achieve the reliability and low delay of the control network while guaranteeing the manageability of the network. Simulations show that min-cover based approach can use as less controllers as possible to ensure the reliability of control network and satisfy the required delay at the same time. Moreover, the approach has steadily good performance in networks of different scales and connectivity.	centralized computing;computer simulation;control plane;multistage interconnection networks;propagation delay;software propagation;software-defined networking;vertex cover	Qinghong Zhong;Ying Wang;Wenjing Li;Xuesong Qiu	2016	NOMS 2016 - 2016 IEEE/IFIP Network Operations and Management Symposium	10.1109/NOMS.2016.7502847	propagation delay;network traffic control;real-time computing;intelligent computer network;network architecture;network management station;network switch;computer science;network simulation;distributed computing;network delay;queuing delay;computer network	Embedded	-11.635870233814243	82.77615089583014	25346
411c544a8f6e4bff8f70656d70250ded8cff015c	a multi-criteria network-aware service composition algorithm in wireless environments	wireless networks;service composition;network awareness;quality of service qos;algorithms	Much work has been conducted to design effective and efficient algorithms for Quality of Service (QoS)aware service algorithms in recent years. With the advent of high-capacity smart mobile devices and ubiquitous presence of wireless communications, service composition in wireless environments starts picking up momentum. While the majority of the know-how from service composition in wired fixed networks is still applicable to service composition in wireless environments, wireless networks also impose their own features that need to be specifically taken into consideration during service engineering process. To this end, this paper proposes a network-aware algorithm for service composition where network features such as network availability and delay are considered during service composing process. These network metrics incorporate with other non-network QoS parameters such as price and reputation, that are usually utilized in service composition in the current literature. Together these metrics specify the QoS constraints that need to be satisfied by a successful service composition, which is formulated as a multi-dimension multi-choice 0–1 knapsack problem (MMKP) in this paper. The evaluation results show the effectiveness of the proposed algorithm and also indicate the impact of the network parameters such as delay on the performance of service composition. 2012 Elsevier B.V. All rights reserved.	algorithm;internet backbone;mobile device;quality of service;scalability;simulation;smart device	Yuansheng Luo;Kun Yang;Qiang Tang;Jianming Zhang;Bing Xiong	2012	Computer Communications	10.1016/j.comcom.2012.02.009	best-effort delivery;service set;real-time computing;mobile qos;wireless wan;wireless site survey;differentiated service;computer science;wireless network;distributed computing;service discovery;tiered service;data as a service;customer service assurance;computer network	Mobile	-13.479427202052754	87.32339213973582	25351
622a803129a24f0ab74cc9d4230f2ad28d6ff8ee	cross-monotonic multicast	budget balance;optimal flow routing;graph theory;random graph;optimisation;two stage linear optimization model;multicast communication;two stage linear optimization model cross monotonic multicast group strategy proofness multicast schemes optimal flow routing cross monotonic cost sharing budget balance random graph theory optimal multicast cost;routing cost function multicast algorithms algorithm design and analysis graph theory robustness cost accounting communications society computer science game theory;probabilistic method;routing;optimal multicast cost;monotone scheme;group strategy proofness;satisfiability;cross monotonic multicast;receivers;upper bound;cost accounting;multicast schemes;computational modeling;telecommunication network routing;network configuration;games;linear optimization;optimization;random graph theory;cost sharing;cross monotonic cost sharing;algorithm design and analysis;telecommunication network routing graph theory multicast communication optimisation	In the routing and cost sharing of multicast towards a group of potential receivers, cross-monotonicity is a property that states a user's payment can only be smaller when serviced in a larger set. Being cross-monotonic has been shown to be the key in achieving group-strategyproofness. We study multicast schemes that target optimal flow routing, cross-monotonic cost sharing, and budget balance. We show that no multicast scheme can satisfy these three properties simultaneously, and resort to approximate budget balance instead. We derive both positive and negative results that complement each other for directed and undirected networks. We show that in directed networks, no cross-monotonic scheme can recover a constant fraction of optimal multicast cost. We provide a simple scheme that does achieve 1/k-budget-balance, where k is the number of receivers. Using a probabilistic method rooted in random graph theory, we prove an upper-bound of 2/radic(k) for the budget balance ratio. For undirected networks, we derive a constant upper-bound of 1/2 instead. We further apply a smooth dual growing technique to design a cross- monotonic scheme that recovers k+1/2kzeta of optimal multicast cost in undirected networks, where zeta is a network-dependent parameter close to 1. This is almost tight against the upper-bound |. We finally present a two-stage linear optimization model that pursues maximum budget balance in any given specific network, with trade-off in complexity. Optimization results in various network configurations confirm the theoretically established bounds.	approximation algorithm;complement (complexity);flow network;graph (discrete mathematics);graph theory;linear programming;mathematical optimization;multicast;program optimization;provisioning;random graph;requirement;routing;simulation	Zongpeng Li	2008	IEEE INFOCOM 2008 - The 27th Conference on Computer Communications	10.1109/INFOCOM.2008.219	random graph;games;algorithm design;mathematical optimization;routing;computer science;graph theory;probabilistic method;theoretical computer science;mathematics;distributed computing;upper and lower bounds;computational model;computer network;cost accounting;satisfiability	Theory	-5.46307019935942	80.23557979581044	25359
54f50765611c1df449043aefe21c1ef4d8c86d4d	a content-based locality-aware collaborative p2p lookup algorithm	groupware;autonomous system;peer to peer computing semantics network topology routing delay object recognition clustering algorithms;p2p;interest p2p network autonomous system;numerical simulation experiments content based locality aware collaborative p2p lookup algorithm structured systems classical routing algorithms logic hops peer to peer networks p2p networks physical network topology logical network topology self organizing content aware collaborative p2p network clp2p;autonomic system;network topology;long distance;p2p network;success rate;routing algorithm;overlay network;self organization;p2p networks;peer to peer computing;interest;telecommunication network topology;table lookup;peer to peer;telecommunication network topology groupware peer to peer computing table lookup;numerical simulation	In structured systems, classical routing algorithms such as Chord, Pastry can always find resources within lower logic hops. However, they are independent of the physical network, so that they often find resources in a long delay due to undesirably long distances in some physical links. Resources are always stored in the simple form of <;key,value>; pair in these systems. Similarly, it will result in a long delay due to not considering the semantic properties of data objects and the data searched by clients. In order to solve the problems in peer-to-peer (P2P) networks, such as the mapping problem of mismatching between physical and logical network topology, and the problem of resource storage. Based on self-organizing content-aware collaborative P2P network, a new content-based locality-aware collaborative P2P lookup algorithm (CLP2P) is presented, which comprehensively considers the users' physical locations and interests. It maps nodes of physical proximity and same interest to proximal location in overlay network, and stores the resources on the interested nodes. The proposed algorithm has been assessed through a collection of numerical simulation experiments and the results show that the average hop count and the average routing latency among nodes are reduced, the performance of average resource search success rate is kept high, and the average resource search latency is reduced.	algorithm;experiment;internet backbone;key (cryptography);locality of reference;lookup table;map;network topology;network traffic control;numerical analysis;numerical weather prediction;organizing (structure);overlay network;peer-to-peer;response time (technology);routing;self-organization;simulation	Mei Yu;Wenglin Wang;Shuang Mei	2012	2012 9th International Conference on Fuzzy Systems and Knowledge Discovery	10.1109/FSKD.2012.6234147	computer simulation;self-organization;overlay network;computer science;autonomous system;interest;theoretical computer science;peer-to-peer;distributed computing;network topology;computer network	HPC	-12.731296567157594	74.95516656965644	25400
2646b0e8533589d39065d468632fb83caa3707b4	cost minimization for computational applications on hybrid cloud infrastructures	constrained optimization;distributed systems;cloud computing	We address the problem of task planning on multiple clouds formulated as a mixed integer nonlinear programming problem (MINLP). Its specification with AMPL modeling language allows us to apply solvers such as Bonmin and Cbc. Our model assumes multiple heterogeneous compute and storage cloud providers, such as Amazon, Rackspace, GoGrid, ElasticHosts and a private cloud, parameterized by costs and performance, including constraints on maximum number of resources at each cloud. The optimization objective is the total cost, under deadline constraint. We compute the relation between deadline and cost for a sample set of dataand compute-intensive tasks, representing bioinformatics experiments. Our results illustrate typical problems when making decisions on deployment planning on clouds and how they can be addressed using optimization techniques.	ampl;bioinformatics;cloud computing;constraint logic programming;experiment;mathematical optimization;modeling language;nonlinear programming;software deployment	Maciej Malawski;Kamil Figiela;Jarek Nabrzyski	2013	Future Generation Comp. Syst.	10.1016/j.future.2013.01.004	mathematical optimization;constrained optimization;parallel computing;cloud computing;computer science;theoretical computer science;operating system;distributed computing	Embedded	-19.658136154922538	64.4337469545403	25403
da0741a4d49eb6d16282e922cd371d42da9b7556	a workflow scheduling technique using genetic algorithm in spot instance-based cloud	spot instances;kpubs;kpubs org;fault tolerance;workflow;genetic algorithm;price history;cloud computing	Cloud computing is a computing paradigm in which users can rent computing resources from service providers according to their requirements. A spot instance in cloud computing helps a user to obtain resources at a lower cost. However, a crucial weakness of spot instances is that the resources can be unreliable anytime due to the fluctuation of instance prices, resulting in increasing the failure time of users’ job. In this paper, we propose a Genetic Algorithm (GA)-based workflow scheduling scheme that can find the optimal task size of each instance in a spot instance-based cloud computing environment without increasing users’ budgets. Our scheme reduces total task execution time even if an out-of-bid situation occurs in an instance. The simulation results, based on a before-and-after GA comparison, reveal that our scheme achieves performance improvements in terms of reducing the task execution time on average by 7.06%. Additionally, the cost in our scheme is similar to that when GA is not applied. Therefore, our scheme can achieve better performance than the existing scheme, by optimizing the task size allocated to each available instance throughout the evolutionary process of GA.	genetic algorithm	Daeyong Jung;Taeweon Suh;Heon-Chang Yu;Joon-Min Gil	2014	TIIS	10.3837/tiis.2014.09.010	workflow;fault tolerance;real-time computing;genetic algorithm;cloud computing;computer science;operating system;machine learning;data mining;distributed computing	EDA	-18.48964594781182	62.443347765048784	25453
48b9c296811c3a7adeabda7a4d056df216e3a1ce	periodic resource integration	periodic resource;real time scheduling;multi resource scheduling	Developed an integration method for two arbitrary fixed-pattern periodic resources.Provided the lower and upper bounds of the available time of an integrated resource.Provided a theoretical schedulability analysis for an integrated periodic resource.Provided an empirical study of task schedulability on an integrated resource. Scheduling periodic real-time tasks on multiple periodic resources is an emerging research issue in the real-time scheduling community and has drawn increased attention over the last few years. This paper studies a sub-category of the scheduling problem which focuses on scheduling a periodic task on multiple periodic resources where none of these resources have sufficient capacity to support the task. Instead of splitting the task into sub-tasks, which is not always practical in real systems, we integrate resources together to jointly support the task. First, we develop a method to integrate two fixed but arbitrary pattern periodic resources into an equivalent periodic resource. Second, for two periodic resources with unknown but fixed resource occurrence patterns, we give the lower and upper bounds of the available time provided by an integrated periodic resource within a period. Third, we present theoretical and empirical analysis on the schedulability of a non-splittable periodic task on two periodic resources and their integrated periodic resource.		Xiayu Hua;Zhijun Li;Hao Wu;Chunhui Guo;Shangping Ren	2015	Journal of Systems and Software	10.1016/j.jss.2015.08.050	real-time computing;computer science;distributed computing	OS	-9.44514178815739	61.90913216165005	25536
1d008742a5d48bb6922af96932f937748d0429f3	joint routing and channel assignment in multi-channel wireless infrastructure networks	wireless channels;wireless network;exact solution;communication complexity;satisfiability;telecommunication network routing;routing throughput bandwidth wireless networks computer networks costs transceivers interference constraints directional antennas polynomials;routing algorithm network routing multichannel wireless infrastructure network directional antenna path assignment channel assignment path bandwidth link bandwidth channel discontinuity constraint graph expansion technique minimum cost path polynomial time minimum cost perfect matching algorithm;polynomial time;routing algorithm;wireless channels channel allocation communication complexity directive antennas telecommunication network routing;directional antenna;channel allocation;directive antennas;channel assignment;perfect match	"""Multi-channel wireless networks are increasingly being employed as infrastructure networks in metro areas. In addition, nodes in these networks employ directional antennas to improve spatial throughput. In such networks, given a source and destination, it is of interest to compute a path and channel assignment on every link in the path such that the path bandwidth is the same as that of the link bandwidth. Such a path must satisfy the constraint that no two consecutive links on the path are assigned the same channel, referred to as """"channel discontinuity constraint."""" In this paper, we develop two graph expansion techniques to compute the minimum cost path between a given node pair that satisfy the channel discontinuity constraint. The first expansion provides the exact solution in polynomial time using minimum cost perfect matching algorithm. The second expansion results in a lesser complexity algorithm compared to the former and is amenable to distributed implementation, while it may result in infeasible paths at times. Through extensive simulations, we study the effectiveness of the routing algorithms developed based on the two expansion techniques and the benefits of employing the minimum cost perfect matching based solution. We show that the lesser complexity algorithm may not be able to compute a path for less than 2% of the calls in the networks considered."""	bandwidth (signal processing);exact algorithm;interference (communication);matching (graph theory);mike lesser;reflections of signals on conducting lines;routing;shortest path problem;simulation;throughput;time complexity	Sandeep Kour Ahuja;Abishek Gopalan;Srinivasan Ramasubramanian	2008	2008 5th International Conference on Broadband Communications, Networks and Systems	10.1109/BROADNETS.2008.4769106	time complexity;mathematical optimization;fast path;computer science;directional antenna;wireless network;communication complexity;distributed computing;computer network;satisfiability	Mobile	-4.673761355648178	82.27040879417241	25552
f9bdf32dd2962be4fbd006b0a37aeaf0ce99a515	role based cross-layer communities on wmn	cross layer	The community notion can be exploited as a rational concept leading users to cooperate in sharing resources on Wireless Mesh Networks. We propose a novel concept for self-organizing networks, where multiple entities (network elements or users) collaborate to achieve common goals, and in particular, to establish the basic connectivity and service delivery infrastructures. The resulting architecture is based on wireless mesh communications, with different entities taking different roles in the communities in a cross-layer approach. These communities can collaborate, leading to increasingly complex and geographically extended scenarios.	entity;itil;mesh networking;organizing (structure);self-organization;wireless mesh network	João Paulo Barraca;Susana Sargento;Rui L. Aguiar	2007			computer science	HCI	-18.820010785635674	80.87773196776918	25652
c15349b55f040b5b0c923249bca740c010c93adc	management of application qos-level adaptation for real-time systems		Allocating computing resources to various applications running on distributed computing platforms in order to satisfy real-time quality-of-service (QoS) requirements is an important problem, as is evident from a recent NASA research challenge problem concerning an autonomous hot-spot convergence system for the next-generation constellation-based satellite sensor webs. This paper presents a new resource management mechanism based on service levels and utility, and motivated by the hot-spot example, to address this problem. Existing approaches to adaptive resource and QoS management typically perform either reallocation of resources or adaptation of application QoS levels in response to dynamic environment changes. While success has been achieved with both of these approaches, this paper demonstrates the potential synergy of implementing both types of techniques. A proof-of-concept implementation is shown and our initial experimental results are analyzed.	quality of service;real-time operating system;real-time transcription	Shikha Jain;Lonnie R. Welch;Barbara Pfarr;David M. Chelberg;Carl Bruggeman;David Fleeman;David Parrott;Zhenyu Tan;Meagan L McCoy;Chris Shuler	2002	Scalable Computing: Practice and Experience		simulation;engineering;operations management;management science	Embedded	-27.626600564742848	62.13814388330058	25873
f962bdf37a092146fd7fae97d454970719fca09f	on satisfying timing constraints in hard-real-time systems	hard-real-time systems;large complex hard-real-time system;major concern;available algorithm;timing constraint;satisfying timing constraints;mathematical scheduling problem;pre-run-time scheduling;correctness;embedded systems;formal verification;kernel;concurrency	We explain why pre-run-time scheduling is essential if we wish to guarantee that timing constraints will be satisfied in a large complex hard-real-time system. We examine some of the major concerns in pre-run-time scheduling and consider what formulations of mathematical scheduling problems can be used to address those concerns. A purpose of this paper is to provide a guide to the available algorithms.	algorithm;real-time computing;real-time locating system;real-time transcription;run time (program lifecycle phase);scheduling (computing)	Jia Xu;David Lorge Parnas	1991	IEEE Trans. Software Eng.	10.1145/125083.123066	embedded system;parallel computing;real-time computing;real-time operating system;dynamic priority scheduling;computer science;operating system;scheduling	Embedded	-9.300013215702148	60.68497039075051	25899
3ab6a0dfc7addfae3e079c6217aef1e61806f4a6	matchmaker: signaling for dynamic publish/subscribe applications	minimisation;routing protocols;subscriptions signal processing broadcasting communication channels relays subcontracting application software computer science topology signal analysis;optimization problem;active matchmaker signaling protocol publish subscribe paradigm content oriented data dissemination communication channels matchmaking content forwarding state matchmaking signaling messages;content distribution;publish subscribe;information dissemination;telecommunication signalling;telecommunication channels;dynamic adaptation;data dissemination;routing protocols information dissemination telecommunication channels telecommunication signalling minimisation	The publish/subscribe (pub/sub) paradigm provides content-oriented data dissemination in which communication channels are established between content publishers and content subscribers based on a matching of subscribers interest in the published content provided – a process we refer to as “matchmaking”. Once an interest match has been made, content forwarding state can be installed at intermediate nodes (e.g., active routers, application-level relay nodes) on the path between a content provider and an interested subscriber. In dynamic pub/sub applications, where published content and subscriber interest change frequently, the signaling overhead needed to perform matchmaking can be a significant overhead. We first formalize the matchmaking process as an optimization problem, with the goal of minimizing the amount of matchmaking signaling messages. We consider this problem for both shared and per-source multicast data (content) distribution topologies. We characterize the fundamental complexity of the problem, and then describe several efficient solution approaches. The insights gained through our analysis are then embodied in a novel Active Matchmaker Signaling Protocol (AMSP). AMSP dynamically adapts to applications’ changing publication and subscription requests through a link-marking approach. We simulate AMSP and two existing broadcastbased approaches for conducting matchmaking, and find that AMSP significantly reduces signaling overhead.	algorithm;item unique identification;matchmaking (video games);mathematical optimization;multicast;optimization problem;overhead (computing);programming paradigm;publish–subscribe pattern;relay;signaling protocol;simulation;time complexity	Zihui Ge;Ping Ji;James F. Kurose;Donald F. Towsley	2003		10.1109/ICNP.2003.1249773	optimization problem;minimisation;computer science;operating system;distributed computing;publish–subscribe pattern;routing protocol;world wide web;dissemination;computer network	Metrics	-9.768376812860126	75.86296291687827	25943
f4d90357aa97037a7415cbf3e3a41d08d03d2399	apollon: file system level support for qos augmented i/o	workload;sistema operativo;controle acces;evaluation performance;text;legacy software;base donnee;theorie type;equipement menager;domestic appliances;multimedia;performance evaluation;gestion archivos;real time;evaluacion prestacion;database;audio video;base dato;semantics;gestion fichier;texte;file management;semantica;semantique;deadline;qualite service;systeme linux;logiciel patrimonial;operating system;sistema linux;file system;scheduling;information appliance;logicial herencia;temps reel;type theory;charge travail;next generation;tiempo real;systeme exploitation;access control;equipo domestico;date limite;carga trabajo;linux system;fechas ultimas;texto;database search;legacy system;service quality;ordonnancement;reglamento;admission control;calidad servicio	Next generation information appliances are required to handle realtime audio/video playback and in the mean time should be able to handle text based requests such as database search, file recording, etc. Although several techniques are presented to address this problem, most of them are rather theoretical to be employed into practical systems as they are. In this paper, we present our experience in developing the file system which can efficiently handle mixed workload. To this end, we develop practical I/O scheduling mechanism to prioritize the incoming disk I/O requests: deadline-driven I/O scheduler and admission control module. We also discuss some issues on QoS enhanced I/O semantics. The proto-type file system Apollon is developed on Linux Operating System. Compared to legacy system, Apollon exhibits superior performance in guaranteeing the QoS requirement of real-time requests.	control unit;i/o scheduling;information appliance;input/output;legacy system;linux;next-generation network;operating system;quality of service;real-time transcription;scheduling (computing);streaming media;text-based (computing);gift	Taeseok Kim;Youjip Won;Doohan Kim;Kern Koh;Yong H. Shin	2005		10.1007/11582267_6	embedded system;real-time computing;computer science;operating system;semantics;world wide web;legacy system	Embedded	-11.555758630065508	65.47181203075432	26007
c46e9702fb6cb66ac25450662cbd7bd2a1788c92	meta-heuristic based reliable and green workflow scheduling in cloud computing		Efficient workflow scheduling in modern cloud environment involves optimization of various conflictive objectives like execution performance (time), reliability, energy consumption etc. Despite this trend, numerous heuristics have been devoted to workflow scheduling mainly focused on the optimization of makespan (execution time) only without giving much attention on other important objectives. Reducing energy consumption is the major concern as it brings several important benefits like reduction in the operating costs, increase in the system reliability and environmental protection. Moreover, the compute processors in cloud are not failure free. Any kind of failure can be critical for an application. Hence in this paper, we proposed the multi-objective NSGA-II based scheduling algorithm for workflow applications with the aim to optimize three conflicting criterion simultaneously: makespanexecution time, reliability and energy consumption for executing the workflow application in cloud environment. In order to reduce the computation complexity of the algorithm, we used the efficient non-domination level update mechanism rather than applying the non-domination sorting from the scratch each time. The simulation analysis of the proposed algorithm on CloudSim toolkit shows that the Pareto optimal solutions obtained have good convergence, uniform diversity and computational efficiency.		Nidhi Rehani;Ritu Garg	2018	Int. J. Systems Assurance Engineering and Management	10.1007/s13198-017-0659-8	job shop scheduling;workflow management system;workflow application;cloud computing;cloudsim;real-time computing;scheduling (computing);workflow;multi-objective optimization;computer science;distributed computing	DB	-18.939395166857295	63.372288107664325	26022
86d6d784585190a15a654eb3a0a2d6488b47fc90	dbs: a bit-level heuristic packet classification algorithm for high speed network	multicore network processor platform;packet classification;high speed networks;bit level heuristic design;satellite broadcasting;indexes;internet;satellite broadcasting classification algorithms heuristic algorithms high speed networks partitioning algorithms scalability algorithm design and analysis intrusion detection internet throughput;multicore network processor platform discrete bit selection bit level heuristic packet classification algorithm high speed internet bit level heuristic design;heuristic algorithms;classification algorithms;pattern classification;software algorithms;discrete bit selection;high speed;algorithm design and analysis;pattern classification internet;bit level heuristic packet classification algorithm;partitioning algorithms;high speed internet	Packet classification is one of the most critical techniques in many network devices such as Firewall, IDS and IPS, etc. In order to meet the performance requirement for high speed Internet (even higher than 10 Gbps), practical algorithms must keep better spatial and temporal performance. Moreover, as the size of rule set is increasing to tens of thousands, novel packet classification algorithms must have good scalability. In this paper, we propose a novel packet classification algorithm named DBS (Discrete Bit Selection) which takes a bit level heuristic design to partition the rule set effectively. To the best of our knowledge, DBS is the first try to design a heuristic classification algorithm at bit-level. To evaluate the performance of our algorithm, DBS is deployed on a popular multi-core Network Processor platform, compared with two existing well-known algorithms. Experimental results show that DBS achieves 300% higher throughput than HiCuts and HSM, while the memory requirement is reduced to about 10% averagely. DBS works well especially with large rule set (10K), which trends a good scalability.	algorithm;bit-level parallelism;data rate units;direct-broadcast satellite;firewall (computing);heuristic;ips panel;multi-core processor;network packet;network processor;scalability;throughput	Baohua Yang;Xiuli Wang;Yibo Xue;Jun Li	2009	2009 15th International Conference on Parallel and Distributed Systems	10.1109/ICPADS.2009.53	statistical classification;database index;algorithm design;parallel computing;real-time computing;the internet;internet access;computer science;theoretical computer science;distributed computing;computer network	HPC	-6.640570231323744	67.29940767785092	26086
98755019fcc4aab5032b3abedd7ca7aca50b846a	an efficient ieee 802.11 ess mesh network supporting quality-of-service	mesh distributed coordination function mdcf;time division multiple access;concurrent traffic flow;wireless local area network;concurrent traffic flow ieee 802 11 ess network extended service set quality of service basic service set interconnect bss wireless local area network wlan mesh distributed coordination function mdcf distributed control time division multiple access frequency channel ieee 802 11a b g physical layer;access point;physical layer;basic service set;distributed coordinated function;wlan;multihop relaying;ieee 802 11 extended service set ess mesh network;traffic flow;interconnect bss;telecommunication traffic;extended service set;ieee 802 11 ess network;frequency channel;electronic switching systems mesh networks quality of service wireless lan lan interconnection access protocols distributed control frequency physical layer channel capacity;channel capacity;quality of service qos;wireless lan quality of service telecommunication network topology telecommunication traffic time division multiple access;mesh distributed coordination function;mdcf;mesh network;wireless lan;quality of service;telecommunication network topology;distributed control;quality of service qos ieee 802 11 extended service set ess mesh network mesh distributed coordination function mdcf multihop relaying;ieee 802 11a b g physical layer	IEEE 802.11 infrastructure basic service set (BSS) wireless local area networks (WLANs) are widely used, each comprising an access point (AP) and its associated stations. There is a need to interconnect BSSs wirelessly to create an extended service set (ESS) mesh network. We propose a solution for the architecture and protocols of a mesh distributed coordination function (MDCF) to interconnect a large number of APs in order to form an efficient ESS mesh network under distributed control. MDCF applies time-division multiple access to share the radio medium and is able to run on a single frequency channel on top of the IEEE 802.11a/b/g physical layers, concurrently to legacy stations. MDCF is capable to efficiently exploit channel capacity, fairly distribute bandwidth among the mesh points and support multihop relaying of a large number of concurrent traffic flows strictly observing specific quality-of-service requirements. Example simulation results proof the outstanding performance of the new concept proposed	channel (communications);channel capacity;distributed control system;mesh networking;quality of service;requirement;simulation;wireless access point	Rui Zhao;Bernhard Walke;Guido R. Hiertz	2006	IEEE Journal on Selected Areas in Communications	10.1109/JSAC.2006.881635	ieee 802.11s;wireless mesh network;switched mesh;service set;wi-fi;telecommunications;computer science;shared mesh;distributed computing;computer network	Visualization	-4.728163617244566	84.77179511231175	26087
bbae730a396c251d356a26ea7129b53bbf573df7	toward incremental fib aggregation with quick selections (faqs)		Several approaches to mitigating the Forwarding Information Base (FIB) overflow problem were developed and software solutions using FIB aggregation are of particular interest. One of the greatest concerns to deploy these algorithms to real networks is their high running time and heavy computational overhead to handle thousands of FIB updates every second. In this work, we manage to use a single tree traversal to implement faster aggregation and update handling algorithm with much lower memory footprint than other existing work. We utilize 6year realistic IPv4 and IPv6 routing tables from 2011 to 2016 to evaluate the performance of our algorithm with various metrics. To the best of our knowledge, it is the first time that IPv6 FIB aggregation has been performed. Our new solution is 2.53 and 1.75 times as fast as the-state-of-the-art FIB aggregation algorithm for IPv4 and IPv6 FIBs, respectively, while achieving a near-optimal FIB aggregation ratio.		Yaoqing Liu;Garegin Grigoryan	2018		10.1109/NCA.2018.8548101	computer science;distributed computing;tree traversal;ipv6	DB	-12.72913920930824	80.96719916752762	26120
8b2e8dcbc280ce31352f37f64f4bb12cccf75676	a two-level caching protocol for hierarchical peer-to-peer file sharing systems	cache storage;protocols;cache;super peer;search engines;cache size two level caching protocol hierarchical peer to peer file sharing system lookup service two level caching architecture static data dynamic data;frequency estimation;protocols cache storage peer to peer computing;servers;cache peer to peer super peer;probabilistic logic;peer to peer computing;peer to peer;peer to peer computing protocols servers search engines probabilistic logic concrete frequency estimation;concrete	In hierarchical Peer-to-Peer (P2P) systems, several selected peers are promoted as super-peers to provide an efficient lookup service for the ordinary peers, although it would cause a service bottleneck and a heavy workload at the point of the promoted peers. In this paper, we propose a two-level caching architecture consisting of level-1 cache and level-2 cache to relax such bottlenecks in hierarchical P2Ps. Each cache is partitioned into two parts so that it could manage both of static and dynamic data in a space-efficient manner, where static data indicates popular pages which are frequently requested by many users and dynamic data indicates pages which may not be popular but repeatedly requested during a short time period. The performance of the proposed method is evaluated by simulation. The result indicates that our caching protocol significantly reduces the network traffic and exhibits a high hit rate even in small cache sizes.	cpu cache;cache (computing);dynamic data;lookup table;network packet;peer-to-peer file sharing;simulation	Qi Ying Wei;Ting Ting Qin;Satoshi Fujita	2011	2011 IEEE Ninth International Symposium on Parallel and Distributed Processing with Applications	10.1109/ISPA.2011.26	communications protocol;real-time computing;cache coloring;page cache;concrete;cache;computer science;write-once;cache invalidation;operating system;database;distributed computing;smart cache;probabilistic logic;cache algorithms;cache pollution;dead peer detection;server;computer network	Arch	-17.522724069781507	70.78128059954301	26191
45b567313abea7e1aedaa3a12f7de4d8ae136236	extensible provisioning protocol (epp) host mapping			ieee 1284;provisioning	Scott Hollenbeck	2004	RFC	10.17487/RFC3732		Theory	-18.114309315503668	87.56276380744579	26195
aa637d5a7091fac2d5f08d9818911027ff51bedf	optimal controller placement in large scale software defined networks based on modified nsga-ii	software-defined network (sdn);controller placement;multi-objective combinatorial optimization (moco);heuristic algorithms;optimal pareto front (pf);hybrid nsga-ii (hnsga-ii)	Software Defined Network (SDN) is an emerging approach to overcome challenges of traditional networks. One particularly important issue in SDN architectures is that of controller placement problem (CPP), i.e., deploying a desired number of controllers within a network while some possibly conflicting requirements have to be fulfilled. A single optimal placement may not be possible and decision makers need to seek for an appropriate trade-off among the metrics. Although an exhaustive evaluation of all possible placements can be practically performed well for small and medium-sized networks, regarding realistic time and resource restrictions, heuristic approaches are required for large-scale networks. Hence, a heuristic called Multi-Start Hybrid NSGA-II (MHNSGA-II) is introduced which yields faster computation times and needs reasonable memory to perform. The obtained results on several topologies extracted from Internet Topology Zoo showed the efficiency of the proposed approach.	computation;heuristic;internet topology;optimal control;requirement;software-defined networking	Ahmad Jalili;Manijeh Keshtgari;Reza Akbari	2017	Applied Intelligence	10.1007/s10489-017-1119-5	machine learning;artificial intelligence;computer science;network topology;computation;internet topology;software-defined networking;control theory;heuristic;distributed computing	Embedded	-11.66633453201512	82.0498629647703	26276
8c1a78da293d98f78eae12814fc92a9bb1c171d4	software defined 5g networks for anything as a service [guest editorial]	technological innovation;special issues and sections;software radio;software architecture;5g mobile communication;communication channels;special issues and sections software radio technological innovation software architecture communication channels 5g mobile communication	"""The advanced fifth generation (5G) infrastructure is expected to become the “nervous system” of the digital society, digital economy, and silver economy. New service paradigms such as “immersive experience” and “anything as a service” (XaaS) everywhere are envisioned as among the primary drivers for global adoption and market uptake of new 5G technology components. Above all, 5G networks will support mission-critical machine communications and massive machine type of traffic. As a result, the key performance metrics that 5G is expected to improve are in terms of, but not limited to, latency, reliability, capacity, and spectrum and network agility. This calls for a complete rethinking of all functional domains, including access stratum (AS), non-access stratum (NAS), and transport network layer (TNL), in terms of protocols and procedures. New emerging technologies, such as software defined networking (SDN), network functions virtualization (NFV), mobile edge computing (MEC), and high-performance computing (HPC), provide momentum for new design principles toward software (service) defined 5G networks, targeting a software defined air interface (SDAI) for available bands (spectrum); sliced """"networks on demand"""" for multiple industries, especially for vertical markets (new architecture); and flexibility and spectral efficiency for mobile broadband and machine type communications (new air interface)."""		David Soldani;Bernard Barani;Rahim Tafazolli;Antonio Manzalini;I Chih-Lin	2015	IEEE Communications Magazine	10.1109/MCOM.2015.7263348	software architecture;simulation;telecommunications;computer science;operating system;software-defined radio;software as a service;resource-oriented architecture;computer network;channel	Visualization	-15.238185181941464	86.75438994183818	26298
847a6fef16292a4877c7db5ef11904c39d4dcb84	checking the integrity constraints of mobile databases with three-level model	mobile device;mobile host;mobile databases;constraint checking;mobile database;wireless communication;mobile environment;integrity constraints;data access	In a mobile environment, due to the various constraints inherited from limitations of wireless communication and mobile devices, checking for integrity constraints to maintain the consistent state of mobile databases is an important issue that needs to be addressed. Hence, in this paper we propose Three-Level (3-L) model, wherein the process of constraint checking is realized at three different levels. Here, we use sufficient and complete tests together with the idea of caching relevant data items during the relocation period for checking the integrity constraints. This has improved the checking mechanism by preventing delays during the process of checking constraints and performing the update. Also, the 3-L model reduces the amount of data accessed given that much of the tasks are performed at the mobile host. Hence, our model speeds up the checking process.	data integrity	Hamidah Ibrahim;Zarina Dzolkhifli;Praveen Madiraju	2008		10.1007/978-3-540-70504-8_18	real-time computing;mobile database;computer science;database;distributed computing;mobile computing	DB	-15.415968486784564	68.34163919947119	26322
fb8d3e5e3aa79adbc97589ceb1801da1756be3bd	p2pconf: a medium-size p2p internet conference with effective floor control	teleconferencing;virtual reality;p2p;internet telephony;skype;design and implementation;internet peer to peer computing web server control systems streaming media space technology conference management bandwidth network servers centralized control;p2pconf;virtual reality internet telephony peer to peer computing teleconferencing;conference quality p2pconf p2p internet conference virtual space skype peer to peer technology voip application floor control mechanism;floor control mechanism;voip application;peer to peer technology;peer to peer computing;p2p internet conference;virtual space;conference quality	Internet-Conferencing allows a number of participants, separated by substantial distances, to meet in a virtual space and communicate with each other. In contrast to existing systems that typically require dedicated servers to manage conferences, Skype has illustrated the potential of using P2P (peer- to-peer) technology to construct a simple yet very large VoIP application over the Internet. However, each conference in Skype is limited to at most five participants. As the interaction between Internet users increases, a conference that can accommodate more participants becomes imminent. This paper presents the design and implementation of such a P2P-based conference system, along with an effective floor control mechanism to ensure conference quality.	centralized computing;dedicated hosting service;internet;loose coupling;peer-to-peer;server (computing);streaming media;virtual reality	Yuh-Jzer Joung;Pao Han Chien	2008	2008 International Conference on Information Networking	10.1109/ICOIN.2008.4472792	teleconference;telecommunications;computer science;peer-to-peer;virtual reality;multimedia;world wide web;computer network	Visualization	-22.4252196889415	72.12357791263352	26344
2023c6b97e7c9e81d5a5a86bd328762429e14682	adaptive data broadcasting in asymmetric communication environments	broadcasting databases feedback processor scheduling computer science power system modeling mobile communication feeds traffic control information systems;client server systems;satisfiability;data communication;information delivery adaptive data broadcasting asymmetric communication environments adaptive broadcast dissemination flexible responses client requests client average waiting time;waiting time;information dissemination;client server systems data communication broadcasting information dissemination;data broadcast;broadcasting	We present a new adaptive broadcast dissemination model to support flexible responses to client requests. Several features distinguish our model. First, client queries do not target individual documents, but specify the required information by attributes. Second, clients are satisfied by responses that are sufficiently close to the desired information. Finally, the server in our model solicits randomized feedback from clients to adapt its broadcast program to client needs. Our simulation results show that our model captures the interest patterns of clients more efficiently and more accurately and scales very well with the number of clients, while reducing overall client average waiting times.	client (computing);datacasting;randomized algorithm;server (computing);simulation	Wei Wang;Chinya V. Ravishankar	2004	Proceedings. International Database Engineering and Applications Symposium, 2004. IDEAS '04.	10.1109/IDEAS.2004.8	real-time computing;computer science;database;distributed computing;broadcasting;computer network;satisfiability	OS	-17.139244807015665	70.00917209454363	26392
1eb861c6229f9b95306dbbc033f3db04c6be94a5	stackelberg game-based models in energy-aware cloud scheduling.				Damián Fernández-Cerero;Alejandro Fernández-Montes;Agnieszka Jakobik;Joanna Kolodziej	2018		10.7148/2018-0460	cloud computing;stackelberg competition;scheduling (computing);computer science;distributed computing	Embedded	-24.33287302836395	69.63300833400528	26439
ffe8be4ef34114ab3678cba9917c09e2bc659099	network-oriented intelligent agent infrastructure for internetworking with guaranteed quality of service in high-speed network		This paper describes an Agent-based InterNetworking Platform (AINP) which has a hierarchical infrastructure for internetworking with guaranteed Quality of Service in a high-speed network. The AINP system intelligently controls and manages the AINP network through network-oriented agents due to its policy which is periodically updated using the user/network-state information. In this approach, for implementing network-oriented agents and agent-based communications in intelligent AINP infrastructure, a Common Information Model is used which is the international standardization of object-oriented modeling. Extensible Markup Language is used for encapsulation and the HyperText Transfer Protocol is used for transference of user/network-state information. We concluded that the AINP was robust and suitable for an intelligent network management system in a high-speed network.	intelligent agent;internetworking;quality of service	Joonhyeon Jeon;Donghyeok Kim;Gunmin Kim	2011		10.1007/978-3-642-24106-2_4	real-time computing;distributed computing;computer network	ECom	-20.66270601642704	85.05257969333083	26468
fd8532c27b98f9f38d4880b65e865f6836428bb8	maximizing coverage in low-power wide-area iot networks	reliability;sociology statistics reliability monitoring switches;monitoring;statistics;switches;sociology	The Internet of Things (IoT) promises to allow everyday objects to connect to the Internet and seamlessly interact with users and other machines. Essential for the IoT to function is a reliable Internet connection. In 2016 the International Telecommunication Union reports 3.9 billion people - 53% of the world's population are not using the Internet [1]. Projects like Loon (X) and Aquila (Facebook) aim to solve this connectivity gap using atmospheric satellites to deliver 4G-like signals to underserved regions. With the recent interest in low-power wide-area networks (LPWAN) in the license-free ISM bands, we consider using atmospheric satellites to improve coverage in LPWAN networks. We find that LPWAN technologies are compatible with atmospheric satellites and demonstrate that significant connectivity gains are possible by locating an LPWAN base station at altitude from 1 km – 28 km when compared to a typical ground-based base station.	implicit shape model;internet of things;low-power broadcasting	Alan Marchiori	2017	2017 IEEE International Conference on Pervasive Computing and Communications Workshops (PerCom Workshops)	10.1109/PERCOMW.2017.7917608	embedded system;simulation;telecommunications;network switch;computer science;reliability;computer security;statistics;computer network	Robotics	-20.5968375597165	77.88279426802359	26536
0c0e26564071cf8bf0b326a5dd8c036c168116f6	acceleratingweb protocols using rdma	iwarp;acceleration protocols web server network servers tcpip supercomputers internet distributed computing web services scalability;file servers;protocols;memory protocols;web protocol;iwarp web protocol remote direct memory access high performance computing internet server generated content apache web server;high performance computing;tcpip;distributed computing;server generated content;acceleration;apache web server;remote direct memory access;network servers;internet;web services;high performance computer;memory protocols file servers internet;scalability;web server;supercomputers	High-performance computing, just like the world at large, is continually discovering new uses for the Internet. Interesting applications rely on server-generated content, severely taxing the capabilities of web servers. Thus it is common for multiple servers to run a single site. In our work, we use a novel network feature known as RDMA to vastly improve performance and scalability of a single server. Using an unmodified Apache web server with a dynamic module to enable iWARP (RDMA over TCP), we can handle more clients with lower CPU utilization, and higher throughput.	central processing unit;iwarp;internet;remote direct memory access;scalability;server (computing);throughput;web server	Dennis Dalessandro;Pete Wyckoff	2007	Sixth IEEE International Symposium on Network Computing and Applications (NCA 2007)	10.1109/NCA.2007.4	acceleration;web service;file server;communications protocol;supercomputer;scalability;the internet;remote direct memory access;computer science;operating system;database;internet protocol suite;iwarp;world wide web;web server;server;computer network	Arch	-19.071340371589123	70.86736641502685	26565
f11304092e65ef951050cd67dabebcbc7b839509	joint pricing and capacity planning for iaas cloud	convex programming;pricing;monopoly;virtual machines;profitability;cloud computing	We consider a monopoly Infrastructure-as-a-Service (IaaS) provider market with a set of Software-as-a-Service (SaaS) providers, where each SaaS provider lease the virtual machines (VMs) from the IaaS provider to provide cloud-based application services to its end-users. We investigate the problem of designing a joint pricing and capacity planning scheme from the IaaS provider's perspective. Specifically, we first study the SaaS providers' optimal decisions in terms of the amount of end-user requests to admit and the number of VMs to lease, given the resource price charged by the IaaS provider. Next, based on the best responses of the SaaS providers, we study joint pricing and capacity planning to maximize the IaaS provider's profit, which is determined by the revenue obtained through supplying the VMs and the energy cost for maintaining the active servers. By exploring the relationship between the optimal capacity and price, we simplify the original optimization problem into the a convex problem with respect to the price, and then we derive the expressions of the optimal solutions. Finally, the numerical results illustrate the efficacy of our proposed joint pricing and capacity planning scheme.	automated planning and scheduling;cloud computing;convex optimization;entropy maximization;mathematical optimization;monopoly;numerical analysis;optimization problem;software as a service;virtual machine	Ling Tang;Jinghui Qian;Lei Xu;Yan Yu	2014	The International Conference on Information Networking 2014 (ICOIN2014)	10.1109/ICOIN.2014.6799661	pricing;convex optimization;cloud computing;computer science;virtual machine;operating system;profitability index	Robotics	-22.4612933202877	64.76915773453902	26586
9ab87350ea2eb959efd56a41aab5aca824ce2f11	managing cancellations and no-shows of reservations with overbooking to increase resource revenue	resource overbooking;resource utilization;revenue management;grid overbooking advance reservation revenue management;incentive;resource allocation;grid;overbooking;incentive schemes;advance reservation;reservation cancellation no show;grid computing;incentive reservation cancellation no show resource revenue management grid system resource overbooking resource utilization;resource management costs grid computing pricing computer applications processor scheduling computer science software information science computer networks;grid system;resource allocation grid computing incentive schemes;resource revenue management	Advance reservation allows users to request available nodes in the future, whereas economy provides an incentive for resource owners to be part of the Grid, and encourages users to utilize resources optimally and effectively. In this paper, we use overbooking models from Revenue Management to manage cancellations and no-shows of reservations in a Grid system. Without overbooking, the resource owners are faced with a prospect of loss of income and lower system utilization. Thus, the models aim to find an ideal limit that exceeds the maximum capacity, without incurring greater compensation cost. Moreover, we introduce several novel strategies for selecting which bookings to deny, based on compensation cost and user class level, namely Lottery, Denied Cost First (DCF), and Lower Class DCF. The result shows that by overbooking reservations, a resource gains an extra 6-9% in the total net revenue.	advanced audio coding;design rule for camera file system;job stream;offset binary;overselling;performance evaluation;quantum lc circuit;risk management;sl (complexity)	Anthony Sulistio;Kyong Hoon Kim;Rajkumar Buyya	2008	2008 Eighth IEEE International Symposium on Cluster Computing and the Grid (CCGRID)	10.1109/CCGRID.2008.65	in situ resource utilization;incentive;resource allocation;computer science;grid;management;grid computing	HPC	-24.045794320580026	64.83344585312922	26767
347bbf145d50fc3529848c415a3d60407436fded	partitioning composite web services for decentralized execution using a genetic algorithm	composite web service;web service;component web services;web service composition;composite web services;genetic algorithm;genetic algorithms;program partitioning	Composite web services comprise several component web services. When a composite web service is executed centrally, a single web service engine is responsible for coordinating the execution of the components, which may create a bottleneck and degrade the overall throughput of the composite service when there are a large number of service requests. Potentially this problem can be handled by decentralizing execution of the composite web service, but this raises the issue of how to partition a composite service into groups of component services such that each group can be orchestrated by its own execution engine while ensuring acceptable overall throughput of the composite service. Here we present a novel penalty-based genetic algorithm to solve the composite web service partitioning problem. Empirical results show that our new algorithm outperforms existing heuristic-based solutions.	genetic algorithm;web service	Lifeng Ai;Maolin Tang;Colin J. Fidge	2011	Future Generation Comp. Syst.	10.1016/j.future.2010.08.003	web service;web processing service;web modeling;data web;genetic algorithm;computer science;ws-policy;service-oriented architecture;ws-addressing;database;distributed computing;world wide web;mashup	Arch	-19.542166833958614	63.90651326183061	26833
41cdf9557b77320ffc33fb2699441dc03444536a	complexity of scheduling in high level synthesis	high level synthesis	This work examines the complexity of scheduling for high level synthesis. It has been shown that the problem of finding the minimum time schedule for a set of chains of operations of two types using two processors, one of each type, is NP-complete. However, for two chains only, a polynomial time algorithm can been obtained for scheduling with two processors. The problem of scheduling a rooted binary tree of two operation types on two processors, one of each type, has been shown to be NP-complete. It has also been proved that absolute approximations for schedule length minimization or processor minimization are NP-complete. A related resource constrained scheduling problem has also been shown to be NP-hard.	high-level synthesis;scheduling (computing)	Chittaranjan A. Mandal;P. P. Chakrabarti;Sujoy Ghose	1998	VLSI Design	10.1155/1998/52807	fair-share scheduling;nurse scheduling problem;fixed-priority pre-emptive scheduling;open-shop scheduling;mathematical optimization;parallel computing;real-time computing;earliest deadline first scheduling;gang scheduling;dynamic priority scheduling;computer science;rate-monotonic scheduling;two-level scheduling;stride scheduling;least slack time scheduling;high-level synthesis;round-robin scheduling;multiprocessor scheduling	EDA	-10.645904517124615	61.55305069289327	26901
5e642d098f25fd4c7889ee4209c35c3ee78f6e16	a resource management protocol for mobile cloud using auto-scaling		Cloud radio access network (C-RAN) and Mobile Cloud Computing (MCC) have emerged as promising candidates for the next generation access network techniques. MCC offers resource limited mobile devices to offload computationally intensive tasks to the cloud, while C-RAN offers a technology that addresses increasing mobile traffic. In this paper, we propose a protocol that allows task offloading and managing resources in both C-RAN and mobile cloud together using a centralised controller. Experiments on resource management using cloud auto-scaling shows that resource (CPU, RAM, Storage) scaling times vary.	autoscaling;broadcast delay;c-ran;central processing unit;centralisation;image scaling;mobile cloud computing;mobile device;network packet;next-generation access;next-generation network;performance;radio access network;random-access memory;real-time clock;real-time computing	Chathura M. Sarathchandra Magurawalage;Kun Yang;Ritosa Patrik;Michael Georgiades;Kezhi Wang	2017	CoRR		real-time computing;simulation;computer science;operating system;distributed computing	Mobile	-23.491725148511474	67.429751992679	26914
9fa19cbcfcfd7d889cbac3c5abbd738633aaa98c	violet: a storage stack for iops/capacity bifurcated storage environments		In this paper we describe a storage system called Violet that efficiently marries fine-grained host side data management with capacity optimized backend disk systems. Currently, for efficiency reasons, real-time analytics applications are forced to map their in-memory graph like data structures on to columnar databases or other intermediate disk friendly data structures when they are persisting these data structures to protect them from node failures. Violet provides efficient fine-grained end-to-end data management functionality that obviates the need to perform this intermediate mapping. Violet presents the following two key innovations that allow us to efficiently do this mapping between the finegrained host side data structures and capacity optimized backend disk system: 1) efficient identification of updates on the host that leverages hardware in-memory transaction mechanisms and 2) efficient streaming of fine-grained updates on to a disk using a new data structure called Fibonacci Array.	computer data storage;data structure;end-to-end encryption;family computer disk system;in-memory database;real-time clock;software transactional memory	Douglas Santry;Kaladhar Voruganti	2014			telecommunications	OS	-7.622957360016102	64.68330836366314	26991
16832146ef6b5c8a273cda804413faf47f115ff8	real time tasks scheduling optimization using quantum inspired genetic algorithms		Real Time Scheduling (RTS) optimization is a key step in Real Time Embedded Systems design flow. Since RTS is a hard problem especially on multiprocessors systems, researchers have adopted metaheuristics to find near optimal solutions. On the other hand, a new class of genetic algorithms inspired from quantum mechanics appeared and proved its efficiency with regard to conventional genetic algorithms. The objective of this work is to show how we can use quantum inspired genetic algorithm to resolve the RTS problem on embedded multicores architecture. Our proposed algorithm tries to minimize the tasks response times mean and the number of tasks missing their deadlines while balancing between processors cores usage ratios. Experimental results show a big improvement in research time with regard to conventional genetic algorithms.	central processing unit;embedded system;genetic algorithm;mathematical optimization;metaheuristic;quantum mechanics;real-time operating system;scheduling (computing);systems design	Fateh Boutekkouk;Soumia Oubadi	2016		10.1007/978-3-319-33625-1_7	real-time computing;theoretical computer science;distributed computing	Embedded	-13.510910039860027	62.11449775279139	27039
c590a1f698055d161809ae6f36eb91bb507beb1a	an efficient tuple pruning scheme for packet classification using on-chip filtering and indexing		Packet classification is one of the core functions in present-day networking applications. Various classification algorithms have been developed, including tuple space search (TSS) which is used in the Open vSwitch due to its flexibility and scalability. In order to solve the problem of excessive memory access to the vast rule-set stored off-chip, many algorithms adopt bloom filter (BF) to reduce unnecessary accesses. However, deteriorated false positive and increased collisions at high load ratio may still be a problem. Here in this paper a new tuple pruning based packet classification algorithm is proposed that can achieve much reduced off-chip access per-lookup even at high load by adopting a better compact structure on-chip and Cuckoo hash off-chip. At the same time, we can accelerate the classification rate further by optimizing the search sequence of tuples making it more likely to find the matching rules earlier. Experimental results show that with the proposed mechanism the off-chip table lookup time is only 1/3 to 1/4 of the baseline BF- based scheme.	algorithm;baseline (configuration management);bloom filter;brainfuck;cuckoo hashing;lookup table;network packet;open vswitch;scalability;tuple space	Shaowei Zhao;Junmao Li;Dagang Li	2018	NOMS 2018 - 2018 IEEE/IFIP Network Operations and Management Symposium	10.1109/NOMS.2018.8406226	tuple;tuple space;computer science;real-time computing;distributed computing;scalability;cuckoo hashing;network packet;statistical classification;search engine indexing;bloom filter	Networks	-6.3974795055523375	66.76332094980529	27128
66e452c4fc27ecb4be266226161244b0ff87c14c	discovering the structure of cloud applications using sampled packet traces	topology servers network topology ports computers routing data mining cloud computing;sfinder cloud applications sampled packet traces cloud infrastructure cloud management tenant onboarding optimized vm placement performance optimization debugging cloud tenant application structures packet header sampling commodity network switches sampled sflow data private cloud;virtual machines cloud computing sampling methods	Accurate and up-to-date knowledge of how a cloud tenant's VMs utilize the underlying cloud infrastructure is essential for many cloud management tasks including tenant onboarding, optimized VM placement, performance optimization, and debugging. Unfortunately, existing solutions such as instrumentation at the hypervisors or standard networking protocols such as LLDP only provide a partial picture of cloud tenant's application structures and how they stress the underlying infrastructure. In this paper, we consider whether it is possible to use sFlow, a standardized mechanism for packet header sampling available in most commodity network switches, to extract such information in an accurate and scalable manner. We overcome the challenges posed by the purely passive and highly sampled nature of sFlow data, and describe a tool, sFinder, that automatically and continuously extracts such information. Our evaluation using sampled sFlow data from a real private cloud show that sFinder is accurate and efficient.	cloud management;communications protocol;debugging;digital footprint;hypervisor;link layer discovery protocol;mathematical optimization;network packet;network switch;sampling (signal processing);scalability	Hiroya Matsuba;Matti A. Hiltunen;Kaustubh R. Joshi;Richard D. Schlichting	2014	2014 IEEE International Conference on Cloud Engineering	10.1109/IC2E.2014.45	real-time computing;cloud computing;computer science;distributed computing;computer network	HPC	-12.318594321841527	79.59807946662082	27210
de488251429f38544e3ea9d75e2e1a8aa387fab9	network resource search system based on cluster architecture		The paper proposes network resource search system applying cluster architecture. Resource search system uses incremental update to control the cluster, which can realize collection and updating maintenance of network resource. The paper focuses on describing operating principle of the system, based on which the paper proposes the design and implementation of the system. Based on hash method of vector space, the system realizes load balance of cluster assignment, dynamically achieves running state of computing nodes by balanced CPU, MEMEORY, I/O and NET, and realizes dynamic monitor and change of task assignment scheduling policy. And the paper improves the efficiency of network resource search system by combing angle cosine vector method and incremental update.	computer cluster	Chen Yandong	2013		10.1007/978-3-642-53703-5_3	real-time computing;simulation;computer science;distributed computing	Robotics	-17.989436051249818	67.84515434850583	27288
363b8b652a34899a8851a87b041447c64ca17499	mobile wireless sensor network gateway: a raspberry pi implementation with a vpn backend to openstack		The paper discusses a solution to allow permanent access to a cloud for the devices in mobile wireless sensor networks. Concepts like Dew Computing DC distributes the cloud infrastructure but has a lack of mobility. Seamless connectivity for applications and services is ensured by implementing a mobility system over different access technologies relying on dynamic context-based routing mechanism in edge nodes. The application scenario involves mobile wireless sensor networks gateways MWSNGs, designed to be installed in public transportation (mainly electric vehicles). The sensors are presumed to be scattered all around a smart city, monitoring environmental parameters and centralizing them through permanent Internet connectivity. The implemented cloud-based testbed includes a Raspberry PI acting as a Compute Node, allowing the deployment of the application in a virtualized manner.	algorithm;benchmark (computing);centralisation;cloud computing;gateway (telecommunications);internet;mobile phone;raspberry pi 3 model b (latest version);routing;seamless3d;sensor;smart city;software deployment;testbed	Eduard-Florentin Luchian;Adrian Taut;Iustin-Alexandru Ivanciu;Gabriel Lazar;Virgil Dobrota	2017	2017 25th International Conference on Software, Telecommunications and Computer Networks (SoftCOM)	10.23919/SOFTCOM.2017.8115561	computer science;smart city;computer network;wireless sensor network;pi;internet access;embedded system;cloud computing;mobile computing;mobile wireless sensor network;default gateway	Mobile	-17.34299463537943	85.73053003240267	27373
0a1d58becf4da7d30ae05d23265f84996c40eef8	monitoring infrastructure for converged networks and services	easy-to-use network management platform;various service;unique performance requirement;service providers critical information;monitoring infrastructure;underlying ip network;ip network;service provider;internet protocol;network convergence;carrier grade service	Network convergence is enabling service providers to deploy a wide range of services such as Voice over Internet Protocol (VoIP), Internet Protocol television (IPTV), and push-to-talk on the same underlying IP networks. Each service has unique performance requirements from the network, and IP networks have not been designed to satisfy these diverse requirements easily. These requirements drive the need for a robust, scalable, and easy-to-use network management platform that enables service providers to monitor and manage their networks to provide the necessary quality, availability, and security. In this paper, we describe monitoring mechanisms that give service providers critical information on the performance of their networks at a per-user, per-service granularity in real time. This allows the service providers to ensure that their networks adequately satisfy the requirements of the various services. We present various methods to acquire data, which can be analyzed to determine the performance of the network. This platform enables service providers to offer carrier grade services over their converged networks, giving their customers a high-quality experience. © 2007 Alcatel-Lucent.	approximation algorithm;carrier grade;chapel;computer science;computer vision;database;geographic information system;iptv;internet protocol suite;microsoft windows;mobile phone;network convergence;network topology;operating system;peer-to-peer;provisioning;requirement;routing;scalability;scheduling (computing);semantic network;software agent;software system;symbian;xml	Shipra Agrawal;C. N. Kanthi;K. V. M. Naidu;Jeyashankher Ramamirtham;Rajeev Rastogi;Scott Satkin;Anand Srinivasan	2007	Bell Labs Technical Journal	10.1002/bltj.20236	multi-frequency network;service provider;network intelligence;mobile qos;quality of service;value-added network;service design;tiered service;world wide web;computer security;computer network;service system	Networks	-15.96961591617625	84.45596529862449	27382
317537ec30ddc2d40a39629baf09c0bc24f5d4b1	paper: assigning dependency graphs onto processor networks	parallel calculus;parallelisme;heuristic;gestion labor;multiprocessor;resource allocation;sistema informatico;heuristic method;dependence graph;metodo heuristico;computer system;search;parallelism;dependency graphs;calculo paralelo;gestion tâche;paralelismo;scheduling;ordonamiento;systeme informatique;task assignment;asignacion recurso;methode heuristique;task scheduling;multiprocesador;allocation ressource;calcul parallele;ordonnancement;graphe dependance;multiprocesseur	This paper addresses the problem of assigning inter-dependent tasks to processing elements in parallel and distributed computers. We consider tasks with non-uniform execution and communication times. We present a new heuristic scheme to assign dependency graphs nonpreemptively. The heuristics are based on satisfying two properties: independent tasks execute on distinct processors and dependent tasks execute on the same processor. The algorithm is based on the so-called depth-first breadth-next (DFBN) search. We show that the time complexity of our scheme is at least one order less compared to other related schemes.		Sathiamoorthy Manoharan;Peter Thanisch	1991	Parallel Computing	10.1016/S0167-8191(05)80018-3	parallel computing;real-time computing;multiprocessing;heuristic;resource allocation;computer science;operating system;distributed computing;scheduling	HPC	-12.850683389799233	62.157513840964796	27427
cfb0591028ce218b25c661a7f10bdb2480503ae9	virtual active network for live streaming media delivery	live broadcasting;content delivery networks;server farm;data stream;overlay networks;p2p;dynamic clustering;active network;virtual active network;streaming media;overlay network;cost effectiveness;load balance;content delivery network;system architecture;active networks;proxy server;network congestion;wide area network;lower bound	The large amount of bandwidth and other resources required to deliver streaming media limits the number of concurrent users. We propose a virtual active network (VAN) architecture for streaming media data delivery over wide area networks. In the proposed architecture, cooperating proxies support multiplexing and delivery of live streaming media. The hierarchical delivery structure is dynamically adjusted based on user population distribution, usage patterns, and network conditions. The proposed system architecture provides (1) reliable and high quality live streaming media delivery; (2) lower server resource requirements at the content provider sites; (3) reduced inter-ISP traffic; (4) application level routing for rapid deployment; and (5) cost-effective media data delivery. To deal with one characteristics of live broadcasting events, burst traffic at the beginning of the events, our system features a unique function that dynamically clusters multiple proxy servers to form a server farm to handle a large number of user login events when needed. Experimental results show that the proposed VAN architecture consistently delivers reliable live data streams using resources within 10 percent of the theoretically possible lower bound. The experimental results also show the effectiveness of our load balance algorithms to handle various user patterns, server capacity, and network congestion events.	active networking;algorithm;display resolution;load balancing (computing);login;multiplexing;network congestion;proxy server;requirement;routing;server (computing);server farm;software deployment;streaming media;systems architecture	Wen-Syan Li;Divyakant Agrawal;K. Selçuk Candan;Yusuf Akca;Murat Kantarcioglu	2007	Journal of Interconnection Networks	10.1142/S0219265907001904	active networking;real-time computing;overlay network;computer science;operating system;world wide web;computer security;computer network;systems architecture	Metrics	-16.409383471382913	73.49244472941517	27499
4c2e0419ba6bf2bbdb6ac821fb6692a4897943ee	a business process aware semantic qos provisioning scheme	application independent usage;difference operator;corporate network;semantics;workflow management software business data processing quality of service;qos provisioning;business process aware semantic qos provisioning scheme;computer architecture;internet;business data processing;qos provisioning system;business;qos provisioning system semantic business process workflow;semantic;diffserv networks;workflow management software;workflow;ip networks;operating systems business process aware semantic qos provisioning scheme corporate network application independent usage;quality of service;quality of service business semantics diffserv networks computer architecture ip networks internet;business process;operating systems	The execution of business processes is supported by running many applications within a corporate network. Each business process includes several tasks which have different priorities expressing each task's relevance in helping to achieve the related business objectives. The provisioning of a certain level of QoS according to the requirements of an entire business process can hardly be accomplished using existing QoS provisioning schemes because these do not account for the dynamic requirements introduced by business processes. The definition of a certain level of QoS using the existing models is just driven by technical aspects of the running applications. In this paper we present a novel business process aware semantic QoS provisioning scheme that accounts for the dynamic requirements and permits application-independent usage. In the business world the priority of a task depends on the current context it is executed in. So equal tasks may need different conditions of QoS in different situations, which can be characterized by the tasks that ran before or run in parallel. Therefore, the semantic behavior is based on the entire business processes as input for the QoS provisioning process. With the proposed QoS provisioning scheme a fair application conditioning can be achieved that is much closer to the business requirements on QoS. For the validation of the scheme, it has been implemented as a QoS-driver in different operating systems.	algorithm;business process;business requirements;network packet;noise shaping;operating system;provisioning;quality of service;relevance;requirement;scheduling (computing);testbed;traffic shaping	Patrick-Benjamin Bök;Dennis Pielken;York Tüchelmann	2010	IEEE Local Computer Network Conference	10.1109/LCN.2010.5735692	workflow;real-time computing;the internet;quality of service;business requirements;computer science;artifact-centric business process model;database;semantics;business process;business rule;computer network	Visualization	-27.825269242140664	61.25694892333467	27527
2798a24e7ccbaa9517fdb2bf407b9fc07c64a3c7	anticipatory networking in future generation mobile networks: a survey		A growing trend for information technology is to not just react to changes, but as much as possible anticipate them. This paradigm made modern solutions such as recommendation systems a ubiquitous presence in today’s digital transactions. Anticipatory networking extends the idea to communication technologies by studying patterns and periodicity in human behavior and network dynamics to optimize network performance. This survey collects and analyzes recent papers leveraging context information to forecast the evolution of network conditions and, in turn, to improve network performance. In particular, we identify the main prediction and optimization tools adopted in this body of work and link them with objectives and constraints of the typical applications and scenarios. Finally, we consider open challenges and research directions to make anticipatory networking part of next generation networks.	access network;accessibility;computer data storage;context awareness;database;end-to-end principle;hoc (programming language);individual mobility;interaction;internet access;mathematical optimization;network architecture;network function virtualization;network performance;next-generation network;personally identifiable information;privacy;programming paradigm;quasiperiodicity;real-time transcription;recommender system;reliability (computer networking);remote surgery;requirement;scalability;scheduling (computing);seamless3d;software-defined networking;streaming media;transfer function;wireless access point	Nicola Bui;Matteo Cesana;S. Amir Hosseini;Qi Liao;Ilaria Malanchini;Joerg Widmer	2016	CoRR		active networking;simulation;telecommunications;artificial intelligence;management science;computer network	Networks	-20.051823074504707	78.7677782766205	27538
1029012669cf56c8296a7bfb252e8a22bb8c463c	fast recovery from dual link failures in ip networks	graph theory;ip networks protection peer to peer computing routing costs tunneling network topology internet robustness computer networks;routing;protection graph;construction industry;internet dual link failure recovery ip network routing approach protection graph network topology;routing approach;connected graph;network topology;internet;telecommunication network routing;ieee;telecommunication network topology computer network reliability graph theory internet ip networks telecommunication network routing;link failure;joining processes;ip network;ip networks;dual link failure recovery;peer to peer computing;telecommunication network topology;computer network reliability;tunneling	This paper develops a novel mechanism for recovering from dual link failures in IP networks. The highlight of the developed routing approach is that a node re-routes a packet around the failed link without the knowledge of the second link failure. The proposed technique requires three protection addresses for every node, in addition to the normal address. Associated with every protection address of a node is a protection graph. Each link connected to the node is removed in at least one of protection graphs and every protection graph is guaranteed to be two-edge connected. The network recovers from the first failure by tunneling the packet to the next-hop node using one of the protection addresses of the next-hop node; and the packet is routed over the protection graph corresponding to that protection address. We prove that it is sufficient to provide up to three protection addresses per node to tolerate any arbitrary two link failures in a three-edge connected graph. We evaluate the effectiveness of the proposed technique over several network topologies.	algorithm;backup;connectivity (graph theory);digital visual interface;encapsulation (networking);internet protocol suite;network packet;network topology;overhead (computing);routing;scalability;simulation;tunneling protocol	Shrinivasa Kini;Srinivasan Ramasubramanian;Amund Kvalbein;Audun Fosselie Hansen	2009	IEEE INFOCOM 2009	10.1109/INFCOM.2009.5062052	routing;the internet;telecommunications;computer science;connectivity;graph theory;distributed computing;quantum tunnelling;network topology;computer network	Metrics	-7.15965421192953	80.40160456844436	27559
8a9f33eec9b3924def4177051f89dc63a26057e5	efficient security mechanisms for overlay multicast based content delivery	distributed system;eje troncal;virtual network;systeme reparti;mise a jour;web pages;multimedia;red www;service provider;network access control;real time;securite informatique;reseau web;multidestinatario;flux donnee;flujo datos;overlay multicast;commande repartie;probabilistic approach;orientado servicio;scaling up;reseau federateur;actualizacion;computer security;sistema repartido;internet;criptografia;enfoque probabilista;cryptography;approche probabiliste;seguridad informatica;temps reel;multimedia data;content delivery;security key;overlay network;tiempo real;cryptographie;world wide web;oriente service;access control;group key management;control repartido;dos resilient;backbone;data flow;cle securite;distributed control;multidestinataire;updating;red virtual;multicast;service oriented;reseau virtuel;key distribution;llave seguridad	• Node Presence Dynamics • Exponential Distributions • A Queuing Model A k-Random Injection Scheme There are two major security problems of overlay multicast: network access control and group key management. Previous research studied these two issues separately. By exploiting the special property of overlay multicast that a node is both a group member and a router, we propose: • A bandwidth-efficient scheme CRBR that seamlessly integrates network access control and group key management. • A DoS-resilient key distribution scheme k-RIP which delivers updated keys to a large fraction of nodes with high probability even if an attacker can selectively compromise nodes in the multicast data delivery hierarchy.	access network;digital distribution;group key;key distribution;key management;multicast;network access control;overlay network;router (computing);with high probability	Sencun Zhu;Chao Yao;Donggang Liu;Sanjeev Setia;Sushil Jajodia	2007	Computer Communications	10.1016/j.comcom.2006.10.003	service provider;multicast;overlay network;telecommunications;protocol independent multicast;computer science;cryptography;access control;operating system;pragmatic general multicast;source-specific multicast;network access control;key distribution;computer security;xcast;computer network	Security	-5.344934672266471	76.31593867226161	27589
23fd18f19869a8db7364814aa44dcded67abcaf0	a contract-ruled economic model for qos guarantee in mobile peer-to-peer streaming services	service provider;component;qos guarantee;contractual constraint contract ruled economic model qos guarantee mobile peer to peer streaming service mobile streaming application qos trading market;structural equation modeling;economic model;qos;quality of service media streaming mobile communication peer to peer computing;youtube;peer to peer streaming;mobile communication;qoe;media streaming;quality of service contracts bandwidth mobile communication resource management joints cost accounting;peer to peer computing;quality of service	In this paper, we provide a comprehensive treatment of QoS guarantee for mobile streaming applications through a contract-ruled approach. We envision a peer-to-peer streaming system as a QoS trading market, where the involved parties, Services Provider (SP), End User (EU) and assisting peers, are all real economic entities that are organized with contractual constraints for achieving a stable and guaranteed QoS output. The QoS trading in the market is classified into two parts, a basic contract that establishes the business agreement between an interested EU and a SP and a subcontract that achieves a desired joint QoS output. The proposed scheme can benefit all parties.	contingency (philosophy);end-to-end encryption;entity;pareto efficiency;peer-to-peer;quality of service;software deployment	Libin Yang;Wei Lou	2012	2012 IEEE 20th International Workshop on Quality of Service	10.1109/IWQoS.2012.6245998	mobile qos;quality of service;computer science;internet privacy;computer security;computer network	Embedded	-24.852882983850066	75.47476398816337	27670
4ccbc02229c96d7208ec273e858ad43bc3b84feb	characterizing tenant behavior for placement and crisis mitigation in multitenant dbmss	tenant characterization;shared nothing architectures;database consolidation;multitenancy;elastic data management	A multitenant database management system (DBMS) in the cloud must continuously monitor the trade-off between efficient resource sharing among multiple application databases (tenants) and their performance. Considering the scale of \attn{hundreds to} thousands of tenants in such multitenant DBMSs, manual approaches for continuous monitoring are not tenable. A self-managing controller of a multitenant DBMS faces several challenges. For instance, how to characterize a tenant given its variety of workloads, how to reduce the impact of tenant colocation, and how to detect and mitigate a performance crisis where one or more tenants' desired service level objective (SLO) is not achieved.  We present Delphi, a self-managing system controller for a multitenant DBMS, and Pythia, a technique to learn behavior through observation and supervision using DBMS-agnostic database level performance measures. Pythia accurately learns tenant behavior even when multiple tenants share a database process, learns good and bad tenant consolidation plans (or packings), and maintains a pertenant history to detect behavior changes. Delphi detects performance crises, and leverages Pythia to suggests remedial actions using a hill-climbing search algorithm to identify a new tenant placement strategy to mitigate violating SLOs. Our evaluation using a variety of tenant types and workloads shows that Pythia can learn a tenant's behavior with more than 92% accuracy and learn the quality of packings with more than 86% accuracy. During a performance crisis, Delphi is able to reduce 99th percentile latencies by 80%, and can consolidate 45% more tenants than a greedy baseline, which balances tenant load without modeling tenant behavior.	array dbms;baseline (configuration management);cloud computing;colocation centre;database;embarcadero delphi;experiment;greedy algorithm;hill climbing;interaction;load balancing (computing);multitenancy;operating system;pythia;search algorithm;self-management (computer science);semiconductor consolidation;sensor	Aaron J. Elmore;Sudipto Das;Alexander Pucher;Divyakant Agrawal;Amr El Abbadi;Xifeng Yan	2013		10.1145/2463676.2465308	real-time computing;multitenancy;database;computer security	DB	-23.209300333134077	60.93773198117747	27829
544873bf2a4b9350c9132d09a97c81f5607604ff	tcp-based media transport in the session description protocol (sdp)		"""Status of this Memo This document specifies an Internet standards track protocol for the Internet community, and requests discussion and suggestions for improvements. Please refer to the current edition of the """"Internet Official Protocol Standards"""" (STD 1) for the standardization state and status of this protocol. Distribution of this memo is unlimited. Abstract This document describes how to express media transport over TCP using the Session Description Protocol (SDP). It defines the SDP 'TCP' protocol identifier, the SDP 'setup' attribute, which describes the connection setup procedure, and the SDP 'connection' attribute, which handles connection reestablishment."""	identifier;internet;std bus;session description protocol	David Yon;Gonzalo Camarillo	2005	RFC	10.17487/RFC4145	real-time computing;computer science;distributed computing;computer network	Networks	-25.39061069063273	88.53064604328871	27854
d1ec5b704bf75e30aacda6c5c36b22ce7a9f0ae5	a* algorithm based optimization for cloud storage	a* algorithm;cloud atorage;cloud computing;optimization	Cloud Storage provide users with storage space and make user friendly and timely acquire data, which is foundation of all kinds of cloud applications. However, there is lack of deep studies on how to optimize cloud storage aiming at improvement of data access performance. In this paper, mathematical description for cloud storage optimization is given and as a objective optimization problems which is solved by our proposed optimized A* algorithm, as a result the data is distributed in appropriate nodes with the best efficiency. The experimental results demonstrate the performance of the algorithms is feasible in reducing MakeSpan, and the optimization can produce a storage strategy which is keeping with the real conditions. Besides, lastly, the time limitation of A* algorithm is investigated in experiments.	a* search algorithm;cloud computing;cloud storage;data access;experiment;makespan;mathematical optimization;usability	Xun-Yi Ren;Xiao-Dong Ma	2010	JDCTA		real-time computing;simulation;converged storage;computer science;distributed computing	HPC	-19.557933965793328	63.21659189439269	27931
700da8defd3fb19206d15eff4ec0eb439504ba4b	a remote control and management scheme for deployed vsats: an approach for the usaf pathfinder flexible modem interface		This paper describes an approach to address the challenges currently found in the management, provisioning, and troubleshooting of deployed SATCOM Terminals. We believe the proposed solution will address a major capabilities gap in the DOD's ability to maintain reliable and resilient network communications flows required for mission success in a dynamic net-centric battlefield. The proposed solution when fully implemented, will strengthen communications reliability, flexibility, and performance, while decreasing the support and logistics burden on the Warfighter in the field, resulting in increased mission effectiveness and resiliency. This paper outlines the problems we address, the high-level technology solution, and a brief description of an implementation of the proposed architecture which we believe implements most if not all the key requirements of the USAF SMC Pathfinder Flexible Modem Interface (FMI).	computer performance;embedded system;finnish meteorological institute;high- and low-level;logistics;net-centric;provisioning;remote control;remote support;requirement;router (computing);satellite modem;throughput	David N. Meadows;Jordan Thomas	2017	MILCOM 2017 - 2017 IEEE Military Communications Conference (MILCOM)	10.1109/MILCOM.2017.8170818	computer network;architecture;troubleshooting;computer science;battlefield;pathfinder;software;provisioning;remote control;government	HPC	-11.070918221796985	85.38669050264131	27939
64afe8b9a5df70fe93df86ab0f0488ffb6a81eec	adaptive multimedia mining on distributed stream processing systems	large scale mining;topology;semantic concept detection;ucla;resource adaptive mining multimedia mining stream processing semantic concept detection large scale mining;support vector machines;multimedia streaming;resource manager;semantics;distributed stream processing systems;multimedia mining;data mining;streaming media multimedia communication semantics topology data mining optimization;system resource manager;large scale;streaming media;multimedia communication;operating characteristic;support vector machines data mining;optimization;resource availability;support vector machine;stream processing;hierarchical topology;dynamic adaptation;semantic concept detection adaptive multimedia mining distributed stream processing systems multimedia streams support vector machine hierarchical topology system resource manager distributed game theoretic optimization;multimedia streams;distributed game theoretic optimization;adaptive multimedia mining;resource adaptive mining	We present an application for distributed semantic concept detection in multimedia streams. The streams are mined using Support Vector Machine based concept detectors (classifiers) deployed on a distributed stream processing system. We organize the classifiers into a hierarchical topology based on semantic relationships between the concepts of interest, and use the system resource manager to place the topology across a set of processing nodes. We then develop distributed game theoretic optimization strategies for dynamic adaptation of individual classifier operating characteristics in order to maximize end-to-end application utility under varying resource availability. As part of this paper, we will demonstrate the principles behind large-scale multimedia stream mining, and showcase the design, development, deployment, and distributed adaptation of such applications on a large scale cluster. A video demonstration of the system can be found at: http://childman.bol.ucla.edu/ICDM/demovideoicdm2009.swf	end-to-end principle;mathematical optimization;mined;network topology;sensor;software deployment;stream processing;support vector machine;theory;tree network	Deepak S. Turaga;Hyunggon Park;Rong Yan;Olivier Verscheure	2010	2010 IEEE International Conference on Data Mining Workshops	10.1109/ICDMW.2010.159	support vector machine;computer science;theoretical computer science;machine learning;data mining;database;semantics	DB	-26.392443185036996	69.99222756214571	27970
4931ad48dfb056a83bd2b592eefba66a32f98548	enhancing opportunistic networking using location based social networks	delay tolerant networks;machine learning;mobile opportunistic networks;location based social networks	The wireless communication capabilities of mobile devices have evolved rapidly during the last decade. Exploiting the various connectivity technologies available devices are capable of forming intermittently connected networks; in these networks, defined as Mobile Opportunistic Networks (MONs), a multitude of mobile devices are carried by people and data packets are transferred between these devices opportunistically i.e. when communication opportunities arise. One important issue that arises in MONs concerns routing which must cope with network partitioning, long delays, and dynamic topology changes. Several approaches have been proposed in the literature, including the use of location information and the exploitation of social characteristics. In this paper we aim to enhance MONs during the routing process by combining both location and social information. To achieve this we introduce the use of Location-Based Social Networks (LBSNs) in order to collect necessary information about users' possible future locations. We present the deployment architecture of the proposed system and analyse the business processes and application services, including foreseen components and their interactions.	business process;interaction;location-based service;mobile device;network packet;network partition;routing;social network;software deployment	Lambros Lambrinos;Pavlos Kosmides	2016		10.1145/2944789.2949545	simulation;evolving networks;telecommunications;engineering;computer security	HCI	-22.198529109472386	80.97843862591019	28140
dbedacd5d0e1b2771386d08c668e7b15295815a0	a qos information dissemination service for soa-based cscw applications	quality of service application software service oriented architecture collaborative work computerized monitoring computer science subscriptions packaging engines scalability;reverse chord ring;component services;information dissemniation;node partitioning technique;load balancing issue;web services peer to peer computing quality of service software architecture software reliability;computer supported cooperative work;p2p based publish subscribe service;p2p;qos information dissemination service;information reliability;data mining;message buffering;computer supported cooperative work applications;information dissemniation service oriented architecture computer supported cooperative work quality of service;software architecture;monitoring;publish subscribe;information dissemination;web services;fingers;subscriptions;rp ring;packaged delivery mechanism;load balance;rendezvous point;scalability;peer to peer computing;quality of service;service oriented architecture;software reliability;load balancing issue qos information dissemination service computer supported cooperative work applications service oriented architecture component services p2p based publish subscribe service information reliability message buffering packaged delivery mechanism reverse chord ring rp ring node partitioning technique	A fundamental problem that confronts SOA-based CSCW applications is the efficient and timely QoS information obtainment of component services. However, this issue has largely been overlooked. This paper presents a P2P based publish/subscribe service to disseminate new revised QoS information reliably and efficiently. Specialized rendezvous points and a replica mechanism are introduced to reduce the risk of subscriptions loss and consequently improve reliability. A message buffering and packaged delivery mechanism helps to reduce notification traffic. A reverse Chord ring, called RP ring, is designed to quicken subscription delivery and QoS information publication. Node partitioning technique is suggested to tackle the load balancing issue. Simulation results show that the service is reliable, efficient and scalable.	computer-supported cooperative work;load balancing (computing);peer-to-peer;publish–subscribe pattern;quality of service;rp (complexity);scalability;simulation	Xiao Zheng;Junzhou Luo;Jiuxin Cao	2009	2009 IEEE International Conference on Systems, Man and Cybernetics	10.1109/ICSMC.2009.5346848	web service;software architecture;real-time computing;scalability;quality of service;computer science;load balancing;service-oriented architecture;computer-supported cooperative work;peer-to-peer;distributed computing;publish–subscribe pattern;software quality;computer network	HPC	-21.311948969209396	69.64519907006652	28174
cd35c9cd1c6ed140d21b6b1e2350e35b05a40457	pcoord: network position estimation using peer-to-peer measurements	peer to peer computing position measurement network topology computer networks web and internet services solid modeling distance measurement collaboration predictive models economic indicators;network measurement;distributed networks;topology discovery;network coordinate;overlay multicast;euclidean distance;peer nodes network position estimation peer to peer measurements peer to peer network coordinate system geometric model overlay network topology decentralized peer to peer fashion pcoord approach real network measurements simulated topologies pair wise distance prediction nearest neighbor discovery;decentralized system;network topology;internet;computer network reliability peer to peer computing internet network topology;position estimation;overlay network;internet services;geometric model;file sharing;peer to peer computing;peer to peer;coordinate system;computer network reliability	Several recently emerged Internet services make use of application-level or overlay networks. Examples of such services include overlay multicast, structured peer-to-peer lookup services, and peer-to-peer file sharing. Many of these services could benefit from enabling participating end hosts to estimate their relative network locations within the overlay. We present PCoord, a peer-to-peer network coordinate system for overlay topology discovery and distance prediction. The goal of PCoord is to allow participating peer nodes in an overlay network to collaboratively construct an accurate geometric model of the overlay network topology in a completely decentralized peer-to-peer fashion. We evaluate the PCoord approach through extensive simulations using both real network measurements and simulated topologies. Our results indicate that the constructed geometric model can give accurate pair-wise distance prediction and nearest neighbor discovery. In particular, using a simulated overlay network consisting of over 3,400 peer nodes, our results indicate that over 90% of the peers can predict their closest peers by probing only a small fraction of the global peer population.	geometric modeling;lookup table;multicast;network topology;overlay network;peer-to-peer file sharing;simulation	Li-wei Lehman;Steven Lerman	2004	Third IEEE International Symposium on Network Computing and Applications, 2004. (NCA 2004). Proceedings.	10.1109/NCA.2004.1347756	the internet;overlay network;decentralised system;computer science;geometric modeling;coordinate system;euclidean distance;distributed computing;world wide web;file sharing;network topology;computer network	Networks	-11.71254804953122	76.83363987732565	28196
12b81a2234e7433e78043c27e7a13c732b32f313	location-aware self-organizing methods in femtocell networks	self optimization;femtocell access point;location;self organizing networks son;indoor;self healing	The evolution of cellular technologies has been followed by a continuous increase in their capacity and complexity. As a consequence, network management has become a challenge for network operators, especially at indoor environments. In these scenarios the percentage of calls and traffic is much higher than outdoors. Hence, intelligent and automatic mechanisms for network operation and maintenance are deemed necessary, leading to the so-called Self-Organizing Networks (SON). SON mechanisms analyze network indicators like counters, alarms, etc. in order to improve the network performance. Furthermore, in indoor scenarios, the recent advances in indoor positioning systems allow the integration of terminal position in the definition of novel SON techniques. The availability of this additional information provides knowledge about terminal distributions, mobility patterns, etc., which is useful data to enhance the efficiency and performance of SON techniques. In this sense, this paper proposes and develops location-aware SON techniques for indoor femtocell networks. In particular, novel self-optimization and self-healing algorithms are defined, which are supported by an indoor cellular-positioning system. Such mechanisms are evaluated in a real testbed envi-	algorithm;fingerprint;indoor positioning system;load balancing (computing);location awareness;mathematical optimization;medical algorithm;mobile phone;network performance;object access method;organizing (structure);rss;real-time clock;self-organization;software deployment;testbed	Alejandro Aguilar;Sergio Fortes Rodriguez;Mariano Molina García;Jaime Calle-Sánchez;José I. Alonso;Aaron Garrido Martin;Alfonso Fernandez-Durán;Raquel Barco	2015	Computer Networks	10.1016/j.comnet.2015.10.011	telecommunications;location;computer security;computer network	AI	-14.386628640405394	87.58931420174552	28240
f8274a2a9c212ecc7e3e9df97855a97eb5d2d987	qos-driven adaptive trust service coordination in the industrial internet of things	qos-driven;adaptive coordination;blockchain;industrial internet of things;multi-objective gray-wolf optimization;trust service	The adaptive coordination of trust services can provide highly dependable and personalized solutions for industrial requirements in the service-oriented industrial internet of things (IIoT) architecture to achieve efficient utilization of service resources. Although great progress has been made, trust service coordination still faces challenging problems such as trustless industry service, poor coordination, and quality of service (QoS) personalized demand. In this paper, we propose a QoS-driven and adaptive trust service coordination method to implement Pareto-efficient allocation of limited industrial service resources in the background of the IIoT. First, we established a Pareto-effective and adaptive industrial IoT trust service coordination model and introduced a blockchain-based adaptive trust evaluation mechanism to achieve trust evaluation of industrial services. Then, taking advantage of a large and complex search space for solution efficiency, we introduced and compared multi-objective gray-wolf algorithms with the particle swarm optimization (PSO) and dragonfly algorithms. The experimental results showed that by judging and blacklisting malicious raters quickly and accurately, our model can efficiently realize self-adaptive, personalized, and intelligent trust service coordination under the given constraints, improving not only the response time, but also the success rate in coordination.	acclimatization;algorithm;aspect-oriented software development;chi;chi-square test;conceptualization (information science);conflict (psychology);convergence (action);downstream (software development);face;index;internet of things;malware;mathematical optimization;natural science disciplines;numerous;open research;pareto efficiency;particle swarm optimization;personalization;quality of service;requirement;resource allocation;response time (technology);service-oriented device architecture;solutions;throughput;universities;yutopar;college	Jin Qi;Zian Wang;Bin Xu;Mengfei Wu;Zian Gao;Yanfei Sun	2018		10.3390/s18082449	engineering;quality of service;electronic engineering;systems engineering;industrial internet	Mobile	-19.017869227858046	64.00246658658946	28334
20579d65e08954b37584940129e2a6fb7f91a519	analysis of real-time multi-modal fp-scheduled systems with non-preemptible regions	software;control systems;real time systems hardware software mathematical model control systems time factors upper bound;upper bound;time factors;mathematical model;schedulability comparison realtime multimodal fp scheduled systems systems with nonpreemptible regions hardware operating mode software operating mode device resource utilization rts mms realtime control systems fixed priority schedulability analysis cyber physical systems pseudopolynomial complexity adaptive cruise control automotive systems;scheduling resource allocation;hardware;real time systems	Over the years, multiple hardware and software operating modes have been employed in many computing devices (e.g., tablets, smart-phones, GPS receivers) to efficiently utilize device resources. Similar advantages are also preferred in realtime systems (RTS) due to the requirement that a RTS must respond in a timely manner to a physical environment that may change sporadically. An efficient multi-modal system (MMS) is also a prerequisite for the development of real-time control systems which can maintain stable system behavior while ensuring timing guarantees for a changing set of real-time tasks. However, the currently-available fixed-priority (FP) schedulability analysis for multi-modal systems with both software/hardware modes is computationally expensive. In addition, current schedulability analysis for systems that support mode changes requires an assumption that is often not suitable for cyber-physical systems (CPS): sensing and actuation in the underlying physical plant are preemptible activities. However, sensors such as radar transmitter/ receiver requires non-preemptible access to the processor upon sending and then processing the return signal for accuracy. In this research, we develop a framework for multi-modal RTS scheduled by FP algorithm along with efficient schedulability analysis with pseudo-polynomial complexity considering the advantages and limitations of specific software/hardware model. Two simulations: a case study on adaptive cruise control in automotive systems, and schedulability comparison are included to corroborate the performance of the schedulability analysis.	algorithm;analysis of algorithms;cobham's thesis;control system;cyber-physical system;earliest deadline first scheduling;extensibility;global positioning system;iterative method;modal logic;pdf/a;parallel computing;physical plant;polynomial;preemption (computing);radar;real-time clock;scheduling (computing);scheduling analysis real-time systems;sensor;simulation;smartphone;tablet computer;time complexity	Masud Ahmed;Pradeep M. Hettiarachchi;Nathan Fisher	2015	21st IEEE Real-Time and Embedded Technology and Applications Symposium	10.1109/RTAS.2015.7108415	embedded system;real-time computing;simulation;computer science;control system;operating system;mathematical model;upper and lower bounds;worst-case execution time	Embedded	-7.988385878287929	60.79816334092397	28373
461eccb2ddd93cc5fe3d35803913109128328b6a	a simple analysis of the lru buffer policy and its relationship to buffer warm-up transient	analytical models;independent reference model;steady state value least recently used buffer policy nonempty buffer buffer warm up transient transient buffer hit probability empty buffer independent reference model replacement policy load surge;probability;steady state value;least recently used buffer policy;probability buffer storage transients;empty buffer;reference model;buffer storage;nonempty buffer;transient buffer hit probability;state estimation;surges;transient analysis;transaction databases;database systems;load surge;transients;buffer warm up transient;least recently used;transient analysis steady state state estimation surges transaction databases database systems analytical models;steady state;transient behavior;hitting probability;replacement policy	In a database system, a buffer hit transient may occur after a load surge or a node failure. The buffer warm-up transient is the expected buffer hit probability as a function of the time, starting with an empty buffer until the buffer is full. It is only after the buffer becomes full that a buffer replacement policy kicks in. The buffer transient analysis presented in this paper has three main contributions. First, we present a simple approximation for the buffer warm-up transient, and show that it agrees very well with simulation estimates. This result can be used to estimate how long it takes for the buffer hit probability to get to any specified fraction of its steady state value, starting with an empty buffer, say after a failure. Secondly, we show that the analysis for the buffer warm-up transient leads to a simple and very accurate estimate of the steady state buffer hit probability for the LRU buffer replacement policy. Previous approximations to the LRU policy are comparatively more complicated, but we show that they result in estimates indistinguishable from the simple analysis we present. Thirdly, we generalize this method to estimate the transient behavior of the LRU policy starting with a non-empty buffer. This method can be used, for instance, t o estimate the effect of a load surge on the buffer hit probability. We show that after a short load surge, it can take much longer than the surge duration for the buffer hit probability to return t o its steady state value.	approximation;database;simulation;steady state;transient state	Anupam Bhide;Asit Dan;Daniel M. Dias	1993		10.1109/ICDE.1993.344070	real-time computing;reference model;computer science;probability;database;distributed computing;steady state;cache algorithms;statistics	Metrics	-11.635752201096068	67.54438374710105	28388
5a5e5ba5998f33187612de223cb871614c1a816c	a methodology for clock benchmarking	software clock benchmarking;graph theory;clocks;data collection;distributed computing;telecommunication traffic global positioning system graph theory synchronisation telecommunication computing;telecommunication computing;testing;unix software clock benchmarking traffic monitoring distributed computing network latency accurate timestamping gps directed acyclic graph card;software performance;clocks delay synchronization computer errors testing global positioning system telecommunication traffic monitoring distributed computing software performance;synchronisation;telecommunication traffic;gps;monitoring;global positioning system;synchronization;fiber to the home;directed acyclic graph card;traffic monitoring;network latency;unix;computer errors;accurate timestamping	Accurate timestamping is a basic need in traffic monitoring as well as distributed computing in the broad sense, and is destined to become increasingly important as network latency becomes a hard barrier to improved performance across networks. Software clocks need to be improved to meet this challenge, however evaluating their performance is non trivial, as they are imbedded inside computing systems. We present a methodology for clock validation which allows many of the difficult problems to be resolved. Our method involves a combination of external and internal validation strategies, and makes use of GPS synchronized DAG cards and system clocks. We illustrate in detail how it may be applied using real data collected from 3 clocks implemented in UNIX PCs.	benchmark (computing);computer;directed acyclic graph;distributed computing;global positioning system;system time;testbed;unix	Julien Ridoux;Darryl Veitch	2007	2007 3rd International Conference on Testbeds and Research Infrastructure for the Development of Networks and Communities	10.1109/TRIDENTCOM.2007.4444689	clock synchronization;embedded system;synchronization;real-time computing;global positioning system;telecommunications;computer science;graph theory;operating system;distributed computing;computer security;computer network	HPC	-7.647817081791105	70.77842952622179	28432
ebeff4f0367c59d6aeebc79aee1fdfadbcc79ffa	design and evaluation of a system for mesh-based p2p live video streaming	video streaming;intelligent song selection;best practice;p2p;classification;overlay network;mobile computing;modeling	This paper introduces StreamComplete, a new architecture and prototype system for mesh-based P2P live video streaming; it realizes a new concept of overlay network's management as well as merges the best practices of treeand mesh-based approaches. StreamComplete creates a dynamic overlay network that optimizes itself on the basis of local conditions of peers. We have extensively evaluated the performance and the behavior of StreamComplete over the PlanetLab. Our experiments demonstrate the ability of peers in managing the overlay network with autonomic behavior in case of network changes. Furthermore the system is scalable w.r.t. the cardinality of the overlay network, by requiring very few control traffic.	autonomic computing;best practice;experiment;mesh networking;overlay network;peer-to-peer;planetlab;prototype;scalability;streaming media	Federico Covino;Massimo Mecella	2008		10.1145/1497185.1497245	simulation;overlay network;systems modeling;biological classification;computer science;operating system;peer-to-peer;database;mobile computing;world wide web;best practice;computer network	OS	-13.723198821024557	76.83168763649975	28437
c9ad334a44fd088707b74bc2138849cfdace844a	embedded database management performance	application development;software;database system;embedded database management performance;embedded software mobile computing database systems;mobile device;performance evaluation;database management systems;resource constrained device;resource allocation;information retrieval;mobile communication benchmark testing software mobile handsets performance evaluation database systems;mobile computer;input output option;software engineering;design decision;database management;persistent data retrieval;input output;embedded systems;data storage;indexation;database systems;software development;mobile communication;ad hoc manner;mobile handsets;software engineering database management systems embedded systems information retrieval mobile computing resource allocation;mobile computing;benchmark testing;dbms solution;embedded software;dbms solution embedded database management performance software development mobile device input output option design decision ad hoc manner resource constrained device persistent data retrieval	Current methods for developing software for mobile devices don't account for input/output (I/O) options when design decisions are made. I/O needs are typically addressed in an ad hoc manner, and inexperienced application developers are not accustomed to programming for resource constrained devices and tend to ignore differences in performance between various persistent storage options. In this paper, we investigate the two primary methods for persistent storage on mobile devices and use a battery of tests to evaluate the optimal ways in which to retrieve persistent data from mobile devices. In our investigation, we uncover that if the number of records are less than 1000 then sequential files should be used as the data storage option. Furthermore, in cases involving nonindexed columns, the clear winner appears to be the embedded DBMS solution, especially as the data scales.	column (database);computer data storage;embedded database;embedded system;experience;hoc (programming language);input/output;mobile device;persistence (computer science)	Venkata N. Ramarekha Patchigolla;John A. Springer;Kyle Lutes	2011	2011 Eighth International Conference on Information Technology: New Generations	10.1109/ITNG.2011.171	input/output;benchmark;real-time computing;mobile telephony;embedded software;resource allocation;computer science;software development;operating system;computer data storage;data mining;mobile device;database;rapid application development;mobile computing;computer network	DB	-15.716298405483569	67.83246686794514	28511
71aa40f76552010cadfe839c17b3db471b484fa6	a meta-heuristic load balancer for cloud computing systems	meta heuristic;science and technology;genetic algorithm cloud computing systems service allocation system stability maintenance abstract model specification cloud resource utilization service migration costs prototype metaheuristic load balancer;resource allocation cloud computing formal specification genetic algorithms;simulated annealing;genetics;genetic algorithms algorithm design and analysis load modeling simulated annealing genetics computational modeling;computational modeling;load balancing;genetic algorithms;load modeling;meta heuristic cloud computing load balancing;algorithm design and analysis;cloud computing	This paper introduces a strategy to allocate services on a cloud system without overloading the nodes and maintaining the system stability with minimum cost. We specify an abstract model of cloud resources utilization, including multiple types of resources as well as considerations for the service migration costs. A prototype meta-heuristic load balancer is demonstrated and experimental results are presented and discussed. We also propose a novel genetic algorithm, where population is seeded with the outputs of other meta-heuristic algorithms.	cloud computing;experiment;function overloading;genetic algorithm;heuristic;heuristic evaluation;load balancing (computing);metaheuristic;pool (computer science);precomputation;procedural generation;prototype;tabu search	Leszek Sliwko;Vladimir Getov	2015	2015 IEEE 39th Annual Computer Software and Applications Conference	10.1109/COMPSAC.2015.223	algorithm design;real-time computing;genetic algorithm;simulated annealing;cloud computing;computer science;load balancing;theoretical computer science;operating system;cloud testing;distributed computing;utility computing;computational model;computer security;science, technology and society	Embedded	-16.929187524882437	63.0612530393356	28615
00c65c614ff8a1241d334a0ff87a53a90efffff1	harnessing renewable energy in cloud datacenters: opportunities and challenges	renewable energy sources;computer centres;load balancing renewable energy cloud datacenters large scale datacenters generation models prediction methods capacity planning green datacenters intradatacenter workload scheduling;renewable energy sources green products cloud computing predictive models wind speed wind forecasting energy harvesting data centers;power consumption;green computing;renewable energy sources computer centres green computing power consumption	The proliferation of cloud computing has promoted the wide deployment of largescale datacenters with tremendous power consumption and high carbon emission. To reduce power cost and carbon footprint, an increasing number of cloud service providers have considered green datacenters with renewable energy sources, such as solar or wind. However, unlike the stable supply of grid energy, it is challenging to utilize and realize renewable energy due to the uncertain, intermittent and variable nature. In this article, we provide a taxonomy of the state-of-the-art research in applying renewable energy in cloud computing datacenters from five key aspects, including generation models and prediction methods of renewable energy, capacity planning of green datacenters, intra-datacenter workload scheduling and load balancing across geographically distributed datacenters. By exploring new research challenges involved in managing the use of renewable energy in datacenters, this article attempts to address why, when, where and how to leverage renewable energy in datacenters, also with a focus on future research avenues.	cloud computing;data center;load balancing (computing);scheduling (computing);software deployment;variable (computer science)	Wei Deng;Fangming Liu;Hai Jin;Bo Li;Dan Li	2014	IEEE Network	10.1109/MNET.2014.6724106	renewable energy;green computing;real-time computing;simulation;computer science;operating system	HPC	-21.278847865173024	62.385114846113105	28684
d4a0bab0b12701b9f41043748c70ebaf29262e86	an active access-point selection approach for dependable wireless mesh networks	active access point selection;wireless mesh network;algorithm;np complete;throughput maximization	As an inexpensive, flexible, and scalable Internet-access wireless network, we have studied the architecture, protocols, and design optimizations of the Wireless Internet-access Mesh NETwork (WIMNET) that adopts multiple access-points (APs) connected through wireless links. WIMNET can improve the dependability to failures of APs and/or their links by allocating APs redundantly in the network field. Because redundant APs may increase the operational cost and degrade the throughput due to increasing radio interferences, only the necessary APs for connectivity between the hosts and the Internet gateway should be activated in communications. In this paper, we first define the active AP selection problem of selecting the minimum number of active APs, and prove the NP-completeness of its decision version through reduction from the known minimum set cover problem. Then, we propose an active AP selection algorithm of deactivating APs one by one until no more AP can be deactivated. Due to the limited transmission capacity in WIMNET, we further present an algorithm extension for throughput maximization. We verify the effectiveness of our proposal through simulations in three instances, where the number of active APs is reduced by more than 40% and the throughput is improved by more than 10% from the original in any instance.		Nobuo Funabiki;Junki Shimizu;Masaharu Hata;Shigeru Tomisato;Toru Nakanishi;Kan Watanabe	2011	Journal of Interconnection Networks	10.1142/S0219265911002915	wireless mesh network;real-time computing;np-complete;computer science;operating system;distributed computing;computer security;computer network	Mobile	-7.4547285515561	81.64983580419171	28710
43a27f6a3f7b3c52b66e1d634ad76d91ca5ba984	adaptive partitioning and scheduling for enhancing www application performance	distributed system;largeur bande;architecture systeme;systeme reparti;red www;etude experimentale;digital library;equilibrio de carga;resource management;equilibrage charge;program library;algorithme;alexandria digital library;algorithm;gestion recursos;sistema repartido;internet;scheduling;analyse performance;anchura banda;performance analysis;load balancing;bibliotheque programme;gestion ressources;bandwidth;world wide web;arquitectura sistema;ordonamiento;reseau www;load balance;information system;system architecture;communication;comunicacion;estudio experimental;systeme information;ordonnancement;biblioteca programa;digital mapping;algoritmo;sistema informacion;analisis eficacia	This paper studies runtime partitioning, scheduling and load balancing techniques for improving performance of online WWW-based information systems such as digital libraries. The main performance bottlenecks of such a system are caused by the server computing capability and Internet bandwidth. Our observations and solutions are based on our experience with the Alexandria Digital Library (ADL) testbed at UCSB, which provides online browsing and processing of documents, digitized maps, and other geo-spatially mapped data via the WWW. A proper partitioning and scheduling of computation and communication in processing a user request on a multiprocessor server and transferring some computation to client-site machines can reduce network traffic and substantially improve system response time. We propose a partitioning and scheduling mechanism that adapts to resource changes and optimizes resource utilization and demonstrate the application of this mechanism for online information browsing. We also provide a performance analysis and experimental results to study the impact of resource availability and the effectiveness of our scheduling techniques. © 1998 Academic Press	computation;digital library;information system;library (computing);load balancing (computing);map;multiprocessing;national geospatial digital archive;network traffic control;profiling (computer programming);response time (technology);scheduling (computing);server (computing);testbed;www	Daniel Andresen;Tao Yang;Oscar H. Ibarra;Ömer Egecioglu	1998	J. Parallel Distrib. Comput.	10.1006/jpdc.1998.1423	fair-share scheduling;embedded system;digital library;simulation;digital mapping;dynamic priority scheduling;computer science;load balancing;resource management;world wide web	HPC	-12.504596249684948	64.44843211966193	28718
130044ec7fd9db6a5d84de9e02c5f976c9b194c8	scheduling with optimized communication for time-triggered embedded systems	protocols;time triggered;distributed embedded system;information science;system modeling;statecharts;processor scheduling;distributed computing;scheduling embedded systems data flow computing safety critical software;control flow time triggered embedded systems scheduling safety critical data flow;packaging;communication model;embedded system;computer architecture;embedded systems;scheduling algorithm;polis;scheduling;execution environment;safety critical software;control flow;time triggered embedded systems;communication protocol;data flow computing;embedded system processor scheduling protocols communication system control packaging computer architecture delay distributed computing embedded computing information science;communication system control;data flow;system architecture;process scheduling;cfsms;safety critical;large classes;embedded computing	We present an approach to process scheduling for synthesis of safety-critical distributed embedded systems. Our system model captures both the flow of data and that of control. The communication model is based on a timetriggered protocol. We take into consideration overheads due to communication and the execution environment. Communications have been optimized through packaging of messages into slots with a properly selected order and lengths. Several experiments demonstrate the efficiency of the approach.	dataflow;embedded system;experiment;scheduling (computing)	Paul Pop;Petru Eles;Zebo Peng	1999		10.1145/301177.303812	embedded system;real-time computing;computer science;distributed computing	Embedded	-7.388893781480295	61.69946631040537	28721
63d6be3ecfda07a5964e1456ca1a93dc30467042	performance impact of load balancers on server farms	load balance	Server Farms have gained popularity for providing scalable and reliable computing / Web services. A load balancer plays a key role in this architecture, serving as a “traffic cop” to direct the requests to suitable servers. Selecting and using the proper load balancer to match the characteristics of the servers will have a significant performance impact. This paper examines some commonly used loadbalancing algorithms for server farms, introduces a performance model as a basis for the analysis, and will show how to select a load balancer to maximize the performance potential of the server farms.	algorithm;load balancing (computing);scalability;server (computing);server farm;web service	Yiping Ding	2004			server farm;computer network;load balancing (computing);business	Metrics	-22.66589481451077	61.831975888029696	28742
3731de6410abf65c74f8d9f018b9bd1a8777a209	design and analysis of permutation-based pyramid broadcasting	schema pyramidal;latencia respuesta;video a peticion;bandwidth allocation;video a la demande;radiodifusion;conception;latence reponse;permutation;forme pyramidale;pyramid schemes;response latency;forma piramidal;waiting time;video on demand;analyse performance;permutacion;performance analysis;pyramidal shape;diseno;design;broadcasting;radiodiffusion;set top box;analisis eficacia	Periodic broadcasting can be used to support near-video-on-demand for popular videos. For a given bandwidth allocation, pyramid broadcasting schemes substantially reduce the viewer latency (waiting) time compared to conventional broadcasting schemes. Nevertheless, such pyramid schemes typically have substantial storage requirements at the client end, and this results in set-top boxes needing disks with high transfer rate capabilities. In this paper, we present a permutation-based pyramid scheme in which the storage requirements and disk transfer rates are greatly reduced, and yet the viewer latency is also smaller. Under the proposed approach, each video is partitioned into contiguous segments of geometrically increasing sizes, and each segment is further divided into blocks, where a block is the basic unit of transmission. As in the original pyramid scheme, frequencies of transmission for the different segments of a video vary in a manner inversely proportional to their size. Instead of transmitting the blocks in each segment in sequential order, the proposed scheme transmits these blocks in a prespecified cyclic permutation to save on storage requirements in the client end. Performance analyses are provided to quantify the benefits of the new scheme.	bitstream;block (programming);client-side;cyclic permutation;fm broadcasting;forward error correction;pyramid (image processing);requirement;server-side;set-top box;transmitter	Charu C. Aggarwal;Joel L. Wolf;Philip S. Yu	1999	Multimedia Systems	10.1007/s005300050144	design;real-time computing;simulation;telecommunications;computer science;operating system;permutation;broadcasting;algorithm;computer network;bandwidth allocation	HPC	-14.519640569266725	70.88032526118621	28802
c0a4d6ce503ca502d34f82ffa360ff8647ea8229	introduction from session chair - multimedia and telecommunications track session: content delivery	content delivery	Technologies for content delivery over large-scale networks supporting the distribution of audio and video streams are broadly investigated at present. Various approaches have been suggested such as, e.g., batching and patching techniques, seeking the optimal trade-off between multicast and unicast communication. A clear trend towards personalized and on-demand multimedia services further increases the challenge to find appropriate solutions providing high performance and throughput on the one hand as well as low latencies on the other hand. Such divergent requirements can only be met if new mechanisms for content delivery are developed that take advantage of the intelligence and resources being present within and at the edges of the network. Recent investigation in peer-to-peer and overlay networks brought up new communication mechanisms that are highly scalable and efficient. These approaches particularly make use of functionality and resources provided by the end-users which are located at the edges of the Internet. All papers introduced in this session go into this direction. The first paper, entitled “An Implementation of an overlay network architecture scheme for streaming media distribution” by Ch. Z. Patrikakis, Y. Despotopoulos, A. M. Rompotis, N. Minogiannis, A. L. Lambiris and A. D. Salis uses end-clients as relaying nodes in an overlay network infrastructure for the distribution of video streams. The second paper is about “Providing Interactive Video On Demand Services in Distributed Architectures” and is written by B. Oazzaz, R. Suppi, A. Ripoll, F. Cores, P. Hernández and E. Luque. It presents the design of an interactive VoD proxy server combining multicast and unicast channels with the prefetching technique that makes use of client buffering. The third paper, called “A New Asynchronous Hybrid Mechanism for Video on Demand” by Ramesh Yerraballi, Xiaoru Zhao and Jasmin Kanabar proposes a new strategy introducing the property of asynchronicity to satisfy requests at peak loads by accordingly compromising on latency.	cpu cache;digital distribution;interactivity;internet;jasmin;multicast;network architecture;overlay network;patch (computing);peer-to-peer;personalization;proxy server;requirement;scalability;server (computing);streaming media;throughput;unicast	David Hausheer	2003		10.1109/EURMIC.2003.1231590	computer science;multimedia;world wide web;computer network	Networks	-14.372009375643874	84.55621831754193	28818
0117f7b9b3d0fa473062ab7ce6d1047c76403b1f	a precise computational approach to knowledge	electrical engineering and computer science;thesis	The seminal work of Goldwasser, Micali and Rackoff put forward a computational approach to knowledge in interactive systems, providing the foundation of modern Cryptography. Their notion bounds the knowledge of a player in terms of his potential computational power (technically defined as polynomial-time computation). In this thesis, we put forward a stronger notion that preciselybounds the knowledge gained by a player in an interaction in terms of the actualcomputation he has performed (which can be considerably less than any arbitrary polynomialtime computation). Our approach not only remains valid even if P = NP, but is most meaningful when modeling knowledge of computationally easy properties. As such, it broadens the applicability of Cryptography and weakens the complexity theoretic assumptions on which Cryptography can be based.	computation;cryptography;p versus np problem;polynomial;theory;time complexity	Rafael Pass	2006			computer science;theoretical computer science;algorithm	Crypto	-33.55825965316532	73.25625562747294	28830
57fd8fa5aff0d811e8e7e8e6e0bf3612c7dff137	research on communication-efficient method for distributed threshold monitoring	distributed data;distributed system;adjustment factor distributed data stream threshold monitoring continuous query communication reduction representative object;adjustment factors;routing;distributed threshold monitoring;monitoring algorithm design and analysis resource management distributed databases artificial neural networks routing data models;continuous query;distributed processing;resource management;threshold monitoring;system monitoring;representative object;communication reduction;artificial neural networks;distributed data stream;monitoring;distributed databases;adjustment factors communication efficient method distributed threshold monitoring communication reduction continuous threshold monitoring distributed systems;experimental evaluation;adjustment factor;distributed systems;system monitoring distributed processing;communication efficient method;continuous threshold monitoring;correctness proof;algorithm design and analysis;data models	The problem of communication reduction over continuous threshold monitoring in distributed systems is considered in this paper. A Communication Efficient Method (CEM) is proposed which utilizes the relationship among objects and processes them as a whole, therefore achieves better performance than those who holding each object separately. In specific, the object with largest value is chose as the representative object, and adjustment factors are used to guarantee that local value of representative object is also the largest one in each remote node. Therefore, only the representative object needs to be monitored continuously as long as all the local constraints are valid. When local constraint is violated, communication is needed among the coordinator and remote nodes to rebuild the constraint. The algorithms are described in this paper; algorithms' correctness proof and extension are also provided. Experimental evaluation on real data sets show the efficiency of CEM on communication reduction over distributed threshold monitoring.	algorithm;correctness (computer science);distributed computing	Li Tian;Peng Zou;Feng Wu;Aiping Li	2008	2008 The Ninth International Conference on Web-Age Information Management	10.1109/WAIM.2008.55	data modeling;algorithm design;system monitoring;routing;real-time computing;computer science;resource management;data mining;database;distributed computing;data transfer object	DB	-15.019456428535484	64.8648971674199	28890
83eeb53e5183df40531a317797e51f514c6800e1	mace: a multi-attribute combinatorial exchange	quality attributes;004;distributed computing;numerical simulation;auctions and bidding integer programming combinatorial exchange market engineering grid;economic performance;time constraint	The Grid is a promising technology for providing access to distributed computational capabilities such as processors or storage space. One of the key problems in current Grid infrastructures is deciding which jobs are to be allocated to which resources at what time. In this context, the use of market mechanisms for allocating resources is a promising approach toward solving these problems. This paper proposes an auction mechanism for allocating and scheduling computer resources which have multiple quality attributes and time constraints. The mechanism is evaluated according to its economic performance by means of a numerical simulation.	central processing unit;computer simulation;grid computing;job stream;kronos;list of system quality attributes;location-based service;scheduling (computing);value (ethics)	Björn Schnizler	2006		10.1007/978-3-540-77554-6_7	simulation;computer science;operations management;theoretical computer science	HPC	-17.920137908682285	64.22720001275009	28937
689e40035b5060514eb4225db62dd5c70d2734b9	robust network tomography: k-identifiability and monitor assignment	monitoring measurement tomography network topology additives reliability merging;topology computer network reliability;isp network topologies robust network tomography k identifiability link failures polynomial time algorithms	Network tomography is an attractive approach for inferring internal network states at edge nodes. Recently, there is a growing interest in the basic understanding of the topological conditions that ensure identifiability in a general network. Un, existing works assume an ideal network model where all network elements are reliable. In this paper, we are aiming to propose topological conditions to ensure identifiability in the presence of any k link failures (k ≥ 0), using measurement paths and cycles. We propose a novel concept called k-identifiability. We propose sufficient and necessary topological conditions to ensure k-identifiability. Based on the established theoretical foundations, we propose two efficient polynomial-time algorithms for addressing two closely related questions. (1) Given a network with specified monitors, which links are k-identifiable? (2) Given a network and κ monitors, where should these monitors be placed such that the number of k-identifiable links is maximized? Simulation results on real ISP network topologies show the effectiveness of our algorithms.	algorithm;intranet;monitor (synchronization);network model;network topology;simulation;time complexity;tomography	Wei Ren;Wei Dong	2016	IEEE INFOCOM 2016 - The 35th Annual IEEE International Conference on Computer Communications	10.1109/INFOCOM.2016.7524375	simulation;theoretical computer science;mathematics;network simulation;distributed computing;network delay;network topology;computer network	Embedded	-7.270420031821373	78.79044853102477	28969
5defd3d8642cbf0461610d7b1152f091d44e66c4	understanding demand volatility in large vod systems	quality assurance;garch;time varying;volatility;service level;measurement;resource allocation;time series;statistical model;large scale;volatility forecasting;demand prediction;video on demand;cost effectiveness;diversification;traffic forecast	Bandwidth usage in large-scale Video on Demand (VoD) systems varies rapidly over time, due to unpredictable dynamics in user demand and network conditions. Such bandwidth volatility makes it hard to provision the exact amount of server resources that matches the demand in each video channel, posing significant challenges to achieving quality assurance and efficient resource allocation at the same time. In this paper, we seek to statistically model time-varying traffic volatility in VoD servers, leveraging heteroscedastic models first used to interpret economic time series, with the goal of forecasting not only traffic patterns but also traffic volatility. We present the application of volatility forecast to efficient resource allocation that provides probabilistic service level guarantees to user groups. We also discuss volatility reduction from diversification, and its implications to new strategies for cost-effective server management. Our study is based on monitoring the workload of a large-scale commercial VoD system widely deployed on the Internet.	content delivery network;diversification (finance);emoticon;heuristic (computer science);internet;modern portfolio theory;provisioning;server (computing);time series;tracing (software);video blog;volatility	Di Niu;Baochun Li;Shuqiao Zhao	2011		10.1145/1989240.1989252	diversification;autoregressive conditional heteroskedasticity;statistical model;quality assurance;cost-effectiveness analysis;service level;volatility;resource allocation;time series;measurement;statistics	Metrics	-19.653805981567963	73.25555018285218	29011
4bfbec3af95bc848ba11328ae628718d99f6339d	distributed hot spots caching mechanism for queries with popular distribution	p2p system;cache storage;distributed hash table distributed hot spots caching mechanism zipf like distribution p2p network ip address port number;ip address;distributed hot spots caching mechanism;distributed hash table;availability;routing;p2p;port number;distributed hash table dht;zipf like distribution;hot spot;peer to peer p2p;peer to peer computing cache storage file organisation ip networks;chord;internet;peer to peer computing telecommunication traffic web and internet services frequency gaussian distribution computer science distributed computing educational institutions floods large scale systems;p2p network;fingers;distributed databases;ip networks;p2p networks;peer to peer computing;peer to peer;distributed hash table dht peer to peer p2p chord;file organisation	Peer-to-peer (P2P) systems have gained considerable attention in the past few years. Since the popularity distribution of queries follows a zipf-like distribution in a P2P network, the performance can get significant improvement if a simple and effective caching mechanism called hot spots caching mechanism (HSCM) is used, which stores the IP address and port number of the successor node of the key. Simulations also show that the HSCM is basically independent of particular P2P algorithms and can be easily combined with other improved methods to further improve the performance of P2P search capabilities.	algorithm;cache (computing);computer simulation;peer-to-peer;zipf's law;zipf–mandelbrot law	Jianyong Chen;Haijian Long;Leijuan Liang	2008	2008 International Symposium on Computer Science and Computational Technology	10.1109/ISCSCT.2008.110	computer science;distributed computing;world wide web;computer network	Theory	-13.133569330443539	73.95811463389252	29032
6d14ce8b6865e62f4b9886ed9fe422b84a05cf84	towards fairness and efficiency in storage systems	blocking probability;performance guarantee;storage system;disk scheduling;fair scheduling;qos guarantee;advance reservations;co allocation;flexible time windows;application sharing	Fairness and overall I/O efficiency are two opposing forces when it comes to sharing I/O among different applications. Although providing QoS guarantees for applications sharing a storage server are desirable under many scenarios, existing work has not been able to make a convincing case for using fairness mechanisms for disk scheduling, mainly due to their impact on overall throughout. In this work, we plan to investigate two major issues: (1) study the trade-off between fairness and efficiency, and develop mechanisms to improve the I/O efficiency of fair schedulers (2) provide performance guarantees to applications in terms of higher-level application metrics (such as transactions/sec), by changing the parameters in a fairness algorithm that affect the allocations at the block level.	algorithm;algorithmic efficiency;fair queuing;fairness measure;file server;i/o scheduling;input/output;scheduling (computing);server (computing)	Ajay Gulati;Peter J. Varman;Arif Merchant;Mustafa Uysal	2007	SIGMETRICS Performance Evaluation Review	10.1145/1328690.1328715	fairness measure;real-time computing;computer science;operating system;maximum throughput scheduling;fair queuing;distributed computing;i/o scheduling;computer network	OS	-20.430745326972808	61.60149596359408	29063
389c853210df11721e8ee670a7f9315e32364608	nova: towards on-demand equivalent network view abstraction for network optimization		As many applications today migrate to distributed computing and cloud platforms, their user experience depends heavily on network performance. Software Defined Networking (SDN) makes it possible to obtain a global view of the network, introducing the new paradigm of developing adaptive applications with network views. A naive approach of realizing the paradigm, such as distributing the whole network view to applications, is not practical due to scalability and privacy concerns. Existing approaches providing network abstractions are limited to special cases, such as bottlenecks exist only at networks edges, resulting in potentially suboptimal or infeasible decisions. In this paper, we introduce a novel, on-demand network abstraction service that provides an abstract network view supporting not only accurate end-to-end QoS metrics, which satisfy the requirements of many peer-to-peer applications, but also multi-flow correlation, which is essential for bandwidth-sensitive applications containing many flows to conduct global network optimization. We prove that our abstract view is equivalent to the original network view, in the sense that applications can make the same optimal decision as with the complete information. Our evaluations demonstrate that the abstraction guarantees feasibility and optimality for network optimizations and protects the network service providers' privacy. Our evaluations also show that the service can be implemented efficiently; for example, for an extreme large network with 30,000 links and abstraction requests containing 3,000 flows, an abstract network view can be computed in less than one second.	application programming interface;bottleneck (software);distributed computing;end-to-end principle;flow network;global network;mathematical optimization;network performance;peer-to-peer;privacy;programming paradigm;requirement;scalability;software deployment;software-defined networking;turing completeness;user experience	Kai Gao;Qiao Xiang;Xin Wang;Yang Richard Yang;Jun Bi	2017	2017 IEEE/ACM 25th International Symposium on Quality of Service (IWQoS)	10.1109/IWQoS.2017.7969117	intelligent computer network;network service;element management system;real-time computing;computer network;network traffic control;network simulation;network architecture;network management station;computer science;overlay network;distributed computing	Networks	-12.158014792941884	81.6440261877563	29199
658335c841c2ad9c08a4acbb19f969096f1b3363	securing x.400 content with secure/multipurpose internet mail extensions (s/mime)		"""The techniques described in the Cryptographic Message Syntax [CMS] specification are general enough to support many different content types. The [CMS] specification thus provides many options for providing different security mechanisms. In order to ensure interoperability of systems within the X.400 community, it is necessary to specify the use of CMS features to protect X.400 content (called """"CMS-X.400"""" in this document)."""	cryptographic message syntax;interoperability;s/mime	Paul E. Hoffman;Chris Bonatti;Anders Eggen	2004	RFC	10.17487/RFC3854	privacy-enhanced electronic mail;computer science;internet privacy;world wide web;computer security;s/mime	Security	-27.02223212718255	87.65128541399106	29216
cdfd8177ad7b2b518639d007cd79cea792d2516e	static and dynamic polling mechanisms for fieldbus networks	distributed system;systeme reparti;red local;real time;time window;local network;sistema repartido;temps reel;tiempo real;real time communication;reseau local;communication;comunicacion;local area network;data transfer	Real-time local area networks like Fieldbus have to handle two types ofdata transfer, synchronous and asynchronous. The synchronous data is generated periodically and has to be transmitted before fixed deadlines. Asynchronous messages are generated by unforeseen events and thus cannot be predicted. The data transfer is handled in two different phases or time---windows. In this paper, we apply different algorithms that are known from the real-time schedluing discipline for real-time communication networks. Simplifications are made with respect to frame lengths and the resulting error is shown to be negligible for the type of data transfer considered. The algorithms generate the correct polling sequence for the data transfer automatically respecting the periodic deadlines. We also introduce dynamic mechanisms to extend time-windows and utilize the network bandwidth more efficiently. These algorithms are computed during the real-time operation of the network.	algorithm;fieldbus;microsoft windows;real-time clock;real-time computing;real-time transcription;telecommunications network	Prasad Raja;Guevara Noubir	1993	Operating Systems Review	10.1145/155870.155875	local area network;embedded system;real-time computing;computer science;operating system;distributed computing;computer security	Embedded	-5.685813924617635	70.71499631847165	29296
7b1cc20a021dc15848badeb634b4a41dcfaddacc	improvements in the field of device integration into automation systems with embedded web interfaces	internet protocol;embedded web server;web interface;test bed;software development;communication protocol;web technology	Web-Technologies which came up in many fields of automation seem to be a solution which improves device integration in many ways. On the one hand the used Ethernet improves the installation techniques with reliable and approved network cables and routing devices. On the other hand the used internet protocols provide several services for the application software development. With the introduction of those services, the local controller of the measurement devices has to execute complex communication protocols in addition to the device specific tasks. This fact has serious influences on the measurement device instrumentation and the execution of the device firmware. Concerning new developments and compatible adaptations of existing instruments several ways for the integration of web technologies are available. The following article is intended to explain the architectural aspects of device integrations using Industrial Ethernet by means of an embedded web server. As a practical example to this architecture, concepts and results of a new developed communication module called EWI (embedded web interface) are given to demonstrate the improvements in measurement device integration in the field of automotive test bed	automation;coprocessor;embedded http server;embedded system;firmware;graphical user interface;internet protocol suite;networking cables;peer-to-peer;rs-232;routing;server (computing);software development;testbed;user interface;web server;web service	Anton Scheibelmasser;Jürgen Menhart;Bernd Eichberger	2008			internet protocol;web service;web application security;embedded system;hypertext transfer protocol;communications protocol;web development;web modeling;data web;web-based simulation;web design;computer science;software development;web api;web navigation;web page;database;user interface;web 2.0;world wide web;web server;application server;mashup;testbed	Embedded	-23.436245011333153	83.32563834016938	29407
f6218ec36283beff6d72e26f9d328e7e479533e6	improving bittorrent network's performance via deploying helpers	peer to peer computing system performance bandwidth network servers file servers ubiquitous computing computer science embedded software software performance microelectronics;analytical models;dynamic change;bittorrent system;selfish peer resistance bittorrent network performance deploying helper bittorrent system bandwidth upload peer to peer network content file sharing;fluids;deploying helper;peer to peer network;system performance;servers;computational modeling;content file sharing;bittorrent;bandwidth upload;bandwidth;peer to peer computing;bittorrent network performance;selfish peer resistance;model simulation	This paper presents a study on how to increase the BitTorrent Networkpsilas performance via deploying Helpers by modeling, simulating and analyzing. We first define some high-bandwidth, high-connection and controllable super nodes as Helpers, and then try to find the best way to deploy them. Unlike other researchers, we focus on combining the advantages of both multi-server systems and BitTorrent Systems. Our main findings includes: (1) Deploying Helpers into BitTorrent Systems can distinctly enhance the system performance until the overall uploading bandwidth is no longer the constraint condition. (2) After deploying Helpers, the system can present resistance against selfish peers. (3) We can dynamically change the content of Helpers to serve the ever-changing hot torrents and make it only serve charged peers or local peers from economic angle.	bittorrent;constraint algorithm;server (computing);simulation;upload	Ke Xu;Yahui Yang;Tao Chen	2008	2008 IEEE/IFIP International Conference on Embedded and Ubiquitous Computing	10.1109/EUC.2008.96	bittorrent;computer science;operating system;computer performance;internet privacy;computational model;world wide web;bandwidth;server;computer network;fluid mechanics	Robotics	-26.92627754418824	74.58357853347552	29412
3f1db01a133de44c428a278e1150754d34735952	delay composition algebra: a reduction-based schedulability algebra for distributed real-time systems	delay composition algebra;directed graphs;directed acyclic graph;distributed system;control theory;processor scheduling;resource allocation;real time;schedulability analysis tool;schedulability analysis;additives;task end to end delay;split operator;distributed systems end to end delay schedulability analysis algebra;distributed real time system;directed acyclic graph delay composition algebra reduction based schedulability algebra distributed real time task system uniprocessor theory schedulability analysis tool pipe operator split operator workload balancing task end to end delay;algebra;variable speed drives;uniprocessor theory;periodic structures;pipelines;pipe operator;workload balancing;resource allocation algebra directed graphs processor scheduling real time systems;reduction based schedulability algebra;distributed systems;end to end delay;distributed real time task system;real time systems;algebra real time systems processor scheduling performance analysis control theory circuit theory delay systems computer science analytical models circuit stability	This paper presents the delay composition algebra: a set of simple operators for systematic transformation of distributed real-time task systems into single-resource task systems such that schedulability properties of the original system are preserved. The transformation allows performing schedulability analysis on distributed systems using uniprocessor theory and analysis tools. Reduction-based analyses techniques have been used in other contexts such as control theory and circuit theory, by defining rules to compose together components of the system and reducing them into equivalent single components that can be easily analyzed. This paper is the first to develop such reduction rules for distributed real-time systems. By successively applying operators such as PIPE and SPLIT on operands that represent workload on composed subsystems, we show how a distributed task system can be reduced to an equivalent single resource task set from which the end-to-end delay and schedulability of tasks can be inferred. We show through simulations that the proposed analysis framework is less pessimistic with increasing system scale compared to traditional approaches.	control theory;directed acyclic graph;distributed computing;end-to-end principle;job stream;linear algebra;named pipe;network analysis (electrical circuits);operand;real-time clock;real-time computing;real-time locating system;real-time transcription;scheduling (computing);scheduling analysis real-time systems;simulation;tree traversal;uniprocessor system	Praveen Jayachandran;Tarek F. Abdelzaher	2008	2008 Real-Time Systems Symposium	10.1109/RTSS.2008.38	embedded system;parallel computing;real-time computing;directed graph;resource allocation;food additive;computer science;operating system;end-to-end delay;distributed computing;pipeline transport;directed acyclic graph	Embedded	-8.980233989793541	62.07827893848873	29417
22e5910c3d43c150a05cb73784c93521257497e1	improving job scheduling algorithms in a grid environment	adaptive thresholding;computational grid;high speed networks;scheduling algorithm;load balance;grid computing;job scheduling;data grid	Due to the advances in human civilization, problems in science and engineering are becoming more complicated than ever before. To solve these complicated problems, grid computing becomes a popular tool. A grid environment collects, integrates, and uses heterogeneous or homogeneous resources scattered around the globe by a high-speed network. A grid environment can be classified into two types: computing grids and data grids. This paper mainly focuses on computing grids. In computing grid, job scheduling is a very important task. A good scheduling algorithm can assign jobs to resources efficiently and can balance the system load. In this paper, we propose a hierarchical framework and a job scheduling algorithm called Hierarchical Load Balanced Algorithm (HLBA) for Grid environment. In our algorithm, we use the system load as a parameter in determining a balance threshold. And the scheduler adapts the balance threshold dynamically when the system load changes. The main contributions of this paper are twofold. First, the scheduling algorithm balances the system load with an adaptive threshold and second, it minimizes the makespan of jobs. Experimental results show that the performance of HLBA is better than those of other algorithms.	algorithm;job scheduler;scheduling (computing)	Yun Han Lee;Seiven Leu;Ruay-Shiung Chang	2011	Future Generation Comp. Syst.	10.1016/j.future.2011.05.014	fair-share scheduling;parallel computing;real-time computing;flow shop scheduling;dynamic priority scheduling;computer science;rate-monotonic scheduling;load balancing;job scheduler;operating system;two-level scheduling;data grid;distributed computing;thresholding;round-robin scheduling;scheduling;grid computing	HPC	-16.73135397849004	61.90977446712907	29427
c43e4a6e3f34dda30fae71a4d86635b3a0f2eb21	churn: a key effect on real-world p2p software	churn;tcss;performance;unstructured;small world networks;computer network performance evaluation;telecommunication network topology computer network performance evaluation computer network reliability peer to peer computing small world networks;proceedings paper;tcss churn real world unstructured peer to peer performance;crawlers peer to peer computing topology servers measurement protocols dispatching;time 7 min peer to peer networks churn impact real world unstructured p2p networks p2p network topology performance metrics third party to servent crawling with servent to servent sampling tcss system parallel techniques distributed techniques crawling process peer arrivals departures neighbor replacements small world property top rank keyword searches;peer to peer computing;telecommunication network topology;peer to peer;real world;computer network reliability	Churn refers to a large number of arriving and departing participants within a short time in peer-to-peer (P2P) networks. This paper studies the impact of churn on real-world unstructured P2P networks. To this end, we need collecting snapshots of P2P network topology and associated performance metrics. Because P2P topology changes dynamically, the time to take a snapshot must be sufficiently short for the snapshots to be accurate. We propose Third-party-to-servent Crawling with Servent-to-servent Sampling (TCSS) system. TCSS uses a third-party crawling technique to collect network topology information without disturbing the original P2P network under investigation. Furthermore, TCSS adopts distributed and parallel techniques to speed up the crawling process. TCSS also employs a servent-to-servent sampling technique to gather the corresponding performance metrics of the P2P network simultaneously. Empirical results show that TCSS takes around 7 minutes to take a topology snapshot of the P2P network. Besides, we found that churn is indeed a combined effect of peer arrivals/departures and neighbor replacements. As the number of peers increases, the number of very long-lived peers remains nearly constant and the P2P network possesses a small-world property. Moreover, as churn aggravates, the average booting time of peers increases and the variation is proportional to the degree of churn. The response time of the top-rank keyword searches is not affected by the degree of churn.	booting;churn turbulent flow;elegant degradation;expect;file sharing;gnutella;network topology;overlay network;peer-to-peer;response time (technology);sampling (signal processing);small-world experiment;snapshot (computer storage)	Cheng-Yuan Ho;Ming-Chen Chung;Li-Hsing Yen;Chien-Chao Tseng	2013	2013 42nd International Conference on Parallel Processing	10.1109/ICPP.2013.23	performance;computer science;distributed computing;small-world network;world wide web;computer network	Metrics	-12.995282428153537	77.08129217386193	29466
1f0f01c74af83284ff58c3d0a20e5d11d4ddf78a	an algorithm for dynamic multicast traffic grooming in light-trail optical wdm mesh networks		A light trail is a unidirectional bus from a convener node to an end node, whose communication channel can be accessed at any intermediate node resulting in higher flexibility for multiplexing the traffic of multiple connections into the communication channel. The objective of dynamic multicast traffic grooming is to provision dynamically arriving multicast connections by using existing light trails or establishing new light trails such that request blocking ratio is reduced. An effective dynamic multicast traffic grooming algorithm is proposed based on a novel auxiliary graph model that remedies the drawbacks of auxiliary graph models used in previous works in the literature. The performance of the proposed algorithm is shown via simulations to yield significantly better performance than algorithms developed in previous works.	algorithm;blocking (computing);channel (communications);mesh networking;multicast;simulation;wavelength-division multiplexing	Hwa-Chun Lin;Yuan-Xi Zhuang	2018	2018 International Conference on Computing, Networking and Communications (ICNC)	10.1109/ICCNC.2018.8390292	multicast;traffic grooming;mesh networking;algorithm;graph;bandwidth (signal processing);wavelength-division multiplexing;computer science;multiplexing;communication channel	HPC	-4.8771506070075175	83.45268263088748	29566
174ebc5369aa9c73e78e9250931d62f5b9235739	optimal scheduling of secondary content for aggregation in video-on-demand systems	resource utilization;quality of service optimisation scheduling video on demand;optimisation;service aggregation;channel bandwidth requirement optimal scheduling secondary content video on demand systems resource utilization vod systems polynomial time total bandwidth usage;rate adaptation;satisfiability;optimal scheduling;scheduling;video on demand;polynomial time;optimal scheduling merging bandwidth resource management aggregates computer science scheduling algorithm polynomials streaming media motion pictures;technical report;secondary content insertion;quality of service	We present and evaluate an optimal scheduling algorithm for inserting secondary content for improving resource utilization in VoD systems. The algorithm runs in polynomial time, and is optimal with respect to the total bandwidth usage over the merging interval. We present constraints on content insertion which make the overall QoS of the delivered stream acceptable, and show how our algorithm can satisfy these constraints. We discuss dynamic scenarios with user arrivals and interactions, and show by simulations that content insertion reduces the channel bandwidth requirement to almost half.	algorithm;interaction;polynomial;quality of service;scheduling (computing);simulation;time complexity	Prithwish Basu;Ashok Narayanan;Wang Ke;Thomas D. C. Little	1999		10.1109/ICCCN.1999.805503	fair-share scheduling;time complexity;fixed-priority pre-emptive scheduling;in situ resource utilization;real-time computing;earliest deadline first scheduling;quality of service;dynamic priority scheduling;computer science;rate-monotonic scheduling;technical report;operating system;two-level scheduling;distributed computing;round-robin scheduling;scheduling;computer network;satisfiability	EDA	-15.14179965149041	70.86456599300863	29602
89a1d11a8dc655a6f83cca8a57e086b90f530cf5	towards a pluralist internet using a virtual machine server for network customization	virtualization;virtual machine server;future internet	"""The Internet success is frequently credited to its basic pillars, the end-to-end argument and the TCP/IP protocol stack. Nevertheless, this simple architecture does not facilitate the addition of new services such as mobility, security, and quality of service support. As a consequence, virtual networks are often being used as a tool to experiment with new protocol architectures. In this work, we propose a Virtual Machine Server (VMS) to manage virtual networks that are customized upon user needs. The proposed VMS uses the idea of machine virtualization within the networking context. Instead of managing virtual machines, the VMS manages virtual routers and uses them to build virtual networks. The result of the proposed approach is the possibility to experiment with pluralist architectures for the future Internet, which are neither as radical as the """"clean-slate"""" approach nor as conservative as the evolutionary approach. In addition, the proposed VMS is flexible enough to allow the interaction of users, or intelligent software agents, with the network resources. The server is implemented using web services and a prototype with Xen stations is currently operational. Our experimental results show that the operation of the VMS is simple and motivates larger implementations."""	end-to-end principle;future internet;intelligent agent;internet protocol suite;iterative and incremental development;protocol stack;prototype;quality of service;server (computing);software agent;virtual machine;web service	Rafael dos Santos Alves;Miguel Elias M. Campista;Luís Henrique Maciel Kosmalski Costa;Otto Carlos Muniz Bandeira Duarte	2012		10.1145/2402599.2402601	full virtualization;virtualization;temporal isolation among virtual machines;computer science;virtual machine;operating system;distributed computing;world wide web;computer security;computer network	Networks	-17.002662486529125	83.0624182330372	29630
673fce1a2f1cfe079b6ee6d2bdccd2a61f895275	a statistically customisable web benchmarking tool	performance monitoring;web pages;capacity planning;dynamic and static http traffic;traffic characterization;performance metric;statistical properties;internet traffic;probability distribution;web benchmarking	We describe a statistically customisable solution for Web benchmarking that includes three utilities: an Internet traffic generator for HTTP traffic, an static and dynamic Web pages generator in the Web server that is going to be tested and a performance monitor that reports some performance metrics during the test. The design of the tool is based on the implementation of the most important probability distributions that mainly characterise statistical properties of Internet traffic like the inter-arrival rate of the incoming Web traffic to the server, the number of objects contained in a Web page and the size of these Web objects. These properties can be customised for a specific capacity planning analysis. In this work, we describe the generation process of the Web pages and the customisable traffic characterization used by the benchmark. The monitoring process details and the validation of the probability distributions implemented are also included.	benchmark (computing);dynamic web page;hypertext transfer protocol;queueing theory;server (computing);web server;web traffic;world wide web	Katja Gilly;Carlos Quesada-Granja;Salvador Alcaraz;Carlos Juiz;Ramón Puigjaner	2009	Electr. Notes Theor. Comput. Sci.	10.1016/j.entcs.2009.02.052	traffic generation model;probability distribution;web service;web modeling;data web;web analytics;internet traffic;web mapping;web design;computer science;web page;data mining;database;world wide web;web server	Metrics	-21.096832584923884	71.98993680371248	29645
5f6a5516046435a17f6ec38ddbf5370f37b9190d	ant colony optimization applied to web service compositions in cloud computing	service composition;ant colony optimization;期刊论文;cloud combination;multi cloud base	Rapid developments in cloud computing technology mean that many different web services are now published and available in cloud data centers. There has recently been an increasing amount of interest in web service composition, because it is important in practical applications. However, most traditional service composition methods can only find service composition sequences in a single cloud, and cannot consider a multi-cloud service base. It is challenging to efficiently find a composition across multiple clouds, because it involves service compositions and combinatorial optimization. In this paper, we present a greedy algorithm called Greedy-WSC and an ant colony optimization based algorithm called ACO-WSC, which attempt to select cloud combinations that are feasible and use the minimum number of clouds. Our experimental results show that the proposed ant colony optimization method can effectively and efficiently find cloud combinations with a minimal number of clouds. 2014 Elsevier Ltd. All rights reserved.	ant colony optimization algorithms;cloud computing;combinatorial optimization;data center;greedy algorithm;mathematical optimization;service composability principle;web service;world sudoku championship	Qiang Yu;Ling Chen;Bin Li	2015	Computers & Electrical Engineering	10.1016/j.compeleceng.2014.12.004	ant colony optimization algorithms;computer science;data mining;distributed computing;world wide web	Web+IR	-19.478905986716335	64.51729445397459	29687
4770fbf691cd42776e2f331eef917d087965aa93	secod: sdn secure control and data plane algorithm for detecting and defending against dos attacks		Although the popularity of Software-Defined Networking (SDN) is increasing, it is also vulnerable to security attacks such as Denial of Service (DoS) attacks. Since in SDN, the control plane is isolated from the data plane, DoS attackers can easily target the control plane to impair the network infrastructure in addition to the data plane to degrade the user's Quality of Service (QoS). In our previous work, we introduced SECO, an SDN Secure Controller algorithm to detect and defend SDN against DoS attacks. Simulation results showed that SECO successfully defends SDN networks from DoS attacks. In this paper, we present SDN sEcure COntrol and Data Plane (SECOD), which is an improved version of SECO. Basically, SECOD introduces new triggers to detect and prevent DoS attacks in both control and data planes. Moreover, SECOD is implemented and tested using SDN-based hardware testbed, OpenFlow-based switch, and RYU controller to capture the dynamics of realistic hardware and software. The results show that SECOD successfully detects and effectively mitigates DoS attacks on SDN networks keeping data plane performance at 99.72% compared to a network not under attack.	algorithm;control plane;denial-of-service attack;forwarding plane;openflow;quality of service;sensor;simulation;software-defined networking;testbed	Song Wang;Sathyanarayanan Chandrasekharan;Karina Mabell Gomez;Kandeepan Sithamparanathan;Akram Al-Hourani;Muhammad Rizwan Asghar;Giovanni Russello;Paul Zanna	2018	NOMS 2018 - 2018 IEEE/IFIP Network Operations and Management Symposium	10.1109/NOMS.2018.8406196	denial-of-service attack;process control;quality of service;computer science;computer network;distributed computing;control theory;software;forwarding plane;algorithm;openflow;testbed	Security	-15.139252706507524	81.87660328204969	29716
4943fb161d19fbe5f515860cfd505f1fd0078ca7	management information base for ip version 6: icmpv6 group		This document is one in the series of documents that define various MIB object groups for IPv6. Specifically, the ICMPv6 group is defined in this document.		Dimitry Haskin;Steve Onishi	1998	RFC	10.17487/RFC2466	computer science;data mining;database;world wide web	Crypto	-25.562574876722472	88.32992768528946	29734
eb3b0a8d57581fa156f565b119ec07dcb4523a61	management and plug and play of sensor networks using snmp	intelligent sensor;teds snmp sensor node network management protocol internet technology measurement network sensor networking standardization multiple access mechanism protocol development transducer electronic data sheet;protocols;plugs;intelligent actuators;ieee standards;transducers ieee standards intelligent actuators intelligent networks intelligent sensors management information systems;standards;time measurement;plug and play;transducers;multiple access mechanism;sensor network;distributed sensors;teds;internet technology;snmp;internet;intelligent network;sensor networking standardization;management information systems;ip networks;intelligent networks;transducer electronic data sheet;telecommunication network management distributed sensors intelligent sensors internet protocols;management information system;security;intelligent sensors;transducers protocols security ip networks time measurement standards plugs;protocol development;telecommunication network management;sensor node network management protocol;measurement network	Recently, the network management of sensor nodes has gained interest as more sensors are being networked with Internet technologies as opposed to traditional instrumentation and measurement networks. Sensor networking standardization efforts lead a more interoperable way of identification and communication among sensors, and networking technologies provide multiple-access mechanisms to a high number of sensors. The convergence of sensor networking toward internetworking provides flexibility in protocol development for network management. This paper presents a novel demonstration of such a convergence by utilizing a common network management protocol, i.e., Simple Network Management Protocol (SNMP), and a sensor networking standardization effort, i.e., Transducer Electronic Data Sheet (TEDS). The TEDS information for two types of sensors has been transferred to the SNMP domain through a novel management information base design, and the network management system has been implemented on an actual testbed.	datasheet;ieee 1451;internet;internetworking;interoperability;management information system;plug and play;sensor;simple network management protocol;testbed;transducer	Syed Alamdar Hussain;Deniz Gurkan	2011	IEEE Transactions on Instrumentation and Measurement	10.1109/TIM.2011.2113115	network management;embedded system;fcaps;active networking;intelligent network;network management station;telecommunications;computer science;engineering;electrical engineering;management information systems;network management application;structure of management information;computer security;computer network;intelligent sensor	Mobile	-20.40258927603495	85.32785889877611	29774
284c65a4a834af92347784c02b7adfcaaf4734c4	survivability and reliability of a composite-star transport network with disconnected core switches	design model;optical network;transportation networks;reliability;dedicated path protection;composite star network;petaweb;tdm wdm;network architecture;survivability	This paper deals with the design and dimensioning of a novel survivable optical network structure, called Petaweb, that can reach a total capacity of several Pb/s (10 bit/s). The Petaweb has a compositestar architecture that allows two-hop connections between edge nodes through disconnected core nodes. Prior studies of the same authors have tackled the optimization of a Petaweb network architecture with regular and quasi-regular topologies. In this paper, reliability and survivability issues are addressed by introducing a dedicated path protection strategy into the design model. We present by extensive numerical results the reliability and survivability properties of the Petaweb core architecture with respect to single fiber link, core node, or switching plane failure and to switching site disconnection.	intel core (microarchitecture);mathematical optimization;network architecture;network switch;numerical analysis;path protection	Stefano Secci;Brunilde Sansò	2011	Telecommunication Systems	10.1007/s11235-009-9277-3	network architecture;telecommunications;computer science;reliability;distributed computing;computer network	Arch	-7.815836633083499	83.51501182302715	29821
566c64c33fb5a5e4b301ff5261a2fbdd1a5dd448	adaptive pattern matching on binary data	metodo adaptativo;record format;interferencia;network protocol;automate arbre;redundancia;implementation;format enregistrement;telecommunication network;methode adaptative;interference;data format;functional programming;redundancy;tree automaton;red telecomunicacion;pattern matching;automata arbol;contexto;adaptive method;donnee binaire;reseau telecommunication;contexte;dato binario;concordance forme;binary data;formato grabacion;implementacion;context;redondance	Pattern matching is an important operation in functional programs. So far, pattern matching has been investigated in the context of structured terms. This paper presents an approach to extend pattern matching to terms without (much of a) structure such as binaries which is the kind of data format that network applications typically manipulate. After introducing a notation for matching binary data against patterns, we present an algorithm that constructs a tree automaton from a set of binary patterns. We then show how the pattern matching can be made adaptive, how redundant tests can be avoided, and how we can further reduce the size of the resulting automaton by taking interferences between patterns into account. The effectiveness of our techniques is evaluated using implementations of network protocols taken from actual telecom applications.	algorithm;binary data;communications protocol;pattern matching;tree automaton	Per Gustafsson;Konstantinos Sagonas	2004		10.1007/978-3-540-24725-8_10	communications protocol;computer science;artificial intelligence;theoretical computer science;operating system;machine learning;pattern matching;interference;redundancy;programming language;functional programming;implementation;algorithm;telecommunications network	PL	-25.75369479066284	81.27071924291744	29926
7e6ab66ec351fe80c0fcf757232248e47722056e	design and implementation of a high-speed rfid data filtering engine	parallelisme;filtering;filtrage;routeur;cortafuego;engineering design;calculateur embarque;packet classification;redundancia;base donnee tres grande;pervasive computing;securite informatique;filtrado;cache memory;data filtering;analyse temporelle;packet switching;conmutacion por paquete;classification;analisis temporal;time analysis;antememoria;informatica difusa;computer security;pare feu reseau;antememoire;parallelism;paralelismo;redundancy;design and implementation;identification radiofrequence;informatique diffuse;grande vitesse;seguridad informatica;boarded computer;router;radio frequency identification;gran velocidad;information system;very large databases;high speed;clasificacion;calculador embarque;commutation paquet;systeme information;redondance;sistema informacion;firewall	In this paper, we present a high-speed RFID data filtering engine designed to carry out filtering under the conditions of massive data and massive filters. We discovered that the high-speed RFID data filtering technique is very similar to the high-speed packet classification technique which is used in highspeed routers and firewall systems. Actually, our filtering engine is designed based on existing packet classification algorithms, Bit-Parallelism and Aggregated Bit Vector (ABV). In addition, we also discovered that there are strong temporal relations and redundancy in the RFID data filtering operations. We incorporated two kinds of caches, tag and filter caches, to make use of this characteristic to improve the efficiency of the filtering engine. The performance of the proposed engine has been examined by implementing a prototype system and testing it. Compared to the basic sequential filter comparison approach, our engine shows much better performance, and it gets better as the number of filters increases.	algorithm;bit array;bit-level parallelism;cpu cache;firewall (computing);network packet;prototype;radio-frequency identification;redundancy (engineering);router (computing)	Hyunsung Park;Jongdeok Kim	2006		10.1007/11807964_43	radio-frequency identification;filter;firewall;embedded system;real-time computing;cpu cache;telecommunications;biological classification;computer science;collaborative filtering;operating system;database;distributed computing;redundancy;computer security;ubiquitous computing;information system;algorithm;engineering design process;packet switching	Networks	-6.153894535647844	64.3154372369982	29970
de25cdb97b20ce0a5e3e5ed6855e3df879f07186	qos provisioning with qcontracts in web and multimedia servers	legacy software;search engines;e commerce;real time;qos guarantee;multimedia servers;client server systems;qos provisioning;middleware sockets operating systems programming profession contracts computer science laboratories argon business context aware services;indexing terms;multimedia systems;legacy software qos provisioning qcontracts web servers multimedia servers performance critical services online brokerage e commerce qos sensitive services middleware server process operating system;operating system;qos management;real time services;middleware;quality of service;multimedia server;multimedia servers client server systems multimedia systems search engines quality of service	The advent of performance-critical services such as online brokerage and e-commerce, as well as QoS-sensitive services such as streaming multimedia, makes existing FIFO servers incapable of meeting application QoS requirements. Re-designing server code to support QoS provisioning, on the other hand, is costly and time-consuming. To remedy this problem, we propose a new QoS-provisioning approach that does not require modification of server and OS code. We develop a middleware, called qContracts, that can be transparently interposed between the server process and the operating system to achieve performance differentiation and soft QoS guarantees. The middleware enables reuse of existing legacy software in QoS-sensitive contexts, and off-loads QoS management concerns from future real-time service programmers. As an example, we show how the Apache [9] web server is endowed with QoS support using qContracts on UNIX. Experimental results show the efficacy of the middleware in achieving the contracted QoS, while imposing less than 1% overhead.	best-effort delivery;e-commerce;embedded system;fifo (computing and electronics);legacy system;middleware;operating system;overhead (computing);programmer;provisioning;quality of service;real-time clock;real-time computing;real-time operating system;real-time transcription;requirement;server (computing);streaming media;unix;web server	Tarek F. Abdelzaher;Kang G. Shin	1999		10.1109/REAL.1999.818827	e-commerce;real-time computing;mobile qos;index term;quality of service;computer science;operating system;middleware;world wide web;legacy system;computer network	Embedded	-19.8207035348748	70.21750113792312	30130
88b6f83b48ad5aaa28f6511438049526cca0527a	cloud base stations and fixed mobile convergence for the next mobile network	convergence;passive optical networks base stations mobile communication wavelength division multiplexing transceivers mobile computing baseband;mobile radio;mobile radio convergence;in service fiber to the home networks cloud base stations fixed mobile convergence next mobile network customer service mobile operators transmission speed remote radio heads distributed base station architecture	In order to provide the best customer service, mobile operators continuously evolve their network with the next big challenge being a massive increase in transmission speed. In this paper, we combine the concepts of cloud base stations and fixed mobile convergence to deal with this challenge. We examine how the remote radio heads of such a distributed base station architecture can be interconnected over existing in-service fiber-to-the-home networks and present two architectures for this.	cloud computing;fiber to the x;metro (design language);passive optical network	Wolfgang Kiess;Changsoon Choi;Ashiq Khan;Kazuyuki Kozu	2012	2012 IEEE Globecom Workshops	10.1109/GLOCOMW.2012.6477576	radio access network;embedded system;cellular network;intelligent network;mobile identification number;mobile search;3g;convergence;imt advanced;public land mobile network;telecommunications;gsm services;computer science;base station;mobile phone signal;mobile station;small cell;mobile computing;computer network	Mobile	-14.187729863887357	88.43411538162411	30208
19dc2d0f73087f54b68580c7e4727eef39524177	resilient routing of variable traffic with performance guarantees	telecommunication network reliability;combinatorial algorithm;routing;path indexed linear programming formulation;variable traffic;communication complexity;shared backup path restoration;data mining;carrier class reliability;optimization problem;approximation theory;telecommunication traffic;internet;telecommunication network routing;hoses;internet service provider networks;telecommunication traffic approximation theory combinatorial mathematics communication complexity internet linear programming telecommunication network reliability telecommunication network routing;approximating solutions;sbpr disjoint paths;linear programming;rocketfuel project variable traffic two phase routing shared backup path restoration carrier class reliability internet service provider networks optimization problem np hard disjoint paths problem sbpr disjoint paths path indexed linear programming formulation combinatorial algorithm approximating solutions;disjoint paths problem;bandwidth;approximation methods;np hard;two phase routing;combinatorial mathematics;rocketfuel project;throughput;routing telecommunication traffic throughput robustness web and internet services bandwidth linear programming algorithm design and analysis approximation algorithms topology	Two-phase routing, where traffic is first distributed to intermediate nodes before being routed to the final destination, has been recently proposed [11], [12], [20] for handling widely fluctuating traffic without the need to adapt network routing to changing traffic. Pre-configuring the network in a traffic independent manner using two-phase routing simplifies network operation considerably. In this paper, we extend this routing scheme by providing resiliency against link failures through shared backup path restoration. We view this as important progress towards adding carrier-class reliability to the robustness of the scheme so as to facilitate its future deployment in Internet Service Provider (ISP) networks. In shared backup path restoration, each connection consists of a link-disjoint primary and backup path pair - two backup paths can share bandwidth on their common links if their primary paths are link disjoint. We show that the optimization problem for maximum throughput two-phase routing with shared backup path restoration is NP-hard. Assuming an approximation oracle for a certain disjoint paths problem (called SBPR-DISJOINT-PATHS, which is also NP-hard) involving the dual variables of a path indexed linear programming formulation for the problem, we design a combinatorial algorithm with provable guarantees. We also provide heuristics for finding approximating solutions to the SBPR-DISJOINT-PATHS problem. We evaluate the throughput performance and number of intermediate nodes in two-phase routing for the above and other restoration mechanisms for two-phase routing on actual ISP topologies collected for the Rocketfuel project [18].	algorithm;approximation;backup;circuit restoration;combinatorial optimization;duality (optimization);egress filtering;heuristic (computer science);linear programming formulation;mathematical optimization;maximum throughput scheduling;optimization problem;provable prime;real-time clock;routing;software deployment;two-phase commit protocol;two-phase locking	Murali S. Kodialam;T. V. Lakshman;Sudipta Sengupta	2009	2009 17th IEEE International Conference on Network Protocols	10.1109/ICNP.2009.5339683	policy-based routing;wireless routing protocol;routing domain;optimization problem;mathematical optimization;routing;enhanced interior gateway routing protocol;throughput;static routing;the internet;zone routing protocol;equal-cost multi-path routing;computer science;linear programming;dynamic source routing;multipath routing;destination-sequenced distance vector routing;np-hard;communication complexity;distributed computing;routing protocol;link-state routing protocol;triangular routing;path vector protocol;geographic routing;bandwidth;routing information protocol;computer network;approximation theory	Networks	-5.224739825384779	82.37784012668354	30221
b3b8638f9377d8bfd8508ed1e203b9f8ee7be97f	a mechanism of maintaining the survivability of streaming media service in overlay networks	databases;topology;routing;quality of service media streaming overlay networks;overlay networks;quality of services streaming media service survivability overlay network service oriented network qos health value;streaming media service survivability;quality of services;service oriented network;qos;streaming media;media streaming;overlay network;bandwidth;streaming media bandwidth delays quality of service databases topology routing;quality of service;health value;delays	With the quick development of service-oriented network, the services of streaming media and their traffic has become a rather important part in the circumstance of virtual network. However, there hasn't been a unified control mechanism to maintain the qualities of these services. The QoS of streaming media is a great concern of current network, and it'll be vital in future network because of the rapid growth of internet users and traffics. This paper describes a mechanism of maintaining the survivalbility of streaming media service in the circumstance of overlay network. We propose a method to calculate the health value of each path and service. Through this mechanism we can evaluate the current quality of services and provide information for further decisions. As a proof of concept we implement an experimental scenario to assess the functionality and the availability of this mechanism. It has managed effectively in the evaluation of streaming services.	overlay network;quality of service;service-oriented device architecture;streaming media	Bo Bai;Ji-hong Zhao;Hua Qu	2013	2013 IEEE Eighth International Conference on Networking, Architecture and Storage	10.1109/NAS.2013.16	real time streaming protocol;mobile qos;overlay network;quality of service;computer science;world wide web;computer security;computer network	HPC	-10.424579660444389	84.0435278916439	30224
10686d4974af6b6870a8aa446e1633b4f2e8bdd7	survey on load-balancing methods in 802.11 infrastructure mode wireless networks for improving quality of service		Traffic load in any 802.11 infrastructure mode network is typically distributed unevenly between access points (APs), creating hotspots. This is due to the inherent nature of wireless area networks (WLANs), where stations are free to associate to any known AP they desire, and the lack of control by the APs themselves. This imbalance creates a condition where affected APs in the network suffer traffic congestion while others are underutilized, leading to stations experiencing lower throughput, longer latency, and operating below the network potential capacity. To alleviate this problem, some form of load balancing is required to redistribute the work load among other available APs in the wireless network. This article presents a survey of the various works done in performing load balancing in an infrastructure mode wireless network and will cover the common methods including admission control, association management, cell breathing, and association control. Updates to the IEEE standards are also presented that support load-balancing efforts. Finally, software-defined networks are investigated to determine the extent of control integration to support managing and load-balancing WLANs. Trends in load-balancing research are also uncovered that indicate how the introduction of new wireless standards influences the amount of research.	acm computing surveys;hotspot (wi-fi);load balancing (computing);network congestion;quality of service;serial experiments lain;software deployment;software-defined networking;throughput;wireless access point	Wooi-King Soo;Teck Chaw Ling;Aung Htein Maw;Su Thawda Win	2018	ACM Comput. Surv.	10.1145/3172868	theoretical computer science;admission control;wireless network;latency (engineering);throughput;cell breathing;computer network;quality of service;computer science;load balancing (computing);traffic congestion	Networks	-13.602297453829683	85.88616659406611	30381
12a6890e863d2a2c628261974dde5264edc3b922	camdoop: exploiting in-network aggregation for big data applications	production system;design space;network topology;network traffic;small and medium enterprise;high performance;real time application	Large companies like Facebook, Google, and Microsoft as well as a number of small and medium enterprises daily process massive amounts of data in batch jobs and in real time applications. This generates high network traffic, which is hard to support using traditional, oversubscribed, network infrastructures. To address this issue, several novel network topologies have been proposed, aiming at increasing the bandwidth available in enterprise clusters. We observe that in many of the commonly used workloads, data is aggregated during the process and the output size is a fraction of the input size. This motivated us to explore a different point in the design space. Instead of increasing the bandwidth, we focus on decreasing the traffic by pushing aggregation from the edge into the network. We built Camdoop, a MapReduce-like system running on CamCube, a cluster design that uses a direct-connect network topology with servers directly linked to other servers. Camdoop exploits the property that CamCube servers forward traffic to perform in-network aggregation of data during the shuffle phase. Camdoop supports the same functions used in MapReduce and is compatible with existing MapReduce applications. We demonstrate that, in common cases, Camdoop significantly reduces the network traffic and provides high performance increase over a version of Camdoop running over a switch and against two production systems, Hadoop and Dryad/DryadLINQ.	apache hadoop;bandwidth (signal processing);big data;bisection bandwidth;direct connect (protocol);dryad;information;job stream;mapreduce;network packet;network topology;network traffic control;overselling;prototype;real-time computing;simulation	Paolo Costa;Austin Donnelly;Antony I. T. Rowstron;Greg O'Shea	2012			traffic generation model;network traffic control;real-time computing;simulation;computer science;operating system;database;distributed computing;production system;computer security;network topology;computer network	OS	-12.861815475474863	79.618204723744	30417
99cbdf681e7076d66542b478b44b3d4bb93f852c	implementation and experiments of path computation element based backbone network architecture	eje troncal;arquitectura red;tecnologia electronica telecomunicaciones;gmpls;management system;generalized multi protocol label switching;protocole transmission;path computation element;implementation;mpls protocol;management control;telecommunication network;protocolo mpls;architecture reseau;pce;reseau federateur;protocolo transmision;red telecomunicacion;reseau telecommunication;communication protocol;control;network architecture;backbone;tecnologias;implementacion;grupo a;management;backbone network;protocole mpls;transmission protocol	This paper proposes the Path Computation Element (PCE)-based backbone network architecture and verifies its feasibility through implementation and experiments. PCE communication Protocol (PCEP) is implemented for communication between the PCE and the management system to control and manage Generalized Multi-Protocol Label Switching (GMPLS)-based backbone networks.	computation;network architecture	Tomonori Takeda;Eiji Oki;Ichiro Inoue;Kohei Shiomoto;Kazuhiro Fujihara;Shin-Ichi Kato	2008	IEICE Transactions	10.1093/ietcom/e91-b.8.2704	management control system;communications protocol;network architecture;telecommunications;computer science;backbone network;management system;distributed computing;implementation;telecommunications network;scientific control;computer network	HPC	-21.553351080635224	88.22702866958113	30555
46b0f1687b491103158e839cffdf06283b94181a	towards enhanced searching architecture for unstructured peer-to-peer over mobile ad hoc networks	manet;p2p;gnutella;unstructured overlay networks;search	With the rapid growth of individual mobile devices, the researchers are facing new challenges to deploy unstructured peer-to-peer (P2P) applications over mobile ad hoc networks (MANETs). Empirical studies indicates that although P2P and MANETs have similar preferences, but the resultant networks are not performing efficient and effective searching due to peer discovery, connectivity and mobility problems. To resolve these issues, the existing techniques mostly rely on flooding and random walks in P2P over MANETs to discover object of interest and thus introduce incredible network traffic. Thus, this article proposes Gnutella like unstructured P2P network to better meets the mobility requirement of ad hoc networks to optimize search performance. The proposed system presents a novel cache optimization technique and enhances ultrapeer selection scheme to make communication more efficient between peers and ultrapeer. Furthermore for quick and efficient search, we explore a novel jumping multiple walkers random walk approach with controlled replication. The proposed search mechanism not only reduces the effective query search time but also remarkably reduce network overhead. We validate our analysis and compare our proposal to competing protocols in simulations. Simulation results show that proposed scheme gives better performance than the competing protocols in terms of (1) the successful ratio of resolving a query, (2) the time and hop count of routing a query message, (3) the message overhead, and (4) average message response time.	hoc (programming language);peer-to-peer	Babar Shah;Ki-Il Kim	2014	Wireless Personal Communications	10.1007/s11277-013-1560-7	computer science;distributed computing;world wide web;computer network	Mobile	-12.777396914330623	73.82892507628127	30604
54d7cda73e9c3574d234e75e1a92bc25913f38ce	design and implementation of a generic connection management and service level agreement monitoring platform supporting the virtual private network service	virtual private network;specification languages telecommunication network routing distributed object management computer network management software agents;telecommunications information networking architecture;software agents;monitoring virtual private networks;telecommunication network routing;technology and engineering;design and implementation;specification languages;setup generic connection management service level agreement monitoring platform virtual private network service scalable architecture sla vpn layer based design advanced software techniques run time compilation intelligent agents routing algorithms edge device capability matching xml based sls language service level specification language load balancing computational tasks programmable components tina telecommunication information network architecture corba common object request broker architecture;computer network management;distributed object management;intelligent agent;routing algorithm;service level agreement;load balance;service level specification;common object request broker architecture	In this paper we address the design of a generic and scalable architecture for connection management and SLA (service level agreement) monitoring of VPNs (virtual private networks). Layer-based design ensures that the architecture is independent of the network technology. Use of advanced software techniques such as run time compilation and intelligent agents allow easy integration of new monitoring and routing algorithms. The architecture offers advanced features such as VPN edge device capability matching, XML-based SLS (service level specification) language, load balancing of computational tasks, and programmable components. The architecture is compliant with the TINA (telecommunication information network architecture) recommendations and its implementation is based on CORBA (common object request broker architecture). In addition, a sample VPN setup and monitoring scenario will be detailed.	service-level agreement;virtual private network	Filip De Turck;Stefaan Vanhastel;Filip Vandermeulen;Piet Demeester	2001		10.1109/INM.2001.918020	enterprise architecture framework;reference architecture;space-based architecture;real-time computing;computer science;applications architecture;load balancing;software agent;operating system;common object request broker architecture;service;solution architecture;distributed computing;intelligent agent;data architecture;computer network	HPC	-19.708181219640988	87.83176676890146	30673
ebe44caa03966590ceda7fb7818c324ba6dd8c5d	asymptotic behavior of global recovery in srm	collaborative application;best effort;reliable multicast;large scale;size distribution;scalable reliable multicast;reliable multicast transport;group size;binary tree	The development and deployment of a large-scale, wide-area multicast infrastructure in the Internet has enabled a new family of multi-party, collaborative applications. Several of these applications, such as multimedia slide shows, shared whiteboards, and large-scale multi-player games, require reliable multicast transport, yet the underlying multicast infrastructure provides only a best-effort delivery service. A difficult challenge in the design of efficient protocols that provide reliable service on top of the best-effort multicast service is to maintain acceptable performance as the protocol scales to very large session sizes distributed across the wide area. The Scalable, Reliable Multicast (SRM) protocol [6] is a receiver-driven scheme based on negative acknowledgments (NACKs) reliable multicast protocol that uses randomized timers to limit the amount of protocol overhead in the face of large multicast groups, but the behavior of SRM at extremely large scales is not well-understood.In this paper, we use analysis and simulation to investigate the scaling behavior of global loss recovery in SRM. We study the protocol's control-traffic overhead as a function of group size for various topologies and protocol parameters, on a set of simple, representative topologies --- the cone (a variant of a clique), the linear chain, and the binary tree. We find that this overhead, as a function of group size, depends strongly on the topology: for the cone, it is always linear; for the chain, it is between constant and logarithmic; and for the tree, it is between constant and linear.	best-effort delivery;binary tree;cone (formal languages);image scaling;internet;multicast;overhead (computing);randomized algorithm;simulation;software deployment;timer	Suchitra Raman;Steven McCanne;Scott Shenker	1998		10.1145/277851.277880	best-effort delivery;real-time computing;multicast;inter-domain;reliable multicast;binary tree;protocol independent multicast;computer science;size of groups, organizations, and communities;pragmatic general multicast;distributed computing;distance vector multicast routing protocol;source-specific multicast;xcast;computer network	Metrics	-10.943375522969497	76.79884467496318	30867
de1108857c52dd84f46aeef9600cb558fa3e0d27	usvod: a large scale video-on-demand system based on uniform sampling cache mechanism	distributed system;computer network;large scale;video on demand;multimedia communication;peer to peer	BitTorrent (BT) is an effective tool for large-scale P2P content services in the face of dynamic nature of Internet. A P2P content service is usually characterized by the fact that its users leave and join the service frequently and are self-interested. It is further complicated by the flash crowd phenomenon. However, BT does not perform well in streaming applications in which contents are supposed to be delivered timely. For example, users of streaming video expect to start viewing the video as early as possible. This is unlike a BT user who usually has to wait until the entire content is downloaded before one could start to view the video. Furthermore, each byte of the streaming video must arrive in time to avoid unpleasant playback jitters. In this paper, we present our design of USVoD piece selection mechanisms into BT to efficiently overcome the above problems. Instead of selecting rarest pieces, our mechanism selects pieces based on the following principles, (1) moving-window strategy, i.e., selects all pieces which will be played back within a fixed time interval in the near future, (2) on-line cache mechanism, i.e., randomly selects a certain pieces which will be used after the moving window interval, (3) uniform pre-sampling cache mechanism, i.e., in addition to pre-fetching initial portion of the video, it also pre-fetches some randomly selected pieces into the specific cache before playback, and (4) some useful modifications to BT. We evaluate the performance of USVoD and BiToS on a mixture of Poisson arrival and flash crowd by using tradeoff between initial delay and delay jitter as evaluation criterion. Simulation results show that USVoD significantly outperform BiToS.	bittorrent;byte;file sharing;gibbs sampling;internet;online and offline;packet delay variation;peer-to-peer;personal digital assistant;prefetch input queue;programming paradigm;randomness;sampling (signal processing);scalability;set-top box;simulation;slashdot effect;streaming media;versant object database	Chin-Fu Ku;Yu-Fang Zheng;Sao-Jie Chen;Jan-Ming Ho	2009	J. Inf. Sci. Eng.		computer science;operating system;database;multimedia;internet privacy;world wide web;computer security;computer network	Metrics	-16.142851703971715	71.7640004917335	30898
ccbe4f3e6f734ee3fdae0d8b29d257e90e8404fb	onde: a generic xml-based development environment for optimization of wdm optical networks	wdm;optical network;optimisation;programming environments;xml based structure;java programming;physical layer;optical network design tools;wdm optical network;grwa;optical fiber networks;telecommunication computing;graphical user interface;java program;java native interface;jni;wavelength division multiplexing wdm networks optical fiber networks graphical user interfaces xml java network topology physical layer telecommunication traffic design optimization;design optimization;optical networks;network topology;optical fibre networks;java native interface xml based development environment wdm optical network optimization algorithm xml based structure onde development environment onml compliant file parsing function graphical user interface network optimization program xml parser c optimization algorithm java program;telecommunication traffic;c language;development environment;onde development environment;graphical user interfaces;c optimization algorithm;xml application program interfaces c language data structures graphical user interfaces java optical fibre networks optimisation program compilers programming environments telecommunication computing wavelength division multiplexing;onml compliant file parsing function;network optimization program;wdm optical network optimization algorithm;data structures;application program interfaces;optical network design;xml;network optimization;modular design;graphic user interface;wdm networks;optimization;xml parser;program compilers;optimal algorithm;xml based development environment;java;wavelength division multiplexing;jni optical networks optimization grwa wdm optical network design tools xml	Developing optical network optimization algorithms involves representing many different instances related to the network itself: topology, physical layer equipment found in nodes, links, etc. It also requires description of traffic demand. We propose onML; an XML-based structure to fulfill such requirements. The onML structure is used by ONDE, a development environment targeted at optimization algorithms for optical networks. A sought feature of ONDE is a modular design allowing a clear separation of onML files parsing functions, graphical user interfaces and network optimization programs. With such a modular approach, multiple research teams can cooperate to develop and easily share new tools and algorithms. As a result, an XML parser is tailored to parse data in onML-compliant files and is easily interfaced with the main C++ optimization algorithm under development. For graphical user interface aspects, the ONDE environment uses a Java program which is interfaced with the XML parser through the Java native interface (JNI)	algorithm;c++;graphical user interface;java;lemmings;mathematical optimization;modular design;parsing;requirement;wavelength-division multiplexing;xml	Mehdi Haitami;Ghyslain Abel;Alain C. Houle;Brigitte Jaumard	2006	2006 Canadian Conference on Electrical and Computer Engineering	10.1109/CCECE.2006.277843	data structure;computer science;theoretical computer science;operating system;graphical user interface;database;distributed computing;computer network	DB	-20.083100495483265	84.43637609055938	30915
b9d838ee2c2f876109606e205fba6b763979682a	a novel two-phase approach for qos-aware service composition based on history records	silicon;filtering;pattern clustering;service composition;probability;history;service selection;service ranking two phase approach for service composition qos aware service composition history record quality of service service performance dynamic environment end to end qos constraint qos degradation composite service qos record qos fluctuation tpasc preliminary filtering heuristic qos decomposition algorithm local constraint probability mip based service selection mixed integer programming k means clustering mip model;time factors;integer programming;heuristic algorithms;quality of service silicon history filtering heuristic algorithms clustering algorithms time factors;mixed integer programming service composition service selection qos aware qos decomposition;web services;clustering algorithms;mixed integer programming;qos aware;quality of service;qos decomposition;filtering theory;web services filtering theory integer programming pattern clustering probability quality of service	Existing service composition approaches usually assume that the quality of service does not change over time. Actually, the performance of a service may fluctuate due to the dynamic environments, which may violate the end-to-end QoS constraints or degrade the QoS of a composite service. History records (or QoS records) can exhibit QoS fluctuations over the past period and reflect the actual performance of a service. Thus, a novel Two-Phase Approach for Service Composition (TPASC) based on QoS records is presented to address the problem. The proposed approach has the two phases: one is preliminary filtering, where a heuristic QoS decomposition algorithm is proposed to decompose the end-to-end QoS constraints into local constraints, and then some promising services are selected in terms of the probability that they can meet the local constraints; the other is MIP (Mixed Integer Programming)-based service selection, where QoS records associated with each promising service are reduced by K-means clustering method, and then a MIP model is proposed to rank and select services in terms of the reduced QoS records. The experimental results show TPASC can conduct service composition with high efficiency and significant cost savings in dynamic environments.	quality of service;service composability principle;two-phase commit protocol	Yong Zhu;Wei Li;Junzhou Luo;Xiao Zheng	2012		10.1109/SOCA.2012.6449451	filter;web service;real-time computing;integer programming;quality of service;computer science;probability;database;distributed computing;cluster analysis;silicon	HPC	-20.42656905611274	66.1446775685071	30943
f68c3665f0b7fb07c7706eb72d8bcedacb4aee17	a lightweight framework forweb services invocation over bluetooth	client server system;mobile device;http;client server systems;web service;proof of concept;transport protocols;real world application;web services bluetooth client server systems transport protocols;web services;transport protocol;bluetooth;wireless technology;communication channels;soap messages;bluetooth wireless technology;mobile devices web services invocation bluetooth wireless technology client server system soap messages http transport protocol java;mobile devices;bluetooth web services service oriented architecture network servers web server simple object access protocol transport protocols communication channels java programming profession;java;web services invocation	We present an experiment relative to the use of Bluetooth wireless technology to provide network support for midlet applications accessing Web services. We refer to the most common architecture used to invoke Web services, where a client and a server exchange SOAP messages using HTTP as the transport protocol. To the best of our knowledge, there is no implemented support for executing a HTTP POST operation over a Bluetooth channel. Therefore, to guarantee the independence of the application from the type of communication channel used, in this paper, we deal with the problem of designing a framework allowing a Java application programmer to directly interface Web services from a mobile device using a Bluetooth connection. This paper presents a proof of concept of how Bluetooth technology can be used to design, develop, and deploy Web services-based applications. According to our experiments, programming interfaces like Blue Cove and kSOAP, despite being still under development, are mature enough to be used as the underlying technologies for Web services invocation over Bluetooth in a real world application	bluetooth;channel (communications);code;experiment;hypertext transfer protocol;java;linux;midlet;mobile device;network packet;post (http);programmer;soap;server (computing);web service	Vincenzo Auletta;Carlo Blundo;Emiliano De Cristofaro;Guerriero Raimato	2006	2006 IEEE International Conference on Web Services (ICWS'06)	10.1109/ICWS.2006.7	web service;computer science;operating system;bluesnarfing;mobile device;internet privacy;world wide web;transport layer;computer network	Mobile	-26.527304726923948	77.01969446604527	30964
468a82a9ce446b35d9d9b05f67fd09db96b4e21f	an empirical evaluation of wide-area internet bottlenecks	available bandwidth;network measurement;overlay routing;measurement;overlay networks;bottleneck links;hot spot;multi path routing;low latency;optimal routing;networking;route optimization;network services;empirical evaluation	Performance limitations in the current Internet are thought to lie at the edges of the network -- i.e last mile connectivity to users, or access links of stub ASes. As these links are upgraded, however, it is important to consider where new bottlenecks and hot-spots are likely to arise. Through an extensive measurement study, we discover, classify and characterize non-access bottleneck links in terms of their location, latency and available capacity. We find that nearly half of the paths explored have a non-access bottleneck with available capacity less than 50 Mbps. The bottlenecks identified are roughly equally split between intra-ISP links and links between ISPs. These results have implications on issues such as the choice of access providers and route optimization.	bottleneck (software);data rate units;hot spare;internet bottleneck;last mile;mathematical optimization	Aditya Akella;Srinivasan Seshan;Anees Shaikh	2003		10.1145/781027.781075	overlay network;telecommunications;computer science;operating system;distributed computing;hot spot;measurement;computer network;low latency	Metrics	-11.526460683136866	79.40877573212667	30986
6ca6df7daaacbf49ddbdc5561cd4871dc16ecc79	measurement-based adaptive statistical admission control scheme for video-on-demand servers	bandwidth measurement;resource utilization;bandwidth measurement based adaptive statistical admission control video on demand servers vod servers multimedia data response time maximum resource utilization qos guarantee off line process on line process performance evaluation;probability;performance evaluation;off line process;statistical analysis video on demand quality of service video servers multimedia communication telecommunication congestion control adaptive control;adaptive control;qos guarantee;resource management;telecommunication congestion control;video on demand servers;measurement based adaptive statistical admission control;programmable control;response time;multimedia systems;vod servers;statistical analysis;on line process;multimedia data;video on demand;multimedia communication;video server;programmable control adaptive control admission control bandwidth quality of service resource management web server probability multimedia systems equations;bandwidth;video servers;web server;vod;quality of service;disk bandwidth measurement;maximum resource utilization;admission control	In a VoD(Video-on-Demand system), admission control that is used to serve multimedia data efficiently has to be performed by an accurate grasp of the condition of surplus resources. Most of all, we need to adaptable admission control mechanism because the disk has irregular response time caused by external elements of disk, and also has high deviation of amount demanded. In this measurementbased statistical admission control scheme, as we suggested in this research, we can get both maximum resource utilization and QoS guarantee through 2 processes of off-line process and on-line process. On performance evaluations, we shows that the video server can utilize maximum resource utilization with QoS guarantee through the precision of performance by measurement and adaptable admission control according to the requested bandwidth.	online and offline;quality of service;response time (technology);server (computing);video server	In-Hwan Kim;Jeong-Won Kim;Seung-Won Lee;Ki-Dong Chung	2000		10.1109/ICOIN.2001.905467	embedded system;in situ resource utilization;real-time computing;quality of service;adaptive control;computer science;resource management;probability;response time;bandwidth;web server;statistics;computer network	Embedded	-19.22068720272899	68.40487676817737	31026
15307efc5a969eb59811a87a215577ceea375f4b	performance and cost optimization for multiple large-scale grid workflow applications	workflow management;fault tolerant;cost function;time complexity;application software;processor scheduling;resource management;data mining;cooperative game;scientific workflows;cost function large scale systems application software resource management optimal scheduling processor scheduling partitioning algorithms scheduling algorithm heuristic algorithms computer science;optimization problem;large scale;scheduling algorithm;cost optimization;optimal scheduling;heuristic algorithms;games;optimization;computer science;load modeling;resource requirement specification;program processors;np complete problem;large scale systems;partitioning algorithms	Scheduling large-scale applications on the Grid is a fundamental challenge and is critical to application performance and cost. Large-scale applications typically contain a large number of homogeneous and concurrent activities which are main bottlenecks, but open great potentials for optimization. This paper presents a new formulation of the well-known NP-complete problems and two novel algorithms that addresses the problems. The optimization problems are formulated as sequential cooperative games among workflow managers. Experimental results indicate that we have successfully devised and implemented one group of effective, efficient, and feasible approaches. They can produce soultuins of significantly better performance and cost than traditional algorithms. Our algorithms have considerably low time complexity and can assign 1,000,000 activities to 10,000 processors within 0.4 second on one Opteron processor. Moreover, the solutions can be practically performed by workflow managers, and the violation of QoS can be easily detected, which are critical to fault tolerance.	algorithm;bottleneck (software);central processing unit;fault tolerance;karp's 21 np-complete problems;mathematical optimization;quality of service;scheduling (computing);time complexity;whole earth 'lectronic link	Rubing Duan;Radu Prodan;Thomas Fahringer	2007	Proceedings of the 2007 ACM/IEEE Conference on Supercomputing (SC '07)	10.1145/1362622.1362639	time complexity;optimization problem;games;workflow;fault tolerance;application software;parallel computing;real-time computing;np-complete;computer science;resource management;theoretical computer science;operating system;distributed computing;scheduling;algorithm	HPC	-14.35738772551257	61.56794669353042	31037
8b88e40244b68dedc407bf0b3b0a1f6f4faf2f94	small-world characteristics of internet topologies and implications on multicast scaling	structure topologique;evaluation performance;routeur;arquitectura red;small world graphs;performance evaluation;autonomous system;graph clustering;fourniture information;evaluacion prestacion;simulation;multidestinatario;topological structure;simulacion;architecture reseau;small world;information delivery;sistema autonomo;autonomic system;multicast tree;echelle d evaluation;network topology;large scale;entrega informacion;evaluation scale;internet;clustering;diffusion information;diffusion donnee;content delivery;signal classification;systeme autonome;information dissemination;difusion dato;classification signal;router;network architecture;internet topology;difusion informacion;data broadcast;escala evaluacion;classification automatique;automatic classification;clasificacion automatica;estructura topologica;multidestinataire;multicast	Recent work has shown that the physical connectivity of the I nt rnet exhibits small-world behavior. Characterizing such behavior is important not only for gene rating realistic Internet topology, but also for the proper evaluation of large-scale content delivery tech niques. Along this line, this paper tries to explain how the small-world behavior arises in the Internet to pol gies and how it impacts the performance of multicast techniques. First, we attribute the small-wor ld behavior to two possible causes—namely the variability of vertex degree and the preference for local co nnections for vertices. We have found that both factors contribute with different relative degrees to the small-world behavior of the autonomous system (AS) level and router level Internet topologies. For the AS level topology, we observe that the high variability of vertex degree is sufficient to cause the s mall-world behavior, but for the router level topology, the preference for local connectivity plays a mor e important role. Second, we propose better models to generate small-world Internet topologies. Our mo dels incorporate both causes of small-world behavior, and generate graphs closely resemble real Intern et g aphs. Third, using simulation we demonstrate the importance of our work by studying the scaling beh avior of multicast techniques. We show that multicast tree size largely depends on the network topo logy. If topology generators capture only the variability of vertex degree, they are likely to underestim ate the benefit of multicast techniques.	autonomous robot;autonomous system (internet);cluster analysis;degree (graph theory);digital distribution;emoticon;heart rate variability;image scaling;internet topology;loop (graph theory);multicast;network topology;random graph;randomness;router (computing);simulation;spatial variability;synthetic intelligence;topography;vertex (graph theory)	Shudong Jin;Azer Bestavros	2006	Computer Networks	10.1016/j.comnet.2005.04.016	multicast;the internet;simulation;network architecture;internet topology;computer science;autonomous system;clustering coefficient;distributed computing;cluster analysis;network topology;computer network;logical topology	Metrics	-9.63974601054929	77.78820550651457	31116
d215d57f5588b947f0be72283c8de1e49b2ff3c9	on resource pooling and separation for lru caching		Caching systems using the Least Recently Used (LRU) principle have now become ubiquitous. A fundamental question for these systems is whether the cache space should be pooled together or divided to serve multiple flows of data item requests in order to minimize the miss probabilities. In this paper, we show that there is no straight yes or no answer to this question, depending on complex combinations of critical factors, including, e.g., request rates, overlapped data items across different request flows, data item popularities and their sizes. To this end, we characterize the performance of multiple flows of data item requests under resource pooling and separation for LRU caching when the cache size is large.  Analytically, we show that it is asymptotically optimal to jointly serve multiple flows if their data item sizes and popularity distributions are similar and their arrival rates do not differ significantly; the self-organizing property of LRU caching automatically optimizes the resource allocation among them asymptotically. Otherwise, separating these flows could be better, e.g., when data sizes vary significantly. We also quantify critical points beyond which resource pooling is better than separation for each of the flows when the overlapped data items exceed certain levels. Technically, for a broad class of heavy-tailed distributions we derive the asymptotic miss probabilities of multiple flows of requests with varying data item sizes in a shared LRU cache space. It also validates the characteristic time approximation under certain conditions. These results provide new insights on improving the performance of caching systems.	approximation;asymptotically optimal algorithm;cache (computing);data item;organizing (structure);request–response;self-organization	Jian Tan;Guocong Quan;Kaiyi Ji;Ness B. Shroff	2018	POMACS	10.1145/3179408	cpu cache;asymptotically optimal algorithm;distributed computing;popularity;pooling;cache algorithms;cache;computer science;resource allocation	Metrics	-14.029373527914453	66.3219532343596	31121
1f62d0ef9ce356b2e537c4b606fc19fbe58efa52	the influence of atm on operating systems	flow switching;selected works;mpls;atm networks;operating system;transport networks;bepress;high throughput;atm;memory bandwidth;protocol data unit	"""The features of ATM offered many attractions to the application community, such as fine-grained multiplexing and high-throughput links. These created considerable challenges for the O.S. designer, since a small protocol data unit size (the 48 byte """"cell"""") and link bandwidths within a (binary) order of magnitude of memory bandwidths demanded considerable rethinking of operating system structure.Using an historical and personal perspective, this paper describes two aspects of that rethinking which I participated in directly, namely, those of new event signalling and memory buffering schemes. Ideas and techniques stemming from ATM network research influenced first research operating systems and then commercial operating systems. The positive results of ATM networking, although indirect, have benefitted applications and systems far beyond the original design goals."""	atm turbo;byte;high-throughput computing;multiplexing;operating system;stemming;throughput	Jonathan M. Smith	2002	Computer Communication Review	10.1145/774749.774755	high-throughput screening;multiprotocol label switching;real-time computing;telecommunications;computer science;atm adaptation layer;operating system;protocol data unit;atmosphere;computer security;memory bandwidth;computer network	Networks	-10.02956492432377	66.93371437315804	31128
32e3a63b37aa6306fce5de11e11b15d8b810bde9	distributed approach for smartgrids reconfiguration based on the ospf routing protocol	databases;smart power grids distribution networks routing protocols;routing protocols;reliability;substations optimization databases informatics routing protocols monitoring reliability;monitoring;smarts grids distributed approach multiagent sytems network reconfiguration ospf;substations;optimization;informatics;typical centralized reconfiguration algorithm distributed approach smartgrids reconfiguration ospf routing protocol smart grids sg electric power networks automatic network reconfiguration fault detection distribution networks load balancing power losses open shortest path first network reconfiguration electrical distribution company	Smart grids (SG) are essential for efficient management and monitoring of electric power networks. One of the most important tasks in SG focuses on fault detection and automatic network reconfiguration. This process allows minimizing power losses and load balancing in distribution networks. In this paper, an adaptation of the open shortest path first (OSPF) routing protocol to accomplish the network reconfiguration task is proposed. The algorithm is intended to run in secondary substation nodes over an agent-based distributed architecture. The proposed algorithm has been tested on the IEEE 123 modified node test feeder and on an actual grid deployed by an electrical distribution company. Moreover, a performance comparison with a typical centralized reconfiguration algorithm is carried out.	agent-based model;centralized computing;dijkstra's algorithm;distributed computing;fault detection and isolation;load balancing (computing);routing;sonic generations;suicidegirls;traction substation	Francisco J. Rodriguez;Susel Fernández;Ines Sanz;Miguel Moranchel;Emilio José Bueno	2016	IEEE Transactions on Industrial Informatics	10.1109/TII.2015.2496202	real-time computing;computer science;distance-vector routing protocol;reliability;distributed computing;routing protocol;link-state routing protocol;informatics;statistics;computer network	Embedded	-8.824805840476497	79.63374286982929	31139
716c825e4289c27c466f11fed83629d6bf6be6c4	guest editorial: special section on algorithm design and scheduling techniques (realistic platform models) for heterogeneous clusters	distributed algorithms;concurrent computing;heterogeneous cluster;processor scheduling;distributed computing;scheduling algorithm;clustering algorithms;production;clustering algorithms scheduling algorithm algorithm design and analysis processor scheduling distributed computing concurrent computing production distributed algorithms context modeling;context modeling;algorithm design;algorithm design and analysis	THE last decade has seen a dramatic increase in the deployment of heterogeneous distributed computing platforms, in particular, those consisting of heterogeneous clusters, and multiple heterogeneous collections of clusters aggregated over wide-area networks into grids. The software infrastructures and mechanisms to deploy such platforms have been well studied and implementations are already used in production, so that heterogeneous platforms represent a significant, and growing, fraction of the computational power delivered by parallel platforms today. In spite of these successes, many research challenges remain, including those pertaining to distributed algorithms and scheduling algorithms, which are critical for ensuring that these platforms are used effectively. In this context, the goal of this special section on “Algorithm Design and Scheduling Techniques (Realistic Platform Models) for Heterogeneous Clusters” is to gather papers that further our understanding of the impact of platform heterogeneity on the design and evaluation of new such algorithms. In the paper entitled “Allocating Non-Real-Time and Soft Real-Time Jobs in Multiclusters,” Ligang He, Stephen A. Jarvis, Daniel P. Spooner, Hong Jiang, Donna N. Dillenberger, and Graham R. Nudd introduce two workload allocation strategies for large-scale heterogeneous platforms. The first strategy achieves an optimized mean response time for jobs having no real-time requirements. The second strategy obtains an optimized mean miss rate for jobs having soft real-time requirements (i.e., a fraction of jobs are permitted to miss the real-time constraints). Both strategies take into account average system behaviors (such as the mean arrival rate of jobs) to calculate the workload proportions for individual clusters, and update on-the-fly the workload allocation when the change in the mean arrival rate reaches a certain threshold. The allocation schemes are combined with two job dispatching strategies (weighted random and weighted round-robin) to generate new job scheduling algorithms for multicluster environments. In their paper “On the Distribution of Sequential Jobs in Random Brokering for Heterogeneous Computational Grids,” Vandy Berten, Joel Goossens, and Emmanuel Jeannot study resource brokering for scheduling sequential jobs onto a grid platform that consists of heterogeneous sets of homogeneous processors, such as a set of clusters. Resources in each cluster are managed by a local scheduler that maintains a job queue. The paper studies a centralized “metascheduler” that uses a randomized strategy to share available resources among competing jobs. This research considers two cases depending on whether the platform is heavily loaded or lightly loaded. For each case, it obtains both analytical and experimental characterizations of the queue lengths at each local scheduler, CPU utilization, and average job slowdowns. Furthermore, the paper presents a discussion of the system’s behavior when it transitions between a heavily loaded state and a lightly loaded one. All presented theoretical results are corroborated by simulations and provide a thorough description of randomized resource brokering. The research in “Multiple Job Scheduling in a Connection-Limited Data Parallel System” presents a new method for scheduling jobs in a distributed system where the critical resource is the bandwidth to access the stored data. The authors, Alessandro Amoroso and Keith Marzullo, describe an approach that supports the master-worker scheme and can be applied to data parallel computation. They consider a typical wide-area data grid that is comprised of a set of sites, where each site has one or more local area networks. The platform model used is based on the Nile data grid. This paper uses a set of synthetic jobs to compare three schedulers: Greedy, Maxfow, and Hybrid. They tested their new approach under various circumstances and measured its performance by means of several metrics. The new Hybrid scheduler is never worse than either of the other two schedulers, and in 20 percent of the simulated runs, it produced runs that were at least 20 percent better. The paper entitled “Capacity-Aware Multicast Algorithms on Heterogeneous Overlay Networks,” coauthored by Zhan Zhang, Shigang Chen, Yibei Ling, and Randy Chow, addresses the problem of multicast for group IEEE TRANSACTIONS ON PARALLEL AND DISTRIBUTED SYSTEMS, VOL. 17, NO. 2, FEBRUARY 2006 97	algorithm design;central processing unit;centralized computing;computation;daniel goossens;data parallelism;distributed algorithm;distributed computing;entity–relationship model;graham scan;greedy algorithm;job queue;job scheduler;job shop scheduling;job stream;li-chen wang;marzullo's algorithm;meta-scheduling;multicast;overlay network;parallel computing;queueing theory;randomized algorithm;real-time clock;real-time computing;real-time transcription;requirement;response time (technology);round-robin scheduling;scheduling (computing);simulation;software deployment;synthetic intelligence;weighted round robin	Henri Casanova;Yves Robert;Howard Jay Siegel	2006	IEEE Trans. Parallel Distrib. Syst.	10.1109/TPDS.2006.25	fair-share scheduling;fixed-priority pre-emptive scheduling;algorithm design;distributed algorithm;parallel computing;real-time computing;flow shop scheduling;concurrent computing;dynamic priority scheduling;computer science;rate-monotonic scheduling;two-level scheduling;distributed computing;parallel algorithm;distributed design patterns;round-robin scheduling;algorithm	HPC	-16.569945315925054	60.55267724473807	31178
0192f89ac8191987c9fc7b2db05c92f544a9707a	ipv6 essentials - integrating ipv6 into your ipv4 network (2. ed.)				Silvia Hagen	2002			data science;ipv6;ipv4;computer science	Vision	-23.570396516671927	88.02457547741402	31182
08dd25e8c6dbc7441a19306887c6bad0c465ccf7	modelling and solving grid resource allocation problem with network resources for workflow applications	resource allocation;satisfiability;grid;workflow;project scheduling	A problem of allocating resources of a grid to workflow applications is considered. The problem consists, generally, in allocating distributed grid resources to tasks of a workflow in such a way that the resource demands of each task are satisfied. Grid resources are divided into computational resources and network resources. Computational tasks and transmission tasks of a workflow are distinguished. We present a model of the problem, and an algorithm for finding feasible resource allocations. A numerical example is included, showing the importance of the resource allocation phase on a grid. Some conclusions and directions for future research are given.		Marek Mika;Grzegorz Waligóra;Jan Weglarz	2011	J. Scheduling	10.1007/s10951-009-0158-0	workflow;semantic grid;resource allocation;computer science;theoretical computer science;distributed computing;management science;grid;schedule;workflow management system;grid computing;satisfiability	HPC	-18.115014478448	64.27846099065911	31184
863a12da63b4a419647557f3d1e455538dacb77e	fly-by-wireless for next generation aircraft: challenges and potential solutions	avionics;reliability fly by wireless next generation aircraft wireless connectivity fuel consumption maintenance costs weight reduction avionics requirements wireless avionics network wireless aircraft application ultrawideband technology security;ultra wideband communication aircraft communication avionics on board communications telecommunication network reliability telecommunication security;telecommunication network reliability;aircraft communication;reseaux et telecommunications;security time critical avionics network fly by wireless uwb determinism reliability;telecommunication security;ultra wideband communication;reliability aerospace electronics peer to peer computing topology wireless sensor networks communication system security wireless communication;on board communications	“Fly-By-Wireless” paradigm based on wireless connectivity in aircraft has the potential to improve efficiency and flexibility, while reducing weight, fuel consumption and maintenance costs. In this paper, first, the opportunities and challenges for wireless technologies in safety-critical avionics context are discussed. Then, the assessment of such technologies versus avionics requirements is provided in order to select the most appropriate one for a wireless aircraft application. As a result, the design of a Wireless Avionics Network based on Ultra WideBand technology is investigated, considering the issues of determinism, reliability and security.	avionics;man-in-the-middle attack;multicast;overhead (computing);programming paradigm;reliability (computer networking);requirement;scalability;ultra-wideband	Dinh-Khanh Dang;Ahlem Mifdaoui;Thierry Gayraud	2012	2012 IFIP Wireless Days	10.1109/WD.2012.6402820	embedded system;electronic engineering;wireless wan;wireless site survey;engineering;wireless network;key distribution in wireless sensor networks;municipal wireless network;wi-fi array;fixed wireless;computer network	Mobile	-12.886349346890922	85.85360608609521	31251
d4aae277d50baaeedc02c7e74bfd922a8f01d212	recursive ground truth estimator for social data streams		The paper develops a recursive state estimator for social network data streams that allows exploitation of social networks, such as Twitter, as sensor networks to reliably observe physical events. Recent literature suggested using social networks as sensor networks leveraging the fact that much of the information upload on the former constitutes acts of sensing. A significant challenge identified in that context was that source reliability is often unknown, leading to uncertainty regarding the veracity of reported observations. Multiple truth finding systems were developed to solve this problem, generally geared towards batch analysis of offline datasets. This work complements the present batch approaches by developing an online recursive state estimator that recovers ground truth from streaming data. In this paper, we model physical world state by a set of binary signals (propositions, called assertions, about world state) and the social network as a noisy medium, where distortion, fabrication, omissions, and duplication are introduced. Our recursive state estimator is designed to recover the original binary signal (the true propositions) from the received noisy signal, essentially decoding the unreliable social network output to obtain the best estimate of ground truth in the physical world. Results show that the estimator is both effective and efficient at recovering the original signal with a high degree of accuracy. The estimator gives rise to a novel situation awareness tool that can be used for reliably following unfolding events in real time, using dynamically arriving social network data.	application programming interface;assertion (software development);authorization;cns;correctness (computer science);distortion;ground truth;ibm notes;online and offline;participatory sensing;recursion (computer science);sensor;simulation;social network;streaming media;unfolding (dsp implementation);upload;veracity;μ-recursive function	Shuochao Yao;Md. Tanvir Al Amin;Lu Su;Shaohan Hu;Shen Li;Shiguang Wang;Yiran Zhao;Tarek F. Abdelzaher;Lance M. Kaplan;Charu C. Aggarwal;Aylin Yener	2016	2016 15th ACM/IEEE International Conference on Information Processing in Sensor Networks (IPSN)		embedded system;unit disk graph;wireless sensor network;computer science;sensor;noise measurement;theoretical computer science;machine learning;data mining;reliability;statistics	Mobile	-32.876501049939584	64.7293661847507	31281
a66d6ee35dcff00bc5838d78d191b8f10b1e8eb1	an efficient checkpointing scheme using price history of spot instances in cloud computing environment	spot instances;checkpointing;price history;cloud computing	The cloud computing is a computing paradigm that users can rent computing resources from service providers as much as they require. A spot instance in cloud computing helps a user to utilize resources with less expensive cost, even if it is unreliable. When a user performs tasks with unreliable spot instances, failures inevitably lead to the delay of task completion time and cause a seriously deterioration in the QoS of users. Therefore, we propose a price history based checkpointing scheme based on SLA (Service Level Agreement) to avoid the delay of task completion time. The proposed checkpointing scheme reduces the number of checkpoint trials and improves the performance of task execution. The simulation results show that our scheme outperforms the existing checkpointing schemes in terms of the reduction of both the number of checkpoint trials and total costs per spot instances for user’s bid.	application checkpointing;cloud computing;cost efficiency;mike lesser;programming paradigm;quantum fluctuation;service-level agreement;simulation;transaction processing system	Daeyong Jung;Sung-Ho Chin;Kwang-Sik Chung;Heon-Chang Yu;Joon-Min Gil	2011		10.1007/978-3-642-24403-2_16	parallel computing;real-time computing;cloud computing;computer science;operating system;database;distributed computing;computer security	HPC	-19.175098450672728	61.83220553006994	31284
b5545b5f0cb9318db395d3441eb2f0b515a67773	an exact algorithm for host allocation, capacity and flow assignment problem in wan	host allocation;exact algorithm;flow assignment problem;assignment problem	The paper presents the exact algorithm for capacity and flow assignment and hosts allocation problem in wide area computer networks. The problem consists in selection of flow routes, channel capacities and hosts allocation at nodes in order to minimize the total average delay per packet and the connecting cost of the hosts at nodes subject to budget constraint. The branch and bound method to construct the exact algorithm for solving the considered problem is used.	assignment problem;exact algorithm	Marcin Markowski;Andrzej Kasprzak	2002			mathematical optimization;combinatorics;minimum-cost flow problem;multi-commodity flow problem;generalized assignment problem;mathematics;distributed computing;assignment problem;weapon target assignment problem	PL	-4.6003722103028215	79.82503738263273	31341
6c65cdff6b245a9f696ea6ac0ea73647e6818143	addressing cell edge performance by extending andsf and inter-rat ue steering	protocols;lte lte a andsf sib hotspot2 0 real time wifi;ciencia;cell edge performance technique hs2 0 low performance cell edge users rrc sib radio resource control system information block andsf capability global lte lte a performance non3gpp rat access points andsf specification transparent policy based rat selection traffic steering 3gpp andsf 3gpp access network discovery selection function radio access technology pervasive mobile experience hotspot 2 0 passpoint certified access points lte lte a cells small cell heterogeneous network deployment network planning interrat ue steering andsf steering;computer architecture;handover;telecommunication network planning cellular radio long term evolution radio access networks;projetos;ieee 802 11 standards;mobile communication;investigacao;publicacoes;ieee 802 11 standards handover mobile communication computer architecture conferences protocols;iscte iul;conferences	Cell edge performance has always been challenging from network planning and performance perspectives. Several cell edge performance techniques and methods have been widely proposed to enhance it. Small cell heterogeneous network deployments (LTE/LTE-A cells and Hotspot 2.0 Passpoint certified access points) enable pervasive mobile experience, seamlessly connecting users though both radio access technologies (RAT). Underlying, 3GPP's Access Network Discovery and Selection Function (ANDSF) provides transparent policy-based RAT selection and traffic steering. Current ANDSF specifications, however, do not support Real Time (RT) network performance awareness, crucial to intelligently steer traffic or users between 3GPP and non-3GPP RATs. Our contribution is a method of enhancing global LTE-LTE/A performance, focusing on cell edges by a) enhancing ANDSF capabilities using Radio Resource Control (RRC) System Information Block (SIB) to convey RT data to steering decision and b) intelligently steer low performance cell edge users to non-3GPP RAT access points, which we consider to be HS2.0.	access network discovery and selection function;cell (microprocessor);compaq lte;emoticon;hotspot (wi-fi);java hotspot virtual machine;network performance;pervasive informatics;real-time business intelligence;system information (windows);wireless access point	Luis Carlos Goncalves;Pedro Sebastião;Nuno M. B. Souto;Américo Correia	2014	2014 11th International Symposium on Wireless Communications Systems (ISWCS)	10.1109/ISWCS.2014.6933398	communications protocol;real-time computing;mobile telephony;telecommunications;computer science;handover;operating system;access network discovery and selection function;computer network	Mobile	-14.706524329180342	88.01867605037131	31344
ef4435390b54857b145f69d6266154a8e4f2a41b	resource profile advisor for containers in cognitive platform		Containers have transformed the cluster management into an application oriented endeavor, thus being widely used as the deployment units (i.e., micro-services) of large scale cloud services. As opposed to VMs, containers allow for resource provisioning with fine granularity and their resource usage directly reflects the micro-service behaviors. Container management systems like Kubernetes and Mesos provision resources to containers according to the capacity requested by the developers. Resource usages estimated by the developers are grossly inaccurate. They tend to be risk-averse and over provision resources, as under-provisioning would cause poor runtime performance or failures.  Without actually running the workloads, resource provisioning is challenging. However, benchmarking production workloads at scale requires huge manual efforts. In this work, we leverage IBM Monitoring service to profile the resource usage of production IBM Watson services in rolling windows by focusing on both evaluating how developers request resources and characterizing the actual resource usage.  Our resource profiling study reveals two important characteristics of the cognitive workloads. 1. Stationarity. According to Augmented Dickey-Fuller test with 95% confidence, more than 95% of the container instances have stationary CPU usage while more than 85% have stationary memory usage, indicating that resource usage statistics do not change over time. We find for the majority of containers that the stationarity can be detected at the early stage of container execution and can hold throughout their lifespans. In addition, containers with non-stationary CPU or memory usage are also observed to implement predictable usage trends and patterns (e.g., trend stationarity or seasonality). 2. Predictability by container image. By clustering the containers based on their images, container resource usages within the same cluster are observed to exhibit strong statistical similarity. This suggests that the history of resource usage for one instance can be used to predict usage for future instances that run the same container image.  Based on profiling results of running containers in rolling windows, we propose a resource usage advisory system to refine the requested resource values of the running and arriving containers as illustrated in Fig. 1. Our system continuously retrieves the resource usage metrics of running containers from IBM monitoring service and predicts the resource usage profiles in a container resource usage prediction agent. Upon the arrival of a new pod1, the resource profile advisor, proposed as a module in the web-hooked admission controller in Kubernetes, checks whether the resource profile of each container in the pod has been predicted with confidence. If a container's profile has been predicted and cached in the container resource profile database, the default requested values of containers are refined by the predicted ones; otherwise, containers are forwarded to the scheduler without any change. Similarly, a resource profile auto-scaler is proposed to update the requested resource values of containers for running pods2 as soon as the database is updated.  Our study shows that developers request at least 1 core-per-second (cps) CPU and 1 GB memory for ≥ 70% of the containers, while ≥ 80% of the containers actually use less than 1 cps and 1GB. Additionally, ~ 20% of the containers are significantly under provisioned. We use resource usage data in one day to generate container resource profiles and evaluate our approach based on the actual usage on the following day. Without our system, average CPU (memory) usage for >90% of containers lies outside of 50% - 100% (70% - 100%) of the requested values. Our evaluation shows that our system can advise request values appropriately so that average and 95th percentile CPU (memory) usage for >90% of the containers are within 50% - 100% (70% - 100%) of the requested values. Furthermore, average CPU (memory) utilization across all pods is raised from 10% (26%) to 54% (88%).	cache (computing);central processing unit;cloud computing;cluster analysis;cluster manager;gigabyte;microservices;microsoft windows;norm (social);profiling (computer programming);provisioning;risk aversion;run time (program lifecycle phase);scheduling (computing);seasonality;software deployment;stationary process;symposium on principles of database systems;thomas j. watson research center;usage data;watson (computer)	Mehmet F. Aktas;Chen Wang;Alaa Youssef;Malgorzata Steinder	2018		10.1145/3267809.3275448	real-time computing;cpu time;computer science;point of delivery;cache;benchmarking;profiling (computer programming);usage data;cloud computing;provisioning	OS	-23.444640232527497	60.632039568646995	31374
23afb05301520b9c07ac88a17967dfed859c0945	dynamic effective resource allocation based on cloud computing learning model	resources auction strategy;resource allocation;bilateral game strategy;efficiency learning model;cloud computing	In cloud computing field, a service-provider offers large number of resources for customers with a relatively low cost. However, any resource allocation model has to consider computational resources as well as network resources to accurately reflect practical demands. In order to rationally allocate the limited resources to users and improve resource utilization and energy efficiency of cloud systems as much as possible, a dynamic effective resource allocation algorithm based on cloud computing learning model is proposed. According to the dynamic effective resources allocation, Quality of Service Standards Framework is adopted to obtain cloud service management mechanism. In addition, the resources auction strategy and dynamic bilateral game strategy are also adopted to effectively leverage the interest-relationship between the user and the cloud provider so as to assign resources to these users with bigger demand. In the computation of cloud system and resources allocation of storage tasks, the cloud-based learning model is used to balance the demand of energy and resources so as to achieve optimal system efficiency. Simulation experiment results show that our proposed algorithm can assign more reasonably resource and energy for system computation and storage tasks and the performance of the algorithm is superior to other comparison algorithms on the utilization of resource and energy	cloud computing	Fu Xie;Fangai Liu	2014	JNW	10.4304/jnw.9.11.3092-3097	simulation;cloud computing;resource allocation;computer science;operating system;management science;resource allocation;utility computing	AI	-22.272324155047784	64.74667022573124	31393
7d74815651430936b88567fc58a915dc21dab8ef	contention detection by throttling: a black-box on-line approach	cachebench throttling virtualization technology cloud computing paradigm performance isolation virtual machines public cloud providers business confidentiality performance interference detection client quality of service metrics client qos metrics profiling servers cloud providers online black box approach resource metrics hypervisor resource contention detection three phase algorithm alarm phase statistical outliers victim vm resource metrics wikimedia resource hoggers parsec;measurement monitoring cloud computing quality of service detectors virtual machine monitors detection algorithms;virtualisation cloud computing quality of service resource allocation statistical analysis virtual machines	Visualization technology powers up the cloud computing paradigm and inevitably raises concerns about performance isolation of collocated virtual machines (VM). It is imperative for public cloud providers to guarantee performance targets for tenants' VMs while respecting strict business confidentiality, e.g., having no information on applications nor their performance. A large body of related work addresses the challenges of detecting performance interferences by leveraging client's quality of service (QoS) metrics, such as latency, and additional profiling servers. Whereas to assist cloud providers, we resort to an on-line blackbox approach based on throttling that detects a wide range of resource contentions with no cooperation need from the virtual machines. We focus on different resource metrics and actively monitor them from the hypervisor in fine time granularity at low cost. To detect resource contention, we propose a three-phase algorithm: an alarm phase, to identify statistical outliers in the victim's VM resource metrics; a passive diagnosis phase, to match the current sample to historical behaviors; and, an active learning phase, to discern contentions from application phase changes via throttling. We evaluate our algorithm on a prototype running Wikimedia as victim application across a set of VMs collocated with neighboring VMs running resource hoggers, i.e. PARSEC and Cachebench. Our extensive experimental results show that we can reach an average detection accuracy above 90% while limiting the performance degradation experienced by offender workloads to short learning phases.	algorithm;amortized analysis;black box;cloud computing;confidentiality;elegant degradation;hypervisor;imperative programming;isolation (database systems);online and offline;parsec;programming paradigm;prototype;quality of service;resource contention;sensor;testbed;two-phase commit protocol;virtual machine;z/vm	Joel Vallone;Robert Birke;Lydia Y. Chen;Babak Falsafi	2015	2015 IEEE 23rd International Symposium on Quality of Service (IWQoS)	10.1109/IWQoS.2015.7404740	real-time computing;computer science;operating system;computer security;computer network	Arch	-28.022589806134118	64.60904450498798	31397
53496f9bcf1004e5a3eab08b30d1deeaba80750a	when cellular capacity meets wifi hotspots: a smart auction system for mobile data offloading	cellular capacity;procurement;contracts;mobile data offloading cellular capacity auction;auction;ieee 802 11 standards;mobile communication;vcg auction cellular capacity wifi hotspots smart auction system mobile data offloading social networking video streaming mobile data traffic congestion cost minimization cellular service provider optimal procurement mechanism contingent contracts economics computational technology standard vickrey clarke groves auction;mobile data offloading;bandwidth;economics;wireless lan cellular radio contracts economics electronic commerce procurement social networking online telecommunication traffic video streaming;mobile computing;ieee 802 11 standards procurement mobile communication bandwidth contracts mobile computing economics	The surge of social networking and video streaming on the go has led to the explosion of mobile data traffic. To minimize congestion costs for under-served demand (e.g., Dissatisfied customers, or churn), the cellular service provider is willing to pay WiFi hotspots to serve the demand that exceeds capacity. In the present study, we propose an optimal procurement mechanism with contingent contracts for cellular service providers to leverage the advantages of both cellular and WiFi resources. We show the procedure of computing the optimal procurement mechanism with a tight integration of economics and computational technology. Simulation results show that the proposed procurement mechanism significantly outperforms the standard Vickrey-Clarke-Groves (VCG) auction in terms of the cellular service provider's expected payoff.	auction algorithm;bayesian network;computation;contingency (philosophy);edmund m. clarke;java hotspot virtual machine;marginal model;mobile data offloading;monopoly;nist hash function competition;nash equilibrium;network congestion;procurement;quality of service;simulation;social capital;streaming media;usb on-the-go	Liangfei Qiu;Huaxia Rui;Andrew B. Whinston	2015	2015 48th Hawaii International Conference on System Sciences	10.1109/HICSS.2015.581	mobile telephony;procurement;computer science;operating system;mobile computing;computer security;bandwidth;commerce;computer network	Metrics	-23.59592019931509	75.42775315628425	31433
11babdcba084860aaa577144c38aceb5d16f2c9a	embedded unidirectional incomplete hypercubes for optical networks	wdm;embedding;optical network;hypercube;multiplexage longueur onde;high speed wavelength division multiplexing;interconnection;performance node numbers optical networks virtual regular topologies physical topologies high speed wavelength division multiplexing wdm embedding virtual unidirectional incomplete hypercube multichannel multihop network interconnection self routing strategy aggregate throughput paths;optical transmitters;node numbers;routing;performance;wdm optical network;telecommunication network;optical fiber networks;self routing strategy;hypercubes optical fiber networks network topology spread spectrum communication wavelength division multiplexing routing throughput bandwidth optical fibers optical transmitters;optical networks;algorithme;network topology;algorithm;spread spectrum communication;telecomunicacion optica;telecommunication optique;telecommunication network routing;optical fibers;grande vitesse;red telecomunicacion;virtual regular topologies;reseau telecommunication;optical links;aggregate throughput;optical telecommunication;hypercubes;physical topologies;bandwidth;gran velocidad;virtual unidirectional incomplete hypercube;encaminamiento;multichannel multihop network;paths;high speed;multihop network;multiplaje longitud onda;hypercube networks;acheminement;throughput;wavelength division multiplexing;algoritmo;wavelength division multiplex;wavelength division multiplexing hypercube networks network topology optical links telecommunication network routing;hipercubo	Many proposals of virtual regular topologies embedded in physical topologies for high-speed wavelength division multiplexing (WDM) optical networks do not consider the issue of allowing a variable number of nodes in the network. A solution for embedding a virtual unidirectional incomplete hypercube into a physical topology that does is presented. The proposed solution is a multichannel multihop network which has several elegant features: (a) it allows any number of nodes to be connected to the network, (b) it only requires a minor effort to reconfigure the new interconnection whenever a node is added or deleted for the network, (c) it supports a self-routing strategy, (d) the aggregate throughput of the network increases as more nodes are added, and (e) alternate paths are available which have a comparable distance to the destination as the primary path. The performance of the scheme is comparable to the performance of both the unidirectional hypercube and the bidirectional hypercube. >	embedded system	Swie-Tsing Tan;David Hung-Chang Du	1993	IEEE Trans. Communications	10.1109/26.237844	telecommunications;computer science;mathematics;distributed computing;wavelength-division multiplexing;hypercube;computer network	Embedded	-5.694374378402858	80.06205302796984	31474
4ce5745dc0dcdf10d8208371aca62a247e0ab729	temperature aware workload managementin geo-distributed data centers	energy;convergence;routing;resource management;cooling servers temperature distribution distributed databases routing convergence resource management;cooling energy reduction temperature aware workload management approach geo distributed data centers energy consumption reduction energy cost reduction energy efficiency ambient temperature geographical diversity temperature diversity cooling energy overhead reduction delay tolerant batch workloads joint request routing optimization batch workload capacity allocation distributed algorithm m block alternating direction method of multiplier algorithm admm algorithm classical two block algorithm convergence rate trace driven simulations;distributed optimization;servers;admm;cooling efficiency;distributed databases;temperature distribution;workload management;power aware computing computer centres cooling cost reduction distributed algorithms energy conservation energy consumption;cooling;data centers	Lately, for geo-distributed data centers, a workload management approach that routes user requests to locations with cheaper and cleaner electricity has been developed to reduce energy consumption and cost. We consider two key aspects that have not been explored in this approach. First, through empirical studies, we find that the energy efficiency of cooling systems depends critically on the ambient temperature, which exhibits significant geographical diversity. Temperature diversity can be used to reduce the cooling energy overhead. Second, energy consumption comes from not only interactive workloads driven by user requests, but also delay tolerant batch workloads that run at the back-end. The elastic nature of batch workloads can be exploited to further reduce the energy cost. In this paper, we propose to make workload management temperature aware. We formulate the problem as a joint optimization of request routing for interactive workloads and capacity allocation for batch workloads. We develop a distributed algorithm based on an m-block alternating direction method of multipliers (ADMM) algorithm that extends the classical two-block algorithm. We prove the convergence and rate of convergence results under general assumptions. Through trace-driven simulations, we find that our approach consistently provides 15-20 percent cooling energy reduction, and 5-20 percent overall cost reduction over existing methods.		Hong Xu;Chen Feng;Baochun Li	2015	IEEE Trans. Parallel Distrib. Syst.	10.1109/TPDS.2014.2325836	data center;routing;real-time computing;energy;convergence;computer science;resource management;theoretical computer science;distributed computing;server;computer network	HPC	-20.826977938479175	63.201906233771965	31545
0fc28176c6fde2e03f05a0cf074be14deea94e32	qos service routing in one-to-one and one-to-many scenarios in next-generation service-oriented networks	multicast communication;next generation service oriented networks;routing;web and internet services;service orientation;intserv networks;service dependency;one to many scenarios;service model;one to one and one to many scenarios;telecommunication network routing;unicast routing;qos service routing;multicast communication quality of service telecommunication network routing;video on demand;unicast routing next generation service oriented networks qos service routing quality of service one to many scenarios one to one and one to many scenarios service functionality service dependency resource requirement heterogeneity multicast routing;resource requirement heterogeneity;next generation;bandwidth;ip networks;intelligent networks;computer science;quality of service;intelligent networks routing next generation networking unicast intserv networks web and internet services video on demand bandwidth computer science ip networks;multicast routing;next generation networking;unicast;service functionality;integrated services	The QoS service routing problem has recently emerged as a consequence of the increasingly accepted distributed and composable services model. Different from the conventional QoS data routing, QoS service routing presents additional challenges caused by the service functionality, service dependency, resource requirement heterogeneity, and loop formation issues, that make solutions for QoS data routing inapplicable to QoS service routing. We study this problem both in one-to-one and one-to-many application scenarios, so that despite the fact that the component services are located distributively in multiple hosts, the system can still provide integrated services seamlessly and efficiently.	integrated services;one-to-many (data model);one-to-one (data model);quality of service;routing;service-oriented device architecture	Jingwen Jin;Klara Nahrstedt	2004	IEEE International Conference on Performance, Computing, and Communications, 2004	10.1109/PCCC.2004.1395077	policy-based routing;wireless routing protocol;routing table;routing domain;intelligent network;routing;enhanced interior gateway routing protocol;static routing;adaptive quality of service multi-hop routing;real-time computing;mobile qos;quality of service;zone routing protocol;equal-cost multi-path routing;computer science;dynamic source routing;multipath routing;service-oriented modeling;distributed computing;integrated services;routing protocol;link-state routing protocol;bandwidth;routing information protocol;computer network;unicast	HPC	-11.342634647611897	76.08881460007431	31569
5875ac63c6e31c83a1b088a591d5f76ef58065d8	routing and spectrum assignment for dual failure path protected elastic optical networks	routing;elastic optical networks failure analysis optical fiber networks frequency selective surfaces heuristic algorithms routing adaptation models redundancy;optical fiber networks;failure analysis;link fs maximum number minimization routing and spectrum assignment rsa dual failure path protected elastic optical networks dual failure protected eon protection lightpaths frequency slot maximum number minimization protection resource sharing integer linear programming models ilp models spectrum window plane based heuristic algorithms swp based heuristic algorithms spare capacity redundancy;redundancy;heuristic algorithms;telecommunication network routing integer programming linear programming optical fibre networks radio spectrum management telecommunication network reliability;elastic optical networks;adaptation models;spectrum window plane swp elastic optical network eon dual failure dedicated 1 1 1 mixed 1 1 1 1 1 1 1 1 1 ilp model;frequency selective surfaces	We present the design of a dual failure protected elastic optical network (EON) for different sharing capabilities of protection lightpaths. Routing and spectrum assignment (RSA) is considered for such a network so as to minimize the maximum number of frequency slots (FSs) used. The key principles for protection resource sharing among the first and the second protection lightpaths are identified for dedicated 1:1:1, mixed 1:1:1, 1+1:1, and 1+1+1 protection. Both integer linear programming (ILP) models and spectrum window plane (SWP)-based heuristic algorithms are proposed for RSA in dual failure protected EONs. Simulation results indicate that, apart from being efficient, the proposed SWP-based heuristic algorithm not only performs close to the ILP model but also does much better than a benchmark adaptive routing algorithm. We find that 1:1:1 protection technique performs better in terms of the maximum number of FSs used and the spare capacity redundancy than both the 1+1:1 and 1+1+1 techniques. In addition, the mixed 1:1:1 case outperforms the dedicated 1:1:1 case both in minimizing the maximum number of link FSs used and its spare capacity redundancy.	1:1 pixel mapping;algorithm;benchmark (computing);heuristic (computer science);integer programming;like button;linear programming;routing;simulation	Hong Guo;Gangxiang Shen;Sanjay K. Bose	2016	IEEE Access	10.1109/ACCESS.2016.2599511	mathematical optimization;failure analysis;routing;computer science;theoretical computer science;mathematics;distributed computing;redundancy	EDA	-6.461918606982887	82.39843314102171	31593
a71aab4629b6938dd704a45d63a2f00db24270ac	efficient placement of multi-component applications in edge computing systems		Mobile Edge Computing (MEC) is a new paradigm which has been introduced to solve the inefficiencies of mobile cloud computing technologies. The key idea behind MEC is to enhance the capabilities of mobile devices by forwarding the computation of applications to the edge of the network instead of to a cloud data-center. One of the main challenges in MEC is determining an efficient placement of the components of a mobile application on the edge servers that minimizes the cost incurred when running the application. In this paper, we address the problem of multi-component application placement in edge computing by designing an efficient heuristic on-line algorithm that solves it. We also present a Mixed Integer Linear Programming formulation of the multi-component application placement problem that takes into account the dynamic nature of users' location and the network capabilities. We perform extensive experiments to evaluate the performance of the proposed algorithm. Experimental results indicate that the proposed algorithm has very small execution time and obtains near optimal solutions.	computation;data center;edge computing;experiment;heuristic;heuristic (computer science);information needs;integer programming;iterative method;linear programming formulation;mobile app;mobile cloud computing;mobile device;online algorithm;online and offline;programming paradigm;run time (program lifecycle phase);serial digital video out	Tayebeh Bahreini;Daniel Grosu	2017		10.1145/3132211.3134454	computer science;real-time computing;computation;cloud computing;mobile edge computing;mobile cloud computing;mobile device;integer programming;server;distributed computing;edge computing	EDA	-21.671073227735377	66.87958726519662	31705
c2f42bd83da17b1f41224c4daa92a46f50b931a8	effect of data placement on the reliability of data storage systems	graph theory;reliability;storage management;redundancy data storage systems data models distributed databases loss measurement correlation;event driven simulations data storage systems data redundancy erasure codes data protection storage node failures redundant data placement large scale storage systems reliability storage efficiency declustered placement scheme approximate expressions data loss system parameters shortest paths;storage management graph theory reliability	Data redundancy, in the form of replication or advanced erasure codes, is used to protect data from storage node failures. It is known that that the placement of this redundant data across storage nodes can have a significant impact on the reliability, especially for large-scale storage systems. In particular, a declustered placement of redundant data is shown to have significantly higher reliability than the traditionally-used clustered placement for many redundancy schemes. This implies that significant gains in reliability can be obtained without losing storage efficiency by choosing the declustered placement scheme. Approximate expressions for the mean time to data loss of the system in terms of the various parameters of the system are obtained by considering the shortest paths to data loss when node failures occur and rebuild processes commence. These expressions are shown to hold true for parameters of practical interest through detailed event driven simulations.	computer data storage;data redundancy;erasure code;event-driven programming;shortest path problem;simulation;storage efficiency	Vinodh Venkatesan	2013	2013 International Conference on High Performance Computing & Simulation (HPCS)	10.1109/HPCSim.2013.6641442	real-time computing;data striping;computer science;graph theory;theoretical computer science;reliability;database;data efficiency;data redundancy	HPC	-9.76153388096035	72.38883438403151	31721
5b2ab91bc8867f0704e7ca6b44ec9eb32e014154	event driven network topology discovery and inventory listing using reams	network topology;inventory systems;network monitoring;network graph;service detection;event processing;event normalization	Network Topology Discovery and Inventory Listing are two of the primary features of modern network monitoring systems (NMS). Current NMSs rely heavily on active scanning techniques for discovering and mapping network information. Although this approach works, it introduces some major drawbacks such as the performance impact it can exact, specially in larger network environments. As a consequence, scans are often run less frequently which can result in stale information being presented and used by the network monitoring system. Alternatively, some NMSs rely on their agents being deployed on the hosts they monitor. In this article, we present a new approach to Network Topology Discovery and Network Inventory Listing using only passive monitoring and scanning techniques. The proposed techniques rely solely on the event logs produced by the hosts and network devices present within a network. Finally, we discuss some of the advantages and disadvantages of our approach.	image scanner;network topology;no man's sky	Amir Azodi;Feng Cheng;Christoph Meinel	2017	Wireless Personal Communications	10.1007/s11277-015-3061-3	network management station;telecommunications;data mining;network simulation;world wide web;computer security;computer network	Security	-19.428442302774574	84.77383995017823	31739
15f5035a5e5fd6b92d0140cbd6bcd7fd608355b5	conformance statements for version 2 of the simple network management protocol (snmpv2)	simple network management protocol	It may be useful to define the acceptable lower-bounds of#N#implementation, along with the actual level of implementation#N#achieved. It is the purpose of this document to define the notation#N#used for these purposes. [STANDARDS-TRACK]	conformance testing;simple network management protocol	Jeffrey D. Case;Keith McCloghrie;Marshall T. Rose;Steven Waldbusser	1996	RFC	10.17487/RFC1904	computer science;database;distributed computing;network management application;structure of management information;computer network	Theory	-24.674304534674476	88.48985693938046	31752
e07a350dc64325ff7bf4dc4af32dba504e8f75f8	a centralized mechanism to make predictions based on data from multiple wsns		In this work, we present a method that exploits a scenario with inter-Wireless Sensor Networks (WSNs) information exchange by making predictions and adapting the workload of a WSN according to their outcomes. We show the feasibility of an approach that intelligently utilizes information produced by other WSNs that may or not belong to the same administrative domain. To illustrate how the predictions using data from external WSNs can be utilized, a specific use-case is considered, where the operation of a WSN measuring relative humidity is optimized using the data obtained from a WSN measuring temperature. Based on a dedicated performance score, the simulation results show that this new approach can find the optimal operating point associated to the trade-off between energy consumption and quality of measurements. Moreover, we outline the additional challenges that need to be overcome, and draw conclusions to guide the future work in this field.	administrative domain;autonomic computing;autonomic networking;causality;centralized computing;expect;experiment;information exchange;mathematical optimization;operating point;self-management (computer science);simulation	Gabriel Martins Dias;Simon Oechsner;Boris Bellalta	2015		10.1007/978-3-319-23440-3_2	data mining;distributed computing;computer security	AI	-9.261905681599927	74.81278219546046	31819
0a6703c45c51cec132597e18604d17affa9db80b	placing dynamic content in caches with small population	prefetching wireless access networks varying content popularity estimation age based threshold policy abt policy abt optimal performance caching system local caches global caches correlated traffic characteristics hit rate coordination mechanisms global learning popularity scores least recently used policy lru policy;sociology statistics prefetching base stations context wireless networks;radio access networks cache storage	This paper addresses a fundamental limitation for the adoption of caching for wireless access networks due to small population sizes. This shortcoming is due to two main challenges: making timely estimates of varying content popularity and inferring popular content from small samples. We propose a framework which alleviates such limitations. To timely estimate varying popularity in a context of a single cache we propose an Age-Based Threshold (ABT) policy which caches all contents requested more times than a threshold N (τ), where τ is the content age. We show that ABT is asymptotically hit rate optimal in the many contents regime, which allows us to obtain the first characterization of the optimal performance of a caching system in a dynamic context. We then address small sample sizes focusing on L local caches and one global cache. On the one hand we show that the global cache learns L times faster by aggregating all requests from local caches, which improves hit rates. On the other hand, aggregation washes out local characteristics of correlated traffic which penalizes hit rate. This motivates coordination mechanisms which combine global learning of popularity scores in clusters and Least-Recently-Used (LRU) policy with prefetching.	access network;cpu cache;cache (computing);dynamic web page;population	Mathieu Leconte;Georgios S. Paschos;Lazaros Gkatzikis;Moez Draief;Spyridon Vassilaras;Symeon Chouvardas	2016	IEEE INFOCOM 2016 - The 35th Annual IEEE International Conference on Computer Communications	10.1109/INFOCOM.2016.7524380	real-time computing;telecommunications;computer science;operating system;database;world wide web;computer network	Metrics	-17.700199808406282	75.59334610510443	31881
20cd62f174c8002c999b491864d233b6c337e11b	embedded software in network processors - models and algorithms	developpement logiciel;transmision paquete;distributed system;systeme reparti;calculateur embarque;task model;network processor;embedded system;sistema repartido;desarrollo logicial;software development;boarded computer;packet transmission;packet scheduling;design space exploration;task scheduling;quality of service;transmission paquet;calculador embarque;non real time;embedded software	We introduce a task model for embedded systems operating on packet streams, such as network processors. This model along with a calculus meant for reasoning about packet streams allows a unified treatment of several problems arising in the network packet processing domain such as packet scheduling, task scheduling and architecture/algorithm explorations in the design of network processors. The model can take into account quality of service constraints such as data throughput and deadlines associated with packets. To illustrate its potential, we provide two applications: (a) a new task scheduling algorithm for network processors to support a mix of real-time and non-real-time flows, (b) a scheme for design space exploration of network processors.	algorithm;central processing unit;design space exploration;embedded software;embedded system;emoticon;network packet;network processor;quality of service;real-time clock;scheduling (computing);throughput	Lothar Thiele;Samarjit Chakraborty;Matthias Gries;Alexander Maxiaguine;Jonas Greutert	2001		10.1007/3-540-45449-7_29	embedded system;parallel computing;real-time computing;packet analyzer;quality of service;embedded software;computer science;processing delay;software development;operating system;network scheduler;distributed computing;network processor	Embedded	-7.635249685550245	61.99970208370391	31884
3631eb39382490767d89725eb7c5e5009b942518	optimizing server placement for qos requirements in hierarchical grid environments	dynamic programming algorithm;hierarchical networks;dynamic program;binary search;optimal algorithm;service quality	This paper focuses on two problems related to QoS-aware I/O server placement in hierarchical Grid environments. Given a hierarchical network with requests from clients, the network latencies of links, constraints on servers’ capabilities and the service quality requirement, the solution to the minimum server placement problem attempts to place the minimum number of servers that meet both the constrains on servers’ capabilities and the service quality requirement. As our model considers both the different capabilities of servers and the network latencies, it is more general than similar works in the literatures. Instead of using a heuristic approach, we propose an optimal algorithm based on dynamic programming to solve the problem. We also consider the optimal service quality problem, which tries to place a given number of servers appropriately so that the maximum expected response time is minimized. We prove that an optimal server placement can be achieved by combining the dynamic programming algorithm with a binary search on the service quality requirement. The simulation results clearly show the improvement in the number of servers and the maximum expected response time.	binary search algorithm;dynamic programming;experiment;heuristic;input/output;norm (social);optimizing compiler;quality of service;regular expression;response time (technology);server (computing);simulation;tree network	Chien-Min Wang;Chun-Chen Hsu;Pangfeng Liu;Hsi-Min Chen;Jan-Jan Wu	2007		10.1007/978-3-540-72360-8_16	real-time computing;computer science;theoretical computer science;operating system;dynamic programming;database;distributed computing;service quality;computer network;binary search algorithm	DB	-20.371183353816807	67.00645452377348	31910
1cf678d13de024bb77f11554db5935f8ea30a8dd	garden: generic addressing and routing for data center networks	network topology routing topology control systems vegetation ip networks proposals;topology;control systems;routing protocols;routing;resource allocation;trees mathematics cloud computing computer centres computer networks fault tolerance ip networks local area networks network servers resource allocation routing protocols telecommunication network topology telecommunication switching transport protocols;trees mathematics;computer networks;vegetation;computer centres;network topology;transport protocols;network servers;telecommunication switching;fault tolerance;fault tolerance garden generic routing cloud computing services ethernet switching ip routing portland bcube scalable data center network design generic addressing protocol routing protocol forwarding protocol arbitrarily layered network topology multirooted tree network node network host network switch path diversity locator tracking destination node forwarding table forwarding model forwarding state multiple locator mechanism multipath routing load balancing;ip networks;telecommunication network topology;proposals;local area networks;cloud computing	"""Data centers often hold tens to hundreds of thousands of servers in order to offer cloud computing services at scale. Ethernet switching and IP routing have their own advantages and limitations in building data center networks. Recent research, such as PortLand and BCube, has proposed scalable data center network designs. A common feature of these designs is that their addressing and routing are customized to specific topologies. In this paper, we propose a generic addressing, routing and forwarding protocol for data center networks, which works on arbitrarily """"layered'' network topologies. We first form the network as a multi-rooted tree. Each network node (i.e., hosts and switches) is then assigned one or more locators, and each locator encodes a downward path from the roots to this node. Data center networks often have rich path diversity, so tracking all locators of a destination node will cause switches to have very large forwarding tables. We further use a new forwarding model to reduce the forwarding states. In addition, the multiple-locator mechanism brings built-in support for multi-path routing, load balancing and fault tolerance. Evaluations based on simulations and prototype experiments demonstrate that our proposal achieves our design goals."""	aggregate data;cloud computing;data center;experiment;fat tree;fault tolerance;hierarchical database model;load balancing (computing);multipath routing;network switch;network topology;online locator service;prototype;scalability;scheduling (computing);simulation;testbed;throughput;tree network	Yan Hu;Ming Zhu;Yong Xia;Kai Chen;Yanlin Luo	2012	2012 IEEE Fifth International Conference on Cloud Computing	10.1109/CLOUD.2012.9	local area network;routing table;virtual routing and forwarding;routing;fault tolerance;static routing;real-time computing;hierarchical routing;forwarding information base;cloud computing;equal-cost multi-path routing;resource allocation;computer science;control system;dynamic source routing;ip forwarding;distributed computing;packet forwarding;forwarding plane;routing protocol;link-state routing protocol;transport layer;geographic routing;network topology;vegetation;computer network	Networks	-12.11408505623828	77.66456224086875	31927
23fa6d963f93c7ab567a8624797f1273bc556acf	transcasting: cost-efficient video multicast for heterogeneous mobile terminals	wireless access;cost efficient video multicast;multicast communication;video streaming;video signal processing;transcoding service;video delivery path;computer networks;overlay links;video coding;network servers;streaming media;live video streaming;streaming media transcoding video on demand mobile computing bandwidth network servers computational efficiency games computer networks video coding;transcasting;games;video on demand;video server;cost efficiency;load balancing;load balancing transcasting cost efficient video multicast heterogeneous mobile terminal live video streaming content delivery network video server transcoding service video delivery path overlay links;bandwidth;load balance;video streaming multicast communication transcoding video signal processing;content delivery network;heterogeneous mobile terminal;mobile computing;computational efficiency;transcoding;steiner tree;mobile terminal	This paper presents a cost-efficient video multicast method for live video streaming to heterogeneous mobile terminals over a content delivery network (CDN), where CDN consists of a video server, several proxies with wireless access points, and overlay links among the server and proxies. In this method, the original video sent from the server is converted into multiple versions with various qualities by letting proxies execute transcoding services based on the users' requirements, and delivered to mobile terminals along video delivery paths. To suppress the required computation and transfer costs in CDN, we propose an algorithm to calculate cost-efficient video delivery paths which minimizes the sum of the computation cost for proxies and the transfer cost on overlay links. Our basic idea for deriving cost-efficient delivery paths is to place transcoding service on different proxies in load-balancing manner, and to construct a minimal Sterner tree from all transcoding points of requested qualities. The overall goal of the placement is the balance between computation and transfer cost. Through simulations, we show that our algorithm can calculate more cost-efficient video delivery paths and achieve lower request rejections than other algorithms.	algorithm;computation;content delivery network;cost efficiency;digital distribution;list of algorithms;load balancing (computing);multicast;proxy server;requirement;server (computing);simulation;simulcast;streaming media;video server;wireless access point	Morihiko Tamai;Keiichi Yasumoto;Naoki Shibata;Minoru Ito;Klara Nahrstedt	2008	2008 16th Interntional Workshop on Quality of Service	10.1109/IWQOS.2008.25	real-time computing;computer science;load balancing;operating system;mobile computing;world wide web;computer security;computer network	Mobile	-16.14931295396849	73.1894672551276	31973
66d9f73b8b8369bd325b664de7a0e9400c0c836f	resource allocation in software defined wireless networks	wireless networks;resource management;computer architecture;mobile communication;mobile computing;cloud computing resource management computer architecture mobile communication wireless networks mobile computing;cloud computing	Recently, various wireless networks have been deployed, and thus people can access the Internet conveniently. However, traditional architectures are closed and ossified, which causes wireless networks to become complicated, inflexible, and expensive. As a result, there are several challenges for management and QoS guarantees that should be addressed. In order to solve these challenges, a new architecture should be designed. To this end, SDN techniques have been a hot topic due to the advantages of flexibility and cost efficiency. In this article, we first introduce the basic idea of SDN and discuss the reason why using software defined wireless networking (SDWN) is necessary. Second, we review some typical SDWN-based architectures, and show a hierarchical mobile cloud computing based software defined wireless network (MCC-SDWN) for fifth generation wireless networks. Next, the state-of-the-art work on resource allocation for MCC-SDWN is reviewed. For performance evaluation and simulation, some mainstream implemental tools and simulation platforms are introduced. We also discuss potential problems and solutions.	cost efficiency;deductive lambda calculus;fifth generation computer;internet;microelectronics and computer technology corporation;mobile cloud computing;performance evaluation;quality of service;simulation;software-defined networking	Bin Cao;Yun Li;Chonggang Wang;Gang Feng;Shuang Qin;Yafeng Zhou	2017	IEEE Network	10.1109/MNET.2016.1500273NM	real-time computing;wireless site survey;mobile telephony;cloud computing;computer science;radio resource management;resource management;operating system;wireless network;distributed computing;key distribution in wireless sensor networks;wi-fi array;mobile computing;computer security;computer network	Mobile	-14.413618788610705	87.0551015573983	31978
c05f972d3ad813df49500663f26d27aaadb90eec	tiny network caches with large performance gains for popular downloads		File transfers are and will in the future be responsible for a substantial part of the Internet traffic. However, with present solutions transfers of popular files lead to a lot of redundant data transfers in the network. In this paper, we investigate how a link level caching scheme can reduce the number of redundant data transfers. We serve requests from clients that download a file concurrently, but arrived at different times in such a way that they get at a given point in time the same data chunk of the file. This enables link caches to efficiently remove the redundancy. The data chunks are rearranged at the client to compose the original file. Through implementation and experimental studies we show that this approach clearly outperforms traditional file servers in terms of file server capacity and bandwidth consumption; especially when encoding the original file with fountain codes.		Piotr Srebrny;Dag Henning Liodden Sørbø;Thomas Plagemann	2015		10.1007/978-3-319-22572-2_14	link level;redundancy (engineering);file server;computer science;fountain code;computer network;the internet;download	HPC	-15.680104601175033	72.59367930005328	32062
4153b7758d600bafb0d2d09ba3c81a93352a97b3	overlay optimizations for end-host multicast		"""/10)2 3 46587 9;:,<=7#>(? @ 587 @ < < A B)>(@C7#A 5;7#3,AD0,A E,< 4GF 9HA / 7I3):,J 0 < AH4 KML8N 9 : <=7#> ? @ 587PO FQO,: > <(0,> / RD@S7*J @ /,5*E!4 J*7T<(A B A <U4GB A J#<V@ FQKW4 JX0 @C7 @H0 A 2 < > B A J*FI7#4P@ < < 9HA 9;O!A J#5Y> /;@M9;: <=7#> ? @C587ZR J#4 : EY[6O : 7Z@C7Z7#3,A E!A J*KW4 J*2 9D@C/ ? ATE!A /1@C< 7\FD4 KZ3,> R63 A JP/,A 7^] 4 J#_HJ#A 5*4 :,J#? A`:,5#@ R6AI@C/10a3 > R63,A J <(@G7#A / ? Fb> /c0,@C7 @d0 A < >(B6A J*F efL^/g7#3 > 5HE1@CE!A JH]hAiE J#A 5*A / 7a@j58F 582 7#A 9D@C7#> ?T@CE E J#4 @ ? 3D7#4IJ#A 0,: ? >(/,R <(@G7#A / ? > A 5 O!A 7^] A A /D9HA 9;O!A J#5k4CK @C/lA / 0 2 3 4 587-9;:,<=7#>(? @ 587""""R J#4 : EmeonU@C7#A / ? FDJ#A 0 : ? 7#> 46/p> 5""""@ ? 3 > A B A 0 O Fg@ 0 0,> /,Rj< > / _)5;7#4d@C/qA r > 587#> / Rs4CB6A J#<(@ Fg/,A 7^] 4 J#_!ebtjAl3 @GB6A 0 A B A < 4 E!A 0i5*A B A J @C<u< 4 ? @ < 3 A :,J#> 587#> ? 5P7#4aA /1@CO < Av>(/ 0,> B)>(0,:1@C<U9 : <=2 7#> ? @C587""""R J#4 : ED9HA 9;O!A J#5o7#4 @60,0D/,A ]f< > / _)5-@C5h/ A A 0,A 0weutdAM5*3 4 ] 7#3 @C7 [Y: 5*> / Rp7#3 A 5*AS< 4 ? @C<k3,A :,J#> 587#> ? 5 [u0 @C7 @p0,A < > B A J*FxO Fx@ /sA /10)2 3,46587M9;:,<=7#>(? @ 587M4GB A J#<(@ Fl? @C/i@ ? 3 > A B6AI@;<(@C7#A /,? FpKVJ#469zy6{6|}4CB6A J 7#4Q~)e a7#> 9HA 5T7#3 @C7`4CK-/1@G7#> B A;L^N9 : <=7#> ? @ 587 [Y0,A E!A /10 >(/,Rl4 /x7#3,A 587*J#:,? 7#:,J#AH4CK-7#3 AH:,/10,A J#< F > / RlE 3 F 5*>(? @ < 7#46E!46< 4 R F exT: J`J#A 5*: <=7#5 @GJ#A@ E,E < > ? @ O,<(Ai7#4j@ / FgA /10)2\3,46587D9 : <=7#> ? @ 587DE J#4 7#4 ? 4 <(5 [MA >=7#3,A J 7*J#A A 2 O1@ 5*A 0;4 Jo9HA 5*3 2\O @ 5*A 0weugE,J#4C7#4 ? 46<,O1@ 5*A 0;46/v7#3 A 5*A-3,A :,J#> 582 7#> ? 5 [)? @ < < A 0p""""lA 5*3Y[)31@C5 O!A A /D0,A B A <(4 E!A 0meZ""""lA 5*3D? @ /DO!A"""": 5*A 0 > /p? 46/C8: /,? 7#> 46/D]"""">=7#3Q@ / FD4CKU7#3 APA r > 587#>(/,R 7*J#A A 2\O @ 5*A 0DE,J#4C7#4 ? 46< 5 7#4p5*3 4CJ*7#A /s7#3,A;<(@C7#A /,? FxE!A J`/,4)0,ASE @ >=J e;L 7I? @ /x5*: E,E!4 J*7I<(@CJ#R A A /10 2 3,46587""""9;:,<=7#>(? @ 587MR J#4 : E 5-]"""">=7#3lJ#A <(@G7#>(B6A <=Fl< 4 ]4CB6A J#3 A @ 0me 1. INTRODUCTION  ] A / 7^FgF A @GJ#5p@GKW7#A Jp>=7#5p> / 7*J#4)0,:,? 7#> 46/m[""""L8N}l:,<=7#>(? @ 587s  X> 5 587#> < < /,4 7I:,O >( : >=7#46:,5*< Fs@ B @ > <(@ O < AD46/x7#3 AHL\/)7#A J#/ A 7 eHMA ? A /)7IA KW2 KW4 J*7#5v7#4iE,J#4GB)>V0 AH9;:,< 7#> ? @C587 0,A < > B A J*Fs31@ B AS7#3): 5I5*3,> KV7#A 0d46/d7#4 A /10 2 3,46587p9;: <=7#> ? @C587l]""""3 > ? 3fO :,>(<(0 5Q@d7*J @ /,5*E!4 J*7*2 <(@ F A JQ4GB A J#<(@ F /,A 7^] 4 J#_dO!A 7^]hA A /9HA 9;O!A J#5v4CKX@i9 : <=7#> ? @ 587 R J#4 : EYejh3 A J#Ap> 5 -7xX7#3,> 5xJ#A 5*A @CJ#? 3>(5x5*: E,E!4 J*7#A 0>(/E1@CJ*7sO F7#3 A`   MT.o. """"]-@GJ 0sMTL\2\6 y    )[U7#3,ASNZJ#A 5*>(0,A / 7#>(@ <k.o@CJ#<=F  @C2 J#A A JaM]h@CJ 0K 4 Jp)? > A / 7#> 587#5D@ /10. / R >(/,A A J#5 No.  T,.ka  6 [ 7#3,AaP<=KWJ#A 0NueZ < 4 @C/ 46:,/10 @G7#> 46/MA 5*A @CJ#? 3 A < < 4 ]""""5*3 > Eb~ { { 6[ @C/10iO Fp7#3,A P/ >=7#A 0Q`> / R60,4 9 . / R >(/,A A J#> / Ra@C/10No3 F 5*> ? @ <Z ? >=2 A / ? A 5ZMA 5*A @GJ#? 3  46:,/ ? > <m .kNk   Z¡PJ @C/)7u/ 4,e6¡TT¢6 {6y  6 ¢ {  [ @C/10xO)FxA  :,>(E,9HA / 7XRCJ @ / 7#5`KWJ#469£): /dl>(? J#4658F 587#A 9H5IL^/,?6eY@ /10 ¤TN ¢G¥X> R6>=7 @ <"""".o : > E 9HA /)7  4CJ#EYesNZ@CJ*7 4 K""""7#3,>(5I]h4CJ#_j]-@C5;? 4 9S2 E,< A 7#A 0l]""""3 A / :,R6> 3i¦ @C9H>(/Q]h@ 5MB)>(5*>=7#> / RH7#3,A  469HE : 7#A JPnU@CO!4 2 J @G7#4 J*Fd@C7I7#3 AHP/ > B A J#5*>=7^Fx4CK  @ 9;O J#>(0,R6A eQh7v  nY7#3 > 5`J#A 2 5*A @CJ#? 3Q> 5MKW: /10 A 0pO FDX,dR J @C/ 7P/):,9;O!A J""""MTL 2^ 6{6~  ~ )e Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Copyright 2002 ACM 1-58113-619-6/02/0010 ... § 5.00. @vJ#> ? 3p< >=7#A J @G7#:,J#AX4 /a7#3,AT0 A 5*> R6/Y[,> 9HE < A 9HA / 7 @G7#>(4 /Y[)@C/10DA B @ < :1@G2 7#> 46/ 4 K1B @CJ#> 4 : 5ZE,J#4C7#4 ? 46< 5ZK 4CJoA /10)2\3,46587Z9 : <=7#> ? @ 587 [CK 4CJ A r,@ 9HE,<(A [ ̈h-Nz ~  [""""¤`Q-N© yG [""""¤PF E!A J#? @C587i   [""""X@GJ @60 @g G [M@ / 0ak46>(0  «C ek.o/ 0 2 3 4 587 9 : <=7#> ? @ 587 @ B 46>(0 5k7#3 AP0,A E < 4 F,9HA /)7o3):,J 0 < A 5k4CKUL^N l: <=7#> ? @C587M@C7h7#3,AT? 4 587-4 KU3 > R63,A J""""0 @G7 @ 0 A < > B A J*FD<(@C7#A /,? > A 5 [ @ 5h> <=2 < : 587*J @G7#A 0p> /D7#3 ATA r @C9HE < AM/ A 7\]h4 J#_H> /lu>(R ew6eoT4)0 A 5-¬v[ ­H[ ® [ ̄l[ @ / 0H°> /Du> R,e!P@CJ#AM9HA 9;O!A J#5o4CKY@I9 : <=7#> ? @ 587 R J#4 : EY[ / 4)0,A 5 ±  [1±`~ [,@ /10p±Xy;@GJ#AXJ#46: 7#A J#5"""">(/a7#3 AX/,A 7^] 4 J#_![,@ / 0a7#3 AX0 @ 5*3,A 0 < > / A 5S? 46/ /,A ? 7#> / Ri7#3,Aa/,4)0,A 5;@CJ#ApE 3 F 5*>(? @ <h< > / _)5 ejh3 Ap@CJ*J#4 ]""""5 > /iu> R,eY  @ -> < <(:,587*J @C7#AI3 4 ]L8Ng9;:,< 7#> ? @C587""""]h46:,<(0pK 4CJ*]-@CJ 0i0,@C7 @ 5*A / 7DO Fb®27#4j7#3 Ap4 7#3,A Ja9HA 9;O!A J#5 4 KX7#3,AQR J#4 : Emeu> R,eM 3O! 5*3 4 ]""""5""""@IE!465*5*> O < AXA /10 2 3,46587-9 : <=7#> ? @ 587 4CB6A J#<(@ FH]""""3,A J#AT9HA 9;O!A J#5 ­H[Z® [u@ /10s°©@CJ#AS? 4 / /,A ? 7#A 07#4l9HA 9 O!A J` ̄l[u@ /10x9HA 9;O!A J`¬ > 5-? 46/,/ A ? 7#A 0a7#4 9HA 9;O!A Jh­De  ́S 4 JP®7#4 9;: <=7#> ? @C587""""@ E @ ? _ A 7h7#4 7#3 AMR J#4 : Em[)> 7 K 4 J*]h@CJ 0 5h7#3 AME1@ ? _ A 7o7#4  ̄l[ ]""""3,> ? 3HK 4CJ*]-@GJ 0,5->=7 7#4 ­z@ /10x°SμZ@G7v­©7#3,A;E1@C? _6A 7`> 5XK : J*7#3 A J`KW4 J*]-@GJ 0,A 0x7#4Q¬ve;h3 A J#> R63 7-3 @ /10HRCJ @ E 3D4CKuu> R,ew63O!o5*3,4 ]""""5h7#3 AM4CB6A J#<(@ F;]""""> 7#3,46: 7h7#3 A : / 0,A J#<=F > / RXE,3 F,5*> ? @C< /,A 7^] 4 J#_!e  469HE @CJ#> / RIu> R 5 e1  @6o@C/10l3O1 [ >=7M>(5""""? < A @GJ""""7#31@C7M0,@C7 @S0 A < > B A J*Fa: 5*> / R;A /10)2\3,46587-9 : <=7#> ? @ 587""""A r,E!A 2 J#> A / ? A 5""""<(4 / R A JP0,A <(@ F 5h7#31@ /p/1@G7#>(B6AXL8Nbl: <=7#> ? @ 587P0 A < >(B6A J*F e  4CJ A r,@ 9HE,< A6[ 7#3 AM<(@C7#A /,? FHKWJ#4 9©®7#4 ¬4 /a7#3,AP4GB A J#<(@ FD/ A 7^]h4CJ#_H> 5 A r)7#A / 0,A 0@C7I< A @C587IO Fi7#3 A J#4 : / 0 2 7*J#> E7#> 9HA 5TO!A 7^] A A /d±Typ@C/10 ̄¶@ / 0aO!A 7^]hA A /l±vX@C/10a­Deou> R,ew63?G 5*3 4 ]""""5""""@ /aA B A /p< A 5*5-A ·;2 ? > A / 7P4CB6A J#<(@ Fa]""""3 A J#Av9 : <=7#> ? @ 587ME @ ? _ A 7#5""""KWJ#4692® ̧7#4H¬7*J @ B A J#5*A ̄l[U°H[U@ / 0s­©O!A KW4 J#A;J#A @C? 3,> / RQ¬IeSh3,> 5vA r @C9HE < Av5*3 4 ]""""5`7#31@C7 <(@C7#A /,? > A 5hO!A 7\]hA A /a9HA 9;O!A J#5Z> /a@ /DA / 0 2 3 4 587k9 : <=7#> ? @ 587 4GB A J#<(@ F 0,A E!A /10a<V@GJ#R6A <=Fl46/p7#3,AI :1@ < >=7^Fa4CKu7#3 AX4GB A J#<V@ FpO :,>(<=7 e .Zr,> 587#> / RaA / 0 2 3 4 587T9 : <=7#> ? @ 587TE,J#4 7#4 ? 46< 5`? @ /xO!Av? @C7#A R 4 J#> 1 A 0 > / 7#4g7*J#A A 2\O @ 5*A 0@ / 0f9HA 5*3,2 O1@C5*A 0cE,J#4C7#4 ? 46< 5O Fc7#3 A7^F E!Ax4 K 4GB A J#<(@ F7#3 A FO,: > <(0meb¶7*J#A AQ> 5D@ /g4GB A J#<(@ F]""""3 A J#Al7#3,A J#Al> 5D@ 5*> / R <(A E1@G7#3xO!A 7^]hA A /x@ / FQ/,4)0,AvE1@ >=J [!]""""3,>(< A;@a9HA 5*3i9D@ Fp5*: E 2 E!4 J*7Q9H4 J#Ai7#31@C/4 / AsE1@C7#3O!A 7\]hA A /@C/ Ff/ 4)0 AsE @ >=J ez ̈h-Nu[ ¤`Q-Nu[ @ / 0aak46>(0l@GJ#A`A r,@ 9HE < A 5-4CKu7*J#A A 2 O @ 5*A 0aE,J#4 7#4 ? 46< 5 eh ̈kA 2 ? @C: 5*A""""@M7*J#A Ah4GB A J#<(@ F > 5o@ /;@ ? F ? < > ?-R J @CE 3m[6>=Kw@C/)FI/,46/ 2\< A @GK!9HA 9S2 O!A JT<(A @GB6A 5P7#3,Av9 : <=7#> ? @ 587PR J#4 : E4 JT? J @ 5*3,A 5 [!7#3 AI7*J#A Av> 5TE1@GJ*7#>=2 7#> 46/,A 0f@ / 0c9HA 9;O!A J#5D> /f46/,AsE @CJ*7#>=7#> 46/c]""""> < <`/ 4C7lO!As@ O,<(Ai7#4 ? 4 9H9;: /,> ? @C7#AD]"""">=7#3q9HA 9 O!A J#5;> /7#3 Al4C7#3 A JDE @CJ*7#>=7#> 46/mefYJ#A A 2 O1@C5*A 0q@CE E J#4 @ ? 3 A 5S7#3 :,5;J#A  : >=J#AQE @CJ*7#>=7#> 46/q0,A 7#A ? 7#>(4 /c@C/10gJ#A 2 ? 4GB A J*Fq9HA ? 31@ /,> 5*9H5 eo»9HA 5*3 2 O1@ 5*A 0q4GB A J#<(@ F [T4 /7#3,As4C7#3 A J 31@C/10w[131@C5MJ#A 0,: / 0 @C/)7""""? 46/ /,A ? 7#> B)>=7#>(A 5X@ 9H4 / RSRCJ#46:,Ei9HA 9;O!A J#5 [ 7#3): 5a> 5Q< A 5*5Q< > _ A <=Fc7#4R6A 7lE1@GJ*7#> 7#> 4 / A 0we}¤T4 ] A B A J [M7#3 AxA r > 582 7#A /,? A""""4 KwJ#A 0,:,/10,@ / 7 ? 46/,/ A ? 7#>(B)>=7#> A 5 * *1⁄4 ' W # % 9HA 9;O!A J#5u7#4XJ#: /H@ J#46: 7#> / RH@C<(R 4 J#>=7#3 9}7#4;? 46/,587*J#: ? 7""""< 4 46E 2 KWJ#A A`K 4CJ*]-@GJ 0,> / RHE @C7#3U35  O!A 7\]hA A /x9HA 9 O!A J#5 evX@CJ @ 0 @p@ /10¤PF E!A J#? @ 587I@GJ#ASA r,@ 9HE,<(A 5X4 K 9HA 5*3 2\O @ 5*A 0HE J#4 7#4 ? 4 <(5 eoT@CJ @60,@ :,5*A 5-@IE1@C7#3DB A ? 7#4 J""""@C< R64 J#>=7#3,9 ́ tjAl@C5*5*: 9HAg1⁄2^? 4 / /,A ? 7#> 46/,5*3⁄4s4 /gA /10 2 3,46587S9 : <=7#> ? @ 587 4GB A J#<(@ F 5 7#4jO!AlO >=2\0,>=J#A ? 7#> 46/ @ <M: /,>(? @ 587a? 46/,/ A ? 7#>(4 / 5 [-A > 7#3,A Ja@ 5HJ#A < >(@ O,< A   Nq? 4 / /,A ? 7#> 46/,5M4CJM? 46/,/ A ? 7#> 4 / < A 5*5MT¥`N5*A 5*5*> 46/,5 e"""	adaptive multi-rate audio codec;for position only;fully buffered dimm;jt (visualization format);list of amd fx microprocessors;microsoft dynamics ax;multicast;oracle advanced queuing;serial ata;visual j#;wa-tor	Wenjie Wang;David A. Helder;Sugih Jamin;Lixia Zhang	2002			protocol independent multicast;xcast;multicast;computer science;distance vector multicast routing protocol;computer network;source-specific multicast;reliable multicast;overlay;pragmatic general multicast	Web+IR	-26.36790648822396	78.92545824997747	32122
4f1e6181ad8ff941c6cd9210b895415713902e15	distance-adaptive spectrum resource allocation in spectrum-sliced elastic optical path network [topics in optical communications]	optical network;resource management optical fiber networks optical fiber communication optical filters optical modulation optical receivers adaptive optics optical sensors optical design frequency;wavelength routing;resource allocation optical communication optical filters;ring network;resource allocation;optical filters;optical amplifiers;resource management;optical fiber networks;spectrum;optical fibers;spectral resource designation distance adaptive spectrum resource allocation spectrum sliced elastic optical path network end to end physical condition modulation format optical filter width frequency slot current frequency grid standard;optical communication;optical modulation;radio spectrum management	The rigid nature of current wavelength-routed optical networks brings limitations on network utilization efficiency. One limitation originates from mismatch of granularities between the client layer and the wavelength layer. The recently proposed spectrum-sliced elastic optical path network (SLICE) is expected to mitigate this problem by adaptively allocating spectral resources according to client traffic demands. This article discusses another limitation of the current optical networks associated with worst case design in terms of transmission performance. In order to address this problem, we present a concept of a novel adaptation scheme in SLICE called distance-adaptive spectrum resource allocation. In the presented scheme the minimum necessary spectral resource is adaptively allocated according to the end-to-end physical condition of an optical path. Modulation format and optical filter width are used as parameters to determine the necessary spectral resources to be allocated for an optical path. Evaluation of network utilization efficiency shows that distance-adaptive SLICE can save more than 45 percent of required spectrum resources for a 12-node ring network. Finally, we introduce the concept of a frequency slot to extend the current frequency grid standard, and discuss possible spectral resource designation schemes.	best, worst and average case;end-to-end principle;modulation;ring network;routing;wavelength-division multiplexing	Masahiko Jinno;Bartlomiej Kozicki;Hidehiko Takara;Atsushi Watanabe;Yoshiaki Sone;Takafumi Tanaka;Akira Hirano	2010	IEEE Communications Magazine	10.1109/MCOM.2010.5534599	optical transport network;spectrum;ring network;telecommunications;resource allocation;computer science;optical fiber;resource management;optical filter;optical performance monitoring;optical amplifier;optical communication;computer network	Networks	-7.148993572707895	84.9787616390001	32222
ac163d494990f09c472fafde19be2ef588b2b82a	machine learning in disruption-tolerant manets	moving object;resource discovery;peer to peer network;mobile peer to peer networks;machine learning;mobile ad hoc networks;publish subscribe;mobile ad hoc network;peer to peer;mobile data management;data dissemination	In this article we study the data dissemination problem in which data items are flooded to all the moving objects in a mobile ad hoc network by peer-to-peer transfer. We show that if memory and bandwidth are bounded at moving objects, then the problem of determining whether a set of data items can be disseminated to all the moving objects is NP-complete. For a heuristic solution we postulate that a moving object should save and transmit the data items that are most likely to be new (i.e., previously unknown) to future encountered moving objects. We propose a method to be used by each moving object to prioritize data items based on their probabilities of being new to future receivers. The method employs a machine learning system for estimation of the novelty probability and the machine learning system is progressively trained by received data items. Through simulations based on real mobility traces, we show the superiority of the method against some natural alternatives.	bandwidth (signal processing);denial-of-service attack;download;heuristic;hoc (programming language);machine learning;np-completeness;peer-to-peer;simulation;tracing (software)	Bo Xu;Ouri Wolfson;Channah Naiman	2009	TAAS	10.1145/1636665.1636669	mobile ad hoc network;computer science;machine learning;distributed computing;internet privacy;world wide web;computer network	DB	-13.723129004637697	74.93280734750209	32279
28f5aa4b5e3688f37cd45d3f22d25579e1591b78	caching strategy for scalable lookup of personal content	content management;table lookup cache storage content management file organisation peer to peer computing;cache storage;protocols;peer to peer network;cooperative caching;distributed hash table;simulation framework;scalability caching strategy distributed hash table performance analysis personal content;data mining;distributed collection;caching strategy;youtube;scalable lookup;technology and engineering;personal content storage service;peer to peer computing motion pictures content management youtube personal digital assistants indexing information technology explosives quality management cooperative caching;personal content;fingers;pcss;performance analysis;distance metric;request times distance;content management system;least frequently used;least frequently used caching algorithm caching strategy scalable lookup distributed collection content management system personal content storage service pcss peer to peer network distributed hash table request times distance;scalability;least frequently used caching algorithm;peer to peer computing;table lookup;algorithm design and analysis;sliding window;file organisation	Today’s trend is to create and share personal content, such as music files, digital photos and digital movies. The result is an explosive growth of a user’s personal content archive. Managing such an often distributed collection becomes a complex and time consuming task, which indicates the need for a personal content management system that provides storage space transparently, is quality-aware, and is available at any time and at any place to end-users. A solution that fulfills this need is a Personal Content Storage Service (PCSS). A key feature of a PCSS is the ability to search worldwide through the dataset of personal files. Due to the extremely large size of the dataset of personal content, a centralized approach is no longer feasible; therefore the PCSS uses a structured peer-to-peer network: the Distributed Hash Table (DHT). In order to further increase the lookup performance, a caching layer is used between the application layer and the DHT. In this article we present the caching layer and introduce the Request Times Distance (RTD) caching algorithm, which uses popularity and distance metrics to increase the lookup performance. By extending the RTD algorithm with a sliding window and cooperative caching, a more efficient solution than standard algorithms is obtained. The cooperative RTD caching algorithm is evaluated using the PlanetSim simulation framework and shows a performance increase of up to 16% compared to the Least Frequently Used (LFU) caching algorithm.	algorithm;archive;cache (computing);centralized computing;content management system;digital photography;distributed hash table;least frequently used;lookup table;peer-to-peer;planetsim;simulation	Niels Sluijs;Tim Wauters;Bart De Vleeschauwer;Filip De Turck;Bart Dhoedt;Piet Demeester	2009	2009 First International Conference on Advances in P2P Systems	10.1109/AP2PS.2009.11	computer science;database;internet privacy;world wide web	HPC	-15.760199723316088	74.37568609237334	32299
9513e258dfc0b89d0767c187255d20090ac98acd	lsmac and lsnat: two approaches for cluster-based scalable web servers	world wide web lsmac lsnat cluster based scalable web servers server responsiveness server scalability client server network cluster based computers commodity hardware performance results server infrastructures mac based dispatching ip based dispatching application space programs;performance evaluation;application program interfaces search engines client server systems performance evaluation access protocols transport protocols;search engines;perforation;client server systems;transport protocols;client server;web server network servers companies hardware scalability dispatching space technology computer science delay customer service;application program interfaces;access protocols	Server responsiveness and scalability are more important than ever in today’s client/server dominated network environments. Recently, researchers have begun to consider cluster-based computers using commodity hardware as an alternative to expensive specialized hardware for building scalable Web servers. In this paper, we present performance results comparing two cluster-based Web servers based on different server infrastructures: MAC-based dispatching (LSMAC) and IP-based dispatching (LSNAT). Both cluster-based server systems were implemented as application-space programs running on commodity hardware. We point out the advantages and disadvantages of both systems. We also identify when servers should be clustered and when clustering will not improve performance.	algorithm;client–server model;cluster analysis;commodity computing;computer;dynamic web page;fault tolerance;requirement;responsiveness;scalability;server (computing);web content;web server	Xuehong Gan;Trevor Schroeder;Steve Goddard;Byrav Ramamurthy	2000		10.1109/ICC.2000.853680	client;log shipping;clickstream;computer science;web api;operating system;internet authentication service;appleshare;database;server-side;world wide web;transport layer;web server;application server;search engine;client–server model;server;computer network;server farm;remote evaluation	HPC	-19.818486970396513	70.99632165380466	32300
81b3c1dc6a29524e198ab3096cc4d1fbdb406dae	physical layer impairment (pli)-aware rwa algorithm based on a bidimensional qos framework	wavelength assignment;qot physical layer impairment pli aware rwa algorithm bidimensional qos framework qos differentiation framework set up delay transparent optical networks pli aware routing wavelength assignment blocking probability quality of transmission;delays quality of service bit error rate wavelength assignment algorithm design and analysis routing;telecommunication network routing;wavelength assignment quality of service telecommunication network routing;quality of service;transparent optical network physical layer impairments plis quality of service qos routing and wavelength assignment rwa set up delay	In this paper, a bidimensional Quality of Service (QoS) differentiation framework, which considers both the physical layer impairments (PLIs) and the set-up delay as well as the impact of the former on the latter, is proposed to implement service differentiation in transparent optical networks. In addition, a new PLI-aware routing and wavelength assignment (RWA) algorithm based on the proposed framework is designed and simulation results show that the proposed algorithm can reduce the blocking probability (BP) of the network, guarantee the quality of transmission (QoT), and low set-up delay for multiservice offerings.	algorithm;blocking (computing);erlang (unit);network topology;pl/i;quality of service;routing and wavelength assignment;simulation	Jijun Zhao;Wei Li;Xin Liu;Wenyu Zhao;Martin Maier	2013	IEEE Communications Letters	10.1109/LCOMM.2013.043013.130331	real-time computing;quality of service;telecommunications;computer science;computer network	Mobile	-5.666649692697622	85.5294803465463	32367
2a449c2f8ac2f1346e046200e4cbb4f896e70099	optimization-based virtual machine manager for private cloud computing	minimisation;virtual machine;degradation;outsourcing;service provider;cloud service provider;resource allocation;computer model;virtual machining;resource manager;cost reduction;software performance evaluation;virtualisation cloud computing cost reduction minimisation outsourcing resource allocation software performance evaluation stochastic programming virtual machines;stochastic optimization;computational modeling;virtual machines;optimization;virtual machine manager;performance degradation optimization based virtual machine manager private cloud computing optimal resource management framework virtualization technology service provider public cloud cost minimization outsourcing;stochastic programming;stochastic optimization cloud computing virtual machine manager cloud service provider;cloud computing virtual machining outsourcing optimization computational modeling degradation steady state;virtualisation;cloud computing;steady state	In this paper, an optimal resource management framework for cloud computing environment is presented. Based on virtualization technology, the workload to be processed on a virtual machine can be moved (i.e., outsourced) from private cloud (i.e., in-house computer system) to the service provider in public cloud. The framework introduces the virtual machine manager (VMM) in private cloud operating to minimize the cost due to the outsourcing and performance degradation. A stochastic optimization model is developed to obtain an optimal workload outsourcing policy with an objective to minimize a cost. The numerical studies reveal the effectiveness of the optimal resource management framework to achieve an objective of private cloud. This framework will be useful not only to optimize the performance of resource usage, but also to achieve the best benefit from economic perspective of the cloud computing regime.	cloud computing;computer;elegant degradation;markov chain;markov decision process;mathematical optimization;numerical analysis;outsourcing;stochastic optimization;virtual machine manager;x86 virtualization	Dusit Niyato	2011	2011 IEEE Third International Conference on Cloud Computing Technology and Science	10.1109/CloudCom.2011.23	cloud computing security;real-time computing;simulation;cloud computing;computer science;virtual machine;resource management;operating system;stochastic optimization;cloud testing;distributed computing	HPC	-22.43483982888726	63.578693064543515	32474
1f49b26737209bd64e9a28e5be68cc952f0923c6	dynamic topology discovery in sdn-enabled transparent optical networks		Optical technologies play nowadays a crucial role in different network scenarios (e.g., data centres, metro and access networks), mainly due to their support for higher bandwidth and scalability in comparison to electronic-based opaque solutions. In this context, the deployment of the Software Defined Networking (SDN) paradigm over optical networks has gained interest from both industry and research communities, spawning several implementations over multiple well documented use cases. However, in Transparent Optical Networks (TONs), where nodes offer optical switching capabilities, neighbouring nodes adjacencies have to be manually configured at both data and control plane levels, which is a lengthy task that can potentially lead to misconfiguration. Alternative solutions rely on the use of supervisory networks or dedicated channels. Nevertheless, implementing these methods requires both effort and resources to provide adjacencies discovery, making the awareness of the correct underlying topology by the SDN controller a tedious and occasionally very complex process. In this paper, we present a novel SDN-based cost-effective topology discovery method, allowing TONs to automatically learn physical adjacencies between optical devices. In particular, this is achieved by means of a test-signal mechanism and the OpenFlow protocol. The SDN control plane and optical agent implementations, as well as the message exchange flow between the subsystems and the controller are described. Then, the proposed discovery mechanism is experimentally assessed over an emulated TON test-bed, analysing the average time required for the optical topology discovery in different network scenarios.	access network;control plane;emulator;experiment;network topology;openflow;optical switch;programming paradigm;provisioning;scalability;software deployment;software-defined networking;testbed	Rafael Montero;Fernando Agraz;Albert Pages;Jordi Perelló;Salvatore Spadaro	2017	2017 International Conference on Optical Network Design and Modeling (ONDM)		control theory;distributed computing;software deployment;computer network;scalability;openflow;network topology;computer science;software-defined networking;topology;access network;optical switch	Visualization	-15.609209834341959	82.83946643898295	32520
4de65d45dd4780768401883b16af80c3687375fa	a scalable fair heterogeneous resource allocation scheme in distributed systems		Fair and efficient multiple resource allocation is often considered in a data center with a large scale of heterogeneous nodes and requests. Previous work proposed to maximize the minimum resource share received by any user and developed a fast Best-Fit algorithm to allocate jobs to servers. However, Best-Fit algorithm does not always make the optimal assignment. We first apply the subgradient technique to the max-min fairness allocation problem, and further develop two fast online algorithms, the heuristic algorithm and the randomized algorithm, respectively. The latter is completely decentralized and with low complexity. Experiments show that the two algorithms achieve better fairness compared with Best-Fit algorithm.	best practice;cloud computing;computer simulation;curve fitting;data center;distributed computing;experiment;fairness measure;heuristic (computer science);job stream;max-min fairness;maxima and minima;online algorithm;randomized algorithm;scheduling (computing);server (computing);subderivative;subgradient method;virtual machine	Xiaoying Zheng;Ye Xia	2017	2017 IEEE 15th Intl Conf on Dependable, Autonomic and Secure Computing, 15th Intl Conf on Pervasive Intelligence and Computing, 3rd Intl Conf on Big Data Intelligence and Computing and Cyber Science and Technology Congress(DASC/PiCom/DataCom/CyberSciTech)	10.1109/DASC-PICom-DataCom-CyberSciTec.2017.188	resource management;online algorithm;cluster analysis;randomized algorithm;heuristic (computer science);resource allocation;server;computer science;subgradient method;distributed computing	AI	-18.661551173357253	64.24051816743288	32544
81449b2ff7820afc62843e9cf0d5e58806b0a1bb	mathematical representation of quality of service (qos) parameters for internet of things (iot)		Now﻿we﻿are﻿in﻿the﻿era﻿of﻿ubiquitous﻿computing.﻿Internet﻿of﻿things﻿(IoT)﻿is﻿getting﻿matured﻿in﻿various﻿ parts﻿of﻿the﻿world.﻿In﻿coming﻿few﻿years’﻿billions﻿and﻿trillions﻿of﻿things﻿will﻿be﻿connected﻿to﻿the﻿internet.﻿ To﻿deal﻿with﻿these﻿huge﻿number﻿of﻿devices﻿in﻿a﻿network﻿we﻿need﻿to﻿consider﻿Quality﻿of﻿Service﻿(QoS) parameters﻿so﻿that﻿system﻿operations﻿can﻿be﻿performed﻿in﻿a﻿smoother﻿way.﻿Mathematical﻿modelling﻿ of﻿these﻿QoS﻿parameters﻿gives﻿an﻿idea﻿about﻿which﻿factors﻿are﻿needs﻿to﻿consider﻿while﻿designing﻿ any﻿IoT-enabled﻿system﻿at﻿the﻿same﻿time﻿it﻿will﻿give﻿the﻿performance﻿analysis﻿of﻿the﻿system﻿before﻿ implementation.﻿ In﻿ this﻿ paper﻿ comprehensive﻿ literature﻿ survey﻿ is﻿ done﻿ to﻿ discuss﻿ various﻿ issues﻿ related﻿to﻿QoS﻿and﻿gap﻿analysis﻿is﻿also﻿done﻿for﻿IoT﻿Enabled﻿systems.﻿This﻿paper﻿proposes﻿general﻿ steps﻿to﻿build﻿a﻿mathematical﻿model﻿for﻿a﻿system.﻿It﻿also﻿proposes﻿the﻿mathematical﻿model﻿for﻿QoS﻿ parameters﻿like﻿reliability,﻿communication﻿complexities,﻿latency﻿and﻿aggregation﻿of﻿data﻿for﻿IoT.﻿To﻿ support﻿proposed﻿mathematical﻿model﻿proof﻿of﻿concept﻿also﻿given. KeywoRDS Internet of Things, Mathematical Modelling, Quality of Service, Ubiquitous Computing		Sandesh Mahamure;Poonam N. Railkar;Parikshit N. Mahalle	2017	IJRSDA	10.4018/IJRSDA.2017070107	mobile qos;the internet;proof of concept;latency (engineering);computer network;ubiquitous computing;quality of service;representation (mathematics);computer science;internet of things	ECom	-16.434107087897022	87.72046049754854	32574
4169c7e00292d0b2efc322c1145a10f3280c21fc	memory and time-efficient schedulability analysis of task sets with stochastic execution time	static priority;stochastic process;information science;processor scheduling;stochastic processes processor scheduling probability distribution embedded system digital systems real time systems costs distributed computing information science information analysis;distributed computing;task execution time;complexity;schedulability analysis;task sets;embedded system;computational complexity processor scheduling real time systems;stochastic processes;computational complexity;digital systems;probability distribution;datavetenskap datalogi;computer science;underlying stochastic process schedulability analysis task sets stochastic execution time task execution time probability distribution complexity;information analysis;stochastic execution time;underlying stochastic process;real time systems	This paper presents an efficient way to analyse the performance of task sets, where the task execution time is specified as a generalized continuous probability distribution. We consider fixed task sets of periodic, possibly dependent, non-pre-emptable tasks with deadlines less than or equal to the period. Our method is not restricted to any specific scheduling policy and supports policies with both dynamic and static priorities. An algorithm to construct the underlying stochastic process in a memory and time efficient way is presented. We discuss the impact of various parameters on complexity, in terms of analysis time and required memory. Experimental results show the efficiency of the proposed approach.	algorithm;complexity;dspace;image scaling;multiprocessing;profiling (computer programming);rough set;run time (program lifecycle phase);scheduling (computing);scheduling analysis real-time systems;stochastic process	Sorin Manolache;Petru Eles;Zebo Peng	2001		10.1109/EMRTS.2001.933991	probability distribution;stochastic process;complexity;real-time computing;computer science;theoretical computer science;distributed computing;data analysis;computational complexity theory	Embedded	-9.359616914648933	61.51678192573259	32764
0a947cea2377f6e5be42587221641fd8c50f7317	reduction of power consumption for pipelined dpi systems on fpga	frequency scaling;intrusion detection;deep packet inspection;snort;pattern matching	We propose a scheme to reduce power consumption in pipelined AC-DFA (AhoCorasick deterministic finite automaton) tries for deep packet inspection (DPI). It is based on our observation that the access frequency drops dramatically as the input goes through stages of the pipelined implementation of the AC-DFA trie. Experiments show that the access frequency of the fourth stage is one thousandth of the access frequency of the first stage. So, we slow down the stages that are not frequently used in the pipelined AC-DFA trie to reduce unnecessary power consumption. Also, we turn on the next stage before a stage performs a pattern matching, to reduce delays and clock skew without any additional hardware components. Our scheme shows a 25% reduction in power consumption, compared with the state-of-the-art DPI scheme [3] with a pipelined AC-DFA trie.	clock rate;clock skew;context-aware pervasive systems;deep packet inspection;deterministic finite automaton;field-programmable gate array;finite-state machine;pattern matching;snort;string searching algorithm;trie;whole earth 'lectronic link	Hansoo Kim;Ju Wook Jang	2014	J. Inf. Sci. Eng.		intrusion detection system;embedded system;deep packet inspection;frequency scaling;parallel computing;real-time computing;computer science;operating system;pattern matching;programming language;computer security;computer network	EDA	-6.983008348272182	65.93134532532943	32793
c5c171ebc8510eac15deb3ef0af4aae20d6352c0	combining hol-blocking avoidance and differentiated services in high-speed interconnects	topology network topology quality of service switches ports computers proposals routing;topology;network topology high speed interconnects datacenters high performance computing systems highspeed interconnection networks traffic prioritization quality of service qos congestion management mechanism infiniband components combined hol blocking avoidance and differentiated services;routing;network topology;quality of service high speed integrated circuits integrated circuit interconnections network topology;ports computers;quality of service;switches;proposals	Current high-performance platforms such as Datacenters or High-Performance Computing systems rely on highspeed interconnection networks able to cope with the ever-increasing communication requirements of modern applications. In particular, in high-performance systems that must offer differentiated services to applications which involve traffic prioritization, it is almost mandatory that the interconnection network provides some type of Quality-of-Service (QoS) and Congestion-Management mechanism in order to achieve the required network performance. Most current QoS and Congestion-Management mechanisms for high-speed interconnects are based on using the same kind of resources, but with different criteria, resulting in disjoint types of mechanisms. By contrast, we propose in this paper a novel, straightforward solution that leverages the resources already available in InfiniBand components (basically Service Levels and Virtual Lanes) to provide both QoS and Congestion Management at the same time. This proposal is called CHADS (Combined HoL-blocking Avoidance and Differentiated Services), and it could be applied to any network topology. From the results shown in this paper for networks configured with the novel, cost-efficient KNS hybrid topology, we can conclude that CHADS is more efficient than other schemes in reducing the interferences among packet flows that have the same or different priorities.	blocking (computing);cost efficiency;data center;differentiated services;electrical connection;infiniband;interconnection;network congestion;network packet;network performance;network topology;quality of service;requirement;traffic flow (computer networking)	Pedro Yébenes;Jesús Escudero-Sahuquillo;Crispín Gómez Requena;Pedro Javier García;Francisco J. Alfaro;Francisco J. Quiles;José Duato	2014	2014 21st International Conference on High Performance Computing (HiPC)	10.1109/HiPC.2014.7116874	routing;real-time computing;quality of service;network switch;computer science;distributed computing;network topology;computer network;logical topology	HPC	-9.178932991288525	84.11219631788454	32813
4a363a2e07ef16beceb80088685e7ba3c927fe9e	lightweight directory access protocol (ldap): the binary encoding option	lightweight directory access protocol;data type;basic encoding rules	"""Lightweight Directory Access Protocol (LDAP): The Binary Encoding Option Status of This Memo This document specifies an Internet standards track protocol for the Internet community, and requests discussion and suggestions for improvements. Please refer to the current edition of the """"Internet Official Protocol Standards"""" (STD 1) for the standardization state and status of this protocol. Distribution of this memo is unlimited. Abstract Each attribute stored in a Lightweight Directory Access Protocol (LDAP) directory has a defined syntax (i.e., data type). A syntax definition specifies how attribute values conforming to the syntax are normally represented when transferred in LDAP operations. This representation is referred to as the LDAP-specific encoding to distinguish it from other methods of encoding attribute values. This document defines an attribute option, the binary option, that can be used to specify that the associated attribute values are instead encoded according to the Basic Encoding Rules (BER) used by X.500 directories."""	binary file;directory (computing);directory service;internet;lightweight directory access protocol;std bus;x.500;x.690	Steven Legg	2006	RFC	10.17487/RFC4522	lightweight directory access protocol;directory service;computer science;data mining;database;directory information tree;world wide web;organizational unit	Security	-26.400805268205776	88.17789148027981	32833
2911027c75e98fd333668ef5a189552cafd8e635	probability graph based data hoarding for mobile environment	disconnected operation;computacion informatica;grupo de excelencia;mobile computer;mobile environment;ciencias basicas y experimentales;handheld device	Abstract   The vision of mobile environment is severely challenged by disconnected operation. Automated hoarding is an attractive approach solution to this issue. On the other hand, the large overhead of automatic hoarding algorithm is a serious problem for handheld devices. In this paper, we propose an application-independent automatic hoarding algorithm based on probability graph. Simulation results show that it can improve cache hit rate with low time and space overhead in disconnected operation effectively, especially for small cache size, which makes our proposed algorithm preferable for handheld devices.		Huan Zhou;Yulin Feng;Jing Li	2003	Information & Software Technology	10.1016/S0950-5849(02)00160-X	embedded system;simulation;computer science;mobile device;mobile computing;computer security	SE	-15.553684297514085	68.33487346511949	32835
dd9c3b89a61755e10b915c3139f926c6a8dcdac5	supporting ad-hoc resource sharing on the web: a peer-to-peer approach to hypermedia link services	resource discovery;reorganization;selected works;distributed computing;p2p;distributed dynamic link service;peer to peer p2p;open hypermedia;resource sharing;bepress;distribution dynamics;semantic search;peer to peer	The key element to support ad-hoc resource sharing on the Web is to discover resources of interest. The hypermedia paradigm provides a way of overlaying a set of resources with additional information in the form of links to help people find other resources. However, existing hypermedia approaches primarily develop mechanisms to enable resource sharing in a fairly static, centralized way. Recent developments in distributed computing, on the other hand, introduced peer-to-peer (P2P) computing that is notable for employing distributed resources to perform a critical function in a more dynamic and ad-hoc scenario. We investigate the feasibility and potential benefits of bringing together the P2P paradigm with the concept of hypermedia link services to implement ad-hoc resource sharing on the Web. This is accomplished by utilizing a web-based Distributed Dynamic Link Service (DDLS) as a testbed and addressing the issues arising from the design, implementation, and enhancement of the service. Our experimental result reveals the behavior and performance of the semantics-based resource discovery in DDLS and demonstrates that the proposed enhancing technique for DDLS, topology reorganization, is appropriate and efficient.	centralized computing;distributed computing;hoc (programming language);hypermedia;peer-to-peer;programming paradigm;testbed;web application;world wide web	Jing Zhou;Wendy Hall;David De Roure;Vijay Dialani	2007	ACM Trans. Internet Techn.	10.1145/1239971.1239975	shared resource;semantic search;computer science;knowledge management;peer-to-peer;database;distributed computing;world wide web	OS	-13.03324697357714	73.68214810233407	32846
a308fed19e685421ab13fd532fc2e1589028c7aa	application-driven tcp recovery and non-stop bgp	routing protocols;standards;routing;application driven tcp recovery nonstop bgp transparent tcp state recovery routing disruption bgp endpoint tcp connections network protocols tcpr;tcp;non stop routing;transport protocols;servers;fault tolerant systems;transport protocols computer network reliability routing protocols;bgp;fault tolerance;graceful restart;middleware;ports computers;graceful restart tcp fault tolerance middleware bgp non stop routing;routing fault tolerance fault tolerant systems standards ports computers routing protocols servers;computer network reliability	Some network protocols tie application state to underlying TCP connections, leading to unacceptable service outages when an endpoint loses TCP state during fail-over or migration. For example, BGP ties forwarding tables to its control plane connections so that the failure of a BGP endpoint can lead to widespread routing disruption, even if it recovers all of its state but what was encapsulated by its TCP implementation. Although techniques exist for recovering TCP state transparently, they make assumptions that do not hold for applications such as BGP. We introduce application-driven TCP recovery, a technique that separates application recovery from TCP recovery. We evaluate our prototype, TCPR, and show that it outperforms existing BGP recovery techniques.	border gateway protocol;communication endpoint;communications protocol;control plane;denial-of-service attack;failover;prototype;routing;state (computer science);system migration	Robert Surton;Kenneth P. Birman;Robbert van Renesse	2013	2013 43rd Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN)	10.1109/DSN.2013.6575313	routing;fault tolerance;tcp delayed acknowledgment;real-time computing;tcp global synchronization;border gateway protocol;computer science;transmission control protocol;middleware;distributed computing;zeta-tcp;routing protocol;hstcp;tcp tuning;tcp acceleration;tcp friendly rate control;transport layer;server;computer network	Metrics	-9.77000272720232	80.39766392476416	32886
5bb450dd498c6ddf733926c2806ff3141e928e0c	discrete particle swarm optimization algorithm for virtual network reconfiguration	discrete particle swarm optimization;load balancing;network virtualization;reconfiguration algorithm	Network virtualization allows multiple virtual networks (VNs) to coexist on a shared physical substrate infrastructure. Efficient network resource utilization is crucial for such problem. Most of the current researches focus on algorithms to allocate resources to VNs in mapping. However, reconfiguration problem of running VNs is relatively less explored. Aiming at dynamic scheduling of running VNs, this paper introduces a virtual network reconfiguration model to achieve more substrate network resource utilization. We formulate the virtual network reconfiguration problem as a multi object optimal problem and use discrete particle swarm optimization (DPSO) algorithm to search optimal solution. Experimental results show that by rescheduling the running VNs on substrate network according to the optimal reconfiguration solution our approach can observably reduce the biggest load in both physical node and link load, balance average load and avoid bottlenecks in substrate network so as to gain high VNs accept ratio.	algorithm;particle swarm optimization	Ying Yuan;Cuirong Wang;Cong Wang;Shiming Zhu;Siwei Zhao	2013		10.1007/978-3-642-38703-6_30	real-time computing;simulation;distributed computing	Vision	-18.07551152962571	63.17650162109202	32964
75478369cc5616d2fc2e3c4aaa770a0304d460f8	optimization of message encryption for real-time applications in embedded systems		Today, security can no longer be treated as a secondary issue in embedded and cyber-physical systems. Therefore, one of the main challenges in these domains is the design of secure embedded systems under stringent resource constraints and real-time requirements. However, there exists an inherent trade-off between the security protection provided and the amount of resources allocated for this purpose. That is, the more the amount of resources used for security, the higher the security, but the fewer the number of applications which can be run on the platform and meet their timing requirements. This trade-off is of high importance since embedded systems are often highly resource constrained. In this paper, we propose an efficient solution to maximize confidentiality, while also guaranteeing the timing requirements of real-time applications on shared platforms.	block cipher;confidentiality;cyber-physical system;embedded system;encryption;integer programming;iteration;linear programming;matlab;online algorithm;real-time clock;real-time transcription;requirement;time complexity	Amir Aminifar;Petru Eles;Zebo Peng	2018	IEEE Transactions on Computers	10.1109/TC.2017.2778728	encryption;real-time computing;computer science;embedded system	Embedded	-5.081808062605601	61.36318678796465	33018
88d3c0c9a3f31f30099fa5894449729f587fd0f3	optimizing cooling and server power consumption	optimal solution;air conditioning;nonlinear programming;computer model;heuristic programming;computation fluid dynamics;heating;cooling aware consolidation;indexing terms;computational fluid dynamics;computer centres;optimization problem;power aware computing;data center;servers;network servers;computational modeling;time factors;room air;integer programming;variable neighborhood search;search problems air conditioning computer centres heuristic programming integer programming network servers nonlinear programming power aware computing power consumption;servers power demand computational modeling heating atmospheric modeling time factors computational fluid dynamics;time factor;cfd;search problems;atmospheric modeling;power consumption;cfd data center cooling aware consolidation;power demand;lower bound;heuristic algorithm;air temperature;optimal solution optimizing cooling server power consumption optimization problem cooling aware workload placement problem data center power consumption computer room air conditioner power consumption cwpp cross interference matrix cold air temperature state of the art mixed integer nonlinear solver heuristic algorithm integer linear relaxation variable neighborhood search algorithm	This paper proposes new solution strategies for a challenging optimization problem, called Cooling-aware Workload Placement Problem, that looks for a workload placement that optimizes the overall data center power consumption given by the sum of the server power consumption and of the computer room air conditioner power consumption. We formulate CWPP as a Mixed Integer Non Linear Problem using a cross-interference matrix that links the workload placement to the cold air temperature. Since state-of-the-art Mixed Integer Non Linear solvers can solve to optimality only the smallest instances, we devised two heuristics to obtain good feasible solutions: (i) a heuristic algorithm based on an integer linear relaxation of the problem, and (ii) a Variable Neighborhood Search algorithm. Both heuristic algorithms are evaluated against the best lower bounds obtained with a Mixed Integer Non Linear solver. Computational results show that both heuristics provide solutions that have a small percentage gap from the optimal solutions.	computation;computer cooling;data center;heuristic (computer science);integer programming;interference (communication);linear programming relaxation;mathematical optimization;nonlinear system;numerical linear algebra;optimization problem;optimizing compiler;requirement;response time (technology);search algorithm;server (computing);solver;variable neighborhood search	Paolo Cremonesi;Andrea Sansottera;Stefano Gualandi	2011	2011 IEEE 7th International Conference on Intelligent Computer Communication and Processing	10.1109/ICCP.2011.6047916	mathematical optimization;simulation;computer science;theoretical computer science	EDA	-19.88642283447632	63.73899587681311	33117
2674a36a47aed57e7402c756849b6cc22469df99	adaptive post-failure load balancing in fast reroute enabled ip networks	ucl;fast reroute enabled ip networks;availability;network topology adaptive post failure load balancing fast reroute enabled ip networks traffic engineering requirements customer traffic loop free alternates mechanism protection paths;ip networks availability;adaptive control;discovery;network performance;theses;conference proceedings;adaptive post failure load balancing;protection paths;network topology;telecommunication traffic;digital web resources;telecommunication network routing;traffic congestion;ucl discovery;open access;ucl library;ip networks;telecommunication traffic ip networks telecommunication network routing telecommunication network topology;load balance;book chapters;open access repository;loop free alternates mechanism;telecommunication network topology;customer traffic;experience base;traffic engineering requirements;dynamic networks;ucl research	Fast reroute (FRR) techniques have been designed and standardised in recent years for supporting sub-50-millisecond failure recovery in operational ISP networks. On the other hand, if the provisioning of FRR protection paths does not take into account traffic engineering (TE) requirements, customer traffic may still get disrupted due to post-failure traffic congestion. Such a situation could be more severe in operational networks with highly dynamic traffic patterns. In this paper we propose a distributed technique that enables adaptive control of FRR protection paths against dynamic traffic conditions, resulting in self-optimisation in addition to the self-healing capability. Our approach is based on the Loop-free Alternates (LFA) mechanism that allows non-deterministic provisioning of protection paths. The idea is for repairing routers to periodically re-compute LFA alternative next-hops using a lightweight algorithm for achieving and maintaining optimised post-failure traffic distribution in dynamic network environments. Our experiments based on a real operational network topology and traffic traces across 24 hours have shown that such an approach is able to significantly enhance relevant network performance compared to both TE-agnostic and static TE-aware FRR solutions.	algorithm;background process;experiment;fast reroute;load balancing (computing);mathematical optimization;network congestion;network performance;network topology;provisioning;real-time transcription;requirement;test engineer;tracing (software);world wide web	Ning Wang;Abubaker Fagear;George Pavlou	2011	12th IFIP/IEEE International Symposium on Integrated Network Management (IM 2011) and Workshops	10.1109/INM.2011.5990548	availability;adaptive control;telecommunications;computer science;load balancing;network performance;computer security;network topology;computer network	Metrics	-10.436001829629621	83.09707723755471	33134
555359b326d5e8e546e89078afae61ea88364c5a	preemptive flow management in future sdnized wireless networks	wireless networks;handover;hidden markov models;mobile communication;switches;mobile computing	The emerging Software-Defined Networking (SDN) concept aims at simplifying network management and control. SDN is envisioned as one of the core technologies for future wireless networks. However, such networks have inherent challenges, in particular mobility management (MM) and network selection, which require careful design in a centrally controlled SDNized network. In this paper, we propose a proactive flow management solution based on an algorithm that learns users' mobility behavior and proactively processes the handover to reduce the connection delays. The proposed approach was evaluated on a testbed that employs OpenDaylight controller, Mininet emulator, and a custom-built control interface. The results of experiments on the testbed verify the convergence and scalability of the learning algorithm, and showcase the potential of proactive flow setup by the SDN controller in improving the handover delays.	algorithm;emulator;experiment;scalability;software-defined networking;testbed	Manzoor A. Khan;Xuan T. Dang;Sebastian Peters	2016	2016 IEEE 12th International Conference on Wireless and Mobile Computing, Networking and Communications (WiMob)	10.1109/WiMOB.2016.7763208	real-time computing;mobile telephony;telecommunications;network switch;computer science;handover;operating system;wireless network;distributed computing;mobile computing;computer security;computer network	Mobile	-14.470992530473671	85.56643011441749	33195
4d34db1f4486ee68a57d838297f1e7b2c4e8bf1e	weighted routing in hierarchical multi-domain sdn controllers	topology;openflow;switches routing logic gates computer architecture topology network topology;routing;hierarchical architecture;network topology;computer architecture;logic gates;telecommunication traffic control engineering computing software defined networking telecommunication network routing;routing software defined network openflow multicontroller hierarchical architecture;proceedings paper;switches;software defined network;multi controller;congested link avoidance weighted routing service hierarchical multidomain sdn controller software defined networking routing application implementation routing application design hierarchical multicontroller architecture	In the common implementation of software defined networking where only one controller is used, tasks required by various applications may overwhelm the controller as the network grows, leading to degradation of the network performance. Some multi-controller architectures have been proposed to remedy such scalability issue. In this paper, we present our design and implementation of a routing application under a hierarchical multi-controller architecture. In this architecture, a network is partitioned into multiple domains, each of which is managed by a dedicated local controller, which is managed by a common global controller. The routing application is executed on the local and global controllers, jointly providing a routing service for each new flow. We provide effective mechanisms to reduce the link state that should be kept by the global controller. We propose a weight function on the links so that a weighted shortest path can be found that avoids the congested links on the network. Experiments results show that our routing application in the hierarchical multi-controller architecture has a great improvement over that of the single-controller architecture in terms various performance metrics.	algorithm;elegant degradation;emulator;link-state routing protocol;network performance;pathfinding;scalability;shortest path problem;software-defined networking;weight function	Jian-Jhong Huang;Ying-Yu Chen;Chien Chen;Yu Huang Chu	2015	2015 17th Asia-Pacific Network Operations and Management Symposium (APNOMS)	10.1109/APNOMS.2015.7275362	policy-based routing;openflow;routing table;routing domain;routing;enhanced interior gateway routing protocol;static routing;source routing;adaptive quality of service multi-hop routing;real-time computing;hierarchical routing;zone routing protocol;logic gate;equal-cost multi-path routing;network switch;computer science;dynamic source routing;multipath routing;destination-sequenced distance vector routing;distributed computing;software-defined networking;routing protocol;link-state routing protocol;triangular routing;path vector protocol;hazy sighted link state routing protocol;geographic routing;network topology;computer network	Arch	-11.525878620509179	82.89707488790178	33287
5a0c7a7cb798b98e73a13d2f1fbf2ad1f6f6d7a4	subscriptions to request-contained resource lists in the session initiation protocol (sip)		This document specifies a way to create subscription to a list of#N#resources in SIP. This is achieved by including the list of resources#N#in the body of a SUBSCRIBE. Instead of having a subscriber send a#N#SUBSCRIBE for each resource individually, the subscriber defines the#N#resource list, subscribes to it, and gets notifications about changes#N#in the resources' state using a single SUBSCRIBE dialog.		Gonzalo Camarillo;Adam B. Roach;Orit Levin	2006	RFC	10.17487/RFC5367	computer science;database;world wide web;computer network	Theory	-25.83623799561585	87.93098512258474	33293
e53ccba38ccb56a5e98bb30d57be11fbdf40bee6	grid scheduling with makespan and energy-based goals	grid computing;particle swarm optimisation;computer energy measurements;green computing	The need for better energy efficiency in grid computing is significant given the massive amount of energy dissipated by large grids. We approximate the optimal allocation of compute nodes to a job stream, with each job consisting of multiple tasks, and while considering both the computing requirements and a desired balance of shorter makespans and lower energy consumption. The approach is widely applicable to many grid scenarios and does not require the scheduler to have administrative rights to change the workers’ DVFS or hibernation state. A discrete particle swarm optimisation (PSO) determines the worker assignments based on estimations of the tasks’ service times and energy consumption using an online learning process, and taking into account pending task executions from prior jobs. The performance of the proposed system is then evaluated through extensive Monte Carlo simulations using traces of real multi-threaded program executions on representative computer hardware. The results demonstrate the latent energy savings that are possible in grid computing through an energy-aware task scheduling.	approximation algorithm;computer hardware;dynamic voltage scaling;fitness function;grid computing;hibernation (computing);job stream;makespan;mathematical optimization;monte carlo method;online machine learning;particle filter;particle swarm optimization;phase-shift oscillator;relevance;requirement;scheduling (computing);simulation;thread (computing);tracing (software)	Ricardo Lent	2015	Journal of Grid Computing	10.1007/s10723-015-9349-4	green computing;parallel computing;real-time computing;computer science;operating system;database;distributed computing;grid computing	HPC	-18.264576122626075	61.48623830608444	33452
49eaf8e58ef27005cf40a7310a01d4e7c12d1627	incremental optical network topology optimization using meta-mesh span restoration	reliability engineering;optical network;topology;optimisation;meta mesh;communication networks;telecommunication network reliability;telecommunication network topology optical communication optimisation telecommunication network reliability;topology optimization;topology optimization network optimization meta mesh span restoration network survivability network restoration and protection;network topology;network survivability;community networks;mathematical model;network optimization;optical communication;optimization;higher connectivity topology incremental optical network topology optimization meta mesh span restoration localized span restoration like mechanism end to end path restoration meta mesh scheme sparse network topology capacity efficient design node arc meta mesh ilp formulation span restorable network survivability;network restoration and protection;telecommunication network topology;network topology topology optimization equations mathematical model communication networks reliability engineering;span restoration	In recent years, many mechanisms have been proposed for efficient network survivability. Localized span restoration and end-to-end path restoration are two well known general approaches. While path restoration is more efficient with respect to capacity, span restoration is simpler and faster to implement and design. The meta-mesh scheme was proposed a number of years ago to bridge that gap in sparse network topologies, providing more capacity-efficient designs with a simple span-restoration-like mechanism. We develop a new node-arc meta-mesh ILP formulation and further extend that formulation to allow for incremental topology optimization. Results show that even where topology is flexible, thereby allowing a span-restorable network to use a higher-connectivity topology, meta-mesh restoration can outperform span restoration in terms of capacity and number of spans required.	circuit restoration;end-to-end principle;mathematical optimization;mesh networking;network topology;sparse matrix;topology optimization	Ahmed Zaky Kasem;John Doucette	2011	2011 8th International Workshop on the Design of Reliable Communication Networks (DRCN)	10.1109/DRCN.2011.6076887	reliability engineering;topology optimization;telecommunications;computer science;mathematical model;distributed computing;network topology;optical communication;computer network	Arch	-6.108479961459565	81.40487140428364	33482
89fcf167985c17ccedf456bbdeebf76f18d06ab4	a high-performance mapping algorithm for heterogeneous computing systems	mapping algorithm;cost function;heterogeneous computing;processor scheduling;resource allocation;high speed networks;heterogeneous environments mapping algorithm heterogeneous computing systems min min algorithm load balance;heterogeneous environments;distributed processing;heterogeneous environment;resource allocation distributed processing;runtime;heterogeneous computing systems;computer applications;computer networks;scheduling algorithm;min min algorithm;heuristic algorithms;character generation;genetic algorithms;load balance;high performance;computer networks scheduling algorithm cost function processor scheduling high speed networks computer applications runtime character generation heuristic algorithms genetic algorithms	A mapping algorithm for heterogeneous computing systems is proposed in this paper. This algorithm utilizes a new indicator-the relative cost-to obtain optimal mapping. The existing Min-min algorithm can be well explained under synergy of this new indicator. It is found that the Min-min algorithm leaves room for improvement because of its haste to reduce completion time by overlooking the impact of load balance. Our new algorithm retains the advantages of the Min-min algorithm and balances the load very well. It demonstrates the ability to generate good mapping in various heterogeneous environments.	algorithm;heterogeneous computing	Min-You Wu;Wei Shu	2001		10.1109/IPDPS.2001.925020	parallel computing;real-time computing;genetic algorithm;resource allocation;computer science;load balancing;operating system;distributed computing;parallel algorithm;computer applications;dinic's algorithm;scheduling;symmetric multiprocessor system	EDA	-15.220947022693352	61.43965362609581	33564
573e465fa2dedc5af126b7615cc4d7ad0e3583d3	an evaluation of sdn and nfv support for parallel, alternative protocol stack operations		Virtualization on top of high-performance servers has enabled the virtualization of network functions like caching, deep packet inspection. Such Network Function Virtualization (NFV) is used to dynamically adapt to changes in network traffic and application popularity. In this paper, we demonstrate how the combination of Software Defined Networking (SDN) and NFV can support the parallel operation of different Internet architectures on top of the same physical hardware. We introduce our architecture for this approach and evaluate it through a live video streaming application in an actual testbed setup, using CloudLab. We use two vastly different protocol stacks, namely TCP/IP and NDN to demonstrate the capability of our approach. The evaluation of our approach shows that it introduces a new level of flexibility when it comes to operation of different Internet architectures on top of the same physical network.	deep packet inspection;ibm notes;internet protocol suite;network function virtualization;network packet;network topology;network traffic control;protocol stack;software-defined networking;streaming media;testbed;vii	Bhushan Suresh;Divyashri Bhat;Michael Zink	2018	2018 IEEE International Conference on Communications (ICC)	10.1109/ICC.2018.8422752	virtualization;protocol stack;the internet;computer network;architecture;deep packet inspection;software-defined networking;cloud computing;computer science;server	Networks	-14.334712142644014	82.7291764965216	33643
8dc427e562569a48199ddc391bb272987169920a	coqos: coordinating qos-aware shared resources in noc-based socs	simulation ordinateur;internet protocol;distributed system;gestion memoire;systeme reparti;protocolo internet;network on chip;resource allocation;architecture memoire;storage management;resource manager;resource management;protocole internet;cache memory;orientado servicio;system on a chip;qualite service;partage des ressources;antememoria;gestion recursos;gestion memoria;antememoire;fichier log;sistema repartido;fichero actividad;class of service;sistema sobre pastilla;system on chip;memory architecture;resource sharing;particion recursos;gestion ressources;coordinacion;systeme sur puce;oriente service;asignacion recurso;simulacion computadora;quality of service;allocation ressource;computer simulation;arquitectura de la memoria;service quality;log file;coordination;service oriented;calidad servicio	Contention in performance-critical shared resources affects performance and quality-of-service (QoS) significantly. While this issue has been studied recently in CMP architectures, the same problem exists in SoC architectures where the challenge is even more severe due to the contention of shared resources between programmable cores and fixed-function IP blocks. In the SoC environment, efficient resource sharing and a guarantee of a certain level of QoS are highly desirable. Researchers have proposed different techniques to support QoS, but most existing works focus on only one individual resource. Coordinated management ofmultiple QoS-aware shared resources remains an open problem. In this paper,we propose a class-of-service based QoS architecture (CoQoS), which can jointly manage three performance-critical resources (cache, NoC, and memory) in a NoC-based SoC platform. We evaluate the interaction between the QoS-aware allocation of shared resources in a trace-driven platform simulator consisting of detailed NoC and cache/memorymodels. Our simulations show that the class-of-service based approachprovides a low-cost flexible solution for SoCs.We show that assigning the same class-of-service tomultiple resources is not as effective as tuning the class-of-service of each resource while observing the joint interactions. This demonstrates the importance of overall QoS support and the coordination of QoS-aware shared	class of service;emoticon;experiment;fixed-function;interaction;network on a chip;operating system;quality of service;simulation;system on a chip	Bin Li;Lu Zhao;Ravi R. Iyer;Li-Shiuan Peh;Michael Leddige;Michael Espig;Seung Eun Lee;Donald Newell	2011	J. Parallel Distrib. Comput.	10.1016/j.jpdc.2010.10.013	system on a chip;embedded system;real-time computing;computer science;resource management;operating system;computer network	HPC	-12.626111221370998	64.29756303248953	33738
6efc83bb64474b63daf6cceb97b37bd3a22384cf	options, forwards and provision-point contracts in improving cloud infrastructure utilisation	information systems applications incl internet;software engineering programming and operating systems;computer communication networks;special purpose and application based systems;computer system implementation;computer systems organization and communication networks	Cloud computing takes away much of the need to plan future IT demands from the consumer, and puts it in the hands of the provider. Consumers don’t need to give advance notice to start or terminate virtual machines, and can do so in real time to reflect changing business objectives. It is the task of the cloud IaaS provider to optimise the use of her infrastructure, and ensure there are enough resources available. Achieving optimum server utilisation in the data centre is particularly challenging – advance notification can help the provider to schedule workloads more efficiently, but this is at odds with one of the key benefits of cloud computing. In this paper, we propose a pricing method that combines options contracts with on-demand purchasing. We show that the method can provide consumers with the flexibility and cost-benefits afforded by cloud computing, and can benefit the provider by improving server utilisation and therefore reducing energy costs. Furthermore, we show how provision-point contracts, often used by deal-of-the-day websites such as Groupon, can further improve the method, making it even more attractive to the provider.	cloud computing;data center;deal of the day;purchasing;server (computing);terminate (software);virtual machine	Owen Rogers;Dave Cliff	2012	Journal of Cloud Computing: Advances, Systems and Applications	10.1186/2192-113X-1-21	simulation;operating system	OS	-25.964036536745294	60.73582312990723	33755
0191028dbdb6579cc9558c7dc16f282689d64cbf	load dynamics of a multiplayer online battle arena and simulative assessment of edge server placements	software;human computer interaction;computer graphics and computer aided design;resource allocation;online gaming;load dynamics;cloud computing	Free-to-play models, streaming of games and eSports are reasons for online gaming to grow in popularity recently. On the forefront are multiplayer online battle arenas, which gain high popularity by introducing a competitive format that is easy to access and requires cooperation and team play. These games highly rely on fast reaction of the players, which makes latency the key performance indicator of such applications. To obtain low latency, this paper proposes moving game servers close to players towards the edge of the network. The performance of such mechanism highly depends on the geographic distribution of players. By analyzing match histories and statistics, we develop models for the arrival process and location of game requests. This allows us to evaluate the performance of edge server resource migration policies in an event based simulation. Our results show that a high number of edge servers is preferable compared to few larger edge servers to reduce the latency of players. This supports approaches that allow deploying virtual server instances in the back-haul.	backhaul (telecommunications);content delivery network;game server;microsoft forefront;server (computing);simulation;virtual private server	Valentin Burger;Jane Frances Pajo;Odnan Ref Sanchez;Michael Seufert;Christian Schwartz;Florian Wamser;Franco Davoli;Phuoc Tran-Gia	2016		10.1145/2910017.2910601	simulation;cloud computing;resource allocation;computer science;operating system;distributed computing;multimedia;world wide web	Metrics	-19.509702944113684	74.06459622004064	33758
44ff735d239d5eb3cf6dfe82db8435ded2430a50	loopback: exploiting collaborative caches for large-scale streaming	cache storage;streaming;video streaming;par a par;transmision continua;bandwidth allocation;video a la demande;serveur informatique;client server systems;video broadcasting;buffer system;qualite service;sistema amortiguador;i o bandwidth collaborative caches large scale video streaming loopback streaming architecture proxy buffers content delivery network cdn proxy server network bandwidth;diffusion video;peer to peer computing video streaming video servers client server systems cache storage bandwidth allocation;large scale;transmission en continu;content distribution;poste a poste;video streaming content distribution peer to peer streaming;peer to peer streaming;video on demand;servidor informatico;video servers;content delivery network;peer to peer computing;difusion de senales de video;systeme tampon;peer to peer;proxy server;service quality;video a la carta;collaboration large scale systems streaming media network servers bandwidth web server scalability peer to peer computing internet cache storage;calidad servicio;computer server	In this paper, we propose a Loopback approach in a two-level streaming architecture to exploit collaborative client/proxy buffers for improving the quality and efficiency of large-scale streaming applications. At the upper level we use a content delivery network (CDN) to deliver video from a central server to proxy servers. At the lower level a proxy server delivers video with the help of collaborative client caches. In particular, a proxy server and its clients in a local domain cache different portions of a video and form delivery loops. In each loop, a single video stream originates at the proxy, passes through a number of clients, and finally is passed back to the proxy. As a result, with limited bandwidth and storage space contributed by collaborative clients, we are able to significantly reduce the required network bandwidth, I/O bandwidth, and cache space of a proxy. Furthermore, we develop a local repair scheme to address the client failure issue for enhancing service quality and eliminating most required repairing load at the central server. For popular videos, our local repair scheme is able to handle most of single-client failures without service disruption and retransmissions from the central server. Our analysis and simulations have shown the effectiveness of the proposed scheme.	client (computing);content delivery network;denial-of-service attack;digital distribution;disk space;input/output;loopback;proxy server;requirement;server (computing);simulation;streaming media	Ewa Kusmierek;Yingfei Dong;David Hung-Chang Du	2006	IEEE Transactions on Multimedia	10.1109/TMM.2005.864277	reverse proxy;real-time computing;computer science;bicarbonate buffering system;operating system;world wide web;service quality;server;computer network;bandwidth allocation	Metrics	-15.37797849865871	72.31376157404944	33878
6d9402d68ba32ccd5b5644a191dc44b479074c99	load balancing oriented computation offloading in mobile cloudlet		The limited computing ability of mobile device constrains its performance on complex mobile applications. Mobile cloud computing (MCC) has therefore emerged to migrate computation-intensive tasks to remote clouds or mobile cloudlets. Most strategies allocate tasks with minimal response time yet few consider the load of the nodes. In this paper, we focus on the load balancing problem for nodes when they conduct offloading. We first establish a five-tuple characterized task model to capture the response time of offloaded tasks. Then, we formulate the task allocation problem as an integer linear problem (ILP) under certain conditions. Furthermore, we propose a two-step appointment- driven strategy to solve this problem with minimal task response time. Specifically, a modified genetic algorithm (GA) is adopted to coordinate the load of the nodes. Simulations are conducted to prove the feasibility of our strategy and evaluate the performance of load coordination.	cloudlet;computation offloading;computer simulation;genetic algorithm;linear programming;load balancing (computing);mobile app;mobile cloud computing;mobile device;response time (technology);software release life cycle	Danhui Yao;Lin Gui;Fen Hou;Fei Sun;Daihui Mo;Hangguan Shan	2017	2017 IEEE 86th Vehicular Technology Conference (VTC-Fall)	10.1109/VTCFall.2017.8288336	computer science;task analysis;computer network;response time;cloudlet;mobile cloud computing;distributed computing;cloud computing;load management;computation offloading;load balancing (computing)	Embedded	-22.041049577107902	67.03187223928023	34036
d4c66687fa31f27009423e1d86bfe213a772780b	rerouting schemes for dynamic traffic grooming in optical wdm mesh networks	blocking probability;connection blocking probability dynamic traffic grooming optical wdm mesh networks two layer routing problem low rate connections high rate lightpaths rerouting at lightpath level rerouting at connection level critical wavelength avoiding one lightpath limited rerouting heuristic critical lightpath avoiding one connection limited rerouting heuristics;traffic grooming;traffic model;optical fibre networks;telecommunication traffic;telecommunication network routing;mesh network;optical fibre networks telecommunication network routing telecommunication traffic wavelength division multiplexing;telecommunication traffic intelligent networks optical fiber networks wavelength division multiplexing wdm networks mesh networks optical wavelength conversion routing throughput network topology;wavelength division multiplexing	Traffic grooming in optical WDM mesh networks is a two-layer routing problem to pack low-rate connections effectively onto high-rate lightpaths, which, in turn, are established on wavelength links. We employ the rerouting approach to improve the network throughput under the dynamic traffic model. We propose two rerouting schemes, rerouting at lightpath level (RRAL) and rerouting at connection level (RRAC). A qualitative comparison is made between RRAL and RRAC. We also propose the critical-wavelength-avoiding one-lightpath-limited (CWA-1L) and critical-lightpath-avoiding one-connection-limited (CLA-1C) rerouting heuristics, which are based on the respective rerouting schemes. Simulation results show that rerouting reduces the connection blocking probability significantly.	blocking (computing);erlang (unit);heuristic (computer science);mesh networking;routing;simulation;throughput;wavelength-division multiplexing	Wang Yao;Byrav Ramamurthy	2004	IEEE Global Telecommunications Conference, 2004. GLOBECOM '04.	10.1109/GLOCOM.2004.1378291	traffic grooming;telecommunications;computer science;mesh networking;distributed computing;wavelength-division multiplexing;computer network	HPC	-5.76386010585162	84.48766954559427	34178
db96cff1ac81e579eb1307639514e3cf661a1033	a predictive technique for replica selection in grid environment	high energy physics instrumentation computing;data grid replication;neural networks;cost function;bandwidth consumption;neural nets;regression analysis grid computing neural nets;availability;access latency;file replicas;multiregression model;power engineering computing;computational modeling;neural networks delay predictive models high energy physics instrumentation computing availability throughput computational modeling power engineering computing bandwidth cost function;transfer time prediction;grid environment;bandwidth;predictive models;regression analysis;multiregression model replica selection grid environment data grid replication access latency bandwidth consumption neural network transfer time prediction file replicas;grid computing;replica selection;neural network;throughput	Replication in a data grid reduces access latency and bandwidth consumption. However, when different sites hold replicas of a particular file, there is a significant benefit realized by selecting the best replica from among them. The best replica is the one that optimizes the desired performance criterion such as absolute performance (i.e. speed), cost, security or transfer time. By selecting the best replica, the access latency can be minimized. We develop a predictive framework that uses data from various sources and predicts transfer times of the sites that host replicas. With this estimate, one site can request the replica from the site that has the lowest transfer time. We use a neural network (NN) for transfer time prediction of different sites that currently hold file replicas. We compare the results with a multi-regression model and the simulation results demonstrate that the neural network technique is capable of predicting transfer time more accurately than the regression based model.	artificial neural network;simulation	Rashedur M. Rahman;Ken Barker;Reda Alhajj	2007	Seventh IEEE International Symposium on Cluster Computing and the Grid (CCGrid '07)	10.1109/CCGRID.2007.8	availability;throughput;parallel computing;real-time computing;computer science;theoretical computer science;operating system;database;distributed computing;predictive modelling;computational model;artificial neural network;bandwidth;regression analysis;grid computing	HPC	-17.1336425200564	66.56546627893047	34206
d67b1d28a44354584358e2e82872a5b366f44581	a proactive management framework in active clusters	distributed system;metodo adaptativo;evaluation performance;systeme reparti;sistema activo;service level;performance evaluation;red www;gestion red;equilibrio de carga;evaluacion prestacion;reseau web;equilibrage charge;service web;methode adaptative;web service;adaptive load balancing;systeme actif;qualite service;sistema reactivo;active system;active network;sistema repartido;sevicio proactivo;internet;adaptive method;cluster system;gestion reseau;load balancing;proactive;reactive system;systeme reactif;world wide web;network management;service level management;service quality;servicio web;service proactif;calidad servicio	An active Web cluster system is an active network that has a collection of locally distributed servers that are interconnected by active switches, providing a Web application service. In this paper, we introduce the ALBM (Adaptive Load Balancing and Management) active cluster system that provides proactive management. The architecture of the ALBM active cluster and its underlying components are presented. We focus on system-level and service-level management of the active cluster system by presenting the corresponding proactive ALBM framework. The system-level framework considers performance counters of resource state dynamics; the service-level framework concerns service quality and proactive actions based on event occurrences. The experimental results on adaptive load balancing are presented in terms of system-level proactive management. In addition, a proactive event message service tool is introduced for providing effective services and management in terms of service-level proactive management.	active networking;adaptive filter;algorithm;load balancing (computing);network address translation;network packet;network switch;routing;scheduling (computing);server farm;system information (windows);terms of service;web application	Eunmi Choi;Dugki Min	2003		10.1007/978-3-540-24715-9_20	network management;web service;embedded system;active networking;the internet;simulation;service level;reactive system;computer science;load balancing;computer security;service quality	HPC	-11.734106419761474	68.05871897204534	34241
46c9d408361fa5db4567693a52964030000e1083	distributed task allocation for visual sensor networks: a market-based approach	resource allocation distributed processing multi agent systems multimedia systems;resource management quality of service peer to peer computing pricing adaptation model smart cameras visualization;resource allocation;pricing;distributed processing;rate adaptation;resource management;adjusted linear pricing model;multimedia systems;sensor network;visualization;multi agent systems;virtual commodity markets;decentralized producer agents;adaptation model;visual sensor networks;distributed task allocation;task allocation agent distributed task allocation visual sensor networks quality of service user defined interest level virtual commodity markets decentralized producer agents adjusted linear pricing model rate adaptive pricing model;resource sharing;smart cameras;task allocation agent;user defined interest level;rate adaptive pricing model;peer to peer computing;quality of service;work in progress;task allocation	This work in progress presents a novel distributed task allocation method for visual sensor networks based on a computational market. Our proposed method automatically adapts the QoS levels of the individual tasks, depending on the resource requirements and the user-defined interest level of the service. Therefore, we define virtual commodity markets, where decentralized producer agents sell resource shares of nodes and communication links. Producer agents adapt their unit prices for resources depending on the demand for the individual resources. In this paper we discuss two pricing models: adjusted linear pricing and rate adaptive pricing. To allocate resources required for executing a task, a task allocation agent requests a number of offers from different producer agents. Task allocation agents use the received interest levels, which correspond to the virtual money, to lease resource shares for a specific time.	quality of service;requirement;software agent;virtual economy	Felix Pletzer;Bernhard Rinner	2010	2010 Fourth IEEE International Conference on Self-Adaptive and Self-Organizing Systems Workshop	10.1109/SASOW.2010.41	pricing;shared resource;smart camera;real-time computing;simulation;wireless sensor network;visualization;quality of service;resource allocation;computer science;artificial intelligence;resource management;work in process;multi-agent system	Robotics	-17.316602437288406	65.05110413792848	34281
70fbe421673a1b03dd1b1ce4ca9bb8221cac8ef9	a framework for constructing peer-to-peer overlay networks in java	structured overlay network;peer to peer system;overlay network;asynchronous messaging;peer to peer;peer to peer overlay networks;key based routing	Peer-to-peer emerges as a better way for building applications on the Internet that require high scalability and availability. Peer-to-peer systems are usually organized into structured overlay networks, which provide key-based routing capabilities to eliminate flooding in unstructured ones. Many overlay network protocols have been proposed to organize peers into various topologies with emphasis on different networking properties. However, applications are often stuck to a specific peer-to-peer overlay network implementation, because different overlay implementations usually provide very different interfaces and messaging mechanisms. In this paper, we present a framework for constructing peer-to-peer overlay networks in Java. First, networking is abstracted by the interfaces that use URIs to uniformly address peers on different underlying or overlay networks. Then, asynchronous and synchronous messaging support is built upon these interfaces. Finally, overlay networking interfaces are sketched to handle specific issues in overlay networks. We have constructed several overlay networks in this framework, and built peer-to-peer applications which are independent of overlay implementations.	communications protocol;java;key-based routing;overlay network;peer-to-peer;scalability	Rui Shen;Ji Wang;Shengdong Zhang;Siqi Shen;Pei Fan	2009		10.1145/1596655.1596662	overlay network;computer science;key-based routing;distributed computing;world wide web;computer network	Networks	-12.212548350658789	76.09250240778675	34305
6a43faea38ae7a3277b55f5398e253054d90e0d7	a test design method for resilient system on cloud infrastructure	chaos;surges;servers;production systems;network function virtualization;cloud computing;design methodology	IT systems for social infrastructure need to be resilient against a variety of disturbance events including hardware failures, software malfunctions, and application load surges. Techniques of dynamic system reconfiguration such as auto-scaling and auto-healing, which are typically provided in cloud services, can help maintain the system availability and good performance even after disturbance events. Such reconfiguration operations should be carefully designed and tested well on the production system (in real use) since the offline test is not enough to guarantee the functionality and performance of the production system after reconfiguration. In this paper, we propose a new test design method, called Live System Evaluation, to test an expected system configuration after reconfiguration operation triggered by disturbance events (e.g., a server failure). The test system is designed in a way to be embedded on the production system so that it can validate the expected system with high confidence with the minimum additional resources. We formulate the problem as an optimization problem and develop a prototype solver. An example case study on Network Function Virtualization application shows that our design method reduces the total resource cost by half compared with a conventional approach which requires a separated test system.	autoscaling;branch and cut;cloud computing;dynamical system;embedded system;image scaling;mathematical optimization;network function virtualization;online and offline;optimization problem;production system (computer science);prototype;scalability;server (computing);social infrastructure;solver;system configuration;test design	Masaya Fujiwaka;Fumio Machida;Seiichi Koizumi	2016	2016 IEEE 9th International Conference on Cloud Computing (CLOUD)	10.1109/CLOUD.2016.0065	network functions virtualization;real-time computing;simulation;design methods;cloud computing;computer science;operating system;distributed computing;production system;server	Mobile	-29.754731889497005	63.53179343219965	34310
34f4f2cde32e01c3fb5b607538d5bd6420cd6f3a	building a network-aware and load-balanced peer-to-peer system for range queries	locality awareness;range query;overlay construction;proximity;load balance;peer to peer	We present a structured P2P system called Donuts for range queries, which takes two important yet somewhat conflicting issues into account: proximity and load balance. Proximity allows physically close nodes to be arranged near each other in the overlay so as to reduce the cost of neighbor communications that occur quite often in a range-queriable system. Load balance is crucial because object distribution in a semantically meaningful key space is often skewed. Efficient load balance, however, requires flexible node position in the overlay, and thus conflicts with proximity. Donuts resolves the problem by separating physically close nodes into several overlay sections. By dynamically switching between these sections, they help one another balance their loads without altering overlay proximity too much. Still, breaking apart physically close nodes inevitably compromises overlay proximity. Therefore, we have put much effort in the overlay construction to ensure that load balance can be performed effectively and efficiently, with minimal damage to overlay proximity.	load balancing (computing);peer-to-peer;range query (data structures)	Yuh-Jzer Joung;Wing-Tat Wong;Hsiao-Mei Huang;Yi-Fang Chou	2012	Computer Networks	10.1016/j.comnet.2012.02.018	range query;computer science;load balancing;database;distributed computing;distance;world wide web	Theory	-11.392697483848652	73.11868507622805	34357
2f79b91ed8dc5adf3919c51b33779a43af53066c	a scalability study of aaa support in heterogeneous networking environments with global roaming support	protocols;network design;access network;authorisation;mobility;performance;wireless lan authorisation code division multiple access mobile radio multiprocessing systems protocols subscriber loops telecommunication security;mobility aaa scalability performance radius;code division multiple access;network connectivity;radius;subscriber loops;mobile radio;telecommunication security;cpu load balancing aaa support heterogeneous networking environment global roaming support mobile heterogeneous access network network load radius protocol cdma 2000 umts network scalability network design aaa server cpu power wifi sign on ram memory database performance;aaa;load balance;wireless lan;scalability;multiprocessing systems;servers authentication protocols databases ieee 802 11 standards ip networks mathematical model;heterogeneous network	In this paper, we present a scalability study of AAA support in mobile heterogeneous access networks with respect to server and network load related to AAA processes using the RADIUS protocol. Technologies such as IEEE 802.11, CDMA 2000 and UMTS which all support the RADIUS protocol for AAA handling are discussed and analyzed. Typical performance data are gathered and complemented with a theoretical study in order to achieve an overview of what parameters will affect the performance and scalability of the network. Also, guidelines are developed for network design in order to achieve the desired performance for a given number of users. Results of this study include the conclusion that the main bottleneck of the AAA procedure is not necessarily the AAA server CPU power. Aside the cases with a high proportion of computationally intensive WiFi sign-ons with strong encryption, performance issues may be caused by AAA server network connection bandwidth, and RAM memory. In cases where a high number of users reside in the same user database, database performance becomes a significant issue. In order to achieve better performance, CPU load balancing over several servers may be performed.	aaa (video game industry);access network;central processing unit;encryption;experiment;load balancing (computing);mobile ip;network interface;network planning and design;proxy mobile ipv6;radius;random-access memory;scalability;seamless3d;sensor;server (computing);strong cryptography;systems architecture;wi-fi protected access	Daniel Granlund;Christer Åhlund	2011	2011IEEE 10th International Conference on Trust, Security and Privacy in Computing and Communications	10.1109/TrustCom.2011.63	real-time computing;computer science;distributed computing;computer network	DB	-28.584068864073373	82.3103012669604	34365
98923a50f531892145cb9626ddbdf596c562a040	a shared buffer architecture for interactive vod servers	server buffer;broadband networks;disk scheduling;communications;conference_paper;broadband network;interactive video;fixed length atm cells shared buffer architecture interactive vod servers video on demand disk array based vod server disk array based video servers video segment retrievals service round scan disk scheduling algorithm scan algorithm disk retrieval buffer manager buffer locations deadlines release video starvation buffer overflow cell loss atm based broadband network;buffer storage;video segmentation;broadband networks asynchronous transfer mode scheduling buffer storage interactive video network servers;computer applications;network servers;buffer overflow;scheduling;video on demand;video server;video on demand vod;user interactivity;video servers;network servers asynchronous transfer mode buffer storage buffer overflow broadband communication displays scheduling algorithm communication networks video sequences delay;set top box buffer;set top box;asynchronous transfer mode;disk array	Video-on-demand (VOD) servers need to be efficiently designed in order to support a large number of users viewing the same or different videos at different rates. While considering a disk-array based VOD server, use of a shared buffer at the server end may be more economical than the sole use of dedicated buffers at each user's end. In this paper we propose a simple buffer sharing architecture that may be used when disk-array based video servers are used. Our aim is to support the maximum number of users for a given number of video server disks while employing a simple scheme requiring less buffer space. The number of video segment retrievals that can occur within a certain time (the service round) is maximum when the scan disk scheduling algorithm is used. Consequently, we shall assume use of the scan algorithm for disk retrieval. The VOD server has a buffer manager that directs retrieved segments to appropriate buffer locations depending on their release and deadlines. The release and deadlines of segments are such that buffer requirement at the user's set-top box is minimized to two video segments while avoiding video starvation and buffer overflow at the user's end. We propose a novel scheme for the operation of the shared buffer that aims at increasing buffer utilization and decreasing cell loss due to buffer overflow. An ATM based broadband network is assumed and all segments are stored in buffers as fixed length ATM cells.	versant object database	Senthil Sengodan;Victor O. K. Li	1997		10.1109/INFCOM.1997.631167	real-time computing;computer science;operating system;distributed computing;buffer underrun;write buffer;circular buffer;computer network;broadband networks	DB	-15.342155489190944	71.10656000006928	34395
c30e76eb2404ac3e07321778b13614057e2ad0bd	photonic burst switching (pbs) architecture for hop and span-constrained optical networks	data transmission;optical network;wdm networks photonic burst switching optical networks variable time slot provisioning data transmission hop networks span constrained networks edge node architecture switching node architecture signaling optical switch fabric edge router burst assembly gmpls software building blocks adaptive mac layer functionality multiple generic payloads enterprise networks;multiprotocol label switching;photonic switching systems;out of band;optical switch;building block;enterprise networks;telecommunication computing;business communication;optical fibre networks;software architecture;burst switching optical fiber networks high speed optical techniques computer architecture fabrics software architecture integrated optics data communication optical switches assembly;network architecture;telecommunication computing photonic switching systems optical fibre networks telecommunication signalling multiprotocol label switching software architecture business communication wavelength division multiplexing;telecommunication signalling;high speed;mac layer;wavelength division multiplexing	The paper presents a new architecture, called photonic burst switching (PBS), with variable time slot provisioning, supporting high-speed bursty data transmission within hop and span-constrained networks. First, the edge and switching node architecture for in-band and out-of-band signaling is defined with optical switch fabric performance parameters. Second, the edge router regions of operation for burst assembly are studied via simulations. Third, we introduce: (i) a GMPLS-based PBS software architecture in terms of control and data plane operations that is extended to enable the PBS optical interfaces with software building blocks for edge and switching nodes; (ii) an adaptive PBS MAC layer functionality and framing of multiple generic payloads. The integration of the proposed PBS network architecture with low-cost optical switching fabrics and GMPLS-based software architecture should provide the means for robust and efficient optical transport of bandwidth-demanding applications within enterprise networks.		Shlomo Ovadia;Christian Maciocco;Mario Paniccia;Ramesh Rajaduray	2003	IEEE Communications Magazine	10.1109/MCOM.2003.1244925	multiprotocol label switching;out-of-band management;software architecture;network architecture;optical burst switching;telecommunications;computer science;distributed computing;business communication;optical switch;wavelength-division multiplexing;computer network;data transmission	Vision	-19.725873770049112	87.9833380290895	34450
0d0d157416adcb70f0ebadc938c8b783501c93eb	a user-guided cognitive agent for network service selection in pervasive computing environments	mobile radio software agents telecommunication services cognitive systems ubiquitous computing user centred design;user individual needs;user agent;wireless networks;cognitive systems;network service preferences user guided cognitive agent network service selection pervasive computing environments diverse connectivity wireless network services competitive environment intelligent software agent user individual needs user preferences minimal guidance user interaction adaptive user agent;adaptive user agent;base stations;cognitive agents;pervasive computing;continuous selection;wireless network;user preferences;user guided cognitive agent;software agents;internet;competitive environment;mobile radio;user experience;network service preferences;diverse connectivity;environmental economics;telecommunication services;artificial intelligence;ubiquitous computing;user centred design;intelligent networks;wireless lan;computer science;minimal guidance;network service selection;network services;pervasive computing environments;user interaction;wireless network services;intelligent software agent;large scale systems;intelligent networks pervasive computing environmental economics internet base stations wireless lan large scale systems computer science artificial intelligence wireless networks	Connectivity is central to pervasive computing environments. We seek to catalyze a world of rich and diverse connectivity through technologies that drastically simplify the task of providing, choosing, and using wireless network services; creating a new and more competitive environment for these capabilities. A critical requirement is that users actually benefit from this rich environment, rather than simply being overloaded with choices. We address this with an intelligent software agent that transparently and continually chooses from among available network services based on its user's individual needs and preferences, while requiring only minimal guidance and user interaction. We present an overview and model of the network service selection problem. We then describe an adaptive user agent that learns its user's network service preferences from a very minimal, intuitive set of inputs, and autonomously and continually selects the service that best meets the user's needs. Results from preliminary user experiments are presented that demonstrate the effectiveness of our agent.	access network;autonomous robot;collaborative filtering;complex network;experiment;intelligent agent;machine learning;multi-agent system;peer-to-peer;pervasive informatics;router (computing);selection algorithm;software agent;ubiquitous computing;usability testing;user (computing);user agent	George Lee;Peyman Faratin;Steven Bauer;John Wroclawski	2004	Second IEEE Annual Conference on Pervasive Computing and Communications, 2004. Proceedings of the	10.1109/PERCOM.2004.1276860	human–computer interaction;computer science;wireless network;distributed computing;world wide web;computer security;ubiquitous computing;computer network	AI	-26.06073386465413	71.31617854406332	34472
db956e0ade2c02a9deb233a159e6c6c31d65827a	armature: a structurally adaptive connectivity manager for critical communication services preservation		In this paper, we present ARMATURE, a peer-to-peer overlay that provides highly resilient communication service for critical infrastructure control. ARMATURE can encapsulate all control traffic, e.g. SCADA sessions, within secure and highly resilient transport tunnels. Herein, it does not rely on any particular ISP provisions and can use any available IP interface. Most importantly, the constructed overlay network is able to structurally reshape, i.e. to change its structural graph properties, to face different situations and to reunite otherwise conflicting service requirements. ARMATURE can be easily deployed in the current critical infrastructures to protect their monitoring and control communications.		Artur Hecker;Yacine Benchaïb;Claude Chaudet	2013		10.3182/20130619-3-RU-3018.00521	engineering;distributed computing;computer security;computer network	Robotics	-16.26847027763021	82.53005346611349	34522
067bd735f1aff6e1485b4b2f473dd89376cb35ae	ieee access special section editorial: recent advances in software defined networking for 5g networks	special issues and sections;special issues and sections software defined networks computer architecture cloud computing wireless communication 5g mobile communication;wireless communication;computer architecture;5g mobile communication;cloud computing	The demand for flexible network management has been growing significantly over the last several decades, which comes with a series of other related demands in network virtualization, stringent security, tenant isolation in cloud, and high performance and reliability for broadband access. To meet these demands from both users and enterprises, numerous networking protocols had been designed and developed. However, these protocols were usually defined independently targeting various specific problems using different systems and sub-systems, without a holistic approach. On the other hand, cloud computing brings many challenges to traditional networking, from naming and addressing to the traditional routing. In addition, companies seek to use more standard and vendor-independent equipment to reduce the Capital Expenditure (CAPEX) and Operational Expenditure (OPEX).	software-defined networking	Mugen Peng;Tao Huang;Yangyang R Yu;Jianli Pan	2015	IEEE Access	10.1109/ACCESS.2016.2514898	cloud computing security;cloud computing;telecommunications;computer science;operating system;distributed computing;computer security;wireless;computer network	Visualization	-15.56775827105805	86.26114175746581	34530
0d21f26c1056de45ba4c05a5186bbfb16fe2eb4c	spatial hoarding: a hoarding strategy for location-dependent systems	spatial;cache invalidation	In a context-aware environment, the system must be able to refresh the answers to all pending queries in reaction to perpetual changes in the user’s context. This added to the fact that mobile systems suffer from problems like scarce bandwidth, low quality communication and frequent disconnections, leads to high delays before giving up to date answers to the user. A solution to reduce latency is to use hoarding techniques. We propose a hoarding policy particularly adapted for location-dependent information systems managing a huge amount of multimedia information and where no assumptions can be made about the future user’s location. We use the user’s position as a criterion for both hoarding and cache invalidation.	cache (computing);cache coherence;cache invalidation;hit (internet);information access;information system;server (computing);telecommunications link	Karim Zerioh;Omar El Beqqali;Robert Laurini	2004		10.1007/3-540-26772-7_17	business;real-time computing;latency (engineering);cache invalidation;information system	DB	-15.503631963873692	68.5592811863847	34531
0b5981f14209a6484cc094ffd838fdcd6924232f	icicd: an efficient content distribution architecture in mobile cellular network	computer architecture;servers;internet;streaming media;mobile communication;load management;mobile computing	With the recent proliferation of powerful mobile devices, such as smart phones and tablets, data traffic on mobile networks is growing explosively. To cope with the challenges brought by the explosive growth of mobile traffic, mobile network operators tend to deploy and operate their own content distribution system within their existing network infrastructure. In this paper, we present a novel content distribution architecture called ISP-Controlled In-network Content Distribution (ICICD) to improve the content delivery performance in mobile network, which benefits from content request aggregation, hybrid cache decision mechanism, distributed load balancing, and seamless mobility support. Content request aggregation is used to decrease duplicate transmission. Hybrid cache decision mechanism enables the ICICD to cache content more efficiently. Distributed load balancing is able to ensure the overall performance and reliability of the content distribution architecture. Seamless mobility support function enables service continuity when mobile users move from one eNodeB to another. In this paper, we first give a detailed description about the key components of the ICICD architecture and then discuss a number of challenges in deploying the proposed ICICD architecture. Finally, simulation results are presented to show the performance and benefits of the proposed mobile content distribution architecture.	digital distribution;load balancing (computing);mobile device;mobile phone;scott continuity;seamless3d;simulation;smartphone;tablet computer	Junfeng Xie;Renchao Xie;Tao Huang;Jiang Liu;Yunjie Liu	2017	IEEE Access	10.1109/ACCESS.2017.2671745	embedded system;real-time computing;mobile search;the internet;mobile web;mobile telephony;telecommunications;mobile database;computer science;operating system;mobile technology;mobile computing;computer security;server;computer network	Mobile	-19.724762990284052	75.68974285270279	34541
956032e5bad45195b34099418f6cc449dc88d66a	performance estimation of embedded software with instruction cache modeling	instruction cache;search space;performance estimation;real time;code generation;software systems;embedded system;upper bound;memory access;worst case execution time;system design;memory systems;integer linear program;dsp;embedded software	Embedded systems generally interact in some way with the outside world. This may involve measuring sensors and controlling actuators, communicating with other systems, or interacting with users. These functions impose real-time constraints on system design. Verification of these specifications requires computing an upper bound on the worst-case execution time (WCET) of a hardware/software system. Furthermore, it is critical to derive a tight upper bound on WCET in order to make efficient use of system resources.  The problem of bounding WCET is particularly difficult on modern processors. These processors use cache-based memory systems that vary memory access time based on the dynamic memory access pattern of the program. This must be accurately modeled in order to tightly bound WCET. Several analysis methods have been proposed to bound WCET on processors with instruction caches. Existing approaches either search all possible program paths, an intractable problem, or they use highly pessimistic assumptions to limit the search space. In this paper we present a more effective method for modeling instruction cache activity and computing a tight bound on WCET. The method uses an integer linear programming formulation and does not require explicit enumeration of program paths. The method is implemented in the program cinderella and we present some experimental results of this implementation.	access time;best, worst and average case;cas latency;cpu cache;central processing unit;computational complexity theory;effective method;embedded software;embedded system;flow network;integer programming;interaction;linear programming formulation;memory access pattern;memory bound function;memory management;microarchitecture;microsoft windows;motorola 68000;real-time locating system;register window;run time (program lifecycle phase);sensor;software system;systems design;worst-case complexity;worst-case execution time	Yau-Tsun Steven Li;Sharad Malik;Andrew Wolfe	1999	ACM Trans. Design Autom. Electr. Syst.	10.1145/315773.315778	embedded system;parallel computing;real-time computing;embedded software;computer science;operating system;digital signal processing;distributed computing;upper and lower bounds;programming language;code generation;software system;worst-case execution time;systems design	EDA	-7.303305882078985	60.832201005194634	34562
348b162ff66096e88f5c878c32bce007ee08bc05	deadline-aware advance reservation scheduling algorithms for media production networks	video streaming;advance bandwidth reservation;deadline aware scheduling;time;multicommodity;ibcn;media production network;technology and engineering;flow problems	In the media production process a substrate network can be shared by many users simultaneously when different media actors are geographically distributed. This allows sophisticated media productions involving numerous producers to be concurrently created and transferred. Due to the predictable nature of media transfers, the collaboration among different actors could be significantly improved by deploying an efficient advance reservation system. In this paper, we propose a model for the advance bandwidth reservation problem, which takes the specific characteristics of media production networks into account. Flexible and time variable bandwidth reservations, meeting delivery deadlines, supporting splittable flows and interdependent transfers and all types of advance reservation requests imposed by the media production transfers are incorporated into this model. In addition to the optimal scheduling algorithms, which are presented based on this model, near optimal alternatives are also proposed. The experimental results show that the proposed algorithms are scalable in terms of physical topology and granularity of time intervals and obtain a satisfactory performance, executing significantly faster than an optimal algorithm and within 8.78% of the optimal results.	algorithm;scheduling (computing)	Maryam Barshan;Hendrik Moens;Jeroen Famaey;Filip De Turck	2016	Computer Communications	10.1016/j.comcom.2015.10.016	real-time computing;computer science;distributed computing;computer network	Networks	-17.5564834518507	65.83051873526517	34569
1bee72d952a1c2a0bab63b628a95d546c82bc774	a reliable-adaptive scheduler for computational grids with failure recovery and rescheduling mechanisms	tiempo respuesta;dynamic programming;distributed system;algoritmo paralelo;grafo aciclico;metodo adaptativo;programacion dinamica;systeme reparti;parallel algorithm;digraph;agent mobile;resource allocation;ags;mobile agents;adaptive grid scheduling;agente movil;resource management;distributed computing;digrafo;response time;graphe acyclique;methode adaptative;acyclic graph;algorithme parallele;temps reponse;grid;gestion recursos;sistema repartido;monitoring;rejilla;scheduling;directed graph;robustesse;grid resource monitoring;decouverte connaissance;adaptive method;graphe oriente;programmation dynamique;grille;gestion ressources;calculo repartido;descubrimiento conocimiento;robustness;grafo orientado;computational grids;asignacion recurso;monitorage;rescheduling;mobile agent;allocation ressource;monitoreo;failure recovery;grid computing;calcul reparti;ordonnancement;reglamento;robustez;knowledge discovery;resource failures;digraphe	Computational grids (CGs) have become an attractive research area as they suggest a suitable environment for developing large scale parallel applications. CGs integrate a large amount of distributed heterogeneous resources into a single powerful platform. However, to make good use of CGs, grid resources should be scheduled efficiently. Various scheduling strategies have been introduced, including static and dynamic behaviours. The former maps tasks to resources at submission time, while the latter operates at schedule time. While static scheduling is unsuitable for the dynamic grid environment, scheduling in CGs is still more complex than the proposed dynamic ones. This paper introduces a decentralised adaptive grid scheduler (AGS) based on a novel rescheduling mechanism. AGS has several salient properties as it is: hybrid, adaptive, decentralised, and efficient. AGS is also robust as it has the ability to: 1) detect resource failures; 2) continue its functionality in spite of the failure existence; 3) recover back as soon as possible. Moreover, it integrates both static and dynamic scheduling behaviours. An initial static scheduling map is proposed for an input directed acyclic graph (DAG). However, DAG tasks may be rescheduled if the hosting resources' performance changes in a way that affects the tasks' response time. AGS tries to overcome drawbacks of traditional schedulers by utilising the mobile agent unique features to enhance the resource discovery and monitoring processes. Experimental results have shown that AGS outperforms traditional grid schedulers as it introduces a better scheduling efficiency.	scheduling (computing)	Amany M. Sarhan;Ahmed I. Saleh;Amr M. Hamed	2011	IJGUC	10.1504/IJGUC.2011.039981	real-time computing;simulation;directed graph;computer science;resource management;operating system;distributed computing	HPC	-11.044402829039429	69.20159762626704	34626
be92fcfa4f638d31dae7f1cf7f735e7ff8a2e09c	putting intelligence in the network edge through nfv and cloud computing: the sesame approach		The core challenges in the actual SESAME EU-funded project is to develop an ecosystem to sustain network infrastructure openness, built on the pillars of network functions virtualization (NFV), mobile-edge computing (MEC) capabilities and cognitive network management that will provide multi-tenancy and flexible cloud-network interaction with highly-predictable and flexible end-to-end performance characteristics. Based on this aspect, we discuss the potential benefits of including NFV and MEC in a modern mobile communications infrastructure, through Small Cells coordination and virtualization, also focused upon realistic 5G-oriented considerations. Within the proposed SESAME architecture, we also assess the various advantages coming from a more enhanced network operation and management of resources, as it appears with the incorporation of cognitive capabilities embracing knowledge and intelligence.	cloud computing;cognitive network;ecosystem;edge computing;end-to-end principle;multitenancy;network function virtualization;openness;serial digital video out;sesame	Ioannis P. Chochliouros;Anastasia S. Spiliopoulou;Alexandros Kostopoulos;Maria Belesioti;Evangelos Sfakianakis;Philippos Georgantas;Eirini Vasilaki;Ioannis Neokosmidis;Theodoros Rokkas;Athanassios Dardamanis	2017		10.1007/978-3-319-65172-9_59	virtualization;edge device;distributed computing;architecture;cloud computing;simulation;network functions virtualization;mobile telephony;cognition;cognitive network;computer science	Metrics	-15.080987560603512	86.10300796209582	34644
63f892eae8341bb8be82e1f36418631b0abfb74c	a multimessage capacity region for undirected ring networks	multicast communication;capacity region;clocks;routing;ring network;nickel;trees mathematics multicast communication set theory telecommunication network routing telecommunication network topology;progressive d separating edge set bound multimessage capacity region undirected ring network japanese theorem multiple multicast session minimal length routing tree;optical fiber networks;usa councils;set theory;trees mathematics;distance measurement;telecommunication network routing;telecommunication network topology;encoding;routing unicast broadcasting telecommunication network reliability communication systems real time systems optical fiber communication communication networks metropolitan area networks wide area networks	We develop an extension of the Japanese theorem to multiple multicast sessions and interpret the result in terms of the collection of minimal length routing trees for the various multicast sessions. We use this result as a step in providing the capacity region for multiple unicast and broadcast sessions on an undirected ring network via a simple characterization of the family of bounds needed. We further demonstrate that routing is rate-optimal using new extensions to progressive d-separating edge set bounds.	graph (discrete mathematics);multicast;ring network;routing;unicast	S. M. Sadegh Tabatabaei Yazdi;Serap A. Savari;Farzad Farnoud;Gerhard Kramer	2007	2007 IEEE International Symposium on Information Theory	10.1109/ISIT.2007.4557369	nickel;ring network;routing;telecommunications;computer science;mathematics;distributed computing;encoding;computer network;set theory	Arch	-5.806152412960628	79.62333492803096	34693
3d0e3f62fd54dbb1151f61fd21f21b6f2edb3364	energy efficient virtual network embedding for green data centers using data center topology and future migration	virtual network embedding;energy efficient;green networks	We formulate energy efficient virtual network embedding that incorporates energy costs of operation and migration for nodes and links.We prove the NP-hardness of the problem and develop a heuristic algorithm to minimize the energy consumption.We consider a practical intra-DC architecture to further improve energy efficiency.We conduct extensive evaluations and comparisons with existing algorithms to show that the proposed algorithm substantially saves energy consumption and allows high acceptance ratios. With the rapid proliferation of data centers, their energy consumption and greenhouse gas emissions have significantly increased. Some efforts have been made to control and lower energy consumption of data centers such as, proportional energy consuming hardware, dynamic provisioning, and virtualization machine techniques. However, it is still common that many servers and network resources are often underutilized, and idle servers spend a large portion of their peak power consumption.We first build a novel model of virtual network embedding in order to minimize energy usage in data centers for both computing and network resources by taking practical factors into consideration. Due to the NP-hardness of the proposed model, we develop a heuristic algorithm for virtual network scheduling and mapping. In doing so, we specifically take the expected energy consumption at different times, virtual network operation and future migration costs, and a data center architecture into consideration. Our extensive evaluation results show that our algorithm could reduce energy consumption up to 40% and take up to a 57% higher number of virtual network requests over other existing virtual mapping schemes.	data center	Xinjie Guan;Baek-Young Choi;Sejun Song	2015	Computer Communications	10.1016/j.comcom.2015.05.003	real-time computing;simulation;computer science;operating system;distributed computing;efficient energy use;computer network	Networks	-20.730461760840218	63.06910202839463	34761
d3c4051be6816f429c8ed4c4c8214b14b16a241b	explicit coordination to prevent congestion in data center networks	virtualization;ethernet;data center;congestion	Large cluster-based cloud computing platforms increasingly use commodity Ethernet technologies, such as Gigabit Ethernet, 10GigE, and Fibre Channel over Ethernet (FCoE), for intra-cluster communication. Traffic congestion can become a performance concern in the Ethernet due to consolidation of data, storage, and control traffic over a common layer-2 fabric, as well as consolidation of multiple virtual machines (VMs) over less physical hardware. Even as networking vendors race to develop switch-level hardware support for congestion management, we make the case that virtualization has opened up a complementary set of opportunities to reduce or even eliminate network congestion in cloud computing clusters. We present the design, implementation, and evaluation of a system called XCo, that performs explicit coordination of network transmissions over a shared Ethernet fabric to proactively prevent network congestion. XCo is a software-only distributed solution executing only in the end-nodes. A central controller uses explicit permissions to temporally separate (at millisecond granularity) the transmissions from competing senders through congested links. XCo is fully transparent to applications, presently deployable, and independent of any switch-level hardware support. We present a detailed evaluation of our XCo prototype across a number of network congestion scenarios, and demonstrate that XCo significantly improves network performance during periods of congestion. We also evaluate the behavior of XCo for large topologies using NS3 simulations.	cloud computing;data center bridging;disk controller;fault tolerance;fibre channel over ethernet;gigabit;network congestion;network performance;network switch;prototype;semiconductor consolidation;simulation;temporal logic;virtual machine	Vijay Shankar Rajanna;Anand Jahagirdar;Smit Shah;Kartik Gopalan	2011	Cluster Computing	10.1007/s10586-011-0156-9	embedded system;data center;parallel computing;real-time computing;virtualization;synchronous ethernet;ethernet flow control;computer science;ata over ethernet;operating system;carrier ethernet;ethernet;ethernet over pdh;slow-start;computer network	HPC	-14.004988956705386	80.56075552781883	34772
43e69c65a3b4890e5ce41acdc786ff565bb47f09	caching and replacement of streaming objects based on a popularity function			cache (computing)	T. S. B. Sudarshan;Thyagarajan Ganesh;G. Raghurama	2005			computer network;popularity;computer science	DB	-18.061865841237147	73.22514961578538	34773
9d8c359bacfb0d07735f8894c708f4b01df1b281	on the disk layout for periodical video broadcast services	disk scheduling;video broadcasting;quality of service;data placement	In this paper, we base on region-based disk layout and propose a data placement technique and its associated disk scheduling policy for providing periodical video broadcast services. We present a quantitative study and design algorithms, while still maintain the quality of service, for (1) placing video data on disk, and (2) simultaneously serving of maximum number of broadcast channels with minimal data buffer. By an example evaluation, we demonstrate the advantage of our design.		Meng-Huang Lee	2004		10.1007/978-3-540-30541-5_72	real-time computing;quality of service;computer science;operating system;distributed computing;i/o scheduling;computer network	HCI	-15.130155837657934	70.72946752400524	34799
e9183e553eb460c0bb6a394809b6fa817af0c6d3	simulated-annealing load balancing for resource allocation in cloud environments	virtual machine;simulated annealing algorithm;virtual machines cloud computing computer centres contracts power aware computing resource allocation scheduling simulated annealing;load balancing cloud computing virtual machine simulated annealing algorithm;load balancing;cloud computing environment resource allocation cloud service providers vm energy cost reduction data center physical machine sla simulated annealing load balancing algorithm resource scheduling problem;cloud computing;load management clouds resource management cloud computing servers simulated annealing computational modeling	Recently, the development of cloud computing has received considerable attention. For cloud service providers, packing VMs onto a small number of servers is an effective way to reduce energy costs, so as to improve the efficiency of the data center. However allocating too many VMs on a physical machine may cause some hot spots which violate the SLA of applications. Load balancing of the entire system is hence needed to guarantee the SLA. In this paper, we present a simulated-annealing load balancing algorithm for solving the resource allocation and scheduling problem in a cloud computing environment. Experimental results show that this method is able to achieve load balancing, and performs better than the round robin and basic simulated-annealing algorithms.	algorithm;cpu cache;central processing unit;cloud computing;cloudsim;data center;disk space;load balancing (computing);round-robin scheduling;scheduling (computing);service-level agreement;set packing;simulated annealing	Zongqin Fan;Hong Shen;Yanbo Wu;Yidong Li	2013	2013 International Conference on Parallel and Distributed Computing, Applications and Technologies	10.1109/PDCAT.2013.7	network load balancing services;parallel computing;real-time computing;simulated annealing;cloud computing;computer science;virtual machine;load balancing;operating system;cloud testing;distributed computing	HPC	-19.859941983999626	63.25474110870888	34810
384549fa0ba78a9849897514cf8d121f8fd09861	a dynamic task scheduling method for multiprocessor system	processing element;multiprocessor systems;round robin;load balance;task scheduling;high throughput;dynamic scheduling	Eecauseof itspracticalworking environment requirement, dynamic task scheduling methods meet a wide range of applications for task scheduling on a multiprocessor system. However, extra load balancing messages of these methods may seriously affect the system @ormance. Round Robin dynamic task scheduling methcds is an extension of tbe traditional RR task scheduling method. It does not produce any load balancing messages. Active tasks ars executed by different PEa in a rotation. Such rotational execution mmida the generation of any idle PEa. The RR method does not require the task migration either. The rotational task execution make tasks available to all the PE?a.These features of RR scheduling method can drastically reduce the extra burden often incurred by other dynamic task scheduling methcxls while adjusting tbe PE loads.	load balancing (computing);multiprocessing;rapid refresh;round-robin scheduling;scheduling (computing)	Ming-fang Wang	1992		10.1145/130069.130097	fair-share scheduling;fixed-priority pre-emptive scheduling;parallel computing;real-time computing;earliest deadline first scheduling;flow shop scheduling;dynamic priority scheduling;rate-monotonic scheduling;two-level scheduling;deadline-monotonic scheduling;distributed computing;round-robin scheduling;multiprocessor scheduling	HPC	-14.82174007963699	60.69183570838064	34849
123b865b307645e97e264e68c83ae25a7b35619c	principles of delay-sensitive multimedia data storage retrieval	theoretical framework;delay sensitive;continuous media;real time;video retrieval;data type;satisfiability;multimedia systems;multimedia data;data retrieval;time constraint	This paper establishes some fundamental principles for the retrieval and storage of delay-sensitive multimedia data. Delay-sensitive data include digital audio, animations, and video. Retrieval of these data types from secondary storage has to satisfy certain time constraints in order to be acceptable to the user. The presentation is based on digital audio in order to provide intuition to the reader, although the results are applicable to all delay-sensitive data. A theoretical framework is developed for the real-time requirements of digital audio playback. We show how to describe these requirements in terms of the consumption rate of the audio data and the nature of the data-retrieval rate from secondary storage. Making use of this framework, bounds are derived for buffer space requirements for certain common retrieval scenarios. Storage placement strategies for multichannel synchronized data are then categorized and examined. The results presented in this paper are basic to any playback of delay-sensitive data and should assist the multimedia system designer in estimating hardware requirements and in evaluating possible design choices.	acm transactions on information systems;algorithm;auxiliary memory;block size (cryptography);categorization;computer data storage;data buffer;database;digital-to-analog converter;disk sector;fragmentation (computing);hard disk drive performance characteristics;headroom (audio signal processing);portable storage device;real-time clock;real-time computing;real-time transcription;requirement;systems design;translation lookaside buffer	Jim Gemmell;Stavros Christodoulakis	1992	ACM Trans. Inf. Syst.	10.1145/128756.128758	data type;computer science;theoretical computer science;operating system;database;multimedia;programming language;world wide web;data retrieval;information retrieval;satisfiability	DB	-14.764907465789578	70.06465004843658	34891
64e6e8d97890ddf047ab7200abe75772240dc3f9	towards peer-to-peer content indexing	distributed application;distributed system;concepcion sistema;distributed hash table;llave investigacion;localizacion objeto;object location;byzantine agreement;peer to peer system;hot spot;information sharing;unknown network;indexing;system design;dual failure mode;indexation;fault tolerance;partage information;indizacion;search key;identificateur;load balance;application repartie;cle recherche;peer to peer;localisation objet;conception systeme;identificador;identifier	Distributed Hash Tables are the core technology on a significant share of system designs for Peer-to-Peer information sharing. Typically, a location mechanism is provided and object identifiers act as keys in the index of object locations. When introducing a search mechanism, where single words are used as keys, the key image cardinality will be driven by the word popularity and most of the present designs will be unable to load balance the index among the nodes. We present two contributions: A design that allows participating nodes to load balance the indexing of popular keys and avoid content hot-spots on single nodes; A distributed mechanism for probabilistic filtering of popular keys (with low search relevance) that paves the way for scalable full content indexing.	distributed hash table;identifier;load balancing (computing);peer-to-peer;relevance;scalability	Carlos Baquero;Nuno Lopes	2003	Operating Systems Review	10.1145/958965.958974	search engine indexing;fault tolerance;identifier;computer science;chord;load balancing;operating system;database;distributed computing;world wide web;computer security;hot spot;systems design	Web+IR	-11.298657520939479	70.51355857048961	34984
a75a9c965931fc2d35d2a5038df5a1718623c730	a data storage mechanism for p2p vod based on multi-channel overlay	p2p;satisfiability;data storage;single channel;video on demand	It is a big challenge to provide Video-on-Demand streaming services over Internet in a scalable way. Currently, many researchers use a single channel overlay to implement the scalability of on-demand streaming services. However, in a real application environment, various channels in a P2P VOD system have different popularities, which probably cause the imbalance of data storage-capability of the whole system. It results in a problem that a mass of unpopular channels’ caching capability can not be used to satisfy the data requirements of the whole system. In order to solve the problem, this paper proposes a new data-storage mechanism, which constructs a multi-channel overlay to optimize the whole system’s caching-capability and greatly improves unpopular channel’s caching efficiency. The experimental results show that this mechanism can achieve significant effects.	cache (computing);computer data storage;data store;internet;mathematical optimization;requirement;scalability;versant object database	Xiaofei Liao;Hao Wang;Song Wu;Hai Jin	2008		10.1007/978-3-540-88140-7_12	computer science;operating system;peer-to-peer;computer data storage;database;world wide web;computer network;satisfiability	OS	-16.611975970834283	73.4958797281023	35011
7b0a7e247cc1d69a5e004de8e62b50f4631ac254	decentralized replication algorithms for improving file availability in p2p networks	p2p system;content distribution network;optimisation;random algorithm;partitioning algorithms peer to peer computing availability resource management application software ip networks heuristic algorithms collaboration internet multicast algorithms;peer to peer systems;resource allocation;search algorithm;p2p;greedy algorithms;group partition algorithm;partial information;peer to peer system;system level file availability;optimization problem;greedy search algorithm;cooperative resource allocation algorithms;heuristic algorithms;search problems greedy algorithms optimisation peer to peer computing resource allocation;system level file availability decentralized replication algorithms p2p networks peer to peer systems content distribution networks partial information cooperative resource allocation algorithms decentralized algorithms replication problem optimization problem heuristic algorithms random algorithm group partition algorithm greedy search algorithm;decentralized algorithms;content distribution networks;randomized algorithm;decentralized replication algorithms;search problems;p2p networks;peer to peer computing;replication problem;heuristic algorithm	Being autonomous and scalable, peer-to-peer systems provide a paradigm for sharing files in the Internet. However, different from conventional structured replication systems like content distribution networks (CDN), peers in an unstructured P2P system may have different, sometimes low, online availability, and usually get only partial information about the resources of the system. Therefore, how to achieve good system level file availability by autonomous peers is an important goal in P2P replication systems. In this paper, we investigate decentralized and cooperative resource allocation algorithms in a class of P2P systems that provide replication service. We formulate this replication problem as an optimization problem, and propose several heuristic algorithms respectively. They include (a) a random algorithm, (b) a group partition algorithm that relies on peers' forming groups, and (c) a greedy search algorithm based on an estimated system-level file availability target. We compare and evaluate these algorithms by simulations, and observe that each of them has advantages depending on the system parameters.	autonomous robot;content delivery network;digital distribution;emoticon;greedy algorithm;heuristic;internet;mathematical optimization;memory management;optimization problem;peer-to-peer;programming paradigm;randomized algorithm;scalability;search algorithm;simulation	W. K. Lin;Chen Ye;D. M. Chiu	2007	2007 Fifteenth IEEE International Workshop on Quality of Service	10.1109/IWQOS.2007.376545	greedy algorithm;real-time computing;computer science;theoretical computer science;distributed computing;randomized algorithm;replication	Metrics	-12.86779164929936	73.0162883278884	35075
81e5b717f3444583f17d96ce925fe3ad01cfcecc	the impact of large flows in content centric networks	cache storage;limiting electronic mail degradation bandwidth time factors educational institutions computer science;mathematical analysis;cache hit ratio degradation content centric networks ccn routers content cache mathematical analysis;mathematical analysis cache storage	This paper investigates the impact of large flows in Content Centric Networks (CCN). In CCN, routers have caches, and store all the data after forwarding. If large flows temporarily occupy a content cache, they may evict popular chunks from the cache, and it results in low cache hit ratio. We mathematically analyzed the amount of occupancy of a large flow in a cache, and realized that a few large flows can constitute a significant portion of a cache. Our simulation results showed that small flows experience cache hit ratio degradation as the number of large flows increases. Finally, we present that limiting the occupancy of large flows in a cache can effectively improve the cache hit ratios for small flows.	cpu cache;cache (computing);cyclomatic complexity;elegant degradation;hit (internet);router (computing);simulation	Younghoon Kim;Yusung Kim;Ikjun Yeom	2013	2013 21st IEEE International Conference on Network Protocols (ICNP)	10.1109/ICNP.2013.6733619	bus sniffing;pipeline burst cache;parallel computing;real-time computing;cache coloring;page cache;cache;computer science;cache invalidation;operating system;smart cache;cache algorithms;cache pollution;world wide web;computer network	HPC	-15.188958244203826	74.62886880729174	35078
5652481a3cd4e1e7df148bb5d956bc2a55b403c4	deadlock- and livelock-free packet switching networks	packet switched	A controller for a packet switching network is an algorithm to control the flow of packets through the network. A local controller is a controller executed independently by each node in the network, using only local information available to these nodes. A controller is deadlock- and livelock-free if it guarantees that every packet in the network reaches its destination within a finite amount of time. We present a local controller which is proved to be deadlock- and livelock-free.	algorithm;controller (computing);deadlock;network packet;network switch;packet switching	Sam Toueg	1980		10.1145/800141.804656	real-time computing;packet analyzer;fast packet switching;computer science;processing delay;network scheduler;rate limiting;end-to-end delay;mathematics;distributed computing;transmission delay;packet switch;burst switching;circuit switching;computer network	Theory	-5.2725918473611175	87.76490340404244	35137
2e34dce5696aa56976d975bac3f2a0c1d282ca8d	wireless protocol design for a cooperative pedestrian protection system	data transmission;network simulation;time of flight;localization;protocol design;secondary surveillance radar;traffic safety;network simulator;system design;angle of arrival;next generation;link layer;vru esafety;driver assistance system	In the research project Ko-TAG, which is part of the research initiative Ko-FAS, cooperative sensor technology is developed and its benefit for traffic safety applications is evaluated. As a result the new sensor concept shall provide essential input data for next generation driver assistant systems. A secondary radar principle based on communication signals enables localization of objects with simultaneous data transmission. It mainly concentrates on pedestrian and other vulnerable road user (VRU) detection.#R##N##R##N#This paper describes the architectural approach of the system design, as well as the main characteristics of the physical and data link layers of the proposed wireless protocol. The protocol is designed in such a way that it can be used as an extension to IEEE802.11p/WAVE protocol. The complete protocol is modeled in OPNET network simulator.		Dirk Lill;Manuel Schappacher;Shahidul Islam;Axel Sikora	2011		10.1007/978-3-642-19786-4_11	embedded system;simulation;telecommunications;engineering	EDA	-7.572193792786276	75.1914784426416	35197
51d52f363aac5b6ca45b794dbf72fe3d206b9c7e	software defined enterprise passive optical network	passive optical network key flow control dynamic control sden design software defined edge network software defined paradigm dynamic network control mobile computing cloud computing pon;telecommunication congestion control cloud computing mobile computing passive optical networks software defined networking;passive optical networks ports computers portable computers games optical switches bandwidth mobile communication	In the last few years, changing infrastructure and business requirements are forcing enterprises to rethink their networks. Enterprises look to passive optical networks (PON) for increased network efficiency, flexibility, and cost reduction. At the same time, the emergence of Cloud and mobile in enterprise networks calls for dynamic network control and management following a centralized and software-defined paradigm. In this context, we propose a software-defined edge network (SDEN) design that operates on top of PON. SDEN leverages PON benefits while overcoming its lack of dynamic control. This paper is a work-in-progress focusing on enabling key flow control functions over PON: dynamic traffic steering, service dimensioning and realtime re-dimensioning. We also discuss how SDEN edge network can integrate with core SDN solutions to achieve end-to-end manageability. Through case experiment studies conducted on a live PON testbed deployment, we show the practical benefits and potentials that SDEN can offer to enterprise networks redesign.	business requirements;centralized computing;cloud computing;control function (econometrics);emergence;end-to-end principle;experiment;openflow;passive optical network;programming paradigm;requirement;software deployment;software-defined networking;testbed	Ahmed Amokrane;Jinho Hwang;Jin Xiao;Nikos Anerousis	2014	10th International Conference on Network and Service Management (CNSM) and Workshop	10.1109/CNSM.2014.7014203	real-time computing;operating system;distributed computing;computer security;computer network	Mobile	-15.14722620519967	85.03924050636152	35285
33cfcebb0b4e1d716054c33587e07800b9e96606	using libnetvirt to control the virtual network	switches packet loss delays virtualization conferences;virtualisation ip networks public domain software software libraries;computer virtualization virtual network control network virtualization abstraction architecture node representation model libnetvirt unified interface openflow enabled network flow setup time system behavior denial of service attack packet losses udp flow rate;software libraries;communication systems;public domain software;kommunikationssystem;ip networks;virtualisation	LibNetVirt proposes an architecture for a network virtualization abstraction using the single node representation model. LibNetVirt is deployed as a library, similar to libvirt in computer virtualization, with a unified interface towards the underlying network specific drivers. The architecture allows management tools to be independent of the underlying technologies. In addition, it enables programmable and on-demand creation of virtual networks. We have evaluated libNetVirt in an OpenFlow-enabled network in three different tests: the setup time of a flow, the behavior of the system under a Denial of Service attack and the packet losses in high rate UDP flows.	application programming interface;centralized computing;computer programming;dos;denial-of-service attack;flip-flop (electronics);network congestion;network packet;open-source software;openflow;libvirt	Daniel Turull;Markus Hidell;Peter Sjödin	2012	2012 IEEE 1st International Conference on Cloud Networking (CLOUDNET)	10.1109/CloudNet.2012.6483670	full virtualization;real-time computing;virtualization;computer science;virtual machine;distributed computing;service virtualization;computer network	Networks	-15.646750780765805	82.68150618612931	35320
026c74a261af300de66e1545d13da7b14cdb70cd	response time analysis of asynchronous real-time systems	real time;asynchronous systems;response time analysis;schedulability analysis;asynchronous system;hard real time system;periodic tasks;idle time;worst case response time analysis;weakly hard;process model;priority ceiling protocol;worst case response time;real time systems	In asynchronous real-time systems the time when all events occur can not be predicted beforehand. Systems with sporadic tasks, or that operate a protocol for sharing resources like the priority ceiling protocol, for example, are asynchronous real-time systems. In this paper, we present a sufficient and efficient response time based analysis technique for computing R i(k), the worst case response time at each invocation k of the periodic tasks of real-time asynchronous systems. In addition, efficient idle time computation for asynchronous systems is presented. This analysis technique can be applied to the analysis of several process models including weakly hard real-time systems, and slack management techniques like aperiodic servers and slack stealing algorithms. It is also shown that the pattern of response times of tasks in a hyperperiod is pseudoperiodic and that the maximum response time instants tend to occur evenly separated within the hyperperiod.	algorithm;asynchronous system;best, worst and average case;computation;priority ceiling protocol;real-time clock;real-time computing;real-time operating system;real-time transcription;response time (technology);responsiveness;slack variable	Guillem Bernat	2003	Real-Time Systems	10.1023/A:1025115923862	asynchronous system;embedded system;real-time computing;computer science;process modeling;distributed computing;asynchronous operation;priority ceiling protocol	Embedded	-10.090375764302358	60.45625553011378	35444
19a97a686faec68da19e239b7a047425da8a719c	motivating human-enabled mobile participation for data offloading		The exploding popularity of mobile devices enables people to enjoy benefits brought by various interesting mobile apps. However, the ever-increasing data traffic has exacerbated the congestion on current cellular networks, which results in users’ dissatisfaction, especially in crowded areas. Hence, how to alleviate data traffic in cellular networks becomes a challenging problem. Traditional methods rely on mobile offloading techniques to deviate the data traffic originally targeted to cellular networks, such as the small cell, Wi-Fi, and opportunistic communication. Unfortunately, mobile users still experience severe congestion when a large number of users request for data. Facing these challenges, we introduce the concept of mobile participation to assist data offloading by leveraging the mobility of users and the social features among a group of users. A mobile caching user, who pre-caches a certain amount of contents, will roam around congested areas to participate in content dissemination in order to satisfy users’ requests, which is expected to benefit both himself and users in the crowd simultaneously. To motivate such human-enabled mobile participation for data offloading, a Stackelberg game is deployed with joint considerations on social effect and delay effect. Based on detailed performance analysis, we demonstrate the feasibility and efficiency of the proposed approach.	mass effect trilogy;mobile app;mobile device;network congestion;profiling (computer programming)	Xiaonan Zhang;Linke Guo;Ming Li;Yuguang Fang	2018	IEEE Transactions on Mobile Computing	10.1109/TMC.2017.2773087	computer network;distributed computing;stackelberg competition;computer science;mobile computing;mobile device;popularity;cellular network	Mobile	-22.268098597877177	75.7069090561669	35456
e11e0fa2343667a9fba2d188dd41598636e659fb	paste: network stacks must integrate with nvmm abstractions	random graph;clos networks;convertible data center	This paper argues that the lack of explicit support for non-volatile main memory (NVMM) in network stacks fundamentally limits application performance. NVMM devices have been integrated into general-purpose OSes by providing familiar file-based interfaces and efficient byte-granularity access by bypassing page caches. However, this powerful property cannot be fully utilized unless network stacks also support it and applications exploit such support. This requires a thoroughly new network stack design, including low-level buffer management and APIs. We propose such a new network stack architecture to support NVMM and demonstrate its advantages for efficient write-ahead logging, a popular technique to implement transactions.	application programming interface;byte;computer data storage;general-purpose markup language;high- and low-level;non-volatile memory;paste;protocol stack;stack machine;write-ahead logging	Michio Honda;Lars Eggert;Douglas Santry	2016		10.1145/3005745.3005761	random graph;combinatorics;parallel computing;real-time computing;telecommunications;computer science;operating system;computer security;computer network	Arch	-15.423326649275522	80.36172878654162	35463
572ee4db3d10c2841c162a1c151c28bcd368adcb	tossing nosql-databases out to public clouds	databases;random access memory;look ahead optimization;sla violations nosql databases public clouds cloud service providers csp private cloud cloud applications cost aware resource provisioning algorithm quality of service qos requirements look ahead optimization heterogeneous multicloud environment;resource provisioning;look ahead optimization resource provisioning nosqldatabases;nosql databases;predictive models;optimization;sql cloud computing database management systems;throughput random access memory cloud computing delays databases predictive models optimization;delays;cloud computing;throughput	Cloud-Service Providers (CSPs) can now handle heavy workloads by occasionally renting resources from public clouds. The capabilities and respective lease prices of such infrastructure may significantly vary over time. In this environment, two distinct types of SLAs have to work in tandem: a) the SLA furnished by the private cloud to the end user of the application (or database), and b) the SLA offered by the public cloud to the application through its host private cloud. This dual and continuously evolving relationship inherently complicates the computation of the operation of cloud applications. In this paper, we present a cost-aware resource provisioning algorithm for No SQL-databases that aims to meet Quality of Service (QoS) requirements while minimizing the total cost incurred by its deployment on multiple cloud tiers. Our method is based on look-ahead optimization and takes into account the costs incurred by potential database transitions to new configurations in a heterogeneous multi-cloud environment. Experimentation with a prototype shows that our approach reflects the total cost of a cloud application more accurately than the conventional technique of minimizing SLA violations. More importantly, it avoids thrashing of resources.	aggregate data;algorithm;analysis of algorithms;autoscaling;cloud computing;computation;database;emoticon;experiment;image scaling;kerrison predictor;linear programming relaxation;mathematical optimization;nosql;parsing;prototype;provisioning;quality of service;requirement;sql;service-level agreement;software as a service;software deployment;thrashing (computer science)	Alexandros Antoniadis;Yannis Gerbessiotis;Mema Roussopoulos;Alex Delis	2014	2014 IEEE/ACM 7th International Conference on Utility and Cloud Computing	10.1109/UCC.2014.31	throughput;cloud computing;computer science;operating system;database;distributed computing;predictive modelling;world wide web	HPC	-22.370624693135944	63.37753652412936	35468
f3f372b0ab25ee0f54c5b0a13cc97509df855841	a case study of a wdm agent	software;information model;software prototyping;optical filters;prototypes;telecommunication computing;multiplexing equipment;software wdm agent photonic network elements optical add drop multiplexer optical cross connect information model alcatel;bit rate;optical switches;computer aided software engineering wavelength division multiplexing optical add drop multiplexers optical filters prototypes optical sensors software prototyping hardware bit rate wdm networks;software agents;optical fibre networks;computer aided software engineering;optical cross connect;wdm networks;optical add drop multiplexers;optical sensors;wdm agent;optical add drop multiplexer;alcatel;hardware;optical switches wavelength division multiplexing software agents telecommunication computing multiplexing equipment optical fibre networks;wavelength division multiplexing;photonic network elements	This paper presents a case study of the development of a WDM Agent for the control of two prototype photonic network elements, an Optical Add/Drop Multiplexer and an Optical Cross-Connect. Even though the hardware developed for these prototypes is too small for a commercial device, the software is fully featured, and with modifications, could support devices of many times the complexity of the prototypes. The agent is developed using a WDM information model developed at Alcatel, and support two kinds of protection.	digital cross connect system;information model;multiplexer;optical cross-connect;prototype;wavelength-division multiplexing	Hal Badt;Luc Jousset;Xavier Letellier;Vincent Vinit;Christophe Drion	1999		10.1109/INM.1999.770702	telecommunications;information model;computer science;software agent;optical add-drop multiplexer;optical filter;prototype;optical switch;computer-aided software engineering;wavelength-division multiplexing;optical cross-connect;computer network	HCI	-19.723555448787305	88.38110870897229	35481
d28c72bc67646d024fb20273e18945fcb54acec6	label switched path restoration under two random failures	protection multiprotocol label switching routing bandwidth tellurium switches radio access networks telecommunication switching automatic control communication system traffic control;telecommunication network reliability;qos guarantee;packet switching;double simultaneous link failure protection label switched path restoration random failures qos guaranteed tunnels single link failure protection performance evaluation bandwidth reservation alternate paths primary paths backup paths maximum sharing schemes;telecommunication network reliability packet switching telecommunication network routing quality of service;telecommunication network routing;link failure;quality of service;label switched path	Routing of QoS guaranteed tunnels with failure protection requires bandwidth reservation along both primary and alternate paths. By judicious selection of alternate paths, a significant amount of resilient bandwidth can be shared among backup paths. This paper presents maximum sharing schemes for alternate paths that protect against single as well as double simultaneous link failures in the network.	circuit restoration;multiprotocol label switching	Gargi Banerjee;Deepinder P. Sidhu	2001		10.1109/GLOCOM.2001.965074	routing;quality of service;telecommunications;computer science;label switching;distributed computing;packet switching;computer network	Crypto	-7.48008519937454	82.85018384984797	35490
869a9be414b6584ad43a5a1e1e371d2d1cfc7f05	a load balancing algorithm in multi-tenancy environment	multi tenancy;load balancing;cloud computing	"""Multi-tenancy brings new challenges to load balancing, since it incurs resource competition and different QoS requirements of hosted applications. Therefore, servers with multiple deployed applications need a proper request scheduling policy to guarantee their quality of service, e.g., response time. However, when under heavy loads, mean response time of some applications may become too high to be acceptable due to the mutual intervention among tenants. In this work, we propose a new load balancing algorithm, """"Server Throughput Restriction(STR)"""", based on M/G/s/s+r queueing model, in order to guarantee each application's mean response time."""	algorithm;load balancing (computing);multitenancy;quality of service;queueing theory;requirement;response time (technology);scheduling (computing);throughput	Tao Zhao;Hailong Sun;Yu Tang;Xudong Liu	2013		10.1145/2541614.2541631	round-robin dns;network load balancing services;real-time computing;computer science;load balancing;operating system;distributed computing	Metrics	-22.687129161118104	62.32611273433097	35577
8276d6eb8ea6bfc69af8c4fc2aaf79c97086b592	on-line load balancing with task buffer			load balancing (computing)	Jiayin Wei;Daoyun Xu;Yongbin Qin;Ruizhang Huang	2017	Computing and Informatics		theoretical computer science;computer science;distributed computing;load balancing (computing)	HPC	-11.664574220358043	62.58817214320939	35596
99175600234fb0b8db4f50db8162df4182fe82a5	o-mi/o-df vs. mqtt: a performance analysis		Over the past decade, a flourishing number of concepts and architectural shifts appeared such as Industrial Internet of Things (IIoT), Industrial CPS or even Industry 4.0. Unfortunately, today's IoT as well as Industry 4.0 environments, look more like a collection of isolated “Intranets of Things”, also referred to as “vertical silos”, rather than a federated infrastructure. Breaking down these silos is a key challenge in both the IoT and Industry 4.0 communities. This paper is intended to present and discuss two open and standardised messaging protocols designed for IoT applications, namely: MQTT and O-MI/O-DF. First, a traffic load's analytical model derived from the MQTT standard specifications is presented. Second, a comparison study between MQTT and O-MI/O-DF standards is carried out based on a real-life industrial implementation. This study brings a deep understanding of the extent to which these protocols are performant (from a traffic load perspective) and how they can impact on future architectural designs.	direction finding;industry 4.0;internet of things;intranet;mqtt;profiling (computer programming);real life	Paul-Lou Benedick;Jérémy Robert;Yves Le Traon;Sylvain Kubler	2018	2018 IEEE Industrial Cyber-Physical Systems (ICPS)	10.1109/ICPHYS.2018.8387652	information silo;control engineering;systems engineering;quality of service;mqtt;industrial internet;engineering;internet of things	DB	-16.368063503853772	86.77667086305257	35617
1707eb5c84c4a3a39fc0995e5388625b3c8b2b5f	multimedia resource replication strategy for a pervasive peer-to-peer environment	p2p system;context aware;replication strategy;pervasive computing;p2p;user preferences;indexing terms;paradigm shift;network delay;peer to peer;peer relations	The computer world is experiencing a paradigm shift towards context-aware pervasive computing, where diverse computer devices communicate with each other through different network access technologies, and allow resource access based on user preferences. P2P computing is an area which will be affected by this new trend. In this paper, we proposed a resource replication strategy for context-aware P2P computing in a pervasive environment. The replication strategy takes an active approach through using the resource request rate as the primary metric to trigger the replication process, and then adaptively replicate resources into various configuration states according to the properties of peers (i.e., terminal capabilities and user preferences) and the size of peer clusters. Also, the strategy uses peer related information stored on super peers to determine which peers should be selected to perform adaptive replications and where the resulting replicas should be stored. Simulation results show that the proposed strategy reduces network delays while increasing resource hit rate in comparison to commercial super peer P2P systems and random replication strategies.	access network;download;java;peer-to-peer;programming paradigm;self-replication;simulation;terminal capabilities;ubiquitous computing;user (computing)	Letian Rong	2008	JCP	10.4304/jcp.3.4.9-15	paradigm shift;simulation;index term;computer science;operating system;peer-to-peer;distributed computing;world wide web;computer security;ubiquitous computing;network delay	HPC	-16.846299456882377	70.42488772002237	35809
c6938cc1d59cbea7336a887a2e4686d7a98956f3	augustus: a ccn router for programmable networks	performance evaluation;nformation centric router;modular icn router;commodity hardware;system design;experimental evaluation;prototype	Despite the considerable attention that the ICN paradigm received so far, its deployment has been hindered by the scale of upgrades required to the existing infrastructure. Software programmable networking frameworks would constitute a remarkable opportunity for ICN as they enable fast deployment of novel technologies on commodity hardware. However, a software ICN router implementation for commodity platforms guaranteeing adequate packet processing performance is not available yet. This paper introduces Augustus, a software architecture for ICN routers, and detail two implementations, stand-alone and modular, released as open-source code. We deployed both implementations on a state-of-the-art hardware platform and analyzed their performance under different configurations. Our analysis shows that with both implementations it is possible to achieve a throughput of approximately 10 Mpps, saturating 10 Gbit/s links with packet as small as 100 bytes. However, to achieve such performance, routers must be carefully configured to fully exploit the capabilities of the hardware platforms they run on.	byte;commodity computing;cyclomatic complexity;gigabit;icn gps;network packet;open-source software;programming paradigm;router (computing);software architecture;software deployment;throughput	Davide Kirchner;Raihana Ferdous;Renato Lo Cigno;Leonardo Maccari;Massimo Gallo;Diego Perino;Lorenzo Saino	2016		10.1145/2984356.2984363	embedded system;real-time computing;telecommunications;operating system;prototype;computer security;computer network;systems design	Networks	-15.431777185835335	83.37893623802104	35836
02bb762c3bd1b3d1ad788340d8e9cdc3d85f33e1	consistent hashing and random trees: distributed caching protocols for relieving hot spots on the world wide web	packet routing;rounding theorems;randomized algorithms;randomized rounding;quorum system;approximation algorithms;random tree;hot spot;discrete ham sandwich theorems;covering integer programs;linear programming;world wide web;hash function	nodes that have working paths to the root. This lead s to the following lemma: Lemma 7.1 Suppose that d = (logN). With high probability, the fraction of abstract-tree leaves that have a working pat h to the root is (slogd C). In particular, if s = 1 O(1= logd C), this fraction is a constant. The modification to the protocol is therefore quite simple. Choose a parameter t, and simultaneously send t requests for the page. A logarithmic number if requests is sufficient to give a high probability of one of the requests goes through. This change i the protocol will of course have an impact on the system. This imp act is described in the full paper. Note that since communication is a chancy thing on the Internet, failure to get a quick response from a machine is not a par ticularly good indication that it is down. Thus, we focused o n the tolerance of faults, and not on their detection. However, gi ven some way to decide that a machine is down, our consistent hash func tions make it trivial to reassign the work to other machines. If a yo u decide a machine is down, remove it from your view. 8 Adding Time to the Model So far, we have omitted any real mention of time from our analy ses. We have instead considered and analyzed a single “batch ” of R requests, and argued that this batch causes a limited amount of caching (storage usage) at every machine, while simultaneo usly arguing that no machine gets swamped by the batch. In this secti on, we show how this static analysis carries implications for a t emporal model in which requests arrive over time. Recall that our tem poral model says that browsers issues requests at a certain rate . Time is a problematic issue when modeling the Internet, because the communication protocols for it have no guarantees r garding time of delivery. Thus any one request could take arb itrarily long. However, we can consider the rate at which serv ers receive requests. This seems like an overly simplistic meas ur , but the rate at which a machine can receive requests is in fact the s atistic that hardware manufacturers advertise. We consider an i nterval of time , and apply our “requests all come at once” analysis to the requests that come in this interval. We can write the bounds from the static analysis on R requests as follows: cache size= asR+ bs cache load= alR+ bl Suppose machines have cache size m. Consider a time interval small enough to make R = small enough so that m > asR+bs. In other words, the number of requests that arrive in this int erval is insufficient, according to our static analysis, to use stora ge exceedingm per machine. Thus once a machine caches a page during this interval, it keeps it for the remainder of the interval. Thus our static analysis will apply over this interval. This gives us a bound o how many requests can arrive in the interval. Dividing by the int erval length, we get the rate at which caches see requests: (al+ blas m bs ). Plugging in the bounds from Section 3, we get the following: Theorem 8.1 If our machines havem = (logN) storage, for some constant N , then with probability1=N , the bound on the rate of new requests per cache when we have C machines of size m is 2 logd C C +O dq m . Observe the tradeoffs implicit in this theorem. Increasing m causes the load to decrease proportionately, but never belo w ( logC=C). Increasingd increases the load linearly (but reduces the number of hops on a request path). Increasing q seems only to hurt, suggesting that we should always take q = 2. The above analysis used the rate at which requests were issue d to measure the rate at which connections are established to m achines. If we also assume that each connection lasts for a fini te duration, this immediately translates into a bound on the nu mber of connections open at a machine at any given time. 9 Conclusion This paper has focused on one particular caching problem—tha t of handling read requests on the Web. We believe the ideas hav e broader applicability. In particular, consistent hashing may be a useful tool for distributing information from name servers such as DNS and label servers such as PICS in a load-balanced and faul ttolerant fashion. Our two schemes may together provide an in teresting method for constructing multicast trees [4]. Another important way in which our ideas could be extended is in handling pages whose information changes over time, du to either server or client activity. If we augment our protocol to et the server know which machines are currently caching its page, t h n the server can notify such caches whenever the data on its pag es changes. This might work particularly well in conjunction w ith the currently under development multicastprotocols [4] that broadcast information from a server to all the client members of a multi cast “group.” Our protocol can be mapped into this model if we assu me that every machine “caching” a page joins a multicast group f r that page. Even without multicast, if each cache keeps track, for each page it caches, of the at most d other caches it has given the page to, then notification of changes can be sent down the tree to on ly the caches that have copies. It remains open how to deal with time when modeling the Internet, because the communication protocols have no guaran tees regarding time of delivery. Indeed, at the packet level, the re are not even guarantees regarding eventual delivery. This suggest s modeling the Internet as some kind of distributed system. Clearly , in a model in which there are no guarantees regarding delivery ti mes, the best one can hope to prove is some of the classical livenessand safetyproperties underlying distributed algorithms. It is not cl ear what one can prove about caching and swamping in such a model. We think that there is significant research to be done on the pr oper way to model this aspect of the Internet. We also believe that interesting open questions remain rega rding the method of consistent hashing that we present in this p aper. Among them are the following. Is there a k-universal consistent hash function that can be evaluated efficiently?? What trade offs can be achieved between spread and load? Are there some kind o f “perfect” consistent hash functions that can be constructe d deterministically with the same spread and load bounds we give? On what other theoretical problems can consistent hashing giv e us a handle? References [1] Anawat Chankhunthod, Peter Danzig, Chuck Neerdaels, Mi chael Schwartz and Kurt Worrell. A Hierarchical Internet Object C ache. In USENIX Proceedings , 1996. [2] Robert Devine. Design and Implementation of DDH: A Distr ibuted Dynamic Hashing Algorithm. InProceedings of 4th International Conference on Foundations of Data Organizations and Algorithm s, 1993. [3] M. J. Feeley, W. E. Morgan, F. P. Pighin, A. R. Karlin, H. M. Levy and C. A. Thekkath. Implementing Global Memory Management i n a Workstation Cluster. InProceedings of the 15th ACM Symposium on Operating Systems Principles , 1995. [4] Sally Floyd, Van Jacobson, Steen McCanne, Ching-Gung Li u and Lixia Zhang. A Reliable Multicast Framework for Light-weig ht Sessions and Application Level Framing, SIGCOMM'95 [5] Witold Litwin, Marie-Anne Neimat and Donovan A. Schneid r. LH -A Scalable, Distributed Data Structure. ACM Transactions Database Systems, Dec. 1996 [6] Radhika Malpani, Jacob Lorch and David Berger. Making Wo rld Wide Web Caching Servers Cooperate. In Proceedings of World Wide Web	application-layer framing;blas;cache (computing);chuck;consistent hashing;cryptographic hash function;data structure;decisional diffie–hellman assumption;distributed algorithm;distributed cache;distributed computing;framing (social sciences);ge-600 series;lh (complexity);liveness;load balancing (computing);memory management;morgan;multicast;network packet;objective-c;platform for internet content selection;sally floyd;server (computing);steen rasmussen;symposium on operating systems principles;ti-basic;ven (currency);web cache;workstation;world wide web	David R. Karger;Eric Lehman;Frank Thomson Leighton;Rina Panigrahy;Matthew S. Levine;Daniel Lewin	1997		10.1145/258533.258660	mathematical optimization;randomized rounding;combinatorics;hash function;computer science;linear programming;theoretical computer science;mathematics;distributed computing;randomized algorithm;hot spot;approximation algorithm	Theory	-13.197664611054757	67.31172751001667	35883
d209977c3386af4480cbc442913184634d71bbea	a coordination-level middleware for supporting flexible consistency in cscw	protocols;groupware;total order;collaborative application;col;single channel;cooperative streaming coordination level middleware cscw flexible consistency support highly interactive collaborative applications strong ordering protocols stream interaction capturing stream interaction delivery flexible coordination middleware partial order protocol total order protocol;protocols middleware groupware;middleware;middleware collaboration streaming media collaborative work transport protocols computer networks distributed computing multicast protocols costs application software	Highly interactive collaborative applications need to offer each user a consistent view of the interactions represented by the streams exchanged between dispersed groups of users. At the coordination level, strong ordering protocols for capturing and delivering streams' interactions (e.g. CAUSAL, TOTAL order) may be too expensive due to the variability of the network conditions. This paper builds upon previous work on expressing streams causality and proposes a flexible coordination middleware in order to integrate different delivery modes (e.g. FIFO, CAUSAL, TOTAL) into a single channel (with respect to each of these protocols). Moreover, the proposed abstract channel can handle the mix of any partial or total order protocols. We present a cooperative streaming scenario and an experimental platform for measuring the cost of combining several protocols on various network conditions and show how our coordination service can adjust the degree of synchronization according to network variations.	causality;computer-supported cooperative work;cooperative mimo;data compression;experiment;fifo (computing and electronics);fragmentation (computing);interaction;jgroups;mathematical optimization;middleware;spatial variability;synchronized multimedia integration language	Cezar Plesca;Romulus Grigoras;Philippe Quéinnec;Gérard Padiou;Jean Fanchon	2006	14th Euromicro International Conference on Parallel, Distributed, and Network-Based Processing (PDP'06)	10.1109/PDP.2006.7	communications protocol;real-time computing;computer science;operating system;middleware;database;distributed computing;total order;computer network	Robotics	-23.680210655414164	71.49292942339405	36021
0ce0220d5f03faa41e33edd06adeb0b41cdee9e0	cost efficient and performance guaranteed virtual network embedding in multicast fat-tree dcns	data center networks;fat tree;nonblocking;virtual machine migration data center networks fat tree multicast nonblocking;switches servers bandwidth computers virtual machining virtualization resource management;virtualisation computer centres embedded systems multicast communication trees mathematics virtual machines;cost saving data center networks multi rooted tree structure rich path multiplicity fat tree dcn core switch modules nonblocking capability network cost virtual network embedding schemes virtual machines multicast capable virtual network mvn vm migration;multicast;virtual machine migration	Most of today's data center networks (DCNs) adopt a multi-rooted tree structure called fat-tree, which delivers large bisection bandwidth through rich path multiplicity. In fat-tree DCNs, core switch modules play an important role in providing nonblocking capability, and form a significant part of network cost simultaneously. Reducing core switches while simultaneously guaranteeing performance has been a constant challenge. For example, multicast is an essential communication pattern in cloud services which needs to be supported efficiently. In this paper, we propose virtual network embedding schemes to deal with this problem. In the first scheme, we place the virtual machines (VMs) of a multicast-capable virtual network (MVN) as compact as possible, without any disturbance to existing traffic. In the second scheme, we manage to keep VMs in an even more compact way to reduce cost by allowing a small degree of VM migration. Both schemes are guaranteed to support any multicast communications within MVNs, and simultaneously achieve significant cost saving in terms of core switches, compared to currently best known result. Moreover, we show that our schemes incur only a small overhead in terms of migrations. Finally, we evaluate the performance of proposed schemes and validate the theoretical analysis through extensive simulations.	bisection bandwidth;cloud computing;data center;fat tree;file allocation table;multicast;network switch;overhead (computing);simulation;tree structure;virtual machine;z/vm	Jun Duan;Zhiyang Guo;Yuanyuan Yang	2015	2015 IEEE Conference on Computer Communications (INFOCOM)	10.1109/INFOCOM.2015.7218376	real-time computing;multicast;fat tree;computer science;operating system;distributed computing;source-specific multicast;xcast;computer network	Networks	-11.80256685021331	80.88097678006426	36228
ae6a13876d7ee054631f6fc926688aaf6b31bd57	does network coding improve the throughput of a survivable multicast network ?	standards;routing;pricing;throughput network coding routing encoding pricing computational modeling standards;trees mathematics directed graphs multicast communication network coding network theory graphs telecommunication network reliability telecommunication network routing;network coding;computational modeling;directed graph networks network coding survivable multicast network throughput single arc failures telecommunication network routing multicast routing steiner trees subtrees single max flow values linear problems column generation maximal throughput ratio unitary combination digraphs;encoding;throughput	We address survivability considerations for telecommunication networks where a part of the network may fail. We focus on single arc failures in multicast networks, with or without network coding. The problem is to compute a routing such that, if any single arc failure occurs, the remaining throughput is as large as possible. In the case of multicast routing without network coding, two ways for computing the impact of an arc failure are considered. Either the throughput of entire Steiner trees containing that arc vanishes, or only the throughput of subtrees, starting from that arc to terminals, is discarded. In the case of multicast with network coding, since the total throughput is computed as the minimum of single max-flow values from the source to any terminal, we consider that a failure of an arc implies that the throughput of all paths containing that arc vanishes. The three obtained models are formulated as linear problems. We solve these problems either directly or by use of column generation. Further, the survivable network coding gain is defined as the ratio of maximal throughput with - over without - network coding, when arc failures can occur. We show that this ratio is unbounded for unitary combination digraphs and hence for any directed networks. We also show that this ratio is equal to one for bidirected graphs with uniform capacities. Finally, some numerical results are carried out on randomly generated networks showing that the gain ratio is equal to one for almost 98 percent of the instances. However, we observe that routing with network coding requires much less redundancy in order to achieve the optimal throughput.	coding gain;column generation;data redundancy;directed graph;linear network coding;linear programming;maximal set;maximum flow problem;multicast;numerical analysis;planar graph;procedural generation;randomness;routing;single sign-on;steiner tree problem;throughput;tree (data structure)	Sourour Elloumi;Éric Gourdin;Thibaut Lefebvre	2014	2014 10th International Conference on the Design of Reliable Communication Networks (DRCN)	10.1109/DRCN.2014.6816152	pricing;routing;throughput;linear network coding;non-broadcast multiple-access network;computer science;theoretical computer science;distributed computing;computational model;encoding;computer network	Networks	-5.752323682368271	79.82199921977349	36303
e81c58342eb694efd562dfbb760dfa75ea4ed8c8	approximations to maximum weight matching scheduling algorithms of low complexity	maximum weight matching scheduling algorithms;approximation algorithms;processor scheduling;design criteria;queueing theory;output queued switch maximum weight matching scheduling algorithms input queued switch computational complexity approximation parameters;low complexity;packet switching;maximum weight matching;satisfiability;stability;input output;approximation theory;scheduling algorithm;telecommunication switching;computational complexity;scheduling;queueing theory scheduling telecommunication switching computational complexity approximation theory;combined input output queued;approximation parameters;scheduling algorithm switches algorithm design and analysis approximation algorithms stability telecommunication switching processor scheduling laboratories computational complexity packet switching;input queued switch;switches;algorithm design and analysis;output queued switch	The choice of the scheduling algorithm is a major design criterion of a switch. Whereas it is known that maximum weight matching algorithms guarantee the stability of an input-queued switch, their computational complexity does not allow their practical deployment. In consequence, researchers have designed scheduling algorithms of low complexity and with satisfying performance features. We extend this field of research by investigating the application of matching algorithms of low complexity that approximate maximum weight matching algorithms as scheduling algorithms for input-queued switches. We prove that an algorithm that approximates a maximum weight matching algorithm with approximation parameters (c, d), stabilizes a combined input/output-queued switch with a speed-up of 1/c. As an application, we show that four known scheduling algorithms of low complexity stabilize a combined input/output-queued switch with a speed-up of two. Finally, we prove that the improve/spl I.bar/matching algorithm can stabilize an input-queued switch when it is deployed with a speed-up of (3/2)+/spl epsiv/.	approximation algorithm;computational complexity theory;input/output;matching (graph theory);motif window manager;network switch;scheduling (computing);software deployment	Claus Bauer	2005	Advanced Industrial Conference on Telecommunications/Service Assurance with Partial and Intermittent Resources Conference/E-Learning on Telecommunications Workshop (AICT/SAPIR/ELETE'05)	10.1109/AICT.2005.29	mathematical optimization;probabilistic analysis of algorithms;real-time computing;computer science;3-dimensional matching;operating system;distributed computing;scheduling;approximation algorithm	Metrics	-5.1894405366919685	71.35659759432868	36336
429e1e07f911871feb6da17f9509bd360243d6ed	design and implementation of an interoperable messaging system for iot healthcare services		"""The spry maturation of Internet of Things (IoT) has paved way to the rapid development of numerous sectors and these have been envisioned in; connected transport, smart cities, connected homes, connected healthcare, etc. IoT is a technology that connects """"things"""" that are embedded with sensors, actuators and network connectivity to collect and exchange the data to the internet. The ability of IoT that offers distinct technologies for a small constrained device to collect and deliver messages across sophisticated networks leaves room for more exploration. Zeroing down to the healthcare sector, a couple of Personal Health Devices (PHDs) have been developed to collect and share information across the internet. One Machine to Machine (oneM2M), ISO/IEEE 11073 PHD are some of the healthcare standards that have been developed have been developed to deal with the issue of interoperability in the IoT. In this paper we design and implement an interoperable messaging system that is based on international standards for IoT healthcare services. Standard IoT protocols; Message Queuing Telemetry Transport (MQTT) and Constrained Application Protocol (CoAP) are some of the protocols that were designed to be used in an IoT environment. We designed and implemented a message system using CoAP following international standards for IoT healthcare services. This is due to better performance that CoAP offers in a constrained environment over other protocols. The paper further analyses and evaluates a comparative performance of number of packets transmitted in a transaction and packet loss rate number during transmission between the designed system and existing messaging system that uses MQTT."""	constrained application protocol;embedded system;inter-process communication;internet of things;interoperability;mqtt;machine to machine;network packet;performance evaluation;prototype;publish–subscribe pattern;sensor;smart city;spry framework	Brian Oryema;Hyun-Su Kim;Wei Li;Jong-Tae Park	2017	2017 14th IEEE Annual Consumer Communications & Networking Conference (CCNC)	10.1109/CCNC.2017.7983080	computer network;message queue;quality of service;the internet;telecommunications;constrained application protocol;interoperability;mqtt;computer science;network packet;machine to machine	Mobile	-22.613528216237857	82.74472652129556	36362
a949eb3133cdba2c58f9d62a9f835a93c00b8bfb	selecting proper wireless network interfaces for user experience enhancement with guaranteed probability	execution time;wireless interfaces;confidence probability;transmit data;wireless network interfaces;mobile users;journal;delay tolerant;probabilistic assignment;user experience;期刊论文;data access;communication cost;mobile user experience;mobile users access	With the increasing capabilities of mobile phones, mobile users access data via wireless interfaces pervasively. Although WiFi has limited coverage and resulted in a bigger delay of data access, it is not uncommon that mobile users are willing to use WiFi to transmit data to decrease communication costs instead of 3G. Hence it is reasonable to use delay tolerance strategies to balance execution time, energy consumption, and communication cost. In this paper, we model mobile user experience as a combination of three random variables (energy consumption, execution time and communication cost). We present a wireless interface scheduling algorithm to select proper wireless interfaces for a set of data-dependent sporadic tasks to enhance user experience under the constraints of execution time, energy consumption, and communication cost with a guaranteed confidence probability in a delay-tolerant environment. The experimental results show that our approach can effectively enhance the user experience.	user experience	Jianwei Niu;Yuhang Gao;Meikang Qiu;Zhong Ming	2012	J. Parallel Distrib. Comput.	10.1016/j.jpdc.2012.08.006	data access;user experience design;real-time computing;mobile search;computer science;distributed computing;mobile station;wi-fi array;mobile computing;computer network	Mobile	-20.41927591618988	75.29398229211075	36380
0b4b70ca441cff3274b992cd7d7fa8fdbcc7edef	libra: an economy driven job scheduling system for clusters	high availability;cluster computing;management system;resource allocation;resource manager;system performance;performance analysis;quality of service;high throughput;high performance;perceived value;job scheduling;user satisfaction;resource management system	Clusters of computers have emerged as mainstream parallel and distributed platforms for high-performance, highthroughput and high-availability computing. To enable effective resource management on clusters, numerous cluster managements systems and schedulers have been designed. However, their focus has essentially been on maximizing CPU performance, but not on improving the value of utility delivered to the user and quality of services. This paper presents a new computational economy driven scheduling system called Libra, which has been designed to support allocation of resources based on the users’ quality of service (QoS) requirements. It is intended to work as an add-on to the existing queuing and resource management system. The first version has been implemented as a plugin scheduler to the PBS (Portable Batch System) system. The scheduler offers market-based economy driven service for managing batch jobs on clusters by scheduling CPU time according to user-perceived value (utility), determined by their budget and deadline rather than system performance considerations. The Libra scheduler ensures that both these constraints are met within an O(n) run-time. The Libra scheduler has been simulated using the GridSim toolkit to carry out a detailed performance analysis. Results show that the deadline and budget based proportional resource allocation strategy improves the utility of the system and user satisfaction as compared to system-centric scheduling strategies.	add-ons for firefox;central processing unit;computer;high availability;job shop scheduling;microsoft academic search;portable batch system;quality of service;requirement;scheduling (computing)	Jahanzeb Sherwani;Nosheen Ali;Nausheen Lotia;Zahra Hayat;Rajkumar Buyya	2002	CoRR		high-throughput screening;fixed-priority pre-emptive scheduling;parallel computing;real-time computing;simulation;quality of service;computer cluster;resource allocation;computer science;resource management;job scheduler;operating system;management system;distributed computing;computer performance;high availability;scheduling	HPC	-17.58912605588169	61.02585878215638	36395
b1c28c040d3832e77d3b898d5c355bbf47eb4ffe	hash-based overlay partitioning in unstructured peer-to-peer systems	hachage;parallelisme;distributed system;eje troncal;virtual network;categorisation;flooding;keyword;systeme reparti;flood;par a par;localization;mantenimiento sistema;recubrimiento;interrogation base donnee;inundacion;interrogacion base datos;overlay;blind;palabra clave;localizacion;mot cle;peer to peer system;recouvrement;reseau federateur;inondation;categorizacion;parallelism;hashing;sistema repartido;localisation;paralelismo;poste a poste;random walk;overlay network;marcha aleatoria;backbone;peer to peer;system maintenance;database query;ciego;marche aleatoire;red virtual;resource location;categorization;maintenance systeme;reseau virtuel;aveugle	Unstructured peer-to-peer (P2P) networks suffer from the increased volume of traffic produced by flooding. Methods such as random walks or dynamic querying managed to limit the traffic at the cost of reduced network coverage. In this paper, we propose a partitioning method of the unstructured overlay network into a relative small number of distinct subnetworks. The partitioning is driven by the categorization of keywords based on a uniform hash function. The method proposed in this paper is easy to implement and results in significant benefit for the blind flood method. Each search is restricted to a certain partition of the initial overlay network and as a result it is much more targeted. Last but not least, the search accuracy is not sacrificed to the least since all related content is searched. The benefit of the proposed method is demonstrated with extensive simulation results, which show that the overhead for the implementation and maintenance of this system is minimal compared to the resulted benefit in traffic reduction.	binary space partitioning;categorization;gnutella;hash function;overhead (computing);overlay network;peer-to-peer;search algorithm;simulation	Harris Papadakis;Paraskevi Fragopoulou;Evangelos P. Markatos;Marios D. Dikaiakos;Alexandros Labrinidis	2009	Parallel Processing Letters	10.1142/S0129626409000067	hash function;overlay network;internationalization and localization;telecommunications;computer science;operating system;flooding;distributed computing;overlay;world wide web;random walk;categorization	HPC	-10.809385483240204	69.99716058795312	36435
3bd736a79c154b5a07b7814f1cb89a6df5875ced	challenges in future broadband radio access, co-operative communications and self-organising networks	radio networks;energy efficiency;wireless networks;broadband networks;wireless network;self organising networks;cooperative communications;wireless networking broadband radio access cooperative communications self organising networks;broadband radio access;internet;radio networks broadband networks;cellular network;land mobile radio cellular systems;wireless networking;wireless sensor networks;land mobile radio cellular systems internet centralized control ip networks intelligent networks wireless sensor networks wireless networks network topology energy efficiency resource management	Despite of great improvements in e.g. mobile cellular networks during the past decade, the changes in the future may be even more dramatic. Several enabling basic technological barriers seem to become solved in the near future. This will potentially cause dramatic changes the way commercial wireless networks will function and deliver services for users. In this paper, an overview of critical enabling technologies which are foreseen to change the future wireless networking is given.	mobile phone;self-organization	Matti Latva-aho	2009	2009 International Conference on Telecommunications	10.1109/ICTEL.2009.5158608	telecommunications;computer science;engineering;operating system;wireless network;computer security;computer network	Mobile	-14.285445801516564	88.17920609235568	36446
61389b4f6476b7f692426898a70e46b1d22a086b	file sharing strategy based on webrtc	information science;collaboration;time factors;web services;quality of service;sparse matrices;throughput	File-sharing is an important feature for web real-time applications. The traditional way of implement file-sharing is uploading files to file server by a sender, then receivers can download and display on browsers in time. With the increasing awareness of the data security, the way hosting file data by a third party server can not meet the needs of users. Discarding the server side seems like a good idea, then file data can be send directly among browsers, but there is no pure web technique can achieve the function of peer-to-peer connection until Web Real-Time Communication technology(WebRTC). We design and implement a file sharing strategy among browsers by WebRTC and related HTML5 technology. Experimental result indicates that our method achieve efficient transmission performance.	data security;download;file server;file sharing;file transfer;html5;list of device bit rates;peer-to-peer;real-time web;server (computing);server-side;upload;webrtc	Duan Quanfeng;Liang Zhenghe	2016	2016 13th Web Information Systems and Applications Conference (WISA)	10.1109/WISA.2016.11	self-certifying file system;computer science;stub file;ssh file transfer protocol;journaling file system;web log analysis software;database;file inclusion vulnerability;open;internet privacy;file system fragmentation;world wide web	OS	-19.34379833996894	71.72715509220053	36512
25076f36dc23f62d626786834c4fa8b6217c0218	assay of white space technology standards for vehicular cognitive access		The provisioning of innovative connections between vehicles and backend information systems will enable new ways of vehicle management, traffic safety and efficiency. In this article we present Vehicular Cognitive Access, the concept of using TV white space access technology to support and facilitate end-to-end connectivity for certain types of automotive applications. We defined common requirements that an optimized radio system is expected to fulfill. An overview of different TV white space access standards is presented; motivations and open challenges of these standards as enabling technologies for vehicular communications are analyzed. It also provides an evaluation of the overall suitability of TV white space access for these applications and discusses research directions. TV white space access standards do show significant potential for vehicular cognitive access. However, some issues such as seamless handover schemes for high speed vehicles and the capability to support applications that have strict timeline and reliability requirements need to be further optimized before its full potential can be realized.	assistive technology;end-to-end principle;information system;provisioning;requirement;seamless3d;timeline;white spaces (radio)	Muhammad Dawood;Woldemar F. Fuhrmann;Bogdan V. Ghita	2014			white spaces;computer security;cognition;engineering	HCI	-15.313899437112708	87.31589475145024	36543
813ed455e2492f46de9b2c5637d5263e64b30354	all-optical multicast routing in wavelength routed wdm networks. (routage multicast tout optique dans les réseaux wdm)		In this thesis, we studied the all-optical multicast routing (AOMR) problem in wavelength-routed WDM networks. The objective is to find a set of light structures, for instance a light-tree or a light-forest, to distribute the multicast messages to all the destinations concurrently while either taking account of both the end-to-end delay and the link stress or minimizing the total cost or the power budget. With respect to the delay and link stress sensitive AOMR, an efficient algorithm based on avoiding multicast incapable branching nodes in light-trees is proposed. This algorithm is shown to be able to improve the end-to-end delay of light-trees and to find a good tradeoff among the end-to-end delay, the link stress and the total cost. Regarding the power-aware AOMR, a new but more accurate and realist power loss model is given for all-optical multicasting. It distinguishes two types of node tapping loss : the one tapped by intermediate optical nodes for network management and the other one tapped by destination nodes for the recovery of multicast messages. Based on this new model, the power optimal design of light-trees is formulated by a mixed-integer programming (MILP). To achieve so, a set of novel linear equations is introduced to replace the nonlinear ones induced by the light splitters. In order to analyze the AOMR heuristic algorithms and assess their performances, light-trees computed using AOMR heuristic algorithms are evaluated mathematically by deriving the cost bounds and the approximation ratios in both unweighted and non-equally weighted WDM mesh networks. Concerning the cost optimal AOMR, a new structure called light-hierarchy is proposed. It is proven that the optimal structure is not the light-tree but the proposed light-hierarchy. The computation of light-hierarchy is modeled as an ILP to search the optimal solution for small instances. A heuristic algorithm using a graph renewal strategy is also proposed for fast AOMR in large scale WDM networks. Simulation results strongly sug-	algorithm;approximation;computation;cost efficiency;end-to-end encryption;end-to-end principle;heuristic (computer science);integer programming;linear equation;linear programming;mesh networking;multicast;nonlinear system;optimal design;performance;routing;simulation;wavelength-division multiplexing	Fen Zhou	2010				Metrics	-5.139491661580898	82.10001098493426	36558
1eef2bafb60e0e8e5ee51d57e1ee5af7bd0f39ce	a semantic overlay for self- peer-to-peer publish/subscribe	filtering;content based filtering;design principle;comparative analysis;fault tolerant;distributed networks;publish subscribe system;filters;dynamic network;research and development;peer to peer computing subscriptions scalability filters computer science telecommunications research and development performance analysis filtering fault tolerance;fault tolerance;publish subscribe;performance analysis;subscriptions;self organization;scalability;experimental evaluation;computer science;peer to peer computing;peer to peer;telecommunications	Publish/Subscribe systems provide a useful platform for delivering data (events) from publishers to subscribers in an anonymous fashion in distributed networks. In this paper, we promote a novel design principle for self-. dynamic and reliable content-based publish/subscribe systems and perform a comparative analysis of its probabilistic and deterministic implementations. More specifically, we present a generic content-based publish/subscribe system, called DPS (Dynamic Publish/Subscribe). DPS combines classical content-based filtering with self-. (self-organizing, selfconfiguring, and self-healing) subscription-driven clustering of subscribers. DPS gracefully adapts to failures and changes in the system while achieving scalable events delivery. DPS includes a variety of fault-tolerant deterministic and probabilistic content-based publication/subscription schemes. These schemes are targeted toward scalability, and aim at reducing and distributing the number of messages exchanged. Reliability and scalability of our system are shown through analytical and experimental evaluation.	cluster analysis;dependability;fault tolerance;load balancing (computing);organizing (structure);peer-to-peer;pictbridge;publish–subscribe pattern;qualitative comparative analysis;recommender system;scalability;self-organization;simulation;tree traversal;virtual world	Emmanuelle Anceaume;Maria Gradinariu Potop-Butucaru;Ajoy Kumar Datta;Gwendal Simon;Antonino Virgillito	2006	26th IEEE International Conference on Distributed Computing Systems (ICDCS'06)	10.1109/ICDCS.2006.12	fault tolerance;computer science;database;distributed computing;world wide web;computer network	Embedded	-12.429761552231932	73.45259817591706	36571
704fda7cc589b91598a7ead935cf4be047cd0896	double auction protocols for resource allocation in grids	resource utilization;continuous double auction;protocols;threshold price double auction protocol;resource allocation;protocols grid computing resource allocation;economic efficiency;resource management;protocols resource management environmental economics power generation economics power system modeling system performance computer networks power system economics computer network reliability computational modeling;null;system performance;computer networks;computational modeling;power system economics;continuous double auction protocol;environmental economics;resource utilization double auction protocols resource allocation grid computing double auction allocation model preston mcafee threshold price double auction protocol continuous double auction protocol economic efficiency system performance;preston mcafee;double auction protocols;power system modeling;double auction allocation model;grid computing;double auction;power generation economics;computer network reliability	In this paper we propose the double auction allocation model for grids, and three double auction protocols for resource allocation: Preston-McAfee Double Auction Protocol (PMDA), threshold price double auction protocol (TPDA) and continuous double auction protocol (CDA). We study these protocols in terms of economic efficiency and system performance. The results show that CDA protocol is better from both resource's and user's perspective providing high resource utilization.	.cda file;communications protocol;round-robin dns;simulation	Umesh Kant;Daniel Grosu	2005	International Conference on Information Technology: Coding and Computing (ITCC'05) - Volume II	10.1109/ITCC.2005.135	industrial organization;combinatorial auction;economics;microeconomics;commerce	Robotics	-24.141326231721266	65.13071121137483	36589
31310497cb59bfcc2e3c00a79c86e36383de53ad	a study of protocol analysis for packet switched network		Communication failures may occur because of residual hardware or software implementation flaws, operator errors, transmission noises and transient or permanent machine failures. For packet switched network operation, some means are necessary to detect the errors and to analyze the phenomena to identify the causes of the errors, since, generally, it is almost impossible to predict errors or to implement systems without errors or failures.  This paper describes general aspects of communication protocol analysis, protocol analysis technologies for CCITT X.25 and the protocol analyzer to be used in DDX packet switched network operation.	communications protocol;network packet;packet switching;user interface;x.org server	K. Tsukamoto;T. Itoh;M. Nomura;Yoshiki Tanaka	1981		10.1145/800081.802664	communications protocol;digital signature;real-time computing;public switched data network;computer science;mean squared prediction error;distributed computing;transmission delay;arbitration;computer security;protocol analysis;computer network;internetwork protocol	Networks	-28.264100086161484	83.12765999197879	36606
bab73efe772fae79f5386c5f8116240c11594038	data center, a cyber-physical system: improving energy efficiency through the power management		"""A Data Center (DC) can be defined as a cyber-physical """"complex"""" system since within it computing and energy aspects coexist together with their interdependencies. Due to this dual aspect, the measurement of DC energy efficiency is an articulated and open issue, because it involves both Information Technology (IT) and Cooling Technology perspectives. Therefore, the analysis of energy efficiency in DCs, through a set of globally accepted metrics, is an ongoing challenge. In particular, the area of productivity metrics - that are parameters referred to the actual processes of computing, storage and data transfer – needs to be further explored. Moreover, till now none of the existing proposed metrics provides a direct measure of the useful work in a DC. To this purpose, this work aims to investigate and analyze the relationship between different types of server workloads and power consumed by the relative computing nodes (core) used. The paper aims to make a step forward beyond state of the art in productivity metrics and also to server performance and power management, by analyzing the server energy consumption behavior through statistical data analysis. To this purpose in this work real data obtained by experimental campaigns on the ENEA-C.R. Portici facilities have been analyzed."""	coexist (image);cyber-physical system;data center;interdependence;power management;server (computing);turing reduction	Marta Chinnici;Davide De Chiara;Andrea Quintiliani	2017	2017 IEEE 15th Intl Conf on Dependable, Autonomic and Secure Computing, 15th Intl Conf on Pervasive Intelligence and Computing, 3rd Intl Conf on Big Data Intelligence and Computing and Cyber Science and Technology Congress(DASC/PiCom/DataCom/CyberSciTech)	10.1109/DASC-PICom-DataCom-CyberSciTec.2017.56	real-time computing;power management;efficient energy use;cyber-physical system;energy consumption;data transmission;information technology;data center;server;computer science	HPC	-18.921875621036776	78.34467194840592	36692
b32a3348fd8c10bb04aeadd995807dd1d80eb72b	research on a framework of task scheduling and load balancing in heterogeneous server environment	load balancing;task scheduling	In this paper, we study task scheduling and load balancing in a heterogeneous server environment. Through a research on the dynamic requirements of load balancing service of the servers, we form an adaptive task scheduling and load balancing service framework based on customizable load feedback and dynamic scheduling strategy. Finally, we build and test a solution within a multidomain physical modeling and simulation service platform in the web environment-WebMWorks. © 2013 The Authors and IOS Press.	load balancing (computing);schedule (project management);scheduling (computing)	Tifan Xiong;Chuan Wang;Li Wan;Qinghua Liu	2013		10.3233/978-1-61499-302-5-101		HPC	-17.282562051533	61.458729961314305	36712
f39f449f340c654052d0e7aa1ae0a4fff822d6fb	a generic and overlay-agnostic publish-subscribe protocol	middleware overlay agnostic publish subscribe protocol generic publish subscribe protocol unstructured peer to peer network dht based peer to peer network routing algorithms multicast topology structure creation multicast topology structure maintenance distributed collaborative application;multicast topology structure creation;topology;protocols;pediatrics;multicast topology structure maintenance;peer to peer network;generic publish subscribe protocol;routing algorithms;p2p;maintenance engineering;peer to peer p2p middleware publish subscribe;network topology;telecommunication network routing;p2p middleware;publish subscribe;routing algorithm;telecommunication network topology middleware peer to peer computing protocols telecommunication network routing;overlay agnostic publish subscribe protocol;middleware;publish subscribe protocols multicast algorithms peer to peer computing network topology information technology routing middleware proposals access control;peer to peer computing;telecommunication network topology;distributed collaborative application;peer to peer;distributed collaboration;integrated circuits;shared workspace;unstructured peer to peer network;dht based peer to peer network	This paper introduces a generic publish-subscribe protocol, that works both for the unstructured and DHT-based Peer-to-Peer networks. Unlike most of the approaches, it does not rely on the overlay-specific features of the routing algorithms for the efficient multicast topology structure creation and maintenance. Moreover it is highly customizable to address the optimization issues and support different topology structures. The described framework may be used by the distributed collaborative applications as middleware to implement presence or exchange information about the shared workspace.	algorithm;distributed hash table;event (computing);mathematical optimization;middleware;multicast;peer-to-peer;point-to-point protocol;publish–subscribe pattern;routing;workspace	Paulina Adamska;Adam Wierzbicki;Tomasz Kaszuba	2009	2009 First International Conference on Advances in P2P Systems	10.1109/AP2PS.2009.41	protocol independent multicast;computer science;distributed computing;world wide web;computer network	EDA	-11.855758577488821	76.10671753820395	36731
70d8a5ffd5f4fdf8b594776e77055675b5362770	an intelligent technique for controlling web prefetching costs at the server side	negative affect;performance evaluation;web prefetching;telecommunication congestion control client server systems intelligent control internet storage management;traffic regulation;storage management;web performance;prefetching;telecommunication congestion control;prediction algorithms;prefetching costs network servers communication system traffic control delay intelligent agent web server system performance traffic control proposals;client server systems;intelligent control;system performance;adverse effect;servers;internet;engines;traffic regulation web prefetching;network traffic;network traffic estimation model intelligent technique web prefetch cost control server side;mathematical model;quality of service;proposals	Prefetching is an interesting technique for improving web performance by reducing the user-perceived latency when surfing the web. Nevertheless, due to its speculative nature, prefetching can increase the network traffic and the server load. This could negatively affect the overall system performance and decrease the quality of service. To minimize and maintain under control these adverse effects, in this paper we propose an intelligent prefetching mechanism that dynamically adjusts the aggressiveness of the prefetching algorithm at the server side. To this end, we also propose a traffic estimation model that permits to accurately calculate, in the server side, the extra load and traffic generated by the prefetching. The performance evaluation study shows that our proposal effectively regulates the adverse effects of web prefetching without affecting its benefits.	algorithm;cpu cache;link prefetching;network traffic control;performance evaluation;quality of service;server (computing);server-side;speculative execution;web development;web performance	Johann Márquez;Josep Domènech;José A. Gil;Ana Pont	2008	2008 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology	10.1109/WIIAT.2008.340	real-time computing;the internet;quality of service;prediction;adverse effect;computer science;mathematical model;world wide web;server;statistics;affect;computer network;intelligent control	Metrics	-17.858367940660255	71.03727556185329	36747
f0a60c200e2f9b655f07b445e443c734be095e55	scalable and elastic cloud data center for self-organizing dense small cell networks	resource management;cloud data center;cloud data center auto scaling load balancing;computer architecture;5g mobile communication;engines;radio access technology cloud data center self organizing dense small cell networks wireless data traffic wireless network vendors 5g wireless network 3g 4g systems self organizing radio access networks;telecommunication traffic 3g mobile communication 4g mobile communication 5g mobile communication cloud computing mobile computing radio access networks self adjusting systems;engines load management computer architecture 5g mobile communication radio access networks resource management;proceedings paper;load management;load balancing;auto scaling;radio access networks	The exponential growth of wireless data traffic has pushed wireless network vendors and researchers to rethink of a revolutionizing architecture for the fifth generation (5G) wireless network that is capable of supporting 100 times the network capacity of the current 3G/4G systems, yet is able to reduce the net energy consumption of the systems by up to 90 percent. Numerous concepts and technologies have been proposed to approach this goal from various aspects of system design. A consensus reached so far is that 5G is going to be a collection of technology evolutions that include soft core networks, small or even no cellular, pervasive but invisible base stations, and heterogeneous yet self-organizing radio access networks. In addition to advanced radio access technologies, the success of such an ambitious goal really relies on a flexible and scalable network infrastructure to accommodate and harmonize these technologies. On the other hand, virtualization is viewed as one of the essential technologies of the 5G network to provide cost effectiveness of management, maintenance, and hardware upgrade. In this paper, we introduce a cloud service model that has the potential to serve the numerous stringent requirements for future 5G networks. Besides, we describe the designed auto scaling and load balancing rules of each functional block defined in the cloud service model. We conduct emulation to evaluate the performance of resource utilization for the cloud data center.	access network;autoscaling;cloud computing;computer hardware;data center;emulator;fifth generation computer;image scaling;load balancing (computing);organizing (structure);pervasive informatics;requirement;scalability;self-organization;software-defined networking;systems design;time complexity	Yun-Ting Lee;Hsi-Lu Chao;Jin-Wei Tang	2015	2015 17th Asia-Pacific Network Operations and Management Symposium (APNOMS)	10.1109/APNOMS.2015.7275357	radio access network;real-time computing;wireless wan;public land mobile network;telecommunications;computer science;radio resource management;load balancing;resource management;operating system;wireless network;distributed computing;computer security;computer network	Networks	-14.272834483121295	86.88819940281124	36952
a892362053db126468eb062034efea5559b8854a	characterization of bandwidth-aware meta-schedulers for co-allocating jobs across multiple clusters	workload;modelo dinamico;distributed system;largeur bande;time varying;cluster computing;parallel job scheduling;systeme reparti;gestion labor;reseau interconnecte;resource allocation;racimo calculadura;simulation;dynamic model;job co allocation;communication model;time varying system;partage des ressources;scheduling algorithm;grappe calculateur;sistema repartido;gestion tâche;multiple clusters;network contention;systeme parametre variable;modele dynamique;anchura banda;resource sharing;particion recursos;charge travail;bandwidth;multi site scheduling;asignacion recurso;sistema parametro variable;task scheduling;allocation ressource;carga trabajo;red interconectada;bandwidth aware;interconnected power system	In this paper, we present a bandwidth-centric job communication model that captures the interaction and impact of simultaneously co-allocating jobs across multiple clusters. We compare our dynamic model with previous research that utilizes a fixed execution time penalty for co-allocated jobs. We explore the interaction of simultaneously co-allocated jobs and the contention they often create in the network infrastructure of a dedicated computational multi-cluster. We also present several bandwidth-aware co-allocating meta-schedulers. These schedulers take inter-cluster network utilization into account as a means by which to mitigate degraded job run-time performance. We make use of a bandwidth-centric parallel job communication model that captures the time-varying utilization of shared inter-cluster network resources. By doing so, we are able to evaluate the performance of multi-cluster scheduling algorithms that focus not only on node resource allocation, but also on shared inter-cluster network bandwidth.	algorithm;broadcasting (networking);clustered file system;computation;computational resource;computer cluster;job scheduler;job stream;linear programming relaxation;load balancing (computing);mathematical model;meta-scheduling;multi-core processor;parallel computing;run time (program lifecycle phase);scheduling (computing);simulation;time-varying network	William M. Jones;Walter B. Ligon;Louis W. Pang;Daniel C. Stanzione	2005	The Journal of Supercomputing	10.1007/s11227-005-2337-x	shared resource;parallel computing;real-time computing;simulation;models of communication;computer cluster;resource allocation;computer science;operating system;scheduling;bandwidth	HPC	-12.770875934630473	64.07407076143367	37022
9aa0b258aca5cc498f2e7097db089c871046268e	performance implications of meshing degree for optical burst switched networks using one-way resource reservation protocols	optical burst switching;optical burst switched;performance;european optical network;resource reservation protocols;resource reservation;mesh network;optical internet	This paper discusses performance implications of meshing degree (or nodal degree) for optical burst switching (OBS) mesh networks using one-way resource reservation protocols. The analysis is focused on the following topologies: rings, chordal rings with nodal degrees ranging from three to six, mesh-torus, NSFNET, ARPANET and the European Optical Network (EON). It is shown that the largest nodal degree gain, due to the increase of the nodal degree from two to around three, is observed for degree-three chordal ring topology, where as the smallest gain is observed for the ARPANET. For these cases, the magnitude of the nodal degree gain is slightly less than three orders for the degree-three chordal ring and less than one order of magnitude for the ARPANET. On the other hand, when the nodal degree increases from two to a value ranging from about four up to six, the nodal degree gain ranges between four and six orders of magnitude for chordal rings. However, EON, which has a nodal degree slightly less than four has the smallest nodal degree gain. The observed gain for this case is less than one order of magnitude. Since burst loss is a key issue in OBS networks, these results clearly show the importance of meshing degree for this kind of networks.	emoticon;mesh networking;national science foundation network;one-way function;optical burst switching;ring network	Joel Jos&#x00E9; P. C. Rodrigues;Mário M. Freire;Pascal Lorenz	2005	Telecommunication Systems	10.1007/s11235-005-4312-5	optical burst switching;performance;telecommunications;computer science;mesh networking;mathematics;distributed computing;computer network	Mobile	-6.298633837638035	85.72356358227195	37058
6c0eec533f2c0289c1e45802040a642ead003013	in search of energy-efficient mobile networking	energy efficiency;mobile fixed power devices;simple cell;mobile device;energy efficient;cellular radio;energy efficient mobile networking;heat dissipation;future internet;research and development;internet;network mobility;energy consumption;batteries;ieee 802 11 standards;mobile communication;power management;mobile handsets;energy efficiency energy consumption computer aided manufacturing energy management cellular phones research and development costs geometry mobile computing hardware;gsm cellular phones;power consumption;mobile computing;mobile networked devices;subject areas;binary use gadgets;internet architectures energy efficient mobile networking mobile fixed power devices energy consumption heat dissipation binary use gadgets gsm cellular phones mobile networked devices power management;mobile network;mobile computing cellular radio internet;internet architectures	With the proliferation of mobile fixed-power devices, energy consumption emerged as a vibrant research and development subject area in networking. Mobile devices are designed with several hard constraints such as low cost and small geometries, as well as, low heat dissipation, and operation using fixed power sources. Manufacturers have been adding an ever increasing set of features to small mobile devices, which are no longer binary-use gadgets, but fully-fledged computers. With respect to power management, several mechanisms have been introduced; but, by and large, gains in power consumption at the hardware level have been essentially traded for extended functionality. All in all, the overall operational time has not increased. For example, early GSM cellular phones could only allow for less than an hour of talk time in a single battery charge. By the late 1990s, top models, introduced through better engineering and an evolutionary development approach, featured talk times increased by a factor of 3-5. This level of performance has remained the same over the last decade, although it is well below user expectations. This article reviews the evolution from simple cell phones toward the feature-rich mobile networked devices we have come to expect from manufacturers, and explains the factors that have led to stagnation in operational time. We then turn our attention to the multiaccess nature of modern mobile devices and the respective implications for power management. We find that the current host-centric mobile networking paradigm, based on end-to-end always on connectivity, leads to energy-inefficient operation. Finally, this article introduces information-centric networking and outlines open research issues in the design of energy-efficient future Internet architectures.	computer;end-to-end principle;future internet;high availability;mobile device;mobile phone;open research;power management;power semiconductor device;programming paradigm;software feature;thermal management (electronics)	Kostas Pentikousis	2010	IEEE Communications Magazine	10.1109/MCOM.2010.5394036	embedded system;real-time computing;mobile search;telecommunications;computer science;operating system;efficient energy use;mobile computing;computer network	Mobile	-14.990519645989615	88.00914557567415	37085
2cae0ba7f3f7fa8d602ed1c496f8a7aa49a85870	care: content aware redundancy elimination for disaster communications on damaged networks		During a disaster scenario, situational awareness information, such as location, physical status and images of the surrounding area, is essential for minimizing loss of life, injury, and property damage. Today’s handhelds make it easy for people to gather data from within the disaster area in many formats, including text, images and video. Studies show that the extreme anxiety induced by disasters causes humans to create a substantial amount of repetitive and redundant content. Transporting this content outside the disaster zone can be problematic when the network infrastructure is disrupted by the disaster. This paper presents the design of a novel architecture called CARE (Content-Aware Redundancy Elimination) for better utilizing network resources in disaster-affected regions. Motivated by measurement-driven insights on redundancy patterns found in real-world disaster area photos, we demonstrate that CARE can detect the semantic similarity between photos in the networking layer, thus reducing redundant transfers and improving buffer utilization. Using DTN simulations, we explore the boundaries of the usefulness of deploying CARE on a damaged network, and show that CARE can reduce packet delivery times and drops, and enables 20-40% more unique information to reach the rescue teams outside the disaster area than when CARE is not deployed.	delay-tolerant networking;image;mobile device;network packet;semantic similarity;simulation;video	Udi Weinsberg;Athula Balachandran;Nina Taft;Gianluca Iannaccone;Vyas Sekar;Srinivasan Seshan	2012	CoRR		simulation;telecommunications;world wide web;computer security;computer network	HCI	-11.975516440100046	84.34806739346855	37177
0726312acc5b78ff9282e90530b5bf15e657405c	standard for the transmission of ip datagrams over ieee 802 networks		This RFC specifies a standard method of encapsulating the InternetnProtocol (IP) datagrams and Address Resolution Protocol (ARP) requestsnand replies on IEEE 802 Networks to allow compatible and interoperablenimplementations. This RFC specifies a protocol standard for thenInternet community.	datagram	Jon Postel;Joyce K. Reynolds	1988	RFC	10.17487/RFC1042	internet protocol;is-is;embedded system;ipsec;link layer;bootstrap protocol;user datagram protocol;ip multicast;extensible authentication protocol;computer science;ipv6;transmission control protocol;internet group management protocol;session initiation protocol;serial line internet protocol;internet protocol suite;simple network management protocol;sigtran;dynamic host configuration protocol;computer security;private network;mobile ip;computer network;open shortest path first	Visualization	-23.78923783867542	88.35506107294106	37273
ec990116541a6241da84dc69de5d4310c2e6bc1a	a mathematical model for file fragment diffusion and a neural predictor to manage priority queues over bittorrent		BitTorrent splits the files that are shared on a P2P network into fragments and then spreads these by giving the highest priority to the rarest fragment. We propose a mathematical model that takes into account several factors such as the peer distance, communication delays, and file fragment availability in a future period also by using a neural network module designed to model the behaviour of the peers. The ensemble comprising the proposed mathematical model and a neural network provides a solution for choosing the file fragments that have to be spread first, in order to ensure their continuous availability, taking into account that some peers will disconnect.		Christian Napoli;Giuseppe Pappalardo;Emiliano Tramontana	2016	Applied Mathematics and Computer Science		wavelet;real-time computing;computer science;mathematics;distributed computing;diffusion;file sharing;artificial neural network;statistics;computer network	DB	-9.495637878828033	70.51748284602532	37355
cf440c5d079e09ebed04ff517348cbcdb4bc5c74	candidate access router discovery (card)		"""To enable seamless IP-layer handover of a mobile node (MN) from one#N#access router (AR) to another, the MN is required to discover the#N#identities and capabilities of candidate ARs (CARs) for handover prior#N#to the initiation of the handover. The act of discovery of CARs has#N#two aspects: identifying the IP addresses of the CARs and finding#N#their capabilities. This process is called """"candidate access router#N#discovery"""" (CARD). At the time of IP-layer handover, the CAR, whose#N#capabilities are a good match to the preferences of the MN, is chosen#N#as the target AR for handover. The protocol described in this document#N#allows a mobile node to perform CARD. This memo defines an#N#Experimental Protocol for the Internet community."""	router (computing)	Marco Liebsch;Ajoy Singh;Hemant Chaskar;Daichi Funato;Eunsoo Shim	2005	RFC	10.17487/RFC4066	engineering;world wide web;computer security;soft handover;computer network	Crypto	-24.411570065147924	87.30587227462742	37424
0d7909c9453d3de3595a554c68c5c6d0005f0b8c	routing algorithms in wdm networks under mixed static and dynamic lambda-traffic	blocking probability;wdm network;cost function;high priority;routing algorithm;mesh network;wavelength conversion;heuristic algorithm;discrete event simulation	Dynamic traffic is becoming important in WDM networks. In the transition towards full dynamic traffic, WDM networks optimized for a specific set of static connections will most likely also be used to support on-demand lightpath provisioning. Our paper investigates the issue of routing of dynamic connections in WDM networks which are also loaded with high-priority protected static connections. By discrete-event simulation we compare various routing strategies in terms of blocking probability and we propose a new heuristic algorithm based on an occupancy cost function which takes several possible causes of blocking into account. The behavior of this algorithm is tested in well-known case-study mesh networks, with and without wavelength conversion. Moreover, Poissonian and non-Poissonian dynamic traffics are considered.	algorithm;apollonian network;blocking (computing);erlang (unit);heuristic (computer science);mesh networking;path protection;provisioning;routing;simulation;wavelength-division multiplexing	Guido Maier;Achille Pattavina;Luigi Barbato;Francesca Cecini;Mario Martinelli	2004	Photonic Network Communications	10.1023/B:PNET.0000031619.18955.b4	heuristic;routing;static routing;real-time computing;computer science;dynamic source routing;discrete event simulation;mesh networking;distributed computing;computer network	Metrics	-5.451830470810684	84.03525759192986	37444
3361379b337918189e631d89dcb2efeb4167ee66	cumulon: cloud-based statistical analysis from users perspective		Cumulon is a system aimed at simplifying the development and deployment of statistical analysis of big data on public clouds. Cumulon allows users to program in their familiar language of matrices and linear algebra, without worrying about how to map data and computation to specific hardware and software platforms. Given user-specified requirements in terms of time, money, and risk tolerance, Cumulon finds the optimal implementation alternatives, execution parameters, as well as hardware provisioning and configuration settings—such as what type of machines and how many of them to acquire. Cumulon also supports clouds with auction-based markets: it effectively utilizes computing resources whose availability varies according to market conditions, and suggests best bidding strategies for such resources. This paper presents an overview of Cumulon and the challenges encountered in building this system.	big data;computation;linear algebra;money;provisioning;requirement;risk aversion;software deployment	Botong Huang;Nicholas W. D. Jarrett;Shivnath Babu;Sayan Mukherjee;Jun Yang	2014	IEEE Data Eng. Bull.		software;cloud computing;linear algebra;software deployment;data mining;bidding;computation;computer science;big data;distributed computing;provisioning	DB	-25.059220945631964	60.66489584001021	37569
161e546cb1295a058da893bcb4de7debf96cc780	fast path session creation on network processors	random access memory;classification algorithm;fast path processing;computed tomography;circuit faults;current transformers;parallel search cross producting;information science;authorisation;random access memory argon program processors fault currents computed tomography current transformers circuit faults;information technology;fault currents;distributed computing;network processor;intellihash;classification;crossed product;argon;computer networks;packet headers authentication;computer security;stateful intrusion prevention systems;tcp connection path session creation network processors security gateways unauthorized accesses packet headers authentication malicious intrusions stateful intrusion prevention systems tcp three way handshake scheme fast path processing two stage intelligent hashing parallel optimized flow classification algorithm parallel search cross producting intellihash;transport protocols;tcp three way handshake scheme;unauthorized accesses;intrusion prevention system;cryptography;security gateways;classification algorithms;process control;malicious intrusions;parallel optimized flow classification algorithm;binary search;two stage intelligent hashing;tcp connection;message authentication;computer science;network processor classification session;network processors;high performance;session;high speed;program processors;transport protocols authorisation computer networks cryptography message authentication microprocessor chips;path session creation;microprocessor chips;data security;automation	The security gateways today are required not only to block unauthorized accesses by authenticating packet headers, but also by inspecting connection states to defend against malicious intrusions. Hence session creation rate plays a key role in determining the overall performance of stateful intrusion prevention systems. In this paper, we propose a high-speed session creation scheme optimized for network processors. Main contribution includes: a) A high-performance flow classification algorithm on network processors; b) An efficient TCP three-way handshake scheme designed for fast-path processing using a two-stage intelligent hashing. Experimental results show that: a) The presented parallel optimized flow classification algorithm, Parallel Search Cross-Producting, outperforms the original Cross-Producting and Binary Search Cross-Producting algorithms with 300% and 60% increase of classification speed; b) The proposed fast path three-way handshake scheme, IntelliHash, achieves a TCP connection creation rate over 2M connections per second.	authentication;authorization;binary search algorithm;central processing unit;emoticon;fast path;intrusion detection system;network packet;network processor;stateful firewall	Bo Xu;Yaxuan Qi;Fei He;Zongwei Zhou;Yibo Xue;Jun Li	2008	2008 The 28th International Conference on Distributed Computing Systems	10.1109/ICDCS.2008.33	telecommunications;information science;computer science;theoretical computer science;operating system;process control;database;distributed computing;information technology;computer security;network processor;computer network	HPC	-6.7621464670314175	67.2724229262905	37573
9b76b84620a24b5d4b8c7bca38fba4d6c869040a	routing proposals for multipath interdomain routing	internet;routing protocols;telecommunication links;bgp;internet;border gateway protocol;independent autonomous systems;interdomain link failure;multipath interdomain routing;multipath routing technique;packet loss;polycy-based protol;reachability information dissemination;routing proposal;traffic flow;transit domain;bgp;interdomain routing;multipath and transient disconnectivity	Internet is composed of numbers of independent autonomous systems. BGP is used to disseminate reachability information and establishing path between autonomous systems. Each autonomous system is allowed to select a single route to a destination and then export the selected route to its neighbors. The selection of single best route imposes restrictions on the use of alternative paths during interdomain link failure and thus, incurred packet loss. Packet loss still occurs even when multiple paths exist between source and destination but these paths have not been utilized. To minimize the packet loss, when multiple paths exist, multipath routing techniques are introduced. Multipath routing techniques ensure the use of alternative paths on link failure. It computes set of paths which can be used when primary path is not available and it also provides a way to transit domains to have control over the traffic flow. This can be achieved by little modification to current BGP. This paper highlights different multipath routing techniques and also discusses the overhead incurred by each of them.	autonomous system (internet);bilateral filter;border gateway protocol;failover;forwarding plane;inter-domain;internet;multipath propagation;multipath routing;network architecture;network packet;overhead (computing);reachability;router (computing);scalability;tunneling protocol	Sardar Muhammad Bilal;Muhammad Naveed Dilber;Atta ur Rehman Khan	2012	2012 15th International Multitopic Conference (INMIC)		policy-based routing;routing domain;routing;enhanced interior gateway routing protocol;static routing;source routing;the internet;border gateway protocol;dsrflow;zone routing protocol;telecommunications;equal-cost multi-path routing;computer science;interior gateway protocol;dynamic source routing;multipath routing;destination-sequenced distance vector routing;distributed computing;routing protocol;link-state routing protocol;default-free zone;path vector protocol;geographic routing;routing information protocol;computer network	Networks	-7.850168711370268	86.05353488998038	37586
ce112f7a822be10a83f4eed1b0e206383a15c2bb	selecting news and elders in unstructured peer-to-peer network under churn	file servers;protocols;churn;computer crashes;peer to peer network;application software;churn concept;p2p information dissemination;file sharing system;churn peer to peer;protocols peer to peer computing;p2p;computer networks;protection;network servers;selecting news and elders protocol;information dissemination;file sharing system unstructured distributed peer to peer network selecting news and elders protocol churn concept conservative neighbor maintenance scheme p2p information dissemination;file sharing;computer science;peer to peer computing;peer to peer computing computer crashes protocols computer networks network servers application software computer science protection file servers costs;conservative neighbor maintenance scheme;peer to peer;unstructured distributed peer to peer network;flash crowds	The concept of Churn is the continuous process of node arrival and departure in distributed peer-to-peer network. There exists two eprotocol Selecting News and Eldersxtreme cases. The first one is that enormous nodes joining the system concurrently, which results in a flash crowd scenario for special nodes in the system. The other is that enormous nodes crashed or the connections between nodes are failed in a moment, which comes out a shrink search later. In this paper, we present a novel protocol Selecting News and Elders (SNE) with positive communication policy among peers and conservative neighbor maintenance scheme under churn, to keep desirable properties such as a low network diameter and clustering. The protocol is resilient against different churn and fit for P2P information dissemination and file sharing systems especially.	cluster analysis;file sharing;peer-to-peer;slashdot effect	Yanxiang He;Haowen Liu;Naixue N. Xiong;Laurence Tianruo Yang	2008	22nd International Conference on Advanced Information Networking and Applications - Workshops (aina workshops 2008)	10.1109/WAINA.2008.67	file server;communications protocol;application software;computer science;operating system;peer-to-peer;database;internet privacy;world wide web;file sharing;computer network	HPC	-13.53384669973723	73.80072646654753	37699
d40c86fd42aabb661fa5bf24c4baf807d8032499	virtual source based multicast routing in wdm optical networks	multicast routing;wavelength conversion capability;paper concern;wdm network;virtual source;virtual source;splitting capability;wdm optical networks;proposed algorithm;virtual source node;wavelength conversion;optical multicast routing;new multicast tree construction	Wavelength-division multiplexed (WDM) networks using wavelength-routing are considered to be potential candidates for the next generation wide-area backbone networks. Multicasting is the ability to transmit information from a single source node to multiple destination nodes and is becoming an important requirement in high-speed networks. As WDM technology matures and multicast applications become increasingly popular, supporting multicast routing at the WDM layer becomes an important and yet a challenging topic. This paper concerns with the problem of optical multicast routing in WDM networks. A few nodes in the network may have wavelength conversion and/or splitting capabilities. In this paper, a new multicast tree construction algorithm is proposed. This algorithm is based on a concept called virtual source. A virtual source is a node having both the splitting and wavelength conversion capabilities. By exploiting the presence of virtual source nodes, the proposed algorithm achieves improved performance. To further improve the performance, the algorithm assigns priorities to nodes based on their capabilities. The effectiveness of the proposed algorithm is verified through extensive simulation experiments.	algorithm;experiment;internet backbone;multicast;next-generation network;routing;simulation	N. Sreenath;Chebiyyam Siva Ram Murthy;Gurusamy Mohan	2001	Photonic Network Communications	10.1023/A:1011443013088	intelligent network;performance;telecommunications;protocol independent multicast;computer science;distributed computing;node;distance vector multicast routing protocol;source-specific multicast;network topology;xcast;wavelength-division multiplexing;computer network	HPC	-4.669810030023132	82.81599827084302	37717
a8cc43954f00042cd549d28e98018d5606aecc52	a scalable application-level multicast approach based on mobile agents	technology;mobile agents;telecommunication computing mobile agents multicast protocols internet;telecommunication computing;science technology;internet;multicast protocols;mobile agents multicast protocols cloning scalability java robust stability analytical models performance analysis local area networks hardware;simulation based comparative analysis mobile agents scalable application level multicast approach ip multicast dynamic networking environments;mobile agent;telecommunications;application level multicast	IP multicast is used to deliver services to groups of users. However, this approach needs an infrastructure support in place, which makes the service not always available. We propose a novel application-level multicast approach based on mobile agents, which does not require any specific layer 3 support and suits the requirements of dynamic networking environments. We present a simulation-based comparative analysis between our approach and DVMRP, focussing on performance and scalability.	mobile agent;multicast;qualitative comparative analysis;requirement;scalability;simulation	Carmelo Ragusa;Antonio Liotta;George Pavlou	2003		10.1109/ICON.2003.1266190	real-time computing;multicast;ip multicast;inter-domain;reliable multicast;telecommunications;mbone;protocol independent multicast;computer science;pragmatic general multicast;geocast;internet group management protocol;mobile agent;distributed computing;distance vector multicast routing protocol;source-specific multicast;multimedia broadcast multicast service;xcast;computer network;multicast address;technology	HPC	-10.438224479284454	83.75591801217168	37775
6d61319a127ca16567112b9dc67492378f772937	energy-efficient scheduling for parallel applications running on heterogeneous clusters	scientific application;energy efficient task duplication schedule;heterogeneous cluster;energy efficient;heterogeneous computing;task model;heterogeneous clusters;energy efficient scheduling algorithms;large scale;scheduling algorithm;energy efficient task duplication schedule energy efficient scheduling parallel applications heterogeneous clusters high performance clusters energy efficient scheduling algorithms;workstation clusters parallel algorithms scheduling;scheduling;high performance clusters;energy efficient scheduling;energy efficiency processor scheduling high performance computing energy consumption large scale systems algorithm design and analysis scheduling algorithm costs concurrent computing computational modeling;energy cost;workstation clusters;power consumption;high performance;parallel applications;parallel algorithms	High performance clusters have been widely used to provide amazing computing capability for both commercial and scientific applications. However, huge power consumption has prevented the further application of large-scale clusters. Designing energy-efficient scheduling algorithms for parallel applications running on clusters, especially on the high performance heterogeneous clusters, is highly desirable. In this regard, we propose a novel scheduling strategy called energy efficient task duplication schedule (EETDS for short), which can significantly conserve power by judiciously shrinking communication energy cost when allocating parallel tasks to heterogeneous computing nodes. We present the preliminary simulation results for Gaussian and FFT parallel task models to prove the efficiency of our algorithm.	algorithm;computer cluster;fast fourier transform;heterogeneous computing;scheduling (computing);simulation;supercomputer	Ziliang Zong;Xiao Qin;Xiaojun Ruan;Kiranmai Bellam;Mais Nijim;Mohammed I. Alghamdi	2007	2007 International Conference on Parallel Processing (ICPP 2007)	10.1109/ICPP.2007.39	parallel computing;real-time computing;computer science;operating system;distributed computing;scheduling;cost efficiency	HPC	-15.339512554718814	61.60214811351766	37788
d3c8ea81507ab1300ecd85d4937bed799e614480	wlan communities and internet access sharing: a regulatory overview	broadband networks;internet access;broadband internet connections wireless lan wlan communities internet access cellular networks mobile industry wireless internet service provider mobile network operators aggressive preemptive strategies;mobile computing wireless lan internet broadband networks mobile communication;wireless communication;internet;wireless lan ip networks land mobile radio cellular systems business disaster management web and internet services cities and towns investments throughput turning;mobile communication;cellular network;wireless internet service provider;wireless lan;point of view;mobile computing;mobile network operator	The widespread adoption of wireless LAN has paved the way for the emergence of a compelling alternative to cellular networks for obtaining Internet access on the move. This has generated interesting opportunities to a variety of players to position in the mobile industry as wireless Internet service provider. Mobile network operators have insofar managed to take control of this sector through aggressive preemptive strategies. However, the rapid emergence of private WLAN networks and broadband Internet connections among households has raised the crucial issue of the sharing of Internet access through these networks. While most owners are unaware of this, some have consciously organized themselves to form free wireless communities aiming at providing free Internet access to members or even to the public. One fundamental concern about this conduct is whether these sharing practices are allowed from a regulatory point of view, determine the rights and obligations of the various parties involved and the sanctions that they may incur. The purpose of this paper is to investigate this important issue by considering two examples of regulation (the French and Swiss ones) and examines its implication for the various actors involved.	consciousness;emergence;internet access;switzerland	Giovanni Camponovo;Davide Cerutti	2005	International Conference on Mobile Business (ICMB'05)	10.1109/ICMB.2005.118	motorola canopy;internet backbone;mobile broadband;mobile broadband modem;the internet;wireless wan;mobile web;imt advanced;internet access;public land mobile network;internet transit;wireless network;business;internet privacy;municipal wireless network;i-mode;mobile computing;policies promoting wireless broadband in the united states;internet connection sharing;computer security;computer network	DB	-14.845844672143008	88.45990745169796	37816
0b1284fb5da712f2b61b093e93d78af19647a393	elastic stream processing for the internet of things	hybrid clouds;stream processing;distributed data processing	Emerging trends like Big Data and the Internet of Things pose new challenges to established data stream processing engines. Especially, with the advent of the Internet of Things, the data that has to be processed can become very large. Since companies usually aim for cost efficiency, engines need to support resource elasticity to minimize the operational cost while maintaining real-time processing capabilities. In the work at hand, we propose and realize the distributed Platform for Elastic Stream Processing (PESP). An extensive evaluation demonstrates the practical feasibility and efficiency of the system design. The evaluation shows that PESP is able to reduce cost by 20% with minimal effects on the Quality of Service in comparison to an over-provisioning baseline. Compared to an under-provisioning baseline, PESP allows a Quality of Service improvement of 72%.	algorithm;baseline (configuration management);big data;channel (communications);cost efficiency;elasticity (cloud computing);elasticity (data store);image scaling;internet of things;load (computing);pattern recognition;peer-to-peer;provisioning;quality of service;real-time clock;requirement;stream (computing);stream processing;streaming media;system requirements;systems design	Christoph Hochreiner;Michael Vögler;Stefan Schulte;Schahram Dustdar	2016	2016 IEEE 9th International Conference on Cloud Computing (CLOUD)	10.1109/CLOUD.2016.0023	real-time computing;stream processing;computer science;operating system;database;world wide web	DB	-27.65348716676222	60.61283060316908	37918
fee2cb1c39f3c471a93378bfff1f233fd876c121	a study for task time performance dynamic prediction model in cloud resource scheduling	system load condition time performance cloud resource dynamic prediction model;statistical analysis;task time performance dynamic prediction model load conditions statistical property task completion time starting point task workload virtualization technology resource management cloud computing resource utilization method cloud resource scheduling;predictive models load modeling computational modeling data models analytical models cloud computing linear regression;virtualisation;virtualisation cloud computing statistical analysis;cloud computing	The unique of resource utilization method in cloud computing determines that there are strict requirements for the resource management and scheduling, as virtualization technology is widely applied in cloud computing, it extremely enhances the dynamic of the system and improves the efficiency of resource utilization. However, it also brings the resource scheduling with great challenges. Making an accurate prediction of task workload will improve the efficiency of cloud resource scheduling, and this paper regards this as the starting point, makes the task completion time as a metric of task workload, proposes a dynamic prediction model for task workload, studies the statistical property of task completion time in different load conditions, and the simulation experiment results show that the prediction model is correct and feasible.	cloud computing;requirement;scheduling (computing);simulation;x86 virtualization	Yeqiao Wang;Chunxiao Fan;Zhigang Wen	2012	2012 IEEE 2nd International Conference on Cloud Computing and Intelligence Systems	10.1109/CCIS.2012.6664426	real-time computing;simulation;cloud computing;computer science;operating system;cloud testing;distributed computing	Embedded	-22.179525534989008	62.08739563886454	37998
fc5f8221c5ac6754348494a3ec51a1475e2e1bb2	regular expression filtering on multiple q-grams		Regular expression matching is essential in network and big-data applications; however, it still has a serious performance bottleneck. The state-of-the-art schemes use a multi-pattern exact stringmatching algorithm as a filtering module placed before a heavy regular expression engine. We design a new approximate string-matching filter using multiple q-grams; this filter not only achieves better space compactness, but it also has higher throughput than the existing filters. key words: regular expression, string matching, q-gram, intrusion detection, deep packet inspection	approximate string matching;approximation algorithm;big data;deep packet inspection;grams;intrusion detection system;n-gram;network packet;regular expression;string searching algorithm;throughput	Seon-Ho Shin;HyunBong Kim;MyungKeun Yoon	2018	IEICE Transactions			Networks	-6.898193648093586	66.61643671474721	38054
fdc2416d4a662efea7afe9488fee39f371432410	an efficient link protection scheme for link-state routing networks	backup path;resilient routing;availability;telecommunication network routing computer network reliability resource allocation;network topology topology complexity theory computational modeling reliability routing quality of service;resilient routing backup path availability;backup path protection efficient link protection link state routing networks network reliability hybrid link protection failure resilient routing load balancing multiple next hop protection single shortest path tree construction	To enhance the network reliability without incurring significant extra overhead, we propose a novel link protection scheme, Hybrid Link Protection (HLP), to achieve failure resilient routing. Compared to previous schemes, HLP ensures high network availability in a more efficient way, and also provides other features such as load balancing. HLP is implemented in two stages. Stage one provides Multiple Next-hop Protection (MNP), where only one single Shortest Path Tree (SPT) needs to be constructed on each node to find multiple next hops for any destination. Stage two provides Backup Path Protection (BPP), where only a minimum number of links need to be protected, using special paths and packet headers, to meet the network availability requirement. We evaluate these algorithms in a wide spread of relevant topologies, both real and synthetic, and the results reveal that HLP can achieve high network availability without introducing conspicuous overhead.	algorithm;bpp (complexity);backup;business models for open-source software;link-state routing protocol;load balancing (computing);microcom networking protocol;network packet;next-generation network;overhead (computing);path protection;symmetry protected topological order;synthetic intelligence	Haijun Geng;Xingang Shi;Xia Yin;Zhiliang Wang;Han Zhang	2015	2015 IEEE International Conference on Communications (ICC)	10.1109/ICC.2015.7249282	policy-based routing;routing table;availability;optimized link state routing protocol;routing;static routing;real-time computing;equal-cost multi-path routing;multipath routing;destination-sequenced distance vector routing;distributed computing;routing protocol;link-state routing protocol;path vector protocol;computer network	Mobile	-6.979044303338866	80.65831537279297	38055
4cd707847d943b7faf319500d20e52ad495d56eb	characterizing inter-domain rerouting after japan earthquake	betweenness centrality;japan earthquake;bgp;inter domain routing	The Internet is designed to survive when some of its components become faulty. Rerouting is an important approach to bypassing faulty links. In this paper, we propose a method to characterize interdomain rerouting as a result of the massive earthquake in Japan on March 2011. Moreover, the characterization helps correlate inter-domain rerouting events and end-to-end path-quality degradation measured in Hong Kong. We analyse the variation of AS betweenness centrality extracted from BGP data to identify the time span when most routes changed, the ASes that were most seriously affected, and the correlative and backup paths. The results show that three major providers of inbound traffic to Hong Kong were affected by unstable routing state caused by a cable fault after the earthquake. Our work provides a new method of utilizing control plane’s information to diagnose data plane’s problem.	backup;betweenness centrality;border gateway protocol;classless inter-domain routing;control plane;control theory;denial-of-service attack;elegant degradation;end-to-end encryption;forwarding plane;hyperlink;inbound marketing;internet;router (computing);social network	Yujing Liu;Xiapu Luo;Rocky K. C. Chang;Jinshu Su	2012		10.1007/978-3-642-30054-7_10	geography;telecommunications;computer security;cartography	Metrics	-10.864820388536387	78.51964533048168	38085
077375fcf5f4311c9360d988057abc1d9b2ef28c	a framework for qos-aware traffic classification using semi-supervised machine learning in sdns	semi supervised;qos;conference paper;traffic classification;sdn;semi supervised machine learning	In this paper, a QoS-aware traffic classification framework for software defined networks is proposed. Instead of identifying specific applications in most of the previous work of traffic classification, our approach classifies the network traffic into different classes according to the QoS requirements, which provide the crucial information to enable the fine-grained and QoS-aware traffic engineering. The proposed framework is fully located in the network controller so that the real-time, adaptive, and accurate traffic classification can be realized by exploiting the superior computation capacity, the global visibility, and the inherent programmability of the network controller. More specifically, the proposed framework jointly exploits deep packet inspection (DPI) and semi-supervised machine learning so that accurate traffic classification can be realized, while requiring minimal communications between the network controller and the SDN switches. Based on the real Internet data set, the simulation results show the proposed classification framework can provide good performance in terms of classification accuracy and communication costs.	categorization;computation;deep packet inspection;feature extraction;internet;machine learning;network interface controller;network packet;network switch;network traffic control;quality of service;real-time clock;real-time computing;requirement;semi-supervised learning;semiconductor industry;simulation;software-defined networking;supervised learning;traffic classification;traffic exchange	Pu Wang;Shih-Chun Lin;Min Luo	2016	2016 IEEE International Conference on Services Computing (SCC)	10.1109/SCC.2016.133	traffic generation model;traffic classification;computer science;data mining;distributed computing;computer network	Metrics	-14.137477775612407	79.77054805478582	38089
1a7652b8b219c7bedb0375eb52771586c1dfaa1c	security policy system: status and perspective	policy based networking;internet telecommunication security message authentication transport protocols;data security virtual private networks authentication protocols databases access control quality of service protection authorization electrostatic precipitators;transport protocols;internet security policy system ipsec policy based networking architectural requirements functional requirements security policy provisioning network access control protocols authentication confidentiality ip networks;internet;telecommunication security;access control;message authentication;security policy	With the recent definition of the Security Policy System, IPsec has joined the area of policy-based networking. This paper discusses the general architectural and functional requirements for systems in charge of security policy provisioning, and presents a critical evaluation of SPS. Some extensions are also suggested to increase SPS functionality in the network access control field.	access network;authorization;entity;functional requirement;ibm 1401 symbolic programming system;ipsec;internet;network access control;provisioning;scalability;transport layer security	Madalina Baltatu;Antonio Lioy;Daniele Mazzicchi	2000		10.1109/ICON.2000.875802	computer security model;message authentication code;cloud computing security;password policy;ipsec;the internet;security through obscurity;computer access control;security information and event management;security association;covert channel;computer science;security policy;information security;access control;internet security;security service;distributed system security architecture;internet privacy;security analysis;security testing;network access control;network security policy;computer security;transport layer;computer network	Security	-25.091600594410114	86.42363128835896	38095
65d02f970e7d4fd6cfff0d38ccbd8264d58b8597	efficient filtering algorithm for repeated queries in dns log	filtering;domain name system;log files;cn tld root server log;query processing;efficient algorithm;information filtering;efficient filtering algorithm;data mining;filtering algorithms internet telecommunication traffic computer networks domain name system information filtering information filters web server intelligent networks computer applications;dns traffic;servers;cn tld root server log efficient filtering algorithm domain name system internet dns traffic query processing;internet;filtering algorithms;ip networks;algorithm design and analysis;query processing information filtering internet	The Domain Name System (DNS) is a fundamental component of the modern Internet, and repeated queries make up of a large amount of DNS traffic. To filter out the repeated queries in BIND DNS log file, an efficient algorithm is proposed. The algorithm is characterized by maintaining the time sequence of original queries during the processing. The experimental results using CN TLD root server log are analyzed.	algorithm;internet;server (computing);server log;time series	Zheng Wang;Xiaodong Lee;Jian Jin;Baoping Yan	2009	2009 Eighth IEEE International Symposium on Network Computing and Applications	10.1109/NCA.2009.31	filter;dns zone transfer;algorithm design;the internet;computer science;theoretical computer science;operating system;database;world wide web;domain name system;server;computer network	Metrics	-7.9398397689875875	68.16951970913645	38099
b24a52d62078cf8fd55bb69cc9f7c23c3cec17c8	parallel and distributed systems and networking track editorial	parallel and distributed system;file formats;buffer management;streaming media;mpeg 4;avi;divx	7he 06ject1ve 0f the P5DN track 15 t0 pr0v1de a f0rum f0r 5c1ent15t5, en91neer5 and pract1t10ner5 1n academ1a, 1ndu5try and re5earch 1n5t1tute5 t0 5hare techn1ca1 1dea5, exper1ence5 and re5u1t5 and t0 pre5ent the1r 1ate5t f1nd1n95 1n any a5pect5 0f Para11e1 and D15tr16uted C0mput1n9 and Netw0rk1n9. 7he t0p1c5 0f the track empha512e the de519n, arch1tecture and 50ftware 0f para11e1, d15tr16uted and netw0rk1n9 5y5tem5 w1th the1r 5c1ent1f1c and en91neer1n9 app11cat10n5.	distributed computing	Robert A. van Engelen;Turgay Korkmaz;Nectarios Koziris;Kleanthis Psarris	2003		10.1145/952532.952725	parallel computing;computer science;operating system;distributed computing;file format;mpeg-4;computer network	OS	-26.044575715078256	78.64008791788972	38140
abdbe2e35dbc6f3c042864eb54b467ec24e2b38a	control tasks delay reduction under static and dynamic scheduling policies	control systems;static scheduling;static scheduling policy;dynamic scheduling policies;dai;cai;control action delays;scheduling policies;control action interval;control performances;control task delay reduction;task decomposition;scheduling;dynamic scheduling policy;industrial control;control design phase control task delay reduction dynamic scheduling policy static scheduling policy industrial application digital control control algorithms control systems control performances data acquisition control action delays dynamic scheduling policies worst case response time static scheduling edf scheduling task decomposition data acquisition interval control action interval dai cai scheduling policies;data acquisition interval;edf scheduling;industrial application;control design phase;digital control;worst case response time;data acquisition;control algorithms;delays;delays scheduling industrial control data acquisition;delay dynamic scheduling job shop scheduling control systems data acquisition scheduling algorithm electrical equipment industry industrial control digital control algorithm design and analysis	Industrial application of digital control requires the synergy between well designed control algorithms and carefully implemented control systems. The control performances can be strongly influenced depending on the data acquisition and control action delays. The paper shows how to evaluate these delays (jitter) under static or dynamic scheduling policies. An evaluation of several set of tasks executed under both scheduling policies is analysed and compared. The results allow us to determine the goodness of both algorithms with respect to the delays due to scheduling. While worst case response time in static scheduling can be easily determined, under EDF scheduling the result is not trivial. A method to determine the worst case response time under EDF scheduling is proposed. The measurement of these delays can be drastically reduced with a task decomposition. This decomposition is studied and evaluated from the delays point of view. The reduction of the data acquisition interval (DAI) and control action interval (CAI) under both scheduling policies can be considered in the control design phase in order to properly adjust the control algorithm.	algorithm;best, worst and average case;control system;data acquisition;earliest deadline first scheduling;performance;response time (technology);scheduling (computing);synergy	Patricia Balbastre Betoret;Ismael Ripoll;Alfons Crespo	2000		10.1109/RTCSA.2000.896437	fair-share scheduling;fixed-priority pre-emptive scheduling;real-time computing;earliest deadline first scheduling;flow shop scheduling;digital control;dynamic priority scheduling;computer science;control system;rate-monotonic scheduling;operating system;distributed computing;gain scheduling;data acquisition;round-robin scheduling;scheduling	Embedded	-9.68542101852507	61.02552698073513	38141
6a884981d10785cb5a9ff6a84ec8ed1595a25554	virtual private lan service (vpls) interoperability with customer edge (ce) bridges		One of the main motivations behind Virtual Private LAN Service (VPLS) is its ability to provide connectivity not only among customer routers and servers/hosts but also among customer IEEE bridges. VPLS is expected to deliver the same level of service that current enterprise users are accustomed to from their own enterprise bridged networks or their Ethernet Service Providers. When customer edge (CE) devices are IEEE bridges, then there are certain issues and challenges that need to be accounted for in a VPLS network. The majority of these issues have been addressed in the IEEE 802.1ad standard for provider bridges and they can be leveraged for VPLS networks. This document extends the provider edge (PE) model described in RFC 4664 based on IEEE 802.1ad bridge module, and it illustrates a clear demarcation between the IEEE bridge module and IETF LAN emulation module. By doing so, it shows that the majority of interoperability issues with CE bridges can be delegated to the 802.1ad bridge module, thus removing the burden on the IETF LAN emulation module within a VPLS PE. Sajassi, et al. Informational [Page 1] RFC 6246 VPLS Interop with CE Bridges June 2011	customer edge;demarcation point;emulator;interoperability;provider edge;semantic network;virtual private lan service	Ali Sajassi;Frank Brockners;Dinesh Mohan;Yetik Serbest	2011	RFC	10.17487/RFC6246	computer network	Visualization	-23.464547461028378	88.00020230745758	38210
89483dabedbfb20c476f632ccdb593f0be22fae7	performance of adaptive space-sharing policies in dedicated heterogeneous cluster systems	performance evaluation;heterogeneous systems;heterogeneous cluster;processor scheduling;space sharing policies;heterogeneous clusters;performance improvement;cluster system;user requirements;cluster systems	In this paper, we propose a new two-level space-sharing policy for dedicated heterogeneous systems. This policy is based on the concept of basic processor unit (BPU). At a higher level, the policy computes the partition size in terms of BPUs. At the second-level, the BPUs of the first level are mapped to physical processors. The proposed policy is an adaptive space-sharing policy as this type of policy has been shown, in homogeneous systems, to provide better performance than the fixed and static policies by taking system load and user requirements into account. We compare the performance of our new policy with a previous policy. The results presented here show that the proposed policy provides substantial performance improvements at system loads of interest (i.e., medium to high system loads). © 2004 Elsevier B.V. All rights reserved.	central processing unit;clustered file system;load (computing);requirement;user requirements document	Sivarama P. Dandamudi;Zhengao Zhou	2004	Future Generation Comp. Syst.	10.1016/j.future.2004.02.001	parallel computing;real-time computing;simulation;computer science;user requirements document;operating system;distributed computing	HPC	-14.87397920684055	60.49701911710035	38280
0c2f0459a20ae9abc0a455e79c4b0dccc1c6305b	djsb: dynamic job scheduling benchmark		High-performance computing (HPC) systems are very big and powerful systems, with the main goal of achieving maximum performance of parallel jobs. Many dynamic factors influence the performance which makes this goal a non-trivial task. According to our knowledge, there is no standard tool to automatize performance evaluation through comparing different configurations and helping system administrators to select the best scheduling policy or the best job scheduler. This paper presents the Dynamic Job Scheduler Benchmark (DJSB). It is a configurable tool that compares performance metrics for different scenarios. DJSB receives a workload description and some general arguments such as job submission commands and generates performance metrics and performance plots. To test and present DJSB, we have compared three different scenarios with dynamic resource management strategies using DJSB experiment-driven tool. Results show that just changing some DJSB arguments we can set up and execute quite different experiments, making easy the comparison. In this particular case, a cooperative-dynamic resource management is evaluated compared with other resource management approaches.		Víctor López;Ana Jokanovic;Marco D'Amico;Marta Garcia;Raúl Sirvent;Julita Corbalán	2017		10.1007/978-3-319-77398-8_10	computer science;resource management;real-time computing;workload;distributed computing;job scheduler;scheduling (computing)	HPC	-17.87210949886727	60.689905448626995	38377
900c8111304c41d1ce02b4910621bdbc41b41d80	configuration and performance issues in the metanet design	sense of direction;shortest path;fairness;convergence;performance evaluation;metropolitan area networks;routing;arbitrary topology;online routing decisions;local flow of traffic;distributed computing;design parameters;deflection routing;configuration issues;lan man architecture;virtual embedding configurations;computer networks;network topology;telecommunication traffic;fault tolerance;convergence routing;bandwidth;broadcasting;switch based lan configuration issues fairness performance issues metanet design virtual embedding configurations design parameters online routing decisions local flow of traffic load conditions convergence routing lan man architecture arbitrary topology;local area networks routing bandwidth convergence telecommunication traffic broadcasting fault tolerance network topology computer networks distributed computing;performance issues;metanet design;local area networks;switch based lan;load conditions	This paper examines various virtual embedding configurations fo r the MetaNet architecture. It compares and contrast the suggested embedding structures, and identifies design parameters and their trade-off. This study is based on the combination of convergence routing with the fairness mechanism, which controls the internal traffic load. More specifically, the fairness is used as a mechanism to ensure that the network internally will not be over-loaded. Therefore, packets can be sent from source to destination on a route which is close to the shortest path. The routing on the MetaNet is a variant of deflection routing. It makes on-line routing decisions based on the local flow of traffic (load conditions). Unlike other deflection techniques the MetaNet routing is along a global sense of direction, which guarantees that packets will reach their destinations. Therefore, we call this method convergence routing (previous deflection algorithms did not guarantee deterministic routing convergence, i. e., a cell/packet can be deflected indefinitely inside the network). The MetaNet is a LAN/MAN architecture with an ”arbitrary topology” (i.e., a switch-based LAN). Its design provides on one hand a service in which every node can try to transmit asynchronously, in a bursty manner without reservation, as much as it can, as in sharedmedia LANs. On the other hand, the network access and flow control ensure the following properties: (1) no cell/packet loss due to congestion, (2) fair access to the network and (3) broadcast-with-feedback. The switching over this network requires only a single buffer per link as in bufler insertion rings.	access network;algorithm;deterministic routing;fairness measure;metanet software;network congestion;network packet;online and offline;shortest path problem;virtual lan	Bülent Yener;Yoram Ofek;Moti Yung	1993		10.1109/LCN.1993.591236	static routing;real-time computing;convergence;computer science;dynamic source routing;distributed computing;computer network	Networks	-4.993470640881044	87.04827602639996	38471
91d36f4f9ce16708bf36a114ca34abc97e91a9d0	a ptas for static priority real-time scheduling with resource augmentation	static priority;approximation algorithms;fixed priority;real time scheduling	We present a polynomial time approximation scheme for the real-time scheduling problem with fixed priorities when resource augmentation is allowed. For a fixed ε> 0, our algorithm computes an assignment using at most (1+ε)·OPT +1 processors in polynomial time, which is feasible if the processors have speed 1+ε. We also show that, unless P = N P , there does not exist an asymptotic FPTAS for this problem.	algorithm;central processing unit;like button;ptas reduction;polynomial;polynomial-time approximation scheme;real-time clock;scheduling (computing);time complexity	Friedrich Eisenbrand;Thomas Rothvoß	2008		10.1007/978-3-540-70575-8_21	priority inheritance;fixed-priority pre-emptive scheduling;mathematical optimization;real-time computing;earliest deadline first scheduling;dynamic priority scheduling;computer science;rate-monotonic scheduling;deadline-monotonic scheduling;mathematics;distributed computing;approximation algorithm;priority ceiling protocol	Theory	-10.509955449578944	61.26214822322941	38710
8ffaf6e338cbf799bcc4501bbf9eb5ed825295a7	dynamic scheduling of real-time tasks, by assignment	automatic control;assignment;prediccion;asignacion;multiprocesseur numa;gestion labor;multiprocessor;processor scheduling;equilibrio de carga;real time;equilibrage charge;assignation;satisfiability;algorithme;algorithm;numa architecture multiprocessor architecture real time tasks scheduling sequence oriented representation problem constraints assignment oriented representation rt sad algorithm;gestion tâche;parallel architectures;multiprocessor architecture;temps reel;numa multiprocessor;load balancing;tiempo real;parallel architectures processor scheduling multiprocessing systems;multiprocessing systems;task scheduling;multiprocesador;prediction;dynamic scheduling processor scheduling costs scheduling algorithm time factors process design timing heuristic algorithms scalability delay;dynamic scheduling;algoritmo;multiprocesseur	Sequencing and assignment are two important issues we need to address a when scheduling real-time tasks on a multiprocessor architecture. Different problem representations can schedule such tasks, each emphasizing either a sequencing or assignment task. A sequence-oriented representation satisfies problem constraints by emphasizing the search for an appropriate tasks order, while an assignment-oriented representation emphasizes the search for an appropriate assignment of tasks. The authors introduce the RT-SAD algorithm, which uses an assignment-oriented representation to dynamically schedule tasks on the processors of a NUMA architecture. The proposed technique automatically controls and allocates the scheduling time to minimize the scheduling overhead and deadline violation of real-time tasks. The authors compare RT-SADS performance with another dynamic algorithm that uses a sequence-oriented representation. The results show interesting performance trade-offs among the candidate algorithms.	real-time clock;scheduling (computing)	Babak Hamidzadeh;Yacine Atif	1998	IEEE Concurrency	10.1109/4434.736402	parallel computing;real-time computing;multiprocessing;prediction;dynamic priority scheduling;computer science;generalized assignment problem;load balancing;operating system;deadline-monotonic scheduling;automatic control;assignment;distributed computing;programming language;multiprocessor scheduling;satisfiability	Embedded	-12.914090885988552	61.81817727762393	38749
d036df251117d33ccdacaeca95fe9b522373b294	differentiated recovery in wdm networks	spare capacity allocation;delay sensitive recovery;dual failure;differentiated survivability	A scheme is proposed for supporting dual-failure priority-aware survivability in wavelength division multiplexing (WDM) networks with two classes of working traffic by means of a proportional spare capacity allocation strategy. The proposed scheme not only provides a differentiated recovery capability but also maximizes the capacity utilization. A simple routing strategy for enabling multi-priority delay-aware survivability in WDM networks with three classes of working traffic is also proposed. The simulation results show that the dual-failure recovery scheme achieves the desired restoration ratio for the two classes of working traffic given appropriate settings of the reservation and allocation ratios. In addition, it is shown that the multi-priority delay-aware survivability scheme successfully achieves a delay-sensitive differentiated recovery capability.	circuit restoration;network topology;optical mesh network;routing;simulation;single point of failure;wavelength-division multiplexing	Jung-Shian Li;Ching-Fang Yang	2011	Photonic Network Communications	10.1007/s11107-011-0311-5	telecommunications;computer network	Mobile	-7.810142861196095	83.04378692749216	38821
5933ea60f1f204d6b9740459611c80ffa89df60b	application-layer group communication server for extending reliable multicast protocols services	distributed application;wide area networks transport protocols computer network reliability local area networks;group communications;network protocol;service provider;telecommunication network reliability;reliable multicast transport protocols;application software;heterogeneous environments;computer aided instruction;distance learning;performance;collaboration;multicast protocols telecommunication network reliability computer aided instruction local area networks wide area networks application software collaboration multimedia systems computer science network servers;primitive group communication services;application interface;iri distance learning;lan;performance application layer group communication server reliable multicast protocols services group communications iri distance learning application layer reliable multicast server primitive group communication services heterogeneous environments lan wan networks automatic fault recovery application interface;application layer reliable multicast server;satisfiability;group communication;multimedia systems;reliable multicast;distributed applications;transport protocols;network servers;col;application layer group communication server;multicast protocols;reliable multicast transport;wan networks;computer science;automatic fault recovery;reliable multicast protocols services;fault recovery;local area networks;wide area networks;computer network reliability	Reliable multicast protocols are becoming an essential ele m nt in distributed applications such as interactive distance learning applications. However, the existin g implementations of reliable multicast protocols are not sufficient to satisfy the group communications requi r ments of some distributed applications. Our experience of using number of multicast protocols in IRI dis tance learning applications shows the necessity of providing an application-layer Reliable Multic ast Server (RMS) to extend the primitive group communication services provided by such multicast protoco ls. Examples of such services include handling heterogeneous environments (such as LAN vs. WAN networks an d different reliable multicast protocols), automatic fault recovery and simple application interface . In this paper, we motivate and describe the design and the implementation of RMS architecture which has been used in IRI learning sessions for two semesters. We also show how RMS improves the reliability, pe rformance and flexibility of IRI sessions via supporting extended group communication services.	atm turbo;application programming interface;distributed computing;experiment;inter-protocol exploitation;limbo;multicast;real-time clock;requirement;scheduling (computing);television	Ehab Al-Shaer;Hussein M. Abdel-Wahab;Kurt Maly	1997		10.1109/ICNP.1997.643728	local area network;real-time computing;multicast;ip multicast;inter-domain;reliable multicast;protocol independent multicast;computer science;operating system;pragmatic general multicast;internet group management protocol;distributed computing;distance vector multicast routing protocol;source-specific multicast;xcast;computer network;multicast address	Networks	-23.31126730124136	71.70649712424267	38826
b54b871315642d870b6fe3a284e56fd7a7850f30	multicasting in the scoq switch	switches packet switching sorting feedback centralized control asynchronous transfer mode tin samarium teleconferencing local area networks;point to point;queueing theory;packet switched;packet switching;nonblocking switch scoq switch fast packet switch output queueing shared concentration point to point transmissions point to multipoint functions multicasting packet duplications copy network feedforward path point to point switching feedback position point to point information transfer input buffers feedback loop;information transfer;queueing theory packet switching electronic switching systems;feedback loop;electronic switching systems;functional requirement;high performance	SCOQ, a high performance fast packet switch with Shared Concentration and Output Queueing, as described in [l], supports point-to-point transmissions only. The incorporation of multicast (point-tomultipoint) functions require packet duplications. If the copy network were placed on the feedforward path of the switch, it is not transparent to, and can interfere with, point-to-point switching. By placing the copy network in the feedback position, its operation can be made transparent to the point-to-point information transfer. The copy network incorporated onto the SCOQ switch is non-blocking even without an arbitration or selection network. Contrary to the feedforward approach in which the input buffers must be centrally controlled, with the copy network in the feedback loop, the input buffers all operate independent of	blocking (computing);feedback;feedforward neural network;multicast;network packet;non-blocking algorithm;packet switching;point-to-point protocol	David X. Chen;Jon W. Mark	1994		10.1109/INFCOM.1994.337606	real-time computing;lan switching;information transfer;fast packet switching;point-to-point;computer science;processing delay;cut-through switching;feedback loop;distributed computing;transmission delay;queueing theory;packet switch;burst switching;functional requirement;packet switching;circuit switching;computer network	Networks	-5.319596894732852	87.91069947842874	38881
621bdb101efa8ac76c704d96d20b9ed973ceb480	allocating roadside units in vanets using a variable neighborhood search strategy		In this work, we propose a GRASP+VNS algorithm for solving the allocation of Roadside Units (RSUs) in a Vehicular Network. Our main objective is to find the minimum set of RSUs to meet a Deployment Delta (ρ1,ρ2). The Deployment Delta (ρ1,ρ2) is a metric for specifying minimal communication guarantees from the infrastructure supporting the Vehicular Network. We compare GRASP+VNS to some baseline algorithms: (i) Delta-g; (ii) Delta-r and, (iii) the optimal value. Our results demonstrate that our approach requires up to 90% less Roadside Units to meet the QoS required by Deployment Delta (ρ1,ρ2) metric. Besides, different from the baseline algorithms, our approach find results that differ no more than 17% from the optimal values for all tested instances.	algorithm;baseline (configuration management);optimization problem;quality of service;software deployment;variable neighborhood search	Joao F. M. Sarubbi;Tais R. Silva;Flávio V. C. Martins;Elizabeth F. Wanner;Cristiano M. Silva	2017	2017 IEEE 85th Vehicular Technology Conference (VTC Spring)	10.1109/VTCSpring.2017.8108447	resource management;delta;computer network;quality of service;computer science;software deployment;variable neighborhood search;grasp;distributed computing;mathematical optimization	Metrics	-8.603280281563872	75.4804058005726	38901
98c0cd3c031a708a5d26cbf3bc4907904bdc4a7a	truck scheduling on multicore			multi-core processor;schedule (project management)	Victor Pankratius;Walter F. Tichy	2011	it - Information Technology	10.1524/itit.2011.0626	fair-share scheduling;embedded system;real-time computing	EDA	-11.22666511889814	61.90520948541414	38907
aa9f6c807ec6757e7cca21efefafa35185b6f2e4	an investigation into the application of different performance prediction techniques to e-commerce applications	hd industries land use labor;electronic commerce;performance evaluation;predictive models resource management application software delay queueing analysis data analysis quality management quality of service performance analysis java;resource allocation;e commerce;queueing theory;benchmark testing grid computing resource allocation electronic commerce quality of service queueing theory performance evaluation;hf commerce;qa76 electronic computers computer science computer software;qa75 electronic computers computer science;data analysis;e commerce benchmark performance prediction models e commerce applications grid workload management e commerce clients quality of service resource allocation coarse grained modelling approaches layered queuing modelling historical performance data analysis heterogeneous servers;performance model;performance prediction;quality of service;grid computing;benchmark testing	Summary form only given. Predictive performance models of e-Commerce applications allows grid workload managers to provide e-Commerce clients with qualities of service (QoS) whilst making efficient use of resources. We demonstrate the use of two 'coarse-grained' modelling approaches (based on layered queuing modelling and historical performance data analysis) for predicting the performance of dynamic e-Commerce systems on heterogeneous servers. Results for a popular e-Commerce benchmark show how request response times and server throughputs can be predicted on servers with heterogeneous CPUs at different background loads. The two approaches are compared and their usefulness to grid workload management is considered.	benchmark (computing);central processing unit;e-commerce;performance prediction;quality of service;response time (technology);scalability;server (computing);throughput;while	David A. Bacigalupo;Stephen A. Jarvis;Ligang He;Graham R. Nudd	2004	18th International Parallel and Distributed Processing Symposium, 2004. Proceedings.	10.1109/IPDPS.2004.1303306	e-commerce;benchmark;parallel computing;real-time computing;simulation;quality of service;resource allocation;computer science;operating system;database;distributed computing;data analysis;queueing theory;grid computing;computer network	HPC	-23.063182818967924	63.052065359767745	39004
0a7836349d705ac3a37d6abf3f830703e5e9548f	bgp-based locality promotion for p2p applications	routing information bgp based locality promotion p2p applications isp;topology;routing protocols;routing;isp;p2p;network topology;telecommunication traffic;servers;routing information;telecommunication network routing;p2p applications;telecommunication traffic peer to peer computing telecommunication network routing;ip networks;bgp based locality promotion;servers routing peer to peer computing ip networks routing protocols topology network topology;peer to peer computing	P2P applications attract a lot of users and generate the dominant portion of the overall traffic in the Internet today. On the one hand, this large amount of traffic results in high operational costs for ISPs, mainly because of expensive interdomain connections. On the other hand, the performance of P2P applications is constricted by suboptimal peer selection or by bandwidth limitations of ISPs. To overcome these problems, the collaboration of P2P applications and ISPs is desirable, where locality promotion is one of the possible approaches. In this paper, we propose a locality promotion mechanism based on BGP routing information of an ISP and show by simulations that it can reduce inter-domain traffic, prefers shorter connections and peering links over transit links while P2P applications can achieve a better performance as well.	bittorrent;border gateway protocol;bottleneck (engineering);download;exponent bias;inter-domain;locality of reference;network topology;overlay network;peer-to-peer;peering;routing;simulation;swarm	Peter Racz;Simon Oechsner;Frank Lehrieder	2010	2010 Proceedings of 19th International Conference on Computer Communications and Networks	10.1109/ICCCN.2010.5560090	routing;computer science;peer-to-peer;distributed computing;routing protocol;computer security;network topology;server;computer network	Visualization	-11.5786368822475	78.08532032942082	39005
11a0e4e629ca38dcdb285cf656bec4ee398bbdb6	a scalable and hierarchical p2p architecture based on pancake graph for group communication			scalability	Abdelhalim Hacini;Mourad Amad;Fouzi Semchedine	2017	J. High Speed Networks	10.3233/JHS-170572	pancake graph;theoretical computer science;architecture;communication in small groups;scalability;computer science;distributed computing	Networks	-13.883146567304266	72.65929997238858	39033
e35a582ba60a62e92d01e3528db4da411fc9e9fa	connection availability analysis of span-restorable mesh networks	allocation rule;network performance;failure mode;computational method;mesh network	Dual-span failures are the key factor of the system unavailability in a mesh-restorable network with full restorability of single-span failures. Availability analysis based on reliability block diagrams is not suitable to describe failures of mesh-restorable networks with widely distributed and interdependent spare capacities. Therefore, a new concept of restoration-aware connection availability is proposed to facilitate the analysis. Specific models of span-oriented schemes are built and analyzed. By using the proposed computation method and presuming dual-span failures to be the only failure mode, we can exactly calculate the average connection unavailability with an arbitrary allocation rule for spare capacity and no knowledge of any restoration details, or the unavailability of a specific connection with known restoration details. Network performance with respect to connection unavailability, traffic loss, spare capacity consumption, and dual failure restorability is investigated in a case study for an optical span-restorable long-haul network.	backup;circuit restoration;computation;concatenation;downtime;emoticon;failure cause;interdependence;mesh networking;network performance;ordered pair;reliability block diagram;return-oriented programming;simulation;switzerland;unavailability	Ling Zhou;Marcel Held;Urs Sennhauser	2007	Photonic Network Communications	10.1007/s11107-007-0062-5	computer science;mesh networking;network performance;failure mode and effects analysis;computer network	Networks	-6.729914151060584	78.2928890538384	39065
0efb8202db17750627b9a91349abd8656bea810f	a stochastic model for heterogeneous computing and its application in data relocation scheme development	stochastic modeling;optimisation;data relocation;application software;heterogeneous computing;search space;processor scheduling;high speed networks;optimal matching;greedy algorithms;random variables;computer architecture optimisation stochastic processes application program interfaces;computer applications;computer networks;optimization problem;computer architecture;stochastic processes;application program;optimal scheduling;scheduling;data relocation scheme development;matching;greedy algorithm based approach;application program interfaces;random variable;local optimization criterion;greedy algorithm;multiple independent subtasks;systems and applications;global optimization;optimization;mapping;local optimization criterion stochastic model heterogeneous computing data relocation scheme development application program multiple independent subtasks optimization problem optimal matching scheduling greedy algorithm based approach;stochastic model;stochastic processes computer applications processor scheduling application software random variables optimal matching computer networks greedy algorithms hardware high speed networks;data transfer;hardware	In a dedicated, mixed-machine, heterogeneous computing (HC) system, an application program may be decomposed into subtasks, then each subtask assigned to the machine where it is best suited for execution. Data relocation is defined as selecting the sources for needed data items. It is assumed that multiple independent subtasks of an application program can be executed concurrently on different machines whenever possible. A theoretical stochastic model for HC is proposed, in which the computation times of subtasks and communication times for intermachine data transfers can be random variables. The optimization problem for finding the optimal matching, scheduling, and data relocation schemes to minimize the total execution time of an application program is defined based on this stochastic HC model. The global optimization criterion and search space for the above optimization problem are described. It is validated that a greedy algorithm-based approach can establish a local optimization criterion for developing data relocation heuristics. The validation is provided by a theoretical proof based on a set of common assumptions about the underlying HC system and application program. The local optimization criterion established by the greedy approach, coupled with the search space defined for choosing valid data relocation schemes, can help developers of future practical data relocation heuristics.	computation;computational resource;data dependency;data element;data item;directed graph;emoticon;global optimization;graph (discrete mathematics);greedy algorithm;heterogeneous computing;heuristic (computer science);identifier;iteration;local search (optimization);matching (graph theory);mathematical optimization;nat (unit);optimal matching;optimization problem;p (complexity);run time (program lifecycle phase);scheduling (computing);theoretical definition;time complexity	Min Tan;Howard Jay Siegel	1998	IEEE Trans. Parallel Distrib. Syst.	10.1109/71.735956	random variable;mathematical optimization;greedy algorithm;computer science;theoretical computer science;distributed computing;statistics;global optimization	DB	-13.353755558721494	60.854469714478796	39119
bea7b023920855ce267bb8bb09323e965f9458fe	network flow query language—design, implementation, performance, and applications	protocols;standards;band pass filters;behavioural signatures network flow query language design network flow query language performance network flow query language application cisco netflow protocol internet engineering task force internet protocol flow information export open standard network flow statistics traffic patterns expressive queries flow record processing absolute filters relative filters allen interval algebra rules group record merging nfq1 silk operational capabilities nfql ssh compromise detection attacks;protocols database languages ip networks pipelines band pass filters standards internet;ssh compromise detection netflow ipfix flow tools nfdump silk application signatures;internet;pipelines;ip networks;transport protocols algebra computer network security digital signatures internet merging query languages telecommunication traffic;database languages	Cisco’s NetFlow protocol and Internet engineering task force’s Internet protocol flow information export open standard are widely deployed protocols for collecting network flow statistics. Understanding intricate traffic patterns in these network statistics requires sophisticated flow analysis tools that can efficiently mine network flow records. We present a network flow query language (NFQL), which can be used to write expressive queries to process flow records, aggregate them into groups, apply absolute or relative filters, and invoke Allen interval algebra rules to merge group records. We demonstrate nfql, an implementation of the language that has comparable execution times to SiLK and flow-tools with absolute filters. However, it trades performance when grouping and merging flows in favor of more operational capabilities that help increase the expressiveness of NFQL. We present two applications to demonstrate richer capabilities of the language. We show queries to identify flow signatures of popular applications and behavioural signatures to identify SSH compromise detection attacks.	aggregate data;allen's interval algebra;antivirus software;compiler;data-flow analysis;flow network;lazy evaluation;performance evaluation;query language;silk	Vaibhav Bajpai;J&#x00FC;rgen Sch&#x00F6;nw&#x00E4;lder	2017	IEEE Transactions on Network and Service Management	10.1109/TNSM.2016.2633511	communications protocol;the internet;computer science;operating system;data mining;database;band-pass filter;pipeline transport;law;world wide web;computer security;query language;computer network	Security	-23.270732625015963	85.00421654330864	39144
2621ff44e8899c7f07e4eb6e6ab1aead1c4eeb24	radiator - an approach for controllable wireless networks	wireless networks;media access protocol;metadata;wireless lan computer network management computer network performance evaluation computer network security public domain software software defined networking telecommunication traffic;open source software radiator controllable wireless networks software defined networking architecture enterprise wireless local area networks wlan chipsets ieee 802 11 frames management tasks beaconing client authentication lightweight wireless access points thin ap media access conversion radio frequency conversion simple task scheduling traffic filtering precise frame transmit timings rf spectrum analysis client geolocalization energy consumption optimization cots devices;ieee 802 11 standard communication system security wireless lan wireless networks metadata media access protocol;wireless lan;ieee 802 11 standard;communication system security	In this paper we propose a novel software-defined networking architecture for enterprise wireless local area networks (WLANs). The goal is to build a framework that exposes tools and methods for a centralized processing of IEEE 802.11 frames. In our architecture all management tasks, including beaconing, client authentication and association, are performed by the central controller instead of the distributed wireless access points as in traditional networks. The generated frames are tunneled to lightweight wireless access points (APs) or thin APs that perform the media access and radio frequency (RF) conversion. Agents executed on thin APs allow scheduling of simple tasks like traffic filtering for local execution. Additionally, the agents provide functions found in modern WLAN chipsets, such as precise frame transmit timings or RF spectrum analysis to the controller. Our architecture allows to delegate computationally intensive tasks to a central instance with enough processing power. Thus, it is best suited for devices with limited resources that we use as thin APs. We present applications that can be built using our framework, e.g., client geolocalization or energy consumption optimization. Finally we evaluate the performance of our architecture in a testbed using COTS devices with open-source software.	algorithm;anomaly detection;authentication;centralized computing;chipset;denial-of-service attack;enterprise software;interference (communication);internet of things;machine learning;mathematical optimization;open-source software;radio frequency;reliability engineering;scheduling (computing);sensor;single point of failure;software framework;software-defined networking;testbed;thin client;wireless access point	Radoslaw Cwalinski;Hartmut König	2016	2016 IEEE NetSoft Conference and Workshops (NetSoft)	10.1109/NETSOFT.2016.7502421	embedded system;service set;wi-fi;real-time computing;wireless wan;wireless site survey;inter-access point protocol;computer science;radio resource management;wireless network;wireless distribution system;wireless lan controller;key distribution in wireless sensor networks;capwap;municipal wireless network;wi-fi array;fixed wireless;network access control;wireless intrusion prevention system;hidden node problem;computer network;ieee 802.11e-2005	Mobile	-17.915366884583285	86.0014555982241	39271
f92aa6a087ae96946bfdcfd23e63a7732a2b17a7	object caching model for cell phone mobile database	cell-phone database minimum object replication identification;dynamic adoptive object access pattern identification.;dewma scheme;mobile computer;mobile database;mathematical model	Inherent limitations of mobile computing environment such as limited bandwidth, limited resourced mobile phones, and instability of wireless environment require summarized mobile database at mobile phones. Therefore the critical database summarization is done through an adoptive model incorporating object accessibility pattern in database queries by making optimal use of exponentially weighted moving averages. The database will keep only most frequently access objects at mobile phone to improve performance and provide high data availability for disconnected operations. Mathematical model and summarization scheme is proposed, along with simulation study, which identifies most frequently accessed objects to ensure high data availability for small memory mobile phones.	accessibility;database;instability;mathematical model;mobile computing;mobile phone;simulation;web cache	Khubaib Ahmed Qureshi	2006			phone;mobile database;mobile search;world wide web;mobile phone;mobile technology;mobile station;mobile computing;computer science	DB	-15.50890460450665	68.52825498597107	39320
0131eb93f0befbaedb476e6ba7d0cdfe3aaa5e30	dynamic scheduling on a pc cluster	traveling salesman problem;heterogeneous systems;iterative algorithms;heterogeneous computing;optimal method;optimization method;iterative algorithm;pc cluster;heterogeneous system;automatic classification;language model;dynamic scheduling;asymmetric traveling salesman problem	The goal of this work is to generate a better scheme for communicating data among subtasks during application program execution. Dynamic scheduling on a heterogeneous system PC cluster was implemented to minimize the application program execution time. Our method decomposes the program workload into computationally homogeneous subtasks, which may be of different size, depending on the current load of each machine in a heterogeneous computer system. We present some experimental results of two practical applications. The first one is called automatic classification of words in language modeling, and the second one is the asymmetric traveling salesman problem.	computer cluster;language model;run time (program lifecycle phase);scheduling (computing);travelling salesman problem	Janez Brest;Viljem Zumer;Milan Ojstersek	1999		10.1145/298151.298428	2-opt;mathematical optimization;dynamic priority scheduling;computer science;theoretical computer science;operating system;distributed computing;iterative method;travelling salesman problem;symmetric multiprocessor system;3-opt;bottleneck traveling salesman problem;language model	HPC	-13.33898623732953	61.67184619570122	39324
1f3ad164e36e579fafad907c157c1a237405c1ee	idle block based methods for cloud workflow scheduling with preemptive and non-preemptive tasks		Abstract Complex workflow applications are widely used in scientific computing and economic analysis, which commonly include both preemptive and non-preemptive tasks. Cloud computing provides a convenient way for users to access different resources based on the “pay-as-you-go” model. However, different resource renting alternatives (reserved, on-demand or spot) are usually provided by the service provider. The spot instances provide a dynamic and cheaper alternative comparing to the on-demand one. However, failures often occur due to the fluctuations of the price of the instance. It is a big challenge to determine the appropriate amount of spot and on-demand resources for workflow applications with both preemptive and non-preemptive tasks. In this paper, the workflow scheduling problem with both spot and on-demand instances is considered. The objective is to minimize the total renting cost under deadline constrains. An idle time block-based method is proposed for the considered problem. Different idle time block-based searing and improving strategies are developed to construct schedules for workflow applications. Schedules are improved by a forward and backward moving mechanism. Experimental and statistical results demonstrate the effectiveness of the proposed algorithm over a lot of tests with different sizes.	preemption (computing);scheduling (computing)	Long Chen;Xiaoping Li;Rubén Ruiz	2018	Future Generation Comp. Syst.	10.1016/j.future.2018.07.037	distributed computing;service provider;renting;real-time computing;workflow;cloud computing;computer science;scheduling (computing);job shop scheduling;schedule;idle	HPC	-18.75450958020417	63.102780523165244	39434
f674767a0b3cd5351f6abbcd5ec6579be499d806	energy-cost-aware scheduling of hpc workloads	cost aware scheduling;scheduling electricity supply industry power engineering computing power grids pricing renewable energy sources;electrical pricing;electrical grid;renewable energy sources;pricing;electricity prices;dynamic electrical pricing power optimization green computing sustainable computing cost aware scheduling;environmentally friendly renewable energy source;high priority jobs;hpc workload;energy cost aware scheduling;power demand reduction;resource access;energy availability;power engineering computing;electricity cost saving energy cost aware scheduling hpc workload high performance computing workloads high priority jobs resource access cluster scheduler power price power demand reduction energy availability carbon footprint electrical grid electrical pricing environmentally friendly renewable energy source electrical grid;sustainable computing;scheduling;power optimization;pricing power demand servers renewable energy resources electricity benchmark testing delay;cluster scheduler;electricity cost saving;high performance computing workloads;energy cost;power grids;electricity supply industry;power price;dynamic electrical pricing;carbon footprint;green computing	Job submission in high performance computing workloads exhibits a diurnal pattern similar to electrical prices. While high-priority jobs may need immediate access to resources, by altering the cluster scheduler to delay the execution of lower-priority jobs when power prices are high, significant cost savings can be achieved. Reduction of power demands by consumers such as data centres when energy availability is low, as signaled by high prices, can also help to simplify challenges faced in reducing the carbon footprint of the electrical grid. In this paper we discuss patterns in electrical pricing and also look at some challenges in integrating more volatile, but environmentally friendly renewable energy sources into the electrical grid. Simulation results are also presented showing that high-priority jobs can still receive rapid service while achieving 25–50% electricity cost savings for lower priority jobs.	backup;computer cooling;data center;high availability;job stream;level of detail;redundancy (engineering);scheduling (computing);simulation;supercomputer;synergy	David Aikema;Cameron Kiddle;Rob Simmonds	2011	2011 IEEE International Symposium on a World of Wireless, Mobile and Multimedia Networks	10.1109/WoWMoM.2011.5986476	green computing;real-time computing;computer science;operating system	HPC	-20.835500525503125	61.57320617480169	39596
01e1d923e9dfa4a863c2e31638af9ebc3a01a4f3	maestro: an nfv orchestrator for wireless environments aware of vnf internal compositions	dynamic programming;wireless networks;dynamic c ran nfv orchestration vnf composition;computer architecture;proposals;cloud computing proposals wireless networks dynamic programming computer architecture;cloud computing	Dynamic Cloud Radio Access Network (Dynamic C-RAN) is an emerging wireless architecture that aims for flexibility, business agility, adaptability, among other benefits. In a Dynamic C-RAN, wireless functionalities can be split into smaller components and distributed along a hierarchical cloud infrastructure. Network Functions Virtualization (NFV) concepts have been recently investigated to facilitate management-related operations of these wireless functionalities. Despite the many advocated advantages of the function's splitting and the effectiveness of NFV orchestration solutions, both academia and industry are considering Virtualized Network Functions (VNF)s as atomic elements, disregarding the potential advantages of splitting VNFs into several different components. Aiming to improve VNF orchestration in Dynamic C-RAN scenarios, in this paper we propose Maestro: an NFV orchestrator for wireless environments that is able to decide among several possible VNF compositions which are more suitable for each situation. Maestro is designed to operate using different decision mechanisms that can be defined based on network operators' needs. We evaluate the effectiveness of our proposal by modeling the orchestrator's decision mechanism as a linear programming problem. Thus, we show how fronthaul bandwidth consumption can be reduced threefold considering different VNF compositions against atomic VNF placement.	block-oriented terminal;c-ran;cloud computing;computer monitor;data rate units;linear programming;network function virtualization;radio access network;uncompressed video;vim	Ariel Galante Dalla-Costa;Lucas Bondan;Juliano Araujo Wickboldt;Cristiano Bonato Both;Lisandro Zambenedetti Granville	2017	2017 IEEE 31st International Conference on Advanced Information Networking and Applications (AINA)	10.1109/AINA.2017.126	embedded system;real-time computing;cloud computing;telecommunications;computer science;operating system;wireless network;dynamic programming;database;distributed computing;computer security;computer network	Mobile	-14.264819474381188	85.25963594355068	39672
a5d0ff6e37323cd2e925b9196454145d5696f7d8	evaluating the cost and robustness of self-organizing distributed hash tables		Self-organizing construction principles are a natural fit for large-scale distributed system in unpredictable deployment environments. These principles allow a system to systematically converge to a global state by means of simple, uncoordinated actions by individual peers. Indexing services based on the distributed hash table DHT abstraction have been established as a solid foundation for large-scale distributed applications. For most DHTs, the creation and maintenance of the overlay structure relies on the exploration and update of an already stabilized structure. We evaluate in this paper the practical interest of self-organizing principles, and in particular gossip-based overlay construction protocols, to bootstrap and maintain various DHT implementations. Based on the seminal work on T-Chord, a self-organizing version of Chord using the T-Man overlay construction service, we contribute three additional self-organizing DHTs: T-Pastry, T-Kademlia and T-Kelips. We conduct an experimental evaluation of the cost and performance of each of these designs using a prototype implementation. Our conclusion is that, while providing equivalent performance in a stabilized system, self-organizing DHTs are able to sustain and recover from higher level of churn than their explicitly-created counterparts, and should therefore be considered as a method of choice for deploying robust indexing layers in adverse environments.	distributed hash table;organizing (structure)	Sveta Krasikova;Raziel Carvajal Gómez;Heverson B. Ribeiro;Etienne Rivière;Valerio Schiavoni	2016		10.1007/978-3-319-39577-7_2	computer science;operating system;key-based routing;database;distributed computing;world wide web;computer network	Networks	-12.169516794307269	72.80288770678101	39711
b88ab0e3400e22b0ad0cf5a50fc1346c77efae50	transport layer security (tls) authorization extensions		This document specifies authorization extensions to the Transport#N#Layer Security (TLS) Handshake Protocol. Extensions are carried in the#N#client and server hello messages to confirm that both parties support#N#the desired authorization data types. Then, if supported by both the#N#client and the server, authorization information, such as attribute#N#certificates (ACs) or Security Assertion Markup Language (SAML)#N#assertions, is exchanged in the supplemental data handshake message.#N#This document defines an Experimental Protocol for the Internet#N#community.	authorization;transport layer security	Mark Brown;Russ Housley	2010	RFC	10.17487/RFC5878	computer science;authorization certificate;database;world wide web;computer security	Security	-26.56060914143248	87.4288225127757	39718
0e22681115240d9edeb01204bca209849e223e2f	latency-driven replica placement	client server systems;greedy algorithms;indexing terms;delay computational efficiency solid modeling costs web and internet services greedy algorithms bandwidth acceleration algorithm design and analysis computational complexity;internet;computational complexity;internet latency latency driven replica placement hotzone algorithm wide area network client to replica latency hotspot algorithm geometric model;geometric model;large scale distributed systems;replicated databases;wide area network;client server systems internet computational complexity greedy algorithms replicated databases	This paper presents HotZone, an algorithm to place replicas in a wide-area network such that the client-to-replica latency is minimized. Similar to the previously proposed HotSpot algorithm, HotZone places replicas on nodes that along with their neighboring nodes generate the highest load. In contrast to HotSpot, however, HotZone provides nearly-optimal results by considering overlapping neighborhoods. HotZone relies on a geometric model of Internet latencies, which effectively reduces the cost of placing K replicas among N potential replica locations from O(N/sup 2/) to O(N /spl middot/ max(logN, K)).	algorithm;algorithmic efficiency;computation;content delivery network;distributed computing;geometric modeling;greedy algorithm;interrupt latency;java hotspot virtual machine;mp3;peer-to-peer;time complexity	Michal Szymaniak;Guillaume Pierre;Maarten van Steen	2005	The 2005 Symposium on Applications and the Internet	10.1109/SAINT.2005.37	greedy algorithm;real-time computing;the internet;index term;computer science;theoretical computer science;geometric modeling;operating system;database;distributed computing;computational complexity theory;law;world wide web;computer network	OS	-15.670153541246588	73.01184107755711	39730
20a2df278cbd9468ac1a955e50b51317c716641f	a comparative study of online scheduling algorithms for networks of workstations	dynamic change;online scheduling;scheduling algorithm;network of workstation;resource management system	Networks of workstations offer large amounts of unused processing time. Resource management systems are able to exploit this computing capacity by assigning compute-intensive tasks to idle workstations. To avoid interferences between multiple, concurrently running applications, such resource management systems have to schedule application jobs carefully. Continuously arriving jobs and dynamically changing amounts of available CPU capacity make traditional scheduling algorithms difficult to apply in workstation networks. Online scheduling algorithms promise better results by adapting schedules to changing situations. This paper compares six online scheduling algorithms by simulating several workload scenarios. Based on the insights gained by simulation, the three online scheduling algorithms performing best were implemented in the Winner resource management system. Experiments conducted with Winner in a real workstation network confirm the simulation results obtained.	algorithm;central processing unit;job stream;scheduling (computing);simulation;workstation	Olaf Arndt;Bernd Freisleben;Thilo Kielmann;Frank Thilo	2000	Cluster Computing	10.1023/A:1019024019093	fair-share scheduling;fixed-priority pre-emptive scheduling;parallel computing;real-time computing;earliest deadline first scheduling;simulation;dynamic priority scheduling;computer science;rate-monotonic scheduling;operating system;two-level scheduling;distributed computing;lottery scheduling;round-robin scheduling;scheduling	HPC	-15.720732787375763	60.56829291460936	39811
7ce76c9eb92efdc4513283ecdddbdeec14cd76b4	information resilience: source recovery in an information-centric network	qa75 electronic computers computer science	Recent years have witnessed explosive growth in traffic demands combined with evolving content characteristics and dissemination patterns. This growth has resulted in an increasing demand for information identification as well as information-based communication functions that can meet this evolution. Consequently, information-centric networking envisions a shift in the future Internet communication paradigm from relying on the notion of an end node toward making information itself the primary object. This is realized by adopting information as the primary identifier of a user's demand. With this new concept in networking, new (information- focused) solutions can be developed to conventional problems found in IP networks, such as resilient content delivery. In this article we introduce a novel resiliency solution that goes beyond the scope of path recovery to tackle source failure scenarios in order to achieve the more general form of information resilience. We show that by utilizing the knowledge of information, offered by a publish/subscribe information-centric networking model, multiple publishers of a single information item can be natively identified, thereby allowing for recovery of the delivery process using alternative publishers should a publisher fail.	atm turbo;backup;basis pursuit;digital distribution;dirk helbing;future internet;generalized multi-protocol label switching;hdmi;icn gps;identifier;information;interval exchange transformation;ising model;mit computer science and artificial intelligence laboratory;multiprotocol label switching;network architecture;network security;programming paradigm;publish–subscribe pattern;yang	Mays F. Al-Naday;Martin J. Reed;Dirk Trossen;Kun Yang	2014	IEEE Network	10.1109/MNET.2014.6843230	simulation;telecommunications;computer science;world wide web;computer security;computer network	Networks	-17.40210906799236	87.44487863147154	39855
cb1b2b92bbed045eb1659a91290f183780a2ba71	p4guard: designing p4 based firewall		A virtual firewall based on Network Function Virtualization (NFV) with Software Defined Networking (SDN) provides high scalability and flexibility for low-cost monitoring of legacy networks by dynamically deploying virtual network appliances rather than traditional hardware-based appliances. However, full utilization of virtual firewalls requires efficient management of computer virtualization resources and on-demand placement of virtual firewalls by steering traffic to the correct routing path using an SDN controller. In this paper, we design P4Guard, a software-based configurable firewall based on a high-level domain-specific language to specify packet processing logic using P4. P4Guard is a protocol-independent and platform-agnostic software-based firewall that can be incorporated into software switches that is highly usable and deployable. We evaluate the efficiency of P4Guard in processing traffic, compared to our previous virtual firewall in NFV.		Rakesh Datta;Sean Choi;Anurag Chowdhary;Younghee Park	2018	MILCOM 2018 - 2018 IEEE Military Communications Conference (MILCOM)	10.1109/MILCOM.2018.8599726	virtualization;computer network;computer science;scalability;virtual network;firewall (construction);software;software-defined networking;packet processing;virtual firewall	Networks	-14.957061215458628	82.55732017721208	39877
7a0925454d5749641c39be32a0cdb03682d8bd42	towards an intelligent grid scheduling system	grid scheduling;distributed system;algoritmo paralelo;besoin de l utilisateur;base donnee;posicionamiento;haute performance;systeme intelligent;sobrecarga;systeme reparti;project management;computational grid;parallel algorithm;criterio resultado;cost function;surveillance;resource allocation;data collection;sistema inteligente;heuristic method;exigence usager;logicial personalizado;exigencia usuario;distributed computing;database;base dato;performance requirement;metodo heuristico;necesidad usuario;critere performance;intelligence artificielle;algorithme parallele;intergiciel;grid;positioning;vigilancia;sistema repartido;col;monitoring;user need;rejilla;user requirement;scheduling;surcharge;intelligent system;alto rendimiento;grille;calculo repartido;artificial intelligence;gestion projet;middleware;asignacion recurso;methode heuristique;inteligencia artificial;monitorage;allocation ressource;overload;monitoreo;application;high performance;calcul reparti;ordonnancement;gestion proyecto;reglamento;positionnement	The main objective of the Intelligent GRID Scheduling System (ISS) project is to provide a middleware infrastructure allowing a good positioning and scheduling of real life applications in a computational GRID. According to data collected on the machines in the GRID, on the behaviour of the applications, and on the performance requirements demanded by the user, a heuristic cost function is evaluated by means of which a well suited computational resource is detected and allocated to execute his application. The monitoring information collected during execution is put into a database and reused for the next resource allocation decision. In addition to providing scheduling information, the collected data allows to detect overloaded resources and to pin-point inefficient applications that could be further optimised.	computation;computational resource;database;grid computing;heuristic;loss function;middleware;real life;requirement;scheduling (computing);side effect (computer science)	Ralf Gruber;Vincent Keller;Pierre Kuonen;Marie-Christine Sawley;Basile Schaeli;Ali Tolou;Marc Torruella;Trach-Minh Tran	2005		10.1007/11752578_90	project management;fair-share scheduling;embedded system;real-time computing;simulation;dynamic priority scheduling;resource allocation;computer science;user requirements document;operating system;two-level scheduling;middleware;distributed computing;parallel algorithm;grid;scheduling;data collection	HPC	-14.483958280314257	63.521619077748426	40127
0d08c5b74f7a1813481dfb6e8e833b5875b9a307	proposal of stackable roadm for wavelength transparent ip-over-cwdm networks	loss measurement;multiplexage longueur onde;wavelength measurement;proposals optical fiber networks passive optical networks ip networks telecommunication traffic wavelength division multiplexing wavelength routing optical add drop multiplexers network topology wide area networks;reconfigurable optical add drop multiplexers stackable roadm wavelength transparent ip over cwdm networks passing through wavelengths coarse wavelength division multiplexing;optical ip network;reconfigurable architectures;fiber optics;telecommunication network;stackability;optical fiber networks;multiplexor optico insercion extraccion;red fibra optica;optical fibre networks;optical fibers;red telecomunicacion;reseau fibre optique;reseau telecommunication;roadm;ip networks;wavelength division multiplexing ip networks optical fibre networks;optical fiber network;optical add drop multiplexers;multiplexeur optique insertion extraction;optical add drop multiplexer;optical fiber communication;architecture reconfigurable;optical losses;multiplaje longitud onda;communication fibre optique;wavelength division multiplexing	Stackable ROADMs (S-ROADMs) have been proposed for use in regional IP-over-CWDM networks. The S-ROADM can be constructed by connecting modules with different wavelengths required in the node. The experimental results clarified that the S-ROADM could mux and demux the wavelengths successfully, and gave no limit to the passing-through wavelengths, making the network be wavelength transparent. Contrary to the S-ROADM, the existing fixed ROADMs were not wavelength transparent.	left 4 dead 2;multiplexer;reconfigurability;reconfigurable computing;scalability;wavelength-division multiplexing	Md. Nooruzzaman;Yuichi Harada;Osanori Koyama;Yutaka Katsuyama	2008	2008 14th Asia-Pacific Conference on Communications	10.1093/ietcom/e91-b.10.3330	telecommunications;computer science;optical fiber;computer network	HPC	-7.18582267134222	85.97759329589088	40159
068aec1102858a4718a163a664444be1df3c01a6	distributing authoritative name servers via shared unicast addresses	domain name system;network topology	Distributing Authoritative Name Servers via Shared Unicast Addresses Status of this Memo This memo provides information for the Internet community. It does not specify an Internet standard of any kind. Distribution of this memo is unlimited. Abstract This memo describes a set of practices intended to enable an authoritative name server operator to provide access to a single named server in multiple locations. The primary motivation for the development and deployment of these practices is to increase the distribution of Domain Name System (DNS) servers to previously under-served areas of the network topology and to reduce the latency for DNS query responses in those areas.	internet;network topology;server (computing);software deployment;unicast	Ted Hardie	2002	RFC	10.17487/RFC3258	dns hijacking;root name server;round-robin dns;computer science;dns spoofing;distributed computing;dns zone;zone file;dns root zone;name server;world wide web;nsupdate;domain name system;computer network	Metrics	-25.845390617629146	86.39646853806062	40233
4b04c2e3b3982ed6e088acd5956d4aacbde95e6f	rescheduling for reliable job completion with the support of clouds	distributed system;large scale;bag of tasks;advance reservation	A major performance issue in large-scale decentralized distributed systems, such as grids, is how to ensure that jobs finish their execution within the estimated completion times in the presence of resource performance fluctuations. Previously, several techniques including advance reservation, rescheduling and migration have been adopted to resolve/relieve this issue; however, they have some non-negligent practicality hurdles. The use of cloudsmay be an attractive alternative, since resources in clouds aremuch more reliable than those in grids. This paper investigates the effectiveness of rescheduling using cloud resources to increase the reliability of job completion. Specifically, schedules are initially generated using grid resources, and cloud resources (relatively costlier) are used only for rescheduling to copewith a delay in job completion. A job in our study refers to a bag-of-tasks (BoT) application that consists of a large number of independent tasks; this job model is common in many science and engineering applications. We have devised a novel rescheduling technique, called rescheduling using clouds for reliable completion (RC2) and applied it to three well-known existing heuristics. Our experimental results reveal that RC2 significantly reduces delay in job completion. © 2010 Elsevier B.V. All rights reserved.	cloud computing;distributed computing;heuristic (computer science);job stream;max–min inequality;multistage interconnection networks;scheduling (computing);system migration	Young Choon Lee;Albert Y. Zomaya	2010	Future Generation Comp. Syst.	10.1016/j.future.2010.02.010	parallel computing;real-time computing;simulation;computer science;distributed computing	HPC	-18.343201969570686	61.77854338074791	40341
ab2e0e443337d2d299d7cb6452a59f5cd882cc28	bandwidth optimization for real-time online and mobile applications		This work proposes a novel algorithm to maximize the utilization of bandwidth for any text based application. The algorithm is used for real-time online text chatting, as well as offline SMS in mobile phones. Text is handled transparently without any modification in the core network. The proposed algorithm is an application of ‘A-M’ compression framework. Applying such algorithm will save at least 25% and up to 90% of the bandwidth depending on the context of the transferred data. Other applications such as email, web browsing, etc…will also gain from applying such algorithm. This paper demonstrated two types of applications; the real-time text chatting, and the mobile SMS application. The algorithm depends on a pre-defined dictionary of maximum size of 16 Kbyte installed on the client side or on the cloud near each client.	real-time transcription	Ahmed Mokhtar A. Mansour;Mona A. M. Fouad	2014		10.1007/978-3-319-05948-8_27	mobile computing;dynamic bandwidth allocation	Embedded	-18.843587432647592	73.82058728567756	40347
51836a93aa69e8c03de901e80ee01f3c6290cb56	using the elliptic curve signature algorithm (ecdsa) for xml digital signatures		This document specifies how to use Elliptic Curve Digital Signature Algorithm (ECDSA) with XML Signatures. The mechanism specified provides integrity, message authentication, and/or signer authentication services for data of any type, whether located within the XML that includes the signature or included by reference. Blake-Wilson, et al. Informational [Page 1] RFC 4050 ECDSA for XML Digital Signatures April 2005 Table of	algorithm;digital signature;message authentication;xml	Simon Blake-Wilson;Gregor Karlinger;Tetsutaro Kobayashi;Yongge Wang	2005	RFC	10.17487/RFC4050	ring signature;xml encryption;elliptic curve digital signature algorithm;computer science;digital signature algorithm;database;internet privacy;xml signature;world wide web	Security	-26.821195952330868	87.76957704798379	40374
da7aabe9c5d7523dca9bd8852a7efc36f65ce20d	a density-based offloading strategy for iot devices in edge computing systems		Collaboration spaces formed from edge servers can efficiently improve the quality of experience of service subscribers. In this paper, we first utilize a strategy based on the density of Internet of Things (IoT) devices and  ${k}$ -means algorithm to partition network of edge servers, then an algorithm for IoT devices’ computation offloading decisions is proposed, i.e., whether we need to offload IoT devices’ workload to edge servers, and which edge server to choose if migration is needed. The combination of locations of edge servers and the geographic distribution of various IoT devices can significantly improve the scheduling of network resources and satisfy requirements of service subscribers. We analyze and build mathematical models about whether/how to offload tasks from various IoT devices to edge servers. In order to better simulate operations of the mobile edge servers in more realistic scenarios, the input size of each IoT device is uncertain and regarded as a random variable following some probability distribution based on long-term observations. On the basis of that, an algorithm utilizing sample average approximation method is proposed to discuss whether the tasks to be executed locally or offloaded. Besides, the algorithm proposed can also help decide whether service relocation/migration is needed or not. Finally, simulation results show that our algorithm can achieve 20% of global cost less than the benchmark on a true base station dataset of Hangzhou.		Cheng Zhang;Hailiang Zhao;Shuiguang Deng	2018	IEEE Access	10.1109/ACCESS.2018.2882452	workload;computer network;scheduling (computing);relocation;dynamic priority scheduling;distributed computing;computer science;base station;edge computing;server;computation offloading	HPC	-23.332202247731047	67.14190413289148	40396
0327467e72d67447f25132dfb020cdb98bbc77fd	schedulability analysis of fixed-priority systems using timed automata	verification;tiempo respuesta;systeme temps reel;modelizacion;subtraction;computer engineering;maskinteknik;reachability;sistema temporizado;tool;execution time;sistema periodico;arrival time;real time;rate monotonic analysis;modelling and verification;response time analysis;timed system;computer and information science;sustraccion;priorite;periodic system;soustraction;response time;automaton;fixed priority;schedulability analysis;temps reponse;modelisation;mechanical engineering;automata;embedded systems;data dependence;periodic tasks;tiempo llegada;informatique theorique;scheduling;asequibilidad;automate;scheduling theory;systeme temporise;atteignabilite;scheduling problem;temps execution;systeme periodique;real time system;timed automata;sistema tiempo real;datorteknik;fixed priority scheduling;verificacion;inbaddad systemteknik;tiempo ejecucion;data och informationsvetenskap;temps arrivee;priority;prioridad;modeling;ordonnancement;reglamento;computer theory;real time systems;informatica teorica	In classic scheduling theory, real-time tasks are usually assumed to be periodic, i.e. tasks are released and computed with fixed rates periodically. To relax the stringent constraints on task arrival times, we propose to use timed automata to describe task arrival patterns. In a previous work, it is shown that the general schedulability checking problem for such models is a reachability problem for a decidable class of timed automata extended with subtraction. Unfortunately, the number of clocks needed in the analysis is proportional to the maximal number of schedulable task instances associated with a model, which is in many cases huge. In this paper, we show that for fixed-priority scheduling strategy, the schedulability checking problem can be solved using standard timed automata with two extra clocks in addition to the clocks used in the original model to describe task arrival times. The analysis can be done in a similar manner to response time analysis in classic Rate-Monotonic Analysis (RMA). The result is further extended to systems with data-dependent control, in which the release time of a task may depend on the time-point at which other tasks finish their execution. For the case when the execution times of tasks are constants, we show that the schedulability problem can be solved using n+ 1 extra clocks, where n is the number of tasks. The presented analysis techniques have been implemented in the Times tool. For systems with only periodic tasks, the performance of the tool is comparable with tools implementing the classic RMA technique based on equation-solving, without suffering from the exponential explosion in the number of tasks. © 2005 Elsevier B.V. All rights reserved.	algorithm;approximation;automata theory;computation;data dependency;equation solving;fixed-priority pre-emptive scheduling;maximal set;reachability problem;real-time locating system;response time (technology);revolution in military affairs;scheduling (computing);scheduling analysis real-time systems;shared variables;the times;time complexity;timed automaton;undecidable problem	Elena Fersman;Leonid Mokrushin;Paul Pettersson;Wang Yi	2006	Theor. Comput. Sci.	10.1016/j.tcs.2005.11.019	job shop scheduling;real-time computing;simulation;real-time operating system;computer science;artificial intelligence;automaton;algorithm	Embedded	-9.685520165063423	60.98381084945971	40423
64af06caded9576bc7c0303680435c992537a10e	a solitary wave approach to parallel optimization for multi-agent systems and computer networks	resource utilization;optimisation;complexity theory;multi agent system;social interaction;solitary wave propagation approach;task allocation and resource assignment;source assignment;resource allocation;nonlinear space;bandwidth allocation;social interactions solitary wave multi agent systems task allocation and resource assignment network bandwidth allocation parallel optimization;multiagent systems computer networks resource management aggregates quality of service telecommunication traffic bandwidth channel allocation parallel algorithms optimization methods;resource management;solitary wave;computer networks;computer network;optimization problem;distance measurement;multi agent systems;multiple objectives;nonlinear space multi agent systems computer networks solitary wave propagation approach task allocation source assignment parallel optimization problem;resource allocation computer networks multi agent systems optimisation quality of service;aggregates;bandwidth;optimization;parallel optimization problem;social interactions;quality of service;linear space;parallel optimization;network bandwidth allocation;task allocation	This paper presents a solitary wave propagation (SWP) approach to optimize task allocation and source assignment in multi-agent systems (MAS) and computer networks (CN). The proposed approach transforms the parallel optimization problem in MAS and CN into the solitary wave propagation process in non-linear space. Features of the SWP approach include a powerful processing ability in a complex environment that involves the priority, personality, autonomy, congestion degree, and interaction of different entities in MAS and CN. Furthermore, the SWP-basedmodel can realize the optimization of multiple objectives, including the aggregate utility, the personal utility, the minimal personal utility, the resource utilization, and the users' satisfactory degree.	aggregate data;algorithm;autonomy;bottom-up parsing;entity;hyper-threading;interdependence;mathematical optimization;multi-agent system;network congestion;nonlinear system;optimization problem;paradiseo;problem solving;software propagation;soliton;state space;top-down and bottom-up design	Dianxun Shuai;Qing Shuai	2008	2008 Fifth International Conference on Fuzzy Systems and Knowledge Discovery	10.1109/FSKD.2008.205	optimization problem;mathematical optimization;in situ resource utilization;simulation;quality of service;resource allocation;computer science;multi-agent system;distributed computing;bandwidth;linear space;bandwidth allocation	AI	-15.827256878481258	64.60490087997454	40424
e6a4f21d3f2c2f8da20535fff7ce6615dccc7093	v2c: a secure vehicle to cloud framework for virtualized and on-demand service provisioning	cloud networking;vehicular network;next generation network;best effort;engineering and technology;teknik och teknologier;security architecture;vehicular networks;next generation networks;service provision;cloud computing	Cloud computing has revolutionized the IT industry by enabling a virtualized resource provisioning model for organizations. The Network-as-a-Service (NaaS) provisioning model enables new ways of providing virtually isolated and on-demand networking capabilities in existing cloud provisioning models, resulting in best-effort performance, scalable data throughput, reduced latency, and reduced configuration complexity. In this paper we propose V2C, an elastic Vehicle-to-Cloud infrastructure that integrates NaaS into the automotive ecosystem and enables provisioning of vehicle-based services for automobile users. However, V2C introduces various security challenges and the main objective of this paper is to propose a secure provisioning model to address them.	best-effort delivery;cloud computing;ecosystem;network as a service;provisioning;scalability;throughput	Sathyanarayanan Rangarajan;Monica Verma;Anand Kannan;Ayush Sharma;Ingmar Schoen	2012		10.1145/2345396.2345422	thin provisioning;next-generation network;computer science;engineering;world wide web;computer security;provisioning;computer network	HPC	-15.70014574533909	85.66063786865324	40474
5afaeccf1dd72eda6f8b2a7cf54fbc9605638e66	an empirical study of a segment-based streaming proxy in an enterprise environment	workload;distributed system;grain size;evaluation performance;entreprise;empirical study;tratamiento transaccion;streaming;systeme reparti;methode empirique;web pages;performance evaluation;red www;localite;routing;perforation;transmision continua;evaluacion prestacion;metodo empirico;prefetching;empresa;empirical method;reseau web;serveur informatique;prechargement donnee;look ahead;routage;locality;cache memory;system performance;antememoria;antememoire;transmission en continu;sistema repartido;internet;senal video;signal video;streaming media;grosor grano;comportement utilisateur;firm;charge travail;video signal;servidor informatico;cost effectiveness;world wide web;user behavior;transaction processing;carga trabajo;precargamento dato;web proxy;trace driven simulation;comportamiento usuario;traitement transaction;computer server;grosseur grain;enrutamiento	Streaming media workloads have a number of desirable properties that make them good candidates for caching via proxy systems. The content does not get modified, and access patterns exhibit some locality of reference. However, media files tend to be much larger in size than traditional web pages, and users tend to view video clips only partially. Hence, segment-based strategies have been proposed to deliver large streaming media objects via a web-proxy. In this work, we evaluate the performance of such a segment-based streaming proxy using extensive trace driven simulation. We use representative workloads from enterprise media server logs, and evaluate the caching system performance regarding different cache sizes, different segment sizes, and different prefetching methods. Our results show that cost-effective caching requires only about 8 16 % of the total unique object size as proxy storage. Secondly, a segment size of around 200 Kbytes provides a good trade-off between cache object granularity and transaction overhead. Finally, a lazier prefetching schedule that provides a half-segment look-ahead has a significant performance gain when compared to a more aggressive one-segment look-ahead scheme.	cpu cache;cache (computing);kilobyte;locality of reference;media server;overhead (computing);proxy server;server (computing);simulation;streaming media;video clip;web page	Sumit Roy;Bo Shen;Songqing Chen;Xiaodong Zhang	2004		10.1007/978-3-540-30471-5_20	embedded system;real-time computing;computer science;operating system;database;distributed computing;computer performance;empirical research;world wide web;computer security	Web+IR	-17.331112894856776	71.07220418573583	40520
c452c382c8e0951c00821b4cce9933efe20f0635	flying object control-inertial measurement unit for an embedded system		This paper describes a new industrial communicatio n protocol, dNet protocol suite, and its application in control systems. Protocols in this s uite have some useful properties known from higher communication protocols. For example, abstract of a ddresses and connection, encryption and application services. They also have some characteristics typic al rather for industrial protocols, e.g. simple implementation in microcontrollers, compatibility w ith existing bus standards (CAN), support for program downloading and device configuration. The s uite can be operated almost over any data link layer. Document then presents a typical way of prot ocol usage, definition of application services and networks management.	control system;dnet;distributed control system;download;embedded system;encryption;microcontroller;protocol stack;uniprot	Jan Floder	2009		10.3182/20090210-3-CZ-4002.00022	internet protocol;embedded system;universal composability;real-time computing;user datagram protocol;computer science;link control protocol;application layer;distributed computing;internet protocol suite;protocol stack;transport layer	Embedded	-24.2214227175585	85.73990621043808	40552
dfe7d2fafa41a98da637faf77ee5600abdb9621d	collaborative ensemble-learning based intrusion detection systems for clouds	bagging;training;collaboration;intrusion detection;learning systems;decision trees;cloud computing	Cloud computation has become prominent with seemingly unlimited amount of storage and computation available to users. Yet, security is a major issue that hampers the growth of cloud. In this research we investigate a collaborative Intrusion Detection System (IDS) based on the ensemble learning method. It uses weak classifiers, and allows the use of untapped resources of cloud to detect various types of attacks on the cloud system. In the proposed system, tasks are distributed among available virtual machines (VM), individual results are then merged for the final adaptation of the learning model. Performance evaluation is carried out using decision trees and using fuzzy classifiers, on KDD99, one of the largest datasets for IDS. Segmentation of the dataset is done in order to mimic the behavior of real-time data traffic occurred in a real cloud environment. The experimental results show that the proposed approach reduces the execution time with improved accuracy, and is fault-tolerant when handling VM failures. The system is a proof-of-concept model for a scalable, cloud-based distributed system that is able to explore untapped resources, and may be used as a base model for a real-time hierarchical IDS.	cloud computing;computation;decision tree;distributed computing;ensemble learning;fault tolerance;intrusion detection system;performance evaluation;real-time clock;real-time data;run time (program lifecycle phase);scalability;virtual machine	Poonam Mehetrey;Behrooz Shahriari;Melody Moh	2016	2016 International Conference on Collaboration Technologies and Systems (CTS)	10.1109/CTS.2016.0078	intrusion detection system;simulation;bootstrap aggregating;cloud computing;computer science;operating system;decision tree;data mining;management;world wide web;computer security;collaboration	HPC	-27.876723989743056	63.25687316362214	40578
da393abe39335f5e167be07fe4b5de46624a6f03	an optimal topology for a static p2p live streaming network with limited resources	peer to peer computing servers topology usa councils equations network topology delay;p2p;telecommunication network topology peer to peer computing;flash crowd static p2p live streaming network network topology network resource peer to peer network viewer node amplifiers node server upload capacity rayv commercial system;peer to peer computing;telecommunication network topology	In this paper we propose a P2P live streaming topology, prove its optimality under common constraints, and match the analytical research with results from a running commercial network. We assume two types of nodes: viewers that consume the entire media, and amplifiers which are non-viewing nodes utilized for their upstream bandwidth. We analytically derive the minimum needed server upload capacity, for any topology, under the following assumptions: the amount of amplifiers and buffer time are limited, dynamics are low, and the total bandwidth required by the viewers exceeds the total upstream bandwidth of all peers. Then, we present a two-level topology and prove that it achieves the minimum possible server upload, up to a small fraction. Finally, the assumptions and derivation are supported by performing several experiments on RayV's real-world commercial system, with varying network parameters. Namely, we show our predictions are valid while varying the viewers to amplifiers ratio, the stream bit-rate, and the country of the peers. These results not only verify the analytical static predictions, but also evaluate the dynamic costs during the `flash crowd', the initial time when peers are joining the system.	amplifier;experiment;server (computing);slashdot effect;streaming media;upload;upstream (software development)	Jonathan Stern;Omer Luzzatti;Raphael Goldberg;Eran Weiss;Mira Gonen	2011	2011 IEEE 17th International Conference on Parallel and Distributed Systems	10.1109/ICPADS.2011.27	parallel computing;real-time computing;computer science;operating system;peer-to-peer;database;distributed computing;computer security;network topology;computer network;logical topology	DB	-13.245579539933123	75.42783770969555	40586
850b71a333572d47ccb3ec29b63b8fb96ab1e9c9	layer two tunneling protocol l2tp management information base		This memo defines a portion of the Management Information Base (MIB) for use with network management protocols in TCP/IP-based internets. In particular, it defines objects for managing networks using Layer 2 Tunneling Protocol (L2TP).		Evan Caves;Pat R. Calhoun;Ross Wheeler	2002	RFC	10.17487/RFC3371	tunneling protocol;world wide web;computer security;osi model;layer 2 tunneling protocol;computer network	Crypto	-23.70393874239603	88.04852912089063	40629
cbc73d0ae3808c5f4b56dfa16fcd040897f656f4	node degree-aware link cost for traffic load-distribution in large-scale networks	loss measurement;stress;routing protocols;telecommunication traffic complex networks internet telecommunication network topology;complex networks;network robustness node degree aware link cost large scale networks traffic engineering traffic load distribution network resources traffic demand scale free property network topology node outbound degree distribution scale free network internet node degree information network congestion;routing;scale free network;degree distribution;network topology;large scale;telecommunication traffic;scale free;internet;load distribution;traffic engineered;routing protocol;telecommunication network topology;routing protocols stress internet delay network topology routing loss measurement	"""Traffic Engineering (TE) is required for reducing highly-loaded links / nodes in parts of a network, thereby distributing the traffic load in the network. For efficient use of network resources, it is important to efficiently map traffic demands to network resources. Therefore, we should consider an appropriate definition of ``distance'' in networks with the topological features of the network instead of traffic demands. Recent studies have demonstrated a scale-free property of network topology, and node outbound degree distribution is an important factor in the scale-free networks. This paper proposes a new definition of """"distance"""" between two arbitrary communication nodes in the Internet by using node degree information for avoiding congestion in the network. Some simulation results show that the proposed scheme can distribute traffic load from high degree nodes to other nodes, and thus provides robustness of networks."""	business architecture;coefficient;degree (graph theory);degree distribution;internet;load balancing (computing);network congestion;network topology;simulation;test engineer	Hitomi Tamura;Mario Köppen;Masato Uchida;Masato Tsuru;Yuji Oie	2011	2011 Third International Conference on Intelligent Networking and Collaborative Systems	10.1109/INCoS.2011.126	traffic generation model;ring network;network planning and design;network traffic control;intelligent computer network;weighted network;overlay network;degree distribution;evolving networks;telecommunications;network formation;computer science;scale-free network;hierarchical network model;network simulation;distributed computing;routing protocol;node;interdependent networks;traffic shaping;network delay;internet traffic engineering;computer network;network traffic simulation	Mobile	-9.082309857763416	78.6390321820138	40679
20f3b3f2ca327b823cf86218a06357d73eff845b	novel optical access network architectures and transmission system technologies for optical fiber communications			access network;fiber-optic communication;optical fiber	Zhaoxin Wang	2006				Networks	-11.70372129481876	85.93058642700042	40681
59c6f10ea7d4574d544e1aff14bd77a73d569246	rldp: a novel risk-level disjoint protection routing algorithm with shared backup resources for survivable backbone optical transport networks	blocking probability;optical transport networks;distributed system;resource utilization;survivable routing;eje troncal;virtual network;reseau communication;systeme reparti;service level;reseau optique;optical transport network;longitud onda;routing;risk level disjoint;algoritmo encaminamiento;routage;wavelength;diferenciacion servicio;probabilistic approach;red fibra optica;journal;partage des ressources;reseau federateur;fault tolerant system;telecomunicacion optica;telecommunication optique;sistema repartido;optical arrays;algorithme routage;enfoque probabilista;approche probabiliste;reseau fibre optique;resource sharing;particion recursos;sistema tolerando faltas;routing algorithm;optical telecommunication;service differentiation;systeme tolerant les pannes;optical fiber network;longueur onde;backbone;red de comunicacion;communication network;shared risk link groups srlg;differenciation service;shared risk link group;red virtual;reseau virtuel;enrutamiento	In this paper, we investigate the problem of survivable routing in backbone optical transport networks with Shared-Risk Link Groups (SRLG) constraints. We present a new idea that considers the different risk-level protection for difference service level requirements of connection requests. Based on the presented idea, we propose an effective Risk-Level Disjoint Protection (RLDP) routing algorithm for provide different service level for connection requests. In RLDP, the backup path can be partial SRLG-disjoint with the primary path, and the backup wavelengths also can be shared by different backup paths if their corresponding primary paths are risk-level disjoint. Compared with the conventional SRLG-Disjoint Protection (SDP) routing algorithm that provide full SRLG-disjoint survivable routing for each connection request, RLDP can perform better resource utilization ratio and blocking probability. Simulation results are shown to be promising. 2007 Elsevier B.V. All rights reserved.	algorithm;backup;blocking (computing);erlang (unit);internet backbone;requirement;routing;shared risk resource group;simulation	Xingwei Wang;Lei Guo;Cunqian Yu	2008	Computer Communications	10.1016/j.comcom.2007.10.006	shared resource;optical transport network;routing;fault tolerance;in situ resource utilization;service level;telecommunications;computer science;wavelength;distributed computing;telecommunications network;computer network	Metrics	-4.79183581395534	77.43067906163334	40837
b422ca05fcd9c139739305f7d8c9d0a1223fe447	simulation toolbox for studying energy consumption in wired networks		Networking infrastructures are considered to consume as much energy as terminal end-user equipment or datacenters. While energy consumption of wireless networks is a matter of concern since their beginning, it is not the case for wired networks as they do not rely on batteries, but on plugged equipment. Yet, facing growing consumption, energy-efficient techniques start to be implemented in wired networks. However, measuring the end-to-end energy consumption of wired networking infrastructures remains a real challenge for network operators and scientists. This article presents the ECOFEN (Energy Consumption mOdel For End-to-end Networks) framework which allows to support precise simulation of energy consumption of large-scale complex wired networks. The experimental validation shows that Ecofen provides accurate energy consumption values.	end-to-end principle;energy modeling;linux;native (computing);real life;simulation;the void (virtual reality)	Anne-Cécile Orgerie;Betsegaw Lemma Amersho;Timothée Haudebourg;Martin Quinson;Myriana Rifai;Dino Lopez Pacheco;Laurent Lefèvre	2017	2017 13th International Conference on Network and Service Management (CNSM)	10.23919/CNSM.2017.8256037	computer network;wireless network;distributed computing;operator (computer programming);toolbox;energy consumption;computer science	Embedded	-18.775945317815523	78.6122548874131	40879
22c61ad99e4982fb84261c15d4847df8d473618c	an fpga-based cloud system for massive ecg data analysis	electrocardiography engines pipelines data processing feature extraction tcpip hardware;tcpip;data processing;field programmable gate array fpga cloud computing electrocardiogram ecg data analysis;electrocardiography;engines;feature extraction;pipelines;system on chip electrocardiography field programmable gate arrays;fpga cloud computing ecg data analysis;energy efficiency fpga based cloud system massive ecg data analysis stand alone system on a programmable chip sopc based cloud system massive electrocardiogram data analysis network i o handling hardware data processing pipeline field programmable gate array tcp ip hardware stack macropipeline architecture network packet processing ecg signal processing qrs detection feature extraction feature classification xc6vlx550t fpga;hardware	In this brief, we propose a stand-alone system-on-a-programmable-chip (SOPC)-based cloud system to accelerate massive electrocardiogram (ECG) data analysis. The proposed system tightly couples network I/O handling hardware to data processing pipelines in a single field-programmable gate array (FPGA), offloading both networking operations and ECG data analysis. In this system, we first propose a massive-sessions optimized TCP/IP hardware stack using a macropipeline architecture to accelerate network packet processing. Second, we propose a streaming architecture to accelerate ECG signal processing, including QRS detection, feature extraction, and classification. We verify our design on XC6VLX550T FPGA using real ECG data. Compared to commercial servers, our system shows up to 38× improvement in performance and 142× improvement in energy efficiency.	cloud computing;communications protocol;feature extraction;field-programmability;field-programmable gate array;input/output;internet protocol suite;network packet;pipeline (computing);prototype;server (computing);signal processing;speedup	Xu Wang;Yongxin Zhu;Yajun Ha;Meikang Qiu;Tian Huang	2017	IEEE Transactions on Circuits and Systems II: Express Briefs	10.1109/TCSII.2016.2556861	embedded system;electronic engineering;real-time computing;data processing;feature extraction;computer science;engineering;pipeline transport;internet protocol suite	Arch	-7.127642359288916	65.4648765036542	40947
da5b8a7fcc3f3d07f394936473c4bd702ab15d5e	software defined networks: it's about time	packet loss synchronization clocks bandwidth topology resource management;onf software defined networks sdn dynamic traffic engineering centralized traffic engineering forwarding paths path reconfiguration time4 network updates update scenarios flow swaps lossless flow allocation problem time4 enabled openflow prototype openflow protocol open networking foundation;software defined networking protocols	With the rise of Software Defined Networks (SDN), there is growing interest in dynamic and centralized traffic engineering, where decisions about forwarding paths are taken dynamically from a network-wide perspective. Frequent path reconfiguration can significantly improve the network performance, but should be handled with care, so as to minimize disruptions that may occur during network updates. In this paper we introduce Time4, an approach that uses accurate time to coordinate network updates. We characterize a set of update scenarios called flow swaps, for which Time4 is the optimal update approach, yielding less packet loss than existing update approaches. We define the lossless flow allocation problem, and formally show that in environments with frequent path allocation, scenarios that require simultaneous changes at multiple network devices are inevitable. We present the design, implementation, and evaluation of a time4-enabled OpenFlow prototype. The prototype is publicly available as open source. Our work includes an extension to the OpenFlow protocol that has been adopted by the Open Networking Foundation (ONF), and is now included in OpenFlow 1.5. Our experimental results demonstrate the significant advantages of Time4 compared to other network update approaches.	carrier grade;centralized computing;lossless compression;network packet;network performance;open-source software;openflow;prototype;software-defined networking;vii	Tal Mizrahi;Yoram Moses	2016	IEEE INFOCOM 2016 - The 35th Annual IEEE International Conference on Computer Communications	10.1109/INFOCOM.2016.7524418	openflow;real-time computing;telecommunications;computer science;distributed computing;software-defined networking;computer network	Visualization	-13.220389921746712	82.48842762064696	40975
acf056d0842c114d897edbc85f6d1ed9c711a15c	experiences with node virtualization for scalable network emulation	distributed application;estensibilidad;performance measure;distributed system;red sin hilo;virtual network;emulateur;systeme reparti;informatique mobile;protocolo red;network protocol;protocole transmission;network emulation;reseau sans fil;transparence;routing;evaluation performance logiciel;wireless network;software performance evaluation;routage;wireless ad hoc network;ad hoc network;red ad hoc;transparencia;software performance;upper bound;protocolo transmision;sistema repartido;reseau ad hoc;virtual routing;mobile ad hoc network;transparency;extensibilite;scalability;emulador;protocole reseau;borne superieure;mobile computing;emulator;red virtual;cota superior;reseau virtuel;enrutamiento;transmission protocol	During the development of network protocols and distributed applications, their performance has to be analyzed in appropriate environments. Network emulation testbeds provide a synthetic, configurable network environment for comparative performance measurements of real implementations. Realistic scenarios have to consider hundreds of communicating nodes. Common network emulation approaches limit the number of nodes in a scenario to the number of computers in an emulation testbed. To overcome this limitation, we introduce a virtual node concept for network emulation. The key problem for node virtualization is a transparent, yet efficient separation of node resources. In this paper, we provide a brief survey of candidate node virtualization approaches to facilitate scalable network emulation. Based on the gathered insights, we propose a lightweight virtualization solution to achieve maximum scalability and discuss the main points regarding its implementation. We present extensive evaluations that show the scalability and transparency of our approach in both a traditional wired infrastructure-based, and in two wireless ad hoc network emulation scenarios. The measurements indicate that our solution can push the upper limit of emulation scenario sizes by a factor of 10 to 28. Given our emulation testbed consisting of 64 computers, this translates to possible scenario sizes of up to 1792 nodes. In addition to the evaluation of our virtualization approach, we discuss key concepts for controlling comprehensive emulation scenarios to support scalability of our system as a whole.	cartography;communications protocol;computer;decade (log scale);dhrystone;distributed computing;emulator;hardware virtualization;hoc (programming language);linux;network emulation;protocol stack;requirement;resource contention;scalability;synthetic intelligence;testbed;virtual routing and forwarding;x86 virtualization	Steffen Maier;Daniel Herrscher;Kurt Rothermel	2007	Computer Communications	10.1016/j.comcom.2006.08.018	wireless ad hoc network;telecommunications;computer science;operating system;distributed computing;mobile computing;computer security;computer network	Networks	-5.223394812561709	75.6250431463607	40994
a1ec1d1bd8b096ed21e05516cd599549e1b93532	concise mib definitions		"""Concise MIB Definitions Status of this Memo This memo defines a format for producing MIB modules. This RFC specifies an IAB standards track document for the Internet community, and requests discussion and suggestions for improvements. Please refer to the current edition of the """"IAB Official Protocol Standards"""" for the standardization state and status of this protocol. Distribution of this memo is unlimited."""	mebibyte	Marshall T. Rose;Keith McCloghrie	1991	RFC	10.17487/RFC1212	engineering;genealogy;cartography	Web+IR	-25.725320323639583	88.57770316620635	41033
1e9d12b8362e2113a2fa7eb98044a2dc0ab98af4	lossy node identification in wireless sensor network	loss measurement;sensor phenomena and characterization;performance evaluation;intelligent networks wireless sensor networks network topology sensor phenomena and characterization electric breakdown hamming distance computer science performance loss loss measurement bandwidth;lossy node identification;network performance;parent child node;prior knowledge;electric breakdown;sensor network;wireless sensor network;packet loss rate;network topology;end to end measurement;hamming distance;data aggregation;wireless sensor networks performance evaluation;sensor nodes;reverse data aggregation topology;bandwidth;passive end to end measurement;intelligent networks;computer science;network services;reverse data aggregation topology lossy node identification wireless sensor network network performance passive end to end measurement hamming distance parent child node;performance loss;wireless sensor networks	In a sensor network, the nodes that have a packet loss rate greater than a given threshold are called lossy nodes. Lossy nodes adversely affect network performance and collectively cause breakdown of network service in many cases. In this paper, we propose a new and simple approach to identify the lossy nodes from passive end-to-end measurements. Specifically, we consider the case of identifying lossy nodes during the aggregation of data from a collection of the sensor nodes to a sink node. The proposed method is based on the hamming distance of sequences on receipt/loss of aggregated data between each pair of parent-child node. With prior knowledge of the reverse data aggregation topology, our approach can identify all lossy nodes effectively. Finally, we validate the proposed approach	data aggregation;end-to-end principle;hamming distance;lossy compression;network packet;network performance;tree (data structure)	Yongjun Li;Wandong Cai;Wei Wang;Guangli Tian	2006	Fifth IEEE International Symposium on Network Computing and Applications (NCA'06)	10.1109/NCA.2006.39	wireless sensor network;telecommunications;computer science;key distribution in wireless sensor networks;computer network	Mobile	-7.630546792159977	77.49175694656812	41058
a90d685f60550e5d9f5bc2512dfdeaf4ec43c10f	array design for trie-based ip lookup	estensibilidad;internet protocol;routeur;random access memory;protocolo ipv6;sram based multi pipeline array design;protocolo internet;debit information;routing;high speed networks;information transmission;protocole internet;protocole ipv6;random access memory pipelines throughput systolic arrays chromium ip networks binary trees availability circuit topology wrapping;sram chips integrated circuit design ip networks;indice informacion;arrays;integrated circuit design;ip lookup speed possible;pipelines;ipv6;ipv6 protocol;information rate;router;trie based ip lookup;ipv6 trie based ip lookup sram based multi pipeline array design ip lookup speed possible;ip networks;ip lookup;extensibilite;scalability;transmision informacion;transmission information;router high speed networks ip lookup;throughput;sram chips	A novel SRAM based multi-pipeline array design is proposed for trie-based IP lookup. The new structure increases parallelism and achieves a higher throughput, making for example a 2 Tbps IP lookup speed possible. The new design is scalable and applicable to IPv6.	graphics pipeline;lookup table;parallel computing;scalability;static random-access memory;systolic array;throughput;trie	Oguzhan Erdem;Cüneyt F. Bazlamaçci	2010	IEEE Communications Letters	10.1109/LCOMM.2010.08.100398	internet protocol;routing;throughput;parallel computing;real-time computing;scalability;computer science;ipv6;pipeline transport;computer network;integrated circuit design	Networks	-5.5430128759248385	66.97789486787651	41122
a3c173f3928582c0259dd845512dea8673f81347	the software architecture and interprocess communications of iri: an internet-based interactive distance learning system	data sharing;udp multicasting;interprocess communication;unix domain protocol;autonomous cooperating components;video streaming;reference implementation;iri;distance learning;audio streams;xtv data sharing engine;interprocess communications;multi user;video streams;group management;software architecture;shared applications;scalable expandable system;internet;software architecture internet streaming media multicast protocols computer aided instruction multimedia systems application software collaboration video sharing search engines;internet based interactive distance learning system;interactive remote instruction system;reliable multicasting protocol;messages;multi user collaborative utilities;continuous multimedia;messages software architecture interprocess communications iri internet based interactive distance learning system reference implementation interactive remote instruction system continuous multimedia shared applications multi user collaborative utilities group management udp multicasting unix domain protocol audio streams video streams reliable multicasting protocol xtv data sharing engine scalable expandable system autonomous cooperating components	This paper discusses the software architecture, inter-process communication and the reference implementation of IRI, an Interactive Remote Instruction system for distance learning. IRI is an Internet-based system which integrates continuous multimedia, shared applications and a variety of multiuser collaborative utilities. Internet multicasting is used by IRI for group management and data sharing; UDP-multicasting is used for audio and video streams while reliable mul-ticasting protocol (RMP) is used by XTV, the data sharing engine of IRI. The system is both scalable and expandable. It is scalable through the use of multi-casting for interprocess communication. It is expand-able due to its partitioning into a set of autonomous but cooperating components. The interaction among components is speciied by a set of messages and the functions needed to send and receive these messages.	autonomous robot;inter-process communication;internet;multi-user;multicast;reference implementation;risk management plan;scalability;software architecture;streaming media	Hussein M. Abdel-Wahab;Kurt Maly;Alaa Youssef;Emilia Stoica;C. Michael Overstreet;J. Christian Wild;Ajay Gupta	1996		10.1109/ENABL.1996.555030	reference implementation;distance education;software architecture;message;real-time computing;the internet;computer science;operating system;database;distributed computing;world wide web;computer security;computer network;inter-process communication	OS	-23.187096568491636	71.74618331258121	41211
5f3f3e90812bd5af4ec8ffb9082aa300c4111a87	optimal rate-based scheduling on multiprocessors	fairness;real time;task model;multiprocessors;optimality;scheduling;real time scheduling;pfair	"""The PD2 Pfair/ERfair scheduling algorithm is the most efficient known algorithm for optimally scheduling periodic tasks on multiprocessors. In this paper, we prove that PD2 is also optimal for scheduling """"rate-based"""" tasks whose processing steps may be highly jittered. The rate-based task model we consider generalizes the widely-studied sporadic task model."""	scheduling (computing)	Anand Srinivasan;James H. Anderson	2006	J. Comput. Syst. Sci.	10.1016/j.jcss.2006.03.001	fair-share scheduling;fixed-priority pre-emptive scheduling;parallel computing;real-time computing;earliest deadline first scheduling;flow shop scheduling;dynamic priority scheduling;computer science;rate-monotonic scheduling;two-level scheduling;deadline-monotonic scheduling;distributed computing;least slack time scheduling;lottery scheduling;round-robin scheduling;scheduling	Theory	-10.627613152446893	61.06440564033934	41247
4d2d72ce959d746f3f62b35923d24dfcf6d6b8e8	towards online shortest path computation	radio networks;shortest path;air index;wireless channels;live traffic index;wireless channels broadcasting client server systems driver information systems query processing radio networks radionavigation;maintenance time;query processing;wireless network;broadcasting shortest path air index;client server systems;maintenance engineering;maintenance time online shortest path computation live traffic circumstances modern car navigation systems live traffic information collection radio network wireless network live traffic index broadcasting channel lti query response time broadcast size;modern car navigation systems;radionavigation;indexes;navigation;servers;computational modeling;time factors;indexes roads servers maintenance engineering computational modeling time factors navigation;roads;live traffic circumstances;broadcast size;live traffic information collection;spatial databases;spatial databases and gis;lti;broadcasting channel;radio network;broadcasting;query response time;driver information systems;online shortest path computation	The online shortest path problem aims at computing the shortest path based on live traffic circumstances. This is very important in modern car navigation systems as it helps drivers to make sensible decisions. To our best knowledge, there is no efficient system/solution that can offer affordable costs at both client and server sides for online shortest path computation. Unfortunately, the conventional client-server architecture scales poorly with the number of clients. A promising approach is to let the server collect live traffic information and then broadcast them over radio or wireless network. This approach has excellent scalability with the number of clients. Thus, we develop a new framework called live traffic index (LTI)which enables drivers to quickly and effectively collect the live traffic information on the broadcasting channel. An impressive result is that the driver can compute/update their shortest path result by receiving only a small fraction of the index. Our experimental study shows that LTI is robust to various parameters and it offers relatively short tune-in cost (at client side), fast query response time (at client side), small broadcast size (at server side), and light maintenance time (at server side)for online shortest path problem.	automotive navigation system;client-side;client–server model;computation;experiment;overhead (computing);pareto efficiency;response time (technology);scalability;server (computing);server-side;shortest path problem	U Hou LeongHou;Hong Jun Zhao;Man Lung Yiu;Yuhong Li;Zhiguo Gong	2014	IEEE Transactions on Knowledge and Data Engineering	10.1109/TKDE.2013.176	maintenance engineering;database index;navigation;constrained shortest path first;shortest job next;computer science;wireless network;database;distributed computing;shortest path problem;computational model;world wide web;broadcasting;server;computer network	DB	-19.27632030806743	76.29927216585384	41270
4afa16b57d8acd38512e9394ade8258873331a12	openflow supporting inter-domain virtual machine migration	virtual machine;topology;server virtualization;control systems;protocols;openflow;virtual machines computer centres internetworking middleware network servers protocols;virtual machining;bi section bandwidth;iaas middleware;data center networks;interdomain virtual machine migration;software defined networking;computer centres;network topology;computer architecture;servers;network servers;virtual machines;workload migration;iaas middleware openflow interdomain virtual machine migration data center networks server virtualization traffic patterns bi section bandwidth workload migration interworking protocols interworking cloud dcn software defined networking;interworking cloud dcn;interworking protocols;internetworking;topology virtual machining control systems servers protocols network topology computer architecture;middleware;traffic patterns	Today, Data Center Networks (DCNs) are re-architected in different new architectures in order to alleviate several emergent issues related to server virtualization and new traffic patterns, such as the limitation of bi-section bandwidth and workload migration. However, these new architectures will remain either proprietary or hidden in administrative domains, and interworking protocols will remain in-process of standardization for a time longer than the usually required time to market. Therefore, interworking cloud DCNs to provide the federated clouds is a very challenging issue that seems to be potentially alleviated by a software-defined networking (SDN) approach such as Openflow. In this paper, we propose a network infrastructure as a services (IaaS) software middleware solution based on Openflow in order to abstract the DCN architecture specifities and instantly interconnect DCNs. As a proof of concept we implement an experimental scenario dealing with virtual machine migration. Then, we evaluate the network setup and the migration delay. The use of the IaaS middleware allows automating these operations. OpenFlow solves the problem of interconnecting heterogeneous Data Centers and its implementation offers interesting delay values.	administrative domain;cloud computing;complex network;data center;dynamic circuit network;emergence;inter-domain;interconnection;interoperability;middleware;on the fly;openflow;software-defined networking;tag cloud;virtual machine;virtual private server	Bochra Boughzala;Racha Ben Ali;Mathieu Lemay;Yves Lemieux;Omar Cherkaoui	2011	2011 Eighth International Conference on Wireless and Optical Communications Networks	10.1109/WOCN.2011.5872945	computer science;virtual machine;control system;operating system;distributed computing;computer network	Networks	-15.495100485640315	82.00698332014649	41403
2b78c34e2c48f60de37a36ff822024bc319a530b	dimensioning server access bandwidth and multicast routing in overlay networks	network design;value added services;differentiated services;network planning;packet remarking;ip multicast;audio video;satisfiability;analytical method;overlay network;cost effectiveness;active buffer management;load balance;inproceedings;multicast routing;cost model;application level multicast	Application-level multicast is a new mechanism for enabling multicast in the Internet. Driven by the fast growth of network audio/video streams, application-level multicast has become increasingly important for its efficiency of data delivery and its ability of providing value-added services to satisfy application specific requirements. From a network design perspective, application-level multicast differs drastically from traditional IP multicast in its network cost model and routing strategies. We present these differences and formulate them as a network design problem consisting of two parts: one is bandwidth assignment in the overlay network, the other is load-balancing multicast routing with delay constraints. We use analytical methods and simulations to show that our design solution is a valid and cost-effective approach. Simulation results show that we are able to achieve network utilization within 10% of the best possible utilization while keeping the session rejection rate low.	analysis of algorithms;internet;load balancing (computing);multicast;network planning and design;overlay network;rejection sampling;requirement;routing;server (computing);simulation;streaming media	Sherlia Shi;Jonathan S. Turner;Marcel Waldvogel	2001		10.1145/378344.378357	network planning and design;real-time computing;multicast;overlay network;ip multicast;non-broadcast multiple-access network;inter-domain;reliable multicast;mbone;protocol independent multicast;computer science;pragmatic general multicast;classful network;geocast;internet group management protocol;distributed computing;distance vector multicast routing protocol;source-specific multicast;multimedia broadcast multicast service;computer security;xcast;computer network;multicast address	Networks	-6.020612161759103	85.78075981318388	41406
3c2be5a6bbbb4f0d5c0a7bcb9d19ededd2bd9965	cost and reliability considerations in designing the next-generation ip over wdm backbone networks	reconfigurable optical add drop multiplexer;network design;reliability;central office;path diversity;telecommunication network reliability;optical transport network;ip over wdm;internet service provider;multiplexing equipment;transport layer;internet;telecommunication network routing;network model;next generation;optical links;wavelength division multiplexing reliability transponders ip networks optical fiber communication repeaters;ip networks;repeaters;transponders;wavelength division multiplexing internet ip networks multiplexing equipment optical links telecommunication network reliability telecommunication network routing;optical fiber communication;survive failures ip networks wdm reliability internet service providers reconflgurable optical add drop multiplexers optical links isp backbone routers intelligent optical transport network next generation backbone network;wavelength division multiplexing;wavelength division multiplex	To accommodate the increasing demands for bandwidth, Internet Service Providers (ISPs) have deployed higher-speed links and reconfigurable optical add drop multiplexers (ROADMs) in their backbone networks. To address the reliability challenges due to failures and planned outages, ISPs typically use two backbone routers at each central office in a dual-home configuration. Thus at the IP layer, redundant backbone routers as well as redundant transport equipment to interconnect them are deployed to provide reliability through node and path diversity. However, adding such redundant resources increases the overall cost of the network. Hence, a fundamental redesign of the backbone network which avoids such redundant resources by leveraging the capabilities of an intelligent optical transport network is a highly desirable objective. It is clear that such a redesign must lower costs without compromising on the reliability achieved by today's backbone networks. Modeling the costs and reliability of the network at all layers is an important step in achieving this objective. In this paper, we undertake an in-depth investigation of the cost and reliability considerations involved in designing the next-generation backbone network. Our work includes a detailed analysis of the operation, cost and reliability of the network at the IP layer and the multiple layers below it. We discuss alternative backbone network designs which use only a single router at each central office but use the optical transport layer to carry traffic to routers at other offices in order to survive failures or outages of the single local router. We discuss trade-offs involved in using these designs.	agile software development;baseline (configuration management);internet backbone;multiplexer;network topology;next-generation network;router (computing);wavelength-division multiplexing	Byrav Ramamurthy;K. K. Ramakrishnan;Rakesh K. Sinha	2011	2011 Proceedings of 20th International Conference on Computer Communications and Networks (ICCCN)	10.1109/ICCCN.2011.6006102	optical transport network;network planning and design;the internet;telecommunications;computer science;network model;transponder;reliability;backbone network;transport layer;wavelength-division multiplexing;repeater;computer network	Metrics	-8.946879108096248	84.96563650245898	41413
f71cbca10ec68dee400840a27916a22d3faf555e	a scalable logical topology for optical networks	optical network;multihop networks;low diameter;logical topology;scalable topology;satisfiability;optical networks;multihop network;regular graph	One of the approaches investigated for multihop lightwave networks is to consider regular graphs as the logical topology for a multihop network. Standard regular topologies are defined only for networks with the number of nodes satisfying some rigid criteria and are not directly usable for multihop networks. Only a few recent proposals (e.g., GEMNET) are regular and yet allow the number of nodes to have any arbitrary value. These networks have one major problem - node addition requires a major redefinition of the network. For example, in a multistar implementation, a large number of retuning of transmitters and receivers and/or renumbering nodes are needed for GEMNET. In this paper we present a new logical topology which has a low diameter but is not strictly regular. The interesting aspect of this topology is that it allows the network to be expanded incrementally involving a relatively small number of edge definitions/redefinitions. In this paper we have described our new topology and its properties. We have also implemented a routing scheme that ensures a low diameter and an algorithm for adding nodes to the network.	logical topology;scalability	Arunita Jaekel;Subir Bandyopadhyay;S. Roychoudhury;Abhijit Sengupta	2002	J. High Speed Networks		regular graph;hierarchical network model;distributed computing;extension topology;network topology;computer network;logical topology;satisfiability	Theory	-5.983109356484181	80.39670804564244	41472
1f9274fe0934a0773d691d08becb9568ba507028	analyzing bittorrent traf?c across large network	telecommunication traffic peer to peer computing;protocols;measurement;pollution measurement;traffic control;p2p;p2p file transform systems large network peer to peer applications isp network workload generation bittorrent websites;evolution biology;telecommunication traffic;network traffic;bittorrent;measurement bittorrent p2p;telecommunication traffic traffic control communication system traffic control peer to peer computing gain measurement character generation capacity planning computer science application software solids;experimental evaluation;peer to peer computing;peer to peer;load modeling;data transfer	The use of peer-to-peer (P2P) applications is growing dramatically, particularly for BitTorrent system. In order to gain insights into BitTorrent systems and the network traffic load they place on ISPs, we have undertaken an measurement study. Our experimental evaluation is ISP oriented instead of peer oriented, which enables us to study the global characteristics of BitTorrent system. We have developed a dedicated BitTorrent sniffer platform to collected extensive packet across a large ISP network. The measurement results bring important insights into BitTorrent systems. Specifically,our results show that 1) BitTorrent flashcrowd appears around midnight due to the BitTorrent users habits of behavior; 2) workload generated by BitTorrent extention - DHT is much more than it generated by calssic BitTorrent; 3) overhead rather than data transfer is the dominant component of the totle BitTorrent traffic due to DHT; 4) Zipf and pareto are the suitable model to characterize the distribution of visits to both trackers and BitTorrent Websites.Insights obtained in this study will be valuable for the management and development of future P2P file transform systems.	bittorrent;distributed hash table;distributed shared memory;download;image scaling;internet backbone;network packet;network traffic control;overhead (computing);pareto efficiency;peer-to-peer file sharing;rich internet application;software deployment;tier 1 network;zipf's law	Jiayin Qi;Hongli Zhang;Zhenzhou Ji;Liu Yun	2008	2008 International Conference on Cyberworlds	10.1109/CW.2008.150	communications protocol;traffic classification;bittorrent;computer science;peer-to-peer;internet privacy;world wide web;measurement;computer network	Metrics	-15.191304075102984	76.34091094096794	41474
1588ae653292d0cf82c9facc2c31130ffa4f22df	openflow-compliant topology management for sdn-enabled information centric networks		Information-Centric Networking (ICN) has emerged as an interesting approach to overcome many of the limitations of legacy IP-based networks. However, the drastic changes to legacy infrastructure required to realise an ICN have significantly hindered its adoption by network operators. As a result, alternative deployment strategies are investigated, with Software-Defined Networking (SDN) arising as a solution compatible with legacy infrastructure, thus opening new possibilities for integrating ICN concepts in operators' networks. This paper discusses the seamless integration of these two architectural paradigms and suggests a scalable and dynamic network topology bootstrapping and management framework to deploy and operate ICN topologies over SDN-enabled operator networks. We describe the designed protocol and supporting mechanisms, as well as the minimum required implementation to realize this inter-operability. A proof-of-concept prototype has been implemented to validate the feasibility of the approach. Results show that topology bootstrapping time is not significantly affected by the topology size, substantially facilitating the intelligent management of an ICN-enabled network.	icn gps;interoperability;legacy system;network switch;network topology;openflow;operability;prototype;scalability;seamless3d;software deployment;software-defined networking	George Petropoulos;Konstantinos Vasileios Katsaros;Maria-Evgenia Xezonaki	2017	2017 IEEE Symposium on Computers and Communications (ISCC)	10.1109/ISCC.2017.8024648	software deployment;operator (computer programming);distributed computing;computer network;dynamic network analysis;scalability;computer science;network topology;openflow;bootstrapping;topology;logical topology	Networks	-15.87067213792278	84.8729934165534	41512
7457ca0af3a155ec7bcff0f8f4ef40393859f0f8	ethernet topology discovery for networks with incomplete information	optimisation;ethernet topology discovery;topology discovery;layer 2 network;layer 2 topology discovery;snmp mib;telecommunication network topology local area networks optimisation;network topology;incomplete information;np hard problem;np hard layer 2 topology discovery ethernet lans snmp mib switches;layer 2 network ethernet topology discovery polynomial time heuristic algorithm snmp mib incomplete information;ethernet lans;polynomial time;polynomial time heuristic algorithm;layer 2;snmp mib incomplete information;np hard;ethernet networks network topology protocols switches bridges iso polynomials algorithm design and analysis heuristic algorithms environmental management;telecommunication network topology;switches;local area networks;heuristic algorithm	In this paper, we investigate the problem of finding the layer-2 network topology of large, heterogeneous multisubnet Ethernet networks that may include uncooperative network nodes. We prove that finding a layer-2 network topology for a given incomplete input is an NP-hard problem, even for single subnet networks, and that deciding whether a given input defines a unique network topology is a co-NP-hard problem. We design several heuristic algorithms to find network topology, evaluate their complexity, and provide criteria for instances in which the input guarantees a unique network topology. We have implemented one of our algorithms and conducted extensive experiments on the Kent State University Computer Science network. Our experiments demonstrate that our approach is quite practical and discovers the accurate network topology of multisubnet networks whose input may not necessarily be complete.	algorithm;co-np;computer science;experiment;heuristic;np-hardness;network topology;subnetwork	Hassan Gobjuka;Yuri Breitbart	2007	2007 16th International Conference on Computer Communications and Networks	10.1109/ICCCN.2007.4317888	real-time computing;computer science;np-hard;distributed computing;extension topology;particular point topology;euclidean topology;network topology;computer network;logical topology	DB	-4.577751009266042	80.3556632847725	41528
3dd662fa15fb58540d8d8011171ebc5beb0e011d	snmp administrative model		"""SNMP Administrative Model Status of this Memo This document specifies an IAB standards track protocol for the Internet community, and requests discussion and suggestions for improvements. Please refer to the current edition of the """"IAB Official Protocol Standards"""" for the standardization state and status of this protocol. Distribution of this memo is unlimited."""	simple network management protocol	James R. Davin;James M. Galvin;Keith McCloghrie	1992	RFC	10.17487/RFC1351	computer science;data mining;database;world wide web	Networks	-25.774026901821436	88.4639514707799	41595
b5fda20211bef0f6898001e5e76f0d91271b1940	energy-efficient optical access networks: issues and technologies	wavelength routing next generation energy efficient optical access network long term evolution power consumption next generation broadband services;telecommunication network routing next generation networks optical fibre subscriber loops;telecommunication network routing;optical fibre subscriber loops;passive optical networks optical network units power demand integrated optics next generation networking energy efficiency;next generation networks	This article discusses and clarifies the issues and technologies for the next-generation energy efficient optical access network from the viewpoints of its mid-term upgrade and long-term evolution. For reducing the total power consumption in the mid-term upgrade to 10-gigabit access, it is necessary to optimize the network configuration as well as the usage of various technologies while avoiding any service degradation in the next-generation broadband services. In the long-term evolution, wavelength routing will play a key role by drastically decreasing the total power consumption of the access network.	access network;elegant degradation;gigabit;routing	Junichi Kani;Satoshi Shimazu;Naoto Yoshimoto;Hisaya Hadama	2013	IEEE Communications Magazine	10.1109/MCOM.2013.6461185	passive optical network;routing;next-generation network;telecommunications;10g-pon;computer science;optical performance monitoring;computer network;access network	HPC	-13.087378730454759	87.27076184697523	41597
f858896fb293f757f6ae07cf701c52af57537b20	enhanced qos management sdn-based in ims with qoe evaluation			quality of service;software-defined networking	Sara Khairi;Brahim Raouyane;Mostafa Bellfakih	2017	J. Mobile Multimedia		computer vision;computer science;artificial intelligence;quality of service;computer network	Embedded	-13.725339129989239	86.78764307750833	41598
9d0642aeedd2760e4066f813ddc08f6551101a17	click-up: towards software upgrades of click-driven stateful network elements			state (computer science);stateful firewall	Jun-xiao Wang;Yuchen Huang;Heng Qi;Keqiu Li;Steve Uhlig	2018		10.1145/3234200.3234206	distributed computing;computer network;stateful firewall;computer science;software;software-defined networking;network element	Networks	-17.017302214601408	83.67236735004252	41640
dd94a778631334d0ca1008b758d5f678b8ccf316	mobile services for enhancing human crowdsourcing with computing elements	software;elasticity;services mobile crowdsourcing;mobile services task assignment automated software resources machine crowdsourcing components human crowdsourcing components;mobile;face recognition mobile communication elasticity crowdsourcing mobile handsets face software;face recognition;mobile communication;mobile handsets;face;services;mobile computing;crowdsourcing	Crowdsourcing enables one to leverage the power of the crowd. Normally, it involves utilizing humans for tasks that machines have difficulty performing. We propose a system, delivered as a mobile service, which dynamically adapts to the application domain and selects a combination of human and machine crowdsourcing components. Our work is towards the design of elastic systems that adaptively optimizes the use of human and automated software resources in order to maximize overall performance. We propose a performance model that predicts both human and machine outcomes for a certain task and then optimizes task assignment accordingly. Our experimentation shows that our proposed system significantly enhances the outcome precision of a crowdsourced task.	application domain;crowdsourcing;elasticity (data store);facial recognition system;host card emulation;server (computing)	Julian Jarrett;Iman Saleh;M. Brian Blake;Sean S. E. Thorpe;Tyrone Grandison;Rohan Malcolm	2014	2014 IEEE International Conference on Mobile Services	10.1109/MobServ.2014.30	mobile search;simulation;crowdsourcing software development;engineering;internet privacy;mobile computing;world wide web	Robotics	-25.083470228416225	66.15669607387461	41709
ea1dfb677ccde927f894758c4ba7395c1af90d07	an sla support system for cloud computing	sla specificity;cloud computing;sla support system;available cc infrastructure parameter;it infrastructure;specific performance parameter;certain cloud application;cloud providers;cloud users;specific sla parameter;sla specification	Nowadays, even with the existence of many Cloud Providers (CP) in the market, it is still impossible to see CPs who guarantee, or at least offer, an SLA specification to Cloud Users (CU) interests: not just offering percentage of availability, but also guaranteeing specific performance parameters for a certain Cloud application. Due to (1) the huge size of CPs’ IT infrastructures and (2) the high complexity with multiple inter-dependencies of resources (physical or virtual), the estimation of specific SLA parameters to compose Service Level Objectives (SLOs) with trustful Key Performance Indicators (KPIs) tends to be inaccurate. This paper proposes the initial design and preliminary approach for an SLA Support System for CC (SLACC) in order to estimate in a formalized methodology — based on available CC infrastructure parameters — what CPs will be able to offer/accept as SLOs or KPIs and, as a consequence, which increasing levels of SLA specificity for their customers can be reached.	cloud computing;sensitivity and specificity;service-level agreement;tip (unix utility)	Guilherme Sperb Machado;Burkhard Stiller	2011			real-time computing;database;computer security	HPC	-24.8167991676916	60.89451860254566	41740
60d659d6a7c880c56b04c50a20202aa08eccc0ae	network service abstractions for a mobility-centric future internet architecture	trust;future internet architecture;mobility;internet;network services;application programming interface	The increasing composition of mobile devices and mobile applications in the Internet requires us to revisit the traditional principles of fixed, host-centric communications, when designing a next-generation architecture. To support this major shift, we define in this paper a set of basic service abstractions that should be afforded by a future Internet that is centered upon the notion of self-certifying globally unique IDs (GUID) for all network principals - hosts, content, services, etc. alike. We followup with a specific set of network service APIs that provide full access to the proposed abstractions, and implement these on Linux and Android hosts that connect to an instantiation of the future Internet architecture proposal - MobilityFirst [5]. Using performance benchmarks and the implementation of representative use cases we show that the API is flexible and can enable efficient and robust versions of present and future applications.	android;application programming interface;future internet;linux;mobile app;mobile device;universal instantiation	Francesco Bronzino;Kiran Nagaraja;Ivan Seskar;Dipankar Raychaudhuri	2013		10.1145/2505906.2505908	the internet;computer science;distributed computing;world wide web;computer security	OS	-17.205505075926744	83.18891014529771	41856
c988031e62864fb4f1a3c7b300133ba76997c465	custodian-based information sharing	performance measure;routing protocols;routing protocols peer to peer computing media mobile communication information exchange ieee 802 11 standards ip networks;internet routing;open source ccn custodian based information sharing system icloud dropbox facebook twitter server infrastructure always on internet connectivity secure sharing information routing model internet routing protocol information centric networking;information sharing;internet;social networking online internet routing protocols security of data;information exchange;social networking online;mobile communication;ip networks;peer to peer computing;routing protocol;security of data;open source	Information sharing systems such as iCloud, Dropbox, Facebook, and Twitter are ubiquitous today, but all of them depend on massive server infrastructure and always-on Internet connectivity. We have designed and implemented a sharing system that does not require infrastructure yet supports robust, distributed, secure sharing by opportunistically using any and all connectivity, local or global, permanent or transient, to communicate. One key element of this system is a new information routing model that so far has proven to be as scalable and efficient as the best of the current Internet routing protocols, while operating in an environment more complex and dynamic than they can tolerate. The new routing model is made possible by new affordances offered by information-centric networking, in particular, the open source CCN [1] release. This article describes the new system and its routing model, and provides some performance measurements.	converge;cyclomatic complexity;dropbox;high availability;icn gps;image scaling;megabit;open-source software;overhead (computing);peering;routing;scalability;server (computing);social graph;software propagation;icloud	Van Jacobson;Rebecca Braynard;Tim Diebert;Priya Mahadevan;Marc Mosko;Nicholas H. Briggs;Simon Barber;Michael F. Plass;Ignacio Solis;Ersin Uzun;Byoung-Joon Lee;Myeong-Wuk Jang;Dojun Byun;Diana K. Smetters;James D. Thornton	2012	IEEE Communications Magazine	10.1109/MCOM.2012.6231277	policy-based routing;routing domain;static routing;telecommunications;computer science;distributed computing;routing protocol;world wide web;computer network	Networks	-12.028546412557779	76.75242553720874	41929
033789fcbf3b74513ffceee1c7cca3e324d44488	network coding for protection against multiple link failures in multi-domain networks	communications society;interconnection elements network coding multiple link failures multidomain networks protection schemes protection mechanism dual homing;dual homing;availability;ieee communications society;simulation;multidomain networks;interconnection elements;electric breakdown;protection mechanism;network coding protection peer to peer computing unicast joining processes electric breakdown virtual private networks grid computing communications society telecommunication traffic;multiple link failures;protection;telecommunication traffic;network coding;multi domain;protection schemes;link failure;joining processes;book reviews;peer to peer computing;grid computing;unicast;virtual private networks	Many networks today are composed of numerous subnetworks or domains. The connection points of these domains are important and vulnerable parts of the communication. Therefore, one of the key points of protection schemes today is being able to protect these interconnections. Hence, in this type of networks a protection mechanism is applied, where there is 1+1 protection inside each domain and dual homing at the borders. With this mechanism, the breakdown due to the failure of the interconnection elements is prohibited. This system enables the network to survive any node or link failure in each domain. However, it suffers from the high capacity need on the border links, where data has to be transmitted bidirectionally for each single demand. We are showing that combining network coding with this protection mechanism gives a realization, which outperforms the existing mechanism by providing high resource savings. We present the theoretical basis and the application methodology of the proposed method.	connection-oriented communication;domain theory;duplex (telecommunications);interconnection;like button;linear network coding;missile guidance;node (computer science);protection mechanism	Isil Burcu Barla Harter;Franz Rambach;Dominic A. Schupke;Mohit Thakur	2010	2010 IEEE International Conference on Communications	10.1109/ICC.2010.5502271	availability;linear network coding;telecommunications;computer science;computer security;grid computing;statistics;computer network;unicast	Robotics	-6.782053350797376	80.75878250957044	41942
065d3625051ae44db0bc9423ba9fa2afc65d685a	receiver-driven flow scheduling for commodity datacenters		To achieve scalable performance, datacenter applications (e.g., search and social networking) are designed to have high fanout. However, such a design leads to frequent fabric congestion (e.g., due to incast, imperfect hashing) even when the utilization is low. Such fabric congestion exhibits spatial (e.g., within a rack and across racks) as well as temporal variations. Unfortunately, current approaches infer congestion by focusing on a localized view leading to non-optimal performance. We propose RecFlow, a receiver-based proactive congestion control scheme that uses OpenFlow and ACK spacing to dynamically track changing bottlenecks and reduces buffer overflows while maintaining fairness and high link utilization. Experimental results show that compared to the state-of-the-art, RecFlow achieves negligible packet loss and high goodput while sharing the link capacity fairly between flows.	acknowledgement (data networks);buffer overflow;data center;fairness measure;fan-out;forwarding plane;goodput;network congestion;network packet;openflow;scalability;scheduling (computing);simulation;software-defined networking;tcp congestion control	Aadil Zia Khan;Ihsan Ayyub Qazi	2017	2017 IEEE International Conference on Communications (ICC)	10.1109/ICC.2017.7996676	scalability;real-time computing;computer network;buffer overflow;scheduling (computing);network congestion;goodput;packet loss;computer science;openflow;hash function	Mobile	-13.579858321826878	80.86457010244231	41977
a992478711eeddadd7f37539a1a991243655467e	distributed partial-express routing of broad-band transport network demands	iterative method;transportation networks;optimisation;broadband networks;optimizacion;routing;cost saving;optimal method;reseau ordinateur;wide band;search strategy;matrix algebra;multiplaje;multiplexing;computer network;metodo iterativo;communication system routing;large bande;network topology;optical fibre networks;multiplexage;telecommunication network routing;methode iterative;system design;search problems broadband networks telecommunication network routing economics optical fibre networks network topology matrix algebra wavelength division multiplexing;optical communication terminals;strategie recherche;red ordenador;optical communication;cost effectiveness;routing optical fiber devices costs optical fiber networks repeaters search problems testing network topology wdm networks optical fiber communication;optimization;encaminamiento;search problems;economics;wdm based networks distributed partial express routing broadband transport network design equipment savings cost savings dedicated transmission system nonadjacent nodes intermediate cross connecting nodes intermediate grooming nodes express routes hubbing sites remultiplexing economic express system co routed demands search problem maximally coherent subgroups economic payback test results transport network topology demand matrix models industry supplied cost data distributed partial express system design;acheminement;ancho banda;estrategia investigacion;wavelength division multiplexing;optimization methods;matrix model	There are a number of contexts in transport network design where cost savings arise from providing a dedicated transmission system between two nonadjacent nodes. This occurs when the cost to terminate demands at intermediate cross-connecting and grooming nodes exceeds the alternative of providing a dedicated, perhaps only partly filled, system. Today, dedicated end-toend “express routes” are usually found where large demands flow between major centers or to/from hubbing sites where traffic can be aggregated to warrant an express system. Smaller demand flows are usually terminated at each flexibility point en route to permit remultiplexing with other demands, thereby keeping the fiber system fill high. We consider a new means to find economic express system opportunities among combinations of the smaller co-routed demands. The hypothesis is that certain collections of demand may warrant express treatment over some common portion of their routes. These demands need not share common end nodes or be aggregated at a hub. Rather, they are discovered among the natural pattern of demand flows as a group of demands that travel together over some sequence of spans on which an express system might be cost-effective. The search problem is to detect the maximally coherent subgroups of demands en route that yield the best economic payback. Test results were obtained in four representative transport network topology and demand matrix models. Assuming a 75% level of system fill in the nonexpress baseline case, opportunities worth up to $45 M in equipment savings, relative to conventional design, were obtained using industry-supplied cost data. The concept of distributed partial-express system design may also be applicable to WDM-based networks to assign OCn level units of demand to various express or nonexpress wavelengths.	baseline (configuration management);coherence (physics);network planning and design;network topology;routing;search problem;systems design;terminate (software);usb hub;wavelength-division multiplexing	Mike H. MacGregor;Wayne D. Grover	1997	IEEE/ACM Trans. Netw.	10.1109/90.650155	routing;cost-effectiveness analysis;telecommunications;computer science;iterative method;network topology;multiplexing;wavelength-division multiplexing;optical communication;computer network;systems design;broadband networks	Networks	-5.073564847947294	79.35102065972438	41983
56462edd9f3f6a40dcf03b1a1aa3b4140ba8af36	the look-ahead-maximize-batch batching policy	pending requests;multimedia traffic management lamb look ahead maximize batch video servers pending requests;look ahead;bandwidth streaming media network servers displays telecommunication traffic hdtv large scale systems delay throughput scheduling;telecommunication traffic;network servers;streaming media;scheduling;displays;video server;multimedia traffic management;hdtv;bandwidth;lamb;video servers;look ahead maximize batch;large scale systems;throughput	This paper introduces a new batching policy, called look-ahead-maximize-batch (LAMB), for reducing the bandwidth demand of video servers. LAMB maximizes the number of users admitted in a window, which includes the reneging time of all pending requests at that scheduling time. LAMB admits a greater number of users than other existing batching policies. Furthermore, the benefits of integrating batching and piggybacking is analyzed.		Nelson Luis Saldanha da Fonseca;Roberto De A. Façanha	2002	IEEE Trans. Multimedia	10.1109/6046.985559	throughput;real-time computing;computer science;operating system;distributed computing;scheduling;bandwidth;computer network	Visualization	-15.200548383135445	70.89562678572594	42145
d491db1ae3a60662df77805982bfd890941cb9ec	hierarchical and hash based naming with compact trie name management scheme for vehicular content centric networks	longest prefix matching;compact trie;fib;hierarchical naming;vehicular content centric networks	Content-Centric Network (CCN) is a promising future Internet architecture, attracting research community and being widely adopted in the vehicular networks. The main concept of CCN is to smoothly distribute digital contents between the content provider and consumer. In these types of networks, contents are identified by unique names, however, naming those contents is still a challenging task. Therefore, we propose a hierarchical and hash based naming with efficient Compact Trie (CT) management scheme for Vehicular Content-Centric Network (VCCN). The proposed naming scheme makes the best use of the features offered by hierarchical as well as hash-based or flat naming schemes. The hierarchical part of the digital content name contains information about the content provider, type, its sub-types and attributes of the content itself that is shared between vehicles. The hash part uniquely identifies the digital content required for VCCN applications. The proposed naming scheme satisfies two main purposes: first, it helps in minimizing the routing table by aggregating the name prefixes and simplifying the routing decisions. Second, it contains attributes, spatial, temporal and their range information to easily find and resolve the content. The proposed scheme manages prefixes (e.g. Add, Search and Delete) in the tables e.g. Forwarding Information Base (FIB), Pending Interest Table (PIT), etc. The CT is relatively faster and space-efficient than Simple Trie and has better performance compared to the existing solutions of naming the required content(s). The evaluation results show that the proposed CT based prefix management scheme performs 45.5% and 23.3% faster prefix search and 55% and 34% faster prefix delete operation compared to Simple Trie and Bloom-Filter based name management schemes, respectively. The memory profile results show that average memory consumption of the proposed CT implementation is 24 and 186 times smaller than the Simple Trie and the NLAPB, respectively. © 2015 Elsevier B.V. All rights reserved.	bloom filter;cyclomatic complexity;digital recording;future internet;routing table;smoothing;trie	Safdar Hussain Bouk;Syed Hassan Ahmed;Dongkyun Kim	2015	Computer Communications	10.1016/j.comcom.2015.09.014	focused ion beam;telecommunications;computer science;theoretical computer science;operating system;database;hash array mapped trie;longest prefix match;world wide web;computer security;computer network	Mobile	-14.832178697274072	74.54322018965622	42158
37cb4384f360ea1cc2be3900699f6882717fada4	networking smartphones for disaster recovery	disaster recovery off the shelf smartphones android platform emergency messages opportunistic networking ad hoc networking cellular networking self rescue system messaging system teamphone;poles and towers;routing;smart phones;smart phones routing ad hoc networks logic gates poles and towers mobile communication ieee 802 11 standard;logic gates;mobile communication;ad hoc networks;ieee 802 11 standard;smart phones ad hoc networks cellular radio electronic messaging emergency management mobile computing	In this paper, we investigate how to network smart-phones for providing communications in disaster recovery. By bridging the gaps among different kinds of wireless networks, we have designed and implemented a system called TeamPhone, which provides smartphones the capabilities of communications in disaster recovery. Specifically, TeamPhone consists of two components: a messaging system and a self-rescue system. The messaging system integrates cellular networking, ad-hoc networking and opportunistic networking seamlessly, and enables communications among rescue workers. The self-rescue system energy-efficiently groups the smartphones of trapped survivor and sends out emergency messages so as to assist rescue operations. We have implemented TeamPhone as a prototype application on the Android platform and deployed it on off-the-shelf smartphones. Experiment results show that TeamPhone can properly fulfill communication requirements and greatly facilitate rescue operations in disaster recovery.	android;bridging (networking);disaster recovery;hoc (programming language);inter-process communication;prototype;requirement;scheduling (computing);smartphone	Zongqing Lu;Guohong Cao;Thomas F. La Porta	2016	2016 IEEE International Conference on Pervasive Computing and Communications (PerCom)	10.1109/PERCOM.2016.7456503	vehicular ad hoc network;wireless ad hoc network;embedded system;routing;adaptive quality of service multi-hop routing;mobile telephony;logic gate;telecommunications;computer science;delay-tolerant networking;computer security;computer network	Mobile	-25.573562079735044	82.57251930108454	42172
00de7982628b375b0c2ddf5acd28df1542706305	modeling the probability of failure on ldap binding operations in iplanet web proxy 3.6 server	data collection;probability of failure;theoretical analysis;stochastic approximation;web proxy	This paper is devoted to the theoretical analysis of a problem derived from interaction between two Iplanet products: Web Proxy Server and the Directory Server. In particular, a probabilistic and stochasticapproximation model is proposed to minimize the occurrence of LDAP connection failures in Iplanet Web Proxy 3.6 Server. The proposed model serves not only to provide a parameterization of the aforementioned phenomena, but also to provide meaningful insights illustrating and supporting these theoretical results. In addition, we shall also address practical considerations when estimating the parameters of the proposed model from experimental data. Finally, we shall provide some interesting results from real-world data collected from our customers.	lightweight directory access protocol;proxy server	Alejandro Chinea Manrique De Lara	2002	CoRR		stochastic approximation;computer science;operating system;data mining;database;mathematics;world wide web;statistics;data collection	Web+IR	-25.413366095594668	70.59107267455553	42195
248aa02eea9d2b39da2d1a7baa71a93a779829cc	toward a reliable, secure and fault tolerant smart grid state estimation in the cloud	smart power grids cloud computing fault tolerance phasor measurement power engineering computing power system reliability power system state estimation reactive power;power engineering computing;smart power grids;fault tolerance;phasor measurement units cloud computing state estimation smart grids monitoring power measurement extraterrestrial measurements;power system state estimation;phasor measurement;power system reliability;fault tolerant smart grid state estimation cloud platform standard cloud infrastructure cloud architecture pmu based state estimation application smart grid community cloud computing system grid control applications risk reduction catastrophic large scale outage reactive power grid management applications smart power grid reliability smart power grid security synchrophasor measurement analysis;cloud computing;reactive power	The collection and prompt analysis of synchrophasor measurements is a key step towards enabling the future smart power grid, in which grid management applications would be deployed to monitor and react intelligently to changing conditions. The potential exists to slash inefficiencies and to adaptively reconfigure the grid to take better advantage of renewables, coordinate and share reactive power, and to reduce the risk of catastrophic large-scale outages. However, to realize this potential, a number of technical challenges must be overcome. We describe a continuously active, timely monitoring framework that we have created, architected to support a wide range of grid-control applications in a standard manner designed to leverage cloud computing. Cloud computing systems bring significant advantages, including an elastic, highly available and cost-effective compute infrastructure well-suited for this application. We believe that by showing how challenges of reliability, timeliness, and security can be addressed while leveraging cloud standards, our work opens the door for wider exploitation of the cloud by the smart grid community. This paper characterizes a PMU-based state-estimation application, explains how the desired system maps to a cloud architecture, identifies limitations in the standard cloud infrastructure relative to the needs of this use-case, and then shows how we adapt the basic cloud platform options with sophisticated technologies of our own to achieve the required levels of usability, fault tolerance, and parallelism.	cloud computing;commodity computing;computation;data security;distributed operating system;fault tolerance;map;parallel computing;power management unit;real-time clock;slash (cms);technical standard;usability	Ketan Maheshwari;Marcus Lim;Lydia Wang;Kenneth P. Birman;Robbert van Renesse	2013	2013 IEEE PES Innovative Smart Grid Technologies Conference (ISGT)	10.1109/ISGT.2013.6497831	embedded system;real-time computing;engineering;smart grid;computer security;grid computing	HPC	-28.21618399165817	60.738308425891454	42231
43bf009807c2decd344b6a6bd91e3ef9f4a2b31c	adaptive optimierung des prefetch-verhaltens bei objektorientierten multi-tier client-server-systemen	content management;client server	In distributed client-server-applications prefetching – the speculative tranfer of data which could probably be used in future – describes an important concept to improve efficiency, interactivity and performance of the system. Especially for rich-client applications, which have their application logic and processing powers located on client-side, a well-adapted prefetching behaviour holds a significant potential for increasing the total performance of the client-server-system. Optimization of prefetching behavior for client-server-systems is both a time consuming and demanding task especially for systems which allow varying data models, special modifications for customers and user role specific operation. Therefore it is the aim of this thesis to present a technique for automatic calculation of the prefetching logic which is able to adapt to a varying data models as well as to the individual behaviour of each user using the content management platform SCHEMA ST4 as software foundation.	actor (uml);business logic;cpu cache;client-side;client–server model;data model;fat client;interactivity;multitier architecture;server (computing);speculative execution	Matthias Hofmann;Arno Klein;Gabriella Kókai	2007			client–server model;operating system;instruction prefetch;computer science	OS	-25.343004145844986	63.12992377006497	42235
c7d44765f163fd33b7947f163878e7b0469ce5ce	parallel simulation of mobile communication networks using a distributed workstation environment			simulation;workstation	Jari Porras;Jarmo Harju;Jouni Ikonen	1995			mobile station;workstation;mobile telephony;distributed computing;mobile computing;computer science	HPC	-16.98954340683401	88.54916389884104	42347
d8b7775f6acebadeb336e9d37ec025c6a4e92c33	autonomic role and mission allocation framework for wireless sensor networks	optimisation;telecommunication network reliability;resource management monitoring equations acceleration temperature sensors accelerometers computer architecture;real time;pervasive system;sensor network;wireless sensor network;performance metric;conference paper;np hard problem;monitoring system;fault tolerant computing;network traffic;wireless sensor networks fault tolerant computing optimisation telecommunication network reliability ubiquitous computing;autonomic task allocation wireless sensor network self adapting;ubiquitous computing;autonomic;task assignment;quality of service;component failures autonomic role mission allocation framework wireless sensor networks pervasive applications physical components external factors pervasive systems transparent asset autonomic mechanism initial task assignment np hard problem online adaptation real time metrics smooth service degradation;self adapting;wireless sensor networks;task allocation	Pervasive applications incorporate physical components that are exposed to everyday use and a large number of conditions and external factors that can lead to faults and failures. It is also possible that application requirements change during deployment and the network needs to adapt to a new context. Consequently, pervasive systems must be capable to autonomically adapt to changing conditions without involving users becoming a transparent asset in the environment. In this paper, we present an autonomic mechanism for initial task assignment in sensor networks, an NP-hard problem. We also study on-line adaptation of the original deployment which considers real-time metrics for maximising utility and lifetime of applications and smooth service degradation in the face of component failures.	algorithm;approximation;autonomic computing;cell (microprocessor);elegant degradation;embedded system;formal specification;heuristic;np-hardness;online and offline;pervasive informatics;problem domain;real-time clock;requirement;simulated annealing;software deployment;ubiquitous computing;universal instantiation	Themistoklis Bourdenas;Kenji Tei;Shinichi Honiden;Morris Sloman	2011	2011 IEEE Fifth International Conference on Self-Adaptive and Self-Organizing Systems	10.1109/SASO.2011.17	real-time computing;wireless sensor network;computer science;operating system;distributed computing;ubiquitous computing;computer network	Robotics	-29.630485824548355	61.20482204287746	42404
8ad0ed4d80edb4a75c5a143ba795a974e3f46efa	performance evaluation and verification of communication protocol for railway signaling systems	modal mu calculus;verification;performance evaluation;labeled transition system;simulation;model checking method;formal method;digital communication;model checking;error correction;lts labeled transition system;communication protocol for railway signaling;communication protocol	As long as railway signaling systems is digitalized, communication link is getting more important as a result of variety of communication links, such as links for interface between each signaling are replaced by digital communication channels. However, the communication links for current railroad signaling have some problems in Korea. At first, the maintenance is difficult because protocols for interface are applied differently at the each manufacturer. Also, communication protocols, such as structure, byte format, and error correction method, have a little non-logical part, which threatens safety. In order to solve this problem, the standard communication verified by using formal method is required. After designing new protocol for railway signaling, this paper analyzed the designed protocol’s structure and performance through simulation. Also, as a very important part in the development of protocol, this paper specified the designed protocol in Labeled Transition System (LTS) with model check method, and verified safety and liveness proprieties of the designed protocol. Therefore, it is expected that the safety, reliability, and efficiency of maintenance for the railway signaling systems will be increased by using the newly designed communication protocol in Korea. D 2004 Elsevier B.V. All rights reserved.	byte;communications protocol;error detection and correction;formal methods;liveness;model checking;performance evaluation;profiling (computer programming);simulation;synchronous data link control;transition system	Jae-Ho Lee;Jong-Gyu Hwang;Gwi-Tae Park	2005	Computer Standards & Interfaces	10.1016/j.csi.2004.08.004	model checking;communications protocol;universal composability;real-time computing;verification;error detection and correction;formal methods;telecommunications;computer science;operating system;distributed computing;programming language;computer security;computer network	Networks	-5.9695701223963455	70.88811099168989	42429
332ab9c79e31fa6b4d9aa16b70f0a2e520702d73	modeling the effect of parallel execution on multi-site computation offloading in mobile cloud computing.		As the smart mobile devices are becoming an inevitable part of our daily life, the demand for running complex applications on such devices is increasing. However, the limitations of resources (e.g. battery life, computation power, bandwidth) of these devices are restricting the type of applications that can run on them. The restrictions can be overcome by allowing such devices to offload computation and run parts of an application in the powerful cloud servers. The greatest benefit from computation offloading can be obtained by optimally allocating the parts of an application to different devices (i.e. the mobile device and the cloud servers) that minimizes the total cost—the cost can be the response time of the application or the mobile battery usage, or both. Normally, different devices can have different number of processing cores. Unlike prior work in the modeling of computation offloading, this work models the effect of parallel execution of different parts of an application—on different devices (external parallelism) as well as on different cores of a single device (internal parallelism)—on offloading allocation. This work considers each device as a multi-server queueing station. It proposes a novel algorithm to evaluate the response time and energy consumption of an allocation while considering both the application workflow as well as the parallel execution across the cores of different devices. For finding the near-optimal allocation(s), it uses an existing genetic algorithm that invokes our proposed algorithm to determine the fitness of an allocation. This work is more advantageous for cases where a workflow has multiple tasks that can execute in parallel. The results show that modeling the effect of parallel execution yields better near-optimal solution(s) for the allocation problem compared to not modeling parallel execution at all.		Ismail Sheikh;Olivia Das	2018		10.1007/978-3-030-02227-3_15	real-time computing;mobile cloud computing;computation;cloud computing;mobile device;response time;computer science;computation offloading;server;workflow	HPC	-23.022004272025036	66.45136583661281	42465
60cf2edc0c57004c2d1ba497820d0c4e06b85e6a	lisp: a southbound sdn protocol?	routing protocols;semantics;layout;software defined networking;aerospace electronics semantics scalability layout routing protocols;aerospace electronics;scalability;locator id separation protocol lispmob open source implementation sdn requirements systematic analysis inherent control data decoupling ip address southbound sdn protocol software defined networking lisp components lisp architecture;article;software defined networking access protocols public domain software	The Locator/ID Separation Protocol (LISP) splits current IP addresses overlapping semantics of identity and location into two separate names-paces. Since its inception the protocol has gained considerable attention from both industry and academia, motivating several new use cases to be proposed. Despite its inherent control-data decoupling and the abstraction and flexibility it introduces into the network, little has been said about the role of LISP on the SDN paradigm. In this article we try to fill that gap and analyze if LISP can be used for SDN. The article presents a systematic analysis of the relevant SDN requirements and how such requirements can be fulfilled by the LISP architecture and components. This results in a set of benefits (e.g. incremental deployment, scalability, flexibility, interoperability, and inter-domain support) and drawbacks (e.g. extra headers and some initial delay) of using LISP for SDN. In order to validate the analysis, we have built and tested a prototype using the LISPmob open-source implementation.	coupling (computer programming);inter-domain;interoperability;northbound interface;open-source software;programming paradigm;prototype;requirement;scalability;software deployment;software-defined networking	Alberto Rodríguez-Natal;Marc Portoles-Comeras;Vina Ermagan;Darrel Lewis;Dino Farinacci;Fabio Maino;Albert Cabellos-Aparicio	2015	IEEE Communications Magazine	10.1109/MCOM.2015.7158286	layout;real-time computing;scalability;locator/identifier separation protocol;computer science;operating system;database;distributed computing;semantics;software-defined networking;routing protocol;computer network	Networks	-15.767343768412065	83.84725468319681	42506
8ff4f5e09304c6d33c6dc15243cb1c3c7b556260	sands: specialized active networking for distributed simulation	content based filtering;multicast communication;content based retrieval distributed processing digital simulation real time systems information dissemination multicast communication transport protocols;active filters virtual prototyping filtering algorithms large scale systems information filtering information filters protocols multicast algorithms contracts computer science;ip multicast;real time;distributed processing;active network;transport protocols;large scale;publish subscribe;information dissemination;active filter;modsaf sands specialized active networking for distributed simulation darpa content based information dissemination real time system active interest filtering publish subscribe mechanism active routers ip multicast distribution tree per node algorithms signaling protocol;distributed simulation;content based retrieval;digital simulation;real time systems	This paper provides an overview of SANDS (Specialized Active Networking for Distributed Simulation), a DARPA-ITO sponsored research project that is using active networking to develop a new approach to real-time, content-based information dissemination. Our approach is based on the use of active interest filtering, a publish/subscribe mechanism that uses active networks technology to install and control dynamically-established content-based filters in intermediate active routers in an IP multicast distribution tree. Active filters prune unneeded information as early as possible in the distribution tree, ensuring that only data desired (i.e., subscribed to) by a receiver actually reaches that receiver. In this paper, we describe active interest filtering, the per-node algorithms that implement active filtering, and the signaling protocol that installs interest filter state in the active routers. We describe our prototype implementation effort and present measurements from a working prototype that demonstrate the advantages of active interest filtering in a large-scale ModSAF distributed simulation scenario.	active filter;active networking;algorithm;indium tin oxide;multicast;prototype;publish–subscribe pattern;real-time clock;signaling protocol;simulation	Steve Zabele;M. Dorsch;Zihui Ge;Ping Ji;Mark Keaton;James F. Kurose;Jonathan K. Shapiro;Donald F. Towsley	2002		10.1109/DANCE.2002.1003507	active networking;real-time computing;computer science;distributed computing;computer network	Networks	-9.95720611219061	75.78049876623437	42521
e15fc3e17b8ea22769be615e283ef9884fbbbdf6	gmpls with interlayer control for session-uninterrupted disaster recovery across distributed data centers	distributed data;disaster recovery;data center;process migration;bandwidth on demand	We propose a session-uninterrupted disaster recovery system using a novel session migration technique as a GMPLS application.  Existing disaster recovery systems have a problem of a service interruption. The session migration based on an interlayer  control of GMPLS, VLAN change-over, and process migration, maintains continuous TCP service between a user and a virtualized  server, even when the service migrates from a primary data center to a backup one. We developed a prototype system and showed  that BoD (bandwidth on demand) by GMPLS improved the recovery time from 80.10 sec to 9.85 sec, during transmitting a process  data of 40MByte.  	disaster recovery;generalized multi-protocol label switching	Tetsuo Imai;Soichiro Araki;Tomoyoshi Sugawara;Norihito Fujita;Yoshihiko Suemura	2004		10.1007/0-387-23178-1_20	distributed computing;business;computer security;computer network	ML	-18.335264635899957	79.69926120861696	42524
4fa18e4bc6ff1a7e15aa2941ab1a9cf91574a01a	energy-efficient virtual machine replication for data centers		Virtual Machine (VM) replication is used primarily for achieving fault tolerance and load balancing of requests. We tackle the virtual machine replication problem (VMR) for data centers and take into account reducing the total power consumption. Each VM will be replicated R times on different physical machines (PMs). As such, in case of a server failure, there will be at least another PM that has the requested VM. Solving the VMR problem is equivalent to minimum cost flow problem, that can be solved optimally. After replication of VMs, we turn off the inactive PMs in order to reduce the power consumption even more. We simulate different data center scenarios and analyse how many inactive PMs we have achieved.	algorithm;big data;data center;directshow;fat tree;fault tolerance;file allocation table;flow network;load balancing (computing);machine learning;minimum-cost flow problem;replication (computing);self-replicating machine;self-replication;server (computing);simulation;virtual machine;watts humphrey	Raluca Oncioiu;Florin Pop	2018	2018 17th International Symposium on Parallel and Distributed Computing (ISPDC)	10.1109/ISPDC2018.2018.00026	real-time computing;fault tolerance;efficient energy use;distributed computing;data center;virtual machine;load balancing (computing);electrical efficiency;minimum-cost flow problem;computer science	HPC	-19.934018928525834	62.55501072410088	42621
ab2be2a7d969ed213cbaaf97a63eeb468a0b207a	energy efficient secured cluster based distributed fault diagnosis protocol for iot		The rapid growth of internet and internet services provision offers wide scope to the industries to couple the various network models to design a flexible and simplified communication infrastructure. A significant attention paid towards Internet of things (IoT), from both academics and industries. Connecting and organizing of communication over wireless IoT network models are vulnerable to various security threats, due to the lack of inappropriate security deployment models. In addition to this, these models have not only security issues; they also have many performance issues. This research work deals with an IoT security over WSN model to overcome the security and performance issues by designing a Energy efficient secured cluster based distributed fault diagnosis protocol (EESCFD) Model which combines the self-fault diagnosis routing model using cluster based approach and block cipher to organize a secured data communication and to identify security fault and communication faults to improve communication efficiency. In addition we achieve an energy efficiency by employing concise block cipher which identifies the ideal size of block, size of key, number of rounds to perform the key operations in the cipher.		Tabassum Ara	2018	IJCNIS		software deployment;the internet;cipher;computer network;block cipher;network model;wireless;distributed computing;efficient energy use;computer science;internet of things	HPC	-18.650211102985253	86.77667275272043	42655
75214045fda65a066e5bf70d0d75aed742009e4a	pcapindex: an index for network packet traces with legacy compatibility	network monitoring;network security;satisfiability;large scale;packet indexing;network traffic;indexation	Long-term historical analysis of captured network traffic is a topic of great interest in network monitoring and network security. A critical requirement is the support for fast discovery of packets that satisfy certain criteria within large-scale packet repositories. This work presents the first indexing scheme for network packet traces based on compressed bitmap indexing principles. Our approach supports very fast insertion rates and results in compact index sizes. The proposed indexing methodology builds upon libpcap, the de-facto reference library for accessing packet-trace repositories. Our solution is therefore backward compatible with any solution that uses the original library. We experience impressive speedups on packet-trace search operations: our experiments suggest that the index-enabled libpcap may reduce the packet retrieval time by more than 1100 times.	backward compatibility;bitmap;experiment;hard disk drive;hybrid drive;library;network packet;network security;network traffic control;packet analyzer;tracing (software);winpcap	Francesco Fusco;Xenofontas A. Dimitropoulos;Michail Vlachos;Luca Deri	2012	Computer Communication Review	10.1145/2096149.2096156	traffic generation model;network traffic control;packet analyzer;packet generator;computer science;processing delay;network security;operating system;data mining;database;network simulation;packet forwarding;packet switch;world wide web;computer security;network monitoring;computer network;satisfiability	Metrics	-15.431114010577902	78.00745121041118	42867
49b7c1fbdcd7020f9004f62c66e594a3d45a7d07	gateways and mime security multiparts		"""(IETF), its areas, and its working groups. Note that other groups may also distribute working documents as Internet-Drafts. Internet-Drafts are draft documents valid for a maximum of six months. Internet-Drafts may be updated, replaced, or obsoleted by other documents at any time. It is not appropriate to use Internet-Drafts as reference material or to cite them other than as a """"working draft"""" or """"work in progress"""". To learn the current status of any Internet-Draft, please check the 1id-abstracts.txt listing contained in the Internet-Drafts Shadow Directories on ds.internic.net (US East Coast), nic.nordu.net (Europe), ftp.isi.edu (US West Coast), or munnari.oz.au (Pacific Rim). The current draft of this memo reflects comments received during the last call period. In particular, a reference to RFC 2119 has been added, as have some directives on how to handle character sets with embedded language tagging facilities. 1. Abstract This document examines the problems associated with use of MIME security multiparts and gateways to non-MIME environments. A set of requirements for gateway behavior are defined which provide satisfactory facilities to accomodate the transfer of security multiparts through gateways."""	character encoding;directive (programming);document;embedded system;gateway (telecommunications);pacific rim;requirement	Ned Freed	1999	RFC	10.17487/RFC2480	computer science;internet privacy;world wide web;computer security	Crypto	-26.471105137489907	88.56156016294413	42901
872a70de581c082e134ec508fb8124970584379c	an integrated management framework for virtual machines, switches, and their sdns	computer networks;openflow controller integrated management framework virtual machines switches sdn software defined networks openflow networking network virtualization virtual networking vm kumoi framework;data centers virtual machines openflow sdns resource management;virtual machines;kernel protocols control systems hardware bridges dsl;virtualisation computer networks virtual machines;virtualisation	The paradigm of software-defined networks (SDNs) and one of its enabling technologies, OpenFlow, have been widely welcomed by researchers and practitioners because of their flexibility in networking. Most cloud operators are attracted by the ability to “virtualize” networks at data centers, which is one of the most appealing out of various promising applications. How virtual networking is implemented in SDNs still remains to be solved in future research despite such enthusiasm to achieve virtualization. When researchers are involved in SDN investigations, they soon notice the tediousness of setting up the study environment, which consists of virtual machines (VMs), switches, and SDN controllers. Therefore, they need to spend a great deal of effort and time on non-essential parts of their studies. We present Kumoi in this paper, which is an integrated development framework for VMs, switches, and SDNs. Kumoi enables us to rapidly deploy VMs along with OpenFlow networking. Kumoi is not just an OpenFlow controller, but it also provides the ability to manage VMs in a single environment. We believe Kumoi could accelerate research on VMs and SDNs.	comparison of command shells;data center;network switch;openflow;programming paradigm;software-defined networking;virtual machine;virtualize	Akiyoshi Sugiki	2013	2013 19th IEEE International Conference on Networks (ICON)	10.1109/ICON.2013.6781968	real-time computing;computer science;virtual machine;operating system;distributed computing;computer network	Visualization	-15.87122935904973	84.86804520668197	42908
39d9787a54240b577e2839ea8aa1cff0238afc8d	deadlock-free dynamic network reconfiguration based on close up*/down* graphs	distributed system;interconnection network;computational complexity;virtual channel;network services;dynamic networks	Current high-performance distributed systems use a switch-based interconnection network. After the occurrence of a topological change, a management mechanism must reestablish connectivity between network devices. This mechanism discovers the new topology, calculates a new set of routing paths, and updates the routing tables within the network. The main challenge related to network reconfiguration (the change-over from one routing function to another) is avoiding deadlocks. Former reconfiguration techniques significantly reduce network service. In addition, most recent proposals either need extra network resources (such as virtual channels) or their computation complexities are prohibitive. For up*/down* routed networks we propose a new reconfiguration method that supports a virtually unaffected network service at a minor computational cost. This method is suitable for both source and distributed routing networks, and does neither restrict the injection of packets nor the updating of routing tables during the topology-change assimilation.	deadlock	Antonio Robles-Gómez;Aurelio Bermúdez;Rafael Casado;Åshild Grønstad Solheim	2008		10.1007/978-3-540-85451-7_101	policy-based routing;routing table;routing domain;routing;static routing;parallel computing;real-time computing;intelligent computer network;overlay network;network architecture;hierarchical routing;network management station;bridging;computer science;dynamic source routing;multipath routing;destination-sequenced distance vector routing;network simulation;distributed computing;routing protocol;computational complexity theory;hazy sighted link state routing protocol;geographic routing;algorithm;computer network	Robotics	-8.799645188068732	79.93341742860815	42957
9cef15259b248adf4c4f79ae6933ff55c28a6e22	a delay optimal algorithm to locate and migrate data resources in broadband networks	migration;broadband network;data resources;time delay;atm networks;simulation study;transaction processing;optimal algorithm	The dynamic migration of data resources such as databases and files has become more popular with the advent of broadband networks such as ATM, especially for transaction processing. In a system that uses data resource migration based methods for transaction processing, the data resources are migrated to the transaction initiation site before any operations are performed on them. In such an environment the location of the data resources therefore keeps on changing. Hence some mechanisms are required to first identify the exact locations of the data resources and then migrate them to the transaction initiation site. Such a system operation is referred to as locate and migrate operation and is to be dealt in a manner so that the time delay in locating the data resources is reduced. This in turn reduces the transaction processing time. In this paper, we propose a new algorithm to locate and migrate data resources that focuses on reducing the time delay to locate the migratory data resources. We evaluate the performance of the proposed algorithm and also compare it with one of the existing algorithms by simulation studies under several system parameters such as frequency of request generation, frequency of data resource migration and scale of network. q 2002 Elsevier Science B.V. All rights reserved.	atm turbo;attribute-value system;binary tree;broadcast delay;database;dijkstra's algorithm;electronic case filing system;experiment;simulation;transaction processing;tree network	P. C. Saxena;D. Roy Choudhury;Goldie Gabrani	2003	Computer Communications	10.1016/S0140-3664(02)00110-X	real-time computing;transaction processing;telecommunications;computer science;human migration;database;distributed computing;online transaction processing;computer network;broadband networks	DB	-16.6959026978459	69.13480283890584	42966
ad9b5f5c80bb1995571c4df276e95122d9e84d81	aerial control system for spectrum efficiency in uav-to-cellular communications		The next generation of mobile systems, 5G, will be the communication standard that accommodates the proliferation of the Internet of Things (IoT). Unmanned aerial vehicles (UAVs) are envisioned to support many applications in providing 5G connectivity to the IoT, by extending highspeed connectivity from the sky to objects on the ground, or even by carrying onboard some IoT devices. However, given their critical nature, the management of UAVs induces high exchange of control messages with the ground control station, resulting in the crowded spectrum used by cellular networks. The authors raise the problem of degrading the network spectrum with UAVs' management messages, and discuss the need for an efficient orchestration system. In this article, they propose a novel scheme, dubbed the aerial control system, which is based on separating the data plane from the control plane of UAVs, and pushing the latter to be performed in the air by UAVs. The solution provides an orchestration logic that takes advantage of the autonomous nature of UAVs to organize UAVs in one or several clusters. UAV-to-UAV communication enables spectrum reuse and avoids crowding the network with management messages, while dedicating more 5G spectrum for ensuring more bandwidth to the IoT through UAV-to-infrastructure communication.	aerial photography;autonomous robot;control plane;control system;crowding;forwarding plane;internet of things;next-generation network;unmanned aerial vehicle	Hamed Hellaoui;Bolaji Lilian Ilesanmi-Oyelere;Miloud Bagaa;Tarik Taleb	2018	IEEE Communications Magazine	10.1109/MCOM.2018.1800078	orchestration (computing);computer network;reuse;wireless;distributed computing;ground control station;forwarding plane;computer science;control system;spectral efficiency;cellular network	Mobile	-13.88519679508526	85.45974125590236	42969
4df6cda190e8d2f90e667d6d8a7e99766d0d917b	peer-to-peer vs. the internet: a discussion on the proper and practical location of functionality.	network architecture peer to peer client server nd to end arguments protocol layering policy ussle;resource discovery;004;closed system;group communication;information sharing;client server;low latency;social issues;network architecture;internet application;peer to peer;network computing;support function	Peer-to-peer information sharing has become one of the dominant Internet applications, measured not only in the number of users, but also in the network bandwidth consumed. Thus, it is reasonable to examine the location of support functionality such as self-organisation, resource discovery, multipoint-to-multipoint group communication, forwarding, and routing, to provide the needed service to applications while optimising resource usage in the network. This position paper is intended to stimulate discussion in two related areas: First, where should functionality to support peer-to-peer applications be located: in the network, or as an application overlay among end systems. Second, where can functionality be located, given the practical constraints of the modern Internet including closed systems and middleboxes, as well as administrative, legal, and social issues. We will discuss the performance implications of these decisions, including whether low latency bounds for delay sensitive peer-to-peer applications (such as distributed network computing) can ever be achieved in this environment.	as we may think;border gateway protocol;borůvka's algorithm;cidr;carlson's theorem;closed system;cyberspace;differentiated services;distributed computing;domain name system security extensions;extranet;hypertext transfer protocol;internet;jim gettys;low-energy adaptive clustering hierarchy;middlebox;multipoint ground;network address translation;p (complexity);peer-to-peer;routing;search engine optimization;self-organization	James P. G. Sterbenz	2005			computer science;distributed computing;world wide web;computer network	OS	-15.485333524109869	79.48308817970432	42982
feef50156dd09cb4d2df907f5c8d9b71de8d4782	model-based qos evaluation and validation for embedded wireless sensor networks	databases;analytical models;real life system setup model based qos evaluation embedded wireless sensor network wireless communication technologies cabling cost reduction industrial embedded system technological switch wired interconnection model based system engineering standard network simulation software system operational mode industrial embedded wireless network avionic environment software architectural framework domain specific simulation based tools quality of service throughput reliability energy consumption delay;wireless sensor networks wsns energy consumption modeling quality of service qos simulation validation;wireless sensor networks aircraft communication avionics cost reduction energy consumption on board communications quality of service telecommunication computing;quality of service;wireless sensor networks hardware analytical models data models databases quality of service;wireless sensor networks;data models;hardware	Wireless communication technologies have the potential to significantly reduce cabling cost, cut down on weight, and simplify the overall structure of industrial embedded systems. Potential risks and costs of a technological switch from wired interconnections toward a wireless solution are difficult to estimate, however. Model-based system engineering can help to reduce risk and cost and to increase the quality of the resulting system. However, standard network simulation software has to be adapted to the particular requirements of embedded wireless sensor networks such as system operational modes and phases, comprehensive means of configuration, and performance analysis; and models are not easy to validate in detail. This paper presents a highly scalable model for industrial embedded wireless networks to validate different system configurations and applies it to a system setup designed for avionic environments, using a software architectural framework for domain-specific simulation-based tools. The presented model is detailed enough to cover the significant behavior for quality of service requirements, including delays, throughput, reliability, energy consumption, and node lifetime. An additional important contribution is the direct connection between design tool and test bed or prototype system, allowing a seamless configuration of a hardware setup and an integration of measured behavior for a fine-grained validation of model and prototype. The application to a real-life system setup shows the benefits of the integrated approach.	design tool;embedded system;enterprise architecture framework;non-functional requirement;prototype;quality of service;real life;scalability;seamless3d;simulation software;systems engineering;testbed;throughput	Sven Jäger;Tino Jungebloud;Ralph Maschotta;Armin Zimmermann	2016	IEEE Systems Journal	10.1109/JSYST.2014.2359690	embedded system;data modeling;real-time computing;wireless wan;wireless sensor network;quality of service;wireless site survey;computer science;engineering;operating system;wireless network;key distribution in wireless sensor networks;wi-fi array;fixed wireless;computer network	Embedded	-20.544314031958358	82.63208715953564	43043
a41890192543da3b522b153731600224c57e8c43	a network level power management for home network devices	databases;home computing;energy conservation;power reduction network level power management home network devices energy aware plug and play power control element ubiquitous home environment;plugs;plug and play;telecommunication network management home automation power aware computing power control;epnp technique network level power management home network devices energy aware plug and play power consumption power control elements fine grain power control;digital tv;collaboration;indexing terms;ubiquitous home environment;wireless communication;home network;power aware computing;network interfaces;servers;network servers;epnp technique;logic gates;energy consumption;power system management;power management;power control elements;ubiquitous computing;power reduction;power consumption;power control element;ubiquitous computing energy conservation home computing network servers power control;power demand;energy management home automation power control network servers energy consumption automatic control collaboration power system management communication system control plugs;fine grain power control;wireless sensor networks;iptv;network level power management;home network devices;energy management home automation power system management energy consumption power control network servers plugs collaboration wireless sensor networks digital tv;energy aware plug and play;energy management;home automation;telecommunication network management;power control	This paper proposes a network level power management based on the energy-aware plug and play (EPnP) for home network devices. The power management can reduce the power consumption of devices by reconfiguring power control elements of each device depending on a service collaborating with many devices in the home network. It also can reduce the power consumption of devices without user intervention by the EPnP technique. It can maximize a power reduction by a fine grain power control based on the power control elements that are functional elements of a device which is related with a specific home network service. The proposed power management showed that it was very effective when a service works together with many devices that have multi-function in ubiquitous home environment .	control plane;distributed computing environment;plug and play;power management	Youn-Kwae Jeong;Intark Han;Kwang-Roh Park	2008	IEEE Transactions on Consumer Electronics	10.1109/TCE.2008.4560119	embedded system;home automation;real-time computing;wireless sensor network;index term;energy conservation;logic gate;telecommunications;power control;computer science;engineering;network interface;ubiquitous computing;wireless;server;computer network;energy management;collaboration	Mobile	-18.862762143670892	82.69551041460521	43092
a32a3e93974509cd9af17abcf31a3584bf644e1d	effective processing over continuous data stream	multiple input streams;aqp swto method effective processing continuous data stream multiple input streams continuous queries query execution delays;continuous queries;performance evaluation;query processing;data stream;continuous query;system performance;out of order;effective processing;aqp swto method;waiting time;query processing data handling;continuous data stream;query execution delays;frequency satellite broadcasting out of order delay effects us department of transportation query processing information technology computer science system performance sensor systems;delay time;data handling;stream processing	Due to a late and out-of-order arrival of infinite, unbound and multiple input streams, processing continuous queries over them may lead to producing an inaccurate answer or delaying query execution. Particularly, to minimize this delay time, previous works have used timeout technique without considering the frequency of timeouts. It results in decreasing the accuracy of query execution results since the more the frequency of timeouts, the more the loss of data. We propose a AQP-SWTO method using StB that stores operator's state and a window time-out method based on the waiting time for the next tuple by resetting the size of a queue according to the frequency of timeouts. It reduces a loss rate of data and increases the tuples output-rate. We compare AQP-SWTO method with an existing method and use output-rate and response time as criteria for performance evaluation. As a result of experiment, our proposed method shows an improvement in system performance.	experiment;performance evaluation;response time (technology);set-top box;timeout (computing)	Misook Bae;Jun Park;Buhyun Hwang;Jiseung Nam	2007	7th IEEE International Conference on Computer and Information Technology (CIT 2007)	10.1109/CIT.2007.110	real-time computing;stream processing;computer science;out-of-order execution;group method of data handling;database;distributed computing;computer performance	DB	-14.89778096161788	68.08868361971408	43171
f6c4c51c08adf044934c59722e4480cacc310dc2	management of server farms for performance and profit	profitability	We examine some of the problems associated with managing a server farm, that is, a collection of servers which are used to provide different types of services to paying customers. The users are charged for the services provided, but are also promised that certain Quality-of-Service (QoS) criteria will be met. Failure to satisfy those QoS undertakings incurs pre-specified penalties. In order to maximize the revenue obtained, the service provider must employ intelligent dynamic policies dealing with server allocation and job admission decisions. A number of such policies are surveyed.	heuristic (computer science);job shop scheduling;middleware;prototype;provisioning;quality of service;server (computing);server farm;time complexity;web traffic	Isi Mitrani	2010	Comput. J.	10.1093/comjnl/bxp079	computer science;profitability index	Metrics	-22.266115388498633	63.54158629754558	43245
724e46cb25743ceac2bc0c61e754c7eb1a8eb304	a task scheduling algorithm considering bandwidth competition in cloud computing	scheduling;workflow;cloud computing	Workflow scheduling in the cloud environment is a challenging and urgent to be solve. Existing studies usually only take the computing power and storage capacity scheduling into consideration, but neglect network bandwidth allocation. In this paper, we present a bandwidth-awared schedule algorithm in cloud computing by using simulated annealing based greedy. We compare the time costs of GSA algorithm with dynamic bandwidth changes situation or not. The result proved that our method is more effective than traditional scheduling without considering bandwidth scheduling strategy.	algorithm;cloud computing;scheduling (computing)	Jie Zhang;Xudong Zhu;Bishan Ying	2013		10.1007/978-3-642-41428-2_22	fair-share scheduling;fixed-priority pre-emptive scheduling;parallel computing;real-time computing;earliest deadline first scheduling;flow shop scheduling;dynamic priority scheduling;computer science;rate-monotonic scheduling;two-level scheduling;deadline-monotonic scheduling;distributed computing;scheduling;least slack time scheduling;lottery scheduling;round-robin scheduling	HPC	-18.47713167822403	62.7791289902282	43302
7593589f5ac25982968f746508865382050c144e	performance evaluation of remote display access for mobile cloud computing	mobile cloud computing;energy efficient networking;remote access protocols;cloud gaming;experimental evaluation	Mobile applications are increasingly exploiting cloud computing to overcome the resource limitations of mobile devices. To this end, the most computationally expensive tasks are offloaded to the cloud and the mobile application simply interacts with a remote service through a network connection. One way to establish such a connection is given by remote display access, in which a mobile device just operates as a thin client by relaying the input events to a server and updating the screen based on the content received. In this article, we specifically address remote display access as a means for mobile cloud computing, with focus on its power consumption at mobile devices. Different from most of the existing literature, we take an experimental approach based on real user sessions employing different remote access protocols and types of applications, including gaming. Through several experiments, we characterize the impact of the different protocols and their features on power consumption and network utilization. We conclude our analysis with considerations on usability and user experience. © 2015 Elsevier B.V. All rights reserved.	analysis of algorithms;experiment;mobile app;mobile cloud computing;mobile device;performance evaluation;server (computing);thin client;usability;user experience	Youming Lin;Teemu Kämäräinen;Mario Di Francesco;Antti Ylä-Jääski	2015	Computer Communications	10.1016/j.comcom.2015.05.006	radio access network;mobile search;mobile web;mobile database;computer science;operating system;mobile technology;distributed computing;internet privacy;mobile station;mobile computing;world wide web;computer security;computer network	Mobile	-20.06748267838924	75.47163695569654	43453
c483b07aea42dc47756686341690fd8fb28d434e	optimal load scheduling mechanism and a mobile-to-grid gateway model for e-health service in wireless grid	wireless devices;e health application wireless grid mobile to grid service mobile gateway load scheduling;availability;processor scheduling;mobile to grid service;wireless grid;distributed computing;e health application;load management availability mobile computing grid computing distributed computing processor scheduling mediation electrocardiography carotid arteries system performance;system performance;carotid arteries;mobile gateway;load scheduling;electrocardiography;mediation;carotid artery;grid service;load management;load balance;health services;mobile computing;grid computing	The mission-critical application, in particular e-Health service such as ECG application and Carotid artery application, normally demands the highly sophisticated handling method and reliable processing scheme in wireless Grid environments. Due to the huge amounts of data set from the numerous wireless devices, we propose the refined procedures based on wireless Grid to guarantee the optimal processing time and reliability as prime factor of the system performance by using the proposed scheduling scheme. The simulation results show that proposed load scheduling can support the load balancing and guarantee the high system availability.	grid computing;indivisible;load balancing (computing);mission critical;mobile device;performance evaluation;scheduling (computing);simulation	Youngjoo Han;Chan-Hyun Youn;Tran Minh Trung;Wuon-Shik Kim;Lin Zhang	2006	The Sixth IEEE International Conference on Computer and Information Technology (CIT'06)	10.1109/CIT.2006.134	availability;real-time computing;computer science;load balancing;operating system;distributed computing;mediation;mobile computing;grid computing;computer network	HPC	-22.75026697647099	68.29544554804164	43501
23d54fdb3ebaba85f71373e88e9823f5b28c735e	hdfilter: toward faster bloom filter-based packet forwarding	mathematical model equations memory management optimization educational institutions electronic mail data structures;electronic mail;memory management;data structures;mathematical model;optimization	We propose Bloom filter-based data structure, hdFilter to improve the forwarding performance in Bloom filter-based packet forwarding architecture. hdFilter includes one Bloom filter for corresponding prefixes and one negative Bloom filter for some prefixes that cause the false positive. Through mathematical work and corresponding simulations, we show that hdFilter lowers the false positive rate (that affects the number of accesses to the slow memory) while showing the same fast memory access time or reduces the fast memory access time while showing similar false positive rate compared to normal Bloom filter.	access time;bloom filter;cas latency;data structure;forwarding plane;network packet;simulation	HyunYong Lee;Akihiro Nakao	2014	2014 IEEE Network Operations and Management Symposium (NOMS)	10.1109/NOMS.2014.6838345	real-time computing;data structure;telecommunications;computer science;theoretical computer science;mathematical model;distributed computing;computer network;memory management	Networks	-5.26343754807148	67.15512867855381	43727
cf76898ae6d483242996f952c38b308d0f363309	many-to-one traffic grooming with aggregation in wdm networks	wdm network;heuristic solution;traffic grooming;arbitrary topology;heuristic programming;communication system traffic;dynamic program;dynamic programming style approach;network routing;communication system routing;mixed integer linear solution;optical fibre networks;telecommunication traffic;telecommunication network routing;integer programming;linear programming;dynamic programming style approach wdm network wavelength division multiplexing traffic grooming arbitrary topology mixed integer linear solution network routing heuristic solution;telecommunication traffic intelligent networks wdm networks bandwidth costs bifurcation traffic control wavelength division multiplexing add drop multiplexers network topology;telecommunication network topology;wavelength division multiplexing heuristic programming integer programming linear programming optical fibre networks telecommunication network routing telecommunication network topology telecommunication traffic;optical fiber communication;wavelength division multiplexing	Most of the network applications bandwidth requirements are far less than the bandwidth offered by a full wavelength in WDM networks. Hence, traffic grooming is needed to make efficient use of the available resources. In this paper we address the grooming of many-to-one traffic demands in WDM networks on arbitrary topologies. Traffic streams from different sources, but part of the same session and thus terminating at the same destination, can be aggregated using arbitrary, but application dependent, aggregation ratios. We provide optimal as well as heuristic solutions to the problem. The objective is to minimize the cost of the network, by minimizing the total number of the higher layer components and the total number of the wavelengths used in the network. One of the main contributions of this work is to provide a mixed integer linear solution, to an otherwise non-linear problem, by exploiting the specifics of routing and aggregation sub-problems, while still maintaining the optimality of the solution. The formulation is generic and can handle varying amounts of traffic from each source to a common destination, as well as arbitrary aggregation fractions of the data coming from the different sources. This fraction is made to be a function of the number of the streams participating in the aggregation. For the heuristic solution we developed a Dynamic Programming style approach that builds the solution progressively, going through a number of stages, while choosing the best partial solutions among a number of possible partial solutions at each stage	dynamic programming;heuristic;linear programming;newman's lemma;nonlinear system;one-to-many (data model);programming style;requirement;routing;traffic exchange;wavelength-division multiplexing	Raza Ul-Mustafa;Ahmed E. Kamal	2006	IEEE Journal on Selected Areas in Communications	10.1109/JSAC.2006.1677255	routing;integer programming;traffic grooming;telecommunications;computer science;linear programming;distributed computing;wavelength-division multiplexing;computer network	Metrics	-5.224580437094187	83.17541236172694	43731
9d9764f1a8f805c52f354dbdbc7bcbb1e02e6779	task matching and scheduling by using self-adjusted genetic algorithms	genetic operator;instruments;task matching;processor scheduling;task scheduling genetic algorithm grid computing;resource management;distributed computing;scheduling algorithm;computational modeling;genetic algorithm;genetic algorithms;fitness function task matching task scheduling self adjusted genetic algorithm grid computing;genetic mutations;computer science;task scheduling;genetic algorithms grid computing processor scheduling distributed computing computer science computational modeling resource management scheduling algorithm genetic mutations instruments;grid computing;self adjusted genetic algorithm;grid computing genetic algorithms;fitness function	Grid computing is a new computing-framework to meet the growing computational demands. Grid computing provides mechanisms for sharing and accessing large and heterogeneous collections of remote resources. However, how to scheduling the subtasks in these heterogeneous resources is a critical problem. This paper puts forward a task scheduling algorithm based on genetic algorithm. It first generates a fitness function through weighted least connection algorithm, and than generates a new group of individuals through genetic operation such as reproduction, crossover, mutation, etc. It approaches optimization gradually through frequent evolutions. Finally, the simulation results of the algorithm and conclusion are given	fitness function;genetic algorithm;grid computing;mathematical optimization;schedule (project management);scheduling (computing);simulation	Changwu Zhu;Shangping Dai;Zhi Liu	2006	2006 5th IEEE International Conference on Cognitive Informatics	10.1109/COGINF.2006.365613	fair-share scheduling;parallel computing;dynamic priority scheduling;computer science;theoretical computer science;genetic algorithm scheduling;distributed computing	HPC	-17.049937402650762	62.83452084939298	43769
c8b65996d5f796f9078fa228714b4c860ab8640f	a two-layer cache replication scheme for dense mobile ad hoc networks	manets replication data accessibility caching;overhead traffic two layer cache replication scheme dense mobile ad hoc network data replication scheme cooperative data caching architecture manet query directory caching node cost minimization model;telecommunication traffic cache storage cost reduction mobile ad hoc networks	This paper proposes a data replication scheme implemented on top of a cooperative data caching architecture in MANETs that caches submitted queries in special nodes, called query directories (QDs), and uses them to locate data (responses) stored in the nodes that requested them, and called caching nodes (CNs). The QD entries are replicated according to a cost minimization model, and the actual data items are placed in nearby CNs. The proposed system is dynamic, as it adapts to topology changes and relocates replicas as necessary. The preliminary prototype of the proposed method is simulated using ns2 to assess its performance experimentally. Enhancements in performance in terms of lowered access delay and improved hit rates are reported, while maintaining a cap on overhead traffic.	cache (computing);data item;directory (computing);experiment;hoc (programming language);overhead (computing);prototype;quantum dot;replication (computing);simulation	Kassem Fawaz;Hassan Artail	2012	2012 IEEE Global Communications Conference (GLOBECOM)	10.1109/GLOCOM.2012.6503156	false sharing;computer science;database;distributed computing;computer network	Mobile	-15.588080263000242	68.98928198359894	43808
fda24067b737f38f2c7116ff95f92104585bd372	an improved design and implementation of layer 4 network load balancing switch	internet layer 4 network load balancing switch implementation operating principle analysis testing software programming;servers ip networks switches load management clustering algorithms testing software;telecommunication switching internet resource allocation	Based on the analysis of the existing problems of several typical network load balancing technology and conventional layer 4 load balancing switches, a new implementation of load balancing system for layer 4 switches is proposed. The analysis of operating principle with the novel load balancing system is provided in this paper. To illustrate the proposed the new design, a testing software is programmed to evaluate the system performance. The simulation results show the effectiveness of the proposed new layer 4 network load balancing switches.	associative entity;central processing unit;checksum;load balancing (computing);multilayer switch;network load balancing;network address translation;network switch;simulation;systems architecture	Chifu Yao;Xuemin Chen	2016	2016 IEEE 13th International Conference on Networking, Sensing, and Control (ICNSC)	10.1109/ICNSC.2016.7479006	network load balancing;round-robin dns;network load balancing services;real-time computing;multilayer switch;computer science;load balancing;channel bonding;distributed computing;computer network	Embedded	-17.103007635318665	80.62048877172522	43899
bac9387bf9806797c573a81270d8d0cfab56abaa	qos-constraint configuration management policy in grid over gmpls networks	policy enforcement;resource management quality of service computer architecture costs environmental management grid computing engineering management throughput technology management quality management;generalized multi protocol label switching;resource manager;resource management;network performance;low complexity;technology management;computer architecture;engineering management;grid service;quality of service;high throughput;environmental management;grid computing;high performance;configuration management;quality management;throughput	In Grid service, resource management is important to support capability for good quality and efficiency for the computing and storage service. In order to provide this resource management which has low complexity, high performance and high throughput with guaranteeing QoS, the well defined network resource management architecture and scheme have to be considered. Thus, we propose the integrated grid resource management architecture based on QoSconstraint policy and we derive cost-sensitivity policy enforcement procedure which can be applied to this architecture in Grid over GMPLS (Generalize Multi- Protocol Label Switch) network. Finally, the results show that the proposed scheme outperforms the conventional scheme in the network performance such as a blocking rate of resource request messages and the operation cost.	algorithm;analysis of algorithms;blocking (computing);configuration management;generalized multi-protocol label switching;network performance;quality of service;run time (program lifecycle phase);service-level agreement;throughput;whole earth 'lectronic link	Hyewon Song;Chan-Hyun Youn;Dong Su Nam;Gwang-Ja Jin;Sangjin Jeong	2006	The Sixth IEEE International Conference on Computer and Information Technology (CIT'06)	10.1109/CIT.2006.156	high-throughput screening;throughput;quality of service;computer science;resource management;database;distributed computing;configuration management;network performance;grid computing;computer network	HPC	-7.315146286572354	83.29308697508657	43936
5cffa8f339b31eaf6073126d1e8b24072986d809	a self-adaptable agent system for efficient information gathering	estensibilidad;extraction information;distributed system;systeme autoregulation;evaluation performance;multiagent system;systeme reparti;procesamiento informacion;agent mobile;performance evaluation;ucl;information extraction;evaluacion prestacion;localization;agente movil;reseau ordinateur;self adjusting systems;discovery;theses;conference proceedings;localizacion;systeme autoreglable;computer network;information gathering;monitoring system;digital web resources;sistema repartido;localisation;ucl discovery;open access;information processing;red ordenador;agent systems;ucl library;extensibilite;scalability;book chapters;open access repository;mobile agent;traitement information;sistema multiagente;sistema autoregulacion;systeme multiagent;ucl research;extraction informacion	As networks become all-pervasive the importance of efficient information gathering for purposes such as monitoring, fault diagnosis, and performance evaluation can only increase. Extracting information out of largescale, dynamic networked systems is becoming increasingly difficult. Distributed monitoring systems based on static object technologies such as CORBA and Java-RMI can cope with scalability problems only to a limited extent. They are not well suited to monitoring systems that are both very large and highly dynamic because the monitoring logic, although distributed, is statically pre-determined at design time. The paper presents an active distributed monitoring system based on mobile agents. Agents act as area managers which are not bound to any particular network node and can sense the network, estimate better locations, and migrate in order to pursue location optimality. Simulations demonstrate the capability of this approach to cope with large-scale systems and changing network conditions. The limitations of our approach are also discussed in comparison to more conventional monitoring systems.	common object request broker architecture;computer simulation;java remote method invocation;mobile agent;performance evaluation;pervasive informatics;scalability	Antonio Liotta;George Pavlou;Graham Knight	2001		10.1007/3-540-44651-6_14	scalability;simulation;internationalization and localization;information processing;computer science;artificial intelligence;operating system;mobile agent;database;distributed computing;operations research;computer security;information extraction	ML	-10.946422216899503	69.43103132802398	43954
1f6558642e6e963e1d3d3efd6d152964d139c2c8	diverse routing in networks with probabilistic failures	optimal solution;disjoint path protection;integer nonlinear program;routing protection optical fiber communication emp radiation effects optical fiber networks communication networks optical fiber cables satellites communications society isolation technology;non linear programming;probabilistic shared risk link group;approximation algorithms;integer nonlinear program diverse network routing probabilistic failures disjoint path protection natural disasters intentional attacks probabilistic shared risk link group;telecommunication network routing integer programming;joints;data mining;natural disasters;reliable communication;telecommunication network routing;integer programming;community networks;heuristic algorithms;link failure;natural disaster;intentional attacks;diverse network routing;correlation;probabilistic logic;optical fiber;failure probability;shared risk link group;probabilistic failures;disjoint paths	We develop diverse routing schemes for dealing with multiple, possibly correlated, failures. While disjoint path protection can effectively deal with isolated single link failures, recovering from multiple failures is not guaranteed. In particular, events such as natural disasters or intentional attacks can lead to multiple correlated failures, for which recovery mechanisms are not well understood. We take a probabilistic view of network failures where multiple failure events can occur simultaneously, and develop algorithms for finding diverse routes with minimum joint failure probability. Moreover, we develop a novel Probabilistic Shared Risk Link Group (PSRLG) framework for modeling correlated failures. In this context, we formulate the problem of finding two paths with minimum joint failure probability as an integer nonlinear program (INLP) and develop approximations and linear relaxations that can find nearly optimal solutions in most cases.	algorithm;approximation;nonlinear programming;nonlinear system;path protection;routing	Hyang-Won Lee;Eytan Modiano	2009	IEEE/ACM Transactions on Networking	10.1109/INFCOM.2009.5062015	routing;integer programming;natural disaster;computer science;theoretical computer science;multipath routing;distributed computing;computer network	Networks	-6.018431709208488	81.49461823941425	44028
98f743960775f25790b469a8fa0f058233d6a2e0	an efficient caching algorithm for peer-to-peer 3d streaming in distributed virtual environments	caching;distributed virtual environment;3d streaming;peer to peer	Recent technical progress on the Internet and virtual reality has enabled the proliferation of the applications of distributed virtual environments (DVEs). In a DVE, high-resolution 3D contents may generate huge data while peer-to-peer (P2P) streaming takes advantages to carry these huge traffic in a cost-effective manner. In this P2P paradigm, peers can cache and share DVE data cooperatively to reduce server workload and improve streaming quality. Nevertheless, it is critical to maintain and update the cached contents in each peer efficiently. In this paper, we propose an efficient caching algorithm for a P2P 3D content streaming framework. The proposed caching algorithm is based on a new preservation metric that is defined for balancing visual saliency, reusability and potential relevance of cached 3D objects. Then, these cached 3D objects in each peer are updated adaptively with the ascendant order in importance quantified using this new metric. We implemented the proposed caching algorithm in a simulated DVE platform for P2P-based 3D streaming. We conducted a comprehensive simulation study and our experimental results demonstrate that the proposed peer-to-peer streaming method outperforms the classic 3D streaming methods (including FLoD and MRM) in terms of fill ratio, base latency, requests by nodes and requests to the server.	algorithm;peer-to-peer;virtual reality	Jinyuan Jia;Wei Wang;Xiaojun Hei	2014	J. Network and Computer Applications	10.1016/j.jnca.2014.03.005	real-time computing;computer science;operating system;distributed computing;world wide web;computer network	HPC	-16.910931639463254	74.51906961029992	44032
a0a9beae92ddef1074fa3874c0b4797ed739d593	dns-enhanced web for faster content delivery	content distribution network;performance evaluation;content delivery;performance analysis;patching;peer to peer networks;trace driven simulation;video on demand service	With a key component of latency on the Web being connection set up between clients and Web servers, several ways to avoid connections have been explored. While the work in recent years on Content Distribution Networks (CDNs) have moved some content 'closer' to users at the cost of increasing DNS traffic, they have not fully exploited the available unused potential of existing protocols. We explore ways by which a variety of Web responses can be piggybacked on DNS messages. While we evaluated our idea in the Web context, the approach is generic and not restricted to Web responses. We propose an architecture for HTTP piggybacking in DNS messages and carry out a detailed performance analysis based on a trace-driven simulation study. Our architecture requires minimal extensions to existing protocols, utilizing only the allowed optional fields for these extensions. It is fully compatible and can coexist with the current Web.	coexist (image);content delivery network;digital distribution;hypertext transfer protocol;piggybacking (security);simulation;web server;world wide web	Balachander Krishnamurthy;Richard Liston;Michael Rabinovich	2003		10.1145/775152.775196	web service;web analytics;computer science;database;multimedia;internet privacy;world wide web	Web+IR	-15.688988490905482	75.96561133031135	44065
ba774c18fc99deec35c6e6eaed0d530e18116071	online scheduling switch for maintaining data freshness in flexible real-time systems	database system;protocols;switches real time systems processor scheduling usa councils algorithm design and analysis database systems scheduling algorithm runtime degradation costs;runtime processor workload;database management systems;processor scheduling;real time;online scheduling;runtime processor workload online scheduling switch data freshness maintenance flexible real time database system mode changes periodic scheduling policies update workload temporal validity search based switch adjustment based switch;scattering;real time data;mode changes;online scheduling switch;data freshness maintenance;time factors;real time systems data handling database management systems processor scheduling;schedules;flexible real time database system;adjustment based switch;update workload;search based switch;data handling;switches;periodic scheduling policies;real time systems;temporal validity	Maintaining the temporal validity of real-time data is one of the crucial issues in a real-time database system. Past studies focus on designing algorithms to minimize imposed workload by a fixed set of update transactions while maintaining data freshness within validity intervals. In this paper we revisit this problem by investigating the cost of data freshness maintenance and online scheduling overhead in the presence of mode changes in real-time systems. We propose to apply periodic scheduling policies when the imposed update workload is low to maintain high data freshness. When the update workload becomes high, we propose to switch to more sophisticated algorithms to improve schedulability. In the latter case, not only each scheduling policy must be able to schedule the task set in the corresponding mode, temporal validity must also be maintained during the mode changes. To address this problem, two algorithms, named search-based switch (SBS) and adjustment-based switch (ABS) are proposed to search for the proper switch point online. SBS checks the temporal validity at the beginning time slot of each idle period while ABS further relaxes this restriction through schedule adjustment. Our experimental results demonstrate the correctness and efficiency of these two algorithms. Our results also show that scheduling switch according to the runtime processor workload can significantly outperform a single fixed scheduling policy in terms of data freshness while incurring only limited online switch overhead.	algorithm;bundle adjustment;correctness (computer science);database;overhead (computing);real-time clock;real-time computing;real-time data;real-time operating system;real-time transcription;replay attack;scheduling (computing);smart battery system	Song Han;Deji Chen;Ming Xiong;Aloysius K. Mok	2009	2009 30th IEEE Real-Time Systems Symposium	10.1109/RTSS.2009.36	embedded system;communications protocol;real-time data;parallel computing;real-time computing;network switch;schedule;computer science;operating system;group method of data handling;distributed computing;scattering	Embedded	-14.905624704582003	67.81406067005607	44074
77e2818c62c003f7447fa619a5f46c3019b5b8ed	index distribution in a group-based resource sharing application	groupware;bloom filter;routing;resource allocation;index distribution;group based sharing;resource allocation groupware mobile computing;bloom filters;bloom filters index distribution group based resource sharing application mobile network mobile environment;social network;indexes;distance measurement;mobile environment;group based resource sharing application;social networks index distribution peer to peer group based sharing;social networks;indexation;resource sharing;mobile communication;media streaming;matched filters;floods;peer to peer computing;mobile computing;peer to peer;resource management peer to peer computing social network services application software collaboration streaming media bandwidth video sharing internet laboratories;mobile network	This paper presents an application for locating resources, such as files or media streams, shared by users of a mobile network. The application is fully distributed without centralized components in the fixed network. The paper proposes a simple method to define groups using local information about each userpsilas social contacts. The groups are used in combination with user-defined policies to control the distribution of shared resources. The paper further provides an evaluation whether an index-driven approach is feasible for the given purpose. The approach aims to minimize traffic, which is particularly important in the mobile environment. To achieve this, a unique method is proposed for efficiently distributing the index by replacing flooding with direct updates. Bloom filters are used to compress the index in order to reduce the bandwidth and storage space. The solutions are evaluated analytically and compared using simulation.	bsd;bandwidth (signal processing);bloom filter;centralized computing;computer file;network traffic control;server (computing);simulation;social network	Nicklas Beijar	2007	2007 International Conference on Collaborative Computing: Networking, Applications and Worksharing (CollaborateCom 2007)	10.1109/COLCOM.2007.4553854	computer science;bloom filter;operating system;database;distributed computing;mobile computing;world wide web;computer network;social network	HPC	-13.694877937641397	73.21387589827481	44084
4a3ab9bbd5b59fa0aafe2f57878c70d26399b9f5	content delivery networks in the cloud with distributed edge servers	outsourcing;sockets;media;servers;time factors;content distribution networks;static var compensators;performance cdns content distribution content networks design;servers media static var compensators time factors outsourcing sockets content distribution networks	Media traffic has become the major traffic of the Internet and will keep on increasing. Numerous storage services, media applications and devices have emerged to provide Internet enabled content storage and delivery capabilities. Content Delivery Networks (CDN) based on cloud storage, adopting distributed storage technology in the edge servers, enable efficient data storage and retrieval system that reduce storage cost and provide effective resource utilization. However, current CDNs based on cloud storage, do not utilize distributed storage on edge servers, with each edge server having a complete copy of the content files to be served. In this paper we propose to implement co-operative push based content outsourcing mechanism in CDN. This solution will split the media content (video file) from the cloud onto multiple edge servers and study its performance gain in CDN arena.	cloud storage;clustered file system;computer data storage;content delivery network;digital video;internet;multiple edges;outsourcing;server (computing);testbed;web server	Parag Panchal;Nikhil Meenakshaiah Ramaswamy;Xiao Su;Yi Dong	2013	2013 IEEE 10th International Conference on High Performance Computing and Communications & 2013 IEEE International Conference on Embedded and Ubiquitous Computing	10.1109/HPCC.and.EUC.2013.81	real-time computing;media;computer science;operating system;world wide web;computer security;server;outsourcing;computer network	HPC	-16.80234950917238	74.23016720404532	44150
35f3b895897522ad52fcc9a6cb997837b18e99f1	treep: a self-reconfigurable topology for unstructured p2p systems	p2p system;distributed computing;p2p;age distribution;network topology;load balance;grid computing	We present an efficient and robust network topology for managing distributed resources in P2P-Grid environments. This topology is called TreeP and exploits both features of P2P and grid computing models. It uses P2P properties in looking for available resources, while using Grid properties to implement communications and computations on a distributed computing platform. Here, we present how this architecture is distributively built and maintained, the related properties and our first experimental results. We show that this topology is very scalable, robust, load-balanced, and easy to construct and maintain.	computation;data mining;distributed algorithm;distributed computing;grid computing;load balancing (computing);mathematical model;network topology;peer-to-peer;robustness (computer science);routing table;scalability;self-reconfiguring modular robot;software deployment	Euloge Edi;M. Tahar Kechadi;Ronan McNulty	2006		10.1007/978-3-540-75755-9_131	real-time computing;population pyramid;computer science;load balancing;theoretical computer science;peer-to-peer;distributed computing;utility computing;network topology;grid computing;logical topology	HPC	-12.295841322777324	72.62528410877951	44160
014401960e76fe78ee3f82ad03f4a969231b2787	backlog aware low complexity schedulers for input queued packet switches	packet switching;queueing theory;backlog aware low complexity schedulers;input queued packet switches;maximum weight matching scheduler;wrapped wavefront arbiter	We study the problem of packet scheduling in input queued packet switches, with an emphasis on low complexity and ease of implementation. Toward this end, we propose a class of subset based schedulers, wherein an N x N switch is operated using only a small set of N configurations in every time-slot. We show that the performance of subset based scheduling is comparable to that of the benchmark maximum weight matching (MWM) scheduler, albeit at much lower complexity. Next, we relate subset based scheduling to the well known wrapped wavefront arbiter (WWFA) [14] and propose BA-WWFA, a backlog aware version of WWFA. The BA-WWFA scheduler significantly enhances the performance of WWFA, while retaining its ease of hardware implementation. The performance gains are especially noteworthy under non-uniform loading of the switch. Given their ease of implementation and MWM like performance, the schedulers proposed in this paper represent an attractive option for high performance packet switching.	alias systems corporation;arbiter (electronics);benchmark (computing);business architecture;matching (graph theory);motif window manager;network packet;network switch;packet switching;scheduling (computing);web traffic;whole earth 'lectronic link	Aditya Dua;Nicholas Bambos;Wladek Olesinski;Hans Eberle;Nils Gura	2007	15th Annual IEEE Symposium on High-Performance Interconnects (HOTI 2007)	10.1109/HOTI.2007.4	real-time computing;computer science;distributed computing;queueing theory;packet switching;computer network	Embedded	-4.875307030155716	64.18892002792347	44163
ccb544909c67b7fceadbfa0c1386935437c09318	comparison of request admission based performance isolation approaches in multi-tenant saas applications	isolation;performance;multi tenancy;qos;saas	In the Software-as-a-Service model one single application instance is usually shared between different tenants to decrease operational costs. However, sharing at this level may lead to undesired influence from one tenant onto the performance observed by the others. Intentionally, the application does not manage hardware resources and the responsible OS is not aware of application level entities like tenants. Consequently, it is difficult to control the performance of individual tenants to make sure they are isolated. In this paper we present an overview and classification of methods to ensure performance isolation based on request admission control. Further, informational requirements of these methods are discussed.	discrepancy function;entity;multitenancy;operating system;performance prediction;requirement;run time (program lifecycle phase);software as a service	Rouven Krebs;Manuel Loesch	2014		10.5220/0004948804330438	real-time computing;isolation;quality of service;performance;computer science;multitenancy;software as a service;computer security	HPC	-23.653724634145025	60.61125551415472	44172
b8ceec3258c6bce09097d4c30b8b6b8444cc194c	swicom: an sdr-based wireless communication gateway for vehicles	performance measure;software;metodo caso peor;traitement signal;radio logicial;evaluation performance;telematics;wireless communication gateway;adaptability;adaptabilite;wireless communication gateway embedded software platform software defined radio sdr;wireless communication connectivity;wireless communication protocols;performance evaluation;protocole transmission;clientela;automovil;execution time;logiciel;in car infotainment;securite;software prototyping;telecommunication sans fil;software defined radio;flexibilidad;sdr based wireless communication gateway;wireless communication systems;implementation;data flow graphs;evaluacion prestacion;wireless application protocol;telematique;run time performance;gateway device;synchronous data flow graphs;analyse temporelle;wireless hardware devices;wireless services;synchronous data flow;analisis temporal;software defined radio sdr;adaptabilidad;software performance;time analysis;software radio;graphe flux donnee;embedded software platform;wireless communication;prototipo;protocolo transmision;worst case execution time;radio logicielle;automobile;internetworking telecommunication;telematica;telecomunicacion sin hilo;signal processing;sdr technology;generic hardware platform;motor car;safety applications;safety;clientele;methode cas pire;vehicle to vehicle communications;internetworking;conexidad;logicial;temps execution;hardware dependency;vehicles internetworking software radio;information gateway;flexibilite;wireless communication vehicles hardware wireless application protocol telematics safety costs software performance signal processing software prototyping;worst case execution time analysis;vehicles;computer hardware;connexite;tiempo ejecucion;implementacion;connectedness	A wide range of emerging and promising wireless communication protocols are rapidly being introduced into vehicles. They are commonly used for in-car infotainment, telematics, and safety applications. However, adopting new wireless communications into vehicles requires them to be equipped with the corresponding hardware devices. This hardware dependency incurs extra costs to customers to deploy and maintain wireless services in vehicles. To alleviate this problem, this paper proposes a novel wireless communication gateway for vehicles that is called the software-defined radio (SDR)-based wireless communication gateway (SWICOM). It exploits the SDR technology that uses software running on a generic hardware platform to perform signal processing instead of dedicated hardware. The SWICOM can thus integrate multiple wireless hardware devices into a single generic wireless gateway device, which improves flexibility, adaptability, and connectivity of wireless communications. We built its prototype implementation and performed measurements to quantify its run-time performance. The worst-case execution time (WCET) analysis is also given using synchronous data flow (SDF) graphs. All entire results clearly show the viability of the SWICOM.	best, worst and average case;dataflow;etsi satellite digital radio;prototype;run time (program lifecycle phase);signal processing;synchronous data flow;telematics;wireless gateway;worst-case execution time	Boncheol Gu;Jinman Jung;Kyongdong Kim;Junyoung Heo;Nam-Hoon Park;Gwangil Jeon;Yookun Cho	2010	IEEE Transactions on Vehicular Technology	10.1109/TVT.2009.2040004	embedded system;real-time computing;wireless site survey;telecommunications;computer science;engineering;signal processing;software-defined radio;key distribution in wireless sensor networks;municipal wireless network;wi-fi array;fixed wireless;computer network	Mobile	-6.527905149708804	73.65633617082351	44198
bdd1ba470a199fe00731cedbce6cf45242652979	energy saving and maximize utilization cloud resources allocation via online multi-dimensional vector bin packing		In data center, which use virtualization technology and provide virtual machines (VMs) for their customers, they often receive the VMs renting request with determined multiple resource demanded which tends to arrive at an arbitrary time. Resource allocation strategies become one of considerable problem as they can affect the energy efficiency and resource utilization significantly. In this paper, we explore the resource allocation strategies which can minimize the number of used servers, in order to save the energy and maximize the resources utilization. We model this problem as the Vector Bin Packing Problem (VBPP) which is a variant of classic bin packing, proposed Multi-Dimensional Cloud Resource Dynamic Allocation Model(MDCRA) based on VBPP. Since most of existed algorithms aim to solve offline VBPP. We generalized those algorithms to online and proposed Single Weight and Double Weight family online algorithms based on the offline work. Through both rigorous theoretical analyses and extensive simulations, we demonstrate that the proposed allocation strategies achieve energy saving and utilization maximization.	bin packing problem;data center;entropy maximization;memory management;online algorithm;online and offline;set packing;simulation;virtual machine;x86 virtualization	Liang Guo;Pu Du;Abdul Razaque;Muder Almiani;Amer Al-Rahayfeh	2018	2018 Fifth International Conference on Software Defined Systems (SDS)	10.1109/SDS.2018.8370438	online algorithm;resource management;cloud computing;dynamic priority scheduling;virtual machine;resource allocation;server;computer science;bin packing problem;distributed computing	Embedded	-19.36178483434202	62.955686435869374	44214
648d34a7f5549175fb246a52fe7608599959ac45	toward the rapid network-wide deployment of new application specific protocols using application level active networking			active networking;software deployment	Atanu Ghosh	2002				Networks	-17.227979640729817	85.44295181426216	44295
4174926497848e40ba53be63af8c0b2dc7bd0946	seventh heaven: anatomy of a url (and other internet-scale namespaces, part 1)	information resources;internet;anatomy uniform resource locators internet web pages fires information resources writing law legal factors search engines;uniform resource locator;information resources internet;http messages url internet scale namespace uniform resource locator domain names ip address mac address phone numbers path names	The author discusses the anatomy of a URL (Uniform Resource Locator). He considers domain names, IP addresses, MAC addresses, phone numbers, path names and names in HTTP messages.	computational anatomy;namespaces	Rohit Khare	1999	IEEE Internet Computing	10.1109/4236.793464	uniform resource locator;percent-encoding;the internet;locator/identifier separation protocol;computer science;persistent uniform resource locator;database;internet privacy;law;world wide web;computer security;computer network	Vision	-26.010609819653485	87.80943451848128	44383
7d5563bb3806bb70e09153b8ebcd6bd7866ba770	energy efficient content delivery in service provider networks with content caching	google;video on demand integer programming internet linear programming quality of service;peer to peer computing energy consumption optimization conferences internet google heuristic algorithms;internet;energy consumption;heuristic algorithms;quality of service delivery energy efficient content delivery service provider networks content caching video on demand content delivery internet service provider over the top content catalog ott content catalog integer linear program isp content network peering points peering node vod services energy consumption reduction network congestion;optimization;peer to peer computing;conferences	We study the impact of video on demand content delivery on service provider networks focusing on the interplay between Internet service provider (ISP) owned and over-the-top (OTT) content catalogs. We utilize an Integer Linear Program to show that the delivery of OTT content consumes significantly more energy than ISP content, which can be cached freely in the network. Retrieving OTT content from designated network peering points increases congestion in links surrounding the peering node. We demonstrate how ISPs offering competing VoD services can reduce energy consumption as well as network congestion and improve the quality of service delivery. Finally, we show how a caching arrangement between the ISP and OTT provider that allows the ISP to cache OTT content can also address these concerns.	cache (computing);digital distribution;itil;linear programming;network congestion;over-the-top content;peering;quality of service	Nadeem Abji;Ali Tizghadam;Alberto Leon-Garcia	2015	2015 IEEE Online Conference on Green Communications (OnlineGreenComm)	10.1109/OnlineGreenCom.2015.7387374	internet transit;business;internet privacy;world wide web;internet exchange point;computer network	Networks	-16.336194687515594	75.30668427326222	44394
47f0f870f83f846f6793369dd6eae0e0e47f2d11	initial hypertext transfer protocol (http) method registrations		This document registers those Hypertext Transfer Protocol (HTTP)nmethods that have been defined in RFCs before the IANA HTTP MethodnRegistry was established.	hypertext transfer protocol	Julian F. Reschke	2014	RFC	10.17487/RFC7237	computer science;database;internet privacy;world wide web	Vision	-25.900987073838436	87.85728738340508	44417
608550973581d61fd04ea624904a526548896185	fluctuations and lasting trends of qos on intercontinental links		The paper presents an analysis of shortand long-term changes in the QoS of intercontinental connections. First we will show that despite fast and numerous advances in physical layer, link layer, router capacity and new telecommunication cables deployment, QoS measures are hardly progressing in long-term (years) perspective. Transatlantic (North America – Europe) connections will be thoroughly analyzed. Next we will show that due to submarine cable breakages temporary network performance is unpredictable. It may be much poorer than average and sometimes drops below the acceptable level – case study is provided. Even if the links are fully operational, due to the rerouting the QoS may deteriorate in the case of cable fault in another part of the World. The research is based mainly on data taken from IEPM (Internet End-to-end Performance Measurement) database.	cable modem;network performance;quality of service;router (computing);software deployment	Tomasz Bilski	2009		10.1007/978-3-642-10625-5_16	the internet;software deployment;quality of service;performance measurement;router;computer network;physical layer;business;link layer;network performance	Metrics	-10.289204553115498	86.74360542606958	44464
8d586bd0bb267d642513e7ec8106d79c3f25e8cb	novel efficient particle swarm optimization algorithms for solving qos-demanded bag-of-tasks scheduling problems with profit maximization on hybrid clouds		School of Computer Science and Engineering, Nanjing University of Science and Technology, No. 200 Xiaolingwei Street Nanjing 210094, China Correspondence Yi Zhang, School of Computer Science and Engineering, Nanjing University of Science and Technology, No. 200 Xiaolingwei Street, Nanjing 210094, China. Email: yzhang@njust.edu.cn Funding information National Natural Science Foundation of China, Grant/Award Number: 71501096 and 61502234; Natural Science Foundation of Jiangsu Province, Grant/Award Number: BK20150785; China Postdoctoral Science Foundation, Grant/Award Number: 2015M581801; Fundamental Research Funds for the Central Universities, Grant/Award Number: 30916011325 Summary Users are willing to execute bag-of-task applications consisting of multiple tasks on clouds, since cloud resources are delivered in a pay-as-you-go manner. Given multiple bag-of-task applications to be executed with user-specified quality-of-service demands, a cloud provider has to outsource some tasks to public clouds when its private cloud has insufficient resources to afford all applications' tasks. The key issue is how to schedule tasks on hybrid clouds (environments consisting of a private cloud and multiple public clouds) for maximizing the cloud provider's profit while meeting the quality-of-service demands. To solve this problem, we propose an efficient particle swarm optimization algorithm (EPSO) and three hybrid ones (HEPSO1-HEPSO3), in which task sequences are considered as solutions. A mapping operator (BBMO) is developed to map particles to solutions and a quick task dispatching method containing an acceleration method is designed to calculate solutions' objectives. Experimental results show that EPSO not only outperforms an existing PSO (the best algorithm for solving a problem that is a special case of ours) significantly but also achieves a 11.48x speedup. The HEPSO1 to HEPSO3 outperform EPSO. The BBMO outperforms the well-known ranked-order value rule and achieves a 5.47x speedup. The acceleration method in quick task dispatching brings a 2.69x speedup.	baseline (configuration management);cloud computing;computer science;data-intensive computing;email;expectation–maximization algorithm;experiment;incremental funding methodology;mathematical optimization;np-completeness;outsourcing;paging;particle swarm optimization;quality of service;scheduling (computing);simulation;speedup;system global area;whole earth 'lectronic link;psos	Yi Zhang;Jin Sun	2017	Concurrency and Computation: Practice and Experience	10.1002/cpe.4249	parallel computing;computer science;distributed computing;quality of service;operator (computer programming);cloud computing;scheduling (computing);real-time computing;special case;algorithm;profit maximization;speedup;particle swarm optimization	AI	-18.639017292475216	63.624352145245574	44499
13241e0cd0a679e6609b375130cce542afbeb693	japanese character encoding for internet messages		"""Status of this Memo This memo provides information for the Internet community. It does not specify an Internet standard. Distribution of this memo is unlimited. Introduction This document describes the encoding used in electronic mail [RFC822] and network news [RFC1036] messages in several Japanese networks. It was first specified by and used in JUNET [JUNET]. The encoding is now also widely used in Japanese IP communities. The name given to this encoding is """"ISO-2022-JP"""", which is intended to be used in the """"charset"""" parameter field of MIME headers (see [MIME1] and [MIME2]). Description The text starts in ASCII [ASCII], and switches to Japanese characters through an escape sequence. For example, the escape sequence ESC $ B (three bytes, hexadecimal values: 1B 24 42) indicates that the bytes following this escape sequence are Japanese characters, which are encoded in two bytes each. To switch back to ASCII, the escape sequence ESC (B is used."""	byte;character encoding;email;hexadecimal;iso/iec 2022;internet;japanese language and computers;network switch	Kenzaburo Tamaru	1997	RFC	10.17487/RFC2237	computer science;internet privacy;communication;world wide web;mx record	Security	-26.40343151241092	88.14001541688599	44514
75cc36b7fad019977e985ca9a4cfd4004d0b4914	a multi-constrained routing optimization algorithm in the ip networks	traffic equilibrium;potential penalty the ip network traffic equilibrium link failure;the ip network;potential penalty;telecommunication traffic ip networks optimisation telecommunication links telecommunication network reliability telecommunication network routing;link failure;link failure multiconstrained routing optimization algorithm ip networks traffic flow demand load imbalance network operator balanced distribution traffic engineering link allocation methods;economics ip networks bandwidth routing optimization network topology indexes	Nowadays, with the increasing scale of the IP network, the traffic flow demand also increases. And the situation of load imbalance is becoming more obvious. In the IP network, the failure of a link not only causes the interruption of the traffic flow on this link, but also makes the network operator pay the corresponding penalty to the user. So how to select an appropriate path to reduce the operator's payment while achieving a balanced distribution of the traffic flow at the same time is a big challenge. Usually, traffic equilibrium is used as a routing optimization objective in traffic engineering in order to avoid network traffic flow congestion. In practical problems, the economic losses of the network operators also need to be taken into consideration. Existing link allocation methods often take the failure of links as connection problems and ignore the restrictions of the traffic flow, or only consider the traffic interruption and ignore the network operator's economic losses caused by the failure of links. In this paper, we propose a routing optimization algorithm to achieve traffic equilibrium while reducing the potential penalty of the network operators at the same time. Experiments show that our algorithm can achieve traffic equilibrium and effectively reduce the network operator's potential penalty.	algorithm;internet protocol suite;interrupt;mathematical optimization;network congestion;network traffic control;routing	Ying Zeng;Peiming Zhang;Yun Luo	2015	2015 11th International Conference on Natural Computation (ICNC)	10.1109/ICNC.2015.7378009	traffic generation model;traffic policing;routing;network planning and design;network traffic control;overlay network;telecommunications;engineering;ip forwarding;distributed computing;traffic shaping;internet traffic engineering;computer network;network traffic simulation	Networks	-8.136721581269358	82.12738075660191	44543
077d84f875425e94e01a8fe498070e8d113fef9e	a case for information-bound referencing	internet traffic;bgp;multimedia data;as path;user interaction	Links and content references form the foundation of the way that users interact today. Unfortunately, the links used today (URLs) are fragile since they tightly specify a protocol, host, and filename. Some past efforts have decoupled this binding to a certain degree; e.g., creating links that bind to byte-level data. We argue that these systems do not go far enough. Our key observation is that users really care about the intent of the referenced link and are relatively agnostic to the byte-level representation. Based on this observation, we argue that references should be bound to the underlying information associated with the referenced content. We call such references Information-Bound References (IBR). In this paper, we focus on the challenges of creating IBRs for multimedia data, since these form a dominant fraction of Internet traffic today. We explore the trade-offs of various alternatives for generating and using IBRs. We identify that it is possible to adapt multimedia fingerprinting algorithms in the literature to generate IBRs.	algorithm;byte;fingerprint (computing);image-based modeling and rendering;internet	Ashok Anand;Aditya Akella;Vyas Sekar;Srinivasan Seshan	2010		10.1145/1868447.1868451	internet traffic;border gateway protocol;computer science;operating system;distributed computing;multimedia;world wide web;computer security;computer network	Networks	-16.26314028653902	76.29142680886712	44564
f8f4037140a0674877f7d9d3bb36ed7c5645b012	information exchange infrastructures for independent system operators and transmission system operators: characteristics and functionalities	power system interconnection power systems information security data security vocabulary wide area measurements monitoring information systems communication system security computer networks;information systems;transmission system operator;information security;wide area measurements;vocabulary;power systems;north american;power system interconnection;independent system operator;computer networks;monitoring;wide area monitoring system;power system;information exchange;open access;power system operation;communication system security;data security;power control	In the world of power system operation, many new systems are rapidly becoming part of our vocabulary seemingly almost overnight. Many of us talk about OASIS, ISN, and powerful control-center technologies such as the CCAPI. Out West, there’s much progress to report and much discussion of the great possibilities that remain for something called WAMS (Wide Area Monitoring System). While some of these systems were born out of the necessity of accommodating open access and competition, others originated from our advancing understanding of how complex, interconnected power systems work. But how do these and other emerging system operation technologies and systems fit together? Is anything integrating them in any way? What is the current role of each, and what are the possibilities for the future? This paper aims to answer these and other questions, while clarifying the puzzle that is today’s, and is evolving into tomorrow’s, North American power system.	ibm power systems;information exchange;international relations and security network;sysop;vocabulary	Dejan J. Sobajic;David Becker;Walter Pfuntner;Nisheeth Singh	2006	Proceedings of the 39th Annual Hawaii International Conference on System Sciences (HICSS'06)	10.1109/HICSS.2006.220	simulation;telecommunications;computer science;artificial intelligence;information security;software engineering;database;electric power system;world wide web;computer security	EDA	-23.91587743537357	79.8419490909678	44624
ab6375b19391f80648af683b2ddb149b6292a53a	integrated differentiated survivability in ip over wdm networks	differentiated integrated survivability algorithm disa;ip over wdm;multi layer integrated survivability mlis;network survivability;generalized multi protocol label switching gmpls;integrated shared pool isp;integer program;disa;ip over wdm networks	The problem of differentiated Multi-Layer Integrated Survivability (MLIS) in IP over WDM networks is studied, which is decomposed into three sub-problems: survivable strategies design (SSD), spare capacity dimensioning (SCD), and dynamic survivable routing (DSR). A related work of network survivability in IP over WDM networks is firstly provided, and adaptive survivable strategies are also designed. A new Integrated Shared Pool (ISP) approach for SCD is then proposed, which is formulated by using integer-programming theory. Moreover, a novel survivable routing scheme called Differentiated Integrated Survivability Algorithm (DISA) for DSR is developed. Simulation results show that the proposed integrated survivability scheme performs much better than other solutions (e.g., “highest layer recovery” and “lowest layer recovery” schemes) in terms of traffic blocking ratio, spare resource requirement, and average traffic recovery ratio in IP over WDM networks.	ansi escape code;algorithm;blocking (computing);integer programming;routing;simulation;solid-state drive;wavelength-division multiplexing	Wei Wei;Qingji Zeng	2004	Journal of Computer Science and Technology	10.1007/BF02973453	distributed computing;computer security;computer network	Metrics	-7.093466464767393	83.21301826793875	44656
3fef16fdc5ff060bf555906af139f9e27ce056ae	online routing of bandwidth guaranteed paths with local restoration using optimized aggregate usage information	minimisation;optimized aggregate usage information;routing protocols;multiprotocol label switching;bandwidth guaranteed paths;bandwidth aggregates telecommunication traffic traffic control switches delay routing protocols costs multiprotocol label switching ip networks;traffic control;protocol overhead minimization distributed online routing bandwidth guaranteed paths local restoration optimized aggregate usage information bandwidth sharing characteristic backup paths network state information routing protocols traffic engineering bandwidth sharing maximization aggregate information scenario;telecommunication traffic routing protocols minimisation;backup paths;protocol overhead minimization;unified model;telecommunication traffic;aggregates;local restoration;bandwidth sharing characteristic;bandwidth;cost effectiveness;ip networks;distributed online routing;traffic engineered;traffic engineering;routing protocol;fault model;switches;network state information;aggregate information scenario;bandwidth sharing;bandwidth sharing maximization	We investigate the problem of distributed online routing of bandwidth guaranteed paths with local restoration. A unified model is proposed that captures the bandwidth sharing characteristic of backup paths that provision local restoration, corresponding to different fault models. We apply the model to describe bandwidth sharing on backup paths for varying degrees of network state information. The extent of backup bandwidth sharing depends on the amount of network state information made available through routing protocols. A key design criterion for traffic engineering schemes is to maximize the sharing between backup paths, while minimizing this protocol overhead. M.S. Kodialam and T.V. Lakshman (see Proc. Infocom, p.376-85, 2001) demonstrated that propagating a constant amount of aggregated information per link leads to cost effective bandwidth sharing. We propose oAIS, a new aggregate information scenario, in which we judiciously select the propagated information, such that the protocol overhead is identical to that of Kodialam and Lakshman. Simulations show that oAIS outperforms other information scenarios with comparable protocol overheads.	aggregate data;backup;circuit restoration;fault model;open archival information system;overhead (computing);routing;television;unified model	Saqib Raza;Faisal Aslam;Zartash Afzal Uzmi	2005	IEEE International Conference on Communications, 2005. ICC 2005. 2005	10.1109/ICC.2005.1494347	traffic engineering;real-time computing;computer science;distributed computing;routing protocol;statistics;computer network	Embedded	-7.527561676835822	82.95059304150138	44726
255d8d48cb007c69ec0d248fdcbed988ac7e45a4	ioncloud: exploring application affinity to improve utilization and predictability in datacenters	bandwidth resource management servers switches aggregates substrates next generation networking;virtualisation bandwidth allocation cloud computing computer centres computer network management resource allocation telecommunication power management;network sharing ioncloud datacenters intracloud network resource allocation strategy resource underutilization management overhead virtual networks	The intra-cloud network is typically shared in a best-effort manner, which causes tenant applications to have no actual bandwidth guarantees. Recent proposals address this issue either by statically reserving a slice of the physical infrastructure for each application or by providing proportional sharing among flows. The former approach results in overprovisioned network resources, while the latter requires substantial management overhead. In this paper, we introduce a resource allocation strategy that aims at providing an efficient way to predictably share bandwidth among applications and at minimizing resource underutilization while maintaining low management overhead. To demonstrate the benefits of the strategy, we develop IoNCloud, a system that implements the proposed allocation scheme. IoNCloud employs the abstraction of attraction/repulsion among applications according to their temporal bandwidth demands in order to group them in virtual networks. In doing so, we explore the trade-off between high resource utilization (which is desired by providers to achieve economies of scale) and strict network guarantees (necessary for tenants to run jobs predictably). Evaluation results show that IoNCloud can (a) provide predictable network sharing; and (b) reduce allocated bandwidth, resource underutilization and management overhead when compared against state-of-the-art proposals.	bandwidth (signal processing);best-effort delivery;data center;emoticon;microsoft azure;network packet;overhead (computing);processor affinity	Daniel S. Marcon;Miguel C. Neves;Rodrigo Ruas Oliveira;Leonardo Richter Bays;Raouf Boutaba;Luciano Paschoal Gaspary;Marinho P. Barcellos	2015	2015 IEEE International Conference on Communications (ICC)	10.1109/ICC.2015.7249198	bandwidth management;network traffic control;real-time computing;resource allocation;operating system;dynamic bandwidth allocation;computer network	Mobile	-21.98193842329348	61.269036611364655	44760
6081c639459ac558287f412aaeffb991da0c9763	client-side content delivery policies in replicated web services: parallel access versus single server approach	replication;performance evaluation;simulation;client side strategies;web service;content delivery policies;content delivery;quality of service	The widespread use of web applications pushes for faster and more reliable web services. Several techniques have been developed to address web-service reliability, and to provide a better Quality of Service (QoS) for Internet users. A relatively new technique is web-services geographical replication. Geographical replication can be achieved with both server-side and client-side policies. Among these policies, in this paper we contrasted, qualitatively and quantitatively (via simulation), the most promising client-side techniques: one parallel strategy and one single-server strategy. The aim of our study was to determine the pros and cons of the two approaches (single server versus parallel servers) with the aim of identifying the best solutions for content-delivery systems. We analytically quantified the overhead introduced by the selected parallel strategy and proposed two extensions of the parallel strategy to reduce its overhead still maintaining the simplicity of the original approach. The selected strategies are evaluated when: (i) a consistent number of clients adopt the same strategy, (ii) clients download both small and/or big files from the web servers, and (iii) clients are connected to the Internet via a slow-link connection. Results of our analysis pointed out the problems of adopting a parallel strategy in a widespread fashion, and indicated the scenarios in which a parallel strategy may be advantageous. As a result of our study, we proposed a hybrid strategy that combines the parallel and the single server strategies. The hybrid strategy applies either the parallel or the single-server strategy depending on the load and system conditions.	client-side;digital distribution;random-access memory;server (computing);web service	Marco Conti;Enrico Gregori;Willy Lapenna	2005	Perform. Eval.	10.1016/j.peva.2004.07.018	web service;replication;real-time computing;quality of service;computer science;distributed computing;world wide web;computer network	Web+IR	-17.489634582163397	71.11407367865779	44792
800f590fe0669f5b065dc4e2d4aa9dc6a714c268	on the benefit of tunability in reducing electronic port counts in wdm/tdm networks	optimisation;wdm network;optical fiber networks;tunable transceiver;hub traffic;tdm network;network topology;optical fibre networks;telecommunication traffic;intelligent networks wavelength division multiplexing wdm networks time division multiplexing telecommunication traffic transceivers passive optical networks optical fiber networks sonet costs;telecommunication network topology wavelength division multiplexing time division multiplexing telecommunication traffic optimisation optical fibre networks;wdm networks;transceivers;intelligent networks;time division multiplexing;telecommunication network topology;electronic port count;heuristic algorithm electronic port count wdm network wavelength division multiplexing time division multiplexing tdm network tunable transceiver np complete problem hub traffic;sonet;heuristic algorithm;np complete problem;passive optical networks;wavelength division multiplexing	"""We study the benefits of using tunable transceivers for reducing the required number of electronic ports in WDM/TDM networks. We show that such transceivers can be used to efficiently """"groom"""" sub-wavelength traffic in the optical domain and so can significantly reduce the number of electronic ports compared to the fixed tuned case. We provide a new formulation for this """"tunable grooming"""" problem. We show that in general this problem is NP-complete, but we are able to efficiently solve it for many cases of interest. When the number of wavelengths in the network is not limited, we show that each node only needs the minimum number of transceivers (i.e., no more transceivers than the amount of traffic that it generates). This holds regardless of the network topology or traffic pattern. When the number of wavelengths is limited, we show an analogous result for both uniform and hub traffic in a ring. We also develop a heuristic algorithm for general traffic that uses nearly the minimum number of transceivers. In most cases, tunable transceivers are shown to reduce the number of ports per node by as much as 60%."""	algorithm;edge coloring;electronic hardware;graph (discrete mathematics);heuristic (computer science);karp's 21 np-complete problems;network topology;ring network;social inequality;toad data modeler;transceiver;transmitter;usb hub;wavelength-division multiplexing	Randall Berry;Eytan Modiano	2004	IEEE INFOCOM 2004	10.1109/INFCOM.2004.1357019	heuristic;intelligent network;passive optical network;np-complete;telecommunications;computer science;synchronous optical networking;network topology;time-division multiplexing;wavelength-division multiplexing;computer network;transceiver	Metrics	-5.400387994836471	81.26785293394052	44815
abd11a01591c827684f41cb068d095fad9e1b7e7	an efficient server bandwidth costs decreased mechanism towards mobile devices in cloud-assisted p2p-vod system	cloud-assisted;p2p-vod;neighbor selection;distributed linear taxation algorithm;chunks downloading algorithm;mobile devices	Recently, more and more devices with small buffer size such as PDAs or mobile phones are joining in the VoD system, which leads to two major challenges: how to efficiently distribute their bandwidth resources with small buffer size, and how to provide assistant mechanism to make them playback smoothness. In face of this situation and for the purpose of decreasing the server bandwidth costs, we propose a peers’ downloading mechanism called NCDLT to solve above challenges. It contains two algorithms. The first is neighbors and chunks downloading selection (NCS) algorithm and it ensures peers to find neighbors who can provide video data with lower refusal rate. The second is distributed linear taxation algorithm (DLT) and it makes peers with lower capability acquire enough download rate to reduce the request to servers. The simulation results demonstrate that our algorithms can offload the server bandwidth costs and improve the download rate of peers with small buffer size.		Xin Cong;Kai Shuang;Sen Su;Fangchun Yang	2014	Peer-to-Peer Networking and Applications	10.1007/s12083-012-0193-z	real-time computing;computer science;operating system;database;distributed computing;world wide web;computer security;computer network	Mobile	-16.338430506442833	73.44826266425648	44871
c5ae03082c7d3ad9626e97b3cf899552fc611c0b	litevisor: a network hypervisor to support flow aggregation and seamless network reconfiguration for vm migration in virtualized software-defined networks		Network virtualization based on software-defined networking (SDN) has become a necessary technology to provide various services in cloud datacenters. Although many network hypervisors have been proposed to support SDN-based network virtualization, their forwarding techniques excessively consume the limited ternary contents addressable memory of OpenFlow-enabled switches. Moreover, they do not consider network reconfiguration after virtual machine migration. In this paper, we propose LiteVisor, that resolves the two problems mentioned above. It develops the Locator, Identifier, and Tenant sEparating (LITE) scheme. The LITE-based forwarding enables flow aggregation that reduces switch memory consumption. In addition, LiteVisor provides seamless network reconfiguration that does not require tenant controllers to be aware of virtual machine migration based on LITE. We evaluate LiteVisor in terms of the number of flow table entries and network reconfiguration time and compare it with OpenVirteX that is an open-source network hypervisor. The results show that the number of flow rules decreases by up to eight times compared with OpenVirteX in a fat-tree topology. We also demonstrate the seamless network reconfiguration of LiteVisor in the experiments and present the results of the reconfiguration time by the topology size and packet sending interval of hosts.	anatomy, regional;experiment;fat tree;hypervisor;identifier;network packet;network switch;nut hypersensitivity;online locator service;open-source software;openflow;platelet glycoprotein 4, human;regular expression;rule (guideline);seamless3d;software-defined networking;switch device component;tree network;virtual machine;contents - htmllinktype	Gyeongsik Yang;Bong-yeol Yu;Seong-Mun Kim;Chuck Yoo	2018	IEEE Access	10.1109/ACCESS.2018.2877416	virtualization;network virtualization;computer network;hypervisor;control reconfiguration;computer science;software-defined networking;network topology;distributed computing;virtual machine;network packet	HPC	-14.025298205532769	82.8385381034815	44888
6f3b07db448f085a146a31ddc842ff65ea69abe1	a lottery-based pricing scheme for peer-to-peer networks	micropayment;peer to peer network;lottery;incentives;pricing;p2p;p2p networks;peer to peer;peer to peer networks;free riding	Users in Peer-to-Peer (P2P) networks tend to exploit the maximum resources they are able to obtain, offering minimum resources in response. This behavior undermines the goal of P2P in spreading files through the network and imposes the concept of free-riding. In this paper we propose a Lotterybased pricing mechanism to enhance the sharing level in P2P network and help increasing the number of objects disseminated. The scheme is an extension of the traditional micropayment mechanism. Our scheme provides higher payoff for peers who contribute to the P2P network and higher cost for peers who act selfishly and choose not to share resources. Finally, we present our simulation results to demonstrate the performance of our proposed mechanism.	micropayment;peer-to-peer;simulation	Manaf Zghaibeh;Fotios C. Harmantzis	2008	Telecommunication Systems	10.1007/s11235-008-9109-x	pricing;incentive;computer science;peer-to-peer;free riding;computer security;micropayment;computer network	Metrics	-25.484152015688547	73.45407472605035	44923
8ef3202f1f28a466e8ad5776ed051d58f7d918fa	vrml: adding 3d to network management	3d visualisation;information model;three dimensional;resource use;network topology;3d model;world wide web;profitability;network management	This paper describes a new approach to the visualisation of network management resources using VRML, a 3D modeling language. VRML has been successfully applied to selected network management problems, showing that network management information can often be presented profitably in 3D format. The ability of modern Web browsers to handle both HTML and VRML allows a simple yet powerful and flexible system for two and three-dimensional network management visualisation to be created.	3d modeling;html;management information system;modeling language;vrml	Luca Deri;Dimitrios Manikis	1997		10.1007/3-540-63135-6_45	element management system;simulation;network architecture;computer science;data mining;network simulation;network management application;structure of management information;world wide web	Networks	-22.261187651594106	85.39063800755402	44930
3448a7cf8127a12dc96af9a32787128b75169e78	i2ot: inexactness in iot	inexact computing;workflow execution;scheduling	Recent research on inexact computing shows promising results for improved energy utilization for resource hungry applications across different layers of the execution stack. The general philosophy of inexact computing is to trade-off correctness within acceptable limits with the premise of improved energy utilization. In this paper, we explore this philosophy in the context of a heterogeneous Internet-of-Things (IoT) architecture for application execution. We consider an application workflow, comprising of a set of methods with their possible inexact lightweight variants, a deadline for completion, and a multi-tiered IoT compute architecture (e.g. mobile device, gateway, cloud, etc.). Our methodology produces a time-optimized execution solution that assigns each method, with an appropriate variant (the exact one or any of its inexact realizations), to an appropriate computing layer such that the deadline is met with quality as best as possible. We present experimental results to demonstrate the efficacy of our proposal on two real-life case studies.	cloud computing;complexity;correctness (computer science);job shop scheduling;mobile device;real life;real-time clock;scheduling (computing)	Ansuman Banerjee;Himadri Sekhar Paul;Arijit Mukherjee	2016		10.1145/2962564.2962567	real-time computing;computer science;theoretical computer science;operating system;distributed computing;scheduling	EDA	-5.942942276575197	61.03910519304574	44949
465976816854ec40c7ef98c3f8fad55583580e4b	a speculative control mechanism of cloud computing systems based on emergency disaster information using sdn		In recent years, a Cloud computing system has been popularly used. Among them, a hybrid Cloud is focused, which combined a public Cloud operated by service providers and a private Cloud constructed inside a company. Because a private Cloud is considered to be secure and a public Cloud is scalable, it is possible to build a Cloud computing system that works effectively by combining the both types of Clouds. However, when a big disaster occurrs, huge volume of data is produced by monitoring censors and users, and flowed into such an information infrastructure. In addition, enormous number of people access to the system in such a case, thus a load of the system becomes extremely high in a short time. Therefore, it is important to change an environment dynamically among inter-Cloud and intra-Cloud to deal with the load. In this paper, bursty increasing load is predicted based on Earthquake Early Warning (EEW), and a speculative control is performed in a short time between a time of occurrence of an earthquake and a time when the system is heavily loaded actually. In addition, network traffic is controlled to give a higher priority to important data replication. The system is constructed on a Cloud computing platform using public domain software, OpenStack in this experiment. Network traffic of the system is controlled by Software Defined Network (SDN), which is controlled by the OpenFlow protocol. As a result of an evaluation, our proposed system works fine and achieves good performance. c © 2016 The Authors. Published by Elsevier B.V. Peer-review under responsibility of the Conference Program Chairs.	cloud computing;earthquake early warning (japan);network packet;openflow;public-domain software;replication (computing);scalability;software-defined networking;speculative execution	Masato Oguchi;Ruriko Hara	2016		10.1016/j.procs.2016.09.065	cloud computing security;simulation;cloud computing;operating system;cloud testing;data mining;world wide web;computer security	HPC	-31.413707736749416	63.619278800834415	44973
d4ca45e2a53c403c9cb63f4cc594a2c358814c47	from mobiles to clouds: developing energy-aware offloading strategies for workflows	energy;resource allocation;mobile communication algorithm design and analysis hardware mobile handsets cloud computing ieee 802 11 standards;mobile computing workflow code offload energy;offload efficiency energy aware offloading strategies cloud computing mobile computing computation intensive services content rich services task offload techniques workflows energy cost mobile devices cloud like infrastructures cloudlets computational resources mission critical mobile workflows energy aware manner workflow software network hardware devices objective functions offload decisions heuristic algorithm statistical plans dynamic offload plans;ieee 802 11 standards;mobile communication;mobile handsets;workflow management software cloud computing mobile computing resource allocation;workflow management software;code offload;workflow;mobile computing;algorithm design and analysis;cloud computing;hardware	Cloud computing and mobile computing are two of the most influential technologies that look set to change the face of computing in the coming years. Combination of the two provides us with an unprecedented opportunity to provide highly portable and yet content-rich and computation-intensive services to the end user. In this paper we investigate the possibility of using code/task offload techniques between mobile and cloud in order to reduce the energy cost of workflows deployed on mobile devices. We first present a vision in which mobile devices are coordinated over a network, which is equipped with a layer of cloud-like infrastructures which we term cloudlets, whose computational resources can be leveraged by the mobile devices to host the execution of mission-critical mobile workflows in an energy-aware manner. We then build a model that encompasses various characteristics of the workflow's software and the network's hardware devices. With this model, we construct the objective functions that guide the offload decisions. We then present a heuristic algorithm that produces statistical and dynamic offload plans according to these objective functions and their variations both statically and dynamically. We conclude the paper with a series of simulation studies, the results of which give insight into the offload-ability of workflows of different characteristics. The results also illustrate how different hardware specifications can affect offload efficiency. These studies indicate that our offload algorithm can significantly improve the energy efficiency and execution speed of mobile workflows.	algorithm;algorithmic efficiency;cloud computing;computation;computational resource;critical path method;executable;heuristic (computer science);inter-process communication;mathematical optimization;mission critical;mobile computing;mobile device;repository (version control);server (computing);server-side;simulation;smartphone	Bo Gao;Ligang He;Limin Liu;Keqin Li;Stephen A. Jarvis	2012	2012 ACM/IEEE 13th International Conference on Grid Computing	10.1109/Grid.2012.20	embedded system;algorithm design;workflow;real-time computing;mobile search;energy;mobile telephony;cloud computing;resource allocation;computer science;operating system;mobile computing	EDA	-22.277106028511888	66.96162817146141	44991
a9778f1ff8483ca6f28da2692c1c73fd0df2707c	qoe-aware device-to-device multimedia communications	multimedia communications;mobile networks;qoe;d2d communications	Multimedia services over mobile device-to-device (D2D) networks has recently received considerable attention. In this scenario, each device is equipped with a cellular communication interface, as well as a D2D interface over a shared medium. In this work, we study the performance properties of the mobile D2D communications in the framework of user satisfaction, and develop a fully distributed QoE-aware multimedia communication scheme (QAMCS). Specifically, we translate the opportunistic multimedia communications issue into a stochastic optimization problem, which opens up a new degree of performance to exploit. Moreover, QAMCS is designed for a heterogeneous and dynamic environment, in which user demand, device mobility, and transmission fashion may vary across different devices and applications. Importantly, QAMCS is able to maximize the user satisfaction and only needs each device to implement its own scheme individually in the absence of a central controller.	mathematical optimization;mobile device;mobile phone;optimization problem;stochastic optimization	Liang Zhou	2015	EAI Endorsed Trans. Creative Technologies	10.4108/icst.mobimedia.2015.259031	call-second;communications server;computer network	Mobile	-23.14524682320321	74.47603128929336	45186
0000899a3de252715b4b67d15e96b5f432bd5db5	designs of high-performance multicast scheduling mechanisms in wdm networks	optical network;wdm network;wdm optical networks;real time;wdm optical network;scheduling algorithm;head of line;scheduling;star networks;high performance;multicast;wavelength division multiplex	In this article, we propose three multicast scheduling mechanisms, lookback queue access, lookback ratio access, and double check head access, for the employment in the single-star Wavelength Division Multiplexing optical network. Each of the proposed scheduling schemes consists of two phases and is executed in real time. In general, the first phase is to search for a candidate multicast packet that can be sent, without partition, to all of its intended recipients. If phase 1 fails, the second phase is then activated to partition a multicast packet into multiple transmissions in accordance with specific criteria of each individual mechanism. These algorithms are designed to mitigate the head-of-line blocking effect, while at the same time achieving excellent network throughput levels and delay performance via the partitioning procedure. Performance results reveal the distinct features of each mechanism under various scenarios. For a wider range of networking environments, we further propose an interconnected dual-star structure and enhanced multicast scheduling algorithms. These enhanced schemes aim to exploit the inter-data channels efficiently and utilize the wavelength reuse property of the intra-data channels properly. Performance results have demonstrated the merits of deploying the proposed multicast algorithms in such a dual-star structure.	algorithm;blocking (computing);hol (proof assistant);heuristic;multicast;network architecture;network packet;network scheduler;random access;reservation station;scheduling (computing);star network;throughput;wavelength-division multiplexing	Ho-Ting Wu;Kai-Wei Ke;Pohsin Hung	2009	Photonic Network Communications	10.1007/s11107-009-0217-7	real-time computing;multicast;inter-domain;reliable multicast;telecommunications;protocol independent multicast;computer science;pragmatic general multicast;distributed computing;distance vector multicast routing protocol;source-specific multicast;scheduling;xcast;computer network;multicast address	Metrics	-4.787996223961622	85.97589751898522	45221
50593880597a5c155c18b8eba3da13321eb496ca	enabling contribution awareness in an overlay broadcasting system	unfolding;evaluation performance;virtual network;largeur bande;haute performance;saturacion;multimedia;performance evaluation;dsl;asymmetry;deploiement;incentive;contribution awareness;evaluacion prestacion;heuristic method;nat;multidestinatario;despliegue;metodo heuristico;saturation detection bandwidth detection incentive multitree overlay multicast nat;overlay multicast;bandwidth demanding broadcasting;asymetrie;equitable bandwidth distribution;saturation detection;network address translation;internet;streaming media;heterogeneidad;bandwidth scarce environment;anchura banda;alto rendimiento;asimetria;overlay broadcasting system;bandwidth;equitable bandwidth distribution contribution awareness overlay broadcasting system bandwidth demanding broadcasting bandwidth scarce environment;modems;methode heuristique;broadcasting;peer to peer computing;multitree;ethernet networks;high performance;power cables;saturation;multidestinataire;red virtual;multicast;heterogeneity;heterogeneite;peer to peer computing broadcasting internet;reseau virtuel;broadcasting bandwidth peer to peer computing internet streaming media dsl network address translation power cables modems ethernet networks;bandwidth detection	We consider the design of bandwidth-demanding broadcasting applications using overlays in environments characterized by hosts with limited and asymmetric bandwidth, and significant heterogeneity in upload bandwidth. Such environments are critical to consider to extend the applicability of overlay multicast to mainstream Internet environments where insufficient bandwidth exists to support all hosts, but have not received adequate attention from the research community. We leverage the multitree framework and design heuristics to enable it to consider host contribution and operate in bandwidth-scarce environments. Our extensions seek to simultaneously achieve good utilization of system resources, performance to hosts commensurate to their contributions, and consistent performance. We have implemented the system and conducted an Internet evaluation on PlanetLab using real traces from previous operational deployments of an overlay broadcasting system. Our results indicate for these traces, our heuristics can improve the performance of high contributors by 10-240% and facilitate equitable bandwidth distribution among hosts with similar contributions.	heuristic (computer science);internet;multicast;overlay network;planetlab;tracing (software);upload	Yu-Wei Eric Sung;Michael A. Bishop;Sanjay G. Rao	2007	IEEE Transactions on Multimedia	10.1109/TMM.2007.907454	multicast;the internet;digital subscriber line;telecommunications;incentive;computer science;nat;heterogeneity;operating system;multitree;distributed computing;network address translation;world wide web;broadcasting;bandwidth;saturation;asymmetry;statistics;computer network	Networks	-6.469140978908089	75.08171966274698	45411
27127b9acbb01c5abd43782d072fe90383dbe09a	connectivity and stability at failures in isp backbone networks	topology;reliability;single link failure;ladder topology;telecommunication network reliability;flow hop length stability;ladder topology internet service providers isp backbone networks telecommunication network reliability single link failure flow hop length stability network connectivity mesh topology;network topology;internet;internet service providers;network connectivity;isp backbone networks;stability analysis;stability spine degradation telecommunication traffic costs web and internet services cause effect analysis investments guidelines ip networks;book reviews;telecommunication network topology internet telecommunication network reliability;peer to peer computing;telecommunication network topology;mesh topology	When a link or node failure occurs, flows are detoured around the failed portion, so the hop count of flows could change dramatically as a result of a failure. It is therefore important to evaluate the reliability of backbone networks from the viewpoint of flow hop length stability as well as network connectivity. In this paper, we analyze the possible primary causes of the degradation of reliability of the backbone networks of 36 commercial ISPs and present guidelines for making effective investments in link addition.	algorithm;electronic filter topology;elegant degradation;internet backbone;network topology	Noriaki Kamiyama;Hiroyoshi Miwa	2008	IEEE GLOBECOM 2008 - 2008 IEEE Global Telecommunications Conference	10.1109/GLOCOM.2008.ECP.300	von neumann stability analysis;the internet;telecommunications;computer science;mesh networking;reliability;backbone network;distributed computing;network topology;computer network	Embedded	-7.822741838965766	82.56569763904963	45427
a38233d0b8ea815913c2e29f785111dcc6fab4f7	social welfare maximization auction in edge computing resource allocation for mobile blockchain		Blockchain, an emerging decentralized security system, has been applied in many applications, such as bitcoin, smart grid, and Internet-of-Things. However, running the mining process may cost too much energy consumption and computing resource usage on handheld devices, which restricts the use of blockchain in mobile environments. In this paper, we consider deploying edge computing service to support the mobile blockchain. We propose an auction-based edge computing resource allocation mechanism for the edge computing service provider. Since there is competition among miners, the allocative externalities are taken into account in the model. In our auction mechanism, we maximize the social welfare while guaranteeing the truthfulness, individual rationality and computational efficiency. Through extensive simulations, we evaluate the performance of our auction mechanism which shows that the proposed mechanism can efficiently solve the social welfare maximization problem for the edge computing service provider.	algorithmic efficiency;allocative efficiency;auction algorithm;bitcoin;edge computing;entropy maximization;expectation–maximization algorithm;mobile device;rationality;simulation	Yutao Jiao;Ping Wang;Dusit Niyato;Zehui Xiong	2018	2018 IEEE International Conference on Communications (ICC)	10.1109/ICC.2018.8422632	service provider;resource management;allocative efficiency;smart grid;microeconomics;business;mobile device;maximization;edge computing;resource allocation	HPC	-24.039221625410008	74.82355698138474	45455
0a00a9ec4aab21b02eca633cd25c5215cd8a2710	a four-terabit single-stage packet switch with large round-trip time support	cmos integrated circuits;queueing theory;packet switched;packet switching;round trip time;telecommunication network routing;application specific integrated circuits;4 tbit s single stage packet switch round trip time support vlsi implementation input queued structure crosspoint queued structure virtual output queuing input buffered switch scalability output buffered switches fabric internal transmission latency line cards asic implementation distributed packet routing switch architecture cmos technology;vlsi;virtual output queuing;switches packet switching centralized control cmos technology laboratories bipartite graph emulation traffic control scalability proposals;queueing theory packet switching vlsi application specific integrated circuits delays telecommunication network routing cmos integrated circuits;delays	We present the architecture and practical VLSI implementation of a 4-Tb/s single-stage switch. It is based on a combined input-and crosspoint-queued structure with virtual output queuing at the ingress, which has the scalability of input -buffered switches and the performance of output-buf-fered switches. Our system handles the large fabric-internal transmission latency that results from packaging up to 256 line cards into multiple racks. We provide the justification for selecting this architecture and compare it with other current solutions. With an ASIC implementation, we show that a single-stage multi-terabit buffered crossbar approach is viable today.	application-specific integrated circuit;crossbar switch;network switch;scalability;terabit;very-large-scale integration	François Abel;Cyriel Minkenberg;Ronald P. Luijten;Mitchell Gusat;Ilias Iliadis	2002		10.1109/CONECT.2002.1039251	real-time computing;computer science;application-specific integrated circuit;very-large-scale integration;transmission delay;queueing theory;packet switch;cmos;round-trip delay time;burst switching;packet switching;computer network	Networks	-5.388413305310937	87.20827124916966	45462
4e911583a67b09f96994bbf8c6eabe86f4236811	fcast: object delivery for the asynchronous layered coding (alc) and nack-oriented reliable multicast (norm) protocols		This document introduces the FCAST reliable object (e.g., file) delivery application. It is designed to operate either on top of the underlying Asynchronous Layered Coding (ALC) / Layered Coding Transport (LCT) reliable multicast transport protocol or the NACKOriented Reliable Multicast (NORM) transport protocol.	acknowledgement (data networks);linear canonical transformation;multicast;reliability (computer networking)	Vincent Roca;Brian Adamson	2013	RFC	10.17487/RFC6968	real-time computing;multicast;ip multicast;inter-domain;reliable multicast;protocol independent multicast;computer science;pragmatic general multicast;distributed computing;source-specific multicast;xcast;computer network	Networks	-8.057821108261685	87.46741585573707	45514
ed87619e6aea8110c29d02e9060aadd54e117e69	lightweight directory access protocol (ldap) authorization identity request and response controls		This document extends the Lightweight Directory Access Protocol (LDAP)#N#bind operation with a mechanism for requesting and returning the#N#authorization identity it establishes. Specifically, this document#N#defines the Authorization Identity Request and Response controls for#N#use with the Bind operation. This memo provides information for the#N#Internet community.	authorization;lightweight directory access protocol	Rob Weltman;Mark Smith;Mark Wahl	2004	RFC	10.17487/RFC3829	lightweight directory access protocol;directory service;computer science;database;world wide web;computer security	Security	-26.2243715750622	87.64683195431786	45587
40eadd0544ce2920918a258b39bfc568135ace57	a high scalability p2p simulation framework with measured realistic network layer support	p2p system;computers;topology;scalability object oriented modeling peer to peer computing protocols ip networks large scale systems circuit simulation java delay network topology;service provider;peer to peer network;simulation framework;p2p;simulator;transport protocols;transport protocols digital simulation message passing parallel processing peer to peer computing;large scale;computational modeling;internet;synchronization;synchronization p2p underlying network simulator parallel;parallel;message passing;cost effectiveness;message level parallel processing high scalability peer to peer simulation framework measured realistic network layer support protocol evaluation;underlying network;p2p networks;peer to peer computing;peer to peer;object oriented modeling;parallel processing;parallel simulation;digital simulation	The Peer-to-Peer (P2P) technology being widely adopted in today's both academic research and practical service providing, has many potential advantages, including high scalability and cost-effectiveness. However, the behavior of these P2P systems under large scale and complex interactions is still poorly understood and many challenges in improving their performance remain. A fundamental problem in studying peer-to-peer networks is the evaluation of new protocols. So the technology of P2P network simulation has become a main method for understanding, researching and evaluating the P2P network algorithms and protocols. In this paper, we present a novel large-scale parallel Peer-to-Peer Simulation Framework with High Scalability (HiFiP2P) which uses message-level parallel process. By performing the comparison experiments, we show that HiFiP2P outperforms the existing simulation platform in both aspects of scalability and efficiency. And we show that with HiFiP2P simulations of networks with up to 500,000 nodes are feasible.	algorithm;experiment;interaction;peer-to-peer;scalability;simulation	Guangyu Shi;Youshui Long;Hao Gong;Changqing Wan;Chuanliang Yu;Xianqing Yang;Hongli Zhang	2008	2008 IEEE International Performance, Computing and Communications Conference	10.1109/PCCC.2008.4745130	service provider;parallel processing;synchronization;message passing;real-time computing;the internet;cost-effectiveness analysis;telecommunications;computer science;theoretical computer science;peer-to-peer;parallel;distributed computing;scalability testing;computational model;transport layer;computer network	HPC	-9.706703806560565	76.74848457977657	45703
0747fe05941ab7f7ff634812fd8c6f05d478d782	the modular wdm-gridconnect as a passive routing structure with distributed interfacing capabilities	wavelength division multiplexing;multihop network;optical bypass;grid network;optical crossconnect	For communication services over transparent optical paths, specified in terms of bit rate and bit error probability, the maximum length is determined by detrimental physical effects like dispersion, crosstalk, noise or nonlinearities. Therefore, fiber-optic wide area networks employing wavelength division multiplexing (WDM) and optical bypassing have to be divided into several small transparent partitions. In this paper a scheme accounting for sufficiently short optical paths is introduced which is called Modular WDM-Gridconnect. In this approach the burden of interconnecting different network partitions (i.e., by using an overlay transport system as an interface) is spread over almost all nodes of the network. This property is referred to as distributed interfacing. The network can be extended step-by-step in a modular fashion adding no more than two nodes to the coverage area at a time. The advantageous properties of such an arrangement as compared to a straightforward partitioning are characterized by the cumulative transit traffic and the path lengths in a Modular WDM-Gridconnect cluster.	atm turbo;bit error rate;computer cluster;crosstalk;mesh networking;network switch;noise (electronics);optical fiber;optical switch;regular grid;requirement;routing;synchronous optical networking;telecommunications network;transport layer security;wavelength-division multiplexing	Hubert A. Jäger	1999	Photonic Network Communication	10.1023/A:1010064715424	electronic engineering;real-time computing;telecommunications;computer science	Networks	-6.740241670529305	85.02291071644461	45725
c0806285df84d3fefa4a3eb360528e8e6e75bf0a	a review of priority assignment in real-time systems	performance;schedulability analysis;c 3 real time and embedded systems;real time scheduling;priority assignment;optimal priority assignment;algorithms;design;fixed priority scheduling;robust priority assignment;deadline monotonic;rate monotonic;real time systems	It is over 40 years since the first seminal work on priority assignment for real-time systems using fixed priority scheduling. Since then, huge progress has been made in the field of real-time scheduling with more complex models and schedulability analysis techniques developed to better represent and analyse real systems. This tutorial style review provides an in-depth assessment of priority assignment techniques for hard real-time systems scheduled using fixed priorities. It examines the role and importance of priority in fixed priority scheduling in all of its guises, including: preemptive and non-pre-emptive scheduling; covering singleand multi-processor systems, and networks. A categorisation of optimal priority assignment techniques is given, along with the conditions on their applicability. We examine the extension of these techniques via sensitivity analysis to form robust priority assignment policies that can be used even when there is only partial information available about the system. The review covers priority assignment in a wide variety of settings including: mixed-criticality systems, systems with deferred pre-emption, and probabilistic real-time systems with worstcase execution times described by random variables. It concludes with a discussion of open problems in the area of priority assignment.	autosar;best, worst and average case;can bus;categorization;central processing unit;composability;correctness (computer science);criticality matrix;earliest deadline first scheduling;expectation propagation;extensibility;fixed-priority pre-emptive scheduling;genetic algorithm;graph coloring;headroom (audio signal processing);heuristic;holism;integer programming;interference (communication);lexicography;linear programming;microelectronics and computer technology corporation;mixed criticality;multiprocessing;network on a chip;network switch;non-monotonic logic;osek;opa;real-time clock;real-time computing;real-time operating system;real-time transcription;requirement;routing;scheduling (computing);scheduling analysis real-time systems;self-organized criticality;separation of concerns;simulated annealing	Robert I. Davis;Liliana Cucu-Grosjean;Marko Bertogna;Alan Burns	2016	Journal of Systems Architecture - Embedded Systems Design	10.1016/j.sysarc.2016.04.002	priority inversion;priority inheritance;fixed-priority pre-emptive scheduling;design;real-time computing;earliest deadline first scheduling;performance;dynamic priority scheduling;computer science;rate-monotonic scheduling;deadline-monotonic scheduling;distributed computing;priority ceiling protocol;algorithm	Embedded	-9.225834193113068	60.93938897594546	45799
98aca1132e4f1f292cc324eb61f1a6ca130fe042	experimental analysis of task-based energy consumption in cloud computing systems	energy efficiency;green cloud;swinburne;energy consumption;performance analysis;cloud computing	Cloud computing delivers IT solutions as a utility to users. One consequence of this model is that large cloud data centres consume large amounts of energy and produce significant carbon footprints. A common objective of cloud providers is to develop resource provisioning and management solutions that minimise energy consumption while guaranteeing Service Level Agreements (SLAs). In order to achieve this objective, a thorough understanding of energy consumption patterns in complex cloud systems is imperative. We have developed an energy consumption model for cloud computing systems. To operationalise this model, we have conducted extensive experiments to profile the energy consumption in cloud computing systems based on three types of tasks: computation-intensive, data-intensive and communication-intensive tasks. We collected fine-grained energy consumption and performance data with varying system configurations and workloads. Our experimental results show the correlation coefficients of energy consumption, system configuration and workload, as well as system performance in cloud systems. These results can be used for designing energy consumption monitors, and static or dynamic system-level energy consumption optimisation strategies for green cloud computing systems.	cloud computing;coefficient;computation;data-intensive computing;dynamical system;experiment;imperative programming;mathematical optimization;provisioning;service-level agreement;system configuration	Feifei Chen;John Grundy;Yun Yang;Jean-Guy Schneider;Qiang He	2013		10.1145/2479871.2479911	real-time computing;simulation;cloud computing;computer science;engineering;operating system;cloud testing;distributed computing;efficient energy use;energy accounting	HPC	-21.650528148823867	61.87678323755794	45910
46c6f728db2940852b549b0c82af2bfa5c403102	evolving robust networks for systems-of-systems	articulo;systems of systems;network calculus;evolving robust networks for systems of systems;genetic algorithms;network enabled capability	Software systems that rely on ad-hoc networks are becoming increasingly complex and increasingly prevalent. Some of these systems provide vital functionality to military operations, emergency services and disaster relief; such systems may have significant impact on the safety of people involved in those operations. It is therefore important that those networks support critical software requirements, including those for latency of packet transfer. If a network ceases to meet the software’s requirements (e.g. due to a link failure) then engineers must be able to understand it well enough to reconfigure the network and restore it to a requirement-satisfying state. Given a complex network, it is difficult for a human to do this under time pressure. In this paper we present a search-based tool which takes a network defined using the Network Description Language (NDL), annotated with a set of network-hosted applications and a set of latency requirements between each. We then evolve variants of the network configuration which meet the requirements and are robust to single link failures. We use network calculus tools to get a fast, conservative evaluation of whether a given network meets its requirements. We demonstrate that this approach is viable, designs networks much faster than a human engineer could, and is superior to a random generate-and-test approach.	complex network;hoc (programming language);network description language;network calculus;network packet;requirement;semantic network;software requirements;software system;system of systems	Jonathan M. Aitken;Robert Alexander;Tim Kelly;Simon M. Poulding	2012		10.1007/978-3-642-33119-0_4	simulation;intelligent computer network;genetic algorithm;evolving networks;system of systems;computer science;systems engineering;engineering;artificial intelligence;software engineering;machine learning;network simulation;distributed computing	Networks	-16.83449937177389	79.11379834807977	45924
5613c3010685e497266e059de3f5f4fbd3c11af9	exploring the reliable multicast transport of bgp in geostationary satellite networks based on network coding			border gateway protocol;geosynchronous satellite;linear network coding;multicast	Wei Han;Baosheng Wang;Zhenqian Feng;Baokang Zhao;Wanrong Yu;Zhu Tang	2017	IEICE Transactions		network load balancing;linear network coding;multicast;border gateway protocol;reliable multicast;telecommunications;computer science;pragmatic general multicast;distributed computing;source-specific multicast;multimedia broadcast multicast service;xcast;computer network;network mapping	Networks	-8.242192851912753	87.01786147350325	45931
1a20e00fe7ca8f0cc765b2acf77ddeee592b20f1	extending ic-scheduling via the sweep algorithm	nuclear magnetic resonance imaging;modelizacion;grafo aciclico;haute performance;computational grid;imagineria rmn;distributed computing;graphe acyclique;acyclic graph;global computing;grid;modelisation;scheduling algorithm;ic scheduling;internet;ic scheduling theory;optimal scheduling;rejilla;scheduling;directed graph;functional magnetic resonance images;theory;scheduling theory;graphe oriente;scheduling dag;alto rendimiento;grille;calculo repartido;simulation study;grafo orientado;imagerie rmn;scheduling dags;modeling;grid computing;high performance;internet based computing;calcul reparti;ordonnancement;reglamento	"""Earlier work has developed the rudiments of a scheduling theory for computations having intertask dependencies - modeled via dags - for Internet-based computing. The goal of the schedules produced is to render tasks eligible for execution as fast as possible, with the aim of: (a) utilizing clients' computational resources well, by always having work to allocate to an available client; (b) lessening the likelihood of a computation's stalling for lack of eligible tasks. Simulation studies suggest that this goal does accelerate computation over the Internet. The theory crafts a schedule for a dag Q by """"parsing"""" Q (if possible) into connected building-block dags that one can """"compose """" to form Q and then analyzing the scheduling dependencies among these building blocks. The current paper extends the theory by developing the Sweep Algorithm, a tool that allows one to: (1) schedule using building blocks that are not necessarily connected, and (2) craft schedules that interleave the execution of subdags that have no interdependencies. The augmented scheduling algorithms allow one to craft optimal schedules for previously unschedulable dags. Examples presented include artificial dags that are """"close"""" to ones arising in real computations, as well as a component of a dag that arises in a functional MRI application."""	algorithm;computation;computational resource;directed acyclic graph;emoticon;interdependence;internet;parsing;schedule (computer science);scheduling (computing);simulation	Gennaro Cordasco;Grzegorz Malewicz;Arnold L. Rosenberg	2008	16th Euromicro Conference on Parallel, Distributed and Network-Based Processing (PDP 2008)	10.1016/j.jpdc.2009.11.001	mathematical optimization;combinatorics;parallel computing;real-time computing;telecommunications;computer science;operating system;distributed computing;scheduling;algorithm	HPC	-12.594739911754383	63.596746259714614	45956
95e39290aa07f2827ff0da695c9ca368eb4245f7	prediction and control of bursty cloud workloads: a fractal framework	process variation;software error behavior;management theory algorithms design;erroneous systems;fractals mathematical model computational modeling cloud computing predictive models optimization servers;resource utilization fractal framework cloud infrastructure resource provisioning energy minimization fractal behavior cloud optimization algorithms fractional calculus concepts cloud computing workload control cloud computing workload prediction cpu memory usage fractal operator time varying fractal properties parameter estimation algorithm forecasting strategy fractal based model predictive control approach cpu utilization energy consumption networked architecture performance constraints queue capacities complex cloud computing dynamics forecasting real world cloud traces google nonfractal models bursty workload conditions bursty request processes cloud computing workload forecasting fractal model based optimization;delay faults;dynamic error estimation;resource allocation cloud computing fractals parameter estimation power aware computing predictive control;variability;variation aware timing analysis	Cloud Computing is a promising approach to handle the growing needs for computation and storage in an efficient and cost-effective manner. Towards this end, characterizing workloads in the cloud infrastructure (e.g., a data center) is essential for performing cloud optimizations such as resource provisioning and energy minimization. However, there is a huge gap between the characteristics of actual workloads (e.g., they tend to be bursty and exhibit fractal behavior) and existing cloud optimization algorithms, which tend to rely on simplistic assumptions about the workloads. To close this gap, based on fractional calculus concepts, we present a fractal model to account for the complex dynamics of cloud computing workloads (i.e., the number of request arrivals or CPU/memory usage during each time interval). More precisely, we introduce a fractal operator to account for the time-varying fractal properties of the cloud workloads. In addition, we present an efficient (online) parameter estimation algorithm, an accurate forecasting strategy, and a novel fractal-based model predictive control approach for optimizing the CPU utilization, and hence, the overall energy consumption in the system while satisfying networked architecture performance constraints like queue capacities. We demonstrate advantages of our fractal model in forecasting the complex cloud computing dynamics over conventional (non-fractal) models by using real-world cloud (Google) traces. Unlike non-fractal models, which have very poor prediction capabilities under bursty workload conditions, our fractal model can accurately predict bursty request processes, which is crucial for cloud computing workload forecasting. Finally, experimental results demonstrate that the fractal model based optimization outperforms the non-fractal based ones in terms of minimizing the resource utilization by an average of 30%.	central processing unit;cloud computing;complex dynamics;computation;data center;energy minimization;estimation theory;fractal;genetic algorithm;mathematical optimization;provisioning;tracing (software)	Mahboobeh Ghorbani;Yanzhi Wang;Yuankun Xue;Massoud Pedram;Paul Bogdan	2014	2014 International Conference on Hardware/Software Codesign and System Synthesis (CODES+ISSS)	10.1145/2656075.2656095	real-time computing;simulation;computer science;theoretical computer science	HPC	-22.72854264008929	61.87104708967948	45991
b75cfeeab048ae8d94c141dc229fe6c4323631f5	a greedy-but-safe dynamic scheduling strategy for an interactive video-on-demand server	varying playout rates;magnetic memory;admission re start delay;real time requests;greedy admission;processor scheduling;information retrieval;interactive video;real time;runtime;dynamic control;multimedia computing;greedy but safe dynamic scheduling strategy;network servers;fast initial service;streaming media;load settings;scheduling;video on demand;multimedia communication;admission re start delay greedy but safe dynamic scheduling strategy interactive video on demand server real time requests vod scheduling approaches admission control admission to start delay earliest initial service greedy admission disk accesses fast initial service buffer capacities load settings varying playout rates;multimedia computing interactive television interactive video network servers scheduling real time systems multimedia communication;buffer capacities;vod scheduling approaches;interactive television;buffer capacity;admission to start delay;interactive video on demand server;disk accesses;optical buffering;earliest initial service;dynamic scheduling delay streaming media network servers runtime throughput processor scheduling information retrieval optical buffering magnetic memory;dynamic scheduling;throughput;admission control;real time systems	We study a dynamic approach to the problem of scheduling real time requests in a video on demand server. Most of the previous VOD scheduling approaches use limited run time information, and thus cannot exploit the potential capacity fully. Our approach improves throughput by making use of run time information to relax admission control, and to reduce admission to start delay by providing earliest initial service. We establish conditions for greedy admission, dynamic control of the sequence and sizes of disk accesses, and fast initial service. We conduct thorough simulations over a wide range of buffer capacities, load settings, and over varying playout rates to demonstrate the significant improvements in throughput and admission re start delay of our approach relative to a typical static approach which does not use run time information.	greedy algorithm;scheduling (computing)	Tsun-Ping J. To;Babak Hamidzadeh	1996		10.1109/MMCS.1996.534965	throughput;real-time computing;dynamic priority scheduling;computer science;operating system;distributed computing;interactive television;scheduling;computer network	DB	-15.169293997978187	70.9208831371224	46010
101ef8bd4ea81bba0c542991527a8cb071c5f65b	verification and validation framework for 5g network services and apps		5G does not only aim at higher capacity and lower latency than current 4G in mobile broadband networks, but also to increase the level of programmability, control and flexibility to meet the requirements from innovative use cases such as IoT, smart manufacturing, and immersive media. However, several difficulties still need to be overcome for a better technological adoption. To reduce the time-to-market for networked services and to lower the entry barrier to third party developers of VNFs and network services, an integrated development and operations (DevOps) methodology is a promising way. One of the biggest challenges in upcoming 5G DevOps is the validation and verification (Vu0026V) of individual VNFs and network services (VNF graphs) so that operators can be sure of their behavior. In this paper, we propose an NFV architecture that supports the DevOps methodology with a Vu0026V platform and an advanced NFV catalogue. The conceptual components of the Vu0026V platform, the foreseen methodology and the outcomes are explained. Finally, we explore some perspectives in applying such Vu0026V approach in another 5G research project.	devops;network function virtualization;requirement;testbed;verification and validation	Mengxuan Zhao;Franck Le Gall;Philippe Cousin;Ricard Vilalta;Raúl Muñoz;Sonia Castro;Manuel Peuster;Stefan Schneider;Maria Siapera;Evgenia Kapassa;Dimosthenis Kyriazis;Peer Hasselmeyer;Georgios Xilouris;Christos Tranoris;Spyros G. Denazis;Josep Martrat	2017	2017 IEEE Conference on Network Function Virtualization and Software Defined Networks (NFV-SDN)	10.1109/NFV-SDN.2017.8169878	operator (computer programming);mobile broadband;latency (engineering);architecture;verification and validation;devops;computer network;metadata;use case;computer science	Mobile	-15.895657607173854	85.67257407934629	46057
7e00b7fa51f0132cf3085db2021e4b76add65178	inter-domain coordination models	game theory;charging and pricing qos;end to end services	In order for the Network Service Providers (NSPs) to provide end-to-end Quality of Service (QoS) at the inter-domain level different coordination models have been proposed by ETICS project. In this work we present and analyse the plausible alternatives of those models and we compare them with each other in terms of information asymmetry issues. We show that different information sets affect the total service provision and we present a basic model analysis on information issues by means of game-theoretic models.	end-to-end encryption;game theory;inter-domain;quality of service	Eleni Agiatzidou;Costas A. Courcoubetis;Olivier Dugeon;Finn Tore Johansen;George D. Stamoulis	2012		10.1007/978-3-642-30039-4_14	game theory;mobile qos;simulation;management science;computer network	AI	-24.815800762391657	75.51338831465297	46085
8c03b3fb5cb0a34652a7281d5150d7748b293452	definitions of managed objects for ieee 802.3 medium attachment units (maus)		This document defines a portion of the Management Information Base (MIB) for use with network management protocols in TCP/IP-based internets. In particular, it defines objects for managing IEEE 802.3 Medium Attachment Units (MAUs).	parallel ata	John Flick	2003	RFC	10.17487/RFC3636	the internet;ieee 802;management information base;network management;computer security;engineering	Vision	-23.701246164367394	87.96131927833913	46122
206e05373aad979b975f72cb359c758110c8ad81	qrp01-6: resource optimization subject to a percentile response time sla for enterprise computing	optimisation;electronic commerce;service provider;resource allocation;service level agreements;qos metric;satisfiability;percentile response time sla;resource use;qos metric resource optimization percentile response time sla enterprise computing service level agreements;enterprise computing;resource allocation electronic commerce optimisation quality of service;delay application software cost function network servers time factors resource management grid computing probability distribution computer science computer network management;service level agreement;quality of service;resource optimization	We consider a set of computer resources used by a service provider to host enterprise applications subject to service level agreements. We present an approach for resource optimization in such an environment that minimizes the total cost of computer resources used by a service provider for an enterprise application while satisfying the QoS metric that the response time for executing service requests is statistically bounded. That is, gamma% of the time the response time is less than a pre-defined value. This QoS metric is more realistic than the mean response time typically used in the literature. Numerical results show the applicability of the approach and validate its accuracy.	enterprise software;mathematical optimization;numerical method;response time (technology);responsiveness;service-level agreement	Kaiqi Xiong;Harry G. Perros	2006	IEEE Globecom 2006	10.1109/GLOCOM.2006.423	e-commerce;service provider;service level requirement;service level objective;real-time computing;quality of service;resource allocation;computer science;database;satisfiability	Metrics	-22.92723564265261	63.54235164456801	46150
b6df8a993f5372e2105fa3270f40529a96af85e1	physical storage organizations for time-dependent multimedia data	time dependent;continuous media;heterogeneous data;data type;satisfiability;data clustering;file system;multimedia data	Multimedia computing requires support for heterogeneous data types with differing storage, communication and delivery requirements. Continuous media data types such as audio and video impose delivery requirements that are not satisfied by conventional physical storage organizations. In this paper we describe a physical organization for multimedia data based on the need to support the delivery of multiple playout sessions from a single rotatingdisk storage device. Our model relates disk characteristics to the different media recording and playback rates and derives their storage pattern. This storage organization guarantees that as long as a multimedia delivery process is running, starvation will never occur. Furthermore, we derive bandwidth and buffer constraints for disk access and present an approach to minimize latencies for non-continuous media media stored on the same device. The analysis and numerical results indicate the feasibility of using conventional rotating magnetic disk storage devices to support multiple sessions for on-demand video applications.	access time;bandwidth (signal processing);computer data storage;data buffer;digital media;disk storage;general-purpose modeling;hard disk drive performance characteristics;intermedia (hypertext);magnetic storage;numerical analysis;overhead (computing);playout;refinement (computing);requirement;round-robin scheduling;scheduling (computing);statistical model	Huang-Jen Chen;Thomas D. C. Little	1993		10.1007/3-540-57301-1_2	data stream clustering;real-time computing;computer science;theoretical computer science;database	HPC	-15.446850459500972	70.75647329263484	46151
357d52620e0a76eed7b441bd37db4747b12a3d40	load balancing with heterogeneous schedulers		Load balancing is a common approach in web server farms or inventory routing problems. An important issue in such systems is to determine the server to which an incoming request should be routed to optimize a given performance criteria. In this paper, we assume the server’s scheduling disciplines to be heterogeneous. More precisely, a server implements a scheduling discipline which belongs to the class of limited processor sharing (LPSd) scheduling disciplines. Under LPS-d, up to d jobs can be served simultaneously, and hence, includes as special cases First Come First Served (d = 1) and Processor Sharing (d = ∞). In order to obtain efficient heuristics, we model the above load-balancing framework as a multi-armed restless bandit problem. Using the relaxation technique, as first developed in the seminal work of Whittle, we derive Whittle’s index policy for general cost functions and obtain a closed-form expression for Whittle’s index in terms of the steady-state distribution. Through numerical computations, we investigate the performance of Whittle’s index with two different performance criteria: linear cost criterion and a cost criterion that depends on the first and second moment of the throughput. Our results show that (i) the structure of Whittle’s index policy can strongly depend on the scheduling discipline implemented in the server, i.e., on d, and that (ii) Whittle’s index policy significantly outperforms standard dispatching rules such as Join the Shortest Queue (JSQ), Join the Shortest Expected Workload (JSEW), and Random Server allocation (RSA). keywords: Queuing, load balancing, restless bandits, limited processor sharing, index policies.	computation;eisenstein's criterion;heuristic (computer science);job stream;lightweight portable security;linear programming relaxation;load balancing (computing);multi-armed bandit;numerical analysis;routing;scheduling (computing);server (computing);server farm;steady state;throughput;web server	Urtzi Ayesta;Manu K. Gupta;Maaike Verloop	2018	CoRR		real-time computing;workload;throughput;scheduling (computing);web server;heuristics;load balancing (computing);computer science;processor sharing;queue	Metrics	-13.101381570841784	66.81830518895204	46293
386f28b2c4a729ca2b3789f94cac819483a21fd8	access regulation mechanism for switch-based lan	tolerancia falta;reseau metropolitain;largeur bande;arquitectura red;red local;reseau transmission donnee;fault tolerant;reseau ordinateur;local area networks lan;signal commande;access regulation;architecture reseau;access protocol;automatic stabilizer;computer network;tree fairness algorithm;metropolitan area networks man;local network;data transmission network;self stabilization;spatial bandwidth reuse;media access control;fault tolerance;anchura banda;bursty traffic;red transmision datos;red ordenador;deadlock;interbloqueo;bandwidth;deadlock freeness;control signal;network architecture;fairness algorithms;interblocage;automatic fault recovery;protocole acces;reseau local;auto stabilisation;media access control mac;red metropolitano;acceso protocolo;tolerance faute;fault recovery;metropolitan area network;local area network;switch based lans;delay bound	This paper describes a mechanism that regulates access of bursty traffic sources to a switch-based LAN. This regulation mechanism ensures global fairness, such that, within a well-defined global control cycle each node can transmit a predefined number of data units over its adjacent links, i.e., it provides deterministic access delay bound and bandwidth. The global control cycle is created over a tree that spans a network with an arbitrary topology, in contrast with previous works, in Ž . which a global control cycle was created over a ring e.g., token-ring, MetaRing . As a result, in this work the global control cycle can be shorter and the access mechanism to the network is more efficient. The regulation mechanism is based on Ž . exchanging control signals between neighboring nodes. The proposed mechanism has the following properties: i Ž . Ž . time-driven automatic stabilization, ii automatic tolerance of one control signal loss in every global control cycle, and iii only two bits of information required for the control signals. q 1999 Elsevier Science B.V. All rights reserved. Ž .	atm turbo;canonical account;clock rate;deadlock;distributed algorithm;duplex (telecommunications);error detection and correction;fairness measure;fault tolerance;local variable;message passing;network interface;real-time clock;scsi;self-balancing binary search tree;serial storage architecture;superuser;timeout (computing);timer;token ring;tree (data structure);tree structure	Yoram Ofek;Moti Yung	1999	Computer Networks	10.1016/S0169-7552(98)00291-8	local area network;fault tolerance;telecommunications;computer science;computer security;computer network	Theory	-5.390369554381086	87.831587292963	46334
079c1e15af2957f82f9f8673aae74db148cd0c8f	the convergence of machine learning and communications		The areas of machine learning and communication technology are converging. Today’s communications systems generate a huge amount of traffic data, which can help to significantly enhance the design and management of networks and communication components when combined with advanced machine learning methods. Furthermore, recently developed end-to-end training procedures offer new ways to jointly optimize the components of a communication system. Also in many emerging application fields of communication technology, e.g., smart cities or internet of things, machine learning methods are of central importance. This paper gives an overview over the use of machine learning in different areas of communications and discusses two exemplar applications in wireless networking. Furthermore, it identifies promising future research topics and discusses their potential impact.	end-to-end principle;internet of things;machine learning;smart city	Wojciech Samek;Slawomir Stanczak;Thomas Wiegand	2017	CoRR		communications system;wireless network;distributed computing;computer science;machine learning;internet of things;communications management;information and communications technology;convergence (routing);artificial intelligence	AI	-22.89375059552802	80.74893409994546	46459
1a00781e7e84c38199e035847766abc4b4831d56	analysis of scheduled latency insensitive systems with periodic clock calculus	relay station;strongly connected component;synchronous programming;delay clocks calculus throughput processor scheduling synchronization protocols lips centralized control signal design;clocks;processor scheduling;data flow graphs;complex handshake control blocks;periodic clock calculus;latency insensitive protocols;central scheduling scheme;handshaking signals;registers;synchronization;calculus;processor scheduling clocks data flow graphs;latency insensitive systems;scheduling sequences latency insensitive systems periodic clock calculus latency insensitive protocols handshaking signals complex handshake control blocks central scheduling scheme synchronous programming;scheduling problem;relays;throughput;scheduling sequences	Originally the Latency insensitive protocols (LIP) were invented to make a system elastic to the interconnect latencies using handshaking signals such as ‘valid’ and ‘stall’. These require extra signals leading to area overhead and may affect throughput of the system. To optimize away some of these overheads, scheduled LIPs were proposed which replaced the complex handshake control blocks by a central scheduling scheme. One can view a scheduled LIP based design as a system where within each strongly connected component of the system, the modules and the relay stations are scheduled by activation signals, which can be thought of as infinite sequence of ‘1’s and ‘0’s. If such sequences are periodic, one can view them as periodic clocks. Given the advances in periodic clock calculus in the synchronous programming context, in this paper, we analyze the LIP scheduling problem within the framework of periodic clock calculus. Such analysis provides straight forward algorithms to compute the throughput of scheduled LIP based systems. Within this framework, we also propose a method to synthesize fractional synchronizers. Fractional synchronizers are used to equalize cycles with different throughputs. Our method can determine the numbers and the scheduling sequences of such fractional synchronizers using the periodic clock calculus.	activation function;algorithm;almost periodic function;broadcast relay station;connected component (graph theory);handshaking;interrupt latency;marked graph;overhead (computing);scheduling (computing);simulation;strongly connected component;synchronous programming language;systems design;throughput	Bin Xue;Sandeep K. Shukla	2009	2009 IEEE International High Level Design Validation and Test Workshop	10.1109/HLDVT.2009.5340183	embedded system;job shop scheduling;synchronization;throughput;real-time computing;computer science;operating system;distributed computing;processor register;strongly connected component	Embedded	-6.606700224819498	62.468474613310406	46493
97e5e6c589feadc5d0efb334d5f4483eb3f6d9de	designing mechanisms for reliable internet-based computing	internet based master worker computation game theoretic approach;protocols;reliability;theoretical model;game theory;concurrent computing;internet based master worker computation;computational mechanism design;games computational modeling protocols resource management internet game theory reliability;resource management;distributed computing;trustworthy computations;game theoretic approach;computer networks;internet game theory;computational modeling;internet;games;trustworthy computations distributed computing mechanism design internet based computing game theory;computer science;mechanism design;grid computing;internet based computing;algorithm design and analysis	In this work, using a game-theoretic approach, cost-sensitive mechanisms that lead to reliable Internet-based computing are designed. In particular, we consider Internet-based master-worker computations, where a master processor assigns, across the Internet, a computational task to a set of potentially untrusted worker processors and collects their responses. Several game-theoretic models that capture the nature of the problem are analyzed and mechanisms that, for each given set of cost and system parameters, achieve high reliability are designed. Additionally, two specific realistic system scenarios are studied. These scenarios are a system of volunteering computing like SETI, and a company that buys computing cycles from Internet computers and sells them to its customers in the form of a task-computation service. Notably, under certain conditions, non redundant allocation yields the best trade-off between cost and reliability.	central processing unit;computation;computer;game theory;internet;search for extraterrestrial intelligence	Antonio Fernández;Chryssis Georgiou;Miguel A. Mosteiro	2008	2008 Seventh IEEE International Symposium on Network Computing and Applications	10.1109/NCA.2008.41	mechanism design;games;game theory;communications protocol;algorithm design;the internet;simulation;concurrent computing;computer science;resource management;theoretical computer science;reliability;distributed computing;computational model;grid computing;computer network	Arch	-27.7596422907344	72.55765068095225	46651
b9aa889d2a0e49503757015a42d67e956cd28d94	configuring topologies of distributed semantic concept classifiers for continuous multimedia stream processing	multimedia stream mining;semantic concept detection;resource constraint;confidence level;resource constrained mining;multimedia streaming;real time;streaming video;optimal algorithm	Real-time multimedia semantic concept detection requires instant identification of a set of concepts in streaming video or images. However, the potentially high data volumes of multimedia content, and high complexity associated with individual concept detectors, have hindered its practical deployment. In this paper, we present a new online concept detection system deployed on top of a distributed stream mining system. It uses a tree-topology of classifiers that are constructed on a semantic hierarchy of concepts of interest. We introduce a novel methodology for configuring such cascaded classifier topologies under constraints on the available resources. In our approach, we configure individual classifiers with optimized operating points after jointly and explicitly considering the misclassification cost of each end-to-end class of interest in the tree, the system imposed resource constraints, and the confidence level of each object that is classified. We describe the implemented application, system, and optimization algorithms, and verify that significant improvement in terms of accuracy of classification can be achieved through our approach.	algorithm;end-to-end principle;mathematical optimization;real-time transcription;sensor;software deployment;stream processing;streaming media	Deepak S. Turaga;Brian Foo;Olivier Verscheure;Rong Yan	2008		10.1145/1459359.1459398	confidence interval;computer science;theoretical computer science;operating system;machine learning;pattern recognition;data mining;world wide web	ML	-26.420640982354875	69.97541390331689	46737
758a76915334cb3658f5f8350f2cef7025899da5	an adaptive compressive sensing scheme for network tomography based fault localization	telecommunication traffic compressed sensing internet telecommunication network reliability;extraterrestrial measurements monitoring tomography compressed sensing quality of service sparse matrices convergence;adaptive algorithms network tomography fault localization compressive sensing;traffic load monitoring adaptive compressive sensing scheme network tomography fault localization scalable network fault localization scheme anomalies detection end to end measurements adaptive measurement data inference gilbert elliott loss model internet topologies planet lab infrastructure	A scalable network fault localization scheme based on compressive sensing is proposed. Aimed at large networks, the proposed scheme monitors a network with a few paths covering the network, and upon detection of anomalies in one or more paths, adaptively carries out additional end-to-end measurements to localize the faulty links. Each adaptive measurement covers a set of links identified based on the previous resolution. The scheme is highly scalable as the total number of measurements required grows logarithmically with the number of links in the network - a level of scalability not practically achieved for network data inference with compressive sensing so far. The scheme is tested on realistic Internet topologies with Gilbert-Elliott loss model calibrated with measurements made on Planet-Lab infrastructure. Results indicate that the converged solution of the proposed scheme achieves over 99% detection rates and less than 1% false positive rates. The proposed scalable scheme is accurate in terms of detection, cost effective in terms of implementation, and casts a minimal monitoring traffic load.	compressed sensing;end-to-end principle;scalability;tomography;type conversion	Vidarshana W. Bandara;Anura P. Jayasumana;Rick Whitner	2014	2014 IEEE International Conference on Communications (ICC)	10.1109/ICC.2014.6883499	telecommunications;computer network	Mobile	-8.720024328337127	80.3702632521713	46846
2864a52d570036d591798954933c02efa259a5c6	performance of atm traffic in optical cdma	vp cross connect;optical prime code;optical cdma;atm	Abstract#R##N##R##N#An ATM transit switch is proposed based on direct sequence optical code division multiple access technique. No buffering is necessary to facilitate the switching. Code conversion is used instead to emulate the switching function. The switch not only provides asynchronous access to the users but also has a limited capability of dynamic bandwidth allocation. It is free from timing jitters and switching delay is significantly reduced. A look-up table is employed in the switching and updated through network management functions. The switch provides a new approach to asynchronous cross-connection in the ATM core network. The performance of the new switch is evaluated by a set of prime codes and modified prime codes. Copyright © 2001 John Wiley & Sons, Ltd.	atm turbo	Liren Zhang;Chih-Hong Eyoh;Chee Hock Ng	2001	Int. J. Communication Systems	10.1002/dac.507	real-time computing;optical burst switching;telecommunications;computer science;cut-through switching;atmosphere;computer network	HPC	-6.621947618838241	87.54139134133361	46869
7828e006dfd4ffc0c0674851a43208f4f0e8c4e5	mtorrent: a multicast enabled bittorrent protocol	internet links;stress;data transmission;protocols;mtorrent protocol;multicast enabled bittorrent protocol;multicast protocols internet unicast stress access protocols data communication large scale systems delay usa councils prototypes;ip multicast;multicast protocols internet ip networks local area networks;lan;internet links mtorrent protocol multicast enabled bittorrent protocol data transmission emulab network lan traffic load;large scale;servers;internet;multicast protocols;bittorrent;traffic load;ip networks;emulab network;local area networks;unicast	In this paper we address the problem of repetitive data transmission in BitTorrent. and propose a new protocol called MTorrent to restrict the same by exploiting IP Multicast functionality wherever available. A prototype system of our protocol have been implemented, and large scale measurement studies were conducted over Emulab network consisting of 44 nodes, spread over 9 LANs and 36 end clients. MTorrent leads to 44% reduction in download time, 65% reduction in traffic load on the Internet links and 40% reduction in download of redundant packets when compared to the BitTorrent. MTorrent is interoperable with BitTorrent, and requires only a few changes at the client end.	bandwidth (signal processing);bitcomet;bittorrent;digital distribution;download;experiment;file sharing;internet;interoperability;megabyte;multicast;network packet;peer-to-peer;prototype;simulation;standards-compliant;vuze;www;µtorrent	Piyush Agrawal;Hitesh Khandelwal;Ratan K. Ghosh	2010	2010 Second International Conference on COMmunication Systems and NETworks (COMSNETS 2010)	10.1109/COMSNETS.2010.5431979	local area network;bittorrent;bittorrent protocol encryption;computer science;distributed computing;bittorrent tracker;internet privacy;computer network	HPC	-12.091536165381942	76.49823507534325	46917
4b6d7db9f1e1cdf1b0a81d2c329c1ce435e17bc2	iterative auction based service selection for multi-tenant service-based systems	service selection;multi tenancy;service based systems;iterative auction;cloud computing	With the benefit of improving the utilization of hardware resources and the convenience of maintenance by sharing one application instance among multiple tenants, multi-tenancy has become a major paradigm in cloud computing. And with the increasing of individual and diverse requirements of tenants, service selection for multi-tenant service-based systems (SBSs) has become a complex question. However, traditional service selection approaches for multi-tenant SBSs fail to fully consider the competition among service providers to increase the possibility of finding an optimal solution. In this paper, we propose a novel iterative auction based service selection for multiple tenants (IASSMT). During the auction, the auctioneer of multi-tenant SBSs aims at finding an optimal solution that can satisfy all multi-dimensional quality constraints of tenants based on the received bids. Besides, service providers can rebid to obtain more chances of winning by iterations. The results of experimental simulation show that IASSMT can significantly increase the success rate over the existing approaches in finding an optimal solution. Meanwhile, the efficiency (the number of auction rounds and computational time) is satisfactory on different scales.	capability maturity model;cloud computing;computation;iteration;moe;mathematical optimization;multitenancy;nonlinear system;programming paradigm;requirement;simulation;time complexity	Yunxiang Zhong;Xuejun Li;Qiang He	2017		10.1145/3014812.3014858	marketing;operations management;business;commerce	AI	-22.117989141387117	65.06124511917818	46921
e3fefc9c992c6e9992fe17dd1d0e914f11525f46	an anomaly recognition and autonomic optimization method to user’s sequence behaviors for d2d communications in mcc		Mobile cloud computing uses cloud computing to deliver applications to mobile devices. These applications can be delivered among different devices with different operating systems, computing tasks, and data storage capabilities, adopting D2D communication mode. However, because the application delivery process covers three entities, namely user-environmental-service, trusted problems are ubiquitous. Therefore, before cloud provides substantive services, how to identify the trusted degree of user identity and its behaviors for D2D communications is the core problem. First, from the perspective of user trustability, this paper proposed an analysis method to user abnormal behaviors for D2D communications in mobile cloud environment. In this method, user behavior is normalized to a “user sequence operation” identity fragment with the same length, offset, and amplitude. The hierarchical matching method and the blacklist mechanism are used to determine whether the user behavior for D2D communications is beyond the scope of trusted tolerance. Second, considering that the user sequence behavior step is a complex graph structure with continuous dynamic growth, this paper proposed a pattern growth method based on maximum and right-most path extension for autonomous optimization. At last, the experimental results showed that the classification accuracy under the KDD CUP99 data set and real network environment was 94.8% and 90.2%, respectively, which was 5.3% and 6.9% higher than the traditional methods. In addition, it can be seen from the experimental results that this scheme could significantly improve the recognition speed.	anomaly detection;application streaming;autonomic computing;autonomous robot;computer data storage;data mining;entity;mathematical optimization;microelectronics and computer technology corporation;mobile cloud computing;mobile device;operating system	Ruijuan Zheng;Junlong Zhu;Mingchuan Zhang;Qingtao Wu;Ruoshui Liu;Kang Liu;Jing Chen	2018	IEEE Access	10.1109/ACCESS.2018.2877423	anomaly detection;mobile cloud computing;cloud computing;normalization (statistics);blacklist;offset (computer science);computer science;mobile device;distributed computing;computer data storage	Mobile	-29.328356660368573	67.06663808484046	46922
cc7d2f7b45ef2bb3b1eb35f7662b485503f06dea	multipath restoration and bitrate squeezing in sdn-based elastic optical networks [invited]	efficient;bitrate squeezing;flexgrid optical networks;multipath restoration;article;software defined network	Sliceable bandwidth-variable transponders (SBVTs) enable the adaptation of transmission parameters according to traffic requirements and network constraints. In this study, SBVTs capabilities are evaluated in the context of restoration. In particular, multipath recovery and bitrate squeezing are applied to maximize the amount of restored bitrate, also exploiting limited portions of spectrum resources along multiple routes. An integer linear programming model and heuristic strategy are proposed. A software defined network (SDN) architecture is then introduced to adequately support the SBVT configuration. The SDN architecture is applied to experimentally assess that the overall re-configuration time upon failure detection is included within two seconds, largely dominated by the proprietary control of bandwidth-variable optical cross-connects. Finally, extensive simulation results show the relevant restoration capabilities achieved by the proposed multipath recovery and bitrate squeezing scheme.	circuit restoration;experiment;heuristic;image restoration;integer programming;linear programming;multipath propagation;programming model;propagation constant;requirement;simulation;software-defined networking;transponder	Francesco Paolucci;Alberto Castro;Filippo Cugini;Luis Velasco;Piero Castoldi	2014	Photonic Network Communications	10.1007/s11107-014-0444-4	real-time computing;simulation;telecommunications;computer science;software-defined networking;computer network	Mobile	-8.496905852398505	84.31363624820388	46992
487686b3acc3355c4513f3de9ee434a4927e52ee	path-protection routing and wavelength assignment (rwa) in wdm mesh networks under duct-layer constraints	optical network;wavelength routing;telecommunication network reliability;wavelength division multiplexing wdm;network performance path protection routing wdm mesh networks duct layer constraints routing and wavelength assignment wavelength division multiplexing fault management optical mesh network fiber cuts primary path backup path duct disjoint paths single duct failures off line algorithms static traffic integer linear programs heuristic algorithm;network topology wavelength division multiplexing telecommunication network routing telecommunication network reliability telecommunication traffic optical fibre networks integer programming linear programming;network topology;optical fibre networks;protection;telecommunication traffic;integer linear program ilp;telecommunication network routing;integer programming;routing and wavelength assignment;lightpath;linear programming;mesh network;wavelength routing wavelength assignment wavelength division multiplexing wdm networks mesh networks optical fiber networks ducts protection earthquakes telecommunication traffic;fault management;integer linear program;shared risk link group;heuristic algorithm;wavelength division multiplexing;wavelength division multiplex	This study investigates the problem of fault management in a wavelength-division multiplexing (WDM)-based optical mesh network in which failures occur due to fiber cuts. In reality, bundles of fibers often get cut at the same time due to construction or destructive natural events, such as earthquakes. Fibers laid down in the same duct have a significant probability to fail at the same time. When path protection is employed, we require the primary path and the backup path to be duct-disjoint, so that the network is survivable under single-duct failures. Moreover, if two primary paths go through any common duct, their backup paths cannot share wavelengths on common links. This study addresses the routing and wavelength-assignment problem in a network with path protection under duct-layer constraints. Off-line algorithms for static traffic is developed to combat single-duct failures. The objective is to minimize total number of wavelengths used on all the links in the network. Both integer linear programs and a heuristic algorithm are presented and their performance is compared through numerical examples.	algorithm;assignment problem;backup;fiber (computer science);heuristic (computer science);linear programming;mesh networking;numerical analysis;optical mesh network;path protection;routing and wavelength assignment;wavelength-division multiplexing	Hui Zang;Canhui Ou;Biswanath Mukherjee	2003	IEEE/ACM Trans. Netw.	10.1109/TNET.2003.810313	heuristic;integer programming;telecommunications;computer science;linear programming;mesh networking;fault management;distributed computing;network topology;wavelength-division multiplexing;computer network	Metrics	-6.148706140821724	81.61851519716011	47002
3dd566d76de5247131ba052bb0c28adddf795c25	on the schedulability analysis for distributed hard real-time systems	distributed algorithms;distributed system;processor scheduling;rate monotonic analysis;distributed computing;concurrency control processor scheduling real time systems distributed algorithms;schedulability analysis;elementary actions;distributed hard real time systems;upper bound;computer architecture;local deadlines;rate monotonic analysis techniques;hard real time system;concurrency control;system testing;elementary actions schedulability analysis distributed hard real time systems rate monotonic analysis techniques worst case response times local response times local deadlines;pattern analysis;local response times;worst case response time;algorithm design and analysis;real time systems delay processor scheduling system testing upper bound timing pattern analysis distributed computing algorithm design and analysis computer architecture;worst case response times;real time systems;timing	___________________ This work has been supported in part by the Comisión Interministerial de Ciencia y Tecnología of the Spanish Government, under Grant TAP94-996 In this paper we investigate into the validity of the Rate Monotonic Analysis techniques for distributed hard real-time systems. A recent paper has shown that the algorithm developed by Tindell and Clark for the analysis of this kind of system was incomplete because it did not test all the possible cases. We will prove that the algorithm is valid as it is stated and that it effectively obtains an upper bound for the worst-case response times to external events in distributed systems, since the longest response always occurs within the cases that are currently tested by this algorithm. In addition, we will extend the analysis technique to determine an upper bound for the local response times of particular actions in a response to an event, thus allowing the definition and verification of local deadlines for elementary actions in distributed systems.	algorithm;best, worst and average case;distributed computing;job stream;numerical analysis;real-time clock;real-time computing;scheduling analysis real-time systems	J. Carlos Palencia;J. Javier Gutiérrez;Michael González Harbour	1997		10.1109/EMWRTS.1997.613774	algorithm design;distributed algorithm;parallel computing;real-time computing;computer science;concurrency control;distributed computing;upper and lower bounds;system testing	Embedded	-9.826526623239397	61.395003814047094	47007
f6fb0c0bdcebb4e84a308d6811a315abb58eb228	ip address location privacy and mobile ipv6: problem statement		In this document, we discuss location privacy as applicable to Mobile#N#IPv6. We document the concerns arising from revealing a Home Address#N#to an onlooker and from disclosing a Care-of Address to a#N#correspondent. This memo provides information for the Internet#N#community.	geolocation software;mobile ip	Rajeev Koodli	2007	RFC	10.17487/RFC4882	geography;ip address management;internet privacy;world wide web;computer security	Mobile	-25.159750145426614	87.25070222308379	47046
2648c3271b5efbef6337719d5d148f85912355d3	transparent interconnection of lots of links (trill) use of is-is		The IETF has standardized the Transparent Interconnection of Lots of#N#Links (TRILL) protocol, which provides transparent Layer 2 forwarding#N#using encapsulation with a hop count and IS-IS link state routing.#N#This document specifies the data formats and code points for the IS-IS#N#extensions to support TRILL. [STANDARDS-TRACK]	interconnection	Donald E. Eastlake;Tissa Senevirathne;Anoop Ghanwani;Dinesh G. Dutt;Ayan Banerjee	2014	RFC	10.17487/RFC7176	telecommunications;engineering;computer security;computer network	Robotics	-23.66273849109119	88.4050414931434	47080
1276ae231c4db0c40c67b4fdcdee8b179cf92336	distributed evaluation of continuous equi-join queries over large structured overlay networks	protocols;dis tributed hash table;query processing;structured overlay network;continuous query;distributed computing;traffic control;null;satisfiability;computer networks;telecommunication traffic;monitoring;network traffic;indexation;overlay network;ip networks;relational databases;experimental evaluation;query processing peer to peer computing ip networks relational databases monitoring protocols computer networks distributed computing telecommunication traffic traffic control;peer to peer computing;simulation environment	We study the problem of continuous relational query processing in Internet-scale overlay networks realized by distributed hash tables. We concentrate on the case of continuous two-way equi-join queries. Joins are hard to evaluate in a distributed continuous query environment because data from more than one relations is needed, and this data is inserted in the network asynchronously. Each time a new tuple is inserted, the network nodes have to cooperate to check if this tuple can contribute to the satisfaction of a query when combined with previously inserted tuples. We propose a series of algorithms that initially index queries at network nodes using hashing. Then, they exploit the values of join attributes in incoming tuples to rewrite the given queries into simpler ones, and reindex them in the network where they might be satisfied by existing or future tuples. We present a detailed experimental evaluation in a simulated environment and we show that our algorithms are scalable, balance the storage and query processing load and keep the network traffic low.	algorithm;distributed hash table;hash function;locality of reference;network packet;network traffic control;overlay network;relational database;rewrite (programming);sql;scalability;virtual reality	Stratos Idreos;Christos Tryfonopoulos;Manolis Koubarakis	2006	22nd International Conference on Data Engineering (ICDE'06)	10.1109/ICDE.2006.50	communications protocol;overlay network;relational database;computer science;theoretical computer science;data mining;database;distributed computing;satisfiability	DB	-16.821418788062093	68.33866027764897	47089
01276552ff4f057b0ea5cf318b2c97e029429273	energy efficient cache invalidation in a disconnected mobile environment	batterie;largeur bande;wireless channels;secondary cell;informatique mobile;huesped movile;maintenance;acumulador electroquimico;energy efficient;availability;disponibilidad;interrogation base donnee;distributed computing;mobile host;interrogacion base datos;cache memory;antememoria;battery;mobile environment;antememoire;bateria;internet;hote mobile;energy consumption;accumulateur electrochimique;diffusion donnee;anchura banda;difusion dato;consommation energie;mantenimiento;calculo repartido;bandwidth;data broadcast;wireless data;mobile computing;energy simulation;disponibilite;calcul reparti;database query;consumo energia	Caching at mobile host is a prominent technique for improving the performance of wireless data dissemination It can reduce number of uplink requests, server load, query latency and can increase data availability A cache invalidation strategy ensures that cached data in a host has same value as on the origin server Due to battery energy constraints of mobile host and unreliable limited bandwidth over the wireless channel, the host may disconnect from the server Frequent disconnections of a host add many challenges to the cache invalidation process In this paper, we present a Synchronous Stateful (SS) cache maintenance strategy with the objectives to minimize the overheads for mobile hosts to validate their cache on reconnection, reduce the use of wireless channel and conserve the host energy Simulation experiments are performed to evaluate the proposed strategy and compare it with Asynchronous Stateful (AS) scheme Results show that our strategy performs better in terms of reconnection overheads, bandwidth utilization and host energy consumption.	cache invalidation	Narottam Chand;Ramesh Chandra Joshi;Manoj Misra	2004		10.1007/978-3-540-30555-2_11	embedded system;availability;real-time computing;the internet;cpu cache;cache;computer science;cache invalidation;operating system;database;distributed computing;efficient energy use;mobile computing;cache algorithms;computer security;bandwidth;battery;computer network	EDA	-14.170998724432566	69.01733351532948	47127
9594e49a66347244e9e6bb1252087ec8ef14ce8f	static protection against single multicast resource failure	multicast network protection optical wdm networks resource failure survivability;topology;integer linear programming;measurement;optical wdm network static protection single multicast resource code failure data transmission multicast request integer linear programming ilp routing and wavelength assignment problem rwa problem redundancy;optical fiber networks;wavelength division multiplexing data communication integer programming linear programming multicast communication redundancy telecommunication network reliability wavelength assignment;network topology;topology optical fiber networks network topology measurement bandwidth adaptive optics integer linear programming;bandwidth;adaptive optics	The multicast paradigm offers tremendous benefits in efficiency for transmitting data across optical networks, allowing a single client to send information to an entire set of endpoints. A multicast request is most efficiently provisioned through the creation of a tree, with the end points, or resources, occasionally serving as branching points. This practice can lead to the source of the request becoming disconnected from the associated resources should one of those branching resources fail. We propose an optimal solution through Integer Linear Programming (ILP) for the static protected multicast Routing and Wavelength Assignment (RWA) problem, where an entire set of requests are provisioned with built-in redundancy against single resource node failure. We compare the optimal performance against several heuristics, and find that protection against this type of failure can be provided without excessive wavelength consumption.	backup;best, worst and average case;blocking (computing);canonical account;cloud computing;clustered file system;dynamic problem (algorithms);heuristic (computer science);integer programming;international federation for information processing;linear programming;multicast;multipoint ground;point-to-multipoint communication;programming paradigm;provisioning;routing and wavelength assignment;simulation;statistical model;streaming media;time complexity;transmitter;wavelength-division multiplexing	Dylan A. P. Davis;Vinod Vokkarane	2015	2015 International Conference on Optical Network Design and Modeling (ONDM)	10.1109/ONDM.2015.7127280	real-time computing;multicast;integer programming;inter-domain;protocol independent multicast;computer science;pragmatic general multicast;distributed computing;distance vector multicast routing protocol;source-specific multicast;adaptive optics;network topology;bandwidth;xcast;measurement;computer network;multicast address	HPC	-6.881449782420406	81.2409970403505	47220
a44e3d340792e3c6c5d6702befa308722124a02c	the continuous stream model of computation for real-time control	continuous systems;probability;system stabilisation continuous stream model of computation real time control moc control system continuous stream task model real time task model probabilistic evolution delays necessary conditions sufficient conditions stochastic stability closed loop system cpu bandwidth;closed loop systems;stochastic processes closed loop systems continuous systems delays probability stability;embedded control;stability;embedded control real time systems;stochastic processes;computational modeling delays sensors mathematical model predictive models time factors processor scheduling;delays;real time systems	This paper presents a new Model of Computation (MoC) for real-time tasks used in control systems. This new model, named continuous stream task model, relaxes some of the constraints imposed by the traditional hard and soft real-time task models. A key advantage of the model is the possibility to easily analyse the probabilistic evolution of the delays. This leads to an easy formalisation of necessary and sufficient conditions for the stochastic stability of the closed loop system producing considerable savings in the amount of CPU bandwidth required to stabilise the system. This fact is confirmed by an extensive set of simulations.	automated planning and scheduling;central processing unit;closed-loop transfer function;control system;model of computation;randomness;real-time clock;real-time transcription;simulation	Daniele Fontanelli;Luigi Palopoli;Luca Abeni	2013	2013 IEEE 34th Real-Time Systems Symposium	10.1109/RTSS.2013.23	stochastic process;real-time computing;stability;computer science;probability	Embedded	-9.179100543330023	61.65645762074033	47266
0d8ee56a29fd2f04f29aaa11e0dd2b37da520f45	profiling computation jobs in grid systems	probability;job arrival process;job execution times;null;job interarrival times;waiting times;probabilistic model;job execution times computation jobs profiling grid systems job arrival process job characteristics job interarrival times waiting times grid infrastructure;grid computing distributed computing computer networks predictive models computer architecture processor scheduling informatics queueing analysis resource management supercomputers;waiting time;long range dependent;grid infrastructure;probability grid computing;grid systems;hurst parameter;grid computing;computation jobs profiling;grid system;job characteristics	The existence of good probabilistic models for the job arrival process and job characteristics is important for the improved understanding of grid systems and the prediction of their performance. In this study, we present a thorough analysis of the job inter-arrival times, the waiting times at the queues, the execution times, and the data sizes exchanged at the kallisto.hellasgrid.gr cluster, which is part of the EGEE Grid infrastructure. By computing the Hurst parameter of the inter-arrival times we find that the job arrival process exhibits self-similarity/long-range dependence. We also propose simple and intuitive models for the job arrival process and the job execution times. The models proposed were validated and were found to be in very good agreement with our empirical measurements.	computation;grid systems corporation;hurst exponent;pareto efficiency;self-similarity;stepwise regression;the times;three-state logic;time complexity;traffic analysis	Michael Oikonomakos;Konstantinos Christodoulopoulos;Emmanouel A. Varvarigos	2007	Seventh IEEE International Symposium on Cluster Computing and the Grid (CCGrid '07)	10.1109/CCGRID.2007.87	statistical model;parallel computing;real-time computing;computer science;probability;distributed computing;hurst exponent;job queue;grid computing;statistics	HPC	-12.128504129140868	66.76761125324016	47325
9623324d7dc9b0281e601b904327bd9a6235658f	an integrated scheduling and buffer management scheme for input queued switches with finite buffer space	gestion integrada;memoria tampon;gestion integree;gestion memoire;memory management;resource allocation;memoria finita;storage management;resource management;buffer management;integrated management;algorithme deterministe;maximum weight matching;buffer system;sistema amortiguador;gestion recursos;deterministic algorithms;gestion memoria;scheduling algorithm;scheduling;gestion ressources;conmutador;asignacion recurso;input queued switch;allocation ressource;systeme tampon;switches;memoire tampon;finite memory;memoire bornee;ordonnancement;reglamento;commutateur;selector switch;buffer memory	This paper addresses scheduling and memory management in input queued switches having finite buffer with the objective of improving the performance in terms of throughput and average delay. Most of the prior works on scheduling related to input queued switches assume infinite buffer space. In practice, buffer space being a finite resource, special memory management scheme becomes essential. Maximum weighted matching (MWM) algorithm, which is known to be the optimal in terms of throughput for infinite buffer case turns out to be sub optimal in the presence of memory limitations. We introduce a buffer management scheme called iSMM (Integrated Scheduling and Memory Management) that can be employed jointly with any deterministic iterative scheduling algorithm. We applied iSMM over iSLIP, a popular scheduling algorithm, and study its effect under various input traffic conditions. Simulation results indicate iSMM to perform better than iSLIP and MWM both in terms of throughput and delay especially under non-uniform traffic. Finally, we show that the scheme is easy-to-implement and has negligible impact on the switching speed.	network switch;scheduling (computing)	Anuj Kumar;Rabi N. Mahapatra	2005	Computer Communications	10.1016/j.comcom.2005.03.006	real-time computing;telecommunications;computer science;resource management;operating system;distributed computing;scheduling	DB	-10.938336419705857	61.600458428508006	47368
855106e9cc6cb3816b088ff44b3492902deaeec1	on the complexity of worst-case blocking analysis of nested critical sections	schedules program processors bismuth real time systems analytical models delays optimization;reachability problem worst case blocking analysis classic sporadic task model recurrent real time systems fifo ordered locks priority ordered locks multiprocessors multiple choice matching problem suspension based locks spin based locks partitioned scheduling global scheduling np hard problem polynomial time;multiprocessor;real time;complexity;np hardness;real time systems computational complexity multiprocessing systems processor scheduling reachability analysis;blocking analysis;real time blocking analysis nested locks np hardness complexity multiprocessor;nested locks	Accurately bounding the worst-case blocking for finite job sets, a special case of the classic sporadic task model of recurrent real-time systems, using either nested FIFO-or priority-ordered locks on multiprocessors is NP-hard. These intractability results are obtained with reductions from the Multiple-Choice Matching problem. The reductions are quite general and do not depend on (1) whether the locks are spin-or suspension-based, or (2) whether global or partitioned scheduling is used, or (3) which scheduling policy is employed (as long as it is work-conserving). Further, we show that, for a special case in which the blocking analysis problem is NP-hard for FIFO- and priority-ordered locks, the problem for unordered spin locks with nested critical sections can be answered in polynomial time by solving a reach ability problem on a suitably constructed graph, although (or rather, because) unordered locks do not offer any acquisition-order guarantees. Finally, we identify several challenging open problems, pertaining both to circumventing the hardness results and to classifying the inherent difficulty of the problem more precisely.	best, worst and average case;blocking (computing);critical section;fifo (computing and electronics);lock (computer science);np-hardness;polynomial;real-time clock;real-time computing;scheduling (computing);time complexity	Alexander Wieder;Björn B. Brandenburg	2014	2014 IEEE Real-Time Systems Symposium	10.1109/RTSS.2014.34	parallel computing;complexity;real-time computing;multiprocessing;computer science;distributed computing;algorithm	Embedded	-10.226561869043476	61.13131903635265	47397
00b889ac3f6bbe725f899578613b193f38fe0d0f	multimedia file systems survey: approaches for continuous media disk scheduling	multimedia file systems;continuous media;disk scheduling	We understand multimedia data processing as the handling of audio and video data together with traditional data like text and images. This multimedia data is to be stored with and by a multimedia file system which comprises one or more of the following three issues: (1) The file system can rely on various types of different physical storage devices; however, we usually encounter the same devices as in any other high performance computers; (2) the organization of files in a contiguous order and the data structuring with ropes and strands improves the throughput at the expense of additional management effort; (3) the main goal of traditional disk scheduling is to reduce the cost of seek operations, to achieve a high throughput, and to provide a fair disk access. In multimedia disk scheduling the main goal is to meet all deadlines of the time critical tasks. The buffer requirement should be kept low, and aperiodic requests should not starve, i.e. a balance between the time constraints and efficiency must be found. This paper presents a survey of these three issues, with the focus on disk scheduling. It shows how the traditional disk scheduling techniques 'first come first serve', 'shortest seek time first', SCAN and C-SCAN are enhanced or substituted by EDF, SCAN-EDF, 'group sweeping scheduling', a 'mixed strategy' and a 'continuous media file system' approach.	i/o scheduling;scheduling (computing)	Ralf Steinmetz	1995	Computer Communications		high-throughput screening;embedded system;real-time computing;data structure;computer science;stub file;operating system;distributed computing;strategy;data file;file system fragmentation;computer security;i/o scheduling;computer network	OS	-15.034216145372678	70.49675473268064	47442
8b7b52126b9f3134910675a94d16c39b066f53d4	practical criteria for scheduling cpu-bound jobs in mobile devices at the edge		The ubiquity of mobile devices, their strong computational capabilities -frequently underused by the owners- and their close relationship to IoT environments, make them valuable providers of computing power at the edge, i.e. as an aid to deal with remote computing servers high-delay communication. Then, researchers have proposed to take advantage of the connection regularity of groups of mobile devices to fixed wireless networking infrastructures, e.g., access points, to scavenge mobile computing resources. However, among the key concerns to achieve such exploitation in an efficient way is providing new scheduling criteria for computations able to deal with the challenges posed by mobile devices finite energy sources. The value of considering battery-related parameters for ranking devices capabilities against not using them has been hardly investigated in the literature. Then, in this paper, we analyze several job scheduling criteria and provide statistical evidence that support our findings. The experiments are performed via a simulation software that employs energy consumption traces derived from real mobile devices, hence practical utility is ensured.	central processing unit;cloud computing;computation;experiment;job scheduler;mobile computing;mobile device;scheduling (computing);simulation software;tracing (software);wireless access point	Matías Hirsch;Cristian Mateos;Alejandro Zunino	2018	2018 IEEE International Conference on Cloud Engineering (IC2E)	10.1109/IC2E.2018.00065	mobile edge computing;job scheduler;scheduling (computing);mobile device;mobile computing;fixed wireless;server;cpu-bound;computer science;distributed computing	Mobile	-24.627971288885078	67.42409670241426	47456
7260e33677c12728dd5c507db7c6d65b263b1a7a	towards a communication network model generator for evaluating smart grid applications	topology;generators;communication networks;network topology;smart grids;fans	In the past, various communication infrastructures and networks, network technologies and topologies, and protocols have been discussed to intelligently interconnect nodes across electric power distribution networks forming a smart grid. Similarly, attempts to esteem bandwidth requirements of smart grid applications under different assumptions were made, by applying models such as the queuing theory. The present paper aims at presenting a conceptual model allowing for the generation and simulation of characteristic communication networks, as part of the communication infrastructure of electric power distribution grids. Feasible input parameters are discussed and fields, where simulation can be used, are presented.	algorithm;network model;queueing theory;requirement;routing;simulation;telecommunications network	Rene Dapra;Christof Brandauer;Filip Prostl Andren;Thomas I. Strasser	2016	2016 IEEE 21st International Conference on Emerging Technologies and Factory Automation (ETFA)	10.1109/ETFA.2016.7733638	embedded system;computer science;theoretical computer science;distributed computing;smart grid;network topology;computer network	EDA	-21.039207862909542	80.70025781187091	47481
ea7c2c2fbd157eb272dc5ddf8f1b167997f397b9	electric power data acquisition system based on multi-thread mechanism	multi threading;electric power data acquisition system;real time;power systems;data acquisition message systems servers real time systems monitoring power systems ip networks;monitoring thread;power grids data acquisition multi threading power engineering computing;servers;power engineering computing;monitoring;large scale data acquisition electric power data acquisition system multithread mechanism multithread scheduling strategy connection reliability;message systems;monitoring thread electric power data acquisition system real time multi thread mechanism scheduling startegy;ip networks;scheduling startegy;multi thread mechanism;power grids;data acquisition;real time systems	An electric power data acquisition system based on multi-thread mechanism is proposed in this paper to solve the problems of large-scale data acquisition such as low acquisition rate, server overload and poor reliability of the IP address of data nodes. Through designing a multi-thread scheduling strategy, the power data can be acquired from multiple data nodes concurrently. The reliability of the connection between the system and a data node can be assured through a monitoring thread. An experiment system of data acquisition from 100 data nodes is designed. The data acquisition rate is 1832 per minute and data update cycle is 30 seconds approximately. The results show that efficient data acquisition can be achieved in large-scale network and the electric power data can be guaranteed to be real-time. The system has met the requirements of the customer and officially run.	data acquisition;real-time clock;requirement;scheduling (computing);server (computing);thread (computing)	Yuzhu Peng;Fanchao Meng;Dianhui Chu	2013	2013 International Conference on Cyber-Enabled Distributed Computing and Knowledge Discovery	10.1109/CyberC.2013.53	embedded system;real-time computing;multithreading;computer science;operating system;database;electric power system;data acquisition;server;computer network	Robotics	-28.065012887806585	65.56393922635	47504
8c5b66b54e6514ef749f0376469af7cfe6f4500c	capu: enhancing p2p file sharing system with capacity aware topology	sensibilidad contexto;estensibilidad;modelizacion;distributed system;estimacion sesgada;algoritmo paralelo;virtual network;optimisation;systeme reparti;context aware;parallel algorithm;algoritmo busqueda;optimizacion;redundancia;algorithme recherche;par a par;proactive service;search algorithm;multidestinatario;distributed computing;recherche aleatoire;p2p;partage fichier;probabilistic approach;algorithme parallele;particion fichero;modelisation;sistema repartido;sevicio proactivo;redundancy;poste a poste;heterogeneidad;random walk;enfoque probabilista;approche probabiliste;indexation;retard;investigacion aleatoria;calculo repartido;optimization;file sharing;extensibilite;scalability;marcha aleatoria;sensibilite contexte;retraso;peer to peer;modeling;biased estimation;random search;calcul reparti;estimation biaisee;multidestinataire;marche aleatoire;red virtual;redondance;multicast;heterogeneity;service proactif;heterogeneite;reseau virtuel	Measurement works show that the unstructured P2P file sharing systems such as Gnutella face the problem of poor scalability and inefficiency search for unpopular items. In this paper, we propose new mechanisms that greatly enhance the performance of file sharing system. Our work exploits the prevalent heterogeneity of the nodes in existing unstructured networks in terms of capacity to construct a quasi-hierarchical topology-aware topology which achieves approximately optimal system throughput. Based on this overlay topology, we propose proactive file index propagation scheme to facilitate search. We also introduce a two-stage search algorithm integrate probabilistic biased random walk that search for popular items and low-redundant multicast (MPR) searching for rare items, achieving approximately O(1) search efficiency for popular items and receivable search latency for rare items respectively. We evaluate our design through simulations and the results show 3 to 5 orders of magnitude improvement in total system capacity compared to other Gnutella-like system.	file sharing	Hongliang Yu;Weimin Zheng;Dongsheng Wang;Haitao Dong;Lu Li	2005		10.1007/11573937_24	multicast;scalability;simulation;random search;systems modeling;computer science;artificial intelligence;heterogeneity;peer-to-peer;database;distributed computing;parallel algorithm;redundancy;file sharing;random walk;statistics;search algorithm	HCI	-11.611353004197667	70.33790300483827	47627
f6eb87b57f6710af7dba1d290056ceb6e8926aee	availability analytical model for permanent dedicated path protection in wdm networks	blocking probability;analytical models;wdm network;probability;telecommunication network reliability;dedicated path protection;availability analytical model;availability;simulation;optical fiber networks;network simulator;network blocking probability availability analytical model permanent dedicated path protection wdm mesh networks cost239 european network;optical fibre networks;accuracy;connection availability;network blocking probability;wdm mesh networks;permanent dedicated path protection;mesh networks;wdm networks;mesh network;wdm mesh networks connection availability dedicated path protection permanent dedicated path protection;wavelength division multiplexing optical fibre networks probability telecommunication network reliability;optical fiber;cost239 european network;analytical model;availability analytical models optical fiber networks simulation wdm networks mesh networks accuracy;wavelength division multiplexing	This paper analyses the connection availability of a protection paradigm, termed permanent dedicated path protection (P-DPP), in WDM mesh networks. An analytical model for calculating the unavailability of P-DPP is introduced. Numerical results on COST239 European network show that the average unavailability of the network is proportional to blocking probability of the network, and fits well with the simulation results.	blocking (computing);digital photo professional (dpp);erlang (unit);fits;mesh networking;numerical method;path protection;programming paradigm;simulation;unavailability;wavelength-division multiplexing	Yanwei Li;Wenda Ni;Heng Zhang;Yanhe Li;Xiaoping Zheng	2012	IEEE Communications Letters	10.1109/LCOMM.2011.110711.111382	telecommunications;computer science;mesh networking;distributed computing;statistics;computer network	HPC	-5.402410823835343	84.30830591733297	47630
3c9ca42f75f41a10305a6f02298a5eb1dbf1d868	automatic link numbering and source routed multicast	small amount;numbering network link;new paradigm;novel forwarding method;automatic link numbering;drawbacks qualitatively;linking number;source routing;steiner tree;distributed algorithm	We present a new paradigm for multicasting. Our paradigm combines two ideas: a simple distributed algorithm for automatically numbering network links with a small amount of numbers, and a novel forwarding method. We describe our paradigm in detail and discuss its benefits and drawbacks qualitatively and quantitatively.	distributed algorithm;multicast;programming paradigm;routing	Visa Holopainen;Raimo Kantola;Taneli Taira;Olli-Pekka Lamminen	2010			distributed algorithm;steiner tree problem;computer science;theoretical computer science;distributed computing;computer network	Networks	-8.301886448715635	77.96040074536012	47692
6320c4732dc7a90eb5d5e718aa2f54b7b6de2155	a two-way active measurement protocol (twamp)		The One-way Active Measurement Protocol (OWAMP), specified in RFC#N#4656, provides a common protocol for measuring one-way metrics between#N#network devices. OWAMP can be used bi-directionally to measure one-way#N#metrics in both directions between two network elements. However, it#N#does not accommodate round-trip or two-way measurements. This memo#N#specifies a Two-Way Active Measurement Protocol (TWAMP), based on the#N#OWAMP, that adds two-way or round-trip measurement capabilities. The#N#TWAMP measurement architecture is usually comprised of two hosts with#N#specific roles, and this allows for some protocol simplifications,#N#making it an attractive alternative in some circumstances. [STANDARDS-#N#TRACK]		Kaynam Hedayat;Roman M. Krzanowski;Al Morton;Kiho Yum;Jozef Babiarz	2008	RFC	10.17487/RFC5357	engineering;world wide web;computer security;computer network	Vision	-23.336265557062227	85.98448114909398	47698
e753a95eac0f739c95dad13355da5840ceba405b	identifying performance bottlenecks in software data planes for cloud-based nfv services		Network Function Visualization (NFV) is transforming the market for computer networks. Most proposed NFV solutions have been implemented and tested in cloud computing environments. In this context, both hardware and software-based features have been used to improve the performance of Virtual Network Functions (VNFs) by speeding up packet processing. However, there are still essential research challenges that need to be tackled to provide better performance experiences for NFV Services, such as detecting and diagnosing performance bottlenecks. However, due to the characteristics inherited from both Cloud and NFV environments, the detection and diagnose of performance problems is a complex task. In this work, we proposed PerfChecker, a monitoring tool that aims at detecting and diagnosing performance bottlenecks in Cloud-based NFV environments. We implemented a PerfChecker prototype for OpenStack and performed some experiments demonstrating that it can assist the cloud infrastructure operator to improve the performance of NFV services.	algorithm;bottleneck (software);cloud computing;control theory;experiment;https;machine learning;network function virtualization;network packet;performance tuning;prototype;sensor	Michel S. Bonfim;Rafael Roque;Emanuel Coutinho;Kelvin Lopes Dias;Stenio F. L. Fernandes	2018	NOMS 2018 - 2018 IEEE/IFIP Network Operations and Management Symposium	10.1109/NOMS.2018.8406161	throughput;computer network;distributed computing;computer science;task analysis;virtual network;virtualization;packet processing;cloud computing;software;server	Metrics	-15.016610550816651	82.4827048534178	47809
edc79c6a6b9016c70347d9d9f72310093eaa89c3	multiagent coalition formation for distributed, adaptive resource allocation	resource allocation	We present a distributed, adaptive resource allocat i n approach for multiagent systems called ARAMS. ARAMS allows a collection of agents to adaptively allocat e CPU resource among themselves to handle dynamic events encountered in a noisy and uncertain environment in real-time manner. Each event encountered may incur a CPU shortage crisis in an agent. ARAMS is aimed to reduce the occurrence and amount of shortage crises o f each agent as well as the entire system as a whole. Th underlying problem-solving strategy of ARAMS is the integration of a monitor-reactive cycle and a goaldirected coalition formation model. The monitor-rea ctive cycle requires the agent to monitor the crisis and ttempt to fix it on its own. The goal-directed coalition f ormation allows the agent to ask for help from other agents ra ionally once it has the resources to do so. Agents als o learn how to form better coalitions faster from their pas t experience. We conducted a series of experiments and the experimental results show that our approach to CPU resource allocation is able to learn and adapt cohere ntly, reacting to and planning for CPU shortages.	agent-based model;central processing unit;coherence (physics);converge;crisis (dynamical systems);emergence;experiment;maximal set;multi-agent system;operating system;overhead (computing);problem domain;problem solving;profiling (computer programming);real-time clock;real-time locating system;resources, events, agents (accounting model)	Leen-Kiat Soh;Xin Li	2004			distributed computing;resource allocation;computer science	AI	-16.003322929843748	62.494047006676695	47830
10f5ea80314feb332e77b6a6ccf53f7e8c86f69b	virtual topology partitioning towards an efficient failure recovery of software defined networks		Software Defined Networking is a new networking paradigm that has emerged recently as a promising solution for tackling the inflexibility of the classical IP networks. The centralized approach of SDN yields a broad area for intelligence to optimise the network at various levels. Fault tolerance is considered one of the most current research challenges that facing the SDN, hence, in this paper we introduce a new method that computes an alternative paths re-actively for centrally controlled networks like SDN. The proposed method aims to reduce the update operation cost that the SDN network controller would spend in order to recover from a single link failure. Through utilising the principle of community detection, we define a new network model for the sake of improving the network's fault tolerance capability. An experimental study is reported showing the performance of the proposed method. Based on the results, some further directions are suggested in the context of machine learning towards achieving further advances in this research area.		Ali Malik;Benjamin Aziz;Chih-Heng Ke;Hao Liu;Mo Adda	2017	2017 International Conference on Machine Learning and Cybernetics (ICMLC)	10.1109/ICMLC.2017.8108982	network interface controller;fault tolerance;network model;network topology;computer science;software;software-defined networking;real-time computing;distributed computing	DB	-12.76419368713904	83.23374069504669	47841
0a392c809a810dab5befdfbbd190a9c1921a74a9	towards an analysis framework for tasks with probabilistic execution times and probabilistic inter-arrival times	probabilistic inter arrival times;probabilistic deadlines;probabilistic real time;probabilistic execution time	In this paper we investigate the problem of calculating the response time distribution for real-time tasks with probabilistic worst-case execution times, probabilistic inter-arrival times and probabilistic deadlines. We propose a definition for the probabilistic deadlines and a first discussion on the response time calculation.	best, worst and average case;real-time clock;response time (technology)	Dorin Maxim;Liliana Cucu-Grosjean	2012	SIGBED Review	10.1145/2452537.2452543	probabilistic analysis of algorithms;real-time computing;probabilistic ctl;estimation of distribution algorithm;theoretical computer science;distributed computing	Embedded	-9.618064883735078	61.344022080272275	47861
51e7f2a5e4f32a46acec16a9e867f4ae899f9614	g-rsvpm: a grid resource reservation model	quality assurance;end to end qos;grid applications;mobile agents;mobile agent grid resource reservation model g rsvpm end to end grid qos assurance;resource reservation;grid computing computer networks computational modeling mobile agents linux protocols processor scheduling dynamic scheduling network servers;mobile agent;quality of service;grid computing;quality of service grid computing mobile agents quality assurance;simulation environment	Because of the heterogeneity, complexity, and autonomy of wide spread grid resources, the assurance of the end-to-end Grid QoS becomes a challenge. The G-RSVPM proposed in this paper is a Grid resource reservation model. Mobile agents are used to implement the model to achieve not only the network resource reservations but also the computing resource reservations for Grid applications. The performance simulation environment of G-RSVPM under RSVP/ns on Linux is designed and implemented. The simulation result shows that the model can flexibly adapt to the changinge environment and achieve better end-to-end QoS assurance both of computing resources and network resources in Grid than the traditional way.	autonomy;complexity;end-to-end principle;linux;mobile agent;nsb/appstudio;performance prediction;simulation	Wandan Zeng;Guiran Chang;Dengke Zhang;Xiuying Zheng	2005	2005 First International Conference on Semantics, Knowledge and Grid	10.1109/SKG.2005.77	quality assurance;real-time computing;quality of service;computer science;mobile agent;distributed computing;drmaa;grid computing;computer network	HPC	-24.113534517367263	63.09411027866794	47910
1fa8d5b075859d603b03b30673ded3a3ee90d0b1	network management initialization for wired and wireless communication: a real time study	real time;wireless network;real time monitoring;wireless communication;design and implementation;bandwidth management;network management;user involvement	  We are presenting a detailed study for the administering and monitoring of the existing IT Infrastructure for SAP. The SAP  Infrastructure requirements like the users involved in the transaction, the real time monitoring and bandwidth management,  are the crucial issues for the designing of the existing IT Infrastructure. Redesigning is done in such a way that, network  becomes simple and secure. During the implementation phase, we have explored different methodology for the PIX firewall implementation  involved in the different security profiles of the wired and wireless network. In the design and implementation phase, some  of the prime solutions are proposed for the effective utilization of the available resources.    	time and motion study	Navneet Tiwari;Siddarth Jain;Saifuddin Tariwala;Ankit Salgia	2010		10.1007/978-3-642-12214-9_3	wi-fi;element management system;real-time computing;wireless wan;heterogeneous network;wireless site survey;network management station;wireless network;distributed computing;key distribution in wireless sensor networks;network management application;base transceiver station;municipal wireless network;wi-fi array;fixed wireless;wired communication;computer network	DB	-18.52900607506014	87.23682344590625	48004
b0b54c61e1e9847f49d404c64e1d2de5e66ba98b	multi-capacity bin packing with dependent items and its application to the packing of brokered workloads in virtualized environments	bin packing;resource allocation;brokerage environment;network aware	Providing resource allocation with performance predictability guarantees is increasingly important in cloud platforms, especially for data-intensive applications, for which performance depends greatly on the available rates of data transfer between the various computing/storage hosts underlying the virtualized resources assigned to the application. With the increased prevalence of brokerage services in cloud platforms, there is a need for resource allocation solutions that provide predictability guarantees in such settings, in which neither application scheduling nor cloud provider resources can be managed/controlled by the broker. This paper addresses this problem, as we define the Multi-Capacity Bin Packing with Dependent Items (MCBP-DI) problem to model the various resource allocation models adopted in such a brokered setting. The MCBP-DI problem represents a class of multi-dimensional bin packing problems, in which the amount of resources consumed by a subset of the items depends on the relationship between these items.Focusing on offering predictability guarantees to data-intensive applications, we define a sub-problem of the MCBP-DI problem, namely the Network-Constrained Packing (NCP) problem, in which the items to be packed form a connected component, and the resources consumed by any subset of these items are equivalent to the cost of the cut of that subset from the component. Our definition of the NCP problem is presented as part of our proposed cloud brokerage framework, in which the optimal mapping of brokered resources to applications is decided with guaranteed performance predictability. We prove that NCP is NP-hard, and we define two special instances of the problem, for which exact solutions can be found efficiently. We develop a greedy heuristic to solve the general instance of the NCP problem, and we evaluate its efficiency using simulations on various application workloads, and network models. Proposal of a novel brokerage model for providing execution predictability services to data-intensive applications.Definition of a new class of multi-dimensional bin packing problems, namely Multi-Capacity Bin Packing with Dependent Items.Definition of the Network-Constrained Packing problem model for resource allocation in our proposed brokerage model.The definition of an exact polynomial algorithm to solve an instance of our proposed packing problem, which occurs frequently in reality.The development of a greedy approximation algorithm to solve the NCP problem in the general model.	bin packing problem;cloud computing;connected component (graph theory);data-intensive computing;greedy algorithm;heuristic;np-hardness;platform as a service;scheduling (computing);set packing;simulation	Christine Bassem;Azer Bestavros	2017	Future Generation Comp. Syst.	10.1016/j.future.2016.08.017	real-time computing;cloud computing;network model;packing problems;approximation algorithm;scheduling (computing);computer science;bin packing problem;distributed computing;greedy algorithm;resource allocation	Metrics	-18.464837581048517	63.09828185121596	48021
93030ae903514b066b21c6b2b2118dd41a365a92	an architecture for self-managing microservices	bigstep full metal cloud;provisioning;advance reservation;metal as a service;cloud computing	Running applications in the cloud efficiently requires much more than deploying software in virtual machines. Cloud applications have to be continuously managed: 1) to adjust their resources to the incoming load and 2) to face transient failures replicating and restarting components to provide resiliency on unreliable infrastructure. Continuous management monitors application and infrastructural metrics to provide automated and responsive reactions to failures (health management) and changing environmental conditions (auto-scaling) minimizing human intervention.  In the current practice, management functionalities are provided as infrastructural or third party services. In both cases they are external to the application deployment. We claim that this approach has intrinsic limits, namely that separating management functionalities from the application prevents them from naturally scaling with the application and requires additional management code and human intervention. Moreover, using infrastructure provider services for management functionalities results in vendor lock-in effectively preventing cloud applications to adapt and run on the most effective cloud for the job.  In this position paper we propose a novel architecture that enables scalable and resilient self-management of microservices applications on cloud.	algorithm;autoscaling;cloud computing;clustered file system;continuous delivery;geolocation;image scaling;leader election;microservices;orchestration (computing);routing;scalability;self-management (computer science);software as a service;software configuration management;software deployment;stateless protocol;vendor lock-in;virtual machine	Giovanni Toffetti Carughi;Sandro Brunner;Martin Blöchlinger;Florian Dudouet;Andrew Edmonds	2015		10.1145/2747470.2747474	real-time computing;simulation;engineering;computer security	OS	-27.8539043291506	60.6361710665976	48039
a58c8d735ee31a02bde0ccc04229752e4a4bfc0c	an experiment in remote printing		"""Status of this Memo This memo defines an Experimental Protocol for the Internet community. It does not specify an Internet standard. Discussion and suggestions for improvement are requested. Please refer to the current edition of the """"IAB Official Protocol Standards"""" for the standardization state and status of this protocol. Distribution of this memo is unlimited."""	internet architecture board;printing	Marshall T. Rose;Carl Malamud	1993	RFC	10.17487/RFC1486	engineering;advertising;internet privacy;world wide web	Networks	-25.82345795810743	88.44215032757836	48064
464c33c355ca90af30f1bd7e1bec403d83506042	multicast provision in transparent optical networks with mixed line rates	wavelength assignment;multicast communication;transponders bandwidth multicast communication routing wavelength assignment heuristic algorithms;cost reduction;multicast provisioning problem multicast communications milp mixed integer linear programming wavelength assignment problems line rate selection light tree optimization wavelength channel joint cost minimization transponder joint cost minimization traffic demand routing multicast session routing mixed line rates transparent optical networks;trees mathematics;optical fibre networks;telecommunication network routing;integer programming;integer linear programming ilp optical networks mixed line rate mlr multicast routing and wavelength assignment mrwa light tree;linear programming;wavelength assignment cost reduction integer programming linear programming multicast communication optical fibre networks telecommunication network routing trees mathematics	We study the multicast provisioning problem in transparent optical networks with Mixed Line Rates. For each multicast session, light-trees with different line rates are used to route the traffic demands. We aim at minimizing the joint cost of transponders and wavelength channels in the light-trees for routing multicast sessions. However, different line rates are subject to different maximum transmission reaches. Besides, the line rate selection, routing and wavelength assignment problems should be solved simultaneously, what makes light-tree optimization complicate. In light of this, we formulate the multicast provisioning problem as a Mixed Integer Linear Programming (MILP). Simulation results validate our model and show that both the transponder cost and the wavelength channel cost can be saved by flexibly using mixed line rates for provisioning multicast communications.	ct scan;integer programming;internet backbone;linear programming;mathematical optimization;multicast;next-generation network;provisioning;routing and wavelength assignment;simulation;transponder	Fen Zhou	2013	2013 17th International Conference on Optical Networking Design and Modeling (ONDM)		real-time computing;multicast;integer programming;protocol independent multicast;computer science;linear programming;distributed computing;distance vector multicast routing protocol;source-specific multicast;xcast;computer network	HPC	-5.77031637197036	82.82173297066163	48075
9a0d122d532430a1dd65448147d48b581384b253	eliminating sorting in ip lookup devices using partitioned table	ternary content addressable memory;partitioned table;storage requirement;clocks;sorting;routing;delays ip networks content addressable storage table lookup network routing;delay effects;sorting routing associative memory coprocessors table lookup delay effects clocks quality of service monitoring wire;coprocessors;network routing;storage requirement ip lookup device partitioned table ternary content addressable memory routing table built in priority encoder clock rate;wire;monitoring;clock rate;ip lookup device;associative memory;ip networks;built in priority encoder;ip lookup;quality of service;content addressable storage;table lookup;routing table;delays	We present a solution to eliminate the requirements of routing table sorting by prefix length in IP lookup devices using ternary content addressable memories (TCAMs). This reduces delays arising from routing table updates from linear to constant time. This solution introduces slight modifications to the organization of the routing table including the elimination of the built-in priority encoder. The routing table entries are split by output port to remove their dependence on length. Overall, the solution presented reduces the insertion problem to lookup speed while maintaining similar clock rates and storage requirements of traditional designs.	best, worst and average case;canonical account;lookup table;priority encoder;requirement;routing table;scalability;simulation;sorting;static random-access memory;time complexity	Enrico Ng;Gyungho Lee	2005	2005 IEEE International Conference on Application-Specific Systems, Architecture Processors (ASAP'05)	10.1109/ASAP.2005.32	routing table;routing;static routing;parallel computing;real-time computing;computer hardware;computer science;destination-sequenced distance vector routing	EDA	-5.680415032863353	66.639067230856	48088
2081ee2dc3048220c9ea56f0245fc14e39ff4c4c	high quality mobile xr: requirements and feasibility		Virtual, augmented and mixed reality are expected to grow rapidly in popularity as the technology gets more mature over the coming years. For mobile networks these applications can put quite challenging requirements. In particular when the user devices shall have low weight and low energy consumption it may be necessary to offload some of the processing to edge cloud servers. This implies strict requirements on latency and high data rate between the edge server and the user device. In this paper we discuss the requirements for different quality levels of virtual reality and the feasibility of providing these in 4G and 5G cellular networks. In particular, we show how reduced latency can reduce the bit rate requirements and enable photo realistic XR over mobile networks.	cloud storage;content delivery network;data rate units;display resolution;mixed reality;requirement;server (computing);virtual reality	Christer Qvarfordt;Henrik Lundqvist;Georgios P. Koudouridis	2018	2018 IEEE 23rd International Workshop on Computer Aided Modeling and Design of Communication Links and Networks (CAMAD)	10.1109/CAMAD.2018.8514957	real-time computing;computer science;latency (engineering);computer network;energy consumption;mixed reality;virtual reality;popularity;cloud computing;server;cellular network	Mobile	-20.2388216607783	77.16453953509472	48101
54f5eeadb36977d7cd17492727336639dfe7732d	a cross-domain sdn architecture for multi-layered space-terrestrial integrated networks		The MLSTIN is considered as a powerful architecture to meet the heavy consumer demand for wireless data access in the coming 5G ecosystem. However, due to the inherent heterogeneity of MLSTIN, it is challenging to manage the diverse physical devices for large amounts of traffic delivery with optimal network performance. As promoted by the advantage of SDN, MLSTIN is expected to be a flexible paradigm to dynamically provision various applications and services. In light of this, a cross-domain SDN architecture that divides the MLSTIN into satellite, aerial, and terrestrial domains is proposed in this article. We discuss the design and implementation details of this architecture and then point out some challenges and open issues. Moreover, illustrative results validate that the proposed architecture can significantly improve the efficiencies of configuration updating and decision making in MLSTIN.		Yongpeng Shi;Yurui Cao;Jiajia Liu;Nei Kato	2018	IEEE Network	10.1109/MNET.2018.1800191	resource management;handover;computer network;distributed computing;architecture;wireless;data access;computer science;control system;network performance	Mobile	-14.74119862287965	85.5670178725968	48165
b7eb91a0c69cebfacd4277c11aa7d8c1893b9da6	tracking ipv6 evolution: data we have and data we need	active measurement;internet measurement techniques;internet measurement;validation;network	Exhaustion of the Internet addressing authority's (IANA) available IPv4 address space, which occurred in February 2011, is finally exerting exogenous pressure on network operators to begin to deploy IPv6. There are two possible outcomes from this transition. IPv6 may be widely adopted and embraced, causing many existing methods to measure and monitor the Internet to be ineffective. A second possibility is that IPv6 languishes, transition mechanisms fail, or performance suffers. Either scenario requires data, measurement, and analysis to inform technical, business, and policy decisions. We survey available data that have allowed limited tracking of IPv6 deployment thus far, describe additional types of data that would support better tracking, and offer a perspective on the challenging future of IPv6 evolution.	address space;ianal;internet;software deployment	Kimberly C. Claffy	2011	Computer Communication Review	10.1145/2002250.2002258	simulation;computer science;data mining;computer security;computer network	Networks	-28.302874063032462	80.70103183987607	48272
a1caa222fceac031d3b993446505387029707cab	a self-organized load-balancing algorithm for overlay-based decentralized service networks	traffic self organized load balancing algorithm overlay based decentralized service network decentralized ownership overlay network virtual cluster decentralized computing framework resilient peer to peer overlay topology reconfiguration;bio inspired algorithms;resource allocation;telecommunication traffic;load balancing;unstructured overlays;telecommunication traffic peer to peer computing resource allocation telecommunication network topology;self organization;bio inspired algorithms load balancing self organization myconet unstructured overlays;load balance;myconet;peer to peer computing biomass protocols topology network topology clustering algorithms robustness;peer to peer computing;telecommunication network topology	"""A service network with decentralized ownership is a system where nodes offering a variety of services are administered by different organizations -- or even by a set of individuals. In such a context, nodes hosting services can dynamically enter and exit the system without prior notice, and there is no centralized point of control. If one wants to build into such a system the ability to direct incoming requests for the various hosted services to those nodes that can efficiently fulfill them, one option is to introduce in the system an entity that serves as a gateway to accept service requests, and is an intermediary to re-direct requests as needed. That implies that this intermediary is able to acquire and maintain accurate and up-to-date information on where it can direct incoming requests. Another option, which is the one we pursue in this paper, is to build the system as an overlay network, in which the nodes hosting instances of each of many different types of services can self-organize as """"virtual clusters"""", and efficiently load-balance incoming requests amongst themselves. We describe our design and evaluation of a decentralized computing framework of this kind. We leverage a resilient peer-to-peer overlay that automatically re-configures its topology, responding to the number of different service types executing on the peer nodes, the dynamics of the participation of those nodes (peer churn), and the traffic coming into the system for the various services."""	algorithm;british informatics olympiad;centralized computing;cluster analysis;decentralized computing;gateway (telecommunications);load balancing (computing);organizing (structure);overlay network;peer-to-peer;response time (technology);scalability;self-organization;service-oriented architecture;simulation;synergy	Giuseppe Valetto;Paul L. Snyder;Daniel J. Dubois;Elisabetta Di Nitto;Nicolò Maria Calcavecchia	2011	2011 IEEE Fifth International Conference on Self-Adaptive and Self-Organizing Systems	10.1109/SASO.2011.28	overlay network;computer science;load balancing;distributed computing;world wide web;computer network	HPC	-18.365725166437258	81.32876269672046	48305
8042b911b27e976fc67acdf9b6063575b9f20c77	quadro: a solution to packet switching in optical transmission networks	commutation telecommunication;conmutacion telecomunicacion;capacidad canal;transmission optique;capacite canal;telecommunication network;packet switched;packet switching;conmutacion por paquete;conmutacion optica;optical switching;channel capacity;telecommunication switching;optical transmission;red telecomunicacion;reseau telecommunication;transmision optica;commutation optique;commutation paquet	"""To provide very high end-to-end bandwidth, all-optical networks need to maintain the transmitted information in the optical domain throughout the network. Through packet switching, this bandwidth can then be flexibly shared among a large number of users according to the demands of their applications. In this process users need to share the various optical communication-handling network resources, such as wavelengths, switches, receivers and transmitters. Extant packet switching solutions, based on electronic buffering and processing, are not appropriate for the optical environment, as, due to the relatively slower electronic rates, their use leads to the """"electronic performance bottleneck"""". In this paper we overview a recent approach termed Quadro (Queueing Arrivals for Delayed Reception/Routing Operation), that supports the sharing of resources in an optical system without the need for O / E and E / O conversions, or electronic buffering and processing of the data packets. We then show how the Quadro resource sharing solution can be generalized to provide optical packet switching. The proposed solution opens a new direction for optical networking, allowing optical network realization without the need to wait for the te~hnol.ogical realization of optical processing devices to r~pl, ac~.the-reIatiYely,slow.nodal.el~qtro~i,c processing in existing nbtworks. ;I'he design and operation of 0uadro is'presented and denionstrated """"for different types ~f LAN and MAN systems."""	end-to-end principle;network packet;network switch;nvidia quadro;packet switching;routing;transmitter	Imrich Chlamtac;Andrea Fumagalli	1994	Computer Networks and ISDN Systems	10.1016/0169-7552(94)90055-8	optical burst switching;telecommunications;computer science;optical switch;optical performance monitoring;burst switching;channel capacity;packet switching;telecommunications network;computer network	Networks	-6.167829335877706	87.3482377254104	48321
6981e8f529553be35001d5d2b494e004793d5327	xorp: an open platform for network research	ucl;discovery;theses;conference proceedings;satisfiability;digital web resources;ucl discovery;open access;network optimization;open system;complex systems;robustness;ucl library;internet topology;book chapters;highly optimized tolerance;open access repository;open source;ucl research	Network researchers face a significant problem when deploying software in routers, either for experimentation or for pilot deployment. Router platforms are generally not open systems, in either the open-source or the open-API sense. In this paper we discuss the problems this poses, and present an eXtensible Open Router Platform (XORP) that we are developing to address these issues. Key goals are extensibility, performance and robustness. We show that different parts of a router need to prioritize these differently, and examine techniques by which we can satisfy these often conflicting goals. We aim for XORP to be both a research tool and a stable deployment platform, thus easing the transition of new ideas from the lab to the real world.	application programming interface;extensibility;open api;open platform;open-source software;router (computing);software deployment	Mark Handley;Orion Hodson;Eddie Kohler	2003	Computer Communication Review	10.1145/774763.774771	complex systems;internet topology;computer science;operating system;database;open system;world wide web;computer security;robustness;computer network;satisfiability	Networks	-16.74325018189871	85.05756078206761	48325
af40aabf0e4b5d4821b13eb711d4cf91bf03f716	maas advanced provisioning and reservation system	bigstep full metal cloud;provisioning;advance reservation;metal as a service;cloud computing	The ongoing adoption of Cloud Computing at a fast rate has lead to an increase in the number of users and in the same time, in the level of complexity and performance. The interaction model is based on services offered to users at different levels. Metal-as-a-service (MaaS) platforms assure a higher level of performance when compared to typical Cloud platforms, but at the cost of a more complex provisioning system. An advanced reservation and provisioning system for MaaS should alleviate the problem of added complexity by accounting for the observed deployment time of the infrastructures. The paper studies the provisioning capabilities of the Bigstep Full Metal Cloud platform in order to allow the construction of such a system. The main issue addressed is oriented on cloud management automation, SLA and QoS management.	algorithm;cloud computing;cloud management;provisioning;schedule;service-level agreement;software deployment	Alexandru Sirbu;Cristian Pop;Florin Pop	2015		10.1145/2747470.2747473	simulation;engineering;computer security;provisioning;computer network	HPC	-27.069976980672543	61.12111097321442	48336
2fd3686b00b02631cde925704eb451573480a155	energy-aware task scheduling: towards enabling mobile computing over manets	energy conservation;heterogeneous processor;manet;energy demand;energy efficient;high performance computing;processor scheduling;resource allocation;distributed computing;mobile computer;wireless ad hoc network;energy conservation mobile computing ad hoc networks scheduling resource allocation;computer networks;heterogeneous processor mobile computing devices mobile wireless ad hoc network manet distributed environment energy conservation energy aware task scheduling problem heuristic algorithm;wireless communication;scheduling algorithm;performance improvement;energy aware task scheduling problem;distributed environment;mobile ad hoc networks;scheduling;mobile communication;scheduling problem;handheld device;ad hoc networks;mobile computing devices;mobile wireless ad hoc network;task scheduling;mobile computing;high performance;handheld computers;heuristic algorithm;hardware;processor scheduling mobile computing mobile ad hoc networks high performance computing hardware distributed computing mobile communication handheld computers computer networks scheduling algorithm	In this paper, we look into the problem of distributing computational tasks amongst a set of mobile computing devices in a mobile wireless ad hoc network (MANET) in such a way that conserves energy and improves performance. In such a distributed environment, the assignment of computational tasks to different devices and the order of their execution play a vital role in energy conservation and performance improvement. The main contributions of this paper are formulating a novel energy-aware scheduling problem and proposing a heuristic algorithm to solve it. Our scheduling algorithm schedules a set of computational tasks, which may have dependencies and communication, into a set of heterogeneous processors in such a way that minimizes both the total consumed energy and the makespan (i.e., the time by which all tasks complete their execution). Experiments show that significant improvement can be achieved by using our scheduler.	algorithm;analysis of algorithms;central processing unit;computation;computational complexity theory;database;energy level;experiment;heuristic (computer science);hoc (programming language);makespan;mathematical optimization;mobile app;mobile computing;mobile phone;persistence (computer science);profiling (computer programming);query plan;run time (program lifecycle phase);scheduling (computing);smart battery;ubiquitous computing	Waleed Alsalih;Selim G. Akl;Hossam S. Hassanein	2005	19th IEEE International Parallel and Distributed Processing Symposium	10.1109/IPDPS.2005.199	wireless ad hoc network;real-time computing;mobile ad hoc network;computer science;operating system;distributed computing;mobile computing;scheduling;computer network	Embedded	-21.96652533401483	67.06576952801863	48375
5aa2e10bc34bca3a8a3c3688103163faf76e3ba8	tree-structured data regeneration in distributed storage systems with regenerating codes	communications society;tree structured data regeneration;maintenance;tree data structures distributed processing storage management telecommunication network topology telecommunication traffic;storage management;distributed processing;ieee communications society;large scale reliable data storage;distributed storage system;tree data structures;indexing terms;network topology;large scale;data storage;telecommunication traffic;network topologies;redundancy;data regeneration;network traffic;tree structure;rctree tree structured data regeneration distributed storage systems regenerating codes large scale reliable data storage network traffic network topologies;distributed storage systems;distributed databases;rctree;bandwidth;book reviews;computer science;it evaluation;peer to peer computing;telecommunication network topology;encoding;peer to peer computing redundancy bandwidth network topology large scale systems telecommunication traffic memory maintenance communications society computer science;memory;regenerating codes;large scale systems	Distributed storage systems provide large-scale reliable data storage by storing a certain degree of redundancy in a decentralized fashion on a group of storage nodes. To recover from data losses due to the instability of these nodes, whenever a node leaves the system, additional redundancy should be regenerated to compensate such losses. In this context, the general objective is to minimize the volume of actual network traffic caused by such regenerations. A class of codes, called regenerating codes, has been proposed to achieve an optimal trade-off curve between the amount of storage space required for storing redundancy and the network traffic during the regeneration. In this paper, we jointly consider the choices of regenerating codes and network topologies. We propose a new design, referred to as RCTREE, that combines the advantage of regenerating codes with a tree-structured regeneration topology. Our focus is the efficient utilization of network links, in addition to the reduction of the regeneration traffic. With the extensive analysis and quantitative evaluations, we show that RCTREE is able to achieve a both fast and stable regeneration, even with departures of storage nodes during the regeneration.	algorithm;clustered file system;code;computer data storage;experiment;fastest;instability;network packet;network topology;network traffic control;redundancy (engineering);simulation	Jun Li;Shuang Yang;Xin Wang;Baochun Li	2010	2010 Proceedings IEEE INFOCOM	10.1109/INFCOM.2010.5462122	computer science;theoretical computer science;distributed computing;distributed database;network topology;computer network	HPC	-10.031324582328327	71.87513741460278	48445
90f9248c1c92dacfa72ed39674c5b7ff8860a5e5	enabling information centric networks through opportunistic search, routing and caching		Content dissemination networks are pervasive in todays’ Internet. Examples of content dissemination networks include peer-to-peer networks (P2P), content distribution networks (CDN) and information centric networks (ICN). In this paper, we propose a new system design for information centric networks which leverages opportunistic searching, routing and caching. Our system design is based on an hierarchical tiered structure. Random walks are used to find content inside each tier, and gateways across tiers are used to direct requests towards servers placed in the top tier, which are accessed in case content replicas are not found in lower tiers. Then, we propose a model to analyze the system in consideration. The model yields metrics such as mean time to find a content and the load experienced by custodians as a function of the network topology. Using the model, we identify tradeoffs between these two metrics, and numerically show how to find the optimal time to live of the random walks.	apple icon image format;average-case complexity;cache (computing);content delivery network;digital distribution;http 404;icn gps;multitier architecture;network topology;numerical analysis;peer-to-peer;router (computing);routing table;scalability;systems design;time to live	Guilherme de Melo Baptista Domingues;Edmundo de Souza e Silva;Rosa Maria Meri Leão;Daniel Sadoc Menasché	2013	CoRR		computer science;internet privacy;world wide web;computer network	Metrics	-16.277542688233055	76.90203739365782	48485
45a8af57d7026af2e60ab226f86d92502f2791b5	hardware-supported softwarized and elastic optical networks		We present elasticity and agility in softwarized optical network construction, service continuation, and service update. Programmability among multiple network protocols and multiple classes of transmission and processing speeds is a necessary solution for lower CAPEX and agile network setup. We present beyond 100 Gbps hardware-support programmability in optical edge. Existing services should be kept transient quality against sudden traffic changes and failures. We also show proper optical power management using burst-tolerable EDFAs in network protection for service continuation of in-service paths.	agile software development;communications protocol;continuation;data rate units;elasticity (data store);power management	Hiroaki Harai;Hideaki Furukawa;Yusuke Hirota	2018	2018 International Conference on Optical Network Design and Modeling (ONDM)	10.23919/ONDM.2018.8396139	computer network;communications protocol;elasticity (economics);continuation;computer science;network access protection;agile software development;transmission (mechanics)	Networks	-11.695928372423037	85.34001021294878	48504
9b1e788c57ed59e9e3b8feafd641edc16690205a	the inforamtion and communication system of the city of unna. a hierarchical client-server network architecture as one module of the information and communication system in the unna municipal administration	network architecture;client server;communication system		information;network architecture	Christian Jänig	1993				HPC	-20.400539266127165	88.22922410198329	48508
85cd107773c76a2ffc25dd0c74ac35d53dfe579d	the elusive internet flattening: 10 years of ixp growth		Over the past decade, IXPs have been playing a key role in enabling interdomain connectivity. Their traffic volumes have quickly become similar to those of Tier-1 ASes and their physical presence has spread across the world. While the relevance of IXPs is undeniable, their contribution to the shaping of the current Internet is not fully understood yet, especially on the so-called “flattening” phenomenon. In this paper, we disentangle “flattening” from “path shortening”: we show that the impact of IXPs on path-length is limited. Surprisingly, Internet path-lengths have globally barely decreased over the last decade, regardless of whether they cross IXPs or not. Instead of a “path-shortening”, we observe a diversion of the routes away from the central Tier-1 ASes, supported by IXPs. This diversion has however not fundamentally changed the existence of a hierarchy, but rather replaced the central Tier-1s with a new set of players.	address space;ecosystem;inter-domain;internet;multitier architecture;noise shaping;peering;reachability;relevance;traverse;tier 1 network;tracing (software);traffic exchange	Timm Böttger;Gianni Antichi;Eder Leão Fernandes;Roberto di Lallo;Marc Bruyere;Steve Uhlig;Ignacio Castro	2018	CoRR		computer network;the internet;flattening;telecommunications;hierarchy;computer science;internet exchange point;phenomenon	Networks	-10.513526792200382	78.09810740269445	48514
666a08e49afa19329a308c3400de4ba339f709ad	a scheduling model for workflows on grids and clouds	scheduling algorithm;performance improvement;optimal scheduling;scheduling;clouds;optimization;quality of service;grids	This paper presents a set of comparisons of the performance of a bi-criteria scheduling algorithm for Workflows with Quality of Service (QoS) support. This work serves as basis to implement a bi-criteria hybrid scheduling algorithm for workflows with QoS support, aiming to optimize the criteria chosen by the users and based on the priority ordering and relaxation specified by them. Analyzing the comparisons and obtained results, indicates a performance improvement when adopting the model proposed in this paper.	algorithm;linear programming relaxation;quality of service;scheduling (computing)	Henrique Kloh;Bruno Schulze;Antonio Roberto Mury;Raquel Coelho Gomes Pinto	2010		10.1145/1890799.1890802	fair-share scheduling;fixed-priority pre-emptive scheduling;real-time computing;earliest deadline first scheduling;flow shop scheduling;dynamic priority scheduling;computer science;rate-monotonic scheduling;genetic algorithm scheduling;two-level scheduling;deadline-monotonic scheduling;database;distributed computing;scheduling;lottery scheduling;round-robin scheduling	HPC	-17.977451362386372	62.83268514649373	48524
90f712a8a69866d29f56134e9af0a407ad40bff0	dynamic walks for searching streaming media in peer-to-peer networks	peer to peer network;search algorithm;search method;p2p;streaming media	With the advance of network technologies, availability and popularity of streaming media contents over the P2P (Peer-to-Peer) Networks have grown rapidly in recent years. However, how to efficiently search a requested steaming media among P2P peers is still a problem which causes a serious user delay and limited hit ratio. This paper presents an efficient search method for streaming media in P2P, which reduces user response delays and exchange overhead simultaneously. Based on an analytical formulation of both streaming media and P2P peers’characteristics, we derive a search algorithm which solves the next two problems quantitatively. (1) How to decide the number of walkers (queries) at each step of search? (2) How to decide the length of walkers (queries) at each step of search? Simulation results verify that the proposed algorithm efficiently resolves the above problems and provides much better performance than conventional methods.	peer-to-peer;streaming media	Zhou Su;Jiro Katto;Yasuhiko Yasuda	2004		10.1007/978-3-540-30541-5_19	beam search;computer science;peer-to-peer;distributed computing;internet privacy;world wide web;computer network;search algorithm	Theory	-13.570912440159383	74.20422819795463	48574
326026a3452a5ef1bf212d6d37b983b21c26d007	a self-optimizing workload management solution for cloud applications	resource allocation;self optimizing workload management solution rubis web application benchmark ibm cloud platform model free controller target less bottleneck detection mechanism cloud dynamics self optimizing application workload management solution cloud application behavior model based workload management performance measure monitoring threshold based bottleneck detection technology cloud application performance management physical resource mapping virtual resource mapping cloud applications;time factors throughput servers monitoring computational modeling convergence time measurement;software performance evaluation;system monitoring;black box modeling;bottleneck analysis application performance management cloud computing black box modeling;bottleneck analysis;application performance management;system monitoring cloud computing resource allocation software performance evaluation;cloud computing	Given the dynamic nature of the cloud, resulting from mapping virtual to physical resources, changes in the usage pattern of resources, migration of virtual resources and the dynamic nature of the applications themselves, the bottleneck resource in a given application changes over time. Promptly identifying the bottleneck of cloud application and consequently taking corrective actions (e.g. admission control) are essential requirements for cloud application performance management. The traditional threshold based bottleneck detection technology, which adopts a pre-defined target performance measure (e.g. response time, CPU utilization, etc.), requires a good understanding of the application. It is difficult to identify which performance measures need to be monitored and how to set accurate threshold values for them. The commonly used technique of model-based workload management also faces a big challenge in modeling the highly dynamic, cloud application behavior. In this paper, we propose a self-optimizing application workload management solution for cloud applications which adapts well to the cloud dynamics. It utilizes a target-less bottleneck detection mechanism, without the need to define target thresholds. It also contains a model-free controller for workload management, thus avoiding the complexity of dynamically changing the model as the cloud environment changes. We believe that this is the first time such a design principle to cloud application performance management is introduced. The validity and efficiency of this solution have been verified by a real-case study on an IBM cloud platform, using the RUBiS web application benchmark.	benchmark (computing);black box;central processing unit;cloud computing;control theory;fairness measure;network congestion;operating point;optimizing compiler;overhead (computing);platform as a service;requirement;response time (technology);software as a service;throughput;utility;web application;white box (software engineering)	Haishan Wu;Asser N. Tantawi;Tao Yu	2013	2013 IEEE 20th International Conference on Web Services	10.1109/ICWS.2013.71	system monitoring;real-time computing;simulation;cloud computing;resource allocation;computer science;operating system;cloud testing;distributed computing	HPC	-23.423552255296908	61.457485426850546	48576
659ddc885eb64cb8e83ade6ce75397b3e79e2904	a survey on decision making for task migration in mobile cloud environments	context awareness;mobile communication heuristic algorithms cloud computing partitioning algorithms decision making mobile handsets conferences;mobile cloud;heuristic algorithms;mobile communication;mobile handsets;task migration;task migration mobile cloud;decision making migration standards comprehensive context awareness backend computing nodes mobile cloud computing mobile cloud environments task migrations;conferences;cloud computing;mobile computing cloud computing decision making;partitioning algorithms	The key idea of MCC is using powerful back-end computing nodes to enhance capabilities of small mobile devices and provide better user experiences. An effective and widely used approach to realize this is task migrations. Decision making is an important aspect of migrations which affects the feasibility and effectiveness of task migrations. There have been a number of research efforts to MCC which help make decisions for task migrations. In this paper, we present a comprehensive survey on decision making for task migrations in MCC, including decision factors and algorithms. We observe that there are still some challenges such as comprehensive context awareness, unified migration standards, large-scale experiments, more involvement of latest achievements from artificial intelligence, and flexible decision-making mechanisms. The paper highlights these issues and challenges to attract more efforts to work on MCC.	algorithm;artificial intelligence;big data;context awareness;experiment;interaction;microelectronics and computer technology corporation;mobile cloud computing;mobile device;programming paradigm;server (computing)	Weishan Zhang;Shouchao Tan;Feng Xia;Xiufeng Chen;Zhongwei Li;Qinghua Lu;Su Yang	2016	Personal and Ubiquitous Computing	10.1007/s00779-016-0915-y	real-time computing;mobile search;simulation;mobile telephony;cloud computing;computer science;operating system;distributed computing;mobile computing	AI	-28.771869498738916	67.31673329669903	48699
dc17bf0a4a73df36ce2335ce75cd40b0a9bd26d2	a novel statistical time-series pattern based interval forecasting strategy for activity durations in workflow systems	scientific application;time series forecasting;time series patterns;non linear time series;swinburne;time series;workflow system;statistical time series;pattern matching;high performance computer;pattern recognition;middleware;activity duration;interval forecasting;cloud computing	Forecasting workflow activity durations is of great importance to support satisfactory QoS in workflow systems. Traditionally, a workflow system is often designed to facilitate the process automation in a specific application domain where activities are of the similar nature. Hence, a particular forecasting strategy is employed by a workflow system and applied uniformly to all its workflow activities. However, with newly emerging requirement to serve as a type of middleware services for high performance computing infrastructures such as grid and cloud computing, more and more workflow systems are designed to be general purpose to support workflow applications from many different domains. Due to such a problem, the forecasting strategies in workflow systems must adapt to different workflow applications which are normally executed repeatedly such as data/computation intensive scientific applications (mainly with longduration activities) and instance intensive business applications (mainly with short-duration activities). In this paper, with a systematic analysis of the above issues, we propose a novel statistical time-series pattern based interval forecasting strategy which has two different versions, a complex version for long-duration activities and a simple version for short-duration activities. The strategy consists of four major functional components: duration series building, duration pattern recognition, duration pattern matching and duration interval forecasting. Specifically, a novel hybrid non-linear time-series segmentation algorithm is designed to facilitate the discovery of duration-series patterns. The experimental results on real world examples and simulated test cases demonstrate the excellent performance of our strategy in the forecasting of activity duration intervals for both long-duration and short-duration activities in comparison to some representative time-series forecasting strategies in traditional workflow systems.	algorithm;application domain;autoregressive model;best, worst and average case;central processing unit;cloud computing;computation;experiment;grid computing;interval arithmetic;load balancing (computing);microsoft windows;middleware;nonlinear system;online and offline;pattern matching;pattern recognition;quality of service;scheduling (computing);simulation;smoothing;supercomputer;test case;time complexity;time series;top-down and bottom-up design	Xiao Qiao Liu;Zhiwei Ni;Dong Yuan;Yuan-Chun Jiang;Zhangjun Wu;Jinjun Chen;Yun Yang	2011	Journal of Systems and Software	10.1016/j.jss.2010.11.927	real-time computing;computer science;data science;operating system;time series;data mining;workflow management system;workflow technology	HPC	-23.038017588262207	61.0776995543303	48809
2805987338f0bf71ff4f2dbfa130e4bd64f62586	deploying a hierarchical management framework using mobile agent technology	hierarchical system;hierarchical structure;multiagent system;flexibilidad;reseau ordinateur;enterprise networks;systeme hierarchise;mobile agent technology;telecommunication network;computer network;sistema jerarquizado;red telecomunicacion;gestion transmission;reseau telecommunication;red ordenador;communications managing;flexibilite;network management;mobile agent;sistema multiagente;dynamic adaptation;gestion transmision;flexibility;systeme multiagent;distributed management	The use of Mobile Agent (MA) paradigm has been proposed by many researchers as an answer to the scalability and flexibility limitations of centralised Network Management (NM). Nevertheless, while large enterprise networks are already hierarchically structured, MA-based management has not yet moved from ‘flat’ to hierarchical structures. That results in non-scalable flat architectures, particularly when the management of remote subnetworks is considered. In this context, the deployment of a hierarchically structured MAbased management framework is a reasonable approach. The migration to hierarchical structures is achieved with an additional management entity, the Mobile Distributed Manager (MDM), which takes the full control of managing a given network segment. This architecture exploits the mobility features of MDMs to dynamically adapt to mutable networking conditions. Empirical results indicate a substantial reduction of the overall management cost compared to both centralised and MA-based flat management approaches.	access control;bus (computing);centralisation;common object request broker architecture;graphical user interface;immutable object;interconnection;interoperability;java remote method invocation;master data management;mathematical optimization;mebibyte;mobile agent;network segment;network topology;osi model;performance evaluation;polling (computer science);programming paradigm;scalability;simple network management protocol;software deployment;subnetwork;traverse	Damianos Gavalas;Dominic A. P. Greenwood;Mohammed Ghanbari;Mike O'Mahony	2000		10.1007/3-540-46525-1_23	network management;simulation;telecommunications;computer science;mobile agent;distributed computing;hierarchical control system;computer security;telecommunications network	Web+IR	-22.549296890916033	82.04325148916652	48923
e5ec2669738c55dabab49d6f8e22a64137d76b72	an economic and energy-aware analysis of the viability of outsourcing cluster computing to a cloud	cluster computing;articulo;cost analysis;green computing;cloud computing	This paper compares the total cost of ownership of a physical cluster with the cost of a virtual Cloud-based cluster. For that purpose, cost models for both the physical cluster and the cluster on the Cloud have been developed. The model for the physical cluster takes into account previous works and incorporates a more detailed study of the costs related to energy consumption and the usage of energy saving strategies. The model for the cluster on the Cloud considers pricing options offered by Amazon EC2, such as reserving instances on a long-term basis, and also considers using tools for powering nodes on and off on demand, in order to avoid the costs associated to keeping idle nodes running. Using these cost models, a comparison is made of physical clusters with Cloud clusters of a similar size and performance. The results show that Cloud clusters are an interesting option for start-ups and other organizations with a high degree of uncertainty with respect to the computational requirements, while physical clusters are still more economically viable for organizations with a high usage rate.	amazon elastic compute cloud (ec2);analysis of algorithms;cloud computing;computation;computer cluster;data center;outsourcing;region of interest;requirement;supercomputer;total cost of ownership	Carlos de Alfonso;Miguel Caballer;Fernando Alvarruiz;Germán Moltó	2013	Future Generation Comp. Syst.	10.1016/j.future.2012.08.014	green computing;simulation;cloud computing;computer cluster;computer science;cost–benefit analysis;operating system;computer security	HPC	-21.27202286075425	62.088055759757964	48983
cabccde04de8695e579dd847f50ed55456fe1a39	design and implementation of an efficient web cluster with content-based request distribution and file caching	content aware web switch;content based request distribution;design and implementation;web cluster;persistent connection;load balance;web caching;content blind web switch	We have implemented an efficient and scalable web cluster named LVS-CAD/FC (i.e. LVS with Content-Aware Dispatching and File Caching). In LVS-CAD/FC, a kernel-level one-way content-aware web switch based on TCP Rebuilding is implemented to examine and distribute the HTTP requests from clients to web servers, and the fast Multiple TCP Rebuilding is implemented to efficiently support persistent connection. Besides, a file-based web cache stores a small set of the most frequently accessed web files in server RAM to reduce disk I/Os and a light-weight redirect method is developed to efficiently redirect requests to this cache. In this paper, we have further proposed new policies related to content-based workload-aware request distribution, in which the web switch considers the content of requests and workload characterization in request dispatching. In particular, web files with more access frequencies would be duplicated in more servers' file-based caches, such that hot web files can be served by more servers. Our goals are to improve cluster performance by obtaining better memory utilization and increasing the cache hit rates while achieving load balancing among servers. Experimental results of practical implementation on Linux show that LVS-CAD/FC is efficient and scales well. Besides, LVS-CAD/FC with the proposed policies can achieve 66.89% better performance than the Linux Virtual Server with a content-blind web switch.	cache (computing);server farm	Mei-Ling Chiang;Yu-Chen Lin;Lian-Feng Guo	2008	Journal of Systems and Software	10.1016/j.jss.2008.02.069	web service;static web page;real-time computing;cache;computer science;load balancing;web api;operating system;web log analysis software;world wide web;computer security;web server;server	OS	-17.968603898176525	70.90081662133144	49007
81ec3e6f9db9f63b1c820900e75ebe8982ed23ae	a trust communication with sip protocol	user agent;protocols;session initiation protocol;pkcs 7;security mechanism;proxy signatory setting;sip protocol;servers;sip security;nonrepudiation service;internet;pkcs 7 session initiation protocol sip security sips non repudiation x509;x 509 certificates trust communication sip protocol session initiation protocol security mechanism nonrepudiation service user agents proxy signatory setting;cryptography;multimedia communication;sips;telecommunication security;non repudiation;servers protocols delay internet multimedia communication cryptography;trust communication;proxy server;user agents;telecommunication security signalling protocols;x 509 certificates;signalling protocols	Session Initiation Protocol (SIP) is an application-layer signaling and control protocol for creating, modifying and terminating sessions including Internet telephone calls, multimedia distribution and multimedia conferences. Flexible, extensible and open, SIP has a complete security mechanism that allows security of both media and signaling. SIP RFC recommends the use of TLS or DTLS to provide an adequate level of protection against attacks. However, missing from these protocols is a way to perform non-repudiation service when used in SIP networks to provide a high level of trust between User Agents. In this paper we propose to modify and sign some header fields in the SIP request messages in order to achieve non-repudiation service over TLS/DTLS. To facilitate the implementation, the portability and the test of our proposal, called SIP SIGN, the new messages will be created and treated by a redirect server named “Proxy Signatory” setting between the User Agents and their local proxy servers. This “Proxy Signatory” provides the caller the ability to sign its SIP messages using certificates such as X.509 and the callee to verify and validate the signature and the caller identity.	ampersand;datagram transport layer security;electronic billing;high-level programming language;newman's lemma;non-repudiation;proxy server;redirection (computing);routing;server (computing);signature;software portability;traceability;x.509	Samer El-Sawda;Pascal Urien;Rami El Sawda	2010	ACS/IEEE International Conference on Computer Systems and Applications - AICCSA 2010	10.1109/AICCSA.2010.5587028	user agent;sip trunking;computer science;session initiation protocol;internet privacy;computer security;computer network	Security	-26.234499113874225	86.82020222236727	49011
5456a7ad13c22d41aba08c831574409725aa0339	a cloud-native approach to 5g network slicing		5G networks will support very diverse and challenging requirements. Network slicing offers an effective way to unlock the full potential of 5G networks and meet those requirements using a common network infrastructure. This article presents a cloud-native approach to network slicing that advances a fundamental rethinking of the mobile network to shift its architectural vision from a network of entities to a network of capabilities, and its driving purpose from a network for connectivity to a network for services. The approach covers the entire life cycle of network slices, encompassing their design, creation, deployment, customization, and optimization. We provide an overview of our cloud-native approach to network slicing and describe a proof-of-concept implementation that demonstrates its key principles.	entity;mathematical optimization;requirement;sim lock;software deployment	Sameerkumar Sharma;Ray Miller;Andrea Francini	2017	IEEE Communications Magazine	10.1109/MCOM.2017.1600942	computer network;network architecture;intelligent computer network;computer science;network management station;dynamic circuit network;wireless wan;distributed computing;open network architecture;core network;network access control	Mobile	-15.306963063085611	85.98698856377914	49020
78ee31069606b91f46c8eb25e0aa2a828c5aae93	analysis of preemptive periodic real time systems using the (max,plus) algebra	graph theory robots synchronisation periodic control real time systems control system analysis computing;graph theory;plus algebra;algebre max;max;control system analysis computing;fixed priority preemption;graphes d evenements;time measurement;clocks;real time;testing;robotics;fixed priority;indexing terms;orccad software;real time systems algebra delay synchronization robot control computational complexity performance analysis testing clocks time measurement;periodic real time systems;plus;synchronisation;periodic control;robot control;algebra;preemption a priorite fixe;computational complexity;synchronization;robots;performance analysis;marked graphs;max plus algebra;response times;periodic systems;systemes temps reel periodiques;response times fixed priority preemption marked graphs max plus algebra periodic systems real time systems synchronization robotics orccad software;real time systems	In this paper we present the model of a system of periodic real-time tasks with fixed priorities, preemption and synchronization, performed by a robot controller, using Marked Graphs. Then, with the help of the (max,plus) algebra, we derive simple tests to check real time constraints on those tasks such as response times and the respect of deadlines. This method takes into account precedence and synchronisation constraints and is not limited to a particular scheduling policy. keywords Periodic real-time systems, synchronisation, fixed priority preemption, marked graphs, (max,plus) algebra.	marked graph;preemption (computing);real-time clock;real-time computing;real-time locating system;scheduling (computing)	François Baccelli;Bruno Gaujal;Daniel Simon	1999	IEEE Trans. Contr. Sys. Techn.	10.1109/87.998024	synchronization;real-time computing;computer science;graph theory;theoretical computer science;control theory;distributed computing;robotics	Embedded	-10.150596662064013	61.68336943716008	49028
faaf7eeb5884167364dff3df0ca76f3547e0ce26	optimal virtual machine resources scheduling based on improved particle swarm optimization in cloud computing	cloud computing;particle swarm optimization	This paper presents virtual machines resources scheduling algorithm taking into computing capacity of processing elements and consideration their computational complexity. We apply the improved particle swarm optimization to solve virtual machines resources scheduling problem. The experiments show that the improved algorithms can provide effective solutions that the original algorithm can not provide on cloud systems.	algorithm;cloud computing;computational complexity theory;experiment;mathematical optimization;particle swarm optimization;scheduling (computing);virtual machine	Hao Yuan;Changbing Li;Maokang Du	2014	JSW		fair-share scheduling;mathematical optimization;multi-swarm optimization;flow shop scheduling;cloud computing;dynamic priority scheduling;computer science;theoretical computer science;operating system;two-level scheduling;distributed computing;utility computing;particle swarm optimization	HPC	-18.325925941814933	63.21948458158401	49043
e43760e993f5c06f5a2718b394056ff90cf02d71	evolving optimally reliable networks by adding an edge	closed form solution;upper bound;network reliability;failure probability;telecommunication networks	Telecommunication networks of known reliability are frequently upgraded as traffic patterns change. In this paper we will present theorems and an algorithm which could be used to solve the problem of adding a single link of known failure probability to a network such that the marginal increase in 2-terminal reliability is maximized. The theorems presented will subsequently be used to derive upper bounds on the 2-terminal reliability of networks with varying numbers of links. A closed form solution for the maximum possible increase in 2-terminal reliability is presented, both for the case of adding a single edge and in the more general nedge problem.	algorithm;marginal model	Tony White	2002			closed-form expression;mathematical optimization;computer science;distributed computing;reliability;upper and lower bounds;computer network	Theory	-5.793187003185812	78.86171923592605	49098
1763f23e600e4bcde685549e4415316d3defab47	a methodology for estimating interdomain web traffic demand	time varying;web pages;web;web accessibility;traffic flow;autonomic system;conference paper;estimation;analysis;traffic demand;interdomain;traffic matrix;geographic database	"""This paper introduces a methodology for estimating interdomain Web traffic lows between all clients worldwide and the ervers belonging to over one housand content providers. The idea is to use the server logs from a large ontent Delivery Network (CDN) to identify client downloads of content provider (i.e., publisher) Web pages. For each of these Web pages, a client typically downloads some objects from the content provider, some from the CDN, and perhaps some from third parties such as banner advertisement agencies. The sizes and sources of the non-CDN downloads associated with each CDN download are estimated separately by examining Web accesses in packet traces collected at several universities.  The methodology produces a (time-varying) interdomain HTTP traffic demand matrix pairing several hundred thousand blocks of client IP addresses with over ten thousand individual Web servers. When combined with geographical databases and routing tables, the matrix can be used to provide (partial) answers to questions such as """"How do Web access patterns vary by country?"""", """"Which autonomous systems host the most Web content?"""", and """"How stable are Web traffic flows over time?""""."""	autonomous system (internet);content delivery network;database;download;hypertext transfer protocol;inter-domain;network packet;routing table;server (computing);the matrix;tracing (software);web banner;web content;web page;web traffic	Anja Feldmann;Nils Kammenhuber;Olaf Maennel;Bruce M. Maggs;Roberto De Prisco;Ravi Sundaram	2004		10.1145/1028788.1028833	web service;web application security;estimation;static web page;web development;data web;web analytics;web mapping;telecommunications;computer science;traffic flow;web navigation;web accessibility;web page;analysis;internet privacy;web 2.0;world wide web;computer security;web server;mashup;computer network	Metrics	-25.611528479869396	85.8915753347176	49155
0a46a270a3361580b892fb639daf1865a3f8d78d	enhancing content distribution through information-aware mechanisms	routing;servers;streaming media;content distribution networks;optimization;proposals;delays	Densely-deployed Content Delivery Network (CDN) solutions are used today for delivering a significant fraction of the Internet traffic through replication mechanisms. However, these networks show technological limitations when dealing with the proliferation of rich media-enabled applications such as video streaming. This paper introduces a new approach to content delivery incorporating Information-Centric Networking principles without requiring any change in the underlying network. This solution improves content delivery performance and enables the implementation of cost efficient request routing strategies. We also develop an on-line algorithm based on Lyapunov optimization theory which allows to dynamically generate effective strategies in order to satisfy operator's objectives. By using real video streaming request traces, it has been shown that the global hit ratio can be increased up to 100% while delivering the content 30% faster compared to currently deployed content delivery schemes. Furthermore, the proposed approach offers stable behavior during peak traffic.	content delivery network;cost efficiency;digital distribution;hit (internet);interactive media;lyapunov fractal;lyapunov optimization;online algorithm;online and offline;routing;simulation;time complexity;tracing (software)	Walid Benchaita;Gioacchino Tangari;Samir Ghamri-Doudane;Sébastien Tixeuil	2016	2016 5th IEEE International Conference on Cloud Networking (Cloudnet)	10.1109/CloudNet.2016.50	real-time computing;computer science;distributed computing;computer network	HPC	-10.982358178939517	83.17617307052033	49160
0a337fe487791f94e65c5dc7c8dd52c26fbb1be5	c-chord: hierarchical peer-to-peer protocol over a fully decentralized iaas cloud	protocols;reliability;overlay networks;multikey web service query c chord hierarchical peer to peer protocol fully decentralized iaas cloud computing infrastructure as a service centralized client server approach peer to peer hierarchical chord network virtual peers;computational modeling;web services client server systems cloud computing peer to peer computing;c chord cloud computing iaas hierarchical chord web service lookup peer to peer overlay network;peer to peer computing;peer to peer computing protocols overlay networks cloud computing reliability computational modeling;cloud computing	Web Services publication and discovery are commonly implemented over a centralized client-server approach. Therefore, at high requests' rate server nodes are bottlenecked and the system scale is unable to follow the increasing load. To address this issue, we consider the Cloud computing concept where huge amount of resources such as, storage, processing and bandwidth capacities are available on demand. In this paper, we propose a decentralized cloud system, which aims to improve the system performances, such as requests latency and reliability, in compare with the classical centralized cloud architecture. Our solution, called C-Chord, is based on peer-to-peer hierarchical Chord network operating over a fully decentralized Infrastructure as a Service (IaaS) cloud system. In order to enhance the reliability of Web services, C-Chord relies on virtual peers that support diversification of Web Services class. It also introduces a multi-keys Web service query instead of one single key.	centralized computing;client–server model;cloud computing;diversification (finance);peer-to-peer;performance;server (computing);web service	Eya Dhib;Nabil Tabbane;Nawel Zangar;Khaled Boussetta	2014	2014 International Conference and Workshop on the Network of the Future (NOF)	10.1109/NOF.2014.7119776	cloud computing;computer science;cloud testing;distributed computing;utility computing;world wide web;computer network	HPC	-20.092086043600013	69.43069700365244	49167
36c5d74ae0f84b2392c8333ffc3103ddfb1cc64a	an efficient accounting architecture for qos-aware internet traffic	business models;quality of service;internet traffic;network management;resource manager;business model;intserv;network analysis	The widespread usage of Internet-based applications and the large diversity of these applications, particularly in terms of Quality of Service (QoS) requirements, necessitate developing a QoS-aware Internet accounting architecture. Developing such a architecture has grown to be increasingly essential for service pricing, cost recovery, resource management, and network analysis. This paper proposes an efficient Internet accounting architecture that employs various packet, flow, link, and end-to-end QoS parameters in a way that allows for a simple and practical implementation. With the help of the proposed architecture, a number of eBusiness applications and advanced network-tracking techniques can be efficiently developed.	end-to-end principle;internet;network packet;quality of service;requirement;traffic flow (computer networking)	Abdelnasser Abdelaal;Hesham H. Ali	2005			internet traffic;internet traffic engineering;value-added network;computer science;internet backbone;computer network;the internet;architecture;quality of service;accounting;internet transit	Networks	-9.6032579934743	85.23286002251805	49199
56079a251d1522dbd5d071fba08f2e4dc6540bdd	on the efficiency of collaborative caching in isp-aware p2p networks	locality aware peer selection collaborative caching inter isp traffic p2p networks peer to peer networks cache servers resource allocation context awareness optimization locality unaware peer selection;optimisation;resource manager;resource management;collaboration;telecommunication traffic;servers;network servers;internet;servers collaboration streaming media resource management bandwidth optimization peer to peer computing;streaming media;telecommunication traffic internet mobile computing network servers optimisation peer to peer computing telecommunication services;telecommunication services;bandwidth;optimization;p2p networks;peer to peer computing;mobile computing	Collaborative ISP caching has been advocated to reduce the otherwise significant amount of costly inter-ISP traffic generated by peer-to-peer (P2P) applications. The fundamental design criteria employed by ISP cache servers are, however, not well understood, with respect to dynamic P2P traffic patterns, ISP peering policies and cache server capacity constraints. In particular, there is a lack of investigations on the design and analysis of resource allocation mechanisms with awareness of inter-ISP traffic and ISP policies in the context of collaborative ISP caching — which is our focus in this study. In this paper, by characterizing practical inter-ISP traffic patterns, we have developed a theoretical framework to analyze representative cache resource allocation schemes within the design space of collaborative caching, with a particular focus on minimizing costly inter-ISP traffic. The optimization framework incorporates both locality-aware and locality-unaware peer selection strategies and ISP peering agreements, in order to examine their respective effects on the design of ISP collaborative caching mechanisms. Our analyses not only help us understand the traffic characteristics of existing P2P systems in light of realistic elements, but also offer fundamental insights into designing collaborative ISP caching mechanisms.	cache (computing);locality of reference;mathematical optimization;peer-to-peer;peering;server (computing);systems design;user experience;web cache	Jie Dai;Bo Li;Fangming Liu;Baochun Li;Hai Jin	2011	2011 Proceedings IEEE INFOCOM	10.1109/INFCOM.2011.5934903	the internet;computer science;telecommunications service;resource management;operating system;distributed computing;world wide web;bandwidth;server;computer network;collaboration	Metrics	-15.527426257520677	76.21176431711667	49214
3d8b53581886c5b25ff5811bea97eeb0b9fba5d1	a virtual machine placement taxonomy	minimization;optimization taxonomy placement scheduling consolidation cloud computing;placement;virtual machining;virtual machines carbon compounds cloud computing contracts quality of service;carbon dioxide emissions virtual machine placement taxonomy cloud computing data cloud markets cloud infrastructure management service level agreement quality of service qos cloud service pricing schemes;consolidation;optimization linear programming cloud computing context energy consumption minimization virtual machining;energy consumption;scheduling;taxonomy;linear programming;optimization;context;cloud computing	Cloud computing data enters dynamically provide millions of virtual machines (VMs) in actual cloud markets. In this context, Virtual Machine Placement (VMP) is one of the most challenging problems in cloud infrastructure management, considering the large number of possible optimization criteria and different formulations that could be studied. VMP literature include relevant research topics such as energy efficiency, Service Level Agreement (SLA), Quality of Service (QoS), cloud service pricing schemes and carbon dioxide emissions, all of them with high economical and ecological impact. This work classifies an extensive up-to-date survey of the most relevant VMP literature proposing a novel taxonomy in order to identify research opportunities and define a general vision on this research area.	cloud computing;mathematical optimization;quality of service;service-level agreement;taxonomy (general);virtual machine	Fabio Lopez Pires;Benjamín Barán	2015	2015 15th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing	10.1109/CCGrid.2015.15	consolidation;real-time computing;simulation;cloud computing;computer science;linear programming;operating system;cloud testing;database;distributed computing;scheduling;taxonomy;placement	HPC	-20.978453317222765	62.88348319170869	49353
ddfcce88729f684043f5fb7d1290015e0bca858b	software defined neighborhood area network for smart grid applications		Abstract Information gathered from the Smart Grid (SG) devices located in end user premises provides a valuable resource that can be used to modify the behavior of SG applications. Decentralized and distributed deployment of neighborhood area network (NAN) devices makes it a challenge to manage SG efficiently. The NAN communication network architecture should be designed to aggregate and disseminate information among different SG domains. In this paper, we present a communication framework for NAN based on wireless sensor networks using the software defined networking paradigm. The data plane devices, such as smart meters, intelligent electronic devices, sensors, and switches are controlled via an optimized controller hierarchy deployed using a separate control plane. An analytical model is developed to determine the number of switches and controllers required for the NAN and the results of several test scenarios are presented. A Castalia based simulation model was used to analyze the performance of modified NAN performance.		Nazmus S. Nafi;Khandakar Ahmed;Mark A. Gregory;Manoj Datta	2018	Future Generation Comp. Syst.	10.1016/j.future.2017.09.064	software deployment;wireless sensor network;architecture;telecommunications network;smart grid;software-defined networking;distributed computing;computer network;forwarding plane;castalia;computer science	Arch	-19.478930829266236	82.01082409229926	49366
c890f8b357b3736dc713d0acea796659283165a5	label switching and ip version 6	ip version 6 ip switching;telecommunication control;asynchronous transfer mode proposals packet switching multiprotocol label switching scalability telecommunication switching routing protocols virtual colonoscopy switches information technology;mpls;packet switching;transport protocols;telecommunication network routing;tag switching;ip;packet switching transport protocols telecommunication network routing asynchronous transfer mode telecommunication control;ip routing;simulation study;label switching;atm;asynchronous transfer mode;network layer forwarding ip version 6 mpls hierarchical address structure route aggregation control driven label switching tag switching destination site address simulation studies	IPv6 was designed to increase Internet global address space to accommodate the rapidly increasing numbers of users and applications that require unique global IP addresses and help enable a global environment where the addressing rules of the network are again transparent to applications. As an early pioneer in IPv6 technology since its inception, Cisco has been a driving force in developing IPv6 standards through various standards bodies, including the Internet Engineering Task Force, and has been shipping a wide variety of end-to-end IPv6 product and solutions.	end-to-end principle;global variable;multiprotocol label switching;partitioned global address space	Paul Boustead;Scott A. Barnett;Joe F. Chicharo;Gary J. Anido	1998		10.1109/ICCCN.1998.998813	internet protocol;multiprotocol label switching;label distribution protocol;virtual routing and forwarding;label information base;lan switching;telecommunications;computer science;label switching;optical ip switching;ip forwarding;asynchronous transfer mode;l2tpv3;distributed computing;network address translation;atmosphere;ip tunnel;transport layer;packet switching;telecommunications network;computer network	Metrics	-11.21087314414409	87.59436638436863	49426
07de0f64259268836266ab70edaee01ebb6f0347	performance evaluation of web proxy cache replacement policies	replacement policies;performance evaluation;proxy caching;side effect;cache replacement;network traffic;cable modem;world wide web;web proxy;trace driven simulation;replacement policy	The continued growth of the World-Wide Web and the emergence of new endtechnologies such as cable modems necessitate the use of proxy caches to reduce network traffic and Web server loads. In this paper we analyze the importanc different Web proxy workload characteristics in making good cache replacem decisions. We evaluate workload characteristics such as object size, recen reference, frequency of reference, and turnover in the active set of objects. Trace-d simulation is used to evaluate the effectiveness of various replacement policies for proxy caches. The extended duration of the trace (117 million requests collected five months) allows long term side effects of replacement policies to be identified quantified. Our results indicate that higher cache hit rates are achieved using size-based replac policies. These policies store a large number of small objects in the cache, increasing the probability of an object being in the cache when requested. To ac higher byte hit rates a few larger files must be retained in the cache. We found freque based policies to work best for this metric, as they keep the most popular files, regar of size, in the cache. With either approach it is important that inactive objects removed from the cache to prevent performance degradation due to pollution.	active set method;byte;cable modem;cache (computing);elegant degradation;emergence;network traffic control;performance evaluation;proxy server;reference architecture;server (computing);side effect (computer science);simulation;web cache;web server;world wide web	Martin F. Arlitt;Rich Friedrich;Tai Jin	2000	Perform. Eval.	10.1016/S0166-5316(99)00062-0	bus sniffing;real-time computing;cache coloring;page cache;cache;cable modem;computer science;cache invalidation;database;smart cache;cache algorithms;cache pollution;world wide web;side effect	Metrics	-17.8742350165101	71.26782601000917	49455
cff1031860833a99a1a3c14032b2ec6bdf249ac5	pce based grid networking	computer networks processor scheduling routing computer architecture grid computing bandwidth internetworking computational modeling protocols telecommunication traffic;virtual service domain framework;signaling mechanism;path computation element;distributed heterogeneous resources;resource reservation;interdomain routing;ietf pce protocol;telecommunication network routing;telecommunication signalling grid computing internetworking telecommunication network routing;inter domain routing;grid internetworking architecture;internetworking;multiple domain environment;telecommunication signalling;grid computing;distributed heterogeneous resources path computation element model grid internetworking architecture virtual service domain framework multiple domain environment signaling mechanism interdomain routing resource reservation ietf pce protocol;path computation element model	Grid allows creation of abundant services by sharing widely distributed heterogeneous resources. As the Grid technology evolves, the network is elevated as the first-class resource like other Grid resources, i.e. CPU and storages, which can be managed and scheduled altogether. In this paper, we first propose a Grid internetworking architecture based on PCE (Path Computation Element) model. Within this architecture, a virtual service domain framework is presented in a multiple-domain environment. Furthermore, a PCE-based network element and a signaling mechanism are designed to address the inter-domain routing and resource reservation. Within our knowledge, this is the first work ever for Grid internetworking based on IETF PCE protocol.	central processing unit;computation;inter-domain;internetworking;routing	Tsegereda Beyene;Yufeng Xin;Mosaddaq Turabi;Khalid Raza	2007	2007 12th IEEE Symposium on Computers and Communications	10.1109/ISCC.2007.4381556	real-time computing;semantic grid;computer science;distributed computing;grid computing;computer network	HPC	-17.381635818771464	82.67672995310032	49472
986a718caf0a7654f8ef49a32c0c3f59ffd5cec3	raven: improving interactive latency for the connected car		Increasingly, vehicles sold today are connected cars: they offer vehicle-to-infrastructure connectivity through built-in WiFi and cellular interfaces, and they act as mobile hotspots for devices in the vehicle. We study the connection quality available to connected cars today, focusing on user-facing, latency-sensitive applications. We find that network latency varies significantly and unpredictably at short time scales and that high tail latency substantially degrades user experience. We also find an increase in coverage options available due to commercial WiFi offerings and that variations in latency across network options are not well-correlated. Based on these findings, we develop RAVEN, an in-kernel MPTCP scheduler that mitigates tail latency and network unpredictability by using redundant transmission when confidence about network latency predictions is low. RAVEN has several novel design features. It operates transparently, without application modification or hints, to improve interactive latency. It seamlessly supports three or more wireless networks. Its in-kernel implementation allows proactive cancellation of transmissions made unnecessary through redundancy. Finally, it explicitly considers how the age of measurements affects confidence in predictions, allowing better handling of interactive applications that transmit infrequently and networks that exhibit periods of temporary poor performance. Results from speech, music, and recommender applications in both emulated and live vehicle experiments show substantial improvement in application response time.	built-in self-test;connected car;emulator;experiment;interrupt latency;kernel (operating system);recommender system;response time (technology);scheduling (computing);user experience	Hyunjong Lee;Jason Flinn;Tulio P. Vieira	2018		10.1145/3241539.3241571	computer network;wireless network;redundancy (engineering);response time;latency (engineering);computer science;user experience design	Mobile	-18.693267454224696	76.43837488196596	49478
d0c6d7cd31fa7731dd41f89cfb100dd68974fe51	networking and communication in cyber physical systems		Cyber-physical systems (CPSs) are emerging as a new technology, which is used to provide seamless interaction between the physical and cyber worlds. This novel paradigm is a natural evolution and extension of wireless sensor networks (WSNs) and control models to allow for effective monitoring and control of physical systems from the computing environment. In order to support this interface and allow such smooth interactions, efficient networking and communication between the physical and cyber worlds take a very important and critical role. In this paper, we identify the various categories and applications of CPS systems, and characterize the associated data traffic that is generated. We also discuss the different protocols and requirements that are needed at the various networking layers for these applications. Subsequently, we identify important parameters such as bandwidth, delay, reliability, security, and mobility, which are essential in order to allow for effective and robust operation of the various CPSs.	communications protocol;control system;cyber-physical system;interaction;programming paradigm;requirement;seamless3d;unmanned aerial vehicle	Imad Jawhar;Jameela Al-Jaroodi;Hassan Noura;Nader Mohamed	2017	2017 IEEE 37th International Conference on Distributed Computing Systems Workshops (ICDCSW)	10.1109/ICDCSW.2017.31	wireless sensor network;network layer;cyber-physical system;physical system;computer network;distributed computing;computer science	EDA	-20.470932312708342	79.81239362375155	49496
a5e2a2286152631985c9447905c29f7b3ed5015a	a structured overlay for non-uniform node identifier distribution based on flexible routing tables	telecommunication network routing overlay networks;routing peer to peer computing structural rings algorithm design and analysis sorting clocks fingers;frt method structured overlay nonuniform node identifier distribution flexible routing tables nonuniform node identifier distributions	A large fraction of structured overlays work efficiently as long as node identifiers follow a uniform distribution with high probability. There is another kind of structured overlay supporting non-uniform node identifier distributions and it enables a DHT to support range queries. This paper presents FRT-Chord#, such a structured overlay for non-uniform node identifier distributions. It is based on Flexible Routing Tables (FRT), a method for designing structured overlays, and inherits advantageous features of FRT, that existing overlays do not hold. Such features include extensibility, arbitrary routing table capacity.	distributed hash table;extensibility;identifier;international solid-state circuits conference;peer-to-peer;range query (data structures);routing table;with high probability	Takehiro Miyao;Hiroya Nagao;Kazuyuki Shudo	2014	2014 IEEE Symposium on Computers and Communications (ISCC)	10.1109/ISCC.2014.6912614	policy-based routing;routing;static routing;overlay network;computer science;dynamic source routing;theoretical computer science;destination-sequenced distance vector routing;key-based routing;distributed computing;link-state routing protocol;geographic routing;computer network	OS	-10.404552270813163	72.94897555186111	49518
d99b6d74c3f617b9753ec23216f27fd73d6022c9	verification of flow matching functionality in the forwarding plane of openflow networks		SUMMARY In OpenFlow, data and control plane are decoupled from switches or routers. While the data plane resides in the switches or routers, the control plane might be moved into one or more external servers (controllers). In this article, we propose verification mechanisms for the data plane functionality of switches. The latter consists of two parts: (1) Flow-Match Header part (to match a flow of incoming packets) and (2) action part (e.g., to forward incoming packets to an outgoing port). We propose a mechanism to verify the Flow-Match Header part of the data plane. The mechanism can be executed at the controller, or on an additional device or server (or virtual machines) attached to the network. Deploying a virtual machine (VM) or server for verification may decrease the load of the controller and/or consumed bandwidth between the controller and a switch. We propose a heuristic to place external verification devices or VMs in a network such that the verification time can be minimized. Verification time with respect to consumed resources are evaluated through emulation experiments. Results confirm that the verification time using the proposed heuristic is indeed shortened significantly, while requiring low bandwidth resources.	control plane;emulator;experiment;forwarding plane;heuristic;network switch;openflow;openvms;router (computing);server (computing);virtual machine	Sachin Sharma;Wouter Tavernier;Sahel Sahhaf;Didier Colle;Mario Pickavet;Piet Demeester	2015	IEICE Transactions		openflow;out-of-band management;real-time computing;verification;telecommunications;computer science;operating system;distributed computing;computer network	OS	-14.529592082296052	81.8119848503872	49524
8dc691d29dbd67c09217df217da7226a2e78ccd6	node status detection and information diffusion in router network using scale-free network		In the field of computer networks various routing and inter networking algorithms and protocols have been introduced according to many performance metrics like network topology, scalability, speed, and congestion control requirements. In this paper we have used the concept of scale-free network theory to design a more robust data dissemination approach which can be used in one dynamical Autonomous Systems (AS) to know the appearance and disappearance of nodes, and speedily propagate the information to all nodes in the routers network. By taking advantage of the features of scale-free network behavior as found inhomogeneous structure, short path lengths, highly cluster and epidemiological spreading an enhanced algorithm has been introduced which effectively finds the node status in the network and speedily broadcasts the information of status to all nodes in the network.	router (computing)	Abdul Waheed Mahesar;Azeddin Messikh;Asadullah Shah;Mohamed Ridza Wahiddin	2014			computer network;linear network coding;network delay;intelligent computer network;network simulation;network topology;network architecture;overlay network;network traffic control;distributed computing;computer science	HPC	-8.969106689993348	78.27019302858376	49539
09a86e9fcc907dd7cb6a245c1f64cb1739d9eac9	data-intensive workflow scheduling in cloud on budget and deadline constraints		With the development of Cloud Computing, large-scale applications expressed as scientific workflows are often executed in cloud. The problems of workflow scheduling are vital for achieving high efficient and meeting the needs of users in clouds. In order to obtain more cost reduction as well as maintain the quality of service by meeting the deadlines, this paper proposed a novel heuristic, PWHEFT (Path-task Weight Heterogeneous Earliest Finish Time), based on Heterogeneous Earliest Finish Time (HEFT). The criticality of tasks in a workflow and data transmission between resources are considered in PWHEFT while ignored in some other algorithms. The heuristic is evaluated using simulation with five different real world workflow applications. The simulation results show that our proposed scheduling heuristic can significantly improve planning success rate.		Xin Zhang;Changze Wu;Kaigui Wu	2016		10.1007/978-3-319-59288-6_24	scheduling (computing);computer science;distributed computing;real-time computing;cloud computing;quality of service;earliest deadline first scheduling;dynamic priority scheduling;cost reduction;workflow;heuristic	HPC	-18.651608579917077	62.79377413526324	49617
9d4ac84890b6943409277cf611d49df9b2963454	ip fast reroute: lightweight not-via without additional addresses	ip fast reroute;address management;complexity theory;routing;telecommunication network routing computational complexity ip networks;prototypes;telecommunication network routing;ip failure recovery scheme;ieee;computational complexity ip fast reroute carrier grade transport technology ip failure recovery scheme address management;computational complexity;carrier grade transport technology;ip networks;peer to peer computing;failure recovery;local area networks;testing prototypes computational complexity routing proposals communications society informatics telecommunication traffic distributed algorithms peer to peer computing	In order for IP to become a full-fledged carriergrade transport technology, a native IP failure-recovery scheme is necessary that can correct failures in the order of milliseconds. IP Fast ReRoute (IPFRR) intends to fill this gap, providing fast, local and proactive handling of failures right in the IP layer. Building on experiences and extensive measurement results collected with a prototype implementation of the prevailing IPFRR technique, Not-via, in this paper we identify high address management burden and computational complexity as the major causes of why commercial IPFRR deployment still lags behind, and we present a lightweight Not-via scheme, which, according to our measurements, improves these issues.	amortized analysis;carrier grade;central processing unit;computational complexity theory;definition;fast reroute;internet protocol suite;performance evaluation;protocol stack;prototype;routing;shortest path problem;software deployment;time complexity	Gábor Enyedi;Péter Szilágyi;Gábor Rétvári;András Császár	2009	IEEE INFOCOM 2009	10.1109/INFCOM.2009.5062229	local area network;routing;real-time computing;computer science;distributed computing;prototype;computational complexity theory;computer network	Mobile	-7.777696448142417	82.01261865398112	49684
a2f7ab1fc72e5a470e1164b5cf75b1750cd06e41	distribution aware collaborative spread replication for rare objects in unstructured peer-to-peer networks	distribution aware;replication;rare objects;query;peer to peer	Existing unstructured peer-to-peer networks have low efficiency to locate the rare objects. Although various algorithms have been provided to address this problem, they do not distinguish whether the objects are rare or not and always incur unnecessary bandwidth consumption. In this paper, we presented a distribution aware replication method for rare objects.  Unlike the traditional replication method, we not only replicate the objects but also replicate the peers’ requirement, because we believe that the rare objects are also always rarely queried. Distribution aware can control the number of the copy to avoid unnecessary overhead. Our replication methods are actually index replication named collaborative spread index replication.  The distribution aware methods include the multi-hop aware and random walk sampling aware. When execute replicating, the algorithm will decide whether replicating the index or not according to the local distribution information obtained. The experimental results show that distribution aware replication can well support to find the rare objects in unstructured peer-to-peer networks with low overhead.	peer-to-peer	Wenming Ma;Yujie Zhang;Xiangwu Meng	2013	JNW	10.4304/jnw.8.5.991-998	replication;computer science;theoretical computer science;distributed computing;world wide web;statistics	PL	-11.608436238123401	73.17748208252463	49690
0b8fac873889859f07f9d95116203e3be75673ba	network science experimentation scale and composition in a virtualized experimentation environment	complexity theory;bridges;servers;statistics;scalability;sociology;cloud computing	The Network Science Collaborative Technology Alliance (NS-CTA) conducts multi-genre network science experimentation that attempts to capture the fundamental underlying commonalities across the social, information and communication networks. Due to the complex nature of network science, there exists a broad variance in experimentation requirements in regard to scalability, fidelity and tractability. In response to this diversity, the NS-CTA has leveraged cloud-based virtual experimentation environments to achieve their experimentation goals. In this paper we consider how the network science specific features exposed by the virtualized experimentation environments affect the scaling and composition of simulation based experiment designs.	cloud computing;design of experiments;experiment;image scaling;network science cta;requirement;scalability;simulation;telecommunications network	John P. Hancock;Kelvin Marcus	2015	MILCOM 2015 - 2015 IEEE Military Communications Conference	10.1109/MILCOM.2015.7357639	simulation;computer science;distributed computing;management science	HPC	-29.16336124995831	63.14199016837793	49706
9d13428a146c2f4a9bb07cc1f891b688a3561198	on the user-scheduler dialogue: studies of user-provided runtime estimates and utility functions	utility functions;utility function;scheduling;high performance computer;runtime estimates;production scheduling	Effective communication between user and scheduler is an important prerequisite to achieving a successful scheduling outcome from both parties’ perspectives. In a grid or stand-alone high-performance computing (HPC) environment, this communication typically takes the form of a user-provided job script containing essential configuration information, including processors/resources required, a requested runtime, and a priority. Users’ requested runtimes are notoriously inaccurate as a predictor of actual runtimes. This study examines whether users can improve their runtime estimates if a tangible reward is provided for accuracy. We show that under these conditions, about half of users provide an improved estimate, but there is not a substantial improvement in the overall average accuracy. Priority, as implemented in many production schedulers, is a very crude approximation of the value users may attach to timely job completion. We show users are capable of providing richer utility functions than most schedulers elicit. Thus we explore two elements of the user–scheduler dialogue to understand if accuracy and completeness of information conveyed could be improved.	approximation;central processing unit;kerrison predictor;runtime system;scheduling (computing);supercomputer	Cynthia Bailey Lee;Allan Snavely	2006	IJHPCA	10.1177/1094342006068414	parallel computing;real-time computing;simulation;computer science;operating system;scheduling;scheduling	HPC	-18.50176625043698	60.724853751181335	49717
f77b2359db8a6e99b4385377fedabcbc1abe02fe	the ready-to-go virtual circuit protocol: a loss-free protocol for multigigabit networks using fifo buffers	circuits delay transport protocols communication system traffic control lightning testing prototypes communication system control switches communication switching;sistema fila espera;teletrafic;transmision paquete;systeme attente;mode transfert asynchrone;architecture systeme;protocole transmission;40 gbit s ready to go virtual circuit protocol loss free protocol multigigabit networks fifo buffers lossless communication lossless transport roundtrip delay immediate transmission protocol abr traffic thunder and lightning testbed university of california flow control protocol connection control protocol rgvc protocol link capacity buffer space node frozen capacity constraints transmission rate allocation bookkeeping measurement based scheme estimation based scheme fibre optic atm network packet transmission;reseau ordinateur;virtual circuit;telecommunication congestion control;buffer storage;university of california;packet switching;conmutacion por paquete;packet switching transport protocols buffer storage telecommunication traffic telecommunication congestion control asynchronous transfer mode optical fibre networks channel capacity;computer network;transport protocols;optical fibre networks;fifo buffers;protocolo transmision;telecommunication traffic;teletrafico;channel capacity;rate allocation;queueing system;red ordenador;teletraffic;packet transmission;arquitectura sistema;capacity utilization;system architecture;flow control;transmission paquet;switch design;commutation paquet;asynchronous transfer mode;flow control protocols;transmission protocol	The Ready-to-Go Wrtual Circuti protocol (or RGVC) is an immediate transmission protocol, in which the source need not wait for an end-to-end roundtrip delay for reservations to he made before transmitting the data. The protocol is designed to handle the lossless transport of ABR traf& and will be used in the 40 Gb/s Thunder and Lightning testbed being profotyped at the University of California at Santa Barbara (UCSB). An important advantage of the RGVC protocol over previous connection and flow control protocols is that it is suitable for networks in which the switches use FIFO buffers that are shared by multiple sessions. The RGVC protocol ensures lossless communication by coupIing link capacity with buffer space, so that when a portion of a buffer at a node is occupied, a proportional fraction of the incoming capacity to that buffer is frozen. Given the constraints on the frozen capacity, au algorithm is executed at each node to allocate the transmission rate to each FIFO buffer so as to maximize capacity utilization. The requirement that the protocol operate with FIFO buffers at the network nodes poses some unique challenges in the design that are not present in rateand credit-based schemes. Briefly, since several sessions share a common FIFO buffer, per-VC flow control is no longer possible so control over the rate of an individual session ls lost. Also, since the contents of the buffers change dynamically, the buffer composition becomes difficult to determine. For the rate-allocation algorithm of the RGVC protocol to be executed, however, the contents of the FIFO buffers at a node must be known. To implement the bookkeeping required, we present two schemes: the measuremerrtbased schenle, where the bookkeeping function is impIemenfed via measurements, dohe essentially in hardware; and the estimationbased scheme, where the bookkeeping ls done analytically via the exchange of control packets between nodes. hdex TermsFIFO buffers, flow control protocols, switch design.	algorithm;communications protocol;end-to-end principle;fifo (computing and electronics);flow control (data);free protocol;gigabyte;lightning;lossless compression;network switch;testbed;translation lookaside buffer;transmitter;virtual circuit	Emmanouel A. Varvarigos;Vishal Sharma	1997	IEEE/ACM Trans. Netw.	10.1109/90.649570	real-time computing;capacity utilization;telecommunications;computer science;operating system;asynchronous transfer mode;flow control;virtual circuit;transport layer;channel capacity;packet switching;computer network;systems architecture	Networks	-5.706080828063707	88.1804481618371	49751
1c690e867647d181705f789d69754feb4b219058	slack time evaluation with rtsj	real time;real time specification for java;qos;periodic tasks;time interval scheduling	We address in this paper the problem of jointly scheduling hard periodic tasks and soft aperiodic events using the Real-Time Specification for Java (RTSJ). We present the programming constraints of RTSJ and propose slack time evaluation and utilization algorithms which take these constraints into account. We evaluate these algorithms and compare their performances with the Background Scheduling (BS) through simulations.	algorithm;performance;real time java;real-time clock;scheduling (computing);simulation;slack variable	Damien Masson;Serge Midonnet	2008		10.1145/1363686.1363769	parallel computing;real-time computing;quality of service;computer science;distributed computing;least slack time scheduling	Embedded	-10.152987619347067	60.70084695100475	49769
6444d17e3efd37488f2cf7f4dd6ebd34543f384e	hybrid mobile edge computing: unleashing the full potential of edge computing in mobile device use cases		Many different technologies fostering and supporting distributed and decentralized computing scenarios emerged recently. Edge computing provides the necessary on-demand computing power for Internet-of-Things (IoT) devices where it is needed. Computing power is moved closer to the consumer, with the effect of reducing latency and increasing fail-safety due to absent centralized structures. This is an enabler for applications requiring high-bandwidth uplinks and low latencies to computing units. In this paper, a new use case for edge computing is identified. Mobile devices can overcome their battery limitations and performance constraints by dynamically using the edge-computing-provided computational power. We call this new technology Hybrid Mobile Edge Computing. We present a general architecture and framework, which targets the mobile device use case of hybrid mobile edge computing, not only considering the improvement of performance and energy consumption, but also providing means to protect user privacy, sensitive data and computations. The achieved results are backed by the results of our analysis, targeting the energy saving potentials and possible performance improvements.	centralized computing;computation;data anonymization;data masking;decentralized computing;distributed computing;edge computing;fail-safe;hypervisor;internet of things;mobile device;pbkdf2;sandbox (computer security);server (computing)	Andreas Reiter;Bernd Prünster;Thomas Zefferer	2017	2017 17th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing (CCGRID)		real-time computing;distributed computing;autonomic computing;mobile cloud computing;computer science;mobile edge computing;utility computing;fabric computing;mobile computing;edge computing;end-user computing	Arch	-26.551284263669938	67.8759568458478	49902
575adab3d713595df735fb2cc073a28dc35ba2c6	characteristic time routing in information centric networks	characteristic time;routing;information-centric networks;latency	Information centric networking (ICN) aims to transform today’s Internet from a host-centric model to a content-centric one by caching content internally within the network at storage-enabled nodes. Recently, multiple routing and cache management strategies have been proposed [ 1 ,2,3,4,5,6] to improve the userlevel performance, primarily latency in ICN. In this paper, we define latency as the download time for a piece of content. In this paper, we propose a simple routing strategy that leverages the concept of characteristic time to improve latency. Characteristic time for a content in a cache indicates the amount of time in future a recently accessed content is likely to remain in that cache. Our proposed algorithm namely, Characteristic Time Routing (CTR) uses characteristic time information to forward requests to caches where the content is likely to be found. CTR augments native routing strategies (e.g., Dijkstra’s algorithm), works with existing cache management and cache replacement policies and thus can be implemented in ICN prototypes with minimal effort. We perform exhaustive simulation in the Icarus simulator [7] using realistic Internet topologies (e.g., GEANT, WIDE, TISCALI, ROCKETFUEL [8] ) and demonstrate that the CTR algorithm provides approximately 10–50% improvement in latency over state-of-the-art routing and caching management strategies for ICN for a wide range of simulation parameters. © 2016 Elsevier B.V. All rights reserved. l t o r b f f f o m h	cpu cache;cache (computing);dijkstra's algorithm;download;icn gps;routing;simulation	Bitan Banerjee;Anand Seetharam;Amitava Mukherjee;Mrinal K. Naskar	2017	Computer Networks	10.1016/j.comnet.2016.12.009	static routing;real-time computing;simulation;telecommunications;computer science;operating system;distributed computing;computer security;computer network	Networks	-15.264741182722675	75.71180207396988	49931
714756d64c62255dad4056a643128a332c45ec41	cloud computing for environment-friendly data centers	decision support;sustainable energy;server utilization;green it;cloud computing;data centers	The purpose of this paper is to analyze the carbon footprint and utilization rates in a data center. The long-term goal of this work is to give data center administrators an enhanced perspective of data center operations to allow for more energy efficient operation, to lower the carbon footprint, and to promote green data centers. Previous literature shows that low utilization rates in data centers are due to the forecasting of demand to meet spikes in data center use. This management policy has led to many servers running idle the majority of the time which is a waste of resources. We argue that a majority of the data centers should be down sized through decommissioning of phantom servers, virtualization, and shifting spikes in demand to a cloud provider. We use data from the operations of a mid-to-large scale data center in a university. We deploy data mining techniques of decision trees and case-based reasoning to conduct analysis for decision support in cloud computing at data centers. We provide recommendations based on a literature search and our own work. This paper describes our work in progress in the area of developing green data centers.	case-based reasoning;cloud computing;data center;data mining;decision support system;decision tree;imaging phantom;server (computing)	Michael J. Pawlish;Aparna S. Varde;Stefan A. Robila	2012		10.1145/2390021.2390030	simulation;data center services;cloud computing;engineering;data virtualization;operations management;data mining	ML	-25.75910115754833	60.598342703086	49963
9b6bfcb654a39e1581d5b728120f32d84590b744	observing the effect of interprocess communication in auto controlled ant colony optimization-based scheduling on computational grid	interprocess communication;ant colony optimization;arrival rate;scheduling;turnaround time;processing rate	Computational grids allow the sharing of geographically distributed computational resources in an efficient, reliable, and secure manner. Grid is still in its infancy, and there are many problems associated with the computational grid, namely job scheduling, resource management, information service, information security, routing, fault tolerance, and many more. Scheduling of jobs on grid nodes is an NP-class problem warranting for heuristic and meta-heuristic solution approach. In the proposed work, a meta-heuristic technique, auto controlled ant colony optimization, has been applied to solve this problem. The work observes the effect of interprocess communication in process to optimize turnaround time of the job. The proposed model has been simulated in Matlab. For the different scenarios in computational grid, results have been analyzed. Result of the proposed model is compared with another meta-heuristic technique genetic algorithm that has been applied for the same purpose. It is found that auto controlled ant colony optimization not only gives better solution in comparison to genetic algorithm, but also converges faster because initial solution itself is good because of constructive and decision-based policy adapted by the former. Concurrency and Computation: Practice and Experience, 2012.© 2012 Wiley Periodicals, Inc.	ant colony optimization algorithms;computation;computational resource;concurrency control;experience;fault tolerance;genetic algorithm;grid computing;heuristic (computer science);information security;inter-process communication;job scheduler;john d. wiley;matlab;mathematical optimization;np (complexity);routing;scheduling (computing)	Pawan Kumar Tiwari;Deo Prakash Vidyarthi	2014	Concurrency and Computation: Practice and Experience	10.1002/cpe.2977	parallel computing;ant colony optimization algorithms;real-time computing;simulation;computer science;operating system;database;distributed computing;scheduling;turnaround time;inter-process communication	HPC	-16.75690601360325	62.63137873683246	49964
fa88c4a4ded272ee5a1148da1a39ea82dbae7ad3	a linked-list data structure for advance reservation admission control	distributed application;distributed system;controle acces;grain size;largeur bande;lien hypertexte;systeme reparti;informatique mobile;multimedia;enlace hipertexto;chainage donnee;hyperlink;qualite service;sistema repartido;grosor grano;estructura datos;algorithme reparti;anchura banda;data link;bandwidth;algoritmo repartido;structure donnee;access control;advance reservation;information system;quality of service;mobile computing;distributed algorithm;data structure;systeme information;service quality;admission control;calidad servicio;sistema informacion;grosseur grain;ligazon datos	With the development of multimedia and grid technologies, more and more distributed applications require guaranteed quality of service and maintain minimum network resource during their running sessions. Thus advance reservation is necessary because it provides a solution for the need of reserving network resources for future use. Many kinds of data structures were proposed to perform fast and efficient admission control. Most of them are based on the time-slotted method, which needs to make an appropriate tradeoff between the efficiency and the granularity of the time slots. In this paper, a linked-list data structure is proposed to perform the admission control for advance reservation. Compared with the existing bandwidth tree and time-slotted array, the proposed linked list shows better performance.	data structure;distributed computing;linked list;quality of service	Qing Xiong;Chanle Wu;Jianbing Xing;Libing Wu;Huyin Zhang	2005		10.1007/11534310_95	distributed algorithm;real-time computing;quality of service;data structure;data link;telecommunications;computer science;access control;operating system;distributed computing;hyperlink;mobile computing;service quality;information system;bandwidth;grain size;computer network	HPC	-11.87823260340755	69.35373207137557	50056
1e37f3bc052f00e4323cefecc2f72e37f8a6c305	odmca: an adaptive data mining control algorithm in multicarrier networks	modelo dinamico;extraction information;explicit rate;dynamique processus;metodo adaptativo;core storage;oscillations;adaptability;z transformation;adaptabilite;control theory;streaming;communication system;control algorithm;red local;pid controller;storage access;canal evanouissement;sintesis control;guerra;analisis datos;information extraction;algoritmo adaptativo;on line;base donnee tres grande;en linea;data stream;approximation algorithm;adaptive control;dynamic model;high data rate;transformation z;distributed computing;memoria central;methode adaptative;transformacion z;dinamica proceso;memoire centrale;data mining;proportional integral plus;data streams;adaptabilidad;computer network;optimisation combinatoire;local network;adaptive algorithm;data analysis;transmission en continu;dynamic data;war;algorithme adaptatif;pd control;control adaptativo;fouille donnee;control pd;rate allocation;synthese commande;multicarrier communications;modele dynamique;adaptive method;retard;acces memoire;fading channel;algoritmo aproximacion;commande adaptative;acceso memoria;calculo repartido;analyse donnee;en ligne;modele donnee;transmision fluyente;commande proportionnelle derivee;very large databases;algorithme approximation;combinatorial optimization;fading channels;retraso;reseau local;process dynamics;busca dato;calcul reparti;extraccion informacion;guerre;control synthesis;network computing;data models;optimizacion combinatoria;steady state	Multicarrier communication is a promising technique to effectively deliver high data rate and combat delay spread over fading channel, and adaptability is an inherent advantage of multicarrier communication systems. It can be implemented in online data streams. This paper addresses a significant problem in multicarrier networks that arises in data streaming scenarios, namely, todayu0027s data mining is ill-equipped to handle data streams effectively, and pays little attention to the network stability and the fast response [http://www-db.standford.edu/stream]. Furthermore, in analysis of massive data streams, the ability to process the data in a single pass, while using little memory, is crucial. For often the data can be transmitted faster than it can be stored or accessed from disks. To address the question, we present an adaptive control-theoretic explicit rate (ER) online data mining control algorithm (ODMCA) to regulate the sending rate of mined data, which accounts for the main memory occupancies of terminal nodes. This single-pass scheme considers limited memory space to process dynamic data streams, and also explores the adaptive capability, which is employed in a general network computation model for dynamic data streams. The proposed method uses a distributed proportional integrative plus derivative (PID) controller combined with data mining, where the control parameters can be designed to ensure the stability of the control loop in terms of sending rate of mined data. The basic PID approach for the computation network transmission is presented and z-transformation and Schur-Cohn stability test are used to achieve the stability criterion, which ensures the bounded rate allocation without steady state oscillation. We further show how the ODMCA can be used to design a controller, analyze the theoretical aspects of the proposed algorithm and verify its agreement with the simulations in the LAN case and the WAN case. Simulation results show the efficiency of our scheme in terms of high main memory occupancy, fast response of the main memory occupancy and of the controlled sending rates.	algorithm;computer data storage;control system;control theory;dspace;data mining;data rate units;dynamic data;feedback;microsoft windows;mined;model of computation;pid;pseudocode;router (computing);simulation;steady state	Naixue N. Xiong;Laurence Tianruo Yang;Yingshu Li	2009	Computer Communications	10.1016/j.comcom.2008.08.026	pid controller;local area network;data modeling;z-transform;adaptability;dynamic data;adaptive control;telecommunications;combinatorial optimization;computer science;artificial intelligence;data analysis;steady state;oscillation;war;information extraction;fading;approximation algorithm;algorithm;communications system	Theory	-11.637057565555097	65.58469136546783	50065
8d6a7e43d3bc939722e8a37b80736c39e21a7cb8	cloud iec 61850: dds performance in virtualized environment with opendds		The idea of using Virtualization and Cloud as the underlying infrastructure for future automation systems in the context of the Internet of Things has been presented in the literature. This paper presents the assessment of the end-to-end performance of a distributed and virtualized architecture from the DDS communication middleware layer, running the performance test benchmark applications of the OpenDDS implementation. The experimental distributed and virtualized environment used considers two ordinary physical hosts connected by a single network. The virtualization layer is realized with KVM as hosted hypervisor with Ubuntu Linux and TinyCore as Guest-OS. A set of test scenarios combining host-host, host-VM and VM-VM communications is defined. Each test consist of publishing circa 11 thousand messages of 250 bytes for each one of the different transport protocol supported by OpenDDS. The round-trip time is measured for each message or sample, from which the respective latency and jitter are calculated. The results obtained are presented in tabular and graphical formats. The results show that soft real-time applications with deadlines up to 1 ms could be run in such virtualized environment. We show that is reasonable to consider the potential of running automation applications on a distributed and virtualized environment. The contribution of this study is to provide information, based on the proposed reference architecture and its time characterization, to engineers responsible for the design of automation solutions to start considering and assessing the use of modern computing architectures and technologies, specially virtualization and communication middlewares, in new engineering projects.	benchmark (computing);byte;circa;cloud computing;end-to-end principle;graphical user interface;hypervisor;internet of things;linux;middleware;operating system;real-time clock;real-time computing;reference architecture;requirement;sandbox (computer security);table (information);ubuntu;z/vm	Roger Daniel Francisco Ferreira;Rômulo Silva de Oliveira	2017	2017 IEEE International Conference on Computer and Information Technology (CIT)	10.1109/CIT.2017.17	computer science;architecture;virtualization;distributed computing;real-time computing;computer network;reference architecture;application virtualization;cloud computing;hypervisor;middleware;service virtualization	EDA	-16.657618811849048	80.78463002164465	50132
d1b6392008d13d44542081565f88f1d0469d9ff1	hardware-assist for ipv6 routing table lookup	carte electronique;networks;bloc diagramme;protocole transmission;building block;routing;reseau ordinateur;high data rate;computer network;protocolo transmision;tarjeta electronica;red ordenador;router;encaminamiento;printed circuit board;computer hardware;diagrama conjunto;routing table;block diagram;acheminement;transmission protocol	Routers are key building blocks in networks. They need to cope with high data rates in the range of multiple gigabit per second that are owing through them. Therefore, speciically performance critical functions should be implemented in dedicated hardware units in order to speed up the forwarding task. These units can be embedded within regular workstations or into dedicated router architectures. This paper we addresses one of the most performance critical components of a router, the routing table and its access and search mechanisms. Earlier work has shown that this is more critical with respect to the resulting performance than IP processing itself. A simple but eecient organization of the routing table using binary trees and oo-the-shelf SRAMs is presented together with a suited search algorithm.	atm turbo;binary tree;central processing unit;data rate units;digital signal processor;embedded system;frame grabber;gigabit;graphics;intel i960;interference (communication);lookup table;microsoft outlook for mac;prototype;random access;router (computing);routing table;search algorithm;video card;workstation	Till Harbaum;Detlef Meier;Martina Zitterbart;Dieter Brökelmann	1998		10.1117/12.321920	routing table;embedded system;virtual routing and forwarding;routing;enhanced interior gateway routing protocol;static routing;telecommunications;computer science;ip forwarding;forwarding plane;routing protocol;default-free zone;computer network	HPC	-5.0396829812013335	67.24427305555436	50186
f672779421cf32a7c03207fa4bd0d6db3ba7344d	dial-in virtual private networks using layer 3 tunneling	virtual private network;layer 3;service provider;point of presence;business communication;access protocols internet inter computer links business communication;layer 3 dial in virtual private network service dial in virtual private networks layer 3 tunneling corporate network internet geographically diverse site networks outsourcing service provider geographically diverse points of presence l2tp mobile ip;inter computer links;internet;virtual private networks tunneling network servers telecommunication traffic protocols ip networks network topology telephony isdn authentication;access protocols;layer 2;mobile ip	"""Corporate networks are making increasing use of the Internet to connect geographically diverse site networks rather than developing their own """"leased line"""" WAN networks. Similarly, they are outsourcing their dial-in capability by replacing their banks of modems with a single connection to a service provider with geographically diverse Points Of Presence (POPs). In this way, users in a corporate network can dial local (or toll free) numbers which will be routed to the nearest POP; then, be connected to their corporate network using some form of tunneling. There are two common forms of tunneling in use in the Internet today: Layer 2 (using L2TP, for example) and Layer 3 (using Mobile IP, for example). The paper presents a design for a Layer 3 Dial-in Virtual Private Network Service (DVS), based on Mobile IP. This design has been implemented by Bay Networks."""	tunneling protocol;virtual private network	Gary Scott Malkin	1997		10.1109/LCN.1997.631026	service provider;data link layer;enterprise private network;the internet;overlay network;network architecture;telecommunications;computer science;point of presence;service layer;virtual leased line;ip tunnel;business communication;world wide web;computer security;network layer;mobile ip;computer network	Vision	-22.553998587181255	88.01528602185229	50355
4fd61fad3788d5dcd11978abe8eca886340a411d	green scheduling for cloud data centers using renewable resources	scheduling cloud computing computer centres global warming green computing integer programming linear programming;integer linear programming model green scheduling cloud data centers renewable resources carbon emissions global warming power aware scheduling renewable energy carbon emission minimization fixed electricity budget constraint optimization problem carbon emission minimisation request processing time constraint total electricity budget;carbon dioxide;renewable energy sources;green products;servers;time factors;servers carbon dioxide time factors green products renewable energy sources wind quality of service;carbon emission reduction cloud computing data center renewable energy schedule green;quality of service;wind	Cloud data centers provide all kinds of service using hundreds of thousands of servers. This naturally leads to concerns about the effect on environment such as carbon emissions and global warming. Huge amounts of effort have been devoted to power-aware scheduling using renewable energy. However, the intermittent availability of the renewable energy brings us a new challenge: how to dynamically distribute the requests to the data centers that are powered by renewable energy, while minimizing carbon emissions under a fixed electricity budget. In this paper, we model our problem as a constraint optimization problem. The goal is to minimize the carbon emissions of the data centers by using renewable energy while satisfying: (1) the request processing time constraint; (2) the total electricity budget in each time slot; (3) the intermittent supply of the renewable resources; (4) the maximal number of servers in each data center. We solve the problem by ingeniously transforming it into an integer linear programming model, and calculate the decision variables using existed method. Experiments show that our scheduler can minimize carbon emissions using renewable resources, while satisfying the constraints mentioned above.	constrained optimization;data center;decision theory;integer programming;linear programming;mathematical optimization;maximal set;optimization problem;programming model;response time (technology);scheduling (computing);wiki	Chonglin Gu;Chun-Yan Liu;Jiangtao Zhang;Hejiao Huang;Xiaohua Jia	2015	2015 IEEE Conference on Computer Communications Workshops (INFOCOM WKSHPS)	10.1109/INFCOMW.2015.7179410	renewable energy;real-time computing;simulation;quality of service;computer science;operating system;carbon dioxide;server;computer network;wind	Metrics	-20.01163345797229	63.52758412534225	50359
24d4aa95f4c8dbdca21067dcaf212951c02ff80d	traffic engineering for provisioning restorable hose-model vpns	virtual private network;teletrafic;data transmission;eje troncal;evaluation performance;virtual network;tecnologia electronica telecomunicaciones;failure restoration;performance evaluation;evaluacion prestacion;gestion trafic;reseau ordinateur;simulation;telecommunication network;simulacion;traffic management;service telecommunication;red privada;computer network;partage des ressources;reseau federateur;algorithme;algorithm;teletrafico;private network;hose model;servicio de red;red telecomunicacion;transmission donnee;resource sharing;defaillance;particion recursos;reseau telecommunication;teletraffic;gestion trafico;service reseau;overlay network;telecommunication services;red informatica;failures;traffic engineered;backbone;tecnologias;traffic engineering;reseau prive;reseau recouvrement;grupo a;fallo;network service;reseau prive virtuel;transmision datos;red virtual;reseau virtuel;algoritmo;virtual private networks	Virtual private networks (VPNs) are overlay networks established on top of a public network backbone with the goal of providing a service comparable to private networks (PNs). The recently proposed VPN hose-model provides customers with flexible and convenient ways to specify their bandwidth requirements. In order to meet specified bandwidth requirements, the network service provider (NSP) must reserve a sufficient amount of bandwidth on the data transmission paths between each endpoint pair of a VPN. In addition, reliability of a VPN depends on the reliability of data transmission paths. Italiano et al. proposed an algorithm that finds a set of backup paths for a given VPN (VPN tree) under the single-link failure model. When any link failure on the VPN tree is detected, a backup path corresponding to the failed link can be activated to restore the disconnected VPN tree into a new one, and hence can ensure reliability of the given VPN. However, Italiano's algorithm cannot guarantee the specified bandwidth requirement of the given VPN under the single-link failure model will be met. To address this issue a new backup path set selection algorithm called BANGUAD is proposed in this work. In addition, issues about establishing multiple bandwidth-guaranteed hose-model VPNs under the single-link failure model have not been investigated. In this paper, we propose a bandwidth sharing algorithm as well as three provisioning algorithms for establishing multiple bandwidth-guaranteed hose-model VPNs under the single-link failure model. Experimental simulations that compare the performance of the proposed algorithms are reported	backup;circuit restoration;communication endpoint;internet backbone;multiprotocol label switching;network service provider;online and offline;overlay network;provisioning;requirement;selection algorithm;simulation;single point of failure;virtual private network	Yu-Liang Liu;Yeali S. Sun;Meng Chang Chen	2006	2006 2nd Conference on Next Generation Internet Design and Engineering, 2006. NGI '06.	10.1093/ietcom/e89-b.9.2394	shared resource;traffic engineering;active traffic management;overlay network;telecommunications;computer science;telecommunications service;computer security;private network;telecommunications network;computer network;data transmission	Networks	-4.8312522043453345	77.42339194802486	50399
48ab2ab29962ad3572a34c9812677f75519875a3	volare mobile context-aware adaptation for the cloud	ucl;discovery;theses;conference proceedings;digital web resources;ucl discovery;open access;ucl library;book chapters;open access repository;ucl research	As the explosive growth in the proliferation and use of mobile devices accelerates, more web service providers move their premises on the Cloud under the Software as a Service (SaaS) service model. Mobile environments present new challenges that Service Discovery methods developed for non-mobile environments cannot address. The requirements a mobile client device will have from internet services may change, even at runtime, due to variable context, which may include hardware resources, environmental variables (like network availability) and user preferences. Binding to a discovered service having QoS levels different from the ones imposed by current context and policy requirements may lead to low application performance, excessive consumption of mobile resources such as battery life and service disruption, especially for long lasting foreground applications like media-streaming, navigation etc. This thesis presents the Volare approach for performing parameter adaptation for service requests to Cloud services, in SaaS architecture. For this purpose, we introduce an adaptive mobile middleware solution that performs context-aware QoS parameter adaptation. When service discovery is initiated, the middleware calculates the optimal service requests QoS levels under the current context, policy requirements and goals and adapts the service request accordingly. At runtime, it can trigger dynamic service rediscovery following significant context changes, to ensure optimal binding. The adaptation logic is built through the characteristics of the declarative domain-specific Volare Adaptation Policy Specification Language (APSL). Key characteristics of this approach include two-level policy support (providing both device specific and application specific adaptation), integration of a User Preferences Model and high behavioral (parameter adaptation) variability, by allowing multiple weighted adaptation rules to influence each QoS variable. The Volare approach supports unanticipated quantitative long term performance goals (LTPGs) with finite horizons. A use case and a proof-of-concept implementation have been developed on cloud service discovery through a cloud service provider, as well as an appropriate case study, which demonstrates significant savings in battery consumption, provider data usage and monetary cost, compared to unadapted QoS service bindings, while consistently avoiding service disruptions caused by QoS levels that the device cannot support. In addition, adaptation policies using the Volare approach tend to increase in size, in a mostly linear fashion, instead of the combinatorial increase of more conventional situation-action approaches.	cloud computing;denial-of-service attack;heart rate variability;internet protocol suite;middleware;mobile device;platform as a service;quality of service;requirement;run time (program lifecycle phase);service discovery;software as a service;specification language;user (computing);web service	Panagiotis Papakos	2014			service level requirement;mobile qos;simulation;differentiated service;computer science;service delivery framework;service design;world wide web;computer security	Mobile	-24.352171333340866	62.555478560877596	50414
7ed103b6a3008aa2787ecf55c666021c85646c2f	efficient qos-aware service composition with a probabilistic service selection policy	service composition;service provider;service selection;polynomial time;linear program;quality of service;service oriented architecture	Service-Oriented Architecture enables the composition of loosely coupled services provided with varying Quality of Service (QoS) levels. Given a composition, finding the set of services that optimizes some QoS attributes under given QoS constraints has been shown to be NPhard. Until now the problem has been considered only for a single execution, choosing a single service for each workflow element. This contrasts with reality where services often are executed hundreds and thousands of times. Therefore, we modify the problem to consider repeated executions of services in the long-term. We also allow to choose multiple services for the same workflow element according to a probabilistic selection policy. We model this modified problem with Linear Programming, allowing us to solve it optimally in polynomial time. We discuss and evaluate the different applications of our approach, show in which cases it yields the biggest utility gains, and compare it to the original problem.	linear programming;loose coupling;quality of service;service-oriented architecture;time complexity	Adrian Klein;Fuyuki Ishikawa;Shinichi Honiden	2010		10.1007/978-3-642-17358-5_13	service provider;time complexity;service level requirement;real-time computing;mobile qos;quality of service;differentiated service;computer science;linear programming;operating system;service-oriented architecture;database;distributed computing;law;world wide web	Web+IR	-21.09114468034565	64.8325442075102	50496
1d77e83643632e01eac2206b9b80f90265168d95	systèmes contrôlés en réseau : evaluation de performances d'architectures ethernet commutées. (networked control systems: performance evaluation of switched ethernet architectures)			control system;network switch;performance evaluation	Jean-Philippe Georges	2005				Networks	-20.64236738162812	87.6913339538663	50559
c79a6b8393ba3081ae7441b6ed7adf22b8f607f7	dhr-trees: a distributed multidimensional indexing structure for p2p systems	p2p system;range query;fault tolerant;query processing;query processing fault tolerant computing peer to peer computing;surveillance;peer to peer systems;fault tolerant dhr trees distributed multidimensional indexing structure p2p systems peer to peer systems distributed hilbert r trees multidimensional range query;temperature sensors;index structure;maintenance cost;peer to peer system;fault tolerant computing;indexing;fault tolerance;dhr trees;distributed hilbert r trees;multidimensional range query;system testing;cities and towns;gas detectors;peer to peer computing;multidimensional systems;multidimensional systems indexing peer to peer computing costs fault tolerance temperature sensors system testing cities and towns gas detectors surveillance;dynamic networks;distributed multidimensional indexing structure;p2p systems	Supporting range query over peer-to-peer systems has attracted many research efforts in recent years. In this paper, we propose a new multidimensional indexing structure for P2P systems called distributed Hilbert R-trees (DHR-trees). DHR-trees enables multidimensional range query to be executed similarly as in overlapping regions tree in P2P systems. Its distributed structure makes it fault-tolerant and scalable to dynamic network environment with a large number of peers as well. Our experiments shows that it performs well on multidimensional range query while the maintenance cost is reasonably low	experiment;fault tolerance;hilbert curve;key space (cryptography);overlay network;peer-to-peer;phylogenetic tree;r-tree;range query (database);scalability;semiconductor industry;spatial database;tree structure	Xinfa Wei;Kaoru Sezaki	2006	2006 Fifth International Symposium on Parallel and Distributed Computing	10.1109/ISPDC.2006.19	query optimization;fault tolerance;computer science;theoretical computer science;database;distributed computing;computer network	DB	-12.094333955095392	73.00093211184476	50565
2a03ce64d41df65f70c21d24ba2dba363acfe041	wasp algorithm used to drive dynamic task allocation in a heterogeneous computing system	task scheduling wasp algorithm task allocation heterogeneous computing system swarm intelligence;swarm intelligence;heterogeneous computing;task analysis particle swarm optimisation scheduling;scheduling;particle swarm optimization processor scheduling dynamic scheduling insects ant colony optimization application software system performance scheduling algorithm drives resource management;task analysis;task scheduling;particle swarm optimisation;task allocation	In this paper, swarm intelligence is introduced into the scheduling of a heterogeneous computing system and a novel dynamic task-scheduling model is proposed. The model describes the interaction between a wasp colony and the environment. Contesting for resources is addressed by dynamically allocating processors in sequence. Experimental results show the effectiveness of the proposed method.	algorithm;central processing unit;dynamic problem (algorithms);heterogeneous computing;memory management;scheduling (computing);swarm intelligence;wasp	Jun Zheng;Wen-xin Hu;Jian-xiong Ji	2009	2009 Fifth International Conference on Natural Computation	10.1109/ICNC.2009.556	fair-share scheduling;fixed-priority pre-emptive scheduling;multi-swarm optimization;parallel computing;real-time computing;dynamic priority scheduling;computer science;rate-monotonic scheduling;two-level scheduling;distributed computing;round-robin scheduling	Robotics	-14.709785753715503	61.43275854878183	50668
6358c0f6b8668b0fef512c9539eef806eba4c6fd	handling conflicts to test transport protocol's parallel routing on a vehicle gateway system	routing;testing;transport protocols;logic gates;explosions;vehicles	This paper addresses the issue of verifying transport protocol's parallel routing functionality on a vehicle gateway system. The focus of the paper is to construct a conflict-free input parameter model for testing this functionality. The input parameter model shall support the reduction of combinations to be tested and serves as a basis for automatic test case generation from a large space of input parameters. In the proposed approach, defined similarity criteria are used to cluster system input parameters represented as transport protocol routing instances into groups which stimulate similar behavior in the gateway when transport protocol routing is established. Subsequently, the two conflict-handling methods sub-models and avoid are utilized to prohibit invalid combinations of transport protocol routing instances. The proposed approach is applied on a complex example of real gateway with five buses, 390 transport protocol routing instances and diverse conflicts to illustrate its applicability.	interaction;parameter (computer programming);routing;simulation;test case;test suite	Hassan Mohammad;Muhammad Shamoon Saleem	2014	2014 Federated Conference on Computer Science and Information Systems	10.15439/2014F73	policy-based routing;wireless routing protocol;virtual routing and forwarding;routing;enhanced interior gateway routing protocol;static routing;simulation;hierarchical routing;supernetwork;border gateway protocol;zone routing protocol;logic gate;computer science;interior gateway protocol;dynamic source routing;distance-vector routing protocol;database;distributed computing;software testing;routing protocol;link-state routing protocol;interior gateway routing protocol;path vector protocol;computer security;hazy sighted link state routing protocol;transport layer;routing information protocol;open shortest path first	HPC	-8.177425997605283	86.13588710155433	50681
b5fbe909328c7863bdca5940fcac9687fdfab9ac	a user-customized virtual network platform for naas cloud		Now all kinds of public cloud providers take computing and storage resources as the user’s main demand, making it difficult for users to deploy complex network in the public cloud.This paper proposes a virtual cloud platformwith network as the core demand of the user, which can provide the user with the capacity of free network architecture as well as all kinds of virtual resources. The network is isolated by port groups of the virtual distributed switch and the data forwarding and access control between different network segments are implemented by virtual machines loading a soft-routing system. This paper also studies the management interface of network architecture and the uniform way to connect the remote desktop of virtual resources on the web, hoping to provide some new ideas for the Network as a Service model.		Lei Xiao;Yu Sheng;Guanlan Tan;Jianxing Wang;Yi Pan	2016	Scientific Programming	10.1155/2016/9315672	intelligent computer network;network architecture;network management station;cloud computing;operating system;network simulation;distributed computing;virtual circuit;world wide web;computer network	HPC	-16.61539464207962	82.09727610638826	50736
31eebbd3711c31cf616c93b1aa6db4d3dcfa4e69	efficient network management system with dacs scheme	security policies;protocols;telecommunication security computer network management protocols telecommunication control;network server;telecommunication control;dacs protocol;control system;destination addressing control system scheme;computer network management;telecommunication security;network services;networked systems;security policy;system management;university network systems;dacs protocol network management system dacs scheme university network systems security policies destination addressing control system scheme client communication management;dacs scheme;network management system;client communication management;network servers computer network management web server computer networks communication system control control systems protocols technology management communication system security computer security	Where customers with different membership and position, use computers as in the university network systems, it often takes much time and effort for them to cope with the change of the system management. This is because the requirements for the respective computer usage are different in the network and security policies. In this paper, a new destination addressing control system (DACS) scheme for the university network services is proposed. The DACS scheme performs the network services efficiently through the communication management of a client. As the characteristic of DACS scheme, only the setup modification is required by a system administrator, when the configuration change is needed in the network server. Then, the setup modification is unnecessary by a customer, which shows a merit for both a system administrator and a customer. This paper describes the instruction and the prototype for DACS protocol as the implementation of DACS scheme. Then, the simplicity of the system management in DACS scheme, is examined from the customer and the system administrator viewpoints	centralized computing;client (computing);computer;control system;digital-to-analog converter;management system;processor affinity;prototype;requirement;server (computing);system administrator;systems management	Kazuya Odagiri;Rihito Yaegashi;Masaharu Tadauchi;Naohiro Ishii	2006	International conference on Networking and Services (ICNS'06)	10.1109/ICNS.2006.43	real-time computing;computer science;security policy;control system;operating system;computer security;computer network	Mobile	-26.655030620982178	75.83575626002825	50774
2fe4c2665050e3cfdff948113eefa75ec7ab858a	energy-efficient caching and prefetching with data consistency in mobile distributed systems	energy efficiency;analytical models;distributed system;cache storage;wireless channels;energy efficiency prefetching bandwidth batteries energy consumption mobile computing analytical models delay information retrieval mobile communication;mobile device;data integrity;energy consumption data consistency mobile distributed systems wireless channel bandwidth data caching mechanism greedydual least utility analytical model cache replacement algorithm passive prefetching algorithm;energy efficient;information retrieval;bandwidth allocation;prefetching;utility function;wireless channel bandwidth;cache replacement algorithm;information access;greedydual least utility;simulation experiment;dynamic data;data cache;cache replacement;energy consumption;batteries;mobile communication;bandwidth;mobile distributed systems;data integrity mobile computing telecommunication channels bandwidth allocation cache storage;passive prefetching algorithm;telecommunication channels;mobile computing;data consistency;data caching mechanism;analytical model;energy saving	Summary form only given. In mobile distributed systems, vital resources like battery power and wireless channel bandwidth impose significant challenges in ubiquitous information access. We propose a novel energy and bandwidth efficient data caching mechanism, called greedydual least utility (GD-LU), that enhances dynamic data availability while maintaining consistency. The proposed utility-based caching mechanism considers several characteristics of mobile distributed systems, such as connection-disconnection, mobility handoff, data update and user request patterns to achieve significant energy savings in mobile devices. Based on the utility function derived from an analytical model, we propose a cache replacement algorithm and a passive prefetching algorithm to cache and prefetch data objects. Our comprehensive simulation experiments demonstrate that the proposed mechanism achieves more than 10% energy saving and near-optimal performance tradeoff between access latency and energy consumption.	cpu cache;cache (computing);distributed computing;dynamic data;estimation theory;experiment;gd-rom;information access;international parallel and distributed processing symposium;lu decomposition;mobile app;mobile device;page replacement algorithm;simulation;utility	Huaping Shen;Mohan Kumar;Sajal K. Das;Zhijun Wang	2004	18th International Parallel and Distributed Processing Symposium, 2004. Proceedings.	10.1109/IPDPS.2004.1302995	parallel computing;real-time computing;computer science;operating system;efficient energy use;mobile computing;computer network	Mobile	-14.951608800211217	68.55819391685922	50833
f2f4eb29b7f00afb6942a4c61055c0fe673f9271	self-aware cyber-physical systems-on-chip		Self-awareness has a long history in biology, psychology, medicine, and more recently in engineering and computing, where self-aware features are used to enable adaptivity to improve a system's functional value, performance and robustness. With complex many-core Systems-on-Chip (SoCs) facing the conflicting requirements of performance, resiliency, energy, heat, cost, security, etc. -- in the face of highly dynamic operational behaviors coupled with process, environment, and workload variabilities -- there is an emerging need for self-awareness in these complex SoCs. Unlike traditional MultiProcessor Systems-on-Chip (MPSoCs), self-aware SoCs must deploy an intelligent co-design of the control, communication, and computing infrastructure that interacts with the physical environment in real-time in order to modify the system's behavior so as to adaptively achieve desired objectives and Quality-of-Service (QoS). Self-aware SoCs require a combination of ubiquitous sensing and actuation, health-monitoring, and statistical model-building to enable the SoC's adaptation over time and space. After defining the notion of self-awareness in computing, this paper presents the Cyber-Physical System-on-Chip (CPSoC) concept as an exemplar of a self-aware SoC that intrinsically couples on-chip and cross-layer sensing and actuation using a sensor-actuator rich fabric to enable self-awareness.	cyber-physical system;manycore processor;multiprocessing;quality of service;real-time transcription;requirement;self-awareness;statistical model;system on a chip	Nikil D. Dutt;Axel Jantsch;Santanu Sarma	2015	2015 IEEE/ACM International Conference on Computer-Aided Design (ICCAD)		system on a chip;embedded system;electronic engineering;real-time computing;simulation;computer science;engineering;sensor;operating system;predictive modelling;computational model	EDA	-29.85623312512898	61.24975601340267	50870
9bbbe0485482f5af27f47ca16453121ed38dd010	policy-based clustering service for network function virtualization over multi-site clouds		In order to reduce operational expenditure (OPEX), network function virtualization infrastructure (NFVI) should be distributed over multiple geographical locations and managed by a centralized and unified management and orchestration system (MANO). In addition, the NFV platform is required to archive a high level of availability and scalability for virtual network functions (VNFs) across multi-site clouds. In this paper, we introduce clustering service architecture to provide available and scalable VNFs over multi-site cloud infrastructures. In particular, we introduce a new policy template in order to support multi-site deployment and policy-based management for VNF clusters in multisite environment. By implementing our proposal using open source Openstack Tacker project, we show the feasibility of our proposal.	archive;centralized computing;cluster analysis;high-level programming language;network function virtualization;open-source software;scalability;software deployment;transfer function	Kim Bao Long;Truong-Xuan Do;YoungHan Kim	2017	2017 International Conference on Information and Communication Technology Convergence (ICTC)	10.1109/ICTC.2017.8190761	orchestration (computing);cloud computing;virtual network;scalability;software deployment;cluster analysis;operating expense;computer network;service-oriented architecture;computer science	HPC	-17.708798971253255	82.69619536898335	50896
03c7faf5f1264a21a6b00fba45f434a5683d8cc6	impairment aware dynamic routing of many-to-many flows in elastic optical networks	static client replica coupling impairment aware dynamic routing many to many flow elastic optical network many to many networking information exchange m2m communication direct full mesh connectivity replicated transmission rendezvous server client server assignment csa scheme optical communication m2m session blocking probability spectrum usage dynamic server assignment fallback replica selection;routing;routing and spectrum allocation many to many communication elastic optical networks dynamic routing;resource management;optical fiber networks;dynamic routing;servers;heuristic algorithms;many to many communication;bandwidth;repeaters;elastic optical networks;routing servers heuristic algorithms resource management optical fiber networks repeaters bandwidth;routing and spectrum allocation;telecommunication network routing client server systems data communication electronic data interchange network servers probability replicated databases	Many-to-many (m2m) networking is a communication paradigm for provisioning numerous types of network services. In this paradigm, a group of hosts exchange information between its members in a synchronous way. We focus on two impairment aware dynamic routing approaches for m2m communication: direct full mesh connectivity and replicated transmission using rendezvous servers. Furthermore, in the latter case several client-server assignment (CSA) schemes are proposed. We provision m2m transmissions in Elastic Optical Networks (EONs), being the next step in development of optical communication. The main contribution of the paper is performance comparison of several impairment aware routing schemes using the metrics of m2m session blocking probability and spectrum usage. In our extensive simulations, dynamic server assignment using fallback replica selection always outperformed the static client-replica coupling.	algorithm;blocking (computing);client–server model;erlang (unit);flow network;heuristic (computer science);many-to-many (data model);mathematical optimization;metaheuristic;multicast;online and offline;programming paradigm;provisioning;rsa (cryptosystem);routing;server (computing);simulation	Damian Bulira;Arunabha Sen	2015	2015 Second European Network Intelligence Conference	10.1109/ENIC.2015.13	policy-based routing;wireless routing protocol;routing table;routing domain;routing;enhanced interior gateway routing protocol;static routing;real-time computing;hierarchical routing;zone routing protocol;equal-cost multi-path routing;computer science;dynamic source routing;multipath routing;destination-sequenced distance vector routing;distributed computing;routing protocol;link-state routing protocol;triangular routing;geographic routing;routing information protocol;computer network	Mobile	-6.970411493375324	84.19589427757265	50955
c017e12cee32b9e33704f6cf3f5d6a10ad2d818d	heuristic methods for shared backup path protection planning	telecommunication cables;optimisation;telecommunication network reliability;telecommunication network planning;heuristic programming;np hard optimization problem heuristic method shared backup path protection planning communication network protection single cable failure automatic protection schemes sbpp;telecommunication network reliability computational complexity heuristic programming optimisation telecommunication cables telecommunication network planning;heuristic algorithms benchmark testing maintenance engineering cooling temperature planning simulated annealing;computational complexity	Protecting communication networks against failures is becoming increasingly important as they have become an integrated part of our society. Cable failures are fairly common, but it is unacceptable for a single cable failure to disconnect communication for more than a few seconds - hence protection schemes are employed. In contrast to manual intervention, automatic protection schemes such as Shared Backup Path Protection (SBPP) can recover from failure quickly and efficiently. SBPP is a simple but efficient protection scheme that can be implemented in backbone networks with technology available today. In SBPP backup paths are planned in advance for every failure scenario in order to recover from failures quickly and efficiently. The SBPP problem is an NP-hard optimization problem, and previous work confirms that it is time-consuming to solve the problem in practice using exact methods. We present heuristic algorithms and lower bound methods for the SBPP planning problem. Experimental results show that the heuristic algorithms are able to find good quality solutions in minutes. A solution gap of less than 3.5% was achieved for more than half of the benchmark instances (and a gap of less than 12% for the remaining instances.)	algorithm;backup;benchmark (computing);heuristic;heuristic (computer science);internet backbone;mathematical optimization;np-hardness;optimization problem;path protection;telecommunications network	Jørgen Thorlund Haahr;Thomas Stidsen;Martin Zachariasen	2012	2012 IV International Congress on Ultra Modern Telecommunications and Control Systems	10.1109/ICUMT.2012.6459757	simulation;computer science;distributed computing;computational complexity theory;computer network	EDA	-6.523390728705606	81.55348687778712	50995
314b4716c126a0301182a144713d074285d00193	virtual network survivability through joint spare capacity allocation and embedding		A key challenge in network virtualization is to efficiently map a virtual network (VN) on a substrate network (SN), while accounting for possible substrate failures. This is known as the survivable VN embedding (SVNE) problem. The state-of-the-art literature has studied the SVNE problem from infrastructure providers’ (InPs’) perspective, i.e., provisioning backup resources in the SN. A rather unexplored solution spectrum is to augment the VN with sufficient spare backup capacity to survive substrate failures and embed the resulting VN accordingly. Such augmentation enables InPs to offload failure recovery decisions to the VN operator, thus providing more flexible VN management. In this paper, we study the problem of jointly optimizing spare capacity allocation in a VN and embedding the VN to guarantee full bandwidth in the presence of multiple substrate link failures. We formulate the optimal solution to this problem as a quadratic integer program that we transform into an integer linear program. We also propose a heuristic algorithm to solve larger instances of the problem. Based on analytical study and simulation, our key findings are: 1) provisioning shared backup resources in the VN can yield ~33% more resource efficient embedding compared to doing the same at the SN level and 2) our heuristic allocates ~21% extra resources compared to the optimal, while executing several orders of magnitude faster.	algorithm;approximation algorithm;autonomous robot;backup;capacity optimization;computational complexity theory;embedded system;heuristic (computer science);integer programming;linear programming;mathematical optimization;optimization problem;provisioning;simulation;single point of failure	Nashid Shahriar;Shihabur Rahman Chowdhury;Reaz Ahmed;Aimal Khan;Siavash Fathi;Raouf Boutaba;Jeebak Mitra;Liu Liu	2018	IEEE Journal on Selected Areas in Communications	10.1109/JSAC.2018.2815430	virtualization;network virtualization;computer network;heuristic (computer science);virtual network;spare part;computer science;provisioning;linear programming;backup	Metrics	-11.087516279151279	81.68417831274513	50997
8a13f00e8b4583d2a7afc35018e894b9ecaf1da8	snap-stabilization and pif in tree networks	fault tolerant;system configuration;waiting time;timing optimization;tree network;propagation of information with feedback;localized state	The contribution of this paper is threefold. First, we present the paradigm of snap-stabilization. A snap- stabilizing protocol guarantees that, starting from an arbitrary system configuration, the protocol always behaves according to its specification. So, a snap-stabilizing protocol is a time optimal self-stabilizing protocol (because it stabilizes in 0 rounds). Second, we propose a new Propagation of Information with Feedback (PIF) cycle, called Propagation of Information with Feedback and Cleaning ( $$\mathcal{PFC}$$ ). We show three different implementations of this new PIF. The first one is a basic $$\mathcal{PFC}$$ cycle which is inherently snap-stabilizing. However, the first PIF cycle can be delayed O(h 2) rounds (where h is the height of the tree) due to some undesirable local states. The second algorithm improves the worst delay of the basic $$\mathcal{PFC}$$ algorithm from O(h 2) to 1 round. The state requirement for the above two algorithms is 3 states per processor, except for the root and leaf processors that use only 2 states. Also, they work on oriented trees. We then propose a third snap-stabilizing PIF algorithm on un-oriented tree networks. The state requirement of the third algorithm depends on the degree of the processors, and the delay is at most h rounds. Next, we analyze the maximum waiting time before a PIF cycle can be initiated whether the PIF cycle is infinitely and sequentially repeated or launch as an isolated PIF cycle. The analysis is made for both oriented and un-oriented trees. We show or conjecture that the two best of the above algorithms produce optimal waiting time. Finally, we compute the minimal number of states the processors require to implement a single PIF cycle, and show that both algorithms for oriented trees are also (in addition to being time optimal) optimal in terms of the number of states.	algorithm;asymptotically optimal algorithm;central processing unit;fastest;mutual exclusion;network topology;path integral formulation;plasma cleaning;powerbuilder foundation classes;programming paradigm;return-oriented programming;self-stabilization;service-oriented architecture;software propagation;system configuration;tcp global synchronization	Alain Bui;Ajoy Kumar Datta;Franck Petit;Vincent Villain	2007	Distributed Computing	10.1007/s00446-007-0030-4	reliability engineering;embedded system;fault tolerance;real-time computing;computer science;theoretical computer science;distributed computing;algorithm	Theory	-5.308504803794934	69.97444374962505	51027
9a8ede90eb771d0acd347a850adefaa3518f2c59	implementation and evaluation of autonomous decentralized system based mobile communications platform for its services	efficient system maintenance;autonomous decentralized system based mobile communications platform;data transmission;phase measurement;multivariable systems;prototypes;online maintainability;automated highways;uninterrupted communication;traffic information systems automated highways mobile communication multivariable systems;remotely operated vehicles;phased system expansion;data communication;microcell mobility management;traffic information systems;fault tolerant systems;smart gateway;fault tolerance;online extendibility;mobile communication;intelligent systems;fast moving vehicles;microcell networks;radio signal environment changes;intelligent networks;mobile communication microcell networks intelligent systems intelligent networks phase measurement data communication remotely operated vehicles fault tolerant systems mobile radio mobility management prototypes;intelligent transport systems;autonomous decentralized system based mobile communications platform intelligent transport systems smart gateway phased system expansion efficient system maintenance data transmission uninterrupted communication radio signal environment changes fast moving vehicles autonomous decentralized system architecture online extendibility online maintainability fault tolerance microcell mobility management;autonomous decentralized system architecture;mobile radio mobility management	"""The development of a mobile network to provide intelligent transport system (ITS) services is underway as a national project in Japan called the """"Smart Gateway"""", responding to nationwide needs for such a network. System issues for implementation include the necessity of measures for phased system expansion and efficient system maintenance. In addition, a data transmission method must be established to provide uninterrupted communication across microcells following radio signal environment changes to deliver information to fast-moving vehicles. To cope with these issues, this system uses an autonomous decentralized system architecture and supports online extendibility, online maintainability and fault tolerance that are critical to set up a system that operates non-stop. Thus, the authors developed microcell mobility management to enable uninterrupted communication across microcells. The authors developed a prototype incorporating the above methods and made an evaluation."""	autonomous decentralized system;decentralised system	Masashi Hiraiwa;Takeiki Aizono;Akitoshi Shimura	2003		10.1109/ISADS.2003.1193958	remotely operated underwater vehicle;embedded system;intelligent network;intelligent transportation system;fault tolerance;mobile telephony;intelligent decision support system;telecommunications;computer science;distributed computing;prototype;computer security;computer network;data transmission	Mobile	-20.980925643888064	84.43262307981577	51046
3d22a64dfd1fad9a5fa243b78392775bf7df7c32	integrated network design tools (indt): a suite of network design tools for current and next generation networking technologies	transportation networks;bell labs;network design;circuit switches;flexible software architecture;switched multimedia services;atm switches;dual ring interconnect;logical designs;optimal network design;logic design;switching circuits sonet software architecture flexible printed circuits asynchronous transfer mode switches bandwidth network topology circuit topology synchronous digital hierarchy;next generation network;intra ring load balancing;cross connects;ring network;telecommunication computing;sonet sdh products;software engineering;multimedia communication optical fibre networks sonet network topology software engineering telecommunication computing voice communication asynchronous transfer mode;network topology;algorithm;optical fibre networks;software architecture;voice communication;network design tools;fiber routes;multimedia communication;pdh;bandwidth;sonet ring design;private line services;intra ring load balancing integrated network design tools network design tools networking technologies bell labs flexible software architecture c optimal network design private line services switched voice services switched multimedia services circuit switches atm switches cross connects bandwidth logical designs mesh topology ring topology dual ring interconnect sonet sdh products fiber routes fiber layout algorithm sonet ring design pdh;load balance;networking technologies;switched voice services;c;mesh topology;integrated network design tools;multimedia services;sonet;asynchronous transfer mode;ring topology;fiber layout	Integrated Network Design Tools (INDT) is a suite of tools being developed at Bell Labs. This suite of tools is built on a flexible software architecture based on C++ and can provide optimal network design for a mix of private line, switched voice and switched multimedia sewices using a mix of circuit and ATM switches and cross connects and facilities with dvferent bandwidth granularily. INDT also has the ability to design, in standalone mode or in COJ?jUnCtiOn with logical designs mentioned above. the core transport network using mesh and/or ring topologies and using PDH or SONET/SDH products. The transport network may be designed over existing3ber routes and capacities or the tool may be used to help decide thejber layout. An overview of INDT architecture has been presented in [l]. In this paper we focus on a new capability within INDT, viz., SONET ring design. We present a high level description of the various submodules in ring network design and provide an overview of the main factors thpt inpuenced our algorithm development. We also present sample studies of our approach to intra-ring load balancing as well as our economic quantgcation of penalties due to Dual Ring Interconnect (DH) and other features ojin terest.	atm turbo;algorithm;c++;high-level programming language;load balancing (computing);network planning and design;network switch;next-generation network;private line;ring network;software architecture;synchronous optical networking;viz: the computer game	Bharat T. Doshi;Cynthia A. Funka-Lea;P. Harshavardhana;J. Gong;Ramesh Nagarajan;S. Ravikumar;S. Chen;Yung-Terng Wang	1997		10.1109/ISCC.1997.616020	ring network;real-time computing;computer science;distributed computing;computer network	EDA	-19.954149080773426	88.35180274276408	51068
bc5d08cb8e4ac5984b05b23967a3fe555ba2ea7d	time-and-energy-aware computation offloading in handheld devices to coprocessors and clouds	coprocessors android cloud computing computation offloading;computation offloading;smart phones;android;smart phones time and energy aware computation offloading handheld devices coprocessors cloud computing ternary decision maker on board cpu on board gpu mobile applications tdm false offloading decision rate;coprocessors;servers;energy consumption;graphics processing units;batteries;mobile communication;smart phones cloud computing coprocessors energy conservation graphics processing units mobile computing power aware computing;energy consumption smart phones graphics processing units coprocessors mobile communication servers batteries;article;cloud computing	Running sophisticated software on smart phones could result in poor performance and shortened battery lifetime because of their limited resources. Recently, offloading computation workload to the cloud has become a promising solution to enhance both performance and battery life of smart phones. However, it also consumes both time and energy to upload data or programs to the cloud and retrieve the results from the cloud. In this paper, we develop an offloading framework, named Ternary Decision Maker (TDM), which aims to shorten response time and reduce energy consumption at the same time. Unlike previous works, our targets of execution include an on-board CPU, an on-board GPU, and a cloud, all of which combined provide a more flexible execution environment for mobile applications. We conducted a real-world application, i.e., matrix multiplication, in order to evaluate the performance of TDM. According to our experimental results, TDM has less false offloading decision rate than existing methods. In addition, by offloading modules, our method can achieve, at most, 75% savings in execution time and 56% in battery usage.	central processing unit;computation offloading;coprocessor;graphics processing unit;matrix multiplication;mobile app;on-board data handling;response time (technology);run time (program lifecycle phase);smartphone;toad data modeler;upload	Ying-Dar Lin;Edward T.-H. Chu;Yuan-Cheng Lai;Ting-Jun Huang	2015	IEEE Systems Journal	10.1109/JSYST.2013.2289556	embedded system;real-time computing;cloud computing;computer hardware;computer science;operating system;android	Mobile	-23.00299143399269	66.44673677647032	51106
4d9352fa10ff51532ad817731573597ecea966f3	network protocol architectures for future deep-space internetworking	deep-space communications;deep-space internetworking;delay-tolerant networking;network protocol architecture;space internetworking	In the next two decades, humans are going to experience a grand age of deep-space exploration, especially in Mars and Lunar spaces. These relatively frequent and long-term activities provide the opportunity, and at the same time, demands the necessity for a true interplanetary network as an essential infrastructure for future deep-space exploration. In this study, we try to provide a picture and a perspective in the current network protocol architectures for future deep-space internetworking. We first investigate the recent technical advances for deep-space internetworking and the challenges to their network protocol architecture. Detailed technical characteristics of three effective network protocol architectures are presented. A special focus is casted on delay tolerant networking (DTN), which is a dedicated network protocol architecture for deep-space internetworking. Finally, several open questions in DTN for future deep-space internetworking are proposed for further study.	categorization;communications protocol;delay-tolerant networking;function problem;humans;internet protocol suite;internetworking;scalability;self-propelled particles	Kanglian Zhao;Qinyu Zhang	2018	Science China Information Sciences	10.1007/s11432-018-9386-5	mathematical optimization;communications protocol;nasa deep space network;architecture;delay-tolerant networking;mathematics;computer network;internetworking;mars exploration program	Metrics	-11.584045059899031	87.08528231868135	51117
25414d962d9d939b561eefe9465f2fa50a5f03b2	reuse of cms content encryption keys		This document describes a way to include a key identifier in a CMS (Cryptographic Message Syntax) enveloped data structure, so that the content encryption key can be re-used for further enveloped data packets.	encryption	Stephen Farrell;Sean Turner	2001	RFC	10.17487/RFC3185	40-bit encryption;client-side encryption;computer science;key wrap;on-the-fly encryption;internet privacy;world wide web;computer security;encryption;56-bit encryption;attribute-based encryption;keyfile	Crypto	-27.229214740624236	87.49475553686963	51239
159cc38745abb78a6b404482e2912a1ccb0c9370	the cloud streaming service migration in cloud video storage system	cloud streaming streaming migration streaming recovery streaming failover;video streaming;video stream data cloud streaming service migration cloud video storage system video surveillance public security evidence preservation secure systems streaming migration cloud storage video system directory host stream processing apparatuses detection apparatuses stream connection;bismuth;storage management;streaming migration;streaming recovery;video streaming cloud computing security of data storage management;servers;monitoring;streaming media;streaming failover;security of data;cameras;cloud streaming;servers streaming media cameras real time systems bismuth monitoring cloud computing;cloud computing;real time systems	Video surveillance is used to solve the problems of public security and preservation of evidence. So far, many researchers have offered their secure systems. However, storage and streaming migration issues must be discussed in more detail. In the paper, a method for streaming service migration in a cloud video storage system and the system using the same are provided, and the cloud storage video system includes a directory host, stream processing apparatuses and detection apparatuses. The method includes: assigning a first stream processing apparatus to establish a first stream connection with a first detection apparatus among the detection apparatuses, and assigning at least a second stream processing apparatus to establish a second stream connection with the first detection apparatus but not to receive the video stream data from the first detection apparatus, and assigning the first processing apparatus to receive and store the video stream data from the first detection apparatus, and the second stream processing apparatus receives and stores the video stream data from the first detection apparatus when the directory host determines that the first stream connection is abnormal, and disconnects the first stream connection.	cloud storage;computer data storage;stream processing;streaming media	Yi-Hsing Tsai	2013	2013 27th International Conference on Advanced Information Networking and Applications Workshops	10.1109/WAINA.2013.146	real-time computing;cloud computing;computer science;operating system;bismuth;internet privacy;server;computer network	DB	-32.02362391772594	63.44129559682568	51275
863e0ca1c251dad439dd0b5c594a0af18c841149	a coordination scheduling mechanism to guarantee packet ordering in parallel packet switch	packet ordering;delay performance;coordination scheduling;cooperation;parallel packet switch;parallel packet switching;cioq switches	A packet switch with parallel switching planes is a parallel packet switch (PPS). It is an open problem to design a PPS that is feasible to guarantee packet ordering with lower computation and communication overhead. Many solutions proposed previously are essentially impractical because of high communication complexity. In this paper, we attempt to make a PPS practical by using a simple cooperating scheduling mechanism between the round-robin demultiplexing at the inputs and the enhanced longest queue first (ELQF) scheduling at the central scheduler. In our scheme, no communication is needed during normal operation, and only sporadic communication between the central scheduler and demultiplexors is launched during the occurrence of starvation instead of each cell slot. As the experiment results demonstrate, our PPS offers improved delay performance compared with existing PPS designs.	network packet;packet switching;scheduling (computing)	Yi Dai;Jinshu Su	2008	IJESDF	10.1504/IJESDF.2008.021454	real-time computing;fast packet switching;computer science;processing delay;distributed computing;transmission delay;packet switch;burst switching;cooperation;computer network	Metrics	-4.770015577147681	87.39080459755981	51381
5806ca6a30eed7a083a66d1adb6e2ee479ae056a	os for graphics and multimedia	cpu scheduling;resource scheduling;relational data;presentation device;multimedia;data stream;multimedia application;multi user;protection domain;soft real time;inverse problem;operating system;synchronization;quality of service qos;quality of service;central processing unit cpu;interrupt processing;graphics	Multimedia and graphics data including video, audio, and realistic animations, are entertaining, informative, and intuitive. The information is continuously updated, in which the timing of the data is part of their semantics, and must be maintained both within a data stream and between related data streams. Operating system support for the soft real-time needs of multimedia applications is crucial and challenging. In this article, we discuss OS support for multimedia quality of service in a general-purpose and multi-user computing environment. We address the issues of (1) resource abstraction and accounting, (2) resource scheduling, and (3) solutions to priority inversion problems arising out of interactions between OS components.	central processing unit;fairness measure;general-purpose markup language;graphics;hierarchical fair-service curve;information;interaction;multi-user;operating system;priority inheritance;priority inversion;quality of service;real-time clock;real-time computing;real-time locating system;requirement;scheduling (computing);throughput;video	David K. Y. Yau	2008		10.1002/9780470050118.ecse289	embedded system;real-time computing;computer science;operating system	HPC	-10.634976470810726	64.49758619207971	51420
d8fafa640d5309b466e58652cfdcfc831061b353	topic 7: peer-to-peer computing	disorganized nature;computer world;peer-to-peer system;general area;client-server systems-largely;key research issue;peer-to-peer computing;symmetric communication model;certain level;first-class citizen;peer-to-peer technology;peer-to-peer concept;best-effort file sharing;twenty-six paper;broader selection;parallel system;decentralized nature;interesting work;accepted research field;file sharing;self organization;best effort;client server;communication model;overlay network;satisfiability;distributed storage;distributed system;parallel systems	"""Distributed systems have experienced a shift of scale in the past few years. This evolution has generated an interest in peer-to-peer systems and resulted in much interesting work. Peer-to-peer systems are characterized by their potential to scale due to their fully decentralized nature. They are self-organizing, adapting automatically to peer arrivals and departures, and are highly resilient to failures. They rely on a symmetric communication model where peers act both as servers and clients. As the peer-to-peer concepts and technologies become more mature, many distributed services and applications relying on this model are envisaged in the context of large-scale distributed and parallel systems. This topic examines peer-to-peer technologies, applications, and systems, and also identifies key research issues and challenges. Twenty-six papers were submitted to the track and we accepted six. We organized two sessions, the first devoted to the problem of query management in structured and unstructured overlay networks, the second containing a broader selection of topics. In """" Path Query Routing in Unstructured Peer-to-Peer Networks """" , a solution is proposed to the problem of storing an XML database over an unstruc-tured peer-to-peer network. The system combines multi-level bloom filters for path queries with exponentially decaying bloom-filters for neighbourhood knowledge , to decide to which neighbours queries should be forwarded in the network. In """" Processing Top-k Queries in Distributed Hash Tables """" , a new algorithm is presented, to extract only the first k replies matching a given query in a Distributed Hash Table. Multiple parameters can be taken into account in the query, provided each parameter domain can be split uniformly among some of the peers. In """" Multi-dimensional Range Queries Over Structured Overlays """" the authors suggest SOMA, a CAN-like overlay for executing range queries on multiple attributes. SOMA is based on a virtual d-dimensional Cartesian coordinate space, where each dimension corresponds to one attribute. SOMA processes range queries in log(N) routing steps, N being the number of nodes. In """" Asynchronous Distributed Power Iteration with Gossip-based Normaliza-tion """" , the authors have designed a fully distributed and robust algorithm based on gossip for finding the dominant eigenvector of large and sparse matrices. In """" Capitalizing on Free Riders in P2P Networks """" , instead of fighting free riders by shutting them out, a mechanism is presented to benefit from them by letting them handle the forwarding of search queries. This mechanism shifts the load of …"""	algorithm;bloom filter;cartesian closed category;distributed hash table;information retrieval;organizing (structure);overlay network;peer-to-peer;power iteration;range query (data structures);routing;self-organization;sparse matrix;web search query;xml database	Dick H. J. Epema;Márk Jelasity;Josep Jorba;Alberto Montresor	2008		10.1007/978-3-540-85451-7_63	best-effort delivery;self-organization;overlay network;models of communication;distributed data store;computer science;database;distributed computing;world wide web;file sharing;client–server model;satisfiability	DB	-12.574480365841891	72.30099303927993	51511
394622c21a8e737a995a0769d065a4cdc4635350	a robust retail pos system based on blockchain and edge computing		New Retail has recently become one of the hottest concepts in the world, particularly in China. Many Internet technologies like Cloud Computing have been employed to address the limitations of the traditional retail industry, and significant progress has been made towards this direction. Despite these achievements, an intractable issue faced by the existing cloud-based retail POS systems is that they cannot provide continuous services when the Internet connections are interrupted. Towards this issue, in this paper, we leverage two new technologies, Blockchain and Edge Computing, to design and develop a new robust retail POS system. More specifically, this type of POS systems deployed in a retail store can use blockchain networking, trustworthiness, and security. We take all cash registers as nodes to build a POS blockchain network and store transaction records in the blockchain network to deal with unexpected network interruptions. Once the Internet connection recovers, a node in the blockchain network will be selected as a POS edge computing server to synchronize data with the POS cloud and resume regular communication between them. The advantages of the robust retail POS system over traditional POS systems include less dependency on the Internet in case of sudden interruptions and little or no hands-on intervention required for changes in our POS system caused by external changes.	bitcoin;edge computing	Bo Hu;Hongfeng Xie;Yutao Ma;Jian Wang;Liang-Jie Zhang	2018		10.1007/978-3-319-94340-4_8	leverage (finance);trustworthiness;cloud computing;synchronization;the internet;blockchain;business;distributed computing;database transaction;edge computing	Crypto	-33.36180507341363	63.03891930199279	51532
2e1b3ae201603e55d2f43a8c72367118ba916afd	scalable hardware monitors to protect network processors from data plane attacks	monitoring program processors hardware multicore processing security internet;telecommunication network routing computer network security field programmable gate arrays grid computing multiprocessing systems;computer network security;multicore prototype scalable hardware monitors network processors protection data plane attacks router hardware computer networks packet forwarding operations network data plane router control interface single malformed udp packet vulnerable packet processing software denial of service attack network processors defense mechanism hardware monitoring systems scalable hardware monitoring grid hardware monitoring resource sharing fpga platform field programmable gate array;telecommunication network routing;multiprocessing systems;field programmable gate arrays;grid computing;fpga network security network infrastructure data plane attack hardware monitor multicore processor	Modern router hardware in computer networks is based on programmable network processors, which implement various packet forwarding operations in software. These processor systems are vulnerable to attacks that can be launched entirely through the data plane of the network without any access to the control interface of the router. Prior work has shown that a single malformed UDP packet can take over a network processor running vulnerable packet processing software and trigger a devastating denial-of-service attack from within the network. One possible defense mechanism for these resource-constrained network processors is the use of hardware monitoring systems that track the operations of each processor core. Any deviation from programmed behavior indicates an attack and triggers reset and recovery actions. Such hardware monitors have been studied extensively for single processor cores, but network processors consist of dozens to hundreds of processors with highly dynamic workloads. In this paper, we present the design of a Scalable Hardware Monitoring Grid, which allows the dynamic sharing of hardware monitoring resources among processor cores. We show the scalability of our monitoring system to network processors with large numbers of cores. We also present a multicore prototype implementation of the monitoring system on an FPGA platform.	attack (computing);central processing unit;denial-of-service attack;field-programmable gate array;forwarding plane;general-purpose markup language;multi-core processor;network packet;network processor;overhead (computing);prototype;router (computing);scalability;single-core;system monitor;throughput	Kekai Hu;Harikrishnan Chandrikakutty;Russell Tessier;Tilman Wolf	2013	2013 IEEE Conference on Communications and Network Security (CNS)	10.1109/CNS.2013.6682721	embedded system;parallel computing;real-time computing;packet analyzer;computer science;network security;operating system;computer security;field-programmable gate array;grid computing;network processor;computer network	Arch	-7.967967224592912	66.46529962885498	51620
a9e5992068ec6c3a280ffab1258412a73491a600	energy efficient cloud networks	energy efficiency;virtualization;renewable energy sources;servers;computational modeling;power demand;cloud computing	Cloud computing is expected to be a major factor that will dominate the future Internet service model. This paper summarizes our work on energy efficiency for cloud networks. We develop a framework for studying the energy efficiency of four cloud services in IP over WDM networks: cloud content delivery, storage as a service (StaaS), and virtual machines (VMS) placement for processing applications and infrastructure as a service (IaaS). Our approach is based on the co-optimization of both external network related factors such as whether to geographically centralize or distribute the clouds, the influence of users' demand distribution, content popularity, access frequency and renewable energy availability and internal capability factors such as the number of servers, switches and routers as well as the amount of storage demanded in each cloud. Our investigation of the different energy efficient approaches is backed with Mixed Integer Linear Programming (MILP) models and real time heuristics.	centralisation;cloud computing;digital distribution;future internet;heuristic (computer science);linear programming;mathematical optimization;network switch;real-time computing;router (computing);virtual machine;wavelength-division multiplexing	Leonard Nonde;Ahmed Q. Lawey;Taisir E. H. El-Gorashi;Jaafar M. H. Elmirghani	2016	2016 12th International Conference on Network and Service Management (CNSM)	10.1109/CNSM.2016.7818457	renewable energy;real-time computing;virtualization;simulation;cloud computing;computer science;operating system;cloud testing;efficient energy use;computational model;server;computer network	HPC	-21.211898492226485	63.098751975577066	51781
174a0e6b2c5c49ca98f85194caea955bb5ce535c	rapid optimal scheduling for time-multiplex switches using a cellular automaton	blocking probability;commutation telecommunication;conmutacion telecomunicacion;graph theory;switched system;special purpose parallel computer packet switching tdm traffic scheduling optimal scheduling time multiplex switches cellular automaton scheduling algorithm;telecommunications computing electronic switching systems graph theory packet switching parallel processing scheduling;concurrent computing;tdm;time measurement;traffic scheduling;time multiplex switches;processor scheduling;packet switching;automata;scheduling algorithm;telecommunications computing;telecommunication switching;optimal scheduling;scheduling;waiting time;special purpose parallel computer;parallel computer;electronic switching systems;optimal scheduling switches automata processor scheduling concurrent computing scheduling algorithm communication switching time measurement packet switching throughput;communication switching;switches;cellular automaton;parallel processing;throughput	Many time-multiplex switching systems require that the incoming traffic be scheduled to avoid conflict at the switch output (two or more users converging simultaneously upon a single output). Optimal scheduling provides a means to assign traffic on demand such that either blocking probability is minimized (unbuffered system) or packet waiting time is minimized (buffered system). However, computation of an optimal schedule for switches of a reasonable size (i.e. N=100) may require many seconds or even minutes, whereas the traffic demand may vary much more rapidly. Since the computation time varies as O(N/sup 2/), the problem becomes readily intractable for large N. This computational bottleneck is overcome by using a scheduling algorithm which is run on a simple special-purpose parallel computer (cellular automaton). A schedule is produced in O(N) time if signal propagation time in the automaton is considered negligible, and therefore increases in computation speed by several orders of magnitude should be possible; the time to compute a schedule for a 1000-input switch would be measured in milliseconds rather than minutes. >	cellular automaton;multiplexing;network switch;scheduling (computing)	Christopher Rose	1989	IEEE Trans. Communications	10.1109/26.24601	cellular automaton;parallel processing;parallel computing;real-time computing;concurrent computing;computer science;graph theory;distributed computing;scheduling	Embedded	-6.313658293178957	63.508559032331625	51798
7e24bf65b2722bdcd627ff5d4e6088e743699847	constructing sub-exponentially large optical priority queues with switches and fiber delay lines	optical switches multiplexing equipment optical fibre networks;large optical priority queues multiplexers optical crossbar switches optical queues fiber link capacity all optical switching fiber delay lines switches;optical switches multiplexing optical buffering delay lines optical packet switching optical feedback	Optical switching has been considered as a natural choice to keep pace with growing fiber link capacity. One key research issue of all-optical switching is the design of optical queues by using optical crossbar switches and fiber delay lines (SDLs). In this paper, we focus on the construction of an optical priority queue with a single (M+2)×(M+2) crossbar switch and M fiber delay lines, and evaluate it in terms of the buffer size of the priority queue. Currently, the best known upper bound of the buffer size is O(2M), while existing methods can only construct a priority queue with buffer O(M3). In this paper, we make a great step towards closing the above huge gap. We propose a very efficient construction of priority queues with buffer 2Θ(√M). We use 4-to-1 multiplexers with different buffer sizes, which can be constructed efficiently with SDL, as intermediate building blocks to simplify the design. The key idea in our construction is to route each packet entering the switch to some group of four 4-to-1 multiplexers according to its current priority, which is shown to be collision-free.	closing (morphology);crossbar switch;multiplexer;network packet;network switch;optical switch;priority queue	Bin Tang;Xiaoliang Wang;Cam-Tu Nguyen;Sanglu Lu	2016	2016 IEEE International Symposium on Information Theory (ISIT)	10.1109/ISIT.2016.7541537	optical transport network;real-time computing;optical burst switching;computer science;optical add-drop multiplexer;distributed computing;optical switch;optical performance monitoring;optical cross-connect;computer network	Arch	-5.9404207701875835	87.15930551437279	51830
ff3999133d27d02b651a7fc60e2a1d0c8eb8fb42	performance-aware scheduling of streaming applications using genetic algorithm		The main objective of Decision Support Systems is detection of critical states and response on them in time. Such systems can be based on constant monitoring of continuously incoming data. Stream processing is carried out on the basis of computing infrastructure and specialized frameworks such as Apache Storm, Flink, Spark Streaming. However, to provide the necessary system performance at high load incoming data, additional data processing mechanisms are required. In particular, the efficient scheduling of streaming applications plays an important role in the data stream processing. Therefore, this paper is devoted to investigation of genetic algorithm to improve the performance of data stream processing system. The proposed genetic algorithm is developed and integrated into Apache Storm platform, and its efficiency is compared with heuristic algorithm for scheduling of Storm streaming applications.	apache storm;batch processing;computer performance;decision support system;evolutionary algorithm;experiment;genetic algorithm;heuristic (computer science);scheduling (computing);software release life cycle;stream processing;streaming media;throughput;urgent computing	Pavel A. Smirnov;Mikhail Melnik;Denis A. Nasonov	2017		10.1016/j.procs.2017.05.249	data stream;genetic algorithm;stream processing;real-time computing;decision support system;heuristic (computer science);computer science;scheduling (computing);distributed computing;data processing	DB	-17.580558140692435	62.69607717112785	51882
a2468ede76e1d014dde5e7ff759107f28feeeae5	debugging the internet of things: a 6lowpan/coap testbed infrastructure	coap;6lowpan;experimentally driven research;internet of things;testbeds	"""This paper is based on two fundamental assumptions about a future Internet of Things (IoT): i) The amount of wireless, resource-constrained devices will outnumber the amount of devices in the current internet by several orders of magnitude and ii) those devices will be connected to the Internet over multi-hop wireless links. We argue that the experimental validation in testbeds is imperative to make those networks robust. However, there are only limited means to support researchers in """"debugging"""" the actual communication on the wireless medium and often developers can only guess why their protocols don't work in a given environment. In this paper, we present such a framework which extends the WISEBED testbed federation. Our contribution allows an easy-to-use browser-based experimentation and evaluation of wireless multi-hop protocols in all WISEBED-compatible testbeds (nine testbeds with 1000 sensor nodes and the SmartSantander [17] smart city testbed which will offer up to 20,000 IoT devices). Using a generic packet tracking framework for multiple platforms, researchers can easily detect hotspots and bottlenecks in the network and follow the routes of individual packets as they are forwarded. Experiment configurations can be shared on the web so that experiments can easily be repeated to verify published results. We demonstrate the usability of our approach by means of a real-world use-case."""	constrained application protocol;debugging;internet of things;testbed	Daniel Bimschas;Oliver Kleine;Dennis Pfisterer	2012		10.1007/978-3-642-31638-8_16	embedded system;6lowpan;computer science;distributed computing;world wide web;internet of things;computer network	OS	-11.745868540891003	86.33170488343553	51940
2555de188aa8a0a20aff6e24abd7612cff3bd24a	constant-time admission control for deadline monotonic tasks	scheduling;telecommunication congestion control;constant-time admission control;deadline monotonic tasks;embedded systems;hyperbolic bounds;real-time systems	The admission control problem is concerned with determining whether a new task may be accepted by a system consisting of a set of running tasks, such that the already admitted and the new task are all schedulable. Clearly, admission control decisions are to be taken on-line, and hence, this constitutes a general problem that arises in many real-time and embedded systems. As a result, there has always been a strong interest in developing efficient admission control algorithms for various setups. In this paper, we propose a novel constant-time admission control test for the Deadline Monotonic (DM) policy, i.e., the time taken by the test does not depend on the number of admitted tasks currently in the system. While it is possible to adapt known utilization bounds from the literature to derive constant-time admission control tests (e.g., the Liu and Layland bound, or the more recent hyperbolic bound), the test we propose is less pessimistic. We illustrate this analytically where possible and through a set of detailed experiments. Apart from the practical relevance of the proposed test in the specific context of DM tasks, the underlying technique is general enough and can possibly be extended to other scheduling policies as well.	algorithm;embedded system;experiment;non-monotonic logic;online and offline;real-time clock;relevance;scheduling (computing)	Alejandro Masrur;Samarjit Chakraborty;Georg Färber	2010	2010 Design, Automation & Test in Europe Conference & Exhibition (DATE 2010)		embedded system;delta modulation;real-time computing;computer science;operating system;distributed computing;upper and lower bounds;system testing;scheduling;assembly language;polynomial	Embedded	-9.595051978723289	61.16386191748858	51953
0dbcaaf5767f00278b672e4937cab67d327f38bd	inter-connection automation for of@tein multi-point international openflow islands	openflow enabled software defined networking testbed;design and implementation;overlay virtual networking;tunneling based inter connection	In realizing futuristic services with agility, testbed environments that provide converged computing/networking resources based on SDN (Software--Defined Networking) and CC (Cloud Computing) are becoming important. Following this trend, OF@TEIN OpenFlow--enabled SDN testbed environment is built with internationally-distributed unique SmartX Racks. In this paper, to automate the multi-point L2 inter-connections of OpenFlow islands, we design and implement a configuration tool for NVGRE (Network Virtualization using Generic Routing Encapsulation) tunneling. The proposed tool manages the desired topology by leveraging the OVSDB (Open vSwitch Database) configuration interface for OpenFlow switches. With the implemented tool and appropriate admin/user privilege management, we can quickly inter-connect the multi-point international OpenFlow islands while letting users to freely control (i.e., tag/steer/map) their own flows for experimentation.	cloud computing;experiment;network switch;open vswitch;openflow;privilege (computing);privilege management infrastructure;routing;software-defined networking;testbed;tunneling protocol	Taeheum Na;JongWon Kim	2014		10.1145/2619287.2619293	openflow;embedded system;engineering;distributed computing;software-defined networking;computer network	Embedded	-16.400389959391536	83.1870602079806	51999
5685697c9fe1303d9c8ac19188b94ebf16a081dc	near-optimal scheduling mechanisms for deadline-sensitive jobs in large computing clusters	maximum degree;social welfare;approximate algorithm;resource allocation;economic model;economic models;data center;scheduling algorithm;scheduling algorithms;optimal scheduling;linear program;capacity constraint;truthful mechanisms;empirical evaluation;cloud computing	We consider a market-based resource allocation model for batch jobs in cloud computing clusters. In our model, we incorporate the importance of the due date of a job rather than the number of servers allocated to it at any given time. Each batch job is characterized by the work volume of total computing units (e.g., CPU hours) along with a bound on maximum degree of parallelism. Users specify, along with these job characteristics, their desired due date and a value for finishing the job by its deadline. Given this specification, the primary goal is to determine the scheduling} of cloud computing instances under capacity constraints in order to maximize the social welfare (i.e., sum of values gained by allocated users). Our main result is a new ( C/(C-k) ⋅ s/(s-1))-approximation algorithm for this objective, where C denotes cloud capacity, k is the maximal bound on parallelized execution (in practical settings, k l C) and s is the slackness on the job completion time i.e., the minimal ratio between a specified deadline and the earliest finish time of a job. Our algorithm is based on utilizing dual fitting arguments over a strengthened linear program to the problem.  Based on the new approximation algorithm, we construct truthful allocation and pricing mechanisms, in which reporting the job true value and properties (deadline, work volume and the parallelism bound) is a dominant strategy for all users. To that end, we provide a general framework for transforming allocation algorithms into truthful mechanisms in domains of single-value and multi-properties. We then show that the basic mechanism can be extended under proper Bayesian assumptions to the objective of maximizing revenues, which is important for public clouds. We empirically evaluate the benefits of our approach through simulations on data-center job traces, and show that the revenues obtained under our mechanism are comparable with an ideal fixed-price mechanism, which sets an on-demand price using oracle knowledge of users' valuations. Finally, we discuss how our model can be extended to accommodate uncertainties in job work volumes, which is a practical challenge in cloud settings.	approximation algorithm;batch processing;central processing unit;cloud computing;computer cluster;data center;degree of parallelism;job stream;linear programming;maximal set;memory management;parallel computing;price point;scheduling (computing);simulation;tracing (software)	Navendu Jain;Ishai Menache;Joseph Naor;Jonathan Yaniv	2012		10.1145/2312005.2312051	mathematical optimization;parallel computing;real-time computing;computer science;linear programming;economic model;operating system;distributed computing;scheduling	ECom	-19.20294351564171	61.46540765067253	52032
0c549b710b2118ea003679fbda65ed175a021c1b	dynamic resource allocation and pricing for shared radio access infrastructure		Flexible resource sharing at short time scales in multi-tenant shared radio access networks has proven to be quite a challenge. In this study, we develop a techno-economic model that enables dynamic short-term resource sharing as well as resource pricing, while simultaneously collecting revenue for network expansion. In order to regulate the resource costs and to prevent monopolization of resources, we define a unit cost of resources which can be scaled dynamically. The proposed framework allows operators to meet their individual utility targets while optimizing their expenditures based on their respective budgets. This work demonstrates that dynamic short timescale resource sharing can help network operators achieve their utility targets while minimizing their total expenditure.	access network;algorithm;fairness measure;hoard;multitenancy;real-time transcription;scalability;service-level agreement	Özgür Umut Akgül;Ilaria Malanchini;Vinay Suryaprakash;Antonio Capone	2017	2017 IEEE International Conference on Communications (ICC)	10.1109/ICC.2017.7997285	computer network;resource management;unit cost;dynamic priority scheduling;computer science;next-generation network;revenue;access network;shared resource;resource allocation	Robotics	-21.855007988897118	63.88563099443706	52082
3e35ea6682f8d80b246b09a76e5fda1c8ed674c5	a novel dynamic mobility management scheme in lisp architecture	mobility management mobile radio;routing protocols;locator id separation;manganese mobile radio mobility management scalability;routing protocols internet mobility management mobile radio;internet;locator id separation protocol dynamic mobility management lisp architecture internet routing table mobile node global id locator mapping system handover cost handover latency;lisp;locator id separation dynamic mobility management lisp;dynamic mobility management	LISP is an important development and implementation effort toward the resolution to the Internet routing table scalable issues. Although the LISP is based on the idea of the Locator/ID separation, it could not support mobility very well until now. This paper proposes a novel dynamic mobility management scheme in LISP architecture. It improves the LISP by introducing three name spaces and two mapping systems. By dynamic configuring the IDs to the mobile nodes, the proposed scheme could provide flexible mobility support with lower overhead, while maintaining the scalability and aggregatability of the global ID/locator mapping system. Furthermore, a fast location update method is presented in the proposed scheme to provide smooth handover. The proposed scheme is evaluated by comparing with the LISP Mobile Node in handover cost and handover latency.	caller id;internet;lisp machine;network packet;online locator service;overhead (computing);routing table;scalability	Yang Li;Zhijun Zhao;Haibo Li;Hui Tang;Song Ci	2012	2012 18th Asia-Pacific Conference on Communications (APCC)	10.1109/APCC.2012.6388103	embedded system;real-time computing;locator/identifier separation protocol;computer science;mobility model;computer network	Mobile	-14.026562385041897	77.82721769348268	52089
d404895fe8c42420f15f4fcd2983393f332d5587	dimensioning of overlay networks for p2p multicasting	multicast communication;optimization overlay network p2p multicasting;multicast algorithms;web and internet services;heuristic algorithm p2p multicasting system overlay network dimensioning network virtualization internet peer to peer multicasting live streaming integer program access link capacities network cost minimization overlay network capacity overlay network management optimization problem;overlay network management;network virtualization;p2p;peer to peer computing computer network management integer programming multicast communication;future internet;network cost minimization;computer networks;optimization problem;overlay network dimensioning;telecommunication traffic;internet;integer programming;p2p multicasting;heuristic algorithms;computer network management;overlay network;ip networks;optimization;peer to peer multicasting;p2p multicasting system;peer to peer computing;integer program access link capacities;integer program;peer to peer;live streaming;overlay network capacity;algorithm design and analysis;iptv;heuristic algorithm;conferences;peer to peer computing ip networks costs iptv web and internet services heuristic algorithms multicast algorithms algorithm design and analysis telecommunication traffic computer networks	Concepts of network virtualization and overlays are nowadays gaining much popularity and are perceived as key approaches for future Internet. One of possible applications used in overlay networks is live streaming based on Peer-to-Peer (P2P) multicasting. This paper deals with the problem of overlay networks dimensioning. In the problem - formulated as an Integer Program - access link capacities are to be selected with the objective to minimize the network cost expressed as the cost of access links. We solve the optimization problem using both CPLEX solver and our own heuristic algorithm that provides results close to optimal but with significantly lower execution time. Based on the proposed framework we examine the problem of how to design the overlay network to provide sufficient capacity for P2P multicasting. Using a simulator of a real P2P multicasting system we run extensive experiments on large networks (up to 100000 nodes) showing the dependency between the overlay network capacity and the performance of P2P multicasting streaming. Our results can be helpful in the process of overlay networks design and management.	algorithm;cplex;call stack;experiment;future internet;heuristic (computer science);integer programming;mathematical optimization;multicast;optimization problem;overlay network;peer-to-peer;run time (program lifecycle phase);solver;streaming media	Krzysztof Walkowiak	2010	2010 IEEE Network Operations and Management Symposium - NOMS 2010	10.1109/NOMS.2010.5488371	heuristic;optimization problem;algorithm design;real-time computing;the internet;overlay network;integer programming;computer science;peer-to-peer;distributed computing;computer network	Metrics	-5.968033474909595	82.55918472497349	52096
43524fe3fd98f741af056a59554bf8836c911619	addressing the out-of-date problem for efficient load balancing algorithm in p2p systems		Load-balancing is of major significance for large-scale decentralized networks such as Peer-to-Peer (P2P networks in terms of enhanced scalability and performance. P2P networks are considered to be the most important development for content distribution and sharing infrastructures. Load balancing among peers in P2P networks is critical and a key challenge. This paper addresses the out-of-date problem as a result of node’s state changes during loads movement among nodes. Consequently, this work proposes a load balancing algorithm that is based on extensive stochastic analysis and virtual server concept in P2P System. Finally, this work is complemented with extensive simulations and experiments.	algorithm;load balancing (computing)	Khaled Ragab;Moawia Elfaki Yahia	2012		10.1007/978-94-007-5860-5_56	scalability;algorithm;load balancing (computing);stochastic process;computer science	Theory	-12.46666957266422	73.25475162389986	52132
9d69ef4035086e71479bdda5e7fec255a5902020	rethinking transfer optimization in a datacenter: integrating load balancing with multipath flow control		The various flows in production datacenters usually can be classified into two types: bandwidth-hungry and delay-sensitive. To improve their performance, datacenter networks require effective load balancing and flow control protocols, respectively. However, as the two techniques are typically employed separately in current datacenters, they are unable to optimize the network in a coordinated way. In this work, we argue that the adaptive routing, in load balancing sense, and the flow control, in congestion control sense, could be tightly coupled at the transport layer to handle the complex datacenter traffic. We design OmniFlow, a novel transfer protocol which aims to achieve a proper balance between throughput and latency in a datacenter. Firstly, it can simultaneously and precisely measure the queueing latencies on multiple paths between two hosts, which enables it to have more visibility of the path congestion and have better control of the transmission states. Secondly, OmniFlow adaptively integrates the load balancing and flow control modules and shares the same congestion metrics (i.e. queueing latencies) between them. Based on different network conditions, it either dynamically reroutes flows to utilize the bisection bandwidth or proactively adjusts flow rates to bound queueing occupancies. The results of extensive experiments show that OmniFlow can provide both low average and tail latency for small flows without sacrificing the throughput of elephant flows.	bisection bandwidth;daemon (computing);data center;experiment;flow control (data);i/o controller hub;load balancing (computing);mathematical optimization;multipath propagation;network congestion;ping (networking utility);queueing theory;routing;simulation;throughput	Zhuzhong Qian;Kaiyuan Wen;Sheng Zhang;Xiaoliang Wang;Sanglu Lu	2017	2017 IEEE/ACM 25th International Symposium on Quality of Service (IWQoS)	10.1109/IWQoS.2017.7969132	latency (engineering);throughput;computer network;real-time computing;network congestion;computer science;transport layer;load balancing (computing);load management;bisection bandwidth;flow control (data);distributed computing	Networks	-13.378007875588704	81.52390453459655	52153
5b9e09ab12d0fc7a0e575afbbd6a23fabdf3cce5	examining the reproducibility of using dynamic loop scheduling techniques in scientific applications		Reproducibility of the execution of scientific applications on parallel and distributed systems is a growing concern, underlying the trustworthiness of the experiments and the conclusions derived from experiments. Dynamic loop scheduling (DLS) techniques are an effective approach towards performance improvement of scientific applications via load balancing. These techniques address algorithmic and systemic sources of load imbalance by dynamically assigning tasks to processing elements. The DLS techniques have demonstrated their effectiveness when applied in real applications. Complementing native experiments, simulation is a powerful tool for studying the behavior of parallel and distributed applications. In earlier work, the scalability [1], robustness [2], and resilience [3] of the DLS techniques were investigated using the MSG interface of the SimGrid simulation framework [4]. The present work complements the earlier work and concentrates on the verification via reproducibility of the implementation of the DLS techniques in SimGrid-MSG. This work describes the challenges of verifying the performance of using DLS techniques in earlier implementations of scientific applications. The verification is performed via reproducibility of simulations based on SimGrid-MSG. To simulate experiments selected from earlier literature, the reproduction process begins by extracting the information needed from the earlier literature and converting it into the input required by SimGrid-MSG. The reproducibility study is carried out by comparing the performance of SimGrid-MSG-based experiments with those reported in two selected publications in which the DLS techniques were originally proposed. While the reproduction was not successful for experiments from one of the selected publications, it was successful for experiments from the other. This successful reproduction implies the verification of the DLS implementation in SimGrid-MSG for the considered applications and systems, and thus, it allows well-founded future research on the DLS techniques.	algorithm;dls format;distributed computing;experiment;load balancing (computing);loop scheduling;scalability;scheduling (computing);simgrid;simulation;trust (emotion)	Franziska Hoffeins;Florina M. Ciorba;Ioana Banicescu	2017	2017 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)	10.1109/IPDPSW.2017.147	computer science;implementation;distributed computing;parallel computing;theoretical computer science;trustworthiness;robustness (computer science);loop scheduling;dynamic priority scheduling;reproducibility;scalability;load balancing (computing)	HPC	-16.521327859504467	60.780614290717985	52169
4df76903459c3e9dae05ef7f45788d050df740db	studying the effect of internet exchange points on internet link delays	denial of service attacks;network simulation;studying the effect of internet exchange points on internet link delays;internet routing;articulo;overlay networks;autonomic system	Internet exchange points (IXPs) are an increasingly important constituent of the Internet at the Autonomous System (AS) level. IXPs are set up with the goal of enabling greater efficiency in traffic exchange between ASes both from economical and technical perspectives. Little is however known about the effect that IXPs have in packet transmission between peering ASes, with a significant focus of the research community being in determining their effect on the topology evolution of the Internet. In this paper, we report on the increasing deployment of IXPs around the world over the past few years and carry out a set of experiments to try and establish the effectiveness of Internet routes traversing an IXP. We find that IXP links entail lesser delays than normal links on the Internet even though their presence does not decrease the length of a path. Our results present pointers towards developing more extensive experiments to verify the effectiveness of deploying IXPs worldwide.	autonomous system (internet);experiment;internet;mike lesser;network packet;peering;pointer (computer programming);software deployment;traffic exchange	Mohammad Zubair Ahmad;Ratan K. Guha	2010		10.1145/1878537.1878645	internet backbone;tier 1 network;simulation;overlay network;autonomous system;internet transit;computer science;network simulation;distributed computing;computer security;denial-of-service attack;internet exchange point;computer network	Networks	-10.238854772037879	78.31679711336038	52247
3342fff41d3959360d2469cb395c3d7dcb454f66	performance analysis of a scaleable design for replicating file collections in wide-area networks	file transfer;distributed system;replication;systeme reparti;storage system;red www;red larga distancia;transferencia fichero;menu;reseau longue distance;distributed storage;gestion fichier;network performance;file management;replicacion;synchronisation;large scale;sistema repartido;internet;transfert fichier;synchronization;systeme memoire;analyse performance;manejo archivos;performance analysis;world wide web;reseau www;serveur fichier;sincronizacion;sistema memoria;high speed;wide area network;file server;open source;analisis eficacia	Mirroring file collections in the global Internet is widely practiced with a recent study estimating the number of WWW hosts with mirrored content at 10% of all WWW hosts. Conventional mirroring tools, however, are not well-suited for the large-scale multiplesite replication services envisioned by projects such as the Internet2 Distributed Storage Infrastructure (I2-DSI) project. This paper presents a scaleable design for the automated synchronization of large collections of files replicated across multiple hosts, as in I2-DSI, and outlines of how the design has been realized using rsyncC, a modification to the popular open-source mirroring tool, rsync. A performance study based on an instrumented mirror usingrsyncC empirically characterizes server-side processing costs under realistic, large-scale workloads, and supplementary measurements of network throughput across Internet2 links illustrate the achievable network performance in a high-speed wide-area network. These experimental results confirm the validity of scalability arguments for the design, uncover key system parameters for rsyncC that must be tuned for efficient operation, and indicate the limitations of TCP-only transport solutions as the number of mirror sites grows.  2000 Academic Press	disk mirroring;internet;key;network performance;open-source software;profiling (computer programming);scalability;server-side;throughput;www;rsync	Bert J. Dempsey	2000	J. Network and Computer Applications	10.1006/jnca.2000.0111	embedded system;synchronization;distributed data store;telecommunications;computer science;operating system;world wide web	Metrics	-22.28673179240763	69.73777534267181	52257
55f5df6213f2f37287e406fb4258dccdf0b38358	dynamic task fetching over time varying wireless channels for mobile computing applications	wireless links;optimal solution;time varying;wireless channels;memory management;mobile device;performance evaluation;online optimization;mobile computer;dynamic program;internet architecture;computational complexity;mobile terminal	The processing, computation and memory requirements posed by emerging mobile broadband services require adaptive memory management and prefetching techniques at t he mobile terminals for satisfactory application performance and sustained device battery lifetime. In this wor k we investigate a scenario where tasks with varied computational requirements are fetched by a mobile device f rom a central server over an error prone wireless link. We examine the buffer dynamics at the mobile terminal and the ce ntral server under varying wireless channel connectivity and device memory congestion states as variable sizes tasks are executed on the terminal. Our goal is to minimize the latency experienced by these tasks while judiciously ut i izing the device buffering capability.We use a dynamic programming framework to model the optimal prefetching pol icy. We further propose a) a prefetching algorithm Fetchor-Not (FON), which uses quasi-static assumption on system tate to make prefetching decisions, and b) a prefetching policy RFON, which uses randomized approximation to the opt imal solution thus obviating the need for dynamic online optimization and substantially reducing the comput ational complexity. Through performance evaluation under slow and fast fading scenarios we show that proposed algorit hms come close to performance of the optimal scheme. I. I NTRODUCTION The advent of portable devices with wireless communication capability (e.g., PDAs, mobile phones) has provided great impetus to mobile computing applications. A broad spe ctrum of wireless broadband services are being offered to billions of users across the globe today. Some of t hese include location based services, streaming of compressed media (e.g. video) to mobile users, distributed execution of parallelizable computational tasks over This is a considerably enhanced version of the work [1] which appeared in ACM International Workshop on Mobility Managem ent and Wireless Access, 2007 Aditya Dua is with Qualcomm Inc., 657 Campbell Technology Pk wy, Campbell CA 95008. Email: adua@qualcomm.com Dimitrios Tsamis and Nicholas Bambos are with Department of Electrical Engineering, Stanford University, 350 Serra Ma ll, Stanford CA 94305. Email:{dtsamis,bambos }@stanford.edu Jatinder Pal Singh is with Deutsche Telekom R&D Laboratorie s, 5050 El Camino Real, Los Altos, CA 94022, Email: jatinder.singh@telekom.com, and with Department of Electrical Engineering, Stanford University, 350 Serra Mall, Stanfor d CA 94305. Email: jatinder@stanford.edu	approximation;cpu cache;camino;cognitive dimensions of notations;computation;dynamic programming;electrical engineering;email;emoticon;icy;location-based service;mathematical optimization;memory management;mobile computing;mobile device;mobile phone;network congestion;online optimization;performance evaluation;personal digital assistant;randomized algorithm;requirement;server (computing)	Aditya Dua;Dimitrios Tsamis;Nicholas Bambos;Jatinder Pal Singh	2009	CoRR		real-time computing;simulation;computer science;operating system;mobile device;distributed computing;computational complexity theory;mobile computing;computer network;memory management	Mobile	-16.008981066190284	66.22880698678186	52341
9308e49de3b3ab657693864e4664253f22263228	towards high-performance ipsec on cavium octeon platform	network security;ipsec;network processor;cryptography;multi core	Providing secure, reliable communications is a big challenge to guarantee confidentiality, integrity, and anti-replay protection, especially between endpoints in current Internet. As one of the popular secure communication protocol, IPsec usually limits the throughput and increases the latency due to its heavy encryption/decryption processing. In this paper, we propose a hardware solution to accelerate it. To achieve high performance processing, we have successfully designed and implemented IPsec on Cavium OCTEON 5860 multi-core network processor platform. We also compare the performance under different processing mechanisms and discover that pipleline works better than run-to-completion for different sizes of packets in our experiments. In order to achieve the best performance, we select different encryption algorithms and core numbers. Experimental results on 5860 processors show that our work achieves 20 Gbps throughput with AES128 encryption, 16 cores for 512-byte packet traffic.	algorithm;anti-replay;central processing unit;communications protocol;confidentiality;data rate units;encryption;experiment;ipsec;internet;multi-core processor;network packet;network processor;network security;reliability (computer networking);run to completion scheduling;scalability;secure communication;throughput	Jinli Meng;Xinming Chen;Zhen Chen;Chuang Lin;Beipeng Mu;Lingyun Ruan	2010		10.1007/978-3-642-25283-9_3	real-time computing;computer science;computer security;computer network	OS	-6.932532979868353	66.28161093906127	52348
6a21595e2c738f874b6c0f9ca8641530aeb01187	design of shared mesh restoration schemes with traffic load balancing constraint	network backup capacity;communications society;transportation networks;network design;iterative load balancing pool sharing algorithm;telecommunication network reliability;network links;iterative algorithms;telecommunication network planning;routing;resource allocation;lakes;survivable transport networks;shared mesh restoration scheme;software engineering;computer networks;network topology;iterative methods;network traffic shared mesh restoration scheme survivable transport networks network links network backup capacity iterative load balancing pool sharing algorithm trap topology problem computation complexity;protection;telecommunication traffic;telecommunication traffic load management iterative algorithms routing protection network topology computer networks communications society software engineering lakes;computational complexity;network traffic;computation complexity;trap topology problem;load management;load balance;quality of service;telecommunication network topology;algorithm design;telecommunication traffic computational complexity iterative methods resource allocation telecommunication network planning telecommunication network reliability telecommunication network topology	This paper presents two novel shared mesh restoration schemes for survivable transport networks. First, we present a two-step load balancing pool sharing (LBPS) scheme and show how this scheme can be used to balance the loads on the network links while still minimizing the reserved working and backup capacity in the network. Then, we propose an iterative load balancing pool sharing (ILBPS) algorithm, designed to eliminate the trap-topology problem associated with all two-step mesh restoration algorithms (including LBPS) while still achieving the LBPS algorithm's goals. We compare the capacity-usage, load balancing, and computation complexity performances of these algorithms with two representative algorithms. We show that with the proposed schemes, the network traffic can similarly, or more evenly, be distributed among network links than with the other schemes, at lower computation cost.	algorithm;backup;circuit restoration;computation;constrained shortest path first;global communications conference;heuristic (computer science);international conference on communications;iterative method;lightwave 3d;list of code lyoko episodes;load balancing (computing);mesh networking;network packet;optical fiber;path protection;pay to surf;performance;r. a. stradling;routing;shared mesh;wavelength-division multiplexing	Hassan Naser;Ming Gong	2008	2008 IEEE International Conference on Communications	10.1109/ICC.2008.995	algorithm design;routing;network planning and design;quality of service;resource allocation;computer science;load balancing;theoretical computer science;distributed computing;iterative method;computational complexity theory;network topology;computer network	HPC	-6.390266396847545	82.50560104304037	52417
70a41cf109efa6cd8a374bb292efe957b9adce36	handy: a hybrid association rules mining approach for network layer discovery of services for mobile ad hoc network	manet;handy;cross layer design;service discovery;semantic discovery;correlation patterns	Mobile Ad hoc Network (MANET) is an infrastructure-less network formed between a set of mobile nodes. The discovery of services in MANET is a challenging job due to the unique properties of network. In this paper, a novel service discovery framework called Hybrid Association Rules Based Network Layer Discovery of Services for Ad hoc Networks (HANDY) has been proposed. HANDY provides three major research contributions. At first, it adopts a cross-layer optimized design for discovery of services that is based on simultaneous discovery of services and corresponding routes. Secondly, it provides a multi-level ontology-based approach to describe the services. This resolves the issue of semantic interoperability among the service consumers in a scalable fashion. Finally, to further optimize the performance of the discovery process, HANDY recommends exploiting the inherent associations present among the services. These associations are used in two ways. First, periodic service advertisements are performed based on these associations. In addition, when a response of a service discovery request is generated, correlated services are also attached with the response. The proposed service discovery scheme has been implemented in JIST/SWANS simulator. The results demonstrate that the proposed modifications give rise to improvement in hit ratio of the service consumers and latency of discovery process.	ansi escape code;algorithm;artificial intelligence;data mining;hit (internet);hoc (programming language);multi-level governance;network congestion;optimized link state routing protocol;personal handy-phone system;scalability;semantic interoperability;service discovery;simulation;tora - toolkit for oracle;transaction processing;ubiquitous computing	Noman Islam;Zubair Ahmed Shaikh;Aqeel-ur Rehman;Muhammad Shahab Siddiqui	2013	Wireless Networks	10.1007/s11276-013-0571-3	mobile ad hoc network;computer science;operating system;data mining;service discovery;world wide web;computer network	Mobile	-9.948924686319842	81.03311226351019	52433
f87cda147363ea087c0ffcc0649da903a5c20d65	mode transition for online scheduling of adaptive real-time systems on multiprocessors	resource utilization;probability;performance evaluation;processor scheduling;real time;online scheduling;multi mode applications real time scheduling adaptive task systems mode transition;resource manager;adaptive task systems;mode transition;processor scheduling multiprocessing systems performance evaluation probability;upper bound;optimal scheduling;real time scheduling;adaptive system;schedules real time systems resource management optimal scheduling adaptive systems protocols processor scheduling;multiprocessing systems;task scheduling;multi mode applications;mode change probability mode transition delay online scheduling algorithm adaptive real time system scheduling tasks resource utilization eagle t performance evaluation average maximal utilization drift;real time systems	This paper presents a novel online scheduling algorithm for scheduling real-time adaptive systems in which tasks may have distinct resource requirements for each of thesystems' operating modes. Apart from prior work that considers only step-wise adaptation of tasks' resource utilization during mode transition, the proposed algorithm (named EAGLE-T)enables tasks to adapt their resource utilization progressively from one mode to another in a timely manner without causing any deadline miss. The upper bound of the delay and the drift between resource utilization achieved by EAGLE-T and the ideal scheduler during mode transition are provided. Performance evaluation shows that the progressive adaptation of EAGLE-Toffers improved performance over a step-wise approach (average maximal-utilization drift and mode-transition delay are reduced by up to 68.75% and 32.16%, respectively). As the probability of a mode change or the number of tasks vary, empirical results show that the resource utilization achieved by tasks scheduled using EAGLE-T is within 56% to 90% of the desired utilization(compared to 11%-81% when the step-wise scheme is used).	adaptive system;algorithm;maximal set;multiprocessing;multiprocessor scheduling;pdf/a;performance evaluation;progressive scan;real-time clock;real-time computing;real-time operating system;real-time transcription;requirement;scheduling (computing)	Prapaporn Rattanatamrong;José A. B. Fortes	2011	2011 IEEE 17th International Conference on Embedded and Real-Time Computing Systems and Applications	10.1109/RTCSA.2011.71	in situ resource utilization;parallel computing;real-time computing;computer science;resource management;adaptive system;probability;distributed computing;upper and lower bounds	Embedded	-10.922792356932945	60.542496329568614	52521
b25f14023641c7c415bf608ad4181831d55de93d	performance analysis of an optical network employing waveband and traffic grooming	ciencias exatas e da terra;ciencia da computacao;traffic grooming;network operating systems;interdisciplinar;90c59;90b18;physical sciences and mathematics;90c35;connection admission control;optical communication;multi granular optical cross connect;90b20;waveband;computer science;80m50;wavelength division multiplexing	This paper analyses an optical network architecture composed by an arrangement of nodes equipped with multi-granular optical cross-connects (MG-OXCs) in addition to the usual optical cross-connects (OXCs). Then, selected network nodes can perform both waveband as well as traffic grooming operations and our goal is to assess the improvement on network performance brought by these additional capabilities. Specifically, the influence of the MG-OXC multi-granularity on the blocking probability is evaluated for 16 classes of service over a network based on the NSFNet topology. A mechanism of fairness in bandwidth capacity is also added to the connection admission control to manage the blocking probabilities of all kind of bandwidth requirements. Comprehensive computational simulation are carried out to compare eight distinct node architectures, showing that an adequate combination of waveband and single-wavelength ports of the MG-OXCs and OXCs allow a more efficient operation of a WDM optical network carrying multi-rate traffic.	blocking (computing);erlang (unit);fairness measure;frequency band;mg (editor);national science foundation network;network architecture;network performance;optical cross-connect;profiling (computer programming);requirement;simulation;wavelength-division multiplexing	Helvécio M. Almeida;Eduardo M. G. de Queiroz;Eduardo J. Aloia;Murilo Araújo Romero;Amílcar C. César	2011	Photonic Network Communications	10.1007/s11107-011-0315-1	network traffic control;traffic grooming;telecommunications;computer science;distributed computing;wavelength-division multiplexing;optical communication;computer network	Networks	-6.127832945711454	86.45372185109493	52523
1a2fdd306240a7beaf82d0810f495d6fb9e1fb3d	cgmp: cloud-assisted green multimedia processing	t technology general	With continued advancements of mobile computing and communications, emerging novel multimedia services and applications have attracted lots of attention and been developed for mobile users, such as mobile social network, mobile cloud medical treatment, mobile cloud game. However, because of limited resources on mobile terminals, it is of great challenge to improve the energy efficiency of multimedia services. In this paper, we propose a cloud-assisted green multimedia processing architecture (CGMP) based on mobile cloud computing. Specifically, the tasks of multimedia processing with energy-extensive consumption can be offloaded to the cloud, and the face recognition algorithm with improved principal component analysis and nearest neighbor classifier is realized on CGMP based cloud platform. Experimental results show that the proposed scheme can effectively save the energy consumption of the equipment.	facial recognition system;mobile cloud computing;mobile computing;mobile device;mobile social network;nearest neighbour algorithm;principal component analysis	Yujun Ma;Yin Zhang;Zhengguo Sheng;Ruan Hang;Junfeng Wang;Yanming Sun	2015	Multimedia Tools and Applications	10.1007/s11042-015-2783-2	mobile search;simulation;mobile web;telecommunications;computer science;operating system;multimedia;mobile computing;world wide web;computer security;computer network	Mobile	-29.35215256077618	67.45200515480815	52621
b01672c370a5b8c6264cc38e1ec0efed55bd3ebe	a dynamic offloading algorithm for mobile computing	optimisation;mobile device;performance evaluation;telecommunication network reliability;wireless network;mobile computer;low complexity;drntu engineering computer science and engineering;satisfiability;journal article;data center;offloading;servers;energy consumption;heuristic algorithms;ieee 802 11 standards;mobile communication;software component;telecommunication network reliability mobile computing optimisation;mobile handsets;lyapunov optimization;mobile computing;wireless network connectivity dynamic offloading algorithm mobile computing handheld mobile device lifetime extension data center energy saving application execution time requirement lyapunov optimization software components;lyapunov optimization offloading mobile computing;heuristic algorithm;energy saving;heuristic algorithms energy consumption mobile handsets servers mobile communication mobile computing ieee 802 11 standards	Offloading is an effective method for extending the lifetime of handheld mobile devices by executing some components of applications remotely (e.g., on the server in a data center or in a cloud). In this article, to achieve energy saving while satisfying given application execution time requirement, we present a dynamic offloading algorithm, which is based on Lyapunov optimization. The algorithm has low complexity to solve the offloading problem (i.e., to determine which software components to execute remotely given available wireless network connectivity). Performance evaluation shows that the proposed algorithm saves more energy than the existing algorithm while meeting the requirement of application execution time.	algorithm;cloud computing;component-based software engineering;computation;data center;dedicated hosting service;direction of arrival;effective method;handheld game console;lyapunov fractal;lyapunov optimization;mathematical optimization;mobile computing;mobile device;performance evaluation;run time (program lifecycle phase);server (computing)	Dong Huang;Ping Wang;Dusit Niyato	2012	IEEE Transactions on Wireless Communications	10.1109/TWC.2012.041912.110912	heuristic;embedded system;data center;real-time computing;mobile telephony;computer science;component-based software engineering;operating system;wireless network;mobile device;distributed computing;mobile computing;lyapunov optimization;server;computer network;satisfiability	Mobile	-21.87505165362208	67.12210473766713	52627
ce2eaf49c78e20ad4c1e23b0b7f38dc53feb1a27	brief announcement: robust and private distributed shared atomic memory in message passing networks	secret sharing;shared memory emulation;network coding;fault tolerance;mrmw;message passing;semi byzantine;network cod ing;privacy	We study the problem of privately emulating shared memory in message passing networks. The system includes $N$ servers, and at most e semi-Byzantine servers that can deviate from the algorithm by sending corrupted data. Moreover, at most f servers can fail and stop.  The focus is on coded atomic storage (CAS) algorithms. We present a variant that ensures no information leakage by letting the servers store their data as secret shares. Our enhancement to CAS uses ⌈(N+k+2e)/2⌉-size quorums and Reed-Solomon codes. This enhancement preserves the algorithm ability to function in asynchronous system settings.  To the best of our knowledge, we are the first to address the privacy issue when emulating shared memory in message-passing systems.	algorithm;asynchronous system;emulator;folded reed–solomon code;information leakage;message passing;semiconductor industry;shared memory;spectral leakage	Shlomi Dolev;Thomas Petig;Elad Michael Schiller	2015		10.1145/2767386.2767450	distributed shared memory;fault tolerance;message passing;linear network coding;real-time computing;computer science;operating system;distributed computing;programming language;secret sharing;privacy;computer security	Theory	-33.53106718518911	68.98375762885497	52643
9d44ab6887b603244b80c105478b3857db2f407b	scheduling problems for parallel and distributed systems	parallel;dynamic scheduling;process queue formation;distributed;new approach;scheduling;scheduling problem;computer system;assignment procedure;two-pass scheduling algorithm;computer systems;algorithms;stages realization;scheduling algorithm	A two-pass scheduling algorithm for parallel and distributed computer systems is presented in this paper. We consider this algorithm as a complex of two stages: process queue formation and assignment procedure. A new approach of both stages realization is proposed. Our algorithm can be used to increase efficiency of static and dynamic scheduling.	algorithm;distributed computing;scheduling (computing)	Olga Rusanova;Alexandr Korochkin	1999		10.1145/319294.319323	fair-share scheduling;nurse scheduling problem;fixed-priority pre-emptive scheduling;job shop scheduling;distributed algorithm;parallel computing;real-time computing;earliest deadline first scheduling;gang scheduling;flow shop scheduling;dynamic priority scheduling;computer science;rate-monotonic scheduling;operating system;two-level scheduling;deadline-monotonic scheduling;distributed computing;scheduling;parallel algorithm;least slack time scheduling;lottery scheduling;round-robin scheduling;scheduling;multiprocessor scheduling	HPC	-12.201116504861192	61.81870223990903	52706
4d8a65b09720cb930136a429d53953d233151421	improving the performances of proxy cache replacement policies by considering infrequent objects	file transfer;performance;proxy caching;spatial workflow;grid;cache replacement;web proxy;replacement policy	"""In this paper, we perform a careful study of the effect of infrequent objects on the performance of many well-known web proxy cache replacement policies including LRU, LFU, GDSF, and LFD (an offline policy). Using a """"frequency-aware"""" version of these policy (one that is aware of these infrequent objects), we show that significant improvement in the performance (hit rates and byte hit rates) can potentially be achieved. We also present LRU-Pred, which is a modified LRU replacement policy that attempts to predict single access objects that it will not cache. The algorithm, though simple, achieve better performance than LRU. The results are encouraging and point to more research on designing more sophisticated replacement policies that can predict infrequent objects."""	algorithm;byte;least frequently used;online and offline;performance;proxy server;single-access key;web cache	Hon Wai Leong;Bo Guan	2006		10.1145/1141277.1141457	real-time computing;performance;computer science;operating system;database;adaptive replacement cache;grid;world wide web	DB	-17.53054790731788	71.01168773739289	52771
889d16dfa15d652377f65a59c5af35004762a7b6	finding maximum-cost minimum spanning trees	fixed cost;protocols;communication networks;history;bridges;trees mathematics;systems engineering and theory;computer networks;mst;network topology;tree graphs;costs tree graphs protocols systems engineering and theory network topology computer networks communication networks bridges local area networks history;minimum spanning tree;network topology maximum cost minimum spanning trees start up communication company mst;profitability;local area networks;maximum cost minimum spanning trees;trees mathematics network topology;start up communication company	Summary form only given. Consider the scenario in which a start-up communication company charges its network users by the cost of the minimum spanning tree (MST) they use in their protocols. Wanting to increase their profits, they aim at maximizing the cost of the MST of their network. We consider two different cases. In the first case, the company has a set of links with fixed cost vector W and wants to configure the network so that the MST of the network has the maximum possible cost. In the second case, the network topology is fixed, but the costs on the links assume d different values W/sub 1/, W/sub 2/, ..., W/sub d/ over the day. The company wants to fix the link costs to a value W~ = /spl Sigma//sub i/ p/sub i/ w/sub i/, for some weights p/sub 1/, p/sub 2/, ..., p/sub d/ where 0 /spl les/ p/sub i/ /spl les/ 1 and /spl Sigma//sub i/p/sub i/ = 1, so that the resulting network has a maximum-cost MST.	file spanning;minimum spanning tree;network topology	Ahmed A. Belal;Amr Elmasry	2005	The 3rd ACS/IEEE International Conference onComputer Systems and Applications, 2005.	10.1109/AICCSA.2005.1387013	local area network;communications protocol;computer science;minimum spanning tree;machine learning;distributed computing;tree;network topology;fixed cost;profitability index;computer network	Theory	-5.17640519841409	79.19650092024578	52814
1bab6c56cacc191addd8de6d472344303b969448	sd-monet: software defined mobility management in enterprise hetnet	heterogeneous mobility;enterprise network;seamless handover;software defined networking sdn;mobility management	The communication industry is envisioning ubiquitous connectivity as a crucial driving force in 5G. Next Generation Network (NGN) should interconnect, integrate and efficiently manage the enterprise networks to realize this vision. Efficient management and an always-on connectivity with seamless mobility across multiple radio access technologies are the paramount requirements of NGN. Media Independent Handover (MIH) is a well-known protocol for providing seamless mobility in Heterogeneous Networks (HetNet) but it imposes a critical requirement of implementing MIH Function (MIHF) in every intermediate entity. This prerequisite, in turn, results in a complex flow sequence of control messages between the intermediaries, causing significant signaling overhead, which ultimately results in higher handover delay and packet loss. Moreover, the lack of centralized strategy for control forwarding across HetNet results in intricate handover procedures. To address these problems, we propose SD-MONET: Software Defined Mobility Management in Enterprise HetNet. SD-MONET is a Software Defined Networking (SDN) based architecture to realize fast and seamless mobility across WiFi and cellular networks, by minimizing the handover signaling overhead. By reducing the number of intermediaries, our analytical model achieves 40% reduction in the signaling overhead compared to an SDN-MIH based handover management scheme.	centralized computing;high availability;network packet;next-generation network;overhead (computing);requirement;seamless3d;secure digital;software-defined networking	Rajesh Challa;Syed M. Raza;Sangyep Nam;Hyunseung Choo	2016		10.1145/2857546.2857652	enterprise private network;real-time computing;computer science;computer security;computer network	Networks	-14.37568601071589	86.19011160125017	52970
545615463633e670474b0121d7a39c5843349f67	assume-guarantee reasoning with local specifications	network congestion	We investigate assume-guarantee reasoning for global specifications consisting of conjunctions of local specifications. We present a sound and complete assume-guarantee rule that permits reasoning about individual modules for local specifications and draws conclusions on global specifications. We illustrate our approach with an example from the field of network congestion control, where different agents are responsible for controlling packet flow across a shared infrastructure. In this context, we derive an assume-guarantee rule for system stability, and show that this rule is valuable to reason about any number of agents, any initial flow configuration, and any topology of bounded degree.	control system;global optimization;interaction;model checking;neighbourhood (graph theory);network congestion;network packet;traffic flow (computer networking)	Alessio Lomuscio;Ben Strulo;Nigel G. Walker;Peng Wu	2010	Int. J. Found. Comput. Sci.	10.1007/978-3-642-16901-4_15	real-time computing;simulation;computer science;network congestion;algorithm	AI	-9.29575242749304	80.21063492501993	53081
5327202693e76fb1a49e8172137553da582565b1	resolution of uniform resource identifiers using the domain name system	uniform resource identifier;domain name system	"""Status of this Memo =================== This memo defines an Experimental Protocol for the Internet community. This memo does not specify an Internet standard of any kind. Discussion and suggestions for improvement are requested. Distribution of this memo is unlimited. Abstract: ========= Uniform Resource Locators (URLs) are the foundation of the World Wide Web, and are a vital Internet technology. However, they have proven to be brittle in practice. The basic problem is that URLs typically identify a particular path to a file on a particular host. There is no graceful way of changing the path or host once the URL has been assigned. Neither is there a graceful way of replicating the resource located by the URL to achieve better network utilization and/or fault tolerance. Uniform Resource Names (URNs) have been hypothesized as a adjunct to URLs that would overcome such problems. URNs and URLs are both instances of a broader class of identifiers known as Uniform Resource Identifiers (URIs). The requirements document for URN resolution systems[15] defines the concept of a """"resolver discovery service"""". This document describes the first, experimental, RDS. It is implemented by a new DNS Resource Record, NAPTR (Naming Authority PoinTeR), that provides rules for mapping parts of URIs to domain names. By changing the mapping rules, we can change the host that is contacted to resolve a URI. This will allow a more graceful handling of URLs over long time periods, and forms the foundation for a new proposal for Uniform Resource Names. In addition to locating resolvers, the NAPTR provides for other naming systems to be grandfathered into the URN world, provides independence between the name assignment system and the resolution protocol system, and allows multiple services (Name to Location, Name to Description, Name to Resource, ...) to be offered. In conjunction with the SRV RR, the NAPTR record allows those services to be replicated for the purposes of fault tolerance and load balancing."""	fault tolerance;internet;load balancing (computing);radio data system;rapid refresh;requirement;resolver one;uniform resource identifier;world wide web	Ron Daniel;Michael Mealling	1997	RFC	10.17487/RFC2168	naptr record;cname record;fully qualified domain name;computer science;data mining;database;dns zone;name server;world wide web;domain name system	Networks	-26.550256345456724	86.53089135798466	53155
915bb58ab0219f68eea04f1dec70dafb0923389f	optimal control of discrete event systems with weakly hard real-time constraints	real time constraints;constraint optimization;cost function;nonlinear programming;efficient algorithm;real time;optimal control computational complexity constraint theory discrete event systems;low complexity;satisfiability;optimization discrete event systems real time constraints;optimal control;optimization problem;discrete event system;performance improvement;optimal control algorithm complexity cost function task processing times nonpreemptive task aperiodic tasks optimization problem weakly hard real time constraints discrete event systems;discrete event systems;optimization;nickel real time systems optimal control cost function programming discrete event systems;structural properties;hard real time	We consider Discrete Event Systems (DES) that can dynamically allocate resources in order to process tasks with real-time constraints. In the case of “weakly hard” constraints, a fraction of tasks is allowed to violate them, as long as m out of any k consecutive tasks meet their respective constraints. This is a generalization of a system with purely hard real-time constraints where m = k = 1. For non-preemptive and aperiodic tasks, we formulate an optimization problem where task processing times are controlled so as to minimize a cost function while guaranteeing that a “weakly hard” criterion is satisfied. We establish a number of structural properties of the solution to this problem which lead to an efficient algorithm that does not require any explicit nonlinear programming problem solver. The low complexity of this algorithm makes it suitable for on-line applications. Simulation examples illustrate the performance improvements in such optimally controlled systems compared to ad hoc schemes.	algorithm;hoc (programming language);loss function;mathematical optimization;nonlinear programming;nonlinear system;online and offline;optimal control;optimization problem;real-time clock;real-time computing;simulation;solver	Shixin Zhuang;Christos G. Cassandras	2007	2007 European Control Conference (ECC)	10.1007/s10626-008-0051-6	optimization problem;mathematical optimization;discrete mathematics;real-time computing;optimal control;nonlinear programming;computer science;mathematics;satisfiability	Embedded	-9.801855023445121	61.432594157877986	53171
d3ad3b16db5def38aabd699db8df05ebfb4e3bbd	a geometric approach for real-time monitoring of dynamic large scale graphs: as-level graphs illustrated		The monitoring of large dynamic networks is a major challenge for a wide range of application. The complexity stems from properties of the underlying graphs, in which slight local changes can lead to sizable variations of global properties, e.g., under certain conditions, a single link cut that may be overlooked during monitoring can result in splitting the graph into two disconnected components. Moreover, it is often difficult to determine whether a change will propagate globally or remain local. Traditional graph theory measure such as the centrality or the assortativity of the graph are not satisfying to characterize global properties of the graph. In this paper, we tackle the problem of real-time monitoring of dynamic large scale graphs by developing a geometric approach that leverages notions of geometric curvature and recent development in graph embeddings using Ollivier-Ricci curvature [47]. We illustrate the use of our method by considering the practical case of monitoring dynamic variations of global Internet using topology changes information provided by combining several BGP feeds. In particular, we use our method to detect major events and changes via the geometry of the embedding of the graph. We first adapt the Ricci curvature to characterize the AS level graph. The key idea is to detect changes in between consecutive snapshots and to separate events that result in considerable geometric alterations, from those that remain local. The variations of curvature are evaluated through a set of landmarks as reference points. We develop an anomaly tracking mechanism to detect large variations of curvature that translate into major variations in the geometry of the graph. These changes are then considered as major BGP level events. In a second stage, we describe a mechanism for identifying the network elements responsible for the set of coordinated changes and isolate their geometric implications. We evaluate this system in operational settings and show its performance in real-life scenarios.	anomaly detection;assortativity;border gateway protocol;centrality;graph theory;real life;real-time clock	Loqman Salamatian;Dali Kaafar;Kavé Salamatian	2018	CoRR		the internet;graph theory;computer science;curvature;distributed computing;centrality;embedding;graph;assortativity	Metrics	-10.781817545413693	77.75499985091912	53241
2cf108ce826f52747025007e3767c3420c6ada38	power budgeting for virtualized data centers	distributed application;data center;quality of service	Power costs are very significant for data centers. To maximally utilize the provisioned power capacity, data centers often employ over-subscription, that is, the sum of peak consumptions of individual servers may be greater than the provisioned capacity. Power budgeting methods are employed to ensure that actual consumption never exceeds capacity. However, current power budgeting methods enforce capacity limits in hardware and are not well suited for virtualized servers because the hardware is shared among multiple applications. We present a power budgeting system for virtualized infrastructures that enforces power limits on individual distributed applications. Our system enables multiple applications to share the same servers but operate with their individual quality of service guarantees. It responds to workload and power availability changes, by dynamically allocating appropriate amount of power to different applications and tiers within applications. The design is mindful of practical constraints such the data center’s limited visibility into hosted application performance. We evaluate the system using workloads derived from real world data center traces.	algorithm;data center;distributed computing;operating-system-level virtualization;provisioning;quality of service;server (computing);theory;tracing (software);uninterruptible power supply;virtual private server	Harold Lim;Aman Kansal;Jie Liu	2011			embedded system;data center;real-time computing;quality of service;computer science;operating system	Arch	-22.430238518347302	61.08317550310798	53263
aa760d8173451c9c75b4dbf0fd7a156f556547fd	an introduction to data capturing	wired lan;kernel;windows system;band pass filters;high speed networks;data capture;windows system wired lan wireless lan data capturing unix;wireless lan data handling unix;engines;local area networks switches kernel engines band pass filters ethernet networks hardware;network management;wireless lan;data handling;switches;ethernet networks;data capturing;unix;local area networks;intrusion detection system;hardware	Data capturing has been the foundation of many network critical application, such as intrusion detection system and network management application. This paper introduces how to implement data capturing in different network situations, including wired LAN and wireless LAN; introduces the data capturing engines in both Unix and Windows system and compares the differences between them, presents the critical techniques of data capturing used in high-speed network, introduces how to discover data capturing behavior in network and finally point out the trend of the future development.	automatic identification and data capture;bitstream;central processing unit;intrusion detection system;microsoft windows;network processor;unix	Liqiang Zhang;Huanguo Zhang	2008	2008 International Symposium on Electronic Commerce and Security	10.1109/ISECS.2008.152	local area network;intrusion detection system;network management;embedded system;kernel;real-time computing;network switch;computer science;operating system;group method of data handling;automatic identification and data capture;band-pass filter;network simulation;unix;computer security	Arch	-21.06150087905787	83.88012995300186	53300
0104cca931c3b250e8899822dcbfb88971ecbb52	interaction-aware video community-based content delivery in wireless mobile networks		The increase in the demand of content quality and the number of mobile users brings new challenges for the multimedia streaming services in wireless mobile networks. The virtual community technologies are promising by grouping the users with common characteristics to get the gains in the performance of resource lookup and system scalability. In this paper, we propose a novel interaction-aware video community-based content delivery (IVCCD) in wireless mobile networks. IVCCD collects and analyzes the interaction information between users to construct user interaction model and further capture the common characteristics in the request and delivery of video content. IVCCD employs a partition-based community discovery scheme to group the mobile users in terms of the common characteristics and uses a community member management mechanism and a resource sharing scheme to achieve low-cost community maintenance and high searching performance. Extensive tests show how IVCCD achieves much better performance results in comparison with other state-of-the-art solutions.		Lujie Zhong;Shijie Jia;Youzhong Ma;Yongxin Zhang	2016	Mobile Information Systems	10.1155/2016/4047213	mobile search;computer science;multimedia;internet privacy;world wide web;computer network	Mobile	-17.28960742042046	74.82758212473186	53306
4d8ab7bd5abb2a7e2700e61e55b09565a2ab6442	enabling service-centric networks for cloudlets using sdn		The current developments in smart devices, wearable gadgets and IoT (Internet-of-Things) are triggering a variety of novel use cases and services. Once the technology matures, a wide range of services is expected to be provided at the edge of the network in coordination with the cloud computing infrastructure. These services will be highly dynamic meaning that they can be served from edge computing facilities and from central cloud servers being transferred back and forth. Also, considering the mobility of the users and the varying demand, those services might need to be live migrated between nearby edge servers on-the-fly. This setup creates an environment that needs to be transparent to the end users. The current legacy networking paradigm, however, allow services to be reached by IP and port addresses, not by their content. Alternatively, in the service-centric approach the services themselves are handled independent of their location and the focus shifts to “what ” instead of “where ”. Due to the complexities involved, it is not a straightforward task to establish service-centricity at the edge scenarios. As a remedy, this paper proposes a service-centric approach at the edge servers using orchestration capabilities offered by the Software-Defined Networking (SDN) technology. To demonstrate how SDN can help to alleviate the problem, an emulation environment is used in which northbound applications are implemented in order to setup the service-centric structure. The effect of service-centric approach is shown with the load balancing experiments where the performance of the proposed system is evaluated for various use cases.	cloud computing;computation;dos;edge computing;emergence;emulator;experiment;focus group;future internet;internet protocol suite;load balancing (computing);programming paradigm;protocol stack;quality of service;requirement;smart device;software-defined networking;wearable computer	Ahmet Cihat Baktir;Atay Ozgovde;Cem Ersoy	2017	2017 IFIP/IEEE Symposium on Integrated Network and Service Management (IM)	10.23919/INM.2017.7987297	computer network;orchestration (computing);distributed computing;computer science;end user;cloudlet;software-defined networking;cloud computing;load balancing (computing);server;edge computing	Networks	-15.134452665321682	84.78621707496808	53379
6946fcfa3360bcbcdc837e068cafe46e8e2a4b99	the system parameter fusion principle and its application to monitoring an ultra-energy efficient house.	energy efficient	Abstract: Modern technology provides a great amount of information. But for computer monitoring systems, we need to reduce the number of variables to one or two parameters, which express the quality and/or security of the whole system. This paper presents a principle for synthesizing measurements of multiple system parameters into a single parameter and the different forms of its quality functions, and shows its application to an ultra-energy efficient house.	computer and network surveillance	Qiangguo Pu	2003			mathematical optimization	EDA	-32.055959999722695	65.22874914102667	53396
a5d4700b04976004541d03d5088562c9b31fe9a8	providing reliable fib update acknowledgments in sdn	reliability;openflow;communication systems;software defined networking;kommunikationssystem;datavetenskap datalogi;computer science	In this paper, we first show that transient, but grave problems such as violations of security policies can occur with real switches even when using consistent updates to Software Defined Networks. Next, we present techniques that are effective in ameliorating this problem. Our key insight is in creating a transparent layer that relies on control and data plane measurements to confirm rule updates only when the rule is visible in the data plane.	forwarding plane;network switch;software-defined networking	Maciej Kuzniar;Peter Peresíni;Dejan Kostic	2014		10.1145/2674005.2675006	openflow;real-time computing;computer science;operating system;reliability;distributed computing;software-defined networking;computer security;communications system;computer network	Networks	-15.639777821380234	81.86001708360446	53501
7504ecdcaf825950400a1d74c1175f5068eba22f	non-sticky fingers: policy-driven self-optimization for dhts	distributed hash table;long distance;cost efficiency	It is a common situation with distributed hash tables (DHT) that insertions and lookups frequently target only specific fractions of the entire value range. We present in this paper a self-optimization scheme for DHTs that optimizes the routing behavior in such situations. In our scheme, called Non-Sticky (NS) fingers, each node continuously measures the routing behavior and guides neighboring nodes to adjust their NS fingers (a subset of all the long distance links that the node establishes) accordingly in order to shortcut the most popular sections of routes. Our scheme enables self-optimization, which means that it adapts to the current system state and only operates when advantageous. It is also policy-driven, which means that the application can specify its policy on the tradeoff between performance and cost efficiency. We implemented the NSfingers scheme for an existing order-preserving DHT and report the evaluation results. Our simulation results show that in a realistic application scenario, NSfingers can halve the number of routing hops.	cost efficiency;distributed hash table;lookup table;mathematical optimization;node (computer science);planetlab;routing;simulation;sticky bit	Matti Siekkinen;Vera Goebel	2009		10.1007/978-3-642-10865-5_8	embedded system;real-time computing;computer science;chord;theoretical computer science;operating system;distributed computing;computer network;cost efficiency	Mobile	-11.231231130041554	75.19966327648186	53524
3291eb3fbccd992775bbf51773d4a46ebac23913	real-time scheduling in heterogeneous systems considering cache reload time using genetic algorithms	heterogeneous systems;multiprocessor systems;np hard problem;multiple objectives;hard real time system;real time scheduling;time use;genetic algorithm;real time application;hard real time;time constraint	Since optimal assignment of tasks in a multiprocessor system is, in almost all practical cases, an NP-hard problem, in recent years some algorithms based on genetic algorithms have been proposed. Some of these algorithms have considered real-time applications with multiple objectives, total tardiness, completion time, etc. Here, we propose a suboptimal static scheduler of nonpreemptable tasks in hard real-time heterogeneous multiprocessor systems considering time constraints and cache reload time. The approach makes use of genetic algorithm to minimize total completion time and number of processors used, simultaneously. One important issue which makes this research different from previous ones is cache reload time. The method is implemented and the results are compared against a similar method.	cpu cache;central processing unit;genetic algorithm;heuristic (computer science);multiprocessing;np-hardness;particle swarm optimization;real-time clock;real-time computing;real-time transcription;scheduling (computing);topological sorting	Mohammad Reza Miryani;Mahmoud Naghibzadeh	2009		10.1007/978-3-642-04284-3_11	parallel computing;real-time computing;computer science;distributed computing;multiprocessor scheduling	Embedded	-13.612024059673688	61.49592486041674	53603
32a77545a38603616a5839fc44097fbf6375bb03	performance evaluation of two-priority network schema for single-buffered delta networks	qos single buffered delta network two priority network schema packet switching conflict resolution network performance evaluation multistage interconnection network;network design;performance evaluation;multistage interconnection networks;network performance;multistage interconnection network;packet switched;packet switching;two priority network schema;qos;single buffered delta network;network performance evaluation;quality of service multistage interconnection networks packet switching performance evaluation;quality of service;conflict resolution;switches traffic control communication switching packet switching fabrics telecommunication traffic multiprocessor interconnection networks multiprocessing systems queueing analysis petri nets	In this paper a novel two-priority network schema is presented, and exemplified through its application on single- buffered Delta Networks in packet switching environments. Network operations considered include conflict resolution and communication strategies. The proposed scheme is evaluated and compared against the single-priority scheme. Performance evaluation was conducted through simulation, due to the complexity of the model, and uniform traffic conditions were considered. Metrics were gathered for the two most important network performance factors, namely packet throughput and the mean time a packet needs to traverse the network. The model can also be uniformly applied to several representative networks providing a basis for fair comparison and the necessary data for network designers to select optimal values for network operation parameters.	apollonian network;network packet;network performance;packet switching;performance evaluation;resolution (logic);simulation;traverse;throughput	Dimitris C. Vasiliadis;George E. Rizos;Costas Vassilakis;Euripidis Glavas	2007	2007 IEEE 18th International Symposium on Personal, Indoor and Mobile Radio Communications	10.1109/PIMRC.2007.4394153	traffic generation model;network traffic control;real-time computing;network architecture;cognitive network;packet analyzer;quality of service;network management station;computer science;processing delay;conflict resolution;network scheduler;rate limiting;network simulation;distributed computing;computer network	Mobile	-5.927021623702871	86.6689440245439	53613
205138c158f613c05b57861d89568b513e3bf48e	dynamic replica placement and traffic redirection in content delivery networks	dynamic replica placement;content delivery networks;satisfiability;simulation experiment;content access;settore ing inf 05 sistemi di elaborazione delle informazioni;content delivery network;user requests redirection	This paper jointly addresses dynamic replica placement and traffic redirection to the best replica in Content Delivery Networks (CDNs). Our solution is fully distributed and localized and trade-offs the costs paid by the CDN provider (e.g., the number of allocated replicas, frequency of replicas additions and removals) with the quality of the content access service as perceived by the final user. Our simulations experiments show that the proposed scheme results into a number of replicas which is only slightly higher than the minimum required to be able to satisfy all users requests, thus keeping the replicas at a good level of utilization.	content delivery network;experiment;internationalization and localization;simulation	Claudio Vicari;Chiara Petrioli;Francesco Lo Presti	2007	SIGMETRICS Performance Evaluation Review	10.1145/1328690.1328719	real-time computing;computer science;world wide web;computer network;satisfiability	Mobile	-16.42302554054434	73.83273451996689	53640
f91bca74c55ef1beba46b22280435523dada6cfc	strategies for assigning virtual geometric node coordinates in peer-to-peer overlays	multicast peer to peer network coordinates;measurement;peer to peer network;p2p overlay virtual geometric node coordinates peer to peer overlays decentralized network round trip time euclidean distance linfinity norm;virtual reality;p2p;euclidean distance;round trip time;multicast tree;computer architecture;servers;internet;bandwidth;network coordinates;ip networks;peer to peer computing;peer to peer;virtual reality peer to peer computing;peer to peer computing computer architecture bandwidth servers measurement internet ip networks;multicast	In this paper we propose new strategies for computing virtual geometric node coordinates in peer-to-peer overlays. The main goal is to obtain a decentralized network where each peer has a set of (multidimensional) coordinates and the distance between two peers is proportional to the round-trip time (RTT) between the peers. We consider methods based on the Euclidean distance and the Linfinity norm. We apply our techniques to a multicast tree P2P overlay that we developed.	euclidean distance;multicast;peer-to-peer;social protection;t-norm;testbed	Ana-Delia Sambotin;Mugurel Ionut Andreica;Eleonora Mocanu	2011	2011 International Conference on P2P, Parallel, Grid, Cloud and Internet Computing	10.1109/3PGCIC.2011.46	computer science;distributed computing;world wide web;computer network	HPC	-11.591145091052441	76.80203550086088	53808
ffa3b9c42c410da0339c5f1fc3ea988e5e477cac	evolutionary design of fast high-quality hash functions for network applications	linear genetic programming;network applications;hash function	High speed networks operating at 100 Gbps pose many challenges for hardware and software involved in the packet processing. As the time to process one packet is very short the corresponding operations have to be optimized in terms of the execution time. One of them is non-cryptographic hashing implemented in order to accelerate traffic flow identification. In this paper, a method based on linear genetic programming is presented, which is capable of evolving high-quality hash functions primarily optimized for speed. Evolved hash functions are compared with conventional hash functions in terms of accuracy and execution time using real network data.	cryptographic hash function;data rate units;linear genetic programming;network packet;run time (program lifecycle phase)	David Grochol;Lukás Sekanina	2016		10.1145/2908812.2908825	security of cryptographic hash functions;hash table;double hashing;real-time computing;hash function;linear hashing;perfect hash function;dynamic perfect hashing;computer science;theoretical computer science;k-independent hashing;distributed computing;rolling hash;cryptographic hash function;swifft;hash tree	Networks	-6.3394314289550495	66.52798472799789	53879
35c77e4fdfb26ce31ad4a33962f62d1964230d8f	uploading deferrable big data to the cloud by improved dynamic self-adaption algorithm	heuristic algorithms cloud computing bandwidth industries distributed databases resource management schedules;resource allocation big data cloud computing parallel processing;improved dynamic self adaption algorithm roa idsa performance randomized online algorithm mapreduce framework deferral big data uploading cloud computing platform cloud data center cost configurable computing resources on demand network access;improved dynamic self adaption algorithm cloud computing bandwidth mapreduce;bandwidth;mapreduce;improved dynamic self adaption algorithm;cloud computing	Cloud computing is a pattern of processing the big data and provides the convenient, on-demand network access to a shared pool of configurable computing resources. Cloud data center's cost is becoming the hot topic in recent years. This paper studies how to minimize the bandwidth cost for uploading deferral big data to a cloud computing platform, based on the MapReduce Framework. We study the deficiency of randomized online algorithm and Dynamic Self-adaption Algorithm, and we propose the improved algorithm to minimize the bandwidth cost based on DSA, and the results demonstrate that the IDSA' performance is better than the ROA and DSA.	access network;angular defect;big data;cloud computing;data center;mapreduce;online algorithm;randomized algorithm;reconfigurable computing;resource-oriented architecture;upload	Baojiang Cui;Peilin Shi;Jun Yang;Yongle Hao	2015	2015 10th International Conference on P2P, Parallel, Grid, Cloud and Internet Computing (3PGCIC)	10.1109/3PGCIC.2015.39	real-time computing;cloud computing;computer science;database;distributed computing;utility computing	DB	-18.863237677163205	63.561049442239444	53882
125986cfeb092fd35f3b25f52e17ed868f5446b7	study on replica strategy based on access pattern mining in smart city cloud storage system	access pattern mining;saptio-temporal data;dynamical replica;prediction;smart city	 The replica strategy in traditional distributed file system, which creates a copy mainly from the perspective of internal resources while changes in external demand are ignored. However, this strategy is not suitable for deployment in a service-based, resource-rich internal storage “smart city” in cloud storage center. This paper proposes a replica strategy, which combines data security (the minimum amount of copies) together with service needs (best copy volume). The strategy predicts file popularity based on access pattern mining algorithms. What’s more, the number of copies of the cloud adjusts itself dynamically according to the popularity of file and system resources. Mining algorithm is based on the analysis of the characteristics of spatio-temporal data in smart cities. The algorithm first maps the historical user access request to the spatio-temporal attribute domain. Then according to the geographical area grid and association rules, the correlation analysis and evolution rule identification of access requests are carried out in the domain of spatio-temporal attributes. Finally dig out the user access mode and predict the user’s access request, calculate the file popularity according to the request. The simulation results show that the popularity of the file calculated by the access pattern mining algorithm in this paper is simple and efficient, and the prediction accuracy of the popularity can reach 84%. The dynamic replica mechanism based on popularity has a significant advantage in coping with sudden large-scale concurrent accesses. Meanwhile, compared with the conventional dynamic replicas based on access frequency, the proposed strategy consumes less storage resources.	cloud storage;data mining;smart city	Xiaojun Liu;Chad W Drake	2018	Wireless Personal Communications	10.1007/s11277-018-5458-2	distributed file system;computer science;real-time computing;replica;smart city;cloud storage;data security;cloud computing;attribute domain;popularity	Mobile	-29.379947541191978	66.3916562508571	53912
471f6500e59483b7a34d073fc5004ed6d01a4239	inferring relative popularity of internet applications by actively querying dns caches	domain name system;data gathering;internet service provider;active content measurement;resource record;internet application;network game;time to live;domain name server;grid computing	"""In this work, we propose a novel methodology that can be used to assess the relative popularity for any Internet application based on the data servers it uses. The basic idea is to infer popularity of data servers by periodically """"poking"""" at local Domain Name servers (LDNSs) that service Domain Name System requests from a set of users running Internet applications and determining if LDNSs have cached resource records for the data servers. This approach allows us to measure the relative percentage of pokes that result in a cache hit as a coarse measure of the relative popularity of a particular data server among the users of a given LDNS. In addition, the time-to-live (TTL) of cached DNS resource records can be used to measure the gaps in time when a resource record for a data server is not cached. The cache gaps can be used to infer request interarrivals for more popular data servers.The methodology can be applied to any Internet application that uses distinguished server names and performs DNS lookups on these names as part of application use. The methodology can be used to collect usage information from any LDNS that accepts DNS queries. As example applications of the methodology, we evaluate the relative popularity of selected Web sites and the relative popularity of different Web servers serving content at a given Web site. We also apply the methodology to servers providing multimedia content, data servers for grid computing, and network game servers. We use data gathered from LDNSs of commercial and educational sites as well as Internet Service Providers serving both commercial and home customers."""	cache (computing);game server;grid computing;rich internet application;server (computing);time to live;transistor–transistor logic;web server	Craig E. Wills;Mikhail Mikhailov;Hao Shang	2003		10.1145/948205.948216	dns hijacking;root name server;round-robin dns;computer science;operating system;database;internet privacy;name server;world wide web;computer security;nsupdate;domain name system;server;computer network	Metrics	-20.86036818149106	72.38590229007218	53953
4950e584d2fd0f228893f04ce223cb62b1e35c71	energy-aware grid scheduling of independent tasks and highly distributed data	minimisation;power supplies;power aware computing energy consumption genetic algorithms grid computing minimisation;green products;processor scheduling;genetic algorithm energy utilization green computing data grid scheduling data center;power aware computing;data center;computational modeling;energy consumption;scheduling;distributed databases;energy utilization;genetic algorithm;genetic algorithms;dynamic mode energy aware grid scheduling independent task distributed data data aware scheduling large scale computing system distributed server energy efficiency independent batch scheduling biobjective minimization problem energy consumption dynamic voltage and frequency scaling dvfs model cumulative power energy data transmission logical network topology sleep link based adaptive link rate alr on off technique energy aware grid scheduler genetic algorithm replacement mechanism static mode;grid computing;processor scheduling computational modeling dynamic scheduling distributed databases data models green products power supplies;data grid;dynamic scheduling;green computing;data models	Data-aware scheduling in today's large-scale computing systems has become a major complex research issue. This problem becomes even more challenging when data is stored and accessed from many highly distributed servers and energy-efficiency is treated as a main scheduling objective. In this paper we approach the independent batch scheduling in grid environment as a bi-objective minimization problem with make span and energy consumption as the scheduling criteria. We used the Dynamic Voltage and Frequency Scaling (DVFS) model for reducing the cumulative power energy utilized by the system resources for tasks executions. We developed for data transmission a general logical network topology and policy based on the sleep link-based Adaptive Link Rate (ALR) on/off technique. Two developed energy-aware grid schedulers are based on genetic algorithms (GAs) frameworks with elitist and struggle replacement mechanisms and were empirically evaluated for four grid size scenarios in static and dynamic modes. The simulation results show that the proposed schedulers perform to a level that is sufficient to maintain the desired quality levels.	automated lip reading;dynamic frequency scaling;dynamic voltage scaling;genetic algorithm;job scheduler;network topology;scheduling (computing);simulation	Joanna Kolodziej;Magdalena Szmajduch;Tahir Maqsood;Sajjad Ahmad Madani;Nasro Min-Allah;Samee Ullah Khan	2013	2013 11th International Conference on Frontiers of Information Technology	10.1109/FIT.2013.46	fair-share scheduling;parallel computing;real-time computing;dynamic priority scheduling;computer science;rate-monotonic scheduling;two-level scheduling;distributed computing;round-robin scheduling	HPC	-18.15175451659394	61.433832237135185	54110
020bcb6961ef9e27074a12416d77ccc61ebd5484	a qos-aware service discovery method for elastic cloud computing in an unstructured peer-to-peer network	journal article;qos;p2p network;service registering;service discovery	Traditionally, service discovery is often promoted by the centralized approach that typically suffers from single point of failure, poor reliability, poor scalability, to name a few. In view of this challenge, a QoS-aware service discovery method is investigated for elastic cloud computing in an unstructured peer-to-peer network in this paper. Concretely speaking, the method is deployed by two phases, that is, service registering phase and service discovery phase. More specifically, for a peer node engaged in the unstructured peer-to-peer network, it firstly registers its functional and nonfunctional information to its neighbors in a flooding way. With the multiple registered information, the QoS-aware service discovery is promoted in a probabilistic flooding way according to the network traffic. At last, extensive simulations are conducted to evaluate the feasibility of our method. Copyright © 2013 John Wiley & Sons, Ltd.	cloud computing;peer-to-peer;quality of service;service discovery	Wenmin Lin;Wan-Chun Dou;Zhanyang Xu;Jinjun Chen	2013	Concurrency and Computation: Practice and Experience	10.1002/cpe.2993	quality of service;computer science;operating system;database;service discovery;world wide web;computer network	HPC	-13.213467888388747	75.80403363135976	54193
8747f55521eb6b8401f0bf5b4b986aef09fef4bb	a simulation tool for tuning ip network parameters based on fluid-flow models and parallel genetic algorithms	parallel genetic algorithm;telecommunication network planning ip networks genetic algorithms internet quality of service;graphical interface tuning ip network parameters fluid flow models parallel genetic algorithms ip network design ip network planning internet quality of service qos;telecommunication network planning;graphical interface;qos guarantee;fluid flow;network simulator;internet;parameter tuning;genetic algorithm;ip networks;genetic algorithms;parallel implementation;ip networks genetic algorithms quality of service computational modeling analytical models web and internet services power system modeling algorithm design and analysis protocols optimization methods;quality of service;simulation tool	In the current Internet scenario increasing interest is being shown in quality of service (QoS) issues, so simulation and parameter tuning are becoming very hot topics. In this paper we present a user-friendly, easily expandable and time-saving tool, which is able to perform network simulation through fluid-flow models and parameter tuning with parallel genetic algorithms. All the network elements involved (TCP sources, links, routers and so on) are modeled with the fluid-flow approach as independent systems: their outputs only depend on their inputs and internal state variables. Network elements can be connected to each other by a powerful graphical interface. Subsequently the user can select network parameters to be optimized in order to achieve prearranged QoS guarantees. During this phase the tool adopts a parallel implementation of a genetic algorithm (GA) which reduces the execution time required for optimization. A case study is also presented.	genetic algorithm;graphical user interface;mathematical optimization;network address translation;network planning and design;quality of service;router (computing);run time (program lifecycle phase);simulation;solver;usability	Mario Barbera;Andrea G. Busà;Alessandro G. Di Nuovo;Alfio Lombardo;Giovanni Schembra	2005	GLOBECOM '05. IEEE Global Telecommunications Conference, 2005.	10.1109/GLOCOM.2005.1577808	genetic algorithm;computer science;theoretical computer science;distributed computing;computer network;fluid dynamics	HPC	-13.187486902231509	79.33959477130637	54202
0f0bd27ac72b39489f1312bc775d1d786220dedf	traffic engineering from a fiber to service area access network	access network;traffic engineered	The objective of this paper is to characterize and model the generated traffic in a real fiber network for voice and data transmission. The analyzed data has been provided by the cable operator Telecable Asturias, S.A.U., with more than 37,000 subscribers to the broadband access. A tool to monitor and analyze the traffic has been designed, and a model of the traffic generated in this fiber broadband access network is implemented, representing the usage that network subscribers make of the system. The traffic in each controller is obtained from the aggregation of the separated traffic streams originated by the user's applications. The most significant applications (ftp, http, p2p services, ...) have been processed. We demonstrate that this traffic is statistically self-similar, such behavior having serious implications for the design, control and analysis of high-speed networks. The results in these processes have been validated using the real data provided by the fiber network operator.	access network;data recovery;fiber to the x;hypertext transfer protocol;internet access;peer-to-peer;self-similarity	Roberto García;Isabel Rodríguez;Víctor G. García;Xabiel G. Pañeda;David Melendi	2005	31st EUROMICRO Conference on Software Engineering and Advanced Applications	10.1109/EURMIC.2005.62	teletraffic engineering;network planning and design;edge device;network traffic control;intelligent computer network;wireless wan;construction engineering;transport engineering;network access control;traffic shaping;internet traffic engineering;computer network;network access point;access network	Networks	-19.00400331556321	86.37180292413949	54263
01304be5e2c85db42e75fd8a38e5f9641b63e94a	a survey of incentive techniques for mobile crowd sensing	cs incentive mechanisms mobile crowd sensing participatory sensing;temperature sensors;crowd sensing incentives games reverse auction;internet of things;heuristic algorithms;taxonomy;heuristic algorithms taxonomy recruitment internet of things temperature sensors incentive schemes;incentive schemes;mobile computing;recruitment	Crowd sensing (CS) is an approach to collecting many samples of a phenomena of interest by distributing the sampling across a large number of individuals. While any one individual may not provide sufficient samples, aggregating samples across many individuals provides high-quality, high-coverage measurements of the phenomena. Thus, for participatory sensing to be successful, one must motivate a large number of individuals to participate. In this work, we review a variety of incentive mechanisms that motivate people to contribute to a CS effort. We then establish a set of design constraints or minimum requirements that any incentive mechanism for CS must have. These design constrains are then used as metrics to evaluate those approaches and determine their advantages and disadvantages. We also contribute a taxonomy of CS incentive mechanisms and show how current systems fit within this taxonomy. We conclude with the identification of new types of incentive mechanisms that require further investigation.	participatory sensing;requirement;sampling (signal processing);taxonomy (general)	Luis G. Jaimes;Idalides J. Vergara-Laurens;Andrew Raij	2015	IEEE Internet of Things Journal	10.1109/JIOT.2015.2409151	simulation;human–computer interaction;computer science;operating system;mobile computing;computer security;internet of things;taxonomy	HCI	-27.68484915056094	71.66358935671127	54281
11fe4b2b97eb391974586e70aabcdee5856745b8	time-domain analysis of web cache filter effects	traffic simulation;web traffic simulation;workload and traffic characterization;workload characterization;internet and www technology;traffic model;time domain analysis;traffic characterization;simulation experiment;web proxy caching;gamma distribution;hurst parameter;web caching;web proxy;trace driven simulation	This paper uses trace-driven simulation to study the traffic arrival process for Web workloads both before and after a Web proxy cache. In particular, the simulation experiments quantify the filter effects of a Web cache on the request arrival process. Both empirical and synthetic Web proxy workloads are used in the study. The simulation results show that (as expected) a Web cache reduces both the mean and the peak arrival rate for Web traffic workloads. However, the presence of the cache has less effect on the variability of the workload, and no impact on the degree of self-similarity in a workload. Finally, we find that a Gamma distribution provides a flexible and robust means of characterizing the request arrival count distribution, both before and after a Web cache, though the parameters for the Gamma distribution depend upon the input Web workload characteristics and the cache parameters used. This model can be used to estimate traffic characteristics in distributed or hierarchical Web caching architectures.	dhrystone;domain analysis;downstream (software development);experiment;heart rate variability;network traffic control;proxy server;quantum superposition;queueing theory;self-similarity;simulation;web cache;web traffic;zipf's law	Guangwei Bai;Carey L. Williamson	2004	Perform. Eval.	10.1016/j.peva.2004.07.009	gamma distribution;real-time computing;simulation;cache;computer science;mathematics;hurst exponent;world wide web;statistics;computer network	Metrics	-12.056831794884564	66.98344596027582	54286
18dbc914e41ea2942f58575ca4bdde6f91fb750a	rejuvenation of the iec 61850 protocol stack for mms	protocols;iso standards;authentication;smart grids;servers;iec standards	One of the most important Smart Grid Control Protocols is MMS over IEC 61850, which is predicted a great future after its extension for usage over Wide Area Networks and its generalization for other Smart Grid and industrial applications. Nevertheless the protocol stack of IEC 61850, which is used for MMS, originated from the 80s of the last century, is outdated and overloaded. It contains a complete ISO/OSI protocol stack of all layers. Nowadays the requirements are different not only under application aspects but also under the aspect of critical infrastructures, which should be able also to communicate over networks with limited capacities. This paper proposes a new slimmed protocol stack for IEC 61850 including improved security services for application oriented security and against denial of service attacks. The proposal is compared with the existing solution, and results are given based on simulations showing the benefits of a rejuvenation cure of the protocol stack for MMS.	broadcast delay;denial-of-service attack;non-repudiation;osi model;protocol stack;requirement;simulation	Christoph Ruland;Namhi Kang;Jochen Sassmannshausen	2016	2016 IEEE International Conference on Smart Grid Communications (SmartGridComm)	10.1109/SmartGridComm.2016.7778831	embedded system;engineering;protocol stack;computer security;computer network	HPC	-23.799282550391638	85.10792013974647	54307
8bc4ea4757e0f708ebe64998f7b423f051327be6	sdn-based distributed mobility management for 5g		Distributed mobility management (DMM) is an attractive approach to address the mobile traffic explosion problem, and thus it is perceived as a promising technology for mobility management in 5G. In this paper, we propose a software-defined networking (SDN) approach for DMM (denoted by SDN-DMM). Unlike the existing approaches for DMM (i.e., network-based or terminal-based), SDN-DMM implements the location and handover management functions at the centralized SDN controller while the packet forwarding function is fully distributed at access routers. Therefore, SDN-DMM can achieve the packet forwarding path optimization and provide significant benefits in terms of network and traffic management.	centralized computing;digital molecular matter (dmm);mathematical optimization;network packet;software-defined networking;wrapper function	Haneul Ko;Insun Jang;Jaewook Lee;Sangheon Pack;Giwon Lee	2017	2017 IEEE International Conference on Consumer Electronics (ICCE)	10.1109/ICCE.2017.7889250	engineering;distributed computing;computer security;computer network	Embedded	-13.574404038097907	83.19942618720123	54321
791193e24bef2e20d32796740705d295eee8fad9	tinysip: providing seamless access to sensor-based services	passive data-gathering;data-related services;sensor nodes;seamless access;session initiation protocol;device interfaces;attribute-based addressing;gateway maps;gateway;20 micaz sensor nodes;telecommunication services;event-related information services;signalling protocols;event correlation services;remote messaging protocol;wireless mesh;communication abstraction;wireless sensor networks;collaborative network;application-level signaling mechanism;internetworking;in-network storage;tinysip;tinysip;sensor-based services	In this paper, we propose TinySIP as a communication abstraction for accessing sensor-based services. TinySIP is based on the session initiation protocol (SIP), which is a standard application-level signaling mechanism. Users on traditional networks remotely interact with a sensor network service by sending SIP messages. A gateway maps the SIP abstractions to the corresponding TinySIP abstractions and propagates the messages to the sensor nodes. We are currently planning on deploying the SIP-based solution that we propose on a research testbed to enable users on a wireless mesh to access the in-network storage and event correlation services offered by a sensor network consisting of 20 MicaZ sensor nodes	elsevier biobase;event correlation;geographic routing;ibm notes;internet protocol suite;lookup table;sensor;testbed;uniform resource identifier;wireless mesh network	Sudha Krishnamurthy	2006	2006 Third Annual International Conference on Mobile and Ubiquitous Systems: Networking & Services	10.1109/MOBIQW.2006.361779	embedded system;wireless sensor network;computer science;key distribution in wireless sensor networks;mobile wireless sensor network;world wide web;computer security;computer network;visual sensor network	Mobile	-20.45967927922177	81.73756755727977	54352
4719f60532c83985f10934779eceb16b31e3e3d0	a multi gigabit fpga-based 5-tuple classification system	classification algorithm;packet classification;bloom filter;next generation network;2sbfce;fpga;multilevel bloom filters;5 tuple classification system;multi dimensional;multilevel bloom filters fpga field programmable gate arrays 5 tuple classification system packet classification dual stage bloom filter classification engine 2sbfce;classification rules;information filters field programmable gate arrays;matched filters hardware next generation networking classification algorithms engines field programmable gate arrays costs quality of service communications society computer networks;classification system;field programmable gate arrays;information filters;off the shelf;hardware implementation;dual stage bloom filter classification engine	Packet classification is one of the most important enabling technologies for next generation network services. Even though many multi-dimensional classification algorithms have been proposed, most of them are precluded from commercial equipments due to their high memory requirements. In this paper, we present an efficient packet classification scheme, called dual stage bloom filter classification engine (2sBFCE). 2sBFC comprises of an innovative 5- field search scheme that decomposes multi-field classification rules into internal single-field rules which are combined using multi-level Bloom filters. The design of 2sBFCE is optimized for the common case based on analysis of real world classification databases. The hardware implementation of this scheme handles 4 K rules while supporting network streams at a rate of 2 Gbps even in the worst case, and more than 6 Gbps in the average case when implemented in an off-the-shelf FPGA.	4k resolution;algorithm;best, worst and average case;bloom filter;cellular automaton;comparison and contrast of classification schemes in linguistics and metadata;data rate units;database;field-programmable gate array;gigabit;high memory;network packet;next-generation network;requirement;static random-access memory	Antonis Nikitakis;Ioannis Papaefstathiou	2008	2008 IEEE International Conference on Communications	10.1109/ICC.2008.399	real-time computing;computer science;theoretical computer science;field-programmable gate array	Mobile	-6.735908906424536	67.38038017853407	54368
c73ab0a958aa8541df720985a428d3d66d1aefde	performance evaluation of software defined and cognitive wireless network based disaster resilient system	monitoring wireless networks satellites switches prototypes optical fiber subscriber loops;optical fiber subscriber loops;wireless networks;openflow;prototypes;disaster network;openflow prototype performance evaluation software defined network cognitive wireless network disaster resilient system information network east japan great earthquake wireless network technologies access network internet control link selection;cognitive network;monitoring;satellites;sdn disaster network openflow cognitive network;sdn;switches;software defined networking cognitive radio disasters	Through the information network recovery experience on the East Japan Great Earthquake on March 11, 2011, we learned that the combination of various existing wireless network technologies such as satellite IP network, 3G/LTE, Wi-Fi was useful in term of network connectivity. In this paper, by integrating those wireless networks into a cognitive wireless network, user can use this cognitive network as an access network to Internet by selecting the best performance network among the possible network links even though the serious disaster occurred and some of those network links were seriously damaged. We also introduce an Open Flow based access network to automatically control link and route selections within the cognitive wireless network to Internet by periodically monitoring and evaluating their network states. In order to verify the usefulness of our proposed system, a prototype of Open Flow based cognitive wireless network system is constructed by connecting the disaster areas in the East Japan Great Earthquake and its performance is evaluated.	access network;cognitive network;compaq lte;internet;performance evaluation;prototype	Goshi Sato;Noriki Uchida;Koji Hashimoto;Yoshitaka Shibata	2014	2014 Ninth International Conference on Broadband and Wireless Computing, Communication and Applications	10.1109/BWCCA.2014.135	openflow;network traffic control;intelligent computer network;wireless wan;network architecture;wireless sensor network;core network;cognitive network;heterogeneous network;network management station;telecommunications;bridging;network switch;dynamic circuit network;computer science;wireless network;network simulation;prototype;software-defined networking;municipal wireless network;wi-fi array;network access control;computer security;satellite;computer network;network access device	Mobile	-18.9451014628449	85.56540665329848	54391
e016be8b2f500284ed5ab13ac8e31d3e21e5090c	dynamic skyscraper broadcasts for video-on-demand	cable television;tiempo espera;gratte ciel;video a peticion;gollete estrangulamiento;layout problem;video a la demande;probleme agencement;radiodifusion;temps attente;upper bound;goulot etranglement;senal video;signal video;waiting time;video on demand;teledistribution;video signal;problema disposicion;broadcasting;bottleneck;teledistribucion;radiodiffusion	Skyscraper Broadcasting is a recently proposed statically scheduled broadcast technique for video-on-demand that addresses the network-I/O bottleneck to provide signiicantly superior performance over previous approaches. This paper deenes a scheme for dynamically scheduling the objects that are broadcast on the skyscraper channels. The dynamic broadcasting scheme is designed to provide all clients with the precise time at which their requested object will be broadcast, or an upper bound on that time if the delay is small. New segment size progressions are proposed that not only improve dynamic scheduling, but also simplify the server disk layout problem and allow clients with inexpensive (single-tuner, limited storage) settops to receive skyscraper broadcasts. Preliminary simulation results show that the proposed dynamic scheme (1) provides factors of two or more improvement in mean client waiting time, (2) outperforms the static system with respect to variability in client waiting time, and (3) delivers reasonable service to clients with inexpensive settops while providing clients that have more expensive settops with a high level of service that is relatively isolated from detrimental performance impact from the diskless clients.	diskless node;heart rate variability;high-level programming language;input/output;scheduling (computing);server (computing);simulation;skyscraper;tv tuner card	Derek L. Eager;Mary K. Vernon	1998		10.1007/3-540-49651-3_4	real-time computing;simulation;telecommunications;computer science;operating system;database;distributed computing;upper and lower bounds;television;law;computer security;broadcasting	Arch	-14.196266792158305	70.72012700506615	54425
290f00f23b2002f7df4153bbff84b84f7f433f1a	"""the """"last-copy"""" approach for distributed cache pruning in a cluster of http proxies"""	coupled cluster;algorithm performance;protocole transmission;red www;http;reseau web;cache memory;protocole http;antememoria;serveur reseau;protocolo transmision;antememoire;network servers;internet;resultado algoritmo;performance algorithme;world wide web;protocolo http;web caching;network congestion;transmission protocol	Web caching has been recognized as an important way to address three main problems in the Internet: network congestion, transmission cost and availability of web servers. As traffic increases, cache clustering becomes a natural way to increase scalability. This paper proposes an efficient scheme for increasing the cache hit-ratio in a looselycoupled cluster. In such a cluster, each proxy is able to serve every request independently of the other proxies. In order to increase the performance, the proxies may share cacheable content using some inter-cache communication protocol. The main contribution of the proposed scheme is an algorithm that increases the performance (hit-ratio) of any cache-pruning algorithm in such a cluster.	algorithm;byte;cpu cache;cache (computing);clara.io;cluster analysis;communications protocol;coupled cluster;distributed cache;hypertext transfer protocol;internet cache protocol;least frequently used;network congestion;proxy server;round-robin scheduling;scalability;scheduling (computing);simulation;web cache;web page;web server;wooster collective;world wide web	Reuven Cohen;Itai Dabran	2002		10.1007/3-540-47828-0_6	coupled cluster;hypertext transfer protocol;real-time computing;the internet;cpu cache;cache;computer science;cache invalidation;operating system;network congestion;cache algorithms;world wide web;computer network	Networks	-12.361019591004798	70.2467848535445	54440
a8838479095c9312324ebc77b5e61fbbc86a6617	a pseudo-random function (prf) for the kerberos v generic security service application program interface (gss-api) mechanism	pseudo random function;application program interface	"""Status of This Memo This document specifies an Internet standards track protocol for the Internet community, and requests discussion and suggestions for improvements. Please refer to the current edition of the """"Internet Official Protocol Standards"""" (STD 1) for the standardization state and status of this protocol. Distribution of this memo is unlimited. Abstract This document defines the Pseudo-Random Function (PRF) for the Kerberos V mechanism for the Generic Security Service Application Program Interface (GSS-API), based on the PRF defined for the Kerberos V cryptographic framework, for keying application protocols given an established Kerberos V GSS-API security context."""	application programming interface;cryptography;generic security services application program interface;internet;kerberos;key (cryptography);primitive recursive function;std bus	Shawn Emery;Nicolas Williams	2016	RFC	10.17487/RFC7802	computer science;database;generic security service algorithm for secret key transaction;world wide web;computer security	Security	-26.471553593601037	87.88595984729716	54563
15fb0019b7d8e73901d9efd2d6b1b2f7b42d2d4a	an on-line capacity-based admission control for real-time service processes	general;end to end real time constraints online capacity based admission control methodology real time service processes admission test periodic task schedulability fixed task capacity earliest deadline first scheduling edf scheduling aperiodic workloads mixed periodic workloads service oriented architecture;system architectures;schedulability analysis;real time admission control;special purpose and application based systems;service oriented architecture graph theory scheduling;service oriented architecture real time admission control schedulability analysis;integration and modeling;service oriented architecture;computer systems organization;real time and embedded systems	This paper presents an on-line admission control methodology for periodic and aperiodic service processes with end-to-end real-time constraints. Both types of service process requests dynamically join and leave a system at run time. During the admission test, the schedulability of a periodic task is determined by using its fixed task capacity. Aperiodic tasks are admitted using the available capacity after admitted periodic tasks. At run time, the earliest deadline first (EDF) scheduling is used to schedule the mixed periodic and aperiodic workloads. Simulation results show that the proposed algorithm may achieve up to 90% in system utilization, while incurring a low admission overhead for each service request.	algorithm;central processing unit;communications protocol;earliest deadline first scheduling;end-to-end principle;multi-core processor;online and offline;overhead (computing);real-time cmix;real-time clock;real-time transcription;run time (program lifecycle phase);scheduling (computing);simulation	Weiran Nie;Sen Zhou;Kwei-Jay Lin;Soo Dong Kim	2014	IEEE Transactions on Computers	10.1109/TC.2013.100	parallel computing;real-time computing;computer science;service-oriented architecture;distributed computing	Embedded	-10.25066665113106	60.71681123972485	54565
44c1943d48ab2d6b6acbb9a6d18a5828eab60b74	exploiting user metadata for energy-aware node allocation in a cloud storage system	energy efficiency;cloud systems;load balancing;metadata aware placement;cloud storage	Cloud computing has gained popularity in recent years delivering various services as cost-effective platforms. However, the increasing energy consumption needs to be addressed in order to preserve the cost-effectiveness of these systems. In this work, we target the storage infrastructure in a cloud system and introduce several energy efficient storage node allocation methods by exploiting the metadata heterogeneity of cloud users. Our proposed methods preserve load balance on demand and switch inactive nodes into low-energy modes to save energy. We provide a mathematical model to estimate the outcome of proposed methods and conduct theoretical and simulative analyses using real-world workloads. Mechanisms to reduce cloud storage energy consumption by around 60%.Dynamic and static storage allocation methods based on user metadata.A mathematical model to estimate energy consumption, latency and load balance.Theoretical and experimental evaluations of the proposed methods.	cloud storage;computer data storage	Cengiz Karakoyunlu;John A. Chandy	2016	J. Comput. Syst. Sci.	10.1016/j.jcss.2015.09.003	real-time computing;computer science;load balancing;cloud testing;distributed computing;efficient energy use;world wide web	Theory	-20.38985922175417	62.292990812510524	54585
2f41238409442773d04c9e5f6d247b5375ee427d	dynamic relationships and the persistence of pairings	third pairing mechanism;dynamic predictors;rank difference plots;stable static pairings;data visualisation mobile computing file organisation;static predictors;long term relationships;last successor predictor;data engineering;computer networks;wireless communication;dynamic relationships;data visualisation;visualization;strong relationships;visualization technique;dynamic predictors dynamic relationships pairing persistence local store mobile user potentially unbounded latencies fully automated file hoarding algorithm strong relationships long term relationships file access stream dynamic relationship predictors static first successor predictor last successor predictor rank difference plots visualization technique stable static pairings dynamic predictor frequently accessed files third pairing mechanism static predictors;dynamic relationship predictors;fully automated file hoarding algorithm;local store;delay bandwidth visualization throughput lifting equipment data engineering computer networks mobile computing wireless communication memory;pairing persistence;bandwidth;static first successor predictor;lifting equipment;file access stream;dynamic predictor;mobile computing;potentially unbounded latencies;frequently accessed files;memory;throughput;file organisation;mobile user	The ability to automatically hoard data on a computer's local store would go a long way towards freeing the mobile user from dependence on the network and potentially unbounded latencies. An important step in developing a fully automatedfile hoarding algorithm is the abili9 to automatically identib strong relationships between files. We present a mechanism for visualizing the degree of long-term relationships inherent in a file access stream. We do this by comparing the performance of static and dynamic relationship predictors. We demonstrate that even the simplest associations (from a static4rst-successor predictor) maintain relatively high accuracy over extended periods of time, closely tracking the performance of an equivalent dynamic (last-successor) predictoor: We then introduce rankdifference plots, a visualization technique which allows us to demonstrate how this behavior is caused by stable static pairings offiles that are lost by the adaptation of the dynamic predictor for a substantial subset of frequently accessed jiles. We conclude by demonstrating how a third pairing mechanism can make use of these observations to outperform both the dynamic and static predictors.	algorithm;data access;david jiles;entity–relationship model;hardware description language;hoard;kerrison predictor;persistence (computer science);recurrence plot;static variable;tom;tracing (software)	Ahmed M Amer;Darrell D. E. Long	2001		10.1109/CDCS.2001.918751	throughput;real-time computing;visualization;computer science;operating system;database;distributed computing;memory;mobile computing;computer security;bandwidth;wireless;computer network;lifting equipment	Arch	-16.111229585901413	69.46578545687561	54600
26477fea39bc3a365095ad0a3d1f6f6afe2521e3	on dynamically adapting registration areas to user mobility patterns in pcs networks	databases;user mobility;protocols;base stations;personal communication networks;pcs networks;location management;mobile networks;is 41;cellular networks;location update;personal communication networks management information systems protocols mobile radio;user mobility patterns;registration area;dynamically adapting registration areas;aggregates;location databases;mobile radio;communication requirements;management information systems;mobility pattern;intelligent networks;communication requirements dynamically adapting registration areas user mobility patterns pcs networks location management mobile networks protocols is 41 gsm location databases;computer science;gsm;intelligent networks personal communication networks costs gsm protocols databases base stations computer science aggregates cellular networks;dynamic adaptation;mobile network	Location management is an essential service in mobile networks. It provides mechanisms for recording and querying location of mobile units in the network. This is needed for establishing calls to mobile units. In PCS networks, location management protocols such as IS-41 and GSM use statically defined Registration Areas (RAs) with two-level hierarchy of location databases. In this paper, we propose an extension to PCS location management protocol by introducing the concept of dynamically overlapping registration areas. We show through simulation that by dynamically adapting the registration areas to aggregate mobility pattern of the mobile units, we can greatly reduce the number of location updates by mobiles. Further, the cost of adapting the registration areas is shown to be low in terms of memory and communication requirements.	aggregate data;database;personal computer;requirement;simulation;traffic collision avoidance system	Georgios Varsamopoulos;Sandeep K. S. Gupta	1999		10.1109/ICPPW.1999.800048	telecommunications;computer science;computer security;computer network	AI	-10.404594789064614	88.3418850070468	54613
db46217bf7dc1e33d7ff8efbd14c921d9e5d4963	dynamic control of flow reconfigurations in sdn	control policy sdn controllers qos data connections iterative routing solver;telecommunication network routing iterative methods quality of service software defined networking;routing computer architecture graphical user interfaces measurement real time systems heuristic algorithms quality of service	SDN controllers include mechanisms to globally reconfigure the network in order to quickly respond to a changing environment. However, the reconfiguration of the network affects the QoS of data connections. This demo presents an architecture for the SDN controller where a control policy operates on top of an iterative routing solver to dynamically decide whether to reconfigure the network. The control policy tracks the deviation of the network status from the optimal configuration and reconfigures the network only when there is a benefit. The demonstrator permits to compare the evolution of the network according to the decisions of different control policies. Furthermore, operators can simulates future scenarios to support strategic decisions aimed at improving the infrastructure.	iteration;quality of service;routing;software-defined networking;solver	Stefano Paris;Apostolos Destounis;Lorenzo Maggi;Georgios S. Paschos;Jeremie Leguay	2016	2016 IEEE Conference on Computer Communications Workshops (INFOCOM WKSHPS)	10.1109/INFCOMW.2016.7562169	policy-based routing;routing table;routing domain;routing;enhanced interior gateway routing protocol;static routing;adaptive quality of service multi-hop routing;real-time computing;computer science;dynamic source routing;multipath routing;distributed computing;routing protocol;link-state routing protocol;computer network	Networks	-12.351635102245186	82.77594533393888	54625
b328688f70a560e213225d40c5be749a5ab38e3f	assessment of spare reliability for multi-state computer networks within tolerable packet unreliability	spare reliability;multi state computer network mscn;transmission time;routing scheme;tolerable packet unreliability	From a quality of service viewpoint, the transmission packet unreliability and transmission time are both critical performance indicators in a computer system when assessing the Internet quality for supervisors and customers. A computer system is usually modelled as a network topology where each branch denotes a transmission medium and each vertex represents a station of servers. Almost every branch has multiple capacities/states due to failure, partial failure, maintenance, etc. This type of network is known as a multi-state computer network (MSCN). This paper proposes an efficient algorithm that computes the system reliability, i.e., the probability that a specified amount of data can be sent through k (k ≥ 2) disjoint minimal paths within both the tolerable packet unreliability and time threshold. Furthermore, two routing schemes are established in advance to indicate the main and spare minimal paths to increase the system reliability (referred to as spare reliability). Thus, the spare reliability can ...	network packet	Yi-Kuei Lin;Cheng-Fu Huang	2015	Int. J. Systems Science	10.1080/00207721.2013.807383	reliability engineering;transmission time;computer science;engineering;computer network	Theory	-6.1946677327421105	78.10035451802025	54632
33e8653bda9e006a9e9d668c05dcdcdd2bfeae0f	generation of fault-tolerant static scheduling for real-time distributed embedded systems with multi-point links	automatic control;automotive engineering;heart;fault tolerant;distributed embedded system;processor scheduling;fault tolerant systems real time systems embedded system distributed computing processor scheduling timing consumer electronics automatic control heart automotive engineering;real time;distributed computing;real time embedded system;consumer electronics;software implemented fault tolerance;embedded system;distributed scheduling;fault tolerant systems;component architecture;distributed architecture;real time systems;timing	We describea solution to automaticallyproducedistributed and fault-tolerant code for real-time distributed embeddedsystems.The failures supportedare processor failures,with fail-stopbehavior . Our solutionis graftedon the “Algorithm Architecture Adequation” method(AAA), usedto obtain automaticallydistributed code. The heart of AAA is a schedulingheuristic that producesautomatically a staticdistributedscheduleof a givenalgorithmonto a givendistributedarchitecture. We designa new heuristic in order to obtaina static,distributedandfault-tolerant schedule. The new heuristic schedules supplementary replicasfor each computationoperation of the algorithm to be distributed and the correspondingcommunications, where is thenumberof processorfailuresintendedto be supported. In the sametime, the heuristicstatically computesthe main replica after each failure, such that the executiontime is minimized. The analysisof this heuristic showsthat it givesbetter resultsfor distributed architecturesusingmulti-point, reliable links. Thissolutioncorrespondsto a software implementedfault-tolerance, by mean of software redundancyof algorithm’s operationsand timing redundancyof communications.	aaa (video game industry);algorithm;apple a5;compile time;compiler;embedded system;fault tolerance;heuristic;real-time clock;scheduling (computing)	Alain Girault;Christophe Lavarenne;Mihaela Sighireanu;Yves Sorel	2001	Proceedings 15th International Parallel and Distributed Processing Symposium. IPDPS 2001	10.1109/IPDPS.2001.925102	embedded system;distributed algorithm;fault tolerance;parallel computing;real-time computing;computer science;operating system;automatic control;distributed computing;heart	Embedded	-11.004643192238323	61.761407934691974	54711
93f189ab267622374a53ac488ecb95444fd8c82d	software-defined architectures and technologies for underwater wireless sensor networks: a survey		The ocean covers nearly two-thirds of the surface on the Earth, and there has been great interest in developing underwater wireless sensor networks (UWSNs) to help us explore the ocean realm. A great deal of efforts have been devoted to it, and significant progress has been made since the beginning of 2000s. However, most of the networks are isolatedly developed currently, inherently hardware-based and application-oriented with inflexible closed-form architectures, which are difficult to reconfigure, reprogram and evolve. They also lack the capability in sharing resources, and are far from service-oriented networks. These limitations impair their capacity for wide range of applications. To further propel the development of UWSNs, next-generation UWSNs have been proposed recently, which are robust, flexible, adaptive, programmable, support resource-sharing feature and are easy to manage and evolve. Moreover, a number of novel software-defined techniques and paradigms, such as software-defined radio, cognitive acoustic radio, network function virtualization, software-defined networking, Internet of Underwater Things, and sensor-cloud, have been emerging. These software-defined technologies have the capability of softwarizing network resources, and then redefining them to satisfy diverse application requirements, improve resource utilization efficiency and simplify network management. Consequently, these evolving technologies are envisioned as critical building blocks and major driving forces, which will transform conventional UWSNs toward software-based, programmable, user-customizable, and service-oriented next-generation UWSNs. In this paper, we provide a comprehensive review of existing works on implementing these techniques, and also present discussions for future research. We hope to inspire more active research on these areas and take a step further toward realizing next-generation UWSNs.	acoustic cryptanalysis;algorithm;architecture as topic;capsule endoscopy;definition;network function virtualization;propel;reprogram;requirement;service-oriented architecture;service-oriented device architecture;software-defined networking;transfer function	Hanjiang Luo;Kaishun Wu;Rukhsana Ruby;Yongquan Liang;Zhongwen Guo;Lionel M. Ni	2018	IEEE Communications Surveys & Tutorials	10.1109/COMST.2018.2842060	distributed computing;the internet;wireless sensor network;computer science;network management;underwater acoustic communication;next-generation network;resource (disambiguation);shared resource;software	Mobile	-14.576547610379581	87.11423115542951	54763
5aab4024a9f274734bb0969d0c681994b1ac03fc	shielding heterogeneous mpsocs from untrustworthy 3pips through security- driven task scheduling	fault tolerance fault tolerant systems complexity theory trojan horses size measurement discrete fourier transforms;system on chip integrated circuit design invasive software multiprocessing systems processor scheduling;processor scheduling;multi dimension optimization security hardware trojan heterogeneous mpsocs task scheduling;integrated circuit design;system on chip;invasive software;multiprocessing systems;security constraints shielding heterogeneous mpsoc untrustworthy 3pip security driven task scheduling outsourcing ic design ic fabrication flow multiprocessor system on chip platforms mpsoc platforms third party intellectual property core 3pip cores design stage 3pip components malicious modifications trojan toleration mpsoc design process security driven diversity constraints scheduling process security constrained mpsoc task scheduling multidimensional optimization problem	Multiprocessor system-on-chip (MPSoC) platforms face some of the most demanding security concerns, as they process, store, and communicate sensitive information using third-party intellectual property (3PIP) cores. The complexity of MPSoC makes it expensive and time consuming to fully analyze and test during the design stage. This has given rise to the trend of outsourcing design and fabrication of 3PIP components, that may not be trustworthy. To protect MPSoCs against malicious modifications, we impose a set of security-driven diversity constraints into the task scheduling step of the MPSoC design process, enabling the system to detect the presence of malicious modifications or to mute their effects during application execution. We pose the security-constrained MPSoC task scheduling as a multidimensional optimization problem, and propose a set of heuristics to ensure that the introduced security constraints can be fulfilled with a minimum impact on the other design goals such as performance and hardware. Experimental results show that without any extra cores, security constraints can be fulfilled within four vendors and 81% overhead in schedule length.	heuristic (computer science);information sensitivity;mpsoc;malware;mathematical optimization;multiprocessing;mute;optimization problem;outsourcing;overhead (computing);scheduling (computing)	Chen Liu;Jeyavijayan Rajendran;Chengmo Yang;Ramesh Karri	2013	IEEE Transactions on Emerging Topics in Computing	10.1109/DFT.2013.6653590	system on a chip;embedded system;electronic engineering;parallel computing;real-time computing;computer science;engineering;operating system;distributed computing;integrated circuit design	EDA	-4.598322766436769	61.162683285629164	54839
39b4264e37887dce087ec2fe4a0ae00ce3d36fc5	a small world overlay network for resource discovery	parallelisme;virtual network;reseau pair;resource discovery;localite;xml language;resource management;periodic structure;locality;estructura periodica;small world;gestion recursos;igual a igual p2p;parallelism;paralelismo;structure periodique;overlay network;autoorganizacion;gestion ressources;self organization;peer to peer;langage xml;lenguaje xml;autoorganisation;red virtual;reseau virtuel	Interest is rising in genuinely distributed (’peer-to-peer’) resource discovery systems, which all provide mechanisms for self-organization of their resource providers and requesters into an overlay network. This paper proposes such a system that uses XML description files to construct overlay networks that exhibit small world properties (i.e., a small diameter and a regular structure) and in which similar resources are grouped together. Resource users can then be linked directly to the regions with the resources of their interest, which allows exploitation of group and time locality. Simulations results validate these concepts.	algorithm;computer simulation;locality of reference;national fund for scientific research;overlay network;scalability;self-organization;xml	Koen Vanthournout;Geert Deconinck;Ronnie Belmans	2004		10.1007/978-3-540-27866-5_144	xml;self-organization;overlay network;computer science;artificial intelligence;resource management;database;distributed computing;world wide web	HPC	-10.535797256820178	69.87574913647362	54853
cf8da4fb6e11dd0566e41d671840a80926261d29	content-centric networking management based on software defined networks: survey		Content-centric networks (CCNs) have received a lot of interest as one of the major innovative future Internet paradigms. The CCN key feature is built around the named content which can be requested, replayed, routed by name, and stored through in-network caching. Software defined networking (SDN) represents a new concept that can leverage the research and innovation enabling migration to future Internet. This stream of thought can be explored through certain research projects. In this survey, we present the basic concept of each paradigm. We introduce a thorough description of CCN mechanisms as well as their related studies. Therefore, we highlight the benefit of combining CCN networks with SDN and OpenFlow. Then, we analyze some of the most prominent approaches combining the CCN and the OpenFlow.	cache (computing);cyclomatic complexity;future internet;openflow;programming paradigm;routing;software-defined networking	Rihab Jmal;Lamia Chaari Fourati	2017	IEEE Transactions on Network and Service Management	10.1109/TNSM.2017.2758681	the internet;openflow;computer network;network architecture;software-defined networking;distributed computing;content centric networking;computer science;software as a service	Security	-15.364654521961668	83.85954910865468	54935
6bf61ce3bfcbbd5411376d9b8c8abcbca19189a1	interface to network security functions for cloud-based security services		Network functions virtualization and cloudbased security services will become increasingly common in enterprise network systems to reduce the system operation costs and take advantage of the diverse network security functions (NSFs) developed by multiple vendors. In such a network environment, standardizing the interfaces to the NSFs of different vendors is essential to simplify the management of these heterogeneous NSFs. In addition, software-defined networking can be imposed to optimize the security service process in such cloud-based service environments by enforcing some types of packet filtering rules at the SDN switches, instead of NSFs possibly placed in remote clouds. The Interface to Network Security Functions (I2NSF) Working Group, which is part of the Internet Engineering Task Force, is currently developing a set of standard interfaces to such heterogeneous NSFs. In this article, we present the design and development of an I2NSF architecture and propose improving its efficiency by integrating it with SDN. In our work, we implement the SDN-integrated I2NSF architecture and its security applications. This article also discusses several standardization and research challenges for I2NSF.	cloud computing;firewall (computing);network function virtualization;network packet;network security;network switch;security service (telecommunication);software-defined networking	Sangwon Hyun;Jinyong Kim;Hyoungshick Kim;Jae Hoon Jeong;Susan Hares;Linda Dunbar;Adrian Farrel	2018	IEEE Communications Magazine	10.1109/MCOM.2018.1700662	the internet;enterprise private network;computer network;network security;distributed computing;computer science;standardization;cloud computing;architecture;network packet;security service	Security	-16.527181574781835	84.14842441249043	54949
52363df63d9e12fd260eb4c5d82c05dca8794d79	scheduling problems in a practical allocation model	approximate algorithm;linear time algorithm;optimal scheduling;network of workstation;precedence constraint;parallel computer;message passing;scheduling problem;performance bounds;parallel machines;task allocation	A parallel computational model is defined which addresses I/O contention, latency, and pipe-lined message passing between tasks allocated to different processors. The model can be used for parallel task-allocation on either a network of workstations or on a multi-stage inter-connected parallel machine. To study performance bounds more closely, basic properties are developed for when the precedence constraints form a directed tree. It is shown that the problem of optimally scheduling a directed one-level precedence tree on an unlimited number of identical processors in this model is NP-hard. The problem of scheduling a directed two-level precedence tree is also shown to be NP-hard even when the system latency is zero. An approximation algorithm is then presented for scheduling directed one-level task trees on an unlimited number of processors with an approximation ratio of 3. Simulation results show that this algorithm is, in fact, much faster than its worst-case performance bound. Better simulation results are obtained by improving our approximation algorithm using heusistics. Restricting the problem to the case of equal task execution times, a linear-time algorithm is presented to find an optimal schedule.	approximation algorithm;best, worst and average case;central processing unit;computational model;computer cluster;input/output;message passing;parallel computing;resource contention;scheduling (computing);simulation;time complexity;workstation	Lisa Hollermann;Tsan-sheng Hsu;Dian Rae Lopez;Keith Vertanen	1997	J. Comb. Optim.	10.1023/A:1009799631608	fair-share scheduling;job shop scheduling;mathematical optimization;parallel computing;message passing;real-time computing;dynamic priority scheduling;computer science;distributed computing;precedence diagram method	Metrics	-13.492800155245927	60.51702899689867	55018
b09274012e0fa6f5428855973e336728baea0233	state independent resource management for distributed grids		Advances in network technologies and computing resources have led to the possibility of deploying large scale computational systems, such as those following a Grid architecture (or related architectures). The scheduling problem is a significant issue in the Grid environment. In practice, a scheduling algorithm should consider multiple objectives. Typically, there are two kinds of objectives. The first is the performance of the system in terms of quantities related to the completion time of tasks, the second is the amount of state information required, which is often measured in terms of quantities such as communications costs. These two objectives are often in tension with one another. For example, gathering large amounts of state information can lead to low completion times. In this work, we introduce a scheduling algorithm which simultaneously addresses the objectives listed above namely, minimizing completion times, while requiring zero dynamic state information. Using simulation, we show the promising performance of our algorithm, and its robustness with respect to errors in parameter estimates. Keywords-Grid Scheduling; Scheduling Algorithms; Shadow Routing Approach	algorithm;scheduling (computing);simulation	Aysan Rasooli Oskooei;Douglas G. Down	2011			grid;resource management;robustness (computer science);computer science;job shop scheduling;data mining;architecture;scheduling (computing);distributed computing;shadow	HPC	-15.824642584779435	61.234252015443644	55075
c4a732410fdedc57817cfe0cf55948fe3385177a	interconnection of body area networks to a communications infrastructure: an architectural study	internet medical services network topology protocols wireless communication routing standards	Many papers in the literature advocate the use of the Internet of Things communication paradigm to connect wearable body area networks with the Internet in order to create a global communication framework for electronic health care management. In this paper we analyze some of the most typical deployment layouts by extracting them from the health care use case of the IoT-A project. In particular, we focus our investigation on the transition phase happening during network topology changes; in fact, during these events it is challenging to satisfy such functional requirements as promptness and availability. Moreover, we take into account how open standard communication protocols such as 6LoWPAN and RPL behave during device mobility and network handover; we highlight issues and propose some simple yet feasible strategies to improve the body area network performance during such events.	interconnection	Nicola Bui;Nicola Bressan;Michele Zorzi	2012			computer science;wireless network;distributed computing;routing protocol;link-state routing protocol;computer security;computer network	HCI	-22.161670993948043	81.06507563913398	55189
dc86a29124bb0ea1d482050d00404cfcf6563a4d	optimal placement of fso relays for network disaster recovery	probability;telecommunication network reliability;transceivers meteorology transmitters xenon availability schedules relays;optical transceivers;telecommunication traffic;integer programming;terrorism disasters integer programming linear programming optical links optical transceivers probability relay networks telecommunication telecommunication network reliability telecommunication traffic;relay networks telecommunication;linear programming;optical links;optimal placement fso transceivers probabilistic heuristic traffic flows link availability prediction ilp integer linear program transceiver reconfiguration network capacity weather conditions fso links fso technology terrorist attacks natural disasters free space optics relay network disaster recovery fso relays;disasters;terrorism	Free Space Optics (FSO) relays can be used to recover a network which is partially disconnected due to natural disasters or terrorist attacks. Rapid and efficient recovery can be achieved thanks to FSO technology being wireless and providing high bandwidth. However, placement of such relays is a challenging problem as FSO links greatly depend on weather conditions. In this paper, we find the minimum number of transceivers and their optimal placement which guarantees the recovery of a certain fraction of network capacity in the worst weather conditions and maximizes the throughput in the best weather conditions through transceiver reconfiguration. The problem is formulated as an integer linear program (ILP) which takes the link availability prediction as an input and guarantees fairness to all existing traffic flows. To avoid the complexity of the ILP, an efficient probabilistic heuristic that computes the placement of FSO transceivers is proposed. We show through extensive simulations that the heuristic performs within 12% of the optimal performance.	computation;context of computational complexity;disaster recovery;fairness measure;heuristic;linear programming;relay;simulation;throughput;transceiver	Farshad Ahdi;Suresh Subramaniam	2013	2013 IEEE International Conference on Communications (ICC)	10.1109/ICC.2013.6655170	disaster;integer programming;telecommunications;linear programming;probability;terrorism;computer network	Robotics	-5.837598277147276	81.84326786152442	55218
5beb37ea4182923c2a8179ef495c1f35c90a0e8f	research of streaming media services based on cloud computing	clouds	In order to solve the problem of mass concurrent access to streaming media,this paper designs the application of streaming media services based on cloud computing with technologies about cloud computing. With the analysis of the actual demand, the system the paper designs includes three parts: streaming media resource center, streaming media edge node and intelligent load balance system. Streaming media resource center could manage and distribute streaming media resources; streaming media edge node is responsible for replaying requests of streaming media playing directly; intelligent load balance system would schedule system loads according to the current state of users requests automatically. After experiments, it proves that the system has good performance and practical value.	cloud computing;computer science;concurrency control;experiment;multidimensional digital pre-distortion;streaming media;windows live mesh	Zongbin Wang	2012		10.1117/12.946111	real time streaming protocol;real-time computing;computer science;multimedia;world wide web	HPC	-16.98880211539847	73.19431208185405	55246
fd9176452459f390785c8a7e24f57c37b5fff402	a joint data and computation scheduling algorithm for the grid	data;algorithm;scheduling algorithm;scheduling;workflow;grid computing;data transfer	In this paper a new scheduling algorithm for the Grid is introduced. The new algorithm (JDCS) combines data transfer and computation scheduling by a back-trace technique to reduce remote data preloading delay, and is aware of resource performance fluctuation in the Grid. Experiments show the effectiveness and adaptability of this new approach in the Grid environment.	algorithm;computation;computational resource;experiment;grid computing;performance prediction;quantum fluctuation;scheduling (computing);selection algorithm;universal conductance fluctuations	Fangpeng Dong;Selim G. Akl	2007		10.1007/978-3-540-74466-5_62	fair-share scheduling;fixed-priority pre-emptive scheduling;parallel computing;real-time computing;flow shop scheduling;dynamic priority scheduling;computer science;rate-monotonic scheduling;operating system;two-level scheduling;distributed computing;lottery scheduling;round-robin scheduling;scheduling	HPC	-17.73345489627083	62.862799839884914	55323
64e7d37666ea9f172cc63cbef84d1d123d6e95e5	scream: sketch resource allocation for software-defined measurement	resource allocation;sketches;software defined measurement	Software-defined networks can enable a variety of concurrent, dynamically instantiated, measurement tasks, that provide fine-grain visibility into network traffic. Recently, there have been many proposals for using sketches for network measurement. However, sketches in hardware switches use constrained resources such as SRAM memory, and the accuracy of measurement tasks is a function of the resources devoted to them on each switch. This paper presents SCREAM, a system for allocating resources to sketch-based measurement tasks that ensures a user-specified minimum accuracy. SCREAM estimates the instantaneous accuracy of tasks so as to dynamically adapt the allocated resources for each task. Thus, by finding the right amount of resources for each task on each switch and correctly merging sketches at the controller, SCREAM can multiplex resources among network-wide measurement tasks. Simulations with three measurement tasks (heavy hitter, hierarchical heavy hitter, and super source/destination detection) show that SCREAM can support more measurement tasks with higher accuracy than existing approaches.	computer simulation;multiplexing;network switch;network traffic control;scream (cipher);static random-access memory	Masoud Moshref;Minlan Yu;Ramesh Govindan;Amin Vahdat	2015		10.1145/2716281.2836099	embedded system;real-time computing;simulation;resource allocation	Metrics	-13.730799634964017	80.40628770650866	55353
afe2e65015535acf0aee8b6599dd7fe5329409d2	ultra-low power, secure iot platform for predicting cardiovascular diseases		Internet of Things (IoT) promises to revolutionize the health-care sector through remote, continuous, and non-invasive monitoring of patients. However, there are two main challenges faced by the IoT-enabled medical devices: energy-efficiency and security/privacy concerns. Researchers have independently attempted to develop solutions, such as low-power ECG-processors and security protocols, that address these challenges on an individual basis. However, it is imperative to investigate holistic solutions that integrate in a synergistic manner, delivering an overall secure and energy-efficient product. In this paper, we develop an ultra-low power and secure IoT sensing/pre-processing platform for prediction of ventricular arrhythmia using ECG signals. Our proposed solution is able to predict the on-set of the critical cardiovascular events upto 3 h in advance with 86% accuracy. Moreover, the proposed architecture is designed using an Application Specific Integrated Circuits design flow in 65-nm Low Power Enhanced technology; the power it consumes is 62.2% less than that of the state-of-the-art approaches, while occupying 16.0% smaller area. The proposed processor makes use of ECG signals to extract a chip-specific ECG key that enables protection of communication channel. By integrating the ECG key with an existing design-for-trust solution, the proposed platform offers protection also at the hardware level, thwarting hardware security threats, such as reverse engineering and counterfeiting. Through efficient sharing of on-chip resources, the overhead of the multi-layered security infrastructure is kept at 9.5% for area and 0.7% for power with no impact on the speed of the design.	central processing unit;channel (communications);cryptographic protocol;holism;imperative programming;integrated circuit;internet of things;layered security;low-power broadcasting;overhead (computing);preprocessor;privacy;reverse engineering;synergy	Muhammad Yasin;Temesghen Tekeste;H Jacob Saleh;Baker Mohammad;Ozgur Sinanoglu;Mohammed Ismail	2017	IEEE Transactions on Circuits and Systems I: Regular Papers	10.1109/TCSI.2017.2694968	hardware security module;system on a chip;application-specific integrated circuit;architecture;real-time computing;reverse engineering;design flow;cryptographic protocol;engineering;communication channel	EDA	-27.336921124229924	68.02412298189381	55356
1a99550d1b2c55504725b32c0cbb14e9d94e990d	representing ip information in the x.500 directory		"""This document describes the objects necessary to include information about IP networks and IP numbers in the X.500 Directory. It extends the work """"Charting networks in the Directory"""" [ND] where a general frame work is presented for representing networks in the Diretory by applying it to IP networks. This application of the Directory is intended to support the work of IP network assigning authorities, NICs, as well as other applications looking for a mapping of IP numbers to data of related networks."""	directory service;general frame;internet protocol suite;network interface controller;norsk data;x.500	Thomas Johannsen;Glenn Mansfield Keeni;Mark Kosters;Srinivas R. Sataluri	1994	RFC	10.17487/RFC1608	lightweight directory access protocol;virtual routing and forwarding;directory service;x.500;computer science;database;directory information tree;world wide web;organizational unit;computer network	ECom	-25.022482664647672	88.3578014833795	55396
3eb5404ce28478aca75774d10ab44161083fec5c	a flexible architecture for multi-hop optical networks	wavelength division multiplexing optical fibre networks network topology telecommunication network routing optical transmitters optical receivers;spread spectrum communication optical fiber networks network topology routing optical transmitters optical receivers computer science wavelength division multiplexing high speed optical techniques optical buffering;optical transmitters;network topology;optical fibre networks;telecommunication network routing;wdm flexible architecture multihop optical networks low diameter logical topologies multihop lightwave networks regular topologies gemnet network nodes routing scheme multistar implementation retuning transmitters receivers scalable logical topology algorithm;optical receivers;wavelength division multiplexing	It is desirable to have low diameter logical topologies for multihop lighhvave nehvorks. Researchers have investigated regular topologies for such networks. Only a few of these (e.g.. GEMNET [8]) are scalable to allow the addition of new nodes to an existing nenvork. Adding new nodes to such networks requires a major change in routing scheme. For example, in a midtistar implementation, a large number of retuning of transmitters and receivers and/or renunibering nodes are needed for [8]. In this paper! we present a scalable logical topology which is not regular but it has a low diameter. This topology is interesting since it allows the nehvork to be expanded indefinitely and new nodes can be added with a relatively small change to the nehvork. In this paper we have presented the new topology, an algorithm to add nodes to the network and two routing schemes.	algorithm;hop;logical topology;routing;scalability;transmitter	Arunita Jaekel;Subir Bandyopadhyay;Abhijit Sengupta	1998		10.1109/ICCCN.1998.998805	optical transport network;routing;telecommunications;computer science;optical performance monitoring;network topology;wavelength-division multiplexing;optical cross-connect;computer network;logical topology	Mobile	-5.94932736698779	80.51963485314901	55455
f772d15f5913ffa58de186fe20d1b0bd0a8c5206	adaptive fair sharing control in real-time systems using nonlinear elastic task models	tecnologia electronica telecomunicaciones;nonlinear elasticity;resource allocation;task model;qos;tecnologias;grupo a;fair sharing control;elastic task model;real time systems	In real-time systems, deadline misses of the tasks cause a degradation in the quality of their results. To improve the quality, we have to allocate CPU utilization for each task adaptively. Recently, Buttazzo et al. address a feedback scheduling algorithm, which dynamically adjusts task periods based on the current workloads by applying a linear elastic task model. In their model, the utilization allocated to each task is treated as the length of a linear spring and its flexibility is described by a constant elastic coefficient. In this paper, we first consider a nonlinear elastic task model, where the elastic coefficient depends on the utilization allocated to the task. We propose a simple iterative method for calculating the desired allocated resource and derive a sufficient condition for the convergence of the method. Next, we apply the nonlinear elastic model to an adaptive fair sharing controller. Finally, we show the effectiveness of the proposed method by computer simulation.	real-time clock;real-time operating system	Toshimitsu Ushio;Haruo Kohtaki;Masakazu Adachi;Fumiko Harada	2007	IEICE Transactions	10.1093/ietfec/e90-a.6.1154	real-time computing;simulation;quality of service;resource allocation;computer science	Embedded	-10.227549045192598	62.58075989885416	55468
d4d1a59c60af8fa3b2973439d50369d3b2a23e8d	snmp-based rma analysis of wired and wireless networks		This research aims at describing a method to subjectively measure specific parameters in a wired or wireless network environment using the Simple Network Management Protocols for the purpose of improving Reliability, Maintainability, and Availability of the network devices. This is of importance in cases where the network is in remote or hard to access locations such as space, defense, or polar applications. Furthermore, the results can be used for troubleshooting and/or failure prediction of the network devices. Applications of health monitoring and prediction in network environments are expanding as are the networks. SNMP-Based RMA Analysis of Wired and Wireless Networks	gene prediction;revolution in military affairs;simple network management protocol	Ehsan Sheybani;L. Ralph;Giti Javidi;Akbar Eslami;Jamiiru Luttamaguzi	2013	IJITN	10.4018/jitn.2013070105	multi-frequency network;network traffic control;intelligent computer network;wireless wan;network architecture;wireless sensor network;heterogeneous network;network management station;telecommunications;wireless network;network simulation;network management application;computer security;computer network	Mobile	-19.141190566220455	85.35672697808114	55490
911125833ef7c70a38712b19d3d41d5d4f16da66	minimum and maximum utilization bounds for multiprocessor rate monotonic scheduling	distributed algorithms;utilization bounds real time systems multiprocessors rate monotonic scheduling allocation;processor scheduling;resource allocation;real time;processor scheduling scheduling algorithm partitioning algorithms system testing performance evaluation real time systems simulated annealing;multiprocessors;allocation;65;real time systems rate monotonic scheduling uniprocessor partitioning based scheduling multiprocessor utilization bound allocation algorithm worst fit allocation heuristic first fit decreasing heuristics best fit decreasing heuristics;computational complexity;resource allocation real time systems distributed algorithms computational complexity processor scheduling;rate monotonic scheduling;utilization bounds;rate monotonic;real time systems;first fit	The utilization bound for real-time rate monotonic (RM) scheduling on uniprocessors is extended to multiprocessors with partitioning-based scheduling. This allows fast schedulability tests to be performed on multiprocessors and quantifies the influence of key parameters, such as the number of processors and task sizes on the schedulability of the system. The multiprocessor utilization bound is a function of the allocation algorithm, so among all the allocation algorithms there exists at least one allocation algorithm providing the minimum multiprocessor utilization bound, and one allocation algorithm providing the maximum multiprocessor utilization bound. We prove that the multiprocessor utilization bound associated with the allocation heuristic worst fit (WF) coincides with that minimum if we use Liu and Layland's bound (LLB) as the uniprocessor schedulability condition. In addition, we present a class of allocation algorithms sharing the same multiprocessor utilization bound which coincides with the aforementioned maximum using LLB. The heuristics first fit decreasing (FFD) and best fit decreasing (BFD) belong to this class. Thus, not even an optimal allocation algorithm can guarantee a higher multiprocessor utilization bound than that of FFD and BFD using LLB. Finally, the pessimism of the multiprocessor utilization bounds is estimated through extensive simulations.	algorithm;best practice;best, worst and average case;binary file descriptor library;central processing unit;clock rate;curve fitting;free-form deformation;heart rate variability;heisenbug;heuristic (computer science);mathematical optimization;memory management;multiprocessing;random number generation;rapid application development;rate-monotonic scheduling;real-time clock;scheduling (computing);simulation;uniprocessor system	José María López;José Luis Díaz;Daniel F. García	2004	IEEE Transactions on Parallel and Distributed Systems	10.1109/TPDS.2004.25	distributed algorithm;parallel computing;real-time computing;resource allocation;computer science;rate-monotonic scheduling;distributed computing;computational complexity theory;multiprocessor scheduling	Embedded	-11.025131940235768	60.65281797807786	55502
c1a55400ba39ac644eb25c0555550f531b1ab004	modeling of sensor clouds under the sensing as a service paradigm		5G technologies will facilitate the emergence of applications integrating multiple physical Things. In such scenarios, Cloud-integrated platforms end up having a key role due to their storage and processing capabilities. Therefore, a clear understanding of Sensor Clouds, and on how Cloud mechanisms can be orchestrated to better face requests, becomes a very relevant issue as Sensing as a Service models emerge. This article presents a model for Sensor Clouds, suitable for emerging IoT related Sensing as a Service business models. Such a model is used to assess the impact of resource allocation approaches and unveil the trade-off between scalability, elasticity and quality of experience. Results show that the best resource allocation approach is highly dependent on the suppliers/consumers scenario.		J. Guerreiro;L. Rodrigues;N. Correia	2018		10.1007/978-3-030-05195-2_3	scalability;cloud computing;computer science;quality of experience;resource allocation;business model;distributed computing;internet of things	Mobile	-27.87588418817892	61.88617141756683	55561
00fdad565f3bb86294580fc01664bdbe862f1b06	an efficient communication aware heuristic for multiple cloud application placement		To deploy a distributed application on the cloud, cost, resource and communication constraints have to be considered to select the most suitable Virtual Machines (VMs), from private and public cloud providers. This process becomes very complex in large scale scenarios and, as this problem is NP-Hard, its automation must take scalability into consideration. In this work, we propose a heuristic able to calculate initial placements for distributed component-based applications on possibly multiple clouds with the objective of minimizing VM renting costs while satisfying applications’ resource and communication constraints. We evaluate the heuristic performance and determine its limitations by comparing it to other placement approaches, namely exact algorithms and meta-heuristics. We show that the proposed heuristic is able to compute a good solution much faster than them.	heuristic;software as a service	Pedro Silva;Christian Pérez	2017		10.1007/978-3-319-64203-1_27	automation;renting;scalability;cloud computing;distributed computing;real-time computing;heuristic;virtual machine;computer science	EDA	-20.32559673984647	64.74840487498169	55582
eb087d5014337ca6715e19a4b195a49d6d2dada4	device-to-device communication for smart grid devices	virtual private networks peer to peer computing smart power grids;agent based systems device to device communication smart grid devices peer to peer virtual private network central control instance communication systems network nodes p2p networks mesh vpn;smart power grids;peer to peer computing smart grids virtual private networks internet communication networks overlay networks routing;peer to peer computing;smart grids communication networks network topology;virtual private networks	This paper analyzes the applicability of existing communication technology on the Smart Grid. In particular it evaluates how networks, e.g. Peer-to-Peer (P2P) and decentralized Virtual Private Network (VPN) can help set up an agent-based system. It is expected that applications on Smart Grid devices will become more powerful and be able to operate without a central control instance. We analyze which requirements agents and Smart Grid devices place on communication systems and validate promising approaches. The main focus is to create a logical overlay network that provides direct communication between network nodes. We provide a comparison of different approaches of P2P networks and mesh-VPNs. Finally the advantages of mesh-VPN for agent-based systems are worked out.	agent-based model;grid computing;mesh networking;overlay network;peer-to-peer;requirement;virtual private network	Simon Fey;Pascal Benoit;Gregor Rohbogner;Andreas H. Christ;Christof Wittwer	2012	2012 3rd IEEE PES Innovative Smart Grid Technologies Europe (ISGT Europe)	10.1109/ISGTEurope.2012.6465751	overlay network;computer science;distributed computing;computer security;internet of things;computer network	HPC	-21.457018403259916	80.26969377409806	55610
ab26dba374f0615091742f288cfbe4bfaa41e004	a new study on network performance under link failure in ops/obs high-capacity optical networks	optical packet switching optical buffering optical fiber networks topology network topology fiber optics;optical fiber communications network protection photonic switching optical packets;optical fibre communication network performance link failure ops obs high capacity optical network metropolitan network optical packet switching optical burst switching ring topology mesh topology hop loss fraction packet loss fraction triple connection node configuration;telecommunication network topology metropolitan area networks optical burst switching optical fibre networks optical links packet switching	In this work we analyze the performance and sensitivity to link failure of metropolitan networks based on the technology of optical packet/burst switching (OPS/OBS). We use ring and mesh topologies to evaluate through analytical modeling and computer simulations the impact of link failure on each topology. We adopt the parameters average number of hops and packet loss fraction to evaluate network performance. It is observed that mesh topologies with triple-connection node configuration (3×3) are more robust; consequently in case of link failure the impact of lost data is minimum compared with the other topologies and configurations considered.	approximation;computer simulation;end-to-end principle;mesh networking;network packet;network performance;optical burst switching;orthogonal polarization spectral imaging;qualitative comparative analysis	Indayara Bertoldi Martins;Felipe Rudge Barbosa;Edson Moschim	2010	2010 ITU-T Kaleidoscope: Beyond the Internet? - Innovations for Future Networks and Services		optical transport network;ring network;passive optical network;lan switching;optical burst switching;fast packet switching;multiwavelength optical networking;telecommunications;label switching;processing delay;optical ip switching;distributed computing;transmission delay;optical switch;optical performance monitoring;burst switching;circuit switching;telecommunications network;optical cross-connect;computer network	Metrics	-6.753925276953611	85.01876165092578	55675
ba7c7d3233a61ad6d4e66d88b5f7f96889a47901	an adaptive energy efficient cache invalidation scheme for mobile databases	implicit and explicit relevance feedback;query processing;energy efficient;user studies;mobile database;mobile environment;efficient implementation;data dissemination	This paper presents Adaptive Energy Efficient Cache Invalidation Scheme (AEECIS) for the wireless mobile environment. The algorithm is adaptive since it changes the data dissemination strategy based on the current conditions. To reduce the bandwidth requirement, the server transmits in one of three modes: slow, fast or super-fast. The mode is selected based on thresholds specified for time and the number of clients requesting updated objects. An efficient implementation of AEECIS is presented and simulations have been carried out to evaluate its caching effectiveness. The results demonstrate that it can substantially improve mobile caching by reducing the communication bandwidth for query processing. Compared to previous IR-based schemes, AEECIS can significantly improve bandwidth consumption and the number of uplink requests.	algorithm;cache (computing);cache invalidation;database;server (computing);simulation;telecommunications link	Alok Madhukar;Reda Alhajj	2006		10.1145/1141277.1141545	real-time computing;mobile database;computer science;database;distributed computing;efficient energy use;dissemination	Mobile	-15.20698987436654	68.68690135972234	55738
4f6e30332967cf3294369d3d22bf1331801b09aa	incentivising resource sharing in social clouds	virtual reality cloud computing computer centres social networking online socio economic effects;social networks cloud computing resource sharing;virtual reality;computer centres;qa75 electronic computers computer science;social networks;resource sharing;social networking online;communities peer to peer computing internet educational institutions exchange rates resource management context;socio economic effects;virtual currency incentivising resource sharing social clouds social network centralized data centre socio economic model;cloud computing	"""Social Clouds provide the capability to share resources among participants within a social network - leveraging on the trust relationships already existing between such participants. In such a system, users are able to trade resources between each other, rather than make use of capability offered at a (centralized) data centre. Incentives for sharing remain an important hurdle to make more effective use of such an environment, which has a significant potential for improving resource utilization and making available additional capacity that remains dormant. We utilize the socio-economic model proposed by Silvio Gesell to demonstrate how a """"virtual currency"""" could be used to incentivise sharing of resources within a """"community"""". We subsequently demonstrate the benefit provided to participants within such a community using a variety of economic (such as overall credits gained)and technical (number of successfully completed transactions) metrics, through simulation."""	centralized computing;cluster analysis;data center;reputation management;simulation;social graph;social network;virtual currency	Magdalena Punceva;Ivan Rodero;Manish Parashar;Omer F. Rana;Ioan Petri	2012	2012 IEEE 21st International Workshop on Enabling Technologies: Infrastructure for Collaborative Enterprises	10.1109/WETICE.2012.68	shared resource;cloud computing;computer science;knowledge management;operating system;distributed computing;virtual reality;world wide web;computer security;social network	HCI	-26.13856521230284	64.4755545922185	55803
c238d148044225ae07a77a6b9927c4e962275acc	granularity-based workflow scheduling algorithm for cloud computing	cloud computing;virtualization;workflow application;task granularity;makespan	The workflow scheduling problem has drawn a lot of attention in the research community. This paper presents a workflow scheduling algorithm, called granularity score scheduling (GSS), which is based on the granularity of the tasks in a given workflow. The main objectives of GSS are to minimize the makespan and maximize the average virtual machine utilization. The algorithm consists of three phases, namely B-level calculation, score adjustment and task ranking and scheduling. We simulate the proposed algorithm using various benchmark scientific workflow applications, i.e., Cybershake, Epigenomic, Inspiral and Montage. The simulation results are compared with two well-known existing workflow scheduling algorithms, namely heterogeneous earliest finish time and performance effective task scheduling, which are also applied in cloud computing environment. Based on the simulation results, the proposed algorithm remarkably demonstrates its performance in terms of makespan and average virtual machine utilization.	algorithm;benchmark (computing);bundle adjustment;cloud computing;heterogeneous earliest finish time;makespan;montagejs;scheduling (computing);simulation;virtual machine	Madhu Sudan Kumar;Indrajeet Gupta;Sanjaya Kumar Panda;Prasanta K. Jana	2017	The Journal of Supercomputing	10.1007/s11227-017-2094-7	workflow management system;distributed computing;workflow application;job shop scheduling;parallel computing;computer science;fair-share scheduling;dynamic priority scheduling;real-time computing;workflow;two-level scheduling;rate-monotonic scheduling	HPC	-18.138965453252812	62.54331639528115	55837
e99c20d3f0351dfad489b85174d530cdbdb61c6f	sdn-sdwsn controller fault tolerance framework for small to medium sized networks		In the OpenFlow-based software defined networking (SDN), a single controller controls the entire network resources. However, it poses a single point of failure and has restricted processing capacity. Multiple controllers emerged as a solution to ensure network reliability, scalability and high availability for large scale networks. Despite the benefits, multiple controllers also brings about increased complexity with several new challenges affecting network management and schedule. Albeit the centralized controller is suitable for small and medium sized networks, the challenge is how to ensure its reliability and resiliency. This means faults have to be detected and failure recover as quickly as possible. Therefore, this paper proposes a fault tolerance framework (FTF) consisting of three controllers and a FT manager (FTM). The FTM has several components that contribute to FT by monitoring and detecting faults using heartbeat messages and recover from failure using checkpointing. The approach is passive replication where only one controller manages the networks and in the event of failure, another controller is elected using a novel voting technique. Additionally, the issue of network state consistency are handled adequately. We theoretically assessed the FTF using several FT design requirements. The evaluation shows our FTF has an acceptable performance operations in ensuring strict consistency and fault tolerant system.	application checkpointing;centralized computing;fault tolerance;high availability;linearizability;openflow;reliability engineering;requirement;scalability;sensor;single point of failure;software-defined networking	Bassey Isong;Ishmael Mathebula;Nosipho Dladlu	2018	2018 19th IEEE/ACIS International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing (SNPD)	10.1109/SNPD.2018.8441131	single point of failure;control theory;distributed computing;openflow;network management;scalability;fault tolerance;computer science;reliability (computer networking);software-defined networking	SE	-27.91658951750412	60.624879585867596	55850
6b5b7bf3de629aec82380891105a8eee6899b4de	internet message access protocol (imap) - url access identifier extension		"""Status of This Memo This document specifies an Internet standards track protocol for the Internet community, and requests discussion and suggestions for improvements. Please refer to the current edition of the """"Internet Official Protocol Standards"""" (STD 1) for the standardization state and status of this protocol. Distribution of this memo is unlimited. Abstract The existing IMAP URL specification (RFC 5092) lists several <access> identifiers and <access> identifier prefixes that can be used to restrict access to URLAUTH-generated URLs. However, these identifiers do not provide facilities for new services such as streaming. This document proposes a set of new <access> identifiers as well as an IANA mechanism to register new <access> identifiers for future applications."""	identifier;internet;std bus;streaming media	Neil L. Cook	2009	RFC	10.17487/RFC5593	url normalization;computer science;extensible resource identifier;unique identifier;management information base;network access identifier;service location protocol;database;internet privacy;info uri scheme;world wide web	Security	-25.794861929185185	88.20164395013052	55939
27e8d900847d194779b8333298479516f3cf60fe	proton: a policy-based solution for future 4g devices	mobile handsets 4g mobile communication multi access systems computational complexity;mobile device;heterogeneous wireless networks proton policy based solution 4g mobile devices integrated wireless networks handover process complexity 4g systems flexible policy based approach;protons context modeling radio access networks laboratories mobile communication wireless networks costs satellite broadcasting gsm ground penetrating radar;computational complexity;multi access systems;mobile handsets;4g mobile communication;heterogeneous wireless networks	We present PROTON, a policy-based solution for 4G mobile devices - it allows users to seamlessly connect to highly integrated heterogeneous wireless networks. The key motivation behind PROTON stems from the statement that handover process complexity will increase in 4G systems, creating the need for augmented knowledge about context, as well as more flexibility. This paper demonstrates (1) how a flexible policy-based approach is suitable for 4G scenarios, and (2) how to incorporate richer context into policies and still maintain a light weight solution appropriate for mobile devices.	algorithm;frank rosenblatt;hard coding;hopper;mobile device;testbed	Pablo Vidales;Rajiv Chakravorty;Calicrates Policroniades	2004	Proceedings. Fifth IEEE International Workshop on Policies for Distributed Systems and Networks, 2004. POLICY 2004.	10.1109/POLICY.2004.1309173	embedded system;mobile search;mobile web;imt advanced;telecommunications;engineering;mobile technology;mobile station;mobile computing;computer network	Mobile	-14.158257583754809	88.53530488562805	56157
208334efc690283f25b8a5839100a1daec5a4640	an internet without the internet protocol	internet protocol;internet routing;routing;internet architecture;future internet;autonomic system;internet router;inter domain routing;new internet architecture;host identification;critical infrastructure	The growth of the Internet has brought about many challenges for its critical infrastructure. The DNS infrastructure, which translates mnemonic host names into IP addresses understood by the routers, is frequently the target of cache poisoning attacks. Internet routers are also experiencing alarming growth in their routing table sizes, which may soon make it impossible for them to forward packets quickly enough to meet demand. Further, concerns about IPv4 address space exhaustion loom on the horizon despite the availability of IPv6. In this paper, we take a fresh look at Internet routing and propose a scheme that addresses all of these concerns cleanly. Our scheme forgoes IP addresses entirely and instead uses host names as identifiers in packets. The scalability of routing is ensured by encapsulating these packets in highly aggregated routing locators: we use autonomous system numbers (ASNs), which are already an integral part of inter-domain routing. We present data and experiments to show that a much simpler and scalable routing infrastructure can be designed for a future Internet by using fewer identifiers for its entities.	address space;autonomous robot;autonomous system (internet);dns spoofing;entity;experiment;floor and ceiling functions;future internet;ipv4 address exhaustion;identifier;inter-domain;loom;router (computing);routing table;scalability	Craig A. Shue;Minaxi Gupta	2010	Computer Networks	10.1016/j.comnet.2010.06.009	internet protocol;policy-based routing;reserved ip addresses;routing domain;routing;enhanced interior gateway routing protocol;static routing;hierarchical routing;autonomous system;supernetwork;border gateway protocol;internet layer;telecommunications;protocol independent multicast;computer science;dynamic source routing;operating system;ipv6;critical infrastructure;internet privacy;routing protocol;default-free zone;computer security;ipv4 address exhaustion;computer network;ipv6 address	Networks	-15.060668714183903	79.46301420058572	56192
3957c01ad3bceee4fe80666ba40e4a1ac351b584	service invocation over content-based communication in disconnected mobile ad hoc networks	network healing techniques;network wide opportunistic dissemination;manet;service provider;and forward;opportunistic networks;mobile communication mobile ad hoc networks middleware routing network topology buildings computational modeling distributed computing information retrieval degradation;service invocation over content based communication;content based networking;mobile radio ad hoc networks customer satisfaction;client satisfaction service invocation over content based communication disconnected mobile ad hoc networks manet store carry and forward approach network wide opportunistic dissemination network healing techniques;customer satisfaction;store carry and forward approach;simulation experiment;disconnected mobile ad hoc networks;content based networking disconnected manets services opportunistic networking;client satisfaction;mobile radio;publish subscribe;ad hoc networks;mobile ad hoc network;middleware;services;opportunistic networking;disconnected manets;peer to peer computing;relays;mobile computing;buildings	This paper presents a middleware platform for the provision of services in disconnected MANETs, focusing on service invocation. This middleware exploits content-based communications (through a publish/subscribe paradigm) and employs a store-carry-and-forward approach for the network-wide opportunistic dissemination of messages. Service invocation is implemented on top of these communication features. The paper first describes the main aspects of the middleware and then details the service invocation mechanism. We namely show that the potential multiplicity of service providers can be exploited in order to increase the client satisfaction and that several network healing techniques allow the reduction of the network load. The paper ends by a description of some simulation experiments in a realistic scenario, whose results reflects the performance of the approach in terms of client satisfaction and network load.	experiment;middleware;programming paradigm;publish–subscribe pattern;simulation	Yves Mahéo;Romeo Said	2010	2010 24th IEEE International Conference on Advanced Information Networking and Applications	10.1109/AINA.2010.48	mobile ad hoc network;computer science;operating system;distributed computing;internet privacy;customer satisfaction;mobile computing;computer network	Embedded	-15.879673973820903	76.97262855726238	56275
18ccdcc647f14bad62a40f663e1cd4324a107b4b	nocdn: scalable content delivery without a middleman		Today's websites achieve scalability by either deploying their own platforms with sufficient spare capacity or signing up for services from a content delivery network (CDN). This paper investigates another alternative, where a website directly recruits Internet users to contribute their resources to help deliver the site's content. We show that this alternative, which we call NoCDN, can be implemented securely, transparently to the users accessing the site, and without changes to the content itself.	content delivery network;digital distribution;internet;peer-to-peer;performance evaluation;scalability;server (computing)	Junbo Xu;Michael Rabinovich	2017		10.1145/3132465.3132476	the internet;scalability;spare part;content delivery network;internet privacy;computer network;engineering	Networks	-18.440368306517193	74.18156131860995	56317
0c6f641c2b2af9929d430add1c36ee13bac6b63f	survivability techniques for ng-pons and fiwi access networks	telecommunication network reliability;smart grid fiwi access networks long reach next generation passive optical networks high speed multichannel next generation passive optical networks ng pon survivability techniques dual homing hitless protection switching equalization delays interconnection fibers protection rings meshed pon topology cost benefit analysis population densities advanced in service monitoring techniques fault detection pon distribution fiber localization partial optical protection wireless protection fiber wireless access networks;passive optical networks optical network units wavelength division multiplexing optical sensors monitoring;cost benefit analysis;telecommunication network reliability cost benefit analysis fault diagnosis passive optical networks;fault diagnosis;passive optical networks	Survivability will play a more prominent role in emerging high-speed, multichannel, long-reach next-generation passive optical networks (NG-PONs) than it did in conventional PONs. In this paper, we report on some of the most promising NG-PON survivability techniques such as dual homing, hitless protection switching by means of equalization delays, interconnection fibers, protection rings, and meshed PON topologies, including their cost-benefit analysis for different population densities. We pay particular attention to the design of advanced in-service monitoring techniques for fault detection and localization in PON distribution fibers and study the merits of combining partial optical protection with wireless protection for realizing reliable fiber-wireless (FiWi) access networks and exploiting them to improve the survivability of other critical networks such as the future smart grid.	10g-pon;access network;fault detection and isolation;interconnection;internet access;multiple homing;passive optical network;protection ring;requirement;total cost of ownership	Martin Maier	2012	2012 IEEE International Conference on Communications (ICC)	10.1109/ICC.2012.6364982	passive optical network;telecommunications;cost–benefit analysis;optical performance monitoring;computer network	EDA	-10.39051340117244	85.9430080671196	56448
e7a12552754148c77e9761349daa387213a80bd2	scheduling of hard real-time systems	generic model;scheduling algorithm;critical system;hard real time system	In this paper we study hard real-time systems: systems where strict time deadlines have to be met. We analyze a special case as well as a general model for hard real-time systems and study pre-emptive, static, scheduling policies for a single processor. The analysis is exact and can handle any arbitrary choice of strict deadlines thereby allowing us to prove the correctness of critical systems. For both the special and general model we present a feasible scheduling algorithm; that is a scheduling algorithm that always produces a priority assignment where all deadlines are met if such a priority assignment exists.	real-time operating system;real-time transcription;scheduling (computing)	Abha Moitra	1986		10.1007/3-540-17179-7_22	fair-share scheduling;nurse scheduling problem;fixed-priority pre-emptive scheduling;parallel computing;real-time computing;earliest deadline first scheduling;flow shop scheduling;dynamic priority scheduling;computer science;rate-monotonic scheduling;two-level scheduling;distributed computing;scheduling;least slack time scheduling;lottery scheduling;round-robin scheduling;scheduling	Embedded	-9.946363814887546	60.91849176191738	56485
3fc7fe55070aba491c3b5821bee7018f10deb4f0	cache predicting algorithm based on context-aware in pervasive computing	disconnected operation;context aware;residence time;context information;mobile device;information retrieval;pervasive computing;notebook computers information retrieval mobile computing;prediction algorithms;buffer management;testing;prediction algorithms pervasive computing mobile computing computer networks frequency handheld computers costs pattern analysis algorithm design and analysis testing;computer networks;data cache;cache replacement;cache predicting algorithm;data access;handheld mobile devices;notebook computers;buffer management algorithms;pattern analysis;handheld mobile devices cache predicting algorithm context aware pervasive computing mobile device data access buffer management algorithms user access user context;quality of service;mobile computing;frequency;user context;user access;algorithm design and analysis;handheld computers	In pervasive computing, mobile device needs to make data access continuously, but in the influence of network and other factors, it could be disconnected. In order to support the continuous data access in case of disconnection, it needs to predict the possible access of data made by users and cache these data on the mobile client. Through data cache, it could store the data that the user could access in future on the client in advance, therefore the effects of disconnected mobile device on data access could be avoided and the quality of service could be accordingly raised. Among the present buffer management algorithms, the computing process either takes no account of context, or divides the data in groups to make a forecast separately according to the context information. These two methods could not fully consider the trend of the whole user access and the impact of user context on the predicted consequences. This paper puts forward a buffer management algorithm, which establishes the association between various data on the basis of data access records and makes data group; after computing the accessing frequency of data sets over the current contexts, it makes cache replacement of the results in terms of cache residence time and accessing frequency. The results of simulation tests show that this kind of algorithm could effectively improve the cache hit rate in the case of disconnected operation for handheld mobile devices, and better support the disconnected operation of mobile devices.	algorithm;cpu cache;cache (computing);data access;handheld game console;mobile device;quality of service;scott continuity;simulation;ubiquitous computing	Jizhong Zhao;Min Xi;Yong Qi	2007	6th IEEE/ACIS International Conference on Computer and Information Science (ICIS 2007)	10.1109/ICIS.2007.71	cache;computer science;cache invalidation;database;distributed computing;cache algorithms;cache pollution;world wide web	Mobile	-15.790023849755432	68.67885608438826	56534
5212c3545640458adcbf388450917af001d9e75e	dcf: dynamic cluster flow architecture for sdn control plane	wireless;controller;sdn;architecture	Software Defined Networking is considered as the new telecom revolution. Within SDN the control plane acts as the brain of the network and should be designed in the most efficient manner. In this paper we propose a novel architecture to deploy the controllers in a SDN based network. We distribute the controllers into clusters which are managed dynamically by a super controller. We develop a load balancing algorithm to avoid overloaded controllers and prove that our solution outperform the existing ones in term of complexity.	algorithm;control plane;design rule for camera file system;load balancing (computing);software-defined networking;super controller	Hadar Sufiev;Yoram Haddad	2017	2017 IEEE International Conference on Consumer Electronics (ICCE)	10.1109/ICCE.2017.7889274	real-time computing;controller;telecommunications;computer science;engineering;architecture;distributed computing;wireless;computer network	Robotics	-13.825587058270433	84.01515473438346	56555
46cb8651df34b388d15cec34137ea22761e80156	control and provisioning of wireless access points (capwap) protocol binding mib for ieee 802.11			capwap;mebibyte;provisioning	Yang Shi;David T. Perkins;Chris Elliott;Yong Zhang	2010	RFC	10.17487/RFC5834	real-time computing;inter-access point protocol;capwap;computer security;computer network	Embedded	-17.5788317946086	88.31825654262816	56579
7639143b167b8b0ad2d13f143ba2877932319c89	divisible load scheduling on single-level tree networks with buffer constraints	directed graphs;distributed computing divisible load scheduling single level tree networks buffer constraints heterogeneous tree network finite size buffers closed form solutions infinite buffer size finite buffer size divisible load theory incremental balancing strategy optimal load distribution step by step incremental balancing reduced optimal network optimal processing time;closed form solution;processor scheduling;resource allocation;optimal scheduling processor scheduling distributed computing closed form solution scheduling algorithm feeds mathematical analysis production hardware software performance;mathematical analysis;iterative methods;divisible load theory;optimal scheduling;load distribution;iterative methods resource allocation processor scheduling directed graphs;tree network	0018-9251/00/$10.00 @ 2000 IEEE Computing over distributed environments has attracted more and more research efforts, since: it leverages the existing hardware and software and outweighs the supercomputer on the flexibility and performance-price ratio. One of the primary issues in the area of distributed computing is on how to divide and schedule loads in order to achieve Ihe best performance in terms of finish time of the loads. According to the type of loads under processing, tasks scheduling problems can be classified into two categories, indivisible tasks scheduling [3 I and divisible tasks scheduling [2]. The divisible load scheduling in multiprocessor systems, commonly referred to as divisible load theory (DLT) in the literature, is of recent origin [4]. Attracted by simple and elegant modeling methodology that DLT adopts, in recent years, there has been an increase in interest in this growing area of research. The applications of DLT can be found in the distributed intelligent sensor networks [4], image processing and 101s of computationally intensive data processing areas [5]. As a new paradigm, DLT offers the ease of analytical tractability and produces a rich set of results in load scheduling in heterogeneous computing systems 12, 6, 71. Since the origination of DLT, the research has spanned from addressing the general optimal scheduling problem on different network architectures to various scenarios with different practical constraints, such as time-varying channels [8], minimizing cost factors [9] and fault-tolerance requirements [ 101 etc. Excellent compilations of results until 1997 can be found in [Z, 111. A divisible load is a kind of load that can be divided arbitrarily into any number of smaller fractions and can be processed independently on different processors. DLT adopts a linear mathematical modeling [2] of the processor speed and channel speed parameters. In this model, the communication time (typically, the transmission time) over a channel is assumed to be proportional to the amount of load that is being transferred over any channel, and the computation time is proportional to the amount of load assigned to a processor. This model is based on a well-accepted and experimentally tested work [12] for practical systems. The primary concern in this research is to determine the optimal fractions of the load to be assigned to each processor such that the total processing time of the entire load is a minimum. To achieve this objective, many researchers propose many strategies to tackle the problems in different environments. The monograph [2] systematically shows a useful set of extensive research results. The closed-form solutions of the optimal processing time are derived for the linear daisy chain, bus networks and the tree networks	central processing unit;clock rate;computation;daisy digital talking book;dlt;daisy chain (electrical engineering);distributed computing;experiment;fault tolerance;heterogeneous computing;image processing;indivisible;mathematical model;multi-level cell;multiprocessing;programming paradigm;requirement;scheduling (computing);supercomputer;time complexity	Xiaolin Li;Bharadwaj Veeravalli;Chi Chung Ko	2000	IEEE Trans. Aerospace and Electronic Systems	10.1109/7.892677	fair-share scheduling;closed-form expression;parallel computing;real-time computing;directed graph;dynamic priority scheduling;resource allocation;computer science;rate-monotonic scheduling;weight distribution;two-level scheduling;mathematics;distributed computing;iterative method	HPC	-13.486264429155847	60.98356062607899	56583
293ef0e832dfd8bf574b7e2483ab43b63950fa94	availability modeling and evaluation of cloud virtual data centers	cloud computing;computer centres;quality of service;stochastic processes;virtual reality;virtualisation;qos factors;san model;vdc;cloud computing;cloud providers;cloud virtual data centers;infrastructure-as-a-service providers;service availability modeling;service delivery;service level agreements;stochastic activity network;virtualization technology;availability;cloud comput-ing;stochastic activity network;virtual data center	Availability of the service delivered by cloud providers is one of the most important QoS factors of the service level agreements between providers and customers. Since current Infrastructure-as-a-Service providers use virtualization technology to manage data centers, virtual data centers (VDCs) have become a popular infrastructure for cloud computing. In order to study the service availability, a stochastic activity network (SAN) model is presented in this paper. The proposed SAN model can be appropriately used to investigate the impact of different characteristics and policies on service availability of VDCs.	cloud computing;data center;norm (social);service-level agreement;stochastic process;virtual private cloud;x86 virtualization	Mohammad Roohitavaf;Reza Entezari-Maleki;Ali Movaghar-Rahimabadi	2013	2013 International Conference on Parallel and Distributed Systems	10.1109/ICPADS.2013.120	cloud computing security;availability;simulation;quality of service;cloud computing;computer science;operating system;cloud testing;distributed computing;virtual reality;world wide web;computer network	HPC	-23.52350972128314	63.04599712713063	56767
05a966dcc0dc5070c3b51a827d718e62f7047fe4	a family of heuristics for agent-based cloud bag-of-tasks scheduling	protocols;resource management cloud computing processor scheduling contracts proposals protocols;agent based cloud computing;processor scheduling;resource management;scheduling heuristics;contracts;bag of tasks applications;software agents;multi agent systems;scheduling;software agents cloud computing protocols scheduling;proposals;contract net protocol agent based cloud bag of tasks scheduling cloud resource scheduling heuristics task ordering phase task mapping phase;cloud computing;agent based cloud computing scheduling heuristics bag of tasks applications cloud computing multi agent systems	The scheduling of bag-of-tasks applications (BoTs) in Clouds deal with fixed predefined allocation slots of Cloud resources, e.g., 1-hour time slots, that start being exhausted right after their allocation disregarding whether tasks are being executed or not. In addition, Cloud resources may be allocated for several hours to execute BoTs. However, some resource types (e.g., clusters) may be allocated for only a few hours, while others (e.g., CPU instances) may be allocated for several hours, so BoTs may be executed in such heterogeneous sets of Cloud resources (probably) allocated for a different number of hours. In this paper, a family of 15 scheduling heuristics consisting of two phases: (i) task ordering and (ii) task mapping (based on the remaining allocation times of Cloud resources) is proposed. The heuristics aim to maximize resource utilization while executing BoTs in heterogeneous sets of Cloud resources allocated for different numbers of hours. Cloud resources for executing BoTs are dynamically composed by adopting the contract net protocol. In addition, an agent-based testbed for Cloud BoT scheduling and execution was implemented. Simulation results show that the agents are capable of successfully and efficiently scheduling and executing BoTs in sets of Cloud resources composed from multiple Cloud environments.	agent-based model;amazon elastic compute cloud (ec2);central processing unit;cloud computing;contract net protocol;elasticity (data store);experiment;heuristic (computer science);maxima and minima;problem solving;scheduling (computing);simulation;testbed	Octavio Gutiérrez;Kwang Mong Sim	2011	2011 International Conference on Cyber-Enabled Distributed Computing and Knowledge Discovery	10.1109/CyberC.2011.74	communications protocol;real-time computing;cloud computing;computer science;resource management;software agent;operating system;distributed computing;scheduling	HPC	-17.81238207651762	63.171953862129236	56770
457dcfc1fab75e8fe0f1839ecef68a6c74ed9dbf	multiprocessor schedulability analyser	multiprocessor scheduling;satisfiability;schedulability analysis;temporal constraints;hard real time system;periodic tasks;exact algorithm;real time scheduling;fault tolerance;fault resilience;fault burst;pseudo periodic fault	Within the context of hard real-time systems, the schedulability analysis of a task set is a major issue. The problem consists in proving that the tasks always satisfy their temporal constraints for a given scheduling policy and a given platform. Extensive work has been done in the last decades for defining sufficient criteria and exact algorithms. Sufficient criteria usually have an excellent complexity but often lead to an over-dimension of the system. On the opposite, exact algorithms, especially in the case of multiprocessor platform, suffer from an exponential complexity.  In this paper, we study an exact technique: we apply a brute force search combined with a model checker (Uppaal) that determines whether the exploration is complete. We consider periodic tasks which execute on parallel platforms composed of homogeneous processors. Under these hypotheses, we have encoded four policies: fixed task priority, gEDF, gLLF and LLREF. The analyser is user friendly and provides promising performances.	algorithm;brute-force search;central processing unit;differential analyser;model checking;multiprocessing;performance;real-time clock;real-time computing;scheduling (computing);scheduling analysis real-time systems;time complexity;uppaal;usability	Mikel Cordovilla;Frédéric Boniol;Eric Noulard;Claire Pagetti	2011		10.1145/1982185.1982345	fault tolerance;parallel computing;real-time computing;computer science;operating system;distributed computing;multiprocessor scheduling;satisfiability	Embedded	-9.571253578614357	60.72670032072621	56847
8481d51a82ddf300152388bba326d613fbcb942e	infoshare : design and implementation of scalable multimedia signage architecture for wireless ubiquitous environments	digital signage;multimedia systems;future communication systems;distributed systems	Digital signage systems have found many interesting applications in the realms of advertising, entertainment and education. One of the most prevalent challenging issues faced by current Local Area Network (LAN) based Digital signage network architectures is that their difficulty in porting to wireless ubiquitous environments. While popularity of wireless LANs promotes such architectural improvement, Traditional thin/thick client based architectures suffer inefficiency and scalability issues introduced by use of proprietary signage content formats. Use of such content formats to store signage contents is less optimal since it could lead to content redundancy, difficulty in creating, managing signage contents and scalability issues. As a solution for this issue we propose a Smart Client based digital signage architecture that uses XAML (an XML based declarative GUI language) contents for expressing its signage displays. While Smart Clients can better tolerate communication disruptions which are quite frequent in wireless environments, use of XAML based open content format promotes use of simple tools and variety of devices for signage content creation and management over the Internet in a ubiquitous environment. We successfully applied this generic architecture to a prototype digital signage system called Infoshare and report its robustness in withstanding network disruptions. We evaluate the easiness of editing XAML based signage contents by comparing Infoshare with a popular LAN based digital signage system which uses proprietary content formats. We demonstrate scalability of Infoshare signage service in terms of hardware resources by deploying it in different hardware platforms.	signage	Miyuru Dayarathna;Anusha I. Withana;Kazunori Sugiura	2011	Wireless Personal Communications	10.1007/s11277-011-0256-0	computer science;operating system;multimedia;internet privacy;world wide web;computer network	Mobile	-26.53252973985584	76.97516583668873	56915
0842021700ca218eb3945b545785df822ac7d44d	the aftermath of prefix deaggregation	routing protocols;telecommunication traffic internet routing protocols telecommunication network management;telecommunication traffic;routing internet economics monitoring advertising topology;internet;billing information prefix deaggregation interdomain level interdomain ingress traffic customer networks selective advertisements transit traffic bill internet service providers isp bgp routing data;telecommunication network management	Prefix deaggregation is recognized as a steady long-lived phenomenon at the interdomain level, despite its well-known negative effects for the community. The advertisement of more-specific prefixes provides network operators with a fine-grained method to control the interdomain ingress traffic. Moreover, customer networks combining this mechanism with selective advertisements may decrease their monthly transit traffic bill and potentially impact the business of their providers. In this paper, we develop a methodology for Internet Service Providers (ISPs) to monitor new occurrences of prefix deaggregation within their customer base. Moreover, the ISPs can detect on their own when deaggregation may decrease the transit bill of their customer networks. We first examine the ISP's BGP routing data for new cases of prefix deaggregation generated by customers. Then, we check for selective advertisements of the newly generated prefixes using external routing data. We look beyond the incentives for deploying this type of strategy and instead we examine its economic impact. We exemplify the proposed methodology on a complete set of data including routing, traffic, topological and billing information provided by a major Japanese ISP and we discuss the implications of the obtained results.	border gateway protocol;electronic billing;exemplification;expect;file spanning;half-life 2: episode one;inter-domain;marginal model;push technology;relevance;routing table	Andra Lutu;Cristel Pelsser;Marcelo Bagnulo;Kenjiro Cho	2013	Proceedings of the 2013 25th International Teletraffic Congress (ITC)	10.1109/ITC.2013.6662950	the internet;telecommunications;computer science;engineering;routing protocol;computer security;computer network	Networks	-11.245680208110118	78.33025299699848	57024
9a666f258fe7d6add8d6ae4614da12af8e3c0b4a	task scheduling for context minimization in dynamically reconfigurable platforms	reconfigurable computing;dynamic reconfiguration;system performance;embedded system;reconfigurable platform;polynomial time;greedy algorithm;real time system;time to market;product design;task scheduling;optimal algorithm;reconfigurable hardware;real time systems	Dynamically reconfigurable hardware provides useful means to reduce the time-to-prototype and even the time-to-market in product designs. It also offers a good alternative in reconfiguring hardware logics to optimize the system performance. This paper targets an essential issue in reconfigurable computing, i.e., the minimization of configuration contexts. We explore different constraints on the CONTEXT MINIMIZATION problem. When the resulting subproblems are polynomial-time solvable, optimal algorithms are presented.	algorithm;decision problem;greedy algorithm;heuristic;np-completeness;prototype;reconfigurable computing;scheduling (computing);time complexity	Nei-Chiung Perng;Shih-Hao Hung;Chia-Heng Tu	2010	Signal Processing Systems	10.1007/s11265-009-0354-3	parallel computing;real-time computing;reconfigurable computing;computer science;distributed computing;product design	EDA	-6.705506107031786	60.54798912782757	57160
d218300f89b61ead863ef1f7ccf7908f40412948	visual discovery of the correlation between bgp routing and round-trip delay active measurements	visual correlation;information visualization;68r10 graph theory including graph drawing;68m11 internet topics;inter domain routing;network dynamics;active measurement networks;68u35 information systems hypertext navigation interfaces decision support etc	Inter-domain routing data and Internet active probing measurements are two types of information commonly available in huge datasets and subject to extensive, focused analysis. However, the study of the correlation between these two complementary types of information still remains one of the most challenging problems in today’s research in networking. In this paper we describe a metaphor for the visualization of the interplay between the routing information exchanged via BGP and the round-trip delay measurements collected by several geolocated probes. We implemented a prototype based on the above metaphor. Our prototype highlights both the Autonomous System topology and the latency associated with each AS-path over time. Further, it shows how probes are partitioned into clusters associated with each border gateway, based on observed traffic patterns. The resulting visualization allows the user to explore the dynamics of the correlation between the two types of information.	algorithm;autonomous system (internet);border gateway protocol;computer cluster;crossing number (graph theory);inter-domain;interface metaphor;online service provider;prototype;routing;traceroute;usability testing	Giordano Da Lozzo;Giuseppe Di Battista;Claudio Squarcella	2013	Computing	10.1007/s00607-013-0287-3	information visualization;computer science;theoretical computer science;network dynamics;mathematics;distributed computing;world wide web	HPC	-11.13662491689537	78.58532758230535	57326
e590a15180da2e133c0f0f3eadc7841d40331712	scalable internet multicast routing	distribution;distributed network applications;routing protocols;teleconferencing;protocol independent multicast protocol;networks;spine;multicast algorithms;application software;routing;web and internet services;distributed networks;wide area internetworks;tcpip;distributed computing;core based tree protocol;computer networks;conferencing communications;receivers;multicast protocols routing protocols multicast algorithms computer networks distributed computing application software teleconferencing web and internet services tcpip spine;transport protocols;internet;telecommunication network routing;multicast protocols;multicasting;one to many communication;many to many communication;communications protocols;multiparty teleconferencing;sources;pim protocol;multicast routing;scalable internet multicast routing;multicast routing protocol scalable internet multicast routing distributed network applications multiparty teleconferencing one to many communication many to many communication wide area internetworks multicasting ip architecture multicast routing core based tree protocol cbt protocol protocol independent multicast protocol pim protocol;ip architecture;limitations;transport protocols internet teleconferencing telecommunication network routing;multicast routing protocol;telecommunications;cbt protocol	In distributed network applications such as multiparty teleconferencing, users often need to send the same message to several other users. To achieve such one-to-many or many-to-many communication eeciently in wide-area internetworks, it is imperative to support mul-ticast, i.e., concurrent sending of messages from one source to multiple receivers. The current IP architecture for multicast routing, the Core-Based Tree (CBT) protocol, and Protocol Independent Multicast (PIM) protocol have a number of limitations for very large internets. To eliminate their limitations , we propose a new multicast routing protocol, called Scalable Internet Multicast Protocol (SIMP).	core-based trees;imperative programming;internet;many-to-many;multicast;one-to-many (data model);routing	Mehrdad Parsa;J. J. Garcia-Luna-Aceves	1995		10.1109/ICCCN.1995.540115	internet protocol;distribution;wireless routing protocol;communications protocol;routing;enhanced interior gateway routing protocol;application software;real-time computing;multicast;the internet;teleconference;ip multicast;inter-domain;spine;reliable multicast;zone routing protocol;resource reservation protocol;many-to-many;protocol independent multicast;computer science;pragmatic general multicast;internet group management protocol;distributed computing;internet protocol suite;routing protocol;distance vector multicast routing protocol;source-specific multicast;transport layer;virtual router redundancy protocol;xcast;computer network;open shortest path first;multicast address	Networks	-11.923930654072166	76.35421886055623	57431
e371096955197403a2b0cbadfe4bd26859359ca6	a common ontology-based intelligent configuration management model for ip network devices	owl;owl s;ontologies artificial intelligence computer network management configuration management internet ip networks;swrl;ontologies intelligent networks ip networks owl xml technology management artificial intelligence computer network management disaster management information management;null;netconf;ontologies artificial intelligence;snmp;internet;owl s ontology based intelligent configuration management model ip network devices internet snmp netconf network configuration management owl swrl;network configuration;computer network management;ip network devices;network configuration management;ip networks;ontology based intelligent configuration management model;configuration management	As the Internet continues to grow, the tasks of configuration management for IP network devices are becoming more and more difficult. Over the past few years, much effort has been given to improve the deficiency of SNMP in the configuration management scope, but only few have succeeded to be standardized, the famous one of which is Netconf, developed by the IETF. Even the Netconf is still far from its aim to implement the automation of the network configuration. These days, ontology has become a promising technology and it seems that it may be used in the intelligent configuration management scope. This paper first discusses the application of ontology and three related languages (including OWL, SWRL and OWL-S) to intelligence configuration management. A common ontology-based intelligent configuration management model for IP network devices is then presented in the paper. To check the feasibility of this model, the paper also provides a possible scenario	angular defect;configuration management;internet protocol suite;owl-s;semantic web rule language;simple network management protocol;web ontology language	Hui Xu;Debao Xiao	2006	First International Conference on Innovative Computing, Information and Control - Volume I (ICICIC'06)	10.1109/ICICIC.2006.1	the internet;computer science;artificial intelligence;database;configuration management;network management application;simple network management protocol;world wide web;owl-s;computer network	SE	-21.766798310546573	84.61000539377814	57452
6d0e6844b6f913ee814dae9e7b1237dc81caa08e	interaction patterns between p2p content distribution systems and isps	p2p system;protocols;interaction patterns;measurement;p2p systems interaction patterns p2p content distribution systems isp peer to peer content distribution systems application layer protocols protocol stack network efficiency internet service providers peer to peer protocol design;routing;isp;protocol stack;protocol design;p2p;internet service provider;other electrical engineering electronic engineering information engineering;network efficiency;network topology;layered structure;internet;internet service providers;content distribution;peer to peer content distribution systems;interaction pattern;application layer protocols;peer to peer protocol design;annan elektroteknik och elektronik;peer to peer computing routing ip networks protocols measurement network topology internet;ip networks;p2p content distribution systems;peer to peer computing;cross layer;peer to peer;p2p systems;protocols internet peer to peer computing	Peer-to-peer (P2P) content distribution systems are a major source of traffic in the Internet, but the application layer protocols they use are mostly unaware of the underlying network in accordance with the layered structure of the Internet's protocol stack. Nevertheless, the need for improved network efficiency and the business interests of Internet service providers (ISPs) are both strong drivers toward a cross-layer approach in peer-to-peer protocol design, calling for P2P systems that would in some way interact with the ISPs. Recent research shows that the interaction, which can rely on information provided by both parties, can be mutually beneficial. In this article we first give an overview of the kinds of information that could potentially be exchanged between the P2P systems and the ISPs, and discuss their usefulness and the ease of obtaining and exchanging them. We also present a classification of the possible approaches for interaction based on the level of involvement of the ISPs and the P2P systems, and we discuss the potential strengths and the weaknesses of these approaches.	communications protocol;digital distribution;internet;peer-to-peer;protocol stack	György Dán;Tobias Hoßfeld;Simon Oechsner;Piotr Cholda;Rafal Stankiewicz;Ioanna Papafili;George D. Stamoulis	2011	IEEE Communications Magazine	10.1109/MCOM.2011.5762821	communications protocol;routing;the internet;computer science;peer-to-peer;application layer;distributed computing;world wide web;protocol stack;network topology;measurement;computer network	Networks	-26.8211982499146	83.57064076571984	57608
0159ef376e2cb6ed1b64cea3eaf22d16b8a71be8	optimal resource allocation for survivable virtual infrastructures	indium phosphide;measurement;resource management;servers;virtual machines cloud computing integer programming linear programming resource allocation;linear programming;bandwidth;cloud computing optimal resource allocation survivable virtual infrastructures dynamic provisioning virtual machines virtual links infrastructure providers inp vi survivability substrate fragmentation mixed integer linear programming;substrates resource management measurement indium phosphide servers bandwidth linear programming;substrates	Virtual infrastructures (VIs) consolidated the dynamic provisioning of computing and communication resources. A VI is a set of virtual machines interconnected by virtual links and switches/routers. Infrastructure providers (InPs) manage the physical substrates in which virtual resources requested by VIs (such as CPU, disk, memory, bandwidth) are reserved and allocated. Resource allocation is a complex problem that needs to satisfy different goals: users expect to run their applications on survivable VIs, while InPs aim to maximize profits, minimize costs and reduce substrate fragmentation. However, there is a dichotomy between minimizing substrate fragmentation, by co-locating VIs, and maximizing VI survivability, by sparsely allocating resources in order to decrease the impact of substrate failures. In this context, this paper discusses VI survivability and its impact on substrate fragmentation. We propose a mixed integer linear programming model to allocate resources considering the joint coordination of fragmentation and survivability. Experimental results suggest that it is possible to enhance VI survivability without significantly impacting substrate fragmentation.	central processing unit;fork (software development);fragmentation (computing);heuristic (computer science);integer programming;linear programming;network switch;programming model;provisioning;router (computing);time complexity;virtual machine	Gustavo A. de S. Cavalcanti;Rafael R. Obelheiro;Guilherme Piegas Koslovski	2014	2014 10th International Conference on the Design of Reliable Communication Networks (DRCN)	10.1109/DRCN.2014.6816146	mathematical optimization;real-time computing;computer science;linear programming;resource management;distributed computing;bandwidth;server;measurement;statistics;computer network	HPC	-21.108653445115948	63.42214128811448	57642
e43f2d00378ed1ee7f5f1bf6f87c2abc79a254e0	high-efficiency urban traffic management in context-aware computing and 5g communication	servers computer architecture urban areas 5g mobile communication real time systems sensors road traffic traffic management mobile communication edge computing;vehicular ad hoc networks 5g mobile communication mobile computing road traffic traffic engineering computing;servers computer architecture vehicles 5g mobile communication real time systems sensors;traffic lights control high efficiency urban traffic management context aware computing 5g communication vanet software defined networks mobile edge computing vehicle localization data prefetching	With the increasing number of vehicle and traffic jams, urban traffic management is becoming a serious issue. In this article, we propose novel four-tier architecture for urban traffic management with the convergence of VANETs, 5G networks, software-defined networks, and mobile edge computing technologies. The proposed architecture provides better communication and more rapid responsive speed in a more distributed and dynamic manner. The practical case of rapid accident rescue can significantly shorten the rescue time. Key technologies with respect to vehicle localization, data pre-fetching, traffic lights control, and traffic prediction are also discussed. Obviously, the novel architecture shows noteworthy potential for alleviating traffic congestion and improving the efficiency of urban traffic management.	edge computing;multitier architecture;network congestion	Jianqi Liu;Jiafu Wan;Dongyao Jia;Bi Zeng;Di Li;Ching-Hsien Hsu;Haibo Chen	2017	IEEE Communications Magazine	10.1109/MCOM.2017.1600371CM	traffic generation model;embedded system;traffic engineering;floating car data;vehicle information and communication system;mobile computing;traffic shaping;computer security;advanced traffic management system;computer network	Mobile	-19.405372389059504	79.55643642730108	57678
5f8c21a2e6c05dec228d6505af87dd4ca3576d9c	survey and challenges of qoe management issues in wireless networks		With the move towards converged all-IP wireless network environments, managing end-user Quality of Experience (QoE) poses a challenging task, aimed at meeting high user expectations and requirements regarding reliable and cost-effective communication, access to any service, anytime and anywhere, and across multiple operator domains. In this paper, we give a survey of state-ofthe-art research activities addressing the field of QoE management, focusing in particular on the domain of wireless networks and addressing three management aspects: QoE modeling, monitoring and measurement, and adaptation and optimization. Furthermore, we identify and discuss the key aspects and challenges that need to be considered when conducting research in this area.		Sabina Barakovic;Lea Skorin-Kapov	2013	Journal Comp. Netw. and Communic.	10.1155/2013/165146	simulation;engineering;knowledge management;management science	Mobile	-15.511453439067793	86.76119068131081	57722
8b02c9b53984d7783af87557d24df0dbbea820e6	an analysis of the extracted parts of opte internet topology		The paper defines a method to extract a part of a graph, which corresponding to a network (Internet) topology covering a certain area. The method refers to data gathered within Opte Project and describing the Internet topology. The extracted parts of graphs have been analyzed in terms of the number of neighbours, longest path length and existence of cycles. Then the resulting topologies are used to model transient behaviour of wide area networks with the use of fluid-flow approximation.	internet topology	Monika Nycz;Tomasz Nycz;Tadeusz Czachórski	2015		10.1007/978-3-319-19419-6_35	the internet;computer network;opte project;longest path problem;internet topology;network topology;computer science;graph	ECom	-9.360646677431863	77.99768940676564	57724
8f91fbbcb9ef3ea959aec4580215693505b84e1c	system level energy aware co-synthesis for distributed embedded real time systems			embedded system	Amjad Mohsen	2006				EDA	-5.653312676585909	60.90512884854563	57745
6e6dfccb81f910cf3544a17f63596089c9434177	pf_key key management api, version 2		A generic key management API that can be used not only for IP Security [Atk95a] [Atk95b] [Atk95c] but also for other network security services is presented in this document. Version 1 of this API was implemented inside 4.4-Lite BSD as part of the U. S. Naval Research Laboratory's freely distributable and usable IPv6 and IPsec implementation[AMPMC96]. It is documented here for the benefit of others who might also adopt and use the API, thus providing increased portability of key management applications (e.g. a manual keying application, an ISAKMP daemon, a GKMP daemon [HM97a][HM97b], a Photuris daemon, or a SKIP certificate discovery protocol daemon).	application programming interface;key management	Daniel L. McDonald;Craig Metz;Bao Phan	1998	RFC	10.17487/RFC2367	computer science;operating system;database;computer security	Theory	-26.446112068081863	87.35099440687407	57772
182d462131f68dfbf577f5256632d35f10e4fde2	offline routing and wavelength assignment for identification of regeneration sites in translucent wdm optical networks		The enormous data carrying capacity and speed of optical WDM networks, have made it an obvious choice for voluminous and high speed data communication. The optical signal can only propagate up to a certain distance (optical reach) retaining its characteristics. Before its quality starts to degrade below a threshold level, it needs to be re-amplified, re-shaped and re-timed using a 3R-regenerator. In this paper, we propose an offline scheme of Routing and Wavelength Assignment (RWA) of connection requests to reduce the number of regeneration sites in a translucent optical network to the extent possible. We compare the performance by of our algorithm with that of an Integer Linear Program (ILP) formulation. We compare the number of regeneration sites computed and channel capacity required for satisfying a given traffic matrix. Performance comparisons show that our algorithm RWA-MRS (RWA to Minimize Regeneration Sites) is able to provide near optimal solution in polynomial time.	algorithm;channel capacity;linear programming;minimal recursion semantics;online and offline;optical communications repeater;polynomial;routing and wavelength assignment;time complexity;wavelength-division multiplexing	Marichi Agarwal;Monish Chatterjee;Saravanan Chandran	2017	2017 International Conference on Advances in Computing, Communications and Informatics (ICACCI)	10.1109/ICACCI.2017.8125910	control engineering;time complexity;optical fiber;computer science;computer network;repeater;wavelength-division multiplexing;matrix (mathematics);linear programming;routing and wavelength assignment;channel capacity	Theory	-5.376400922453369	81.32802006298526	57949
cb9e5fb860f9a22a94ac723ccfd6bb54422d4447	replica placement in cloud through simple stochastic model predictive control	stochastic processes cloud computing contracts optimisation predictive control;optimization mathematical model time factors resource management hardware equations queueing analysis;optimization algorithm replica placement cloud computing stochastic model predictive control optimal service placement osp service level agreements sla administrator preferences objective function;mathematical programming;mathematical programming performance analysis queueing analysis;performance analysis;queueing analysis	This paper presents a model and an algorithm for optimal service placement (OSP) of a set of N-tier software systems, subject to dynamic changes in the workload, Service Level Agreements (SLA), and administrator preferences. The objective function models the resources' cost, the service level agreements and the trashing cost. The optimization algorithm is predictive: its allocation or reallocation decisions are based not only on the current metrics but also on predicted evolution of the system. The solution of the optimization, in each step, is a set some service replicas to be added or removed from the available hosts. These deployment changes are optimal with regards to overall objectives defined over time. In addition, the optimization considers the restrictions imposed on the number of possible service migrations at each time interval. We present experimental results that show the effectiveness of our approach.	algorithm;experiment;loss function;mathematical optimization;multitier architecture;network switch;optimization problem;programming paradigm;service-level agreement;social inequality;software deployment;software system;stepwise regression	Hamoun Ghanbari;Marin Litoiu;Przemyslaw Pawluk;Cornel Barna	2014	2014 IEEE 7th International Conference on Cloud Computing	10.1109/CLOUD.2014.21	real-time computing;simulation;computer science;operating system	EDA	-22.668603475971967	63.43553013263413	58007
9a821640c9cd6d05767f2739223e1234ccbed00e	a hybrid topology architecture for p2p file sharing systems	distributed system;data sharing;p2p;content distribution;overlay network;file sharing;p2p networks;peer to peer;network congestion;application layer multicast	Over the Internet today, there has been much interest in emerging Peer-to-Peer (P2P) networks because they provide a good substrate for creating data sharing, content distribution, and application layer multicast applications. There are two classes of P2P overlay networks: structured and unstructured. Structured networks can efficiently locate items, but the searching process is not user friendly. Conversely, unstructured networks have efficient mechanisms to search for a content, but the lookup process does not take advantage of the distributed system nature. In this paper, we propose a hybrid structured and unstructured topology in order to take advantages of both kind of networks. In addition, our proposal guarantees that if a content is at any place in the network, it will be reachable with probability one. Simulation results show that the behaviour of the network is stable and that the network distributes the contents efficiently to avoid network congestion.	digital distribution;discontinuous galerkin method;distributed computing;déjà vu;file sharing;iteration;lookup table;multicast;network congestion;network topology;overlay network;peer-to-peer;simulation;usability	Juan Pedro Muñoz-Gea;Josemaria Malgosa-Sanahuja;Pilar Manzanares-Lopez;Juan Carlos Sánchez-Aarnoutse;Antonio M. Guirado-Puerta	2006		10.1007/978-3-540-70621-2_18	overlay network;computer science;peer-to-peer;database;distributed computing;network congestion;world wide web;file sharing;computer network	Metrics	-13.356284020359757	74.44200407922747	58051
948862d3bb655c514c80535b4f85f978d5ac06cd	monitoring elastically adaptive multi-cloud services	cloud computing monitoring elasticity measurement topology servers runtime;application monitoring cloud computing elasticity resource provisioning cloud monitoring	Automatic resource provisioning is a challenging and complex task. It requires for applications, services and underlying platforms to be continuously monitored at multiple levels and time intervals. The complex nature of this task lays in the ability of the monitoring system to automatically detect runtime configurations in a cloud service due to elasticity action enforcement. Moreover, with the adoption of open cloud standards and library stacks, cloud consumers are now able to migrate their applications or even distribute them across multiple cloud domains. However, current cloud monitoring tools are either bounded to specific cloud platforms or limit their portability to provide elasticity support. In this article, we describe the challenges when monitoring elastically adaptive multi-cloud services. We then introduce a novel automated, modular, multi-layer and portable cloud monitoring framework. Experiments on multiple clouds and real-life applications show that our framework is capable of automatically adapting when elasticity actions are enforced to either the cloud service or to the monitoring topology. Furthermore, it is recoverable from faults introduced in the monitoring configuration with proven scalability and low runtime footprint. Most importantly, our framework is able to reduce network traffic by 41 percent, and consequently the monitoring cost, which is both billable and noticeable in large-scale multi-cloud services.	adaptive filter;aggregate data;application lifecycle management;cloud computing;cluster analysis;computation;eclipse;elasticity (cloud computing);elasticity (data store);experiment;fault tolerance;high- and low-level;interoperability;layer (electronics);network traffic control;overhead (computing);platform as a service;provisioning;publish–subscribe pattern;real life;run time (program lifecycle phase);sampling (signal processing);scalability;schedule (computer science);sensor;software deployment;software portability	Demetris Trihinas;George Pallis;Marios D. Dikaiakos	2018	IEEE Transactions on Cloud Computing	10.1109/TCC.2015.2511760	real-time computing;scalability;computer science;cloud computing;cloud testing;modular design;distributed computing;provisioning;enforcement;software portability;server	OS	-27.62144776860137	60.64160915276977	58110
a58820b1ecab556b04fff16ae6f50b57eb261dba	efficient and adaptive web replication using content clustering	content distribution network;file servers;network topology adaptive web replication content distribution networks hosting services web content providers content clustering cooperative pushing update traffic replication traffic cdn nodes trace driven simulation websites fine grained replication web server traces performance evaluation cluster based replication url based scheme computation cost management cost users access patterns offline incremental clustering online incremental clustering access history hyperlink structure re clustering overhead document availability;indexing terms;network topology;telecommunication traffic;internet;web sites;number of clusters;network topology internet web sites file servers replicated databases telecommunication traffic digital simulation;computational efficiency telecommunication traffic traffic control uniform resource locators delay topology web server history costs availability;trace driven simulation;replicated databases;digital simulation;flash crowds	Recently there has been an increasing deployment of content distribution networks (CDNs) that offer hosting services to Web content providers. In this paper, we first compare the uncooperative pulling of Web contents used by commercial CDNs with the cooperative pushing. Our results show that the latt er can achieve comparable users’ perceived performance with o nly 4 5% of replication and update traffic compared to the former scheme. Therefore we explore how to efficiently push content to CDN nodes. Using trace-driven simulation, we show that replicating content in units of URLs can yield 60 70% reduction in clients’ latency, compared to replicating in units of Websites. However, it is very expensive to perform such a fine-grained replication. To address this issue, we propose to replicate content in units of clusters, each containing objects which are likelyto be requested by clients that are topologically close. To thi s end, we describe three clustering techniques, and use vario us topologies and several large Web server traces to evaluate t heir performance. Our results show that the cluster-based repli cation achieves performance close to that of the URL-based scheme, but only at 1% 2% of computation and management cost. In addition, by adjusting the number of clusters, we can smooth ly trade off management and computation cost for better client performance. To adapt to changes in users’ access patterns, we also explor e incremental clustering that adaptively adds new documentsto the existing content clusters. We examine both offline and on li e incremental clustering, where the former assumes access hi story is available while the latter predicts access pattern basedon the hyperlink structure. Our results show that the offline clustering yields close to the performance of the complete re-clusteri ng at much lower overhead. The online incremental clustering and replication cut down the retrieval cost by 4.6 8 times compa red to no replication and random replication, so it is especiall y useful to improve document availability during flash crowds.	adobe flash;cluster analysis;computation;content delivery network;digital distribution;hyperlink;network topology;online and offline;overhead (computing);perceived performance;scalability;self-replicating machine;self-replication;server (computing);simulation;smoothing;software deployment;tracing (software);variometer;web content;web server;world wide web	Yan Chen;Lili Qiu;Weiyu Chen;Luan Nguyen;Randy H. Katz	2003	IEEE Journal on Selected Areas in Communications	10.1109/JSAC.2003.814608	file server;the internet;index term;computer science;database;internet privacy;world wide web;network topology;computer network	Web+IR	-18.046325774666727	70.47571118466527	58111
904d3a2fca615d23648533170042f0a983d3313f	a comparative analysis of transition mechanisms for ipv6/ipv4 routing environment	internet protocol;systeme temps reel;comparative analysis;information access;access protocol;routage reseau;network routing;computer network;reseau informatique;acces information;real time system;acceso informacion;sistema tiempo real;information system;protocole acces;routing protocol;acceso protocolo;systeme information;sistema informacion	This paper introduces an analysis for IPv6/IPv4 routed protocols on different transition mechanisms named IPv4 compatibility mechanisms that can be implemented by IPv6 hosts and routers. These mechanisms include providing complete implementations of both versions of the Internet Protocol (IPv4 and IPv6), and tunneling IPv6 packets over IPv4 routing infrastructures. They are designed to allow IPv6 nodes to maintain complete compatibility with IPv4, which should greatly simplify the deployment of IPv6 in the Internet, and facilitate the eventual transition of the entire Internet to IPv6.	routing	Waleed Hosny;Tarek Kamel;Samir I. Shaheen	1999		10.1007/978-3-540-46652-9_34	internet protocol;qualitative comparative analysis;routing;real-time operating system;telecommunications;computer science;routing protocol;computer security;information system;computer network	ECom	-4.7060259548165355	76.27031873297426	58137
08a84756f7df076b0abb25f529f3a0e3edace712	optimize auction bandwidth in content centric network with provider portal for application	telecommunication traffic peer to peer computing;portals;auction bandwidth;content centric network;auction bandwidth content centric network;peer to peer protocol auction bandwidth optimization content centric network provider portal for application ccn backbone traffic p4p transmission bandwidth path seeder hybrid content distribution network hcdn file downloads;servers;content distribution networks;bandwidth;ip networks;peer to peer computing;cloud computing;bandwidth servers peer to peer computing ip networks portals cloud computing content distribution networks	About 5 years ago Content Centric Network (CCN) has a role in the communication on diverse devices which had made bandwidth in backbone traffic was rapidly increasing until now, there was a problem in CCN number of users and devices is connected in network increases. We thus propose a new technique to manage bandwidth between backbone traffic and Content Centric Network that combined the concept of Provider Portal for Application (P4P) to managed bandwidth accordingly which measurably number of seed and speed of download time. When we demonstrate transfer some content on simulate network available transmission bandwidth path in auction algorithm to get information for the best path and counting seeder that occur at different times, we found the number of seeder in optimize Content Centric Network was increases more than native Content Centric Network and Hybrid Content Distribution Network (HCDN). The result of demonstrate that implement in CCN has resilient and performance with file downloads are increasing more than native content centric network (CCN) in number of seeders.	auction algorithm;content delivery network;cyclomatic complexity;digital distribution;download;internet backbone;simulation	Wisarut Suesuwan;Woraphon Lilakiatsakun	2015	2015 IEEE 29th International Conference on Advanced Information Networking and Applications Workshops	10.1109/WAINA.2015.125	multi-frequency network;network traffic control;cloud computing;computer science;operating system;distributed computing;world wide web;bandwidth;server;computer network	Metrics	-16.481647887868924	74.94612894159188	58173
c71ed288ac1683e1941d91746264420f63fefefc	high performance load balancing schemes for cluster based secure web server	resource utilization;back end forwarding;secure web clusters;ssl session;load balancing;load balance;high performance;session migration	Load Balancing is a technique of spreading the single computer's work between two or more computers or other resources in order to get optimal resource utilization, maximized throughput and minimized response time. The main focus of our survey is, determining the problems faced while Load balancing in clustered web servers and identifying a solution. We present a broad classification of Load Balancing Schemes based on two elements: Inter and Intra Cluster, Secure and Non Secure Clustered. While designing the most efficient load balancing scheme, the notification of various problems that can occur in clustered networks are of great help.	computer;load balancing (computing);response time (technology);server (computing);throughput;web server	R. Muley;M. Chatterjee	2010		10.1145/1741906.1742018	network load balancing;round-robin dns;network load balancing services;real-time computing;computer science;load balancing;distributed computing;computer network	Metrics	-17.446241540567115	67.69687109682644	58229
36dd951c59aede93c92cc3dc4073712454ada651	network design with grooming constraints	network design;column generation	Networks are physically and logically decomposed into layers with different technological features. Often, the routing of a demand through a non-multiplexing layer is made by grooming several demands at another, multiplexing-capable layer, thus using less capacity on the former but more on the latter. The problem of designing such a multi-layer network so as to route a set of traffic demands can be solved by embedding multiplexing into a well-suited model. We restrict to a two-layer problem as this is most common in today’s network world, then we represent grooming through a model based on paths and semi-paths, and propose a row-column generation approach to solve a set of problems on real-world large networks.	column generation;layer (electronics);multiplexing;routing;semiconductor industry	Pietro Belotti;Federico Malucelli	2004	Electronic Notes in Discrete Mathematics	10.1016/j.endm.2004.03.013	column generation;mathematical optimization;network planning and design;simulation;traffic grooming;mathematics;distributed computing		-7.591140380983906	83.66365308006354	58244
f35d016ced9c443304ed7d67d0e0a4dd50ccfc30	service composition based on niching particle swarm optimization in service overlay networks	multi constraint optimal service composition path;service composition;son;niching technique;particle swarm optimization	Service oriented architecture (SOA) lends itself to model the application components to coarse-grained services in such a way that the composition of different services could be feasible. Service composition fulfills numerous service requirements by constructing composite applications with various services. As it is the case in many real-world applications, different users have diverse QoS demands issuing for composite applications. In this paper, we present a service composition framework for a typical service overlay network (SON) considering both multiple QoS constraints and load balancing factors. Moreover, a service selection algorithm based on niching technique and particle swarm optimization (PSO) is proposed for the service composition problem. It supports optimization problems with multiple constraints and objective functions, whether linear or nonlinear. Simulation results show that the proposed algorithm results in an acceptable level of efficiency regarding the service composition objective under different circumstances.	particle swarm optimization	Jianxin Liao;Yang Liu;Jingyu Wang;Xiaomin Zhu	2012	TIIS	10.3837/tiis.2012.04.009	mathematical optimization;simulation;computer science;distributed computing;particle swarm optimization	HPC	-19.841842391148926	65.09769327731362	58278
24283fc82eceeace267e6271af1b4d484dc68236	topology-aware virtual network embedding to survive multiple node failures	indium phosphide;topology;virtualization;business;failure recovery network virtualization survivable virtual network embedding topology awareness;linear programming;telecommunication network reliability resource allocation;bandwidth;infrastructure provider multiple node failures survivable virtual network embedding svne single node failure assumption maximum resource sharing topology aware vn embedding approach substrate node failures potential failover choices recoverability based embedding algorithm profit driven remapping algorithm rational resource allocation long term business profit;substrates indium phosphide bandwidth business topology virtualization linear programming;substrates	Survivable virtual network embedding (SVNE) aims at embedding a virtual network (VN) in a way, that after being affected by substrate failures, the VN is still operating. Based on the single node failure assumption, that at any time there can be at most one failed substrate node, the existing studies for the SVNE against substrate node failures back up VNs with a maximum resource sharing. However, multiple node failures do happen in reality, thus those methods are not always effective. In this paper, we propose a topology-aware VN embedding approach to enhancing the survivability against multiple node failures. We make use of the topology attributes to provide each substrate node with multiple potential failover choices, based on which a recoverability-based VN embedding algorithm and a profit-driven VN remapping algorithm are presented. Simulation results show that the proposed approach can achieve rational resource allocation and effectively increase the long term business profit to the infrastructure provider.	algorithm;backup;failover;serializability;simulation;virtual private network	Ailing Xiao;Ying Wang;Luoming Meng;Xuesong Qiu;Wenjing Li	2014	2014 IEEE Global Communications Conference	10.1109/GLOCOM.2014.7037073	real-time computing;virtualization;computer science;linear programming;operating system;distributed computing;bandwidth;computer network	Metrics	-10.663593066123966	81.47144131137107	58279
7d67d22528324cd0638cdb7210b05764935f90ea	flow-and-vm migration for optimizing throughput and energy in sdn-based cloud datacenter	dynamic reroute algorithm flow and vm migration solution throughput optimization energy optimization sdn based cloud data center energy consumption minimization data centers cloud operators traffic aware flow migration fm software defined network dendist fm topology information traffic load reduction eta vmm virtual machines;topology;frequency modulation;routing;computer networks;computer centres;network topology;power aware computing;telecommunication traffic;telecommunication network routing;virtual machines;energy consumption;proceedings paper;telecommunication network topology;virtual machines cloud computing computer centres computer networks power aware computing telecommunication network routing telecommunication network topology telecommunication traffic;routing throughput frequency modulation topology network topology energy consumption cloud computing;cloud computing;throughput	Minimizing energy consumption and improving performance in data centers are critical to cost-saving for cloud operators, but traditionally, these two optimization objectives are treated separately. Therefore, this paper presents an unified solution combining two strategies, flow migration and VM migration, to maximize throughput and minimize energy, simultaneously. Traffic-aware flow migration (FM) is first incorporated in dynamic reroute (DENDIST), evolving into DENDIST-FM, in a software-defined network (SDN) for improving throughput and avoiding congestion. Second, given energy and topology information, VM migration (ETA-VMM) can help reduce traffic loads and meanwhile save energy. Our experimental result indicates that compared to previous works, the proposed method can improve throughput by 42.5% on average with only 2.2% energy overhead. Accordingly, the unified flow-and-VM migration solution has been proven effective for optimizing throughput and energy in SDN-based cloud data centers.	algorithm;cloud computing;data center;experiment;fm broadcasting;hypervisor;mathematical optimization;network congestion;operating system;optimizing compiler;overhead (computing);routing;software-defined networking;throughput;virtual machine manager;z/vm	Wei-Chu Lin;Chien-Hui Liao;Kuan-Tsen Kuo;Charles H.-P. Wen	2013	2013 IEEE 5th International Conference on Cloud Computing Technology and Science	10.1109/CloudCom.2013.35	frequency modulation;routing;throughput;real-time computing;cloud computing;computer science;virtual machine;operating system;distributed computing;network topology;computer network	HPC	-10.572274767384451	82.1989387702119	58326
9681cb29cb8815345bd82966590da50b536ea9d0	ralba: a computation-aware load balancing scheduler for cloud computing		Cloud computing serves as a platform for remote users to utilize the heterogeneous resources in data-centers to compute High-Performance Computing jobs. The physical resources are virtualized in Cloud to entertain user services employing Virtual Machines (VMs). Job scheduling is deemed as a quintessential part of Cloud and efficient utilization of VMs by Cloud Service Providers demands an optimal job scheduling heuristic. An ideal scheduling heuristic should be efficient, fair, and starvation-free to produce a reduced makespan with improved resource utilization. However, static heuristics often lead to inefficient and poor resource utilization in the Cloud. An idle and underutilized host machine in Cloud still consumes up to 70% of the energy required by an active machine (Ray, in Indian J Comput Sci Eng 1(4):333–339, 2012). Consequently, it demands a load-balanced distribution of workload to achieve optimal resource utilization in Cloud. Existing Cloud scheduling heuristics such as Min–Min, Max–Min, and Sufferage distribute workloads among VMs based on minimum job completion time that ultimately causes a load imbalance. In this paper, a novel Resource-Aware Load Balancing Algorithm (RALBA) is presented to ensure a balanced distribution of workload based on computation capabilities of VMs. The RABLA framework comprises of two phases: (1) scheduling based on computing capabilities of VMs, and (2) the VM with earliest finish time is selected for jobs mapping. The outcomes of the RALBA have revealed that it provides substantial improvement against traditional heuristics regarding makespan, resource utilization, and throughput.	algorithm;cloud computing;computation;fault tolerance;heuristic (computer science);hypervisor;job scheduler;job stream;load balancing (computing);makespan;maxima and minima;mobile data terminal;rapid refresh;scheduling (computing);throughput	Altaf Hussain;Muhammad Aleem;Abid Khan;Muhammad Azhar Iqbal;Muhammad Arshad Islam	2018	Cluster Computing	10.1007/s10586-018-2414-6	real-time computing;distributed computing;workload;job scheduler;job shop scheduling;scheduling (computing);cloud computing;load balancing (computing);virtual machine;computer science;heuristics	HPC	-19.610822278102933	62.44084142119014	58386
4a553661b6825d85abb3729a749cd8b49e951c5a	a dynamic scheduling algorithm for large scale multimedia servers	theorie file attente;systeme grande taille;systeme multimedia;queueing theory;large scale system;multimedia systems;serveur reseau;algorithme;algorithm;large scale;network servers;scheduling;ordonamiento;dynamic scheduling algorithm;multimedia server;data placement;ordonnancement;sistema gran escala;dynamic scheduling;admission control;real time systems;algoritmo		algorithm;scheduling (computing)	KyungOh Lee;Heon Young Yeom	1998	Inf. Process. Lett.	10.1016/S0020-0190(98)00168-9	fair-share scheduling;embedded system;real-time computing;dynamic priority scheduling;computer science;rate-monotonic scheduling;operating system;two-level scheduling;queueing theory;scheduling;algorithm;server	HPC	-11.802333670794626	63.21315309316197	58389
8e3eb810909df6f4f0d6dbf00d469fbfa5c39de3	path computation with multiple constraints qos in multi-domain	topology;performance guarantee;path segments;complexity theory;measurement quality of service complexity theory topology additives routing algorithm design and analysis;measurement;routing;exact solution;additives;multiple constraints;telecommunication network routing;multi domain;computational complexity;computational complexity path computation multiple constraints qos path segments;path computation;multiple constraints qos;telecommunication network routing computational complexity quality of service;quality of service;algorithm design and analysis	The interest for providing services with performance guarantees across different connected networks has given new technical solutions allowing the computation of constrained inter-domain paths. Thus, the present paper treats the problem of computing inter-domain paths subject to multiple constraints. We study here existing algorithms for inter-domain computations, and describe new approach approximating exact solutions. Some previous study proposed an exact solution, named pID-MCP, allowing the pre computation of path segments in the domains. We propose a novel algorithm named ID-MCPAA that treats the computational complexity of the problem, can find a feasible path not found by previous solutions and ameliorate existing techniques. Our algorithm is compatible with existing techniques and fulfills the multi constraints requirements after proving the correctness and the complexity of exact solutions, we evaluate by simulation the performance of the algorithm.	approximation algorithm;computation;computational complexity theory;correctness (computer science);http 404;id-wsf;inter-domain;quality of service;requirement;simulation	Wajih Amari;Ridha Gadhgadhi;Asma Ben Letaifa;Sami Tabbane	2010	ACS/IEEE International Conference on Computer Systems and Applications - AICCSA 2010	10.1109/AICCSA.2010.5587037	algorithm design;mathematical optimization;routing;quality of service;food additive;computer science;theoretical computer science;distributed computing;computational complexity theory;measurement;computer network	DB	-4.941294108792117	82.68826831172473	58482
cf390482a40242240988ed1f70351a03a15f1b57	scheduling of parallel migration for multiple virtual machines	topology;network topology;servers;bandwidth;program processors;cloud computing	Virtualization technology can readily change the placement of an execution environment, such as a virtual machine (VM), in accordance with the current statuses. To effectively manage system resources in the virtualized infrastructure, the elasticity of a virtualized infrastructure has attracted significant attention for determining on which server VM should be deployed. However, there has been little attention to how long it takes to relocate VMs and in what order VMs migrate. It is difficult to determine the migration order of VMs in consideration of the residual resources of the destination server and network topology. In this paper, we propose two methods for scheduling the parallel migration of multiple VMs to reduce the impact on performance degradation due to VM migrations. We first formulate an integer linear programming (ILP) model to determine the VM migration order. To solve the problem in an acceptable time for large infrastructures, we also design a heuristic method based on dependencies between VM migrations and network bandwidth. Simulation results demonstrate that the heuristic-based method obtained the solutions in a few seconds for the settings with small differences with the optimal solutions obtained from the ILP-based method.	elasticity (cloud computing);elegant degradation;heuristic;integer programming;linear programming;network topology;openvms;scheduling (computing);server (computing);simulation;virtual machine	Koichi Onoue;Satoshi Imai;Naoki Matsuoka	2017	2017 IEEE 31st International Conference on Advanced Information Networking and Applications (AINA)	10.1109/AINA.2017.136	parallel computing;real-time computing;cloud computing;computer science;operating system;database;network topology;bandwidth;server;computer network	HPC	-20.12172615108743	62.7560789425079	58625
a0bc4f1d510de7d4b64efedd2af2c70b6d7080c9	game-theoretic analysis of advance reservation services	servers games random variables analytical models queueing analysis educational institutions	In many services, such as cloud computing, customers have the option to make reservations in advance. However, little is known about the strategic behavior of customers in such systems. In this paper, we use game theory to analyze several models of time-slotted systems in which customers can choose whether or not making an advance reservation of server resources in future time slots. Since neither the provider nor the customers know in advance how many customers will request service in a given slot, the models are analyzed using Poisson games, with decisions made based on statistical information. The games differ in their payment mechanisms, and the main objective is to find which mechanism yields the highest average profit for the provider. Our analysis shows that the highest profit is achieved when advance reservation fees are charged only from customers that are granted service. Furthermore, informing customers about the availability of free servers prior to their decisions do not affect the provider's profit in that case.	autoregressive model;cloud computing;game theory;server (computing);vii	Eran Simhon;David Starobinski	2014	2014 48th Annual Conference on Information Sciences and Systems (CISS)	10.1109/CISS.2014.6814104	computer science	Metrics	-24.03996161265128	63.96688138267703	58633
02e6c4e8ddb1ad6626ed5c1ab15cda8ab9341b5a	multi-layered service orchestration in a multi-domain network environment	ibcn;control systems computer architecture containers abstracts ports computers europe network topology;technology and engineering;virtualisation cloud computing computer centres software prototyping;odl controller multilayered service orchestration multidomain network environment network function virtualization nfv cloud network escape prototyping framework openstack os data center opendaylight	In this demo, we show a novel method to multi-layer service orchestration in a multi-domain network. This method is a basic implementation of the three layered concept with multi-layer orchestration designed by the UNIFY project. A global orchestrator is capable of instantiating service elements, i.e., virtual network functions (VNFs), in separate domains. Dedicated local orchestrators indifferent infrastructure domains are responsible for setting up new VNF instances and configuring the underlying network. Our implementation is based on the ESCAPE prototyping framework and an OpenStack (OS) data center with the OpenDaylight (ODL) controller.	data center;layer (electronics);orchestration (computing)	Attila Csoma;Balázs Sonkoly;Levente Csikor;Felician Németh;András Gulyás;David Jocha;János Elek;Wouter Tavernier;Sahel Sahhaf	2014	2014 Third European Workshop on Software Defined Networks	10.1109/EWSDN.2014.32	embedded system;engineering;operating system;distributed computing	Networks	-17.185434804132516	83.05030772222561	58677
b07e9e3126845593d2821ddcb2d8009e7669002d	polynomial time optimal algorithms for time slot assignment of variable bandwidth systems	minimisation;assignment problem;switching networks;time division multiple access;switched system;polynomials bandwidth switching systems time division multiple access throughput communication system traffic control switches multiplexing telecommunication traffic satellites;polynomials;polynomial time algorithm;telecommunication traffic;computational complexity;polynomial time;fast optimal algorithm polynomial time optimal algorithms time slot assignment variable bandwidth systems minimum length variable bandwidth switching systems polynomial time complexity cv algorithm chalasani and varma algorithm network flow based optimal algorithm np complete problem;time division multiple access minimisation switching networks telecommunication traffic computational complexity polynomials;variable bandwidth switching system;network flow;combinatorial optimization;optimal algorithm	AbstnzctIn this paper, we consider the optimal (i.e., minimum length) time slot assignment problem for variable bandwidth switching systems. Existing algorithms for this problem are known to be pseudo-polynomial. The practical question of finding a fast optimal algorithm, as well as the theoretical question of whether the above problem is NP-complete were left open. We present here a technique to show polynomial time complexity of some time slot assignment algorithms. Such a technique applies to an algorithm proposed by Chalasani and Varma in 1991 (called CV algorithm), as well as to a network flow based optimal algorithm, proposed here for the first time. CV algorithm and the one proposed here are slightly different. Thus, we give an answer to both the above questions, by establishing that the problem is in P, and by showing effective algorithms for it.	algorithm;assignment problem;effective method;electronic switching system;flow network;np-completeness;p (complexity);polynomial;pseudo-polynomial time;time complexity	Piera Barcaccia;Maurizio A. Bonuccelli	1994	IEEE/ACM Trans. Netw.	10.1109/90.311622	time complexity;minimisation;mathematical optimization;combinatorics;flow network;combinatorial optimization;computer science;mathematics;distributed computing;assignment problem;weapon target assignment problem;computational complexity theory;time division multiple access;polynomial	Theory	-5.165332324592329	81.22765601086621	58702
4d3beb97f5f561597f62a0c2078bb0892e6dd941	determining the peer resource contributions in a p2p contract	internet;client-server systems;peer-to-peer computing;p2p contract;p2p file sharing;centralized p2p networks;centralized architecture;decentralized p2p networks;decentralized architecture;file downloads;fixed contract;peer resource contributions;request broadcast;server capacity;time-to-live parameter	In this paper we study a scheme called P2P contract which explicitly specifies the resource contributions that are required from the peers. In particular, we consider a P2P file sharing system in which when a peer downloads the file it is required to serve the file to up to N other peers within a maximum period of time T. We study the behavior of this contribution scheme in both centralized and decentralized P2P networks. In a centralized architecture, new requests are forwarded to a central server which hands out the contract along with a list of peers from where the file can be downloaded. We show that a simple fixed contract (i.e., fixed values of N and T) is sufficient to create the required server capacity which adapts to the load. Furthermore, we show that T, the time part of the contract is a more important control parameter than N. In the case of a decentralized P2P architecture, each new request is broadcast to a certain neighborhood determined by the time-to-live (TTL) parameter. Each server receiving the request independently doles out a contract and the requesting peer chooses the one which is least constraining. If there are no servers in the neighborhood, the request fails. To achieve a good request success ratio, we propose an adaptive scheme to set the contracts without requiring global information. Through both analysis and simulation, we show that the proposed scheme adapts to the load and achieves low request failure rate with high server efficiency.	bandwidth (signal processing);centralized computing;communications protocol;decentralised system;design by contract;failure rate;peer-to-peer file sharing;server (computing);simulation;time to live;transistor–transistor logic	Behrooz Khorashadi;Xin Liu;Dipak Ghosal	2005	Second International Workshop on Hot Topics in Peer-to-Peer Systems	10.1109/PTPSYS.2005.9	computer science;distributed computing;bittorrent tracker;world wide web;server;computer network	Arch	-15.581350772017089	73.46565610149055	58725
0a81727ce21c39e51671f2a8a62ed328d084140e	a mobility-aware dynamic database caching scheme for wireless mobile computing and communications	sra informations och kommunikationsteknik;database system;cache consistency;communication systems;sra ict;invalidation report;mobile computer;mobile database;dynamic data;kommunikationssystem;mobile systems;mobile user	This paper describes a mobility-aware dynamic database caching scheme for wireless mobile computing and communications. A mobile-floating agent scheme is proposed, in which caching techniques are cognizant of the mobile nature of mobile users and the location-sensitive nature of mobile systems. The mobile-floating agent maintains a second class cache in the fixed network and employs Barbara's “invalidation reports broadcasting” cache consistency strategies to maintain a dynamic cache consistent with the first class cache in the mobile client. The “invalidation reports broadcasting” scheme is combined with knowledge of the mobility behavior of each individual mobile user and broadcasts of invalidation reports only occur within the user's mobility area. The evaluation results show that, for a large system (200 cells), this scheme can reduce the system cost by more than 87%, for even highly mobile users, compared with a fully replicated database system.	british undergraduate degree classification;cache (computing);cache coherence;database caching;first-class function;mobile computing;replication (computing)	George Y. Liu;Gerald Q. Maguire	1996	Distributed and Parallel Databases	10.1007/BF00140953	mobile identification number;mobile search;dynamic data;mobile web;mobile database;computer science;cache invalidation;operating system;mobile technology;database;distributed computing;mobile station;mobile computing;cache algorithms;world wide web;communications system	Mobile	-15.579536720005942	68.6698798538078	58796
e13c9098272362a00d1643859218d4019493934a	adaptive resource management in paas platform using feedback control lru algorithm	application development;distributed system;resource utilization;resource management feedback control quality of service heuristic algorithms cloud computing prediction algorithms;web services cloud computing feedback multiprocessing systems quality of service resource allocation three term control;resource allocation;resource manager;resource management;prediction algorithms;service model;feedback;adaptive resource management;infrastructure as a service;three term control;heuristic algorithms;web services;cpu utilization paas platform feedback control lru algorithm flexible dynamic it infrastructure qos guaranteed computing configurable software services quality of service cloud computing saas software as a service paas platform as a service iaas infrastructure as a service application development hosting platform distributed system adaptive resource management algorithm feedback control technique least recently used algorithm;paas;software as a service;multiprocessing systems;quality of service;lru algorithm cloud computing paas resource management feedback control;feedback control;lru algorithm;least recently used;heuristic algorithm;cloud computing	Cloud computing gets more and more popular because of its abilities on offering flexible dynamic IT infrastructure, QoS (Quality of Service) guaranteed computing environments and configurable software services. Cloud computing supports three service models: SaaS (Software as a Service), PaaS (Platform as a Service), and IaaS (Infrastructure as a Service). PaaS provides users with an application development and hosting platform with great reliability, scalability and convenience and it has many advantages in helping customers create applications compared with other service models. However, as a typical distributed system with limited computing resources, PaaS platform has to address the problems of resource management in order to achieve satisfactory QoS as well as efficient resource utilization. This paper presents an adaptive resource management algorithm called Feedback Control LRU (FC-LRU) which integrates the feedback control technique with LRU (Least Recently Used) algorithm. Simulation is conducted to evaluate the performance of FC-LRU and the results demonstrate that FC-LRU achieves satisfactory performance: it enables PaaS platform to maintain a low missed deadline ratio and high CPU utilization under the conditions of multitasks with different workloads.	algorithm;central processing unit;chow–liu tree;cloud computing;coefficient;distributed computing;experiment;feedback;fibre channel;os-tan;pid;platform as a service;pseudo-lru;quality of service;scalability;simulation;software as a service;vii	Rui Hu;Yong Li;Yan Zhang	2011	2011 International Conference on Cloud and Service Computing	10.1109/CSC.2011.6138508	real-time computing;cloud computing;computer science;resource management;feedback;database;distributed computing;cache algorithms	HPC	-23.242848116246062	62.62012146823989	58926
609d3d1faed1ff6b07ad93de6f7d8139bc61baf1	characterization of grid computing resources using measurement-based evaluation		An important factor that needs to be considered by every Grid application end-user and systems (such as schedulers or mediators), during Grid resource selection and mapping to applications, is the performance capacity of hardware resources attached to the Grid, and made available through its Virtual Organizations. In this paper, we represent the performance of a computational Grid as a regression model that can be used to fine-tune the selection of suitable Grid resources. A study on the performance of distributed systems with respect to particular variations in parameters is presented. Our objective is to use a measurement-based evaluation technique to characterize the specific performance contribution of the individual Grid resource configurations. In the process, we identify the key primary parameters (or factors) that should be considered when selecting and allocating a computational node for user application execution.	grid computing	Ezugwu E. Absalom;Marc Frîncu;Sahalu B. Junaidu	2016	Multiagent and Grid Systems	10.3233/MGS-160241	computer science;data grid;distributed computing;management science	HPC	-22.23319886347782	61.461931557008825	58948
40fbd8979b66aebc39166954b8cbcffeda6131ea	delay budget partitioning to maximize network resource usage efficiency	end to end qos;resource utilization;resource utilization efficiency;multiprotocol label switching;multicast communication;path selection;probability;telecommunication links;multicast flow;multicast algorithms;resource allocation;interpath load balancing problem;intrapath load balancing problem;resource management;quality of service propagation delay telecommunication traffic traffic control bandwidth load management multicast algorithms partitioning algorithms aggregates resource management;mpls delay budget partitioning algorithm network resource usage efficiency network flow qos interpath load balancing problem intrapath load balancing problem resource utilization efficiency unicast flow multicast flow delay violation probability bound path link path selection slack partition network path multiprotocol label switching;traffic control;mpls;telecommunication links internet multicast communication multiprotocol label switching probability quality of service resource allocation;network resource usage efficiency;qos;multicast tree;telecommunication traffic;delay violation probability bound;internet;slack partition;aggregates;propagation delay;load management;delay budget partitioning algorithm;bandwidth;network path;simulation study;load balance;network flow;quality of service;end to end delay;unicast flow;path link;partitioning algorithms	Provisioning techniques for network flows with end-to-end QoS guarantees need to address the interpath and intrapath load balancing problems to maximize the resource utilization efficiency. This paper focuses on the intrapath load balancing problem: How to partition the end-to-end QoS requirement of a network flow along the links of a given path such that the deviation in the loads on these links is as small as possible? We propose a new algorithm to solve the end-to-end QoS partitioning problem for unicast and multicast flows that takes into account the loads on the constituent links of the chosen flow path. This algorithm can simultaneously partition multiple end-to-end QoS requirements such as the end-to-end delay and delay violation probability bound. The key concept in our proposal is the notion of slack, which quantifies the extent of flexibility available in partitioning the end-to-end delay requirement across the links of a selected path (or a multicast tree). We show that one can improve network resource usage efficiency by carefully selecting a slack partition that explicitly balances the loads on the underlying links. A detailed simulation study demonstrates that, compared with previous approaches, the proposed delay budget partitioning algorithm can increase the total number of long-term flows that can be provisioned along a network path by up to 1.2 times for deterministic and 2.8 times for statistical delay guarantees	algorithm;end-to-end principle;flow network;fork (software development);global optimization;interaction;load balancing (computing);mathematical optimization;multicast;partition problem;provisioning;quality of service;requirement;routing;simulation;slack variable;unicast	Kartik Gopalan;Tzi-cker Chiueh;Yow-Jian Lin	2004	IEEE INFOCOM 2004	10.1109/INFCOM.2004.1354614	multiprotocol label switching;real-time computing;quality of service;computer science;resource management;distributed computing;network delay;computer network	Embedded	-5.130634342729205	84.03089524319626	59089
20a3e212e21edba242ad70af0ca3c41b200c4a83	motivating smartphone collaboration in data acquisition and distributed computing	databases;google;game theory;game theory incentive mechanisms smartphone collaboration motivate distributed computing applications data acquisition applications massive sensitive data collect reward based collaboration mechanism user private information smartphone computation resources complex computing problems task reward combinations master preference characteristic user type unit cost distribution zero payoff contract theory;collaboration;distributed computing;collaboration data acquisition games computational modeling databases distributed computing google;computational modeling;games;contract theory smartphone application data acquisition distributed computing game theory;contract theory;data acquisition;smartphone application;smart phones contracts data acquisition game theory mobile computing	This paper analyzes and compares different incentive mechanisms for a master to motivate the collaboration of smartphone users on both data acquisition and distributed computing applications. To collect massive sensitive data from users, we propose a reward-based collaboration mechanism, where the master announces a total reward to be shared among collaborators, and the collaboration is successful if there are enough users wanting to collaborate. We show that if the master knows the users' collaboration costs, then he can choose to involve only users with the lowest costs. However, without knowing users' private information, then he needs to offer a larger total reward to attract enough collaborators. Users will benefit from knowing their costs before the data acquisition. Perhaps surprisingly, the master may benefit as the variance of users' cost distribution increases. To utilize smartphones' computation resources to solve complex computing problems, we study how the master can design an optimal contract by specifying different task-reward combinations for different user types. Under complete information, we show that the master involves a user type as long as the master's preference characteristic outweighs that type's unit cost. All collaborators achieve a zero payoff in this case. If the master does not know users' private cost information, however, he will conservatively target at a smaller group of users with small costs, and has to give most benefits to the collaborators.	computation;data acquisition;distributed computing;personally identifiable information;smartphone	Lingjie Duan;Takeshi Kubo;Kohei Sugiyama;Jianwei Huang;Teruyuki Hasegawa;Jean C. Walrand	2014	IEEE Transactions on Mobile Computing	10.1109/TMC.2014.2307327	games;game theory;contract theory;simulation;computer science;knowledge management;operating system;data acquisition;computational model;world wide web;collaboration	HCI	-27.819899958478157	72.50863666901168	59129
9d5b085deb472e13424442925240f931bf228ab3	lightweight boolean network tomography based on partition of managed networks	decentralized management;network monitoring;network partition;link failure localization;set cover problem	Boolean network tomography is a promising technique to achieve fault management in networks where the existing IP-based troubleshooting mechanism cannot be used. Aiming to apply Boolean network tomography to fault management, a variety of heuristic methods for configuring monitoring trails and paths have been proposed to localize link failures in managed networks. However, these existing heuristic methods must be executed in a centralized server that administers the entire managed network and the methods present scalability problems when applied to large-scale managed networks. Thus, this paper proposes a novel scheme for achieving lightweight Boolean network tomography in a decentralized manner. The proposed scheme partitions the managed network into multiple management areas and localizes link failures independently within each area. This paper also proposes a heuristic network partition method with the aim of efficiently implementing the proposed scheme. The effectiveness of the proposed scheme is verified using typical fault management scenarios where all single-link failures and all dual-link failures are localized by the least number of monitoring paths on predetermined routes. Simulation results show that the proposed scheme can greatly reduce the computational load on the fault management server when Boolean network tomography is deployed in large-scale managed networks. Furthermore, the degradation of optimality in the proposed scheme can be mitigated in comparison with a centralized scheme that utilizes heuristics to reduce the computational load on the centralized server.	boolean network;centralized computing;computation;elegant degradation;heuristic (computer science);network partition;scalability;server (computing);simulation;tomography	Nagao Ogino;Takeshi Kitahara;Shin'ichi Arakawa;Go Hasegawa;Masayuki Murata	2017	Journal of Network and Systems Management	10.1007/s10922-017-9416-1	boolean network;scalability;computer network;real-time computing;network partition;distributed computing;computer science;heuristics;network management station;troubleshooting;fault management;network monitoring	Metrics	-8.998201137864152	80.99183111884754	59299
48f9c9d4c5e4356f8a1ef3084b00a3703da654ff	problem statement: overlays for network virtualization		This document describes issues associated with providing multi-tenancy#N#in large data center networks and how these issues may be addressed#N#using an overlay-based network virtualization approach. A key multi-#N#tenancy requirement is traffic isolation so that one tenant's#N#traffic is not visible to any other tenant. Another requirement is#N#address space isolation so that different tenants can use the same#N#address space within different virtual networks. Traffic and address#N#space isolation is achieved by assigning one or more virtual networks#N#to each tenant, where traffic within a virtual network can only cross#N#into another virtual network in a controlled fashion (e.g., via a#N#configured router and/or a security gateway). Additional functionality#N#is required to provision virtual networks, associating a virtual#N#machine's network interface(s) with the appropriate virtual network#N#and maintaining that association as the virtual machine is activated,#N#migrated, and/or deactivated. Use of an overlay-based approach enables#N#scalable deployment on large network infrastructures.		Thomas Narten;Eric Gray;David Black;Luyuan Fang;Lawrence Kreeger;Maria Napierala	2014	RFC	10.17487/RFC7364	full virtualization;temporal isolation among virtual machines;overlay network;virtual address space;engineering;kernel virtual address space;virtual circuit;world wide web;computer security;computer network	NLP	-15.781013273964867	82.31212906192353	59306
aa0db98ec144b7d0996661e51dabd214bde6f129	commodity resource pricing in dynamic computational grids	supply and demand equilibrium commodity resource pricing dynamic computational grids resource management cpu resources;computational grid;pricing;resource manager;resource management;cpu resources;dynamic computational grids;commodity resource pricing;pricing grid computing resource management computational modeling cost accounting mathematics fabrics computer applications computer vision lagrangian functions;grid economics;computational market;market based resource management;market based resource management computational market grid computing grid economics;supply and demand equilibrium;economics;grid computing;pricing economics grid computing;supply and demand	We investigate resource management in computational grids based on an economic perspective. Specifically, we model the grid as a commodity market of CPU resources that are traded at prices determined by the supply-and- demand equilibrium. This approach has been shown to function for small, static grids. We present simulation results to demonstrate it can be extended to grids with a dynamic fabric and large (thousands) number of resources.	algorithm;central processing unit;computational resource;simulation	Khalid Abdelkader;Jan Broeckhove;Kurt Vanmechelen	2008	2008 IEEE/ACS International Conference on Computer Systems and Applications	10.1109/AICCSA.2008.4493568	pricing;resource management;supply and demand;grid computing	HPC	-23.518582825201253	64.89412881760549	59407
bf1fd1427473539242811b8641577cf792249172	higher sla satisfaction in datacenters with continuous vm placement constraints		In a virtualized datacenter, the Service Level Agreement for an application restricts the Virtual Machines (VMs) placement. An algorithm is in charge of maintaining a placement compatible with the stated constraints.  Conventionally, when a placement algorithm computes a schedule of actions to re-arrange the VMs, the constraints ignore the intermediate states of the datacenter to only restrict the resulting placement. This situation may lead to temporary violations of the constraints. In this paper, we discuss the causes of these violations. We then advocate for continuous placement constraints to restrict also the actions schedule. We discuss why their development requires more attention and how the extensible placement algorithm BtrPlace can address this issue.	algorithm;data center;service-level agreement	Huynh Tu Dang;Fabien Hermenier	2013		10.1145/2524224.2524226	embedded system;parallel computing;real-time computing;engineering	EDA	-25.5952498877336	64.7721548727637	59432
4380a63f112fa8f271158776c424eabe74028b3d	on the placement of web replicas in the internet with server capacity constraints			internet;server (computing)	Fathi Tenzakhti	2004				Metrics	-18.950120022829747	72.88103065564557	59518
82772ad0d6e32b8f4049c108229e24b299c5834e	distributed algorithms in service overlay networks: a game theoretic perspective	service overlay network;distributed algorithms intelligent networks game theory peer to peer computing algorithm design and analysis application software ip networks network topology computer networks distributed computing;distributed algorithms;optimisation;game theory;payoff function;application overlay network;application software;distributed computing;computer networks;network topology;theoretical analysis;overlay network;ip networks;optimization;payoff function distributed algorithm service overlay network game theory application overlay network optimization;intelligent networks;peer to peer computing;distributed algorithm;algorithm design and analysis;optimisation distributed algorithms wide area networks ip networks game theory;wide area networks	When designing distributed algorithms for application overlay networks, it is usually assumed that the overlay nodes are cooperative to collectively achieve optimal global performance properties. However, this assumption does not hold in reality, as nodes generally tend to be noncooperative and always attempt to maximize their gains by optimizing their strategies. With such an assumption, we present extensive theoretical analysis to gain insights from a game theoretic perspective, with respect to the behavior of nodes and the equilibrium of the system. The main idea in our analysis is to design appropriate payoff functions, so that the equilibrium of the system may achieve the optimal properties that we desire. Driven by the per-node goal of maximizing gains, such payoff functions naturally lead to distributed algorithms that lead to the desired favorable properties of overlay networks.	distributed algorithm;game theory;overlay network	Jiang Guo;Baochun Li	2004	2004 IEEE International Conference on Communications (IEEE Cat. No.04CH37577)	10.1109/ICC.2004.1312746	algorithm design;distributed algorithm;intelligent network;application software;overlay network;computer science;theoretical computer science;distributed computing;network topology;computer network	Robotics	-9.024009697626209	76.98115157724857	59568
7ad639665c2cecf1da63370e72e7cf4bd254d5d3	false rate analysis of bloom filter replicas in distributed systems	updating protocol false rate analysis distributed bloom filter replicas distributed systems distributed queries;distributed system;protocols;probability;analytical models protocols computer science data structures encoding costs information filtering information filters broadcasting routing;bloom filter;distributed processing;false negative;dynamic environment;system design;data structures;false rate analysis;distributed bloom filter replicas;distributed queries;distributed systems;false positive;protocols data structures distributed processing probability;analytical model;updating protocol	Bloom filters have been widely used in distributed systems where they are replicated to process distributed queries. Bloom filter replicas become stale in a dynamic environment. A good understanding of the impact of staleness on false negatives and false positives can provide the system designers with important insights into the development and deployment of distributed Bloom filters in many distributed systems. To our best knowledge, this paper is the first one that analyzes the probabilities of false negatives and positives by developing analytical models, which take the staleness into consideration. Based on the theoretical analysis, we proposed an updating protocol that directly control the false rate. Extensive simulations validate the analytical models and prove the updating protocol to be very accurate and effective	bloom filter;distributed computing;simulation;software deployment	Yifeng Zhu;Hong Jiang	2006	2006 International Conference on Parallel Processing (ICPP'06)	10.1109/ICPP.2006.42	communications protocol;data structure;type i and type ii errors;computer science;theoretical computer science;bloom filter;probability;database;distributed computing;systems design	HPC	-9.417695045619658	72.64651337074149	59632
3a68f4f03843cfe7cb85cb0c4491c5638c24b9bd	on-the-cloud computing: challenges in controlling cloud resources	computers;educational institutions cloud computing computers humans algorithm design and analysis computer architecture information technology;information technology;computer architecture;humans;algorithm design and analysis;cloud computing	Cloud Computing is defined as a pool of virtualized computer resources deployed and scaled-out quickly through the rapid provisioning of virtual or physical machines. Virtual machine services offered by cloud utility providers led to the creation of the ecosystem of cloud services as they enable customers to use computing resources based on the dynamic behaviour of the application and of the computer resource used. As the control system approach is more and more accepted by the computer research communities the perspective of implementing an adaptive resource provisioning and optimization looked attractive enough for investing efforts and human resources to move it from the theory benches to experimental implementations.	cloud computing;control system;ecosystem;mathematical optimization;provisioning;virtual machine	Dan Ionescu	2012	2012 International Conference on Collaboration Technologies and Systems (CTS)	10.1109/CTS.2012.6261066	cloud computing security;algorithm design;simulation;single-chip cloud computer;cloud computing;computer science;theoretical computer science;operating system;cloud testing;distributed computing;utility computing;information technology;computer security;provisioning	HPC	-25.303638212087268	63.769981880623924	59633
fde49b0068173360df3a7955084f0810c2b5d500	dynamic segment trees for ranges and prefixes	routing protocols;protocols;time complexity;binary search trees;web and internet services;helium;internet protocol version 4;multiway range tree dynamic segment tree tree data structure dynamic table lookup problem binary search tree time complexity routing table internet protocol version 4;b trees;segment tree;multiway range tree;dynamic segment tree;testing;tree data structures;indexing terms;dynamic routing;binary trees;tree data structures internet protocols table lookup telecommunication network routing;elementary intervals;internet;telecommunication network routing;dynamic table lookup problem;tree data structure;binary search tree;data structures;priority queue;web sites;dynamic routing tables;dynamic routing tables segment tree elementary intervals b trees;table lookup;routing table;data structure;binary tree	In this paper, we develop a segment tree data structure for solving dynamic table lookup problems. The proposed dynamic segment tree (DST) uses all of the distinct end points of ranges as the keys based on a new range end point scheme. The new end point scheme generates fewer end points than the traditional end point scheme. DST is implemented as a balanced binary search tree augmented with a range set in each node. The performance of accessing and updating the ranges stored in each node is improved by an efficient range set data structure that combines the priority queue and the interval tree. Based on the proposed data structures, the time complexities of search, insertion, and deletion in a set of N arbitrary ranges are O(log N), O(log N times log Max), and O(Max times log N times log Max), respectively, where Max is the maximum number of ranges covering any address. In practical routing tables, Max is a small constant (six for the routing tables we tested). The memory requirement for DST is O(N log N). The experimental results using real Internet Protocol version 4 (IPv4) routing tables show that both the DST and prefix binary tree on binary tree (PBOB) by Lu et al. (2004) perform much better than the multiway range tree (MRT) by Warkhede et al. (2004) and prefix in B-tree (PIBT) by Lu et al. (2005) in terms of update speed and memory consumption, but DST performs much better than PBOB and a little slower than MRT and PIBT in terms of search speed	b-tree;binary tree;data structure;dynamic array;dynamic range;experiment;interval tree;lu decomposition;lookup table;priority queue;range tree;routing table;segment tree;self-balancing binary search tree;tree (data structure)	Yeim-Kuan Chang;Yung-Chieh Lin	2007	IEEE Transactions on Computers	10.1109/TC.2007.1037	segment tree;binary search tree;data structure;binary tree;computer science;theoretical computer science;range tree;interval tree;distributed computing;tree;programming language;algorithm;computer network	Theory	-5.9946426839109295	67.63411152595835	59648
f838c9de3b93c26048b76dcf005af48446f11325	understanding internet topology: principles, models, and validation	graph theory;routing protocols;network design;heuristically optimal topology;router configuration;statistics internet telecommunication network topology transport protocols routing protocols graph theory;internet topology statistics graph theory bandwidth tcpip protocols constraint theory costs robustness;degree based generators;first principle;network topology;empirical evidence;transport protocols;topology metrics;internet;topology metrics degree based generators heuristically optimal topology network design network topology router configuration;heuristic optimization;statistics;internet topology;telecommunication network topology;network design internet topology router level connectivity graph theory statistics tcp ip protocol stack;caltech library services;article;reverse engineering	Building on a recent effort that combines a first-principles approach to modeling router-level connectivity with a more pragmatic use of statistics and graph theory, we show in this paper that for the Internet, an improved understanding of its physical infrastructure is possible by viewing the physical connectivity as an annotated graph that delivers raw connectivity and bandwidth to the upper layers in the TCP/IP protocol stack, subject to practical constraints (e.g., router technology) and economic considerations (e.g., link costs). More importantly, by relying on data from Abilene, a Tier-1 ISP, and the Rocketfuel project, we provide empirical evidence in support of the proposed approach and its consistency with networking reality. To illustrate its utility, we: 1) show that our approach provides insight into the origin of high variability in measured or inferred router-level maps; 2) demonstrate that it easily accommodates the incorporation of additional objectives of network design (e.g., robustness to router failure); and 3) discuss how it complements ongoing community efforts to reverse-engineer the Internet.	abilene paradox;graph theory;internet protocol suite;internet topology;map;network planning and design;protocol stack;reverse engineering;router (computing);spatial variability;tier 1 network	David L. Alderson;Lun Li;Walter Willinger;John Doyle	2005	IEEE/ACM Transactions on Networking	10.1109/TNET.2005.861250	network planning and design;the internet;internet topology;empirical evidence;first principle;computer science;graph theory;theoretical computer science;distributed computing;routing protocol;transport layer;network topology;reverse engineering;computer network	Metrics	-11.218377307906302	79.22432088201899	59663
ab9f014cdc87f4ef65c0fa2314b7186b47194246	are incentive schemes needed for webrtc based distributed streaming?: a crowdsourced study on the relation of user motivation and quality of experience	incentive;p2p;quality of experience	Video traffic is the main driver of Internet traffic volume. Thus, content providers and Content Delivery Networks (CDNs) are searching for ways to provide reliable video transmission at a low cost. Hybrid CDN/Peer-to-Peer (P2P) deployments like Akamai NetSession have been shown to combine the high reliability of a CDN backbone and the low cost of P2P networks. In the near future, the biggest barrier for user adoption will fall: the installation of a dedicated P2P client software will be replaced by website embedded browser-to-browser communication logic. However, this requires the explicit consent of users, and, since users need to share their upload capacity, their willingness to participate in such a system. In this work, the efficiency of incentive mechanisms trading a higher Quality of Experience (QoE) of video transmission for user's consent to utilize their upload capacity are investigated. This is the first study to investigate the question of incentives in distributed, adaptive streaming systems from a user perspective using a crowd working approach. The work presents results from 192 test subjects. We identify three classes of users and show how behavioral economics can be utilized to increase the impact of an incentive scheme.	client (computing);content delivery network;crowdsourcing;embedded system;internet backbone;peer-to-peer;upload;webrtc	Matthias Wichtlhuber;Nikola Aleksandrov;Markus Franz;Oliver Hinz;David Hausheer	2016		10.1145/2910017.2910598	incentive;computer science;peer-to-peer;internet privacy;world wide web;computer security	Metrics	-18.445098169796534	74.35476972542062	59708
0f8458875df99ec6232f8b4334877f96491ec808	logical topology design for wdm networks using survivable routing	logical topology design;survivable routing;wavelength routing;wavelength assignment;wdm network;sufficient conditions;network topology;protection;telecommunication traffic;link failure;optimal design;logical topology design wdm networks survivable routing;network topology wdm networks telecommunication traffic wavelength routing wavelength assignment protection sufficient conditions np complete problem partitioning algorithms wavelength division multiplexing;wdm networks;np complete problem;partitioning algorithms;wavelength division multiplexing	Survivable routing of a logical topology ensures that the lightpaths are routed in such a way that a single link failure does not disconnect the network. However, even if the network remains connected after a failure, there is no guarantee that the resulting logical topology will be able to support the required traffic. In this paper, we introduce a new approach that integrates the logical topology design and survivable routing problems. When a topology is generated using our approach, it is guaranteed to have a survivable routing. We further ensure that the topology is able to handle the entire traffic demand, for any single link failure. We have formulated an ILP that optimally designs a survivable logical topology, and also proposed a fast heuristic which can be used for large networks.	heuristic;logical topology;mesh networking;network topology;routing;scalability;single point of failure;wavelength-division multiplexing	Arunita Jaekel;Subir Bandyopadhyay;Yash P. Aneja	2006	2006 IEEE International Conference on Communications	10.1109/ICC.2006.255150	np-complete;telecommunications;computer science;optimal design;mathematics;distributed computing;network topology;wavelength-division multiplexing;computer network;logical topology	Robotics	-6.707805311016883	81.1017587657207	59718
b39ce2bf8f3d76eec828dd328c29127d2aa693d1	maximizing open capacity in mobile optical backbone networks using controllable mobile agents	agent based;point to point;resource allocation;mobile agents;telecommunication control;heuristic algorithm open capacity maximization mobile optical backbone network controllable mobile agent free space optical link point to point link network resource source destination pair np hard problem;network performance;telecommunication computing;computational complexity;mobile communication mobile agents computational complexity resource allocation optical communication optical links telecommunication control telecommunication computing;mobile communication;optical links;optical communication;free space optics;intelligent networks optical fiber networks spine optical control mobile agents bandwidth mobile ad hoc networks radio frequency aggregates optical fiber communication;mobile agent;heuristic algorithm	We consider a mobile backbone network with free space optical point-to-point links. Requests for aggregate bandwidth between pairs of backbone nodes arrive one-by-one, and a bandwidth guaranteed connection is established if there are sufficient network resources; otherwise, the request is rejected. In addition to the ordinary backbone nodes, there are a limited number of controllable mobile agents; these are nodes that may be located as desired to optimize the performance of the network. The specific problem we consider is that of determining the positions for the mobile agents to maximize the minimum max How over all source-destination pairs. We show that this problem is NP-hard. We then develop a heuristic algorithm to locate the agents based on the current network state. It is shown that by using the algorithm to strategically place a limited number of agents, a significant improvement in network performance can be achieved.	aggregate data;aggregate function;algorithm;experiment;heuristic (computer science);internet backbone;maximum flow problem;mobile agent;np-hardness;network performance;point-to-point (telecommunications);simulation	Fangting Sun;Abhishek Kashyap;Mark A. Shayman	2005	Proceedings. 14th International Conference on Computer Communications and Networks, 2005. ICCCN 2005.	10.1109/ICCCN.2005.1523832	heuristic;free-space optical communication;mobile telephony;telecommunications;point-to-point;resource allocation;computer science;backbone network;mobile agent;distributed computing;network performance;computational complexity theory;optical communication;computer network	Robotics	-4.665034259417222	81.84541514118641	59775
a376109fa496f4d08018a417e0e4a2b6ab6bf7be	improving the tor traffic distribution with circuit switching method	switching circuits;switching circuits throughput indexes switches heuristic algorithms bandwidth active circuits;indexes;telecommunication traffic circuit switching telecommunication network routing telecommunication security;heuristic algorithms;tcp tor anonymity onion router or onion proxy op circuit switching throughputs fairness;bandwidth;active circuits;switches;default entry onion router algorithm fairness indexes tor user privacy networks tor network circuit switching method tor traffic distribution;throughput	The Tor network has its user grown by thousands every year. The increasing number of users around the world makes Tor become one of the widely used privacy networks today. However, as the number of Tor user increases, the performance of Tor degrades badly due to traffic is not fairly distributed. As a result, the Tor network does not provide a better quality of communication for all its users. To improve these problems, we proposed a simple method of dynamic circuit switching on the Tor application level to distribute the bulk and light traffic on Tor. We calculated the fairness indexes of transferred bulk and light traffic to observe any improvement and, compared our method with the default entry onion router algorithm. Our experimental results show the proposed method improves the distribution of traffic and achieves fairness of throughputs for all Tor users.	algorithm;circuit switching;fairness measure;network congestion;performance;router (computing);tor messenger	Kale Timothy Girry;Satoshi Ohzahata;Celimuge Wu;Toshihiko Kato	2016	2016 IEEE 17th International Conference on High Performance Switching and Routing (HPSR)	10.1109/HPSR.2016.7525647	database index;throughput;real-time computing;telecommunications;network switch;computer science;bandwidth;computer network	Metrics	-12.65454754169853	78.332178060232	59790
2bf79d6a5445d7f1f438970a264d7c0f57b68f41	an osi oriented architecture for virtual private networks based on public packet switching data facilities			network packet;osi model;packet switching;virtual private network	Giuseppe Fantauzzi	1988			public switched data network;packet switching;processing delay;computer network;enterprise private network;business;x.25;virtual circuit;frame relay;network packet;distributed computing	Networks	-20.70315453397474	88.35822790138678	59861
b6f8976518ddcdf0e61807852189d40eb8c83af4	an emulated test framework for service discovery and manet research based on ns-3	protocols;telecommunication computing;linux emulation containers topology network topology protocols clocks;public domain software;real time evaluations emulated test framework ns 3 based manet research service discovery protocols mobile ad hoc networks real world software implementations controlled network environment open source simulator ns 3 network emulation linux containers degree of automation;mobile ad hoc networks;linux;telecommunication computing linux mobile ad hoc networks protocols public domain software real time systems service oriented architecture;service oriented architecture;real time systems	In this paper we present our framework for emulated evaluation of service discovery protocols in mobile ad-hoc networks (MANETs). Emulation is preferable to simulation when evaluating real world software implementations, as it provides a controlled network environment without requiring modifications to the software. We base our work on the open-source simulator ns-3, which also has support for network emulation. Our own test framework consists of a set of scripts running in Linux Containers, providing a means to bootstrap and populate service discovery protocols with services and queries. Our setup allows us to perform controlled and repeatable service discovery protocol experiments in MANETs with a high degree of automation. Experiment series are set up, controlled, and statistics calculated by scripts, thus enabling complex, large, and real-time evaluations to be performed without human interaction.	booting;emulator;expect;experiment;hoc (programming language);lxc;linux;network emulation;network topology;open-source software;population;real-time clock;service discovery;simulation;test automation;xojo	Magnus Skjegstad;Frank T. Johnsen;Jørgen Nordmoen	2012	2012 5th International Conference on New Technologies, Mobility and Security (NTMS)	10.1109/NTMS.2012.6208683	embedded system;communications protocol;real-time computing;computer science;operating system;service-oriented architecture;distributed computing;service discovery;public domain software;computer security;linux kernel;computer network	Mobile	-18.500836994838842	81.78667898901844	59865
0d0d0a712e8aa5be1374703d94aa5118e2f978fd	accelerating sketch-based computations with gpu: a case study for network traffic change detection	sketch;time scale;change detection;telecommunication traffic computer graphic equipment computer network management coprocessors network interfaces;computer graphic equipment;gpu;coprocessors;network interfaces;telecommunication traffic;network traffic;computer network management;kernel graphics processing unit monitoring data structures internet change detection algorithms usa councils;gpu sketch change detection netfpga opencl;graphic processing unit;netfpga;opencl;data structure;netfpga network interface cards sketch based computations graphics processing unit gpu network traffic change detection sketch data structure fine grained time scale	Sketch-based algorithms are widely used in networking applications due to its many good attributes. We propose to use Graphics Processing Unit (GPU) as an accelerating engine to offload heavy sketch computations for network traffic change detection. Our experiment results show that GPU can conduct fast change detection with query operation up to 9 million distinct keys per second. It is capable of processing sketch data structure for wide-range of applications in fine-grained time scale efficiently.	algorithm;computation;data structure;graphics processing unit;network packet;sketch	Theophilus Wellem;Yu-Kuen Lai;Chun-Chieh Lee;Kuei-Sheng Yang	2011	2011 ACM/IEEE Seventh Symposium on Architectures for Networking and Communications Systems	10.1109/ANCS.2011.18	parallel computing;data structure;computer hardware;computer science;network interface;operating system;programming language;change detection;coprocessor;computer network;computer graphics (images)	Security	-7.559838115333644	66.1578768686192	59867
744636e9da011546cfccc0a8bd71dfcc2fa755dd	routers vs switches, how much more power do they really consume? a datasheet analysis	databases;multiprotocol label switching;power consumption database;routers and switches;telecommunication network planning;energy efficient;energy efficient networks;datasheet analysis;optical switches;telecommunication switching telecommunication network planning telecommunication network routing;internet;telecommunication network routing;telecommunication switching;energy consumption;green communications;energy efficient networks routers switches datasheet analysis power consumption database;power demand databases optical switches benchmark testing energy consumption internet multiprotocol label switching;power consumption;routers and switches green communications energy efficient networks power consumption;switches;power demand;routers;benchmark testing	This paper presents an analysis of a compiled database of power consumption and networking functionalities found in datasheets of routers and switches of some major manufacturers. We found very striking differences in consumption between switches and routers of the same nominal capacity. The paper analyzes the significance of such results and sheds some light on the most consuming elements and networking features that could be extremely useful in the re-planning and operation of energy-efficient networks.	compiler;datasheet;network switch;router (computing)	Hakim Mellah;Brunilde Sansò	2011	2011 IEEE International Symposium on a World of Wireless, Mobile and Multimedia Networks	10.1109/WoWMoM.2011.5986484	multiprotocol label switching;benchmark;real-time computing;the internet;telecommunications;network switch;computer science;efficient energy use;optical switch;computer network	Arch	-18.27208055207822	78.5520335764547	59894
a8b37f042346d57cce935d5c40eae4660483da0f	migration-based online cpscn big data analysis in data centers		It is critical to schedule online data-intensive jobs effectively for various applications, including cyber-physical-system and social network system. It is also useful to support timely decision making and better prediction. In this paper, we investigate the online job scheduling problem with data migration for global job execution time reduction. We first establish a time model based on the real experimental results, and propose an online job placement algorithm by taking into account the benefit of both instantaneity and locality for the jobs. We then introduce data migration to the job placement algorithm. The core idea is to make a tradeoff between the migration cost and remote access cost. The simulation results demonstrate that our algorithm has a significant improvement than FIFO, and data migration shows effectiveness on global job execution time reduction. Our algorithms also provide an acceptable fairness for jobs.	algorithm;big data;data-intensive computing;fifo (computing and electronics);fairness measure;job scheduler;job stream;locality of reference;remote desktop software;run time (program lifecycle phase);scheduling (computing);simulation;social network	Xin Li;Liangyuan Wang;Zhen Lian;Xiaolin Qin	2018	IEEE Access	10.1109/ACCESS.2018.2810255	task analysis;approximation algorithm;job scheduler;fifo (computing and electronics);computer science;scheduling (computing);big data;distributed computing;data migration;server	HPC	-18.90199892663966	61.610430692076676	59901
a6b7eb5129e9397eb24743cbd29694995b478d24	recursive construction of fifo optical multiplexers with switched delay lines	conmutador optico;sdls;methode recursive;recursive estimation;fibra optica;optical switch;resolucion conflicto;fiber delay line;routing;first in first out;metodo recursivo;routage;recursive method;routing path recursive construction fifo optical multiplexers switched fiber delay lines first in first out crossbar switches delayed loss multiplexers departure process;multiplexing equipment;multiplexeur optique;commutateur optique;optical switches;fifo system;65;telecommunication network routing recursive estimation multiplexing equipment optical delay lines optical switches;switched delay lines sdls;multistage switches;systeme fifo;telecommunication network routing;buffer overflow;resolution conflit;switched delay lines sdls conflict resolution multistage switches optical switches self routing switches;sistema fifo;ligne retard;multiplexor optico;optical multiplexer;switched delay lines;linea retardo;optical delay lines;optical fiber;conflict resolution;self routing switches;multiplexing delay lines optical buffering optical switches optical packet switching high speed optical techniques educational institutions optical network units packet switching chaos;delay line;fibre optique;enrutamiento	In this paper, we develop mathematical theory for recursive construction of first-in first-out (FIFO) optical multiplexers by the combination of (bufferless) crossbar switches and fiber delay lines (SDLs). We show that by cascading multistage SDL units, 2-to-1 multiplexers with a large buffer can be emulated exactly for both the departure process and the loss process from the multiplexer. Such results are extended to the case of n-to-1 multiplexers by introducing a new class of multiplexers, called delayed-loss multiplexers. A delayed-loss multiplexer has the same departure process as an ordinary multiplexer. However, lost packets due to buffer overflow in a multiplexer might be delayed. A key result from our theory is the self-routing n-to-1 multiplexer, where the routing path of a packet through the multistage SDL units can be determined upon its arrival.	buffer overflow;crossbar switch;emulator;fifo (computing and electronics);multiplexer;multistage amplifier;network packet;network switch;recursion (computer science);routing	Cheng-Shang Chang;Duan-Shin Lee;Chao-Kai Tu	2004	IEEE Transactions on Information Theory	10.1109/TIT.2004.838092	multiplexer;telecommunications;computer science;optical add-drop multiplexer;conflict resolution;optical switch;computer network	Networks	-6.453421895771479	86.6651962619474	59917
24ca00624088a6427e6ae7b06dbf2d50de0100cf	qos-guaranteed path selection algorithm for service composition	routing protocols;service composition;path selection;kcp algorithm;multiconstraint service;search space;resource allocation;load balancing service composition quality of service qos guaranteed path selection heuristic algorithm k closest pruning kcp algorithm multiconstraint service service overlay networking son network proximity information;heuristic programming;qos guarantee;routing protocols heuristic programming ip networks quality of service resource allocation;k closest pruning;network proximity information;son;delay aggregates bandwidth routing proposals heuristic algorithms polynomials joining processes resource management samarium;polynomial time;load balancing;service overlay networking;qos guaranteed path selection;ip networks;load balance;quality of service;heuristic algorithm	Service overlay networking is an emerging approach, which employs overlay nodes to provide advanced services by dynamically composing it from basic services available on overlay nodes. Advanced service request from users can have different and multiple quality-of-service (QoS) requirements and finding a service path that meets these multiple requirements is an open problem. Also, network operators have operating requirements such as load-balancing to minimize hotspots and/or minimizing the overall utilization of resources in their network. In this work, we describe a novel algorithm K-Closest Pruning (KCP), based on proximity based tree pruning, to efficiently determine a service path meeting all the QoS requirements. An additional novel feature in this algorithm is that it incorporates the minimal resource utilization or load-balancing constraints into the path selection process. KCP algorithm achieves a polynomial running time and is the first, in our knowledge, to take both the QoS requirements (user/application perspective) and resource utilization (operator perspective) into account. We show that the KCP algorithm performs significantly better than previous solutions in terms of meeting the QoS requirements of user requests.	alpha–beta pruning;hotspot (wi-fi);load balancing (computing);polynomial;quality of service;requirement;selection algorithm;time complexity	Manish Jain;Puneet Sharma;Sujata Banerjee	2006	200614th IEEE International Workshop on Quality of Service	10.1109/IWQOS.2006.250485	suurballe's algorithm;computer science;load balancing;theoretical computer science;distributed computing;computer security;computer network	HPC	-4.907288555046542	82.82575552076905	59986
195c38f7696bb6cc2197e2e2e193844dd7416859	enabling efficient content location and retrieval in peer-to-peer systems by exploiting locality in interests	peer to peer system	Services on the Internet are evolving from centralized client-server architectures to fully distributed architectures. End-hosts are becoming more ubiquitous, more powerful, and more involved in providing services. The wide-spread adoption of Internet access as a utility service is enabling new modes of interaction between end-hosts. End-hosts can provide services as well as use services. We call systems based on such service architectures peer-to-peer systems, and end-hosts participating in such systems peers. Our interests lie in peer-to-peer content publishing and distribution, where peers publish content to the system and download content from the system. Peers contribute storage and collaborate while participating in the system. Downloading content involves locating peers who have copies of the content, selecting a peer, and retrieving a copy from that peer. The characteristics unique to peer-to-peer systems are dynamicity and variability. For example, content in the system is dynamically replicated, and peers dynamically join and leave the system. Furthermore, peers have a wide range of network access speeds, and variability in load and available bandwidth at each peer can be extensive. To study variability in performance, we measured ping times to endhosts on the Internet at 30-second intervals over a 24-hour period. Variability in ping time implies variability in download performance. We collected IP addresses of peers participating in Gnutella [1], a filesharing application, on April 16, 2001. Out of the 58,400 addresses collected, 2454 were randomly chosen and pinged on April 23 and May 1, 2001. Figure 1 depicts the measured ping time to a peer with cable modem access. The ping times vary over a wide range from 300 milliseconds to 24 seconds. The standard deviation is on the order of seconds, which is typical for a third of the peers measured in our experiments. Unlike servers, end-hosts are not exclusively provisioned for providing service. End-hosts can be used to run many applications locally while actively participating in peer-to-peer content distribution. For many hosts, bandwidth is a scarce resource. Supporting a few concurrent downloads is feasible. But, additional connections can significantly degrade download performance. Protocols designed for peer-topeer systems need to take into account its dynamic and variable nature. There are many challenges in designing peer-to-peer content distribution systems. In this work, we address the challenge of locating and retrieving content in a scalable, efficient, and distributed way when peers and the network have extremely high variability in performance. Existing solutions, such as Tapestry [6], Chord [5], CAN [3], and Pastry [4] have addressed scalability. However, no solution explicitly addresses performance. In order to achieve good performance, it is necessary to consider dynamic conditions. Incorporating dynamic performance into existing protocols is not trivial because it can greatly reduce scalability. We propose a novel solution based on locality in interests to identify a small set of peers for which to maintain dynamic performance state. Peers self-organize into groups. Each peer maintains a list of peers who share similar interests. Peers on the list are ranked based on current in-	24-hour clock;access network;advanced configuration and power interface;bandwidth (signal processing);cable modem;centralized computing;client–server model;computer performance;digital distribution;download;experiment;file sharing;gnutella;heart rate variability;internet access;locality of reference;peer-to-peer;ping (networking utility);provisioning;randomness;replication (computing);scalability;self-organization;server (computing);service-oriented architecture;spatial variability	Kunwadee Sripanidkulchai;Bruce M. Maggs;Hui Zhang	2002	Computer Communication Review	10.1145/510726.510754	computer science;internet privacy;world wide web;information retrieval	Metrics	-14.98171012850337	73.15548604322537	60065
761639db5d738d43017be96c0426c60a83046b49	creating multipoint-to-point lsps for traffic engineering	internet multiprotocol label switching telecommunication traffic;multiprotocol label switching;isp;internet service provider;communication system traffic;mpls;indexing terms;multipoint to point lsp;telecommunication traffic;multiprotocol label switching merging resource management quality of service load management telecommunication traffic web and internet services packet switching bandwidth routing;internet;traffic engineered;traffic engineering;multiprotocol label switching multipoint to point lsp label switched path traffic engineering isp internet service provider mpls;label switched path	Traffic engineering enhances an ISP's capability to manage and utilize its resources effectively. MPLS has emerged as an efficient packet forwarding tool that gives a significant boost to the traffic engineering capabilities of an ISP. A fundamental problem in MPLS is to reduce label space usage by label switched paths while meeting the requirements of the flows traversing the network. Using multipoint-to-point LSP trees has been proposed as one of the techniques to reduce label space usage. We look at the problem of creating multipoint-to-point LSPs given a set of precomputed point-to-point LSPs. We propose a heuristic for multipoint-to-point LSP creation and show its effectiveness.	heuristic;multipoint ground;multiprotocol label switching;network packet;point-to-point protocol;precomputation;requirement;space–time tradeoff	Sudeept Bhatnagar;Samrat Ganguly;B. R. Badrinath	2005	IEEE Communications Magazine	10.1109/MCOM.2005.1381881	multiprotocol label switching;label distribution protocol;traffic engineering;label information base;telecommunications;computer science;label switching;l2tpv3;computer security;internet traffic engineering;computer network	SE	-5.765640026968375	83.90809784252664	60123
2ced938cd4f12285260e9e9074bb8c2cf32f96d2	socialhelpers: introducing social trust to ameliorate churn in p2p reputation systems	p2p system;time scale;convergence;social network socialhelpers social trust p2p reputation system peer to peer system natural transaction rate reputation building;model system;ieee communications society;simulation;p2p;social network;reputation system;social networking online;mathematical model;convergence peer to peer computing buildings mathematical model ieee communications society equations simulation;peer to peer computing;convergence time;peer to peer;security of data;buildings;social networking online peer to peer computing security of data	Reputation systems rely on historical information to account for uncertainty about the intention of users to cooperate. In peer-to-peer (P2P) systems, however, accumulating experience tends to be slow due to the high rates of churn — the continuous process of arrival and departure of peers. The flow of transactions is continuously interrupted by departures, which can significantly affect the convergence of reputation systems. To shed light on this, this paper presents an accurate model for capturing the influence of churn on the process of building reputations. Using our model, system architects can determine the minimal transaction rate that guarantees fast convergence and design their systems accordingly. Unfortunately, the natural transaction rate of users is sometimes too low (e.g., due to physical constraints like network bandwidth, etc.) that many of them are likely to experience significant delays in the process of building reputations for their neighbors. We face this problem by leveraging the inherent trust in social networks. The basic idea is that users ask their social links to transact with strangers and together generate reputation ratings in a short time scale. Our simulation results report reductions of 50% or greater in the convergence time in environments with high churn rates.	central processing unit;interrupt;peer-to-peer;reputation system;semiconductor industry;simulation;social network	Marc Sánchez Artigas;Blas Herrera	2011	2011 IEEE International Conference on Peer-to-Peer Computing	10.1109/P2P.2011.6038752	convergence;computer science;peer-to-peer;mathematical model;distributed computing;internet privacy;world wide web;computer security;computer network;social network	DB	-25.503911734864396	72.97991107319216	60130
928c320f5c7a34fde731aafa7aed82715332d76f	throughput maximization in software-defined networks with consolidated middleboxes	consolidated middleboxes;network resource allocation;routing;routing algorithms;optical switches;software defined networking;conference paper;bandwidth;middleboxes;network function virtualization;delays;throughput	Today's computer networks rely on a wide spectrum of specialized middleboxes to improve their security and performance. Traditional middleboxes that are implemented by dedicated hardware are expensive and hard to manage. A promising technique of consolidated middleboxes - implementing traditional middleboxes in Virtual Machines (VMs) - offers economical yet simplified management of middleboxes in Software-Defined Networks (SDNs). However there are still challenges to realizing user routing requests with network function enforcement (a sequence of middleboxes) while maximizing the network throughput, due to various resource constraints on SDNs, such as forwarding table capacity at each switch, bandwidth resource capacity at each link, and computing resource capacity at each server (Physical Machine). In this paper, we study the problem of maximizing the network throughput of an SDN by admitting as many user requests as possible, where each user request has both bandwidth and computing resource demands to implement its network functions (consolidated middleboxes). We first formulate the problem as a novel network throughput maximization problem. We then provide an Integer Linear Program (ILP) solution for it if the problem size is small, otherwise, we devise two heuristics that strive for the fine tradeoff between the accuracy of solutions and the running times of achieving the solutions. We finally evaluate the performance of the proposed algorithms by simulations, based on real and synthetic network topologies. Experimental results demonstrate that the proposed algorithms are very promising.	analysis of algorithms;entropy maximization;expectation–maximization algorithm;heuristic (computer science);linear programming;middlebox;network topology;requirement;routing;server (computing);simulation;software-defined networking;synthetic intelligence;throughput;tracing (software);transfer function	Meitian Huang;Weifa Liang;Zichuan Xu;Mike Jia;Song Guo	2016	2016 IEEE 41st Conference on Local Computer Networks (LCN)	10.1109/LCN.2016.58	routing;real-time computing;computer science;operating system;distributed computing;computer network	Networks	-11.50087059165366	81.78454862082	60269
03df41ac84388557c4775298d821548e341bbcee	a heuristic task scheduling algorithm for heterogeneous virtual clusters		Cloud computing provides on-demand computing and storage services with high performance and high scalability. However, the rising energy consumption of cloud data centers has become a prominent problem. In this paper, we first introduce an energy-aware framework for task scheduling in virtual clusters. The framework consists of a task resource requirements prediction module, an energy estimatemodule, and a scheduler with a task buffer. Secondly, based on this framework, we propose a virtual machine power efficiency-aware greedy scheduling algorithm (VPEGS). As a heuristic algorithm, VPEGS estimates task energy by considering factors including task resource demands, VM power efficiency, and server workload before scheduling tasks in a greedy manner. We simulated a heterogeneous VM cluster and conducted experiment to evaluate the effectiveness of VPEGS. Simulation results show that VPEGS effectively reduced total energy consumption by more than 20% without producing large scheduling overheads. With the similar heuristic ideology, it outperformed Min-Min and RASA with respect to energy saving by about 29% and 28%, respectively.	cloud computing;data center;experiment;frequency scaling;greedy algorithm;heuristic (computer science);performance per watt;requirement;scalability;scheduling (computing);semiconductor consolidation;server (computing);simulation;virtual machine	Weiwei Lin;Wentai Wu;James Zijun Wang	2016	Scientific Programming	10.1155/2016/7040276	fair-share scheduling;fixed-priority pre-emptive scheduling;parallel computing;real-time computing;computer science;operating system;distributed computing	HPC	-19.291577914541644	62.02356755684836	60400
462ea521969f2d2b425d1d4130488b4777243a14	super monitor design for fast link failure localization in all-optical networks	optical receiver;optical communication equipment;telecommunication network reliability;conference_paper;optical transmitters;monitoring peer to peer computing hardware optical transmitters optical receivers optical fibers optical reflection;optical reflection;monitoring cycle m cycle;super monitor;all optical network;cost reduction;telecommunication network reliability fault diagnosis integer programming linear programming optical beam splitters optical communication equipment optical links;integer linear programming super monitor design all optical network optical loop back precross connection supervisory wavelength cycle based link failure detection scheme m cycle single laser source optical splitter conventional monitors colocating;monitoring;link failure detection and localization;integer programming;optical fibers;link failure;fault detection;linear programming;optical links;optical beam splitters;all optical networks;peer to peer computing;optical fiber;optical receivers;integer linear program;fault diagnosis;hardware	Monitoring cycle (m-cycle) based design is cost efficient for fast link failure detection and localization in all-optical networks. An m-cycle is an optical loop-back pre-cross-connection of a supervisory wavelength with a dedicated monitor. Generally, a simple monitor is placed at an arbitrary node of an m-cycle for supervision. In this paper, we propose a novel monitor structure, called super monitor. A super monitor is used to supervise multiple intersecting cycles and placed at the intersection node. For a given set of m-cycles, we use super monitors to replace some (or all) simple monitors that originally locate in the set. Two major advantages of the super monitor are: 1) it has lower hardware cost; 2) the collocation of monitoring devices reduces the management cost simultaneously. Besides, the super monitor does not incur additional bandwidth cost. We formulate an integer linear program (ILP) to solve the problem of monitor placement. Numerical results show that our ILP can efficiently place the monitors with a significantly minimized monitoring cost.		Minjing Mao;Kwan Lawrence Yeung	2011	2011 IEEE International Conference on Communications (ICC)	10.1109/icc.2011.5963339	embedded system;real-time computing;integer programming;telecommunications;computer science;linear programming;optical fiber;computer network	EDA	-7.325306625195138	80.72401759666454	60406
724a106bf875c00bb39f1f05c0e7cb145dd2f88d	a trading-inspired approach to the dynamic server consolidation problem in data centers	virtual machining;resource management;servers;energy consumption;heuristic algorithms;algorithm design and analysis;dynamic scheduling	Energy efficiency of data centers has become a hot topic in recent years and one of the most effective ways to save energy consumed by servers in a data center is through server consolidation. In this paper, a new dynamic server consolidation approach is proposed. The new dynamic server consolidation approach is inspired by the process of human trading. The new dynamic server consolidation has been evaluated by experiments, and the experimental results have shown that the new dynamic server consolidation approach outperforms the most popular dynamic server consolidation approach and it is scalable.	algorithm;data center;experiment;free-form deformation;scalability;semiconductor consolidation;server (computing)	Grant Wu;Maolin Tang	2016	2016 IEEE International Conference on Computer and Information Technology (CIT)	10.1109/CIT.2016.99	algorithm design;real-time computing;dynamic priority scheduling;computer science;resource management;operating system;database;server;server farm	Vision	-19.46142931465528	62.08926020374828	60447
24a9fe8f88946080e130ed8a45fc6b729edc3615	distributed task force scheduling in multi-microcomputer networks	queueing model;task scheduling;network computing	Efficient task scheduling techniques are needed for microcomputer networks to be used as general purpose computers. The Wave Scheduling technique, developed for the MICRO-NET network computer, co-schedules groups of related tasks onto available network nodes. Scheduling managers are distributed over a logical control hierarchy. They subdivide requests for groups of free worker nodes and send waves of requests towards the leaves of the control hierarchy, where all workers are located. Because requests from different managers compete for workers, a manager may have to try a few times to schedule a task force. Each task force manager actually requests slightly more workers than it really needs. It computes a request size which minimizes expected scheduling overhead, as measured by total idle time in worker nodes. Using a Markov queueing model, it is shown that Wave Scheduling in a network of microcomputers is almost as efficient as centralized scheduling.	centralized computing;markov chain;microcomputer;network computer;overhead (computing);queueing theory;scheduling (computing)	André M. Van Tilborg;Larry D. Wittie	1981		10.1145/1500412.1500452	fair-share scheduling;fixed-priority pre-emptive scheduling;real-time computing;earliest deadline first scheduling;flow shop scheduling;dynamic priority scheduling;computer science;rate-monotonic scheduling;operations management;two-level scheduling;deadline-monotonic scheduling;distributed computing;lottery scheduling;round-robin scheduling	HPC	-13.762176466706787	65.02215787447412	60554
a971e0b5e2ea1c75eef0a277a49095e85806c3bf	remote network monitoring mib protocol identifier reference		This memo defines a notation describing protocol layers in a protocol encapsulation, specifically for use in encoding INDEX values for the protocolDirTable, found in the RMON-2 MIB (Remote Network Monitoring Management Information Base) [RFC2021]. The definitions for the standard protocol directory base layer identifiers are also included.	identifier;mebibyte	Andy Bierman;Chris Bucci;Robin Iddon	2000	RFC	10.17487/RFC2895	user datagram protocol;computer science;data mining;database;world wide web;osi model	ML	-25.421089616925975	88.09028189707516	60603
0fde831b13d3e24419ac54b506f36f79144fe3ac	understanding the topological properties of internet traffic: a view from the edge	institutional repositories;traffic graph internet traffic dynamic loop free graph internet internal architecture netflow measurement;fedora;vital;internet ip networks topology network topology indexes histograms stability analysis;telecommunication traffic graph theory internet;vtls;ils	Traffic between an edge network and the rest of the Internet can be represented as a dynamic loop-free graph. Understanding in depth the dynamics in time and space (spatial structure, topological breadth, destination persistency, traffic dominating paths) of this graph provides significant insight on the Internet internal architecture and capabilities. This paper analyzes inter-domain traffic from a large campus network based on one month by way of Netflow measurements. Our analysis reveals the topological properties and structure of the traffic graph (breadth, depth, volume), the stability of contacted destinations and the relationship between their popularity and their path length. Based on the observed traffic, we explore the suitability of a simple mathematical model to describe the structure of the outgoing traffic graph.	inter-domain;internet;mathematical model	Juan Antonio Cordero;Olivier Bonaventure	2014	2014 IFIP Networking Conference	10.1109/IFIPNetworking.2014.6857090	traffic generation model;internet topology;computer science;distributed computing;world wide web;internet traffic engineering;computer network	Networks	-10.714645715965434	78.44030266908635	60645
9d6c3c37109b0cfeab318535e3a97df888357797	obstacles of enterprises moving towards the next generation internet	internet protocols;simulation;internet service provider;test bed;isp support;development tool;internet;internet service providers;next generation internet ngi;continuous improvement;ipv6;ngi infrastructure;enterprise applications;ngi testing;ipv4;ngi development tools;next generation internet	The next generation internet (NGI) has already been deployed, but few enterprises actually migrate to it. What is wrong with the NGI? In this paper, we build an NGI testing bed. In our tests, we set up a current network environment and an NGI environment to simulate a real enterprise using the internet. The results show that the overall environment of NGI has not yet caught up with the functionality of the current network. The best way to remove these obstacles faced by enterprises moving towards next generation internet is to continuously improve the supporting infrastructure of the NGI such as internet service provider (ISP) supports, development tools, and enterprise applications.	internet;next-generation network	Wen-Lung Shiau;Han-Chieh Chao;PingYu Hsu	2005	IJIPT	10.1504/IJIPT.2005.007557	internet protocol;the internet;computer science;ipv6;world wide web;computer security;computer network;testbed	Networks	-17.348064708004127	86.28348028155006	60658
5014bbdad6b861e63f6e79a9c80217171d6ed1f8	shaman - an environment for distributed management applications	prototype software package;management functions;control functions;programming environments;im;flexible dynamic network management;location management;application software;spreadsheet programs;environmental management resource management application software computer network management power system management energy management software development management internet prototypes laboratories;prototypes;telecommunication control;resource management;spreadsheet based hierarchical architecture for management;military communication;shaman;graphical user interfaces;snmp;internet;mobile tactical battlefield network;land mobile radio;hierarchical management;power system management;environment;computer network management;distributed object management;software package;gui;distributed management applications;environmental management;software development management;dynamic networks;software packages;intermediate manager;energy management;distributed management;programming environments internet computer network management distributed object management military communication land mobile radio telecommunication control software packages graphical user interfaces spreadsheet programs;spreadsheet based hierarchical architecture for management shaman distributed management applications environment hierarchical management snmp flexible dynamic network management control functions management functions prototype software package intermediate manager gui im location management mobile tactical battlefield network	SHAMAN is a framework for hierarchical management of networks with SNMP that provides flexible and dynamic network management by permitting distribution of control and management functions over a hierarchical management structure. We have implemented a prototype software package that contains a SHAMAN Intermediate Manager (IM), a GUI for controlling the IM and for developing applications for it, and an example application of location management in a mobile tactical battlefield network.	graphical user interface;prototype;simple network management protocol	Adarshpal S. Sethi;Dong Zhu;Pramod Kalyanasundaram	2001		10.1109/INM.2001.918049	network management station;computer science;resource management;operating system;graphical user interface;network management application;structure of management information	DB	-20.298609591534994	85.18553358025991	60697
ba867069162ae56e454bff35a31995edba5a082c	a memory-efficient scheme for address lookup using compact prefix tries	cache storage;packet switching;data structures routing cache memory computer science databases velocity measurement data mining tree data structures hardware cache storage;tree data structures;packet switching tree data structures telecommunication network routing table lookup cache storage;general purpose processor;829 kb memory efficient address lookup compact prefix tries general purpose processors caching support ip core router database mae west database forwarding table packet switching;telecommunication network routing;table lookup	In this paper we present a new memory-efficient scheme for address lookup that exploits the caching support provided by general-purpose processors. We propose Compact Prefix Tries, in which prefixes occurring at multiple levels of a subtrie are compressed into a single node that fits in a single cache line. The scheme performs well in compressing dense as well as sparse tries. For an IP core router (Mae-West) database with 93354 prefixes, the simulation results for Compact Prefix Tries show up to 70% improvement in lookup performance and up to 33% reduction in memory when compared with LC-Tries. In fact, the entire forwarding table for Mae-West required only 829 KB space. Measurements for Compact Prefix Tries, when compared with most existing schemes, show better results in terms of memory usage as well as lookup speeds. Moreover, as the memory usage is significantly less and sparse tries with long paths can be compressed into only a few nodes, this scheme is particularly attractive for IPv6. I. IP ADDRESS LOOKUP PROBLEM The primary role of a router is to route the packet to its destination. In order to do so, for each packet it receives, the router must determine the address of the next hop where it should be forwarded. Router maintains a table called forwarding table that stores the forwarding information. Each entry in the routing table has a network address, length and an output port identifier or next hop address. The pair of address and its length is called as a prefix. When a packet is received, the router extracts the destination address from the packet header. It is then matched with the prefixes in the routing table using some lookup algorithm to find the next hop address. This operation is called as address lookup. Since the prefixes are of different lengths in the router tables, multiple prefixes match a given address. So, in order to find the next hop address for the destination address, the router has to find the most specific prefix or the longest matching prefix. The router then forwards the packet from incoming port to corresponding outgoing port. This is called as switching.	algorithm;central processing unit;core router;fits;general-purpose markup language;identifier;lookup table;network address;network packet;router (computing);routing table;simulation;sparse matrix	Anand Sarda;Arunabha Sen	2003		10.1109/GLOCOM.2003.1258969	parallel computing;computer science;theoretical computer science;operating system;database;tree;packet switching;computer network	Metrics	-5.753706732263467	66.78418337099573	60698
272464eb619da994acb1105c9abd3ec40caf868b	a safe, efficient update protocol for openflow networks	reliable update;openflow;boolean function;logic synthesis	We describe a new protocol for update of OpenFlow networks, which has the packet consistency condition of [?] and a weak form of the flow consistency condition of [?]. The protocol conserves switch resources, particularly TCAM space, by ensuring that only a single set of rules is present on a switch at any time. The protocol exploits the identity of switch rules with Boolean functions, and the ability of any switch to send packets to a controller for routing. When a network changes from one ruleset (ruleset 1) to another (ruleset 2), the packets affected by the change are computed, and are sent to the controller. When all switches have been updated to send affected packets to the controller, ruleset 2 is sent to the switches and packets sent to the controller are re-released into the network.	network packet;network switch;openflow;routing;telecommunications access method	Rick McGeer	2012		10.1145/2342441.2342454	real-time computing;computer science;distributed computing;computer network	Networks	-8.59790485710252	80.46692572701242	60704
5177bfba27fc17bd740b70b4bc0a9d95b2814cbe	an implementation of the 802.1ae mac security standard for in-car networks	in car network controllers 802 1ae mac security standard in car networks automotive electronics electronic control units ecu ethernet backbone security standards car passenger safety risks macsec stratix v fpga standard cell cmos technology standard cell technology adaptive logic modules alm;standards automotive engineering hardware protocols encryption automobiles;on board communications access protocols automotive electronics cmos logic circuits computer network security field programmable gate arrays local area networks	The continuous increase in complexity in automotive electronics has led to cars that include up to 80 Electronic Control Units (ECUs). As a consequence, in-car networks are currently up to their limit in terms of data load, flexibility and bandwidth. The Ethernet backbone is thus considered as the best performing solution. On the other hand, the growing interconnection of cars with the external world requires high security standards in order to prevent safety risks for car passengers. The IEEE 802.1AE MAC Security Standard (MACSec) solves the security issues of Ethernet networks by providing confidentiality, authenticity and integrity of data. This paper presents an efficient hardware implementation of the MACSec standard for the automotive world. The system was synthesized on a Stratix V FPGA and on a 28nm standard-cell CMOS technology. In terms of maximum throughput, the FPGA results in 1.1 Gbps while the standard-cell technology reaches 3.9 Gbps. The FPGA implementation occupies 4.5% of the Adaptive Logic Modules (ALMs) while the standard-cell one gives a 285 kgate size. The proposed architecture represents a suitable implementation for a low area and high-performance solution as usually required by in-car network controllers.	cmos;confidentiality;data rate units;field-programmable gate array;ieee 802.1ae;ieee 802.1x;interconnection;internet backbone;key exchange;maximum throughput scheduling;standard cell;stratix	Berardino Carnevale;Francesco Falaschi;Luca Crocetti;Harman Hunjan;Samson Bisase;Luca Fanucci	2015	2015 IEEE 2nd World Forum on Internet of Things (WF-IoT)	10.1109/WF-IoT.2015.7389021	embedded system;real-time computing;telecommunications;operating system;computer security;computer network	EDA	-25.0112726172974	79.72867645336521	60756
82efe16a328c8fef577ddd304b98d31c00104353	run-time prediction of power consumption for component deployments		The Power consumption of servers in data centers depends greatly on the software running on each server and how it interacts with the hardware. Different deployments of distributed software components on heterogeneous servers can lead to significant differences in power consumption, depending on the server allocation and the current workload. As workloads and load intensity change, components may be re-deployed or exchanged in order to reduce the power consumption for the current load profile. The decision on which component to place on which server during run-time remains difficult as the power consumption that would result from such a placement remains unknown. Existing work on component deployment optimization at run-time focuses on maximizing performance or considers power in the context of static design time decisions. In this paper, we introduce a model to predict the power consumption of component placements at run-time based on the load and power profile collected for a running distributed application in a heterogeneous environment. In addition, we present a model that enables the use of our approach without dedicated power measurement devices, predicting power consumption based on load intensity and performance counters. We show that we can predict the power consumption of two different distributed web applications with a mean absolute percentage error of 2.21% and with an error of 1.04% when predicting a previously unobserved load level.	approximation error;component-based software engineering;data center;distributed computing;load profile;mathematical optimization;server (computing);software deployment;web application	Jóakim von Kistowski;Maximilian Deffner;Samuel Kounev	2018	2018 IEEE International Conference on Autonomic Computing (ICAC)	10.1109/ICAC.2018.00025	software deployment;real-time computing;throughput;workload;software;distributed computing;data modeling;mean absolute percentage error;server;computer science;load profile	HPC	-24.58755702736083	61.36997788886384	60757
964df751e2c1107b9a6d3a0428d7826be8df6569	content delivery network with hot-video broadcasting and peer-to-peer approach	proxy caching;video broadcasting;hash table;video server;content delivery network;peer to peer;java language	With the growth of bandwidth, video/audio streaming services have become popular, and are considered a future killer application on the Internet. Many researches proposed several possible technologies for streaming services, such as hot-video broadcasting, caching, content delivery network (CDN), and peer-to-peer communications. In the paper, we propose a new streaming architecture combining the above technologies. We construct our CDN using two-level hashing, which the first level maps user requests to video servers, and in the second level, the selected video servers choose proxy cache servers for the requests. Once receiving the user request, the cache server first checks whether it has the requested video data. If the data are available, the server transmits them to the user over hot-video broadcasting. Otherwise, the server connects to the original video server for the data, which are then broadcast to the user. In addition, the server saves the user information in its hash table. When a user request for the same video arrives, the server can direct the request to the former user with the data, so as to save bandwidth. Finally, we have realized our architecture using Java language.	content delivery network;digital distribution;hash table;internet;java;killer application;map;peer-to-peer;server (computing);streaming media;video server;web cache	Julian Liu;Su-Chiu Yang;Hsiang-Fu Yu;Li-Ming Tseng	2004	J. Inf. Sci. Eng.		hash table;computer science;operating system;database;internet privacy;programming language;world wide web;application server;server;computer network;server farm	Metrics	-16.577744348092043	72.89013392294227	60854
d72c53cde41681aebf455e1bf4652b2d878fe1df	restorability analysis of two protection cycles in random mesh networks	network parameters;decomposition;mesh optical network;restorability analysis;hamiltonian survivable networks protection cycles network protection restorability decomposition;telecommunication networks mesh generation network parameters optical fibre networks;hamiltonian;random mesh networks;restorability;protection mesh networks computer networks information analysis information technology optical fiber networks availability failure analysis computational modeling analytical models;network protection;optical fibre networks;two protection cycles;protection capacity;distributed working capacitty;total network restorability;mesh network;mesh generation;survivable networks;telecommunication networks;total network restorability restorability analysis two protection cycles random mesh networks mesh optical network distributed working capacitty protection capacity network parameters;protection cycles	This paper studies the total network restorability using only two protection cycles in a mesh optical network with fixed and uniformly distributed working and protection capacities. We present a detailed analysis for the shared case when two cycles share the capacity in a number of edges common between the two cycles, and also for the non-shared case when the capacities are not shared. We study how the restorability changes with respect to different network parameters.	mesh networking	Wail Mardini;Oliver W. W. Yang	2006	2006 3rd International Conference on Broadband Communications, Networks and Systems	10.1109/BROADNETS.2006.4374304	mesh generation;hamiltonian;telecommunications;computer science;mesh networking;distributed computing;decomposition;computer network;network access protection	HPC	-5.99220582370965	79.93633645906866	60861
092b099e1abe61ff7bac3bb3e3fa988cec2f5bf0	continuous and multimedia os support in real-time control applications	real time active databases;control application;control systems;active databases multimedia computing computerised control operating systems computers real time systems;integrated resource models;real time active databases multimedia os support real time control applications operating systems soft real time constraints integrated resource models reflective real time kernels quality of service call admission hard real time constraints;multimedia;call admission;computerised control;application software;real time control;active database;real time;agile manufacturing;spectrum;multimedia systems;soft real time;reflective real time kernels;multimedia computing;time factors;transaction databases;multimedia databases real time systems multimedia systems application software control systems time factors transaction databases agile manufacturing process control timing;multimedia databases;process control;active databases;soft real time constraints;quality of service;real time control applications;hard real time constraints;operating systems computers;hard real time;operating systems;os support;real time systems;timing	Integrating multimedia into real-time control applications requires careful consideration. The impact of the system support needed to meet the soft real-time constraints of multimedia on meeting the hard deadlines of the control application is of paramount concern. We propose that integrated resource models and reeective real-time kernels can provide the basis for the needed solutions. Features such as quality of service and call admission would then span a spectrum of requirements from the soft real-time requirements of multimedia to the hard real-time constraints of the control application. The connuence of multimedia, real-time control and real-time active databases is also discussed.	active database;operating system;quality of service;real-time clock;real-time computing;real-time transcription;requirement	John A. Stankovic	1995		10.1109/HOTOS.1995.513446	embedded system;spectrum;application software;real-time computing;simulation;real-time control system;quality of service;computer science;operating system;process control	Embedded	-10.567746694105324	64.3306791904879	60942
c440dea9fb0b76ff9f613b9ac1798818c32ebc31	an analytical model for predicting the locations and frequencies of 3r regenerations in all-optical wavelength-routed wdm networks	wavelength routing;wdm network;cost saving;analytical models frequency optical fiber networks repeaters wdm networks costs routing protocols optical switches wavelength division multiplexing optical wavelength conversion;optical switches;optical repeaters wavelength division multiplexing optical fibre networks telecommunication network routing optical switches;model accuracy analytical model 3r regenerations all optical wavelength routed wdm networks all optical wavelength switched networks cost savings network node location prediction relative frequency prediction network topological information network operating parameters routing protocol simulation results;optical fibre networks;telecommunication network routing;optical repeaters;routing protocol;analytical model;wavelength division multiplexing	 In all-optical wavelength-switched WDM networks, 3R regeneration does not need to be performed at every node in a path. Thus, a significant cost savings can be realized by efficiently provisioning a limited amount of 3R regeneration resources in each node in the network and utilizing these resources efficiently. In order to aid in these two tasks, we present an analytical model to predict the location and relative frequency of 3R regeneration requests in the network. Because the model is based solely on the topological information of the network, the predictions provided are very general and are independent of specific network operating parameters, such as the routing protocol employed. Simulation results are also presented to verify the accuracy of the model.	next-generation network;provisioning;routing;simulation;wavelength-division multiplexing	Neil Barakat;Alberto Leon-Garcia	2002		10.1109/ICC.2002.997355	optical transport network;passive optical network;routing;shared risk resource group;telecommunications;computer science;dynamic source routing;optical add-drop multiplexer;routing protocol;link-state routing protocol;optical switch;optical performance monitoring;wavelength-division multiplexing;optical cross-connect;computer network;optical communications repeater	Networks	-6.884407647171157	84.85931042579391	60985
1e23986c21f4a5561be3896a29ee960b251d2cf2	a fixed-parameter tractable approach for the wavelength assignment problem in transparent networks	optical network;wavelength assignment;multiplexage longueur onde;parameterized complexity;fixed parameter tractable;heuristic method;wavelength assignment problem;exact solution;optical wdm networks;parameterized complexity theory;telecommunication network;problema np duro;metodo heuristico;solucion exacta;transparent networks;red fibra optica;parameterized complexity theory fixed parameter tractable approach wavelength assignment problem transparent networks rwa problem np hard problem;optical fibre networks;allocation frequence;np hard problem;telecomunicacion optica;telecommunication optique;telecommunication network routing;probleme np difficile;frequency allocation;red telecomunicacion;reseau fibre optique;asignacion frecuencia;reseau telecommunication;optical telecommunication;wavelength division multiplexing optical fibre networks telecommunication network routing wavelength assignment;optical fiber network;methode heuristique;wavelength assignment np hard problem complexity theory optical fiber networks wdm networks network topology optical wavelength conversion wavelength routing costs;solution exacte;fixed parameter tractable approach;rwa problem;optical fiber communication;multiplaje longitud onda;communication fibre optique;wavelength division multiplexing	One possibility for the formulation of the RWA problem in transparent networks is the creation of an auxiliary undirected graph with vertices representing lightpaths in the network. Coloring graphs is an NP-hard problem and various heuristics have been proposed for the solution of wavelength assignment problem in optical networks. This letter introduces an approach for exact solution for the assignment of wavelengths to lightpaths in transparent networks using a novel parameterized complexity theory.	algorithm;assignment problem;complex adaptive system;computational complexity theory;graph (discrete mathematics);graph coloring;heuristic (computer science);modulation;np-hardness;parameterized complexity	André C. Drummond;Nelson Luis Saldanha da Fonseca	2008	IEEE Communications Letters	10.1109/LCOMM.2008.080450	parameterized complexity;mathematical optimization;combinatorics;frequency allocation;telecommunications;computer science;generalized assignment problem;np-hard;mathematics;telecommunications network;wavelength-division multiplexing	Theory	-5.005543731235883	80.95336976387894	61026
796f8ea3d878113af9477892f9e5bb881ec0798d	guest editors' introduction to special section on mobile computing and wireless networks	wireless networks;concurrent computing;application software;wireless network;distributed computing;mobile computer;computer networks;internet;mobile computing computer networks wireless networks concurrent computing distributed computing computer science conferences application software parallel algorithms internet;computer science;mobile computing;conferences;parallel algorithms	IN recent years, the areas of mobile computing and wireless networks have seen explosive growth both in terms of the number of services provided and the types of technologies that have become available. Indeed, cellular telephony, radio paging, cellular data, and even rudimentary cellular multimedia services have become commonplace and the demand for enhanced capabilities will continue to grow into the foreseeable future. It is anticipated that, in the not-so-distant future, mobile users will be able to access their data and other services, such as electronic mail, video telephony, stock market news, map services, electronic banking, while on the move. Already today, there are more portable phones than computers connected to the Internet. However, the trend toward the Internet with its protocols around IP as the common basis for all communication applications seems to be quite clear. The stated goal of this special section was to provide a forum for the most recent results on a broad range of topics of relevance to mobile computing and wireless networks. The intention was to offer both researchers and practitioners working in this area an opportunity to express their views on the current trends, challenges, and state-of-art solutions to various problems in this important area. In response to the Call for Papers, we received 59 submissions from all over the world, leading to a truly international competition. The manuscripts underwent a very rigorous, peer review process. Each paper was sent to at least five referees. Based on the referee reports, a total of eight papers were selected for inclusion in the special section. The final result is truly remarkable: The special section of IEEE Transactions on Parallel and Distributed Systems on Mobile Computing and Wireless Networks is an outstanding collection of papers on various aspects of mobile computing, wireless networks, and their applications. We take this opportunity to thank all the authors for their submissions. We are indebted to all the referees who have put in the hard work and the long hours to review each paper in a timely and professional way.	email;internet;mobile computing;online banking;paging;portable computer;relevance;videotelephony	Stephan Olariu;Koji Nakano	2002	IEEE Trans. Parallel Distrib. Syst.	10.1109/TPDS.2002.1036061	mobile broadband;computing;mobile search;the internet;mobile web;computer science;theoretical computer science;operating system;wireless network;mobile technology;mobile agent;distributed computing;utility computing;services computing;mobile computing;ubiquitous computing;computer network;autonomic computing	Mobile	-28.683322692368733	70.29787577448668	61067
376cb4187c444885b6d95d037c76c821478a9c4c	tcp tuning guide for distributed application on wide area networks	data transmission;manuals;general and miscellaneous mathematics computing and information science;computer networks;tuning			Brian Tierney	2001	;login:		telecommunications;computer science;theoretical computer science;world wide web;computer network;data transmission	HPC	-21.359355390854763	86.14180937967303	61124
3afd8d749a7a7da106406d9dec85819ba12b5f71	a dynamic routing method for inbound e-mail delivery considering route and mta conditions on multihomed environment	dynamic load balancing;electronic mail;routing;mta conditions;prototypes;mail transfer agent dynamic routing method inbound e mail delivery considering route mta conditions multihomed environment;mail transfer agent;telecommunication network routing electronic mail;dynamic routing;servers;internet;telecommunication network routing;load balancing;load balancing multihomed environment e mail;load balance;servers electronic mail proposals delay routing prototypes internet;proposals;inbound e mail delivery considering route;e mail;multihomed environment;dynamic routing method	To operate e-mail systems stably multihomed networks are well used. As an operation method on multihomed networks, we have proposed a dynamic route selection method considering status of networks. However, status of Mail Transfer Agents(MTAs) have not been considered in this method so that a heavily loaded MTA would be possibly selected. In this paper, we propose a new dynamic route selection method considering not only status of networks but also that of MTAs. With this method, an appropriate route could be selected based on status of networks and MTAs so that dynamic load balancing of MTAs could be realized. Furthermore in case failed MTAs exist, such MTAs could be avoided automatically.	central processing unit;email;inbound marketing;load (computing);load balancing (computing);multihoming;performance evaluation;prototype;routing;selection (genetic algorithm);yahoo mail	Sho Jitsuto;Yong Jin;Kiyohiko Okayama;Nariyoshi Yamai	2010	2010 10th IEEE/IPSJ International Symposium on Applications and the Internet	10.1109/SAINT.2010.96	embedded system;real-time computing;computer science;load balancing;computer security;computer network	Metrics	-10.647486491981235	84.16494370634463	61125
c07d47149c0867034aa4f78da09bd0a4c1b9616a	solution: sdn-based optical traffic steering for nfv	traffic steering;optical communications;service chaining;network function virtualization;wavelength division multiplexing		network function virtualization;software-defined networking	Ming Xia;Meral Shirazipour;Howard Green;Attila Takács	2014		10.1145/2620728.2620777	embedded system;telecommunications;engineering;computer network	HPC	-12.283645576221305	85.41148057573693	61214
c2a857e5bb9490cbedb090d9ae05f6b8cdd61649	building online performance models of grid middleware with fine-grained load-balancing: a globus toolkit case study	globus toolkit;grid middleware;satisfiability;performance model;on the fly;performance prediction;load balance;quality of service;grid computing;admission control	As Grid computing increasingly enters the commercial domain, performance and Quality of Service (QoS) issues are becoming a major concern. To guarantee that QoS requirements are continuously satisfied, the Grid middleware must be capable of predicting the application performance on the fly when deciding how to distribute the workload among the available resources. One way to achieve this is by using online performance models that get generated and analyzed on the fly. In this paper, we present a novel case study with the Globus Toolkit in which we show how performance models can be generated dynamically and used to provide online performance prediction capabilities. We have augmented the Grid middleware with an online performance prediction component that can be called at any time during operation to predict the Grid performance for a given resource allocation and load-balancing strategy. We evaluate the quality of our performance prediction mechanism and present some experimental results that demonstrate its effectiveness and practicality. The framework we propose can be used to design intelligent QoS-aware resource allocation and admission control mechanisms.	control system;grid computing;load balancing (computing);middleware;on the fly;performance prediction;quality of service;requirement	Ramon Nou;Samuel Kounev;Jordi Torres	2007		10.1007/978-3-540-75211-0_10	real-time computing;quality of service;semantic grid;computer science;load balancing;distributed computing;world wide web;grid computing;satisfiability	HPC	-23.11680304853368	62.319756603818966	61229
3ba708f77a9b72fb80a81c01a2f5329cdc217a6d	synchronous distributed load balancing on totally dynamic networks	multiprocessor interconnection networks;distributed algorithms;iterative algorithm load balancing totally dynamic networks;resource allocation distributed algorithms iterative methods multiprocessor interconnection networks network topology processor scheduling;processor scheduling;resource allocation;first order diffusion load balancing algorithms;totally dynamic networks;iterative algorithm;totally dynamic network topology;network topology;iterative methods;first order;load management network topology iterative algorithms equations iterative methods heuristic algorithms distributed processing processor scheduling linear systems vectors;iterative methods synchronous distributed load balancing totally dynamic network topology load evolution first order diffusion load balancing algorithms;load balancing;synchronous distributed load balancing;load balance;load evolution;dynamic networks	In this paper, first order diffusion load balancing algorithms for totally dynamic networks are investigated. Totally dynamic networks are networks in which the topology may change dynamically. Some edges or nodes can appear, disappear or move during the time. In our previous works on dynamic networks, the dynamism was limited to the edges. The main result of this study consists in proving that the load balancing algorithms reduce the unbalance on arbitrary dynamic networks. Notice that the hypotheses of our result are realistic and that for example the network does not have to be maintained connected. To study the behavior of these algorithms, we compare the load evolution by several simulations.	algorithm;central processing unit;computation;experiment;google app engine;grid computing;hoc (programming language);load balancing (computing);node (computer science);peer-to-peer;simulation;volatility	Jacques M. Bahi;Raphaël Couturier;Flavien Vernier	2007	2007 IEEE International Parallel and Distributed Processing Symposium	10.1109/IPDPS.2007.370572	distributed algorithm;parallel computing;real-time computing;evolving networks;computer science;load balancing;distributed computing;iterative method	Theory	-12.79526682130507	65.16633989163668	61247
db36d30a5fe2c4133599b30e759076579e856ba7	design and performance evaluation of fail-over and recovery strategies for large-scale multimedia storage systems	optimal solution;storage system;performance evaluation;multimedia servers;multimedia systems;large scale;waiting time;large scale systems multimedia systems network servers information retrieval file servers computer science design engineering computer networks laboratories algorithm design and analysis;performance evaluation multimedia servers multimedia systems;multimedia server;obtc strategy performance evaluation recovery strategy multimedia storage system active active fail over policy heuristic algorithm multimedia server minimum average waiting time mawt strategy one of best two choices;heuristic algorithm	"""Failure-over and recovery is a crucial issue for large-scale multimedia storage system (MSS). In the literature, there are two fail-over policies: active-standby fail-over and active-active fail-over. In this paper, we adopt an active-active policy and design two heuristic algorithms to determine the number and the placement of the object replicas among the multimedia servers. One is named as """"minimum average waiting time"""" (MAWT) strategy, in which we will choose the server to store an object replica according to an optimal solution, and the other algorithm is named as """"one of the best two choices"""" (OBTC) strategy, in which we will randomly choose one out of the first two best choices according to an optimal solution. We analyze their performance in the cases when the system runs normally and when some failure occurs. Via rigorous simulations, we find that when the system is running normally (without failures), MAWT performs better than OBTC and when some server fails, OBTC performs much better than MAWT"""	abstract window toolkit;algorithm;computer data storage;failover;heuristic;object-based language;performance evaluation;randomness;real-time transcription;self-replication;server (computing);simulation;supercomputer education research centre	Zeng Zeng;Bharadwaj Veeravalli;Jaideep Srivastava	2006	2006 14th IEEE International Conference on Networks	10.1109/ICON.2006.302604	heuristic;real-time computing;simulation;computer science;operating system;database;computer network	HPC	-16.17618032089818	70.45975228732695	61257
6eeb863b929f204287d65ecf21c809a79b9b9276	on the false-positive and false-negative behavior of a soft-state signaling protocol	distributed system;soft state signaling protocol;protocols;wireless networks;mathematics;maintenance;application software;state cancelation mechanism;availability;messages overhead;probability density function;paper technology;soft state;consistency soft state false positive false negative;false negative;false negative behavior;data mining;false positive behavior;receivers;protocols delay scalability availability application software mathematics computer science paper technology maintenance wireless networks;sensitivity;scalability;computer science;distributed systems;false positive;loss probability;consistency;signalling protocols;loss probability false positive behavior false negative behavior soft state signaling protocol distributed systems state cancelation mechanism messages overhead	This paper addresses the consistency and scalability behavior of a soft-state signaling protocol. Soft-state is state that has a predefined validity period. A soft-state protocol is a signaling approach in which soft-states are periodically refreshed by the receipt of a message indicating a new validity period and possibly a new value. Unrefreshed state eventually expires and recovers as soon as a subsequent refresh message is received. This protocol is widely used in distributed systems where components need to keep track of the state of other components. Within such a system, the state consistency is affected by many parameters, some given by the environment while others are tunable. The environment parameters are the loss probability and latency of the channel between the endpoints, and the change rate of the source state. The tunable parameters are the refresh period and timeout period. In this study, we dissect the overall system inconsistency into false-positive and false-negative cases, address the tradeoff between the two, and analyze their sensitivity towards parameter changes. In the end, we identify the necessary measures to optimize each of them. Our results show that false-positive ratio can be optimized by using a state cancelation mechanism, whilst the false-negative ratio can be optimized by specifying the timeout period as a function of the other parameters. Moreover, we study the system’s scalability behavior by observing the growth of messages overhead that is needed to keep inconsistency ratio constant as the channel’s loss probability increases.	distributed computing;negative feedback;overhead (computing);scalability;signaling protocol;soft state;timeout (computing);while	Melissa Tjiong;Johan J. Lukkien	2009	2009 International Conference on Advanced Information Networking and Applications	10.1109/AINA.2009.130	communications protocol;availability;probability density function;application software;real-time computing;scalability;type i and type ii errors;telecommunications;sensitivity;computer science;theoretical computer science;operating system;wireless network;soft state;distributed computing;consistency;computer security;statistics;computer network	SE	-9.141115456344526	72.8560757722085	61312
670a8f70b6e3a33cf6ff28c4d2e711608cf2524b	pdr: a protocol for dynamic network reconfiguration based on deadlock recovery scheme	dynamic reconfiguration;deadlock detection;fault tolerance;interconnection networks;deadlock recovery	Dynamic network reconfiguration is described as the process of replacing one routing function with another while the network keeps running. The main challenge is avoiding deadlock anomalies while keeping limitations on packet injection and forwarding minimal. Current approaches which have a high complexity and as a result have a limited practical applicability either require the existence of extra network resources, or they will affect the network performance during the reconfiguration process. In this paper we present a simple, fast and efficient mechanism for dynamic network reconfiguration which is based on regressive deadlock recovery instead of avoiding deadlock. The mechanism which is referred to as PDR guarantees a deadlock-free reconfiguration based on wormhole switching. In PDR, a particular approach is taken to handle both deadlocks and performance degradation. We propose the use of a packet injection restriction mechanism that prevents performance degradation near the saturation by controlling the network traffic. Further, in this approach, to accurately detect deadlocks, the deadlock detection mechanism is implemented and also improved by using only the local information, thereby considerably reducing false deadlock detections. In the rare cases when deadlocks are suspected, we propose a new technique that absorbs the deadlocked packet at the current node instead of dropping deadlocked packets and re-injects it later into the network. The main advantage of this method is its simplicity and also it does not require any additional buffers in intermediate nodes to handle deadlocks. It requires only some buffer space in the local node to temporarily hold the deadlocked packets removed from the network. Evaluating results reveal that the mechanism shows substantial performance improvements over the other methods and it works efficiently in different topologies with various routing algorithms. 2012 Elsevier B.V. All rights reserved.	algorithm;deadlock;design review (u.s. government);elegant degradation;interconnection;network on a chip;network packet;network performance;network traffic control;packet switching;requirement;routing;sensor;wormhole switching	Majed Valad Beigi;Farshad Safaei	2012	Simulation Modelling Practice and Theory	10.1016/j.simpat.2012.02.002	fault tolerance;real-time computing;computer science;distributed computing;computer security;deadlock prevention algorithms;computer network	DB	-8.562854198490314	80.29260932621897	61374
2da50df262e07a91aff026fe1133947b8a78951d	design and analysis of green optical line terminal for tdm passive optical networks	optical switches;passive optical networks;energy consumption;optical network units;power demand;epon	Sommario—This paper proposes a novel scheme which can efficiently reduce the energy consumption of Optical Line Terminals (OLTs) in Time Division Multiplexing (TDM) Passive Optical Networks (PONs) such as EPON and GPON. Currently, OLTs consume a significant amount of energy in PON, which is one of the major FTTx technologies. To be environmentally friendly, it is desirable to reduce energy consumption of OLT as much as possible; such requirement becomes even more urgent as OLT keeps increasing its provisioning data rate, and higher data rate provisioning usually implies higher energy consumption. In this paper, we propose a novel energy-efficient OLT structure which guarantees services of end users with the smallest number of power-on OLT line cards. More specifically, we adapt the number of power-on OLT line cards to the real-time incoming traffic. Also, in order to avoid service disruption resulted by powering off OLT line cards, proper optical switches are equipped in OLT to dynamically configure the communications between OLT line cards and ONUs.	chassis;data rate units;denial-of-service attack;ethernet in the first mile;fiber to the x;multiplexing;network switch;optical line termination;optical switch;passive optical network;provisioning;real-time clock;real-time transcription;toad data modeler	Mina Taheri;Nirwan Ansari	2015	CoRR			Networks	-9.44659777498711	87.25609876945126	61375
d23124e8f4a765b04b79de9b4205c50ff5172b64	a proactive customer-aware resource allocation approach for data centers	service level agreements;resource management;resource allocation computer centres contracts internet;self adaptation;servers;monitoring;web services;web sites;predictive models;response time data center resource allocation service level agreements internet application workload predictions proactive allocation strategy overall resource utilization;data center optimization;web services web sites resource management predictive models servers monitoring;proactive resource allocation;service level agreements web services self adaptation data center optimization proactive resource allocation	Internet application workloads typically vary over time, periods of low demand alternate with spikes which, if not properly handled, can saturate the allocated infrastructure and violate Service Level Agreements. In this work, we leverage the usage patterns associated with the different customers of an Internet application to make tailored workload predictions. These workload predictions are then used to proactively adapt the allocation of resources in a data center right before load spikes happen. Such proactive allocation strategy improves the overall resource utilization and, at the same time, guarantees the service level agreements. A real life prototype has been implemented to compare our solution with both over-provisioning and reactive approaches. Results show up to 60% reduction in response time over a reactive approach with the same adaptation frequency, and up to 84% reduction in the amount of resources allocated compared to a typical over-provisioning approach.	data center;denial-of-service attack;job stream;openvms;proactive parallel suite;prototype;provisioning;real life;response time (technology);rich internet application;scheduling (computing);service-level agreement;throughput;web service	Filippo Seracini;Xiang Zhang;Tajana Simunic;Ingolf Krüger	2014	2014 IEEE International Symposium on Parallel and Distributed Processing with Applications	10.1109/ISPA.2014.13	web service;simulation;resource allocation;computer science;knowledge management;resource management;operating system;predictive modelling;server	Metrics	-23.69972200534805	62.10502827227698	61473
302362c21f9c01d0550720d2f0ededc16b6aaa40	d3w: towards self-management of distributed data-driven workflows with qos guarantees	multimedia streaming;multi cloud;distributed workflows	Data-driven application workflows that leverage compute capabilities and hosted services near the network edge can support latency-sensitive and critical applications in emerging areas such as Internet of Things (IoT) and smart infrastructure. However, distributed instantiation and execution of these workflows using resources across service providers and datacenters can be challenging. In this paper, we present the formulation of a decentralized workflow management approach for the autonomous instantiation and execution of dynamic data-driven workflows based on the opportunistic discovery and composition of services on-demand. Given a workflow template specification, this approach allows us to decouple workflow stages, allowing the execution of different stages to be performed by individual services, which are discovered and instantiated dynamically, and can be independently scaled as needed. These services may be geographically distributed and may be offered by different service providers using various QoS levels and cost models. The design, implementation and experimental evaluation of a decentralized workflow management framework using a live media stream application in a multi-cloud infrastructure is presented. Evaluations using a sample topology shows up to 2.5 times increase in QoS-meeting throughput when using our dynamic multi-cloud approach instead of using a fixed centralized cloud of identical capacity.	autonomous robot;centralized computing;cloud computing;dynamic data;internet of things;quality of service;self-management (computer science);throughput;universal instantiation	Mengsong Zou;Javier Diaz Montes;Kiran Nagaraja;Nimish Radia;Manish Parashar	2016	2016 IEEE 9th International Conference on Cloud Computing (CLOUD)	10.1109/CLOUD.2016.0029	real-time computing;computer science;database;distributed computing;workflow management system	HPC	-26.497748946846926	61.85048189631899	61513
6bc82351afd1df29264f0904b0edf8d7af8c2d7c	streamsmart: p2p video streaming for smartphones through the cloud	video streaming;video streaming cloud computing multimedia communication peer to peer computing real time systems smart phones;cloud clone streamsmart p2p video streaming smartphones inherent connectivity internet multimedia content content sharing real time video streaming unique server virtual p2p network smartphone software clones;smart phones;cloning streaming media smart phones real time systems servers watches protocols;multimedia communication;peer to peer computing;cloud computing;real time systems	Thanks to their power, the many sensors they embed, and their inherent connectivity to Internet, smartphones are certainly becoming the primary source of multimedia content and the main tool for content sharing. In this demo, we analyze the complexity of real-time video streaming among smartphone users. Firstly, we show that the traditional solution-a unique server receiving and dispatching all devices' content-suffers from scalability issues. Then, we present StreamSmart, a distributed system for real-time video streaming of smartphones, that leverages a virtual P2P network of smartphone software clones on the cloud. In StreamSmart, the captured content is forwarded from the sharing device to its own cloud clone, that in turn forwards it to the clones of other users. These latter transmit the content to the respective devices and, at the same time, contribute to further spread it to other possible clones in the network. We show that the StreamSmart system is highly scalable, responsive, and fault tolerant.	distributed computing;fault tolerance;hp prime;ibm pc compatible;internet;primary source;real-time clock;scalability;sensor;server (computing);smartphone;streaming media	Alessandro Gaeta;Sokol Kosta;Julinda Stefa;Alessandro Mei	2013	2013 IEEE International Conference on Sensing, Communications and Networking (SECON)	10.1109/SAHCN.2013.6644983	embedded system;real-time computing;cloud computing;computer science;operating system;multimedia;internet privacy;computer network	Mobile	-20.49650823995442	76.9435743011877	61569
b7b2cdaa3dfff14512e9b508c07c4190a044dc42	an analysis of the end system heterogeneity in many-to-many application layer multicast	internet protocol;distributed system;red sin hilo;systeme reparti;informatique mobile;protocolo internet;reseau sans fil;process capability;ip multicast;wireless network;protocole internet;multidestinatario;network simulator;simulator;sistema repartido;simulador;heterogeneidad;adaptive applications;retard;simulateur;mobile computing;retraso;multidestinataire;multicast;heterogeneity;heterogeneite;application layer multicast	The lack of the IP multicast deployment and the increased interest of the multi-party applications promotes the use of application layer multicast. The existing many-to-many application layer multicast schemes, Narada, TBCP, and NICE do not concern the heterogeneity of the processing capability of the end systems. We propose the modification of the existing schemes that considers the processing delay in the delivery tree construction algorithm. The performance of the modified versions are evaluated and compared with the original version using the network simulator. The analysis results and the modification proposal can be used as the basis to design a scalable and adaptable application layer multicast schemes.	end system;many-to-many;multicast	Kyungran Kang;Sunghoon Kim;Dongman Lee	2004		10.1007/978-3-540-25978-7_103	internet protocol;multicast;ip multicast;process capability;inter-domain;reliable multicast;telecommunications;protocol independent multicast;computer science;heterogeneity;wireless network;pragmatic general multicast;network simulation;distributed computing;distance vector multicast routing protocol;source-specific multicast;mobile computing;xcast;computer network;multicast address	EDA	-4.712651987954658	76.12717470773582	61816
e38034eae624134385a1bbef2d52e1404f5b1695	design principles of generalized network orchestrators	heating;computer network management;business;cloud computing music conductors context business heating;music;context;design principles orchestration definitions networking technologies generalized orchestration generalized network orchestrators;service chaining orchestration nfv sdn clouds network management;cloud computing;conductors	This paper deals with a concept of generalized orchestration applicable to a broad scope of networking technologies. Orchestration is a relatively new concept, which definition and scope is not clearly defined yet. Moreover, the relationship between orchestration and management brings many confusions. In the first part of the paper an analysis of different orchestration definitions is presented and on that basis the key orchestration properties are developed. In the second part of the paper a concept of orchestration that can be used in heterogeneous environment is drawn. The described concept can be seen as a first step towards the definition of generalized network orchestration.	control system;flow network;orchestration (computing);proxy server;software deployment	Slawomir Kuklinski;Khoa Truong Dinh;Christian Destré;Imen Grida Ben Yahia	2016	2016 IEEE International Conference on Communications Workshops (ICC)	10.1109/ICCW.2016.7503825	simulation;cloud computing;computer science;knowledge management;operating system;music;world wide web	Robotics	-16.518452034596933	84.35999883534289	61879
15296a68e170cc1d4c0f69ef152c0da073a34fea	multi-dimensional incentive mechanism in mobile crowdsourcing with moral hazard	crowdsourcing;contracts;google;mobile computing;ethics;hazards;smart phones	In current wireless communication systems, there is a rapid development of location based services, which will play an essential role in the future 5G networks. One key feature in providing the service is the mobile crowdsourcing in which a central cloud node denoted as the principal collects location based data from a large group of users. In this paper, we investigate the problem of how to provide continuous incentives based on user’s performances to encourage users’ participation in the crowdsourcing, which can be referred to the moral hazard problem in the contract theory. We not only propose the one-dimensional performance-reward related contract, but also extend this basic model into the multi-dimensional contract. First, an incentive contract which rewards users by evaluating their performances from multiple dimensions is proposed. Then, the utility maximization problem of the principal in both one-dimension and multi-dimension are formulated. Furthermore, we detailed the analysis of the multi-dimensional contract to allocate incentives. Finally, we use the numerical results to analyze the optimal reward package, and compare the principal’s utility under the different incentive mechanisms. Results demonstrate that by using the proposed incentive mechanism, the principal successfully maximizes the utilities, and the users obtain continuous incentives to participate in the crowdsourcing activity.	crowdsourcing;expectation–maximization algorithm;location-based service;moral hazard;numerical analysis;performance;utility	Yanru Zhang;Yunan Gu;Miao Pan;Nguyen H. Tran;Zaher Dawy;Zhu Han	2018	IEEE Transactions on Mobile Computing	10.1109/TMC.2017.2732982	distributed computing;cloud computing;incentive;contract theory;computer science;mobile computing;utility maximization problem;location-based service;crowdsourcing;moral hazard	Web+IR	-23.891253711503154	75.92445053976633	61895
4d3823473e96fd868a78b935b3931ab570f8f370	evaluation of loadsharing algorithms for heterogeneous distributed systems	qa mathematics;performance;simulation;power distribution;performance metric;heterogeneous distributed system;network of workstation;loadsharing;tk electrical engineering electronics nuclear engineering electric circuits electronic circuits;communication delay;heterogeneous networks;tk electrical engineering electronics nuclear engineering;heterogeneous network;qa76 computer software	The performance of loadsharing algorithms for heterogeneous distributed systems is investigated by simulation. The systems considered are networks of workstations (nodes) which differ in processing power. Two parameters are proposed for characterising system heterogeneity, namely the variance and skew of the distribution of processing power among the network nodes. A variety of networks are investigated, with the same number of nodes and total processing power, but with the processing power distributed differently among the nodes. Two loadsharing algorithms are evaluated, at overall system loadings of 50% and 90%, using job response time as the performance metric. Comparison is made with the ideal situation of 'perfect sharing', where it is assumed that the communication delays are zero and that complete knowledge is available about job lengths and the loading at the different nodes, so that an arriving job can be sent to the node where it will be completed in the shortest time. The algorithms studied are based on those already in use for homogeneous networks, but were adapted to take account of system heterogeneity. Both algorithms take into account the differences in the processing powers of the nodes in their location policies, but differ in the extent to which they 'discriminate' against the slower nodes. It is seen that the relative performance of the two is strongly influenced by the system utilisation and the distribution of processing power among the nodes.	algorithm;distributed computing	Robert Leslie;Sati McKenzie	1999	Computer Communications	10.1016/S0140-3664(98)00262-X	real-time computing;simulation;heterogeneous network;telecommunications;computer science;operating system;distributed computing;computer network	Theory	-13.814707244255006	63.629241258834746	61902
0867698aa852bdfd4586d0c1be9b74d45aa3d8a7	issues with private ip addressing in the internet		The purpose of this document is to provide a discussion of the potential problems of using private, RFC 1918, or non-globally routable addressing within the core of a Service Provider (SP) network. The discussion focuses on link addresses and, to a small extent, loopback addresses. While many of the issues are well recognised within the ISP community, there appears to be no document that collectively describes the issues.	internet;loopback;private ip;private network;routing	Anthony Kirkham	2012	RFC	10.17487/RFC6752	reserved ip addresses;engineering;world wide web;computer security;private network;computer network	Networks	-24.969380281682707	86.59601150368924	61920
4e4227c7bb6ebbb8bfd7d2d091cee741bf39fdb0	performance enhancement techniques for infiniband? architecture	packet routing;multicast communication;design tradeoffs performance enhancement techniques infiniband architecture system area networks san iba specification shortest path first algorithm spf algorithm deterministic packet routing multipath routing mechanism congestion minimization selective packet dropping deadlock multicasting support customized applications integrated workload simulation testbed clusters;performance evaluation;shortest path first;perforation;telecommunication congestion control;packet switching;deterministic algorithms;multi path routing;telecommunication network routing;concurrency control;switches routing system recovery multicast algorithms traffic control communication system traffic control computer architecture clustering algorithms delay ofdm modulation;multipath routing;local area networks;multicast communication performance evaluation local area networks telecommunication network routing deterministic algorithms packet switching telecommunication congestion control concurrency control	InfiniBandTM Architecture (IBA) is envisioned to be the default communication fabric for future system area networks (SANs). However, the released IBA specification outlines only higher level functionalities, leaving it open for exploring various design alternatives. In this paper, we investigate four co-related techniques to provide high and predictable performance in IBA. These are: (i) using the Shortest Path First (SPF) algorithm for deterministic packet routing; (ii) developing a multipath routing mechanism for minimizing congestion; (iii) developing a selective packet dropping scheme to handle deadlock and congestion; and (iv) providing multicasting support for customized applications. These designs are evaluated using an integrated workload on a versatile IBA simulation testbed. Simulation results indicate that the SPF routing, multipath routing, packet dropping, and multicasting schemes are quite effective in delivering high and assured performance in clusters. One of the major contributions of this research is the IBA simulation testbed, which is an essential tool to evaluate various design tradeoffs.	data recovery;deadlock;dijkstra's algorithm;infiniband;multicast;multipath routing;network congestion;network packet;simulation;testbed	Eun Jung Kim;Ki Hwan Yum;Chita R. Das;Mazin S. Yousif;José Duato	2003		10.1109/HPCA.2003.1183543	local area network;parallel computing;real-time computing;computer science;multipath routing;concurrency control;distributed computing;packet switching;computer network	Arch	-4.659662412383266	85.70092946657701	61967
28a9cf51d4310edceef96a6bddcf101e7baf31b4	caching strategy on mobile rich media engine	character drawing mode;computers;cache storage;resource limitation;mobile device;multimedia systems cache storage mobile computing;character cache;multimedia systems;media;time factors;caching strategy;engines;cache replacement;theoretical analysis;cache replacement policy;cache resources caching strategy mobile rich media engine character drawing mode cache replacement policy;mobile communication;mobile handsets;cache resources;rich media engine character cache mobile device replacement strategy;optimization;mobile rich media engine;rich media engine;mobile computing;replacement strategy;mobile communication media engines mobile handsets optimization time factors computers	With the increasing development of mobile rich media applications, it has become an important research topic on how to reduce application response time so as to run more smoothly on resource-limited devices. On the basis of the in-depth study of character drawing mode, cache replacement policy and full use of the cache resources, this paper presents a strategy to cache the characters of mobile rich media pages. The detailed structure, replacement strategies, etc. of this caching strategy are also discussed. Theoretical analysis and simulation data show that the strategy can effectively reduce application’s response time, bringing users more smooth experiences.	cache (computing);experience;interactive media;response time (technology);simulation;smoothing	Xin Min;Jixian Zhang;Lei Luo	2010	2010 10th IEEE International Conference on Computer and Information Technology	10.1109/CIT.2010.368	real-time computing;media;mobile telephony;computer hardware;cache;computer science;operating system;mobile device;database;mobile computing;cache algorithms;world wide web	Robotics	-20.598947434950308	73.96117583666948	62057
f4214aeb73eba46393b9c1267ae0931a8b89ff51	relational network manager for ip networks	ip network;snmp;network management;mib;relational database;data consistency;data management;query language	This paper deals with an issue of effective network management for an enterprise IP network. It focuses on SNMP based protocols that are widely used in current network management. The major problem with the SNMP based network management is that it does not provide network managers with a unified picture of the network when the network manager may query the network from several SNMP tables with a single request. Furthermore, SNMP does not provide network manager with historical network information. In this paper we propose a new network management tool that is also based on SNMP but uses a relational database approach to the storing and accessing the SNMP data. Our tool uses SQL query language to access network information and allows network manager to keep network historical information. The major advantage of our tool is in guaranteeing scalability and network data management data consistency.	access network;connectionism;internet protocol suite;query language;relational database;sql;scalability;select (sql);simple network management protocol	Yuri Breitbart;Deepakraj Shanthilal	2004			sql;relational model;database;network management;network management station;relational database;ip address management;database model;network management application;computer science	DB	-21.75480098601059	85.80064196141677	62143
0df9dd09fc8582a90e4832db2bb15111f071a8ab	a sip servlets-based framework for service provisioning in stand-alone manets	value added services;manets;overlay networks;sip servlets;business model	Mobile Ad hoc Networks (MANETs) are transient networks formed dynamically by a collection of arbitrarily located wireless mobile nodes without relying on any existing network infrastructure or centralized administration. They are either stand alone or connected to a fixed infrastructure such as 3G. They are useful in situations such as natural disasters, and their use is gaining more and more momentum. This paper proposes a framework for service provisioning in stand-alone MANETs. It focuses on the invocation and execution phases of the service life cycle. The framework is based on SIP servlets and comprises a novel business model and an overlay network. The business model enables service invocation and execution. The overlay network is used for service execution and is based on a distributed SIP servlets engine. Validation aspects are also discussed.		Slimane Bah;Roch H. Glitho;Rachida Dssouli	2013	J. Network and Computer Applications	10.1016/j.jnca.2012.10.005	business model;overlay network;computer science;world wide web;computer security;computer network	HPC	-18.64457839884642	81.59526277459287	62287
1b82a3690a5e6f307e928cad2f18dee5b56c596a	connection and performance model driven optimization of pageview response time	delay web server admission control html cost function containers network servers internet switches protocols;optimisation;electronic commerce;queueing theory electronic commerce internet online front ends optimisation quality of service;network protocol;optimal qos;e commerce;queueing theory;web servers;model performance;e commerce environment;network protocol layers;data mining;online front ends;html;web browsers;time factors;class of service;internet;connection and performance model driven optimization;client perceived pageview response time;latency model;performance model;web server;pageview drop rate;quality of service;server performance model;inter arrival time client perceived pageview response time e commerce environment connection and performance model driven optimization optimal qos pageview drop rate network protocol layers web browsers web servers latency model server performance model queueing theory;inter arrival time;containers;admission control	Managing client perceived pageview response time for multiple classes of service is essential in today's highly competitive, e-commerce environment. We present Connection and Performance Model Driven Optimization (CP-MDO), a novel approach for providing optimal QoS as defined by a cost objective based on client perceived pageview response time and pageview drop rate. Our approach combines two vital models: 1) a latency model for connection establishment that captures the interactions between web browsers and web servers across network protocol layers and 2) a server performance model based on queueing theory that models performance across all tiers of a server complex. An algorithm capable of enforcing the optimal admission control based on the inter-arrival time between pageview admissions is given. Our approach has been implemented and evaluated in an experimental setting, demonstrating how CP-MDO achieves the minimal cost while providing minimal pageview response times under minimal drop rates across multiple classes of service.	algorithm;cp/m;client–server model;communications protocol;database server;e-commerce;interaction;mathematical optimization;multidisciplinary design optimization;multitier architecture;page view;quality of service;queueing theory;response time (technology);server (computing);server-side;time of arrival;web application;web server	Dinesh Kumar;David P. Olshefski;Li Zhang	2009	2009 IEEE International Symposium on Modeling, Analysis & Simulation of Computer and Telecommunication Systems	10.1109/MASCOT.2009.5366184	e-commerce;real-time computing;computer science;operating system;world wide web;web server;computer network	Metrics	-19.787273215259034	68.22286374524118	62374
74f335295275568c06c8bfee288401254f69c83b	using network node description language for modeling networking scenarios	documenting computer networks;virtual network laboratories;virtual network scenarios;xml based language;node description language;language design	0965-9978/$ see front matter 2011 Elsevier Ltd. A doi:10.1016/j.advengsoft.2011.08.004 ⇑ Corresponding author. Tel.: +381 23 550 515; fax E-mail addresses: ddobrilo@tfzr.rs (D. Dobrilo (Z. Stojanov), bodadzic@tfzr.uns.ac.rs (B. Odadzic), mar 1 Tel.: +381 23 550 515; fax: +381 23 550 520. This paper presents an approach for designing a language for network description, leading to a Network Node Description Language (NNDL). NNDL is generic and platform independent XML based language designed to describe a complete configuration of each network node. The node description in NNDL has all necessary information for the nodes configurations, from the common IPv4 and IPv6 addressing, firewall settings, static and dynamic routing to the complete description of the network services configuration. It provides the basis for description of a wide range of virtual network laboratory scenarios. The language has been tested in a virtual network laboratory VNLab used in a university networking course. With the introduction of NNDL language, VNLab environment becomes more flexible in terms of number of available scenarios and the time needed to create and modify them. Some extensions of NNDL for documenting computer networks are also explored in this paper. 2011 Elsevier Ltd. All rights reserved.	cognitive dimensions of notations;fax;firewall (computing);hypertext transfer protocol;network description language;refinement (computing);routing;software documentation;virtual machine;xml	Dalibor Dobrilovic;Zeljko Stojanov;Borislav Odadzic;Branko Markoski	2012	Advances in Engineering Software	10.1016/j.advengsoft.2011.08.004	intelligent computer network;computer science;theoretical computer science;network simulation;distributed computing;programming language;world wide web	Networks	-22.261621519257698	87.37017819679856	62406
3a3b22804238939d9d3ed14ab147ddc15ffa9e84	border gateway protocol (bgp)		"""A Border Gateway Protocol (BGP) Status of this Memo This RFC outlines a specific approach for the exchange of network reachability information between Autonomous Systems. At the time of this writing, the Border Gateway Protocol implementations exist for cisco routers as well as for the NSFNET Nodal Switching Systems. A public domain version for """"gated"""" is currently being implemented. Distribution of this memo is unlimited."""	autonomous system (internet);border gateway protocol;national science foundation network;reachability	Kirk Lougheed;Jakob Rekhter	1989	RFC	10.17487/RFC1105	is-is;performance-enhancing proxy;secure neighbor discovery;autonomous system;border gateway protocol;extensible authentication protocol;computer science;management information base;service location protocol;distributed computing;trivial file transfer protocol;simple network management protocol;dynamic host configuration protocol;computer security;private network;computer network;open shortest path first	Networks	-24.088926836319622	88.1721057934681	62417
27043e48ee365965ebf49986adb26255e674824b	a transport-layer network for distributed fpga platforms	flow control field programmable gate arrays;field programmable gate arrays bandwidth protocols aerospace electronics prototypes resource management computer architecture;bit rate 420 gbit s distributed fpga platforms transport layer network virtual channels end to end flow control error characteristic rack level fpga network low overhead credit source code buffer size scarce on chip memory resources traffic pattern xilinx vc707 boards serial links	We present a transport-layer network that aids developers in building safe, high-performance distributed FPGA applications. Two essential features of such a network are virtual channels and end-to-end flow control. Our network implements these features, taking advantage of the low error characteristic of a rack level FPGA network to implement a low overhead credit based end-to-end flow control. Our design has many parameters in the source code which can be set at the time of FPGA synthesis, to provide flexibility in setting buffer size and flow control credits to make best use of scarce on-chip memory resources and match the traffic pattern of a virtual channel. Our prototype cluster, which is composed of 20 Xilinx VC707 boards, each with 4 20Gb/s serial links, achieves effective bandwidth of 85% of the maximum physical bandwidth, and a latency of 0.5us per hop. User feedback suggest that these features make distributed application development significantly easier.	communication endpoint;distributed computing;end-to-end principle;field-programmable gate array;flow control (data);lossless compression;overhead (computing);prototype;quanta computer;requirement;virtual channel	Sang Woo Jun;Shuotao Xu;Arvind	2015	2015 25th International Conference on Field Programmable Logic and Applications (FPL)	10.1109/FPL.2015.7293976	embedded system;parallel computing;real-time computing;operating system	Networks	-4.692659150107091	65.1795218683631	62420
05dacaee4f019fc54bd08de950bdbe97bda377ee	preliminary performance analysis of multi-rail fat-tree networks		Among the low-diameter, high-radix networks beingdeployed in next-generation HPC systems, dual-rail fat-treenetworks are a promising approach. Adding additional injectionconnections (rails) to one or more network planes allows multirailfat-tree networks to alleviate communication bottlenecks. These multi-rail networks necessitate new design considerations, such as routing choices, job placements, and scalability of rails. We extend our fat-tree network model in the CODES parallelsimulation framework to support multi-rail and multi-planeconfigurations in addition to different types of static routing, resulting in a powerful research vehicle for fat-tree network analysis. Our detailed packet-level simulations use communicationtraces from real applications to make performance predictionsand to evaluate the impact of single-and multi-rail networks inconjunction with schemes for injection rail selection and intraplane routing.	electrical connection;fat tree;file allocation table;multigrid method;network model;network packet;profiling (computer programming);router (computing);routing;scalability;simulation;supercomputer;tree network	Noah Wolfe;Misbah Mubarak;Nikhil Jain;Jens Domke;Abhinav Bhatele;Christopher D. Carothers;Robert B. Ross	2017	2017 17th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing (CCGRID)		distributed computing;real-time computing;dynamic source routing;network analysis;fat tree;network topology;scalability;computer science;network model;infiniband;static routing	Arch	-11.756559416875257	80.22329598581784	62435
f79bb4839d03655fd7288d0f49fcf246b1ebf211	challenges with transition and user accounting in next generation networks	protocols internet monitoring ip networks organizations hardware probes;protocols;probes;internet;monitoring;protocols ip networks next generation networks;ip networks;organizations;recursive inter network architecture user accounting next generation networks network administrators network control protocol tcp ip ipv4 ipv6;hardware	Future networks may change the way how network administrators monitor and account their users. History shows that usually a completely new design (clean slate) is used to propose a new network architecture - e.g. Network Control Protocol to TCP/IP, IPv4 to IPv6 or IP to Recursive Inter Network Architecture. The incompatibility between these architectures changes the user accounting process as network administrators have to use different information to identify a user. The paper presents a methodology how it is possible to gather all necessary information needed for smooth transition between two incompatible architectures. The transition from IPv4 and IPv6 is used as a use case, but it should be able to use the same process with any new networking architecture.	clean slate program;internet protocol suite;network architecture;next-generation network;software incompatibility	Matej Grégr;Miroslav Svéda	2014	2014 IEEE 22nd International Conference on Network Protocols	10.1109/ICNP.2014.79	communications protocol;real-time computing;the internet;overlay network;network architecture;next-generation network;ip address management;computer science;organization;ip forwarding;distributed computing;ip tunnel;computer network;amprnet	Visualization	-16.65935140000149	83.95675913646487	62444
751b39dddbb33c535b77dd454002a1fcce34876b	streamer: a distributed framework for incremental closeness centrality computation	distributed memory systems;graph streamer incremental closeness centrality computation traffic pattern modeling social interaction modeling web page modeling cc global metric distributed memory framework closeness centrality score maintenance pipelined parallelism replicated parallelism numa effects;parallel processing distributed memory systems;parallel processing	Networks are commonly used to model the traffic patterns, social interactions, or web pages. The nodes in a network do not possess the same characteristics: some nodes are naturally more connected and some nodes can be more important. Closeness centrality (CC) is a global metric that quantifies how important is a given node in the network. When the network is dynamic and keeps changing, the relative importance of the nodes also changes. The best known algorithm to compute the CC scores makes it impractical to recompute them from scratch after each modification. In this paper, we propose Streamer, a distributed memory framework for incrementally maintaining the closeness centrality scores of a network upon changes. It leverages pipelined and replicated parallelism and takes NUMA effects into account. It speeds up the maintenance of the CC of a real graph with 916K vertices and 4.3M edges by a factor of 497 using a 64 nodes cluster.	algorithm;closeness centrality;computation;correctness (computer science);distributed memory;dynamic problem (algorithms);interaction;news aggregator;parallel computing;pipeline (computing);relevance;speedup;tape drive;web page	Ahmet Erdem Sariyüce;Erik Saule;Kamer Kaya;Ümit V. Çatalyürek	2013	2013 IEEE International Conference on Cluster Computing (CLUSTER)	10.1109/CLUSTER.2013.6702680	parallel processing;parallel computing;computer science;theoretical computer science;alpha centrality;distributed computing;centrality	HPC	-8.493898011724673	69.89557541790558	62474
24d59fe99245948e34dcd43a23e0530387ffe696	the research on the td-scdma-based remote control system	environmental adaptation;microcontrollers;protocols;information transmission;component;wireless communication;code division multiple access;internet;scheduling system;environmental adaptation component network scheduling system information transmission;telecontrol;time division synchronous code division multiple access;ip networks;time division synchronous code division multiple access protocols internet dynamic scheduling wireless communication ip networks channel allocation;control engineering computing;channel allocation;telecontrol code division multiple access control engineering computing home automation ip networks microcontrollers protocols;network;dynamic scheduling;home automation;remote monitoring system td scdma based remote control system system demand single chip core network microcontroller single chip module ipv4 network td scdma protocol multiple appliances infrared communication mode software system modular design method home automation applications remote industrial control areas	On the basis of analyzing the system demand, a remote control system is designed with a single-chip and the core network microcontroller. The system realizes communication between each single-chip module and the IPv4 network using TD-SCDMA protocol. The single-chip controls multiple appliances simultaneously by infrared communication mode. The method to construct the remote control system is proposed. In order to improve the portability and real-time ability of the system, the software system is completely designed by modular design method. Therefore, the results show that the designed system is simple, reliable, and a promising candidate for home automation applications, remote industrial control areas and remote monitoring system.	adaptive coding;business logic;control system;direction of arrival;experiment;home automation;hybrid automatic repeat request;internet of things;location-based service;microcontroller;modular design;modulation;network packet;real-time transcription;remote control;requirement;retransmission (data networks);server (computing);signal processing;smart antenna;software system;telecommunications link;temporal difference learning;thread (computing);web server	Lei Xiao;Lejiang Guo;Fangxin Chen;Yahui Hu	2012	2012 Third International Conference on Digital Manufacturing & Automation	10.1109/ICDMA.2012.221	time-variant system;embedded system;home automation;real-time computing;engineering;remote monitoring and control;computer network	Robotics	-17.303913662151018	87.85980896027925	62521
4bbdbc89f44245bf35ee1d4b39d60fcb20ba9e3b	pitfalls in http traffic measurements and analysis	content-length accuracy;total traffic volume;actual content;content-type header field;content-length header;actual transmitted volume;traffic analysis;content-type mismatch;european residential broadband customer;passive traffic measurement	Being responsible for more than half of the total traffic volu me in the Internet, HTTP is a popular subject for traffic analysis. Fro m ur experiences with HTTP traffic analysis we identified a number of pitfalls w hich can render a carefully executed study flawed. Often these pitfalls can be avoided easily. Based on passive traffic measurements of 20.000 European resident ial broadband customers, we quantify the potential error of three issues: Non -c sideration of persistent or pipelined HTTP requests, mismatches between the Cont nt-Type header field and the actual content, and mismatches between the Content-Length header and the actual transmitted volume. We find that 60 % (30 %) of al l HTTP requests (bytes) are persistent (i. e., not the first in a TCP con nection) and 4 % are pipelined. Moreover, we observe a Content-Type mismatch for 35 % of the total HTTP volume. In terms of Content-Length accuracy our data shows a factor of at least 3.2 more bytes reported in the HTTP header than actuall y tr nsferred.	byte;digital distribution;download;http pipelining;hypertext transfer protocol;list of http header fields;mike lesser;naruto shippuden: clash of ninja revolution 3;network packet;persistence (computer science);persistent data structure;pipeline (computing);traffic analysis;web service	Fabian R N Schneider;Bernhard Ager;Gregor Maier;Anja Feldmann;Steve Uhlig	2012		10.1007/978-3-642-28537-0_24	telecommunications;computer science;internet privacy;world wide web;computer security;computer network	Metrics	-26.894007226247886	84.36878201722776	62531
0cd95dfeb770fe94ae1bccf499537511a5d1fe36	from protocol stack to protocol heap: role-based architecture	layered architecture;network protocol;ucl;metadata;discovery;theses;role based;conference proceedings;feature interaction;signaling;digital web resources;design and implementation;ucl discovery;open access;ucl library;network architecture;modularity;book chapters;open access repository;processing rules;ucl research;non layered architecture	Questioning whether layering is still an adequate foundation for networking architectures, this paper investigates non-layered approaches to the design and implementation of network protocols. The goals are greater flexibility and control with fewer feature interaction problems. The paper further proposes a specific non-layered paradigm called role-based architecture.	communications protocol;feature interaction problem;programming paradigm;protocol stack	Robert Braden;Theodore Faber;Mark Handley	2003	Computer Communication Review	10.1145/774763.774765	signalling;communications protocol;network architecture;computer science;multitier architecture;operating system;database;modularity;metadata;world wide web;computer network	Networks	-25.494714719621296	81.3573669366422	62611
d79d3f9bca54878145c9c3863282d288e7a5e797	balancing electricity bill and performance in server farms with setup costs	performance evaluation;impatient customers;optimization;distributed systems;green computing	High electricity consumption, associated with running Internet scale server farms, not only reflects on the data center’s greenhouse gas emissions, but also increases the cost of running the data center itself. In this paper, we consider the problem of maximizing the revenues of service providers running large scale data centers subject to setup cost by reducing their electricity bill, while considering the fact that clients consuming the offered services have finite non-deterministic patience. As a solution, we present and evaluate the performance of allocation policies which, in the context of both one and two-tiered systems, dynamically switch servers on and off according to changes in user demand. The algorithms we present aim at maximizing the users’ experience while minimizing the amount of electricity required to run the IT infrastructure in spite of non-stationary traffic which cannot be predicted with the absolute accuracy. The results of several experiments are presented, showing that the proposed schemes perform well under different traffic conditions. © 2011 Elsevier B.V. All rights reserved.	algorithm;computer cooling;data center;experiment;failure rate;file allocation table;heuristic;hypertext transfer protocol;job stream;multitier architecture;provisioning;server (computing);server farm;stationary process;tracing (software);wikipedia;yet another	Michele Mazzucco;Dmytro Dyachuk	2012	Future Generation Comp. Syst.	10.1016/j.future.2011.04.015	green computing;real-time computing;simulation;computer science;operating system;distributed computing;computer security	Metrics	-22.451001053741006	62.86215876551205	62767
4d4eda6f2c461ea693c81d35f7e27b7eaa3544fa	general bounds for the assignment of irregular dependency graphs	instruction level parallel;optimal solution;dependence graph;communication delay;generalization bounds	Abst rac t . Given an irregular dependency graph consisting of interdependent tasks, the problem of finding an optima] assignment on a number of parallel execution units is NP-complete. Assignment schemes thus settle for some heuristics that produce sub-optimal solutions. Most popular of these are the work-greedy assignment schemes. This paper presents new bounds on the performance of work-greedy schemes, taking into account the degree of parallelism visible between the tasks and the inter-task communication delays.	assignment (computer science);degree of parallelism;execution unit;greedy algorithm;heuristic (computer science);inter-process communication;interdependence;np-completeness;parallel computing	Sathiamoorthy Manoharan	1995		10.1007/3-540-60321-2_7	mathematical optimization;combinatorics;discrete mathematics;mathematics	PL	-11.863976858046753	61.3751606107465	62812
a5b719aaee7fbf6603bdb38aad66a3679ec67fac	a distributed event-based system based on compressed fragmented-iterated bloom filters	bloom filter;wireless sensor network;distributed event based system;iterated hash function;compressed bloom filter	In this research, we propose the construction of a new architecture of Fragmented-Iterated Bloom Filters to redirect events of a distributed event-based system. We introduce two novel structures of Bloom Filters: Fragmented Bloom Filters and Iterated Bloom Filters. The aim of Iterated Bloom Filters is to discard single events that do not match any subscription. Then, Fragmented Bloom Filters deal with conjunctive and disjunctive set of events. Whether a match is found at the Fragmented Bloom Filters the publication is forwarded. Our strategy is compared to the alternative one relying on Standard Bloom Filters. The results show that Fragmented Bloom Filters lead to save memory and computational resources at the membership test. Moreover, we show that there is no memory cost for dividing a Bloom Filter in smaller Bloom Filters using the same: (1) number of elements to insert and (2) probability of false positives. Then, we prove that fast hash functions required for Fragmented Bloom Filters present a lower complexity that those required for Standard Bloom Filters. Additionally, we determine that the double hashing technique does not result in a lower complexity. Afterwards, we show that the construction of a structure of Iterated Bloom Filters using an Iterated Hash Function reduces the complexity because smaller filters and less hash functions are required. Furthermore, if information is structured in a tree Iterated Bloom Filters decrease the probability of false positives. We also focus on the improvement of data exchange for updating Fragmented-Iterated Bloom Filters between nodes. The goal is to reduce data transmitted. For this purpose, we study the effect of compressing Fragmented-Iterated Bloom Filters. The main benefit of Compressed Bloom Filters is that they transmit less bits. Therefore, less bandwidth is required and the latency of the network is reduced. The choice of Compressed Fragmented Bloom Filters preserves all these positive effects by limiting the number of transmitted bits due to its flexible structure. Besides, Compressed Iterated Bloom Filters also decrease computation.	bloom filter;iterated function	Cristina Muñoz;Pierre Leone	2017	Future Generation Comp. Syst.	10.1016/j.future.2017.02.021	latency (engineering);iterated function;real-time computing;architecture;double hashing;computer science;hash function;distributed computing;bloom filter;bandwidth (signal processing);division (mathematics)	Arch	-7.949711210331869	68.55989667171245	62831
e39d1683a00cca8483ec3bbc6fe5ef774af88a52	dives: a distributed support for networked virtual environments	publish routing mechanism;optimisation;dives;filtering theory virtual reality peer to peer computing optimisation subscriber loops telecommunication network routing telecommunication traffic approximation theory;peer to peer network;dynamic reconfiguration;routing;filters;virtual reality;optimization strategy;approximation theory;telecommunication traffic;subscribe routing mechanism;telecommunication network routing;subscriber loops;information exchange;publish subscribe;filter approximation;distributed virtual environment;distributed support;avatars;bandwidth;filter approximation distributed support networked virtual environment dives peer to peer network optimization strategy publish routing mechanism subscribe routing mechanism message traffic;message traffic;shape control;interaction model;broadcasting;peer to peer computing;virtual environment;networked virtual environment;filters avatars virtual environment routing telecommunication traffic wide area networks shape control broadcasting bandwidth publish subscribe;filtering theory;wide area networks	This paper presents DiVES, a distributed support for the development of networked distributed virtual environments. DiVES exploits the publish subscribe interaction model to define a flexible communication support. An acyclic peer-to-peer network of brokers has been defined to support an event based communication framework. The network can be dynamically reconfigured and it can tolerate broker crashes by a proper recovery mechanism. A set of optimization strategies of the basic publish/subscribe routing mechanism has been defined through an accurate analysis of the information exchanged in DVE applications. The message traffic on the network is reduced by packing notifications and filters into a single message. Furthermore, approximated filters are introduced to further reduce message traffic. Advertisements are exploited to optimize the routing of filters.	approximation algorithm;digital video effect;directed acyclic graph;mathematical optimization;peer-to-peer;publish–subscribe pattern;routing;set packing;virtual reality	A. Bonotti;Luca Genovali;Laura Ricci	2006	20th International Conference on Advanced Information Networking and Applications - Volume 1 (AINA'06)	10.1109/AINA.2006.153	routing;real-time computing;information exchange;telecommunications;computer science;virtual machine;operating system;distributed computing;virtual reality;publish–subscribe pattern;broadcasting;bandwidth;statistics;computer network;approximation theory	HPC	-10.113327860084715	75.77255082891212	62841
95d7c4ac102333c1a15754dc1a0f4e62dfc582e9	self-stabilizing pif algorithm in arbitrary rooted networks	distributed algorithms;protocols;deterministic distributed pif protocol;self stabilizing pif algorithm;tree;fault tolerant;arbitrary rooted networks;trees mathematics protocols distributed algorithms deterministic algorithms;distributed computing;propagation of information with feedback protocol;trees mathematics;tree graphs;self stabilizing wave protocol;intelligent networks feedback protocols tree graphs broadcasting distributed computing algorithm design and analysis fault tolerance computer science fault detection;deterministic algorithms;feedback;fault detection;fault tolerance;fault tolerance self stabilizing pif algorithm arbitrary rooted networks deterministic distributed pif protocol propagation of information with feedback protocol tree self stabilizing wave protocol;intelligent networks;spanning tree;computer science;broadcasting;propagation of information with feedback;algorithm design and analysis	We present a deterministic distributed Propagation of Information with Feedback (PIF) protocol in arbitrary rooted networks. The proposed algorithm does not use a preconstructed spanning tree. The protocol is self-stabilizing, meaning that starting from an arbitrary state (in response to an arbitrary perturbation modifying the memory state), it is guaranteed to behave according to its specification. Every PIF wave initiated by the root inherently creates a tree in the graph. So, the tree is dynamically created according to the progress of the PIF wave. This allows our PIF algorithm to take advantage of the relative speed of different components of the network. The proposed algorithm can be easily used to implement any self-stabilizing system which requires a (self-stabilizing) wave protocol running on an arbitrary network.	algorithm;asynchronous i/o;file spanning;path integral formulation;rooted graph;self-stabilization;shortest path problem;spanning tree;tree (data structure)	Alain Cournier;Franck Petit;Vincent Villain;Ajoy Kumar Datta	2001		10.1109/ICDSC.2001.918937	distributed algorithm;fault tolerance;real-time computing;computer science;theoretical computer science;distributed computing	Theory	-6.855621966590814	72.11552223272436	62892
447b558ffb46e0b51d79cd6df4c579b9fb8c5edf	pim-sm configuration and scalability on satellite unidirectional links	routing protocols;internet satellite links routing protocols multicast protocols;feeds;satellite links;join prune message suppression strategy pim sm configuration pim sm scalability satellite unidirectional links nodes pim sm multicast routing protocol multicast traffic flow;telecommunication traffic;internet;multicast protocols;satellites;scalability satellites multicast protocols internet feeds costs routing protocols telecommunication traffic unicast tunneling;scalability;multicast routing;unicast;tunneling	This paper considers satellite unidirectional links having a large number of nodes and discusses the PIM-SM configuration on these links if there is no separate multicast routing information base. Looking closely at the PIM-SM specification documents, we propose a PIM-SM configuration that enables multicast traffic to flow on unidirectional links. We also discuss the scalability of PIM-SM on satellite unidirectional links. We expect that the Join/Prune message suppression strategy is an important element for scaling PIM-	image scaling;multicast;regular expression;routing table;scalability;zero suppression	Achmad Husni Thamrin;Hidetaka Izumiyama;Hiroyuki Kusumoto	2003		10.1109/SAINTW.2003.1210121	multicast;scalability;the internet;ip multicast;inter-domain;telecommunications;protocol independent multicast;computer science;pragmatic general multicast;database;distributed computing;quantum tunnelling;routing protocol;link-state routing protocol;distance vector multicast routing protocol;source-specific multicast;law;satellite;xcast;computer network;multicast address;unicast	Networks	-7.03485467558871	85.49022443611301	63003
a68eca0692c29693bbf5a506621731aacdc8110f	a scalable and license free 5g internet of radio light architecture for services in homes & businesses		In this paper we present a 5G Internet Radio-Light (IoRL) architecture for homes that can be readily deployed because it utilizes unlicensed visible light and millimeter wave part of the spectrum, which does not require Mobile Network Operator (MNO) permission to deploy and which is used to provide inhabitants of houses with accurate location, interaction, access to Internet and Cloud based services such as high resolution video on a Tablet PC. The paper describes the home use cases and the IoRL architecture.		John Cosmas;Ben Meunier;Kareem Ali;Nawar Jawad;Mukhald A. Salih;Hongying Meng;Martin Ganley;James Gbadamosi;Aleksandar Savov;Zion Hadad;Baruch Globen;Haluk Gokmen;Sibel Malkos;Memduh Emre Cakan;Harilaos Koumaras;Michail-Alexandros Kourtis;Christos Sakkas;Eliron Salomon;Yoav Avinoam;Daniel Nézru	2018	2018 IEEE International Symposium on Broadband Multimedia Systems and Broadcasting (BMSB)	10.1109/BMSB.2018.8436938	license;computer science;computer network;visible light communication;the internet;wireless;mobile network operator;architecture;cloud computing;software-defined networking	Arch	-17.20505920748825	86.79231512644037	63105
1cdb12fe3bc5f518f71add4d43e534361bd7d3c8	a history-based job scheduling mechanism for the vector computing cloud	vector computing;metacomputing job shop scheduling;job shop scheduling;processor scheduling;prototypes;cloud;meta computing;computational modeling;hpc;round robin;job scheduling mechanism;clouds processor scheduling scheduling supercomputers cloud computing computational modeling prototypes;hpc job scheduling grid computing cloud;scheduling;clouds;sx 9 system job scheduling mechanism vector computing meta computing job execution vector supercomputer round robin scheduling mechanism;queueing system;high performance computer;next generation;vector supercomputer;sx 9 system;metacomputing;round robin scheduling mechanism;grid computing;job scheduling;supercomputers;cloud computing;job execution	The wide-area vector meta computing infrastructure named a vector computing cloud has been proposed as a next generation high-performance computing infrastructure. However, in the vector computing cloud, the difference in site policies between organizations causes inefficient usage of vector computing resources. To achieve fairness and efficient job scheduling on the vector computing cloud, this paper presents a history-based job scheduling mechanism for a queue system. The proposed mechanism estimates the time to start the job execution in a queue system from the history of job-execution on vector supercomputers. Based on the estimation, the job scheduling mechanism automatically allocates the job to an appropriate site, which can execute the job earlier. The simulation results show that the proposed job scheduling mechanism improves the utilization efficiency of vector computing resources, compared to the conventional round-robin scheduling mechanism. In addition, the experiment using a prototype of the vector computing cloud indicates that the proposed job scheduling mechanism has enough potential for transparently executing jobs between the two SX-9 systems.	cloud computing;fairness measure;job scheduler;job shop scheduling;job stream;nec sx-9;prototype;round-robin scheduling;scheduling (computing);simulation;supercomputer;vector processor	Yoshitomo Murata;Ryusuke Egawa;Manabu Higashida;Hiroaki Kobayashi	2010	2010 10th IEEE/IPSJ International Symposium on Applications and the Internet	10.1109/SAINT.2010.43	fair-share scheduling;job shop scheduling;parallel computing;real-time computing;flow shop scheduling;cloud computing;computer science;rate-monotonic scheduling;job scheduler;operating system;distributed computing;utility computing;job queue	HPC	-18.871420283391537	60.46193595931572	63121
354f9fa795bea421858b23cb9dbe6acdefdf5a07	a large-scale trojans control model based on layered and p2p structure	network security	In order to achieve large-scale Trojan control in an effective way, a Trojan control model based on layered and P2P structure has been proposed in this paper. According to our model a hundred thousand magnitude Trojan server could be under control. This model could adjust the number of Trojan dynamically by revising the layer number. In addition, the load balancing of severs have been realized by peer-to-peer network which could control large scale Trojan within an acceptable range of system resources consumption. In the end, a prototype system has been established to prove the model validation. The experiment results have shown that the large-scale Trojan control model is effective and powerful.	algorithm;load balancing (computing);peer-to-peer;prototype;server (computing);trojan horse (computing)	Qindong Sun;Xiuwen Sun;Nan Wang;Qian Wang	2014	JSW		real-time computing;simulation;computer science;network security;computer security	OS	-21.716816606671106	73.64056279699874	63128
58c6f150ae7ad913d139bf014c2856fec04f59cf	survey on signaling techniques for cognitive networks	protocols;signalling cognitive radio;signalling;network evolution;building block;signaling cognitive networks;signaling;computer architecture;engines;cognitive radio;monitoring;cross layer signaling signaling techniques cognitive networks self aware autonomous adaptive networking performance degradation;protocols computer architecture ip networks engines monitoring optimization delay;ip networks;optimization;cross layer;cognitive networks	Network evolution towards self-aware autonomous adaptive networking aims at reducing the burden of configuring and managing networks, which leads to performance degradation. In order to optimize network operations, the introduction of self-awareness, self-management, and self-healing into the network was proposed, leading to a novel paradigm in networking - known as cognitive networking. This paper surveys the state-of-the-art, in cognitive networking - identifying fundamental techniques and basic building blocks enabling cognition. Following an overview of existing methods for cross-layer signaling, the paper identifies the most appropriate approaches to be used for cognitive network implementation outlining advantages, drawbacks, and provides guidance for usage of each signaling method.	autonomous robot;cognition;cognitive network;consortium;elegant degradation;informatics;information exchange;programming paradigm;self-awareness;self-management (computer science);software deployment	Dzmitry Kliazovich;Fabrizio Granelli;Nelson Luis Saldanha da Fonseca	2011	2011 IEEE 16th International Workshop on Computer Aided Modeling and Design of Communication Links and Networks (CAMAD)	10.1109/CAMAD.2011.5941118	signalling;active networking;real-time computing;cognitive network;telecommunications;computer science;computer network	Mobile	-13.958860135643683	84.34844687513753	63219
a5f9304aa0ec87bd5ef215858a9a2cec3cb6e98d	a new cgi queueing model designed in embedded web server	tiempo respuesta;common gateway interface;developpement logiciel;file attente;systeme temps reel;modelizacion;reponse temporelle;embedded web server;calculateur embarque;red www;sistema temporizado;real time;timed system;reseau web;queue;response time;embedded system;temps reponse;modelisation;internet;time response;desarrollo logicial;queueing model;temps reel;software development;retard;boarded computer;subroutine;systeme temporise;tiempo real;world wide web;information gateway;real time system;sous programme;sistema tiempo real;service level specification;respuesta temporal;pasarela informacion;retraso;passerelle d information;modeling;fila espera;calculador embarque;subprograma;embedded device	The embedded web servers play very important part in embedded system. Controlling the timing performance of each individual request, such as CGI (Common Gateway Interface), between client and server is a challenging problem. CGI requests/responses not only are the useable access to interaction with the web server in embedded device, but also are executed in web server in real-timing performance of a network close to the service level specification. To ensure the CGI response within a specified time to meet the needs of real-time demand, the principal of the CGI queueing model in embedded web server is studied, and the approach to the problem of meeting relative delay guarantees in web servers is extended. Furthermore, the process of CGI request executed in server is divided into several subroutines, which is useful to reduce the CGI request response time. This web server has been successfully implemented in embedded platform for a real-time controlling system and the tested CGI response performance shows that the new CGI Queueing Model is efficient.	common gateway interface;embedded http server;queueing theory;web server	Xihuang Zhang;Wenbo Xu	2004		10.1007/11535409_43	embedded system;the internet;real-time operating system;systems modeling;computer science;subroutine;software development;web api;operating system;database;common gateway interface;programming language;world wide web;response time;queue;web server;application server	Metrics	-12.15769139408878	64.91318854581307	63311
4c901108b63b6a38075a5395d7dc465a03ce645f	monitoring the spatial-temporal effect of internet traffic based on random matrix theory	eigenvalues and eigenfunctions;spatial temporal effect;service orientation;peer to peer service;p2p;client server systems;matrix algebra;computer network;autonomic system;network topology;telecommunication traffic client server systems internet matrix algebra monitoring peer to peer computing spatiotemporal phenomena telecommunication network topology telecommunication services;telecommunication traffic;servers;client server;internet traffic;internet;monitoring;internet measurement;client server service;temporal pattern;spatiotemporal phenomena;overlay network;telecommunication services;bandwidth;c s service spatial temporal effect internet traffic random matrix theory peer to peer service p2p client server service network topology;c s service;file sharing;correlation;peer to peer computing;telecommunication network topology;random matrix theory;peer to peer;internet eigenvalues and eigenfunctions correlation peer to peer computing monitoring servers bandwidth	Monitoring traffic pattern is always an important approach to improve the performance of computer networks. In recent years, peer-to-peer (P2P) service gradually dominates the Internet traffic against traditional client-server (C-S) service such as Web. The changed situation of networks is mainly in two aspects. One is that popular P2P file-sharing applications require both board downstream and upstream bandwidth, which conflicts to asymmetry structure of the C-S service oriented networks, and another is that the topology of P2P overlay networks is varying with peers joining and leaving. The dramatic shift of Internet traffic may cause different patterns from that observed in early years. This leads a new round of Internet measurement, which requires effective monitoring of network-wide traffic within the region of ISP or autonomous system. Unfortunately, few of technologies can capture well the dynamics of C-S and P2P traffic in a macroscopic level. In this paper, we propose a method based on random matrix theory (RMT) for the detection of networkwide traffic pattern. Using only a few observation points, our method can monitor the macroscopic effect of the Internet traffic. We show that such macroscopic-level monitoring can be used to capture shifts in spatial-temporal patterns caused by P2P and C-S traffic, and inform where and when P2P and C-S traffic possibly arise in transit networks.	autonomous system (internet);client–server model;downstream (software development);file sharing;internet;overlay network;peer-to-peer;server (computing);virtual economy	Jia Liu;Wenzhu Zhang;Jian Yuan;Depeng Jin;Lieguang Zeng	2008	2008 33rd IEEE Conference on Local Computer Networks (LCN)	10.1109/LCN.2008.4664178	traffic generation model;the internet;overlay network;internet traffic;computer science;telecommunications service;random matrix;peer-to-peer;distributed computing;traffic shaping;world wide web;correlation;file sharing;network topology;bandwidth;client–server model;server;internet traffic engineering;computer network	Metrics	-10.927348478380436	77.94506786631182	63342
4840dbcf5e0d60d12e4c5c0fa2f3f8d124d380a1	measuring the effectiveness of hierarchical address assignment	internet routing semantics peer to peer computing government aggregates ieee communications society;and forward;routing;ieee communications society;government;semantics;hierarchical address assignment;internet use;interdomain level hierarchical address assignment ipv4 observed semantics;internet;aggregates;ip networks;observed semantics;peer to peer computing;telecommunication network topology;interdomain level;ipv4;telecommunication network topology ip networks	Hierarchical, topology-based addressing has long been considered crucial to routing and forwarding scalability. Recently, however, a number of research efforts are considering alternatives to this traditional approach. With the goal of informing such research, we investigated the efficiency of address assignment in the existing (IPv4) Internet--that is, the assignment of prefixes to ASes. In particular, we ask the question: ``Exactly how much does addressing hierarchy help us at the interdomain level?'''' To do so, we first define a notion of efficiency or locality based on the total number of bit-hops required to advertise all prefixes in the Internet in BGP, and compute this quantity for the current Internet using RouteViews data. In order to quantify how far from	border gateway protocol;forwarding plane;inter-domain;internet;locality of reference;network topology;overhead (computing);proxy server;route views;routing;scalability;turing completeness	Yinfang Zhuang;Kenneth L. Calvert	2010	2010 IEEE Global Telecommunications Conference GLOBECOM 2010	10.1109/GLOCOM.2010.5683979	routing;computer science;distributed computing;semantics;world wide web;government;computer network	Networks	-11.32820122512732	77.76004941917954	63352
8d3b9d8fc79c606471129b6b150104bfc97b1b49	enhancements to policy distribution for control flow and looping	estensibilidad;distributed system;systeme reparti;traitement flux donnee;gestion red;reseau ordinateur;simulation;simulacion;abstract syntax tree;computer network;policy language;sistema repartido;data flow processing;control flow;gestion reseau;red informatica;coordinacion;extensibilite;network management;scalability;conference proceeding;coordination	Our previous work proposed a simple algorithm for the distribution and coordination of network management policies across a number of autonomous management nodes by partitioning an Abstract Syntax Tree into different branches and specifying coordination points based on data and control flow dependencies. We now extend this work to support more complex policies containing control flow logic and looping, which are part of the PRONTO policy language. Early simulation results demonstrate the potential performance and scalability characteristics of this framework.	abstract syntax tree;algorithm;autonomous robot;control flow;exception handling;linkage (software);marginal model;parse tree;response time (technology);scalability;simulation;the australian	Nigel Sheridan-Smith;Tim O'Neill;John Leaney;Mark Hunter	2005		10.1007/11568285_23	network management;scalability;simulation;computer science;artificial intelligence;programming language;control flow;algorithm;abstract syntax tree;computer network	DB	-22.64738788598797	81.95354862547153	63355
61eaafbf43295f6878b1b9dde76e50be6397df2f	successive c-optimal designs: a scalable technique to optimize the measurements on large networks	c optimality;socp;network monitoring;netflow;second order cone program;optimal design;ip networks;optimal experimental design	We propose a new approach to optimize the deployment and the sampling rates of network monitoring tools, such as Netflow, on a large IP network. It reduces to solving a stochastic sequence of Second Order Cone Programs. We validate our approach with experiments relying on real data from a commercial network.	cone;experiment;sampling (signal processing);scalability;software deployment	Guillaume Sagnol;Mustapha Bouhtou;Stéphane Gaubert	2010		10.1145/1811039.1811080	real-time computing;computer science;optimal design;distributed computing;network monitoring;netflow;computer network	ML	-12.339975643889755	79.75360046613338	63484
bfbdb05de62384a23f23da4a773a06fb40824843	improved static multiprocessor scheduling using cyclic task graphs: a genetic approach	genetics;genetic algorithm;multiprocessor scheduling;real time control	"""Genetic algorithms have successfully been applied to multiprocessor task graph scheduling. In these previous attempts the schedules are constructed from directed acyclic task graphs. However, recurrent applications such as real-time control and digital signal processing can be expressed as directed cyclic task graphs. This paper presents a method for transforming a cyclic task graph into several alternate acyclic task graphs, The beneets of this are demonstrated through an example where the task graphs become easier to schedule through restructuring. Thus, the new task graphs result in better load balancing and less inter-processor traac than the \standard"""" acyclic task graphs. A genetic algorithm has been used to search for the task graph and schedule that best t a particular application and hardware connguration. The results are encouraging."""	digital signal processing;directed acyclic graph;genetic algorithm;load balancing (computing);multiprocessing;multiprocessor scheduling;real-time locating system;scheduling (computing)	Frode Eika Sandnes;Graham M. Megson	1997			parallel computing;real-time computing;genetic algorithm;real-time control system;computer science;distributed computing;multiprocessor scheduling	HPC	-13.08934107180804	61.983426943244226	63488
5174a1e57243013d90041ed9b559fddfd3248dbc	celliq : real-time cellular network analytics at scale		We present CellIQ, a real-time cellular network analytics system that supports rich and sophisticated analysis tasks. CellIQ is motivated by the lack of support for realtime analytics or advanced tasks such as spatio-temporal traffic hotspots and handoff sequences with performance problems in state-of-the-art systems, and the interest in such tasks by network operators. CellIQ represents cellular network data as a stream of domain specific graphs, each from a batch of data. Leveraging domain specific characteristics—the spatial and temporal locality of cellular network data—CellIQ presents a number of optimizations including geo-partitioning of input data, radiusbased message broadcast, and incremental graph updates to support efficient analysis. Using data from a live cellular network and representative analytic tasks, we demonstrate that CellIQ enables fast and efficient cellular network analytics—compared to an implementation without cellular specific operators, CellIQ is 2× to 5× faster.	binary space partitioning;locality of reference;network science;real-time clock;real-time transcription	Anand Padmanabha Iyer;Erran L. Li;Ion Stoica	2015				Networks	-18.642784559132135	76.67619317081946	63557
93bcfb52931b7bcf444ce67b73b54e6dd05f896a	sla-aware survivability	availability;restoration;optical networks;protection;survivability	The paper discusses the provision of differentiated guarantees to a population of users who share a network with different requirements for their connections. The basic concept underlying the proposed solutions is the required availability of the connections, both in the long term and during the period covered by the Service Level Agreement. An adequate metric for the latter is provided by the interval availability. The paper discusses how Markov chains may be used to model interval availability during the SLA period.	markov chain;mathematical optimization;numerical analysis;requirement;service-level agreement	Helio Waldman;Darli A. A. Mello	2008	2008 10th Anniversary International Conference on Transparent Optical Networks	10.4304/jnw.5.2.251-255	availability;computer security;computer network	Robotics	-8.567530031136876	84.496206658813	63578
5ab06f3be056497ac9aea36df0b17df0f17a8304	on the resilience of software defined routing platform	telecommunication network routing software defined networking;resilience routeflow sdn routing;ripv2 software defined routing platform software defined networking openflow network architecture splitting control data planes production networks current internet architecture ip routing routeflow emulator mininet physical switches link failures failover time;routing routing protocols software ip networks computer architecture resilience	In recent years, there has been an increasing interest in Software Defined Networking (SDN)/OpenFlow, which is a novel network architecture splitting control and data planes. The SDN-enabled products have also been widely deployed in many production networks aiming to bypass the limitations of current Internet architecture. There are several efforts on building Software Defined Routing Platform (SDRP), which integrates SDN/OpenFlow within IP routing. However, to the best of our knowledge, there are a few successful works on realizing SDRP despite of the flexibility and rich features of SDN. In this paper, we investigate state-of-the-art works towards SDRP. We have evaluated the performance of a mainstream SDRP named RouteFlow. Our evaluations have been conducted using both the emulator Mininet and a real testbed with physical switches. Different to other works, we focus on the resilience aspect of the routing platform. The evaluation results show that RouteFlow is resilient against both single and multiple link failures. Additionally, OSPF provided by RouteFlow achieves a shorter failover time than the legacy OSPF. In the case of RIPv2, RouteFlow's protocol has a comparable performance value with the distributed one.	centralized computing;emulator;failover;network architecture;network switch;openflow;routing;software-defined networking;testbed	Pengcheng Zeng;Kien Nguyen;Yao Shen;Shigeki Yamada	2014	The 16th Asia-Pacific Network Operations and Management Symposium	10.1109/APNOMS.2014.6996605	policy-based routing;wireless routing protocol;routing table;routing domain;virtual routing and forwarding;routing;enhanced interior gateway routing protocol;static routing;source routing;adaptive quality of service multi-hop routing;real-time computing;hierarchical routing;zone routing protocol;equal-cost multi-path routing;interior gateway protocol;dynamic source routing;multipath routing;ip forwarding;distributed computing;routing protocol;link-state routing protocol;triangular routing;computer network	Networks	-13.443112084415121	82.8404102837754	63584
5b10b9a92d2e4db6b7b18a5ed7ed3f0dc5ad6cce	resilient, uav-embedded real-time computing		"""In this paper, we propose a hierarchical computational system architecture to support the target domain of realtime mobile computing in the context of unmanned aerial vehicles (UAVs). The overall architectural vision includes support for system resilience in the presence of uncertainties in the operational environment of surveillance UAVs. We report measurement-based results that are obtained from a UAV proxy demonstration apparatus. The apparatus consists of a Raspberry Pi (RPi) board that serves as an on-board UAV computer, working with support from a laptop that serves as the on-ground computing infrastructure where an operator """"consumes"""" video information received from the UAV. We quantify the gap between the on-board UAV camera frame rate (input) and the on-ground operator-observed frame rate (output) for a specialized class of computer vision applications germane to the UAV-based aerial surveillance domain. The goal is to keep the frame rate observed by the ground operator as close (or ideally equal) to the on-board UAV camera frame rate (i.e. to preserve the real-time aspect) despite the unstable bandwidth availability in the channel connecting both ends. The proposed hierarchical approach significantly outperforms two considered baselines: one in which computation takes place entirely on the UAV computer and another in which computation takes place entirely on the ground. This improved performance is due to a more balanced resource sharing between the on-board UAV computer and UAV-to-ground communication channel. Later, we show how the observed frame rate improves when the RPi board is replaced with an NVIDIA Jetson TK1 board. Based on the observations gleaned from these """"proxy"""" experiments, we sketch the fundamentals of our ongoing work in model-based predictive analysis of resilient """"UAV swarm"""" computational architectures of the future."""	aerial photography;channel (communications);computation;computer vision;control knob;control theory;embedded system;experiment;heart rate variability;laptop;mobile computing;on-board data handling;raspberry pi 3 model b (latest version);real-time clock;real-time computing;swarm;systems architecture;tegra;unmanned aerial vehicle	Augusto Vega;Chung-Ching Lin;Karthik Swaminathan;Alper Buyuktosunoglu;Sharath Pankanti;Pradip Bose	2015	2015 33rd IEEE International Conference on Computer Design (ICCD)	10.1109/ICCD.2015.7357189	frame rate;real-time computing;pi;systems architecture;baseline (configuration management);computer science;computation;mobile computing;shared resource;communication channel	Robotics	-28.30500591591298	69.16922971638658	63604
fbc958156518c224ac56029e1a791f6bbd70a52b	an assignment method for ipus in distributed systems	distributed system;assignment problem;independent processing unit ipu;generalized assignment problem;self learning;algorithm;robust method;distributed systems;optima;markov chain	In a distributed system, one of the most important things is to establish an assignment method for distributing tasks. It is assumed that a distributed system does not have a central administrator, all independent processing units in this system want to cooperate for the best results, but they cannot know the conditions of one another. So in order to undertake the tasks in admirable proportions, they have to adjust their undertaking tasks only by self-learning. In this paper, the performance of this system is analyzed by Markov chains, and a robust method of self-learning for independent processing units in this kind of systems is presented. This method can lead the tasks of the system to be distributed very well among all the independent processing units, and can also be used to solve the general assignment problem.	assignment problem;distributed computing;markov chain	Liang Li;Guowei Yang	1999	Journal of Computer Science and Technology	10.1007/BF02948514	markov chain;mathematical optimization;real-time computing;computer science;generalized assignment problem;distributed computing;assignment problem	DB	-14.14507127836924	64.49034593327514	63636
29cc7653993dbf7b4fe930ce706175bace38ce2d	a regular expression matching engine with hybrid memories	matching engine;deep packet inspection;regular expression;markov chain	A key technique of network security inspection is by using the regular expression matching to locate the specific fingerprints of networking applications or attacks in the packet flows, and accordingly identify the underlying applications or attacks. However, due to the surge of various networking applications and attacks in recent years, even more fingerprints need to be investigated in this process, which leads to a high demand on a large memory space for regular expression matching. In addition, with the frequent upgrading of the network links nowadays, the network flow rate also increases dramatically. As a result, it demands the fast operation of regular expression matching accordingly with the enhanced throughput for network inspection. However, due to the limited space of the fast memory, the requirements on fast operations and large memory space are conflicting. On addressing this challenge, in this paper, we propose to use hybrid memory for regular expression matching. In specific, by investigating on the transition table state access probability through the Markov theory, it can be observed that there exist a number of states which are much more frequently accessed than others. Therefore, we devise a matching engine which is suitable for FPGA implementation with two-level memories, where the first-level memory uses the on-chip memory of FPGA to cache the frequently accessed state transitions, and the second-level memory, composed of slow and cheap DRAM, stores the whole state transitions. Furthermore, the L7-filter's regular expression patterns have been applied to obtain the state access probability, and different quantities of memory assignment approaches have also been investigated to evaluate the throughput.	compiler;computer architecture;data rate units;electronic component;field-programmable gate array;intrusion detection system;l7-filter;regular expression;state transition table;throughput	Shuhui Chen;Rongxing Lu	2014	Computer Standards & Interfaces	10.1016/j.csi.2013.12.001	deep packet inspection;markov chain;interleaved memory;real-time computing;telecommunications;computer science;theoretical computer science;operating system;database;distributed computing;programming language;computer security;regular expression;statistics;computer network	Arch	-7.064834227353319	66.58987106886893	63753
7d27a53c53bf6aa3c0701711e798493e61d9a99d	management information base for telephony routing over ip (trip)		This memo defines a portion of the Management Information Base (MIB)#N#module for use with network management protocols in the Internet#N#community. In particular, it describes a set of managed objects that#N#are used to manage Telephony Routing over IP (TRIP) devices.#N#[STANDARDS-TRACK]	routing	David Zinman;David Walker;Jianping Jiang	2004	RFC	10.17487/RFC3872	computer science;ip forwarding;structure of management information;world wide web;computer security;computer network	ECom	-23.639885256060317	88.02439845940948	63757
d9726c4aafada745ee141cc3c3bf57e3e7a8bbdb	a techno-economie study of network coding protection schemes	multiprotocol label switching;nonlinear optics;optical network units;network coding multi layer networks network protection techno economic;ip network network coding protection scheme techno economic study optical technology mpls optical layer multilayer network capital expenditure operational expenditure capex reduction opex reduction proactive protection scheme;telecommunication network reliability ip networks multiprotocol label switching network coding optical fibre networks;ip networks multiprotocol label switching optical network units encoding nonlinear optics;ip networks;encoding	The recent advances in optical technologies pave the way to the deployment of high-bandwidth services. As reliability becomes a mandatory requirement for some of these services, network providers must endow their networks with resilience capabilities. In recent years, network coding protection (NCP) has emerged as a tentative solution aiming at enabling network resilience in a proactive and efficient way. The goal of this paper is to conduct a techno-economic study to evaluate the protection cost required by NCP schemes deployed either at the IP/MPLS or at the Optical layer of a multi-layer network, as well as its impact on both the capital and operational expenditures (CAPEX, OPEX) of a network provider. Our evaluation results show that a significant reduction in both CAPEX and OPEX is obtained with NCP. Indeed, at least a 49% and 52% of CAPEX and OPEX reduction is achieved respectively in comparison with conventional proactive protection schemes.	layer (electronics);linear network coding;multiprotocol label switching;requirement;software deployment	Wilson Ramírez;Xavier Masip-Bruin;Eva Marín-Tordera;Marcelo Yannuzzi;Anny Martínez;Sergio Sánchez-López;M. S. Siddiqui;Víctor López	2014	2014 IEEE Global Communications Conference	10.1109/GLOCOM.2014.7037126	multiprotocol label switching;nonlinear optics;overlay network;network architecture;telecommunications;computer science;label switching;computer security;encoding;computer network	HPC	-9.9131847491526	85.53994278183407	63760
ce5f7ef733758c8b10de67382796ddcddf5e4055	telecommunications management network : a novel approach for its architecture through software platforms			telecommunications management network	Georgios Pavlou	1998				SE	-20.62659242172763	86.97168665564799	64043
0a043d026d1f1e187439e984880fae58ff545177	scalable flow-based networking with difane	access control;openflow;scalability;network architecture	Ideally, enterprise administrators could specify fine-grain policies that drive how the underlying switches forward, drop, and measure traffic. However, existing techniques for flow-based networking rely too heavily on centralized controller software that installs rules reactively, based on the first packet of each flow. In this paper, we propose DIFANE, a scalable and efficient solution that keeps all traffic in the data plane by selectively directing packets through intermediate switches that store the necessary rules. DIFANE relegates the controller to the simpler task of partitioning these rules over the switches. DIFANE can be readily implemented with commodity switch hardware, since all data-plane functions can be expressed in terms of wildcard rules that perform simple actions on matching packets. Experiments with our prototype on Click-based OpenFlow switches show that DIFANE scales to larger networks with richer policies.	centralized computing;fast path;forwarding plane;network packet;network switch;openflow;prototype;scalability;wildcard character	Minlan Yu;Jennifer Rexford;Michael J. Freedman;Jia Wang	2010		10.1145/1851182.1851224	openflow;real-time computing;scalability;network architecture;computer science;access control;operating system;distributed computing;computer security;computer network	Networks	-14.367250155114093	81.83499412569302	64044
4d913332a251adb9b48dd659b72537c6dbb60b79	ekta: an efficient dht substrate for distributed applications in mobile ad hoc networks	distributed application;resource discovery ekta distributed application mobile ad hoc networks distributed hash tables content sharing internet bandwidth limitation node mobility multiaccess interference manet multihop routing protocol;routing protocols;internet mobile computing ad hoc networks routing protocols;resource discovery;distributed hash table;physical layer;ad hoc network;mobile ad hoc networks physical layer broadcasting spread spectrum communication routing protocols robustness ip networks web and internet services bandwidth interference;col;internet;ad hoc networks;mobile ad hoc network;multi access interference;routing protocol;network services;mobile computing	Distributed hash tables (DHTs) have proven to be a novel and efficient platform for building a variety of scalable and robust distributed applications like content sharing and location in the Internet. Similar to those in the Internet, distributed applications and network services in mobile ad hoc networks (MANETs) can potentially benefit from the deployment of a DHT. However, bandwidth limitations, node mobility, and multi access interference pose unique challenges to deploying such DHTs in MANETs. In this paper, we first study how to efficiently implement DHTs in MANETs. We explore two disparate design options: the simple approach of directly overlaying a DHT on top of a MANET multi-hop routing protocol, and Ekta which integrates a DHT with a multi-hop routing protocol at the network layer. Second, we examine the efficiency of DHT substrates in supporting applications in MANETs by examining the performance of a resource discovery application built on top of Ekta with one that directly uses physical layer broadcast. Such a study answers the fundamental question of whether a DHT substrate can be more efficient in supporting applications than a physical layer broadcast-based protocol, since in MANETs, DHT protocols effectively rely on physical layer broadcast to discover and maintain routes.	distributed computing;distributed hash table;hoc (programming language);hop-by-hop transport;interference (communication);internet;link-state routing protocol;routing;routing table;scalability;software deployment;source routing	Himabindu Pucha;Saumitra M. Das;Y. Charlie Hu	2004	Sixth IEEE Workshop on Mobile Computing Systems and Applications	10.1109/MCSA.2004.11	computer science;distributed computing;world wide web;computer network	Mobile	-12.08982845297602	77.13227561018417	64111
6f9593164e0476ea00e5a21a68730111faf73f36	frugal online incentive mechanisms for crowdsourcing tasks truthfully		Mobile Crowd Sensing (MCS) is a new paradigm which takes advantage of pervasive smartphones to efficient ly collect data, enabling numerous novel applications. To ach ieve good service quality for a MCS application, incentive mecha nisms are necessary to attract more user participation. Mos t of existing mechanisms apply only for theoffline scenario where all users’ information are known a priori. On the contrary, we focus on a more realistic scenario where users arrive one by one online in a random order. Based on theonline auction model, we investigate the problem that users submit their private profiles to the crowdsourcer when they arrive, and the crowdsourcer aims at selecting a subset of users before a specified deadline for minimizing the total payment while a specific number of tasks can be completed. We design three online mechanisms , Homo-OMZ, Hetero-OMZ and Hetero-OMG, all of which can satisfy thecomputational efficiency , individual rationality, cost-truthfulness, and consumer sovereignty . The Homo-OMZ mechanism is applicable to the homogeneous user model and can satisfy thesocial efficiencybut not constant frugality. The Hetero-OMZ and Hetero-OMGmechanisms are applicable to both the homogeneous and heterogeneous user models, and can satisfy theconstant frugality. Besides, the Hetero-OMGmechanism can also satisfy thetime-truthfulness. Through extensive simulations, we evaluate the performanc e and validate the theoretical properties of our online mechanisms.	crowdsourcing;pervasive informatics;programming paradigm;rationality;simulation;smartphone	Dong Zhao;Huadong Ma;Liang Liu	2014	CoRR		simulation;computer science;data mining;computer security	ECom	-24.126644932642886	74.5632782093451	64179
5c4cd285c36adfc6836d597d233649da8104045f	tree-based string pattern matching on fpgas	intrusion detection;fpga;string matching;nids;binary tree	Network intrusion detection systems (NIDSs) monitor Internet Protocol (IP) traffic to detect anomalous and malicious activities on a network. Despite the plethora of studies in this field, hardware-based string matching engines that can accommodate the advancements in optical networking technology are still in high demand. Furthermore, memory efficient data structures to store intrusion patterns have recently received a great deal of research attention. In this paper, we introduce a tree-based pattern matching (TPM) scheme that comprises a forest of Binary Search Tree (BST) data structures and an accommodating high-throughput multi-pipelined architecture for scalable string matching on hardware. To improve the resource efficiency in hardware implementations, we enhanced TPM scheme (extended-TPM) with two novel tree structures, namely BST-epsilon (BST?) and hierarchical BST (H-BST). Our entire design accomplishes a memory efficiency of 1.07?bytes/char for the latest Snort dictionary. Utilizing a state-of-the-art Field Programmable Gate Arrays (FPGAs), TPM architecture can sustain a throughput of 2.7?Gbps.	field-programmable gate array;pattern matching	Oguzhan Erdem	2016	Computers & Electrical Engineering	10.1016/j.compeleceng.2015.11.025	intrusion detection system;parallel computing;real-time computing;binary tree;telecommunications;computer science;theoretical computer science;operating system;algorithm;field-programmable gate array;computer network;string searching algorithm	DB	-7.186834006770384	66.51380831226489	64240
780280ce2b8f42f5d32a2c20ada28e72d555dfb6	implementing a p2p network through updatable database views	peer to peer network;p2p networks	We present a novel approach to implement a business-oriented peer-to-peer network through updatable object views. We assume that each peer maintains an integrating view through which it can access the resources made public by all the peers. Each peer keeps also another view which makes some of its local resources public.	peer-to-peer;view (sql)	Radoslaw Adamus;Hanna Kozankiewicz;Krzysztof Stencel;Kazimierz Subieta	2007		10.1007/978-3-540-76888-3_18	computer science;database;internet privacy;world wide web	DB	-33.3897883307484	63.522880624365435	64250
29e5c120a7910fcb8b7aa3a3bef6105e19edc7c0	hierachical heterogeneous wireless sensor network management system	management system;performance evaluation;performance management;graphical interface;network topology topology wireless sensor networks fault detection wireless networks monitoring;real time;telecommunication computing;wireless sensor network;network topology hierachical heterogeneous wireless sensor network management system multifunctional management system configuration management performance management fault management management information base mac professional graphic interface component twaver java;network topology;snmp;fault detection heterogeneous wireless networks network management snmp topology management;fault detection;topology management;wireless sensor networks fault diagnosis java telecommunication computing telecommunication network management telecommunication network topology;heterogeneous wireless networks;network management;cross layer;telecommunication network topology;networked systems;configuration management;fault management;wireless sensor networks;fault diagnosis;management information base;telecommunication network management;java	We design a multi-functional management system for hierachical heterogeneous wireless sensor network, including configuration management, performance management and fault management. This system is compatible with SNMP. The MIB(Management Information Base) is extended according to the features of heterogeneous wireless sensor network, so that it can support custom configuration for wireless nodes. Using the cross-layer technology, the information of the lower layer (the MAC and the network layer) and network topology can be collected; Adopting professional graphic interface component TWaver Java to display network topology, supporting both circular layout and spring layout network topology displaying mode, as well as real time switching between two type of network topology displaying mode, then the network topology can be dispersedly and clearly displayed on the screen; In addition, an adaptive fault detection algorithm, AFD, is proposed. This system can be used in daily maintenance and management of the heterogeneous wireless sensor network, also can be used for performance evaluation of network system.	active format description;algorithm;circular layout;configuration management;fault detection and isolation;force-directed graph drawing;graphical user interface;java;network topology;performance evaluation;sensor web;simple network management protocol;testbed;widget (gui)	Junjiao Ye;Zenghua Zhao;Hao Li;Hao Chen	2011	2011 International Conference on Wireless Communications and Signal Processing (WCSP)	10.1109/WCSP.2011.6096858	out-of-band management;embedded system;element management system;real-time computing;intelligent computer network;wireless wan;network architecture;wireless sensor network;heterogeneous network;network management station;engineering;wireless network;network simulation;key distribution in wireless sensor networks;network management application;mobile wireless sensor network;network topology;computer network;visual sensor network;logical topology	Mobile	-19.621575988363748	85.74855870772875	64269
4891129aeed3e2e43300fd0385926bae49c784a0	a server-mediated peer-to-peer system	p2p system;collaboration;peer to peer system;design;server mediated;experimentation;peer to peer;file distribution;decentralized	A peer-to-peer (P2P) system is a popular means of file distribution. Existing P2P systems do not adequately address a variety of common problems including (1) limited search scope, (2) dynamic nature of peers and (3) lack of collaboration among peers. In this paper, we propose a server-mediated peer-to-peer system to address these problems and to improve the performance of existing decentralized P2P systems by incorporating a central server into the decentralized P2P system to facilitate collaboration among peers. Two main features of our proposed system are Assisted-search and Assisted-download. Experimental results show that the search coverage was increased by 289.91% by using Assisted-search, while the overall download speed was improved by 33% by using Assisted-download.	download;peer-to-peer;server (computing)	Sai Ho Kwok;K. Y. Chan;Y. M. Cheung	2005	SIGecom Exchanges	10.1145/1120680.1120686	design;economics;computer science;database;distributed computing;management;world wide web;collaboration	Web+IR	-13.261543480220226	73.30979230510927	64282
5c0c92f274932dbdccd4ec1957823847781ac186	on the simulation of grid market coordination approaches	resource allocation;000 informatik informationswissenschaft allgemeine werke;330 wirtschaft;decision problem;resource broker;000 allgemeines wissenschaft;grid computing	Grid computing has recently become an important paradigm for managing computationally demanding applications, composed of a collection of services. The dynamic discovery of services, and the selection of a particular service instance providing the best value out of the discovered alternatives, poses a complex multi-attribute n:m allocation decision problem, which is often solved using a central resource broker. However, decentralized approaches to this service allocation problem represent a much more flexible alternative, thus promising improvements in the efficiency of the resulting negotiations and service allocations. This paper compares centralized and decentralized service allocation mechanisms in Grid market scenarios according to a defined set of metrics.	algorithm;bilateral filter;bilateral sound;catallaxy;centralized computing;computation;decision problem;grid computing;grid network;heuristic;interdependence;java resource bundle;population;procurement;programming paradigm;prototype;service-orientation;service-oriented device architecture;simulation;time complexity	Werner Streitberger;Sebastian Hudert;Torsten Eymann;Björn Schnizler;Floriano Zini;Michele Catalano	2007	Journal of Grid Computing	10.1007/s10723-007-9092-6	resource allocation;computer science;decision problem;data mining;database;management science;management;grid computing	HPC	-22.530999429675322	65.2894100405777	64415
00ca82d98e7c77de5d25bc8ea693195d4a4e727b	crowdsourcing for mobile networks and iot			crowdsourcing	Xiping Hu;Zhaolong Ning;Kuan Zhang;Edith C.-H. Ngai;Kun Bai;Fei Wang	2018	Wireless Communications and Mobile Computing	10.1155/2018/6231236	computer network;distributed computing;computer science;crowdsourcing;internet of things	Mobile	-16.510613399818226	87.73506834707453	64422
6dddae48d1a85c9174bc1712840f2a16c3ca95e9	decentralized and hierarchical discovery of software applications in the ishare internet sharing system	self organization;p2p	We present the design and evaluation of a fully decentralized software application discovery scheme – iDiscover, which is used in the iShare Internet-sharing system being built at Purdue University. The scheme employs a structured peer-to-peer (P2P) overlay routing mechanism and a hierarchical name space. The structured P2P routing mechanism is self-organizing and scalable. The hierarchical nam e space provides an effective way to describe software applications with their semantics. Measurements using a set of real software applications show that our resource discover y mechanism is efficient and scalable.	north american mesoscale model;organizing (structure);peer-to-peer;routing;scalability;self-organization;xojo	Xiaojuan Ren;Zhelong Pan;Rudolf Eigenmann;Y. Charlie Hu	2004			software;internet connection sharing;peer-to-peer;computer network;distributed computing;computer science	Networks	-19.859554653408598	83.28125498247505	64433
124ba1f4ca40320307ad1a4b35a00102d5ae0b27	adaptive multipath routing for network functions virtualization	optimization;multipath routing;network functions virtualization	Network Functions Virtualization (NFV) is a recent trend of network transformation that helps service providers offer new and multiple services in a more agile and cost effective way. However, the softwarization and cloudization of network functions can result in high congestion and low network performance for virtual networks. We develop a multipath routing solution for minimizing the maximum link utilization, thus leading to the performance improvement of NFV-based systems, as well as the efficient utilization of network resources. Our proposed algorithm can adapt the link weight system to the dynamic change of service demands for optimizing the distribution of network traffic, with regard to the fundamental NFV characteristics and the Equal-cost Multipath (ECMP) routing feature. The evaluation results show that the proposed solution outperforms a multipath solution with fixed link weight on various performance metrics. Interestingly, we find that the network performance is not significantly improved by increasing the number of paths beyond a threshold.	agile software development;algorithm;equal-cost multi-path routing;multipath propagation;multipath routing;network congestion;network function virtualization;network performance;network traffic control	Thi-Thuy-Lien Nguyen;Tuan-Minh Pham;Huynh Thi Thanh Binh	2016		10.1145/3011077.3011123	routing;real-time computing;computer science;multipath routing;distributed computing;computer network	Metrics	-9.254911287686149	83.9447756998496	64518
28718954bd7bfea28aac94daaa335d92c99d48fa	artemis: an event operation tool for telecommunication management systems	management system;heterogeneous systems;network management;telecommunication networks	The management of both computer and telecommunication networks is an activity that has as main requirement the integration of heterogeneous systems. This work presents the Artemistool, which has as key feature the capability to combine distinct systems of network management as well as their information concerning the network in order to exhibit them concisely and through a unique interface to users. The tool is part of the SIS management platform used by TELEMAR, the largest Brazilian telecommunications company.	management system	José Marcos S. Nogueira;Antonio Alfredo Ferreira Loureiro;Ana Paula R. da Silva;Daniel F. Macedo;Leonardo B. Oliveira;Fernando Augusto Teixeira	2003			network management;element management system;real-time computing;systems management;network management station;computer science;operating system;management system;network management application;computer security;computer network	DB	-20.727270094103076	86.46980121074454	64522
ef7e92cb9705f45ef7b5613edd28fb895d4d8848	optimization and early-warning in dsl access networks based on simulation	network administration;dsl access network;existing pms;continuous forecast;heavy use;use case;large dsl-based access network;network provider;dsl network;link failure;real network performance data	Network providers operate large DSL-based access networks to offer customers Broadband Internet. These networks are observed and managed by Performance Management Systems (PMS), that capture the actual situation to support network administration. In this regard, the administrator can cope with incidents such as link failures or congestion. We present an application for optimization and forecast of traffic distributions in DSL networks as an addition to an existing PMS. This application makes heavy use of simulation. In this way, we give a description of traffic models based on real network performance data reflecting: (I) individual subscribers and (II) an aggregated model for multiple subscribers. Then, we introduce the overall simulation approach based on the Network Security Simulator NeSSi2. The evaluation takes place by a use case for simulation-based verification of applied optimization strategies and a use case for continuous forecast to predict upcoming link congestion.	access network;digital subscriber line;simulation	Rainer Bye;Joël Chinnow;Jan Hendrik Clausen;Karsten Bsufka;Sahin Albayrak	2010			simulation;telecommunications;operating system;computer security;computer network	Arch	-18.674991479745223	85.57714426423574	64566
62ce9f967da262f23a6628aba5fe9a980abc5cad	performance analysis of offloading systems in mobile wireless environments	wireless links;analytical models;communications society;mobile wireless environments;personal communication networks;performance analysis personal digital assistants mobile computing personal communication networks analytical models wireless lan communications society systems engineering and theory educational institutions computer science;model performance;random waypoint mobility scheme offloading systems mobile wireless environments pervasive services wireless links;systems engineering and theory;personal digital assistants;radio links mobile radio;pervasive services;mobile radio;performance analysis;offloading systems;random waypoint mobility scheme;wireless lan;computer science;mobile computing;radio links	Offloading is an approach to leverage the severity of resource constrained nature of mobile devices (such as PDAs, mobile phones) by migrating part of the computation of applications to some nearby resource-rich surrogates (e.g., desktop PCs, mobility support stations). It is an essential mechanism for the execution of pervasive services. However, the mobile nature of mobile devices and the unstable connectivity of wireless links all render a less predictability of the performance of a pervasive service running under the control of offloading systems. This paper proposes an analytical model to express the performance of offloading systems in mobile wireless environments. We investigate the surrogate unreachability when mobile devices move following random waypoint (RWP) mobility scheme. We model the failure recovery time and total execution time of pervasive applications that run under the control of offloading systems. Detailed evaluation and analysis results are reported and the results of this paper can be used as design guidance for pervasive service offloading systems.	computation;control theory;desktop computer;mobile device;mobile phone;personal digital assistant;pervasive informatics;profiling (computer programming);run time (program lifecycle phase);surrogates;waypoint	Shumao Ou;Kun Yang;Antonio Liotta;Liang Hu	2007	2007 IEEE International Conference on Communications	10.1109/ICC.2007.304	mobile search;simulation;telecommunications;computer science;operating system;small cell;mobile computing;computer network	Mobile	-20.03333530011053	75.64683185399001	64709
b16ccbd94b75ec00ea9f1ba7c69eb2cc6aff09cd	q-learning based collaborative load balancing using distributed search for unstructured p2p networks	groupware;peer to peer structure;learning;resource allocation;peer to peer computing load management mobile agents search problems learning distance measurement probabilistic logic;mobile agents;reinforcement learning;distributed processing;q learning;dynamic unstructured p2p network;peer effect;internet based data management;collaborative load balancing;resource allocation distributed processing groupware learning artificial intelligence mobile agents peer to peer computing;distance measurement;query load balancing;reinforcement learning q learning collaborative load balancing distributed search dynamic unstructured p2p network peer to peer structure internet based data management query load balancing mobile agent;load management;distributed search;load balance;search problems;p2p networks;probabilistic logic;peer to peer computing;learning artificial intelligence;mobile agent;peer to peer;data management system	Peer-to-peer structures are becoming more and more popular and an exhilarating new class of ground-breaking, Internet-based data management systems. Query load balancing is an important problem for the efficient operation of unstructured P2P networks. The key issue is to identify overloaded peers and reassign their loads to others. This paper proposes a novel mobile agent based two-way load balancing technique for dynamic unstructured P2P networks. In this scheme, target peers are selected based on the result of reinforcement learning. Simulation results indicate that our technique manages the load on peers effectively and increases the search performance significantly.	agent-based model;distributed web crawling;load balancing (computing);mobile agent;peer-to-peer;q-learning;reinforcement learning;simulation	Sabu M. Thampi;K. Chandra Sekaran	2008	2008 33rd IEEE Conference on Local Computer Networks (LCN)	10.1109/LCN.2008.4664283	resource allocation;computer science;load balancing;mobile agent;database;distributed computing;probabilistic logic;world wide web;reinforcement learning;q-learning	HPC	-12.665454894529452	73.17602924239081	64729
666a63576fc5abefc59d0c5a7cda3285c7cce195	on the effects of user ratings on the profitability of cloud services		In todays cloud market, providers are taking advantage of consumer reviews and ratings as a new marketing tool to establish their credibility. However, to achieve higher ratings, they need to enhance their service quality which comes with an additional cost. In this paper, we model this conflicting situation as a Stackelberg game between a typical service provider and multiple service users in a cloud environment. The strategy of the service provider is to adjust the price and IT capacity by predicting the users ratings as well as their demands variation in response to his given price, quality and rating. The game is solved through a backward induction procedure using Lagrange function and Kuhn-Tucker conditions. To evaluate the proposed model, we performed experiments on three real world service providers who have low, medium and high average of users' ratings, obtained from the Trust Feedback Dataset in the Cloud Armor project. The results show that improvement in ratings is mostly profitable for highly rated providers. The surprising point is that providers having low ratings do not get much benefit from increasing their average ratings, meanwhile, they can perform well when they lower the service price.	backward induction;cloud computing;display resolution;experiment;karush–kuhn–tucker conditions;lagrange multiplier;online and offline;platform as a service;quality of service;simulation;tucker decomposition	Mona Taghavi;Jamal Bentahar;Hadi Otrok;Omar Abdel Wahab;Azzam Mourad	2017	2017 IEEE International Conference on Web Services (ICWS)	10.1109/ICWS.2017.8	service provider;computer science;data mining;scalability;backward induction;quality of service;profitability index;cloud computing;marketing;software as a service;service quality	Web+IR	-22.690135512343417	65.10606204611216	64743
6fa54d1e89b0342959ae866d6938e06aee6f671e	leveraging software-defined-networking for energy optimisation in mobile-cloud-computing		Abstract   Both mobile and cloud computing are two areas which are rapidly expanding in terms of use case and functionality. Whilst mobile computing enables a variety of feature rich functionality for users in a non-fixed location, cloud computing is revolu-tionising the way in which computing resources are being provisioned, used and optimised for both service providers and end users. These two fields are being combined in order to provide greater functionality for mobile devices by off loading resources to the cloud. However, the advantages of this only hold true if the device resources are truly optimised. This paper examines the effect of network simulation on understanding methods for optimising device life and suggests a number of ways in which Software-Defined-Networking (SDN) may be leveraged in order to determine the exact nature of optimisations available through this combination.	mathematical optimization;mobile cloud computing	Elhadj Benkhelifa;Thomas Welsh;Lo'ai Tawalbeh;Yaser Jararweh;Mahmoud Al-Ayyoub	2016		10.1016/j.procs.2016.08.074	simulation;computer science;theoretical computer science;utility computing;world wide web	Vision	-24.70352962150241	67.6385396614953	64770
720c184338d8fd696afed306398cc8bc2f0323f2	managing the token ring		Abstract#R##N##R##N#General Technology's GT16N series Smart MAU (SMAU) is the heart of a network management system which offers administrators and managers the hardware necessary to take control of 4/16 Mbps token ring networks.	token ring	Curtis Waters	1992	Int. Journal of Network Management	10.1002/nem.4560020209	token bus network;real-time computing;token passing;token ring;computer security;computer network	Networks	-20.55941924114671	88.15992467703352	64795
0aaf94fd5d740138ffa2a1d9beb277887379396b	dynamic reconfiguration of flexray schedules for response time reduction in asynchronous fault-tolerant networks	fault tolerant;dynamic reconfiguration;embedded system	In this paper, we present fault-tolerance strategies for implementing passive replication techniques in networked embedded systems based on TDMA-communication such as FlexRay busses. In particular, we assume that processes are replicated at different nodes for tolerating node failures. Hence, if one node fails another node can execute the process and requires the bandwidth for transmitting those messages created by the process over the bus medium. Two concepts are introduced to solve this problem: 1.) to replicate not only the processes but also the messages and to reserve the required bandwidth a priori at design time or 2.) to reconfigure the TDMA-schedule and assign the bandwidth dynamically to the nodes. Obviously, reserving bandwidth for each failure case might lead to a huge overhead and to long response times. Therefore, we provide different reconfiguration strategies for the recently developed FlexRay bus. Moreover, the timing behavior as well as the implementation overhead are evaluated with the help of an experimental setup consisting of five FlexRay nodes.	flexray	Robert Brendle;Thilo Streichert;Dirk Koch;Christian Haubelt;Jürgen Teich	2008		10.1007/978-3-540-78153-0_10	embedded system;fault tolerance;parallel computing;real-time computing;computer science;operating system;distributed computing	EDA	-8.71818564243338	64.60310362274325	64884
0d165b784e824521667fa42444061516015aa500	a flexible hash table design for 10gbps key-value stores on fpgas	logic design;memory architecture;table lookup dram chips field programmable gate arrays logic design memory architecture;computer architecture pipelines throughput indexes field programmable gate arrays bandwidth prototypes;field programmable gate arrays;table lookup;bit rate 10 gbit s maximum packet rate udp binary encoded memcached packets ddr3 dram memcached prototype access speeds memory types scalable architecture packet reception time lookup time hash collisions concurrent mechanism line rate performance fully pipelined design fpga dataflow architecture scale out workloads power efficiency reduction sublinear scalability cloud servers web sites databases access load reduction distributed main memory key value stores web infrastructure flexible hash table design;dram chips	Common web infrastructure relies on distributed main memory key-value stores to reduce access load on databases, thereby improving both performance and scalability of web sites. As standard cloud servers provide sub-linear scalability and reduced power efficiency to these kinds of scale-out workloads, we have investigated a novel dataflow architecture for key-value stores with the aid of FPGAs which can deliver consistent 10Gbps throughput. In this paper, we present the design of a novel hash table which forms the centre piece of this dataflow architecture. The fully pipelined design can sustain consistent 10Gbps line-rate performance by deploying a concurrent mechanism to handle hash collisions. We address problems such as support for a broad range of key sizes without stalling the pipeline through careful matching of lookup time with packet reception time. Finally, the design is based on a scalable architecture that can be easily parametrized to work with different memory types operating at different access speeds and latencies. We deployed this hash table in a memcached prototype to index 2 million entries in 24GBytes of external DDR3 DRAM while sustaining 13 million requests per second for UDP binary encoded memcached packets which is the maximum packet rate that can be achieved with memcached on a 10Gbps link.	attribute–value pair;collision (computer science);computer data storage;database;dataflow architecture;dynamic random-access memory;field-programmable gate array;hash table;key size;lookup table;memcached;network packet;performance per watt;prototype;scalability;surface web;throughput;usb flash drive;web server	Zsolt István;Gustavo Alonso;Michaela Blott;Kees A. Vissers	2013	2013 23rd International Conference on Field programmable Logic and Applications	10.1109/FPL.2013.6645520	embedded system;parallel computing;logic synthesis;real-time computing;computer science;operating system;field-programmable gate array	OS	-5.7608802019114185	65.40461211085925	64918
1dbada4f125a26c41f0e98181c0c56dca8c5dd18	a qos-based scheme for planning and dimensioning of optical label switched networks	optical label switching;data transmission;optical network;optical label switched networks;cost function;queuing model;telecommunication network planning;optical network planning;queueing theory;link capabilities;traffic control;differentiated service;optical fiber networks;design optimization;data communication;optimization problem;qos based scheme;optical fibre networks;telecommunication traffic;queuing model qos based scheme optical label switched networks quality of service optical network planning data transmission costs ip traffic optical buffering link capabilities;ip traffic;telecommunication switching;optical fiber networks quality of service traffic control telecommunication traffic optical buffering data communication bandwidth wavelength division multiplexing design optimization cost function;conservation law;telecommunication traffic data communication ip networks optical fibre networks quality of service queueing theory telecommunication network planning telecommunication switching;bandwidth;ip networks;quality of service;optical buffering;wavelength division multiplexing;data transmission costs	To support the growing demand for transmission, optical label switching (OLS) technology seems to be attractive due to its ability to allow fast switching and quality of service (QoS) support. Planning is a major issue in optical networks, since switch design and data transmission costs are essential criteria in OLS networks. In this paper, we use a novel OLS node architecture to build planning and dimensioning of OLS network based on a set of QoS parameters. We address the issue of providing the differentiated services to IP traffic through the use of optical buffering and link capabilities. We also formulate dimensioning and optimization problems using a conservation law and queuing model. Finally, we evaluate the performance of the proposed model through simulation.	blocking (computing);differentiated services;mathematical optimization;memory management;multiprotocol label switching;ordinary least squares;provisioning;quality of service;queueing theory;scalability;simulation;thyristor	Yassine Khlifi;Noureddine Boudriga;Mohammad S. Obaidat	2007	2007 IEEE International Conference on Communications	10.1109/ICC.2007.78	optimization problem;real-time computing;multidisciplinary design optimization;internet traffic;quality of service;telecommunications;differentiated service;computer science;queueing theory;conservation law;bandwidth;wavelength-division multiplexing;computer network;data transmission	Robotics	-6.4001520398798	84.37645962403965	64926
06c6df47368424515a9851eb604a495b67783d66	towards energy management in cloud federation: a survey in the perspective of future sustainable and cost-saving strategies	energy efficiency;energy sustainability;energy costs saving;cloud federation;cloud computing	Nowadays, the increasing interest in Cloud computing is motivated by the possibility to promote a new economy of scale in different contexts. In addition, the emerging concept of Cloud federation allows providers to optimize the utilization of their resources establishing business partnerships. In this scenario, the massive exploitation of ICT solutions is increasing the energy consumption of providers, thus many researchers are currently investigating new energy management strategies. Nevertheless, balancing Quality of Service (QoS) with both energy sustainability and cost saving concepts is not trivial at all. The growing interest in this area has been highlighted by the increasing number of contributions that are appearing in literature. Currently, most of energy management strategies are specifically focused on independent Cloud providers, others are beginning to look at Cloud federation. In this paper, we present a survey that helps researchers to identify the future trends of energy management in Cloud federation. In particular, we select the major contributions dealing with energy sustainability and cost-saving strategies aimed at Cloud computing and federation and we present a taxonomy useful to analyze the current state-of-the-art. In the end, we highlight possible directions for future research efforts. © 2015 Published by Elsevier B.V.	cloud computing;new economy;quality of service	Maurizio Giacobbe;Antonio Celesti;Maria Fazio;Massimo Villari;Antonio Puliafito	2015	Computer Networks	10.1016/j.comnet.2015.08.031	simulation;cloud computing;computer science;operating system;management science;efficient energy use	Metrics	-26.055665225867383	65.91174237175058	64960
2d346b0ebdf0d71275cf0bc3c020d85df6f4ea9a	estimating network proximity and latency	location service;network measurement;measurement error;service provider;distance estimation;large scale;network distance estimation	Network proximity and latency estimation is an important component in discovering and locating services and applications. With the growing number of services and service providers in the large-scale Internet, accurately estimating network proximity/latency with minimal probing overhead becomes essential for scalable deployment. Although there exist a number of network distance estimation schemes, they either rely on extensive infrastructure support, require the IP address of the potential targets, falsely cluster distant nodes, or perform poorly with even few measurement errors. We propose Netvigator, a scalable network proximity and latency estimation tool that uses information obtained from probing a small number of landmark nodes and intermediate routers (termed milestones) that are discovered en route to the landmarks, to identify the closest nodes. With very little additional probing overhead, Netvigator uses distance information to the milestones to accurately locate the closest nodes. We developed a Netvigator prototype and report our performance evaluation on PlanetLab and in the intranet of a large enterprise. Netvigator is a running service on PlanetLab as a part of HP Labs' S3 (Scalable Sensing Service).	existential quantification;internet;intranet;overhead (computing);performance evaluation;planetlab;prototype;scalability;software deployment	Puneet Sharma;Zhichen Xu;Sujata Banerjee;Sung-Ju Lee	2006	Computer Communication Review	10.1145/1140086.1140092	service provider;real-time computing;computer science;world wide web;computer security;computer network;observational error	Metrics	-13.262913065113313	77.62102801830633	64973
39ce1546efd1e48455e05ca6d09dddf8cd1f07e1	evaluating gpus for network packet signature matching	packet inspection;high performance microprocessor;protocols;nvidia geforce 8800 gtx;networks;simd based g80 gpu network packet signature matching network device packet inspection intrusion detection traffic shaping load balancing packet payload regular expression based signature network speed performance requirement hardware centric asic fpga implementation high performance microprocessor programmable signature matching system nvidia g80 gpu microarchitectural analysis simd processing standard deterministic finite automata extended finite automata;paper;deterministic automata;heart;regular expression based signature;microarchitectural analysis;prototypes;radiation detectors;digital signatures;networking and internet architecture;performance requirement;intrusion detection;standard deterministic finite automata;data mining;inspection;computer networks;security of data application specific integrated circuits computer networks deterministic automata digital signatures field programmable gate arrays finite automata microprocessor chips parallel architectures;cuda;deep packet inspection;automata;fpga implementation;telecommunication traffic;engines;parallel architectures;application specific integrated circuits;data structures;network speed;deterministic finite automata;network packet signature matching;simd based g80 gpu;prototypes automata inspection intrusion detection telecommunication traffic load management heart engines payloads application specific integrated circuits;control flow;finite automata;load management;load balancing;network device;nvidia;hardware centric asic fpga implementation;programmable signature matching system;payloads;load balance;computer science;field programmable gate arrays;simd processing;high performance;program processors;security of data;regular expression;doped fiber amplifiers;traffic shaping;nvidia g80 gpu;extended finite automata;microprocessor chips;packet payload	Modern network devices employ deep packet inspection to enable sophisticated services such as intrusion detection, traffic shaping, and load balancing. At the heart of such services is a signature matching engine that must match packet payloads to multiple signatures at line rates. However, the recent transition to complex regular-expression based signatures coupled with ever-increasing network speeds has rapidly increased the performance requirements of signature matching. Solutions to meet these requirements range from hardwarecentric ASIC/FPGA implementations to software implementations using high-performance microprocessors. In this paper, we propose a programmable signature matching system prototyped on an Nvidia G80 GPU. We first present a detailed architectural and microarchitectural analysis, showing that signature matching is well suited for SIMD processing because of regular control flow and parallelism available at the packet level. Next, we examine two approaches for matching signatures: standard deterministic finite automata (DFAs) and extended finite automata (XFAs), which use far less memory than DFAs but require specialized auxiliary memory and small amounts of computation in most states. We implement a fully functional prototype on the SIMD-based G80 GPU. This system out-performs a Pentium4 by up to 9X and a Niagara-based 32-threaded system by up to 2.3X and shows that GPUs are a promising candidate for signature matching.	antivirus software;application-specific integrated circuit;automata theory;auxiliary memory;byte;computation;concurrency (computer science);control flow;data breach;deep packet inspection;deterministic finite automaton;field-programmable gate array;finite-state machine;geforce 8 series;graphics processing unit;high memory;intrusion detection system;load balancing (computing);microarchitecture;microprocessor;network packet;network traffic control;noise shaping;parallel computing;pentium 4;prototype;regular expression;requirement;simd;traffic shaping;ultrasparc t1;xml	Randy Smith;Neelam Goyal;Justin Ormont;Karthikeyan Sankaralingam;Cristian Estan	2009	2009 IEEE International Symposium on Performance Analysis of Systems and Software	10.1109/ISPASS.2009.4919649	embedded system;deep packet inspection;computer architecture;parallel computing;real-time computing;data structure;computer science;load balancing;operating system;finite-state machine	Arch	-7.194528632882158	66.45629664697266	65002
67364a1fcbc1b5697d6a40a02154c95276799074	simulation model for obs contention avoidance routing strategies	network architecture and design;optical network;path selection;optical burst switched;source routing;shortest path routing;contention resolution;traffic engineered;simulation model	Optical burst switching (OBS) provides a feasible paradigm for the next IP over optical network backbones. However, due to its bufferless nature, OBS efficiency can be reduced by resource contention leading to burst loss. Several methods have been proposed to address this problem, most of them relying on reactive mechanisms which increase the complexity of core nodes, hampering scalability. In this work we consider a preventive traffic engineering approach for contention resolution which provides source routing with the objective of minimizing contention at the transmission links considering only topological information. This paper presents a simulation model aimed at the evaluation of different offline routing strategies in terms of burst contention. The simulation model is used to compare the performance of different novel path selection strategies with the traditional shortest path routing approach. Results confirm that the proposed strategies are effective in reducing the overall blocking and the model is feasible for the proposed QoS evaluation.	adobe streamline;algorithm;blocking (computing);bus contention;online and offline;optical burst switching;programming paradigm;resource contention;scalability;shortest path problem;simulation;source routing;test engineer	Alvaro L. Barradas;Maria do Carmo R. Medeiros	2010		10.1007/978-3-642-11628-5_30	policy-based routing;private network-to-network interface;routing;static routing;source routing;telecommunications;equal-cost multi-path routing;computer science;dynamic source routing;simulation modeling;distributed computing;link-state routing protocol;computer network	HPC	-5.379550270984254	84.39226424524158	65038
2fba447e504606e90908966d5a5f4c1de972a7ba	step: a time-efficient tag searching protocol in large rfid systems	protocols;testing slot;testing;radiofrequency identification access protocols iterative methods;tag searching;servers;iterative elimination searching by iterative testing and eliminating protocol step time efficient tag searching protocol radiofrequencyidentification rfid systems testing slot wanted tags interrogation region transmission overhead searching process multiple readers;vectors;multiple reader;rfid system;testing slot rfid system tag searching time efficiency multiple reader;search problems;cats;time efficiency;radiofrequency identification;protocols testing radiofrequency identification search problems servers	The radio frequency identification (RFID) technology is greatly revolutionizing applications such as warehouse management and inventory control in retail industry. In large RFID systems, an important and practical issue is tag searching: Given a particular set of tags called wanted tags, tag searching aims to determine which of them are currently present in the system and which are not. As an RFID system usually contains a large number of tags, the intuitive solution that collects IDs of all the tags in the system and compares them with the wanted tag IDs to obtain the result is highly time inefficient. In this paper, we design a novel technique called testing slot, with which a reader can quickly figure out which wanted tags are absent from its interrogation region without tag ID transmissions. The testing slot technique thus greatly reduces transmission overhead during the searching process. Based on this technique, we propose two protocols to perform time-efficient tag searching in practical large RFID systems containing multiple readers. In our protocols, each reader first employs the testing slot technique to obtain its local searching result by iteratively eliminating wanted tags that are absent from its interrogation region. The local searching results of readers are then combined to form the final searching result. The proposed protocols outperform existing solutions in both time efficiency and searching precision. Simulation results show that, compared with the state-of-the-art solution, our best protocol reduces execution time by up to 60 percent, meanwhile promotes the searching precision by nearly an order of magnitude.	communications protocol;inventory control;overhead (computing);radio frequency;radio-frequency identification;run time (program lifecycle phase);simulation;tag cloud	Xuan Liu;Bin Xiao;Shigeng Zhang;Kai Bu;Alvin Chan	2015	IEEE Transactions on Computers	10.1109/TC.2015.2394461	communications protocol;telecommunications;computer science;operating system;data mining;software testing;world wide web;server	Mobile	-30.01610273851335	71.36741104866412	65154
8565dd8b1cbb5502361b90d8fd7d323276890c63	improving the service time of web clients using server redirection	performance evaluation;load sharing;experimental evaluation;quality of service;distributed systems	This paper describes and evaluates experimentally a web server infrastructure, which consists of a small number of servers that redirect client requests based on the estimated client service time. The web servers have replicated content, are located in geographically different regions, and redirect clients between servers. The web servers use metrics obtained from server logs to estimate the service time of a client. Based on the estimated service time the server redirects the web client. The implementation of the measurement and redirection mechanism is done in the web servers and is independent of the clients. Using server logs the measuring mechanism does not introduce traffic into the network. We have experimentally evaluated the proposed web server infrastructure. In our experiments the client service time improved from 4 to 40 % when using the proposed mechanism. The web server infrastructure could be applied to improve the service time of selected clients, which frequently access a web server to retrieve a significant amount of data.	experiment;redirection (computing);server (computing);url redirection;web server;world wide web	Oscar Ardaiz-Villanueva;Felix Freitag;Leandro Navarro-Moldes	2001	SIGMETRICS Performance Evaluation Review	10.1145/572317.572324	client;web service;round-robin dns;reverse proxy;quality of service;clickstream;computer science;web api;operating system;appleshare;web log analysis software;database;fat client;world wide web;web server;application server;client–server model;server;computer network;server farm;inter-process communication	Web+IR	-18.379448345602704	70.48582987255537	65156
121b64c386a2c30109b22a607bf24d7a5baf52f6	economics of wifi offloading: trading delay for cellular capacity	game theory;cellular radio;wireless lan cellular radio;trace driven numerical analysis wifi offloading economics trading delay cellular capacity cellular networks smart handheld device traffic hungry application cost effective cellular data mobility wifi ap mobile data explosion economic incentives network providers;ieee 802 11 standards pricing delays economics numerical models mobile communication conferences;wireless lan;trace driven numerical analysis wi fi offloading economics trading delay cellular capacity cellular networks traffic overload smart handheld device traffic hungry application cellular data offload delayed wifi offloading user data delay mobility wi fi ap wi fi access points mobile data explosion economic incentives economic benefit two stage sequential game;wireless lan cellular radio game theory	Cellular networks are facing severe traffic overloads due to the proliferation of smart handheld devices and traffic-hungry applications. A cost-effective and practical solution is to offload cellular data through WiFi. Recent theoretical and experimental studies show that a scheme, referred to as delayed WiFi offloading, can significantly save the cellular capacity by delaying users' data and exploiting mobility and thus increasing chance of meeting WiFi APs (Access Points). Despite a huge potential of WiFi offloading in alleviating mobile data explosion, its success largely depends on the economic incentives provided to users and operators to deploy and use delayed offloading. In this paper, we study how much economic benefits can be generated due to delayed WiFi offloading, by modeling the interaction between a single provider and users based on a two-stage sequential game. We first analytically prove that WiFi offloading is economically beneficial for both the provider and users. Also, we conduct trace-driven numerical analysis to quantify the practical gain, where the increase ranges from 21% to 152% in the providers revenue, and from 73% to 319% in the users surplus.	mobile device;numerical analysis	Joohyun Lee;Yung Yi;Song Chong;Youngmi Jin	2013	2013 Proceedings IEEE INFOCOM	10.1109/INFCOM.2013.6567156	game theory;telecommunications;computer security;computer network	Mobile	-22.63152944436005	75.73213111588552	65245
1d3ed55d50d56ea1d43e4bd08357eb15b2007671	scaling properties of the internet graph	shortest path routing;internet;computer networks workload;congestion;policy routing;power law distribution	As the Internet grows in size, it becomes crucial to understand how the speeds of links in the network must improve in order to sustain the pressure of new end-nodes being added each day. Although the speeds of links in the core and at the edges roughly improve according to Moore's law, this improvement alone might not be enough. Indeed, the structure of the Internet graph and routing in the network might necessitate much faster improvements in the speeds of key links in the network.In this paper, using a combination of analysis and extensive simulations, we show that the worst congestion in the Internet in fact scales poorly with the network size (n1+Ω(1), where n is the number of nodes), when shortest-path routing is used. We also show, somewhat surprisingly, that policy-based routing does not exacerbate the maximum congestion when compared to shortest-path routing.Our results show that it is crucial to identify ways to alleviate this congestion to avoid some links from being perpetually congested. To this end, we show that the congestion scaling properties of the Internet graph can be improved dramatically by introducing moderate amounts of redundancy in the graph in terms of parallel edges between pairs of adjacent nodes.	image scaling;internet;moore's law;multiple edges;network congestion;routing;shortest path problem;simulation	Aditya Akella;Shuchi Chawla;Arvind Kannan;Srinivasan Seshan	2003		10.1145/872035.872087	routing;static routing;the internet;simulation;computer science;pareto distribution;distributed computing;routing protocol;slow-start;statistics;computer network	Networks	-9.420337122140428	78.89029417625642	65260
04ff1fa021492dd53d6e274f55fe04ba31726b41	improving the scalability of logarithmic-degree dht-based peer-to-peer networks	estensibilidad;institutional repositories;p2p system;hachage;parallelisme;distributed system;reseau pair;distance minimale;systeme reparti;fedora;peer to peer network;distributed hash table;redundancia;routing;logicial personalizado;routage;p2p;vital;minimal distance;intergiciel;funcion logaritmica;igual a igual p2p;parallelism;hashing;logarithmic function;sistema repartido;paralelismo;redundancy;fonction logarithmique;middleware;extensibilite;scalability;vtls;peer to peer;ils;redondance;distancia minima;enrutamiento	High scalability in Peer -to-Peer(P2P)systemshasbeenachieved with the emergenceof the networks basedon DistributedHashTables(DHT). Most of the DHTs canbe regardedas exponentialnetworks. Their network sizeevolvesexponentiallywhile theminimal distancebetweentwo nodesaswell asthe routingtablesize,i.e., thedegree,at eachnodeevolve linearly or remainconstant.In this paperwe presenta modelto bettercharacterizemostof thecurrent logarithmic-degreeDHTs. Weexpressthemin termsof absolute andrelative exponentialstructurednetworks. In relative exponentialnetworks,suchasChord,whereall nodesarereachable in atmost hops,thenumberof pathsof lengthinferioror equalto betweentwo nodesgrows exponentiallywith thenetwork size.WeproposetheTango approachto reducethisredundanc y andto improveotherpropertiessuchasreducingthelookuppathlength.WeanalyzeTango and show thatit is morescalablethanthecurrentlogarithmic-degreeDHTs. Givenits scalabilityand structuringflexibility, wechoseTango to bethealgorithmunderlyingour P2Pmiddleware.	distributed hash table;scalability;tango	Bruno Carton;Valentin Mesaros	2004		10.1007/978-3-540-27866-5_143	routing;logarithm;real-time computing;scalability;hash function;computer science;chord;artificial intelligence;theoretical computer science;operating system;peer-to-peer;middleware;database;distributed computing;redundancy;algorithm	DB	-11.135699384601228	69.92016522755122	65318
47511c70649995f945e883e35766c3aeeee83ba2	measurement-based design of roadside content delivery systems	reliability;wireless;computer systems organization wireless wide area networks communication networking and information technology computer systems organization performance of systems;performance of systems;communication networking and information technology;ieee 802 11 standards;mobile communication;vehicles;encoding;vehicles throughput encoding unicast ieee 802 11 standards mobile communication reliability;wide area networks;unicast;throughput;computer systems organization	With today's ubiquity of thin computing devices, mobile users are accustomed to having rich location-aware information at their fingertips, such as restaurant menus, shopping mall maps, movie showtimes, and trailers. However, delivering rich content is challenging, particularly for highly mobile users in vehicles. Technologies such as cellular-3G provide limited bandwidth at significant costs. In contrast, providers can cheaply and easily deploy a small number of WiFi infostations that quickly deliver large content to vehicles passing by for future offline browsing. While several projects have proposed systems for disseminating content via roadside infostations, most use simplified models and simulations to guide their design for scalability. Many suspect that scalability with increasing vehicle density is the major challenge for infostations, but few if any have studied the performance of these systems via real measurements. Intuitively, per-vehicle throughput for unicast infostations degrades with the number of vehicles near the infostation, while broadcast infostations are unreliable, and lack rate adaptation. In this work, we collect over 200 h of detailed highway measurements with a fleet of WiFi-enabled vehicles. We use analysis of these results to explore the design space of WiFi infostations, in order to determine whether unicast or broadcast should be used to build high-throughput infostations that scale with device density. Our measurement results demonstrate the limitations of both approaches. Our insights lead to Starfish, a high-bandwidth and scalable infostation system that incorporates device-to-device data scavenging, where nearby vehicles share data received from the infostation. Data scavenging increases dissemination throughput by a factor of 2-6, allowing both broadcast and unicast throughput to scale with device density.	high-throughput computing;location awareness;map;offline reader;scalability;simulation;thin client;throughput;unicast	Vinod Kone;Haitao Zheng;Antony I. T. Rowstron;Greg O'Shea;Ben Y. Zhao	2013	IEEE Transactions on Mobile Computing	10.1109/TMC.2012.90	embedded system;throughput;mobile telephony;telecommunications;computer science;operating system;reliability;wireless;encoding;statistics;computer network;unicast	Mobile	-19.704049690363448	76.49368438096283	65335
7be465ff84894264e0ad8c5c9936f1e11ddb0b18	towards efficient and lightweight collaborative in-network caching for content centric networks	analytical models;routing protocols;collaboration;publishing;internet;redundancy	In-network content caching is an inherent capability of Content Centric Networking (CCN) architecture. Undoubtedly, efficient caching strategies can help CCN networks to achieve high performance content dissemination. In general, there are two types of caching strategies: collaborative and non-collaborative caching strategies. Compared with non-collaborative caching strategies, collaborative caching strategies have much better caching performance. However, collaborative caching strategies incur extra overhead (e.g., computation and communication). To make a trade-off between the performance and overhead, we propose a distributed lightweight collaborative in-network caching strategy in this paper, called Popularity Publishing based caching strategy (PopPub for short). PopPub uses a lightweight protocol to publish the content popularity statistics counted by edge routers to other routers, and caches different contents at different routers along the content delivery paths based on the popularities of the contents. To evaluate the performance of PopPub, we conduct both theoretical analysis and extensive simulations on different topologies. The evaluation results confirm that PopPub yields the best performance compared with several state-of-art caching strategies, and the extra overhead incurred by PopPub is low.	cache (computing);computation;cyclomatic complexity;digital distribution;lightweight protocol;overhead (computing);router (computing);simulation;vii	Xiongbiao Wang;Jing Ren;Tong Tong;Rui Dai;Shizhong Xu;Sheng Wang	2016	2016 IEEE Global Communications Conference (GLOBECOM)	10.1109/GLOCOM.2016.7842342	the internet;false sharing;computer science;publishing;internet privacy;routing protocol;redundancy;world wide web;computer network;collaboration	HPC	-14.754011871247888	75.38378863173241	65345
6ef2e3f880490684a7e9cede67bbeadc24691bfb	on factors affecting the performance of dynamically groomed optical wdm mesh networks	wavelength division multiplexing wdm · differentiated path availability dpa · routing and wavelength assignment rwa;ring network;heuristic algorithm	In this paper, we consider the problem of traffic grooming in optical wavelength division multiplexed (WDM) mesh topology-based networks, under dynamic traffic conditions. Individual channels in a WDM network have capacities of up to 40 Gbps and are expected to increase further. However, individual connections (or sessions) typically do not require the entire wavelength capacity. Thus, allocating a lightpath with a full wavelength capacity for a single connection results in low bandwidth utilization. One way to solve this is by using electronic SONET add-drop multiplexers (SADMs) at each node to multiplex several low-rate connections on to the high-capacity wavelength channel, and provision them as a single lightpath. This is referred to as traffic grooming. However, SADMs are costly devices and it is expensive to equip each port and wavelength in every node with grooming capabilities. This leads to the concept of limited grooming that requires fewer SADMs at the nodes: only a subset of the ports and wavelengths will be equipped with SADMs. In this paper, we propose four different limited grooming node architectures and develop grooming policies for each architecture. We also conduct a systematic performance evaluation of a limited grooming optical network supporting dynamic traffic requests. We consider the effect of several important factors including: the connection granularity, traffic grooming policy, the number of SADMs at a node, the grooming port tunability and wavelength conversion. The results indicate that limited grooming at each node is sufficient to attain the performance obtained with full grooming, especially when connections occupy a small fraction of the wavelength capacity. Further, the connection granularity, the grooming policy and the number of wavelengths used per link for a connection are also seen to have a significant effect on the blocking performance. Interestingly, the SADM tunability and the port-sharing architecture are not seen to have a significant impact on the performance.	apollonian network;blocking (computing);data rate units;mesh networking;multiplexer;performance evaluation;routing;simulation;synchronous optical networking;wavelength-division multiplexing	Mahesh Sivakumar;Krishna M. Sivalingam;Suresh Subramaniam	2005	HPSR. 2005 Workshop on High Performance Switching and Routing, 2005.	10.1007/s11107-006-0011-8	traffic grooming;telecommunications;computer science;mesh networking;computer network	Metrics	-6.1620286401219895	84.46705321150867	65385
d60f757a3ee7e819127bfdbdc3beeeae55e013bf	novel resource and energy management for 5g integrated backhaul/fronthaul (5g-crosshaul)		The integration of both fronthaul and backhaul into a single transport network (namely, 5G-Crosshaul) is envisioned for the future 5G transport networks. This requires a fully integrated and unified management of the fronthaul and backhaul resources in a cost-efficient, scalable and flexible way through the deployment of an SDN/NFV control framework. This paper presents the designed 5G-Crosshaul architecture, two selected SDN/NFV applications targeting for cost-efficient resource and energy usage: the Resource Management Application (RMA) and the Energy Management and Monitoring Application (EMMA). The former manages 5G-Crosshaul resources (network, computing and storage resources). The latter is a special version of RMA with the focus on the objectives of optimizing the energy consumption and minimizing the energy footprint of the 5G-Crosshaul infrastructure. Besides, EMMA is applied to the mmWave mesh network and the high speed train scenarios. In particular, we present the key application design with their main components and the interactions with each other and with the control plane, and then we present the proposed application optimization algorithms along with initial results. The first results demonstrate that the proposed RMA is able to cost-efficiently utilize the Crosshaul resources of heterogeneous technologies, while EMMA can achieve significant energy savings through energy-efficient routing of traffic flows. For experiments in real system, we also set up Proof of Concepts (PoCs) for both applications in order to perform real trials in the field.		Xi Li;Raihana Ferdous;Carla-Fabiana Chiasserini;Claudio Casetti;Francesca Moscatelli;Giada Landi;Ramon Casellas;Kei Sakaguchi;Shahzoob Bilal Chundrigar;Ricard Vilalta;Josep Mangues;Andres Garcia-Saavedra;Xavier Pérez Costa;Leonardo Goratti;Domenico Siracusa	2017	2017 IEEE International Conference on Communications Workshops (ICC Workshops)	10.1109/ICCW.2017.7962753	architecture;computer network;real-time computing;resource management;transport network;computer science;scalability;mesh networking;backhaul (telecommunications);network management application;energy management	HPC	-19.562392945048032	80.72590276492022	65444
084e40035e72df4b4607d30939affa8e3209a128	design and implementation of a lan monitoring tool	design and implementation	The seven layer Open Systems Interconnection (OSI) protocol reference model has achieved the goal of dividing network operations into distinct implementation modules. High level protocols shield the user from activities occurring at the lower levels. Unfortunately, these high level protocols also keep the user from seeing low level problems that can cause insidious network events. The LANalyzer EX 5000E is an Ethernet network analysis tool created to provide insight into network problems, and to assist in the debugging of network applications and protocols. This paper discusses the conception and implementation of the EX 5000E. Design tradeoffs are addressed, and the hardware and software architecture of the product is explained.	debugging;high-level programming language;iso 10303 application modules;interconnection;osi model;reference model;software architecture	Steve Spanier	1988	Computer Communications	10.1016/0140-3664(88)90097-7	embedded system;network planning and design;real-time computing;computer science;operating system;distributed computing;computer security;computer network	Networks	-21.196516046244156	85.88658787391243	65446
aa6a7b01b9d594ba5daea0bba042d9a8f03552ea	a simple high-speed optical local area network based on flooding	protocols;concurrency high speed optical network space division multiplexing short address packet broadcasting local area network flooding lan point to point connectivity topology independent routing method protocol end to end path source destination path tree network blocking delays full electronics speed;flooding;red local;protocole transmission;optical interconnection;routing;point to point;source destination path;high speed optical techniques;telecommunication network;end to end path;optical fiber networks;short address packet broadcasting;full electronics speed;lan;multiplaje;multiplexing;lan interconnection;point to point connectivity;local network;protocolo transmision;concurrency;multiplexage;telecomunicacion optica;telecommunication optique;red telecomunicacion;topology independent routing method;blocking delays;analyse performance;performance analysis;reseau telecommunication;high speed optical techniques optical fiber networks optical fiber lan optical receivers optical interconnections lan interconnection local area networks light sources broadcasting routing;optical links;optical telecommunication;broadcasting;tree network;reseau local;protocols local area networks multiplexing optical links;optical fiber lan;high speed optical network;high speed;local area networks;local area network;optical receivers;light sources;interconeccion optica;optical interconnections;analisis eficacia;protocol;interconnexion optique;transmission protocol;space division multiplexing	The problem of interconnecting many high-speed terminal users via an optical local area network (LAN) is addressed. Space-division multiplexing (SDM) is used to provide point-to-point connectivity, so simple light sources and receivers are all that is required. The call setup between a source and a destination is based on the broadcasting of a short address packet called flooding, which is a simple topology-independent routing method that alleviates the need to have intelligent nodes (cross points). A simple protocol is used to establish an end-to-end path using flooding. Once a source/destination path is established, the actual call starts. The established path is not interrupted by other call setup flooding attempts and/or other cells. A performance analysis for a simple tree network indicates that a capacity of 66% can be achieved at reasonable average blocking delays. The network users can each access full electronics speeds, and the total throughput of the network is a multiple of full electronics speed, with concurrency achieved by SDM. >		Mohsen Kavehrad;Isam M. I. Habbab	1988	IEEE Journal on Selected Areas in Communications	10.1109/49.1957	local area network;telecommunications;computer science;flooding;distributed computing;computer network	Vision	-5.604642670565324	87.69134241911325	65495
14f1ed0d42b976325be6b860533ea4241651cb74	geni - global environment for network innovations	computer networks;innovation management computer networks;national infrastructure;innovation management;community networks;national science foundation;global environment for network innovations;global communications networks;global communications networks global environment for network innovations national science foundation national infrastructure	ion: One of the central tenets of computer science is that complexity can be reduced and managed with abstraction. Simple interfaces allow complex functions to be used by programs that don't understand the details of those functions. Remarkably, network management completely lacks a decent low-level abstraction. This is not to say that there aren't standardized management interfaces: SNMP is one such interface. SNMP, however, does nothing to abstract away the complexity of protocol operation. Every managed protocol object (counter, parameter, etc.) is exposed, forcing network management functions to cope with all the complexity of protocols and their interaction. There has been considerable attention paid to reducing the complexity seen by the human manager. For instance, a key selling point of products like HP Openview is that it allows non-experts to manage large networks. But these products must still cope with a complex network, and often fail to hide much of the network complexity, especially for cutting-edge network devices.	complex network;computer science;global variable;high- and low-level;simple network management protocol	Chip Elliott	2008		10.1109/LCN.2008.4664143	innovation management;knowledge management;computer network	Theory	-16.059114526152634	84.16240911181478	65579
b56992d3bddade4a0e02bdb4ed45ccc375a408a7	an exact algorithm for non-preemptive peak demand job scheduling		Peak demand scheduling aims to schedule jobs so as to min- imize the peak load in the schedule. An important application of this problem comes from scheduling power jobs in the smart grid. Currently, peaks in power demand are due to the aggregation of many jobs being scheduled in an on-demand fashion. Often these have some flexibility in their starting times which can be leveraged to lower the peak demand of a schedule. While the general version of the problem is known to be NP- hard (we observe it is even NP-hard to approximate), we provide an opti- mal algorithm based on dynamic programming that is fixed-parameter tractable (FPT). Simulation results using household power usage data show that peak power demand can be significantly reduced by allowing some flexibility in job execution times and applying scheduling.	exact algorithm;job scheduler;job shop scheduling;scheduling (computing)	Sean Yaw;Brendan M Mumey	2014		10.1007/978-3-319-12691-3_1	mathematical optimization;real-time computing;dynamic priority scheduling;computer science	HPC	-20.974193466543813	63.906140365731005	65613
5319e5e0299359a0f2b7115e36e7bf3fba8bb554	testing switched ethernet networks in automotive embedded systems	computers;software;automotive electronics;switching networks;network simulation;software testing;network simulation ethernet ip udp switch testing packet monitoring packet generation;testing automotive electronics controller area networks embedded systems lan interconnection switching networks telecommunication traffic;ethernet;switch;udp;ethernet test switch switched ethernet network testing automotive embedded system distributed automotive system interconnection traffic simulation distributed embedded system lin can flexray physical shared medium;controller area networks;testing;packet generation;embedded system;computer network;lan interconnection;embedded systems;telecommunication traffic;monitoring;ip;fabrics;bandwidth;switches;switches monitoring fabrics bandwidth software testing computers;packet monitoring	Ethernet is currently being discussed within the automotive community to become a general network technology for interconnecting future distributed automotive systems. If this is the case, a complete tool chain will be necessary to support developers to implement their functions. One important component is the availability of tools to monitor, generate, manipulate, and simulate traffic in distributed embedded systems. Today's established communication technologies like LIN, CAN, or FlexRay have the enormous advantage to be based on a physical shared medium which makes it relatively easy to add an additional test device to a network under test. This paper describes an approach to implement such a test device for switched Ethernet networks, presents performance measurements of our implemented Ethernet-Test-Switch, and introduces a concept to integrate simulated and existing devices with each other.	bit error rate;data buffer;embedded system;field-programmable gate array;flexray;lookup table;microsoft outlook for mac;network packet;network switch;simulation;toolchain	Andreas Kern;Hongyan Zhang;Thilo Streichert;Jürgen Teich	2011	2011 6th IEEE International Symposium on Industrial and Embedded Systems	10.1109/SIES.2011.5953657	embedded system;real-time computing;computer science;operating system;software testing;computer network	Embedded	-20.955964683753464	83.4739656232358	65642
b50a20396057010c7d1a2818d56e47e477d9b3f5	online auctions in iaas clouds: welfare and profit maximization with server costs	cost function;resource allocation;pricing;resource management;servers;computational modeling;cloud computing computer centres convex programming costing duality mathematics electronic commerce profitability resource allocation virtual machines;auction;cloud computing auction resource allocation pricing online algorithms truthful mechanisms;convex server cost functions lagrangian duality convex programs fenchel duality social welfare maximizing auctions randomized reduction algorithm vm allocation online primal dual optimization framework truthful polynomial time auctions cloud provider net profit maximization resource allocation server operational costs requested vm heterogeneous physical machines data centers occupation durations customized vm assembly cloud user resource bidding online vm auction design vm provisioning virtual machine dynamic resource bundling server costs iaas clouds online auctions;servers resource management cloud computing algorithm design and analysis cost function computational modeling;online algorithms;truthful mechanisms;algorithm design and analysis;truthful mechanisms cloud computing auction resource allocation pricing online algorithms;cloud computing	Auction design has recently been studied for dynamic resource bundling and virtual machine VM provisioning in IaaS clouds, but is mostly restricted to one-shot or offline setting. This paper targets a more realistic case of online VM auction design, where: 1 cloud users bid for resources into the future to assemble customized VMs with desired occupation durations, possibly located in different data centers; 2 the cloud provider dynamically packs multiple types of resources on heterogeneous physical machines servers into the requested VMs; 3 the operational costs of servers are considered in resource allocation; and 4 both social welfare and the cloud provider’s net profit are to be maximized over the system running span. We design truthful, polynomial time auctions to achieve social welfare maximization and/or the provider’s profit maximization with good competitive ratios. Our mechanisms consist of two main modules: 1 an online primal-dual optimization framework for VM allocation to maximize the social welfare with server costs, and for revealing the payments through the dual variables to guarantee truthfulness and 2 a randomized reduction algorithm to convert the social welfare maximizing auctions to ones that provide a maximal expected profit for the provider, with competitive ratios comparable to those for social welfare. We adopt a new application of Fenchel duality in our primal-dual framework, which provides richer structures for convex programs than the commonly used Lagrangian duality, and our optimization framework is general and expressive enough to handle various convex server cost functions. The efficacy of the online auctions is validated through careful theoretical analysis and trace-driven simulation studies.	augmented lagrangian method;cloud computing;convex optimization;data center;duality (optimization);entropy maximization;expectation–maximization algorithm;fenchel's duality theorem;mathematical optimization;maximal set;online and offline;provisioning;randomized algorithm;server (computing);simulation;time complexity;virtual machine	Xiaoxi Zhang;Zhiyi Huang;Chuan Wu;Zongpeng Li;Francis C. M. Lau	2015	IEEE/ACM Transactions on Networking	10.1109/TNET.2016.2619743	pricing;algorithm design;online algorithm;simulation;cloud computing;resource allocation;computer science;resource management;operating system;distributed computing;computational model;server	Metrics	-22.32515117274306	64.76675511492817	65677
eea5ff6f3f3f0243059d2f788b3c8fb8471523c1	idealist data plane solutions for elastic optical networks	optical fiber networks optical fibers optical filters optical switches optical signal processing optical receivers;digital layer idealist data plane solution elastic optical network resource utilization traffic demand software defined architecture ict idealist project flexgrid technology flex rate technology optical cross connect transponder;telecommunication traffic optical fibre networks;elastic optical networks optical communication;computer networks and communications;optical communication;elastic optical networks	The elastic optical networks paradigm offers a competitive solution in terms of resource utilization to cope with the ever-increasing traffic demand. Specifically, the ability to make a number of previously fixed transmission parameters tunable, for example the data rate or channel spacing, requires an evolution of the node architecture. To fully benefit from elasticity, the data plane should evolve towards a software-defined architecture. In this paper, we report the work carried out in the ICT IDEALIST project and in particular the data plane solutions towards 1Tb/s optical networks with flexgrid and flex-rate technology. Flexibility requires changes in optical cross-connect, transponder as well as in the digital layer. The consortium builds pre-commercial experimental testbeds to validate the proposed building blocks and to analyze candidate applications.	channel spacing;computer hardware;digital cross connect system;elasticity (data store);forwarding plane;optical cross-connect;programming paradigm;propagation constant;testbed;transponder;uncompressed video	Patricia Layec;Annachiara Dupas;Markus Nolle;Johannes Karl Fischer;Colja Schubert;Josep M. Fabrega;Michela Svaluto Moreolo;Nicola Sambo;Gianluca Meloni;Francesco Fresi;Antonio Napoli;Danish Rafique;Marc Bohn;Antonio D'Errico;Talha Rahman;Emilio Hugues-Salas;Yan Yan;Shuangyi Yan;Georgios Zervas	2015	2015 European Conference on Networks and Communications (EuCNC)	10.1109/EuCNC.2015.7194098	optical transport network;passive optical network;electronic engineering;optical burst switching;multiwavelength optical networking;telecommunications;10g-pon;engineering;optical performance monitoring;optical cross-connect;computer network;optical communications repeater	Mobile	-11.208598202834983	85.99323823087268	65683
027e91b4495d7c9cc98520ca19360ce51a5a72c1	improving the reliability of internet paths with one-hop source routing	source routing	Recent work has focused on increasing availability in the face of Internet path failures. To date, proposed solutions have relied on complex routing and pathmonitoring schemes, trading scalability for availability among a relatively small set of hosts. This paper proposes a simple, scalable approach to recover from Internet path failures. Our contributions are threefold. First, we conduct a broad measurement study of Internet path failures on a collection of 3,153 Internet destinations consisting of popular Web servers, broadband hosts, and randomly selected nodes. We monitored these destinations from 67 PlanetLab vantage points over a period of seven days, and found availabilities ranging from 99.6% for servers to 94.4% for broadband hosts. When failures do occur, many appear too close to the destination (e.g., last-hop and end-host failures) to be mitigated through alternative routing techniques of any kind. Second, we show that for the failures that can be addressed through routing, a simple, scalable technique, called one-hop source routing, can achieve close to the maximum benefit available with very low overhead. When a path failure occurs, our scheme attempts to recover from it by routing indirectly through a small set of randomly chosen intermediaries. Third, we implemented and deployed a prototype onehop source routing infrastructure on PlanetLab. Over a three day period, we repeatedly fetched documents from 982 popular Internet Web servers and used one-hop source routing to attempt to route around the failures we observed. Our results show that our prototype successfully recovered from 56% of network failures. However, we also found a large number of server failures that cannot be addressed through alternative routing. Our research demonstrates that one-hop source routing is easy to implement, adds negligible overhead, and achieves close to the maximum benefit available to indirect routing schemes, without the need for path monitoring, history, or a-priori knowledge of any kind.	internet;overhead (computing);planetlab;prototype;randomness;scalability;server (computing);source routing;web server	Krishna P. Gummadi;Harsha V. Madhyastha;Steven D. Gribble;Henry M. Levy;David Wetherall	2004			policy-based routing;routing table;routing domain;routing;enhanced interior gateway routing protocol;static routing;source routing;dsrflow;zone routing protocol;equal-cost multi-path routing;computer science;dynamic source routing;multipath routing;destination-sequenced distance vector routing;operating system;distributed computing;routing protocol;link-state routing protocol;triangular routing;default-free zone;path vector protocol;computer security;geographic routing;routing information protocol;computer network	OS	-13.168517491473144	77.48528908805905	65745
368dbbf9d9b5f47dd4ee529d1197da3bac519f45	piece selection algorithms for layered video streaming in p2p networks	streaming;layered scalable content;multimedia;peer to peer network;piece selection;knapsack problem	This paper introduces the piece selection problem that arises when streaming layered video content over peer-to-peer networks. The piece selection algorithm decides periodically which pieces to request from other peers (network nodes) for download. The main goal of the piece selection algorithm is to provide the best possible quality for the available bandwidth. Our recommended solution approaches are related to the knapsack problem. In this paper, a number of layered piece picking algorithms are presented and they are compared to each other. In a competitive analysis, the presented online algorithms are compared to an optimal offline algorithm.	algorithm;peer-to-peer;streaming media	Tibor Szkaliczki;Michael Eberhard;Hermann Hellwagner;László Szobonya	2014	Discrete Applied Mathematics	10.1016/j.dam.2013.11.007	mathematical optimization;computer science;mathematics;distributed computing;multimedia;knapsack problem;world wide web	ML	-15.884489952314992	73.18242441144815	65787
a06ae4e4828507049353307c3c64a428bbf2ac95	flowshadow: a fast path for uninterrupted packet processing in sdn switches		Updating rules in the flow tables of SDN switches are complex and time-consuming. Therefore, we propose a cache-based scheme (named FlowShadow) to improve the packet processing performance and keep continuous operating while updating rules in the flow tables. FlowShadow caches the microflows in the hash table to build a fast path for packet processing. By leveraging the Action Table, FlowShadow achieves update consistency and good update performance. In order to examine the reliability, validity, utility and scalability of FlowShadow, we implement FlowShadow on the Open VSwitch and conduct numerous experiments with different settings to measure the performance of FlowShadow. The experimental results demonstrate that FlowShadow achieves a lookup speed of 75 million packets per second on a commodity PC under the real backbone traces; the system with FlowShadow speeds up 3.4X times of the original Open VSwitch.	cpu cache;experiment;fast path;hash table;internet backbone;lookup table;network packet;network switch;open vswitch;scalability;software-defined networking;throughput;tracing (software)	Yi Wang;Dongzhe Tai;Shaobo Zhang;Linxiao Jin;Huichen Dai;Bin Liu;Xin Wu	2015	2015 ACM/IEEE Symposium on Architectures for Networking and Communications Systems (ANCS)		parallel computing;real-time computing;data structure;computer science;operating system;distributed computing;software-defined networking;computer security;computer network	OS	-13.26947665954788	81.58472108266874	65792
7ec486630b5514e9b66182c0dad9a1ebb1dd9470	an enhanced algorithm of spare capacity assignment for self-healing networks	distributed algorithms;optimisation;synchronous digital hierarchy;optimisation telecommunication network reliability synchronous digital hierarchy channel capacity search problems telecommunication links telecommunication traffic telecommunication network routing sonet network topology distributed algorithms;telecommunication links;telecommunication network reliability;network topology;telecommunication traffic;costs telecommunication traffic asynchronous transfer mode electrical capacitance tomography sonet laboratories telecommunication switching postal services electronic switching systems synchronous digital hierarchy;telecommunication network routing;channel capacity;binary search optimisation algorithm enhanced algorithm spare capacity assignment optimal link capacity design self healing sdh networks bsoa computation time reduction network installation cost reduction traffic demands route diversity sonet large scale networks distributed self healing algorithms dcs;binary search;search problems;sonet	This paper addresses an optimal link capacity design problem for self-healing SDH networks. By taking advantages of the binary search and inducing two parameters, we proposed an enhanced algorithm, binary search optimisation algorithm (BSOA), which results in a great reduction on the computation time and network installation cost (spare capacity). The proposed algorithm was tested on three sample networks for several typical traffic demands. The results indicate that this algorithm is more effective than before.	algorithm	Lijun Chen;Yuehui Jin;Shiduan Cheng	1998		10.1109/ISCC.1998.702603	distributed algorithm;telecommunications;computer science;synchronous optical networking;distributed computing;channel capacity;network topology;computer network;binary search algorithm	EDA	-4.91016527145173	82.01947869466937	65850
a96b8e324612d3cef5366db8690db0809d02996d	wire speed name lookup: a gpu-based approach	filtering;networks;paper;cuda;nvidia geforce gtx 590;nvidia;computer science	This paper studies the name lookup issue with longest prefix matching, which is widely used in URL filtering, content routing/switching, etc. Recently Content-Centric Networking (CCN) has been proposed as a clean slate future Internet architecture to naturally fit the contentcentric property of today’s Internet usage: instead of addressing end hosts, the Internet should operate based on the identity/name of contents. A core challenge and enabling technique in implementing CCN is exactly to perform name lookup for packet forwarding at wire speed. In CCN, routing tables can be orders of magnitude larger than current IP routing tables, and content names are much longer and more complex than IP addresses. In pursuit of conquering this challenge, we conduct an implementation-based case study on wire speed name lookup, exploiting GPU’s massive parallel processing power. Extensive experiments demonstrate that our GPU-based name lookup engine can achieve 63.52M searches per second lookup throughput on large-scale name tables containing millions of name entries with a strict constraint of no more than the telecommunication level 100μs per-packet lookup latency. Our solution can be applied to contexts beyond CCN, such as search engines, content filtering, and intrusion prevention/detection. c ⃝Prof. Qunfeng Dong (qunfeng.dong@gmail.com) and Prof. Bin Liu (lmyujie@gmail.com), placed in alphabetic order, are the correspondence authors of the paper. Yi Wang and Yuan Zu, placed in alphabetic order, are the lead student authors of Tsinghua University and University of Science and Technology of China, respectively. This paper is supported by 863 project (2013AA013502), NSFC (61073171, 61073184), Tsinghua University Initiative Scientific Research Program(20121080068), the Specialized Research Fund for the Doctoral Program of Higher Education of China(20100002110051), the Ministry of Education (MOE) Program for New Century Excellent Talents (NCET) in University, the Science and Technological Fund of Anhui Province for Outstanding Youth (10040606Y05), by the Fundamental Research Funds for the Central Universities (WK0110000007, WK0110000019), and Jiangsu Provincial Science Foundation (BK2011360).	application-oriented networking;clean slate program;content-control software;cyclomatic complexity;experiment;future internet;graphics processing unit;intrusion detection system;longest prefix match;lookup table;moe;network packet;parallel computing;routing table;throughput;web search engine	Yi Wang;Yuan Zu;Shaobo Zhang;Kunyang Peng;Qunfeng Dong;Bin Liu;Wei Meng;Huichen Dai;Xin Tian;Zhonghu Xu;Hao Wu;Di Yang	2013			filter;parallel computing;computer science;theoretical computer science;operating system;database;distributed computing;computer security;computer network	Networks	-5.36658809430824	66.10080160794769	65921
3270087b458a08170df01a48d6da5ba9c8b78080	on-demand provisioning of data-aggregation requests over wdm mesh networks	mixed integer linear program;scientific application;routing;wavelength division multiplexing integer programming linear programming optical fibre networks;processor scheduling;large scale scientific applications;optical networks;optical fibre networks;large scale;tel;optical networks on demand provisioning data aggregation requests wdm mesh networks large scale scientific applications wavelength division multiplexing backbone network mathematical formulation mixed integer linear program wavelength division multiplexing;integer programming;data aggregation;linear programming;mathematical model;wdm mesh networks;bandwidth;mesh network;wavelength division multiplexing wdm networks mesh networks large scale systems supercomputers traffic control processor scheduling aggregates scientific computing optical fiber networks;peer to peer computing;mathematical formulation;on demand provisioning;wavelength division multiplexing backbone network;data aggregation requests;wavelength division multiplexing;wavelength division multiplex	Many large-scale scientific applications need to aggregate large amounts of data from multiple distributed sites to a centralized facility. We call such a request as a data-aggregation request (DAR). In this study, we investigate the novel problem of on-demand DAR provisioning over a wavelength-division multiplexing (WDM) backbone network. We provide a mathematical formulation for our problem as a mixed integer linear program (MILP). To solve large versions of our problem, we propose a DAR provisioning heuristic (called DARP). We use the MILP with various objectives as a benchmark for studying the performance of DARP.	aggregate data;benchmark (computing);centralized computing;heuristic;heuristic (computer science);internet backbone;linear programming;mesh networking;provisioning;requests;routing;scheduling (computing);wavelength-division multiplexing	Dragos Andrei;Massimo Tornatore;Dipak Ghosal;Charles U. Martel;Biswanath Mukherjee	2008	IEEE GLOBECOM 2008 - 2008 IEEE Global Telecommunications Conference	10.1109/GLOCOM.2008.ECP.509	data aggregator;routing;integer programming;telecommunications;computer science;linear programming;mesh networking;mathematical model;distributed computing;bandwidth;wavelength-division multiplexing;computer network	HPC	-5.673471191092669	82.51130978709728	65961
091299a1a9e1f93de3b15663ac4ad2084252ee55	network and service management [series editorial]	cloud computing;network security;internet;virtualization;mobile computing;next generation networking;cellular networks;computer architecture;big data;quality of service;mobile communication;telecommunication services		operating system service management	George Pavlou;Jürgen Schönwälder	2015	IEEE Communications Magazine	10.1109/MCOM.2015.7158276	computer network;the internet;quality of service;network security;big data;computer science;service management;telecommunications service;mobile telephony	Visualization	-16.41182926099035	87.83161468595051	66082
877488119b279958681b83f7fad754696140889d	easymanet: an extensible and configurable platform for service provisioning in manet environments	protocols;visualization;servers;mobile ad hoc networks;ip networks;bluetooth;mobile ad hoc networks ip networks visualization bluetooth protocols servers	Mobile ad hoc networks are highly dynamic networks that offer multihop communications in the presence of changing topologies without the need for any fixed infrastructure support. These networks can be useful in a wide variety of scenarios, but setting them up and deploying services on them is a difficult task, even for experienced users. In this article we present EasyMANET ¿ an extensible platform the main objective of which is to encourage the widespread adoption and use of MANETs by non-expert users. To achieve this objective, EasyMANET provides two essential elements: an address autoconfiguration system and a name resolution service known as Visual DNS. The autoconfiguration system allows users to join an 802.11-based MANET by establishing the parameters of their terminal interfaces quickly and transparently. Thereafter, Visual DNS offers a graphical view of MANET participants and gives users the possibility to access the services made available by other users. Examples are communication services (text-based chat, VoIP, videoconference), file sharing, and localization services. We performed several laboratory experiments, and evaluated the performance of EasyMANET based on address autoconfiguration time and Visual DNS performance. Results show that EasyMANET can be established within seconds, and EasyMANET applications are easy to use. In fact, over 360 students have tried using Easy- MANET without problems.	auto-configuration;experiment;file sharing;graphical user interface;hoc (programming language);internationalization and localization;manet database;provisioning;text-based (computing)	José Cano;Juan-Carlos Cano;Chai-Keong Toh;Carlos Miguel Tavares Calafate;Pietro Manzoni	2010	IEEE Communications Magazine	10.1109/MCOM.2010.5673087	communications protocol;visualization;computer science;operating system;internet privacy;bluetooth;world wide web;server;computer network	Mobile	-15.48355089320824	77.92482116668076	66085
3f30c1bd9131e8c11907acca880e2ef76554543e	the ipv4 dynamic host configuration protocol (dhcp) option for the internet storage name service		"""Status of This Memo This document specifies an Internet standards track protocol for the Internet community, and requests discussion and suggestions for improvements. Please refer to the current edition of the """"Internet Official Protocol Standards"""" (STD 1) for the standardization state and status of this protocol. Distribution of this memo is unlimited. Abstract This document describes the Dynamic Host Configuration Protocol (DHCP) option to allow Internet Storage Name Service (iSNS) clients to discover the location of the iSNS server automatically through the use of DHCP for IPv4. iSNS provides discovery and management capabilities for Internet SCSI (iSCSI) and Internet Fibre Channel Protocol (iFCP) storage devices in an enterprise-scale IP storage network. iSNS provides intelligent storage management services comparable to those found in Fibre Channel networks, allowing a commodity IP network to function in a similar capacity to that of a storage area network."""	iscsi;internet fibre channel protocol;internet storage name service;name service switch;scsi;std bus;server (computing);storage area network	Charles Monia;Joshua Tseng;Kevin Gibbons	2005	RFC	10.17487/RFC4174	hyperscsi;ipconfig;ip address management;business;internet privacy;world wide web;dynamic host configuration protocol;computer network	Networks	-25.439253582973677	88.01032740977703	66131
9d4317b9cc0fc8e79a8d9cc4688f55ea0cc6a233	the benefits of rich internet applications on network performance	rich internet application;network performance	"""Adobe has a long history of providing technologies that have changed how people engage with ideas and information: technologies that have redefined business, entertainment, and personal communications. For nearly two decades, Adobe has focused on improving the web experience and on delivering the underlying technologies used to produce more interactive and expressive websites and applications. These engaging experiences have been widely adopted and deliver tangible return on investment (ROI) to the businesses that deploy them. The term rich Internet application (RIA) describes the new category of applications that bridge the client and the Internet cloud. They have come about as a means of solving the """" rich versus reach """" conundrum, enabling Internet applications to be both rich in functionality and engaging to use, yet able to take full advantage of the Internet's reach, connectivity, and deployment model. To date, RIAs have been promoted in support of engaging and retaining consumers and applied broadly to improve consumer facing applications and interactions. However, many of the capabilities that make RIAs a significant value proposition for consumer-facing applications offer similar benefits for business-to-business interactions and applications. Online stores, product selection and customization, the streaming of video, and rich imagery all have value within the context of enterprise-facing applications. The real excitement is that RIAs enable new classes of enterprise applications that can greatly improve the access to data stored within the organization, helping employees to better understand and use that data and to support their working practices in richer, more interactive, and more intuitive ways. The outcome of this is not only increased levels of employee productivity and effectiveness; it can be the differentiator needed to achieve competitive success, business innovation, and operational excellence. The most important consideration for RIAs is that they are used appropriately and within the context of the interaction. The Adobe® Flash® Platform is an integrated solution that enables designers and developers to easily work together to build and deploy enterprise RIAs that enable more effective interaction. Understanding rich Internet applications What is an RIA? A rich Internet application is the focal point of the convergence between desktop applications and browser-based clients. RIAs combine the strengths of both domains while liberating the user from their respective constraints. 1 Understanding rich Internet applications 3 RIA access points 4 The role of RIAs in the enterprise 6 The value proposition of RIAs compared to existing technologies 8 The Adobe Flash …"""	adobe flash;definition;desktop computer;differentiator;enterprise software;experience;focal (programming language);interaction;network performance;norm (social);region of interest;rich internet application;service innovation;software deployment;streaming media;web application;wireless access point	Luis Derechin	2005			rich internet application;world wide web;computer network;dynamic circuit network;network performance;computer science	HCI	-20.051868478603165	74.12939400866209	66264
f16325153448d49876209be96d00ad7810782b3c	overhead control heuristics in boundary fair real-time multiprocessor scheduling		The optimal scheduling algorithms in real-time multiprocessor systems are considered impractical. This is mainly because of the overhead generated due to the frequent scheduling points, migrations and preemptions. The solution to this problem is either to propose new algorithms with less overhead or to improve the existing ones. In this article, some simple heuristics to control the overhead are proposed for a class of optimal algorithms known as Boundary Fair scheduling. The heuristics do not disturb the optimality of the original algorithms. This paper gives some detailed simulation results along with description of experimental conditions. The given results show the basic strength of the heuristics and validate their efficiency both for non-work-conserving and work-conserving systems.	algorithm;central processing unit;earliest deadline first scheduling;fair-share scheduling;fairness measure;heuristic (computer science);multiprocessing;multiprocessor scheduling;overhead (computing);preemption (computing);real-time clock;real-time transcription;scheduling (computing);simulation	Muhammad Naeem Shehzad;Anne-Marie Déplanche;Yvon Trinquet;Richard Urunuela	2017	22017 IEEE International Conference on Computational Science and Engineering (CSE) and IEEE International Conference on Embedded and Ubiquitous Computing (EUC)	10.1109/CSE-EUC.2017.207	lottery scheduling;fair-share scheduling;round-robin scheduling;distributed computing;genetic algorithm scheduling;heuristics;real-time computing;computer science;multiprocessor scheduling;fixed-priority pre-emptive scheduling;two-level scheduling	Embedded	-11.014619318647176	61.06972693921041	66277
c9ca3a73b5c9f54b8f6c58c070ee6c150963d32b	modeling peer-to-peer networks from the impact of nodes' characters on the system performance	analytical models;peer to peer network;query processing;resource allocation;publishing;time sharing;peer to peer system;system performance;indexes;distance measurement;resource allocation peer to peer computing query processing;peer to peer computing system performance publishing broadcasting sun analytical models information science educational technology laboratories distributed computing;ip networks;query processing peer to peer network node character quantitative measure resource sharing scheme;peer to peer computing;node character quantitative measure;analytical model;resource sharing scheme	In current peer-to-peer systems, system performance is evaluated by the metrics that characterize the features of the whole system while how each node's character affects the system performance is rarely considered. In this paper, we first introduce a new metric of publishing efficiency to quantitatively measure the impact of node's character on the system performance, and also we demonstrate the significance of the proposed metric. Then we build an analytical model to study how nodes' online time, shared resources and the ranges that the indices and resources of the nodes serve queries affect their publishing efficiency. We validate the analytical results through simulation and discuss their significance to improving the average nodes' publishing efficiency in peer-to-peer systems.	peer-to-peer;simulation	Yadong Gong;Xiaola Lin	2008	IEEE GLOBECOM 2008 - 2008 IEEE Global Telecommunications Conference	10.1109/GLOCOM.2008.ECP.423	database index;resource allocation;computer science;theoretical computer science;publishing;distributed computing;computer performance;world wide web;time-sharing;computer network	DB	-11.871333984907189	74.54201614857864	66299
937bfd94e7857dc544d546b376875fa0bd26c3b1	generating bursty web traffic for a b2c web server		The paper deals with the problem of emulating highly bursty Web traffic that can be observed at inputs of Web servers hosting online Web stores. This problem is related to the broad issue of Web server performance prediction and evaluation through simulation experiments. Based on up-to-date results on real Web server workload analyses a workload model has been proposed. It combines a model of a user session at a Business-to-Consumer (B2C) Web site with HTTP-level workload models for business and non-business Web servers. The proposed model has been implemented in a workload generator. Based on statistics registered during a simulation experiment, a burstiness factor has been computed for the generated workload, which has proven to be highly variable and bursty.	web server;web traffic	Grazyna Suchacka	2011		10.1007/978-3-642-21771-5_20	web service;clickstream;database;internet privacy;world wide web;web server	Web+IR	-21.042711661376032	71.88542067898562	66352
470b7a039de92aab0ce19ce2e757f6c62f095b8a	on implicit denial of service attack in ndn and potential mitigations		One major benefit of named-data networking (NDN) is its potential to control network load by leveraging in-network caching and request aggregation. Both the network operator and consumers benefit from these features, as operating costs are reduced and quality-of-experience is increased. However, request aggregation, combined with NDN's loop prevention mechanisms, can create denial-of- service (DoS) against client interests (intentionally and unintentionally) by clients employing multicast forwarding. In this paper, we discuss this problem and propose three increasingly efficient solutions to address the problem; our arguments are backed by simulation and numerical analyses.	acknowledgement (data networks);cache (computing);denial-of-service attack;disk staging;multicast;numerical analysis;simulation	Gaurav Panwar;Reza Tourani;Travis Mick;Satyajayant Misra;Abderrahmen Mtibaa	2018	2018 IEEE International Conference on Communications Workshops (ICC Workshops)	10.1109/ICCW.2018.8403579	control network;denial-of-service attack;computer science;multicast;operator (computer programming);computer network;the internet	HPC	-13.93553917376099	81.18161179952796	66458
1563dde8226105b3dd5faeec9de3eb5747d5ed31	mobile low latency services in 5g	ip networks mobile communication mobile computing vehicles mission critical systems optimization traffic control;5g mobile communication;delay sensitive mobile applications mobile low latency services 5g architecture traffic volumes	"""Networks beyond 2020 will experience 10000-fold increase in wireless traffic, connect 10-100 times more devices and support the most diverse use cases. Thus, the 5G architecture needs to be flexible and cater for both traffic volumes and diversity of service requirements. Among the set of new use cases, support of delay sensitive """"mobile"""" applications, such as vehicular communications (V2X, where X stands for either Vehicle or Infrastructure), require architecture enhancements to natively offer low latency and high mobility. In this paper we propose the necessary technology enablers for the architectural solution to support such use cases."""	centralized computing;forwarding plane;gw-basic;internet access;interrupt latency;mobile virtual private network;network architecture;network function virtualization;requirement;sim lock;scott continuity;software-defined networking;switch	Andrea F. Cattoni;Devaki Chandramouli;Cinzia Sartori;Rainer Stademann;Paolo Zanier	2015	2015 IEEE 81st Vehicular Technology Conference (VTC Spring)	10.1109/VTCSpring.2015.7145936	embedded system;real-time computing;mobile search;mobile web;imt advanced;engineering;mobile technology;mobile station;mobile computing;computer network	Mobile	-14.716226987799692	88.49040967014489	66475
5438349118a48da1322ab10f626eb2df0d32f651	energy efficiency in telecom optical networks	energy efficiency;optical;energy conservation;optical network;energy;networks;access network;energy efficiency telecommunications optical fiber networks energy consumption energy conservation hydrocarbons communications technology humans protection grid computing;optical transmitters;energy efficient;efficiency;information technology;optical fiber networks;optical fibre networks computer centres energy conservation grid computing information technology;metro networks;integrated optics;optical switches;telecommunication optical networks;environmental protection;computer centres;optical fibre networks;protection;data center;information and communication technology;energy consumption;networks energy efficiency telecom optical;access networks;hydrocarbons;communications technology;humans;energy minimization;data centers energy efficiency telecommunication optical networks energy crisis environmental protection information and communication technology energy minimization core networks metro networks access networks grid computing;telecom;grid computing;optical receivers;core networks;telecommunications;energy crisis;data centers	"""Since the energy crisis and environmental protection are gaining increasing concerns in recent years, new research topics to devise technological solutions for energy conservation are being investigated in many scientific disciplines. Specifically, due to the rapid growth of energy consumption in ICT (Information and Communication Technologies), lot of attention is being devoted towards """"green"""" ICT solutions. In this paper, we provide a comprehensive survey of the most relevant research activities for minimizing energy consumption in telecom networks, with a specific emphasis on those employing optical technologies. We investigate the energy-minimization opportunities enabled by optical technologies and classify the existing approaches over different network domains, namely core, metro, and access networks. A section is also devoted to describe energy-efficient solutions for some of today's important applications using optical network technology, e.g., grid computing and data centers. We provide an overview of the ongoing standardization efforts in this area. This work presents a comprehensive and timely survey on a growing field of research, as it covers most aspects of energy consumption in optical telecom networks. We aim at providing a comprehensive reference for the growing base of researchers who will work on energy efficiency of telecom networks in the upcoming years."""	access network;data center;grid computing;metro (design language)	Yi Zhang;Pulak Chowdhury;Massimo Tornatore;Biswanath Mukherjee	2010	IEEE Communications Surveys & Tutorials	10.1109/SURV.2011.062410.00034	data center;information and communications technology;telecommunications;computer science;efficient energy use;information technology;computer security;computer network;access network	HPC	-12.941618592493214	86.9818160652325	66496
0bc9d401954ce8e0a68ee92c47154174e0d06802	throughput maximization in traffic grooming in wdm mesh networks	integer linear programming;traffic grooming;logical topology;wdm optical mesh networks;network cost;mesh network;throughput maximization;throughput	We consider the problem of efficient grooming of low-speed connections onto high-capacity lightpaths in WDM mesh networks. Maximizing the throughput and minimizing the network cost are the two most important objectives of the traffic grooming problem. It may not be possible to achieve both the goals simultaneously. We present an efficient heuristic algorithm to maximize throughput without compromising on the network cost. Our algorithm decides the placement of the transceivers at the nodes instead of operating on a fixed number of transceivers. Multihop routing and rerouting techniques have been used to achieve higher throughput. We use a two stage ILP approach to enable comparison of our algorithm with the optimum. We also present simulation results to contrast the performance of our approach with two recently proposed heuristic algorithms.#R##N##R##N#This work was supported by the Department of Science and Technology, New Delhi.		N. Srinivas;Chebiyyam Siva Ram Murthy	2004	J. High Speed Networks		wireless mesh network;throughput;integer programming;traffic grooming;telecommunications;computer science;mesh networking;distributed computing;computer network;logical topology	Metrics	-5.54148164384522	82.60527587942977	66527
87d430b14db2c3539a4c86d680c109db351045cc	an architecture of internetworking system for different management networks	simple network management protocol;internetworking;network management;internetworking protocols computer network management information management ip networks computer architecture computer science;movi internetworking system network management protocols simple network management protocol cmip common management information protocol management protocols	This paper presents a system for internetworking between different network management protocols. The internetworking system between SNMP (Simple Network Management Protocol) and CMIP (Common Management Information Protocol) has been designed. SNMP has been used as a standard protocol in Internet while CMIP has been selected as management protocol in OSI network. This approach is different from previous researches which convert protocols between management protocols. We have newly defined managed objects structure. Thus, even if a new management protocol would be introduced in addition, the new gateway system needs not be designed. We can achieve it through minimum modification in the interface of the managed objects. So, we can support managed objects defined previously using MOVI (Managed Object View Interface) concept presented in our previous research.		Tae-Soo Kim;Kwang-Hui Lee	1998		10.1109/NOMS.1998.654842	internet protocol;network management;out-of-band management;fcaps;general inter-orb protocol;element management system;network management station;internet layer;computer science;link control protocol;distributed computing;telecommunications management network;network management application;internet protocol suite;simple network management protocol;structure of management information;common management information protocol;computer security;computer network;internetwork protocol	Mobile	-23.04814704911763	87.91107877916828	66594
066e3e191663b21a5bfe111e507ad09576a0664c	sharing the dream	computers;protocols;disruption tolerant networking;delay tolerant networking;convergence;internet bundle protocol delay tolerant networking disruption tolerant networking;dtn;bundle protocol;probes;disruption tolerant network;internet;delay tolerant network;ad hoc networks;protocols internet;dtn bundle protocol delay tolerant networking;disruption tolerant networking protocols internet convergence ip networks propagation delay payloads australia intelligent networks timing	We reconsider desirability of the Bundle Protocol (BP) as a universal solution for Delay- and Disruption-Tolerant Networking (DTN). The BP is intended to provide a single solution that is applicable to a wide variety of differently-challenged DTN networks, even though those networks are unlikely to interact with one another. This paper asks whether such a single protocol can encompass all varied DTN networking needs. It asks whether attempting to repeat the previous success of the homogeneous Internet by layering over all networks is suitable for the heterogeneous DTN world, where diverse application needs and operational requirements lead to diverse, scenario-specific, applications. This position paper is intended to encourage discussion of the role, scope, and adoption of the BP.	delay-tolerant networking;requirement	Lloyd Wood;Peter Holliday;Daniel Floreani;Wesley M. Eddy	2009	2009 International Conference on Ultra Modern Telecommunications & Workshops	10.1109/ICUMT.2009.5345655	computer science;delay-tolerant networking;distributed computing;computer security;computer network	Robotics	-11.467266663074842	87.1027255307764	66671
3d5511d1335f9432d5219033e1cb4c9969704916	a solver for the network testbed mapping problem	technical history;time synchronization;simulated annealing;satisfiability;computer network;np hard problem;algorithmic memoirs;distributed simulation	Network experiments of many types, especially emulation, require the ability to map virtual resources requested by an experimenter onto available physical resources. These resources include hosts, routers, switches, and the links that connect them. Experimenter requests, such as nodes with special hardware or software, must be satisfied, and bottleneck links and other scarce resources in the physical topology should be conserved when physical resources are shared. In the face of these constraints, this mapping becomes an NP-hard problem. Yet, in order to prevent mapping time from becoming a serious hindrance to experimentation, this process cannot consume an excessive amount of time.In this paper, we explore this problem, which we call the network testbed mapping problem.We describe the interesting challenges that characterize it, and explore its applications to emulation and other spaces, such as distributed simulation. We present the design, implementation, and evaluation of a solver for this problem, which is in production use on the Netbed shared network testbed. Our solver builds on simulated annealing to find very good solutions in a few seconds for our historical workload, and scales gracefully on large well-connected synthetic topologies.	computer hardware;emulator;experiment;host (network);np-hardness;network switch;router (computing);simulated annealing;simulation;solver;synthetic data;synthetic intelligence;testbed	Robert Ricci;Chris Alfeld;Jay Lepreau	2003	Computer Communication Review	10.1145/956981.956988	simulation;simulated annealing;computer science;theoretical computer science;operating system;np-hard;distributed computing;computer security;computer network;satisfiability	Networks	-11.469377240982856	81.53732226035255	66682
9a250917762090b8fcb4d1a27ef872f32ee36f58	a hybrid open queuing network model approach for multi-threaded dataflow architecture	performance measure;tiempo respuesta;time average;file attente;modelizacion;multi programming;reponse temporelle;timed systems;longitud hilera;availability;disponibilidad;resource allocation;synchronization and execution processors;queue length;resource manager;modelo hibrido;resource management;queue;response time;promedio temporal;flux donnee;valor medio;flujo datos;value analysis;modele hybride;hybrid model;mean value analysis;paralelismo masivo;analyse valeur;temps reponse;synchronisation;modelisation;gestion recursos;single server queue;fila 1 servidor;time response;file 1 serveur;synchronization;retard;analisis valor;valeur moyenne;gestion ressources;multithread;mean value;longueur file;queuing networks;sincronizacion;multitâche;asignacion recurso;response times;allocation ressource;data flow;respuesta temporal;retraso;modeling;disponibilite;fila espera;parallelisme massif;massive parallelism;multitarea;queue lengths;dynamic scheduling;moyenne temporelle;throughput	Multi-threading has been proposed as an execution model for massively built parallel processors. Due to the large amount of potential parallelism, resource management is a critical issue in multi-threaded architecture. The challenge of multi-threading is to hide the latency by switching among a set of ready threads and thus to improve the processor utilization. Threads are dynamically scheduled to execute based on availability of data. In this paper, two hybrid open queuing network models are proposed. Two sets of processors: synchronization processors and execution processors exist. Each processor is modeled as a server serving a single-queue or multiple-servers serving a single-queue. Performance measures like response times, system throughput and average queue lengths are evaluated for both the hybrid models. The utilizations of the two models are derived and compared with each other. A mean value analysis is performed and different performance measures are plotted. Crown copyright 2008 Published by Elsevier B.V. All rights reserved.	central processing unit;crown group;dataflow architecture;multithreading (computer architecture);network model;parallel computing;server (computing);thread (computing);throughput;two-hybrid screening	Vidhyacharan Bhaskar;Kondo Hloindo Adjallah	2008	Computer Communications	10.1016/j.comcom.2008.08.017	synchronization;parallel computing;real-time computing;telecommunications;computer science;resource management;operating system;statistics	Arch	-12.372577000054648	64.65817577070791	66700
1ec361d4b56a665e4652b1d995dbc3e59214dcd3	pareto-based soft real-time task scheduling in multiprocessor systems	minimisation;optimal solution;pareto based genetic algorithm;multiprocessor systems;real time;performance;environmental conditions;deadline missing time;real time systems multiprocessing systems optimal scheduling processor scheduling minimization methods scheduling algorithm computer science application software genetic algorithms algorithm design and analysis;parallel programming;satisfiability;pareto optimal set;soft real time;scheduling algorithm;scheduling;pareto optimal set soft real time task scheduling multiprocessor systems processor minimization deadline missing time parallel program pareto based genetic algorithm experimental results performance;genetic algorithms real time systems scheduling multiprocessing systems minimisation parallel programming;genetic algorithm;genetic algorithms;multiprocessing systems;task scheduling;parallel programs;processor minimization;experimental results;real time application;soft real time task scheduling;parallel program;pareto optimality;real time systems	We develop a new method to map (i.e. allocate and schedule) real-time applications into certain multiprocessor systems. Its objectives are 1) the minimization of the number of processors used and 2) the minimization of the deadline missing time. Given a parallel program with real time constraints and a multiprocessor system, our method finds schedules of the program in the system which satisfy all the real time constraints with minimum number of processors. The minimization is carried out through a Pareto-based Genetic Algorithm which independently considers the both goals, because they are non-commensurable criteria. Experimental results show that our scheduling algorithm achieved better performance than previous ones. The advantage of our method is that the algorithm produces not a single solution but a family of solutions known as the Paretooptimal set, out of which designers can select optimal solutions appropriate for their environmental conditions.	central processing unit;definition;dominating set;fitness function;genetic algorithm;heuristic;multi-objective optimization;multiprocessing;parallel computing;pareto efficiency;real-time clock;real-time computing;scheduling (computing);software release life cycle	Jaewon Oh;Hyokyung Bahn;Chris Wu;Kern Koh	2000		10.1109/APSEC.2000.896679	parallel computing;real-time computing;genetic algorithm;computer science;operating system;distributed computing;scheduling;multiprocessor scheduling	Embedded	-13.290547475395314	61.67003796898918	66798
c17030cf1c124aa1f102a1480a0255707b2da8cc	an adaptive distributed wavelength routing algorithm in wdm networks	network topology wavelength division multiplexing optical fibre networks telecommunication network routing distributed algorithms adaptive systems transport protocols data communication telecommunication traffic computational complexity;distributed algorithms;wavelength routing;wdm network;data communication;computational complexity adaptive distributed wavelength routing algorithm wdm networks heuristic wavelength routing algorithm ip datagrams distributed networks loose virtual topology connectivity property dynamic traffic demands high speed routing algorithm internet protocol average wavelength utilization simulation distributed wdm networks blocking performance control traffic overhead;network topology;transport protocols;optical fibre networks;telecommunication traffic;telecommunication network routing;adaptive systems;computational complexity;wavelength routing wavelength division multiplexing traffic control heuristic algorithms wdm networks communication system traffic control network topology telecommunication traffic computational modeling computational complexity;high speed;generalization bounds;wavelength division multiplexing	AbstmctIn this paper, we propose a heuristic wave length routing algorithm for IP datagrams in WDM networks which operates in a distributed manner. We first present an efflcient construction method for a loose virtual topology with a required connectivity property, which reserves a few wavelengths to cope with dynamic trafflc d e mands properly. We then develop a high-speed distributed wavelength routing algorithm adaptive to dynamic traffic demands and derive the general bounds on average wave length utilization in distributed wavelength routing algorithms. Finally, through simulation, i t is shown that our algorithm is efflcient enough to be used in distributed WDM networks in terms of blocking performance, control traffic overhead, and computational complexity.	algorithm;blocking (computing);computational complexity theory;datagram;heuristic;overhead (computing);routing;simulation;wavelength-division multiplexing	Han-You Jeong;Ssang-Soo Lee;Seung-Woo Seo;Byoung-Seok Park	2000		10.1109/GLOCOM.2000.891338	distributed algorithm;routing;static routing;telecommunications;computer science;dynamic source routing;adaptive system;destination-sequenced distance vector routing;distributed computing;computational complexity theory;transport layer;network topology;wavelength-division multiplexing;computer network	Networks	-6.332039576247824	81.4087388842516	66829
8468738b3d92ec5a1128d81c5cae79e80885d898	an object oriented architectural library for the design and implementation of network protocols	protocols;network protocol;computer networks;computer network;load and stress testing devices;operating system;design and implementation;object oriented;c;library;stress testing;telecommunications;open source software	The society of telecommunication and computer networks encompasses a wide variety of organizations, forums and industry companies that specify, standardize, evaluate, implement and deploy network infrastructures. These infrastructures are well defined and deployed in order to offer high quality end-user services and meet the need for interconnectivity, expandability and upgradeability. What users see and experience is the tip of the iceberg. Great amount of time and money is spent in specification, standardization, design, debugging, testing (both conformance and stress) and finally evaluating network components or subsystems before the deployment takes place. The framework, proposed in the current paper and implemented in open source software library, provides an object oriented methodology for the implementation of network protocols and the software realization of network components. The method is formed in respect to: (a) operating system architecture (b) network architecture and (c) Object Oriented (OO) methodology.		Nikolas Stylianides;Elias Koukoutsis	2007	Wireless Personal Communications	10.1007/s11277-006-9206-7	communications protocol;intelligent computer network;network architecture;open network architecture;computer science;operating system;network simulation;distributed computing;computer network	Mobile	-21.118871562409176	85.86983495899759	66848
a38c87a7e87531669f2e137023f716121bbb558f	an energy perspective of multimedia streaming systems	energy efficiency;protocols;streaming media multimedia communication protocols servers power demand peer to peer computing;data centre;multimedia streaming;p2p;multimedia systems;computer centres;power aware computing;telecommunication traffic;servers;p2p infrastructure data centre empowered streaming services computing power components networking components data transmissions multimedia streaming system streaming protocols underlay physical network structure peer to peer network infrastructure power savings router connectivity end user devices peer to peer infrastructure;telecommunication network routing;streaming media;multimedia communication;media streaming;telecommunication traffic computer centres green computing media streaming multimedia systems peer to peer computing power aware computing protocols telecommunication network routing;data centre energy efficiency multimedia streaming p2p;peer to peer computing;power demand;green computing	The demand for multimedia streaming is growing at a phenomenal rate, and data-centre-empowered streaming services are becoming more common nowadays. To better accommodate the demand, the computing power and networking components in data centres are being upgraded regularly, leading to higher energy bills. Many studies have been conducted around reducing the power consumed by data centres, but very little attention has been paid to the data transmissions and the power consumed by the entire system, from the streaming source to the end-user devices. In this paper, we are interested in the power efficiency of multimedia streaming system as a whole. We take on the analysis in three directions: traffic imposed by different streaming protocols, underlay physical network structure, and the network infrastructure (data centre vs. Peer-to-Peer). Three main conclusions drawn from the study are: (1) very insignificant power savings can be achieved by tuning the streaming protocol, router connectivity, or the network infrastructure, (2) significant power savings can be achieved through reducing the idle power of routers and end-user devices, and (3) the energy efficiency of the end-user devices determines whether the Peer-to-Peer (P2P) infrastructure can be a green alternative for data-centre-empowered streaming.	data center;performance per watt;router (computing);social peer-to-peer processes;streaming media	Yongxin Liu;Mea Wang	2013	2013 International Conference on Cloud and Green Computing	10.1109/CGC.2013.23	real-time computing;computer science;distributed computing;computer network	HPC	-18.087376959266482	78.05388429814182	66884
edff7d4fba4685a7ff4cb7397bcd895bf6d7c44d	data scheduling for multi-item and transactional requests in on-demand broadcast	mobile;efficient algorithm;mobile computer;transaction;wireless communication;scheduling algorithm;wireless internet;waiting time;scheduling problem;information system;on demand	Recent advances in mobile computing and wireless communication have enabled the deployment of broadcast based information systems such as, wireless internet, traffic information, etc. The users and research community have recognized its potential for meeting the growing information demands of the future. At present existing systems are mainly pull-based (on-demand) and their performance highly depends on the broadcast schedule they use. Previous studies in on-demand scheduling have focused mainly on single item requests to keep the investigation simple. However, scheduling algorithms for single item request are unable to manage efficiently multi-item requests which are becoming more common. In addition to this these more and more requests are becoming transactional in nature. In this paper we take into consideration these requirements and study scheduling problems arising in on-demand broadcast environment and propose an efficient algorithm. We report its performance and demonstrate that our algorithm successfully manage multi-item simple and transactional requests and significantly reduces the wait time, tuning time and avoids transaction aborts.	algorithm;information system;mathematical optimization;mobile computing;optimization problem;requirement;schedule (computer science);scheduling (computing);simulation;software deployment;transaction processing	Nishanth Prabhu;Vijay Kumar	2005		10.1145/1071246.1071254	fair-share scheduling;job shop scheduling;real-time computing;dynamic priority scheduling;computer science;rate-monotonic scheduling;operating system;mobile technology;two-level scheduling;distributed computing;mobile computing;scheduling;information system;wireless;computer network	DB	-15.129697102036289	69.08858999060482	66913
b36a88afb84fee8e85d223a4a9d1a18b6d557ad9	enabling autonomicity in wireless mesh networks with the etsi afi gana reference model		SummaryrnThe distributed nature of wireless mesh networks (WMNs) allows them to benefit from multiple autonomic functionalities. However, the existing landscape of self-x solutions (eg, self-configuration) is fragmented and the lack of a standardized framework through which interoperable autonomics can be developed has been hampering adoption and deployment of autonomics in real-world service networks. There is a need for a standardized architectural framework that enables to comprehensively support and integrate interoperable components for autonomicity in WMNs. Such an architecture (autonomicity-enabled wireless mesh architecture) is currently being standardized by the working group called Evolution of Management towards Autonomic Future Internet (AFI) in the European Telecommunications Standards Institute within the Network Technologies Technical Committee. The proposed autonomic wireless mesh architecture is an instantiation of the AFI GANA (Generic Autonomic Network Architecture) reference model, a standards-based approach to autonomics. This paper complements and extends the early version of the architecture by further detailing the architectural principles and providing experimental and validation results. First, we provide a brief overview of the AFI GANA reference model and then show how each of its building blocks can be instantiated for WMNs. We evaluate the proposed architecture by implementing and testing the 4 basic self-x functionalities defined by the GANA model. The provided guidelines can now help researchers and engineers build autonomicity-enabled WMNs using a standardized framework that enables adoption and deployment of autonomics by industry, thereby enabling researchers and engineers to contribute to the further evolution of the standard in the European Telecommunications Standards Institute.	mesh networking;reference model;wireless mesh network	Szymon Szott;Janusz Gozdecki;Katarzyna Kosek-Szott;Krzysztof Loziak;Marek Natkaniec;Michal Wagrowski;Ranganai Chaparadza	2017	Int. Journal of Network Management	10.1002/nem.1993	computer network;network architecture;architecture;software deployment;the internet;computer science;reference model;interoperability;wireless mesh network;architecture framework	Networks	-17.628683777825398	85.99799948480629	66938
ebbb9054b8a9c08fa97ac332508129dc43719ea5	neural network based feedback scheduler for networked control system with flexible workload	workload;algorithme rapide;control application;no determinismo;time varying;teleenseignement;elman neural network;availability;disponibilidad;actionneur;probabilistic approach;online learning;systeme non deterministe;time varying system;actuator;non deterministic system;network control;non determinism;non determinisme;scheduling;enfoque probabilista;approche probabiliste;systeme parametre variable;fast algorithm;integrated control;charge travail;arquitectura modular;accionador;teleensenanza;sistema no determinista;sistema parametro variable;reseau neuronal;networked control system;remote teaching;carga trabajo;disponibilite;modular architecture;algoritmo rapido;red neuronal;ordonnancement;architecture modulaire;reglamento;neural network	Most control applications closed over a shared network are suffering from the time-varying characteristics of flexible network workload. This gives rise to non-deterministic availability of communication resources and may significantly impact the control performance. In the context of integrating control and scheduling, a novel feedback scheduler based on neural networks is suggested. With a modular architecture, the proposed feedback scheduler mainly consists of a monitor, a predictor, a regulator and an actuator. An online learning Elman neural network is employed to predict the network conditions, and then the control period is dynamically adjusted in response to estimated available network utilization. A fast algorithm for period regulation is employed. Preliminary simulation results show that the proposed feedback scheduler is effective in managing workload variations and can provide runtime flexibility to networked control applications.	algorithm;artificial neural network;computer monitor;control system;feedback;kerrison predictor;requirement;sampling (signal processing);scheduling (computing);simulation	Feng Xia;Shanbin Li;Youxian Sun	2005		10.1007/11539117_36	availability;network traffic control;real-time computing;simulation;computer science;networked control system;operating system;network scheduler;rate limiting;distributed computing;scheduling;artificial neural network;actuator	Embedded	-11.713546690489105	65.09240301502525	66953
2be1aea85758648544b9afebd4529bbef12c5bf6	exploring practical limitations of tcp over transatlantic networks	tcp response behavior;grid networking;tcp;hstcp;long distance;near real time;high speed;large data	Tomorrow’s large physics and astronomy projects will require to transport tremendous amounts of data over long distances in near real time. Traditional TCP implementations have severe problems in reaching the necessary performance. In the recent past, researchers have shown that TCP implementations can be scaled to achieve multi-gigabit per second speeds over high-bandwidth high-delay networks. The ability of TCP to scale to high speeds opens possibilities for very large data transfers over vast distances. We analyze here whether TCP can fulfill this task and what problems we are faced with. We also examine TCP in the context of dedicated links (Lambdas).	data rate units;gigabit;real-time computing	Antony Antony;Johan Blom;Cees T. A. M. de Laat;Jason Lee	2005	Future Generation Comp. Syst.	10.1016/j.future.2004.10.004	simulation;telecommunications;computer science;transmission control protocol;zeta-tcp;hstcp;tcp tuning;tcp acceleration;tcp friendly rate control;slow-start;computer network	HPC	-7.19690088303712	88.42646534980456	66988
19ab0229869c75652aeb7ae106bf158dc1d40353	robust provisioning of multicast sessions in cognitive radio networks	cognitive radio robustness approximation algorithms interrupters complexity theory multicast communication;spurg cognitive radio networks robust provisioning multicast service mode robust multicasting multicast sessions protection link sharing trees shared primary user risk group;protection;protection multicast cognitive radio resilience;multicast;trees mathematics cognitive radio multicast communication;cognitive radio networks	Today's wireless networks use fixed spectrum over long term and fixed geographical regions. However, spectrum utilization varies by time and location, which leads to temporal and special spectrum underutilization. Cognitive radio is an emerging technology that enables dynamic sharing of the spectrum in order to overcome the spectrum underutilization problem. In this paper, we consider the problem of supporting the multicast service mode in cognitive radio networks. Moreover, we are concerned with supporting this mode of service such that it is robust in the face of failures. We develop two algorithms which provide robust multicasting in such networks. Our proposed algorithms are: 1) multicast sessions protection with link-sharing trees and 2) multicast sessions protection using rings. These algorithms provision multiple multicast sessions, and protect them against a single primary user interruption at a time. They also take into account that the activities of a primary user may disrupt communication in several groups, of secondary users, which are referred to as Shared Primary User Risk Group (SPURG). The objective of the proposed algorithms is to increase the number of sessions that can be accommodated in the network and minimize the cost of provisioning the sessions while protecting them against failures.	algorithm;cognitive radio;ibm systems network architecture;interrupt;multicast;provisioning	Abdullah M. Almasoud;Ahmed E. Kamal	2014	2014 International Wireless Communications and Mobile Computing Conference (IWCMC)	10.1109/IWCMC.2014.6906393	cognitive radio;multicast;ip multicast;inter-domain;reliable multicast;telecommunications;protocol independent multicast;computer science;pragmatic general multicast;distributed computing;distance vector multicast routing protocol;source-specific multicast;multimedia broadcast multicast service;xcast;computer network;multicast address	Mobile	-7.611562153215067	82.94270608492127	67046
01c5a2ede66212db1ad703c9cf46bd04e1d05d46	cloud application predictability through integrated load-balancing and service time control		Cloud computing provides the illusion of infinite capacity to application developers. However, data center provisioning is complex and it is still necessary to handle the risk of capacity shortages. To handle capacity shortages, graceful degradation techniques sacrifice user experience for predictability. In all these cases, the decision making policy that determines the degradation interferes with other decisions happening at the infrastructure level, like load-balancing choices. Here, we reconcile the two approaches, developing a load-balancing strategy that also handles capacity shortages and graceful degradation when necessary. The proposal is based on a sound control-theoretical approach. The design of the approach avoids the pitfalls of interfering control decisions. We describe the technique and provide evidence that it allows us to achieve higher performance in terms of emergency management and user experience.	autoscaling;cloud computing;countermeasure (computer);data center;elegant degradation;fault detection and isolation;fault tolerance;image scaling;load balancing (computing);provisioning;setpoint (control system);software as a service;user experience	Tommi Nylander;Marcus Thelander Andren;Karl-Erik Årzén;Martina Maggio	2018	2018 IEEE International Conference on Autonomic Computing (ICAC)	10.1109/ICAC.2018.00015	real-time computing;fault tolerance;economic shortage;predictability;provisioning;user experience design;cloud computing;data center;load balancing (computing);computer science	Visualization	-26.103869116210312	61.239473125997094	67049
07b7bafc3a9674a03cfd2e1b87ea8cdbb1f8e70e	model-driven network emulation with virtual time machine	virtual-machine-based emulation;futuristic network system;commodity computing infrastructure;time advancement;network virtualization technique;large-scale network model;holistic machine;communication requirement;novel model-driven network emulation;virtual time machine;model-driven network emulation;real time systems;virtual machines;virtual machine;emulation;bandwidth;distributed application;computational modeling;network model;innovation management;resource management	We present VENICE, a project that aims at developing a high-fidelity, high-performance, and highly-controllable experimental platform on commodity computing infrastructure to facilitate innovation in existing and futuristic network systems. VENICE employs a novel model-driven network emulation approach that combines simulation of large-scale network models and virtual-machine-based emulation of real distributed applications. To accurately emulate the target system and meet the computation and communication requirements of its individual elements, VENICE adopts a holistic machine and network virtualization technique, called virtual time machine, in which the time advancement of simulated and emulated components are regulated in complete transparency to the test applications. In this paper, we outline the challenges and solutions to realizing the vision of VENICE.	commodity computing;computation;distributed computing;emulator;holism;model-driven architecture;model-driven integration;network emulation;requirement;simulation;virtual machine	Jason Liu;Raju Rangaswami;Ming Zhao	2010	Proceedings of the 2010 Winter Simulation Conference		real-time computing;simulation;innovation management;computer science;engineering;virtual machine;resource management;distributed computing	HPC	-29.505005736644645	60.554385312956626	67050
5daed44444b7da01965864c364caffb1f91dc58c	joint anycast and unicast routing and spectrum allocation with dedicated path protection in elastic optical networks	servers unicast optical fiber networks heuristic algorithms routing resource management optimization;telecommunication network routing bandwidth allocation computer network reliability integer programming internet linear programming;routing;resource management;optical fiber networks;servers;heuristic algorithms;optimization;anycast traffic elastic optical networks routing and spectrum allocation network survivability network optimization;unicast;afa jau dpp joint anycast routing unicast routing dedicated path protection elastic optical network bandwidth allocation contemporary internet content delivery network video streaming grid computing communication network network failure joint optimization eon survivability routing and spectrum allocation rsa jau dpp integer linear programming ilp problem heuristic algorithm	Elastic Optical Networks (EONs) are considered as a very promising approach for effective bandwidth allocation in optical networks. Concurrently, anycast (one-to-one-of-many transmission technique) is gaining more and more interest in contemporary Internet due to its connection with as popular services as Content Delivery Networks, video streaming, computing grids. Moreover, the Internet and other communication networks are an indispensable part of the present and future world, and the consequences of network failures can become critical, especially when related to backbone networks. Therefore, the survivability aspects are increasingly important when analyzing existing and designing new networks. In this paper, we focus on joint optimization of anycast and unicast flows in EONs with survivability consideration. In particular, we formulate Routing and Spectrum Allocation problem with Dedicated Path Protection consideration (RSA-JAU-DPP) as an Integer Linear Programming (ILP) problem and propose a heuristic algorithm AFA-JAU-DPP to solve it. We evaluate the performance of our algorithm and compare it with both optimal results obtained by CPLEX and results obtained with heuristic methods proposed in the literature. Numerical results show that proposed heuristic algorithm outperforms other reference methods.	algorithm;alternating finite automaton;anycast;backup;cplex;digital photo professional (dpp);experiment;frequency allocation;grid computing;heuristic (computer science);integer programming;internet backbone;iterative method;linear programming;mathematical optimization;metaheuristic;numerical analysis;numerical method;one-to-one (data model);optimization problem;path protection;routing;server (computing);simulated annealing;solver;streaming media;tabu search;telecommunications network;unicast	Róza Goscien;Krzysztof Walkowiak;Miroslaw Klinkowski	2014	2014 10th International Conference on the Design of Reliable Communication Networks (DRCN)	10.1109/DRCN.2014.6816137	wireless routing protocol;routing;static routing;real-time computing;computer science;resource management;distributed computing;server;computer network;unicast	Metrics	-5.6362794519040005	82.56069475177155	67064
a739f4947ec529672e4b00b1a3fb1fb2bf96db78	sla-based operation of massively multiplayer online games in competition-based environments	qos;sla;business services;mmog;cloud computing	To sustain the variable load of Massively Multiplayer Online Games (MMOGs) with guaranteed Quality of Service (QoS), game operators over-provision a static infrastructure capable of sustaining the peak load, even though a large portion of the resources is unused most of the time. This inefficient way of provisioning resources has negative impacts, leading to inefficient resource utilisation, high service prices, and limited market participation accessible only to the large companies. We propose a new ecosystem and model for hosting and operating MMOGs based on cloud computing principles involving four smaller and better focused business actors whose interaction is regulated through Service Level Agreements (SLAs): resource provider, game operator, game provider, and client. In our model, game providers lease operation SLAs from the game operators to satisfy all client requests and manage multiple distributed MMOG sessions. In turn, game operators efficiently lease on-demand cloud resources based on the dynamic MMOG load and ensure proper game operation that maintains QoS to all clients. In this paper, we focus on the business interaction between the game provider and the game operator by defining the SLA terms and the underlying negotiation protocol, including a model for compensations for QoS violations. We propose a method for ranking operational offers based on price, compensation and resource fitness, and study its impact on game provider's profit in an environment with several providers competing for SLAs from multiple game operators.	cloud computing;ecosystem;load profile;massively multiplayer online role-playing game;provisioning;quality of service;service-level agreement	Vlad Nae;Radu Prodan;Alexandru Iosup	2013		10.1145/2494444.2494468	simulation;quality of service;cloud computing;computer science;operating system;database;distributed computing;world wide web	Metrics	-23.655420720315636	64.66001752202453	67229
f82206e838bdccee7d74e35ab8f9a6a34b3c8405	load balancing placement of gateways in wireless mesh networks with qos constraints	radio networks;optimal solution;resource allocation;network performance;qos constraints;greedy algorithms;satisfiability;resource allocation genetic algorithms greedy algorithms internetworking radio networks;wireless mesh network;load management wireless mesh networks clustering algorithms telecommunication traffic partitioning algorithms internet spine costs greedy algorithms genetic algorithms;genetic algorithm load balancing gateway placement wireless mesh networks qos constraints network performance greedy algorithm ga lbc algorithm;internet;logic gates;load balancing gateway placement;load management;greedy algorithm wireless mesh network gateway placement load balance genetic algorithm;internetworking;wireless mesh networks;clustering algorithms;greedy algorithm;genetic algorithm;genetic algorithms;load balance;gateway placement;quality of service;algorithm design and analysis;ga lbc algorithm;hybrid algorithm	In wireless mesh networks (WMNs), load balancing placement of gateways is important to the network performance. In this paper, we address the problem of load balancing gateway placement, and propose a greedy algorithm GA-LBC to partition a WMN into load-balance and disjointed clusters, each cluster satisfies QoS requirements. Based on GA-LBC algorithm and the principles of genetic algorithm, we propose a hybrid algorithm HA-LBPG to get the near-optimal solution. Simulation results show that the number of gateways generated by HA-LBPG is nearly equal to the result from other gateway placement algorithms, and as far as the load balancing on the gateways is concerned, HA-LBPG performs much better than the others.	balancing network;cluster analysis;genetic algorithm;genetic operator;greedy algorithm;hybrid algorithm;load balancing (computing);mesh networking;network performance;quality of service;requirement;simulation;software release life cycle;wireless mesh network	Feng Zeng;Zhigang Chen	2008	2008 The 9th International Conference for Young Computer Scientists	10.1109/ICYCS.2008.15	greedy algorithm;real-time computing;genetic algorithm;computer science;distributed computing;algorithm;computer network	HPC	-4.616163222550501	82.49688314363557	67293
243370ceb7af70f07cacc42648230212ceef78d4	cutting throughput on the edge: app-aware placement in fog computing.		Fog computing extends cloud computing technology to the edge of the infrastructure to let IoT applications access objects’ data with reduced latency, location awareness and dynamic computation. By displacing workloads from the central cloud to the edge devices, fog computing overcomes communication bottlenecks avoiding raw data transfer to the central cloud, thus paving the way for the next generation IoT-based applications. In this paper we study scheduling and placement of applications in fog computing, which is key to ensure profitability for the involved stakeholders. We consider a scenario where the emerging microservice architecture allows for the design of applications as cascades of coupled microservice modules. It results into a mixed integer non linear problem involving constraints on both application data flows and computation placement. Due to the complexity of the original problem, we resort to a simplified version, which is further solved using a greedy algorithm. This algorithm is the core placement logic of the FogAtlas platform, a fog computing platform based on existing virtualization technologies. Extensive numerical results validate the model and the scalability of the proposed solution, showing it attains performance close to the optimal solution and, in our real implementation, it scales well with respect to the number of served applications.	cloud computing;computation;experiment;fog computing;gradient;greedy algorithm;knapsack problem;linear programming;location awareness;mathematical optimization;microservices;numerical analysis;orchestration (computing);scalability;scheduling (computing);throughput	Gonzalo Himiob;Francesco De Pellegrini;Domenico Siracusa;Daniele Santoro;Silvio Cretti	2018	CoRR		edge device;raw data;virtualization;distributed computing;architecture;scalability;scheduling (computing);greedy algorithm;cloud computing;computer science	HPC	-21.899273264011487	65.95930984972111	67318
ea5aec743a80be3b4af0cae5a1a62de9f47db0b0	mqual: a mobile peer-to-peer network framework supporting quality of service	mobile communication mobile computing ieee 802 11 standard servers peer to peer computing smart phones;d2d mobile peer to peer mobile p2p wifi direct;quality of service mobile computing peer to peer computing;d2d;mobile peer to peer;mobile p2p;mobile apps mqual mobile peer to peer network quality of service wifi direct android;wifi direct	Mobile peer-to-peer applications require devices to network themselves on-the-fly to communicate directly with each another. This paper presents mQual, a framework to help create such networks that meet different application requirements, and is able to adjust the network to ensure that these requirements are met in dynamic environments. Our prototype mQual extends the current WiFi-Direct in Android, and the experimental results suggests that mobile apps built using mQual outperform those built using WiFi-Direct.	android;mobile app;peer-to-peer;prototype;quality of service;requirement	Hongxu Zhang;Yufeng Wang;Chiu Chiang Tan;Yifan Zhang	2015	2015 IEEE 35th International Conference on Distributed Computing Systems	10.1109/ICDCS.2015.93	embedded system;mobile search;mobile web;imt advanced;public land mobile network;mobile database;computer science;mobile technology;mobile deep linking;internet privacy;mobile station;mobile computing;mobile communications over ip;computer network;mobile payment	Mobile	-19.96726967920075	75.72448587165134	67357
6478334db0f4adc02a5b5dbdb34dde42081e0ccf	investigation of energy efficiency on cloud computing	energy efficiency;resource management;servers cloud computing resource management energy efficiency energy consumption cooling dispersion;invistigation energy cloud computing;servers;energy consumption;allocation policy cloud computing energy consumption resource management cloudsim environment energy reduction service level agreement sla energy efficiency control;power aware computing cloud computing contracts energy conservation;dispersion;cooling;cloud computing	Energy consumption is one of the key challenges faced by cloud computing. In this paper, we investigate ways of improving the energy usage of cloud computing environments by better resource management and consolidation. Our methodology focuses on critically reviewing and comparing the existing methods that are available in relation to schedulers and allocation policies through a simulated environment and experimentation. The experiments evaluate the energy efficiency of the identified schedulers and allocation policies in the CloudSim environment. The results highlight which policy performs the best at energy reduction whilst maintaining the service level agreement (SLA). This is potentially a valuable source of information for future energy efficiency control in real-world cloud computing environments.	cloud computing;cloudsim;experiment;information source;semiconductor consolidation;service-level agreement;virtual reality;while	Nathan Whittington;Lu Liu;Bo Yuan;Marcello Trovati	2015	2015 IEEE International Conference on Computer and Information Technology; Ubiquitous Computing and Communications; Dependable, Autonomic and Secure Computing; Pervasive Intelligence and Computing	10.1109/CIT/IUCC/DASC/PICOM.2015.309	dispersion;real-time computing;simulation;cloud computing;computer science;resource management;operating system;distributed computing;utility computing;efficient energy use;server	HPC	-21.442747214286275	61.89904573461182	67586
9321a62f426b1d99f63fb083d31bec937cc10e23	"""an analysis of """"hot-potato"""" routing in a fiber optic packet switched hypercube"""	routing optical fibers hypercubes fiber lasers photodetectors optical buffering optical packet switching tunable circuits and devices performance analysis optimal control;deflection routing;packet switched;packet switching;packet switching computer networks hypercube networks optical links;computer networks;fiber optic;shortest path routing;potato;random traffic localised multiprocessor interconnection network distributed computer network fiber optic packet switched hypercube hot potato routing optimal performance;optical links;flow control;hypercube networks	Two implementations of a fiber-optic packet-switched hypercube are proposed. In the first, each directed link is implemented with a fixed wavelength laser and photodetector, and all optical transmissions are wavelength multiplexed onto one or more fibers. In the second, the electronic crosspoint matrices within the nodes are eliminated by allowing each laser to be tunable over a range of log N wavelengths. Assume that a hot potato, or deflection, routing algorithm is used; as soon as a packet is received at a node, a routing decision is made and the packet is sent out. The node attempts to send the packet towards its destination. The analysis indicates that a hypercube, hot-potato routing offers essentially optimal performance for random traffic, regardless of how large the hypercube grows, and it significantly outperforms traditional shortest-path routing with buffering and flow control. A few variations, including an algorithm which gives priority to packets closer to their destinations and one which gives priority to various classes of traffic, are also proposed and analyzed. >	hot spare;hot-potato and cold-potato routing;optical fiber;packet switching;passive optical network	Ted H. Szymanski	1990		10.1109/INFCOM.1990.91340	routing table;link state packet;routing;static routing;source routing;fast packet switching;dsrflow;telecommunications;equal-cost multi-path routing;computer science;dynamic source routing;flooding;optical fiber;destination-sequenced distance vector routing;flow control;distributed computing;routing protocol;transmission delay;link-state routing protocol;triangular routing;packet switch;burst switching;geographic routing;packet switching;computer network	Networks	-5.698368747766907	86.64208339847285	67598
19d4b4680d034e6d0c53b86b8af3907a80e2e304	scheduling of tasks with precedence delays and relative deadlines framework for time-optimal dynamic reconfiguration of fpgas	branch and bound algorithm optimal task scheduling relative deadline framework time optimal dynamic reconfiguration field programmable gate array universal framework oriented graph edge runtime dynamic reconfiguration on chip processor synchronization arithmetic unit sram memory np hard problem optimal schedule integer linear programming;fpga off line scheduling high 8211;high 8211;field programmable gate array;integer linear programming;resource constraint;design process;complexity theory;on chip processor synchronization;dynamic reconfiguration;availability;branch and bound algorithm;relative deadline framework;fpga;satisfiability;runtime;dynamic scheduling delay field programmable gate arrays optimal scheduling process design algorithm design and analysis scheduling algorithm runtime availability arithmetic;level synthesis;process design;optimal task scheduling;chip;ilp;high level synthesis;np hard problem;scheduling algorithm;tree searching computational complexity field programmable gate arrays integer programming linear programming scheduling;integer programming;computational complexity;oriented graph edge;optimal scheduling;scheduling;runtime dynamic reconfiguration;timing optimization;fpga off line scheduling high level synthesis branch and bound ilp;sram memory;linear programming;arithmetic;optimal schedule;field programmable gate arrays;tree searching;level synthesis branch and bound ilp;branch and bound;algorithm design and analysis;off line scheduling;integer linear program;arithmetic unit;dynamic scheduling;time optimal dynamic reconfiguration;universal framework	This paper is motivated by existing architectures of field programmable gate arrays (FPGAs). To facilitate the design process we present an optimal scheduling algorithm using a very universal framework, where tasks are constrained by precedence delays and relative deadlines. The precedence relations are given by an oriented graph, where tasks are represented by nodes. Edges in the graph are related either to the minimum time or to the maximum time elapsed between the start times of the tasks. This framework is used to model the runtime dynamic reconfiguration, synchronization with an on-chip processor and simultaneous availability of arithmetic units and SRAM memory. The NP-hard problem of finding an optimal schedule satisfying the timing and resource constraints while minimizing the makespan Cmax, is solved using two approaches. The first one is based on integer linear programming and the second one is implemented as a branch and bound algorithm. Experimental results show the efficiency comparison of the ILP and branch and bound solutions	algorithm;branch and bound;central processing unit;data-intensive computing;field-programmable gate array;file sharing;hall-effect thruster;input/output;integer programming;linear programming;makespan;map;optimal design;orientation (graph theory);schedule (project management);scheduling (computing);simulation;static random-access memory	Premysl Sucha;Zdenek Hanzálek	2006	Proceedings 20th IEEE International Parallel & Distributed Processing Symposium	10.1109/IPDPS.2006.1639404	parallel computing;real-time computing;integer programming;computer science;distributed computing;scheduling;branch and bound;field-programmable gate array	Embedded	-6.594637344186686	60.47756255402988	67659
b90b62ee735922edd08207d38036aedcda956e08	simulation in quasi-polynomial time, and its application to protocol composition	one way function;protocole transmission;temps polynomial;simulator;protocolo transmision;simulador;polynomial time;simulateur;zero knowledge protocol;protocol composition;zero knowledge;temps quasi polynomial;composition operator;tiempo polinomial;transmission protocol	We propose a relaxation of zero-knowledge, by allowing the simulator to run in quasi-polynomial time. We show that protocols satisfying this notion can be constructed in settings where the standard definition is too restrictive. Specifically, we construct constant-round straightline concurrent quasi-polynomial time simulatable arguments and show that such arguments can be used in advanced composition operations without any set-up assumptions. Our protocols rely on slightly strong, but standard type assumptions (namely the existence of one-to-one oneway functions secure against subexponential circuits).	linear programming relaxation;one-to-one (data model);p (complexity);protocol stack;quasi-polynomial;simulation;standard-definition television;time complexity;zero-knowledge proof	Rafael Pass	2003		10.1007/3-540-39200-9_10	time complexity;discrete mathematics;computer science;composition operator;mathematics;one-way function;algorithm;zero-knowledge proof	Crypto	-33.01891461387087	74.0791944377473	67662
2d68dcca5e99e32f049969d4aeb85bf97afd3115	addressing tcam limitations of software-defined networks for content-based routing		In recent years, content-based publish/subscribe middleware has harnessed the power of Software-Defined Networking (SDN) to leverage performance gains in terms of throughput rates, end-to-end latency, etc. To this end, content filters are directly installed on the Ternary Content Addressable Memory (TCAM) of switches. Such a middleware assumes unlimited TCAM space to deploy content filters. However, in reality, TCAM is a scarce resource and the number of flow table entries available for publish/subscribe traffic is severely limited. While such a limitation poses severe problems for the deployment of publish/subscribe middleware in practice, it is yet to be addressed in literature.  So, in this paper, we design a filter aggregation algorithm that merges content filters on individual switches to respect TCAM constraints while ensuring minimal increase in unnecessary network traffic. Our algorithm uses the knowledge of advertisements, subscriptions, and a global view of the network state to perform bandwidth-efficient aggregation decisions on necessary switches. We provide different flavors of this algorithm with varying degrees of accuracy and complexity and thoroughly evaluate their performances under realistic workload. Our evaluation results show that our designed aggregation algorithm successfully meets TCAM constraints on switches while also reducing unnecessary traffic introduced in the network due to aggregation as compared to a baseline approach by up to 99.9%.	algorithm;baseline (configuration management);content-addressable memory;end-to-end principle;experiment;kalman filter;middleware;network packet;network switch;online advertising;performance;publish–subscribe pattern;routing;software deployment;software-defined networking;telecommunications access method;testbed;throughput	Sukanya Bhowmik;Muhammad Adnan Tariq;Alexander Balogh;Kurt Rothermel	2017		10.1145/3093742.3093924	latency (engineering);content-addressable memory;software deployment;real-time computing;throughput;computer science;workload;software-defined networking;distributed computing;middleware;ternary operation	Networks	-13.541955637221951	81.57235976338006	67683
6ba03fd9e8816ee1d6b8677a27b50ae7a4f8f7b8	keep your nice friends close, but your rich friends closer — computation offloading using nfc		The increasing complexity of smartphone applications and services necessitate high battery consumption but the growth of smartphones' battery capacity is not keeping pace with these increasing power demands. To overcome this problem, researchers gave birth to the Mobile Cloud Computing (MCC) research area. In this paper we advance on previous ideas, by proposing and implementing the first known Near Field Communication (NFC)-based computation offloading framework. This research is motivated by the advantages of NFC's short distance communication, with its better security, and its low battery consumption. We design a new NFC communication protocol that overcomes the limitations of the default protocol; removing the need for constant user interaction, the one-way communication restraint, and the limit on low data size transfer. We present experimental results of the energy consumption and the time duration of two computationally intensive representative applications: (i) RSA key generation and encryption, and (ii) gaming/puzzles. We show that when the helper device is more powerful than the device offloading the computations, the execution time of the tasks is reduced. Finally, we show that devices that offload application parts considerably reduce their energy consumption due to the low-power NFC interface and the benefits of offloading.	android;application programming interface;bluetooth;communications protocol;computation offloading;data rate units;duplex (telecommunications);encryption;key generation;laptop;low-power broadcasting;mobile app;mobile cloud computing;near field communication;one-way function;operating system;rapid;run time (program lifecycle phase);smart device;smartphone;tablet computer	Kathleen Sucipto;Dimitris Chatzopoulos;Sokol Kosta;Pan Hui	2017	IEEE INFOCOM 2017 - IEEE Conference on Computer Communications	10.1109/INFOCOM.2017.8057147	distributed computing;computer network;computation;mobile cloud computing;encryption;energy consumption;communications protocol;computer science;computation offloading;near field communication;bluetooth	Mobile	-21.347757256445703	76.58187144169035	67686
2c56e5a5768f684f8378753ab0e426071ab893a5	a comparative performance evaluation of dns tunneling tools	different network configurationswith;different performance metrics;dns query;dns tunneling tool;comparative performance evaluation;brief architectural analysis;proper tool;dns traffic;network performance;comparative analysis;dns tunnels	DNS Tunnels are built through proper tools that allow embedding data on DNS queries and response. Each tool has its own approach to the building tunnels in DNS that differently affects the network performance. In this paper, we propose a brief architectural analysis of the current state-of-the-art of DNS Tunneling tools. Then, wepropose the first comparative analysis of such tools in term of performance, as a first step towardsthe possibility to relateeach tool with a proper behavior of DNS traffic. To this aim, we define an assessment of the toolsin three different network configurationswith three different performance metrics. We finallysummarize the most interesting results and provide some considerations on the performance of each tool.	intrusion detection system;network performance;performance evaluation;qualitative comparative analysis;test case;tunneling protocol	Alessio Merlo;Gianluca Papaleo;Stefano Veneziano;Maurizio Aiello	2011		10.1007/978-3-642-21323-6_11	simulation;world wide web;computer security	Metrics	-25.929497176850493	84.84782899088077	67687
40edb3f45185902dd982ec562537c044cbea9d1d	information-centric networking for machine-to-machine data delivery: a case study in smart grid applications	phasor measurement units smart grids network architecture network topology delays real time systems information retrieval information technology content based retrieval power distribution;ucl;information centric networking;discovery;theses;conference proceedings;smart grids;phasor measurement units pmus;digital web resources;ucl discovery;open access;ucl library;book chapters;open access repository;power grid component failures machine to machine data delivery smart grid applications content centric applications internet information centric networking icn spatiotemporal decoupling in network caching smart grid distributed energy resources electric vehicles power distribution network netherlands host centric paradigm medium voltage power grid topologies synchrophasor measurement data;epfl smartgrids;spatiotemporal phenomena distribution networks internet phasor measurement smart power grids;machine to machine applications;ucl research	Largely motivated by the proliferation of content-centric applications in the Internet, information-centric networking has attracted the attention of the research community. By tailoring network operations around named information objects instead of end hosts, ICN yields a series of desirable features such as the spatiotemporal decoupling of communicating entities and the support of in-network caching. In this article, we advocate the introduction of such ICN features in a new, rapidly transforming communication domain: the smart grid. With the rapid introduction of multiple new actors, such as distributed (renewable) energy resources and electric vehicles, smart grids present a new networking landscape where a diverse set of multi-party machine-to-machine applications are required to enhance the observability of the power grid, often in real time and on top of a diverse set of communication infrastructures. Presenting a generic architectural framework, we show how ICN can address the emerging smart grid communication challenges. Based on real power grid topologies from a power distribution network in the Netherlands, we further employ simulations to both demonstrate the feasibility of an ICN solution for the support of real-time smart grid applications and further quantify the performance benefits brought by ICN against the current host-centric paradigm. Specifically, we show how ICN can support real-time state estimation in the medium voltage power grid, where high volumes of synchrophasor measurement data from distributed vantage points must be delivered within a very stringent end-to-end delay constraint, while swiftly overcoming potential power grid component failures.	coupling (computer programming);digital distribution;end-to-end encryption;enterprise architecture framework;entity;experiment;icn gps;internet;machine to machine;network processor;programming paradigm;prototype;rp (complexity);real-time clock;requirement;simulation	Konstantinos Vasileios Katsaros;Wei Koong Chai;Ning Wang;George Pavlou;Herman H. I. Bontius;Mario Paolone	2014	IEEE Network	10.1109/MNET.2014.6843233	telecommunications;computer science;operating system;smart grid;world wide web;computer security;computer network	HPC	-29.367361755529902	62.18090639797197	67693
9a9bfb3d09c4c507e95b131f25d457a389e80b1a	an architecture for consumer-oriented online database services	databases;access cost;efficient algorithms;wireless networks;finance;cost function;software libraries;access patterns;caching;costing;service orientation;resource allocation;information retrieval;retrieval protocols;communication costs;consumer oriented online database services architecture;business communication;information services;information retrieval information services costing finance resource allocation;retrieval protocols consumer oriented online database services architecture access cost communication cost dynamic allocation efficient algorithms communication costs cost models access patterns;dynamic allocation;data allocation;portable computers;heuristic algorithms;access protocols;communication cost;subscriptions;cost models;radio spectrum management;mobile computing;databases access protocols cost function subscriptions mobile computing radio spectrum management heuristic algorithms business communication portable computers software libraries;cost model	In this paper we introduce an architecture for online database services oriented towards consumers. We identify two types of costs| access cost and communication cost. We demonstrate that dynamic allocation of data can minimize these costs. We do so by presenting eecient algorithms based on dynamic allocation; these algorithms optimize access and communication costs for various cost models, access patterns, and retrieval protocols.	algorithm;memory management	A. Prasad Sistla;Ouri Wolfson;Son Dao;Kailash Narayanan;Ramya Raj	1996		10.1109/RIDE.1996.492242	computer science;database;world wide web;computer network	DB	-20.06480496593983	67.49627951508464	67704
6faa33d8bd3a02bc45dbd3ea93b4162b513c2e96	algorithms to distribute a database for parallel searching	computer networks biographies distributed databases tin testing;computer network;redundancy computer network multiple segment queries parallel search;redundancy;parallel search;multiple segment queries	Algorithm of Ghosh [1] for distribution of segments over computer network for parallel searchability of multiple segments required by queries have been modified to reduce average running time.	algorithm;time complexity	Bhuvanesh Srinivasan;R. Sankar	1981	IEEE Transactions on Software Engineering	10.1109/TSE.1981.234513	computer science;theoretical computer science;database;distributed computing;redundancy	Visualization	-7.380855198487406	68.60393022511785	67741
2f225997338ba70643574fcf0895171bb563e5ce	a wavelength assignment scheme for wdm networks with limited range wavelength converters	blocking probability;wavelength routing;wavelength assignment;degradation;wdm network;nonlinear optics;fiber nonlinear optics;wdm networks;optical wavelength conversion;wavelength conversion;optical buffering;wavelength assignment wdm networks optical wavelength conversion wavelength conversion optical buffering wavelength routing wavelength division multiplexing degradation fiber nonlinear optics nonlinear optics;wavelength division multiplexing	In this paper, we propose a new wavelength assignment scheme that improves the blocking probability of WDM networks that use limited-range wavelength converters. Limited-range wavelength converters are attractive for wavelength-routed networks given current technology since they offer good utilization of the wavelength resource and improved blocking probability. However, their conversion ranges are limited, the maximum difference between the input and output wavelengths is restricted. Thus, we must take into account the existence of these limited-range wavelength converters. In our proposed scheme, each connection request is assigned a different wavelength according to its hop number. We tend to use different wavelengths for connection requests with different hop numbers. As a result, we can reduce the blocking probability by two decades compared to simply assigning the shortest available wavelengths. In addition, it allows the number of wavelength converters used in each node to be reduced with almost no degradation in blocking probability. Simulation results show that the proposed scheme can reduce the wavelength converters by about 20%.	blocking (computing);elegant degradation;erlang (unit);input/output;maxdiff;routing;simulation;wavelength-division multiplexing	Sho Shimizu;Yutaka Arakawa;Naoaki Yamanaka	2006	2006 IEEE International Conference on Communications	10.1109/ICC.2006.255202	nonlinear optics;degradation;telecommunications;wavelength-division multiplexing	Robotics	-6.931998563237761	85.1705179476719	67803
2fd0c7f285a4f67c1a62a5a1c1f1c8acdd1bdf0a	linked data (in low-resource) platforms: a mapping for constrained application protocol	coap;http;linked data platform;web of things	This paper proposes a mapping of the Linked Data Platform (LDP) specification for Constrained Application Protocol (CoAP). Main motivation stems from the fact that LDP W3C Recommendation presents resource management primitives for HTTP only. A general translation of LDP-HTTP requests and responses is provided, as well as a framework for HTTP-to-CoAP proxying. Experiments have been carried out using the LDP W3C Test Suite.	constrained application protocol;http tunnel;hypertext transfer protocol;linked data platform;test suite	Giuseppe Loseto;Saverio Ieva;Filippo Gramegna;Michele Ruta;Floriano Scioscia;Eugenio Di Sciascio	2016		10.1007/978-3-319-46547-0_14	hypertext transfer protocol;web of things;computer science;world wide web	Mobile	-25.116698505805243	84.69088110796764	67818
313d8b9a25f11290b1472a9ef705902303dcbc5e	interactive information flow - (invited talk)	information flow;a priori knowledge;probability distribution	In recent years, there has been a growing interest in considering the quantitative aspects of Information Flow, partly because often the a priori knowledge of the secret information can be represented by a probability distribution, and partly because the mechanisms to protect the information may use randomization to obfuscate the relation between the secrets and the observables. We consider the problem of defining a measure of information leakage in interactive systems. We show that the information-theoretic approach which interprets such systems as (simple) noisy channels is not valid anymore when the secrets and the observables can alternate during the computation, and influence each other. However, the principle can be retrieved if we consider more complicated types of channels, that in Information Theory are known as channels with memory and feedback. We show that there is a complete correspondence between interactive systems and such kind of channels. Furthermore, the proposed framework has good topological properties which allow to reason compositionally about the worst-case leakage in these systems.	best, worst and average case;computation;information flow;information leakage;information theory;observable;spectral leakage	Catuscia Palamidessi;Mário S. Alvim;Miguel E. Andrés	2010		10.1007/978-3-642-16074-5_8	discrete mathematics;theoretical computer science;data mining;mathematics	Logic	-33.5818818405083	73.05899295771835	67862
525b36b24b8e4951406afa8cbdb34b0351218ac0	a task scheduling method after clustering for data intensive jobs in heterogeneous distributed systems	task clustering;eterogeneous;heterogeneous;data intensive;task scheduling	Several task clustering heuristics are proposed for allocating tasks in heterogeneous systems to achieve a good response time in data intensive jobs. However, it has been one of challenging problems that how each task should be scheduled after a task allocation by a task clustering. We propose a task scheduling method after task clustering, leveraging Worst Schedule Length (WSL) as an upper bound of the schedule length. In our proposed method, a task in a WSL sequence is scheduled preferentially to make WSL smaller. Experimental results by simulation show that the response time is improved in several task clustering heuristics. In particular, our proposed scheduling method with the task clustering we proposed previously outperforms conventional list-based task scheduling methods. Category: Task Scheduling	cluster analysis;computer cluster;data-intensive computing;distributed computing;heuristic (computer science);job stream;response time (technology);schedule (project management);scheduling (computing);simulation;wide-spectrum language	Kazuo Hajikano;Hidehiro Kanemitsu;Moo Wan Kim;Hee-Dong Kim	2016	JCSE	10.5626/JCSE.2016.10.1.9	fixed-priority pre-emptive scheduling;parallel computing;real-time computing;distributed computing	Embedded	-15.041731340360549	61.10908239780492	67923
d98d10a340449961d4e6c47c793c52fd0ad5ee2e	protecting digital music delivery and consumption using the occamm project framework	content management;watermarking;electronic commerce;project management;protection multiple signal classification content management electronic commerce internet telecommunications laboratories iec multimedia systems project management;drm digital rights management;application program interfaces electronic commerce music copyright project engineering watermarking;occamm;copyright;iec;multimedia systems;digital rights management;content rules;standardisation;digital music;protection;multiple signal classification;internet;mpeg opima occamm ipmps system digital rights management content rules user rules electronic commerce;project engineering;application program interfaces;ipmps system;mpeg;ipmps;music;digital right management;opima;telecommunications;user rules	Several standardisation initiatives recognised that content has value to both the user and the owner, and to ensure that this value is preserved it must be protected. One of those initiatives is called OPIMA, an initiative in the Industry Technical Agreement (ITA) program of the International Electro technical Commission (IEC). OPIMA specification was implemented and validated in OCCAMM an EC IST funded project. In OCCAMM a full-fledged system based on OPIMA, for secure distribution of multimedia material was set-up and trial scenarios where established. Thus, this paper describes a usage case established by the OCCAMM project, in which digital music is traded in an Electronic Commerce Platform and distributed to final users in a secure, conditional and protected way. Music consumption is also controlled in the client through the enforcement of content and usage rules by a specific developed player.	authentication;data compression;digital distribution;digital recording;digital watermarking;e-commerce;emoticon;encryption;interoperability;open verification methodology;operating system	Carlos Serrão;Joaquim Marques;Trevor Baker;Massimo Balestri;Panos Kudumakis	2002		10.1109/WDM.2002.1176192	engineering;multimedia;world wide web;computer security	HCI	-30.508528171217698	87.14474732332549	67935
41a32a790fb679e51faed26e736d11e15abb7128	morm: a multi-objective optimized replication management strategy for cloud storage cluster	replication management;multi objective optimization;artificial immune algorithm;cloud storage	Effective data management is an important issue for a large-scale distributed environment such as data cloud. This can be achieved by using file replication, which efficiently reduces file service time and access latency, increases file availability and improves system load balancing. However, replication entails various costs such as storage and energy consumption for holding replicas. This article proposes a multi-objective offline optimization approach for replica management, in which we view the various factors influencing replication decisions such as mean file unavailability, mean service time, load variance, energy consumption and mean access latency as five objectives. It makes decisions of replication factor and replication layout with an improved artificial immune algorithm that evolves a set of solution candidates through clone, mutation and selection processes. The proposed algorithm named Multi-objective Optimized Replication Management (MORM) seeks the near optimal solutions by balancing the trade-offs among the five optimization objectives. The article reports a series of experiments that show the effectiveness of the MORM. Experimental results conclusively demonstrate that our MORM is energy effective and outperforms default replication management of HDFS (Hadoop Distributed File System) and MOE (Multi-objective Evolutionary) algorithm in terms of performance and load balancing for large-scale cloud storage cluster.	cloud storage	Saiqin Long;Yuelong Zhao;Wei Chen	2014	Journal of Systems Architecture - Embedded Systems Design	10.1016/j.sysarc.2013.11.012	embedded system;parallel computing;real-time computing;computer science;operating system;multi-objective optimization;database;distributed computing;replication;computer network	Embedded	-19.345710838770792	62.8328740527028	67969
c4ae229f79049ea6340e0b2bc2b70c21bd0e6a2f	performance evaluation of large scale disaster information system over japan gigabit network	databases;safety back up procedures disasters public administration;safety information database system performance evaluation large scale disaster information system japan gigabit network distributed resident oriented safety information system local database upper layer database redundancy function backup function;distributed system;redundancy function;database system;disater information;communication networks;information systems;performance evaluation;distributed system disater information robustness;large scale systems information systems safety databases wireless lan robustness mobile ad hoc networks communication networks mobile communication out of order;upper layer database;out of order;safety information database system;back up procedures;large scale;long distance;mobile ad hoc networks;japan gigabit network;local database;safety;large scale disaster information system;mobile communication;robustness;wireless lan;information system;backup function;distributed resident oriented safety information system;disasters;large scale systems;public administration	Since various disasters provides serious damage influence at the time to many residents in wide area across Japan island, large scale of disaster information system with more robustness and redundancy covered over wide area is required. In this paper, we introduce a large scale distributed resident- oriented safety information system constructed over Japan gigabit network. The safety information with residents is registered to the local database in the evacuated area and integrated into an upper-layer database in the district area. Those local databases are mutually covered when the some of the databases are destroyed or disordered. On the other hand, the upper-layer databases are located to mutually different locations with long distance to isolate the influence to the same disaster and also mutually mirrored to support when the some of them are out of order. Thus, by introducing two levels of redundancy and backup functions, more large scale and robust safety information database system can be realized. In this paper, we designed and implemented a prototype system by our introduced method over Japan gigabit network to evaluate whether our suggested method is useful or not. Through the functional and performance evaluation, we could verified our suggested resident information system is effective and useful.	backup;database;database server;gigabit;global positioning system;information centre;information system;mobile phone;performance evaluation;prototype;server (computing);user interface	Hiroyuki Echigo;Yoshitaka Shibata	2008	22nd International Conference on Advanced Information Networking and Applications - Workshops (aina workshops 2008)	10.1109/WAINA.2008.260	telecommunications;computer science;data mining;database;computer security;information system;computer network	DB	-4.661659412139347	74.75702595361686	68059
e2af2a9e77c0b8a99b74e4ae3757b9eda0bace57	peer-owl: an adaptive data dissemination scheme for peer-to-peer streaming services	tolerancia falta;distributed system;data transmission;streaming;reseau pair;systeme reparti;fault tolerant;transmision continua;video a la demande;serveur video;igual a igual p2p;transmission en continu;sistema repartido;peer to peer streaming;transmission donnee;fault tolerance;diffusion donnee;video on demand;difusion dato;reseau gnutella;video servers;data broadcast;peer to peer;tolerance faute;video a la carta;transmision datos;data dissemination	More and more researchers have put their emphases on peer-to-peer streaming services, which can provide massive and cheap video-on-demand services. Data dissemination is one of the most important open problems when providing peer-to-peer streaming services, including live streaming and videoon-demand. Considering the performance and fault-tolerance of streaming systems, content should be distributed and replicated onto peer nodes according to some kind of strategy. In this paper, a novel data dissemination scheme is proposed. According to the proposal, media files are recoded into injected objects with several segments according to the characteristics of VCR operations’ frequency, without changing the media compressing formats. Then, a peer who wants to get one media file can acquire the corresponding segmented object files from many source peers, not from only one peer. The new scheme does not need any extra network bandwidth. Results from simulations have proved that our Peer-Owl scheme has good performances.	fault tolerance;gnutella;object file;peer-to-peer;performance;simulation;streaming media;transmitter;videocassette recorder	Xiaofei Liao;Hai Jin	2004		10.1007/978-3-540-30208-7_66	fault tolerance;telecommunications;computer science;distributed computing;world wide web;computer security;computer network	DB	-13.2206711017592	70.71895549280046	68272
48140bc865377d4d9be0af4790a51eb13a5838dc	scheduling in compute cloud with multiple data banks using divisible load paradigm	processor scheduling;compute cloud system satellite image classification problem linear programming problem processing time recursive equations scheduling problem divisible load theory concurrent processing web role shared data banks heterogeneous computing resources scheduling strategy;computational modeling;satellites;linear programming;load modeling;processor scheduling timing satellites program processors linear programming computational modeling load modeling;program processors;storage management cloud computing concurrency control image classification linear programming processor scheduling;timing	The main challenge in a compute cloud system is to design a scheduling strategy for heterogeneous computing resources with shared data banks. The cloud user's job arrives at the Web role, which distributes the load to the worker rules for concurrent processing. The worker role retrieves the respective data from the shared data banks. According to divisible load theory, the scheduling problem is formulated as relevant recursive equations and constraints that are derived from the continuity of processing time due to retrieval from multiple data banks. The scheduling problem in a compute cloud is formulated as a linear programming problem. Finally, we present a satellite image classification problem in a compute cloud as an example to show the adequacy of the proposed solution.	algorithm;cloud computing;computational complexity theory;computer multitasking;computer vision;decision problem;heterogeneous computing;image processing;job scheduler;linear programming;numerical analysis;programming paradigm;recursion;recursion (computer science);scheduling (computing);scott continuity;simulation;world wide web	Sundaram Suresh;Hao Huang;Hyo Jun Kim	2015	IEEE Transactions on Aerospace and Electronic Systems	10.1109/TAES.2014.130201	fair-share scheduling;fixed-priority pre-emptive scheduling;parallel computing;real-time computing;dynamic priority scheduling;computer science;linear programming;rate-monotonic scheduling;two-level scheduling;mathematics;distributed computing;scheduling;computational model;physics;satellite	Embedded	-16.27414933190982	61.44787634454685	68295
bb6ebe91b63262638621c9fddba4ce707bd2aa4b	a scheduling framework for large-scale, parallel, and topology-aware applications	sensibilidad contexto;distributed system;systeme reparti;context aware;machine unique;probleme np complet;calculator cluster;heterogeneous environment;prise de decision;supercomputer;grid;supercomputador;large scale;aproximacion polinomial;grappe calculateur;single machine;maquina unica;sistema repartido;qoscosgrid;rejilla;scheduling;algorithme reparti;approximation polynomiale;scheduler;grille;algoritmo repartido;problema np completo;sensibilite contexte;toma decision;distributed algorithm;ordonnancement;racimo calculadora;reglamento;superordinateur;np complete problem;polynomial approximation	Scheduling of large-scale, distributed topology-aware applications requires that not only the properties of the requested machines be considered, but also the properties of the machines' interconnections. This requirement severely complicates the scheduling process, as even a matching between a single multi-processors task and available machines in a single time slot becomes an NP-complete problem with no polynomial approximation. In this paper we propose a complete scheduling framework for multi-cluster, heterogeneous environments that provides, in practice, an efficient solution for the scheduling of topology-aware applications. The proposed framework is very flexible as it is composed of pluggable components and can be easily configured to support a variety of scheduling policies. W e also describe three novel scheduling and coallocation algorithms that were developed and plugged into the framework. The proposed scheduling framework was integrated into the QosCosGrid1 system, where it is used as the main decision-making module.	algorithm;central processing unit;cluster analysis;heuristic;np-completeness;network topology;polynomial;polynomial-time approximation scheme;quality of service;scheduling (computing)	Valentin Kravtsov;Pavel Bar;David Carmeli;Assaf Schuster;Martin T. Swain	2010	2010 IEEE International Symposium on Parallel & Distributed Processing (IPDPS)	10.1016/j.jpdc.2010.05.001	fair-share scheduling;nurse scheduling problem;fixed-priority pre-emptive scheduling;distributed algorithm;supercomputer;parallel computing;real-time computing;earliest deadline first scheduling;np-complete;gang scheduling;flow shop scheduling;dynamic priority scheduling;computer science;rate-monotonic scheduling;genetic algorithm scheduling;operating system;two-level scheduling;stride scheduling;distributed computing;scheduling;gain scheduling;least slack time scheduling;instruction scheduling;lottery scheduling;round-robin scheduling;grid;scheduling;multiprocessor scheduling;algorithm	Embedded	-14.204283245346158	63.28835722736292	68317
17f844f4f24901b792c1ab7bcabfe5dc039beb16	cloudifying the 3gpp ip multimedia subsystem: why and how?	scalability cloud computing elasticity computer architecture multimedia communication ip networks conferences	The 3GPP IP Multimedia Subsystem (IMS) has been specified as the service delivery platform of 3G networks. It subsequently became the de facto service delivery platform of 4G networks. Cloud computing is an emerging paradigm with inherent benefits such as scalability, elasticity and easy deployment of new applications and services. Scalability and elasticity are currently among the major roadblocks to the wide scale deployment of IMS. Cloudifying IMS can help in removing these roadblocks. It will also certainly bring many other advantages. However, this cloudification is no easy task and is still in its infancy. This paper motivates the cloudification of IMS, critically reviews the architectures proposed so far, sketches a vision and discusses the related research challenges.	cloud computing;elasticity (cloud computing);elasticity (data store);ip multimedia subsystem;itil;programming paradigm;scalability;software deployment	Roch H. Glitho	2014	2014 6th International Conference on New Technologies, Mobility and Security (NTMS)	10.1109/NTMS.2014.6814010	embedded system;real-time computing;telecommunications;computer science;operating system;ip multimedia subsystem;computer security;computer network	HPC	-15.697066188324431	86.09990417581696	68412
1b2a56eaa107cb5ca31be45885084feec1953316	modeling the routing of an autonomous system with c-bgp	institutional repositories;fedora;vital;autonomic system;routing protocols network topology bandwidth telecommunication traffic traffic control ip networks floods propagation delay communication system traffic control;internet;telecommunication network routing;internet telecommunication network routing telecommunication network topology;internet autonomous system routing c bgp isp networks open source routing network topology;vtls;telecommunication network topology;building model;ils;open source	"""Today, the complexity of ISPs' networks make it difficult to investigate the implications of internal or external changes on the distribution of traffic across their network. In this article we explain the complexity of building models of large ISPs' networks. We describe the various aspects important to understanding the routing inside an AS. We present an open source routing solver, C-BGP, that eases the investigation of changes in the routing or topology of large networks. We illustrate how to build a model of an ISP on a real transit network and apply the model on two """"what-if"""" scenarios. The first scenario studies the impact of chances in the Internet connectivity of a transit network. The second investigates the impact of failures in its internal topology."""	amd radeon rx 200 series;autonomous system (internet);border gateway protocol;egress filtering;failure analysis;inbound marketing;inter-domain;internet;network topology;open-source software;peer-to-peer;peering;solver;source routing	Bruno Quoitin;Steve Uhlig	2005	IEEE Network	10.1109/MNET.2005.1541716	policy-based routing;routing table;routing domain;optimized link state routing protocol;routing;enhanced interior gateway routing protocol;static routing;the internet;overlay network;hierarchical routing;convergence;supernetwork;equal-cost multi-path routing;dynamic source routing;multipath routing;ip forwarding;distributed computing;routing protocol;link-state routing protocol;triangular routing;law;computer security;hazy sighted link state routing protocol;geographic routing;computer network	Networks	-10.960651101756168	78.6116927167642	68565
e7317ac651e838b5f3ac6ed96fe2b7470772caa9	highly available, enhanced response file service in network computers				Jason Gait	1986			intelligent computer network;computer network;distributed computing;network management station;computer science;network architecture;ssh file transfer protocol;global namespace;network file system;shared resource;self-certifying file system	OS	-17.50718298588526	81.11622347150023	68642
60f61df72b0b832dd6402e88bc350e9a9fe57c61	a software-defined mac architecture for wi-fi operating in user space on conventional pcs		The ability to access low-level IEEE 802.11 MAC primitives, and in particular to manage single transmission attempts in software at the user space level, is a prerequisite for many application scenarios based on Wi-Fi and characterized by tight timings constraints. Seamless redundancy, traffic scheduling, and TDMA techniques are just a few significant examples. In this paper, a novel software architecture is defined, called SDMAC, which relies on conventional Linux PCs equipped with off-the-shelf Wi-Fi adapters and provides direct control on frame transmission to applications. Its implementation and evaluation on a real testbed showed that integrating SDMAC in the Linux protocol stack is a valid solution, in terms of the latencies introduced by software and hardware components, and suits a wide range of soft real-time applications.	acknowledgement (data networks);application programming interface;centralized computing;device driver;finalize (optical discs);high- and low-level;linux;over the air;point of view (computer hardware company);protocol stack;prototype;real-time clock;real-time computing;real-time transcription;run time (program lifecycle phase);scheduling (computing);seamless3d;software architecture;testbed;user space	Gianluca Cena;Stefano Scanzio;Adriano Valenzano	2017	2017 IEEE 13th International Workshop on Factory Communication Systems (WFCS)	10.1109/WFCS.2017.7991945	computer network;protocol stack;real-time computing;architecture;embedded system;software;user space;testbed;time division multiple access;software architecture;scheduling (computing);computer science	Mobile	-16.34618696357605	81.05677413903233	68648
2d46aeab6600561f6550829fa1feaa7a113dd3ba	an adaptive file distribution algorithm for wide area network	grid computing;scalability;wide-area network;self-stabilizing distributed algorithm;fault tolerance;fault tolerant;distributed algorithm;self organization	This paper describes a data distribution algorithm suitable for copying large files to many nodes in multiple clusters in wide-area networks. It is a self-organizing algorithm that achieves pipeline transfers, fault tolerance, scalability, and an efficient route selection. It works in the presence of today’s typical network restrictions such as firewalls and Network Address Translations, making it suitable in widearea setting. Experimental results indicate our algorithm is able to automatically build a transfer route close to the optimal. Propagation of a 300MB file from one root node to over 150 nodes takes about 1.5 times as long as the best time obtained by the manually optimized transfer route.	algorithm;fault tolerance;firewall (computing);network address;organizing (structure);scalability;self-organization;software propagation;tree (data structure)	Takashi Hoshino;Kenjiro Taura;Takashi Chikayama	2005	Scalable Computing: Practice and Experience		real-time computing;computer science;distributed computing;computer network	HPC	-11.322765005864403	73.46447622375631	68728
531306b89d7dd0a7f73daa041c3ec7af02ce76b0	designing an efficient mpls-based switch for fat tree network-on-chip systems	switching;network on chip;routing;fat tree;mpls	This paper describes a proposal for FAT tree based Network-on-Chip system based on MPLS forwarding mechanism. The FAT tree includes processing nodes and communication switches. IP node (processing nodes) has a message generator unit which randomly generates messages to different destinations with different packet lengths and buffering. The switch is based on MPLS technique and consists of the following units: crossbar switch, input/output link controllers and routing and arbitration units. A simulator has been developed in C++ to analyze the proposed architecture. A comparison with wormhole switch is provided to show the efficiency of the MPLS designed switch.	c++;crossbar switch;fat tree;input/output;multiprotocol label switching;network on a chip;network packet;network switch;randomness;routing;tree network	Najwa Salama;Azeddien M. Sllame	2016		10.1145/2857058.2857059	crossover switch;label information base;real-time computing;telecommunications;engineering;computer network	Metrics	-6.183535722673787	87.13551908514236	68732
c24de44623b49978b1a0f79e55059840e7a59761	network virtualization resource allocation and economics based on prey–predator food chain model		Network virtualization (NV) allows multiple heterogeneous virtual networks (VNs) to coexist and operate over the same physical network (PN) infrastructures. Some of the benefits of this advancement include flexibility in VN topologies, heterogeneity in VN technologies, and modularity of network operations. However, there are a few areas, such as resource allocation and economics, which challenge the implementation of NV. In this paper, we first introduce some NV parameters that influence the resource allocation and economics of an NV system. Next, we formulate an economic model for NV using the prey-predator food chain model. This model takes into account the dynamics in an NV system, such as the service, payoff, failure, and competition rates within each VN and PN. The solution point to this model represents the resource strategy of the service provider (SP) given the number of users trying to use its VN, as well as the resource strategy of the infrastructure provider (InP) given the strategy of the VN leasing its PN. In addition, we establish economic models that relate the capacities of the end users, the SP, and the InP. Finally, we provided simulations that show how the prey-predator food chain model fits well on an NV system.	coexist (image);computational fluid dynamics;fits;food chain;network congestion;numerical linear algebra;nv network;prey;simulation	Reginald A. Banez;Haitao Xu;Nguyen H. Tran;Ju Bin Song;Choong Seon Hong;Zhu Han	2018	IEEE Transactions on Communications	10.1109/TCOMM.2018.2843367	food chain;service provider;resource management;network virtualization;network operations center;network topology;control theory;economic model;computer science;resource allocation;distributed computing	Networks	-12.434856162048089	84.86496181348895	68815
d53d23d1846b25f7515a20dbcc0aa40f95f1383b	a scalable network architecture for a large-scale uni-directional link	large scale;network architecture	Effective bandwidth utilization and scalability are vital issues for IP networking over a large-scale uni-directional link (UDL), such as a wide-area wireless broadcast over satellite or terrestrial digital broadcasting. On a large-scale UDL, the current network architecture is not scalable to cover an extraordinary number of receivers that communicate using a Link-layer Tunneling Mechanism (LLTM). This paper proposes a network architecture for a large-scale UDL that: (1) decreases the traffic load of LLTM at the upstream network of the UDL, (2) coordinates the data link layer and network layer of receivers without communications via UDL, and (3) enables neighbor discovery for direct communication between receivers via a bi-directional link that is used as a return path for LLTM. Simulation results showed that our approach reduces by more than 90% the control messages to be sent via UDL compared with IPv6 stateless address autoconfiguration on the existing network architecture. Our proposal improves the UDL bandwidth consumption from O(N) to O(1), so that the bulk of the bandwidth can be utilized for delivering services, not for network configuration of receivers.	network architecture	Kotaro Kataoka;Achmad Husni Thamrin;Jun Murai	2010	JIP	10.2197/ipsjjip.18.125	network architecture;telecommunications;computer science;distributed computing;computer network	Robotics	-8.761939170253378	88.39927238241859	68847
11ac499f63e354a6b283f6f01c558db0233259a3	high-performance resource allocation and request redirection algorithms for web clusters	analytical models;server migration algorithm high performance resource allocation request redirection algorithms web cluster architectures dynamic content applications resource utilization;client server and multitier systems;resource utilization;degradation;electronic commerce;resource management clustering algorithms network servers delay degradation service oriented architecture algorithm design and analysis analytical models web services quality of service;workstation clusters computer architecture internet resource allocation;resource allocation;e commerce;resource management;web servers;multitier systems;web cluster architectures;request redirection algorithms;indexing terms;statistical multiplexing;computer architecture;network servers;client server;server selection;internet;server migration algorithm;web services;dynamic content applications;clustering algorithms;electronic commerce distributed systems client server client server and multitier systems;request redirection;dynamic content;workstation clusters;quality of service;distributed systems;service oriented architecture;high performance;algorithm design and analysis;high performance resource allocation;wide area network;wide area networks;analytical model	With increasing richness in features such as personalization of content, Web applications are becoming increasingly complex and hence compute intensive. Traditional approaches for improving performance of static content Web sites have been based on the assumption that static content such as images are network intensive. However, these methods are not applicable to the dynamic content applications which are more compute intensive than static content. This paper proposes a suite of algorithms which jointly optimize the performance of dynamic content applications by reducing the client access times while also minimizing the resource utilization. A server migration algorithm allocates servers on-demand within a cluster such that the client access times are not affected even under sudden overload conditions. Further, a server selection mechanism enables statistical multiplexing of resources across clusters by redirecting requests away from overloaded clusters. We also propose a cluster decision algorithm which decides whether to migrate in additional servers at the local cluster or redirect requests remotely under different workload conditions. Through a combination of analytical modeling, trace-driven simulation over traces from large e-commerce sites and testbed implementation, we explore the performance savings achieved by the proposed algorithms.	algorithm;dynamic web page;e-commerce;multiplexing;personalization;redirection (computing);server (computing);simulation;testbed;tracing (software);web application	Supranamaya Ranjan;Edward W. Knightly	2008	IEEE Transactions on Parallel and Distributed Systems	10.1109/TPDS.2007.70810	e-commerce;web service;algorithm design;statistical time division multiplexing;in situ resource utilization;the internet;degradation;index term;quality of service;resource allocation;computer science;operating system;dynamic web page;service-oriented architecture;database;distributed computing;cluster analysis;world wide web;web server;client–server model;computer network	HPC	-18.253313888384906	69.66418660644875	68948
3947b59f6fea0a4f0391258bbc360857e52bc4fd	switch scheduling via randomized edge coloring	edge coloring;processor scheduling;queueing theory;communication complexity;randomised algorithms;packet switching;randomised algorithms internet graph colouring packet switching processor scheduling communication complexity telecommunication network routing queueing theory;scheduling algorithm;internet;telecommunication network routing;switches scheduling algorithm packet switching bipartite graph communication switching traffic control hardware internet routing stochastic processes;randomized algorithm;scheduling problem;bipartite graph;queue length switch scheduling randomized edge coloring internet router n spl times n switch packet routing input port output port bipartite graph vertex sets scheduling algorithms time step bipartite matching edge coloring problem bipartite multigraph decentralized algorithm online algorithm randomized algorithm near optimal colors stochastic online edge arrivals;graph colouring	The essence of an Internet router is an n n switch which routes packets from input to output ports. Such a switch can be viewed as a bipartite graph with the input and output ports as the two vertex sets. Packets arriving at input port i and destined for output port j can be modeled as an edge from i to j. Current switch scheduling algorithms view the routing of packets at each time step as a selection of a bipartite matching. We take the view that the switch scheduling problem across a sequence of time-steps is an instance of the edge coloring problem for a bipartite multigraph. Implementation considerations lead us to seek edge coloring algorithms for bipartite multigraphs that are fast, decentralized, and online. We present a randomized algorithm which has the desired properties, and uses only a near-optimal ∆ o ∆ colors on dense bipartite graphs arising in the context of switch scheduling. This algorithm extends to nonbipartite graphs as well. It leads to a novel switch scheduling algorithm which, for stochastic online edge arrivals, is stable, i.e., the queue length at each input port is bounded at all times. We note that this is the first decentralized switch scheduling algorithm that is also guaranteed to be stable.	color;edge coloring;graph coloring;input/output;matching (graph theory);multigraph;randomized algorithm;router (computing);routing;scheduling (computing)	Gagan Aggarwal;Rajeev Motwani;Devavrat Shah;An Zhu	2003		10.1109/SFCS.2003.1238223	job shop scheduling;open-shop scheduling;combinatorics;real-time computing;the internet;bipartite graph;computer science;theoretical computer science;edge coloring;communication complexity;mathematics;distributed computing;randomized algorithm;queueing theory;scheduling;algorithm;packet switching	Theory	-5.066954360916479	71.44486369194809	68955
5332afc4c4882721da6200d5572c74919a3ff7bf	a general constrained shortest path approach for virtual path embedding	protocols;virtualization;energy efficiency constrained shortest path approach virtual path embedding network virtualization data intensive applications bioinformatics retail analytics multidata center scale virtual network service physical path creation virtual network functions virtual link embedding data plane on demand path adaptation service level objective guarantees slo guarantees constrained traffic steering problems optimisation neighborhood method algorithm nm algorithm network utilization;bandwidth;virtualisation computer networks graph theory optimisation;jitter;bandwidth delays virtualization bioinformatics protocols jitter;delays;bioinformatics	Network virtualization has become a fundamental technology to deliver services for emerging data-intensive applications in fields such as bioinformatics and retail analytics hosted at multi-data center scale. To create and maintain a successful virtual network service, the problem of generating a constrained path manifests both in the management plane with a physical path creation -chains of virtual network functions or virtual link embedding - and in the data plane with on-demand path adaptation - traffic steering with Service Level Objective (SLO) guarantees. In this paper, we define the virtual path embedding problem to subsume the virtual link embedding and the constrained traffic steering problems, and propose a new scheme to solve it optimally. Specifically, we introduce a novel algorithm viz., `Neighborhood Method' (NM) which provides an on-demand path with SLO guarantees while reducing expensive over provisioning. We show that by solving the Virtual Path Embedding problem in a set of diverse topology scenarios we gain up to 20% in network utilization, and up to 150% in energy efficiency, compared to the existing path embedding solutions.	algorithm;bioinformatics;data center;data-intensive computing;forwarding plane;management plane;monte carlo method;network function virtualization;provisioning;shortest path problem;simulation;time complexity;viz: the computer game	Dmitrii Chemodanov;Prasad Calyam;Flavio Esposito;Andrei M. Sukhov	2016	2016 IEEE International Symposium on Local and Metropolitan Area Networks (LANMAN)	10.1109/LANMAN.2016.7548863	communications protocol;virtualization;jitter;fast path;constrained shortest path first;computer science;theoretical computer science;operating system;distributed computing;bandwidth;computer network	Arch	-9.603952014273657	82.28045494984603	69049
487627600ba073db011a33bbbbf91aaa10dab20d	peer-to-peer cloud provisioning: service discovery and load-balancing	cluster computing;peer to peer network;experimental test bed;internet architecture;design and implementation;indexation;information dissemination;next generation;overlay network;load balance;experimental evaluation;service discovery;peer to peer;cloud computing	Abstract Clouds have evolved as the next-generation platform that facilitates creation of wide-area on-demand renting of computing or storage services for hosting application services that experience highly variable workloads and requires high availability and performance. Interconnecting Cloud computing system components (servers, virtual machines (VMs), application services) through peerto-peer routing and information dissemination structure are essential to avoid the problems of provisioning efficiency bottleneck and single point of failure that are predominantly associated with traditional centralized or hierarchical approaches. These limitations can be overcome by connecting Cloud system components using a structured peer-to-peer network model (such as distributed hash tables (DHTs)). DHTs offer deterministic information/query routing and discovery with close to logarithmic bounds as regards network message complexity. By maintaining a small routing state of O (log n) per VM, a DHT structure can guarantee deterministic look-ups in a completely decentralized and distributed manner. This chapter presents: (i) a layered peer-to-peer Cloud provisioning architecture; (ii) a summary of the current state-of-the-art in Cloud provisioning with particular emphasis on service discovery and load-balancing; (iii) a classification of the existing peer-to-peer network management model with focus on extending the DHTs for indexing and managing complex provisioning information; and (iv) the design and implementation of novel, extensible software fabric (Cloud peer) that combines public/private clouds, overlay networking, and structured peer-to-peer indexing techniques for supporting scalable and self-managing service discovery and loadbalancing in Cloud computing environments. Finally, an experimental evaluation is presented that demonstrates the feasibility of building next-generation Cloud provisioning systems based on peer-to-peer network management and information	amazon elastic compute cloud (ec2);centralized computing;cloud computing;distributed hash table;dynamical system;fault tolerance;high availability;high-level programming language;load balancing (computing);locality of reference;lookup table;network model;overlay network;peer-to-peer;provisioning;reliability engineering;routing;scalability;service discovery;single point of failure;virtual machine	Rajiv Ranjan;Liang Zhao;Xiaomin Wu;Anna Liu	2010	CoRR	10.1007/978-1-84996-241-4_12	cloud computing security;overlay network;cloud computing;computer cluster;computer science;load balancing;operating system;cloud testing;distributed computing;service discovery;world wide web;provisioning;computer network	HPC	-12.520987880676223	72.19276727116785	69109
50851c979c878ec08f16ed171c3977f219f3e36f	qos-rrc: an overprovisioning-centric and load balance-aided solution for future internet qos-oriented routing	multimedia;over provisioning;future internet;qoe;load balance;qos routing	The concepts and designs of 4WARD project for the Future Internet involve a clean-slate architecture with various networking innovations, including a new connectivity paradigm called Generic Path (GP). In GP architecture, several facilities are designed to efficiently support complex value-added applications and services with assured Quality of Service (QoS). The GP mainly makes transparent the underlying network structure and heterogeneity, and any entities, regardless of their purpose (technology, location or architectural layer) communicate with each other in a single way via a common interface. In addition, cooperation with network-layer provisioning mechanisms is required to map data paths that are compliant with session-demanded resources (QoS requirements - minimum bandwidth and maximum delay/loss experience) in appropriate GPs. In contrast, robust and scalable QoS-provisioning facilities are urgently required as a support for efficient GP allocations. To address this need, this paper introduces the QoS-Routing and Resource Control (QoS-RRC), a set of GP-compliant facilities to meet the requirements mentioned above. QoS-RRC complements GP architecture with QoS-oriented routing, with the aid of load balancing to select paths that comply with session-demands while keeping residual bandwidth to increase user experience. To address scalability issues, QoS-RRC operates on the basis of an overprovisioning-centric approach to achieve cost-effectiveness in terms of state storage, signaling load and network operations. An initial QoS-RRC performance evaluation was carried out in Network Simulator v.2 (NS-2), which showed that there had been drastic improvements in the flow delay experience and bandwidth use among a range of relevant state-of-the-art solutions. Moreover, the impact of QoS-RRC on the user experience (compared to current IP QoS and routing standards) has been evaluated, by analyzing the main objective and subjective Quality of Experience (QoE) metrics, namely Peak Signal to Noise Ratio (PSNR), The Structural Similarity Index (SSIM), Video Quality Metric (VQM) and Mean Opinion Score (MOS).	abstraction layer;digital video;elegant degradation;entity;experiment;future internet;inter-domain;load balancing (computing);multi-user;network congestion;network packet;peak signal-to-noise ratio;performance evaluation;programming paradigm;provisioning;quality of service;real-time clock;real-time transcription;requirement;routing;scalability;simulation;structural similarity;user experience;wireless mesh network	Augusto Neto;Leandro Freitas;Eduardo Cerqueira;Rui L. Aguiar;Danielo Goncalves Gomes	2011	Multimedia Tools and Applications	10.1007/s11042-011-0931-x	real-time computing;simulation;telecommunications;computer science;load balancing;operating system;world wide web;computer security;computer network	Networks	-14.77084388052698	84.34931221352518	69148
99816d094d9593a7dad50b3a2f7dde2041c2aee9	on-path resolver architecture for mobility support in information centric networking	engineering;electrical electronic;routing;technology;telecommunication network routing computer network reliability internet;hardware architecture;science technology;internet;data structures;mobile communication;bandwidth;face;computer science;mobile communication routing face proposals data structures internet bandwidth;proposals;hierarchical name based routing on path resolver architecture mobility support information centric networking named data networking video traffic internet bandwidth ndn content delivery mobile devices opra	Video traffic shares a large portion of the current Internet bandwidth. One of the objectives of designing Named Data Networking (NDN) is to reduce the burden of the large content delivery. Since mobile devices are the prime means of content access for many users, NDN is also required to support mobility. In this paper, we propose an architecture and mechanism called On-Path Resolver Architecture (OPRA) for NDN to support both consumer and producer mobility while maintaining scalability. OPRA exploits the semantics of hierarchical-name-based routing and places route resolvers on multiple points on a path to a content. The series of resolvers on a path provides means to contain naming scope and makes the system scalable while supporting mobility.	digital distribution;experiment;mobile device;oriented point relation algebra;overhead (computing);routing;scalability;scope (computer science);simulation;subnetwork	Hidenori Nakazato;Siran Zhang;Yong-Jin Park;Andrea Detti;Dariusz Bursztynowski;Zbigniew Kopertowski;Ioannis Psaras	2015	2015 IEEE Globecom Workshops (GC Wkshps)	10.1109/GLOCOMW.2015.7413979	face;routing;telecommunications;computer science;operating system;hardware architecture;distributed computing;world wide web;bandwidth;computer network;technology	Mobile	-13.907816450079814	76.9747818944479	69161
5fdadef8ddc64c5981a8f17ca5aef969adbd2d9e	server selection schemes considering node status for a fault-tolerant streaming service on a peer-to-peer network	fault-tolerant streaming services;peer-to-peer network;fault tolerant	Peer-to-Peer (P2P) networks are attracting considerable research interest because of their scalability and high performance relative to cost. One of the important services on a P2P network is the streaming service. However, because each node in the P2P network is autonomous, it is difficult to provide a stable streaming service on the network. Therefore, for a stable streaming service on the P2P network, a fault-tolerant scheme must be provided. In this paper, we propose two new node selection schemes, Playback Node First (PNF) and Playback Node First with Prefetching (PNF-P) that can be used for a service migration-based fault-tolerant streaming service. The proposed schemes exploit the fact that the failure probability of a node currently being served is lower than that of a node not being served. Simulation results show that the proposed schemes outperform traditional node selection schemes.	fault tolerance;link prefetching;node (computer science);peer-to-peer;prenex normal form;scalability;server (computing);simulation;streaming media	Hyunjoo Kim;Sooyong Kang;Heon Young Yeom	2006	JIPS			Metrics	-14.450723917505998	74.1634413551348	69191
9955f39862853ba2717a6348696bbde081a6ac4f	metrics for assessing flexibility and sustainability of next generation data centers	google;electronic mail;measurement;renewable energy sources;green products;energy consumption;measurement energy consumption electronic mail renewable energy sources green products optimization google;optimization;next generation data centers dc flexibility eu research projects dc optimization predictive optimization techniques dc design energy efficient data center;telecommunication power management computer centres energy conservation next generation networks optimisation	Recent advances in energy efficient data center (DC) design in combination with predictive optimization techniques have led to the emergence of DCs that are able to adapt their operation to their environment. Current approaches towards assessing the operational efficiency of the DCs are mostly static, disregarding the flexibility aspects of modern DCs, also failing to reflect the effects of DC optimization on their sustainability profile. In this context, eight EU research projects have joined forces to present new metrics allowing for the evaluation of DC flexibility as well as of the effects of DC optimization to their general operational efficiency. The present paper presents these metrics along with the verification methodologies employed for the evaluation of the obtained measurements and results.	data center;emergence;entity;failure;graphics device interface;machine learning;mathematical optimization;next-generation network;software-defined infrastructure;synergy	Alexis I. Aravanis;Artemis C. Voulkidis;Jaume Salom;Jacinta Townley;Vasiliki Georgiadou;Ariel Oleksiak;Milagros Rey Porto;Fabrice Roudet;Theodore B. Zahariadis	2015	2015 IEEE Globecom Workshops (GC Wkshps)	10.1109/GLOCOMW.2015.7414182	renewable energy;simulation;measurement		-27.680390650812495	62.12899900780506	69309
6e0a5cfd8ca4bd724e8bdd3ea481ea62678b97ff	reservation-based scheduling: if you're late don't blame us!	algorithms;design;distributed systems;scheduling;experimentation;measurement;performance	The continuous shift towards data-driven approaches to business, and a growing attention to improving return on investments (ROI) for cluster infrastructures is generating new challenges for big-data frameworks. Systems originally designed for big batch jobs now handle an increasingly complex mix of computations. Moreover, they are expected to guarantee stringent SLAs for production jobs and minimize latency for best-effort jobs.  In this paper, we introduce reservation-based scheduling, a new approach to this problem. We develop our solution around four key contributions: 1) we propose a reservation definition language (RDL) that allows users to declaratively reserve access to cluster resources, 2) we formalize planning of current and future cluster resources as a Mixed-Integer Linear Programming (MILP) problem, and propose scalable heuristics, 3) we adaptively distribute resources between production jobs and best-effort jobs, and 4) we integrate all of this in a scalable system named Rayon, that builds upon Hadoop / YARN.  We evaluate Rayon on a 256-node cluster against workloads derived from Microsoft, Yahoo!, Facebook, and Cloud-era's clusters. To enable practical use of Rayon, we open-sourced our implementation as part of Apache Hadoop 2.6.	apache hadoop;best-effort delivery;big data;computation;heuristic (computer science);integer programming;job stream;linear programming;region of interest;report definition language;scalability;schedule (project management);scheduling (computing)	Carlo Curino;Djellel Eddine Difallah;Chris Douglas;Subru Krishnan;Raghu Ramakrishnan;Sriram Rao	2014		10.1145/2670979.2670981	embedded system;real-time computing;simulation;telecommunications;engineering;operating system;computer network	OS	-22.018996994082542	63.05134826343467	69378
227fc62a50d5386346f177d967ae39bfaa61ed75	application of the border gateway protocol in the internet		"""This document, together with its companion document, \""""A Border Gateway Protocol 4 (BGP-4)\"""", define an inter-autonomous system routing protocol for the Internet. \""""A Border Gateway Protocol 4 (BGP-4)\"""" defines the BGP protocol specification, and this document describes the usage of the BGP in the Internet."""	border gateway protocol;internet	Jeffrey C. Honig;Dave Katz;Matt Mathis;Yakov Rekhter;Jie Yun Yu	1990	RFC	10.17487/RFC1164	world wide web;internet layer;hot standby router protocol;business;open shortest path first;internet protocol;h.248;border gateway protocol;default-free zone;computer network;internet protocol control protocol	Networks	-24.109790880522084	88.10006281319292	69382
3c1d3020917bdd5c046bc039b8772858883621f8	a kernel-level rtp for efficient support of multimedia service on embedded systems	internet protocol;distributed system;data transmission;streaming;systeme reparti;calculateur embarque;protocole transmission;performance test;protocolo internet;multimedia streaming;transmision continua;real time;orientado aspecto;video a la demande;protocole internet;interface programme application;service process;real time data;proceso servicio;protocole tcp;voice;delai transmission;embedded system;voz;transmission control protocol;transmission time;transport protocols;protocolo transmision;transmission en continu;sistema repartido;processus service;protocolo tcp;senal voceada;transmission donnee;application program interfaces;temps reel;video on demand;boarded computer;signal voise;code size;tiempo real;voiced signal;aspect oriented;real time transport protocol;plazo transmision;processing speed;multimedia services;calculador embarque;video a la carta;transmision datos;oriente aspect;voix;protocole transport;transmission protocol	Since the RTP is suitable for real-time data transmission in multimedia services like VoD, AoD, and VoIP, it has been adopted as a real-time transport protocol by RTSP, H.323, and SIP. Even though the RTP protocol stack for embedded systems has been in great need for efficient support of multimedia services, such a stack has not been developed yet. In this paper, we explain embeddedRTP which supports the RTP protocol stack at the kernel level so that it is suitable for embedded systems. Since embeddedRTP is designed to reside in the UDP module, existing applications which rely on TCP/IP services can be processed the same as before, while applications which rely on the RTP protocol stack can request RTP services through embeddedRTP ’s API. Our performance test shows that packet-processing speed of embeddedRTP is about 7.8 times faster than that of UCL RTP for multimedia streaming services on PDA in spite that its object code size is reduced about by 58% with respect to UCL RTP’s.	application programming interface;embedded system;internet protocol suite;kernel (operating system);network packet;object code;personal digital assistant;protocol stack;real-time clock;real-time data;real-time transcription	Dong Guk Sun;Sung-Jo Kim	2005		10.1007/11424857_9	internet protocol;embedded system;transmission time;real-time data;real-time computing;aspect-oriented programming;telecommunications;rtp control protocol;computer science;transmission control protocol;voice;transport layer;computer network;data transmission	Embedded	-5.764903710096584	73.24177020200281	69405
1cad7b34569c0b77aa7204969e1a395fb6adb0f0	a distributed proxy architecture for service discovery in peer-to-peer networks	distributed searches.;chord;service discovery;peer-to-peer;proxy	In this work we present a service discovery system that supports flexible queries using partial keywords and wildcards. It is built upon a Chord network and it guarantees that any existing data that match a query is found. The main feature of this service is to use a proxy server layer with a mechanism for data distribution that reduces the number of nodes involved in the searching process.	automatic identification and data capture;discovery system;fault tolerance;peer-to-peer;proxy server;server (computing);service discovery;wildcard character	Marcos Madruga;Thaís Vasconcelos Batista;Luiz Affonso Guedes	2005		10.1007/0-387-32015-6_19	distributed system security architecture;internet privacy;world wide web;computer network	OS	-19.36419598465654	72.43665179151914	69446
2fe4ab8857e9986333ebad97b1727fc680e74621	dqdb: an overload cycle analysis of generalized bandwidth balancing with strict priority	sistema fila espera;file attente;modelizacion;low priority;systeme attente;largeur bande;distributed queue dual bus;system structure;reachability;strict priority;multiaccess;automata estado finito;implementation;coaccion;contrainte;priorite;queue;modelisation;ejecucion;sharing;constraint;particion;structure systeme;high priority;asequibilidad;state space;queueing system;anchura banda;atteignabilite;bandwidth;finite automaton;automate fini;partage;overload;priority;dqdb;prioridad;modeling;bandwidth sharing;fila espera;finite state machine;reachability analysis;estructura sistema	"""This paper uses a state-space approach and an analysis of overload cycle constraints to show that a simple extension of Generalized Bandwidth Balancing (GBWB), can be used to strictly enforce non-premptive priorities. The extension associates a Bandwidth Balancing Machine and counter with each queue access machine rather than with the node in order to implement priorities. The entire DQDB network is modeled as a large Finite State machine. Overload cycles are those cycles in the state space that correspond to the situation that all nodes attempting to access the bus are attempting to do so continuously. Simple analytical constraints on the node counters allow derivation of the bandwidth sharing amongst the nodes and give insight into how the system structure results in such sharing. GBWB may be viewed as a mechanism that implements \rate-based"""" priorities that result in predictable apportioning of the bandwidth. In this paper, a system is presented that enforces \access-based"""" priorities where a single high priority node may prevent all access to the bus of low priority nodes."""	finite-state machine;state space	Michael J. Ferguson	1995	Perform. Eval.	10.1016/0166-5316(93)E0063-B	real-time computing;systems modeling;computer science;state space;distributed computing;distributed-queue dual-bus;finite-state machine;constraint;reachability;implementation;queue;bandwidth;computer network	Networks	-4.76981416381223	70.13241914054896	69518
0292c427979e946a697225b2507e5cef0def1779	cph-vod: a novel cdn-p2p-hybrid architecture based vod scheme	video streaming;p2p;large scale;content delivery;hybrid architecture;overlay network;streaming content delivery;cdn;p2p networks;vod;cdn p2p hybrid	Taking advantages of both CDN and P2P networks has been considered as a feasible solution for large-scale video stream delivering systems. Recent researches have shown great interested in CDN-P2P-hybrid architecture and ISP-friendly P2P content delivery. In this paper, we propose a novel VoD scheme based on CDN-P2P-hybrid architecture. First, we design a multi-layer CDN-P2P-hybrid overlay network architecture. Second, in order to provide a seamless connection for different layers, we propose a super-node mechanism, serving as connecting points. Third, as part of experiment works we discuss CPH-VoD implementation scheme based on peer node local RTSP server mechanism, including peer download/upload module, and their working processes. The experimental results show that VoD based on CDN-P2P-hybrid is superior to either pure CDN approach or pure P2P approach.	content delivery network	ZhiHui Lv;Jie Wu;Lijiang Chen;Sijia Huang;Yi Huang	2010		10.1007/978-3-642-17616-6_50	overlay network;computer science;peer-to-peer;database;internet privacy;world wide web;computer network	Vision	-16.731878327180315	74.518527861504	69562
9973bf646fa3f7f629c03da3dd59d2317c4d3478	a framework for planning a unified wired and wireless ict infrastructure	wireless access;access network;convergence;network planning;broadband network;ftth;large scale;information and communication technology;wimax;next generation networks	The increase in the use of information and communication technology (ICT) has pushed the existing access networks to their limits. Whole new access networks are currently being deplo yed and are expected to take full advantage of the already started sy nergy of services converging on to one network. Through a brief sur vey of synergy and technology trends, it is concluded that a futurenetwork will complementary use of wired and wireless technologies. In this context the paper proposes a framework for planning of unified wired and wireless ICT infrastructures. The framework includes different input parameters of relevance for the planning and implementation, which also include a step-wise implementation plan. Plannig methods for wired and wireless planning is presented and a simplifiedlargescale case study is conducted to verify and illustrate the us e of the framework. Keywords— Wireless Access, WiMAX, FTTH, Broadband Networks, Network Planning, ICT infrastructure, Modeling	access network;itil;mathematical optimization;penetration test;relevance;synergy	Tahir M. Riaz;Rasmus H. Nielsen;Jens Myrup Pedersen;Neeli R. Prasad;Ole Brun Madsen	2010	Wireless Personal Communications	10.1007/s11277-009-9720-5	wimax;information and communications technology;network planning and design;wireless wan;next-generation network;wireless site survey;convergence;fiber to the x;telecommunications;computer science;wireless network;municipal wireless network;network resource planning;wired communication;computer security;computer network;broadband networks;access network	Mobile	-15.559501428718487	87.51492990178446	69621
0f0e762b7a2753844c0b37cb80d3b97a2e719686	firmato: a novel firewall management toolkit	entity relationship model;cortafuego;packet filtering;securite informatique;reseau ordinateur;security management;firewall management;model definition language;computer network;computer security;network topology;pare feu reseau;visualization;seguridad informatica;computer network management;red informatica;security policy;management;gestion reseau ordinateur;firewall	In recent years packet-filtering firewalls have seen some impressive technological advances (e.g., stateful inspection, transparency, performance, etc.) and wide-spread deployment. In contrast, firewall and security <i>management</i> technology is lacking. In this paper we present <i>Firmato</i>, a firewall management toolkit, with the following distinguishing properties and components: (1) an entity-relationship model containing, in a unified form, global knowledge of the security policy and of the network topology; (2) a model definition language, which we use as an interface to define an instance of the entity-relationship model; (3) a model compiler, translating the global knowledge of the model into firewall-specific configuration files; and (4) a graphical firewall rule illustrator.  We implemented a prototype of our toolkit to work with several commercially available firewall products. This prototype was used to control an operational firewall for several months. We believe that our approach is an important step toward streamlining the process of configuring and managing firewalls, especially in complex, multi-firewall installations.	algorithm;assembly language;compiler;entity–relationship model;firewall (computing);graphical user interface;network topology;prototype;real life;security management;software deployment;stateful firewall	Yair Bartal;Alain J. Mayer;Kobbi Nissim;Avishai Wool	1999	ACM Trans. Comput. Syst.	10.1145/1035582.1035583	application firewall;firewall;security management;simulation;visualization;entity–relationship model;computer science;security policy;operating system;distributed computing;world wide web;computer security;network topology;context-based access control;computer network	Security	-22.371129426969954	85.50114359204403	69729
1fd04812a395eee2014048b0ce737b65f8752987	an elastic resource allocation algorithm enabling wireless network virtualization	orthogonal frequency division multiplexing access ofdma;resource allocation;wireless network virtualization;network isolation;qa75 electronic computers computer science;virtual mobile network operator	Following the wired network virtualization, virtualization of wireless networks becomes the next step aiming to provide network or infrastructure providers with the ability to manage and control their networks in a more dynamic fashion. The benefit of the wireless mobile network virtualization is a more agile business model where virtual mobile network operators MNOs can request and thus pay physical MNOs in a more pay-as-you-use manner. This paper presents some resource allocation algorithms for joint network virtualization and resource allocation of wireless networks. The overall algorithm involves the following two major processes: firstly, to virtualize a physical wireless network into multiple slices, each representing a virtual network, and secondly, to carry out physical resource allocation within each virtual network or slice. In particular, the paper adopts orthogonal frequency division multiplexing OFDM as its physical layer to achieve more efficient resource utilization. Therefore, the resource allocation is conducted in terms of sub-carriers. Although the motivation and algorithm design are based on IEEE 802.16 or WiMAX networks, the principle and algorithmic essence are also applicable to other OFDM access-based wireless networks. The aim was to achieve the following design goals: virtual network isolation and resource efficiency. The latter is measured in terms of network throughput and packet delivery ratio. The simulation results show that the aforementioned goals have been achieved. Copyright © 2012 John Wiley & Sons, Ltd.	algorithm	Xiaofeng Lu;Kun Yang;Yingting Liu;Dongdai Zhou;Shuhua Liu	2015	Wireless Communications and Mobile Computing	10.1002/wcm.2342	multi-frequency network;network allocation vector;real-time computing;virtualization;intelligent computer network;wireless wan;network architecture;heterogeneous network;telecommunications;bridging;resource allocation;computer science;radio resource management;operating system;wireless network;network simulation;distributed computing;municipal wireless network;network resource planning;wi-fi array;computer security;computer network	Mobile	-13.201276956144472	86.12638230148809	69798
68d65d8756ef78ac8a593d31da361ffc321a1268	improvements on performance of photonic packet switching nodes by priority assignment and buffer sharing	wdm;analytical models;telecommunication network management photonic switching systems packet switching probability wavelength division multiplexing optical wavelength conversion telecommunication traffic buffer storage;optical packet switching;photonic switching systems;shallow optical buffers depth;probability;optical transport network management;low packet loss probability;packet loss;performance;packet switching optical buffering optical losses wavelength division multiplexing optical wavelength conversion analytical models optical packet switching traffic control resource management optimization methods;resource management;optical buffers;buffer storage;traffic control;packet switched;packet switching;buffer sharing;telecommunication traffic;early discard mechanism;priority assignment;uncorrelated traffic;photonic packet switching nodes;optical wavelength conversion;management methodologies;wavelength conversion;optical losses;optical transport network management performance photonic packet switching nodes priority assignment buffer sharing low packet loss probability shallow optical buffers depth wavelength domain wdm wavelength conversion analytical models uncorrelated traffic optical buffers early discard mechanism management methodologies resource usage optimisation;analytical model;optical buffering;telecommunication network management;resource usage optimisation;wavelength domain;wavelength division multiplexing;optimization methods	Photonic packet switching faces a major challenge in providing low packet loss probability under the constraint of shallow optical buffers depth. Although improvements have been found by exploiting the wavelength domain through the use of WDM and wavelength conversion, performance enhancement by assigning priority to packets have yet to be investigated. This paper describes analytical models for the performance of photonic switching nodes under uncorrelated traffic dealing with packets having two different priorities. Nodes with and without optical buffers are considered. Buffer sharing among packets with different priorities backed by an early-discard mechanism is studied. Simple management methodologies are proposed for optimizing resources usage.	network switch;packet switching	Moisés R. N. Ribeiro;Mike J. O'Mahony	2000		10.1109/ICC.2000.853791	real-time computing;telecommunications;computer science;resource management;circuit switching;wavelength-division multiplexing;computer network	Networks	-5.602820379975721	85.64209253063254	69849
c48e58c1774ee20cfc444c10bd26a533b0a64dbb	smart mobile device power consumption measurement for video streaming in wireless environments: wifi vs. lte		The extreme growth in the amount of mobile video streaming data over the world puts significant pressure on power consumption of smart mobile devices. In order to obtain a precise energy consumption model for smart devices streaming video and especially energy consumption for streaming video at various quality levels and with different wireless technologies, an open-source power consumption measurement platform was developed for real-time multimedia content delivery. Using this platform, real life smart device power consumption measurements were performed for different quality video delivery over both WiFi and LTE. The results are expected to be used in research for energy-aware video delivery in heterogeneous wireless network environments.	arduino;compaq lte;digital distribution;java;mobile device;open-source software;real life;real-time clock;smart device;streaming media	Longhao Zou;Ali Javed;Gabriel-Miro Muntean	2017	2017 IEEE International Symposium on Broadband Multimedia Systems and Broadcasting (BMSB)	10.1109/BMSB.2017.7986151	smart device;real-time computing;computer network;computer science;wireless;embedded system;arduino;energy consumption;android (operating system);streaming data;heterogeneous wireless network;mobile device	Embedded	-18.961254174477766	75.49141061014411	69954
416b134a169a0b96b7b8b7d6cb4e7aed0f02457f	cost analysis of sdn/nfv architecture over 4g infrastructure		Abstract Two complementary architectures, software defined networking (SDN) and network function virtualization (NFV) are emerging to comprehensively address several networking issues. In this work, we introduce the most embraced virtualization concepts proposed by SDN and NFV architectures. We quantitatively evaluate hardware and energy cost savings with these two SDN and NFV architectures compared to the existing state-of-the-art network 4G hardware technologies.	network function virtualization;software-defined networking	Khaled Almustafa;Mamdouh Alenezi	2017		10.1016/j.procs.2017.08.328	virtualization;architecture;computer network;network functions virtualization;software-defined networking;computer science	Arch	-15.54579794440389	85.15811306184762	70013
79e39afc154aca15beca1e033d5ac4fb0bc3b4a5	is there a case for mobile phone content pre-staging?	mobile networks;content pre staging	"""Content caching is a fundamental building block of the Internet. Caches are widely deployed at network edges to improve performance for end-users, and to reduce load on web servers and the backbone network. Considering mobile 3G/4G networks, however, the bottleneck is at the access link, where bandwidth is shared among all mobile terminals. As such, per-user capacity cannot grow to cope with the traffic demand. Unfortunately, caching policies would not reduce the load on the wireless link which would have to carry multiple copies of the same object that is being downloaded by multiple mobile terminals sharing the same access link.  In this paper we investigate if it is worth to push the caching paradigm even farther. We hypothesize a system in which mobile terminals implement a local cache, where popular content can be pushed/pre-staged. This exploits the peculiar broadcast capability of the wireless channels to replicate content """"for free"""" on all terminals, saving the cost of transmitting multiple copies of those popular objects. Relying on a large data set collected from a European mobile carrier, we analyse the content popularity characteristics of mobile traffic, and quantify the benefit that the push-to-mobile system would produce. We found that content pre-staging, by proactively and periodically broadcasting """"bundles"""" of popular objects to devices, allows to both greatly i) improve users' performance and ii) reduce up to 20% (40%) the downloaded volume (number of requests) in optimistic scenarios with a bundle of 100 MB. However, some technical constraints and content characteristics could question the actual gain such system would reach in practice."""	cache (computing);call stack;disk staging;internet backbone;megabyte;mobile phone features;programming paradigm;self-replicating machine;transmitter;web server	Alessandro Finamore;Marco Mellia;Zafar Gilani;Konstantina Papagiannaki;Vijay Erramilli;Yan Grunenberger	2013		10.1145/2535372.2535414	real-time computing;mobile search;telecommunications;computer science;operating system;computer security;computer network	Mobile	-18.45539858161555	75.95977342776945	70056
b00e9c01d9ceef464fa1ee7f5860426b8b4c52a3	multi-controller collaborative interconnecting for multilayer heterogeneous sdon		With the rapid development of converged network technology, the network shows an obvious trend to be heterogeneous. In order to solve this problem, this paper proposes a multi-controller collaborative interconnection architecture for multilayer heterogeneous SDON (Software Defined Optical Network). And to enable this architecture, OpenFlow protocol is extended accordingly. Furthermore, the inter-domain path construction under the control of multiple controller is described to illustrate the collaborative interconnecting.	inter-domain;interconnection;network convergence;openflow;scalability;scheduling (computing);software-defined networking	Qinghai Ou;Jing Wang;Xiao Liao;Wenjing Li;Xiaolong Yang	2017	2017 International Conference on Computer, Information and Telecommunication Systems (CITS)	10.1109/CITS.2017.8035293	architecture;control theory;openflow;interconnection;software;computer network;network convergence;computer science;distributed computing;optical switch	Robotics	-16.30641088914112	83.11242187367961	70097
d3ffab30921da823d0875abbfc0e587ddc1c0fec	a multicast atm switch with slotted ring fabric	slotted ring atm switch architecture;delay performance;switching fabric;asynchronous transfer mode fabrics optical switches delay performance analysis b isdn bandwidth timing computer architecture equations;deterministic performance analysis equations;optical switches;performance metric;multicast atm switch;150 mbit s multicast atm switch slotted ring fabric slotted ring atm switch architecture optical fiber switch deterministic performance analysis equations switching fabric delay performance zero blocking performance;computer architecture;optical fiber switch;telecommunication channels asynchronous transfer mode optical switches delays;performance analysis;zero blocking performance;fabrics;b isdn;150 mbit s;bandwidth;telecommunication channels;optical fiber;asynchronous transfer mode;delays;slotted ring fabric;timing	This paper proposes a scalable, optical fiber, slotted ring ATM switch architecture. The internal switching fabric and transport mechanism is developed, a model formulated, and deterministic performance analysis equations derived. The delay and blocking performance metrics of a 16/spl times/16 switch with 150 Mbps links are given. It is shown that zero blocking performance can be achieved, as can delays as low as several bit times.	atm turbo;multicast	Robert R. Henry	1997		10.1109/ICCCN.1997.623358	crossover switch;real-time computing;telecommunications;computer science;optical fiber;asynchronous transfer mode;optical switch;bandwidth;computer network	Networks	-6.1746433324571495	86.94862639160978	70193
de5288990dc726f972926628d9d204d1735549da	a non-cooperative game-theoretic framework for resource allocation in network virtualization	game theory;virtual network embedding;nash equilibrium;resource allocation;network virtualization	Network virtualization is a new technology that aims at allowing multiple virtual networks (VNs) to coexist in the same equipment and to hide the heterogeneity of network infrastructure. The critical issue for a given infrastructure provider (InP), is how to provide customized and on demand resources for multiple service providers (SPs) with different Quality of Service (QoS) requirements. The should also fairly distribute the network physical resources, such as bandwidth of each physical link, buffer spaces, and processing cycles at each node. In this paper, we propose a new framework based on game theory, for both link and node dynamic allocation between multiple infrastructure providers (InPs) and service providers (SPs). Our approach focuses on provisioning and managing the physical resources in a virtualized network infrastructure. We propose a two-stage approach based on non-cooperative games. The first one is the resource negotiation game where the SP requests link and node resources from multiple InPs. The InP may reject the SP's request when it can potentially cause network congestion. The second stage of the proposal concerns dynamic resource provisioning and consists of two non cooperative games; the node allocation game and the link allocation game. The objective of both games is to allocate physical resources for different isolated VNs that are sharing the same physical substrate network. In the node allocation game, the proportional share mechanism is used. Every SP assigns a weight and submits a bid to each physical node and thereafter it receives a share proportional to its bid. In the link allocation game we investigate the case when multiple SPs compete for a portion of the available physical network capacity. Simulation results show that the proposed approach achieves high resource utilization, improves the network performance, and fairly distributes the link and node resources between multiple SPs.	game theory	Mohamed Said Seddiki;Mounir Frikha;Yeqiong Song	2016	Telecommunication Systems	10.1007/s11235-015-9995-7	game theory;simulation;resource allocation;computer science;distributed computing;computer security;nash equilibrium;computer network	ECom	-10.92500135602627	82.09505096787292	70198
16565f6535f90e12049f3a4e8e4616229b97ec23	effective generation of data broadcast schedules with different allocation numbers for multiple wireless channels	databases;time average;red sin hilo;data broadcast scheduling;wireless channels;canal multiple;probability;broadcast channel;reseau sans fil;allocation canal;processor scheduling;broadcast data;data items scheduling;access probability data broadcast scheduling allocation numbers data items scheduling multiple wireless broadcast channels data item assignment channel assignment data access time data item allocation;information technology;wireless network;asignacion canal;database;allocation numbers;base dato;mobile databases;weather forecasting;mobile computer;tiempo acceso;promedio temporal;consumer electronics;business communication;probabilistic approach;databases mobile computing;multiple channel;channel assignment problem;single channel;data item allocation;portable computers;scheduling;enfoque probabilista;approche probabiliste;wireless sensor networks broadcasting channel allocation probability scheduling;diffusion donnee;retard;mobile communication;difusion dato;base de donnees;data access;access probability;temps acces;data broadcast;broadcasting;multiple wireless broadcast channels;data access time;channel allocation;mobile computing;retraso;data item assignment;wireless sensor networks;multiple wireless channels;ordonnancement;data dissemination;reglamento;access time;channel assignment;moyenne temporelle;broadcasting delay mobile communication processor scheduling mobile computing portable computers weather forecasting information technology business communication consumer electronics	Existing methods of scheduling data items over multiple wireless broadcast channels focus on the assignment of a data item to a channel. However, data items are not allocated more than once per broadcast cycle to a single channel. Our scheme considers the numbers of copies of a data item that should be allocated in the context of the channel assignment problem and aims to reduce the average data access time by allocating a popular data item more than once per cycle to the channel to which it is assigned. The number of times that each data item is allocated reflects its access probability. Simulation results show that our scheme reduces the average expected delay, especially when there are few channels.	access time;assignment problem;broadcast domain;broadcasting (networking);data access;data item;scheduling (computing);simulation	Song-Yi Yi;Seunghoon Nam;Sungwon Jung	2008	IEEE Transactions on Knowledge and Data Engineering	10.1109/TKDE.2007.190736	data access;real-time computing;wireless sensor network;mobile telephony;weather forecasting;telecommunications;access time;mobile database;computer science;wireless network;probability;database;mobile computing;scheduling;broadcasting;dissemination;computer network	DB	-14.58583191302223	69.07269224579	70203
fe51bb0168b34d4897485d7fe4fa20a1003baec8	biased random walks on resource network graphs for load balancing	distributed system;estimacion sesgada;unfolding;systeme reparti;balancing resource;resource discovery;deploiement;reseau interconnecte;distribucion carga;resource allocation;equilibrio de carga;random sampling;complex network;resource management;heterogeneous environment;equilibrage charge;distributed computing;despliegue;supercomputer;sistema complejo;carga repartida;supercomputador;gestion recursos;large scale;sistema repartido;systeme complexe;complex system;random walk;muestreo aleatorio;decouverte connaissance;algorithme reparti;load balancing;network graphs load;distribution charge;autoorganizacion;gestion ressources;calculo repartido;charge repartie;descubrimiento conocimiento;self organization;load distribution;algoritmo repartido;load balance;asignacion recurso;marcha aleatoria;allocation ressource;discovery random walk;networked systems;red interconectada;echantillonnage aleatoire;distributed algorithm;interconnected power system;biased estimation;calcul reparti;estimation biaisee;marche aleatoire;autoorganisation;superordinateur;distributed load;knowledge discovery	The currently emerging large-scale complex networks and networks of networks are becoming apparent in the pervasive supply of seamless and transparent access to heterogeneous resources and services such as network domains, applications, services and storage owned by multiple organizations. The dynamics and heterogeneous environments involved, however, pose many challenges for controlling and balancing resource access, composition and deployment across complex grid and network infrastructures. In this paper, a scheme is proposed that gives a distributed load-balancing scheme by generating almost regular resource allocation networks. This network system is self-organized and depends only on local information for load distribution and resource discovery. The in-degree of each node refers to its free resources, and the job assignment and resource discovery processes required for load-balancing are accomplished by using fitted random sampling. Simulation results show that the generated network system provides an effective, scalable, and reliable load-balancing scheme for the distributed resources in grids and networks. The proposed solution is tested with real world data and the performance is tested against a recently reported distributed algorithm for load balancing.	brs/search;complex network;computation;degree distribution;directed graph;distributed algorithm;ecosystem;erdős–rényi model;flow network;job stream;load balancing (computing);monte carlo method;pervasive informatics;programming paradigm;sampling (signal processing);scalability;seamless3d;self-organization;simulation;software deployment;stationary process;steady state	Martin Randles;Osama Abu-Rahmeh;Princy Johnson;A. Taleb-Bendiab	2009	The Journal of Supercomputing	10.1007/s11227-009-0366-6	distributed algorithm;supercomputer;simulation;computer science;load balancing;resource management;distributed computing	HPC	-10.775769287570146	70.23811902352367	70245
93c1335ae26392b3b531a1ef58589c85df33fed3	resilient software defined networking for industrial control networks	protocols;packet loss;telecommunication network management computer centres industrial control software defined networking;datorsystem;computer systems;packet loss logic gates protocols monitoring process control;engineering and technology;teknik och teknologier;logic gates;monitoring;process control;datavetenskap datalogi;datavetenskap;control latency industrial control networks software defined networking sdn controller datacenter networking enterprise networks network management fast failover technologies per link bidirectional forwarding detection bfd packet duplication;computer science	Software Defined Networking (SDN) is currently a hot topic in the area of Datacenter Networking or Enterprise Networks as it has the promise to radically simplify network management and operation. However, it has not been considered so far as a promising candidate for Industrial Control Networks mainly because of the deterministic performance requirements and the dedicated design of those networks to fulfil strict performance guarantees. In this paper, we propose a resilient SDN based architecture for Industrial Control Networks and show that by combining several SDN based fast failover technologies using per-link Bidirectional Forwarding Detection (BFD), preconfigured primary and backup paths and flexible packet duplication orchestrated by an SDN controller, we can reduce significantly the control latency and provide more stringent performance guarantees even under lossy and failing links.	backup;binary file descriptor library;data center;display lag;failover;failure;lossy compression;network packet;requirement;software-defined networking	Jonathan Vestin;Andreas Kassler;Johan Åkerberg	2015	2015 10th International Conference on Information, Communications and Signal Processing (ICICS)	10.1109/ICICS.2015.7459981	communications protocol;real-time computing;logic gate;computer science;process control;distributed computing;packet loss;computer security;computer network	Embedded	-13.053026894235776	83.00466258476659	70315
841a3b6f2d51bea9f868af7255e70a96c321cd49	an efficient session_weight load balancing and scheduling methodology for high-quality telehealth care service based on webrtc	telehealth care;webrtc;big data;load balancing;scheduling;real-time streaming;eye tracking	In the modern life, humans are more interested in their health care; they usually go to the hospital for taking a treatment traditionally, for more convenience, a telecommunication and information technology, telemedicine provide clinical health care at a distance where physicians use email to communicate with patients, order drug prescriptions, and other health services. However, the system is of not much facility in the busy lives nowadays; hence a new telehealth system is recently developed to deliver health-related services and information with one of the most advanced telecommunications technology, WebRTC. Though, we still deal with many problems when the streaming data in some users become big, an existing network structure is susceptible to a large traffic with WebRTC and may cause overloading problems become big streaming data, where data transmits and concentrates on the specific server device in telehealth care service. Thus, we proposed an efficient Session_Weight load balancing and scheduling methodology to improve network performance for telehealth care service based on WebRTC. In this, we assign a weight session for each participant in the network, after that, we make a scheduling algorithm for distributing packages aiming to equalize the traffic network. Furthermore, we prove that our proposed methodology has a high-quality performance evaluation of telehealth care service, we also compare both kinds of technique, one is the original WebRTC technology, and another one is the existing WebRTC network with load balancing and scheduling network, which applied Session Weight.	algorithm;email;eye tracking;goto;load balancing (computing);network performance;operator overloading;performance evaluation;scheduling (computing);server (computing);stream (computing);streaming media;webrtc	Linh Van Ma;Jisue Kim;Sanghyun Park;Jinsul Kim;Jonghyeon Jang	2016	The Journal of Supercomputing	10.1007/s11227-016-1636-8	real-time computing;computer science;operating system;distributed computing;world wide web;computer security;computer network	HPC	-23.370225073389985	69.68405863446375	70322
20a8bc006b18306bfc14ed39e545cf1e28dfcb03	demonstration abstract: globally interconnected wsan testbeds	wireless sensor;wireless sensor networks actuators;interconnected testbeds communication networks computer architecture interconnection networks wireless sensor networks middleware technologies;testing wireless sensor networks actuators asia europe internet ip networks research and development research and development management software algorithms;communication networks;remote software updates;graphical interface;actuators;interconnection network;wireless sensor network;internet of things;computer architecture;research and development;ground penetrating radar;3g mobile communication;interconnected testbeds;logic gates;community networks;gwsan;remote software updates gwsan global wireless sensor actuator network asia europe internet of things web of things graphical interfaces;interconnection networks;middleware;global wireless sensor actuator network;europe;gsm;wireless sensor networks;graphical interfaces;asia;middleware technologies;web of things	This demonstrattion presents the ongoing development of a framework for a global wireless sensor / actuator network (GWSAN). This GWSAN is formed through the interconnection of about 10 WSAN testbeds currently mainly located in Asia and Europe. GWSANs are one of the enabler for the Internet of Things and thus the Web of Things. Similar to the beginning of the Internet in the late 70s this GWSAN is a research network. Topics of the joint research and development activities include management, maintenance and interoperability. Therefore algorithms and autonomous / automatic configuration mechanisms are implemented and tested as well as remote software updates in distributed WSANs. Furthermore, graphical interfaces for the management and the interaction with GWSAN are part of the development.	algorithm;autonomous robot;graphical user interface;interconnection;internet of things;interoperability;patch (computing);testbed;web of things;world wide web	Lasse Thiem;Gabriele Goldacker;Mario Schuster;Thomas Luckenbach;Byung Kyu Kim	2010	2010 8th IEEE International Conference on Pervasive Computing and Communications Workshops (PERCOM Workshops)	10.1109/PERCOMW.2010.5470532	embedded system;wireless sensor network;web of things;computer science;operating system;distributed computing;computer network	Robotics	-20.369268475809303	84.06187774120876	70337
a918020ec3857d7fcf905a43a578399061fdf75d	metrics for sustainable data centers		There are a multitude of metrics available to analyze individual key performance indicators of data centers. In order to predict growth or set effective goals, it is important to choose the correct metric and be aware of their expressivity and potential limitations. As cloud based services and the use of ICT infrastructure are growing globally, continuous monitoring and measuring of data center facilities are becoming essential to ensure effective and efficient operations. In this work, we explore the diverse metrics that are currently available to measure numerous data center infrastructure components. We propose a taxonomy of metrics based on core data center dimensions. Based on our observations, we argue for the design of new metrics considering factors such as age, location, and data center typology (e.g., co-location center), thus assisting in the strategic data center design and operations processes.	algorithm;automated planning and scheduling;biological anthropology;colocation centre;computer cooling;core data;data center;fits;itil;internet of things;numerical analysis;scheduling (computing);sensor;taxonomy (general);total cost of ownership	V. Dinesh Reddy;Brian Setz;G. Subrahmanya V. R. K. Rao;G. R. Gangadharan;Marco Aiello	2017	IEEE Transactions on Sustainable Computing	10.1109/TSUSC.2017.2701883	performance indicator;data center services;data mining;cloud computing;data center;server;information and communications technology;continuous monitoring;engineering;typology	Visualization	-27.831647657313642	62.08817242915487	70434
40c42edab50c34376383de880bb00c72b1ba09d8	semantic small world: an overlay network for peer-to-peer search	p2p system;high dimensionality;peer to peer computing costs scalability internet delay telecommunication traffic traffic control load management proposals indexing;dimension reduction;resource allocation;semantic networks;small world;resource allocation semantic networks peer to peer computing workstation clusters telecommunication traffic;telecommunication traffic;overlay network;self organization;load balancing property peer to peer search overlay network semantic small world semantic clustering dimension reduction adaptive space linearization;load balance;semantic space;workstation clusters;peer to peer computing;small world network;peer to peer	For a peer-to-peer (P2P) system holding massive amount of data, efficient semantic based search for resources (such as data or services) is a key determinant to its scalability. This work presents the design of an overlay network, namely semantic small world (SSW), that facilitates efficient semantic based search in P2P systems. SSW is based on three innovative ideas: 1) small world network; 2) semantic clustering; 3) dimension reduction. Peers in SSW are clustered according to the semantics of their local data and self-organized as a small world overlay network. To address the maintenance issue of high dimensional overlay networks, a dynamic dimension reduction method, called adaptive space linearization, is used to construct a one-dimensional SSW that supports operations in the high dimensional semantic space. SSW achieves a very competitive trade-off between the search latencies/traffic and maintenance overheads. Through extensive simulations, we show that SSW is much more scalable to very large network sizes and very large numbers of data objects compared to pSearch, the state-of-the-art semantic-based search technique for P2P systems. In addition, SSW is adaptive to distribution of data and locality of interest; is very resilient to failures; and has good load balancing property.	cluster analysis;dimensionality reduction;hoc (programming language);load balancing (computing);locality of reference;overhead (computing);overlay network;peer-to-peer;real life;routing;scalability;self-organization;simulation;software deployment;traverse	Mei Li;Wang-Chien Lee;Anand Sivasubramaniam	2004	Proceedings of the 12th IEEE International Conference on Network Protocols, 2004. ICNP 2004.	10.1109/ICNP.2004.1348113	self-organization;overlay network;resource allocation;computer science;load balancing;theoretical computer science;distributed computing;small-world network;semantic network;world wide web;dimensionality reduction;computer network	HPC	-12.367822855706585	73.25373664406345	70483
63988f1a083a468aac7ee54dbef9970585903b36	analysis of randomized join-the-shortest-queue (jsq) schemes in large heterogeneous processor-sharing systems	control systems;convergence;statistical distributions network servers processor scheduling queueing theory resource allocation;routing;job size distribution randomized join the shortest queue schemes large heterogeneous processor sharing systems randomized dynamic routing schemes parallel servers processor sharing server rates randomly sampled servers power of two scheme heterogeneous setting stability region static randomized schemes mean delay server speeds static randomized routing stationary distributions server occupancies tail distribution super exponential behavior mean field analysis;servers stability analysis asymptotic stability control systems load management convergence routing;asymptotic stability;servers;load management;stability analysis;insensitivity load balancing processor sharing power of two mean field approach asymptotic independence	In this paper, we investigate the stability and performance of randomized dynamic routing schemes for jobs based on the Join-the-Shortest Queue (JSQ) criterion in a heterogeneous system of many parallel servers. In particular, we consider servers that use processor sharing but with different server rates, and jobs are routed to the server with the smallest occupancy among a finite number of randomly sampled servers. We focus on the case of two servers that is often referred to as a Power-of-Two scheme. We first show that in the heterogeneous setting, uniform sampling of servers can cause a loss in the stability region and thus such randomized dynamic schemes need not outperform static randomized schemes in terms of mean delay in opposition to the homogeneous case of equal server speeds where the stability region is maximal and coincides with that of the static randomized routing. We explicitly characterize the stationary distributions of the server occupancies and show that the tail distribution of the server occupancy has a super-exponential behavior as in the homogeneous case as the number of servers goes to infinity. To overcome the stability issue, we show that it is possible to combine the static state-independent scheme with a randomized JSQ scheme that allows us to recover the maximal stability region combined with the benefits of JSQ, and such a scheme is preferable in terms of average delay. The techniques are based on a mean field analysis where we show that the stationary distributions coincide with those obtained under asymptotic independence of the servers and, moreover, the stationary distributions are insensitive to the job-size distribution.	job stream;maximal set;power of two;randomized algorithm;randomness;routing;sampling (signal processing);server (computing);stationary process;time complexity	Arpan Mukhopadhyay;Ravi Mazumdar	2016	IEEE Transactions on Control of Network Systems	10.1109/TCNS.2015.2428331	mathematical optimization;routing;von neumann stability analysis;real-time computing;convergence;computer science;control system;distributed computing;server;computer network	Metrics	-13.54161682142671	66.18381782637009	70512
d630f8b65aae145bfc5aca18c7a25eef8a6cd8ca	dimensioning of store-and-transfer wdm network with limited storage	routing;time division multiplexing data transfer delays wdm networks bandwidth routing;performance analysis large data transfer advance reservation wdm networks storage;bandwidth;wdm networks;time slot assignment wavelength store and transfer wdm network limited storage data transfers constrained delays load matrix common deadline common blocking integer matrix mutually prime elements dimensioning process stwn model tdm network m g 1 subsystems source destination pairs time slot assignment routing;time division multiplexing;wavelength division multiplexing matrix algebra telecommunication network routing time division multiplexing;data transfer;delays	For large data transfers, the Store-and-Transfer WDM Network (STWN) provides storage and lightpaths jointly. Constrained delays of the transfers restrict the number of waiting requests, thus the storage size can be limited. For dimensioning of STWN, we propose a method to determine the number of wavelengths and storage size required to satisfy the demand. The demand is given as a load matrix with a common deadline and blocking, then we express the load matrix as a base load multiplying an integer matrix consisting of mutually prime elements. The dimensioning process has two steps. 1) We model STWN as TDM network and analyse channels of the TDM system as M/G/1 subsystems. We calculate approximate performance of source-destination pairs and minimize the service rate provisioned for the demand with linear search to find the maximum allowed number of time-slots. 2) With the number of time-slots fixed, we optimize routing and wavelength and time-slot assignment to minimize the number of wavelengths required to accept the integer matrix. In step 1, the approximate performance calculated includes turnout, distribution of delay and storage size. Numerical results show how to drastically decrease the required resources.	approximation algorithm;blocking (computing);computer simulation;end-to-end principle;experimental system;linear search;routing;software-defined networking;toad data modeler;wavelength-division multiplexing	Da Feng;Weiqiang Sun;Peng Wu;Xiaojian Zhang;Junmin Wu;Weisheng Hu	2016	NOMS 2016 - 2016 IEEE/IFIP Network Operations and Management Symposium	10.1109/NOMS.2016.7502815	routing;telecommunications;computer science;distributed computing;bandwidth;time-division multiplexing;computer network	Metrics	-5.917105331821468	84.83368635538955	70622
a041876b6462d3617919419f6dd222997ae14233	a lossless, minimal latency protocol for gigabit atm networks	protocols;bandwidth reservation delay lossless minimal latency protocol gigabit atm networks very high speed networks asynchronous transfer mode delay cell loss buffer space instant start protocol;high speed networks;buffer storage;protocols asynchronous transfer mode very large scale integration high speed networks delay effects propagation delay bandwidth propagation losses process control hardware;atm networks;fiber optic;optical fibre networks;asynchronous transfer mode;buffer storage asynchronous transfer mode optical fibre networks protocols	Advances in ber-optic and VLSI technology have led to the emergence of very high-speed networks based on Asynchronous Transfer Mode (ATM). The time required to transmit the data into the network at the source is small compared to the delay to propagate the data from source to destination. Cell loss is also a major concern in ATM networks because waiting for the retransmission of lost cells delays the delivery of cells and requires substantial bu er space. The Instant Start protocol eliminates the costly bandwidth reservation delay before transmission can begin. Simultaneously, it provides lossless transmission even when the network cannot handle the o ered rate of transmission. Unlike other lossless protocols, Instant Start requires relatively little special control hardware or processing at each switch.	atm turbo;bandwidth (signal processing);cell (microprocessor);emergence;gigabit;interrupt latency;lossless compression;retransmission (data networks);very-large-scale integration;virtual circuit	Michael D. Santos;P. M. Melliar-Smith;Louise E. Moser	1998		10.1109/ICNP.1998.723735	communications protocol;real-time computing;computer science;atm adaptation layer;optical fiber;asynchronous transfer mode;distributed computing;computer network	Networks	-5.902501107906615	88.49224744869524	70720
4cd4c6f8bb4d7d9c8ddcb3d6dc6be0fd72ba1e0c	using sdn and nfv to implement satellite communication networks	prototypes delays low earth orbit satellites satellite communication virtual private networks control systems;virtualisation delay tolerant networks satellite communication software defined networking telecommunication scheduling telecommunication traffic;openflow sdn nfv space ground integrated multilayer satellite communication network software defined network traffic scheduling network function virtualization based service deployment method reconfigurable satellite service delivery flexible satellite service delivery delay tolerant network;satellite communication networks;network function virtualization satellite communication networks software defined network;software defined network;network function virtualization	Satellite communication system suffers inefficient and inflexible management and configuration due to the traditional system design. To address this issue, in this paper, we present a space-ground integrated multi-layer satellite communication network, based on Software Defined Network and Network Function Virtualization. The framework consists of a Software Defined Network based three-layer satellite network to provide effective traffic scheduling, and a Network Function Virtualization based service deployment method to provide flexible and reconfigurable satellite services delivery. Based on the proposed framework, we implement a prototype with help of Delay Tolerant Network and OpenFlow. Then, we design an experiment scenario and conduct experiments in the prototype to validate the feasibility of the proposed framework and the functionality of the prototype.	communications satellite;delay-tolerant networking;experiment;layer (electronics);multitier architecture;network function virtualization;openflow;prototype;scheduling (computing);software deployment;software-defined networking;systems design;telecommunications network	Taixin Li;Huachun Zhou;Hongbin Luo;Qi Xu;Yue Ye	2016	2016 International Conference on Networking and Network Applications (NaNA)	10.1109/NaNA.2016.22	embedded system;network functions virtualization;real-time computing;intelligent computer network;network architecture;broadcast communication network;global network;computer science;network simulation;software-defined networking;network operations center;law;computer network	Mobile	-12.51458479034823	85.11307295134455	70766
