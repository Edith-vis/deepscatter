id	title	keywords	abstract	entities	authors	year	journal	doi	fos	area	x	y	ix
2ed0cceccea8cbf828e487a21baea5ba71d4046b	prioritization and management of inter-enterprise collaborative performance	business environments;renewable energy sector;competition;performance status;performance management;collaborative enterprise;articulo;decision makers;collaboration;prioritization;inter enterprise;collaborative relationships;industry;analytic network process;decision making process;decision theory;collaborative performance;performance data;innovative approaches	Collaboration among enterprises has gained attention in the business environment as a means to remain competitive. Enterprises that are collaborating look for improving their performance but, in real assessments, they often do not establish efficient frameworks to structure and manage the enterprise association/inter-enterprise performance. This paper provides a methodology based on the Analytic Network Process (ANP) to prioritize and manage, within a performance management framework, inter-enterprise performance. In addition, this approach allows managing the evolution of the performance status by introducing a model for aggregating actual performance data so that decision makers can evaluate the status of the collaborative relationship and analyze the degree of achievement of the strategy. With this innovative approach, enterprises will obtain significant information for the decision-making process regarding which are the inter-enterprise performance elements that generate a higher impact and, therefore, should be prioritized for improving the enterprise competitiveness. This approach has been applied to a collaborative enterprise network belonging to the renewable energy sector in Spain where managers of the network have validated the results obtained as well as the benefits of the approach in supporting the decision making process. Highlights? We present a methodology to prioritize and manage collaborative relationships. ? It allows to aggregate actual performance data into a global evaluation. ? It focuses on analyzing the degree of achievement of the strategy. ? ANP is used to model and solve the problem. ? A case study is presented.		Maria Jose Verdecho;Juan José Alfaro Saiz;Raúl Rodríguez-Rodríguez	2012	Decision Support Systems	10.1016/j.dss.2011.12.011	decision-making;performance management;competition;decision theory;knowledge management;marketing;data mining;management science;management;analytic network process;collaboration	Metrics	-6.4833200490450436	-16.851825059594287	14338
9200192574d90101d529df3d87f847d7aac74769	algorithms for multidimensional partitioning of static files	databases;dynamic programming;file layout;organisation fichier;static files;programacion dinamica;base donnee;file organizations;range query;time measurement;database management systems;helium;heuristic method;interrogation base donnee;database;interrogacion base datos;base dato;size measurement;metodo heuristico;tiempo acceso;search attribute space;storage utilization;storage utilization database theory multidimensional partitioning static files multidimensional file partitioning search attribute space physical disk locations range queries file organizations static algorithm;size control;multidimensional partitioning;partitioning algorithms multidimensional systems databases heuristic algorithms frequency size measurement time measurement size control;particion;computer experiment;organizacion fichero;heuristic algorithms;static algorithm;programmation dynamique;multidimensional file partitioning;partition;temps acces;methode heuristique;physical disk locations;algoritmo optimo;frequency;algorithme optimal;optimal algorithm;file organisation database management systems database theory;database theory;database query;multidimensional systems;access time;range queries;partitioning algorithms;file organisation	Abstruct-The problem of multidimensional file partitioning (MDFP) arises in large databases that are subject to frequent range queries on one or more attributes. In an MDFP scheme, the search attribute space is partitioned into cells, which are mapped to physical disk locations. This mapping preserves the order of the search attribute values so that range queries can be answered most efficiently, while maintaining good performance for other types of queries. Recently, MDFP schemes have equal priority. In this work, we deal with only MDFP	database;range query (data structures)	Doron Rotem;Arie Segev	1988	IEEE Trans. Software Eng.	10.1109/32.9056	range query;computer science;theoretical computer science;operating system;data mining;database	DB	-27.057660124448265	3.941209040275088	14353
d0aa4f1a0a1633601e1270dba8a5e77b959088f1	hasp: a high-performance adaptive mobile security enhancement against malicious speech recognition		Nowadays, machine learning based Automatic Speech Recognition (ASR) technique has widely spread in smartphones, home devices, and public facilities. As convenient as this technology can be, a considerable security issue also raises – the users’ speech content might be exposed to malicious ASR monitoring and cause severe privacy leakage. In this work, we propose HASP – a highperformance security enhancement approach to solve this security issue on mobile devices. Leveraging ASR systems’ vulnerability to the adversarial examples, HASP is designed to cast human imperceptible adversarial noises to real-time speech and effectively perturb malicious ASR monitoring by increasing the Word Error Rate (WER). To enhance the practical performance on mobile devices, HASP is also optimized for effective adaptation to the human speech characteristics, environmental noises, and mobile computation scenarios. The experiments show that HASP can achieve optimal real-time security enhancement: it can lead an average WER of 84.55% for perturbing the malicious ASR monitoring, and the data processing speed is 15×∼ 40× faster compared to the state-of-theart methods. Moreover, HASP can effectively perturb various ASR systems, demonstrating a strong transferability.	automated system recovery;computation;experiment;houston automatic spooling priority;machine learning;mobile device;mobile security;perturbation theory;real-time clock;smartphone;spectral leakage;speech recognition;word error rate	Zirui Xu;Fuxun Yu;Chenchen Liu;Xiang Chen	2018	CoRR		computer security;speech characteristics;security enhancement;computation;word error rate;speech recognition;computer science;transferability;mobile device;data processing;vulnerability	Security	-15.550354128027635	-2.5833637107159078	14364
05cf131079ca8ffc1d0843a7eb21a879620e0f90	preference-based constrained optimization with cp-nets	constrained optimization;decision support;graphical models;autonomous agent;cp networks;optimization;preference;configuration;constraints;product configuration	Many artificial intelligence (AI) tasks, such as product configuration, decision support, and the construction of autonomous agents, involve a process of constrained optimization, that is, optimization of behavior or choices subject to given constraints. In this paper we present an approach for constrained optimization based on a set of hard constraints and a preference ordering represented using a CP-network—a graphical model for representing qualitative preference information. This approach offers both pragmatic and computational advantages. First, it provides a convenient and intuitive tool for specifying the problem, and in particular, the decision makeru0027s preferences. Second, it admits an algorithm for finding the most preferred feasible (Pareto-optimal) outcomes that has the following anytime property: the set of preferred feasible outcomes are enumerated without backtracking. In particular, the first feasible solution generated by this algorithm is Pareto optimal.	anytime algorithm;autonomous agent;autonomous robot;cp/m;computation;constrained optimization;constraint satisfaction;decision support system;goal programming;knowledge-based configuration;local consistency;mathematical optimization;pareto efficiency;precomputation;search algorithm;software propagation;time complexity;user (computing)	Craig Boutilier;Ronen I. Brafman;Carmel Domshlak;Holger H. Hoos;David Poole	2004	Computational Intelligence	10.1111/j.0824-7935.2004.00234.x	optimization problem;mathematical optimization;constrained optimization;computer science;artificial intelligence;autonomous agent;machine learning;graphical model;configuration	AI	-7.905269889894805	3.1507520884090314	14420
d542b70eb233168b64ffee1d48f905aa4beb712c	pictorial knowledge representation using pictorial semantic networks	semantic network;pictures;semantic;knowledge representation;network	"""Classifications of pictures and pictorial knowledge are presented. Pictorial knowledge is divided into three classes angular pictorial knowledge, side pictorial knowledge, and angular and side pictorial knowledge. A block diagram of these three pictorial knowledge classes and a pictorial knowledge transformation module is also presented with illustrative examples. Pictorial semantic networks which in terms of pictorial nodes, property nodes, """"is a"""" links, """"has property"""" links, and """"if and only if"""" links are introduced. Transitivity, generalization, specialization, inheritance hierarchy, and knowledge transformation properties are stated and illustrated by examples. Triangular, quadrangular, and polygonal knowledge representation using pictorial semantic networks are presented. The concepts of deducible property nodes are also presented with illustrative examples. Additional facts can be established from pictorial semantic networks. Thus, pictorial semantic networks are a useful way to represent pictorial knowledge in domains that use well-established taxonomies to simplify problem solving in pictorial information systems. Pictorial semantic networks offer what appears to be a fertile field for future study. The results may have useful applications in knowledge representation, expert systems, artificial intelligence, knowledge based systems, pictorial information systems and related areas."""	angularjs;artificial intelligence;diagram;expert system;image;information system;knowledge representation and reasoning;partial template specialization;problem solving;semantic network;taxonomy (general);vertex-transitive graph	Edward T. Lee	1988	Robotica	10.1017/S0263574700003970	natural language processing;knowledge representation and reasoning;computer vision;semantic similarity;semantic computing;multinet;computer science;artificial intelligence;social semantic web;semantic compression;semantic network;semantic technology;information retrieval	AI	-21.695115547290566	4.050253329651602	14423
3451719479ddc79f5c41dd9ce96ff6865afa3f4c	efficient indexing for past and current position of moving objects on road networks		The ever-increasing volume of trajectories of moving objects and the diversity of intelligent transportation systems and location-based services that rely on spatio-temporal data of moving objects highlight the need for more efficient indexing techniques. The state-of-the-art methods index moving objects at three time modes of past (historical data), present, and future. An integrated method called “PCI” was proposed (past current indexing) to index and store spatial-temporal data of the past and present simultaneously. The method can handle queries in both the time modes and it processes and generates both the past and present indices using an integrated set of processing resources. Two interconnected data structures were utilized to store indices of both the time modes. Connecting the index of different time modes enforces efficiency challenges due to difference in updating costs. Since the method stores the indices in the main memory, the way the structures are connected to each other makes it possible to transfer the current data to the section responsible for historical data. This method indexes them in the trajectory of moving objects at a minimum time expense. As the quality of data inevitably affects the performance of applications, map matching methods was used in PCI to remove noises—e.g., stationary state noises—in the data received from the moving objects. This feature adds to the accuracy and reliability of query results. The effects of data reduction techniques on accelerating indexing, query processing, and reducing memory consumption (in voluminous data sets) were examined. Results of the comparisons, made based on the experiments, showed the higher efficiency of the indexing structure.	computer data storage;data structure;experiment;linked list;location-based service;map matching;preprocessor;response time (technology);spatial database;stationary state;terabyte	Mohammad Reza Abbasifard;Hassan Naderi;Omid Isfahani Alamdari	2018	IEEE Transactions on Intelligent Transportation Systems	10.1109/TITS.2017.2762425	simulation;data reduction;information processing;engineering;data file;search engine indexing;intelligent transportation system;map matching;data structure;data set	DB	-26.93712042142277	0.4676549764895622	14425
c66ad909318bf1a4bbc245463dc476ece6371436	special acoustics area: the center of the malaga city (spain)		The definition as special acoustic area in the center of the city Malaga is determined by a study that looked at the results of the strategic noise map of the city, treating more than 20,000 complaints about noise pollution, noise monitoring established in the city and an exhaustive study of the different acoustic sources existing in the area. Diagnosed noise pollution need a specific zonal plan to achieve the objectives of acoustic quality. The present paper develops methodology of analysis applied with particular emphasis on quantifying noise sources leisure generated by the concentration of people in the street.	acoustic cryptanalysis	Fernando López Santos;David Carretero de la Rocha;Isabel Gimenez Anaya;Ricardo Hernández Molina	2016	Proc. Meetings on Acoustics	10.1121/2.0000520	environmental planning;action plan;noise map;cartography;noise pollution;acoustic area;geography;city centre	ML	-12.840328328034563	-23.423743487339806	14436
aabc03458a2f344aa591d65c859188eafbe74817	models of minimal physical intelligence	signaling;instability;intelligence;oil droplet;memory	The oil droplet is used as a simple model system to study the physical basis of intelligence. The oil droplet is a structure produced by self-assembly. By coupling a chemical re ction in the oil droplet with a physical instability, the dr oplet displays lifelike properties such as autonomous motility, sensor y-motor coupling, gradient following and agent-to-agent sig naling. By developing this system towards ICT capabilities tha t include information processing, -transmission and -transfor mation, data storage and production we explore the minimal physi cochemical basis of intelligence.	autonomous robot;computer data storage;gradient;information processing;instability;self-assembly;signature block	Martin M. Hanczyc;Filippo Caschera;Steen Rasmussen	2011		10.1016/j.procs.2011.09.058	intelligence;simulation;memory;oil droplet;instability	AI	-31.300013842822036	-17.272118609013138	14447
0b4311777df58323886d21083bcb7912fb30be3b	introducing cees: complex economic environments simulator	economic model;simulators;macroeconomics;complex systems	The combination of powerful computers and complex simulators allows us to accurately simulate the behavior of real system. This is specially important in the case of systems that cannot be manipulated, as the economic behavior of a society. CEES is a program that allows a user to simulate the behavior, both in the short and long-term, of an economy. Besides, users of the system can be part of the simulation by taking charge either of a company or of the State. Let us remark that, in contrast with most economic models, CEES takes into account a huge amount of variables (more than one thousand) in order to compute the current state of the economy.	automatic parallelization;computer simulation;e-commerce;emergence;high-level programming language;ibm research;swarm	Ismael Rodríguez;Manuel Núñez	2003		10.1007/3-540-44862-4_71	complex systems;simulation;computer science;artificial intelligence;economic model;management science	ECom	-24.711190647218608	-21.81096493360918	14475
27987315bf643841fb3056ac54bee88d91c65006	analysis of predictive spatio-temporal queries	moving object;nearest neighbor queries;computacion informatica;performance evaluation;database;data type;histogram;ciencias basicas y experimentales;nearest neighbor;spatio temporal;selectivity;nearest distance;grupo a;cost model	Given a set of objects <i>S</i>, a spatio-temporal <i>window query q</i> retrieves the objects of <i>S</i> that will intersect the window during the (future) interval <i>q</i><sub><i>T</i></sub>. A <i>nearest neighbor query q</i> retrieves the objects of <i>S</i> closest to <i>q</i> during <i>q</i><sub><i>T</i></sub>. Given a threshold <i>d</i>, a spatio-temporal <i>join</i> retrieves the pairs of objects from two datasets that will come within distance <i>d</i> from each other during <i>q</i><sub><i>T</i></sub>. In this article, we present probabilistic cost models that estimate the <i>selectivity</i> of spatio-temporal window queries and joins, and the <i>expected distance</i> between a query and its nearest neighbor(s). Our models capture any query/object mobility combination (moving queries, moving objects or both) and any data type (points and rectangles) in arbitrary dimensionality. In addition, we develop specialized spatio-temporal histograms, which take into account both location and velocity information, and can be incrementally maintained. Extensive performance evaluation verifies that the proposed techniques produce highly accurate estimation on both uniform and non-uniform data.	nearest neighbor search;performance evaluation;velocity (software development)	Yufei Tao;Jimeng Sun;Dimitris Papadias	2003	ACM Trans. Database Syst.	10.1145/958942.958943	r-tree;nearest neighbor graph;selectivity;data type;computer science;pattern recognition;data mining;database;histogram;nearest neighbor search;programming language;k-nearest neighbors algorithm	DB	-26.415558408457898	1.0056447374588346	14535
36c329bce68029c886f7839a4889b65a05d5be61	analysis and refinement of temporal relation aggregation		To obtain a complete temporal picture of a relation it is necessary to aggregate fragments of temporal information across relation instances in text. This process is non-trivial even for humans because temporal information can be imprecise and inconsistent, and systems face the additional challenge that each of their classifications is potentially false. Even a small amount of incorrect proposed temporal information about a relation can severely affect the resulting aggregate temporal knowledge. We motivate and evaluate three methods to modify temporal relation information prior to aggregation to address this challenge.	aggregate data	Taylor Cassidy;Heng Ji	2014			machine learning;data mining;algorithm	NLP	-19.221877861355974	2.4569229702742033	14624
299e1084d21cf9a42585fa5e2c7d35a96ca552cc	diagnosis of discrete-event systems from uncertain temporal observations	observation graphs;complex observations;continuous system;power transmission;power transmission networks;temporal observations;temporal constraints;discrete event system;discrete event systems;uncertain observations;diagnosis;communicating automata	Observations play a major role in diagnosis. The nature of an observation varies according to the class of the considered system. In static systems, an observation is the value of a variable at a single time point. In dynamic continuous systems, such a value is observed over a time interval. In discrete-event systems, an observation consists of a sequence of temporally ordered events. In any case, what is observed is assumed not to be ambiguous. This certainty principle, whilst being a useful simplification for a variety of contexts, may become inappropriate for a wide range of real systems, where the communication between the system and the observer is either bound to generate spurious messages, to randomly lose messages, or to lose temporal constraints among them. Consequently, the observation may be underconstrained. To cope with this uncertainty, a number of principles affecting both the observations and the modeled behavior of a system are introduced, that are independent of any specific processing technique. Furthermore, the notion of an uncertain temporal observation for discrete-event systems is introduced and accommodated within a graph whose nodes are labeled by uncertain messages, while edges define a partial temporal ordering among messages. This way, an uncertain observation implicitly defines a finite set of observations in the traditional sense. Thus, solving an uncertain diagnostic problem amounts to solving at one time several traditional diagnostic problems. The notion of an uncertain observation is further generalized to that of a complex observation. Both notions can be exploited by any diagnostic approach pertinent to discrete-event systems. Complex observations are contextualized in the framework of diagnosis of active systems and substantiated by a sample application in the domain of power transmission networks.  2002 Elsevier Science B.V. All rights reserved.	ambiguous grammar;randomness;relevance;temporal logic;text simplification;while	Gianfranco Lamperti;Marina Zanella	2002	Artif. Intell.	10.1016/S0004-3702(02)00123-6	simulation;power transmission;control theory;mathematics	AI	-17.02364613276012	0.05817169355203604	14656
d3e19d96b0176435f947e07dee8e07de31a4ff4f	building a community memory for intelligent tutoring systems	intelligent tutoring system	This article discusses the need for multiple experts to work together to develop knowledge representation systems for intelligent tutors. Three case studies are examined in which the need for a pragmatic approach to the problem of knowledge acquisition has become apparent. Example methodologies for building tools for the knowledge acquisition phase are described including specific tasks and criteria that might be used to transfer expertise from several experts to an intelligent tutoring system.		Beverly Park Woolf;Pat Cunningham	1987			natural language processing;intelligent decision support system;computer science;knowledge management;multimedia	Robotics	-30.927434476749166	-7.104273483020285	14679
d58e4935855697d83bb7e3c452895765faea4b3c	on taxonomic reasoning in conceptual design	task performance;representacion conocimientos;base donnee;conceptualization;concepcion sistema;semantica formal;sistema informatico;database;base dato;base connaissance;conceptual model;computer system;intelligence artificielle;formal semantics;classification;consistencia;semantique formelle;conceptualizacion;semantic model;data semantics;conceptual schema;conceptual design;specification donnee;lenguaje descripcion;system design;knowledge acquisition;consistance;especificacion datos;artificial intelligence;base conocimiento;systeme informatique;inteligencia artificial;information system;point of view;knowledge representation;automatic classification;representation connaissances;schema consistency;clasificacion;conceptualisation;consistency;conception systeme;systeme information;semantic models;langage description;data specification;minimalite;schema minimality;sistema informacion;description language;knowledge base;taxonomic reasoning	Taxonomic reasoning is a typical task performed by many AI knowledge representation systems. In this paper, the effectiveness of taxonomic reasoning techniques as an active support to knowledge acquisition and conceptual schema design is shown. The idea developed is that by extending conceptual models with defined concepts and giving them rigorous logic semantics, it is possible to infer isa relationships between concepts on the basis of their descriptions. From a theoretical point of view, this approach makes it possible to give a formal definition for consistency and minimality of a conceptual schema. From a pragmatic point of view it is possible to develop an active environment that allows automatic classification of a new concept in the right position of a given taxonomy, ensuring the consistency and minimality of a conceptual schema. A formalism that includes the data semantics of models giving prominence to type constructors (E/R, TAXIS, GALILEO) and algorithms for taxonomic inferences are presented: their soundness, completeness, and tractability properties are proved. Finally, an extended formalism and taxonomic inference algorithms for models giving prominence to attributes (FDM, IFO) are given.	algorithm;artificial intelligence;conceptual schema;finite difference method;knowledge acquisition;knowledge representation and reasoning;reasoning system;semantics (computer science);type constructor	Sonia Bergamaschi;Claudio Sartori	1992	ACM Trans. Database Syst.	10.1145/132271.132272	semantic data model;conceptualization;knowledge base;biological classification;computer science;conceptual schema;artificial intelligence;conceptual model;formal semantics;data mining;conceptual design;database;consistency;information system;algorithm;systems design	AI	-22.231828741160086	-1.0267292641476589	14684
7052374fe8c9abbf73136644eacf857b35a08280	bayesian approach to action selection and attention focusing. an application in autonomous robot programming. (approche bayésienne pour la sélection de l'action et la focalisation de l'attention. application à la programmation de robots autonomes)		Autonomous sensory-motor systems, situated in dynamic environments, must continuously answer the ultimate question: how to control motor commands knowing sensory inputs? Solving this question is a very complex problem, because a huge flow of information must be treated under several restrictions: real-time constraints, bounded memory space, and limited processing power. One additional and major challenge is to deal with incomplete and imprecise information, usually occurring in dynamic environments. In this thesis, we address the problem of controlling autonomous sensory-motor systems and propose a succession of cumulative hypotheses and simplifications. They are defined within a precise and strict mathematical framework, called Bayesian programming, an extension of Bayesian networks. This succession consists of five stages: • Internal states summarise the sensory-motor situation to simplify modelling and break the exponential degradation in performance because of dimensionality; • The first-order Markov assumption, stationarity and Bayes filters reduce time dependence without neglecting the influence of the past; • Partial independence between different domains of interest can be exploited to reduce further the dimensionality of the problem while preserving coherence in system decisions; • A behaviour selection mechanism expresses the global behaviour as composed of a repertoire of simple and independent motor patterns; • Attention focusing, guided by behaviour intention, reduces preprocessing time of incoming perception data. Each description of a stage is followed by its analysis according to memory requirement, processing complexity, and difficulty of modelling. Further discussions regarding robot programming and cognitive modelling points of view are also presented. Finally, we describe an implementation on a mobile robot. The results demonstrate that the proposed framework is adequate for practical purposes.		Carla Maria Chagas E. Cavalcante Koike	2005				AI	-23.85223551758749	-18.10784085986486	14724
aac5c11cf29366447c30cc58298a6ab382f515a8	a geometric examination of majorities based on difference in support	stochastic transitivity;reciprocal preferences;difference in support;geometry of voting;geometric voting	Reciprocal preferences have been introduced in the literature of social choice theory in order to deal with preference intensities. They allow individuals to show preference intensities in the unit interval among each pair of options. In this framework, majority based on difference in support can be used as a method of aggregation of individual preferences into a collective preference: option a is preferred to option b if the sum of the intensities for a exceeds the aggregated intensity of b in a threshold given by a real number located between 0 and the total number of voters. Based on a three dimensional geometric approach, we provide a geometric analysis of the non transitivity of the collective preference relations obtained by majority rule based on difference in support. This aspect is studied by assuming that each individual reciprocal preference satisfies a g-stochastic transitivity property, which is stronger than the usual notion of transitivity.	geometric analysis;linear algebra;rule 90;vertex-transitive graph	Richard Baron;Mostapha Diss;Eric Rémila;Philippe Solal	2015	Social Choice and Welfare	10.1007/s00355-015-0870-y	mathematics;mathematical economics;social psychology;welfare economics	AI	-7.6399169182620605	-2.21965430772418	14757
9eb8602e83b334fbbae1e6bcfa29416afad36bde	decision making and plan management by autonomous agents: theory, implementation and applications	autonomous agent	A generic architecture for autonomous agents is presented. In common with other current proposals the agent is capable of reacting to and reasoning about events which occur in its environment, executing actions and plans in order to achieve goals in the environment. In addition the agent can make decisions under uncertainty, including decisions about competing beliefs and alternative actions. The framework is grounded in a nonclassical decision model; this supports manymore capabilities than classical decision theory but under restricted conditions is compatible with it. The model is embodied in a well-de ned knowledge representation language, RL, which explicitly supports the central concepts of decisions and plans, and associated constructs of goals, arguments and commitments. The language provides a sound basis for building knowledge based agents for practical applications including safety-critical ones. This is illustrated with examples of medical applications.	automated theorem proving;autonomous agent;autonomous robot;decision theory;hoc (programming language);knowledge base;knowledge representation and reasoning;knowledge-based systems;norm (social);rl (complexity)	Subrata Kumar Das;John Fox;D. Elsdon;Peter Hammond	1997		10.1145/267658.267729	computer science;knowledge management;artificial intelligence;autonomous agent;management science	AI	-20.643592695597505	-9.182735751675976	14764
d433f1fb6e8d9af97f15e17d2616d4407b61eea4	intelligent technology for space and ground based monitoring of natural objects in cross-boder eu-russia territory	complex natural technical objects;cross boder eu russia territory complex natural technical objects technogenic accidents nuclear power stations hydroelectric power stations chemical production intelligent monitoring technology information technology decision making monitoring problems safety control st petersburg institute for informatics and automation russian academy of sciences riga technical university latvia ground based monitoring space based monitoring;intelligent information technology;information technology;information technology decision making geophysical equipment;aerospace data;monitoring;monitoring software real time systems process control computational modeling aerospace electronics information technology;geophysical equipment;complex natural technical objects monitoring intelligent information technology aerospace data	The comprehensive monitoring technology for complex natural-technical objects inducing high risk of technogenic accidents in the case of malfunction is considered. Nuclear power stations, hydroelectric power stations, chemical production, etc. are the afford examples of such objects. The new intelligent monitoring technology (IMT) developed is based on interdisciplinary methodology of creation and application of any information technology. Unlike existing systems, the IMT is universal, it includes the combined methods and algorithms of decision making in various classes of monitoring problems, forecasting and safety control of complex objects regardless to their appointment. The article presents the basic setup and expected results of joint work St. Petersburg Institute for Informatics and Automation of the Russian Academy of Sciences (Russia) and Riga Technical University (Latvia).	academy;algorithm;automation;informatics;interactive machine translation	Yuri Merkuryev;Mikhail Okhtilev;Boris V. Sokolov;Inese Trusina;Viacheslav A. Zelentsov	2012	2012 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2012.6350354	operations research;information technology	Robotics	-12.431141432031342	-20.303943543842646	14818
b63e5fcde3cc5ebb35da8d35c6d5e797ce559520	electricity market simulation: multiagent system approach	multiagent system;social welfare;software agent;agent based computational economics;market structure;electricity market;market design;complex system;agent based computational economic;market orientation;electricity market simulation;mechanism design;energy markets;multiagent systems	This paper suggests a multiagent system (MAS) approach for market simulation. This is achieved through analysis, modeling, implementation and simulation of artificial markets populated by software agents that represent economic self interested agents. Software agents are the constructs of a complex system, an artificial market that model a real existing market or an outline of a market design. The interest in simulating a market is multiple: exploiting existing market rules, searching for market design flaws and loopholes, and supporting decision making during a market mechanism design process. The main aim of the suggested approach is to analyze the behavior that emerges from the interaction of self interested agents acting in an artificial market.  AEMAS (Artificial Economy MultiAgent System), a multiagent system architecture inspired by the Market Oriented Programming (MOP) approach is defined. In different economical sectors, e.g. energy markets, there is no consensus about which structures lead to social welfare maximization outcomes. An approach to find adequate architectures allows different market structure instances to be created and simulated, to ease the design and analysis of alternative structures.  These alternatives can then be compared and potential design flaws eventually risen by simulation identified. Taking the electricity market as an example, two instances of the proposed architecture are presented, corresponding to the centralized dispatch arrangement common to non restructured markets, and the auction based pool, common to restructured markets.	agent-based model;centralized computing;complex system;dynamic dispatch;entropy maximization;exploit (computer security);multi-agent system;population;simulation;software agent;systems architecture	Isabell Walter;Fernando A. C. Gomide	2008		10.1145/1363686.1363695	mechanism design;complex systems;computer science;multi-agent system	AI	-19.226720946574126	-13.739633400905504	14870
e884f62489f8730368326b427f23d24ec3092c77	modeling social influence on activity-travel behaviors using artificial transportation systems	transportation behavioural sciences decision making demand forecasting;learning;social learning;activity choices;mathematical models;social networks;habitual choices activity travel behaviors artificial transportation systems travel demand forecasting travel demand management social interactions decision making behaviors social learning ats universal social interactions;期刊论文;social learning theory;computational modeling social network services sociology statistics roads;social networks activity travel behaviors artificial transportation systems atss social interactions social learning;travel behavior;social psychology;social interactions;activity travel behaviors;microsimulation;artificial transportation systems atss	A deep understanding of people's activity-travel behaviors is critical and essential for effective travel demand forecasting and management. Although it is acknowledged that social interactions play an important role in people's decision-making behaviors, our understanding of how they shape and impact activity-travel behaviors of people is still limited. Therefore, for the first time, this paper introduces social learning into artificial transportation systems (ATSs) to model their influence on activity-travel behaviors. Based on a specified ATS, three types of universal social interactions (i.e., imitation, conformity, and experience sharing on social networks) are modeled and studied. The results indicate that our models can make artificial agents learn to decide the best behavior, form habitual choices, and emerge fashion gradually.	ats;conformity;intelligent agent;interaction;social network	Songhang Chen;Zhong Liu;Dayong Shen	2015	IEEE Transactions on Intelligent Transportation Systems	10.1109/TITS.2014.2342279	social learning;simulation;mathematical model;travel behavior;social learning theory;social network	AI	-15.959850696287228	-15.875555075652946	14907
53a6a8bcd392da61376c2d668aafbd505d579cbd	social networks and interactions in cities	g geography general;market equilibrium;network centrality;nationalekonomi;urban land use;bonacich centrality;hb economic theory;he transportation and communications;social network;social networks;bl religion;spatial mismatch;economics;social distance	We examine how interaction choices depend on the interplay of social and physical distance, and show that agents who are more central in the social network, or are located closer to the geographic center of interaction, choose higher levels of interactions in equilibrium. As a result, the level of interactivity in the economy as a whole will rise with the density of links in the social network and with the degree to which agents are clustered in physical space. When agents can choose geographic locations, there is a tendency for those who are more central in the social network to locate closer to the interaction center, leading to a form of endogenous geographic separation based on social distance. We also show that the market equilibrium is not optimal because of social externalities. We determine the value of the subsidy to interactions that could support the first-best allocation as an equilibrium. Finally, we interpret our model in terms of labor-market networks and show that the lack of good job contacts would be here a structural consequence of the social isolation of inner-city neighborhoods. © 2013 Elsevier Inc. All rights reserved. JEL classification: D85; R14; Z13	cluster analysis;interaction;interactivity;social network	Robert W. Helsley;Yves Zenou	2014	J. Economic Theory	10.1016/j.jet.2013.09.009	social entropy;economics;dynamic network analysis;social heuristics;socioeconomics;microeconomics;welfare economics;social network	ECom	-13.948258751964289	-15.236832478793328	14946
9461d7f99ab52641770a8c1d021190c6c29819d0	application of parallelized analogical planning to engineering design	analogical reasoning;domain theory;engineering design;parallel algorithm;automatic programming;machine learning;theoretical analysis;parallel architecture	Analogical planning provides a means of solving engineering problems where other machine learning methods fail. Unlike many machine learning paradigms, analogy does not require numerous previous examples or a rich domain theory. Instead, analogical reasoning utilizes knowledge of solved problems in similar domains, adapting the knowledge to the current problem. Unfortunately, the analogical planning task is an expensive one. While the process of forming correspondences between a known and a new problem is complex, the problem of selecting a base case for the analogy is virtually intractable.  This paper addresses the issue of efficiently forming analogical plans. The ANAGRAM planning system is described, which takes advantage of the massively parallel architecture of the Connection Machine to perform base selection and map formation. This approach makes analogical planning a tractable task, in fact sublinear in the size of the plans.  This paper describes the ANAGRAM system and its parallel algorithms. The paper also presents a theoretical analysis and empirical results of testing the system on a large database of plans from the domain of automatic programming.	engineering design process;parallel computing	Diane J. Cook	1990		10.1145/98894.99100	computer science;artificial intelligence;machine learning;domain theory;parallel algorithm;algorithm;engineering design process	HCI	-21.05568536944845	-6.055468159038225	14951
85351789578e02f5d2fc18e0d7bb183422e6163c	theory of cooperation in complex social networks	evolution of cooperation;agreement dynamics;graph laplacian	This paper presents a theoretical as well as empirical study on the evolution of cooperation on complex social networks, following the continuous action iterated prisoner’s dilemma (CAIPD) model. In particular, convergence to network-wide agreement is proven for both evolutionary networks with fixed interaction dynamics, as well as for coevolutionary networks where these dynamics change over time. Moreover, an extension to the CAIPD model is proposed that allows to model influence on the evolution of cooperation in social networks. As such, this work contributes to a better understanding of behavioral change on social networks, and provides a first step towards their active control. Introduction Modelling the evolution of cooperation in social networks has recently attracted much attention, aiming to understand how individuals work together and influence each other, and how society as a whole evolves over time (Nowak and May 1992; Santos and Pacheco 2005; Ohtsuki et al. 2006; Lazer et al. 2009; Hofmann, Chakraborty, and Sycara 2011). Progress made towards understanding how this evolution comes about has been mostly empirical in nature. Though compelling, deeper insights are better gained from an analytical analysis of the problem. Meanwhile, the control theory community has developed strong theories for dealing with various types of multiagent systems. Although many of these theories were initially developed for the analysis of artificial networks such as series of chemical reactors, electrical circuits or robotic swarms (Rosenbrock 1963; Jadbabaie, Lin, and Morse 2003; Ren, Beard, and McLain 2005), they can be extended to the analysis of social networks as well. For instance, OlfatiSaber (2005) uses properties of the Laplacian matrix, a typical tool in the control community for analysis of multi-agent systems, to analyze the information flow in small world networks. Additionally, Liu, Slotine, and Barabási (2011) study controllability, focussing on so-called driving nodes that need to be controlled in various complex networks. Summers and Shames (2013) use theory of nonlinear dynamical systems for modeling and influencing behaviors in specific social networks. Copyright © 2014, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. Recently a formal model for understanding the evolution of cooperation in arbitrary social networks has been proposed by Ranjbar-Sahraei et al. (2014). The authors introduce the continuous action iterated prisoner’s dilemma (CAIPD) as a general framework for modelling the behavior of individuals in complex networks. Moreover, they show that CAIPD is better able to capture the nature of cooperation in arbitrary networks than existing models. Due to its generalization capabilities and broad spectrum of applications, this paper adopts CAIPD as the formal framework on which an in-depth analytical study is conducted. Aiming at a broader theoretical understanding of the evolution of cooperation, this paper provides a formal analysis of agreement among individuals in complex social networks, following the CAIPD model. A set of theorems are presented and empirically validated, proving convergence to a final agreement in (co)evolutionary social networks. Additionally, the CAIPD model is extended to allow for the influence on final agreements in such type of networks. In particular, multi-rate adaptation is discussed. It is shown both theoretically and empirically that individuals with the slowest adaptation rates ultimately determine the final agreement. Finally, state-reference tracking is discussed as a special case of the proposed control extension, showing how a varying reference signal can be incorporated to guide the network to any level of agreement. Background Continuous-Action Iterated Prisoner’s Dilemma CAIPD (Ranjbar-Sahraei et al. 2014) is adopted for describing the evolution of cooperation in arbitrary complex networks. In CAIPD, N individuals are positioned on a vertices vi ∈ V for i = 1, 2, . . . , N of a weighted graph G = (V,W). The symmetrically weighted N × N adjacency matrix W = [wij ], with wij ∈ {0, 1}, describes the i to j individual connections with all wii = 0. One of the advantages of CAIPD over other models is the continuous nature in which cooperation and defection levels are modelled. To this end, Ranjbar-Sahraei et al. introduce xi ∈ [0, 1] to represent the cooperation level of each individual i, where xi = 0 corresponds to pure defection while xi = 1 represents pure cooperation; an individual pays a cost cxi while the opponent receives a benefit bxi, with b > c. This way a defector (i.e., xi = 0) pays no cost and distributes no benefits. Accordingly, the fitness of individual Proceedings of the Twenty-Eighth AAAI Conference on Artificial Intelligence	adjacency matrix;agent-based model;artificial intelligence;complex network;control theory;dynamical system;information flow (information theory);iterated function;iteration;katia sycara;laplacian matrix;mathematical model;multi-agent system;nonlinear system;prisoner's dilemma;robot;social network;the evolution of cooperation;wii;word lists by frequency	Bijan Ranjbar Sahraei;Haitham Bou-Ammar;Daan Bloembergen;Karl Tuyls;Gerhard Weiss	2014			laplacian matrix;artificial intelligence;complex network	AI	-14.708511890739135	-16.4015576858269	14955
9ef3f07bad7aad52aad45fc045d2aa8d297cdafe	towards more data-aware application integration (extended version)		Although most business application data is stored in relational databases, programming languages and wire formats in integration middleware systems are not table-centric. Due to costly format conversions, data-shipments and faster computation, the trend is to “push-down” the integration operations closer to the storage representation. We address the alternative case of defining declarative, table-centric integration semantics within standard integration systems. For that, we replace the current operator implementations for the well-known Enterprise Integration Patterns by equivalent “in-memory” table processing, and show a practical realization in a conventional integration system for a non-reliable, “data-intensive” messaging example. The results of the runtime analysis show that table-centric processing is promising already in standard, “single-record” message routing and transformations, and can potentially excel the message throughput for “multi-record” table messages.	analysis of algorithms;business software;computation;data-intensive computing;declarative programming;enterprise integration patterns: designing, building, and deploying messaging solutions;in-memory database;middleware;programming language;relational database;routing;throughput;whole earth 'lectronic link	Daniel Ritter	2015	CoRR		real-time computing;obstack;computer science;theoretical computer science;data mining;database;virtual synchrony;programming language	DB	-32.480665161546156	2.1887400873603124	14970
4069836129a1a18208a570c143294f6245d75090	integrated process of uncertainty characterization for 4d seismic value of information studies			information science	Marcos Sebastião dos Santos	2015				HCI	-31.043527426612727	-9.951712648180449	14976
d8311981a80f1d8a16f12addad62c5f47d4feb49	supporting preference elicitation : the faw preference elicitation tool	multi criteria decision making;user modeling;preference elicitation;linear programming;human machine interaction	The integration of decision analysis and expert system technology has not yet been sufficiently accomplished. For instance, knowledge-based systems often lack sophisticated abilities with respect to explicitly formulating needs of users, e.g. preference modelling. The approach presented has a broad range of applications but is aimed particularly at those in which the user's objective is not easily identified. Applications for machine scheduling and environmental risk assessment are outlined. We describe how identifying and continuously updating user preferences can be formally established.	decision analysis;expert system;knowledge-based systems;preference elicitation;risk assessment;scheduling (computing);user (computing)	Thomas Kämpke;Franz Josef Radermacher;Peter Wolf	1993	Decision Support Systems	10.1016/0167-9236(93)90048-8	preference learning;user modeling;expert elicitation;computer science;knowledge management;linear programming;data mining	AI	-7.726453569633751	-12.964850895179017	14998
5b8e0bd8e9ab9767c837daa042f8f94e3571b522	automated physical modeling	physical model	The creation of abstract models of physical systems is an important AI research area. I describe a program which can automatically construct such models for machines like mechanical clocks or watches. The program finds an appropriate set of state variables and determines how they change as time passes. The abstract model of the mechanical device may be used to numerically simulate its behavior. My program uses short, controlled simulations to identify repet itive behavior patterns which can be used for long-term behavior prediction. 1 Introduction Reasoning about physical systems generally involves the creation and manipulation of abstract models, normally constructed by the person studying the system. 1 will discuss the automatic generation of such models, as well as their manipulation and analysis. The physical systems I will focus on are mechanical devices. An abstract model of a physical system is usually based on a set of state variables. A set of particular values for the state variables represents a particular state of the system. The model must also include a description how the state variables are related and how they change. The values taken by state variables may be either numerical quantities or qualitative symbols. The abstract models used in engineering and the physical sciences normally use state variables which take numerical values. Much of the work by artificial intelligence researchers on reasoning about physical systems has focused on models in which state variables take only qualitative values. Qualitative models of physical systems are often useful for reasoning in situations where the information available about the system is limited or imprecise. However, many physical systems cannot be adequately represented by qualitative models. Geometry is especially difficult to deal with qualitatively. Geometry plays a central role in the behavior of mechanical devices, so they cannot be described by purely qualitative models, although work has been done with mixed quantitative/qualitative models for such machines. In this paper I will focus on models with numerical state variables. It is often assumed that such quantitative models are not relevant to artificial intelligence because 1. We already know how to use quantitative models. Open problems are highly technical and of interest only to mathematicians. 2. The analysis of quantitative models doesn't yield results at the level needed for artificial intelligence. 3. People reason about physical situations qualitatively. In fact, quantitative models are quite worthy of consideration by AI researchers. Let us consider the objections listed …	artificial intelligence;causal filter;causal model;computation;computational resource;computer simulation;information;mathematical model;numerical analysis;sensor;smartwatch;uml state machine;verification and validation	Andrew Gelsey	1989			physical model;computer science	AI	-30.675568752783118	-13.700608666230522	15027
d4afc4e705904dc535e9d9c2fcca22c832e3a1b5	peerappear: a location-aware framework for extensible image annotation and peer-to-peer discovery	collaboration;data mining;indexes;navigation;visualization;peer to peer computing	This paper addresses the problem of building and maintaining image repositories which form the basis for world-scale visual models. The availability of these models enable capabilities such as visual localization, persistent surveillance, and structure from motion. We approach this problem through the creation of PeerAppear, a location-aware framework for extensible image annotation and peer-to-peer dissemination. Due to the dynamic nature of the world, solutions to this problem generally require significant effort to be spent on mapping. PeerAppear enables a decentralized solution through the implementation of a peer-to-peer middleware framework which automates the indexing and sharing of visual information extracted from images in a user's collection. The PeerAppear network achieves scale through a Bittorrent style overlay network, which indexes the locations of user's image collections using a hierarchical geographic segmentation scheme in a distributed hash table. By enabling a distributed and collaborative solution, network participants are able to provide for frequent remapping and a search capability which leverages efficient and effective visual representations. The framework was implemented in Python and evaluated using Raspberry Pi computers for data collection and a workstation computer to simulate network participants. This evaluation showed that the framework was able to provide an effective image search capability and shows promise for large-scale operations.	automatic image annotation;bittorrent;centralized computing;computer;dspace;distributed hash table;extensibility;image retrieval;information discovery;location awareness;middleware;modal logic;overlay network;peer-to-peer;peering;python;raspberry pi 3 model b (latest version);simulation;single point of failure;structure from motion;workstation	Andrew Compton;John M. Pecarina;Noah Lesch	2016	2016 International Conference on Collaboration Technologies and Systems (CTS)	10.1109/CTS.2016.0053	database index;navigation;visualization;computer science;operating system;data mining;database;management;world wide web;computer security;collaboration	Visualization	-29.812836382532513	-1.566846768321444	15042
b2334fdd191ee90cda750e2a61ae48f3c90196bc	downstream effects of affirmative action		We study a two-stage model, in which students are 1) admitted to college on the basis of an entrance exam which is a noisy signal about their qualifications (type), and then 2) those students who were admitted to college can be hired by an employer as a function of their college grades, which are an independently drawn noisy signal of their type. Students are drawn from one of two populations, which might have different type distributions. We assume that the employer at the end of the pipeline is rational, in the sense that it computes a posterior distribution on student type conditional on all information that it has available (college admissions, grades, and group membership), and makes a decision based on posterior expectation. We then study what kinds of fairness goals can be achieved by the college by setting its admissions rule and grading policy. For example, the college might have the goal of guaranteeing equal opportunity across populations: that the probability of passing through the pipeline and being hired by the employer should be independent of group membership, conditioned on type. Alternately, the college might have the goal of incentivizing the employer to have a group blind hiring rule. We show that both goals can be achieved when the college does not report grades. On the other hand, we show that under reasonable conditions, these goals are impossible to achieve even in isolation when the college uses an (even minimally) informative grading policy.	downstream (software development);fairness measure;information;pipeline (computing);population	Sampath Kannan;Aaron Roth;Juba Ziani	2019	CoRR	10.1145/3287560.3287578	mathematics;mathematical economics;grading (education);posterior probability;welfare economics;affirmative action	ML	-6.411090214642059	-4.582428365815093	15068
9b7d57267f0083d5bc1e14d3286d4f5eb0bba47a	component reliability importance assessment on complex systems using credible improvement potential		Article history: Received 27 June 2016 Accepted 7 July 2016 Available online xxxx Nowadays system reliability performance represents a key issue and being reliable becomes a fundamental requirement of products in many manufacturing fields. The paper is focused on the reliability improvement of fault tolerant complex systems using component Reliability Importance (RI) procedures in order to assess the impact of each component on the overall system reliability. This study is focused on RI assessment during design stage with the aim of optimizing engineers' efforts and focusing on components with the greatest effect on the whole system. The first part of the paper focuses on a particular Reliability Importancemeasure, the Credible Improvement Potential (CIP), which is the most suitable RI metric for our purpose. The Reliability Importance assessment on a dedicated case study based on fault tolerant complex system is then proposed and results are discussed in detail. © 2016 Elsevier Ltd. All rights reserved.	complex system;complex systems;failure cause;fault tolerance;rs-232;reliability block diagram;software engineer	Marcantonio Catelani;Lorenzo Ciani;Matteo Venzi	2016	Microelectronics Reliability	10.1016/j.microrel.2016.07.055	reliability engineering;engineering;forensic engineering	SE	-9.058171052258013	-15.147291606865737	15155
9474c3cc6a8b8bb374519dfefb9f463035dcedef	a note on the paradox of smaller coalitions	game theory;generic model;top coalition property;satisfiability;coalition formation;core;simple games;paradox of smaller coalitions;social choice;simple game	We consider hedonic coalition formation games that are induced by a simple TUgame and a cooperative solution. For such models, Shenoy’s (1979) absence of the paradox of smaller coalitions provides a sufficient condition for core existence. We present three different versions of his condition in order to compare it to the top coalition property of Banerjee et al. (2001) that guarantees nonemptiness of the core in more general models. As it turns out, the top coalition property implies a condition in which Shenoy’s paradox is not present for at least one minimal winning coalition. Conversely, if for each non-null player Shenoy’s paradox is not present for at least one minimal winning coalition containing that player, then the induced hedonic game satisfies the top coalition property. JEL Classification: D72, C71		Dinko Dimitrov;Claus-Jochen Haake	2008	Social Choice and Welfare	10.1007/s00355-007-0266-8	game theory;core;social choice theory;economics;public economics;mathematics;core;microeconomics;mathematical economics;welfare economics;satisfiability	AI	-5.918725361680244	-1.399822835870527	15230
090fdf0052df9145c7c21a5a16bb7247afce8bf7	a unified strategy for implementing curiosity and empowerment driven reinforcement learning		Although there are many approaches to implement intrinsically motivated artificial agents, the combined usage of multiple intrinsic drives remains still a relatively unexplored research area. Specifically, we hypothesize that a mechanism capable of quantifying and controlling the evolution of the information flow between the agent and the environment could be the fundamental component for implementing a higher degree of autonomy into artificial intelligent agents. This paper propose a unified strategy for implementing two semantically orthogonal intrinsic motivations: curiosity and empowerment. Curiosity reward informs the agent about the relevance of a recent agent action, whereas empowerment is implemented as the opposite information flow from the agent to the environment that quantifies the agent’s potential of controlling its own future. We show that an additional homeostatic drive is derived from the curiosity reward, which generalizes and enhances the information gain of a classical curious/heterostatic reinforcement learning agent. We show how a shared internal model by curiosity and empowerment facilitates a more efficient training of the empowerment function. Finally, we discuss future directions for further leveraging the interplay between these two intrinsic rewards.	autonomy;homeostasis;information gain in decision trees;institute for operations research and the management sciences;intelligent agent;kullback–leibler divergence;reinforcement learning;relevance	Ildefons Magrans de Abril;Ryota Kanai	2018	CoRR		computer science;instrumental and intrinsic value;artificial intelligence;curiosity;machine learning;knowledge management;reinforcement learning;autonomy;empowerment	AI	-21.30317822274889	-14.304822975420745	15299
6089675fcd3a3929f7c6a5184ee4397a0daeff34	heterophilious dynamics enhances consensus	clusters;consensus;active sets;kinetic equations;connectivity of graphs;self alignment;heterophilious dynamics;74a25;mean field limits;92d25;agent based models;hydrodynamics;76n10;flocking	We review a general class of models for self-organized dynamics based on alignment. The dynamics of such systems is governed solely by interactions among individuals or “agents,” with the tendency to adjust to their “environmental averages.” This, in turn, leads to the formation of clusters, e.g., colonies of ants, flocks of birds, parties of people, rendezvous in mobile networks, etc. A natural question which arises in this context is to ask when and how clusters emerge through the self-alignment of agents, and what types of “rules of engagement” influence the formation of such clusters. Of particular interest to us are cases in which the self-organized behavior tends to concentrate into one cluster, reflecting a consensus of opinions, flocking of birds, fish, or cells, rendezvous of mobile agents, and, in general, concentration of other traits intrinsic to the dynamics. Many standard models for self-organized dynamics in social, biological, and physical sciences assume that the intensity of alignment increases as agents get closer, reflecting a common tendency to align with those who think or act alike. Moreover, “similarity breeds connection” reflects our intuition that increasing the intensity of alignment as the difference of positions decreases is more likely to lead to a consensus. We argue here that the converse is true: when the dynamics is driven by local interactions, it is more likely to approach a consensus when the interactions among agents increase as a function of their difference in position. Heterophily, the tendency to bond more with those who are different rather than with those who are similar, plays a decisive role in the process of clustering. We point out that the number of clusters in heterophilious dynamics decreases as the heterophily dependence among agents increases. In particular, sufficiently strong heterophilious interactions enhance consensus.	align (company);cluster analysis;consensus (computer science);flocking (behavior);interaction;mobile agent;self-organization	Sébastien Motsch;Eitan Tadmor	2014	SIAM Review	10.1137/120901866	consensus;flocking;fluid dynamics	AI	-14.7303154935807	-15.623323672274362	15316
4aebda757b884c459fb8b7c10f0b0775404f12c2	generating coherence relations via internal argumentation	generation;argumentation;dialogue;automatic generation;rhetorical structure theory;text planning;coherence relations;natural language generation	A key requirement for the automatic generation of argumentative or explanatory text is to present the constituent propositions in an order that readers will find coherent and natural, to increase the likelihood that they will understand and accept the author’s claims. Natural language generation systems have standardly employed a repertoire of coherence relations such as those defined by Mann and Thompson’s Rhetorical Structure Theory. This paper models the generation of persuasive monologue as the outcome of an “inner dialogue”, where the author attempts to anticipate potential challenges or clarification requests. It is argued that certain RST relations such as Motivate, Evidence and Concession can be seen to emerge from various pre-empting strategies.	coherence (physics);intel matrix raid;natural language generation	Rodger Kibble	2007	Journal of Logic, Language and Information	10.1007/s10849-007-9045-2	natural language processing;generation;epistemology;computer science;artificial intelligence;mathematics;linguistics;algorithm	NLP	-13.627955089944356	0.8366670869072679	15317
574629032321b19b3cfd59c927d00a31bc32baa8	monge extensions of cooperation and communication structures	modelizacion;value theory;graph theory;valeur shapley;teoria grafo;game theory;convex programming;91a12;communication structure;91a12 91a40 communication structure convex game cooperation structure monge extension lovasz extension marginal value ranking shapley value supermodularity weber set;lovasz extension;coalicion;cooperation;juego cooperativo;convexite;teoria juego;programmation convexe;theorie jeu;teoria valor;theorie graphe;cooperacion;cooperative game;supermodularity;convexidad;cooperation structure;convex game;modelisation;hierarchical classification;shapley value;ranking;coalition;jeu cooperatif;community structure;marginal value;characteristic function;classification hierarchique;weber set;graph model;convexity;91a40;valor shapley;modeling;clasificacion jerarquizada;theorie valeur;extensive margin;supermodularite;monge extension;supermodularidad;programacion convexa	Cooperation structures without any a priori assumptions on the combinatorial structure of feasible coalitions are studied and a general theory for marginal values, cores and convexity is established. The th eory is based on the notion of a Monge extension of a general characteristic f un tion, which is equivalent to the Lovász extension in the special situat ion of a classical cooperative game. It is shown that convexity of a cooperatio n structure is tantamount to the equality of the associated core and Weber s t. Extending Myerson’s graph model for game theoretic communication, ge eral communication structures are introduced and it is shown that a not io f supermodularity exists for this class that characterizes convexity and properly extends Shapley’s convexity model for classical cooperative games .	marginal model;supermodular function;theory	Ulrich Faigle;Michel Grabisch;M. Heyne	2010	European Journal of Operational Research	10.1016/j.ejor.2010.01.043	game theory;mathematical optimization;combinatorics;value theory;characteristic function;systems modeling;convexity;ranking;graph theory;mathematics;shapley value;mathematical economics;cooperation;community structure;marginal value;statistics	ML	-6.687080314137616	0.08434493535284807	15320
247fd9bf59ec75f3795779d4921ade0c4fafdabf	do bayesians learn their way out of ambiguity?	choquet expected utility;bayesian updating;choquet expected utility theory;nonadditive probability measures;postprint article;standard model;consistent estimator;bayesian learning;probability measure;non additive probability measures	In standard models of Bayesian learning agents reduce their uncertainty about an events true probability because their consistent estimator concentrates almost surely around this probabilitys true value as the number of observations becomes large. This paper takes the empirically observed violations of Savages (1954) sure thing principle seriously and asks whether Bayesian learners with ambiguity attitudes will reduce their ambiguity when sample information becomes large. To address this question, I develop closed-form models of Bayesian learning in which beliefs are described as Choquet estimators with respect to neo-additive capacities (Chateauneuf, Eichberger, and Grant 2007). Under the optimistic, the pessimistic, and the full Bayesian update rule, a Bayesian learners ambiguity will increase rather than decrease to the e¤ect that these agents will express ambiguity attitudes regardless of whether they have access to large sample information or not. While consistent Bayesian learning occurs under the Sarin-Wakker update rule, this result comes with the descriptive drawback that it does not apply to agents who still express ambiguity attitudes after one round of updating. Keywords: Non-additive Probability Measures, Bayesian Learning, Choquet Expected Utility Theory JEL Classication Numbers: C11, D81, D83 I thank Alex Ludwig for helpful comments and suggestions. Financial support from Economic Research Southern Africa (ERSA) is gratefully acknowledged. yDepartment of Economics, University of Pretoria, Private Bag X20, Hateld 0028, South Africa. E-mail: alexander.zimper@up.ac.za	bayesian network;c11 (c standard revision);utility functions on indivisible goods	Alexander Zimper	2011	Decision Analysis	10.1287/deca.1110.0217	bayesian average;econometrics;artificial intelligence;mathematics;mathematical economics;bayesian statistics;bayesian inference;empirical probability;statistics	AI	-10.822838114084231	-0.023203581566209244	15346
8e17f3407dc95001b8bcafc678610eab37d57688	exploit sequencing to accelerate hot xml query pattern mining	frequent pattern;search space;efficient algorithm;query optimization;olap;parent child relationship;sequence mining;pattern mining;query evaluation;tree structure;approximate query answering;data compression techniques	"""Speeding up query evaluation in large XML repositories becomes a challenging and all-important problem with vast XML-related applications arising. Upon discovery of hot XML query patterns, indexing and caching can be effectively adopted for query performance enhancement. Previous algorithms for finding hot query patterns basically introduced a straightforward generate-and-test strategy. In this paper, we present, SOLARIA, an efficient algorithm for mining hot XML query patterns without candidate maintenance and costly tree-containment checking. Efficient algorithm of sequence mining is involved in discovering frequent tree-structured patterns, which aims at replacing expensive containment testing with cheap parent-child checking in sequences. SOLARIA deeply prunes unrelated search space for frequent pattern enumeration by parent-child relationship constraint. With the motivation of indexing and caching in XML query optimization, we also propose the derived algorithm SOLARIA for mining hot """"closed"""" XML query patterns which provide compact and complete structure information. By a thorough experimental study on various real-life data, we demonstrate the efficiency and scalability of SOLARIA over the previous known alternative. SOLARIA is also linearly scalable in terms of XML queries' size."""	algorithm;cache (computing);data mining;experiment;mathematical optimization;query optimization;real life;scalability;sequential pattern mining;test strategy;xml	Jianhua Feng;Qian Qian;Jianyong Wang;Lizhu Zhou	2006		10.1145/1141277.1141400	data compression;sequential pattern mining;sargable;query optimization;query expansion;web query classification;online analytical processing;computer science;data mining;database;tree structure;web search query;information retrieval;query language	DB	-30.847265782255107	4.149833207878066	15348
5bf0965ccd8af3eb2dbcf6964d89a3d2e0aad2ca	optimal agendas for multi-issue negotiation	multi issue negotiation;game theory;expected utility;incomplete information;agendas	There are two ways of handling bilateral multi-issue negotiations -- one is to negotiate all the issues together, and the other is to negotiate them one by one. The order in which issues are negotiated in issue-by-issue negotiation is specified by the agenda, which can be defined in two ways. One way is to decide it exogenously, i.e., before negotiation begins. The other way is to let the players decide which issue they will negotiate next, during the process of negotiation, i.e., the agenda is determined endogenously. Against this background, this paper studies the effect of combining the exogenous and endogenous agendas on the players' utilities. More specifically, we determine whether, decomposing a set of N issues into k stages (for 1 ≤ k ≤ N), determining the issues to be negotiated at each stage exogenously, and negotiating each stage sequentially using an endogenous agenda can improve an agent's utility relative to the utility it gets if the agenda for all the N issues is defined endogenously. For each agent, we find the expected utility for each value of k between 1 and N. The value of k that gives an agent maximum utility is its optimal number of stages.Our study shows that, in some negotiation scenarios, the optimal value of k is identical for the two players, and is greater than one. In other words, in some negotiation scenarios, both the agents can improve their utilities by using the k-stage negotiation relative to the single stage negotiation. However, since the players have incomplete information about the negotiation parameters, they cannot identify such scenarios. We therefore present an extended alternating offers protocol, that allows the agents to identify such scenarios through a mediator, thereby resulting in improved utility to both the agents.	bilateral filter;content negotiation;display resolution;existential quantification;expected utility hypothesis;matchware mediator;optimization problem	S. Shaheen Fatima;Michael Wooldridge;Nicholas R. Jennings	2003		10.1145/860575.860597	game theory;expected utility hypothesis;management science;complete information	AI	-8.734959503473508	-6.722139565372413	15364
21d6fe8140727f8aadef763a7958764994e2307e	brink: initial theory on bounded rationality and inconsistent knowledge	humans decision making morphology cognition buildings knowledge based systems context;cognitive systems;irrational but consistent circumstances brink bounded rationality inconsistent knowledge decision maker cognitive limitations rational behaviors cognitive computing systems human cognitive capability inconsistency handling rational but inconsistent circumstances;decision making cognitive systems;cognitive computing systems bounded rationality inconsistency	The theory of bounded rationality takes into consideration the cognitive limitations of decision makers in accomplishing their goals and emphasizes on satisficing behaviors when searching for solutions. One of the hallmarks of rational behaviors in decision-making process is embodied in how to cope with inconsistency. Building cognitive computing systems for real world applications amounts to developing systems that possess bounded rationality. In this paper, we examine how bounded rationality is exhibited in the human cognitive capabilities in handling inconsistency and propose an initial theory on how to incorporate those capabilities into cognitive computing systems. In particular, we focus our attention on two important phenomena: rational-but-inconsistent circumstances, and irrational-but-consistent circumstances. The main contribution of the work lies in the fact that we shed some new light on the interplay between bounded rationality and inconsistency.	cognitive computing;rationality	Du Zhang;Mehmet A. Orgun	2012	2012 IEEE 11th International Conference on Cognitive Informatics and Cognitive Computing	10.1109/ICCI-CC.2012.6311180	psychology;cognitive hierarchy theory;ecological rationality;rationality;knowledge management;artificial intelligence;social psychology;bounded rationality	Robotics	-23.81129916188569	-13.780147052083489	15393
9e1576a5d36ab66e50f57e369751ed9ac7e114c8	laban movement analysis and affective movement generation for robots and other near-living creatures		This manuscript describes an approach, based on Laban Movement Analysis, to generate compact and informative representations of movement to facilitate affective movement recognition and generation for robots and other artificial embodiments. We hypothesize that Laban Movement Analysis, which is a comprehensive and systematic approach for describing movement, is an excellent candidate for deriving a low-dimensional representation of movement which facilitates affective motion modeling. First, we review the dimensions of Laban Movement Analysis most relevant for capturing movement expressivity and propose an approach to compute an estimate of the Shape and Effort components of Laban Movement Analysis using data obtained from motion capture. Within a motion capture environment, a professional actor reproduced prescribed motions, imbuing them with different emotions. The proposed approach was compared with a Laban coding by a certified movement analyst (CMA). The results show a strong correlation between results from the automatic Laban quantification and the CMA-generated Laban quantification of the movements. Based on these results, we describe an approach for the automatic generation of affective movements, by S.J. Burton (&) Sheridan College, Oakville, Canada e-mail: bsjdanceresearch@gmail.com A.-A. Samadani Institute of Biomaterials and Biomedical Engineering, Bloorview Research Institute, University of Toronto, Toronto, Canada e-mail: ali.samadani@utoronto.ca R. Gorbet Department of Knowledge Integration, University of Waterloo, Waterloo, Canada e-mail: rbgorbet@uwaterloo.ca D. Kulić Department of Electrical and Computer Engineering, University of Waterloo, Waterloo, Canada e-mail: dana.kulic@uwaterloo.ca © Springer International Publishing Switzerland 2016 J.-P. Laumond and N. Abe (eds.), Dance Notations and Robot Motion, Springer Tracts in Advanced Robotics 111, DOI 10.1007/978-3-319-25739-6_2 25 adapting pre-defined motion paths to overlay affective content. The proposed framework is validated through cross-validation and perceptual user studies. The proposed approach has great potential for application in fields including robotics, interactive art, animation and dance/acting training.	cma-es;computer engineering;creatures;cross-validation (statistics);email;feedback;human–computer interaction;information;intelligent agent;interactive art;knowledge integration;map;motion capture;robot;robotics;springer (tank);switzerland;vocabulary	Sarahjane Burton;Ali-Akbar Samadani;Robert B. Gorbet;Dana Kulic	2014		10.1007/978-3-319-25739-6_2	communication	Robotics	-31.43960751449542	-22.129135268989224	15441
ef45ec7408943a210eee975b3832e9c5d384372b	applying fuzzy multi-criteria decision method to evaluate key capabilities of taiwan motion picture companies	fuzzy multi criteria decision making;motion pictures;balanced scorecard;motion picture company;cultural and creative industry;key capability	The purpose of this paper is to provide an algorithm for the motion picture companies to evaluate the key capabilities from firm viewpoint under fuzzy environment. The fundamental concepts we have adopted include the eigenvector method, fuzzy Delphi method, fuzzy set theory, and multi-criteria decision making method. With the concept of balanced scorecard and the interviewing managers of motion picture industry in Taiwan, we collect twenty three sub-criteria and construct the hierarchical structure for evaluating the motion picture company’s key capabilities. The fuzzy Delphi method is integrated with the eigenvector method to form a set of pooled weights of the criteria. The concepts of triangular fuzzy number and linguistic variables are used to assess the preference ratings, including ‘importance’ and ‘appropriateness’, of linguistic variable. Through the hierarchy integration, we obtain the final scores of capabilities, and then use a revised Chang and Chen’s ranking method for choosing the key capability.	algorithm;delphi method;entity–relationship model;fuzzy number;fuzzy set;set theory	Yaw-Chu Chen;Kuei-Lun Chang	2006		10.2991/jcis.2006.164	engineering;knowledge management;marketing;operations management	AI	-5.786509605461117	-17.419097928848643	15460
2f84b082bc0bbe272bf2db8356be938e477aef88	oh behave! agents-based behavioral representations in problem solving environments	agent based simulation;agent based;agent based model;complex adaptive system;electricity market;problem solving environment;decision rule	"""The development of deregulated electricity systems around the world has produced the need for simulation systems that are capable of addressing the complexities that arise in the new markets. Agent-based models allow the use of complex adaptive systems approaches that are capable of producing tools or problem solving environments that can address the behavior of each of the participants within the electricity market. The agents in the tools are allowed to establish their own objectives and apply their own decision rules. They can be developed to learn from their previous experiences and change their behavior when future opportunities arise. In this paper, we will argue that the same type of agent-based technology that is used to produce """"realistic"""" agent behavior in agent-based simulation tools at Argonne National Laboratory can also be used to embed these tools in problem solving environments."""	problem solving	Michael J. North;Charles M. Macal;Peter Campbell	2003		10.1007/3-540-44863-2_96	complex adaptive system;simulation;electricity market;artificial intelligence;decision rule;management science;agent-based social simulation	ECom	-19.254837701189235	-13.92057056779874	15468
ebbad0d524e0b23cf23233c52fb5250089144fc6	evaluating the uncertainty caused by post office box addresses in environmental health studies: a restricted monte carlo approach	lung cancer;po box address;uncertainty;cluster detection;cluster analysis;monte carlo method;environmental health;monte carlo;monte carlo simulation;spatial information	Taylor & Francis makes every effort to ensure the accuracy of all the information (the “Content”) contained in the publications on our platform. However, Taylor & Francis, our agents, and our licensors make no representations or warranties whatsoever as to the accuracy, completeness, or suitability for any purpose of the Content. Any opinions and views expressed in this publication are the opinions and views of the authors, and are not the views of or endorsed by Taylor & Francis. The accuracy of the Content should not be relied upon and should be independently verified with primary sources of information. Taylor and Francis shall not be liable for any losses, actions, claims, proceedings, demands, costs, expenses, damages, and other liabilities whatsoever or howsoever caused arising directly or indirectly in connection with, in relation to or arising out of the use of the Content.	francis;monte carlo method;primary source	X. Shi	2007	International Journal of Geographical Information Science	10.1080/13658810600924211	econometrics;mathematics;monte carlo integration;cartography;statistics;monte carlo method	Robotics	-14.641593940080107	-5.842355170715561	15491
a681343c0be8b63c9cbb98ca427f6fd688a3d080	using the analytic hierarchy process to rank foreign suppliers based on supply risks	analytic hierarchy process;reliability chain;ahp;international business;supply chain management;supplier selection	Essential characteristics of suppliers are identified that must be considered in the supplier selection process. Risk to the disruption of company operations as it relates to the reliability of suppliers is described as a reliability chain. The analytic hierarchy process (AHP) is shown to be the appropriate methodology for evaluating and ranking potential suppliers. A realistic case study is presented in which a manufacturer evaluates and ranks its current foreign supplier against two other potential foreign suppliers based on several criteria of supply reliability.	analytical hierarchy	Reuven R. Levary	2008	Computers & Industrial Engineering	10.1016/j.cie.2008.01.010	international business;supply chain management;analytic hierarchy process;computer science;marketing;operations management;supplier relationship management;commerce	SE	-4.775786928136252	-15.160710238459046	15527
59f0733674a6bedea7c3f63f4b969454d8e76a41	cooperatively controlled collision evasive emergency manoeuvres	langage fonctionnel;distributed system;esquiva colision;sistema de transporte;systeme intelligent;systeme reparti;fuzzy neural nets;automovil;conduccion vehiculo;autonomous system;road traffic;intelligent transportation systems;cooperation;sistema inteligente;logique floue;lenguaje funcional;conduite vehicule;logica difusa;reseau neuronal flou;intelligence artificielle;relacion maestro esclavo;vehicle driving;systeme adaptatif;cooperacion;relation maitre esclave;sistema autonomo;user assistance;emergency;fuzzy logic;sistema repartido;trafic routier;assistance utilisateur;braking;automobile;neuro fuzzy;motor car;asistencia usuario;systeme autonome;inferencia;urgencia;adaptive system;intelligent system;interactive control;urgence;systeme transport;sistema adaptativo;freinage;artificial intelligence;trafico carretera;collision avoidance;inteligencia artificial;reseau neuronal;esquive collision;master slave relationship;functional language;transportation system;inter vehicle communication;red neuronal;inference;driver support systems;neural network;frenado	This study focuses on interactive control paradigm that has been testified as an effective solution for reliable collision avoidance of autonomous vehicular systems. The so called interactive controller negotiates collision scenarios between two vehicular systems leading to cooperative manoeuvres. The key point is that in order to avoid a probable collision situation, both the vehicular systems interactively carry out manoeuvres. The hierarchical differentiation of the participatory vehicular subsystems is done by using a master-slave concept. An inter-vehicle communication (IVC) system plays a pivotal role here. The primary and secondary level data are exchanged between the vehicles through IVC. The main controllers, for braking and steering, onboard each of the vehicular system are based on adaptive neuro-fuzzy inference system (ANFIS). The top-tier of this controller includes all important auxiliary functional components for processing the secondary functional parameters.		Ravipriya Ranatunga;Sisil Kumarawadu	2008	Control and Intelligent Systems	10.2316/Journal.201.2008.4.201-1974	fuzzy logic;control engineering;embedded system;intelligent transportation system;simulation;emergency;computer science;engineering;autonomous system;artificial intelligence;adaptive system;neuro-fuzzy;cooperation;artificial neural network;brake	Robotics	-22.880819451856407	-6.240102296362916	15536
6485ec7bf34571a16a4570337be1fbd72c54148c	models of level-0 behavior for predicting human behavior in games		My primary research interest is in using data-driven machine learning models to predict human strategic behaviour; that is, behaviour in interactions where each participant’s rewards depend partially on the actions of other participants. My long-term research agenda is to build a general theory for optimally designing algorithms for mediating interactions between humans rather than idealized, perfectly rational game theoretic agents.	algorithm;game theory;interaction;machine learning	James R. Wright;Kevin Leyton-Brown	2016	CoRR		simulation;computer science;artificial intelligence;mathematics;mathematical economics;algorithm;statistics	ML	-14.778151467950424	-12.216309933298708	15565
ce7ae6ddc645a0d10ea19dce18078e2f3b752320	causal representation of patient illness for electrolyte and acid-base diagnosis	electrical engineering and computer science;thesis;knowledge base	Much of the medical knowledge in the first generation Al in Medicine programs is phenomenological; that is, it describes the associations among phenomena without knowledge of the underlying causal mechanisms. Although these AIM programs provide a good first approximation of the way clinicians reason, they fail to reproduce clinicians'' reasoning based on a deeper understanding of the phenomena. More specifically, they do not deal with the knowledge of disease at different levels of detail, nor do they utilize causal relations to organize and explain the clinical facts and disease hypothesis. They also cannot deal with illnesses resulting from multiple diseases, especially when one disease alters the presentation of the others. Finally, they are unable to capture the notions of adequacy and parsimony that play such a large role in diagnosis. To explore these issues and rectify these deficiencies, we have undertaken the task of providing expert consultation for electrolyte and acid-base disturbances. This thesis reports the implementation of ABEL, the diagnostic component of the consultation program. In it, we explore the problems of modeling the causal understanding of a patient''s illness. We develop techniques for dealing with illness resulting from multiple interacting diseases. We describe a multi-level representation of causal knowledge, and explore issues of the aggregation of available case specific knowledge into concise summaries of the patient''s illness. We discuss structural criteria for evaluation parsimony, coherence and adequacy of diagnostic explanations. We also explore some of the issues involved in information gathering and propose expectation-driven diagnostic planning as a means of improving it. Finally, we discuss the issues of explanation and justification of the program''s understanding and argue that these facilities are crucial for acceptability of a consultation program.	causality	Ramesh S. Patil	1981			knowledge base;knowledge management;management science	NLP	-20.440781784712733	-4.021306126372932	15594
1ab27884c4edd829e504d9a506390f4167b1fe90	telerobotic systems for restoration work in structured hazardous environments	variable controlled task programming;structured hazardous environment;recreated structured virtual environment;virtual simulation;restoration work;structured environment;operational reliability;task planning;hazardous environment;dangerous job;telerobotic system;hazardous human environment;operational aspect	A hazardous human environment is one in which harm could potentially occur to any human or animal that enters into it. There is a need for autonomous and/or semiautonomous systems to replace humans on such dangerous jobs. The operational reliability of the robot in the hazardous environment is critical. This paper will address possible improvements in mission success when variable controlled task programming is applied to task planning in concert with virtual simulation. This is achieved through the use of a telerobot in a structured environment to mimic its recreated structured virtual environment. By programming more of the operators' knowledge of the task into the operational aspects of the robot, the robot is better able to complete a task when and if contact is lost with its operator due to environmental conditions and/or system malfunction.	autonomous robot;circuit restoration;humans;job stream;simulation;telerobotics;virtual reality	Jimmy Huff;Silvanus J. Udoka	2005			simulation;engineering;artificial intelligence	Robotics	-25.672033142973707	-22.942135269435344	15597
829af05e6863ab96c0acd755b58cfc277cbfcc7b	path query routing in unstructured peer-to-peer networks	bloom filter;peer to peer network;indexation;xml document;structural properties;query routing	In this article, we introduce a way to distribute an index database of XML documents on an unstructured peer-to-peer network with a flat topology (i.e. with no super-peer). We then show how to perform content path query routing in such networks. Nodes in the network maintain a set of Multi Level Bloom Filters that summarises structural properties of XML documents. They propagate part of this information to their neighbor nodes, allowing efficient path query routing in the peerto-peer network, as shown by the evaluation tests presented.	algorithm;bloom filter;cluster analysis;experiment;peer-to-peer;routing;sqr;xml database	Nicolas Bonnel;Gildas Ménier;Pierre-François Marteau	2007		10.1007/978-3-540-74466-5_52	policy-based routing;query optimization;routing;static routing;xml;computer science;bloom filter;database;routing protocol;link-state routing protocol;programming language;world wide web;path vector protocol;information retrieval	DB	-29.358835913397428	-0.3705931383243176	15607
cf63b0cf6c316d6ed65dc5d673b9bb7b9c5eb162	approaches to natural language discourse processing	modelizacion;lenguaje natural;sistema operativo;linguistique;architecture systeme;theory and modeling;discourse processing;discurso;natural language dialogue;computer model;langage naturel;semantics;tratamiento lenguaje;intelligence artificielle;semantica;semantique;modelisation;linguistica;operating system;language processing;discours;natural language;contexto;traitement langage;contexte;artificial intelligence;coherence;arquitectura sistema;systeme exploitation;articial intelligence;inteligencia artificial;coherencia;system architecture;discourse;modeling;natural language processing;context;linguistics	One of the most difficult problems within the field of Artificial Intelligence (AI) is that of processing language by computer, or natural-language processing. A major problem in natural-language processing is to build theories and models of how individual utterances cling together into a coherent discourse. The problem is important because, to properly understand natural language, a computer should have some sense of what it means for a discourse to be coherent and rational. Theories, models and implementations of natural-language processing argue for a measure of coherence based on three themes: meaning, structure, and intention. Most approaches stress one theme over all the others. Their future lies in the integration of components of all approaches. A theory of intention analysis solves, in part, the problem of natural-language dialogue processing. A central principle of the theory is that coherence of natural-language dialogue can be modelled by analysing sequences of intention. The theory of intention analysis has been incorporated within a computational model, called Operating System CONsultant (OSCON), implemented in Quintus Prolog, which understands, and answers in English, English questions about computer operating systems. Theories and implementations of discourse processing will not only enable people to communicate better with computers, but also enable computers to better communicate with people.	artificial intelligence;coherence (physics);computational model;computer;dialog system;natural language processing;operating system;prolog;theory	Paul Mc Kevitt;Derek Partridge;Yorick Wilks	1992	Artificial Intelligence Review	10.1007/BF00123689	natural language processing;systems modeling;coherence;computer science;artificial intelligence;semantics;linguistics;natural language	AI	-25.06984128248056	-7.992434163463813	15687
0bbc74853f870798eeacee3535f00a519140a253	the preferences of homo moralis are unstable under evolving assortativity	moral values;assortative matching;evolution	Differing degrees of assortativity in matching can be expected to have both genetic and cultural determinants. When assortativity is subject to evolution, the main result of Alger and Weibull (2013) on the evolution of stable otherregarding preferences does not hold. Instead, both non-Nash and Pareto inefficient behavior are evolutionarily unstable.	assortativity;control theory;nash equilibrium;pareto efficiency	Jonathan Newton	2017	Int. J. Game Theory	10.1007/s00182-016-0548-4	evolution;mixing patterns;welfare economics;assortativity	AI	-5.457608066613388	-4.697760638398856	15765
003644b3864a27468dd47385c0bf58179ee52fc8	set-monotonicity implies kelly-strategyproofness		This paper studies the strategic manipulation of set-valued social choice functions according to Kelly’s preference extension, which prescribes that one set of alternatives is preferred to another if and only if all elements of the former are preferred to all elements of the latter. It is shown that set-monotonicity—a new variant of Maskin-monotonicity—implies Kellystrategyproofness in comprehensive subdomains of the linear domain. Interestingly, there are a handful of appealing Condorcet extensions—such as the top cycle, the minimal covering set, and the bipartisan set—that satisfy set-monotonicity even in the unrestricted linear domain, thereby answering questions raised independently by Barberà (1977a) and Kelly (1977).	kelly criterion	Felix Brandt	2015	Social Choice and Welfare	10.1007/s00355-015-0881-8	mathematics;mathematical economics;law;algorithm	AI	-7.308031797323674	-1.3903743656697651	15954
201d800e851a43a30787384bf5e1d1ed19297b07	interface structures: conceptual, logical, and physical patterns applicable to human-computer interaction	representacion mental;interfase usuario;structural model;representacion conocimientos;human computer interaction;metodologia;user interface;sistema informatico;relacion hombre maquina;specification;representation mentale;man machine relation;cognitive theory;computer system;methodologie;mental representation;theorie cognitive;modele structure;especificacion;teoria cognocitiva;modelo estructura;interface utilisateur;systeme informatique;relation homme machine;methodology;knowledge representation;representation connaissances	Abstract   Structural patterns are known to be important to human memory and cognition. They are essential to the knowledge representation of conceptual, logical and physical entities. At the same time, computer interfaces are implemented using a variety of logical and physical structures that have implications for human use. These two categories of structures, representing both sides of the human-computer partnership, are characterized and compared. Emphasis is on identifying a basic set of structures amenable both to the user's mind and to the computer-based application. The user is capable of conceiving and visualizing structures in each of several different representation “spaces” behind the interface surface. Careful structural mappings between these spaces and the user-visible interface are essential. To aid interface designers in these tasks, a formal definition of interface structure is proposed and an example specification is presented. Expected benefits and required research are discussed.		Siegfried Treu	1992	International Journal of Man-Machine Studies	10.1016/0020-7373(92)90024-F	knowledge representation and reasoning;computer science;artificial intelligence;mental representation;methodology;user interface;specification;algorithm	DB	-24.971916310155713	-7.011883864393583	15999
164967e5ab2470b42819764f8dd33d104dd3f4e8	evaluation of waste management systems using fuzzy cognitive maps and optimization	optimization integrated waste management system fuzzy cognitive maps bacterial evolutionary algorithm;evolutionary computation;parameter causal relations waste management system evaluation fuzzy cognitive map optimization integrated waste management system iwms complex system uncertainty waste management objectives waste management goals decision making process support fcm bacterial evolutionary algorithm bea method complex mechanism time series connection matrix;integrated waste management system;fuzzy cognitive maps;waste management causality decision making evolutionary computation fuzzy set theory large scale systems matrix algebra optimisation time series;time series analysis;optimization;bacterial evolutionary algorithm;waste management;microorganisms;algorithm design and analysis;waste management time series analysis microorganisms evolutionary computation optimization algorithm design and analysis	Integrated Waste Management Systems (IWMS) are very complex systems with a lot of uncertainty. These can be defined as the selection and application of suitable techniques, technologies and management programs to achieve waste management objectives and goals. In order to support the decision making process in waste management we propose the use of Fuzzy Cognitive Map (FCM) and Bacterial Evolutionary Algorithm (BEA) methods since the combination of the FCM and BEA seem to be suitable to model complex mechanisms such as IWMS. While the FCM is formed for a chosen system by determining the concepts and their relationships, it is possible to quantitatively simulate the system considering its parameters. However, if the time series of the factors of the system are known, then the connection matrix of FCM, thus the causal relations among the parameters can be determined by optimization. This way a more objective description of IWMS can be given.	causal filter;complex systems;evolutionary algorithm;fuzzy cognitive map;management system;mathematical optimization;norm (social);simulation;text mining;time series	Adrienn Buruzs;Miklós F. Hatwágner;Péter Földesi;László T. Kóczy	2015	2015 10th Asian Control Conference (ASCC)	10.1109/ASCC.2015.7244894	engineering;artificial intelligence;operations management;management science	DB	-8.066406514674265	-20.483935843677674	16001
bf8502906d8b69bcca6aee2b7b5a1d5f8334ddd1	modeling and simulation of scsa performance under e-commerce environment	co algorithm;improved dea model;index terms—scsa;performance evaluation;indices system;electronic commerce;parameter estimation;indexing terms;indexation;e commerce;data envelope analysis;supply chain;modeling and simulation	The performance evaluation of supply chain strategy alliance (SCSA) has the novelty compares with the traditional enterprise organization form under electronic commerce environment. This paper constructs a set of systematic SCSA evaluating indices system that included four aspects of customer and node enterprise satisfaction, supply chain operation flow, supply chain economic benefit, supply chain innovation and learning capability based on SCSA performance characteristic, uses the thought of balanced scoreboard and supply chain performance metrics reference mode1 (SCPR). Aiming at the problem of how to evaluate the SCSA performance, this paper proposes the data envelopment analysis (DEA) model based on chaos optimization (CO) algorithm, which not only can use the chaotic motion characteristics of the initial value sensitivity, the ergodicity, and the randomness, remove from the partial minimum point, but display the DEA's advantage of not involving the parameter estimation and weight determination, cause the evaluation results not influenced by the different index dimension. The SCSA performance evaluating results of 16 samples show that the model is simple and feasible, and improve the evaluating accuracy and efficiency.	algorithm;chaos theory;data envelopment analysis;e-commerce;ergodicity;estimation theory;mathematical optimization;performance evaluation;randomness;simulation	Zhibin Liu;Wenwen Cao;Shengliang Yuan	2009	JSW		e-commerce;mathematical optimization;simulation;index term;computer science;data envelopment analysis;supply chain;estimation theory	Web+IR	-7.149500439216111	-19.40679615062247	16023
95c365c5c279b6c20db8cd759dde2c81a57443b3	theory flexibility and inconsistency in science	humanidades;filosofia etica;classical electrodynamics;eliminativism;kirchhoff;inconsistency;scientific theory;bohr	For several decades now philosophers have discussed apparent examples of internally inconsistent scientific theories. However, there is still much controversy over how exactly we should conceive of scientific theories in the first place. Here I argue for a new approach, whereby all of the truly important questions about inconsistency in science can be asked and answered without disagreements about theories and theory-content getting in the way. Three examples commonly described as ‘internally inconsistent theories’ are analysed in the light of this approach. In the process, the question ‘Is the theory inconsistent or not?’ is identified as a bad, or at least unimportant, question.	doxastic logic;http public key pinning;theory	Peter Vickers	2014	Synthese	10.1007/s11229-014-0464-8	classical electromagnetism;bohr model;philosophy;epistemology;mathematics;scientific theory;quantum mechanics;eliminative materialism	AI	-12.254734820551223	3.5133319357029804	16036
5b66f1f6636e19c5ac09b50cd305184f95f9bff1	identifying dynamic sequential plans	bayesian network	We address the problem of identifying dynamic sequential plans in the framework of causal Bayesian networks, and show that the problem is reduced to identifying causal effects, for which there are complete identification algorithms available in the literature.	algorithm;bayesian network;causal filter	Jin Tian	2008			machine learning;artificial intelligence;computer science;data mining;bayesian network;pattern recognition	AI	-18.108134885024675	-4.523352910441158	16043
f83db4984a7732dc41c77b65c85e0c64801aee39	research on multiple queries processing technology in wide area sensor databases	query redundancy problem;query processing;database management systems;query processing databases space technology xml sensor phenomena and characterization intelligent sensors sensor systems and applications ip networks global positioning system computational intelligence;queries processing algorithms;sensor network multiple queries processing technology wide area sensor databases query redundancy problem queries processing algorithms query attribute graphs subqueries algorithm;sensor network;distributed sensors;wide area sensor databases;query processing database management systems distributed sensors;subqueries algorithm;multiple queries processing technology;query attribute graphs	Wide area sensor databases are a hotspot research area internationally at present. The query processing technology in wide area sensor databases is analyzed in detail in this paper. Focusing on the query redundancy problem among multiple queries, the multiple queries processing algorithms are proposed. First of all, it divides these queries into a number of sub-queries equally. Secondly, it constructs a query attribute graph using all the sub-queries and deletes the repeated queries using the eliminating repeated sub-queries algorithm. Finally, it unites the results based on the relations between the query and the sub-queries and gains the query results of users. Theoretical analyses and experimental results demonstrate that the method can dramatically reduce the users' query response times, decrease the messages transferred in the sensor network and improve the utilization ratio of the network bandwidth.	algorithm;database;java hotspot virtual machine;sensor	Guohua Liu;Shuzhi Zhang;Dongming Zhang	2006	2006 International Conference on Computational Inteligence for Modelling Control and Automation and International Conference on Intelligent Agents Web Technologies and International Commerce (CIMCA'06)	10.1109/CIMCA.2006.182	online aggregation;sargable;query optimization;query expansion;web query classification;wireless sensor network;computer science;query by example;data mining;database;rdf query language;web search query;information retrieval;query language;visual sensor network;spatial query	DB	-27.45380324372915	1.1303357058549126	16120
43a1d4e11b65120d53e5edf8c18b38708c8c5941	bounds of neglect benevolence in input timing for human interaction with robotic swarms	robotic swarms;human robot interaction	Robotic swarms are distributed systems whose members interact via local control laws to achieve a variety of behaviors, such as flocking. In many practical applications, human operators may need to change the current behavior of a swarm from the goal that the swarm was going towards into a new goal due to dynamic changes in mission objectives. There are two related but distinct capabilities needed to supervise a robotic swarm. The first is comprehension of the swarm's state and the second is prediction of the effects of human inputs on the swarm's behavior. Both of them are very challenging. Prior work in the literature has shown that inserting the human input as soon as possible to divert the swarm from its original goal towards the new goal does not always result in optimal performance (measured by some criterion such as the total time required by the swarm to reach the second goal). This phenomenon has been called Neglect Benevolence, conveying the idea that in many cases it is preferable to neglect the swarm for some time before inserting human input. In this paper, we study how humans can develop an understanding of swarm dynamics so they can predict the effects of the timing of their input on the state and performance of the swarm. We developed the swarm configuration shape-changing Neglect Benevolence Task as a Human Swarm Interaction (HSI) reference task allowing comparison between human and optimal input timing performance in control of swarms. Our results show that humans can learn to approximate optimal timing and that displays which make consensus variables perceptually accessible can enhance performance.	approximation algorithm;distributed computing;flocking (behavior);horizontal situation indicator;robot;swarm robotics	Sasanka Nagavalli;Shih Yi Chien;Michael Lewis;Nilanjan Chakraborty;Katia P. Sycara	2015	2015 10th ACM/IEEE International Conference on Human-Robot Interaction (HRI)	10.1145/2696454.2696470	human–robot interaction;swarm robotics;simulation;computer science;artificial intelligence	Robotics	-26.709245109626227	-22.8783087143039	16130
405cc7b229969b955e59ad3b4e7befafffdf499e	efficient schemes for similarity-aware refinement of aggregation queries	query refinement;data exploration	Interactive data exploration platforms in Web, business and scientific domains are becoming increasingly popular. Typically, users without prior knowledge of data interact with these platforms in an exploratory manner hoping they might retrieve the results they are looking for. One way to explore large-volume data is by posing aggregate queries which group values of multiple rows by an aggregate operator to form a single value: an aggregated value. Though, when a query fails, i.e., returns undesired aggregated value, users will have to undertake a frustrating trial-and-error process to refine their queries, until a desired result is attained. This data exploration process, however, is growing rather difficult as the underlying data is typically of large-volume and high-dimensionality. While heuristic-based techniques are fairly successful in generating refined queries that meet specified requirements on the aggregated values, they are rather oblivious to the (dis)similarity between the input query and its corresponding refined version. Meanwhile, enforcing a similarity-aware query refinement is rather a non-trivial challenge, as it requires a careful examination of the query space while maintaining a low processing cost. To address this challenge, we propose an innovative scheme for efficient Similarity-Aware Refinement of Aggregation Queries called (EAGER) which aims to balance the tradeoff between satisfying the aggregate and similarity constraints imposed on the refined query to maximize its overall benefit to the user. To achieve that goal, EAGER implements efficient strategies to minimize the costs incurred in exploring the available search space by utilizing similarity-based and monotonic-based pruning techniques to bound the search space and quickly find a refined query that meets users’ expectations. Our extensive experiments show the scalability exhibited by EAGER under various workload settings, and the significant benefits it provides.	aggregate data;aggregate function;experiment;heuristic;refinement (computing);requirement;scalability;world wide web	Abdullah M. Albarrak;Mohamed A. Sharaf	2017	World Wide Web	10.1007/s11280-017-0434-4	data mining;computer science;web query classification;online aggregation;artificial intelligence;machine learning;web search query;workload;scalability;heuristic;spatial query;query optimization	DB	-24.952403614330404	3.9140127397095585	16132
cc5ae11f404a820ca8618a9a905ceb16580d0d49	metaphysical necessity dualism		A popular response to the Exclusion Argument for physicalism maintains that mental events depend on their physical bases in such a way that the causation of a physical effect by a mental event and its physical base needn’t generate any problematic form of causal overdetermination, even if mental events are numerically distinct from and irreducible to their physical bases. This paper presents and defends a form of dualism that implements this response by using a dispositional essentialist view of properties to argue that the psychophysical laws linking mental events to their physical bases are metaphysically necessary. I show the advantages of such a position over an alternative form of dualism that merely places more “modal weight” on psychophysical laws than on physical laws. The position is then defended against the objection that it is inconsistent with dualism. Lastly, some suggestions are made as to how dualists might clarify the contribution that mental causes make to their physical effects.	causal system;causality;irreducibility;mental event;metaphysical naturalism;modal logic;numerical analysis;physicalism	Ben White	2016	Synthese	10.1007/s11229-016-1308-5	property dualism;philosophy;epistemology;mathematics	HCI	-13.278691706278472	2.8492637212557894	16161
dd643d877446ab099189855cbf95545caad0d772	cooperative multi-agent reconfigurable manufacturing environments	reconfiguration;cooperative control;modelizacion;selection problem;reconfiguracion;multiagent system;problema seleccion;agent based systems;cooperative and distributed control;control inteligente;cooperation;adaptive control;atelier flexible;mass production;commande repartie;cooperacion;intelligent control;self organising agents;modelisation;multi agent systems;intelligent agents;flexible manufacturing;control adaptativo;flexible manufacturing system;agent intelligent;commande adaptative;intelligent agent;autoorganizacion;fmc;self organization;coordinacion;reconfigurable manufacturing;sistema flexible produccion;commande intelligente;agente inteligente;control repartido;manufacturing cells;sistema multiagente;produccion en masa;production masse;modeling;distributed control;autoorganisation;systeme multiagent;coordination;probleme selection	This paper discusses the use of resource-bounded intelligent agents acting in (complex) manufacturing environments. Agents operate for the coordination of multitasks performed within the plant. In particular, we discuss the agents' operation selection problem. The agent's required capabilities requires effective design and implementation approaches able to cope with the high-level demands. In this paper, we provide a cooperative control scheme for a team of Flexible Manufacturing Workcells. This paper provides a modelling framework that eases the design of autonomous agents for complex large-scale multi-agent production systems. Agents' behaviours are simple, allowing to be easily implemented, scalable and practical. The proposed approach creates effective coordinated and self-organised agents capable of accomplishing their goals.	multi-agent system	Shichun C. Zho;Alejandro Ramirez-Serrano;Robert W. Brennan	2006	IJMTM	10.1504/IJMTM.2006.008799	control engineering;mass production;self-organization;simulation;systems modeling;computer science;engineering;artificial intelligence;control reconfiguration;operations management;intelligent agent;cooperation	Robotics	-22.719111559290955	-6.522203125516369	16232
c7eb7693c03e30fa608d252318f2172cbd8cf417	on stability of nash equilibrium situations and pareto optimal situations in finite games		A non-cooperative finite game of several persons is considered in the case, where payoff functions are linear. Extreme levels of independent perturbations of payoff functions parameters, which remain Nash and Pareto optimality of a situation, are specified. Necessary and sufficient conditions of such stability are stated. AMS Mathematics Subject Classification : 90C27, 90C29.	mathematics subject classification;nash equilibrium;pareto efficiency;vhdl-ams	Vladimir A. Emelichev;Sergey E. Bukhtoyarov	2003	The Computer Science Journal of Moldova		epsilon-equilibrium;simulation;best response;mathematical economics;welfare economics;nash equilibrium	ECom	-4.8941782233039	-1.1702175793177405	16287
8a454bf4e90ac45f1551e91e63045ad10fb0634b	experimental evaluation of the efficiency of a case-based organizational memory information system used as a decision aid	databases;organisational memory;information technologies;decision support;case based omis;information systems;decision aid;case based omis case based organisational memory information system decision aid computer based information system information technologies;identity based encryption;information systems decision support systems databases decision making prototypes memory size measurement identity based encryption content addressable storage intelligent systems;prototypes;information technology;size measurement;organizational memory;evaluation of decision support systems;decision making process;decision support systems;intelligent systems;case based organisational memory information system;computer based information system;experimental evaluation;information system;case based reasoning;content addressable storage;knowledge based systems;memory	An organisational memory information system (OMIS) a computer-based information system that supports capture, storage, and recall of organisational memory. wide range of information technologies have be proposed as the means for organisational memo information systems. This paper describes a project to evaluate the quality decision making using a case-base as the technology an organisational memory aid. The paper reports specifically on the efficiency of t decision making process when using a case-based O as a decision aid.	information system	F. V. Burstein;H. G. Smith;S. M. Fung	1998		10.1109/HICSS.1998.653102	decision support system;computer science;knowledge management;artificial intelligence;management information systems;data mining;management science;information technology;information system	AI	-27.67059138964561	-3.460448032588251	16373
0d3899baebf31c6505fd6a83a167e6a3a095dc4a	an abm java applet to explore the free market equality/efficiency tradeoff		A classical disputed question regarding the effect of free market economy on the social welfare is the right balance between equality and efficiency called by Okun: the big tradeoff.		Hugues Bersini	2016		10.1007/978-3-319-39324-7_21	real-time computing;theoretical computer science;mathematics;algorithm	NLP	-5.626273687715053	-2.744045056179659	16381
9d722c943ff7edd7ba65eaee323d541c87c0f455	declarative query processing in imperative managed runtimes		The falling price of main memory has led to the development and growth of in-memory databases. At the same time, new advances in memory technology, like persistent memory, make it possible to have a truly universal storage model, accessed directly through the programming language in the context of a fully managed runtime. This environment is further enhanced by language-integrated query, which has picked up significant traction and has emerged as a generic, safe method of combining programming languages with databases with considerable software engineering benefits.	computer data storage;declarative programming;imperative programming;in-memory database;language integrated query;persistent memory;programming language;software engineering;storage model;traction teampage	Stratis Viglas	2015			natural language processing;database;programming language	PL	-31.96410081803298	2.1767616685573983	16460
9e382410199caea6010ac128e3a1f75971f75aa6	parallel in situ indexing for data-intensive computing	database indexing;middleware parallel in situ indexing data intensive computing disk storage data storage management data access database research literature data records database management systems dbms compressed bitmap indexes fastbit software data analysis;time dependent;storage management data analysis database indexing database management systems disc storage information retrieval middleware records management;database management systems;information retrieval;disc storage;computer model;storage management;scientific data;data processing;mathematics and computing;records management;data model;data analysis;computational modeling;indexing;indexation;data access;middleware;data intensive computing;high performance;database management system;scientific research;parallel processing;buildings;indexing data processing parallel processing buildings data models computational modeling;data models	As computing power increases exponentially, vast amount of data is created by many scientific research activities. However, the bandwidth for storing the data to disks and reading the data from disks has been improving at a much slower pace. These two trends produce an ever-widening data access gap. Our work brings together two distinct technologies to address this data access issue: indexing and in situ processing. From decades of database research literature, we know that indexing is an effective way to address the data access issue, particularly for accessing relatively small fraction of data records. As data sets increase in sizes, more and more analysts need to use selective data access, which makes indexing an even more important for improving data access. The challenge is that most implementations of indexing technology are embedded in large database management systems (DBMS), but most scientific datasets are not managed by any DBMS. In this work, we choose to include indexes with the scientific data instead of requiring the data to be loaded into a DBMS.We use compressed bitmap indexes from the FastBit software which are known to be highly effective for query-intensive workloads common to scientific data analysis. To use the indexes, we need to build them first. The index building procedure needs to access the whole data set and may also require a significant amount of compute time. In this work, we adapt the in situ processing technology to generate the indexes, thus removing the need of reading data from disks and to build indexes in parallel. The in situ data processing system used is ADIOS, a middleware for high-performance I/O. Our experimental results show that the indexes can improve the data access time up to 200 times depending on the fraction of data selected, and using in situ data processing system can effectively reduce the time needed to create the indexes, up to 10 times with our in situ technique when using identical parallel settings.	access time;bandwidth (signal processing);bitmap;data access;data-intensive computing;database;embedded system;middleware;scientific literature	Jinoh Kim;Hasan Abbasi;Luis Chacón;Ciprian Docan;Scott Klasky;Q. X. Liu;Norbert Podhorszki;Arie Shoshani;Kesheng Wu	2011	2011 IEEE Symposium on Large Data Analysis and Visualization	10.1109/LDAV.2011.6092319	computer science;data mining;database;information retrieval	DB	-30.99958820411122	-0.17073192122385858	16478
9922d6ec69429b5e0d66d2a758f26e881873f567	agent-based crowd simulation in airports using games technology	g400 computer science;airport simulation;pedestrian crowd simulation;multi agent modelling;game technology;physics middleware;game ai	We adapt popular video-games technology for an agent-based crowd simulation framework in an airport terminal. To achieve this, we investigate game technology, crowd simulation and the unique traits of airports. Our findings are implemented in a virtual airport environment that exploits a scalable layered intelligence technique in combination with physics middleware and a social force approach for crowd simulation. Our experiments show that the framework runs at interactive frame-rate and evaluate the scalability with increasing number of agents demonstrating event triggered airport behaviour.	crowd simulation	Olivier Szymanezyk;Tom Duckett;Patrick Dickinson	2012	Trans. Computational Collective Intelligence	10.1007/978-3-642-34645-3_9	simulation;engineering;multimedia;computer security	HCI	-21.619779949469823	-22.841336038694692	16675
c9060f07e4237bbdeaec6ee9ff233f41595c1946	a partner selection method for forming innovation alliance	partner selection;fuzzy ahp;innovation alliance;national mega project	Establishing innovation alliance has now become a very important and indispensable way for achieving the mission of research and development (R&D) of national mega projects in China. As an important component for constructing the collaborative partnership system, an appropriate approach of partner selection should be able to evaluate the performance of candidates objectively. Innovation alliance has members with different backgrounds, but the most suitable partner should be involved in the alliance by launcher before establishing alliance. For this reason, the aim of this paper is to take the different characteristics of organization as the influence factors into the account of weight setting, and propose a fuzzy analytic hierarchy approach (fuzzy AHP) to effectively evaluate candidates. According to the extension principle of fuzzy set theory, linguistic variables defined as fuzzy numbers are applied to pair-wise comparisons to avoid the vague situation, and this study proposes an approximate method for calculating the multiplication products of fuzzy number. This method can handle the vagueness and incompletion during the process of evaluation. A case study is also given to demonstrate the potential of the methodology.	analytical hierarchy;approximation algorithm;fuzzy number;fuzzy set;set theory;vagueness	Yang Yang;Wendai Lv;Guangming Hou;Junpeng Wang	2014	JSW	10.4304/jsw.9.11.2981-2988	knowledge management;management science	NLP	-5.5666903102473615	-17.81435261949647	16748
bcba1f683d174b7ac223a8fc2bb81c74be5baccd	dynamic space allocation for temporary storage	numerical experiment;optimal algorithm	Taylor & Francis makes every effort to ensure the accuracy of all the information (the “Content”) contained in the publications on our platform. However, Taylor & Francis, our agents, and our licensors make no representations or warranties whatsoever as to the accuracy, completeness, or suitability for any purpose of the Content. Any opinions and views expressed in this publication are the opinions and views of the authors, and are not the views of or endorsed by Taylor & Francis. The accuracy of the Content should not be relied upon and should be independently verified with primary sources of information. Taylor and Francis shall not be liable for any losses, actions, claims, proceedings, demands, costs, expenses, damages, and other liabilities whatsoever or howsoever caused arising directly or indirectly in connection with, in relation to or arising out of the use of the Content.	francis;primary source	Kap Hwan Kim;Kang Tae Park	2003	Int. J. Systems Science	10.1080/0020772031000115533	mathematical optimization;engineering;mathematics;operations research	Robotics	-14.624161329214468	-5.546146520412176	16804
c1ff8e634f2d178893cfe5b11148f95ede705254	a knowledge scoring engine (kse) for real-time knowledge base generation used in intelligent tutoring systems	human performance;intelligent tutoring system;integrable model;real time;inference mechanisms;pilot action planning knowledge scoring engine real time knowledge base generation intelligent tutoring systems computational cognitive models eye tracking human performance data knowledge inference generator student knowledge bases adapt comprehension based framework construction integration model;engines real time systems intelligent systems computational intelligence computational modeling humans computer architecture aircraft laboratories instruments;inference mechanisms intelligent tutoring systems;action plan;intelligent tutoring systems;eye tracking;cognitive model;adaptive architecture;discrete event;knowledge base	This paper provides a detailed account of a tool developed to facilitate the development of individual computational cognitive models to be used in intelligent tutoring systems (ITS). A generic tool that is called the knowledge scoring engine (KSE) reads eye tracking and human performance data in real-time, parses the data into discrete events, and uses a knowledge inference generator to build and update student knowledge bases. Student knowledge bases are generated by interpreting actions in real-time based on the context in which the actions take place. The knowledge bases generated by KSE are used by ADAPT, a comprehension-based framework construction-integration model of pilot action planning. This paper provides a detailed description of KSE, the current ADAPT architecture, how the ADAPT model interacts with KSE, and the potential for future developments.	cognitive model;eye tracking;human reliability;knowledge base;real-time locating system	Mark T. Jodlowski;Stephanie M. Doane	2004	37th Annual Hawaii International Conference on System Sciences, 2004. Proceedings of the	10.1109/HICSS.2004.1265330	cognitive model;human performance technology;knowledge base;simulation;eye tracking;computer science;knowledge management;artificial intelligence;knowledge-based systems;database	AI	-26.366903680980602	-23.56108094507844	16875
ecc5c9dc0c3ef8efb37f1041187d3eb51aa0774f	a model of institutional control	hierarchical two-player game;institutional control;lower-level player;untrue information	An hierarchical two-player game is analyzed. Player 1 delegates the right of choosing his strategies to the partner and controls the constraints imposed on the choice of the lower-level player. Moreover, the described model is shown to possess a connection to games admitting the exchange of (generally) untrue information.		Mikhail A. Gorelov	2013	Automation and Remote Control	10.1134/S0005117913030132	bayesian game;simulation;control theory	Robotics	-5.787406229194655	-3.4276862656070657	16912
c0a695ba0ac03838247e0632b48833dfcd1e7fdf	an asp-based architecture for autonomous uavs in dynamic environments: progress report.		Traditional AI reasoning techniques have been used successfully in many domains, including logistics, scheduling and game playing. This paper is part of a project aimed at investigating how such techniques can be extended to coordinate teams of unmanned aerial vehicles (UAVs) in dynamic environments. Specifically challenging are real-world environments where UAVs and other network-enabled devices must communicate to coordinate—and communication actions are neither reliable nor free. Such network-centric environments are common in military, public safety and commercial applications, yet most research (even multi-agent planning) usually takes communications among distributed agents as a given. We address this challenge by developing an agent architecture and reasoning algorithms based on Answer Set Programming (ASP). ASP has been chosen for this task because it enables high flexibility of representation, both of knowledge and of reasoning tasks. Although ASP has been used successfully in a number of applications, and ASP-based architectures have been studied for about a decade, to the best of our knowledge this is the first practical application of a complete ASP-based agent architecture. It is also the first practical application of ASP involving a combination of centralized reasoning, decentralized reasoning, execution monitoring, and reasoning about network communications. This work has been empirically validated using a distributed network-centric software evaluation testbed and the results provide guidance to designers in how to understand and control intelligent systems that operate in these environments.	aerial photography;agent architecture;algorithm;answer set programming;centralized computing;experiment;intelligent agent;logistics;multi-agent system;run time (program lifecycle phase);scheduling (computing);testbed;unmanned aerial vehicle	Marcello Balduccini;William C. Regli;Duc Nhan Nguyen	2014	CoRR		software evaluation;machine learning;architecture;computer science;software engineering;scheduling (computing);intelligent decision support system;answer set programming;testbed;artificial intelligence;agent architecture	AI	-18.40677481264134	-8.852813752342808	16914
0a7cf8deef9e01300ee73e29361e92c6b63700dc	how the number of strategies impacts the likelihood of equilibria in random graphical games	graphical games;game theory	This paper studies the likelihood of the existence of a pure Nash equilibrium (PNE) in random payoff graphical games. Here, players are represented by vertices, they choose a strategy in finite discrete sets of strategies, and the scope of a player’s utility function is only local. In this setting, the probability of existence of a PNE has been deeply studied for various graphical structures when the number of players tends to infinity, but only in the two strategies-perplayer case: this paper extends these studies to an arbitrary number of strategies-per-player. We prove theoretically how more strategies-per-player makes the distribution of the number of equilibria get closer to a Poisson distribution. We apply these results to various graph structures and conclude with numerical experiments.	experiment;graph (discrete mathematics);graphical user interface;nash equilibrium;numerical analysis;utility;vertex (graph theory)	Anisse Ismaili;Evripidis Bampis;Nicolas Maudet;Patrice Perny	2014			game theory;computer science	ECom	-4.693998607687834	-0.6181804199168934	16925
c5ac34e4572bb5f4a892b93353b39613e4068fd1	continuity properties of walras equilibrium points	market equilibrium;min sup points;utility function;lopsided convergence;equilibrium point;ky fan functions;max inf points	We explore convergence notions for bivariate functions that yield convergence and stability results for their max/inf points. The results are then applied to obtain continuity results for Walras equilibrium points under perturbations of the utility functions of the agents.	bivariate data;nash equilibrium;scott continuity	Alejandro Jofré;Roger J.-B. Wets	2002	Annals OR	10.1023/A:1021022522035	equilibrium point;mathematical optimization;calculus;mathematics;mathematical economics	Robotics	-5.101686850976672	-1.1025356605833339	17009
14d939453a397f905525990d634e4ddad476d01c	hard and soft constraints for reasoning about qualitative conditional preferences	cp nets;soft constraints;optimization problem;hard and soft constraints;computational efficiency;preferences	Many real life optimization problems are defined in terms of both hard and soft constraints, and qualitative conditional preferences. However, there is as yet no single framework for combined reasoning about these three kinds of information. In this paper we study how to exploit classical and soft constraint solvers for handling qualitative preference statements such as those captured by the CP-nets model. In particular, we show how hard constraints are sufficient to model the optimal outcomes of a possibly cyclic CP-net, and how soft constraints can faithfully approximate the semantics of acyclic conditional preference statements whilst improving the computational efficiency of reasoning about these statements.	approximation algorithm;cp/m;computational complexity theory;computers and intractability: a guide to the theory of np-completeness;constrained optimization;constraint (mathematics);constraint satisfaction problem;de morgan's laws;directed acyclic graph;experiment;formal system;fuzzy control system;hadamard transform;handbook;intelligent agent;international joint conference on artificial intelligence;machine learning;mathematical optimization;michael garey;morgan;preference elicitation;real life;solver;user (computing);wallace tree;while	Carmel Domshlak;Steven David Prestwich;Francesca Rossi;Kristen Brent Venable;Toby Walsh	2006	J. Heuristics	10.1007/s10732-006-7071-x	optimization problem;mathematical optimization;computer science;machine learning;mathematics;algorithm	AI	-8.410299039480675	2.822529134599007	17022
7ea31d93b22639bcdb1be13a752a543d3d22d182	efficient xml query processing in rdbms using gui-driven prefetching in a single-user environment	query formulation;xml query processing;experimental evaluation;biological data	In this paper, we address the problem of efficient processing of XQueries in single-user relational environment where the queries are formulated using a user-friendly GUI. We take a novel and non-traditional approach to improving query performance by prefetching data during the formulation of a query. The latency offered by GUI-based query formulation is utilized to prefetch portions of the query results. To realize this, we present an algorithm for prefetching based on data synopses statistics and GUI actions during visual query formulation. Experimental evaluation indicates that prefetching is viable as the combined time taken by all the prefetching operations is not significantly more than normal query execution time. Our experiments in the context of biological data show that prefetching improves the query response time by 7-96% with a greater improvement for larger data sets. Also, we show the impact of errors committed by users during query formulation on the query performance.	algorithm;cpu cache;efficient xml interchange;experiment;graphical user interface;input/output;link prefetching;mathematical optimization;multi-user;query optimization;query plan;relational database;response time (technology);run time (program lifecycle phase);usability	Sandeep Prakash;Sourav S. Bhowmick;Klarinda G. Widjanarko;C. Forbes Dewey	2007		10.1007/978-3-540-71703-4_68	online aggregation;sargable;query optimization;query expansion;web query classification;ranking;biological data;computer science;query by example;data mining;database;rdf query language;web search query;view;information retrieval;query language;object query language;spatial query	DB	-31.07386169470408	3.554414937830764	17048
74abe60c4bc1cabdc52f091953af6a08c5c338c0	file organization: consecutive storage of relevant records on drum-type storage		Certain structure relationships between a query set, a record set, and storage media provide an opportunity to organize the record set without redundancy on the storage media, in such a manner that all records pertinent to any query in the query set can be retrieved with minimum access time. This property between query sets and record sets has been studied for drum-type storage media. Sufficient conditions for such a property have been established. It has been shown that the two dimensional storage capability of the drum-type storage can be utilized to extend the class of query sets and record sets for which the consecutive retrieval property exists on a linear storage media.		Sakti P. Ghosh	1974	Information and Control	10.1016/S0019-9958(74)90851-1	query optimization;computer science;data mining;database;information repository;information retrieval	DB	-27.632208665778165	3.756700708207362	17064
fdc1adfa9e4b2757375cbba5383df1c58b5e448b	bounded memory and incomplete information		Abstract This paper studies incomplete information games where players observe only a summary statistic of the history, including reputation games as a special case. A recursive characterization of the equilibrium payoff set is derived for the case where time is observable, relating it to a self-generating set of tuples that capture equilibrium behavior and payoffs. With unobservable time, equilibria have a particularly simple interpretation as self-generating points. The tools are applied to a product choice game where the firm may be an “honest” commitment type and consumers have 1-period memory with imperfect monitoring, solving for the worst equilibrium payoff. The recursive algorithm shows that the observable-time game allows lower equilibrium payoffs due to non-stationary behavior.		Benjamin Sperisen	2018	Games and Economic Behavior	10.1016/j.geb.2018.01.004	mathematical economics;tuple;complete information;recursion;economics;unobservable;bounded function;stochastic game;special case;observable	ECom	-8.297956453367407	-3.835348313323234	17080
6602450cc6aa107b9ab77b19bf9dbc5ff98056a9	creating affective autonomous characters using planning in partially observable stochastic domains	affective computing appraisal computer games formal logic inference mechanisms markov processes planning artificial intelligence trees mathematics;uncertainty;affective autonomous characters planning partially observable stochastic domains nonplayer characters npc partially observable markov decision process pomdp based framework two level appraisal model emotion generation probabilistic computation tree logic pctl reasoning;psychology;probabilistic computation tree logic pctl pomdp affective computing primary and secondary emotions emotion dynamics;appraisal;appraisal computational modeling games uncertainty psychology planning markov processes;computational modeling;games;planning;markov processes;affective computing emotion dynamics pomdp primary and secondary emotions probabilistic computation tree logic pctl	The ability to reason about and respond to their own emotional states can enhance the believability of Non-Player Characters (NPCs). In this paper, we use a Partially Observable Markov Decision Process (POMDP)-based framework to model emotion over time. A two-level appraisal model, involving quick and reactive vs. slow and deliberate appraisals, is proposed for the creation of affective autonomous characters based on POMDPs, wherein the probability of goal satisfaction is used in an appraisal and reappraisal process for emotion generation. We not only extend Probabilistic Computation Tree Logic (PCTL) for reasoning about the properties of emotional states based on POMDPs but also illustrate how four reactive (primary) emotions and nine deliberate (secondary) emotions can be derived by combining PCTL with the belief-desire theory of emotion. The results of an empirical study suggest that the proposed model can be used to create characters that appear to be more believable and more intelligent.	autonomous robot;computation tree logic;markov chain;partially observable markov decision process;partially observable system;probabilistic ctl;probabilistic turing machine	Xiangyang Huang;Shudong Zhang;Yuanyuan Shang;Weigong Zhang;Jie Liu	2017	IEEE Transactions on Computational Intelligence and AI in Games	10.1109/TCIAIG.2015.2494599	planning;games;simulation;uncertainty;partially observable markov decision process;artificial intelligence;machine learning;markov process;computational model;statistics	AI	-22.311501783273908	-19.437154616651213	17086
57e2f2b64adddac3758e668099dd9f2d84fc6bce	preliminary report on a program for generating natural language	working paper	A p r o g r a m f r a m e w o r k has been designed in which the l ingu is t ic facts and heurist ics necessary for generating fluent n a t u r a l l anguage can be encoded. The l inguist ic data is represented in annotated procedures and data structures which are designed to make English translations of already formulated messages given in a primary program's internal representation. The messages must include the program's intentions in saying them, in order to adequately specify the grammatical operations requ i red for a translation. The pertinant questions in this research have been: what s t r u c t u r e does natural language have that allows it to encode mutifaceted messages; and how must that structure be taken into account in the design of a generat ion facil i ty for a computer program. This paper describes the control and data structures of the des ign and and their mot ivat ion. It is a condensation of my Master's Thesis <1>, to which the reader is retered for further i n fo rma t ion . Work is present ly underway on implementing the design in LISP and developing a grammar for use in one or more of the domains given below.	computer program;data structure;encode;lisp;natural language	D. McDonald	1975			natural language processing;computer science;artificial intelligence;machine learning;mathematics;programming language;algorithm	AI	-32.227537929218556	-13.67739181985121	17153
e3b3330aa50a3c78347af05bba8fd947493e79a9	agent modeling in expert critiquing systems	agent modeling;model performance;collaborative system;error rate;problem solving	Expert critiquing systems are a type of humancomputer collaborative system in which a computer agent presents reasoned opinions about a human agent’s problem-solving process for a given task. The challenge in such systems is to provide timely critiques relevant to the user’s focus of attention. A problem with many expert critiquing systems is that their critiques are not always timely or relevant; consequently such systems interfere with problem-solving rather than provide assistance. The problem arises in part from insufficient representations of the human’s problem-solving processes. In this paper, we discuss the flexible use of an agent model based on a task-decomposition hierarchy of human experts in a critiquing system called SEDAR. The model differs from previous research efforts in three ways: 1) the structure of the model, 2) the function the model performs in the expert critiquing system, and 3) the influence of the model on communication between the computer and human agents. A prototype of SEDAR was implemented for the flat and low-slope roof design domain. The results of early testing on the prototype show that SEDAR assists users effectively and reduces the error rate.	computer simulation;problem domain;problem solving;prototype;software agent;system for electronic document analysis and retrieval	Michael Chin-Ming Fu;Caroline C. Hayes	1996			simulation;word error rate;computer science;knowledge management;artificial intelligence	AI	-22.815026379952304	-9.043517620933638	17212
b99da8d3f7af15844c73fa735615a39658d14c9b	"""the """"mind or no-mind"""" dilemma in agents behaving in a market"""	swarm;economic simulation;agent based models	"""In computer simulation models based upon agents, what is the degree of sophistication that we have to put into the agents? Should we provide them or not with a “mind”? The answer ranges from Axelrod’s simplicity principle to the use of full BDI (Beliefs, Intentions, Desires) cognitive agents. To discuss the subject we introduce here three models: one with “no-mind” agents that operate in an unstructured market, the second with “minded” agents assuring some stability to an emerging unstructured market and, finally, the third with no mind agents, that show a sophisticated outcome in a structured market. No generalised results come from this presentation, but many useful doubts. RÉSUMÉ: Quel degré de complexité faut-il introduire dans un modèle de simulation fondé sur des agents? Doivent-ils disposer d'un """"esprit""""? Nous présentons ici trois modèles qui utilisent des agents, avec et sans """"esprit"""", et ou les résultats obtenus sont très différents suivant la structure du marché dans lequel opèrent les agents."""	ansi escape code;computer simulation;estimation of signal parameters via rotational invariance techniques;intelligent agent;linear algebra;mind;quel;sans institute	Pietro Terna	2000	Advances in Complex Systems	10.1142/S0219525900000194	swarm behaviour;simulation;economics;artificial intelligence;social psychology	AI	-20.45685629030949	-13.599637099601798	17217
b4fd1de570be14f66a6460cba1e4a671fb1fe0ef	hierarchical credit allocation in a classifier system	classifier system;learning system	"""Learning systems which engage in sequential activity face the problem of properly allocating credit to steps or actions which make possible later steps that result in environmental payoff. In the classifier systems studied by Hol-land and others, credit is allocated by means of a """"bucket-brigade"""" algorithm through which, over time, environmental payoff in effect Bows back to classifiers which take early, stage-setting actions. The algorithm has advantages of simplicity and locality, but may not adequately reinforce long action sequences. We suggest an alternative form for the algorithm and the system's operating principles designed to induce behavioral hierarchies in which modularity of the hierarchy would keep all bucket-brigade chains short, thus more reinforceable and more rapidly learned, but overall action sequences could be long. I INTRODUCTION Many learning systems face the problem of temporal credit allocation: the proper reinforcement of activities which do not directly result in need satisfaction or external reward but are nevertheless essential precursors to such outcomes. Animals learn extensive hunting, stalking , or foraging behaviors aimed at the ultimate payoff of something to eat. A person who values others' cooperation must discover and reinforce effective precursor strategies. In the message-passing, rule-based classifier systems (Holland, 1986), credit is allocated by means of a """"bucket-brigade"""" algorithm to earlier-acting rules which """"set the stage"""" for later actions that bring external payoff. The essential idea is that classifiers which match messages and become active on a given time step """"pay"""" a fraction e of their """"strengths"""" to the strengths of the classifiers which posted the messages and were active on the previous time step. When finally external payoff enters the system, it is added to the strengths of the then currently active classifiers. If over time a given payoff-achieving sequence gets repeated, strength increments will in effect flow back to reinforce its early-acting classifiers. Consequently , early-acting classifiers that indeed participate in sequences that make possible later payoff will, by the algorithm, receive due credit. In certain other AI systems which learn to perform multiple-step tasks [e.g., Mitchell's LEX system for symbolic integration (Mitchell, Utgoff, and Banerji, 1983), and the ACT"""" cognitive architecture of Anderson (1983)], credit is assigned to early steps by keeping and analysing a record of all pre-payoff actions, both considered and taken, and the associated reasoning. In contrast, Hol-land's bucket brigade technique does not depend on retrospective analysis but operates locally, during performance , in the strength …"""	active galactic nucleus;algorithm;cognitive architecture;learning classifier system;lex (software);locality of reference;logic programming;machine learning;message passing;mitchell corporation;symbolic integration	Stewart W. Wilson	1987			simulation;computer science;artificial intelligence;machine learning	AI	-15.814804558093753	-17.916846166216352	17286
dac12441965eca66ad5bee64ea6cde56ea62d503	fuzzy inference approach to uncertainty in budget preparation and execution		In recent times, diverse uncertainties in the global economic environment have made it difficult for most countries to meet their financial obligations. For example, according to statistics from European Commission, 24 out of 29 recorded European Economic Area member countries had budget deficits in 2014. Therefore through modelling and simulations, this paper proposes flexible decision support schemes that could be used in managing the uncertainties in budgeting. Rather than entirely relying on estimates of anticipated revenues (which are uncertain and difficult to predict) in government budgeting, the scheme proposes incorporating fuzzy inference systems (which is able to capture both the present and future uncertainty) in predicting the anticipated revenues and consequently, in proposing government expenditures. The accuracy of fuzzy rule base helps in mitigating adverse effects of uncertainties in budgeting. We illustrated the proposed scheme with a case study which could easily be adapted and implemented in any budgeting scenarios.		Festus Oluseyi Oderanti	2016		10.1007/978-3-319-32877-5_5	real-time computing;adaptive neuro fuzzy inference system;computer science;machine learning;data mining	SE	-7.114404543430024	-14.513099718524867	17376
ddb23841f0086b957170a78e65c3a9d9095f06d9	a critique of qualitative simulation from a consolidation viewpoint	simulation;artificial intelligence expert systems robustness power system modeling water heating problem solving analytical models fires laboratories information science;simulation artificial intelligence;qualitative reasoning artificial intelligence qualitative simulation consolidation viewpoint problem solving;artificial intelligence	To understand commonsense reasoning, we need to discover what kinds of problems a commonsense reasoner should be able to solve, what the reasoner needs to have in order to solve those problems, and the relationships among the various kinds of problem solving abilities. The paper examines four methods for performing qualitative reasoning about the behavior of physical situations. Three of the methods perform qualitative simulation, which determines the behavior of a situation by a qualitative version of simulation methods. The other method is called consolidation, which derives the behavior of a situation by composing the behavior of the situation’s components. Ihe work shows that qualitative simulation and consolidation work on different problems of qualitative reasoning, and that their differences and similarities lead to several implications about their role in qualitative reasoning.	commonsense reasoning;problem solving;semantic reasoner;semiconductor consolidation;simulation	Tom Bylander	1988	IEEE Trans. Systems, Man, and Cybernetics	10.1109/21.3464	commonsense reasoning;simulation;qualitative reasoning;computer science;artificial intelligence;model-based reasoning;machine learning;management science	AI	-26.234273023018105	-10.163077774841462	17397
7c37fffc892b1bc43be69d3e7c377e7013dde5f1	dynamic model development of performance indices for planning of sustainable transportation systems	environmental factors;environment system dynamic model development performance index sustainable transportation system economic environmental system interdependent behavior predator prey model interdependent system nonlinear modeling technique activity system periodic behavior phase lag;transportation system management;environmental impacts;mathematical model transportation equations predator prey systems sociology statistics biological system modeling;predator prey systems;biological system modeling;transportation economics environmental factors predator prey systems sustainable development;dynamics;transportation;statistics;mathematical model;economic development;economics;performance measurement;sociology;sustainable development	Sustainability has recently become a very important research area in transportation because of the dependencies between transportation, economic and environmental system. A lot of research is taking place in various aspects that try to understand the interdependencies. However, there is a need to capture the behavior of such systems over time. The research presented in this paper is the first attempt to build dynamic models that try to capture the interdependent behavior of these systems. The research is influenced and motivated by the predator-prey models developed by renowned researchers Lotka and Volterra. The current study is performed to capture the interaction between interdependent systems i.e. transportation system, activity system, and environmental system. To study the interactions from a macro-scale, this research emphasizes non-linear modeling techniques to capture the nominal behavior of all the three systems. The results indicate that the performance of transportation system and the activity system follow a periodic behavior with phase lag, while the performance of environment system decreases with time. The modeling approach proposed in this research will be helpful to other researchers so that they can modify and enhance such models for proper analysis of sustainable systems.	interaction;interdependence;lotka–volterra equations;nonlinear system;prey	Pankaj Maheshwari;Romesh Khaddar;Pushkin Kachroo;Alexander Paz;Neveen Shlayan	2012	2012 15th International IEEE Conference on Intelligent Transportation Systems	10.1109/ITSC.2012.6338861	simulation;system of systems;engineering;operations management;ecology	Robotics	-15.888989461393649	-19.959563451141907	17442
358e33ffd72b64ed5797ac4e4ff4960b681d239f	fiscal equalisation: principles and an application to the european union	theoretical model;fiscal equalisation;agricultural sector;finanzausgleich;european union;working paper;eu staaten;theorie	The paper derives a normative model for partial fiscal equalisation based on a number of axioms and allows for the existence of a specific fiscal need in the jurisdictions. The theoretical model is then empirically tested for the case of the European Union using data from 1986-97. It is found that most restrictions of the model appear to hold, in particular, relatively richer countries contribute more and those with greater fiscal needs, approximated by the importance of the agricultural sector, pay less. However, in the EU, an adjustment of net payments to changes in the actual importance of the spe-cific fiscal need for a country is lacking. JEL Classification: H77, H87. Bernd Hayo Department of Economics University of Essen 45117 Essen Germany bhayo@vwl.uni-essen.de Matthias Wrede Department of Economics and Business Administration Aachen University 52056 Aachen Germany mwr@fiwi.rwth-aachen.de The paper was presented at the CESifo Area Conference on Public Sector Economics 2001 in Munich and at a research seminar in Berlin. Thanks to the participants, Matthias Brückner, Johann Brunner, Jeremy Edwards, Friedrich Heinemann, Eckhard Janeba, Roland Strausz, and Alfons Weichenrieder for helpful comments. Special thanks to an anonymous referee for many detailed suggestions. All remaining errors are our own.	adaptive equalizer;approximation algorithm;theory	Bernd Hayo;Matthias Wrede	2004	Social Choice and Welfare	10.1007/s00355-003-0252-8	fiscal union;economics;public economics;economy;law;welfare economics	ML	-7.796203953459397	-4.5885060448686845	17493
ffbcbc35fae39e9e539752562e25d8a7b3770094	the advent of cryptology in the game of bridge	bridge;cryptology	Taylor & Francis makes every effort to ensure the accuracy of all the information (the “Content”) contained in the publications on our platform. However, Taylor & Francis, our agents, and our licensors make no representations or warranties whatsoever as to the accuracy, completeness, or suitability for any purpose of the Content. Any opinions and views expressed in this publication are the opinions and views of the authors, and are not the views of or endorsed by Taylor & Francis. The accuracy of the Content should not be relied upon and should be independently verified with primary sources of information. Taylor and Francis shall not be liable for any losses, actions, claims, proceedings, demands, costs, expenses, damages, and other liabilities whatsoever or howsoever caused arising directly or indirectly in connection with, in relation to or arising out of the use of the Content.	cryptography;francis;primary source	Peter Winkler	1983	Cryptologia	10.1080/0161-118391858053	simulation;computer science;mathematics;computer security;bridge;statistics	Robotics	-15.185234480755476	-5.559883384290323	17495
cf54cffdbd5471237be87ead1a23fd26cfd52e61	exploring agent architectures for farmer behavior in land-use change. a case study in coastal area of the vietnamese mekong delta	bdi architecture;agent based simulation;mekong delta;land use change;agent architecture;systeme multi agents	Farmers are the key actors of land-use change processes. It is thus essential to choose a suitable architecture for farmer behavior to model such processes. In this paper, we compared three models with different architectures to model the farmer behavior in the coastal areas of the Ben Tre province: (i) The first one is a probabilistic model that allows farmer to select the land-use pattern based on land change probability; (ii) The second model is based on multi-criteria decision making and takes into account the land suitability of the parcel and the farmer benefit; (iii) The third model used a BDI (Beliefs Desires Intentions) architecture. For each of these models, we have compared the difference between simulated data and real data by using the Fuzzy Kappa coefficient. The results show the suitability of the BDI architecture to build land-use change model and to support decision-making on land-use planning.		Quang Chi Truong;Patrick Taillandier;Benoit Gaudou;Minh-Quang Vo;Trung Hieu Nguyen;Alexis Drogoul	2015		10.1007/978-3-319-31447-1_10	agent architecture;biology;land use, land-use change and forestry;computer science;artificial intelligence	ML	-15.329757106271122	-20.626329040008294	17509
af4a5ef667d689635f32c4942f672bd51c3b3bdb	intelligent multi-stakeholder environmental management	watershed management;aggregation operator;stakeholders weight;consensus measure;group decision making;environmental management;fuzzy linguistic quantifiers	In any group decision making, stakeholders have different powers, proficiency and also experiences. These power weights are very difficult to obtain, because group managers avoid revealing the relative powers of the stakeholders to prevent more conflict among them. Therefore, in many studies, the different powers have not been well accounted and then equal power weights have been assigned to each stakeholder. This paper will show that considering the powers is necessary and then it introduces a new intelligent approach to obtain consensus based relative power weights. This method is based on the opinions of the stakeholders on the alternatives. A case study of watershed management is used to illustrate the application of the model to a real decision making problem. A suitable aggregation operator is also used to combine the goodness measures, considering the optimism/pessimism view of the group manager. Results indicate that obtaining the stakeholders’ weights and also considering the preferences of the group manager on the risk are essential parts for soft group decision making process, especially in the environmental management problems. 2010 Elsevier Ltd. All rights reserved.	environmental resource management;experience;group policy;watershed (image processing)	Hojjat Mianabadi;Abbas Afshar;Mahdi Zarghami	2011	Expert Syst. Appl.	10.1016/j.eswa.2010.07.054	watershed management;group decision-making;knowledge management;management science	AI	-5.321631568998288	-17.032798822435627	17607
56a28fb96efa0bb6f738fd61cc208439ea4d85ab	representing the insincere: strategically robust proportional representation		Proportional representation (PR) is a fundamental principle of many democracies world-wide which employ PR-based voting rules to elect their representatives. e normative properties of these voting rules however, are oen only understood in the context of sincere voting. In this paper we consider PR in the presence of strategic voters. We construct a voting rule such that for every preference profile there exists at least one costly voting equilibrium satisfying PR with respect to voters’ private and unrevealed preferences – such a voting rule is said to be strategically robust. In contrast, a commonly applied voting rule is shown not be strategically robust. Furthermore, we prove a limit on ‘how strategically robust’ a PR-based voting rule can be; we show that there is no PR-based voting rule which ensures that every equilibrium satisfies PR. Collectively, our results highlight the possibility and limit of achieving PR in the presence of strategic voters and a positive role for mechanisms, such as pre-election polls, which coordinate voter behaviour towards equilibria which satisfy PR.	converge;deterministic algorithm;intermediate representation;microsoft outlook for mac;robustness (computer science);rule 184	Barton E. Lee	2018	CoRR		mathematics;normative;mathematical economics;sincere voting;proportional representation;welfare economics;voting;existential quantification	AI	-7.123789689303376	-3.220472816873943	17663
075fa0463b76e2d2d89f05dc49eab9a86ca548f7	with a spoon in hand this must be the eating frame	language comprehension;indexation	"""A language comprehension program using """"frames"""", """"scripts"""", etc. must be able to decide which frames are appropriate to the text. Often there will be explicit indication (""""Fred was playing tennis"""" suggests the TENNIS frame) but it is not always so easy. (""""The woman waved while the man on the stage sawed her in half"""" suggests MAGICIAN but how?) This paper will examine how a program might go about determining the appropriate frame in such cases. At a sufficiently vague level the model presented here will resemble that of Minsky (1975) in it's assumption that one usually has available one or more context frames. Hence one only needs worry if information comes in which does not fit them. As opposed to Minsky however the suggestions for new context frames will not come from the old ones, but rather from the conflicting information. The problem them becomes how potential frames are indexed under the information which """"suggests"""" them."""	drew mcdermott;fred (chatterbot);vagueness	Eugene Charniak	1978		10.3115/980262.980294	psychology;simulation;communication;social psychology	AI	-12.695118742354527	2.8638813029115853	17755
ee65226536fdea351b57b7f1c47088bf607b87b7	migrating auctioneers on internet auctions for improved utility and performance	simulated annealing;internet auction;simulation study;quality of service	The paper studies a technique to improve the utility and performance of an automated auction application where the auctioneer and bidders communicate through the Internet. The lack of quality-of-service guarantees from site to site can severely influence the results of an auction by affecting the seller's income rate, auction fairness, and overall protocol efficiency. By properly identifying and migrating auctioneers to suitable hosts on the network, it is shown that the expected seller's utility can be improved along with other metrics of interest. The paper proposes a scalable approach to conduct the host search on a large network by applying the Simulated Annealing metaheuristic in conjunction with network probing. A detailed simulation study assess the performance of the system and quantifies the benefits of the proposal.		Ricardo Lent	2009		10.1007/978-3-642-02924-0_13	auction algorithm;simulation;marketing;business;auction theory;commerce	ECom	-5.799664732659691	-8.403807496559486	17764
78409fb8ce6b8b4981ec7c5878246f95de15fd81	using conceptual structures to translate data models: concepts, context and cognitive processes	working group;conceptual analysis;data model;cognitive process;knowledge representation;mental model	Sowa's conceptual structures work is broadly framed in terms of logic, linguistics, knowledge representation, conceptual analysis and mental models. Recently the CG representation has been proposed as a normative language for metalevel descriptions of traditional data models by the ANSI Information Resource Directory System (IRDS) working group (X3H4). This paper explores some issues that arise from attempts to use ontologies and crystallized representations to perform such things as data model translation and integration. Issues and alternate views that grow out of Sowa's knowledge soup metaphor are described and a functional architecture is proposed that addresses some of these issues. The notions of model knowledge as a dynamic and cognitive construction based on contexts is developed and combined with the idea of global workspaces.	cognitive science;personal knowledge base	Gary Berg-Cross;John Hanna	1992		10.1007/3-540-57454-9_14	knowledge representation and reasoning;data modeling;conceptual model;working group;cognition;data model;computer science;knowledge management;conceptual schema;artificial intelligence;conceptual model;conceptual system;management science;logical data model	SE	-29.65290244104622	-3.2916129018141533	17821
f349702d487ec08f9ef4c12b814672995275172d	distributed and incremental visual object categorization for humanoid platform nao		"""Robotics is an essential component of current and future technological existence of mankind. Interaction between human and technology such as robots and their coexistence with humans will be extremely important. In fact, a fully embodied intelligence is one version of the future but another option is distributed intelligence when a part of intelligence is """"somewhere in the Cloud"""", and the second part is on the robot itself. Certainly there are several questions about connectivity and reduced activity in case of off-line robot life comparing to life in on-line robot existence. Meanwhile, a notion of Cloud Robotics came out, and it brings new challenges and endless possibilities for the future. The paper gives theoretical and experimental research about utilization of selected Neural technology specifically modified MF-ARTMAP neural network for object categorization. We used the categorization test-bed a Humanoid platform NAO connected to Global framework (MASS), which categorize in distributive and incremental approach objects. This approach creates a power of sharing knowledge among other robots and building collective intelligence. Papers gives the results of a pilot study and refers about preliminary results on different experimental data with building a database of objects on off-robot ecosystem. The system also works with fuzzy logic relations among objects and maintain a list of statements about the relationship between objects seen by the robot."""	categorization;nao (robot)	Peter Sincak;Peter Smolar;M. Vircik;Martin Pala	2012		10.1007/978-3-642-37374-9_69	computer vision;simulation;computer science;artificial intelligence;machine learning	Vision	-25.644814516434145	-17.46574138206013	17910
abbeb4e0866add96cad93946ee5ed78aadaa0a59	scidfs: an in-situ processing system for scientific array data based on distributed file system		Recently, the amount of array data generated by scientific observation instruments increases rapidly. The array data is usually stored in standard formats such as HDF5 and NetCDF. To support high-level queries on the array data, a number of array DBMSs such as SciDB have been proposed. However, they typically have two drawbacks: slow data loading and not directly supporting standard formats. In particular, slow data loading is fatal since the speed of scientific data generation might be faster than that of data loading. To solve those drawbacks, we propose a distributed in-situ processing system called SciDFS that exploits a distributed file system (DFS) for storing and managing array data. SciDFS is a hybrid system that tightly integrates the query processing layer of an array DBMS with a DFS via an in-situ layer. It stores raw array data as DFS blocks very fast and processes queries in an in-situ manner by accessing the relevant DFS blocks. Through experiments using NASA's real satellite array data, we have shown three major features of SciDFS: high performance data loading (50X faster than SciDB), fast in-situ query processing performance, and running legacy applications for the HDF5 format.	array dbms;clustered file system;dce distributed file system;database;experiment;hierarchical data format;high- and low-level;hybrid system;netcdf;scidb	Donghyoung Han;Yoon-Min Nam;Min-Soo Kim;Kyongseok Park;Sunggeun Han	2018	2018 IEEE International Conference on Big Data and Smart Computing (BigComp)	10.1109/BigComp.2018.00062	distributed file system;array dbms;database;hierarchical data format;hybrid system;legacy system;netcdf;test data generation;distributed database;computer science	DB	-31.281184638447435	0.6349662622525087	17925
5ab84267e2604422a76a6e4f7fd3b4ad780085c1	a three-stage colonel blotto game: when to provide more information to an adversary		In this paper, we formulate a three-player three-stage Colonel Blotto game, in which two players fight against a common adversary. We assume that the game is one of complete information, that is, the players have complete and consistent information on the underlying model of the game; further, each player observes the actions taken by all players up to the previous stage. The setting under consideration is similar to the one considered in our recent work [1], but with a different information structure during the second stage of the game; this leads to a significantly different solution. In the first stage, players can add additional battlefields. In the second stage, the players (except the adversary) are allowed to transfer resources among each other if it improves their expected payoffs, and simultaneously, the adversary decides on the amount of resource it allocates to the battle with each player subject to its resource constraint. At the third stage, the players and the adversary fight against each other with updated resource levels and battlefields. We compute the subgameperfect Nash equilibrium for this game. Further, we show that when playing according to the equilibrium, there are parameter regions in which (i) there is a net positive transfer, (ii) there is absolutely no transfer, (iii) the adversary fights with only one player, and (iv) adding battlefields is beneficial to a player. In doing so, we also exhibit a counter-intuitive The corresponding author for this article is Abhishek Gupta. Research was supported in part by AFOSR MURI Grant FA9550-10-1-0573, and in part by NSA through the Information Trust Institute of the University of Illinois. The research by Galina Schwartz is supported by NSF grant CNS-1239166, which provides funding for a frontier project FORCES (Foundations of Resilient CybEr-Physical Systems), NSF grant CNS-0910711, and by TRUST (Team for Research in Ubiquitous Secure Technology), which receives support from the NSF (#CCF-0424422) and the following organizations: AFOSR (#FA9550-06-1-0244), BT, Cisco, DoCoMo USA Labs, EADS, ESCHER, HP, IBM, iCAST, Intel, Microsoft, ORNL, Pirelli, Qualcomm, Sun, Symantec, TCS, Telecom Italia, and United Technologies. The authors would like to thank the anonymous referees for helpful suggestions. R. Poovendran and W. Saad (Eds.): GameSec 2014, LNCS 8840, pp. 216–233, 2014. c © Springer International Publishing Switzerland 2014 A Three-Stage Colonel Blotto Game 217 property of Nash equilibrium in games: extra information to a player in the game does not necessarily lead to a better performance for that player. The result finds application in resource allocation problems for securing cyber-physical systems.	adversary (cryptography);computation;cyber-physical system;data center;ibm notes;information trust institute;lecture notes in computer science;nash equilibrium;server (computing);springer (tank);switzerland;yousef saad	Abhishek Gupta;Tamer Basar;Galina Schwartz	2014		10.1007/978-3-319-12601-2_12	non-cooperative game;bayesian game;simulation;extensive-form game;simultaneous game;engineering;information set;repeated game;stochastic game;strategy;screening game;outcome;operations research;computer security;complete information;equilibrium selection	Theory	-8.874734327744028	-5.358427427822136	17940
ac37498ab93bfdb00e237c1d8063ee611e2d1865	the analysis of amodal completion for modeling visual perception		The challenge of creating a real-life computational equivalent of the human mind encompasses several aspects. Of fundamental relevance is to understand the cognitive functions of natural intelligent systems. Most of human brain is devoted to perceptual tasks which are not purely perceptive but convey also emotional competence.		Liliana Albertazzi;James Dadam;Luisa Canal;Rocco Micciolo	2012		10.1007/978-3-642-34274-5_60	cognitive psychology;amodal perception;emotional competence;intelligent decision support system;perception;human brain;psychology;cognition;visual perception	Robotics	-25.873443602479494	-14.935922059986188	17958
facd2d000a40f84322beeb1fb61bb6df3dcd6c85	proceedings of the sixth international workshop on machine learning (ml 1989), cornell university, ithaca, new york, usa, june 26-27, 1989		"""This paper presents a new approach to combining explanation-based and empirical learning called Induction Over the Unexplained (IOU). Unlike other approaches to integrated learning, which use one method to focus the other or provide it with information, IOU uses each method to learn a different part of the final concept definition. It is therefore suited for learning concepts with both explainable and unexplainable aspects. An initial nonincremental feature-based implementation of IOU is presented together with an example illustrating IOU's advantage over a purely empirical or analytical system and over other integrated learning systems such as IOE. INTRODUCTION Current approaches to integrating empirical and explanation-based learning (EBL) methods use one of the methods to focus the other method or supply it with needed information (e.g. [Flann88, Lebowitz86, Pazzani88]). Although the first method helps to bias the overall system in these approaches, the final concept definition is com­ pletely constructed by the second method. An alternative approach is to use each method to learn different aspects of individual concepts. Many concepts have aspects which can be explained in terms of functionality or intentionality as well as others apspects which cannot be explained by the current theory, and may be just """"conventional."""" We are developing a learning technique called Induction Over the Unexplained (IOU), which combines EBL and empir­ ical techniques to efficiently learn both explanatory and nonexplanatory aspects of a concept. This paper describes the basic IOU approach and presents an initial implementation of IOU. THE IOU APPROACH Many important concepts have both explanatory and nonexplanatory aspects. Scripts for events such as a birthday party or a wedding have goal-directed as well as ritualistic actions. Concepts for artifacts such as a cup or a building have functionally important features as well as aesthetic or conventional ones. Animals have some attri­ butes with clear survival value as well as more obscure features. Diseases have some symptoms which can be causally explained by current biological theory as well as others which are simply known to be correlated with the condition. The general method we are proposing for learning such concepts is to use EBL techniques to learn as much as possible and then use similarity-based learning (SBL) methods to detect regularities in the unexplainable aspects of the examples and thereby add ' 'conventional'' features to the concept definition. Features which can be explained are learned from a single instance using standard explanation-based learning techniques. These aspects are then removed from the initial example and all subsequent examples and the reduced example descriptions are passed on to an empirical system which finds additional commonalities and adds them to the concept definition. In IOU, SBL complements EBL's inability to learn unexplainable features of a concept. On the other hand, EBL immediately identifies certain features as important, resulting in early and efficient learning of these aspects of the concept. In previous research, the approach has been to focus the SBL component on aspects of the examples which explanations reveal may be relevant. In IOU, the approach is to allow EBL to eliminate those features which explanations reveal are definitely relevant and focus on unexplained aspects of the examples. The general problem IOU addresses is the theory-based concept specialization problem [Flann88]. The sys­ tem is assumed to have a correct theory for a generalization of the concept to be learned. The theory is incomplete in that it is incapable of justifying the restrictions necessary for the specialized concept. As an example of a * This research was partially supported by the University Research Institute and the Department of Computer Sciences at the University of Texas at Austin. 6 Mooney and Ourston problem suitable for IOU, consider the classic CUP example. The domain theory is the standard one except the """"target"""" concept is renamed DRINKING-VESSEL since the theory cannot actually distinguish between the concepts CUP, GLASS, MUG, SHOT-GLASS etc.. STABLE(x) ALIFTABLE(x) AOPEN-VESSEL(x) -> DRINKING-VESSEL(x) HAS-BOTTOM(x) A FLAT-BOTTOM(x) -> STABLE(x) GRASPABLE(x) ALIGHT(x) -> LIFTABLE(x) HAS-HANDLE(x) -* GRASPABLE(x) WIDTH(x, SMALL) A INSULATING« -> GRASPABLE(x) HAS-CONCAVITY(x) A UPWARD-POINTING-CONCAVITY(x) -» OPEN-VESSEL(x) Assume the set of examples includes cups, shot-glasses, mugs and cans as shown in Table 1. The problem is to use the domain theory and explanation-based techniques to learn the explainable features of a cup and to use empirical techniques to learn the nonexplanatory features which rule out shot glasses and mugs. AN INITIAL IOU ALGORITHM The current implementation of IOU is nonincremental and restricted to a purely featural language. A descrip­ tion of the basic algorithm used by the current system is show below: 1) Compute and generalize proofs demonstrating that each positive example is an instance of the overlygeneral """"target"""" concept. 2) Disjunctively combine the resulting definitions to form the explanatory component (Ce) of the concept. 3) Disregard any negative examples which do not satisfy the explanatory component. 4) Remove features mentioned in the explanatory component from the descriptions of the positive examples and remaining negative examples. 5) Give the """"reduced"""" set of examples to a standard inductive learning from examples system to compute the nonexplanatory component of the concept (Cn) 6) Output: Ce ACn as the final concept description. Step one uses standard EBL techniques to construct and generalize explanations for each of the positive examples. A version of the EGGS system [Mooney88] is used for this task. Step two combines the resulting definitions dis­ junctively to form the explanatory component of the concept. For the CUP example, this produces the following definition for C : e HAS-BOTTOM(x) Λ FLAT-BOTTOM(x) AHAS-CONCAVTTY(x) A UPWARD-POINTING-CONC AVITY(x) ALIGHT(x) A [ HAS-HANDLE(x) V { WIDTH(x,SMALL) A INSULATING« } ] Step three eliminates negative examples which do not satisfy the explanatory constraints on the concept. Since the explanatory component adequately explains why these examples cannot be members of the concept, there is no need to pass them along to the empirical system. In the CUP example, the negative CAN-1 instance can be discarded since it does not quite meet the functional requirements of a drinking vessel. Step four removes the explained features of the remaining examples to allow the empirical component to focus on their unexplained aspects. The resulting reduced set of data for the example is show in Table 2. In step five, the unexplained data is given to a stan­ dard empirical system for learning from examples. We currently have implementations of the version-space Table 1. Examples for Learning CUP NAME(CLASS) CUP-1(+) CUP-2(+) SHOT-GLASS-l(-) MUG-1(-) CAN-l(-) BOTTOM YES YES YES YES YES FLAT YES YES YES YES YES CONC YES YES YES YES YES UP LIGHT YES YES YES YES YES YES YES YES YES YES HANDLE YES NO NO YES NO WIDTH INSUL SMALL NO SMALL YES SMALL YES MED NO SMALL NO COLOR WHITE RED CLEAR COPPER SILVER VOLUME SMALL SMALL TINY LARGE SMALL SHAPE CYLINDER CYLINDER CYLINDER CYLINDER CYLINDER Table 2. Reduced Examples for CUP NAME(CLASS) CUP-1(+) CUP-2(+) SHOT-GLASS-l(-) MUG-l(-) COLOR VOLUME SHAPE WHITE SMALL CYLINDER RED SMALL CYLINDER CLEAR TINY CYLINDER COPPER LARGE CYLINDER Induction Over the Unexplained 7 algorithm, ID3, and A, any of which can be used as the empirical component of IOU. For the example, all of these systems generate the same most-general (simplest) description for Cn: VOLUME(x,SMALL). The version-space algorithm also generates the most specific description: VOLUME(x, SMALL) A SHAPE(x, CYLINDER). The final step of IOU simply conjunctively combines the explanatory and nonexplanatory descriptions into a final concept definition. There are two important aspects to notice about IOU's use of the SBL component. First, it can use any SBL system which supports the description language used by the overall system since the IOU algorithm is independent of the details of the SBL component. Even a neural-net learning algorithm can be used to learn the nonexplanatory part of the concept. Second, the amount of data given to the SBL component can be greatly reduced by the EBL component. This decreases computational complexity and helps focus the empirical component. IOU VERSUS PURE SBL AND IOE By using an existing domain theory to learn the explanatory part of a concept and to focus empirical learning on unexplained features, IOU is capable of learning a concept from many fewer examples than a purely empirical system. When ID3 and A are run on the original examples shown in Table 1, their bias for simple hypotheses causes them to focus on the irrelevant feature, COLOR, and construct the erroneous definition: COLOR(x, RED) V COLOR(x,WHITE). ID3 or A would require a much larger set of examples to learn the correct definition. Comprehensive experiments and formal analysis are needed to better determine the advantage IOU has over a purely empirical system. Many approaches to combining EBL and SBL are also inappropriate for learning concepts with explanatory and conventional aspects. For example, Induction Over Explanations (IOE) [Flann88] is incapable of learning such concepts since it assumes that all relevant features are present in the explanations of the examples. If IOE is applied to the example presented above, the resulting concept description is identical to the explanatory component learned by IOU which fails to correctly classify all of the examples in Table 1. CONCLUSIONS AND FUTURE RESEARCH IOU is an integrated learning mechanism for acquiring concepts with both explanatory and nonexplanatory aspects. It combines existing explanation-based and s"""	a* search algorithm;artificial neural network;cups;carrier-to-noise ratio;color;computational complexity theory;computer science;concept image and concept definition;domain theory;experiment;explanation-based learning;functional requirement;glass;id3 algorithm;inductive reasoning;intentionality;machine learning;partial template specialization;relevance;small;single-instance storage;ical	June;EDITORAWORKSHOP CHAIR;Alberto Maria Segre;John Galbraith	1989				AI	-19.957569262394248	-5.046940220613245	18194
165df04c43467c2723ae0c7ba3b1a7ed96f1b1ca	transportability from multiple environments with limited experiments: completeness results		This paper addresses the problem of mz-transportability, that is, transferring causal knowledge collected in several heterogeneous domains to a target domain in which only passive observations and limited experimental data can be collected. The paper first establishes a necessary and sufficient condition for deciding the feasibility of mz-transportability, i.e., whether causal effects in the target domain are estimable from the information available. It further proves that a previously established algorithm for computing transport formula is in fact complete, that is, failure of the algorithm implies non-existence of a transport formula. Finally, the paper shows that the do-calculus is complete for the mz-transportability class.	algorithm;approximation;causal filter;complete (complexity);sharp mz	Elias Bareinboim;Judea Pearl	2014			mathematical optimization;discrete mathematics;mathematics;algorithm	ML	-10.034949167017073	1.0788587568976613	18227
4aca88f10986ccb0f2278145ff7bc7cb826d933d	contracting experts with unknown cost structures		We investigate the problem of a principal looking to contract an expert to provide a probability forecast for a categorical event. We assume all experts have a common public prior on the event’s probability, but can form more accurate opinions by engaging in research. Various experts’ research costs are unknown to the principal. We present a truthful and efficient mechanism for the principal’s problem of contracting an expert. This results in the principal contracting the best expert to do the work, and the principal’s expected utility is equivalent to having the second best expert in-house. Our mechanism connects scoring rules with auctions, a connection that is useful when obtaining new information requires costly research. ∗Princeton University, research partially supported by an Alfred P. Sloan Fellowship, an NSF CAREER award, and a Turing Centenary Fellowship. †Princeton University 1 ar X iv :1 40 4. 72 39 v1 [ cs .G T ] 2 9 A pr 2 01 4	expected utility hypothesis;ibm notes;turing	Mark Braverman;Gal Oshri	2014	CoRR		public relations;economics;data mining;management science	ECom	-6.79226197437093	-5.141125262591186	18325
439962c72a5b51b9773b7704b86119bdad61325c	adaptive selection of materialized queries in a mediator	systeme information heterogene;base donnee repartie;distributed database;mediador;query processing;decay rate;heterogeneous information systems;traitement requete;interrogation base donnee;base repartida dato;interrogacion base datos;materialisation donnee;distributed query processing;mediator;mediateur;data materialization;tratamiento pregunta;information system;database query;systeme information;sistema informacion	In a mediator, query usage should be carefully monitored to determine the optimized set of materialized sub-queries, since the integration schema of a mediator can be incrementally modified and the evaluation frequency of a global query can also be continuously varied. This paper proposes a theoretical basis for adaptive selection of materialized sub-queries such that available storage in a mediator can be highly utilized at any time. In order to differentiate the recent usage of a query from the past, the accumulated usage frequency of a query decays as time goes by. Consequently, it is possible to find the optimum set of materialized sub-queries which minimizes the total evaluation cost of global queries in linear search complexity.		Kil Hong Joo;Won Suk Lee	2005	Parallel Processing Letters	10.1142/S0129626405002362	materialized view;radioactive decay;computer science;mediator;data mining;database;world wide web;distributed database;information system	DB	-25.93027824093764	3.4013523394065164	18402
4746376951a19c8f16e3abac03915b9727b77f91	social welfare functions with a reference income	social preferences;social welfare function	A foundation of social welfare functions is considered with a given reference income (or utility): relative and absolute invariance of the underlying welfare ordering are defined to hold for societies with either all members having incomes below the reference income or all members having incomes above the reference income. These conditions, alongside standard properties of a social preference relation, provide reference income dependent extensions of traditional classes of welfare functions. Dalton’s principle of positive transfers is incorporated, under which relative invariance leads to a class of piecewise (rank-)linear welfare functions, including the class of generalized Gini social welfare functions as a special case. To ensure quasi-concavity a new preference condition is proposed, which has the interpretation of aversion to income dropping below the reference income.		Horst Zank	2007	Social Choice and Welfare	10.1007/s00355-006-0184-1	distribution;economics;income;social preferences;public economics;microeconomics;welfare economics;labour economics	ECom	-7.055114985137955	-2.147313681591563	18426
4baa42a69a8a75909eb0d9525a25280220ac0acf	boundary estimating of urban road network for traffic impact analysis when reconstructing intersections: methodology and evaluation		Intersections are major points of conflict for road users and the key parts of urban road network. It is necessary to reconstruct some intersections to improve capacity and safety. A methodology to estimate the boundary of a road network for traffic impact analysis of intersection improvements is discussed in this paper. Firstly, models are presented for two types of degrees of correlation. The degree of saturation and free-flow travel time are considered in the model for the degree of correlation between two adjacent intersections, and the degree of correlation between any two intersections in the network is analysed using a Laplacian matrix algorithm. Secondly, a new method for estimating a road network boundary is proposed. Thirdly, two measures are adopted to evaluate the boundary of road networks: the minimum average cut degree of correlation and the minimum traffic influence on intersections outside the boundary. Finally, the method is demonstrated using a city road network. The results of the case ...		Yingying Ma;Ying Zeng	2018	IJSPM	10.1504/IJSPM.2018.10012819	degree of saturation;engineering;operations management;laplacian matrix;mathematical optimization;correlation	Vision	-11.369921044570592	-23.811883700148382	18457
4c71e0b6c3f458b7535314c372df088557685f60	a framework for modeling payments for ecosystem services with agent-based models, bayesian belief networks and opinion dynamics models	bayesian network;iamo luc;agent based modeling;land use change;payments for environmental services;human environment interaction;social influence;china	We present an integrated modeling framework for simulating land-use decision making under the influence of payments for ecosystem services. The model combines agent-based modeling (ABM) with Bayesian belief networks (BBNs) and opinion dynamics models (ODM). The model endows agents with the ability to make land-use decisions at the household and plot levels. The decision-making process is captured with the BBNs that were constructed and calibrated with both qualitative and quantitative information, i.e., knowledge gained from group discussions with stakeholders and empirical survey data. To represent interpersonal interactions within social networks, the decision process is further modulated by the opinion dynamics model. The goals of the model are to improve the ability of ABM to emulate land-use decision making and thus provide a better understanding of the potential impacts of payments for ecosystem services on land use and household livelihoods. Our approach provides three important innovations. First, decision making is represented in a causal directed graph. Second, the model provides a natural framework for combining knowledge from experts and stakeholders with quantitative data. Third, the modular architecture and the software implementation can be customized with modest efforts. The model is therefore a flexible, general platform that can be tailored to other studies by mounting the appropriate case-specific “brain” into the agents. The model was calibrated for the Sloping Land Conversion Program (SLCP) in Yunnan, China using data from participatory mapping, focus group interviews, and a survey of 509 farm households in 17 villages. 2012 Elsevier Ltd. All rights reserved.	agent-based model;bayesian network;causality;directed graph;ecosystem services;focus group;interaction;modulation;ontology definition metamodel;simulation;social network	Zhanli Sun;Daniel Müller	2013	Environmental Modelling and Software	10.1016/j.envsoft.2012.06.007	social influence;computer science;engineering;knowledge management;environmental resource management;machine learning;bayesian network;management science;ecology;china	AI	-15.288584777579807	-20.547972710059557	18463
afea10a61f1f5e3d00082e0ec04cb9de93754c75	a compiled project and open-source code to generate web-based forest modelling simulators		Abstract Sustainable forest management requires decision support systems to evaluate possible scenarios and anticipate the consequences of decisions. Forest modellers typically develop complex systems of equations to predict the behaviour of forests which makes the use of forest models difficult for end-users in general, affecting transfer of knowledge and technology. To overcome these difficulties and facilitate their practical use, models can be integrated into software to generate user-friendly forest simulators. In this paper we introduce and describe ForestMTIS, a cloud computing compiled and editable open-source project to generate forest simulators which was developed for statistical, non-spatial, deterministic, disaggregated, single species even-aged stand growth and yield models. We demonstrate the use of ForestMTIS based on the development of FlorNExT®, its first practical application, based on a collaborative approach to make growth and yield modelling and sustainable forest management available to a large community of users in the Northeast of Portugal.	compiler;open-source software;simulation;web application	Esteban Gómez-García;João Azevedo;Fernando Pérez-Rodríguez	2018	Computers and Electronics in Agriculture	10.1016/j.compag.2018.02.010	complex system;systems engineering;control engineering;decision support system;source code;web application;sustainable forest management;software;engineering;cloud computing	AI	-14.794309742776408	-22.172048852977884	18501
3ebc15e4e43dafea680fce41d5220a485da357c0	behavioral diversity generation in autonomous exploration through reuse of past experience	reality gap;sensorimotor exploration;robotics;behavioral diversity;goal babbling;sensorimotor learning;transfer learning	The production of behavioral diversity – producing a diversity of effects – is an essential strategy for robots exploring the world when facing situations where interaction possibilities are unknown or non-obvious. It allows to discover new aspects of the environment that cannot be inferred or deduced from available knowledge. However, creating behavioral diversity in situations where it is most crucial – new and unknown ones – is far from trivial. In particular in large and redundant sensorimotor spaces, only small areas are interesting to explore for any practical purpose. When the environment does not provide clues or gradient toward those areas, trying to discover those areas relies on chance. To address this problem, we introduce a method to create behavioral diversity in a new sensorimotor task by re-enacting actions that allowed to produce behavioral diversity in a previous task, along with a measure that quantifies this diversity. We show that our method can learn how to interact with an object by reusing experience from another, that it adapts to instances of morphological changes and of dissimilarity between tasks, and how scaffolding behaviors can emerge by simply switching the attention of the robot to different parts of the environment. Finally, we show that the method can robustly use simulated experiences and crude cognitive models to generate behavioral diversity in real robots.	autonomous robot;cognitive model;gradient;type inference	Fabien C. Y. Benureau;Pierre-Yves Oudeyer	2016	Front. Robotics and AI	10.3389/frobt.2016.00008	simulation;transfer of learning;computer science;artificial intelligence;machine learning;robotics	Robotics	-22.962344245146276	-18.509352950838725	18534
2e036e877d3cdcb1bd69e666c5121d69f11f3865	the influence of information on negotiation equilibrium	utilisation information;negociation;information use;systeme aide decision;influencia;sistema ayuda decision;prise decision;influence;estudio impacto;decision support system;etude impact;negociacion;bargaining;information system;toma decision;utilizacion informacion;impact study;systeme information;sistema informacion	This paper studies the influence of the agents’ information states on the negotiation equilibrium. This analysis is undertaken by examining a range of negotiation scenarios in which the amount of information that agents have about their opponent’s parameters is systematically varied. For each such scenario, we show that a unique equilibrium exists and we investigate how the information states of agents influence the distribution propertyof the equilibrium solution. Our study shows the relative impacts of the opponent’s parameters on the negotiation outcome. The results obtained are useful for decision making in situations where an agent has the option of choosing whom to negotiate with, from among a set of bargainers, on the basis of its information state. Our analysis also indicates which of its opponent’s parameters an agent should learn in order to maximize its utility.	bilateral filter;content negotiation;display resolution;state (computer science)	S. Shaheen Fatima;Michael Wooldridge;Nicholas R. Jennings	2002		10.1007/3-540-36378-5_11	decision support system;computer science;artificial intelligence;operations research;negotiation;information system	AI	-5.477755920542969	-8.663430916118855	18542
62f9fee5c3358f7dbec8815fd32e991d53d8c29a	a multi-agent approach to fuzzy landmark-based navigation	articulo	This work explores the use of bidding mechanisms to coordinate the actions requested by a group of agents in charge of achieving the task of guiding a robot towards a specified target in an unknown environment. This approach is based on a fuzzy approach to landmark-based navigation.	fuzzy logic;robot	Dídac Busquets;Carles Sierra;Ramón López de Mántaras	2003	Multiple-Valued Logic and Soft Computing		computer vision;simulation;computer science;artificial intelligence	AI	-18.450455060336846	-10.931023874819402	18608
eb59b4385c23610c9a3f2528a566eb85eb5af4bb	a rule-based approach to robust granular planning	routing protocols;top down;real time;rule based;planning artificial intelligence;rule based top down route derivation rule based approach robust granular planning real time execution planned routes ad hoc re planning solution quality real time constraints urban route planning problem domain;junctions;traffic engineering computing knowledge based systems planning artificial intelligence real time systems;roads;cities and towns;traffic engineering computing;robustness;planning;knowledge based systems;route planning;partitioning algorithms;robustness urban planning artificial intelligence telecommunication traffic power system planning partitioning algorithms production planning strategic planning roads computer science;real time systems	Real-time execution of planned routes often requires re-planning, especially in dynamic, highly unpredictable environments. Ad-hoc re-planning in case of failure of an optimal (suboptimal) plan leads to deterioration of solution quality. Moreover, it becomes costly and often unmanageable under real time constraints. This paper describes an approach of a partitioning scheme for urban route planning problem domain into a hierarchy of subproblems and an algorithm for rule-based top-down route derivation. A hierarchical, rule-based approach is aimed at granular planning for generating robust, multi-variant plans.	algorithm;automated planning and scheduling;hoc (programming language);logic programming;problem domain;real-time transcription;search algorithm;top-down and bottom-up design	Sebastian Ernst;Antoni Ligeza	2008	2008 International Multiconference on Computer Science and Information Technology	10.1109/IMCSIT.2008.4747225	rule-based system;planning;simulation;computer science;artificial intelligence;knowledge-based systems;top-down and bottom-up design;routing protocol;robustness	AI	-19.035918721750853	-6.517742569191778	18615
3fac0a466bec3cc5fd384f9239e42d5a9ed5b8b8	balanced cooperative modeling	learning algorithm;multistrategy learning;process integration;mobal;machine learning;balanced cooperative modeling;knowledge engineering	Machine learning techniques are often used for supporting a knowledge engineer in constructing a model of part of the world. Different learning algorithms contribute to different tasks within the modeling process. Integrating several learning algorithms into one system allows it to support several modeling tasks within the same framework. In this article, we focus on the distribution of work between several learning algorithms on the one hand and the user on the other hand. The approach followed by the MOBAL system is that ofbalanced cooperation, i.e., each modeling task can be done by the user or by a learning tool of the system. The MOBAL system is described in detail. We discuss the principle of multi-functionality of one representation for the balanced use by learning algorithms and users.	algorithm;knowledge engineer;machine learning	Katharina Morik	1993	Machine Learning	10.1007/BF00993078	unsupervised learning;robot learning;proactive learning;multi-task learning;instance-based learning;error-driven learning;algorithmic learning theory;computer science;knowledge management;artificial intelligence;online machine learning;machine learning;knowledge engineering;inductive transfer;learning classifier system;stability;competitive learning;computational learning theory;active learning;process integration	ML	-29.12904266910659	-19.22883412940489	18638
3ee9fda66f2356adb209d8d2adfb0c5c6414fc51	endowments-swapping-proof house allocation		We consider house (re)allocation problems (Shapley and Scarf, 1974) with strict preferences. We are concerned with the possibility that a pair of agents may gain by swapping their endowments before the operation of the chosen rule. A rule is called endowments-swapping-proof if it is immune to this kind of manipulation. Our main result is that the top trading cycles rule is the only rule that satisfies individual rationality, strategy-proofness, and endowments-swapping-proofness.	paging	Yuji Fujinaka;Takuma Wakayama	2018	Games and Economic Behavior	10.1016/j.geb.2018.05.004	welfare economics;economics;swap (computer programming);rationality	ECom	-5.878004133168296	-2.836141948651091	18642
3218ff560ff03e4ec5b2f49b0238ef665926f7e7	cognitive informatics and denotational mathematical means for brain informatics	search engine;brain informatics;theoretical framework;cognitive robotics;formal model;visual semantic algebra;cognitive informatics;cognitive computing;computational intelligence;reference model;cognitive computers;granular algebra;artificial intelligent;concept algebra;cognitive process;engineering applications;special needs;machine intelligence;ebrain;intelligent system;artificial intelligence;denotational mathematics;machinable intelligence;natural intelligence;theoretical foundation;autonomous learning;rtpa;abstract intelligence;system algebra	Cognitive informatics studies the natural intelligence and the brain from a theoretical and a computational approach, which rigorously explains the mechanisms of the brain by a fundamental theory known as abstract intelligence, and formally models the brain by contemporary denotational mathematics. This paper, as an extended summary of the invited keynote presented in AMT-BI 2010, describes the interplay of cognitive informatics, abstract intelligence, denotational mathematics, brain informatics, and computational intelligence. Some of the theoretical foundations for brain informatics developed in cognitive informatics are elaborated. A key notion recognized in recent studies in cognitive informatics is that the root and profound objective in natural, abstract, and artificial intelligence in general, and in cognitive informatics and brain informatics in particular, is to seek suitable mathematical means for their special needs that were missing in the last six decades. A layered reference model of the brain and a set of cognitive processes of the mind are systematically developed towards the exploration of the theoretical framework of brain informatics. The current methodologies for brain studies are reviewed and their strengths and weaknesses are analyzed. A wide range of applications of cognitive informatics and denotational mathematics are recognized in brain informatics toward the implementation of highly intelligent systems such as world-wide wisdom (WWW+), cognitive knowledge search engines, autonomous learning machines, and cognitive robots.	artificial intelligence;autonomous robot;cognition;cognitive computing;cognitive robotics;cognitive science;cognitive tutor;computational intelligence;computer science;denotational semantics;formal concept analysis;informatics;information processing;information science;knowledge search;mind;reference model;theory;web search engine;world wide web	Yingxu Wang	2010		10.1007/978-3-642-15314-3_2	psychology;neuroscience;reference model;cognition;engineering informatics;computer science;artificial intelligence;cognitive computing;machine learning;computational intelligence;informatics;cognitive science;search engine;cognitive robotics	AI	-27.168957699337252	-13.394611703630217	18664
542bc82d560ce148e6aaf2e8b9ab3df181f2d175	"""corrigendum to """"hybrid computational models for the characterization of oil and gas reservoirs"""" [experts systems with applications 36 (7) (2010) 5353-5363]"""	computer model;oil and gas;expert system		computation;computational model	Tarek Helmy;Anifowose Fatai;Kanaan A. Faisal	2011	Expert Syst. Appl.	10.1016/j.eswa.2010.10.004	fossil fuel;computer science;artificial intelligence;expert system	Metrics	-28.302219449489076	-8.234534541008733	18709
ca47b7204c9ee1babe73ea7af3f3c03ae413676f	application of objective criteria saturation to select best value alternative from fuzzy requirements		This paper presents a modified Technique for Order of Preference by Similarity to Ideal Solution (TOPSIS) for evaluating system concepts using minimum and maximum customer requirements to determine a best value alternative. The purpose of this decision analysis technique is to identify system alternatives with an optimal combination of performance, reliability, and cost based on ideal customer requirements. Currently, most conventional TOPSIS models use minimum and maximum values under a specific criterion to evaluate each alternative. Using these models, an alternative being evaluated could receive significantly higher scores when reported capabilities are greater than ideal customer requirements. This problem is pronounced whenever weights are applied to criteria where excessive capabilities are recorded. If an organizational goal is to select the best value alternative, use of conventional TOPSIS models may not lead to the best value decision. The modified TOPSIS method presented in this paper restricts scoring for alternatives that provide excess capabilities beyond ideal customer requirements. Criteria weights are assigned according to a customer's prioritized requirements. This Objective Criteria Saturation TOPSIS (OCS-TOPSIS) method was created to provide Decision Makers (DM) with a tool to evaluate system alternatives against performance criteria, reliability and life cycle costs. To demonstrate the effectiveness of OCS-TOPSIS, a basic example is provided that displays the cost savings outcome over traditional TOPSIS.	decision analysis;offset binary;original chip set;requirement	Wesley Gunnar White;V. Chandrasekar	2018	2018 Annual IEEE International Systems Conference (SysCon)	10.1109/SYSCON.2018.8369542	decision analysis;reliability engineering;fuzzy logic;best value;saturation (chemistry);topsis;computer science	SE	-5.760555276161517	-17.540380902986914	18780
5b8ddb4c039b24b0360ee39e4ea30b6482b7e821	performance measurement evaluation framework and co-benefit\/tradeoff analysis for connected and automated vehicles (cav) applications: a survey		A number of Connected and/or Automated Vehicle (CAV) applications have recently been designed to improve the performance of our transportation system. Safety, mobility and environmental sustainability are three cornerstone performance metrics when evaluating the benefits of CAV applications. These metrics can be quantified by various measures of effectiveness (MOEs). Most of the existing CAV research assesses the benefits of CAV applications on only one (e.g., safety) or two (e.g., mobility and environment) aspects, without holistically evaluating the interactions among the three types of MOEs. This paper first proposes a broad classification of CAV applications, i.e., vehicle-centric, infrastructure-centric, and traveler-centric. Based on a comprehensive literature review, a number of typical CAV applications have been examined in great detail, where a categorized analysis in terms of MOEs is performed. Finally, several conclusions are drawn, including the identification of influential factors on system performance, and suggested approaches for obtaining co-benefits across different types of MOEs.		Danyang Tian;Guoyuan Wu;Kanok Boriboonsomsin;Matthew J. Barth	2018	IEEE Intelligent Transportation Systems Magazine	10.1109/MITS.2018.2842020	vehicle information and communication system;transport engineering;simulation;performance measurement;engineering;traffic flow	SE	-16.71945730381184	-22.697417533296324	18794
ec98dfc7990fb7383d539af80efd334608f79ce4	supporting top-k aggregate queries over unequal synopsis on internet traffic streams	real time;internet traffic streams;dsw dynamic sub window algorithm;internet traffic;top k query;data structure;sliding window;synopsis data structure	Queries that return a list of frequently occurring items are important in the analysis of real-time Internet packet streams. While several results exist for computing Top-k queries using limited memory in the infinite stream model (e.g., limited-memory sliding windows). To compute the statistics over a sliding window, a synopsis data structure can be maintained for the stream to compute the statistics rapidly. Usually, a Top-k query is always processed over an equal synopsis, but it's very hard to implement over an unequal synopsis because of the resulting inaccurate approximate answers. Therefore, in this paper, we focus on periodically refreshed Top-k queries over sliding windows on Internet traffic streams; we present a deterministic DSW (Dynamic Sub-Window) algorithm to support the processing of Top-k aggregate queries over an unequal synopsis and guarantee the accuracy of the approximation results.	aggregate data;video synopsis	Ling Wang;Yang Koo Lee;Keun Ho Ryu	2008		10.1007/978-3-540-78849-2_59	sliding window protocol;internet traffic;data structure;computer science;data mining;database;programming language;world wide web	DB	-27.346359788489217	-1.0491539502098022	18806
cbab234fcb48da58597efc596184b2d4d233f891	developing a knowledge engineering capability in the trw defense systems group	knowledge engineering	The TRW Dcfensc Systems GI oup develops large mailmachine net,works that, solve problems for govrrmnent agencies. IJntil a few years ago these networks were tither tightly-coupled humans loosely supported by machineslike 0111 ballistic missile system engineering organization, which provides technical advice to the Air Force, or tightlycouplrd machines loosely controlled by human~likc the ground station fox the NASA Tracking and Data R.elay Satellite Syst,em. Because we have been producing firstof-a kind syst,ems like these since the early 195Os, we consider ourselves leaders in the social art of assembling effective teams of diverse expcrt,s, and in the engineering art, of conceiving and developing networks of interacting machines But in t,he mid-1970s WC began building systems in which humans and machines must be tightly coupled to each other-syst,ems like the Sensor Data Fusion Ccntcr (Figure I). Then WC found that our well-worked system development techniques did not complet,ely apply, and that our system engineering handbook needed a new chaptIer on comnnmication bct,ween people and machines We’re still writing that, chapt,er, and it won’t, be finished until we can add some not-yet understood cognitive psychology and some not-yet fully developed artificial intelligence t,echniques Nevertheless, we have learned some lessons worth passing along.	artificial intelligence;ballistic missile;humans;interaction;knowledge engineering;systems engineering;writing commons	Edward C. Taylor	1985	AI Magazine		simulation;computer science;engineering;artificial intelligence;mechanical engineering	AI	-32.481561697380165	-20.059059117714096	18930
86604e7eddbf8f94af82db590ade2ea617e41e36	throughput centered prioritization of machines in transfer lines	system engineering;decision aid;asset management;production system;prioritization;product line;production line;throughput analysis;risk mitigation;buffer capacity;influence diagram	In an environment of scarce resources and complex production systems, prioritizing is key to confront the challenge of managing physical assets. In the literature, there exist a number of techniques to prioritize maintenance decisions that consider safety, technical and business perspectives. However, the effect of risk mitigating elements—such as intermediate buffers in production lines—on prioritization has not yet been investigated in depth. In this line, the work proposes a user-friendly graphical technique called the  system efficiency influence diagram  (SEID). Asset managers may use SEID to identify machines that have a greater impact on the system throughput, and thus set prioritized maintenance policies and/or redesign of buffers capacities. The tool provides insight to the analyst as it decomposes the influence of a given machine on the system throughput as a product of two elements: (1) system influence efficiency factor and (2) machine unavailability factor. We illustrate its applicability using three case studies: a four-machine transfer line, a vehicle assembly line, and an open-pit mining conveyor system. The results confirm that the machines with greater unavailability factors are not necessarily the most important for the efficiency of the production line, as it is the case when no intermediate buffers exist. As a decision aid tool, SEID emphasizes the need to move from a maintenance vision focused on machine availability, to a systems engineering perspective.	throughput	Rodrigo Pascual;David R. Godoy;Darko M. Louit	2011	Rel. Eng. & Sys. Safety	10.1016/j.ress.2011.05.006	reliability engineering;influence diagram;risk management;production line;systems engineering;engineering;production system	Arch	-9.045139887247366	-13.660194792360294	18966
7df8806ca8cd47f5000c8a95da1be6a01b7e6b76	the smith-walley interpretation of subjective probability: an appreciation	subjective probability	The right interpretation of subjective probability is implicit in the theories of upper and lower odds, and upper and lower previsions, developed, respectively, by Cedric Smith (1961) and Peter Walley (1991). On this interpretation you are free to assign contingent events the probability 1 (and thus to employ conditionalization as a method of probability revision) without becoming vulnerable to a weak Dutch book.	contingency (philosophy);theory	Carl G. Wagner	2007	Studia Logica	10.1007/s11225-007-9064-7	frequentist probability;imprecise probability;conditional probability;philosophy;computer science;artificial intelligence;propensity probability;mathematics;statistics	AI	-12.370949860165116	2.222053657366068	18999
762a21f13031d6ac492beae940a5a61608fc5468	combining multicriteria decision aid and system dynamics for the control of socio-economic processes. an iterative real-time procedure	dynamique processus;multicriteria analysis;business studies;control theory;economic system;decision aid;system dynamics;real time control;real time;long term planning and real time control;estrategia;ayuda decision;sistema complejo;long terme;decision maker;dinamica proceso;long term;socioeconomie;mcda promethee methodology;strategy;socioeconomics;control proceso;planificacion;largo plazo;systeme complexe;complex system;multicriteria decision aid;temps reel;process control;aide decision;tiempo real;planning;hypercomplex socio economic systems;analisis multicriterio;analyse multicritere;planification;socioeconomia;process dynamics;strategie;commande processus	The paper presents the elements of a new methodology to control complex and hypercomplex socio-economic structures. The control process is iterative, combining the principles of System Dynamics, Control theory and the PROMETHEE Multicriteria Decision Aid (MCDA) methodology. It consists of three main stages: setting up and calibration of a quantitative model, de®nition of long-term strategies and short-term control. The purpose is to de®ne within a panel of decision makers appropriate strategies towards long-term goals, and to implement suitable control measures. These should in particular help cope with progressive and catastrophic variations in the behaviour of the system. Ó 1998 Published by Elsevier Science B.V. All rights reserved.	automated planning and scheduling;complex system;control theory;diagram;feedback;fractal dimension;iteration;mental representation;preference ranking organization method for enrichment evaluation;real-time computing;real-time locating system;system dynamics	Jean-Pierre Brans;Cathy Macharis;Pierre L. Kunsch;Aline Chevalier;Markus Schwaninger	1998	European Journal of Operational Research	10.1016/S0377-2217(98)00068-X	planning;decision-making;real-time control system;economics;strategy;artificial intelligence;operations management;process control;system dynamics;operations research;business studies	Robotics	-23.889572909193173	-5.439834531176443	19069
5a0f3e892feb0dbb04944e2c145ac0790c44dfda	analysis of the effectiveness of preventive and deterrent piracy control strategies: agent-based modeling approach	agent based modeling;piracy control;supply chain coordination	We use agent-based modeling approach to analyze the impact of various digital piracy control strategies on consumers, retailers, record labels, and artists. We model heterogeneous agent behavior, motives, and interactions to examine the consequences in terms of aggregate system behavior. Using a multi-agent programmable modeling environment (Netlogo), several experiments were conducted to test the simulation model and develop managerial insights. We show that an educational strategy is more effective when consumers are resistant to anti-piracy efforts and budgets for combating piracy are small. Furthermore, value-added service and low-price strategies should be used to encourage legitimate purchases since legal and educational strategies alone deter piracy but do not provide consumers' incentives to purchase legitimate products. Therefore, effectiveness of piracy control strategies can be improved by combining a legal or an educational strategy with a value-added or a low-price strategy. We also find that the profit-maximizing strategies are different for different players in the supply chain. While the record label prefers a low-cost strategy, it is optimal for the whole supply chain to use combined legal or educational strategy with a value-added strategy. Therefore, there is potential for all parties in the supply chain being better off if the record label and the retailer cooperate in combating piracy.		Bong-Keun Jeong;Moutaz Khouja	2013	Computers in Human Behavior	10.1016/j.chb.2013.07.029	knowledge management;psychology;marketing;supply chain;netlogo;incentive	AI	-6.94467317464066	-8.558466284879007	19070
07ecdddf6c6229a9bbc67bffd4a14ac726898fb1	research on urban water security evaluation based on technique for order preference by similarity to ideal solution model	evaluationindex systemtechnique for order preference by similarity to ideal solution topsis � urban water safety	  Urban water safety evaluation is an important content of urban water safety management. In this paper, combining with the  characters and influencing factors of urban water safety system, index system of urban water safety evaluation is established.  The model of urban water safety evaluation based on Technique for Order Preference by Similarity to Ideal Solution is provided  and is used to evaluate water security of Nanjing. The result shows that the model is effective and the state of Nanjing water  security is better and better in the future years.    		Junfei Chen;Lu Xia;Huimin Wang	2011		10.1007/978-3-642-18387-4_38	geography;data mining;management science;social psychology	HCI	-10.003414624153415	-22.398884178990766	19144
4f2fb20dd35283ff331dc711ad99a797bf2d94d1	fuzzy mcdm for evaluating the e-commerce strategy	electronic commerce;fuzzy mcdm;e commerce;ahp;taiwan;e commerce strategy	This study aimed to provide a theoretically and empirically based model for evaluating and selecting an e-commerce strategy. In practical environments, mangers face a variety of information types that are vague. Traditional decision making methods cannot fulfill the e-commerce managers' needs. Therefore, a Fuzzy Multiple Criteria Decision-Making (MCDM) method is adopted in this research. In order to show the practicality and usefulness of this model, an empirical study of the Taiwan ISP industry is demonstrated. The results show that the first to market strategy is the most applicable.	e-commerce	Yi-Chia Chiu;Joseph Z. Shyu;Gwo-Hshiung Tzeng	2004	IJCAT	10.1504/IJCAT.2004.003656	e-commerce;analytic hierarchy process;computer science;marketing;management science	ECom	-5.475437182264831	-16.552226663381624	19196
0d0718bc62c441c8f2e76e929a0e0b22c8336d92	assisting construction of meta-cognitive competence by scaffolding discovery of plans in problem-solving	sensibilidad contexto;teoria cognitiva;learning control;theorie type;teleenseignement;context aware;cognitive theory;intelligence artificielle;theorie cognitive;resolucion problema;collaborative environment;type theory;decouverte connaissance;deadlock;interbloqueo;artificial intelligence;descubrimiento conocimiento;context dependent;teleensenanza;inteligencia artificial;ingenierie simultanee;sensibilite contexte;interblocage;ingenieria simultanea;remote teaching;concurrent engineering;problem solving;resolution probleme;knowledge discovery	In our collaborative environment for learning by problem-solving, whose implementation so far will be briefly described, we provide the learners with an environment in which they edit plans for solving given problems by selecting and connecting problem types provided by the system. In the problem types, on which we first discuss, context-dependent plans consisting of problem types are embedded. The learners should recursively edit plans. Embedded plans, however, are provided, when they get deadlock. A library of sample problems are also provided so as to be examined by the learners to learn what are and how are used the plans and the problem types in concern. Finally we propose, as learning control to realize construction of meta-cognitive competence, to make use of the library of sample problems with solution to scaffold discovering plans for the problem given to the learners, through retrieving and providing pertinent sample problems using, as indices, the problem types and plans as well as annotations for bridging problem types or plans.		Kohji Itoh;Eisuke Mihara;Kenji Hasegawa;Masahiro Fujii;Makoto Itami	2005		10.1007/11553939_182	simulation;computer science;artificial intelligence;deadlock;machine learning;context-dependent memory;database;mathematics;knowledge extraction;programming language;type theory;algorithm;concurrent engineering	AI	-23.21705754670264	-2.1192030043237	19268
f64d88e2506dc6a22f067add17a361a746ce540c	reputation-based pricing for grid computing in e-science	incentive;pricing;reputation;grid computing	One of the fundamental aspects for an efficient Grid usage is the optimization of resource allocation among the participants. However, this has not yet materialized. Each user is a self-interested participant trying to maximize his utility whereas the utility is not only determined by the fastest completion time, but on the prices as well. Future revenues are influenced by users’ reputation. Reputation mechanisms help to build trust between loosely coupled and geographically distributed participants. Providers need an incentive to reduce selfish cancellation of jobs and privilege own jobs. In this paper we present a reputation-based pricing mechanism for a simple, but fair pricing of resources. In e-Science researchers do not appreciate idiosyncratic pricing strategies and policies. Their interest lies in doing research in an efficient manner. Consequently, in our mechanism the price is tightly coupled to the reputation of a site to guarantee fairness of pricing and facilitate price determination. Furthermore, the price is not the only parameter as completion time plays an important role, when deadlines have to be met. We provide a flexible utility and decision model for every participant and analyze the outcome of our reputation-based pricing system via simulation.	e-science;fairness measure;fastest;grid computing;job stream;loose coupling;mathematical optimization;reputation;simulation	Arun Anandasivam;Dirk Neumann	2008			financial economics;pricing;variable pricing;economics;incentive;reputation;computer science;marketing;finance;grid computing	ECom	-6.7439951145584995	-7.785472673977262	19287
f301ff66e5b0356ce40f8d9ae1adcca64d95c955	a selection model to logistic centers based on topsis and mcgp methods: the case of airline industry		The location selection of a logistics center is a crucial decision relating to cost and benefit analysis in airline industry. However, it is difficult to be solved because there are many conflicting and multiple objectives in location problems. To solve the problem, this paper integrates fuzzy technique for order preference by similarity to an ideal solution (TOPSIS) and multichoice goal programming (MCGP) to obtain an appropriate logistics center from many alternative locations for airline industry. The proposed method in this paper will offer the decision makers (DMs) to set multiple aspiration levels for the decision criteria. A numerical example of application is also presented.		Kou-Huang Chen;Chin-Nung Liao;Li-Chun Wu	2014	J. Applied Mathematics	10.1155/2014/470128	management science;operations research	ML	-4.688805400049836	-16.75790852855554	19303
02c57a635ea3e16e58e49ba16de524c40d34a16f	sharing in bittorrent can be rational - (extended abstract)		Consider a game played by two mountaineers climbing a mountain.Both are only interested in attaining the summit and can only reach it with help from the other. Over an infinite number of discrete periods they play a symmetric simultaneous game where they may either help the other a fixed distance up the mountain at some cost, or do nothing. Can these mountaineers climb their mountain? BitTorrent, the popular peer to peer file distribution protocol, is strategically similar to this mountain climbing game. Peers’ single goal is to acquire the complete file—to reach the summit—and incomplete files have zero value. Also, like mountaineers, peers can only progress with others’ help. Of course, a BitTorrent swarm is more complex than the mountaineering game, containing many peers who can only provide certain pieces of the file to a subset of others. Importantly, however, this metaphor captures BitTorrent’s goal-oriented nature, an often overlooked but salient feature of BitTorrent. In our paper we explicitly model BitTorrent as a goal-oriented game that has a unique one time payoff for acquiring the complete file. We use this model to obtain novel results about the rationality of sharing in BitTorrent, distinct from previous work on peer to peer networks (e.g. [1] and [3]) and repeated matching games [4]. Only by accurately modeling peers’ incentives and understanding their rational strategies can we design maximally efficient file distribution protocols.	bittorrent;block (data storage);file sharing;peer-to-peer;rationality;swarm	Michael Ruberry;Sven Seuken	2011		10.1007/978-3-642-30913-7_8	internet privacy;computer network	Metrics	-8.26408007555756	-7.715728256140359	19313
149b394d449e1eff7d6d59414061ce510c0fa9ed	distributed real-time traffic simulation for autonomous vehicle testing in urban environments		This work presents a distributed real-time simulation setup for automated driving function testing in urban environments. In the automotive domain, a large number of simulation frameworks are utilized which are tailored towards a specific application. However, virtual testing of automated driving functions requires a holistic simulation of realistic urban traffic environments. We set up a distributed simulation framework, integrated an ego-vehicle and linked a pedestrian simulator. Further, we developed a pedestrian behavior model, which is able to interact with all agents of the different simulation instances. Our simulation setup was evaluated from different perspectives including a performance test and comparing the developed model to real life data.		Christoph Sippl;Benedikt Schwab;Peter M. Kielar;Anatoli Djanatliev	2018	2018 21st International Conference on Intelligent Transportation Systems (ITSC)	10.1109/ITSC.2018.8569544		Robotics	-21.345725070311275	-23.110400223232098	19340
00b2ba487d62b2f53f777b6950effc425f88bdc8	evolving cooperation strategies		We propose an approach to developing cooperation strategies for multiagent problem solving situations which is different from existing techniques in two ways: strategies are incrementally constructed by repeatedly solving problems in the domain, i.e., on-line; and, we utilize an automated method of strategy formulation and modification, that relies little on domain details and human expertise, and more on performance on randomly generated problems in the domain. The genetic programming (GP) (Koza 1992) paradigm used to develop, through repeated problem solving, increasingly efficient strategies. Populations of structures are represented as Lisp symbolic expressions (Sexpressions). These are manipulated to evolve better structures by propagating and combining parts of structures that perform well compared to others in the population. To use this approach, we have to develop an encoding of strategies as S-expressions and choose an evaluation criterion for a strategy corresponding to an arbitrary S-expression. Strategies are evaluated by allowing the agents to execute them in the application domain and by measuring their efficiency and effectiveness by a set of criteria relevant to the domain.	agent-based model;application domain;genetic programming;lisp;online and offline;population;problem solving;procedural generation;programming paradigm;regular expression;s-expression;strategic management	Thomas Haynes;Roger L. Wainwright;Sandip Sen	1995			application domain;encoding (memory);genetic programming;theoretical computer science;population;expression (mathematics);lisp;computer science	AI	-20.809895930736275	-7.5650687059550465	19360
122ccc26fc0ce20648b6a909316dd9f2d6181132	spacetimes with semantics (iii) - the structure of functional knowledge representation and artificial reasoning		Using the previously developed concepts of semantic spacetime, I explore the interpretation of knowledge representations, and their structure, as a semantic system, within the framework of promise theory. By assigning interpretations to phenomena, from observers to observed, we may approach a simple description of knowledgebased functional systems, with direct practical utility. The focus is especially on the interpretation of concepts, associative knowledge, and context awareness. The inference seems to be that most if not all of these concepts emerge from purely semantic spacetime properties, which opens the possibility for a more generalized understanding of what constitutes a learning, or even ‘intelligent’ system. Some key principles emerge for effective knowledge representation: 1) separation of spacetime scales, 2) the recurrence of four irreducible types of association, by which intent propagates: aggregation, causation, cooperation, and similarity, 3) the need for discrimination of identities (discrete), which is assisted by distinguishing timeline simultaneity from sequential events, and 4) the ability to learn (memory). It is at least plausible that emergent knowledge abstraction capabilities have their origin in basic spacetime structures. These notes present a unified view of mostly well-known results; they allow us to see information models, knowledge representations, machine learning, and semantic networking (transport and information base) in a common framework. The notion of ‘smart spaces’ thus encompasses artificial systems as well as living systems, across many different scales, e.g. smart cities and organizations.	artificial intelligence;causality;context awareness;emergence;information model;irreducibility;knowledge representation and reasoning;living systems;machine learning;promise theory;smart tv;smart city;timeline	Mark Burgess	2016	CoRR		computer science;artificial intelligence;machine learning;pure mathematics;mathematics	AI	-25.27211893728852	-14.275346336571694	19374
19570117e4e10e80c0166de2f1a6b423e79df1fe	bridging qualitative and quantitative methods for classifying policy actors into policy discourse communities: thematic analysis and formal concept analysis approaches	policy making;policy communities;data collection;policy actors;policy networks;classification;cluster analysis;policy decisions;decision process;object classification;discourse analysis;quantitative method;thematic analysis;problem solving;formal concept analysis	Policy decision process is usually depicted as a neutral and technical process in which problem solving capacity of a policy decision determines the validity of its effectiveness. However, socio-political space is fragmented and policy making process reflects the conflicts between different socio-political actors. Empirical detection of policy networks is a problematic issue since world views reflecting policy beliefs can best be elicited in unstructured narrative forms which do not easily lend themselves to a systematic and objective classification of the narrating actors. Thus, the data for such research is usually collected through structured interviews which provide a solid basis for quantitative classification techniques such as cluster analysis. However, structured interviews are prone to imposing researcher’s perspective to the data rather than reflecting the world views of the policy actors. The aim of this paper is to offer a systematic way of classifying policy actors into policy communities according to the data collected through unstructured policy narratives. For this purpose the paper proposes a method that bridges qualitative thematic analysis with quantitative formal concept analysis.	acf;abstract interpretation;bridging (networking);cluster analysis;correspondence analysis;design rationale;formal concept analysis;problem solving;social security;taxonomy (general)	Ahmet K. Süerdem	2010	IJDATS	10.1504/IJDATS.2010.034056	quantitative research;biological classification;computer science;formal concept analysis;knowledge management;policy analysis;discourse analysis;machine learning;data mining;management science;cluster analysis;thematic analysis;data collection	AI	-23.6943574473464	-10.237485590967921	19479
1608f27702f4bfc516f6afa6710ef416cd0c91f6	conflict management in interactive financial service selection		Knowledge-based systems are often used to support search and navigation in a set of financial services. In a typical process users are defining their requirements and the system selects and ranks alternatives that seem to be appropriate. In such scenarios situations can occur in which requirements can not be fulfilled and alternatives (repairs) must be proposed to the user. In this paper we provide an overview of model-based diagnosis techniques that can be applied to indicate ways out from such a ”no solution could be found” dilemma. In this context we focus on scenarios from the domain of financial services.	conjunctive query;constraint satisfaction;knowledge representation and reasoning;knowledge-based systems;open research;requirement	Alexander Felfernig;Martin Stettinger	2015			management science;dilemma;service product management;accounting management;financial services;business;conflict management	HCI	-7.253931651738981	-13.621211364996766	19515
6e62dcbf59316230a651ace8d9a6d4d712fd7b71	multiagent teamwork: analyzing the optimality and complexity of key theories and models	multiagent system;interactivist;theory and modeling;comparative analysis;cognitive;decision problem;agent;dynamics;computational complexity;philosophy;software package;communication cost;mind	Despite the significant progress in multiagent teamwork, existing research does not address the optimality of its prescriptions nor the complexity of the teamwork problem. Thus, we cannot determine whether the assumptions and approximations made by a particular theory gain enough efficiency to justify the losses in overall performance. To provide a tool for evaluating this tradeoff, we present a unified framework, the COMmunicative Multiagent Team Decision Problem (COM-MTDP) model, which is general enough to subsume many existing models of multiagent systems. We analyze use the COM-MTDP model to provide a breakdown of the computational complexity of constructing optimal teams under problem domains divided along the dimensions of observability and communication cost. We then exploit the COM-MTDP's ability to encode existing teamwork theories and models to encode two instantiations of joint intentions theory, including STEAM. We then derive a domain-independent criterion for optimal communication and provide a comparative analysis of the two joint intentions instantiations. We have implemented a reusable, domain-independent software package based COM-MTDPs to analyze teamwork coordination strategies, and we demonstrate its use by encoding and evaluating the two joint intentions strategies within an example domain.	agent-based model;algorithm;approximation;complement (complexity);computational complexity theory;decision problem;encode;general-purpose modeling;local optimum;multi-agent system;problem domain;qualitative comparative analysis;unified framework	David V. Pynadath;Milind Tambe	2002		10.1145/544862.544946	qualitative comparative analysis;mind;dynamics;simulation;cognition;computer science;knowledge management;artificial intelligence;decision problem;management science;computational complexity theory	AI	-17.48614801821893	-9.155727948605325	19569
df7e4a8897b9675b96bf01179abb7bd3955dbfe2	a dynamic event tree informed approach to probabilistic accident sequence modeling: dynamics and variabilities in medium loca	success criteria;mloca;accident dynamic simulator;dynamic event tree analysis	In Probability Safety Assessments, accident scenario dynamics are addressed in the accident sequence analysis task. In an analyst-driven, iterative process, assumptions are made about equipment responses and operator actions and simulations of the scenario evolution are performed. To calculate how scenario dynamics and stochastic variabilities may affect the results of this process in terms of estimated risk, this work applies Dynamic Event Trees (DETs) to more comprehensively examine the accident scenario space. Alternative event tree models are developed and the core damage frequency is quantified to reveal the effects of different delineations of the sequences and of the bounding assumptions underlying success criteria. The results from a case study on Medium-break Loss of Coolant Accident scenarios in a Pressurized Water Reactor are presented, considering the break size, available injection trains, and the timing of rapid cooldown and the switchover to recirculation. The results show not only that estimated risk can be very sensitive to the numerous assumptions made in current accident sequence analysis but also that bounding assumptions do not always result in conservative risk estimates, thereby confirming the benefits that DETs provide in terms of characterizing scenario dynamics.	event tree	Durga Rao Karanki;Tae-Wan Kim;Vinh N. Dang	2015	Rel. Eng. & Sys. Safety	10.1016/j.ress.2015.04.011	reliability engineering;real-time computing;simulation;engineering	Robotics	-10.223013062742925	-15.900113435425673	19573
40a16d6b3a7c86a28b8f7d8eddf22dc9d6ba012c	size effect during emergence of symbolic communication system revealed by agent-based modelling.				Guanhong Li;Takashi Hashimoto	2012			simulation;computer science;artificial intelligence;communication	HCI	-23.447689571922993	-15.696315851084757	19576
c64ebd9dba5771329487ac41cec8cb8f80c061c5	artificial life and machine consciousness		Over the last several decades research efforts have explored various forms of artificial life and embodied artificial life as methods for developing autonomous agents. Such approaches, although a part of the AI canon, are rarely used in research aimed at creating artificial general intelligence. This paper explores the prospects of using in silico artificial evolution to develop machine consciousness, or strong AI. It is possible that artificial evolution and situated selforganizing agents could become viable tools for studying machine consciousness, but there are several issues that must be overcome. One problem is the use of exogenous selection methods to drive artificial evolutionary processes. A second problem relates to agent representation that is inconsistent with the environment in which the agents are situated. These issues limit the potential for open-ended evolution and fine-grained fitting of agents to environment, which are likely to be important for the eventual development of situated artificial consciousness.	artificial consciousness;artificial general intelligence;artificial life;autonomous agent;autonomous robot;evolutionary algorithm;nonlinear gameplay;situated	Andrew L. Nelson	2013				AI	-20.722745922869358	-16.722111985551027	19640
c49fac03c78f74e67e13ea54003ea9db7e31e9c6	leveraging enterprise application characteristics to optimize incremental aggregate maintenance in a columnar in-memory database		An analysis of database workloads generated by enterprise applications revealed a mixed workload of short-running transactional and long-running analytical queries. With the latter type of queries containing many aggregate operations, we implemented an efficient aggregate caching mechanism. But the incremental materialized view maintenance is very costly for aggregate queries joining multiple tables. To overcome this problem, we analyzed the characteristics of enterprise applications with respect to the creation of business objects and their persistence in the database layer. We evaluated how the detected patterns can be leveraged to reduce the join operations between the main and delta partitions of the involved tables in a columnar in-memory database. The resulting performance improvements are significant and close to using the caching mechanism with a denormalized schema.	aggregate function;enterprise software;in-memory database	Stephan Müller;Paul Möller;Hasso Plattner	2014		10.1007/978-3-662-43984-5_8	data mining;database	DB	-30.64159208938527	2.12078081442677	19652
e459525aa190e234337143afae8285b0d294a4d6	persuasion games with higher-order uncertainty	information structure;decision maker;higher order;economic theory;state space;information revelation	In persuasion games, it is well known that a perfectly revealing equilibrium may fail to exist when the decision maker is uncertain about the interested party’s payoff-relevant information. However, by explicitly integrating higher order uncertainty into the information structure, this paper shows that a perfectly revealing equilibrium does exist when disclosures are not restrained to intervals of the payoff-relevant state space. On the contrary, when payoffirrelevant disclosures are impossible, a perfectly revealing equilibrium fails to exist as long as there is a strictly positive probability that the decision maker does not know whether the interested party is informed or not. In this case, a partially revealing equilibrium and associated inferences are characterized.	decision theory;state space	Frédéric Koessler	2003	J. Economic Theory	10.1016/S0022-0531(03)00036-X	public relations;decision-making;higher-order logic;economics;state space;microeconomics;mathematical economics;welfare economics	ECom	-8.396253246243132	-3.678451561757019	19665
9de9d0f0468e4e8c13bc56240303751474e48a1d	towards an automated multiagent taxi-dispatch system	taxi operators;singapore;traffic management system design automated multiagent taxi dispatch system taxi operators singapore customer satisfaction human driver satisfaction multiagent architecture software collaborative agents mitsimlab;mitsimlab;human driver satisfaction;traffic management;transportation customer satisfaction multi agent systems software agents traffic engineering computing;customer satisfaction;software agents;multi agent systems;traffic management system design;multiagent architecture;system design;waiting time;transportation;customer satisfaction dispatching computer architecture collaborative software computer simulation global positioning system collaboration automation usa councils distributed computing;traffic engineering computing;computer simulation;automated multiagent taxi dispatch system;software collaborative agents	This paper presents the study of a novel approach towards an automated taxi dispatch system that handles current bookings in a distributed fashion. Existing systems in use by taxi operators in Singapore attempt to increase customer satisfaction locally, by sequentially dispatching nearby taxis to service customers. The proposed dispatch system attempts to increase customer satisfaction more globally, by concurrently dispatching multiple taxis to the same number of customers in the same geographical region, and vis-a-vis human driver satisfaction. To realize the system, we propose a multiagent architecture, populated with software collaborative agents that can actively negotiate on behalf of taxi drivers in groups of size N for available customer bookings. The operational efficiency of the existing and proposed dispatch systems was evaluated through computer simulations on MITSIMLab, an existing simulation-based laboratory originally developed for evaluating traffic management system designs at the operational level. The empirical results, obtained for a 1000-strong taxi fleet over a discrete range of N, show that the proposed system can dispatch taxis with up to 33.1% and 26.3% reduction in customer waiting time and empty taxi cruising time, respectively.	agent-based model;computer simulation;dynamic dispatch;population	Kiam Tian Seow;Nam Hai Dang;Der-Horng Lee	2007	2007 IEEE International Conference on Automation Science and Engineering	10.1109/COASE.2007.4341673	simulation;engineering;operations management;transport engineering	SE	-13.89612112823843	-9.04250579968178	19739
b05b237e5a5bd62108cbedfb9f6bbc24dd5473de	power source selection problems for electric vehicles	analytic hierarchy process;component analysis;expectation-maximization principal;power source selection	This paper developed two models to analyze the criteria in the selection of power sources for electric vehicles, the Expectation-Maximization Principal Component Analysis Model and Analytic Hierarchy Process Model. EM-PCA model can extract key independent factors among those complicated issues related to the selection of electric vehicles while AHP model tells us the selection of power source in a certain region. The results show that optimal selection of power sources differ from regions. For example, North America should put forward the priority to renewable energy as the selection of power source while Middle East should use petroleum.		Ping Li	2011		10.1007/978-3-642-23339-5_63	simulation;engineering;operations management;operations research	Robotics	-8.680704524882199	-19.686340297001195	19769
4ae5368e0f80ddead495c2567f9e28a5caf5dd48	car-driving assistance using organization measurement of reactive multi-agent system	evaluation function;multi agent system;statistical physics;obstacle avoidance;agent systems;virtual environment	This work presents an approach to the obstacle avoidance problem, applicable in the frame of driver assistance. A decision, expressed as a proposed acceleration vector for the vehicle, is elaborated from the evaluation of a set of indicators characterizing the global state of a system of reactive agents (RMAS). Those agents evolve in a virtual environment produced on the base of vehicle’s perceptions of the material environment around it. Agent-to-agent and agent-to-environment interactions are defined in order to produce a distribution of agents over the virtual environment. This distribution, taken as the global state of the system, is analyzed by applying a set of indicators inspired from statistical physics, to calculate a new vehicle’s acceleration vector. This work presents the details of the RMAS model and its interaction laws, together with the global state evaluation functions. The approach has been applied to experimentation with a laboratory vehicle. Some experimental results are presented here.	device driver;evaluation function;experiment;interaction;multi-agent system;obstacle avoidance;virtual reality	Franck Gechter;Jean-Michel Contet;Pablo Gruer;Abder Koukam	2010		10.1016/j.procs.2010.04.035	simulation;computer science;virtual machine;artificial intelligence;evaluation function;multi-agent system;obstacle avoidance	Robotics	-20.4077539506153	-20.658342606763593	19812
bd661355041d9a758d4cdab38da1f577b16e89ed	answering multidimensional queries on cubes using other cubes	query language;optimisation;data cube;query processing;query performance multidimensional queries cubes on line analytical processing multiple hierarchies multidimensional data structures user interaction algebraic md query language optimization declarative conditions;optimization technique;multidimensional systems data analysis data structures database languages decision support systems computer science context modeling data models cost accounting availability;complexity analysis;olap;data mining;data model;data structures;query evaluation;aggregate queries;optimisation data structures query processing data mining;view usability;materialized views;user interaction;data structure;multidimensional databases;on line analytical processing	Recently there is an important interest on On-Line Analytical Processing (OLAP) technology. In this context, in order to facilitate complex analysis, data are usually modeled multidimensionally, where multiple hierarchies are associated with the dimensions. These Multidimensional (MD) data structures are called data cubes. In the existing OLAP products, the user interaction is limited to one operation at a time. Further, computing OLAP operations is very expensive since sequential scans are required. In this paper, we provide a simple data model for MD databases, and a simple algebraic MD query language that permit the modeling of the principal OLAP operations. The MD query language allows the user to directly specify the result. Therefore, optimization techniques can be applied globally to the MD query evaluation. We state declarative conditions for answering queries on cubes using exclusively one or more precomputed queries (derived cubes). Then, we provide instance independent expressions that compute an MD query on a cube from derived cubes. These results can be used to increase availability of data and to improve MD query performance.	aggregate data;aggregate function;computation;cryptographic hash function;cubes;data cube;data model;data structure;data-intensive computing;database;klee–minty cube;linear algebra;mathematical optimization;model-driven engineering;molecular dynamics;online analytical processing;optimization problem;precomputation;query language;query optimization;relational operator;response time (technology)	Dimitri Theodoratos;Timos K. Sellis	2000		10.1109/SSDM.2000.869782	materialized view;data structure;data model;online analytical processing;computer science;theoretical computer science;data mining;database;query language;data cube	DB	-28.78795208374531	2.7450684946165507	19863
5fc62c5454df46b4dc5d67cbf756d0c05e34db7a	integrating skills into multi-agent systems	elementary operator;multi agent system;design and development;agent communication;knowledge representation;autonomous robot	Currently, an important topic of robotic research is the design and development of multi-agent robot systems (MASs). In these a number of autonomous robots cooperate and coordinate themselves in order to pursue given goals. The agents of an MAS not only have to work autonomously or in cooperation with other agents, but in dynamic, relatively unstructured environments. Therefore, the agents require agent-speci®c but ̄exible skills to cope with their tasks and the environment's variability. On the other hand, the actions to be performed by agents in an MAS have to meet certain requirements imposed by the MAS's structure. The representation of actions has to support planning, inter-agent communication, task negotiation etc. In this paper, we describe a method of combining the agent-speci®c nature of skills with the requirements for a general action knowledge representation inherent to MASs, by presenting elementary operations (EOs) that provide an appropriate interface. Ó 1998 Chapman & Hall	automated planning and scheduling;autonomous robot;computer science;data structure;elementary;glossy display;hardware description language;heart rate variability;inter-process communication;knowledge acquisition;knowledge representation and reasoning;multi-agent system;real-time transcription;requirement;skill	Holger Friedrich;Oliver Rogalla;Rüdiger Dillmann	1998	J. Intelligent Manufacturing	10.1023/A:1008811827890	knowledge representation and reasoning;simulation;computer science;artificial intelligence;multi-agent system	AI	-26.542020303820653	-21.70694065969448	19869
f628344953bb6e2abb5713ef60c59486e5739d3d	negotiating concurrently with unknown opponents in omplex, real-time domains		We propose a novel strategy to enable autonomous agents to negotiate concurrently with multiple, unknown opponents in realtime, over complex multi-issue domains. We formalise our strategy as an optimisation problem, in which decisions are based on probabilistic information about the opponents’ strategies acquired during negotiation. In doing so, we develop the first principled approach that enables the coordination of multiple, concurrent negotiation threads for practical negotiation settings. Furthermore, we validate our strategy using the agents and domains developed for the International Automated Negotiating Agents Competition (ANAC), and we benchmark our strategy against the state-of-the-art. We find that our approach significantly outperforms existing approaches, and this difference improves even further as the number of available negotiation opponents and the complexity of the negotiation domain increases.	agent-based model;autonomous robot;benchmark (computing);bilateral filter;computation;experiment;many-to-many;mathematical optimization;one-to-many (data model);real-time locating system;real-time web;simulation	Colin R. Williams;Valentin Robu;Enrico Gerding;Nicholas R. Jennings	2012		10.3233/978-1-61499-098-7-834	knowledge management;artificial intelligence	AI	-11.028601459329876	-8.78457282321032	19907
2d8fbd1a2f967324c06692dea388279ee65953bd	a formal model for soft enforcement: influencing the decision-maker	dr thomas gross;eprints newcastle university;open access;professor aad van moorsel;dr iryna yevseyeva;dr charles morisset	We propose in this paper a formal model for soft enforcement, where a decision-maker is influenced towards a decision, rather than forced to select that decision. This novel type of enforcement is particularly useful when the policy enforcer cannot fully control the environment of the decision-maker, as we illustrate in the context of attribute-based access control, by limiting the control over attributes. We also show that soft enforcement can improve the security of the system when the influencer is uncertain about the environment, and when neither forcing the decision-maker nor leaving them make their own selection is optimal. We define the general notion of optimal influencing policy, that takes into account both the control of the influencer and the uncertainty in the system.	game-maker	Charles Morisset;Iryna Yevseyeva;Thomas Groß;Aad P. A. van Moorsel	2014		10.1007/978-3-319-11851-2_8	access control;computer science;computer security;management science;enforcement;limiting;security policy	AI	-11.505928206766228	-3.6424194742127955	19922
72b50b24bb4287adc9b491f4326b88c109b3cdc3	decision analysis using belief functions	belief function;probability;uncertainty;decision analysis;decision theory;reasoning	Abstract   A primary motivation for reasoning under uncertainty is to derive decisions in the face of inconclusive evidence. Shafer's theory of belief functions, which explicity represents the underconstrained nature of many reasoning problems, lacks a formal procedure for making decisions. Clearly, when sufficient information is not available, no theory can prescribe actions without making additional assumptions. Faced with this situation, some assumption must be made if a clearly superior choice is to emerge. This paper offers a probabilistic interpretation of a simple assumption that disambiguates decision problems represented with belief functions. It is proved that it yields expected values identical to those obtained by a probabilistic analysis that makes the same assumption. A strict separation is maintained between evidence that carries information about a situation and assumptions that may be made for disambiguation of choices. In addition, it is shown how the decision analysis methodology frequently employed in probabilistic reasoning can be extended for use with belief functions. This generalization of decision analysis allows the use of belief functions within the familiar framework of decision trees.	decision analysis	Thomas M. Strat	1990	Int. J. Approx. Reasoning	10.1016/0888-613X(90)90014-S	optimal decision;influence diagram;uncertainty;decision theory;decision analysis;decision field theory;decision engineering;belief structure;artificial intelligence;probability;data mining;mathematics;evidential reasoning approach;reason;weighted sum model;statistics;business decision mapping	AI	-15.57777226399787	-0.03262578451903065	19978
19aab14b8eb0e86bb30ea5d40138ae4311185896	task modeling with reusable problem-solving methods	knowledge based system;task model;domain knowledge;task analysis;problem solving method	"""Problem-solving methods for knowledge-based systems establish the behavior of such systems by de ning the roles in which domain knowledge is used and the ordering of inferences. Developers can compose problem-solving methods that accomplish complex application tasks from primitive, reusable methods. The key steps in this development approach are task analysis, method selection (from a library), and method con guration. Prot eg e-ii is a knowledge-engineering environment that allows developers to select and con gure problem-solving methods. In addition, prot eg e-ii generates domain-speci c knowledge-acquisition tools that domain specialists can use to create knowledge bases on which the methods may operate. The board-game method is a problem-solving method that de nes control knowledge for a class of tasks that developers can model in a highly speci c way. The method adopts a conceptual model of problem solving in which the solution space is construed as a \game board"""" on which the problem solver moves \playing pieces"""" according to prespeci ed rules. This familiar conceptual model simpli es the developer's cognitive demands when con guring the board-game method to support new application tasks. We compare con guration of the board-game method to that of a chronological-backtracking problem-solving method for the same application tasks (for example, Towers of Hanoi and the Sisyphus room-assignment problem). We also examine how method designers can specialize problem-solving methods by making ontological commitments to certain classes of tasks. We exemplify this technique by specializing the chronologicalbacktracking method to the board-game method."""	assignment problem;backtracking;exemplification;feasible region;knowledge engineering environment;knowledge-based systems;naruto shippuden: clash of ninja revolution 3;problem solving;solver;task analysis;tower of hanoi	Henrik Eriksson;Yuval Shahar;Samson W. Tu;Angel R. Puerta;Mark A. Musen	1995	Artif. Intell.	10.1016/0004-3702(94)00040-9	simulation;computer science;knowledge management;artificial intelligence;knowledge-based systems;task analysis;domain knowledge	AI	-20.663068766519928	-7.888010694863679	19982
97b338160c3f2ac591daff7881a1116fc2869e7a	metastrategies in the colored trails game	metastrategies;colored trails	This paper presents a novel method to describe and analyze strategic interactions in settings that include multiple actors, many possible actions and relationships among goals, tasks and resources. It shows how to reduce these large interactions to a set of bilateral normal-form games in which the strategy space is significantly smaller than the original setting, while still preserving many of its strategic characteristics. We demonstrate this technique on the Colored Trails (CT) framework, which encompasses a broad family of games defining multi-agent interactions and has been used in many past studies. We define a set of representative heuristics in a threeplayer CT setting. Choosing players’ strategies from this set, the original CT setting is analytically decomposed into canonical bilateral social dilemmas, i.e., Prisoners’ Dilemma, Stag Hunt and Ultimatum games. We present a set of criteria for generating strategically interesting CT games and empirically show that they indeed decompose into bilateral social dilemmas if players play according to the heuristics. Our results have significance for multi-agent systems researchers in mapping large multi-player task settings to well-known bilateral normal-form games in a way that facilitates the analysis of the original setting.	bilateral filter;ct scan;heuristic (computer science);interaction;multi-agent system	Steven de Jong;Daniel Hennes;Karl Tuyls;Ya'akov Gal	2011			simulation;computer science;artificial intelligence	AI	-15.57123742087924	-12.47598219861991	20058
d9ea2e256bb3e1657611496460e21503cfd879bc	viewing control structures as patterns of passing messages artificial intelligence	control systems;iterations;computer communications;data storage systems;control structure;computerized simulation;recursive functions;artificial intelligence;methodology;parallel processing;problem solving	The purpose of this paper is to discuss some organizational aspects of programs using the actor model of computation. In this paper we present an approach to modelling intelligence in terms of a society of communicating knowledge-based problem-solving experts. In turn each of the experts can be viewed as a society that can be further decomposed in the same way until the primitive actors of the system are reached. We are investigating the nature of the communication mechanisms needed for effective problem-solving by a society of experts and the conventions of civilized discourse that make this possible. In this way we hope eventually to develop a framework adequate for the discussion of the central issues of problem-solving involving parallel versus serial processing and centralization versus decentralization of control and information storage.#R##N##R##N#This paper demonstrates how actor message passing can be used to understand control structures as patterns of passing messages in serial processing. This paper is a pre-requisite for successors which treat issues of parallelism and communication within the framework established here. The ability to analyze or synthesize any kind of control structure as a pattern of passing messages among the members of a society provides an important tool for understanding control structures. Ultimately, we hope to be able to characterize various control structures in common use by societies in terms of patterns of passing messages. This paper makes a small step in this direction by showing how to characterize familiar control structures such as iteration and recursion in these terms.	artificial intelligence	Carl Hewitt	1977	Artif. Intell.	10.1016/0004-3702(77)90033-9	parallel processing;simulation;iteration;computer science;artificial intelligence;theoretical computer science;methodology;mathematics;control flow	AI	-24.693676399558896	-11.075508805880082	20063
cea6137926b2daba764906befaaa15841d29c909	integration of robotic arm manipulator with computer vision in a project-based learning environment	robot mechanics robotic arm manipulator computer vision project based learning environment teaching undergraduate students electrical engineering sogn og fjordane university college norway tic tac toe game fully autonomous robot navigation robot vision;robot sensing systems;educational robots robot kinematics computer vision robot sensing systems service robots games;service robots;educational robots;computer vision;teaching computer aided instruction control engineering computing control engineering education electrical engineering computing electrical engineering education further education manipulators path planning robot vision;games;robot kinematics	This work-in-progress paper describes our experience in introduction of a Project-Based Learning environment in teaching of undergraduate students in the field of electrical engineering at Sogn og Fjordane University College in Norway. In the scope of this work, a robot capable of playing the tic-tac-toe game with a human and an additional laboratory exercise in robotic manipulation with computer vision has been developed. In this lab, the students integrated the robotic manipulator with computer vision in order to prepare a fully autonomous robot navigation using a prepared library that provides the functions for robot control and image processing. The project can be an interesting tool for learning some advanced topics such as robot vision, robot mechanics and autonomous robot navigation. The results show that students with strong motivation start to carry out an advanced project without any theoretical background in robotics and image processing. Another advantage is that the students can test in practice the influence of all stages of image processing on final robot navigation and understand that we may control robotic manipulators by using the vision information.	autonomous robot;computer vision;electrical engineering;image processing;positive feedback;robot control;robotic arm;robotic mapping	Krystian Radlak;Marcin Fojcik	2015	2015 IEEE Frontiers in Education Conference (FIE)	10.1109/FIE.2015.7344198	mobile robot;robot learning;computer vision;simulation;engineering;artificial intelligence;social robot;arm solution;robot control;ubiquitous robot;mobile robot navigation;personal robot	Robotics	-33.35347308909286	-21.597717846937034	20074
078ab4caf956ed65f321a0de57aa4e6a1762c6cd	evolutionary multi-objective optimization for landscape system design	hierarchical clustering;evolutionary multi objective optimization;habitat fragmentation;environmental policy;landscape structure;system design;pareto optimality;landscape design;land use planning	Increasing recognition of the extent and speed of habitat fragmentation and loss, particularly in the urban fringe, is driving the need to analyze qualitatively and quantitatively regional landscape structures in land-use planning and environmental policy implementation. This paper introduces an Evolutionary Multi-objective Optimization (EMO) methodology to estimate the Pareto optimal set of landscape designs generated from a series of underlying ecological principles. The results of applying these principles via EMO to a study site are presented and a hierarchical clustering methodology is introduced to assist in evaluating the population of solutions generated.	multi-objective optimization;systems design	Steven A. Roberts;G. Brent Hall;Paul H. Calamai	2011	Journal of Geographical Systems	10.1007/s10109-010-0136-2	land-use planning;geography;hierarchical clustering;landscape design;habitat fragmentation;systems design	EDA	-13.778944711860042	-23.487856670141426	20081
248b48b3fe0328514a4bcc74e4229ef00a219918	rainbow: a distributed and hierarchical rdf triple store with dynamic scalability	statistical analysis big data database indexing distributed processing fault tolerant computing query processing semantic web;resource description framework indexing distributed databases scalability fault tolerance fault tolerant systems pattern matching;distributed computing;fault tolerance rainbow distributed hierarchical rdf triple store dynamic scalability big data single node rdf data stores semantic web community rdf data indexing scheme statistical analysis user query space hybrid indexing scheme distributed hierarchical storage architecture hbase scalable persistent storage distributed memory storage query performance rdf data partitioning consistent hashing algorithm;distributed computing sparql rdf big data;big data;sparql;rdf	In the Big Data era, the ever-increasing RDF data have reached a scale in billions of triples and brought obstacles and challenges to single-node RDF data stores. As a result, many distributed RDF stores have been emerging in the Semantic Web community recently. However, currently published ones are either not enough efficient on performance or failed to achieve flexible scalability. In this paper, we propose Rainbow, a scalable and efficient RDF triple store. The RDF data indexing scheme in Rainbow is a hybrid one which is designed based on the statistical analysis of user query space. Further, to better support the hybrid indexing scheme, Rainbow adopts a distributed and hierarchical storage architecture that uses HBase as the scalable persistent storage and combines a distributed memory storage to speedup query performance. The RDF data in memory storage is partitioned by the consistent hashing algorithm to achieve the dynamic scalability. Experiments show that Rainbow outperforms typical existing distributed RDF triple stores, with excellent scalability and fault tolerance.	algorithm;apache hbase;big data;consistent hashing;data store;distributed memory;fault tolerance;hash function;hierarchical storage management;persistence (computer science);resource description framework;scalability;scheme;semantic web;speedup;triple des;triplestore	Rong Gu;Wei Hu;Yihua Huang	2014	2014 IEEE International Conference on Big Data (Big Data)	10.1109/BigData.2014.7004274	cwm;computer science;sparql;linked data;data mining;database;rdf query language;world wide web	DB	-29.981712274579014	0.8293923846509592	20114
73716201c11bd64688bd90bbb6aebe93633117ba	modellansatz zur geotopographischen analyse von wohngebieten und urbaner grüner infrastruktur		Compactness, efficiency and environmental quality are perceived as key topics of sustainable urban development. Density and green infrastructure can be a complementary accomplishment. Based on this issue, a complex methodological approach for spatial analysis of large and medium-sized cities was developed. In addition to spatial basic parameters, modified indices of the landscape ecological structure research have been incorporated. The determination of the parameters and indices are GISsupported on the basis of available nationwide official geodata. The focus of this paper is an example of the tension between urban density residential use on the one hand and urban green infrastructure on the other. The results of the analysis are presented (carto-) graphically in comparison with other cities.	biological organisation;kinetic data structure;spatial analysis	Ulrich Schumacher;Iris Lehmann;Martin Behnisch	2016	AGIT Journal	10.14627/537622071		HCI	-13.850395584910235	-23.300791579864597	20115
ff6616a9b43052beff6241fbbed79207c8f4c6c0	evaluating alternative plans for guiding tourism on nantucket island	solid waste;environmental impact;system modeling;water consumption;technical report	This paper discusses the application of a GPSS (General Purpose Simulation System) model to a unique planning situation on Nantucket Island, Massachusetts. Various factors influencing levels of tourism are evaluated in addition to resultant economic and environmental impacts. Specifically, passive regulation of visitor traffic via ferry schedule modification is examined in relation to daily expenditures by visitor type versus the associated costs of increased police and medical services, water consumption, and solid waste disposal.	gpss;resultant;simulation;stunt island	Douglas P. Schleusner;Eugene E. Kaczka	1977			simulation;systems modeling;municipal solid waste;environmental engineering;computer science;engineering;technical report;civil engineering;world wide web;environmental impact assessment	AI	-11.957485167969613	-21.255138093290036	20133
0a5c6d6e6719ed13c91f661efed74a474603480d	delegating decisions in strategic settings		We formalise and investigate the following problem. A principal must delegate a number of decisions to a collection of agents. Once the decisions are delegated, the agents to whom the decisions are delegated will act selfishly, rationally, and independently in pursuit of their own preferences. The principal himself is assumed to be self-interested, and has some goal that he desires to be achieved. The delegation problem is then, given such a setting, is it possible for the principal to delegate decisions in such a way that, if all the agents to whom decisions have been delegated then make decisions rationally, the principal’s goal will be achieved in equilibrium. We formalise this problem using Boolean games, which provides a very natural framework within which to capture the delegation problem: decisions are directly represented as Boolean variables, which the principal assigns to agents. After motivating and formally defining the delegation problem, we investigate the computational complexity of the problem, and some issues surrounding it.	analysis of algorithms;boolean satisfiability problem;computational complexity theory;digital command language;true quantified boolean formula	Sarit Kraus;Michael Wooldridge	2012		10.3233/978-1-61499-098-7-468	delegation;management science	ECom	-10.810070035674078	-1.5746350590814402	20135
142eed7ab69849cf1f2026b3be00cd8a862264cd	an aggregative fuzzy risk analysis for flood incident management	emergency response;analytic hierarchy process;risk analysis;fuzzy number;fuzzy risk;risk factors;flood incident management fim;aggregative risk analysis;emergency response system;risk assessment;fuzzy numbers and emergency response;hierarchical model	Mitigation of loss or damage is the prime focus in flood incident management (FIM). Emergency response program, a key element in flood incident management can fail in multiple ways; however it can be mainly attributed to failure of infrastructure and/or failure of human institutions. Characterization and quantification of various risk factors in emergency response is a difficult task because responses to floods are complex and dynamic in nature. For these reasons, high level of uncertainties are inherent in the estimation of risk associated with the emergency response and may warrant the usage of a quantitative–qualitative risk assessment framework. In this paper, a multi-stage hierarchical model is developed to estimate the aggregative risk associated with the failure of emergency response system in case of flood. Each risk item is defined by the product of the likelihood of a failure event and associated consequences. Both likelihood and the consequences of a failure event are defined using fuzzy numbers to capture vagueness in the concept of relevant risk factors. An analytic hierarchy process is used for estimating the priority matrix (weights) for grouping risk attributes. Utility of a proposed model is demonstrated through a simplified risk hierarchy representing emergency response system failure of a FIM.	incident management	Samiran Das;Rehan Sadiq;Solomon Tesfamariam	2011	Int. J. Systems Assurance Engineering and Management	10.1007/s13198-011-0053-x	reliability engineering;risk assessment;analytic hierarchy process;risk analysis;computer science;engineering;fuzzy number;operations management;computer security;risk factor;hierarchical database model	SE	-9.504855948806936	-17.05938967480002	20142
3ea6dc39d7b419921d65d10fac775ccd8684d1ae	modelling the suitability of urban networks for pedestrians: an affordance-based framework		In this chapter, a framework for modelling the suitability of urban networks for pedestrians is presented. Based on the psychological theory of affordances, a model of spatial suitability is developed that acknowledges the fact that suitability must always be analysed relative to the agent, the task and the environment. We extend existing affordance concepts by moving beyond simple true/false statements to express that there are various degrees to which an action can be afforded by an environmental object. In our model, environmental dispositions and agent capabilities are repeatedly selected, calculated and specified until atomic property pairs are identified. These can be combined to compute suitability values. We test and implement the model on a routing scenario for mobility-impaired persons. The results show that the framework produces suitable paths for different agents and thus shows promise for future work.		David Jonietz;Wolfgang Schuster;Sabine Timpf	2013		10.1007/978-3-319-00615-4_21	computer science;affordance;systems engineering;geographic information system;human–computer interaction;psychological theory	Vision	-19.775025229501942	-21.79167443656643	20169
d3c0b7d947e0142d0c19f3bdeb16c876dae005aa	a visual, hierarchical approach to implementing rule-based algorithms in classification of discrete, homogenous objects	rule based algorithm;expert systems;user interface generation;graphical interface;real time;rule based;database;visual programming;decision support system;visual basic;decision support systems;graphical model;relational database management system;control;usability;knowledge base;expert system	This research examines the graphical approach to implementing an expert system instead of the programming approach of the traditional ‘‘if then/else’’ construct. The rule base and knowledge base are built into the graphical model and only observation on the part of the user is needed for effective discrimination among choices. The application model is designed around a relational database management system with the user interface generated in Visual Basic and a rule base implemented through a hierarchy of mutually exclusive options presented to the user based on choices made as the user progresses through the various decision levels. Decision factors are based on observation of the discriminatory aspects of the objects to be classified as exhibited by the objects and maintained in the knowledge base. Human control is established through explanation and real-time recording and tracking of all choices made for any object under consideration. D 2003 Elsevier B.V. All rights reserved.	algorithm;cma-es;decision theory;documentation;expert system;graphical model;graphical user interface;hierarchical database model;knowledge base;logic programming;real-time locating system;relational database management system;rule-based system;usability;visual basic	Roy Martin Richards	2004	Decision Support Systems	10.1016/S0167-9236(03)00077-0	relational database management system;usability;decision support system;computer science;knowledge management;artificial intelligence;machine learning;data mining;graphical user interface;database;graphical model;visual programming language;expert system;scientific control	AI	-23.520909722621766	-21.513272994261772	20253
f05b4c9832a686257f3d3364bdd36e1e94c0ed03	representation of procedures and practices in contextual graphs		Over the last ten years a community on context has emerged. Brézillon (1999) proposed a survey of the literature about context in artificial intelligence. There is a now series of conference on context, a web site and a mailing list. The number of web pages with the word “context” has been multiply by ten in the last five years. Being among the instigators of the use of context in real-world applications, we present in this paper the evolution of our thoughts over the last years and the result that is obtained as a representation formalism based on contextual graphs and used in a real-world application called SART. We present how procedures, practices and context are intertwined, as identified in the SART application and in different domains. We root our view of context in the artificial intelligence area and give a general presentation of our view of context under the three aspects of external knowledge, contextual knowledge and proceduralized context, with the implementation of this view in contextual graphs. We discuss the representation of a reasoning, based on procedure and practices, in the formalism of contextual graphs and present how incremental acquisition of practices is integrated in this formalism.	artificial intelligence;semantics (computer science);web page	Patrick Brézillon	2003	Knowledge Eng. Review	10.1017/S0269888903000675	computer science;knowledge management;artificial intelligence;data mining	AI	-31.795129162114186	-11.770407034584796	20402
37624d3ed866c87e296b6f526c2b3d766d1b34b4	model-based diversification for sequential exploratory queries		Today, data exploration platforms are widely used to assist users in locating interesting objects within large volumes of scientific and business data. In those platforms, users try to make sense of the underlying data space by iteratively posing numerous queries over large databases. While diversification of query results, like other data summarization techniques, provides users with quick insights into the huge query answer space, it adds additional complexity to an already computationally expensive data exploration task. To address this challenge, in this paper we propose a diversification scheme that targets the problem of efficiently diversifying the results of multiple queries within and across different data exploratory sessions. Our proposed scheme relies on a model-based diversification method and an ordered cache. In particular, we employ an adaptive regression model to estimate the diversity of a diverse subset. Such estimation of diversity value allows us to select diverse results without scanning all the query results. In order to further expedite the diversification process, we propose an order-based caching scheme to leverage the overlap between sequence of data exploration queries. Our extensive experimental evaluation on both synthetic and real data sets shows the significant benefits provided by our scheme as compared to the existing methods.	analysis of algorithms;cpu cache;cache (computing);database;dataspaces;diversification (finance);exploratory testing;synthetic intelligence	Hina A. Khan;Mohamed A. Sharaf	2017	Data Science and Engineering	10.1007/s41019-017-0038-0	computer science;data mining;database;world wide web	DB	-24.942652239158445	3.8496555744991254	20475
52d424735e30d66da775f8b658d0cc585981d258	a descriptive model of robot team and the dynamic evolution of robot team cooperation	dynamic evolution.;cooperation;robot team;qualitative analysis	At present, the research on robot team cooperation is still in qualitative analysis phase and lacks the description model that can quantitatively describe the dynamical evolution of team cooperative relationships with constantly changeable task demand in Multi-robot field. First this paper whole and static describes organization model HWROM of robot team, then uses Markov course and Bayesian theorem for reference, dynamical describes the team cooperative relationships building. Finally from cooperative entity layer, ability layer and relative layer we research team formation and cooperative mechanism, and discuss how to optimize relative action sets during the evolution. The dynamic evolution model of robot team and cooperative relationships between robot teams proposed and described in this paper can not only generalize the robot team as a whole, but also depict the dynamic evolving process quantitatively. Users can also make the prediction of the cooperative relationship and the action of the robot team encountering new demands based on this model.	dynamical system;evolution;markov chain;robot	Shu-qin Li;Lan Shuai;Xian-Yi Cheng;Zhenmin Tang;Jingyu Yang	2005	CoRR		simulation;knowledge management;qualitative research;artificial intelligence	Robotics	-18.099898751573335	-15.682720774182936	20490
208b70d2cb06b17b8d48a907dc2ad2f4272a8588	pay-as-you-go reconciliation in schema matching networks	databases;uncertainty;measurement uncertainty;schema matching;probabilistic model;computational modeling;pay as you go;probability data integration pattern matching;approximation methods;probabilistic logic uncertainty data integration approximation methods measurement uncertainty databases computational modeling;probabilistic logic;reconciliation;probabilistic model pay as you go reconciliation schema matching networks database schemas data integration reconciliation process consistency expectations;data integration	Schema matching is the process of establishing correspondences between the attributes of database schemas for data integration purposes. Although several automatic schema matching tools have been developed, their results are often incomplete or erroneous. To obtain a correct set of correspondences, a human expert is usually required to validate the generated correspondences. We analyze this reconciliation process in a setting where a number of schemas needs to be matched, in the presence of consistency expectations about the network of attribute correspondences. We develop a probabilistic model that helps to identify the most uncertain correspondences, thus allowing us to guide the expert's work and collect his input about the most problematic cases. As the availability of such experts is often limited, we develop techniques that can construct a set of good quality correspondences with a high probability, even if the expert does not validate all the necessary correspondences. We demonstrate the efficiency of our techniques through extensive experimentation using real-world datasets.	database schema;statistical model	Nguyen Quoc Viet Hung;Nguyen Thanh Tam;Zoltán Miklós;Karl Aberer;Avigdor Gal;Matthias Weidlich	2014	2014 IEEE 30th International Conference on Data Engineering	10.1109/ICDE.2014.6816653	statistical model;uncertainty;computer science;data integration;machine learning;conflict resolution;data mining;database;probabilistic logic;computational model;statistics;measurement uncertainty	DB	-19.427809121952485	0.10326377101821546	20518
24c90fd9c122f39f95f37c05289f0e0a4ea2c866	the effects of agent activeness and cooperativeness on team decision efficiency: a computational simulation study using team-soar	modelizacion;interfase usuario;psychologie sociale;behavioral analysis;redundancia;user interface;sistema n niveles;team decision efficiency;modelisation;cooperativeness;agent activeness;redundancy;systeme n niveaux;team work;team soar;team performance;analyse comportementale;multilevel system;psicologia social;travail equipe;trabajo equipo;interface utilisateur;computational simulation study;social psychology;analisis conductual;modeling;computer simulation;redondance	Within an organizational context, an agent type reflects the behavioral tendency that a member might employ across tasks. Until now, however, the impacts of agent types on team performance are not well understood. To address this issue, this study examines the relationships of agent activeness and cooperativeness with team decision efficiency at different degrees of information redundancy by using a team model consisting of four AI agents. This study presents the team model called ‘‘Team-Soar’’ and describes how the model implements agent activeness at two levels (active and passive) and agent cooperativeness at three levels (cooperative, neutral, and selfish). Then a computational simulation experiment is described. Results of the simulation indicate that the impacts of the agent type depend on the amount of information to be processed and active style boosts the effects of agent cooperativeness on team efficiency. The results also indicate that active agents do not always contribute team efficiency more than passive agents. r 2006 Elsevier Ltd. All rights reserved.	agent-based model;computation;computer simulation;redundancy (information theory)	Mincheol Kang	2007	Int. J. Hum.-Comput. Stud.	10.1016/j.ijhcs.2006.11.001	computer simulation;simulation;systems modeling;teamwork;computer science;artificial intelligence;redundancy;user interface	AI	-23.151162011442153	-8.290853774846491	20539
4f22bff81b71a49d4b228c5cda153ae8064a73b3	order dependence of declarative knowledge representation	knowledge acquisition;knowledge representation	It has been a widely accepted assumption among knowledge representation researchers that declarative knowledge representation is in some sense order independent. In this paper we will argue that there are a number of different possible senses of the term “order independent” and that one needs at least one type of order dependence to develop a cognitively valid knowledge representation system that takes knowledge acquisition into account.	declarative programming;knowledge representation and reasoning	James Geller	1989		10.1007/BFb0022082	natural language processing;knowledge representation and reasoning;knowledge management;body of knowledge;knowledge-based systems;machine learning;procedural knowledge;knowledge extraction;commonsense knowledge	AI	-23.964974710374513	-2.583725151332588	20557
7e7aa292852fd0df097c4e3d8f2ef31ada5823a9	argument diagramming and diagnostic reliability	diagrammatic model;diagram model;argument diagram;argument diagramming;everyday language;present result;detailed example;conventional prose;diagnostic reliability;communications tool;grader agreement study;largo diagram	Diagrammatic models of argument are increasingly prominent in AI and Law. Unlike everyday language these models formalize many of the the components and relationships present in arguments and permit a more formal analysis of an arguments’ structural weaknesses. Formalization, however, can raise problems of agreement. In order for argument diagramming to be widely accepted as a communications tool, individual authors and readers must be able to agree on the quality and meaning of a diagram as well as the role that key components play. This is especially problematic when arguers seek to map their diagrams to or from more conventional prose. In this paper we present results from a grader agreement study that we have conducted using LARGO diagrams. We then describe a detailed example of disagreement and highlight its implications for both our diagram model and modeling argument diagrams in general.	argument map;artificial intelligence;diagram	Collin Lynch;Kevin D. Ashley;Niels Pinkwart;Vincent Aleven	2009		10.3233/978-1-60750-082-7-106	epistemology;computer science;artificial intelligence;algorithm	AI	-14.13526597973607	2.9260460390451133	20560
24668fcb17008dc02897e0d691d1be44d640d6b9	p-best response set	equilibrium selection;set valued concept;p dominance;higher order;perfect foresight dynamics;higher order uncertainty;risk dominance	This paper introduces a notion of p-best response set (p-BR). We build on this notion in order to provide a new set-valued concept: the minimal p-best response set (p-MBR). After proving general existence results of the p-MBR, we show that it characterizes set-valued stability concepts in a dynamic with Poisson revision opportunities borrowed from Matsui and Matsuyama [An approach to equilibrium selection, J. Econ. Theory 65 (1995) 415–434.] Then, we study equilibrium selection. In particular, using our notion of p-BR, we generalize Morris et al. [p-Dominance and belief potential, Econometrica 63 (1995) 145–157.] that aimed to provide sufficient conditions under which a unique equilibrium is selected in the presence of higher order uncertainty. © 2005 Published by Elsevier Inc. JEL classification: C72; C73		Olivier Tercieux	2006	J. Economic Theory	10.1016/j.jet.2005.06.001	higher-order logic;economics;mathematics;microeconomics;risk dominance;mathematical economics;welfare economics;equilibrium selection	ECom	-6.821806434922867	-1.349354179925314	20600
f849f868fe8b4e0dc3b59df50fc3e8afd118df24	knowledge engineering for intelligent decision support		Knowledge can be seen as the collection of skills and information an individual (or group) has acquired through experience, while intelligence as the ability to apply such knowledge. In many areas of Artificial Intelligence, we have been focusing for the last 40 years on the formalization and development of automated ways of finding and collecting data, as well as on the construction of models to represent that data adequately in a way that an automated system can make sense of it. However, in order to achieve real artificial intelligence we need to go beyond data and knowledge representation, and deeper into how such a system could, and would, use available knowledge in order to empower and enhance the capabilities of humans in making decisions in real-world applications. From my point of view, an AI should be able to combine automatically acquired data and knowledge together with specific domain expertise from the users that the tool is expected to help.	artificial intelligence;experience;knowledge engineering;knowledge representation and reasoning	Maria Vanina Martinez	2017		10.24963/ijcai.2017/736	clinical decision support system;r-cast;knowledge engineering;knowledge representation and reasoning;decision engineering;decision support system;intelligent decision support system;domain knowledge;computer science;knowledge management	AI	-31.624439828936435	-7.257153036617562	20606
1c61dca0a0d123a6bf9b20d5c38fa3557d9b9b5d	qualitative distances and qualitative description of images for indoor scene description and recognition in robotics	sensor data integration fuzzy set theory qualitative representation image understanding ontology description logics similarity robotics;qualitative topology;image segmentation;description logics;qualitative shape;image understanding;robotics;fuzzy set theory;info eu repo semantics article;sensor data integration;qualitative representation and modelling;similarity;interval distances;qualitative representation;qualitative orientation;conceptual neighbourhood diagrams;qualitative colour;ontology	This thesis is focused on reducing the gap between the acquisition of low level information by robot sensors and the need of obtaining high level information for enhancing human-machine communication and for applying logical reasoning processes. To this end, approaches for qualitative and semantic image description and qualitative distance sensor interpretation were developed. Experimentation was carried out on di↵erent robotic platforms showing useful	high- and low-level;high-level programming language;robot;sensor	Zoe Falomir	2011		10.3233/AIC-2012-0535	computer vision;description logic;similarity;qualitative reasoning;computer science;artificial intelligence;machine learning;ontology;data mining;fuzzy set;image segmentation;robotics	Robotics	-26.996851200102935	-19.85095551354955	20677
bca9a9ff4621b3ab4ef66a6fd441fa4c28aca95c	emotion generation model with growth functions for robots	self organizing maps;entertainment robot;emotion model		robot	Miho Harata;Masataka Tokumaru	2013	JACIII	10.20965/jaciii.2013.p0335	computer vision;self-organizing map;computer science;artificial intelligence;machine learning	Robotics	-29.150623857252207	-20.164646991374575	20694
4a6feff0e5a190f21c0dedc104ea3bfa1d073091	applying the pcr6 rule of combination in real time classification systems	sensor fusion;pcr6 algorithm;computer hardware;picture compilation;real time classification systems;sensor systems;decision support;dezert-smarandache theory;pcr6;classification;voting	Modern navies face the introduction of new ships with reduced and less trained manning and new, more complex, sensor systems. These trends could result in operator overload which might be solved by introducing a higher level of automation. In case of classification, a sub process of picture compilation, the problem of conflicting sensor data can be solved by proportional redistribution of conflict according to the PCR6 algorithm. This method is computationally demanding to such an extend that the applicability is limited in practice. The methodology in this paper adapts the PCR6 algorithm by simplification of the solution space of the algorithm by preprocessing the input data. Comparison tests show that this simplification reduces computing time by at least a factor hundred while the effects on the output are limited. We conclude that by applying preprocessing the pcr6 algorithm can be applied in real time classifications systems using common computer hardware.	algorithm;compiler;computational complexity theory;computer hardware;feasible region;level of detail;preprocessor;state space;window of opportunity	Krispijn A. Scholte;Wilbert van Norden	2009	2009 12th International Conference on Information Fusion		simulation;computer science;theoretical computer science;data mining	Robotics	-11.229418557054284	-21.211970203207606	20707
6817e9a86f6063693dd6e137c352b28c1994542e	logical form generation as abduction - part i. representation of linguistic concepts	abduction;modelizacion;generation;representation;concept;linguistique;generacion;connaissance;logic;diagnostico;abduction logic;intelligence artificielle;conocimiento;natural language processing computer science;modelisation;knowledge;linguistica;abduccion;inference logic;forme logique;inferencia;artificial intelligence;inteligencia artificial;language and languages;diagnosis;modeling;logical form;inference;representacion;concepto;diagnostic;linguistics	Abstract#R##N##R##N#For some time, researchers have become increasingly aware that some aspects of natural language processing can be viewed as abductive inference. This article describes knowledge representation in dual-route parsimonious covering theory, based on an existing diagnostic abductive inference model, extended to address issues specific to logic form generation. the two routes of covering deal with syntactic and semantic aspects of language, and are integrated by attributing both syntactic and semantic facets to each “open class” concept. Such extensions reflect some fundamental differences between the two task domains. the syntactic aspect of covering is described to show the differences, and some interesting properties are established. the semantic associations are characterized in terms of how they can be used in an abductive model. A major significance of this work is that it paves the way for a nondeductive inference method for word sense disambiguation and logical form generation, exploiting the associative linguistic knowledge. This approach sharply contrasts with others, where knowledge has usually been laboriously encoded into pattern-action rules that are hard to modify. Further, this work represents yet another application for the general principle of parsimonious covering. © 1994 John Wiley & Sons, Inc.		Venu Dasigi	1994	Int. J. Intell. Syst.	10.1002/int.4550090702	natural language processing;generation;logical form;computer science;artificial intelligence;machine learning;mathematics;knowledge;concept;representation;logic;algorithm;abductive logic programming	NLP	-21.895010297746207	-0.6611840900292734	20830
93a0878e3accfd531e9e5ea2d58ed3c93229c93a	multidimensional b-trees for associative searching in database systems	database system	Abstract   A new method for multiple attribute indexing, the Multidimensional  B -Tree (MBDT), is developed. This method is well suited for dynamic databases, since it handles several types of associative queries efficiently and requires low-cost maintenance. Algorithms and search strategies for exact match, partial match, and range queries are presented and statistical procedures are given to estimate the average and worst case retrieval times. The applicability of our organization to practical databases is discussed and analytical tradeoffs with regard to index organizations based on  k-d  trees are established.	b-tree;database	Peter Scheuermann;Aris M. Ouksel	1982	Inf. Syst.	10.1016/0306-4379(82)90024-2	computer science;theoretical computer science;machine learning;data mining;database	DB	-27.96426850928762	3.082566527415139	20842
d5557431f29e1a66bd78b97b455eb3e9526fcf88	analogies, adaptation, and anomalies	generic model;bounded rationality;decision maker;strategic interaction;journal of economic literature	This paper studies decision makers characterized by a stock of models, or analogies, who respond to strategic interactions by applying what appear to be the most suitable models; balancing the gains from more sophisticated decisionmaking against the cost of placing heavier demands on scarce reasoning resources. Equilibrium models will be finely tuned to interactions, leading to seemingly ``rational'' behavior, when the interactions are sufficiently important and sufficiently distinct that a more generic model entails a prohibitive payoff reduction. Interactions that are infrequently encountered, relatively unimportant, or similar to other interactions may trigger seemingly inappropriate analogies, leading to behavioral anomalies. Journal of Economic Literature Classification Numbers: C70, C72. 2001 Academic Press	interaction	Larry Samuelson	2001	J. Economic Theory	10.1006/jeth.2000.2754	decision-making;economics;operations management;mathematics;management science;mathematical economics;operations research;bounded rationality	SE	-6.5823733084757485	-7.775276678020758	20867
84f60cb2054147f6feda986ea5fa4026dc2fb6b4	fundamental ideas and mathematical basis of ontology learning algorithm			algorithm;ontology learning	Linli Zhu;Gang Hua;Sohail Zafar;Yu Pan	2018	Journal of Intelligent and Fuzzy Systems	10.3233/JIFS-169769	machine learning;artificial intelligence;ontology learning;mathematics	ML	-27.727475821789394	-8.570803809941907	20881
94bc9df1084201962f162d71230276358ad384a6	towards adversarial reasoning in statistical relational domains	stackelberg game;markov logic;probabilistic inference;adversarial reasoning	Statistical relational artificial intelligence combines first-order logic and probability in order to handle the complexity and uncertainty present in many real-world domains. However, many real-world domains also include multiple agents that cooperate or compete according to their diverse goals. In order to handle such domains, an autonomous agent must also consider the actions of other agents. In this paper, we show that existing statistical relational modeling and inference techniques can be readily adapted to certain adversarial or non-cooperative scenarios. We also discuss how learning methods can be adapted to be robust to the behavior of adversaries. Extending and applying these methods to real-world problems will extend the scope and impact of statistical relational artificial intelligence.	artificial intelligence;autonomous agent;autonomous robot;first-order logic;first-order predicate	Daniel Lowd;Brenton Lessley;Mino De Raj	2014			statistical relational learning;artificial intelligence;machine learning;data mining;stackelberg competition	AI	-12.849126210674061	-10.440586135160444	20905
0840ca37031ec3220ee8e9ce03fe8acd33d14f6e	the role of knowledge keepers in an artificial primitive human society: an agent-based approach		This paper discusses knowledge accumulation and diffusion mechanisms and their effect on social and institutional change in an artificial society. The focus of this paper is to model the role of knowledge keepers in the context of social control in the CKSW institutional meta-role framework. In literature this role has been associated with helping to maintain social order by spreading social awareness and resolving disputes. In addition to outlining the model of a complex, adaptive, and self-sustaining artificial society, we examine in this context the societal mechanism of violence control.		Marzieh Jahanbazi;Christopher Frantz;Maryam Purvis;Martin K. Purvis	2015		10.1007/978-3-319-42691-4_9	humanities;zoology;geography;anthropology	AI	-16.353443253644667	-14.864045181808267	20908
21889035c59b8243f110ad0e3aec160f0173892f	the urref ontology for semantic wide area motion imagery exploitation	image fusion;image motion analysis;inference mechanisms;information retrieval;information storage;ontologies (artificial intelligence);eturwg;evaluation of technologies for uncertainty representation working group;ifs;urref ontology;wami analysis;mission awareness;multi intelligence information access;multi intelligence information collection;multi intelligence information storage;operational information fusion systems;physics-based uncertainty representations;reasoning evaluation framework;semantic wide area motion imagery exploitation;text-based uncertainty representations;hard-soft information fusion;knowledge representation;measures of effectiveness;ontology;performance evaluation;uncertainty reasoning	Current advances operational information fusion systems (IFSs) require common semantic ontologies for collection, storage, and access to multi intelligence information. One example is the connections between physics-based (e.g. video) and text-based (e.g. reports) describing the same situation. Situation, user, and mission awareness are enabled through a common ontology. In this paper, we utilize the uncertainty representation and reasoning evaluation framework (URREF) ontology as a basis for describing wide-area motion imagery (WAMI) analysis to determine uncertainty attributes. As part of the Evaluation of Technologies for Uncertainty Representation Working Group (ETURWG), both the URREF and a WAMI challenge problem are available for research purposes from which we provide an exemplar schema to link physics-based and text-based uncertainty representations to explore a common uncertainty demonstration.	formal specification;knowledge representation and reasoning;ontology (information science);operational semantics;requirement;text-based (computing);video;web page	Erik Blasch;Paulo Cesar G. da Costa;Kathryn B. Laskey;Haibin Ling;Genshe Chen	2012	2012 IEEE National Aerospace and Electronics Conference (NAECON)		computer vision;computer science;data mining;information retrieval	Vision	-33.37132902675343	-12.401008169951677	20927
af5558267b468ee361d1a73769408df20f6a4467	large-scale residential energy maps: estimation, validation and visualization project sunshine - smart urban services for higher energy efficiency		This paper illustrates the preliminary results of a research project focused on the development of a Web 2.0 system designed to compute and visualize large-scale building energy performance maps, using: emerging platform-independent technologies such as WebGL for data presentation, an extended version of the EU-Founded project TABULA/EPISCOPE for automatic calculation of building energy parameters and CityGML OGC standard as data container. The proposed architecture will allow citizens, public administrations and government agencies to perform city-wide analyses on the energy performance of building stocks.		Umberto Di Staso;Luca Giovannini;Marco Berti;Federico Prandi;Piergiorgio Cipriano;Raffaele de Amicis	2014		10.1007/978-3-319-25936-9_3	simulation	Visualization	-14.51943169711907	-23.226615641785948	21019
2c120e9b3cbb53f531710c33e1a698c31e6f4b9e	decision and game theory for security	game theory;internal structure;satisfiability;expressive power	Attack–defense trees are used to describe security weaknesses of a system and possible countermeasures. In this paper, the connection between attack–defense trees and game theory is made explicit. We show that attack–defense trees and binary zero-sum two-player extensive form games have equivalent expressive power when considering satisfiability, in the sense that they can be converted into each other while preserving their outcome and their internal structure.	game theory	Barbara Kordy;Sjouke Mauw;Matthijs Melissen;Patrick Schweitzer	2010		10.1007/978-3-642-17197-0	game theory;combinatorics;discrete mathematics;computer science;mathematics;sequential game;expressive power;algorithm;satisfiability	Logic	-6.015135823164214	2.8839755219726158	21032
6707e4a87902a49377daac70007662e5d7d5737d	a fuzzy logic system used in safety analysis	puissance electrique;software tool;fuzzy set;securite;rule based;logique floue;logica difusa;fuzzy logic;protection;safety analysis;safety;fuzzy logic system;potencia electrica;proteccion;sistema difuso;electric power;systeme flou;seguridad;fuzzy event tree analysis;fuzzy system	"""The paper focus on the methodology to elaborate a fuzzy logic system (FLS) used in safety analysis of an electric power protection system. The in FLS parameters Occurrence and Severity and the out FLS parameter Safety are proposed. Also an adequate rule based was elaborated. For safety analysis is used the event-tree method. To elaborate the event tree and to use the proposed FLS on each part of the tree, a software tool """"Fuzzy event-tree analysis"""" (FETA) was created. We can obtain a """"Safety"""" fuzzy set on each path of the tree. All the evaluated """"Safety"""" fuzzy sets are introduced in an algorithm to elaborate the """"General Safety"""" of the system."""	fuzzy logic	Mariana Dumitrescu;Toader Munteanu	2001		10.1007/3-540-45493-4_88	fuzzy logic;rule-based system;electric power;computer science;artificial intelligence;fuzzy number;fuzzy set;algorithm;fuzzy control system	Logic	-7.133150281219812	-23.15694997313403	21039
8a617bed0fdfb5361592e51fe1df002023df8188	reducing diffusion time in attitude diffusion models through agenda setting		Attitude diffusion is when “attitudes” (general, relatively enduring evaluative responses to a topic) spread through a population. Attitudes play an incredibly important role in human decision making and are a critical part of social psychology. However, existing models of diffusion do not account for key differentiating aspects of attitudes. We develop the “Multi-Agent, Multi-Attitude” (MAMA) model which incorporates several of these key factors: (1) multiple, interacting attitudes; (2) social influence between individuals; and (3) media influence. All three components have strong support from the social science community. Using the MAMA model, we study influence maximization in a attitude diffusion setting where media influence is possible – we show that strategic manipulation of the media can lead to statistically significant decreases in diffusion of attitudes.	expectation–maximization algorithm;interaction;population	Kiran Lakkaraju	2015			mass media;machine learning;artificial intelligence;simulation;computer science;social psychology;social influence;social network;population;social simulation;maximization	ML	-15.447001876540558	-15.109458705167143	21143
f57f40b4df8662df8da297045d9156edc37415fc	characteristic properties of list proportional representation systems	allocation rule;proportional representation;satisfiability;social preferences	In this paper, three characterizations are given of a rule that models list systems of proportional representation the plurality ranking rule. It is shown that a social preference rule is the plurality ranking rule if and only if it satisfies three independent conditions: consistency, faithfulness, and first score cancellation. It is also shown that first score cancellation is implied by neutrality, anonymity, and topsonlyness. This means a second characterization is found, containing deeper axioms than the previous one. A third characterization contains the notion of top monotonicity. In order to motivate topsonlyness, we show that a scoring seat allocation rule is proof against party fragmentation if and only if it is topsonly. Various other properties of the plurality ranking rule are related to its characterist properties.		Eliora van der Hout;Harrie C. M. de Swart;Annemarie ter Veer	2006	Social Choice and Welfare	10.1007/s00355-006-0103-5	discrete mathematics;economics;social preferences;proportional representation;mathematics;triple product rule;algorithm;statistics;satisfiability	AI	-7.021271010630218	-2.2175620028619396	21148
fc1435e18e121ad025bcd04f5b2cd66b941b310a	caumel: a temporal logic based language for causal maps to explain agent behaviors		Causal maps are a powerful tools, used to deal with causal relations between events. They are frequently developed for specific is- sues such as decision analysis and problems diagnostic. The approach described in this paper underlines their novel utility providing a foun- dation to explain how agents have done actions. In fact, Multi-Agent Systems (MAS) are considered as complex systems, in which agent ac- tions are affected by several factors as uncertain beliefs, intentions of other agents, high interaction, and the dynamic aspect of the environ- ment. Thus, we believe that it is crucial to elucidate the agent system's behavior. To address the explanation of agent behaviors, this research presents, summarily, our method to build the causal map that corre- sponds to observed events during agent activities. Then, it focuses on a formal logic theory to interpret the built causal map, which includes causation between temporally ordered actions.	causality;temporal logic	Aroua Hedhili Sbaï;Wided Lejouad Chaari	2014		10.1007/978-3-319-07650-8_14	artificial intelligence	AI	-23.03206958279267	-13.624106215335889	21165
d407d35c3c2172752128a0f410c1f6a08ef6b442	knowrob-map - knowledge-linked semantic object maps	robot sensing systems;knowrob map;encyclopaedias;semantics;service robots;mobile robots;autonomous household robots;statistical analysis;knowledge linked semantic object maps;statistical analysis encyclopaedias knowledge engineering mobile robots service robots;data structures;relational model;manipulation tasks;common sense;knowledge representation;semantics knowledge based systems data structures robot sensing systems knowledge representation containers;common sense knowledge;human activity;statistical relational models;knowledge based systems;autonomous robot;encyclopedic knowledge;spatial information;containers;statistical relational models knowrob map knowledge linked semantic object maps autonomous household robots manipulation tasks encyclopedic knowledge common sense knowledge;knowledge engineering	Autonomous household robots are supposed to accomplish complex tasks like cleaning the dishes which involve both navigation and manipulation within the environment. For navigation, spatial information is mostly sufficient, but manipulation tasks raise the demand for deeper knowledge about objects, such as their types, their functions, or the way how they can be used. We present KNOWROB-MAP, a system for building environment models for robots by combining spatial information about objects in the environment with encyclopedic knowledge about the types and properties of objects, with common-sense knowledge describing what the objects can be used for, and with knowledge derived from observations of human activities by learning statistical relational models. In this paper, we describe the concept and implementation of KNOWROB-MAP and present several examples demonstrating the range of information the system can provide to autonomous robots.	autonomous robot;geographic information system;map;plasma cleaning	Moritz Tenorth;Lars Kunze;Dominik Jain;Michael Beetz	2010	2010 10th IEEE-RAS International Conference on Humanoid Robots	10.1109/ICHR.2010.5686350	mobile robot;computer vision;relational model;computer science;knowledge management;artificial intelligence;knowledge engineering;semantics;spatial analysis;commonsense knowledge	Robotics	-27.894106614771434	-19.950732973085007	21178
9baa57850546fcd1b4968feacea4ee242c2e1fb9	the absent-minded driver problem redux		Abstract This paper reconsiders the problem of the absent-minded driver who must choose between alternatives with different payoff with imperfect recall and varying degrees of knowledge of the system. The classical absent-minded driver problem represents the case with limited information and it has bearing on the general area of communication and learning, social choice, mechanism design, auctions, theories of knowledge, belief, and rational agency. Within the framework of extensive games, this problem has applications to many artificial intelligence scenarios. It is obvious that the performance of the agent improves as information available increases. It is shown that a non-uniform assignment strategy for successive choices does better than a fixed probability strategy. We consider both classical and quantum approaches to the problem. We argue that the superior performance of quantum decisions with access to entanglement cannot be fairly compared to a classical algorithm. If the cognitive systems of agents are taken to have access to quantum resources, or have a quantum mechanical basis, then that can be leveraged into superior performance.	algorithm;artificial intelligence;quantum entanglement;quantum mechanics;theory	Subhash C. Kak	2017	CoRR		artificial intelligence;common value auction;computer science;machine learning;mathematical economics;absent minded;quantum entanglement;mechanism design;social choice theory;stochastic game;cognition;imperfect	AI	-9.174923327345041	-2.86130836276739	21231
895bef773d705750ac319b144956ea378b79a51d	exploring the periphery of knowledge by intrinsically motivated systems	developmental robotics;intrinsic motivation;inverted u shape;emergence of competences	Intrinsically motivated learning is essential for the development of a wide range of competences. However, the neural substrate for the motivational signal as well as how this signal facilitates the processes of building competences are poorly understood. In this paper we exploit a biologically plausible approach, showing that an intrinsically motivated system where the motivation depends on stimulus familiarity as an inverted U-shape, exhibits well-structured exploration behaviour. Furthermore, we show that such behaviour may lead to the emergence of complex competences such as object affordances.		Kirill Makukhin;Scott Bolland	2015		10.1007/978-3-319-14803-8_4	psychology;artificial intelligence;communication;social psychology	ML	-22.124826901076165	-16.214461627831252	21343
d8aae28c58c83e68fd28e20ef98fae96526ead05	goals and plans in a program for playing go	ill structured problems;artificial intelligent;structural dynamics;plans and goals;artificial intelligence;go program;game playing	A program that plays Go provides a basis for analyzing possibilities for extending present AI conceptions of planning and goal structures to problems that are ill-structured, dynamic, multiperson, resource-bound, and highly interactive. The focus is on mechanisms for communicating information and control over time and among a number of interacting processes, in a flexible but coherent manner.  Using the capabilities of current computer languages, it is possible to specify planning and goal structures, and appropriate conventions for them, that will accommodate the demands of these increasingly complex and sophisticated problem environments.	coherence (physics);computer language;information and computation;interaction	Walter Reitman;James Kerwin;Robert A. Nado;Judith Reitman;Bruce Wilcox	1974		10.1145/800182.810391	simulation;computer science;artificial intelligence;management science	AI	-21.126002780174137	-8.327746113279364	21363
602f5af44fa2da910eb3fc712d4055ea3c95caab	applying machine learning to infant interaction: the development is in the details	modelizacion;animacion por computador;preconditionnement;lenguaje programacion;interfase usuario;programming language;model system;user interface;preconditioning;intelligence artificielle;probabilistic approach;contrato;intentional communication;social cognition;modelisation;contract;machine learning;predictability;enfoque probabilista;approche probabiliste;cognicion social;langage programmation;timing analysis;artificial intelligence;interface utilisateur;precondicionamiento;cognition sociale;predictabilidad;inteligencia artificial;contrat;reseau neuronal;computer animation;predictabilite;modeling;face to face;red neuronal;early interaction;neural network;animation par ordinateur	The face-to-face interactions of infants and their parents are a model system in which critical communicative abilities emerge. We apply machine learning methods to explore the predictability of infant and mother behavior during interaction with an eye to understanding the preconditions of infant intentionality. Overall, developmental changes were most evident when the probability of specific behaviors was examined in specific interactive contexts. Mother's smiled predictably in response to infant smiles, for example, and infant smile initiations become more predictable over developmental time. Analysis of face-to-face interaction--a tractable model system--promise to pave the way for the construction of virtual and physical agents who are able to interact and develop.	behavior;cobham's thesis;intentionality;interaction;machine learning;precondition;simplified molecular-input line-entry system	Daniel M. Messinger;Paul Ruvolo;Naomi V. Ekas;Alan Fogel	2010	Neural networks : the official journal of the International Neural Network Society	10.1016/j.neunet.2010.08.008	contract;social cognition;predictability;computer science;artificial intelligence;machine learning;computer animation;user interface;artificial neural network	ML	-24.122889883814263	-16.544694928552257	21365
49458a68f8378828747adf2f8354cd59d6505815	how do team leaders communicate to develop situation awareness?: an exploratory study in a nuclear submarine simulator	common ground;dialogue;human factors;interface;submarine;situation awareness;team cognition;cognitive ergonomics;complex risky system;language interaction	This exploratory study aimed to identify how team leaders' verbal statements support the development of team situation awareness, in a highly dynamic and risky environment. The study was conducted during seven training sessions in a nuclear submarine simulator. Trainees were Diving-Safety Teams, who are responsible for controlling the ship and ensuring safety. Team leaders' verbal statements were coded according to Endsley's model of situation awareness (SA) in order to determine their underlying intentions. Results showed that operational performance improved when team leaders shared their understanding of the current situation and its potential evolution. They also highlighted the importance of sharing evaluations of data, actions and goals. The key finding was that two-thirds of verbal statements expressed by team leaders support the development of SA. This confirms its crucial role in the context of complex sociotechnical systems in risky environments.	exploratory testing;simulation;sociotechnical system	Vincent Tardan;Léonore Bourgeon;Françoise Darses	2016		10.1145/2970930.2970952	situation awareness;simulation;psychological safety;computer science;engineering;knowledge management;interface;team composition;submarine;cognitive ergonomics	HCI	-24.934939628034467	-23.685608602013865	21384
845b9ee4eefe4326b9800e0cb3121998179190a1	mitigating human-human collaboration problems using software agents	multiagent system;collaborative work;software agent;collaboration;autonomous agent;col;agent communication language;intelligent software agents;workflow;intelligent software agent;multiagent systems	In this paper, we demonstrate the use of autonomous agents to assist humans in complying with the schedule of a collaborative work process. Software agents take over the tasks of communicating between agents and reminding and alerting humans in complying with scheduled tasks. While the FIPA agent communication language implements communication exchanges between agents, an interface for each agent implements the communication between humans and agents. Such interface provides a convenient means for humans to delegate mundane tasks to software agents.		Moamin Ahmed;Mohd Sharifuddin Ahmad;Mohd Zaliman Mohd Yusoff	2010		10.1007/978-3-642-13480-7_22	agent architecture;workflow;simulation;embodied agent;computer science;knowledge management;artificial intelligence;autonomous agent;software agent;belief–desire–intention software model;multi-agent system;distributed computing;intelligent agent;collaboration	Robotics	-26.94460514655318	-21.25335671520197	21465
ac8882a40fb2bf53f86566effb2987fc7f6b43dc	modeling swarm phenomena using logistic agents: application to a predators-prey pursuit	control variable;swarm intelligence phenomenon;predators-prey pursuit simulation;logistic multi-agent system model;complex system;logistic agent;map lattice;adaptive capability;swarm phenomenon	In this paper, we study swarm intelligence phenomena using the logistic multi-agent system model (LMAS). This model derives from the “coupled map lattice” family of models, which is usually considered in the field of complex systems. After recalling the fact that the LMAS enables simulating flocking phenomena in a self-organized way, we study its adaptive capabilities by applying it to a predators-prey pursuit simulation, in order to visualize the effect of the environment on the control variable of the agents.	complex systems;coupled map lattice;multi-agent system;prey;self-organization;simulation;swarm intelligence	Rodolphe Charrier;Christine Bourjot;François Charpillet	2009		10.1145/1558109.1558234	simulation;artificial intelligence;machine learning	AI	-18.49103566565308	-15.836171314393704	21519
6fca390fc65c0c46d1f5de81e3f6a4890af5dcc4	indexing moving objects using short-lived throwaway indexes	moving object;road network;index structure;indexation;exponential growth;experimental evaluation;external memory;short period;massive data sets	With the exponential growth of moving objects data to the Gigabyte range, it has become critical to develop effective techniques for indexing, updating, and querying these massive data sets. To meet the high update rate as well as low query response time requirements of moving object applications, this paper takes a novel approach in moving object indexing. In our approach we do not require a sophisticated index structure that needs to be adjusted for each incoming update. Rather we construct conceptually simple short-lived throwaway indexes which we only keep for a very short period of time (sub-seconds) in main memory. As a consequence, the resulting technique MOVIES supports at the same time high query rates and high update rates and trades this for query result staleness. Moreover, MOVIES is the first main memory method supporting time-parameterized predictive queries. To support this feature we present two algorithms: non-predictive MOVIES and predictive MOVIES. We obtain the surprising result that a predictive indexing approach — considered state-of-the-art in an external-memory scenario — does not scale well in a main memory environment. In fact our results show that MOVIES outperforms state-of-the-art moving object indexes like a main-memory adapted Bx-tree by orders of magnitude w.r.t. update rates and query rates. Finally, our experimental evaluation uses a workload unmatched by any previous work. We index the complete road network of Germany consisting of 40,000,000 road segments and 38,000,000 nodes. We scale our workload up to 100,000,000 moving objects, 58,000,000 updates per second and 10,000 queries per second which is unmatched by any previous work.	algorithm;bx-tree;computer data storage;gigabyte;requirement;response time (technology);scalability;time complexity	Jens Dittrich;Lukas Blunschi;Marcos Antonio Vaz Salles	2009		10.1007/978-3-642-02982-0_14	exponential growth;computer science;data mining;database;world wide web	DB	-27.1115571341526	-0.13947118740031783	21582
ab837c51332bf1de7b6e54f97173730e43a9e922	a subjective measure of complexity	mental models;mental categories	This article presents a quantitative measure of complexity, subjectively understood as a property of the relationship between a system and its observer instead of as a property of the system itself. Within this framework, complexity is quantified by assuming to know the mental categories and the mental model by which a system is represented in the mind of its observer. It is argued that this subjectivist concept of complexity is not in contrast with objective measures of complexity introduced in particular domains, but generalizes complexity to domains where no objective measure is feasible. An extensive numerical example is presented and thoroughly discussed.	blum axioms;complexity;mental model;numerical analysis	Guido Fioretti	1999	Advances in Complex Systems	10.1142/S0219525999000187	complexity;artificial intelligence;mathematics;social psychology	Logic	-14.262256571695344	0.2657310936280038	21599
4ce87c1fb6f0c7bd78792dc32a770bb8a4893bf7	the hourglass of emotions	cognitive and affective modelling;affective hci;nlp	Human emotions and their modelling are increasingly understood to be a crucial aspect in the development of intelligent systems. Over the past years, in fact, the adoption of psychological models of emotions has become a common trend among researchers and engineers working in the sphere of affective computing. Because of the elusive nature of emotions and the ambiguity of natural language, however, psychologists have developed many different affect models, which often are not suitable for the design of applications in fields such as affective HCI, social data mining, and sentiment analysis. To this end, we propose a novel biologically-inspired and psychologically-motivated emotion categorisation model that goes beyond mere categorical and dimensional approaches. Such model represents affective states both through labels and through four independent but concomitant affective dimensions, which can potentially describe the full range of emotional experiences that are rooted in any of us.	affective computing;artificial intelligence;categorization;data mining;experience;human–computer interaction;natural language;refinement (computing);sentiment analysis;window of opportunity	Erik Cambria;Andrew Livingstone;Amir Hussain	2011		10.1007/978-3-642-34584-5_11	psychology;developmental psychology;affective science;communication;social psychology	AI	-26.09551475407025	-15.094642865522696	21625
b42907bd384a44f718cf6b399f254fd19356f5c8	verbalizing computers - a way to everyday language computing	systeme intelligent;protocole transmission;semiotics;verbalizacion;generacion lenguaje;sistema inteligente;information technology;technologie information;semiotique;semiotica;protocolo transmision;intelligent system;communication protocol;verbalisation;generation langage;verbalization;tecnologia informacion;verbalizing computer;language generation;transmission protocol	This paper describes Everyday Language Computing Project that we are currently promoting. An idea of the project is to solve the so-called 'information divide' in IT revolution. To this aim, we propose to verbalize computers like the brain to deal with the meanings of information. Verbalizing computers will be achieved by the semiotic base as a stored-intelligence together with text understanding/generation, language communication protocol, and language-based applications.		Michio Sugeno	2002		10.1007/3-540-45631-7_16	communications protocol;computer science;artificial intelligence;semiotics;information technology;algorithm	NLP	-25.309092527486452	-7.995433860492443	21695
fa300b0d2e1280c9bc2f8f36be1c5ac930ec9eeb	hybrid ai/control system interactions and analysis	oscillations;control algorithm;learning model;dynamic behaviour;autonomic system;control system;intelligent agents;stability analysis;intelligent agent;hybrid system;pilot induced;control algorithms	This paper discusses the nature of interactions between high-level intelligent agents and low-level control algorithms. Control algorithms offer the promise of simplifying a system's dynamic behaviour as perceived by the controlling agent, thus considerably simplifying the agent's tasks of planning and execution. However, the coupled dynamics of such a hybrid system can be difficult to predict and may even lead to undesirable behaviour. This paper demonstrates that it is possible for a rational intelligent agent commanding a system with a well-designed control algorithm to cause catastrophic behaviours, and presents a framework for analysing the coupled dynamics of hybrid systems. A technique for alleviating these behaviours is suggested, using newly developed control algorithms applicable to a wide variety of autonomous systems of current interest. These controllers can also themselves be made adaptive, allowing for the possibility of ‘distributed’ or ‘co-operative’ learning and reasoning. As the control...	control system;interaction	Carl Glen Henshaw;Robert M. Sanner	2004	J. Exp. Theor. Artif. Intell.	10.1080/09528130412331294724	von neumann stability analysis;simulation;real-time control system;computer science;artificial intelligence;oscillation;intelligent agent;hybrid system	AI	-23.744242398026184	-20.27908502990071	21734
eccfba72a62d92fa9f41a0cd268279559a235b85	inferential theory of learning as a conceptual basis for multistrategy learning	abduction;goal orientation;constructive induction;theories of learning;classification of inference;multistrategy learning;abstraction;conceptual framework;learning system;level of detail;induction;machine learning;transmutation;adaptive learning;analogy;background knowledge;dynamic adaptation;learning theory;learning strategies;generalization;inference;deduction	In view of a great proliferation of machine learning methods and paradigms, there is a need for a general conceptual framework that would explain their interrelationships and provide a basis for their integration into multistrategy learning systems. This article presents initial results on theInferential Theory of Learning that aims at developing such a framework, with the primary emphasis on explaining logical capabilities of learning systems, i.e., theircompetence. The theory views learning as a goal-oriented process of modifying the learner's knowledge by exploring the learner's experience. Such a process is described as a search through aknowledge space, conducted by applying knowledge transformation operators, calledknowledge transmutations. Transmutations can be performed using any type of inference—deduction, induction, or analogy. Several fundamental pairs of transmutations are presented in a novel and very general way. These include generalization and specialization, explanation and prediction, abstraction and concretion, and similization and dissimilization. Generalization and specialization transmutations change thereference set of a description (the set of entities being described). Explanations and predictions derive additional knowledge about the reference set (explanatory or predictive). Abstractions and concretions change the level of detail in describing a reference set. Similizations and dissimilizations hypothesize knowledge about a reference set based on its similarity or dissimilarity with another reference set. The theory provides a basis formultistrategy task-adaptive learning (MTL), which is outlined and illustrated by an example. MTL dynamically adapts strategies to thelearning task, defined by the input information, the learner's background knowledge, and the learning goal. It aims at synergistically integrating a wide range of inferential learning strategies, such as empirical and constructive inductive generalization, deductive generalization, abductive derivation, abstraction, similization, and others.	abductive reasoning;entity;inferential theory of learning;level of detail;machine learning;mathematical induction;natural deduction;partial template specialization;synergy	Ryszard S. Michalski	1993	Machine Learning	10.1007/BF00993074	natural language processing;computer science;artificial intelligence;machine learning;learning theory;mathematics	AI	-27.320948738729506	-11.769021504430654	21768
efe860a340f1bc5604b712fbe69d6ac9d4de1627	a contribution to the development of a hms simulation tool and proposition of a meta-model for holonic control. (contribution au développement d'un outil de simulation de systèmes holoniques de production et proposition d'un meta-modèle de contrôle holonique)		The present context and tendencies in modern production system, as mass customization, requires improvements with respect to the agility of the production organizations. In this sense, agile approaches have been proposed, such as the holonic approach. In Holonic Manufacturing System (HMS) the production entities, as resources and products, are envisaged with a type of intelligence. These smart-entities are called holons (HLs) whose intelligence is related to their autonomy and collaboration skills. The HMS also comprises a Holonic Control (HC) that must properly organize holon collaborations in order to become agile. Actually, HMS development requires engineering tools for design and testing. In this doctoral thesis, a meta-model for HC is proposed, whose instances are simulated within a particular tool called ANALYTICE II. This tool presents a clear separation between high-level control and emulated resources. Firstly, before the proposition of the HC meta-model, the resource holonification is proposed in this environment. Each Resource-HL is obtained by means of a virtual resource that provides data and services of an emulated-resource at a high level of control. Subsequently, the meta-model for HC over Resource-HLs following a process-driven production approach is proposed. The essence of the solution is based on Rule Base System (RBS) concepts being the causal relations of control dealt with by entities called Rules. The inference process in this RBS is realized through collaborations based upon notifications. The Resource-HLs notify the Rules about factual knowledge with respect to their states. Each Rule that is notified deliberates about the proper moment to execute some control action, as the coordination of a set of Resource-HLs, using causal knowledge. The inference occurs within a notification chain enabled by a group of Resource-HL agents and Rule agents. This kind of inference can be expected to provide advantages for the HC, such as high reactivity and entity decoupling. Furthermore, it allows for the creation of co-operative mechanisms for dealing with determinism and conflict issues. Moreover, this approach of rule-oriented control allows for coherent control implementation and expression. The control mechanisms emerge based on causal control knowledge expressed by experts in the Rules. Experts are exclusively concerned with the proper control knowledge needed for exploiting system flexibilities in order to increase system agility. Furthermore, some experts could even be artificial agents automatically dealing with knowledge of the Rules. Briefly, this process-driven HC solution concomitantly treats a set of control issues while also being a self-contained and open solution. Indeed, the solution openness allows its interpretation as a product-driven solution. The product-driven control is a tendency to reach agility by the decoupling of production demands and execution via entities like Smart-Product-HLs. Each Smart-Product-HL is concerned with a specific customized production order. The Smart-Product-HLs, with certain autonomy, use Resource-HLs to reach their production goals. In the meta-model interpretation, their interactions are organized by Rules for Resource-HL cooperation that avoids inappropriate system behavior. In this context, the execution of Rules depends upon the explicit Smart-Product-HL interest in their utilization. In some manner, each Smart-ProductHL deals with Rules as a kind of expert agent. The solution has been applied in a set of examples in ANALYTICE II presenting some simulation independence because each control instance is not aware that Resource-HLs and Smart-Product-HLs are simulated.		Jean Marcelo Simão	2005				AI	-21.90016568297526	-12.295850575316162	21780
1688f9d25ee18ede6640d8074161b6205620f33c	from computing with numbers to computing with words - from manipulation of measurements to manipulation of perceptions.	fuzzy logic	Interest in issues relating to consciousness has grown markedly during the last several years. And yet, nobody can claim that consciousness is a well-understood concept that lends itself to precise analysis. It may be argued that, as a concept, consciousness is much too complex to fit into the conceptual structure of existing theories based on Aristotelian logic and probability theory. An approach suggested in this paper links consciousness to perceptions and perceptions to their descriptors in a natural language. In this way, those aspects of consciousness which relate to reasoning and concept formation are linked to what is referred to as the methodology of computing with words (CW). Computing, in its usual sense, is centered on manipulation of numbers and symbols. In contrast, computing with words, or CW for short, is a methodology in which the objects of computation are words and propositions drawn from a natural language (e.g., small, large, far, heavy, not very likely, the price of gas is low and declining, Berkeley is near San Francisco, it is very unlikely that there will be a significant increase in the price of oil in the near future, etc.). Computing with words is inspired by the remarkable human capability to perform a wide variety of physical and mental tasks without any measurements and any computations. Familiar examples of such tasks are parking a car, driving in heavy traffic, playing golf, riding a bicycle, understanding speech, and summarizing a story. Underlying this remarkable capability is the brain's crucial ability to manipulate perceptions--perceptions of distance, size, weight, color, speed, time, direction, force, number, truth, likelihood, and other characteristics of physical and mental objects. Manipulation of perceptions plays a key role in human recognition, decision and execution processes. As a methodology, computing with words provides a foundation for a computational theory of perceptions: a theory which may have an important bearing on how humans make--and machines might make--perception-based rational decisions in an environment of imprecision, uncertainty, and partial truth. A basic difference between perceptions and measurements is that, in general, measurements are crisp, whereas perceptions are fuzzy. One of the fundamental aims of science has been and continues to be that of progressing from perceptions to measurements. Pursuit of this aim has led to brilliant successes. We have sent men to the moon; we can build computers that are capable of performing billions of computations per second; we have constructed telescopes that can explore the far reaches of the universe; and we can date the age of rocks that are millions of years old. But alongside the brilliant successes stand conspicuous underachievements and outright failures. We cannot build robots that can move with the agility of animals or humans; we cannot automate driving in heavy traffic; we cannot translate from one language to another at the level of a human interpreter; we cannot create programs that can summarize non-trivial stories; our ability to model the behavior of economic systems leaves much to be desired; and we cannot build machines that can compete with children in the performance of a wide variety of physical and cognitive tasks. It may be argued that underlying the underachievements and failures is the unavailability of a methodology for reasoning and computing with perceptions rather than measurements. An outline of such a methodology--referred to as a computational theory of perceptions--is presented in this paper. The computational theory of perceptions (CTP) is based on the methodology of CW. In CTP, words play the role of labels of perceptions, and, more generally, perceptions are expressed as propositions in a natural language. CW-based techniques are employed to translate propositions expressed in a natural language into what is called the Generalized Constraint Language (GCL). In this language, the meaning of a proposition is expressed as a generalized constraint, X isr R, where X is the constrained variable, R is the constraining relation, and isr is a variable copula in which r is an indexing variable whose value defines the way in which R constrains X. Among the basic types of constraints are possibilistic, veristic, probabilistic, random set, Pawlak set, fuzzy graph, and usuality. The wide variety of constraints in GCL makes GCL a much more expressive language than the language of predicate logic. In CW, the initial and terminal data sets, IDS and TDS, are assumed to consist of propositions expressed in a natural language. These propositions are translated, respectively, into antecedent and consequent constraints. Consequent constraints are derived from antecedent constraints through the use of rules of constraint propagation. The principal constraint propagation rule is the generalized extension principle. (ABSTRACT TRUNCATED)	assumed;chimeric antigen receptor;color;computation (action);computer;computers;computing methodologies;computing with words and perceptions;concept formation;consciousness;constraint (mathematics);fuzzy logic;graph - visual representation;guarded command language;humans;indexes;inspiration function;language disorders;local consistency;mental world;natural language;physical object;probability learning;robot;rule (guideline);software propagation;telescopes;theory of computation;unavailability;underachievement	Lotfi A. Zadeh	2001	Annals of the New York Academy of Sciences	10.1007/1-4020-3167-X_23	computer science;theoretical computer science;distributed computing;multimedia	AI	-28.99813259955377	-10.038824641601925	21803
dd0275dbaba9452b0a72aa7ed4288e7286486310	an ontology modeling method of mechanical fault diagnosis system based on rsm	ontologies artificial intelligence ac motors fault diagnosis knowledge management;libraries;software;ac motor faults diagnosis ontology modeling method mechanical fault diagnosis system rsm resource space model knowledge quantity knowledge quality library knowledge grid protege 4;knowledge quality;ontologies fault diagnosis;diagnostic accuracy;knowledge management;ontology modeling method;protege;data mining;ontologies artificial intelligence;knowledge grid;ac motors;cognition;ac motor faults diagnosis;resource space model;fault diagnosis system;ontologies;rsm;protege 4;ontology;library;knowledge quantity;mechanical fault diagnosis system;fault diagnosis;protege ontology mechanical fault diagnosis resource space model;mechanical fault diagnosis	The intelligent level and diagnostic accuracy of mechanical fault diagnosis system depend on the knowledge quantity and quality in its library. While fusing existing knowledge is an important method to increase the knowledge quantity and quality in library. Accordingly, this paper using resource space model (RSM) of knowledge grid (KG) to classify and manage the fault diagnosis knowledge, then proposed an ontology modeling method of mechanical fault diagnosis system. Based on the method, we using protege 4 to construct an ontology of AC motor faults diagnosis.	kasparov's gambit;protégé;response surface methodology	Hong Wen;YinLuan Zhen;Huifu Zhang;Anhua Chen;Deshun Liu	2009	2009 Fifth International Conference on Semantics, Knowledge and Grid	10.1109/SKG.2009.57	ac motor;cognition;library;computer science;knowledge management;ontology;artificial intelligence;ontology;data mining	Robotics	-30.894906967131643	-5.279357705668626	22012
eef2c75508095d10703b61f59f7625dbee846504	individual error, group error, and the value of information	decision maker;decision problem;value of information	Extended Abstract Abstract. This paper studies the interaction of error and information both in a single-person setting and in an interactive setting. In contrast to Blackwell's Theorem, which says that more information is always good, the perspective of this paper is that while a lot of information is beneficial, a little information can be harmful. The main achievements of this paper are: (1) A characterization of the class of signals which always benefit a decision-maker in all decision problems. The analysis is carried out in a model which allows for the possibility that the decision-maker makes a mistake. (2) A demonstration that there are public signals within this class which can nevertheless reduce the utility of a team (i.e., a collection of agents with a common objective), as well as a characterization of the class of signals which always benefit a team in every team game. (3) A theorem that shows that in decision problems, beyond a certain threshold of precision, the value of information is increasing in the precision of signals, and which also provides a characterization of this threshold.	blackwell (series);decision problem;game-maker;interaction;matchware mediator	Itai Sher	2005		10.1145/1089933.1089937	decision-making;influence diagram;economics;computer science;artificial intelligence;operations management;value of information;decision problem;mathematics;management science;mathematical economics;expected value of perfect information;operations research;statistics	ECom	-9.28597818426879	-3.347473442820231	22016
f3cfb90c906fea218c24572bbe3b5f846a0ead42	inferring cross-sections: when internal visualizations are more important than properties of external visualizations	cognitive ability;statistical significance;general intelligence;three dimensional;interactive animation;spatial ability;cross section;three dimensional structure	Taylor & Francis makes every effort to ensure the accuracy of all the information (the “Content”) contained in the publications on our platform. However, Taylor & Francis, our agents, and our licensors make no representations or warranties whatsoever as to the accuracy, completeness, or suitability for any purpose of the Content. Any opinions and views expressed in this publication are the opinions and views of the authors, and are not the views of or endorsed by Taylor & Francis. The accuracy of the Content should not be relied upon and should be independently verified with primary sources of information. Taylor and Francis shall not be liable for any losses, actions, claims, proceedings, demands, costs, expenses, damages, and other liabilities whatsoever or howsoever caused arising directly or indirectly in connection with, in relation to or arising out of the use of the Content.	francis;primary source	Peter Khooshabeh;Mary Hegarty	2010	Human-Computer Interaction	10.1080/07370020903586704	three-dimensional space;computer vision;simulation;cognition;computer science;g factor;cross section;statistical significance;multimedia	Robotics	-15.320571910722537	-6.092239048314344	22036
a98aa2494740bf123b3266f56325ae8daa7adcf3	revisiting the self: a sine qua non for understanding embodiment	embodiment;mindfulness;consciousness;sensory motor approach;self	A major stumbling block in understanding the full significance of embodiment is the reflexive self-conception characterised by free-floating nature. The paper, in the initial sections, looks into the sensory motor approach to phenomenal consciousness and the approach to the study of vision where the world is treated as an external memory. Subsequently, the paper argues that the difficulty in exploring the sensory motor approach to phenomenal consciousness stems from the free-floating self-conception humans is endowed with. The assumption that experiences are internal can make us closed to the role external factors play in constituting experience.  Accordingly, a revision in the self-conception carries the possibility of conceptualising experience in a different manner.	consciousness;embodied cognition;situated;stumbleupon	V. Hari Narayanan	2014	AI & SOCIETY	10.1007/s00146-014-0574-3	self;artificial intelligence;consciousness;social psychology	AI	-25.434280770730563	-13.476818638398765	22169
273850608238dc2d0e168cca90259838d239cd46	efficient processing of continual range queries for location-aware mobile services	moving object;range query;location based service;continual range queries;query indexing;location aware service;mobile service;mobile e service;query evaluation;indexation;location awareness;mobile computing	Efficient processing of continual range queries is important in providing location-aware mobile services. In this paper, we study a new main memory-based approach to indexing continual range queries to support location-aware mobile services. The query index is used to quickly answer the following question continually: “Which moving objects are currently located inside the boundaries of individual queries?” We present a covering tile-based (COVET) query index. A set of virtual tiles are predefined, each with a unique ID. One or more of the virtual tiles are used to strictly cover the region defined by an individual range query. The query ID is inserted into the ID lists associated with the covering tiles. These covering tiles touch each other only at the edges. A COVET index maintains a mapping between a covering tile and all the queries that contain that tile. For any object position, search is conducted indirectly via the covering tiles. More importantly, a COVET-based query index allows query evaluation to take advantage of incremental changes in object locations. Computation can be saved for those objects that have not moved outside the boundaries of covering tiles. Simulations are conducted to evaluate the effectiveness of the COVET index and compare virtual tiles of different shapes and sizes.	algorithm;computation;computer data storage;computer simulation;location awareness;range query (data structures);range query (database);wang tile	Kun-Lung Wu;Shyh-Kwei Chen;Philip S. Yu	2005	Information Systems Frontiers	10.1007/s10796-005-4813-5	range query;query optimization;web query classification;computer science;operating system;location-based service;data mining;database;web search query;mobile computing;range query;world wide web;query language	DB	-26.450532050262854	0.5724826587914705	22192
2323662e3ea3cec039d8805bcd49c81b3c86a0f4	similarity-based sld resolution and its role for web knowledge discovery	engineering;fuzzy set;procesamiento informacion;approximation numerique;implementation;prolog;connaissance;similarity relation;conjunto difuso;solucion aproximada;ensemble flou;conocimiento;raisonnement;similitude;aproximacion numerica;ingenierie;approximate reasoning;knowledge;solution approchee;approximate solution;information processing;similarity;defaillance;razonamiento;ingenieria;sistema difuso;numerical approximation;failures;systeme flou;similitud;logic programs;reasoning;implementacion;traitement information;fallo;fuzzy system;knowledge discovery	This work presents the implementation of an extension of SLD resolution towards approximate reasoning and its implementation in an extended Prolog system. The proposed refutation procedure overcomes failures in the unification process by exploiting similarity relations defined between predicate and constant symbols. This enables to compute approximate solutions, with an associated approximation degree, when failures of the exact inference process occur. In this paper we outline the main ideas of this approach and we present an extended PROLOG interpreter, named SiLog, which implements this inference procedure. Then we point out on a web-based platform, usable for knowledge discovery, that exploits as inner feature the similarity-based SLD resolution.	sld resolution	Vincenzo Loia;Sabrina Senatore;Maria I. Sessa	2004	Fuzzy Sets and Systems	10.1016/j.fss.2003.10.018	similarity;information processing;computer science;artificial intelligence;sld resolution;theoretical computer science;similitude;machine learning;mathematics;fuzzy set;knowledge;implementation;prolog;algorithm;fuzzy control system	AI	-23.012910832753565	-1.84355948617749	22199
5c85116fa1bc831ab32ca06b7f97a1ada378ae00	improved topsis method and its application on initial water rights allocation in the watershed	comprehensive weight;game theory;improved topsis method;initial water rights allocation	Initial water rights allocation is a complex decision problem, and it is difficult for traditional methods to determine weights and solve the decision problem. In this study, an improved TOPSIS (Technique for order preference by similarity to ideal solution) method is proposed using vertical distance instead of Euclidean distance to calculate the closeness degree of schemes to the ideal solution, which overcomes the shortage of traditional TOPSIS method. In order to determine the weights of evaluation indexes reasonably, the improved method adopts game theory to harmonize and conjugate the subjective weight and the objective weight. On this basis, a comprehensive weight which eliminates the unilateral result can be obtained, and a model of initial water rights allocation in the watershed is established by the improved TOPSIS method. Finally, the proposed model is applied in the study of initial water rights allocation in Fuhuan River in Hubei Province, which shows rationality and validity when comparing with other models like traditional TOPSIS method, analytic hierarchy process and projection pursuit model. © 2011 Springer-Verlag Berlin Heidelberg.	watershed (image processing)	Chun Xiao;Dongguo Shao;Fengshun Yang	2011		10.1007/978-3-642-27452-7_79	environmental engineering;geography;water resource management;environmental resource management	AI	-5.362881483825397	-19.154243852149097	22234
b100476357e362f64d9ad6f562f9f5161e6c4e36	cognitive shape similarity assessment for 3d part search	part similarity;part search;shape cognition;product variety	Mass customization aims to satisfy diverse customer requirements with high product variety while maintaining reasonable manufacturing cost and lead time. Allowing customers to perceive product differentiation is a critical factor for most design methods developed for mass customization. This study examines 3D part search from the human cognitive perspective. We designed and conducted a quasi-factorial experiment to understand how structured variations of four factors—the shape, type, dimension, and location of the feature volume of a part model—affect human judgment of part similarity. The corresponding factorial similarity values were computed with different shape signatures in the form of the feature adjacency graph. The human responses were obtained by paired comparisons of test parts, and quantified as the cognitive similarity. Statistical analysis of the experimental results showed that the type and shape factors played an important role in the subjects’ judgments. Back-propagation neural networks were trained to model the correlations between the cognitive and the factorial similarity values. The performance of the networks validates our idea of incorporating human cognition into assessment of 3D part similarity. This study presents a systematic approach for personalized part search that reflects individual perception of shape similarity.		Chih-Hsing Chu;Cheng-Hung Lo;Han-Chung Cheng	2017	J. Intelligent Manufacturing	10.1007/s10845-016-1211-4	artificial intelligence;machine learning;data mining;mathematics;similarity heuristic;statistics	Robotics	-7.074509627134451	-19.747144688996734	22275
2a58c6416e121197d4255dafb0a80d1247935c58	competition for the access to and use of information in networks	formation de reseaux;efficiency;externalites negatives;pairwise stability;connections model;efficacite;network formation;modele des connexions;stabilite;negative externalities;information	In a network formation framework, where payoffs reflect an agent's ability to access information from direct and indirect contacts, we integrate negative externalities due to connectivity associated with two types of effects: competition for the access to information, and rivalrous use of information. We consider two separate models to capture the first and the second situations, respectively. In the first model, we assume that information is a non-rivalrous good but that there is competition for the access to information, for example because an agent with many contacts must share his time between them and thus has fewer opportunities to pass on information to each particular contact. The main idea is that the probability that each neighbor receives the information decreases with the number of contacts the sender has. In the second model, we assume that there is not competition for the access to information but that the use of information is rivalrous. In this case, it is assumed that when people receive the information before me, the harmful effect is greater than when others receive the information at the same time as myself. Our results concern pairwise stability and efficiency in both models and allow us to compare and contrast the effects of two kinds of competition for information.		Philipp Möhlmeier;Agnieszka Rusinowska;Emily Tanimura	2018	Mathematical Social Sciences	10.1016/j.mathsocsci.2017.09.006	economics;artificial intelligence;communication;social psychology;interaction information	Theory	-9.615545715140213	-6.218736392220562	22305
63b55498b32ad783b61e4e24c3bd1f2ba192fc21	sustainability index: a fuzzy approach for a municipal decision support system		Changing the behavior and habits of people and promoting sustainable production and consumption, has caused investment and action by Governments in promoting sustainability as a development model. Although many studies have been developed to evaluate the conditions for sustainability, few take into account the economic, environmental and social aspects altogether. Thus, the aim of this study is the development of an index to measure the degree of sustainability of municipalities using indicators for the social, demographic, economic and environmental dimensions. The methodology employed here is based on the concepts of fuzzy logic which models is subjectivity, uncertainty and imprecision. The index is applied to all 5,565 municipalities in Brazil generating a national sustainability study. After an assessment of the data using our index, a comparison is made with the Municipal Human Development index. Similar results are obtained by both methodologies. However, we argue that a fuzzy logic approach is useful since it uses linguistic variables and is intuitive to implement. Thus, the sustainability index is suitable to aggregate the various indicators and it is an important tool for decision makers. Since it provides information that is useful for the formulation, monitoring and evaluation of public policies.	decision support system;fuzzy logic	L. F. S. Soares;Sandra R. M. Masalskiene Roveda;Jose Arnaldo Frutuoso Roveda;Weldon A. Lodwick	2016		10.1007/978-3-319-75408-6_50	fuzzy logic;artificial intelligence;machine learning;environmental sustainability index;decision support system;human development index;public policy;environmental economics;computer science;subjectivity;sustainability;monitoring and evaluation	DB	-10.04026039189189	-19.653254472934368	22324
c974e866f2c407345b25ac765c307be60ad68c1f	performance analysis of alternative database machine architectures	backend computers;performance evaluation;information retrieval;data management;database machines;data bases;database management;performance tests;performance engineering;computer architecture;associative processing;associative processors;performance improvement;interrogation;performance analysis;cost effectiveness;performance evaluation associative processors backend computers computer architecture database machines database management parallel processors;database management system;memory devices;performance analysis database machines hardware proposals computer architecture application software contracts database systems concurrent computing;parallel processors;feasibility studies	The rapid advances in the development of low-cost computer hardware have led to many proposals for the use of this hardware to improve the performance of database management systems. Usually the design proposals are quite vague about the performance of the system with respect to a given data management application. In this paper we predict the performance of several of the proposed database management machines with respect to several representative INGRES queries. The systems analyzed in this paper include associative disks, RAP, CASSM, DBC, DIRECT, and CAFS. We demonstrate that no one database machine is best for executing all types of queries. We will also show that for one class of queries the degree of performance improvement achieved does not warrant use of a database machine.	computer hardware;content addressable file store;database machine;ingres;profiling (computer programming);vagueness	Paula B. Hawthorn;David J. DeWitt	1982	IEEE Transactions on Software Engineering	10.1109/TSE.1982.234775	parallel computing;cost-effectiveness analysis;performance engineering;database tuning;data management;computer science;theoretical computer science;operating system;database;programming language;database design	DB	-29.534102344136578	3.1165838092945015	22373
6f86ad7f86aa58e195b350ffd9eabda8ecfa358b	strategic and structural uncertainty in robust implementation	implementation;robust implementation;b economie et finance;strategic and structural uncertainty	This paper discusses some connections among several robustness concepts of mechanisms in terms of agents’ behaviors. Specifically, under certain conditions such as private values and “rich” interdependent values, we show that implementation in (one-round or iterative) undominated strategies, a solution concept robust to strategic uncertainty, is equivalent to Bayesian implementation with arbitrary type spaces, a solution concept robust to structural uncertainty. I am indebted to Ilya Segal, Stephen Morris, and Tilman Börgers for helpful discussions leading to the research question addressed in this paper. I am also grateful to seminar participants at Hitotsubashi University and the Summer Workshop on Economic Theory in 2011 for their valuable comments and suggestions. This research partly draws on a chapter of my dissertation undertaken at Stanford University, and I would like to thank Matthew Jackson, Jonathan Levin, Paul Milgrom, Andrzej Skrzypacz, and especially Ilya Segal, for their useful advice during candidature. Finally, I gratefully acknowledges the financial support of the B.F. Haley and E.S. Shaw Fellowship for Economics through the Stanford Institute for Economic Policy Research. Toulouse School of Economics. takuro.yamashita@tse-fr.eu	interdependence;iterative method;jackson;matthew flatt	Takuro Yamashita	2015	J. Economic Theory	10.1016/j.jet.2015.06.005	environmental resource management;management science;implementation	AI	-8.095268992952079	-4.447599368084866	22471
cfa60b60db6f87ebba7940c462bb38d570b95cbc	the scope and importance of human interruption in human-computer interaction design	dynamic change;human computer interaction;information sources;perforation	At first glance it seems absurd that busy people doing important jobs should want their computers to interrupt them. Interruptions are disruptive and people need to concentrate to make good decisions. However, successful job performance also frequently depends on people’s abilities to (a) constantly monitor their dynamically changing information environments, (b) collaborate and communicate with other people in the system, and (c) supervise background autonomous services. These critical abilities can require people to simultaneously query a large set of information sources, continuously monitor for important events, and respond to and communicate with other human operators. Automated monitoring HUMAN-COMPUTER INTERACTION, 2002, Volume 17, pp. 1–61 Daniel McFarlane is a computer scientist with an interest in intelligent command and control systems; he is a senior member of the engineering staff in the Advanced Technology Laboratories of Lockheed Martin. Kara Latorella is a human factors engineer with an interest in human performance in aviation; she is a research engineer in the Crew Systems Branch of NASA Langley Research Center. and alerting systems minimize the need to constantly monitor, but they induce alerts that may interrupt other activities. Such interrupting technologies are already widespread and include concurrent multitasking; mixed-initiative interac2 MCFARLANE AND LATORELLA	autonomous robot;computer multitasking;computer scientist;control system;emoticon;human factors and ergonomics;human reliability;human–computer interaction;interaction design;interrupt;interruption science;job stream;vegas connection: casino kara ai wo komete	Daniel C. McFarlane;Kara A. Latorella	2002	Human-Computer Interaction	10.1207/S15327051HCI1701_1	simulation;human–computer interaction;computer science;artificial intelligence;operating system;communication	HCI	-26.750151077954	-22.233309970480395	22508
81a35f9093172fd823af7ff804675d8bfb90999b	optimizing the placement of evacuation signs on road network with time and casualties in case of a tsunami	environmental factors;tsunami;road traffic;agent based model;crowd movement evacuation mixed integer linear programming agent based model;tsunami disasters environmental factors integer programming linear programming road traffic;mixed integer linear programming;integer programming;vietnam evacuation sign placement natural disaster artificial intelligence operation research crowd evacuation simulation human behavior memory less stochastic agent tsunami evacuation sign evacuation time casualties optimization problem mixed integer linear programming milp problem milp solver early warning evacuation road network nhatrang city;tsunami cities and towns roads solid modeling optimization computational modeling sea measurements;linear programming;evacuation;crowd movement;disasters	In recent years, the number of people affected by natural disasters and in particular tsunamis has been increasing. Artificial Intelligence and Operation Research approaches to simulate crowd evacuation and make cities ready for Tsunamis are critical interest. Given an extremely simple model of human behavior, i.e. a memory-less stochastic agent, we address the problem of optimizing the placement of Tsunami evacuation signs with respect to evacuation time and casualties. Moreover, we formalize this optimization problem as a Mixed Integer Linear Programming (MILP) problem and we run some experiments with a MILP solver on two scenarios of early warning evacuation for the road network of Nhatrang city in Vietnam.	academy;artificial intelligence;cplex;experiment;integer programming;linear programming;mathematical optimization;open-source software;operations research;optimization problem;optimizing compiler;simulation;solver	Thi Anh Ngoc Nguyen;Yann Chevaleyre;Jean-Daniel Zucker	2012	2012 IEEE 21st International Workshop on Enabling Technologies: Infrastructure for Collaborative Enterprises	10.1109/WETICE.2012.72	disaster;simulation;integer programming;linear programming;computer security	AI	-18.338138907579037	-23.44270613035481	22530
34431e777fbd5760da35483702c50a1ae07c9bb2	supporting an autonomous social agent within a competitive environment	game theory;multi agent systems;bayesian forecasting;adversarial risk analysis	Taylor & Francis makes every effort to ensure the accuracy of all the information (the “Content”) contained in the publications on our platform. However, Taylor & Francis, our agents, and our licensors make no representations or warranties whatsoever as to the accuracy, completeness, or suitability for any purpose of the Content. Any opinions and views expressed in this publication are the opinions and views of the authors, and are not the views of or endorsed by Taylor & Francis. The accuracy of the Content should not be relied upon and should be independently verified with primary sources of information. Taylor and Francis shall not be liable for any losses, actions, claims, proceedings, demands, costs, expenses, damages, and other liabilities whatsoever or howsoever caused arising directly or indirectly in connection with, in relation to or arising out of the use of the Content.	aisoy1;application release automation;autonomous agent;autonomous robot;cognition;domestic robot;francis;interaction;microphone;nl (complexity);primary source;sensor;simulation;smartphone;speech recognition;speech synthesis	Pablo G. Esteban;David Ríos Insua	2014	Cybernetics and Systems	10.1080/01969722.2014.894852	game theory;simulation;computer science;knowledge management;artificial intelligence;computer security	Robotics	-15.96172566944189	-7.439274436669873	22626
e90e2aa0fe511afdb6807e08e0efe42522a09a9a	predicting cellular automata		We explore the ability of a locally informed individual agent to predict the future state of a cell in systems of varying degrees of complexity using Wolfram’s onedimensional binary cellular automata. We then compare the agent’s performance to that of two small groups of agents voting by majority rule. We find stable rules (Class I) to be highly predictable, and most complex (Class IV) and chaotic rules (Class III) to be unpredictable. However, we find rules that produce regular patterns (Class II) vary widely in their predictability. We then show that the predictability of a Class II rule depends on whether the rules produces vertical or horizontal patterns. We comment on the implications of our findings for the limitations of collective wisdom in complex environments.	automata theory;cellular automaton;regular expression;rule 90	Jameson L. Toole;Scott E. Page	2011	Complex Systems		mathematics;artificial intelligence;machine learning;cellular automaton	Metrics	-15.80200493680403	-17.54461595342118	22627
d4251e606f96aab84d75e31ba69fe6a13d17ecc1	conscious intelligent systems - part ii - mind, thought, language and understanding	artificial intelligent;intelligent system	Preface This is a companion paper to Conscious Intelligent Systems Part 1 by the same author (1), which discusses a possible evolutionary path for consciousness and intelligence from simple systems to human level consciousness and intelligence. Man has long been held to be a thinking animal, his thought processes have been held to be the reason for his superiority over the animals. The grand aim of AI has always been to make an entity that can think. Turing took up this very question in his paper (2) on whether machines can think. On the more prosaic roads that real AI has been forced to follow, such grand questions have almost died down. Another major trigger for the demise has been Searle's Chinese Room (3) parody. With this rather cunning device, Searle set the cat among the pigeons and has helped induce self-doubt in the best of AI theorists. One of the major triggers towards Searle's views was language, whether syntax suffices for semantics and therefore understanding. From our evolutionary learning system perspective, which we discuss in Part I of this discussion, we see that all these processes are tied together, the processes of consciousness, intelligence, mind, thought, and language. In a bid to show the interconnectedness of these factors, we take up the question of understanding and its communication. Similar to our treatment of the subject of consciousness based intelligent systems in Part 1, here we treat understanding from first principles. Understanding In the real world when we use the term understanding, it has two main attributes; one is the capacity to infer, the other is the capacity to recognize or discern. In computing and AI contexts the word understanding is arguably tilted more in favor of inference than perception or cognition, in normal life and in the natural kingdom the reverse is true. This is primarily because AI's aims and present status look elemental when compared to the entities of the natural world. The other reason is that AI entities find it easier to infer than cognize, which is in itself a reflection of their design sources and its aims. For the purposes of this discussion the term understanding implies the natural version, a mix of cognition and inference. If we start from first principles, it is clear that for a rule to emerge out of a set of raw data, an inferential process has to run on it. …	artificial intelligence;chinese room;cognition;consciousness;elemental;entity;hybrid intelligent system;inferential programming;interconnectedness;mind;turing	U. Gayathree	2006	CoRR		natural language processing;computer science;artificial intelligence	AI	-27.981335730232825	-14.601352767129029	22768
4a847ef1a1915862a796d73ba6385a377e5546a7	feasibility study of railway line in hilly region using gis		Aim of this study is to demonstrate the potential of GIS and multi-criteria decision approach (MCDA) as a tool for the selection of alignment of rail route in Hilly region. In the present study, Geographic information system (GIS) and multi-criteria decision approach (MCDA) is used to plan the alignment of railway route from Bhuntar to Kullu in Himachal Pradesh (HP), India. The various factors which affect the alignment of rail route are identified in this study. The factors considered in this study are topography, land-use, distance from power line, drainage pattern and road network of the area. The Analytical Hierarchy Process (AHP) is used to determine the ranking of the relative parameters. The determined ranking is used in pair-wise comparison to find the weights of these relative parameters. The maps with weighted parameters are overlaid and resultant map is created in GIS for route finding, station location and alignment of railway. The final map shows the cumulative effect of all the factors which affect the rail route alignment. The final map is divided into four parts based on feasibility index. It is found that 55% area is highly feasible for route alignment while 25% of the total area comes under category of low feasibility.	geographic information system	Yogesh Kumar;Christine Lentz;Dauda M Madubu;Bhanu Pratap Singh	2017	iJOE		analytic hierarchy process;multiple-criteria decision analysis;engineering;drainage system (geomorphology);geographic information system;transport engineering;transportation planning;ranking	HCI	-11.567804731626412	-23.543897124187467	22804
23c77a552a831ef7e871f4f141554ef94abc8c48	the distribution reliability assessment based on the arithmetic of simulating reasoning	distribution system reliability;belief networks;distributed system;power system distribution reliability assessment simulating reasoning arithmetic bayesian network timing simulation node model bayesian diagnostic reasoning causal reasoning distribution system reliability power net elements reliability flag constringency;bayesian network;arithmetic power system reliability bayesian methods timing educational institutions analytical models failure analysis algorithm design and analysis uncertainty frequency;reliability;power distribution reliability;power net;causal reasoning;bayesian diagnostic reasoning;elements reliability;flag constringency power system reliability assessment bayesian network timing simulation;bayesian methods;node model;convergence rate;distribution reliability assessment;reliability assessment;indexes;power engineering computing;power system;indexation;cognition;power system reliability;simulating reasoning arithmetic;power engineering computing belief networks power distribution reliability;timing simulation;load modeling;flag constringency;bayesian network timing simulation	"""It mentions a new method of distribution reliability assessment based on Bayesian Network timing simulation. It uses node model """"causal"""" to change the gotten or lost duration of load points combined with the characteristics of bayesian diagnostic reasoning and causal reasoning. it can simply effectively obtain the index of distribution system reliability and find out the weakest link of the power net; The value of the elements reliability are converged faster and enhance the index convergence rate by the method Flag Constringency mentioned as followed. The result of operation calculated realistically proves the method here mentioned is effectively."""	bayesian network;causal filter;causality;rate of convergence;simulation;timing closure	Lihua Huang;Jie Hu;Lina Zhang;Yunfang Xie;Limin Huo	2009	2009 First International Workshop on Database Technology and Applications	10.1109/DBTA.2009.76	database index;cognition;causal reasoning;bayesian probability;computer science;theoretical computer science;machine learning;bayesian network;reliability;electric power system;rate of convergence;statistics	AI	-15.189334095483346	-1.2777036922650402	22813
f28bf1b009c06801bb1b9e9c2d3f6b863d09f8b7	modelling immune memory for prediction and computation	modelizacion;infeccion;immune algorithm;sistema inmunitario;intelligence artificielle;dinamica poblacion;algoritmo inmunitario;modelisation;emergent properties;network model;reponse immune;immune system;population dynamics;artificial intelligence;inteligencia artificial;respuesta inmune;dynamique population;infection;modeling;systeme immunitaire;immune response;algorithme immunitaire	This paper investigates the concept of immune memory, and the potential for an Artificial Immune System (AIS), in which memory is an emergent property of the antibody population and its dynamics. Inspiration for the implementation of this concept of memory is taken from current biological theories. However, a difficulty lies in the fact that as yet these theories remain unconfirmed; no conclusive explanation has been put forward to explain how immune memory is created and sustained over time. The approach taken here is to investigate and build on two of the basic models of immune memory : (i) the memory cell model, (ii) the residual antigen model, and iii) provide some initial thoughts as to the influence of the immune network model on our theory of immune memory. We show that each model can partially explain how the immune system can remember infections, and respond quickly to reinfections, but we begin to demonstrate that none of them in isolation result in an effective immune memory response. Our initial appraisal is that all three models should be combined, and updated to reflect new biological concepts, we make some suggestions about how this might be achieved, and we illustrate our discussion with some tentative results.	artificial immune system;computation;computer science;emergence;machine learning;memory cell (binary);network model;online and offline;persistence (computer science);surround sound;system dynamics;theory	William O. Wilson;Simon M. Garrett	2004		10.1007/978-3-540-30220-9_31	immune system;computer science;artificial intelligence;population dynamics;immunology;adaptive memory;algorithm	Metrics	-24.7474747192929	-16.052041370025425	22865
061ae56c3350b8850e15c0e0f4f7c19d24b9a2ab	synthesizing customized planners from specifications	artificial intelligent	Existing plan synthesis approaches in arti cial intelligence fall into two categories { domain independent and domain dependent. The domain independent approaches are applicable across a variety of domains, but may not be very e cient in any one given domain. The domain dependent approaches need to be (re)designed for each domain separately, but can be very e cient in the domain for which they are designed. One enticing alternative to these approaches is to automatically synthesize domain independent planners given the knowledge about the domain and the theory of planning. In this paper, we investigate the feasibility of using existing automated software synthesis tools to support such synthesis. Speci cally, we describe an architecture called CLAY in which the Kestrel Interactive Development System (KIDS) is used to derive a domain-customized planner through a semi-automatic combination of a declarative theory of planning, and the declarative control knowledge speci c to a given domain, to semi-automatically combine them to derive domain-customized planners. We discuss what it means to write a declarative theory of planning and control knowledge for KIDS, and illustrate our approach by generating a class of domain-speci c planners using state space re nements. Our experiments show that the synthesized planners can outperform classical re nement planners (implemented as instantiations of UCP, Kambhampati & Srivastava, 1995), using the same control knowledge. We will contrast the costs and bene ts of the synthesis approach with conventional methods for customizing domain independent planners.	automated planning and scheduling;declarative programming;emi (protocol);experiment;semiconductor industry;state space	Biplav Srivastava;Subbarao Kambhampati	1998	J. Artif. Intell. Res.	10.1613/jair.428	domain analysis;simulation;domain;computer science;artificial intelligence;problem domain;domain engineering;machine learning;algorithm	AI	-18.620739744588167	-7.4547413674827565	22902
ba842deeccbe456b50ac2e2eb557f18ded01edf5	a new intelligent agent-based strategy for constrained multiple destination routing problems	intelligent agent		destination routing;intelligent agent;optimization problem	Dave Elliman;Sherin M. Youssef	2004	Comput. J.	10.1093/comjnl/47.6.708	agent architecture;mathematical optimization;simulation;computer science;autonomous agent;distributed computing;intelligent agent	Robotics	-18.081084397153546	-11.294084578474891	22925
4aed60fae05114465734c6cf52257e8bd2fb593f	a survey of human computation systems	computers;social aspects of automation artificial intelligence computation theory;computation theory;collaboration;social aspects of automation;distributed human computation problem;optical character recognition software;internet;social games;human computation system;games;initiatory human computation system;artificial intelligence;humans;social games initiatory human computation system distributed human computation problem;humans distributed computing artificial intelligence internet optical character recognition software computer science learning systems testing information science scalability	Human computation is a technique that makes use of human abilities for computation to solve problems. The human computation problems are the problems those computers are not good at solving but are trivial for humans. In this paper, we give a survey of various human computation systems which are categorized into initiatory human computation, distributed human computation and social game-based human computation with volunteers, paid engineers and online players. For the existing large number of social games, some previous works defined various types of social games, but the recent developed social games cannot be categorized based on the previous works. In this paper, we define the categories and the characteristics of social games which are suitable for all existing ones. Besides, we present a survey on the performance aspects of human computation system. This paper gives a better understanding on human computation system.	categorization;computer;human-based computation;social network game	Man-Ching Yuen;Ling-Jyh Chen;Irwin King	2009	2009 International Conference on Computational Science and Engineering	10.1109/CSE.2009.395	games;symbolic computation;the internet;simulation;theory of computation;human-based evolutionary computation;computer science;artificial intelligence;secure two-party computation;theoretical computer science;machine learning;symbolic-numeric computation;human-based computation;collaboration	AI	-32.22167663218426	-17.93550383150895	22972
ab8dff14bb69a8913d81dba0db28783bb1fb826c	enhancing experiential and subjective qualities of discrete structure representations with aesthetic computing	structural model;theory and practice;customization;aesthetics;discrete structure;finite state automata;data flow;modeling	The task of visualization, as it applies to computing, includes by default the notion of pluralism and perspectivism since there is an explicit attempt at representing one, often textual, interface in terms of a more graphical one. This desire for alternate, subjective perspectives is consistent with art theory and practice, and even though rigor and formalism generally mean different things to artists and computer scientists, there is room for collaboration and connection by applying artistic aesthetics to computing, while maintaining that which makes computing a viable, usable field. This new area is called aesthetic computing. Within this area, there is an attempt to balance qualitative with quantitative representational aspects of visual computing, recognizing that aesthetics creates a dimension that is consistent with supporting numerous visual perspectives. We introduce one aspect of aesthetic computing, with specific examples from our research and teaching to illustrate the potential and possibilities associated with alternate representations of discrete structures such as finite state automata and a data flow network. We limit ourselves, and our methodology, to model notations with components that bear a largely symbolic connection to what they represent, thus providing greater degrees of representational freedom. We show that by exploring aesthetics, we surface some important philosophical and cultural questions regarding notation, which turn out to be at least as important as the algorithmic and procedural means of achieving customized model component representations.	discrete mathematics	Paul A. Fishwick	2005	J. Vis. Lang. Comput.	10.1016/j.jvlc.2005.01.001	data flow diagram;systems modeling;computer science;artificial intelligence;finite-state machine	Theory	-29.950763183004874	-12.790561353496061	23033
0e3aba81f5e7619104bdc60f493758ef0f30a3d3	integrating learning with motor schema-based control for a robot soccer team	robot movil;systeme commande;sistema control;multiagent system;learning algorithm;autonomous system;soccer;reinforcement learning;algorithme apprentissage;sistema autonomo;intelligent robot;control system;apprentissage renforce;robot mobile;football;systeme autonome;robot inteligente;robot soccer;sistema multiagente;algoritmo aprendizaje;moving robot;robot intelligent;systeme multiagent;futbol	This paper describes a reinforcement learning-based strategy developed for Robocup simulator league competition. In overview: each agent is provided a common set of skills (motor schema-based behavioral assemblages) from which it builds a task-achieving strategy using reinforcement learning. The agents learn individually to activate particular behavioral assemblages given their current situation and a reward signal. The entire team is jointly rewarded or penalized when they score or are scored against (global reinforcement). This approach provides for diversity in individual behavior.		Tucker R. Balch	1997		10.1007/3-540-64473-3_86	error-driven learning;simulation;computer science;autonomous system;control system;artificial intelligence;machine learning;reinforcement learning	Robotics	-22.568513412648436	-7.066885362044814	23035
b4fe2539dce1a2bf5e746cc357e643c08b04c2c7	on two pseudo-paradoxes in bayesian analysis	bayesian analysis	"""This note discusses two problems that might be considered weaknesses of Bayesian analysis. The rst was noted in a recent paper of Cozman (2000), and concerns the notion of \relevance"""" when complete probabilistic model is not available. The second, stimulated by an example due to Philippe Smets, concerns the interpretation of evidential reports that are cast as betting odds. I will describe the two problems, o er their resolution, and then argue that Bayesian analysis should retain its status as a powerful model of human reasoning."""	bayesian network;encode;observable;odds algorithm;onset (audio);regular expression;relevance;statistical model	Judea Pearl	2001	Annals of Mathematics and Artificial Intelligence	10.1023/A:1016709416174	bayesian vector autoregression;bayes factor;bayesian experimental design;variable-order bayesian network;bayesian probability;computer science;bayesian linear regression;bayesian hierarchical modeling;bayesian statistics;bayesian econometrics	AI	-11.883305561014511	1.9253899824269423	23128
886265c3291f2864ac5d55deaec8d44bbb56d20c	quantum theory and the nature of search		The conceptual model and mathematical formalism of quantum theory are employed in creating a novel framework for modeling the computational search process addressing problematic issues that restrict information retrieval research. Mapping the mathematical formalism of search to that of quantum theory presents insightful perspectives about the nature of search. However, differences in operational semantics of quantum theory and search restrict the utility of the mapping. An approach is suggested for resolving these semantic differences aiming toward a sound mathematical and conceptual framework for search inspired by quantum theory.	computation;experiment;formal specification;information retrieval;operational semantics;quantum mechanics;self-reference;semantics (computer science);simulation	Sachi Arafat;C. J. van Rijsbergen	2007			machine learning;conceptual model;artificial intelligence;theoretical computer science;ping (video games);quantum information science;computer science;formalism (philosophy of mathematics);operational semantics;quantum mechanics;restrict	AI	-27.415127249938898	-13.14510818073689	23148
56feb16e84ed614172ae99cfadf1452bc814c8f3	embodied conversational agents for h5n1 pandemic crisis	artificial intelligence ai;embodied conversational agent eca;natural language processing understanding and reasoning nlur;h5n1 bird flu;qa75 electronic computers computer science;embodied conversational agent	This paper presents a novel framework for modeling embodied conversational agent for crisis communication focusing on the H5N1 pandemic crisis. Our system aims to cope with the most challenging issue on the maintenance of an engaging while convincing conversation. What primarily distinguishes our system from other conversational agent systems is that the human-computer conversation takes place within the context of H5N1 pandemic crisis. A Crisis Communication Network, called CCNet, is established based on a novel algorithm incorporating natural language query and embodied conversation agent simultaneously. Another significant contribution of our work is the development of a Automated Knowledge Extraction Agent (AKEA) to capitalize on the tremendous amount of data that is now available online to support our experiments. What makes our system differs from typical conversational agents is the attempt to move away from strictly task-oriented dialogue.	algorithm;dialog system;embodied agent;experiment;natural language user interface	Ong Sing Goh;Lance Chun Che Fung;Kevin Kok Wai Wong;Arnold Depickere	2007	JACIII	10.20965/jaciii.2007.p0282	simulation;embodied agent;computer science;artificial intelligence	AI	-27.401663525238064	-17.638478715235546	23155
7c3be1bf331fe72eaf4b2e82489de4040e2a3f6a	dynamic team forming in self-interested multi-agent systems	duracion;systems;multiagent system;multi agent system;bepress selected works;team;multi;intelligence artificielle;systeme ouvert;long terme;interested;duration;dynamic team forming;long term;dynamic team forming self interested multi agent systems;agent;dynamic environment;team formation;largo plazo;agent intelligent;forming;intelligent agent;artificial intelligence;agente inteligente;inteligencia artificial;sistema multiagente;open systems;sistema abierto;dynamic;systeme multiagent;duree;self interested agent;self	As social entities, intelligent agents need to collaborate with others, regardless of whether they are cooperative or self-interested. The durations of agent collaborations can be long-term or “one-shot”. Nowadays, many multi-agent system applications require the system to work in open and dynamic domains. In such dynamic environments, how long collaboration should be kept among particular agents are always a problem to be discussed. In this paper, we focus on general self-interested multi-agent systems and analyze the advantages and disadvantages that can be brought by one-shot teams and long-term teams. Furthermore, we present a mechanism that can enable agents to form teams with reasonable terms and objects.	multi-agent system	Quan Bai;Minjie Zhang	2005		10.1007/11589990_70	simulation;self;computer science;artificial intelligence;forming processes;duration;system;open system;intelligent agent	AI	-18.197303784150776	-11.320585231190936	23217
7300bb491f8699d316077285db79da3f982e85e3	planning over multi-agent epistemic states: a classical planning approach	multi agent;epistemic reasoning;planning;nested belief	Many AI applications involve the interaction of multiple autonomous agents, requiring those agents to reason about their own beliefs, as well as those of other agents. However, planning involving nested beliefs is known to be computationally challenging. In this work, we address the task of synthesizing plans that necessitate reasoning about the beliefs of other agents. We plan from the perspective of a single agent with the potential for goals and actions that involve nested beliefs, non-homogeneous agents, co-present observations, and the ability for one agent to reason as if it were another. We formally characterize our notion of planning with nested belief, and subsequently demonstrate how to automatically convert such problems into problems that appeal to classical planning technology. Our approach represents an important first step towards applying the well-established field of automated planning to the challenging task of planning involving nested beliefs of multiple agents.	automated planning and scheduling;autonomous robot;whole earth 'lectronic link	Christian J. Muise;Vaishak Belle;Paolo Felli;Sheila A. McIlraith;Tim Miller;Adrian R. Pearce;Liz Sonenberg	2015			planning;knowledge management;artificial intelligence	AI	-20.670935921625404	-8.539851702087027	23280
09131c2186ab84054f13d1496f16ca493fcd2bfb	from the bankruptcy problem and its concede-and-divide solution to the assignment problem and its fair division solution	bankruptcy problems;concede and divide;assignment problems;core;minimal rights;fair division	We revisit two classic problems: the assignment problem, in which agents create value when matched with a partner, and the bankruptcy problem, in which we need to share an endowment among agents with conflicting claims. We show that since Core Selection constrains us to exactly divide the value created by a pair of matched agents, the assignment problem can be seen as a two-player bankruptcy problem. This interpretation allows us to show that the classic Concede-and-Divide (Aumann and Maschler, 1985) sharing method for the bankruptcy problem is equivalent to the Fair Division solution (Thompson, 1981) for the assignment problem, itself the average of the extreme points of the core of Demange (1982) and Leonard (1983). We then exploit the link between the two problems to offer two characterizations of the Fair Division solution. The key property is an adapation of the Minimal Rights First property (Curiel, Maschler and Tijs, 1987) for the bankruptcy problem. The minimal rights of a claimant is what is left of the endowment, if any, when all claimants but himself have received their full claims. The property states that we obtain the same shares if we distribute the minimal rights first, adjust the claims and endowment and proceed on the reduced problem or simply ignore them and proceed on the original problem. In assignment problems, the conceptual equivalent of minimal rights are the minimal core allocations. Given the important role that minimal core allocations play in this link between assignment and bankruptcy problems, it is important to be able to compute them efficiently. We provide a new algorithm to compute them.	assignment problem	Christian Trudeau	2018	Games and Economic Behavior	10.1016/j.geb.2017.09.005	economics;operations management;mathematical economics;welfare economics	ECom	-5.701132326242872	-3.7009663999464486	23289
0cd92a0a6669d6e09c06f60ee59b2c477cb95338	some features of expert reasoning in qualitative physics	qualitative physics	Sacks and Doyle (1992) point out the absence of mathematics from SPQR (simulation of processes by qualitative reasoning). Undoubtedly QR (qualitative reasoning) at large should embody knowledge about linearity, dynamical systems theory, and numerical analysis. There already exists software, in the form of numerical algorithms written mostly in C or FORTRAN, automating mathematical techniques; and software which acts as an intelligent coordinating interface among numerical modules, as well as between a user and the numerical modules (e.g., Konar et al. 1990), is a step further in this direction. What is not automated is the formulation of real scientific and engineering problems in a solvable mathematical form; i.e., the reasoning of the expert scientists or engineers who are users of existing sophisticated mathematical software. Expert reasoning requires skills which are still informal in the experts’ minds and need to be addressed by QR. These are largely domainand task-specific skills; while some unifying formalisms will undoubtedly emerge, we may be better off looking for them only after we tackle several specific subdomains. Automated construction of models is one of the important issues, and there has been a lot of quiet work in that direction (e.g., Stephanopoulos et al. 1987). Experts formulate, analyze, and revise specific equations (Sacks and Doyle 1992); what QR and A1 should focus on is not the mathematical side of using equations but the model construction and revision process which uses (a) information about the physical system; (b) the structure and results of previously tried models, analyzed and compared; and (c) information about the ultimate applicarion of the model which determines the goals of the modeling effort, because expert assumptions and simplifications are always context dependent. The context dependence of modeling is one of the most important characteristics of expert reasoning. It has not been addressed by SPQR, but it also receives little attention in Sacks and Doyle (1992). The expert makes just the right assumptions, drops what is unimportant or negligible in each particular portion of the model and for the particular system and task at hand, and comes up with a model ofjust the right complexity. The models and values we use in practice are never accurate. Variables never assume an exact value and they never become exactly equal to each other. To use the -, 0, and + values of SPQR, we have to decide how small a value is considered qualitatively zero, and we similarly have to determine when two values are considered equal. Order-ofmagnitude reasoning systems, such as O[M] (Mavrovouniotis and Stephanopoulos 1987, 1988; Mavrovouniotis et al. 1989), FOG (Raiman 1986; Dague et al. 1987), and other systems (Dubois and Prade 1989), aimed to address, in part, the issue of distinguishing between negligible and important parameters. These systems focused on relationships between parameters (which is a better approach than direct reference to “small” and “large” values), but they did not address the context dependence of order-of-magnitude arguments. Simply put, OEM] and FOG have no notion that the premise “ X i s approximately .	algorithm;decision problem;distance fog;dynamical systems theory;emoticon;expert system;fortran;mathematical software;numerical analysis;qr code;simulation;word lists by frequency	Michael L. Mavrovouniotis	1992	Computational Intelligence	10.1111/j.1467-8640.1992.tb00368.x	qualitative reasoning;computer science	AI	-11.288522407777757	2.3688086973172924	23309
fd3733a25d2cc5af23fcbc5ef174a1c5b54f26da	the design of flog, an automatic flowchart generator.				R. P. Watkins	1974	Australian Computer Journal		computer science;data mining;flowchart	Vision	-28.365650997262524	-4.965389811798428	23358
3140a1d6c7687edc555ff60366c0269a2968f3bc	topological framework for representing and solving probabilistic inference problems in expert systems	graph theory;topology;representacion conocimientos;sistema experto;probability;expert systems;incertidumbre;uncertainty;aproximacion probabilista;intelligence artificielle;probabilistic approach;probabilistic inference;expert systems polynomials measurement uncertainty mechanical engineering inference algorithms computer aided instruction knowledge representation history control systems;approche probabiliste;artificial intelligence;incertitude;inteligencia artificial;systeme expert;knowledge representation;representation connaissances;diagnostic query probabilistic inference expert systems state variables topological framework consistency polynomial time symbolic level algorithm;topology artificial intelligence expert systems graph theory probability;expert system	The authors present the concept of influence diagrams for representing probabilistic dependence and independence between state variables in a given problem domain and a topological framework for solving probabilistic inference problems in expert systems. The mathematical basis for influence diagrams is explained and theorems for mathematical manipulation of them are presented, in a graph-theoretic framework. Topological transformation rules developed in previous research are formalized in an axiomatic manner based on a concept of consistency. A polynomial-time symbolic-level algorithm for solving probabilistic inference problems is developed. The algorithm involves searching through the diagram to answer any specific diagnostic query about the system. >	expert system	Ashutosh Rege;Alice M. Agogino	1988	IEEE Trans. Systems, Man, and Cybernetics	10.1109/21.7490	mathematical optimization;uncertainty;probabilistic relevance model;computer science;artificial intelligence;machine learning;probability;mathematics;expert system;algorithm;statistics	Embedded	-20.01110120848714	-1.654525527323497	23376
785a688604d121013c7948fc8beb8829e54e3583	clarc: a cognitive robot for helping geriatric doctors in real scenarios		Comprehensive Geriatric Assessment (CGA) is an integrated clinical process to evaluate the frailty of elderly persons in order to create therapy plans that improve their quality of life. For robotizing these tests, we are designing and developing CLARC, a mobile robot able to help the physician to capture and manage data during the CGA procedures, mainly by autonomously conducting a set of predefined evaluation tests. Built around a shared internal representation of the outer world, the architecture is composed of software modules able to plan and generate a stream of actions, to execute actions emanated from the representation or to update this by including/removing items at different abstraction levels. Percepts, actions and intentions coming from all software modules are grounded within this unique representation. This allows the robot to react to unexpected events and to modify the course of action according to the dynamics of a scenario built around the interaction with the patient. The paper describes the architecture of the system as well as the preliminary user studies and evaluation to gather new user requirements.	cognitive robotics	Dimitri Voilmy;Cristina Suarez-Mejias;Adrián Romero-Garcés;Cristian Reuther;José Carlos Pulido;Rebeca Marfil;Luis Manso;Karine Lan Hing Ting;Ana Iglesias;José Carlos González;Javier García;Angel García Olaya;Raquel Fuentetaja;Fernando Fernández;Alvaro Dueñas;Luis Vicente Calderita;Pablo Bustos	2017		10.1007/978-3-319-70833-1_33	simulation;software;architecture;computer science;user requirements document;unexpected events;abstraction;mobile robot;human–robot interaction;cognition	Robotics	-28.983492703154262	-23.070445176539064	23452
ee063d154f4e54004f913d02c1b1f388e631cb90	imperfect epistemic duties and the justificational fecundity of evidence	humanidades;filosofia etica	Mark Nelson argues that we have no positive epistemic duties. His case rests on the evidential inexhaustibility of sensory and propositional evidence—what he calls their ‘infinite justificational fecundity’. It is argued here that Nelson’s reflections on the richness of sensory and propositional evidence do make it doubtful that we ever have an epistemic duty to add any particular beliefs to our belief set, but that they fail to establish that we have no positive epistemic duties whatsoever. A theory of epistemic obligation based on Kant’s idea of an imperfect duty is outlined. It is suggested that such a theory is consistent with the inexhaustibility of sensory and propositional evidence. Finally, one feature of our epistemic practice suggestive of the existence of imperfect epistemic duties is identified and promoted.	reflection (computer graphics)	Scott Stapleford	2013	Synthese	10.1007/s11229-013-0249-5	philosophy;epistemology;mathematics	AI	-12.278660572816465	3.425130240851203	23561
34b765e6659baa9f4232eadc5b82191d5a7ccaf9	the automatic programming of agents that learn mental models and create simple plans of action	computer program;genetic program;shared memory;automatic programming;automatic generation;intelligent agent;mental model	An essential component of an intelligent agent is the ability to notice, encode, store, and utilize information about its environment. Traditional approaches to program induction have focused on evolving functional or reactive programs. This paper presents MAPMAKER, an approach to the automatic generation of agents that discover information about their environment, encode this information for later use, and create simple plans utilizing the stored mental models. In this approach, agents are multi-part computer programs that communicate through a shared memory. Both the programs and the representation scheme are evolved using genetic programming. An illustrative problem of 'gold' collection is used to demonstrate the approach in which one part of a program makes a map of the world and stores it in memory, and the other part uses this map to find the gold The results indicate that the approach can evolve programs that store simple representations of their environments and use these representations to produce simple plans.	automatic programming;computer program;encode;evolutionary algorithm;experiment;genetic programming;intelligent agent;mental model;shared memory;toy problem	David Andre	1995			shared memory;simulation;computer science;artificial intelligence;theoretical computer science;machine learning;programming language;intelligent agent	AI	-20.84818865045547	-7.482970432511786	23590
cbf5440fa1c22e7289cceee788c1457baece03f5	improved techniques for processing queries in full-text systems	query processing;partial information;satisfiability;boolean operation;text retrieval	In static full-text retrieval systems, which accommodate metrical as well as Boolean operators, the traditional approach to query processing uses a “concordance”, from which large sets of coordinates are retrieved and then merged and/or collated. Alternatively, in a system with l documents, the concordance can be replaced by a set of bit-maps of fixed length l, which are constructed for every different word of the database and serve as occurrence maps. We propose to combine the concordance and bit-map approaches, and show how this can speed up the processing of queries: fast ANDing and ORing of the maps in a preprocessing stage, lead to large I/O savings in collating coordinates of keywords needed to satisfy the metrical and Boolean constraints. Moreover, the bit-maps give partial information on the distribution of the coordinates of the keywords, which can be used when queries must be processed by stages, due to their complexity and the sizes of the involved sets of coordinates. The new techniques are partially implemented at the Responsa Retrieval Project.	bit array;bitmap;boyer–moore string search algorithm;central processing unit;computer;concordance (publishing);database;document retrieval;ibm 7090;information retrieval;input/output;inverted index;logical connective;map;microcomputer;nx bit;optical storage;pattern matching;preprocessor;read-only memory;requirement;sparse matrix;speedup;springer (tank);standard ml of new jersey;string searching algorithm	Yaacov Choueka;Aviezri S. Fraenkel;Shmuel Tomi Klein;E. Segal	1987		10.1145/42005.42039	theoretical computer science;machine learning;data mining;information retrieval;satisfiability	Web+IR	-28.514409268491065	3.762701834070531	23597
4a06b55edf99e3945d67b7490eebba86f7a70954	a new practice course for freshmen using robocup based small robots	multiagent system;soccer;robotics;mechanical engineering;complex system;football;robotica;robotique;electrical engineering;sistema multiagente;systeme multiagent;futbol	Contemporary engineers need to have the ability not only to freely make use of their professional knowledge and skills, but also to integrate and combine a wide range of knowledge and skills and to build a complex system to solve a problem. But the current educational programs of individual departments (mechanical engineering, electrical engineering, electronic engineering, computer science) are usually designed and performed independently. Therefore it is hard for students to understand how knowledge and technologies of each field are integrated and combined in the objects of the real world. In order to increase student understanding in this area, we propose a new practice course dealing with a completely functional object: a robot.	robot	Yasunori Nagasaka;Morihiko Saeki;Shoichi Shibata;Hironobu Fujiyoshi;Takashi Fujii;Toshiyuki Sakata	2005		10.1007/11780519_38	simulation;computer science;artificial intelligence;robotics	Robotics	-32.90853273942289	-21.144133604283258	23658
913135121c70393563e89ea99cfd349a12325016	intergenerational altruism with future bias		We show that standard preferences of altruistic overlapping generations exhibit future bias, which involves preference reversals associated with increasing impatience. This underlies a conflict of interest between successive generations. We explore the implications of this conflict for intergenerational redistribution when there is a sequence of utilitarian governments representing living generations and choosing policies independently over time. We argue that future bias creates incentives to legislate and sustain a pay-as-you-go pension system, which every government views as a self-enforcing commitment mechanism to increase future old-age transfers.	intergenerational struggle	Francisco M. Gonzalez;Itziar Lazkano;Sjak A. Smulders	2018	J. Economic Theory	10.1016/j.jet.2018.10.004	microeconomics;altruism;economics;overlapping generations model;pension;incentive;conflict of interest;government;dynamic inconsistency;redistribution (cultural anthropology)	ECom	-14.823814835130863	-14.111686650282538	23806
958e37a78b0e878a9c7e78e6f50c6273886943b5	improving reinforcement learning results with qualitative spatial representation		Reinforcement learning and Qualitative Spatial Reasoning methods have been successfully applied to create agents able to solve Artificial Intelligence problems in games, robotics, simulated or real. Generally, reinforcement learning methods represent the objects' position as quantitative values, performing the experiments considering these values. However, the humancommonsense understanding of the world is qualitative. This work proposes a hybrid method, that uses a qualitative formalism with reinforcement learning, named QRL, and is able to get better results than traditional methods. We have applied this proposal in the robot soccer domain and compared the results with traditional reinforcement learning method. The results show that, by using a qualitative spatial representation with reinforcement learning, the agent can learn optimal policies and perform more goals than quantitative representation.	algorithm;artificial intelligence;case-based reasoning;discretization;experiment;humanoid robot;hybrid fibre-optic;reinforcement learning;robotics;semantics (computer science);spatial–temporal reasoning	Thiago Pedro Donadon Homem;Danilo Hernani Perico;Paulo E. Santos;Anna Helena Reali Costa;Reinaldo Augusto da Costa Bianchi	2017	2017 Brazilian Conference on Intelligent Systems (BRACIS)	10.1109/BRACIS.2017.63	spatial intelligence;hafnium oxide;robot;reinforcement learning;cognition;formalism (philosophy);robotics;computer science;artificial intelligence	AI	-24.293537505682494	-17.118099148696107	23837
fd2085c59d1210f3cbfe650b60945842ae6a7ee2	efficiently matching proximity relationships in spatial databases	procesamiento informacion;systeme information geographique;urban planning;geographic information system;query processing;spatial query processing and data mining;base donnee tres grande;efficient algorithm;real estate market;interrogation base donnee;road traffic accident;interrogacion base datos;swinburne;weather forecasting;data mining;data distribution;spatial database;spatial data mining;medical image analysis;regle association;traitement question;base donnee spatiale;information processing;very large databases;traitement information;database query;sistema informacion geografica	Spatial data mining recently emerges from a number of real applications, such as real-estate marketing, urban planning, weather forecasting, medical image analysis, road traffic accident analysis, etc. It demands for efficient solutions for many new, expensive, and complicated problems. In this paper, we investigate a proximity matching problem among clusters and features. The investigation involves proximity relationship measurement between clusters and features. We measure proximity in an average fashion to address possible nonuniform data distribution in a cluster. An efficient algorithm, for solving the problem, is proposed and evaluated. The algorithm applies a standard multi-step paradigm in combining with novel lower and upper proximity bounds. The algorithm is implemented in several different modes. Our experiment results do not only give a comparison among them but also illustrate the efficiency of the algorithm.	accident analysis;algorithm;data mining;database;image analysis;medical image computing;medical imaging;programming paradigm	Xuemin Lin;Xiaomei Zhou;Chengfei Liu	1999		10.1007/3-540-48482-5_13	proximity problems;weather forecasting;information processing;computer science;data science;data mining;urban planning;database;geographic information system;computer security;spatial database	DB	-26.994198475870565	1.590545651144337	23862
6224215e26a4510d675df4e17847f0c6c8bdd1c0	playware abc: engineering play for everybody		This paper describes the Playware ABC concept, and how it allows anybody, anywhere, anytime to be building bodies and brains, which facilitates users to construct, combine and create. The Playware ABC concept focuses engineering and IT system development on creating solutions that are usable by all kinds of users and contexts. The result becomes solutions, often based on modular technologies that are highly flexible and adaptable to different contexts, users, and applications.	anytime algorithm;playware	Henrik Hautop Lund	2017	JRNAL	10.2991/jrnal.2017.3.4.15	intelligent decision support system;self-reconfiguring modular robot;human–computer interaction;user friendly;computer science	HCI	-26.984982028320196	-20.370222679990086	23885
a6b18d840cebc0082daa633641865a2bc10b1755	bulk loading the m-tree to enhance query performance	cost saving;metodo arborescente;interrogation base donnee;interrogacion base datos;metric;elemento arquitectural;element architectural;design feature;tree structured method;metrico;methode arborescente;information system;access method;spatial access method;database query;systeme information;metrique;sistema informacion	The M-tree is a paged, dynamically balanced metric access method that responds gracefully to the insertion of new objects. Like many spatial access methods, the M-tree’s performance is largely dependent on the degree of overlap between spatial regions represented by nodes in the tree, and minimisation of overlap is key to many of the design features of the M-tree and related structures. We present a novel approach to overlap minimisation using a new bulk loading algorithm, resulting in a query cost saving of between 25% and 40% for non-uniform data. The structural basis of the new algorithm suggests a way to modify the M-tree to produce a variant which we call the SM-tree. The SM-tree has the same query performance after bulk loading as the M-tree, but further supports efficient object deletion while maintaining the usual balance and occupancy constraints.	algorithm;cluster analysis;m-tree;mathematical optimization;requirement	Alan P. Sexton;Richard Swinbank	2004		10.1007/978-3-540-27811-5_18	metric;computer science;operating system;data mining;database;distributed computing;access method;information system	DB	-26.710483198142917	3.9092087785185923	23936
108b4aae01a641c74f6151abb82a829c7a47abaa	the benefits of robot deception in search and rescue: computational approach for deceptive action selection via case-based reasoning	robot sensing systems;search and rescue;proceedings;computational modeling;computational modeling rescue robots context adaptation models cognition robot sensing systems;rescue robots case based reasoning emergency management;rescue robots;cognition;sar robot deception search and rescue deceptive action selection mechanism case based reasoning rescue robots;adaptation models;context;robotic deception;autonomous rescue robots	By increasing the use of autonomous rescue robots in search and rescue (SAR), the chance of interaction between rescue robots and human victims also grows. More specifically, when autonomous rescue robots are considered in SAR, it is important for robots to handle sensitively human victims' emotions. Deception can potentially be used effectively by robots to control human victims' fear and shock as used by human rescuers. In this paper, we introduce robotic deception in SAR contexts and present a novel computational approach for an autonomous rescue robot's deceptive action selection mechanism.	action selection;autonomous robot;case-based reasoning;computation;rescue robot	Jaeeun Shim;Ronald C. Arkin	2015	2015 IEEE International Symposium on Safety, Security, and Rescue Robotics (SSRR)	10.1109/SSRR.2015.7443002	simulation;rescue robot;engineering;artificial intelligence;communication	Robotics	-20.437945399509257	-19.679214704256857	23965
39551ebeb924889c1d4467d6f0fcbcbef5d1c3f0	the macaims data management system	dynamic index maintenance;key deletion;information retrieval;random access files;key retrieval;data processing;time sharing;operation;set theory;key insertion;paging;data structures;management planning and control;data management system	MacAIMS (MAC Advanced Interactive Management System) is a relatively small research project that was initiated in the summer of 1968 to investigate the feasibility of using some of the then existing computer facilities at M.I.T. to aid in the management of Project MAC. Several interesting and useful interactive programs were developed and are currently in use. However, the primary, and not very suprising, result of our early work was the discovery that no existing system offered either the desired highly human-oriented interactive style or the capability of providing very rapid, yet carefully controlled, access tO a large data base. Thus, early in Ig70, we found ourselves faced with the prospect of developing entirely new information handling tools if we wanted to extend tile capabilities of our management system beyond the level that had already been achieved.	database;google summer of code;information processing;mit computer science and artificial intelligence laboratory;management system	Robert C. Goldstein;Alois Strnad	1970		10.1145/1734663.1734677	operation;data structure;data processing;data management;computer science;theoretical computer science;data mining;database;data retrieval;time-sharing;paging;set theory	DB	-31.91007232735556	-2.5046378907267832	23971
c85c714c67e3b7ff1a27cd5b2f11073c2a10af9e	completing $h$		Nearly a decade ago, the science community was introduced to the h-index, a proposed statistical measure of the collective impact of the publications of any individual researcher. Of course, any method of reducing a complex data set to a single number will necessarily have certain limitations and introduce certain biases. However, in this paper we point out that the definition of the hindex actually suffers from something far deeper: a hidden mathematical incompleteness intrinsic to its definition. In particular, we point out that one critical step within the definition of h has been missed until now, resulting in an index which only achieves its stated objectives under certain rather limited circumstances. For example, this incompleteness explains why the h-index ultimately has more utility in certain scientific subfields than others. In this paper, we expose the origin of this incompleteness and then also propose a method of completing the definition of h in a way which remains close to its original guiding principle. As a result, our “completed” h not only reduces to the usual h in cases where the h-index already achieves its objectives, but also extends the validity of the h-index into situations where it currently does not.		Keith R. Dienes	2015	J. Informetrics	10.1016/j.joi.2015.01.003		DB	-12.920032924229158	1.4523011393869147	24005
933cd7d53e85446859ec9e92e7d919687227794f	a formal representation system for the human-computer interaction process	human computer interaction;representacion sistema;formalization;relacion hombre maquina;man machine relation;intelligence artificielle;systeme conversationnel;interactive system;representation systeme;cognition;system representation;sistema conversacional;formalizacion;cognicion;artificial intelligence;relation homme machine;inteligencia artificial;formalisation	This paper presents a formal representation system for interpretive understanding of users interacting with systems. In order to fully characterize the interaction process, a local-interaction-based approach is taken. An interactive system is represented in the form of rules expressed in terms of cognitive units. A cognitive unit is a combination of a concept and an attribute. The concepts are distinct cognitive objects concerning the system and the attributes are different aspects of each concept. Thus, cognitive units can be regarded as objects through which a user communicates with the system. The interaction process is represented in a sequence of applied system rules. A method for inferring useru0027s cognitive states in the interaction process such as working memory and planning units is presented. Through an investigation on hypothesized user actions carried out on the existing screen-oriented editor system represented by the proposed framework, it is discussed that some statistics of working memory load indicate cognitive complexity of particular tasks, and quite understandable planning units are derived by the method.	human–computer interaction	Muneo Kitajima	1989	International Journal of Man-Machine Studies	10.1016/S0020-7373(89)80015-X	formal system;cognition;computer science;artificial intelligence;algorithm	Visualization	-24.61053199957212	-7.438833835030522	24076
c58c24e4c9199b6a972ac0646ad7ae5775315dea	a bim-based visualization and warning system for fire rescue		Abstract Structural fires are common disasters. In Taiwan, about 100 firefighters die during fire rescues each year, primarily because they are unaware of the causes of the fire and unfamiliar with the location’s environment. Meanwhile, evacuees often die in the panic of evacuation. To solve these problems, this research proposes a Building Information Modeling (BIM)-based visualization and warning system for fire rescue. A fire dynamics simulator (FDS) simulates various conditions of structural fires in conjunction with the visualization and integration properties of BIM, and the simulation results for temperature, carbon monoxide, and visibility can be integrated and presented in the BIM model for briefing purposes before rescue operations begin. In addition, this research integrates Internet of Things (IoT) technology, which allows real-time situation monitoring. In the event of a fire, the BIM model will immediately display the situation of the fire scene and control LED escape route pointers according to the actual situation. The primary objective of this system is to provide useful information to firefighters such that they can be aware of the fire’s environment and create an effective rescue plan. Moreover, the automated LED escape route pointer may assist the building’s occupants to escape, provide the firefighters with valuable information, and allow them quickly to discover hazards so that the number of casualties can be minimized.	bim	Xiu-Shan Chen;Chi-Chang Liu;I-Chen Wu	2018	Advanced Engineering Informatics	10.1016/j.aei.2018.04.015	engineering;systems engineering;building information modeling;visibility;simulation;visualization;fire dynamics simulator;warning system;internet of things	Visualization	-11.832837135795241	-21.88407448637748	24089
a921a44a6a786bcc412cbd3c209cc8d894aba417	control complexity in bucklin, fallback, and plurality voting: an experimental approach	voting system;experimental approach;various voting systems empirically;plurality voting;np-hard control problem;control complexity;fallback voting;electoral control;control problem;various control scenario;natural voting system;control resistance	Walsh [Wal10, Wal09], Davies et al. [DKNW10, DKNW11], and Narodytska et al. [NWX11] studied various voting systems empirically and showed that they can often be manipulated effectively, despite their manipulation problems being NP-hard. Such an experimental approach is sorely missing for NP-hard control problems, where control refers to attempts to tamper with the outcome of elections by adding/deleting/partitioning either voters or candidates. We experimentally tackle NP-hard control problems for Bucklin and fallback voting. Among natural voting systems with efficient winner determination, fallback voting is currently known to display the broadest resistance to control in terms of NP-hardness, and Bucklin voting has been shown to behave almost as well in terms of control resistance [ER10, EPR11, EFPR11]. We also investigate control resistance experimentally for plurality voting, one of the first voting systems analyzed with respect to electoral control [BTT92, HHR07]. Our findings indicate that NP-hard control problems can often be solved effectively in practice. Moreover, our experiments allow a more fine-grained analysis and comparison—across various control scenarios, vote distribution models, and voting systems—than merely stating NP-hardness for all these control problems.	experiment;hadamard transform;np-hardness	Jörg Rothe;Lena Schend	2012		10.1007/978-3-642-30850-5_31	bullet voting;mathematics;cardinal voting systems;mathematical economics;preferential block voting;welfare economics;computer security;anti-plurality voting;condorcet method;algorithm	AI	-7.473062359933314	1.5387391856846688	24283
9ad0bfdf6fba9c456b487f5d8618378c0805b724	enhancing parking simulations using peer-designed agents	urban transport systems enhancing parking simulations peer designed agents pda turn key technology strategic behavior human individuals parking space search domain;road traffic;parking;simulation;personal digital assistants computational modeling legged locomotion reliability search problems vehicles;multi agent systems;traffic engineering computing digital simulation multi agent systems road traffic;traffic engineering computing;behavior;digital simulation;peer designed agents pdas experimentation multiagent systems parking simulations	In this paper, we investigate the usefulness of peer-designed agents (PDAs) as a turn-key technology for enhancing parking simulations. The use of PDAs improves the system's ability to capture the dynamics of the interaction between individuals in the system, each theoretically exhibiting a different strategic behavior. Furthermore, since people in general are inherently rational and computation bounded, simulating this domain becomes even more challenging. The advantage of PDAs in this context lies in their ability to reliably simulate a large pool of human individuals with diverse strategies and goals. We demonstrate the efficacy of the proposed method by developing a large-scale simulation system for the parking space search domain, which plays an important role in urban transport systems. The system is based on 34 different parking search strategies. Most of these strategies are substantially different from synthetic strategies that are used in prior literature. A quantitative analysis of the PDAs indicates that they reliably capture their designers' real-life strategies. Finally, we demonstrate the usefulness of PDA-based parking space search simulation by utilizing it to evaluate four different information technologies that are of increasing use in recent years.	computation;computer simulation;personal digital assistant;real life;synthetic intelligence;turnkey	Michal Chalamish;David Sarne;Raz Lin	2013	IEEE Transactions on Intelligent Transportation Systems	10.1109/TITS.2012.2210545	simulation;computer science;engineering;artificial intelligence;multi-agent system;transport engineering;computer security;behavior	Robotics	-13.627240625696322	-11.141614216786987	24292
9b24d48b8e5b0dc2468255c891962ebf0ff5c914	agent cooperation and collaboration	developpement logiciel;teoria cognitiva;communication process;multiagent system;confiance;psychologie sociale;multi agent system;negociation;ingenierie connaissances;learning model;cooperation;modelo hibrido;structure sandwich;instruction;instruccion;cognitive theory;intelligence artificielle;agent logiciel;modele hybride;cooperacion;theorie cognitive;hybrid model;software agents;proceso comunicacion;sandwich structure;processus communication;confidence;confianza;negociacion;desarrollo logicial;agent intelligent;software development;bargaining;psicologia social;intelligent agent;software framework;artificial intelligence;social psychology;agente inteligente;inteligencia artificial;information system;estructura sandwich;sistema multiagente;systeme information;systeme multiagent;sistema informacion;knowledge engineering	This paper describes preliminary work performed to gain an understanding of how to implement collaboration between intelligent agents in a multi-agent system and/or humans. The paper builds on previous research where an agent-development software framework was implemented based on a cognitive hybrid reasoning and learning model. Agent relationships are formed using a three-layer process involving communication, negotiation and trust. Cooperation is a type of relationship that is evident within structured teams when an agent is required to cooperate with and explicitly trust instructions and information received from controlling agents. Collaboration involves the creation of temporary relationships between different agents and/or humans that allows each member to achieve their own goals. Due to the inherent physical separation between humans and agents, the concept of collaboration has been identified as the means of realizing human-agent teams. A preliminary demonstration used to confirm this research is also presented.	intelligent agent;multi-agent system;multitier architecture;software framework	Christos Sioutis;Jeffrey Tweedale	2006		10.1007/11893004_60	simulation;engineering;artificial intelligence;communication	AI	-23.254779406123344	-8.427638673585552	24334
788cb4517fe731ab9d5a43b11e0ef0152662cbe4	efficient similarity search by combining indexing and caching strategies		A critical issue in large scale search engines is to efficiently handle sudden peaks of incoming query traffic. Research in metric spaces has addressed this problem from the point of view of creating caches that provide information to, if possible, exactly/approximately answer a query very quickly without needing to further process an index. However, one of the problems of that approach is that, if the cache is not able to provide an answer, the distances computed up to that moment are wasted, and the search must proceed through the index structure. In this paper we present an index structure that serves a twofold role: that of a cache and an index in the same structure. In this way, if we are not able to provide a quick approximate answer for the query, the distances computed up to that moment are used to query the index. We present an experimental evaluation of the performance obtained with our structure.	approximation algorithm;cpu cache;cache (computing);computation;computer cluster;inverted index;similarity search;web search engine	Nieves R. Brisaboa;Ana Cerdeira-Pena;Veronica Gil Costa;Mauricio Marín;Oscar Pedreira	2015		10.1007/978-3-662-46078-8_40	sargable;query optimization;query expansion;theoretical computer science;data mining;database;mathematics;algorithm	DB	-27.394683866337584	-0.21277334257026004	24349
c342b3c046472955f63c88400c89bc2a2e2964e6	incomplete information and deception in multi-agent negotiation	incomplete information;autonomous agent;distributed artificial intelligence;solution concept	"""Much d is t r ibu ted ar t i f ic ia l intell igence research on negot iat ion assumes complete knowledge among the in teract ing agents and /o r t r u th fu l agents. These assumptions in many domains w i l l not be realist ic, and this paper extends previous work to begin deal ing w i t h the case of inter-agent negot iat ion w i t h incomplete in fo rma t ion . A discussion of our exist ing negot iat ion framework sets out the rules by which agents operate dur ing this phase of their in teract ion. The concept of a """"so lu t ion"""" w i t h i n this f ramework is presented; the same solut ion concept serves for interact ions between agents w i t h incomplete in fo rmat ion as i t d id for complete in fo rmat ion interact ions. The possibi l i ty o f incomplete in fo rmat ion among agents opens up the possibi l i ty of deception as par t of the negot iat ion strategy of an agent. Deception dur ing negot iat ion among autonomous agents is thus analyzed in the constrained Blocks D o m a i n , and i t is shown tha t beneficial lies do exist in some scenarios. The three types of interact ions, cooperative, compromise, and confl ict , are examined. An analysis is made of how each affects the possibi l i ty of beneficial deception by a negot iat ing agent. 1 I n t r o d u c t i o n The subject of negot iat ion has been of cont inuing interest in the d is t r ibuted ar t i f ic ia l intell igence ( D A I ) commun i t y [Smi th , 1978; Rosenschein and Genesereth, 1985; Durfee, 1988; Malone et al . , 1988; Sycara, 1988; Kuwabara and Lesser, 1989; Conry et a/., 1988; Kreifelts and von M a r t i a l , 1990; Laasri et a l . , 1990; Kraus and Wi lken fe ld , 1991; Ephra t i and Rosenschein, 1991]. Despite the large amount of research on this topic, there does not yet exist a universal ly accepted def ini t ion of what the word even means; as Gasser points out in [Gasser, 1991], """" ' nego t i a t i on ' [is] a term that has been used in l i te ra l ly dozens of different ways in the D A I l i t erature."""" Nevertheless, i t is clear to the D A I communi ty as a whole tha t the operat ion of intel l igent autonomous agents would be greatly enhanced if they were able to communicate their respective desires and compromise to reach mutua l l y beneficial agreements. The work described in this paper fol lows the general direct ion of [Rosenschein and Genesereth, 1985; Z lo tk in and Rosenschein, 1989] in t reat ing negotiat ion in the spir i t of game theory, whi le al ter ing game theory assumptions that are irrelevant to D A I . Much of the research on negot iat ion assumes complete knowledge among the in teract ing agents and /o r t ru th fu l agents. These assumptions in many domains are not realistic, and this paper extends previous work [Z lotk in and Rosenschein, 1989; Z lo tk in and Rosenschein, 1990b] to begin dealing w i th the case of inter-agent negotiat ion w i t h incomplete in fo rmat ion . 2 T h e Ove ra l l N e g o t i a t i o n F r a m e w o r k Each agent i in the interact ion is assumed to have a goal g t , and wants to t ransform the wor ld f rom an in i t ia l state s to a state tha t satisfies this goal. The set of all states sat isfying g i, is denoted by G,. A goal has an associated worth to the agent, which is also the m a x i m u m the agent is w i l l i ng to pay in order to achieve that goal. Because two agents co-existing w i th in the same environment m igh t interfere w i th actions of the other, there needs to be coordinat ion of act iv i ty . At the same t ime, depending on the part icular domain and goals involved, there may be the possibi l i ty that the agents wi l l actually be able to help each other and achieve both goals wi th a lower overall cost. A deal between agents is generally a jo in t p lan, where agents share the work of t ransforming the world from the in i t ia l state to some final state. The plan is """" jo in t """" in the sense tha t the agents might probabi l ist ical ly share the load, compromise over which agent does which act ions, or even compromise over which agent gets its goal satisfied. In this final case, the deal is actual ly a probabil ist ic d is t r ibut ion over j o in t plans (what was called a """"mul t i -p lan deal"""" in [Z lotk in and Rosenschein, 1990c]). In the broad sense, the u t i l i t y for an agent of a deal is the difference between the wor th of the agent's goal achieved through that deal, and the cost of that agent's part of the deal. Zlotkin and Rosenschein 225 2.1 T h e Process o f N e g o t i a t i o n The interaction between agents occurs in two consecutive stages. First the agents negotiate, then they execute the entire jo in t plan upon which they bad agreed. No divergence f rom the negotiated deal is allowed. The sharp separation of stages has consequences, in that it rules out certain negotiation tactics that might be used in an interleaved process. A more general negotiation framework that allowed concurrent negotiation and execution might , however, be approximated by concatenating several negotiation /execution processes together, provided that each agent remembers and uses information about the preceding negotiations. We assume that negotiation is an iterative process: at each step, both agents simultaneously offer a deal. Our protocol specifies that at no point can an agent demand more than it did previously—in other words, each offer either repeats the previous offer or makes a concession to the opponent's posit ion. The negotiation can end in one of two ways: • Confl ict: if neither agent makes a concession at some step, they have by default agreed on the (domain dependent) """"conflict deal.'' • Agreement: if at some step agent A offers agent B more than B himself asks for, they agree on A's offer, and if both agents overshoot the others' demands, then a coin toss breaks the symmetry. The result of these rules is that the agents cannot """"stand s t i l l """" in the negotiation, nor can they backtrack. Thus the negotiation process is strongly monotonic and ensures convergence to a deal. 2.2 T h e C o n c e p t o f a S o l u t i o n When we say that we are looking for a """"solution' ' to the negotiation problem, we mean two things: 1. A precise definit ion of deals and ut i l i ty , which may include probabil ist ic sharing of actions, probabilities associated wi th achieving final states, part ial achievement of goals, and domain dependent attr ibutes (e.g., the nature of the conflict deal). Previous work discussed pure deals, mixed deals [Zlotk in and Rosenschein, 1989], semicooperative deals [Zlotk in and Rosenschein, 1990b], and multi-plan deals [Zlotkin and Rosenschein, 1990c]. 2. A specification of how an agent should negotiate, given a well-defined negotiation environment. How should one evaluate solutions? There are several ways of doing this, related to how we evaluate deals, how we evaluate agents, and how we evaluate interactions among the agents. • Dea l s : Deals may have a variety of attr ibutes that are considered desirable. Certain kinds of deals provide solutions to more general situations (e.g., semicooperative deals offer solutions to conflict resolut ion, whereas mixed deals do not) , thus increasing the size of the negotiation set (the set of possible agreements). Deals may have other positive attr ibutes, such as requiring less ini t ia l information. 226 Automated Reasoning • A g e n t s : Agents are expected to be designed so that they are individual rat ional (meaning they agree on deals wi th positive u t i l i t y ) . • I n t e r a g e n t i n t e r a c t i o n s : When two agents negot iate, it is desirable that they converge to a pareto optimal deal (meaning the only way the deal could be improved for one agent would be to worsen the deal for the other agent). It is also highly desirable that an agent's negotiation strategy be in equilibrium—a strategy S is said to be in equi l ibr ium if assuming that your opponent is using S, the best you can do is to also use S. Thus, no other agent w i l l be able to take advantage of that agent by using a different negotiation strategy. Moreover, there is no need to exercise secrecy regarding the design of that agent—on the contrary, it is actually beneficial to broadcast its negotiation strategy, so that the other agent doesn't blunder and potential ly cause both harm. Different types of deals may change the availabil i ty of strategies that are in equi l ibr ium. There is, in a sense, a meta-game going on between the designers of autonomous agents. Each one wants to design an agent that maximizes the designer's ut i l i ty. There are strong motivations to design your agent so that it uses a negotiation strategy in equi l ibr ium, in that it results in """"best performance"""" in pair-wise competit ions between your agent and any other given agent—conflicts wi l l be avoided whenever possible, and deals that are reached wi l l be pareto opt imal . 1 2.3 N e g o t i a t i o n w i t h I n c o m p l e t e I n f o r m a t i o n If agents negotiate wi thout having fu l l information regarding the other agent's goal, they need to take this lack of information into account in their negotiation strategy. There are several frameworks for dealing w i th this: • In [Zlotkin and Rosenschein, 1989], we introduced the notion of a """"—1 negotiation phase"""" in which agents simultaneously declare their goals before beginning the negotiation. The negotiation then proceeds as if the revealed informat ion were true. There, we analyzed the strategy that an agent should adopt for playing the extended negotiation game, and in particular, whether the agent can benefit by declaring something other than his true goal. • An alternative approach is for the agents to start the negotiation wi th incomplete in format ion, increasing their knowledge as the negotiation process proceeds. Methods for increasing knowledge about another agent's goal we call """"goal recognition"""" techniques. 1 However, there may be ecological motivati"""	approximation algorithm;artificial intelligence;automated reasoning;autonomous agent;autonomous robot;backtracking;citeseerx;concatenation;converge;execution unit;fo (complexity);field electron emission;game theory;interaction;iteration;katia sycara;lu decomposition;mike lesser;non-monotonic logic;overshoot (signal);pareto efficiency;relevance;wake-on-ring;ical	Gilad Zlotkin;Jeffrey S. Rosenschein	1991			computer science;knowledge management;artificial intelligence;autonomous agent;complete information;solution concept	AI	-12.262363734723502	0.06167753508359232	24366
94667d3adcef591a442d94128cc664ae9e8a81b3	analysing the familiar: reasoning about space and time in the everyday world	domain knowledge;qa76 electronic computers computer science computer software;qa76 electronic computers computer science computer software bionics signal processing information theory	The development of suitable explicit representations of knowledge that#R##N#can be manipulated by general purpose inference mechanisms has always#R##N#been central to Artificial Intelligence (AI). However, there has been a#R##N#distinct lack of rigorous formalisms in the literature that can be used#R##N#to model domain knowledge associated with the everyday physical world.#R##N#If AI is to succeed in building automata that can function reasonably#R##N#well in unstructured physical domains, the development and utility of such#R##N#formalisms must be secured.#R##N#This thesis describes a first order axiomatic theory that can be used#R##N#to encode much topological and metrical information that arises in our#R##N#everyday dealings with the physical world. The formalism is notable for#R##N#the minimal assumptions required in order to lift up a very general#R##N#framework that can cover the representation of much intuitive spatial and#R##N#temporal knowledge. The basic ontology assumes regions that can be#R##N#either spatial or temporal and over which a set of relations and#R##N#functions are defined. The resulting partitioning of these abstract#R##N#spaces, allow complex relationships between objects and the description of#R##N#processes to be formally represented. This also provides a useful#R##N#foundation to control the proliferation of inference commonly associated#R##N#with mechanised logics. Empirical information extracted from the domain#R##N#is added and mapped to these basic structures showing how further#R##N#control of inference can be secured.#R##N#The representational power of the formalism and computational#R##N#tractability of the general methodology proposed is substantiated using#R##N#two non-trivial domain problems - modelling phagocytosis and exocytosis#R##N#of uni-cellular organisms, and modelling processes arising during the#R##N#cycle of operations of a force pump.		David Anthony Randell	1991			computer science;artificial intelligence;theoretical computer science	HCI	-29.51869429414385	-12.657537779820197	24382
07a1970839f7e43a64d8734145d32eb8c2517b44	agile planning for real-world disaster response	disaster recovery;flexible autonomy;agile teaming;conference paper;incentive engineering;agent based computing;mechanism design;applications	We consider a setting where an agent-based planner instructs teams of human emergency responders to perform tasks in the real world. Due to uncertainty in the environment and the inability of the planner to consider all human preferences and all attributes of the real-world, humans may reject plans computed by the agent. A naı̈ve solution that replans given a rejection is inefficient and does not guarantee the new plan will be acceptable. Hence, we propose a new model re-planning problem using a Multi-agent Markov Decision Process that integrates potential rejections as part of the planning process and propose a novel algorithm to efficiently solve this new model. We empirically evaluate our algorithm and show that it outperforms current benchmarks. Our algorithm is also shown to perform better in pilot studies with real humans.	agent-based model;agile software development;automated planning and scheduling;benchmark (computing);genetic algorithm;markov chain;markov decision process;rejection sampling;simulation	Feng Wu;Sarvapali D. Ramchurn;Wenchao Jiang;Joel E. Fischer;Tom Rodden;Nicholas R. Jennings	2015			mechanism design;simulation;computer science;artificial intelligence;operations research;disaster recovery	AI	-13.207952139835081	-10.209314927271189	24393
8a084d2aabcbcfd85c7dfe60171823a406de4534	the difference indifference makes in strategy-proof allocation of objects	strategy proofness;housing market;indifference;existing tenants;kidney exchange;top trading cycles;house allocation;indivisible goods	We study problems of allocating objects among people. Some objects may be initially owned and the rest are unowned. Each person needs exactly one object and initially owns at most one object. We drop the common assumption of strict preferences. Without this assumption, it suffices to study problems where each person initially owns an object and every object is owned. For such problems, when preferences are strict, the “top trading cycles” algorithm provides the only rule that is efficient, strategy-proof, and individually rational Ma (1994) [1]. Our contribution is to generalize this algorithm to accommodate indifference without compromising on efficiency and incentives. © 2012 Elsevier Inc. All rights reserved. JEL classification: C71; C78; D71; D78	algorithm;top trading cycle	Paula Jaramillo;Vikram Manjunath	2012	J. Economic Theory	10.1016/j.jet.2012.05.017	economics;public economics;microeconomics;welfare economics;commerce	AI	-5.159810486914879	-3.725660264673214	24424
f94a243b1ae1d17193cc41391294a57e66cf7077	segment oriented compression scheme for molap based on extendible multidimensional arrays		Many statistical and MOLAP applications use multidimensional arrays as the basic data structure to allow the efficient and convenient storage and retrieval of large volumes of business data for decision making. Allocation of data or data compression is a key performance factor for this purpose because performance strongly depends on the amount of storage required and availability of memory. This holds especially for data warehousing environments in which huge amounts of data have to be dealt with. The most evident consequence of data compression is that it reduces storage cost by packing more logical data per unit of physical capacity. And improved performance is a net outcome because less physical data need to be retrieved during scan-oriented queries. In this paper, an efficient data compression technique is proposed based on the notion of extendible array. The main idea of the scheme is to compress each of the segments of the extendible array using the position information only. We compare the proposed scheme for different performance issues with prominent compression schemes.	array data structure;data compression;database;extensibility;multiprocessing;online analytical processing;set packing;sparse matrix;usability	Sk. Md. Masudul Ahsan;K. M. Azharul Hasan	2015	CIT		computer science;theoretical computer science;compression ratio;data mining;database	DB	-28.77363236013399	2.0745550235466097	24440
41dc968c3fef1686eb3a1f7a8d87aa1a813858ad	a betting interpretation for probabilities and dempster-shafer degrees of belief	factor riesgo;belief;mise a jour;risk factor;conditionnement;apuesta;gestion risque;risk management;probabilistic approach;conditioning;facteur risque;artificial intelligent;actualizacion;croyance;teoria dempster shafer;enfoque probabilista;approche probabiliste;statistical computing;dempster shafer theory;pari;dempster shafer;acondicionamiento;gestion riesgo;gamble;creencia;updating;theorie dempster shafer	There are at least two ways to interpret numerical degrees of belief in terms of betting: 1. You can offer to bet at the odds defined by the degrees of belief. 2. You can make the judgement that a strategy for taking advantage of such betting offers will not multiply the capital it risks by a large factor. Both interpretations can be applied to ordinary additive probabilities and used to justify updating by conditioning. Only the second can be applied to Dempster-Shafer degrees of belief and used to justify Dempster’s rule of combination. ∗Professor in the Rutgers Business School Newark and New Brunswick, 180 University Avenue, Newark, New Jersey 07102 USA, and in the Department of Computer Science, Royal Holloway, University of London, Egham, Surrey TW20 0EX UK. E-mail gshafer@rutgers.edu; web site www.glennshafer.com.	computer science;numerical analysis;utility functions on indivisible goods	Glenn Shafer	2011	Int. J. Approx. Reasoning	10.1016/j.ijar.2009.05.012	dempster–shafer theory;risk management;belief structure;artificial intelligence;mathematics;statistics	AI	-10.857398839721498	0.06739409027890067	24514
3845252b2cbdfffb374f8066f17e68ef46b1a915	computing continuous core/periphery structures for social relations data with minres/svd	reseau social;measurement;asymmetry;singular value decomposition;citation;asymetrie;symetrie;minres;algorithme;commerce international;algorithm;social network;least squares;social relation;svd;world economy;least square;model;informatique;modele;mesure;computer science;economie mondiale;core periphery;trade;flow pattern;international trade;algoritmo;permutation test	When diagonal values are missing or excluded, MINRES is a natural continuous model for the core/periphery structure of a symmetric social network matrix. Symmetric models, however, are not so useful when dealing with asymmetric data. Singular value decomposition (SVD) is a natural choice to model asymmetry, but this method also requires the presence of diagonal values. In this paper we offer an alternative, more general, approach to continuous core/periphery structures, the minimum residual singular value decomposition (MINRES/SVD), where each node in the network receives two indices, an “in-coreness” and an “out-coreness.” The algorithm for computing these coreness vectors is a least squares computation similar to, but distinct from the SVD, again because of the missing diagonal values. And in contrast to the standard, symmetric MINRES algorithm, we can more accurately model asymmetric matrices. This allows us to distinguish, for example, countries in the world economy that are more in the exporting core than they are in the importing core. We propose two nested PRE (proportional reduction of error) measures of fit: (1) the PRE from the MINRES vector with respect to the data and (2) the PRE of the product of the two MINRES/SVD vectors. Applying the resulting method to citations between journals and to international trade in clothing, we illustrate insights gained from being able to	algorithm;computation;generalized minimal residual method;least squares;singular value decomposition;social network	John P. Boyd;William J. Fitzgerald;Matthew C. Mahutga;David A. Smith	2010	Social Networks	10.1016/j.socnet.2009.09.003	social relation;social science;simulation;computer science;mathematics;mathematical economics;singular value decomposition;least squares;algorithm;statistics	ML	-8.490543735869572	0.21801276373732087	24603
1a7297f1222828480957f550421dd0f9676ba604	consensus costs and conflict in a collective movement	conflict;conict;collective movement;swarm robotics;coordination	Aggregation, whether it be in natural or artificial systems, provides numerous benefits to both the individual and the group. However, aggregation has costs and frequently involves inter-individual conflict. Although conflicts in natural systems is understood to be at times beneficial, as well as detrimental, conflict in artificial systems, such as a team of robots, is frequently viewed as inhibiting consensus and, therefore, success. This is particularly the case in large-scale aggregations where ensuring consensus is especially challenging. In response, mechanisms are often integrated into the group's control systems to minimize, or even eliminate, conflicts of interest. As a result, the potential benefits of losing consensus, such as increased diversity and reduced consensus costs, are not available. Using a biologically-based collective movement model, we demonstrate that not enforcing consensus and allowing conflict to evolve as agents make decisions results in a system in which agents meet their own needs, thus minimizing consensus costs, while still maintaining group cohesion when possible. Simulations predict that conflict balances consensus costs with individual preferences such that both individual and group goals are met.	aggregate function;aggregation (linguistics);cohesion (computer science);computer simulation;control system;group cohesiveness;robot	Timothy Solum;Brent E. Eskridge;Ingo Schlupp	2014		10.1145/2576768.2598357	swarm robotics;simulation;computer science;artificial intelligence;management science	AI	-13.91175437762088	-13.339083113951043	24620
ae385ad9e73c526e9e43c26dd4cd2902e0634807	a new approach for selecting portfolio of new product development projects	portfolio selection;multi criteria group decision making;fuzzy set theory;fuzzy front end;success rate;fuzzy linear programming;group decision making;new product development;portfolio;competitive advantage;new products;product development	The most decisive factor that survives enterprises under stiff competition is the development of new product (NPD), and when entering the product development stage after the fuzzy front end, a best project portfolio should be finalized in order to potentially create expected revenue and competitive advantage. However, even it reaches the end of the fuzzy front stage; the NPD project is still significantly involved with uncertainties, complexities and fuzziness. To assist R&D managers making decision in this environment, this study proposes a new approach which combines fuzzy set theory and multi-criteria group decision making method into a NPD project portfolio selection model. This model takes into account project performance, project delivery and project risk, and formulates the selection decision of NPD project portfolio as a fuzzy linear programming problem. The illustrative example shows that the model proposed can generate projects with the highest success rate under limited resources and manpower.	new product development	Chiu-Chi Wei;Houn-Wen Chang	2011	Expert Syst. Appl.	10.1016/j.eswa.2010.06.081	management science;new product development;project portfolio management	SE	-5.42648394443874	-15.134668903990146	24688
5d017fb66e8d2b2ae5c6b82ac11d45861581ec9c	team wpi-cmu: achieving reliable humanoid behavior in the darpa robotics challenge		The DARPA Robotics Challenge (DRC) required participating human-robot teams to integrate mobility, manipulation, perception and operator interfaces to complete a simulated disaster mission. We describe our approach to using the humanoid robot Atlas Unplugged developed by Boston Dynamics. We focus on our strategy to avoid failures that required physical human intervention: 1) extensive operator practice, 2) explicit “slow and steady” strategy, 3) explicit monitoring for robot errors, 4) adding additional superhuman sensing, and 5) enabling the operator to control and monitor the robot at varying degrees of abstraction. Our safety-first strategy worked: we avoided falling and remote operators could safely recover from difficult situations. We were the only team in the DRC Finals that attempted all tasks, scored points (14/16), did not require physical human intervention (a reset), and did not fall in the two missions during the two days of tests. We also had the most consistent pair of runs.	autonomous robot;darpa robotics challenge;data validation;humanoid robot	Mathew DeDonato;Felipe Polido;Kevin Knoedler;Benzun P. Wisely Babu;Nandan Banerjee;Christoper P. Bove;Xiongyi Cui;Ruixiang Du;Perry Franklin;Joshua P. Graff;Peng He;Aaron M. Jaeger;Lening Li;Dmitry Berenson;Michael A. Gennert;Siyuan Feng;Chenggang Liu;X. Xinjilefu;Joohyung Kim	2017	J. Field Robotics	10.1002/rob.21685	simulation;engineering;artificial intelligence	Robotics	-25.71669389419521	-23.27340789028712	24751
84bcfa6c06931b7d9dc037a480c8762af3cf5b5c	vtpr-tree: an efficient indexing method for moving objects with frequent updates	developpement logiciel;moving object;bottom up method;trajectoire;mise a jour;bottom up;metodo ascendente;velocity distribution;distribution vitesse;structure arborescente;metodo arborescente;moving object database;corps mobile;interrogation base donnee;conceptual analysis;interrogacion base datos;simultaneidad informatica;analisis conceptual;methode ascendante;indexing method;actualizacion;concurrency;trajectory;indexing;estructura arborescente;desarrollo logicial;indexation;tree structure;cuerpo movil;software development;indizacion;base donnee orientee objet;distribucion velocidad;tree structured method;trayectoria;object oriented databases;methode arborescente;moving body;analyse conceptuelle;simultaneite informatique;database query;updating	Moving object databases are required to support queries on a large number of continuous moving objects. Indexes for moving objects must support both query and update operations efficiently. In previous work TPR-tree is the most popular indexing method for the future predicted position, but its frequent updates performance is very poor. In this paper we propose a novel indexing method, called VTPR-tree, for predicted trajectory of moving objects. VTPRtree takes into account both the velocity and space distribution of moving objects. First the velocity domain is split, and moving objects are classified into different velocity buckets by their velocities, thus objects in one bucket have similar velocities. Then we use an improved TPR-tree structure to index objects in each bucket. VTPR-tree is supplemented by a hash index on IDs of moving objects to support frequent updates. Also an extended bottom-up update algorithm is developed for VTPR-tree, thus having a good dynamic update performance and concurrency. Experimental results show that the update and query performance of VTPR-tree outperforms the TPR*-tree.	algorithm;concurrency (computer science);database;hash table;tree structure;velocity (software development)	Wei Liao;Guifen Tang;Ning Jing;Zhinong Zhong	2006		10.1007/11908883_15	search engine indexing;concurrency;computer science;trajectory;software development;top-down and bottom-up design;data mining;database;tree structure;programming language;algorithm	DB	-26.26775089781639	1.4048721584753434	24790
432b5810a2dfc40b7f7e8a7d26eb2c3231d8d671	deriving belief networks and belief rules from data: a progress report	belief networks;computer program;learning model;intelligent agent;belief seeker;conditional probability;modular architecture;belief network;belief rules;knowledge discovery	"""An in-house developed computer program Belief -SEEKER, capable to generate belief networks and also to generate sets of belief rules, has been presented in this paper. This system has a modular architecture, and consists of the following modules: Knowledge Discovery Module (KDM, an intelligent agent or pre-processor), Belief Network Development Module (BDM, generates belief networks), Belief Network Training Module (BTM, shows the distribution of conditional probabilities using a two-dimensional graph, together with some hints extracted from the investigated data), Belief Network Conversion Module (BCM, converts generated belief networks into relevant sets of belief rules of the type IF...THEN), and Probability Reasoning Module (PRM, checks the correctness of developed learning models as the """"prediction of future"""" in classification of unseen examples)."""	bayesian network	Jerzy W. Grzymala-Busse;Zdzislaw S. Hippe;Teresa Mroczek	2007	Trans. Rough Sets	10.1007/978-3-540-71663-1_4	conditional probability;computer science;artificial intelligence;machine learning;bayesian network;data mining;belief revision;intelligent agent	ML	-18.790363488661605	-5.205665462370312	24809
6e3ffc2e00c39880017758597cb4601445880d51	action without utility. an immodest proposal for the cognitive foundations of behavior				Heinz von Foerster	2003	Cybernetics and Human Knowing		cognitive science;cognitive psychology;developmental psychology;cognition;psychology	AI	-24.794371986771097	-15.298720447726883	24936
bd03b9f1984020f2f6ecc7bd85fc5c75d9258c66	containment and variation; two strands in the development of analyticity from aristotle to martin-löf		My original training as a philosopher, at Uppsala and at Oxford, was ruggedly analytical. Also the notion of an analytic judgement, or ‘proposition’, or ‘sentence’, or ‘statement’, (one did not overly distinguish these notions) was repeatedly treated of by excellent teachers and colleagues. There were aficionados of Quine and experts on Kant among them, but no names, no pack-drill! If there was one central topic in traditional epistemology on which I felt philosophically at ease, it was that of analyticity. In the early 1980s, I entered for the first time a pluralist philosophical environment in the Philosophy Department of the Catholic University at Nijmegen, with ample representation in phenomenology, Hegelian idealism, and (neo)Thomism. To my considerable surprise, I discovered that it could be enjoyable as well as instructive talking to such rare birds in the philosophical aviary. A colleague drew my attention to Thomas Aquinas’ Five Ways, which I had never read, having adopted, from the exposition in Anders Wedberg’s History of Philosophy, the opinion that, like Kant’s transcendental deduction, Aquinas’ demonstrations were ‘worthless’. However, the Summa Theologica was readily available on open shelves in the library at Nijmegen, and my curiosity got the better of me. Upon consultation of its second question, my shock was great. In a discussion of whether the judgement Deus est admits of demonstration, Aquinas introduces the notion of a propositio per se nota, that is, an S is P judgement known in, or—perhaps better—from itself: The explanation offered is that the predicate P is included, or contained, in the notion (= concept) of the subject S. Needless to say, in view of my previous deep and thorough (as I misguidedly thought) exposure to analyticity, I had a powerful deja lu experience, pertaining to Kant, four centuries later. Clearly, I had been choused. What was the hidden tale behind this, and why had my eminent teachers not told me that the notion of an analytic judgement was known long before Kant?		Göran Sundholm	2013		10.1007/978-94-007-5137-8_3	theoretical physics;calculus;mathematics	Robotics	-29.865897597898666	-13.875544952128497	24949
ac979359e50e18d18d30c8251f8d057c27ad843c	domain-adaptive information systems (dais)	softbots;information agents;agent architectures;information system;multi agent communication	1, ABSTRACT Under the Domain-Adaptive Integration System (DAIS) program, Lockheed Martin developed a unique concept of intelligent software agents that enables users to discover and disseminate data in minutes rather than days: DAIS demonstrated 100X improvement in capture-todissemination time of tactical intelligence data using intelligent agents. These software agents move across sites connected by narrow-bandwidth, radio-based packet networks separated by tens of kilometers. The agents collect and distribute data on remote nodes. This provides improved rcadincss through faster, more comprehensive analysis and exploitation of information, The video demonstrates how DAIS provides real-time access to battlefield human intelligence, quickly identifying critical or high-payoff targets, and increasing by two orders of magnitudc intelligence analysts’ ability to monitor and recognize critical events. The video is based on a field-training exercise where DAIS enabled military intelligence analysts to detect and respond to a captured enemy order that had been overlooked in previous exercises. 1.1	adaptive quadrature;information system;intelligent agent;network packet;real-time locating system;software agent	Kenneth R. Whitebread;Harley J. Stein	1998		10.1145/280765.290319	information system	AI	-23.450152451258866	-22.730840416536985	24959
e82f5bea0abc9ce6313abb0200517007bc55c039	predicting human behavior in crowds: cognitive modeling versus neural networks		Being able to make predictions on the behavior of crowds allows for the exploration of the effectiveness of certain measures to control crowds. Taking effective measures might be crucial to avoid severe consequences in case the crowd goes out of control. Recently, a number of simulation models have been developed for crowd behavior and the descriptive capabilities of these models have been shown. In this paper the aim is to judge the predictive capabilities of these complex models based upon real data. Hereby, techniques from the domain of computational intelligence are used to find appropriate parameter settings for the model. Furthermore, a comparison is made with an alternative approach, namely to utilize neural networks for the same purpose.	artificial neural network;cognitive model	Mark Hoogendoorn	2013		10.1007/978-3-642-38577-3_8	artificial intelligence	Robotics	-18.880687012134686	-19.068734328860458	24966
16aced364a30d4c12cd25e6b1d03a77d186876f3	the balance sheet method at work: a dss for the u.s. coast guard fleet mix problem	mix problem;u.s. coast guard fleet;balance sheet method	This paper discusses Fleet Mix, a decision support system (DSS) we have developed for the United States Coast Guard (USCG). It examines the methodology used, the reasoning that led to the methodology, the program itself, the development process, and the technology that allowed the efficient development of this program. We discuss our preliminary findings that 1) the methodology seems sound and is amenable to changes in focus and scope, 2) the program is useful and has been amenable to change, and 3) the development approach used was vital to the success of the program.		Scott A. Moore;Steven Orla Kimbrough;James X. Monaghan	1992		10.1016/B978-0-444-89673-5.50006-9	operations management;operations research	Crypto	-12.753434569643703	-19.648364891575685	24968
6a761152912510b68b4d4babe8ab911bd3e98ae7	mathematical linguistics model for medical diagnostics of organ of hearing in neonates	grammar;distributed system;linguistic model;architecture systeme;systeme reparti;aplicacion medical;linguistic modeling;metalangage;software architecture;modele linguistique;sistema repartido;metalanguage;rewriting systems;rewrite systems;grammaire;diagnostic expert systems;modelo linguistico;analizador sintaxico;arquitectura sistema;audition;medical application;parser;audicion;system architecture;systeme expert diagnostic;analyseur syntaxique;systeme reecriture;gramatica;lenguaje formal;hearing;formal language;architecture logiciel;application medicale;expert system;metalenguaje;langage formel	A mathematical linguistics model for constructing diagnostic expert system for evaluating of organ of hearing in neonates in electric response audiometry is presented in the paper. A model allows one to describe audiometry signals and recognise them with the help of parser. The formal language primitives, the meta-scheme of the rewriting system, and the DPLL(k) grammar are defined. The paper contains also a discussion of the whole system software architecture and its future extensions.		Mariusz Flasinski;Elzbieta Reron;Janusz Jurek;Piotr Wójtowicz;Krzysztof Atlasiewicz	2003		10.1007/978-3-540-24669-5_98	natural language processing;software architecture;formal language;metalanguage;computer science;artificial intelligence;grammar;expert system;algorithm	NLP	-25.903101539647054	-5.598263091518832	24990
517c3d527ea2410cbdabd67353e407b4ec70e8ce	robopinion: opinion mining framework inspired by autonomous robot navigation		Data association methods are used by autonomous robots to find matches between the current landmarks and the new set of observed features. We seek a framework for opinion mining to benefit from advancements in autonomous robot navigation in both research and development.	autonomous robot;robotic mapping	M. A. El-Dosuky;M. Z. Rashad;T. T. Hamza;Ahmed H. El-Bassiouny	2012	CoRR		computer vision;simulation;social robot;data mining;mobile robot navigation	Robotics	-31.137815291696484	-21.21226307501756	25007
48e5599fa5ce868166889cfbc16543e42f9bac2a	resource management for netcentric environments	threat assessment;sensor fusion constraint handling logistics data processing military vehicles resource allocation scheduling;asset management;resource allocation;resource management dynamic programming logistics rivers personnel constraint optimization communication effectiveness fusion power generation surveillance asset management;course of action;resource manager;logistics data processing;military vehicles;data fusion;planning and scheduling;optimization problem;network centric warfare;scheduling;constraint programming;constraint handling;sensor fusion;dynamic resource management environment netcentric environments military resource management problem network centric warfare environment task planning task scheduling data fusion domain collection management process situation threat assessment courses of action generation processes ncw environment constraint programming techniques;constraint programming resource management sense respond logistics network centric warfare planning scheduling;dynamic resource management	"""The military resource management problem involves timely distribution and placement of materiel, personnel, and sensor assets to accommodate mission requirements throughout the world. The resource management problem of today's US military is perhaps the largest and most complex optimization problem in terms of the number of variables representing various resource types and constraints relating the variables. This modern resource management problem needs to be considered within a network centric warfare (NCW) environment, and hence the term """"sense and respond logistics"""" (S&RL). In this article, the author views the resource management issue as intimately related to the problem of planning and scheduling of tasks, that is, one cannot effectively reason with resources in isolation. In the data fusion domain, this view translates to consideration of the collection management process during situation/threat assessment and courses-of-action generation processes. Within a NCW environment a node must proactively determine mission requirements based on the current situation and threat, and then coordinate with other nodes to meet those requirements via some communication mechanism (e.g. publish and subscribe) on the underlying infrastructure. The specific algorithmic approach the author advocates for dynamically managing resources is essentially based on constraint programming (CP) techniques, where constraints are declaratively stated and placed on the types and quantities of resources at hand. The constraints can also be dynamically added or retracted from the system, thus are suitable to meet the demands of a dynamic resource management environment. The approach distinguishes between consumable and non-consumable resources, and in some situations views time as a special kind of resource. The author illustrates the CP approach to resource management in NCW environments in terms of two examples. The first example is related to surveillance asset management and the second is related to logistics"""	automated planning and scheduling;constraint programming;consumability;logistics;mathematical optimization;net-centric;network-centric warfare;optimization problem;publish and subscribe (mac os);requirement;resource management (computing);scheduling (computing)	Subrata Das	2006	2006 9th International Conference on Information Fusion	10.1109/ICIF.2006.301793	simulation;resource allocation;engineering;knowledge management;resource management;operations management;human resource management system;resource	DB	-20.057595558834162	-8.34785755401101	25064
b3b20f39896510312a64c73dbe873903071b2e9c	common value vs. private value categories in online auctions: a distinction without a difference?	online auction;common value;bidding;auction design;private values;common values;auctions	There is a growing body of empirical research that attempts to distinguish private value from common value auctions. Strategic behavior for a seller/bidder in these two paradigms should differ, so the assumption of, or the identification of, the type of auction (private or common) is important for understanding the auction dynamics and strategies in game-theoretic models. However, it is difficult to recognize which of the two paradigms applies to a particular good. In this article, we briefly review some of the empirical work distinguishing common/private values using observed bidding behavior, both structural nonparametric and parametric models of auctions. We then examine the use of a priori beliefs to classify product categories. Specifically, we survey auction experts on their subjective judgment in classifying a list of consumer product categories on a private/common value continuum. We also survey consumers, asking them their subjective assessment. Interestingly, not only are extant models unable empirically to distinguish between private value and common value auctions, but also the experts have strongly divergent opinions on classifying product categories on this continuum. These findings raise doubts about the appropriateness of using a priori beliefs to classify a product as a common value versus a private value, and furthermore the findings question the feasibility of game-theoretic models to empirically distinguish private value from common value auctions. Perhaps decision theory would be a more useful paradigm for modeling auction decisions in practice.		Peter Boatwright;Sharad Borle;Joseph B. Kadane	2010	Decision Analysis	10.1287/deca.1090.0150	economics;bidding;common value auction;microeconomics;welfare economics;auction theory;commerce;forward auction	ECom	-6.028402158676539	-6.779119580426883	25069
e55e393a0fe3aaebe395ee0e94c9ca3d764103ca	a unified approach to imprecision and sensitivity of beliefs in expert systems.	expert system			David J. Spiegelhalter	1987			legal expert system;computer science;knowledge management;data mining;expert system	NLP	-29.335515166493213	-8.951044502465056	25105
02c0cd55e7a5799a4330699c568161bb2f782f38	the jacalive framework for mas in ive: a case study in evolving modular robotics		Abstract This paper presents a framework specially designed for the execution and adaptation of Intelligent Virtual Environments. This framework, called JaCalIVE, facilitates the development of this kind of environments managing in an efficient and realistic way the evolution of parameters for the adaptation of the physical world. The framework includes a design method and a physical simulator which is in charge of giving the Intelligent Virtual Environment the look of the real or physical world, allowing to simulate physical phenomena such as gravity or collision detection. The paper also includes a case study which illustrates the use of the proposed framework as an evolutive algorithm which allows the automatic adaptation of modular robots.	robotics	J. A. Rincon;Emilia Garcia;Vicente Julián;Carlos Carrascosa	2018	Neurocomputing	10.1016/j.neucom.2016.08.160	artificial intelligence;simulation;machine learning;collision detection;self-reconfiguring modular robot;mathematics;virtual machine	Robotics	-24.856663178840734	-20.316932445443452	25119
1fbb333acc7543470d59d32eb1571b77f676ceb9	an essay on the role and evolution of data(base) semntics	relational model	"""ion by which the real world may be observed and the simplicity of the resulting representation, both in domain modeling and in functional specification of the system to be built [Ke78] [So84]. An immediate consequence is that system designers and builders must be able to place perfect trust in the — now implicit— agreements on correct implementations of those primitives. Note that this is exactly what we do when we trust e.g. the computer hardware to add and multiply accurately, or the DBMS to store facts correctly. In [ISO82/90] one may find an early description of a layered modeling architecture (the """"onion model"""", albeit without implementation!) that could result from this, where each higher layer uses the primitives and constructions of its underlying layers. Any analytic treatment so far however leads to tough problems in commonsense reasoning, see for example [GO94]. We have repeatedly introduced the external observers as the necessary intelligent agents of the agreement (e.g. under the form of axioms) without which no sensible starting point exists for a realworld semantics definition. (Some mathematicians of the Platonic persuasion might disagree with this.) The problem in practice is, that these agreements, while usually well-behaved locally, i.e. within one system or system component, need not be static nor even consistent on a global system level. This latter aspect becomes especially apparent when we need to connect heterogeneous autonomous systems with the purpose of interoperation. A well-known seemingly trivial example of this problem is captured by what is sometimes called Schoenmaker's Conundrum [Scho86], in which (simplified here for brevity) one witness only tells a judge """"p"""" but keeps to himself that """"not q"""" , while a second witness independently only tells the judge """"if p then q"""" but also keeps to herself that """"not q"""". Each witness is consistent, but the judge is able to derive """"q"""", supposedly thereby hanging a hapless victim. Finally, relatively few research results are available on the methodological and formal problems that arise when groups of fallible and individually motivated agents/observers need to reach agreements — on which important design decisions will be taken. Each group of observers in fact may define its own version of the real world, as we have seen not necessarily consistent with others. It is even entirely possible that the same individual agent agrees on opposite facts depending on the group she participates in, making a workable definition of """"group logic"""" quite hard. Some work in distributed AI, e.g. [Mo90] may however prove relevant here."""	autonomous system (internet);commonsense reasoning;computer hardware;denotational semantics;distributed artificial intelligence;functional specification;intelligent agent;interoperation;onion model	Robert Meersman	1995			relational model;relational theory;computer science;knowledge management;artificial intelligence;data mining	AI	-11.64392369378925	2.7401717903782794	25165
bbef965921214ab5124194607b877d707a4bfb60	robot learning language - integrating programming and learning for cognitive systems	robot learning;cognitive systems;robot control language;robot control;learning problems;hybrid automata;robot programming	One central property of cognitive systems is the ability to learn and to improve continually. We present a robot control language that combines programming and learning in order to make learning executable in the normal robot program. The language constructs of our learning language RoLL rely on the concept of hierarchical hybrid automata to enable a declarative, explicit specification of learning problems. Using the example of an autonomous household robot, we point out some instances where learning — and especially continued learning — makes the robot control program more cognitive.	artificial intelligence;automata theory;autonomous robot;domestic robot;executable;hybrid automaton;robot control;robot learning	Alexandra Kirsch	2009	Robotics and Autonomous Systems	10.1016/j.robot.2009.05.001	robot learning;error-driven learning;algorithmic learning theory;computer science;artificial intelligence;social robot;machine learning;robot control;personal robot	AI	-27.9052603169557	-20.7889691144814	25246
676c3053feabd588dd6b12382eb955d92ca80be8	cooperative plan identification: constructing concise and effective plan descriptions	computer model;intelligent agent;empirical evaluation;data structure	Intelligent agents are often called upon to form plans that direct their own or other agents’ activities. For these systems, the ability to describe plans to people in natural ways is an essential aspect of their interface. In this paper, we present he Cooperative Plan Identification (CPI) architecture, a computational model that generates concise, effective textual descriptions of plan data structures. The model incorporates previous theoretical work on the comprehension f plan descriptions, using a generate-and-test approach to perform efficient search through the space of candidate descriptions. We describe an empirical evaluation of the CPI architecture in which subjects following instructions produced by the CPI architecture performed their tasks with fewer execution errors and achieved a higher percentage of their tasks’ goals than did subjects following instructions produced by alternative methods.	algorithm;automated planning and scheduling;computational model;computer;data structure;intelligent agent;interpreter (computing);list comprehension	R. Michael Young	1999			simulation;data structure;computer science;artificial intelligence;machine learning;intelligent agent	AI	-18.31157137844305	-6.877427896185294	25347
70d148ab54bf9235e7db8ddb959d8fd2ee5ea407	using copernicus data and growth modelling to globally assess virtual water flows in agricultural production - the viw a concept		The water- food-energy nexus intimately binds food and energy production to water use. The largest fraction of today's water use is through food and energy production in agriculture. Water use in agriculture, however, is predominantly wasteful and not sustainable, due to over-exploitation of scarce water resources on one hand and through inefficient use of water on the other. So far, no global monitoring system for efficiency and sustainability of agricultural water use exists. Both quantities thus are largely unknown especially on a global level. This leads to the limitation that efficiency and sustainability of water use cannot yet be incorporated in control mechanisms for virtual water flows in global food trade. New observational capacities (e.g. the COPERNICUS sensors) and model approaches can now be applied to bridge the gap between local and global scales by quantifying and investigating water flows in detail. This paper presents the outline, basic concept and first results of the ViWA-Initiative, where operational Earth Observation, physically-based growth modelling and economic trade modelling are combined to provide a continuous monitoring system for global virtual water flows in the agricultural commodity chain.	control system;sensor	Tobias Hank;Heike Bach;Tom Jaksztat;Philipp Klug;Florian Zabel;Lena Brueggemann;Elisabeth Probst;Francesca Perosa;Tobias Ruf;Christoph Heinzeller;Wolfram Mauser	2018	IGARSS 2018 - 2018 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2018.8519017	remote sensing;commodity chain;water resource management;farm water;virtual water;sustainability;water use;agriculture;water resources;computer science;agricultural productivity	Embedded	-13.058381625343893	-21.048297533665497	25356
c29a0cb4113fe9892172513a7686313562680d99	letter to the editor - the mean lanchester attrition rate		This note describes a method for obtaining the Lanchester attrition rate when, as suggested by Barfoot, it is defined as the harmonic mean of attrition rates, or, equivalently, the reciprocal of the expected time to defeat a single target.	attrition (website)	Seth Bonder	1970	Operations Research	10.1287/opre.18.1.179	econometrics;artificial intelligence;statistics	HCI	-7.58807412705633	-5.335107283807784	25367
3719a3c0e5768d438fe6e5e99974ac3c799bf8ca	uncovered bargaining solutions	tournaments;non convex problems;bargaining;uncovered set	An uncovered bargaining solution is a bargaining solution for which there exists a complete and strict relation (tournament) such that, for each feasible set, the bargaining solution set coincides with the uncovered set of the tournament. We provide a characterization of a class of uncovered bargaining solutions. J.E.L. codes: C72, D44.	code;complete (complexity);feasible region;relation (database)	Michele Lombardi;Marco Mariotti	2009	Int. J. Game Theory	10.1007/s00182-009-0172-7	bargaining problem;economics;microeconomics;mathematical economics;welfare economics	Metrics	-5.870255425044272	-0.8134067530164276	25472
47098084f1deefcb18099991a7c2814b71c7589b	fuzzy multi attribute assessment model for software outsourcing partnership formation		Building on the preceding studies, this paper aims to extend the latest capability maturity model integration (CMMI)-based organization assessment model to the fuzzy environment. Our approach has overcome the limitations of the preceding CMMI-based models. Our proposed model is based on the multi-attribute decision-making (MADM) approach incorporating the capability of group decision making. The rating of qualitative factors based on crisp values may be insufficient to model the real-world MADM industrial problem. For controlling human subjective vagueness, linguistic variables are translated using the triangular fuzzy number. The proposed model is generalized in order to be easy to adopt by other organizational assessment practitioner and researcher. Other researcher and practitioner can adopt the proposed model procedure and methodology in order to develop their own organizational assessment, capability improvement, and decision-making framework for companies, enterprises, or organization. The proposed model has two working parts. The ranking part of the framework model can be used for ranking the importance of influential factors, while the assessment part of the model can be used as an assessment tool in the SDO organization. Collectively, it might be utilized as a decision support system. A running numerical example of software outsourcing partnership (SOP) formation is presented to validate the proposed model. The ranking part is demonstrated with the help of empirical survey conducted with 35 experts, while the assessment part is demonstrated by conducting two case studies in SDO organization. SDO vendor organization can benefit from the model to gauge their capability toward SOP formation.	capability maturity model integration;decision support system;fuzzy number;numerical analysis;outsourcing;service data objects;vagueness	Sikandar Ali;Hongqi Li;Siffat Ullah Khan;Yanhong Zhao;Li Li	2018	IEEE Access	10.1109/ACCESS.2018.2871710	management science;fuzzy logic;decision support system;group decision-making;outsourcing;distributed computing;computer science;ranking;capability maturity model integration;capability maturity model;fuzzy number	SE	-6.3144859443430805	-17.11946300311077	25576
8afc050e42434c9aff6ad05fffc90b4405be0ed1	a multi-attribute fusion approach extending dempster-shafer theory for combinatorial-type evidences		Human cognition of the world generally begins with attribute perception of things. Knowledge element, which is able to reveal microscopic regularities by attribute network, provides an intelligent support for attribute-based cognition. In the field of emergency management, knowledge element has been widely used in evolution rules, risk analysis and machine learning based on emergency cases. However, since the knowledge of emergency management is multidisciplinary and in addition, limited by diverse cognitive perspectives and language expressions, integrating heterogeneous knowledge from domain experts and data sources for depth mining and decision support seems to be difficult. Especially, with the advent of big data, the problem of developing an efficient multi-attribute fusion method to reorganize complex and massive data in a consensual knowledge framework must be addressed. In this paper, a novel mathematical approach, which extends Dempster–Shafer theory to fuse combinatorial-type evidences, is elaborated to handle multi-attribute integration through the use of knowledge element model. This methodology makes it possible to establish a complete knowledge structure for attribute description of things by implementing new uncertainty measures to determine a degree of belief when combining evidences. It is meaningful to optimize the fusion algorithm in view of reliability and expansibility to some extent. Furthermore, the processing also has the advantage of being effective without any semantic preprocessing. The application of the proposed model is shown in marine disaster monitoring for emergency management. We make an empirical analysis in the attribute fusion of knowledge element “sea”. © 2017 Elsevier Ltd. All rights reserved.	algorithm;big data;cognition;decision support system;it risk management;machine learning;preprocessor	Lin Sun;Yanzhang Wang	2018	Expert Syst. Appl.	10.1016/j.eswa.2017.12.005	data mining;machine learning;knowledge economy;dempster–shafer theory;artificial intelligence;computer science;big data;decision support system;multidisciplinary approach;risk analysis (business);expression (mathematics);cognition	AI	-32.85981621651531	-7.412838001362073	25578
189d115f48f053c886ddf95be1c7dce9c92f4a67	competition vs. fairness – analyzing structured networks by means of user experiments	mars;experiments competition fairness behavioral economics peer to peer systems;network design;fairness;competition;behavioral economics;peer to peer systems;costs and benefits;economic experiment;biological system modeling;peer to peer system;humans intelligent agent economic forecasting concrete network servers web server ip networks control systems;user experience;games;experiments;face;humans;economics;peer to peer computing;network design structured networks user experiments heterogeneity	We investigate how to ensure efficiency (in the economic sense of the word) in structured networks, with a focus on heterogeneity. A network is structured if the network designer has predefined some relationships between individuals (aka. nodes). Structured networks have turned out to be surprisingly efficient – at least as long as nodes face the same costs and benefits, i.e., are homogeneous [25]. However, the homogeneity assumption is unnatural and restrictive. Economic experiments in general (not with a focus on structured networks) suggest that heterogeneity is in the way of efficiency, i.e., reduces the sum of all payoffs. This is because individuals favor outcomes where everybody earns the same. This paper describes behavioral experiments that investigate this issue, i.e., the influence of heterogeneity on efficiency in structured networks. We show that most nodes in structured networks cooperate even if they earn less than others. Our explanation is that – with our design – competition enhances cooperation. This effect is rarely observed with other networks as well as in other, less specific settings where competition is in the way of cooperation. This result is an important step towards establishing networks that yield more tangible payoffs for its nodes.	experiment;fairness measure;social network	Stephan Schosser;Klemens Böhm;Bodo Vogt	2008	2008 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology	10.1109/WIIAT.2008.9	face;games;network planning and design;mars exploration program;simulation;competition;evolving networks;computer science;cost–benefit analysis;distributed computing;world wide web;behavioral economics	ECom	-7.814704884186942	-7.773107745764146	25609
7b797bb6411378731b999e39e649d65662a29e6b	eeg/erp meets act-r: a case study for investigating human computation mechanism	computational mechanics;human cognition;real time;event related potential;cognitive architecture;cognitive process;brain activation	EEG (electroencephalograph) provides information about the electrical fluctuations between neurons that characterize brain activity, and measurements of brain activity at resolutions approaching real time. On the other hand, cognitive architectures such as ACT-R would explain how all the components of the mind work together to generate coherent human cognition. Thus EEG/ERP (event-related potential) and ACT-R will provide two aspects to explore the cognitive processes and their neural basis. In this paper, we present a case study by combining EEG/ERP and ACT-R for investigating human computation mechanism. In particular, we focus on two digits addition tasks with or without carry, and systematically perform a set of behavior and EEG experiments, as well as with the help of ACT-R simulation. Preliminary results show the usefulness of our approach.	act-r;cognition;cognitive architecture;coherence (physics);computational problem;erp;electroencephalography;experiment;human-based computation;simulation;topography	Shinichi Motomura;Yuya Ojima;Ning Zhong	2009		10.1007/978-3-642-04954-5_17	psychology;cognition;developmental psychology;computer science;artificial intelligence;computational mechanics;communication;cognitive science	ML	-24.428768903192072	-15.71128488199691	25696
253b725fdfa1fda3c1dfc2fbe02ee056d23af554	intelligent systems in nanjing university		Intelligent systems is a major research theme in Nanjing University, with the support from the State Key Laboratory for Novel Software Technology of China, one of the top laboratories in the information technology field in the whole country. Currently, the research carried out by the intelligent systems group at Nanjing University mainly fo-cuses on the following topics: • Fundamental methods of intelligent computing, particularly reinforcement learning, incremental learning , granular computing and rough sets. • Intelligent agents and multi-agent systems. • Content-based multimedia (images and 3D models) retrieval. The intelligent systems group aims to design intelligent algorithms and systems to deal with real problems efficiently. The group has developed software tools and applications covering wide areas, including medical treatment, public security, and virtual games. • Reinforcement learning Reinforcement learning is an on-line, incremental learning technology, by which intelligent agents interact with the surrounding world by trial-and-error, and learn the optimal policy of decision sequences according to reinforcement signals. Our group has studied various algorithms for reinforcement learning problems, including average reward reinforcement learning, multi-agent reinforcement learning, relational reinforcement learning, function approximation in reinforcement learning and option discovery , etc. For example, our G-learning algorithm addresses the average reward domain, and is more stable than the classical R-learning and Q-learning. The following figure shows four curves of the average rewards computed in every 10,000 steps in the access-control queuing task. As shown in this figure, G-learning outperforms R-learning and its variation in the learning speed. Besides the theoretical algorithm research , the group also studies the application of reinforcement learning. The proposed algorithms have been applied to video game tasks such as Tetris. The group attended the RL 2008 competition and won the 6th place in the game of Tetris. Research in learning classi-fier systems is related to reinforcement learning as well. Our group has successfully applied the learning classifier systems technology to different problem domains including data mining, medical data analysis and image steganography detection. • Rough set Rough set theory is a sound mathematical tool to deal with imprecise, uncertain, and vague information. Most of the group's work in this area can be characterized by rough-set-based hybrid approaches in classification and features selection. For incomplete information systems, rule generation by the GDT(General Distribution Table) approach and a default rule extracting method were proposed. Incremental algorithms are important, as data sources are increasingly in quantity. The group has investigated the …	approximation algorithm;data mining;dynamic problem (algorithms);granular computing;hybrid intelligent system;information system;intelligent agent;learning classifier system;multi-agent system;online and offline;problem domain;q-learning;reinforcement learning;rough set;set theory;steganalysis;steganography;tetris;vagueness	Yang Gao;Lin Shang;Yubin Yang	2008	IEEE Intelligent Informatics Bulletin		human–computer interaction;intelligent decision support system;engineering	ML	-30.616940492330322	-17.29674217789726	25729
27cf1bbd93cd212dc17c769e61b15b0d290d5698	time in a causal theory	causal reasoning;first order;free will	We present a causal theory based on an interventionist conception of causality, i.e., a preference to select causes among a set of actions which an agent has the ability to perform or not (free will). Emphasis is put on the temporal and explanatory aspects of causal reasoning. We introduce a formal framework enabling to define the notion of voluntary cause in a way allowing for an effective retrieval of causes in a given situation. The causal knowledge is represented by causal rules of two kinds: strict and “normal”. The latter is based on the notions of preferred time lines (futures that the agent normally has in mind when (s)he opts for performing the action) and of inhibiting events (the occurrence of which prevents the anticipated effect to happen). A situation is described by a set of events occurring on time lines; this description is completed by default assumptions (when an agent performs an action, we assume, unless this is inconsistent, that its preconditions are fulfilled and that no inhibiting event will take place). An example is presented, extension to first‐order is briefly discussed, and our approach is compared to related works.	causality;default logic;futures and promises;mind;precondition;ramification problem;real life;timeline;web ontology language	Daniel Kayser;Aïcha Mokhtari	1998	Annals of Mathematics and Artificial Intelligence	10.1023/A:1018994125258	causal decision theory;causal reasoning;free will;computer science;artificial intelligence;first-order logic;mathematics;algorithm	AI	-14.28985102144962	3.474828617109954	25768
63bb9e03a836eb9ee9b5564ecc779d26549c7ee7	on complexity of market equilibria with maximum social welfare	equilibre marche;social welfare;bien etre economique;market equilibrium;procesamiento informacion;algorithm analysis;welfare;complexite calcul;economie leontief;economie marche;problema np duro;equilibrio mercado;leontief economy;exchange economy;market economy;np hard problem;complejidad computacion;np hardness;probleme np difficile;computational complexity;information processing;analyse algorithme;traitement information;economia mercado;bienestar economico;analisis algoritmo;structural properties	We consider the computational complexity of the market equilibrium problem by exploring the structural properties of the Leontief exchange economy. We prove that, for economies guaranteed to have a market equilibrium, finding one with maximum social welfare or maximum individual welfare is NP-hard. In addition, we prove that counting the number of equilibrium prices is #P-hard.	computational complexity theory;computational hardness assumption;np-hardness;nash equilibrium;p (complexity);sharp-p;srinidhi varadarajan	Li-Sha Huang;Xiaotie Deng	2005	Inf. Process. Lett.	10.1016/j.ipl.2005.09.004	information processing;computer science;welfare;np-hard;social welfare;mathematical economics;computational complexity theory;algorithm	ECom	-5.0589370142625105	1.0459225334155318	25843
96c7a93533181bcab4a0af6769efdc7cda10fc9e	investigating performance of command team structures in the nato problem-approach space	u military science general;hd28 management industrial management;games command and control systems organizations team working;team working;command team structures command and control structure subordinate units staff officers military command structures y team structure problem space conditions five team communication structures nato problem approach space;games;team structures nato problem space;organizations;command and control systems	The purpose of this study was to investigate whether the NATO Problem-Approach Space could be mapped to optimal performance of different team structures. The results show that the five team communication structures (chain, Y, circle, wheel, and all-connected) did not generally perform as predicted based on findings in the literature. The team structures all performed most optimally in the same Problem Space conditions: static rate of change, strong information position, and familiarity with the task. Moreover, contrary to predictions, the all-connected team structure did not perform particularly well at all. Instead, the Y team structure produced the highest levels of performance and was, therefore, judged to be the most successful team structure overall. The Y team structure can be seen as a simplified form of typical military command structures including staff officers and subordinate units. Therefore, the findings of the study serve as a reinforcement of the effectiveness of the classic command and control structure.	control flow	Neville A. Stanton;Ling Rothrock;Catherine Harvey;Linda J. Sorensen	2015	IEEE Transactions on Human-Machine Systems	10.1109/THMS.2015.2437993	games;command and control;simulation;computer science;organization;knowledge management;team effectiveness	Visualization	-32.608772416761916	-20.042596544538103	25849
32302af0eacc6bed15bd22915797d206ad2752bc	intelligent and cooperative information systems	cooperative information systems		information system		1993	IEEE Expert	10.1109/MIS.1993.10030	intelligent decision support system	Vision	-30.880218126096928	-9.13715957109168	25927
06d0ef8d5bc8f5f1e64d735940bb4d105b463231	ranking of aircraft maintenance organization based on human factor performance	ahp;human factors;regulation;aircraft maintenance	Human performance in aircraft maintenance is key to rank the organisations.MRO management, infrastructure and many factors are identified and scaled.A multi-criteria decision model is devised to rank the maintenance contractors.The scientific approach is based on literature survey and data collection.Provide a decision making tool for airlines, regulators, insurance firms. Aircraft maintenance organisation is a complex socio-technical setup, where human factors influence the quality of aircraft maintenance service. Maintenance service quality is assessed based on the commitment of management and its ability to provide suitable facility, tools, spares and manpower supported with comfortable environment and maintenance procedures. Assessment of the service quality of the aircraft maintenance organisation is a complex process. Airlines, regulators, insurance companies and other agencies need decision support system, to assess the performance of a maintenance organisation. This paper provides criteria and scientific approach for assessing the maintenance organisation; it presents a methodology of applying Analytical Hierarchy Process to prioritise the key functions and to rank the maintenance organisations under study. The study has established that maintenance service quality in airline is directly correlated to its fleet size.	human factors and ergonomics	A. Shanmugam;T. Paul Robert	2015	Computers & Industrial Engineering	10.1016/j.cie.2015.07.017	reliability engineering;regulation;analytic hierarchy process;aircraft maintenance;computer science;engineering;human factors and ergonomics;operations management;computerized maintenance management system;transport engineering	DB	-8.168465899773382	-15.986336779532477	25935
5e53bd51c3db519d37ee03ed025be2cfb1b9bd42	flame—fuzzy logic adaptive model of emotions	cognitive science;emotions;life like agents;believable agents;computer model;artificial intelligent;domain knowledge;fuzzy logic;inductive learning;intelligent agent;social agents;emotional agents;computer simulation;emotional memory;social agent;human decision making	Emotions are an important aspect of human intelligence and have been shown to play a significant role in the human decision-making process. Researchers in areas such as cognitive science, philosophy, and artificial intelligence have proposed a variety of models of emotions. Most of the previous models focus on an agent's reactive behavior, for which they often generate emotions according to static rules or pre-determined domain knowledge. However, throughout the history of research on emotions, memory and experience have been emphasized to have a major influence on the emotional process. In this paper, we propose a new computational model of emotions that can be incorporated into intelligent agents and other complex, interactive programs. The model uses a fuzzy-logic representation to map events and observations to emotional states. The model also includes several inductive learning algorithms for learning patterns of events, associations among objects, and expectations. We demonstrate empirically through a computer simulation of a pet that the adaptive components of the model are crucial to users' assessments of the believability of the agent's interactions.	algorithm;artificial intelligence;cognitive science;computation;computational model;computer simulation;fuzzy logic;inductive reasoning;intelligent agent;interaction;machine learning	Magy Seif El-Nasr;John Yen;Thomas R. Ioerger	2000	Autonomous Agents and Multi-Agent Systems	10.1023/A:1010030809960	computer simulation;fuzzy logic;emotion;computer science;artificial intelligence;domain knowledge	AI	-23.438052653184457	-15.499187846722545	26017
43372aee07bee8d9a1030fdf677e316c3a47200f	modeling for cooperation and coordination within structured and complex situations like unknown emergency situations	man machine systems cognition disasters emergency management knowledge based systems;teamwork vectors buildings knowledge based systems sensors emergency services disaster management;cognitive supervision and assistance emergency management disaster management human machine interaction hybrid modeling cooperative teamwork;automatic decision error detection cooperation modeling coordination modeling structured complex situations unknown emergency situations disaster management emergency management skilled experienced human operators reaction forces human groups network structuring human operator decision quality human operator team situation awareness overall system reliability overall system performance human interaction roles human interaction qualities cooperative teamwork cooperative interacting team member performance analysis technical systems knowledge bases automatic information generation situation operator modeling approach shared mental situation awareness som based agent supervision som based agent assistance cognitive supervision	Disaster or emergency management becomes more and more important due to an increasing number of catastrophes in combination with advanced complexity of human living, working, and society. In combination with increased options for intervention, the need for related communication and coordination support increases. System allows a suitable management in combination with skilled and experienced human operators, a flexible and situative reaction leading to a suitable guidance of reaction forces as well as of groups of human etc.		Dirk Söffker;Olga Muthig;Xingguang Fu	2014	Proceedings of the 2014 IEEE 18th International Conference on Computer Supported Cooperative Work in Design (CSCWD)	10.1109/CSCWD.2014.6846832	simulation;knowledge management;management science	Robotics	-31.974303636193362	-10.83051525455363	26021
5cc06acceff91f31ef41d59220a80e13d58195af	an influence analysis of diversity and collective cardinality on collective performance		Abstract This paper presents a general framework to demonstrate the prominent role of diversity in the effectiveness of collective performance. There appears to be ample evidence that diversity is one of the essential criteria of which a collective to be intelligent. Intuitively, a collective involving diverse individuals may add new information, new perspectives, and so forth on the problem that needs to be solved. Moreover, the diversity of individual solutions to the given problem has been proven helpful in eliminating the phenomenon of correlated errors. The objective of the paper is to investigate the influence of the latter kind of diversity on the collective performance by taking into account the collective cardinality. Our findings qualify the positive impact of diversity on collective performance. Particularly, collectives with higher diversity levels will lead to better collective performances. Subsequently, expanding the collective cardinality that causes an increase in its diversity will also be positively associated with the collective performance. With some restrictions, the hypothesis “the more diverse the collective, the higher the collective performance” is formally proved. Furthermore, the conditions under which increasing the cardinality of a collective will cause its diversity to be increased (or decreased) are worked out.		Van Du Nguyen;Ngoc Thanh Nguyen	2018	Inf. Sci.	10.1016/j.ins.2017.11.053	machine learning;management science;cardinality;collective intelligence;artificial intelligence;mathematics;phenomenon	HPC	-14.587655731167935	-1.2689687462185477	26046
08789752b95d068fde99d1f0d155292e239a3762	enhanced social learning via trust and reputation mechanisms in multi-agent systems	trust;social learning;reputation;multi agent systems;social networks;phd thesis	The study of multi-agent systems (MAS) focuses on the design, development and understanding of systems composed of multiple interacting autonomous agents. Typically, the artificial agents in the system are equipped with varying cognitive and processing abilities and have access to limited information. Each agent receives a reward (or some measure of utility) for the successful completion of a given task or problem solving activity. Boundedly rational agents attempt to maximize their utility by collaborating with other agents when confronted with tasks that are beyond their individual capacity. However, the inherent uncertainty of open and dynamic MAS makes it difficult for agents to identify, establish, and maintain beneficial relationships. This study investigates the efficacy of enhanced social learning approaches in MAS. Social learning in this instance can be defined as learning through observation or interactions with other agents. In the proposed framework, the social learning paradigm is extended by explicitly incorporating the notions of trust and reputation within an individual agent’s decision making process. This approach enables the agents to keep track of beneficial interactions with others whose actions have proven to be more successful in the past. Subsequently, agents can discriminate between their interaction partners. As a result, agents with lower utility values can learn from trusted peers to improve their performance. The central hypothesis in this research specifies that by incorporating specific measures of trust and reputation within a social learning framework, agents’ interactions will be enhanced and consequently their long term performance in complex problem solving scenarios will be improved. To test this hypothesis, alternative MAS populated with adaptive agents mapped to the nodes of various network structures are developed. Two extensions were introduced into the basic social learning model: (1) the use of adaptive rewards correlated with individual agent strategies and life experiences given a limited agent life span, and (2) novel extensions to the way in which trust and reputation were calculated in the MAS based on endogenous evolving social networks. The performance of the enhanced social learning model was then evaluated in two disparate domains: (1) social dilemmas couched as evolutionary games, and (2) advice-seeking in distributed service provision applications. The investigations in the evolutionary game theory domain are limited to spatial models of the well-known Prisoner’s Dilemma (PD) game. Understanding how cooperative behaviour can be promoted and maintained in this social dilemma is the key challenge here. In the first model developed, agent life experiences and ageing factors are used to generate time varying rewards within the spatial PD game. Given the complexity of the investigated spatial model, only limited theoretical analysis is possible. Therefore, computational modeling and numerical simulations of the 2-player PD game on a regular lattice are studied here. The 2 × 2 evolutionary game model is then extended to a more general framework of an N-player PD game. In this model, endogenous evolving social networks are used as scaffolding for calculating values for trust and reputation in the MAS. The connections between agents are created, reinforced and dissolved autonomously over a period of time based on these values. The strategic behaviour of the agent population coevolves with dynamic social network formation. Thus, there is a bidirectional feedback relationship between the interaction network topology and the overall system behaviour. Of interest here, is the emergent behaviour of the system as a result of dynamic interactions and in turn the effects of these behavioural changes on the individuals’ relationship network itself. The second domain considered in this project, is a generic advice-seeking framework for resource discovery purposes. This model corresponds to many distributed service provision applications. These systems are typically composed of a large number of providers offering different services. Users seek options that “best-fit” their current preferences. The fundamental issue here is that the characteristics of these options are not known in advance. Also the task of finding the best-fit services is difficult due to the large number of available options. Thus, users can benefit from seeking advice from others before making a decision. However, since the individuals have heterogeneous preferences, the choice from whom to accept advice becomes crucial. The enhanced social learning model, utilizing accumulated life experiences and coevolutionary endogenous social networks, is then used to assess trust and reputation of similar minded agents and thus used to guide agent decision making. The simulation experiments provide strong supporting evidence that the enhanced social learning mechanism is effective in the MAS domains examined. The results clearly show that it is beneficial for agents to exploit life experiences and use dynamic social networks when assessing trust and reputation in MAS. Such techniques can be useful for establishing advantageous interactions, which lead to better long term performance for both individuals and the system as a whole. List of publications 1. G. Rezaei and M. Kirley (2008). Heterogeneous payoffs and social diversity in the spatial prisoner’s dilemma game. Proceedings of 7th International Conference on Simulated Evolution and Learning (SEAL), volume 5361 of Lecture Notes in Computer Science, pages 585–594, Springer. 2. G. Rezaei and M. Kirley (2009). The effects of time varying rewards on the evolution of cooperation. Evolutionary Intelligence, 2(4):207-218. 3. G. Rezaei, M. Kirley and J. Pfau (2009). Evolving cooperation in the N-player prisoner’s dilemma: A social network model. In K. B. Korb, M. Randall, and T. Hendtlass, editors, Artificial Life: Borrowing from Biology (ACAL), volume 5865 of Lecture Notes in Computer Science, pages 32-42, Springer Verlag, Berlin. 4. G. Rezaei, J. Pfau and M. Kirley (2010). Distributed Advice-Seeking on an Evolving Social Network. In Proceedings of the 2010 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology Volume 02, WI-IAT ’10, pages 24–31, Washington, DC, USA, 2010. IEEE Computer Society.	artificial life;autonomous robot;best practice;complex adaptive system;curve fitting;data structure;emergence;experience;experiment;game theory;intelligent agent;interaction network;lecture notes in computer science;multi-agent system;network formation;network model;network topology;numerical analysis;population;prisoner's dilemma;problem solving;programming paradigm;rational agent;simulation;social network;springer (tank);the evolution of cooperation;utility;web intelligence;whole earth 'lectronic link	Golriz Rezaei	2011			public relations;knowledge management;business;social psychology;computational trust	AI	-17.126145586551022	-12.942147601660306	26123
fa34309cba9521557b4333f4547ca40afa9e3e8d	on geometric algebra representation of binary spatter codes	artificial intelligent;quantum physics;geometric algebra	Distributed representation is a way of representing information in a pattern of activation over a set of neurons, in which each concept is represented by activation over multiple neurons, and each neuron participates in the representation of multiple concepts [1]. Examples of distributed representations include Recursive Auto-Associative Memory (RAAM) [2], Tensor Product Representations [3], Holographic Reduced Representations (HRRs) [4, 5], and Binary Spatter Codes (BSC) [6, 7, 8]. BSC is a powerful and simple method of representing hierarchical structures in connectionist systems and may be regarded as a binary version of HRRs. Yet, BSC has some drawbacks associated with the representation of chunking. This is why different versions of BSC can be found in the literature. In [6, 7] chunking is given by a majority-rule thresholded addition of binary strings, an operation that often discards a lot of important information. In [8] the ordinary addition is employed, and bits are parametrized differently. The main message we want to convey in this paper is that there exists a very natural representation of BSC at the level of Clifford algebras. Binding of vectors is here performed by means of the Clifford product and chunking is just ordinary addition. Since Cliford algebras possess a geometric interpretation in terms of Geometric Algebra (GA) [17, 18, 19], the cognitive structures processed in BSC or HHRs obtain a geometric content. This is philosophically consistent with many other approaches where cognition is interpreted in geometric terms [14, 22]. Of particular relevance may be the links to neural computation whose GA and HRR versions were formulated by different authors (cf. [5, 29, 30]. The present paper can be also seen in a wider context of a “quantum structures” approach to cognitive problems we have outlined elsewhere [9, 10, 11, 12, 13]. Cartan’s representation of GA in terms of tensor products of Pauli matrices introduces formal links to quantum computation (cf. [23, 24, 25, 26]). The philosophy we advocate here is also not that far from the approach of Widdows, where both geometric an “quantum” aspects play an important role [14, 15, 16]. It should be stressed that the GA calculus has already proved to be a powerful tool in applied branches of computer science (computer vision [20], robotics [21]). GA is a comprehensive language that simplified and integrated many branches of classical and quantum physics [31]. One may hope that it will play a similar role in cognitive science.	artificial neural network;binary symmetric channel;code;cognition;cognitive science;computation;computer science;computer vision;connectionism;holographic principle;holography;neuron;quantum computing;quantum mechanics;recursion (computer science);relevance;robotics;shallow parsing;software release life cycle	Diederik Aerts;Marek Czachor;Bart De Moor	2006	CoRR		geometric algebra;filtered algebra;combinatorics;discrete mathematics;universal geometric algebra;computer science;artificial intelligence;pure mathematics;mathematics;conformal geometric algebra	ML	-26.95816070374421	-14.829487884807289	26153
c168b8b16bd0f3ede193c19f9245bcfa2207582b	sensor resource management driven by threat projection and priorities	sensor system;resource manager;prioritization;dwell time;information flow;threat projection;time use;situation awareness;sensor resource management;information need;sensor fusion;situation calculus;radar	This paper extends previous Sensor Resource Management (SRM) work by addressing information flow from sensor inputs to SRM, through four levels of the US DoD's Joint Directors of Laboratories (JDL) sensor fusion model. The method flexibly adapts to several domains/problems. Human situation awareness information needs are linked to sensor control in a manner similar to perception management. The key to effective integration of JDL levels is the timely determination of the highest priorities via threat projection accomplished via Probabilistic Accumulative Situation Calculus (PASC), which quantifies threat intent using an appropriate level of automated context-based reasoning. The accuracy of the threat projection is improved over time using self-learning techniques. The multiple sensor system levels are unified primarily using the structure of quantified priorities. Algorithms are presented for a radar sensor resource allocation and adjustment method in which the dwell time per track parameter is the key radar sensor resource to be managed. A developed application of the method to an Integrated Air Defense System (IADS) sensor system problem is detailed, with simulation results shown to demonstrate the effectiveness of the method.		Joseph Anderson;Lang Hong	2008	Inf. Sci.	10.1016/j.ins.2007.11.029	information needs;situation awareness;real-time computing;simulation;information flow;computer science;artificial intelligence;resource management;dwell time;sensor fusion;situation calculus;computer security;radar;statistics	AI	-33.410545697651294	-12.486510941730032	26163
30dbbdc0c192a652c91eb15f22116a415ad9e637	the mitre meteor robot control software: simulate as you operate	control engineering computing;mobile robots;software engineering;mitre meteor robot control software;autonomous ground vehicle;software employment transparency	"""The Defense Advanced Research Projects Agency (DARPA) challenged autonomous ground vehicle developers in the """"2005 DARPA Grand Challenge"""" to build a vehicle that could complete a 132 mile course through the American desert southwest. MITRE, a not-for-profit systems engineering company, responded to this challenge by creating the MITRE Meteor in just 11 months. This rapid development relied on software employment transparency to get the maximum utility out of each line of code. Judicious design of the software framework allowed the same body of code to animate the robot in the field, support laboratory experimentation, and analyze recorded field testing data. This paper describes how software employment transparency was achieved and how it increased development efficiency."""	autonomous robot;content-control software;darpa grand challenge;meteor;robot control;software framework;source lines of code;systems engineering	Richard M. Weatherly;Frederick S. Kuhl;Robert H. Bolling;Robert J. Grabowski	2006	Proceedings of the 2006 Winter Simulation Conference		software security assurance;mobile robot;embedded system;personal software process;computing;simulation;computer science;engineering;software design;social software engineering;software framework;component-based software engineering;software development;software construction;robot control;programming language;source lines of code;software deployment;software development process;software requirements;software system	Robotics	-32.657384672279484	-21.692307789315514	26227
1af6558ba398eef3c69e42e7a936621c7b7e9b65	predicting demonstrations' violence level using qualitative reasoning	social simulation;social science;social behavior;decision making process;is success;qualitative modeling;qualitative reasoning;demonstrations	In this paper we describe a method for modeling social behavior of large groups, and apply it to the problem of predicting potential violence during demonstrations. We use qualitative reasoning techniques which to our knowledge have never been applied to modeling crowd behaviors, nor in particular to demonstrations. Such modeling may not only contribute to the police decision making process, but can also provide a great opportunity to test existing theories in social science. We incrementally present and compare three qualitative models, based on social science theories. The results show that while two of these models fail to predict the outcomes of real-world events reported and analyzed in the literature, one model is successful. We believe that this demonstrates the efficacy of qualitative reasoning in the development and testing of social sciences theories.		Natalie Fridman;Tomer Zilberstein;Gal A. Kaminka	2011		10.1007/978-3-642-19656-0_7	decision-making;social science;qualitative reasoning;social behavior;knowledge management;social simulation;management science;social psychology	AI	-17.807501824815155	-18.98139156312365	26250
1ee78daa6c34e36273d7fdf9080bf0a3c0e14fa7	robust bayesian methods for stackelberg security games	payoff uncertainty;significant uncertainty;available intelligence information;game-theoretic analysis;stackelberg security game;security problem;possible security countermeasures;general distributional uncertainty;experimental analysis;security domain;robust bayesian method;bayesian method	Recent work has applied game-theoretic models to real-world security problems at the Los Angeles International Airport (LAX) and Federal Air Marshals Service (FAMS). The analysis of these domains is based on input from domain experts intended to capture the best available intelligence information about potential terrorist activities and possible security countermeasures. Nevertheless, these models are subject to significant uncertainty—especially in security domains where intelligence about adversary capabilities and preferences is very difficult to gather. This uncertainty presents significant challenges for applying game-theoretic analysis in these domains. Our experimental results show that standard solution methods based on perfect information assumptions are very sensitive to payoff uncertainty, resulting in low payoffs for the defender. We describe a model of Bayesian Stackelberg games that allows for general distributional uncertainty over the attacker’s payoffs. We conduct an experimental analysis of two algorithms for approximating equilibria of these games, and show that the resulting solutions give much better results than the standard approach when there is payoff uncertainty.	adversary (cryptography);approximation algorithm;bayesian network;game theory	Christopher Kiekintveld;Milind Tambe;Janusz Marecki	2010		10.1145/1838206.1838435	game theory;simulation;bayesian probability;computer science	AI	-12.468453161358541	-10.4443696333292	26267
6107ed4d80d4eaebd8ea4f66f7f4b958e010e46d	heuristic harvesting of information for case-based argument	task performance;evaluation function;resource limitation;case base reasoning;system modeling;interconnection network;domain knowledge;domain specificity	The BankXX system models the process of perusing and gathering information for argument as a heuristic best-first search for relevant cases, theories, and other domain-specific information. As BankXX searches its heterogeneous and highly interconnected network of domain knowledge, information is incrementally analyzed and amalgamated into a dozen desirable ingredients for argument (called argument pieces), such as citations to cases, applications of legal theories, and references to prototypical factual scenarios. At the conclusion of the search, BankXX outputs the set of argument pieces filled with harvested material relevant to the input problem situation. This research explores the appropriateness of the search paradigm as a framework for harvesting and mining information needed to make legal arguments. We discuss how we tackled the problem of evaluation of BankXX from both the case-based reasoning (CBR) and task-performance perspectives. In particular, we discuss how various system parametersstart node, evaluation function, resource limit-affected BankXX from the CBR perspective and how well BankXX performs its assigned task of gathering information useful for legal argumentation by running BankXX on real legal cases and comparing its output with the published court opinions for those cases.	best-first search;case-based reasoning;decimal mark;evaluation function;heuristic;knowledge-based systems;norm (social);programming paradigm;relevance;traverse;theory	Edwina L. Rissland;David B. Skalak;M. Timur Friedman	1994			systems modeling;computer science;knowledge management;artificial intelligence;machine learning;evaluation function;data mining;domain knowledge	AI	-28.453026377443027	-10.972737031871002	26268
0d9fd3191e230ca47ddf658fa4591c77b470d335	validating the integrated paradigm for advertising involvement with the intuitionistic fuzzy set theory	intuitionistic fuzzy set;intuitionistic fuzzy set theory;market research;fuzzy set;integrable model;social science intuitionistic fuzzy set theory advertising involvement functional relations automata;fuzzy set theory advertising automata theory;statistical method;fuzzy set theory;fuzzy sets;automata;social science;functional relations;automata theory;artificial intelligence;advertising involvement;fuzzy systems;conferences;advertising conferences fuzzy systems fuzzy sets automata artificial intelligence fuzzy set theory;advertising	As far as marketing researchers are concerned, advertising involvement is an important segmentation variable; the advertisers view advertising involvement as a vital factor resulting in advertising effects. Advertising involvement has been discussed in several decades while little literature proposed a complete integrated model. Hence, we collect the antecedents and consequences for advertising involvement. Because the model that we attempt to develop includes too many variables, it is difficult to judge the functional relations among these variables and not appropriate to use a traditional statistical method. We take advantage of the automata to develop an integrated model of advertising involvement. In the social science, a great number of questions are abstract and hard to possess a certain answer. The intuitionistic fuzzy sets, which are generated from the fuzzy sets, more completely express the degree of uncertainty for people. We use the automata in the intuitionistic fuzzy sets, which are named intuitionistic fuzzy automata, to develop an integrated model of advertising involvement. The model is successfully generated. In the future, as long as obtaining consumerspsila degree of antecedents, we can predict their degree of advertising involvement and consequences in terms of this model.	automata theory;automaton;fuzzy concept;fuzzy set;intuitionistic logic;programming paradigm;set theory	Ting-Yu Chen;Hsiao-Pin Wang;Che-Wei Tsui	2008	2008 IEEE International Conference on Fuzzy Systems (IEEE World Congress on Computational Intelligence)	10.1109/FUZZY.2008.4630462	market research;discrete mathematics;computer science;artificial intelligence;data mining;mathematics;fuzzy set;fuzzy control system	DB	-6.088851889379284	-22.71904638241247	26415
31531d9fb3dff86961dbefdc8932fb4153ed293d	learning to efficiently pursue communication goals on the web with the gosmr architecture	boltzmann selection;execution monitoring;web;affordances;cognitive architecture;utility proportional payoff selection	We present GOSMR (“goal oriented scenario modeling robots”), a cognitive architecture designed to show coordinated, goal-directed behavior over the Internet, focusing on the web browser as a case study. The architecture combines a variety of artificial intelligence techniques, including planning, temporal difference learning, elementary reasoning over uncertainty, and natural language parsing, but is designed to be computationally lightweight. Its intended use is to be deployed on virtual machines in large-scale network experiments in which simulated users’ adaptation in the face of resource denial should be intelligent but varied. The planning system performs temporal difference learning of action times, discounts goals according to hyperbolic discounting of time-to-completion and chance of success, takes into account the assertions of other agents, and separates abstract action from site-specific affordances. Our experiment, in which agents learn to prefer a social networking style site for sending and receiving messages, shows that utility-proportional goal selection is a reasonable alternative to Boltzmann goal selection for producing a rational mix of behavior.	artificial intelligence;cognitive architecture;experiment;internet;parsing;robot;temporal difference learning;virtual machine	Kevin Gold	2013			simulation;cognitive architecture;computer science;knowledge management;artificial intelligence;machine learning;affordance	AI	-16.20224178338697	-11.352379475332734	26478
48d6cc74020ce620b5acd17b9aa3afb47ce5c6a3	string hashing for collection-based compression	data compression;hash function;phd thesis	Data collections are traditionally stored as individually compressed files. Where the files have a significant degree of similarity, such as genomes, incremental backup archives, versioned repositories, and web archives, additional compression can be achieved using references to matching data from other files in the collection. We describe compression using long-range or inter-file similarities as collectionbased compression (CBC). The principal problem of CBC is the efficient location of matching data. A common technique for multiple string search uses an index of hashes, referred to as fingerprints, of strings sampled from the text, which are then compared with hashes of substrings from the search string. In this thesis, we investigate the suitability of this technique to the problem of CBC. A CBC system, cobald, was developed which employs a two-step scheme: a preliminary long-range delta encoding step using the fingerprint index, followed by a compression of the delta file by a standard compression utility. Tests were performed on data collections from two sources: snapshots of web crawls (54Gbytes) and multiple versions of a genome (26Gbytes). Using an index of hashes of fixed-length substrings of length 1 024 bytes, significantly improved compression was achieved. The compression of the web collection was six times more than the compression achieved by gzip and three times 7-zip. The genome collection was compressed ten times better than gzip and 7-zip. The compression time was less than taken by 7-zip to compress the files individually. The use	archive;byte;cryptographic hash function;data compression;delta encoding;fingerprint;incremental backup;netbsd gzip / freebsd gzip;software versioning;string searching algorithm;substring;web crawler	Andrew Peel	2015			feature hashing;hopscotch hashing;hash table;double hashing;hash function;linear hashing;extendible hashing;dynamic perfect hashing;computer science;theoretical computer science;universal hashing;database;rolling hash;lossless compression;world wide web;cryptographic hash function	ML	-31.419738670949442	4.043633126587315	26489
04516312b6c2e44b11464fefa35be032a37c6dfc	legal principles and analogical reasoning (extended abstract)	analogical reasoning;representation of legal knowledge;deontic logic;logic of acton	Reasoning by analogy is integral to legal reasoning in common law based legal systems. It is argued that any theory of legal analogizing that seeks to explain the way in which precedents are utilized must account for the influence of legal principles on the creation of legal analogies and for the use of analogies as a means to test and refine these principles. Consequently, any attempt to simulate legal analogizing must simulate the influence of legal principles on legal analogizing and the role of analogizing in determining the breadth of these principles.	case-based reasoning;computer simulation	Michael Aikenhead	1997		10.1145/261618.261660	legal expert system;artificial intelligence;deontic logic;reasoning system;deductive reasoning;logic;defeasible reasoning;algorithm	Logic	-14.699814759132119	2.9402888852990965	26492
ccac9062adb710a5422bee44258c8d96aba2b59d	qualitative versus quantitative interpretation of the mathematical theory of evidence	theory of evidence;base relacional dato;relational data;representacion conocimientos;systeme intelligent;belief function;integration information;rough set theory;soft computing;sistema inteligente;raisonnement qualitatif;relational database;information integration;teoria dempster shafer;dempster shafer theory;integracion informacion;intelligent system;base donnee relationnelle;dempster shafer;razonamiento calitativo;qualitative reasoning;information system;knowledge representation;rough set;representation connaissances;systeme information;theorie dempster shafer;sistema informacion	Abs t rac t . The paper presents a novel view of the Dempster-Shafer belief function as a measure of diversity in relational data bases. The Dempster rule of evidence combination corresponds to the join operator of the relational database theory. This rough-set based interpretation is qualitative in nature and can represent a number of belief function operators.	database theory;relational database;rough set	Mieczyslaw A. Klopotek;Slawomir T. Wierzchon	1997		10.1007/3-540-63614-5_38	knowledge representation and reasoning;rough set;relational theory;dempster–shafer theory;relational database;computer science;artificial intelligence;machine learning;data mining;mathematics;soft computing;algorithm	AI	-21.16899866663753	-1.6850086343022344	26493
191751e99cbc650675f59283489614538579a625	querical data networks		"""IntroductIon Recently, a family of massive self-organizing data networks has emerged. These networks mainly serve as large-scale distributed query processing systems. We term these networks Querical Data Networks (QDN). A QDN is a federation of a dynamic set of peer, autonomous nodes communicating through a transient-form intercon-nection. Data is naturally distributed among the QDN nodes in extra-fine grain, where a few data items are dynamically created, collected, and/or stored at each node. Therefore, the network scales linearly to the size of the dataset. With a dynamic dataset, a dynamic and large set of nodes, and a transient-form communication infrastructure, QDNs should be considered as the new generation of distributed database systems with significantly less constraining assumptions as compared to their ancestors. Peer-to-peer networks (Daswani, 2003) and sensor networks (Estrin, 1999, Akyildiz, 2002) are well-known examples of QDN. QDNs can be categorized as instances of """" complex systems """" (Bar-Yam, 1997) and studied using the complex system theory. Complex systems are (mostly natural) systems hard (or Querical Data Networks complex) to describe information-theoretically, and hard to analyze computationally. QDNs share the same characteristics with complex systems, and particularly, bear a significant similarity to a dominating subset of complex systems most properly modeled as large-scale interconnection of functionally similar (or peer) entities. The links in the model represent some kind of system specific entity-to-entity interaction. Social networks, a network of interacting people, and cellular networks, a network of interacting cells, are two instances of such complex systems. With these systems, complex global system behavior (e.g., a social revolution in a society, or food digestion in stomach!) is an emergent phenomenon, emerging from simple local interactions. Various fields of study, such as sociology, physics, biology, chemistry, etc., were founded to study different types of initially simple systems and have been gradually matured to analyze and describe instances of incrementally more complex systems. An interdisciplinary field of study, the complex system theory a , is recently founded based on the observation that analytical and experimental concepts, tools, techniques, and models developed to study an instance of complex system at one field can be adopted, often almost unchanged, to study other complex systems in other fields of study. More importantly, the complex system theory can be considered as a unifying meta-theory that explains common characteristics of complex systems. One can extend application of the complex system theory to QDNs by: 1. Adopting models and techniques …"""	autonomous robot;categorization;complex system;complex systems;distributed database;emergence;entity;interaction;interconnection;organizing (structure);peer-to-peer;self-organization;systems theory	Cyrus Shahabi;Farnoush Banaei Kashani	2005			wireless sensor network;complex system;complex network;theoretical computer science;percolation theory;distributed computing;computer science;interdependent networks	ML	-14.803792439215936	-16.80763865204098	26522
fc9c291fd2af3983659caf838069f3238f141f37	towards a new fuzzy linguistic preference modeling approach for geolocation applications		In many areas, fuzzy linguistic approaches have already shown their interest and successful results to express the preferences and the choices of a human. This paper focuses on the fuzzy linguistic 2-tuple representation model that is interesting and relevant when we need to express and to refer to linguistic assessments during the whole reasoning process. However, when data have a particular distribution on their axis, this model doesn’t fit well the needs anymore. We propose therefore a variant version of this representation model that allow for a more realistic distribution. We also show that an operation such as an arithmetic mean is easy to implement with it and gives consistent results.	geolocation	Mohammed-Amine Abchir;Isis Truck	2011		10.1007/978-3-642-24001-0_37	machine learning;pattern recognition;data mining	NLP	-4.588680243632583	-23.034114970698734	26620
42e23fb36e555aac798f1802d92c9b28ae3088ca	electronic promotion to new customers using mk	learning algorithm;customer anonymity;seller reputation;market model;e commerce;population size;mk nn learning;electronic marketplace;customer annoyance;e advertisement;k nearest neighbor;profitability;heuristic promotion strategy;mknn learning;new customer;association link;e marketing	Article history: Received 11 August 2007 Received in revised form 3 September 2008 Accepted 18 September 2008	stellar classification	Faria Nassiri Mofakham;Mohammad Ali Nematbakhsh;Ahmad Baraani-Dastjerdi;Nasser Ghasem-Aghaee	2009	Inf. Sci.	10.1016/j.ins.2008.09.019	e-commerce;population size;computer science;machine learning;k-nearest neighbors algorithm;profitability index	AI	-5.12261955962765	-9.810982356127692	26652
ae186d040a097c133b98e1712a86e1f9b4944f51	principles and practice of constraint programming		In many problems we want to reason about the ranking of items. For example, in information retrieval, when aggregating several search results, we may have ties and consequently rank orders. (e.g. [2, 3]). As a second example, we may wish to construct an overall ranking of tennis player based on pairwise comparisons between players. One principled method for constructing a ranking is the Kemeny distance [5] as this is the unique scheme that is neutral, consistent, and Condorcet. Unfortunately, determining this ranking is NP-hard, and remains so when we permit ties in the input or output [4]. As a third example, tasks in a scheduling problem may run in parallel, resulting in a ranking. In a ranking, unlike a permutation, we can have ties. Thus, 12225 is a ranking whilst 12345 is a permutation. To reason about permutations, we have efficient and effective global constraints. Regin [7] proposed an Oðn4Þ GAC propagator for permutations. For BC, there is an even faster Oðn log nÞ propagator [6]. Every constraint toolkit now provides propagators for permutation constraints. Surprisingly, ranking constraints are not yet supported. In [1], we tackle this weakness by proposing a global ranking constraint. We show that simple decompositions of this constraint hurt pruning. We then show that GAC can be achieved in polynomial time and we propose an Oðn3 log nÞ algorithm for achieving RC as well as an efficient quadratic algorithm offering a better tradeoff.	algorithm;constraint programming;information retrieval;np-hardness;polynomial;propagator;scheduling (computing);time complexity;while	Josef Kittler;Moni Naor	2017		10.1007/978-3-319-66158-2	inductive programming;constraint programming;constraint logic programming;programming language;functional logic programming;reactive programming;programming domain;concurrent constraint logic programming;computer science;constraint satisfaction	AI	-7.402247331940353	3.8495887740513504	26670
46aae64aea8c4bc2aab2ab6ed435b9200f49e1f5	robot planning with fuzzy sets	fuzzy set	"""INTRODUCTION The ability to provide a structure for the intelligent achievement of actions by robots is becoming a very important problem. The achievement of a goal by a robot, or for that matter, any organization, is a two step operation. The first phase consists of a plan of action, and the second phase consists of an implementation of this plan to achieve the desired goals. Nilsson has suggested an approach to the problem of having a robot plan the sequence of actions necessary to achieve a goal. The structure suggested by Nilsson provides a useful one for investigating both the planning and implementation portion. Nilsson's approach uses production rules based upon a state description involving predicate calculus. We shall extend this approach to allow for a fuzzy set type description via linguistic values"""" and also for the inclusion of the consideration of the implementation phase. The robot starts off with information about the current state of the environment called the initial state. He is also given information as to a desired state of the environment called the goal state. For example, a box may be located at a particular point in a room and it may be desired for him to move the box to a different location. The robot is also provided with a set of production rules describing the actions available to it for going from the initial state to the goal state. Each production rule consists of two components. The first component, called the antecedent, consists of a set of necessary conditions in the environment that are required if it is to apply or fire this production rule. That is, if these conditions are met by the present state of the environment then it can, if it desires', fire this production rule. The second component of the production, called the consequent, consists of the possible modifications to the environment as a result of implementing this production rule. Thus the effect of the firing of a production rule is the modification of the environment resulting in a new state. The overall planning phase involves the use of a search tree. We start with initial state as the root node. Each production rule whose antecedent is matched by the current state then generates a branch, a possible course of action, whose destination node is a new state determined by the current state and the consequent of the production rule. We continue expanding in tree in this manner until a state is reached that matches the goal conditions. This searching procedure results in a plan of action, the path from the initial node to the node satisfying the goal, used by the robot to achieve its desired goal. The next phase involves the actual implementation of this plan by the robot's implementation of the production rules on this path. However, since there exists some uncertainty in the consequence of each production rule the robot must check after each firing that the antecedents necessary for the next firing are there. If at some point the robot finds that he can't implement the prescribed firing rule he must now replan starting at this point. It is our purpose here to develop a framework for implementing this procedure with the aid of fuzzy subsets."""	automated planning and scheduling;first-order logic;fuzzy set;production (computer science);robot;search tree;thinking outside the box;tree (data structure)	Ronald R. Yager	1983	Robotica	10.1017/S0263574700001053	defuzzification;adaptive neuro fuzzy inference system;fuzzy classification;computer science;artificial intelligence;fuzzy number;neuro-fuzzy;fuzzy set;fuzzy associative matrix;fuzzy set operations;fuzzy control system	AI	-21.08547097327539	-6.75854551483111	26682
90e32c02f1199d1991744a4b647b4e40aea67d05	building a sensorimotor representation of a naive agent’s tactile space	applications active exploration of environment robots with development and learning skills using robots to study development and learning;robot sensing systems manifolds kernel adaptation models buildings	A new approach for robotics perception, rooted in the sensorimotor paradigm, is proposed in this paper. Making systems able to autonomously adapt themselves to changes in their own body or in their environment is still a challenging question for many different scientific communities. Multiple works propose either sophisticated adaptive model-based or learning-based techniques as a solution. Recent contributions have shown that it is possible for an agent to discover the structure of its interaction with the environment or its own body via the so-called sensorimotor flow. The presented work is based on this idea, and a method for building an internal representation of sensorimotor interaction is proposed, which does not require any a priori knowledge or model. A careful mathematical formalization is outlined, together with simulations, demonstrating the effectiveness of the approach. Several cases are considered allowing for a general discussion. Moreover, plausibility of the internal sensorimotor representation is highlighted by showing that it is possible to consider motion planning directly from it.	motion planning;plausibility structure;programming paradigm;robotics;simulation	Valentin Marcel;Sylvain Argentieri;Bruno Gas	2017	IEEE Transactions on Cognitive and Developmental Systems	10.1109/TCDS.2016.2617922	computer vision;simulation;computer science;machine learning	Robotics	-24.998270036737267	-18.662090574423193	27007
bb037f00e4e0ccbb33812d6dda2633148d15d65a	firefighting as a game	algorithmic game theory;price of anarchy;firefighter problem;nash equilibria;info eu repo semantics report;arees tematiques de la upc informatica informatica teorica;spreading models for networks;external research report;coalitions;article;info eu repo semantics publishedversion	The Firefighter Problem was proposed in 1995 [16] as a deterministic discrete-time model for the spread (and containment) of a fire. Its applications reach from real fires to the spreading of deseases and the containment of floods. Furthermore, it can be used to model the spread of computer viruses or viral marketing in communication networks. In this work, we study the problem from a game-theorical perspective. Such a context seems very appropriate when applied to large networks, where entities may act and make decisions based on their own interests, without global coordination. We model the Firefighter Problem as a strategic game where there is one player for each time step who decides where to place the firefighters. We show that the Price of Anarchy is linear in the general case, but at most 2 for trees. We prove that the quality of the equilibria improves when allowing coalitional cooperation among players. In general, we have that the Price of Anarchy is inΘ( k ) where k is the coalition size. Furthermore, we show that there are topologies which have a constant Price of Anarchy even when constant sized coalitions are considered.	anarchy;computer virus;entity;network topology;telecommunications network	Carme Àlvarez;Maria J. Blesa;Hendrik Molter	2014		10.1007/978-3-319-13123-8_9	price of stability;simulation;computer science;artificial intelligence;mathematics;distributed computing;algorithmic game theory;operations research;computer security;algorithm;price of anarchy;nash equilibrium	ECom	-4.562262876679891	1.8123910930803906	27072
7152c2531410d3f32531a854edd26ae7ebccb8d0	the advanced health and disaster aid network: a light-weight wireless medical system for triage	biomedical monitoring;emergency response;semiconductor technology;light weight wireless medical system;pedestrian safety;poison control;pulse oximeter;injury prevention;emergency service;real time;electronic triage tags;real time data collection;blood pressure;safety literature;oximetry;traffic safety;injury control;patient care;embedded system;home safety;injury research;safety abstracts;electrocardiography;human factors;real time systems biomedical electronics biomedical telemetry blood pressure measurement electrocardiography mesh generation oximetry patient monitoring;biomedical electronics;occupational safety;safety;blood pressure cuff;first responder;biomedical telemetry;safety research;multisensor systems;accident prevention;real time communication;violence prevention;patient monitoring;mesh network;bicycle safety;blood pressure measurement;poisoning prevention;mesh generation;falls;ergonomics;suicide prevention;multisensor systems biomedical monitoring emergency services human factors;blood pressure cuff light weight wireless medical system semiconductor technology electronic triage tags real time data collection mesh network biomedical monitoring multisensor systems biomedical sensors pulse oximeter electrocardiogram;electrocardiogram;emergency services;real time systems;biomedical monitoring embedded system patient monitoring real time systems resource management biomedical computing embedded computing biosensors blood pressure mesh networks;biomedical sensors	Advances in semiconductor technology have resulted in the creation of miniature medical embedded systems that can wirelessly monitor the vital signs of patients. These lightweight medical systems can aid providers in large disasters who become overwhelmed with the large number of patients, limited resources, and insufficient information. In a mass casualty incident, small embedded medical systems facilitate patient care, resource allocation, and real-time communication in the advanced health and disaster aid network (AID-N). We present the design of electronic triage tags on lightweight, embedded systems with limited memory and computational power. These electronic triage tags use noninvasive, biomedical sensors (pulse oximeter, electrocardiogram, and blood pressure cuff) to continuously monitor the vital signs of a patient and deliver pertinent information to first responders. This electronic triage system facilitates the seamless collection and dissemination of data from the incident site to key members of the distributed emergency response community. The real-time collection of data through a mesh network in a mass casualty drill was shown to approximately triple the number of times patients that were triaged compared with the traditional paper triage system.	acquired immunodeficiency syndrome;authorization;blood pressure cuff;cnot8 gene;class:type:pt:ekg leads:nom:ekg;drug vehicle;electrocardiography;embedded system;emergency medical service;ieee xplore;mass casualty incidents;mesh networking;patients;pervasive informatics;real-time locating system;real-time transcription;relevance;resource allocation;seamless3d;semiconductor;sensor node;server (computing);skin tag;triage;vital signs;sensor (device)	Tia Gao;Tammara Massey;Leo Selavo;David Crawford;Bor-rong Chen;Konrad Lorincz;Victor Shnayder;Logan Hauenstein;Foad Dabiri;James Jeng;Arjun Chanmugam;David White;Majid Sarrafzadeh;Matt Welsh	2007	IEEE Transactions on Biomedical Circuits and Systems	10.1109/TBCAS.2007.910901	embedded system;computer science;human factors and ergonomics;blood pressure;biological engineering;computer security	Embedded	-23.02050090807146	0.6278850846544596	27104
fe1fd55bb68e722de23d595b9ea577e6bc1fd08c	behavioural decision theory and it's implication for knowledge engineering	decision theory;knowledge engineering	This paper explores the implications of research results in behavioural decision theory on knowledge engineering. Behavioural decision theory, with its performance (versus process) orientation, can tell us a great deal about the validity of human expert knowledge, and when it should be modelled. A brief history of behavioural decision theory is provided. Implications for knowledge elicitation and representation are discussed. An approach to knowledge engineering is proposed that takes into account these implications.	aggregate data;causality;d programming language;decision support system;decision theory;expert system;framing (world wide web);heuristic;knowledge base;knowledge engineer;knowledge engineering;knowledge management	Paul E. Lehner;Leonard Adelman	1990	Knowledge Eng. Review	10.1017/S0269888900005208	causal decision theory;decision theory;decision analysis;decision engineering;computer science;knowledge management;artificial intelligence;knowledge engineering;decision rule;management science;evidential reasoning approach;domain knowledge;business decision mapping	AI	-29.667638853198046	-9.45487986356254	27120
add145761bde7f81e05ad633768ff4a1a3ab024d	a new evaluation model for intellectual capital based on computing with linguistic variable	linguistic variable;information loss;performance evaluation;intellectual capital;multiple criteria decision making;2 tuple fuzzy linguistic approach;subjective evaluation;evaluation model;competitive advantage	In a knowledge era, intellectual capital has become a determinant resource for enterprise to retain and improve competitive advantage. Because the nature of intellectual capital is abstract, intangible, and difficult to measure, it becomes a challenge for business managers to evaluate intellectual capital performance effectively. Recently, several methods have been proposed to assist business managers in evaluating performance of intellectual capital. However, they also face information loss problems while the processes of subjective evaluation integration. Therefore, this paper proposes a suitable model for intellectual capital performance evaluation by combining 2-tuple fuzzy linguistic approach with multiple criteria decision-making (MCDM) method. It is feasible to manipulate the processes of evaluation integration and avoid the information loss effectively. Based on the proposed model, its feasibility is demonstrated by the result of intellectual capital performance evaluation for a high-technology company in Taiwan.		Wei-Shen Tai;Chen-Tung Chen	2009	Expert Syst. Appl.	10.1016/j.eswa.2008.02.017	actuarial science;knowledge management;management science;competitive advantage	NLP	-5.415160309856769	-16.758842127258415	27132
9824412994a760b776446809a9318d6dfbd1dff5	an extended bdi agent architecture with multiple intention reconsideration ability in a vessel berthing application	adaptive neuro fuzzy inference system;environmental change;reinforcement learning	Belief-Desire-intention (BDI) agent based systems have been implemented in many business application systems and found to have some limitations in obverting environmental changes, adaptation and learning in making rational decisions. Our paper presents a new hybrid BDI agent architecture which compares all the available intentions in the intention reconsideration process and is able to observe all the events which are related to the committed intention, before a decision is being made. Limitation in capturing of one event in the intention reconsideration process is overcome with the introduction of our extended BDI execution cycle. Further, the use of “Knowledge Acquisition Module” (KAM) in our proposed model improves the learning ability of the generic BDI agent. Execution of plans for a committed intention is based on the reinforcement learning techniques and Adaptive Neuro Fuzzy Inference System (ANFIS) is used in deciding the intention reconsideration of the proposed agent model. This enables the agent to interact with the environment more closely and use intelligence in making rational decisions, whose behavior may be not known at the design stage.	adaptive neuro fuzzy inference system;agent architecture;agent-based model;backup;belief–desire–intention software model;business software;knowledge acquisition;reinforcement learning;temporal difference learning	Prasanna Lokuge;Damminda Alahakoon	2005			machine learning;artificial intelligence;natural language processing;knowledge acquisition;adaptive neuro fuzzy inference system;reinforcement learning;computer science;agent architecture	AI	-19.599056185308832	-8.290767830200766	27327
399e9bf55015014894fc894b24249c6fdee0093f	on stationary equilibria of a single-controller stochastic game	game theory;average rewards;strategie joueur;theorie jeu;finite algorithms;jeu 2 personnes;extreme equilibrium strategies;superharmonic vector;two person game;equilibre jeu;game equilibrium;stochastic game;orderfield property;jeu stochastique;discounted rewards;stochastic games;equilibre stationnaire;player strategy	We consider a two-person, general-sum, rational-data, undiscounted stochastic game in which one player (player II) controls the transition probabilities. We show that the set of stationary equilibrium points is the union of a finite number of sets such that, every element of each of these sets can be constructed from a finite number of extreme equilibrium strategies for player I and from a finite number of pseudo-extreme equilibrium strategies for player II. These extreme and pseudo-extreme strategies can themselves be constructed by finite (but inefficient) algorithms. Analogous results can also be established in the more straightforward case of discounted single-controller games.	stationary process	Jerzy A. Filar	1984	Math. Program.	10.1007/BF02591936	bayesian game;game theory;simulation;artificial intelligence;repeated game;mathematics;stochastic game;strategy;correlated equilibrium;normal-form game;mathematical economics;equilibrium selection;nash equilibrium	ECom	-4.76607847183188	-1.490482737863811	27392
662b142dd1a6192e92b97c85ae7f26b92da792dc	a graph-based developmental swarm representation and algorithm	agent interaction;modelling framework;multi agent simulation;graph grammar;formal grammar;local interaction	Modelling natural processes requires the implementation of an expressive representation of the involved entities and their interactions. We present swarm graph grammars (SGGs) as a bio-inspired modelling framework that integrates aspects of formal grammars, graphbased representation and multi-agent simulation. In SGGs, the substitution of subgraphs that represent locally defined agent interactions drive the computational process of the simulation. The generative character of formal grammars is translated into an agent’s metabolic interactions, i.e. creating or removing agents from the system. Utilizing graphs to describe interactions and relationships between pairs or sets of agents offers an easily accessible way of modelling biological phenomena. Property graphs emerge through the application of local interaction rules; we use these graphs to capture various aspects of the interaction dynamics at any given step of a simulation.	agent-based model;algorithm;british informatics olympiad;computation;entity;formal grammar;graph (discrete mathematics);interaction;simulation;swarm	Sebastian von Mammen;David Phillips;Timothy Davison;Christian Jacob	2010		10.1007/978-3-642-15461-4_1	grammar systems theory;natural language processing;computer science;artificial intelligence;theoretical computer science;machine learning;formal grammar	AI	-19.629233401188507	-16.939304167504837	27394
75104c2bc54c079ecadb5e276b9bce9b19bca9b6	potential fields in smoke dispersion applied to evacuation simulations		We often visit places with a large concentration of people, such as malls, football stadiums, restaurants or nightclubs. Through the media, there are often reports of emergency’s cases in these places. It is known that in a fire situation, one of the main causes of deaths is the inhalation of smoke. Therefore, it is essential that at the start of emergency situations people leave quickly to avoid possible injuries. We have investigated the dispersion of smoke in closed places and simulate the crowds’ behavior in these situations. This paper aims to present a new proposal to model the smoke dispersion in closed environments using the concept of potential fields joined to cellular automata. To validate the work, a behavioral model for the simulation of people evacuation using the multiagent approach was implemented.	computer simulation	Bruna A. Corrêa;Diana F. Adamatti;Alessandro de Lima Bicho	2018		10.1007/978-3-030-03928-8_7	operations research;behavioral modeling;cellular automaton;crowds;smoke;multi-agent system;football;computer science	NLP	-18.414215352480614	-22.572164903887035	27408
9639c9ac8d04c0491894817eb5c9acacf83cc562	building autonomic systems using collaborative reinforcement learning	reinforcement learning;autonomic system	This paper presents Collaborative Reinforcement Learning (CRL), a coordination model for online system optimization in decentralized multi-agent systems. In CRL system optimization problems are represented as a set of discrete optimization problems, each of whose solution cost is minimized by model-based reinforcement learning agents collaborating on their solution. CRL systems can be built to provide autonomic behaviours such as optimizing system performance in an unpredictable environment and adaptation to partial failures. We evaluate CRL using an ad hoc routing protocol that optimizes system routing performance in an unpredictable network environment.	autonomic computing;reinforcement learning	Jim Dowling;Raymond Cunningham;Eoin Curran;Vinny Cahill	2006	Knowledge Eng. Review	10.1017/S0269888906000956	error-driven learning;real-time computing;simulation;computer science;artificial intelligence;distributed computing;reinforcement learning	NLP	-16.735210439064378	-10.91279350575393	27489
22a2a73bc1707189145f1b1aebc0a4a1a7fd59b7	application of uncertainty measures on credal sets on the naive bayesian classifier	credal set;uncertainty measures;naive bayesian classifier;classification;naive bayes classifier;imprecise probability;probability distribution;imprecise probabilities;imprecise dirichlet model;convex set;maximum entropy	The publisher does not give any warranty express or implied or make any representation that the contents will be complete or accurate or up to date. The accuracy of any instructions, formulae and drug doses should be independently verified with primary sources. The publisher shall not be liable for any loss, actions, claims, proceedings, demand or costs or damages whatsoever or howsoever caused arising directly or indirectly in connection with or arising out of the use of this material.	bayesian network;naive bayes classifier;primary source	Joaquín Abellán	2006	Int. J. General Systems	10.1080/03081070600867039	probability distribution;bayes classifier;naive bayes classifier;imprecise probability;biological classification;principle of maximum entropy;pattern recognition;probability box;data mining;mathematics;convex set;statistics	NLP	-14.212338024224254	-5.446277886203137	27492
812f76a27e45bba0cf6d697601536d74c5442e2f	durango declarations forum commentaries		Taylor & Francis makes every effort to ensure the accuracy of all the information (the “Content”) contained in the publications on our platform. However, Taylor & Francis, our agents, and our licensors make no representations or warranties whatsoever as to the accuracy, completeness, or suitability for any purpose of the Content. Any opinions and views expressed in this publication are the opinions and views of the authors, and are not the views of or endorsed by Taylor & Francis. The accuracy of the Content should not be relied upon and should be independently verified with primary sources of information. Taylor and Francis shall not be liable for any losses, actions, claims, proceedings, demands, costs, expenses, damages, and other liabilities whatsoever or howsoever caused arising directly or indirectly in connection with, in relation to or arising out of the use of the Content.	francis;primary source	Marsha Woodbury	1996	Inf. Soc.	10.1080/019722496129783		Robotics	-15.082724006639852	-5.704039371075067	27569
6d24cd454b16ad9377c1b4ea2dd49f52d4168530	individual incentives in supervised work groups: from human subject experiments to agent based simulation	equity theory;working group;agent based simulation;incentives;worker dissatisfaction;bounded rationality;human subjects;supervised work groups;performance measures;experiments;agent behaviour;grounded theory;subordinates;work group interaction	We consider a model of work group interaction and introduce an incentive scheme in order to prevent dissatisfaction in subordinates. Several behaviours, which are grounded on observing human subjects when interacting in a similar task, are implemented in artificial agents and simulated. Our results shed light on some aspects of interaction between individuals in complex environment and economic performance, and give insights in terms of observation of the performance measures in organisations.	agent-based model;experiment;intelligent agent;interaction;simulation	Arianna Dal Forno;Ugo Merlone	2009	International Journal of Internet and Enterprise Management	10.1504/IJIEM.2009.022931	working group;simulation;economics;incentive;computer science;knowledge management;artificial intelligence;equity theory;grounded theory;social psychology;bounded rationality	ECom	-15.352712057446622	-12.468769511417584	27588
34dbb20fe3f8814d8a505816eacabf3901c96954	a platform-independent robot control architecture for multiple therapeutic scenarios		While social robots are developed to provide assistance to users through social interactions, their behaviors are dominantly pre-programmed and remote-controlled. Despite the numerous robot control architectures being developed, very few offer reutilization opportunities in various therapeutic contexts. To bridge this gap, we propose a robot control architecture to be applied in different scenarios taking into account requirements from both therapeutic and robotic perspectives. As robot behaviors are kept at an abstract level and afterward mapped with the robot’s morphology, the proposed architecture accommodates its applicability to a variety of social robot platforms.	galaxy morphological classification;interaction;remote control;requirement;robot control;social robot	Hoang-Long Cao;Pablo Gómez Esteban;Albert De Beir;Ramona Simut;Greet Van de Perre;Bram Vanderborght	2016	CoRR		robot learning;simulation;engineering;artificial intelligence;social robot;personal robot	Robotics	-25.891808294311883	-20.637985285392514	27660
3085604e2fbac998e450bbb4c4f4ea908a3a295b	a robot sets a table: a case for hybrid reasoning with different types of knowledge	hybrid knowledge representation and reasoning;online robot planning;metric and qualitative temporal constraints;meta csp;datavetenskap datalogi;datavetenskap;computer science;spatio temporal reasoning	An important contribution of AI to Robotics is themodel-centred approach, whereby competent robot behaviour stems from automated reasoning in models of the world which can be changed to suit different environments, physical capabilities and tasks. However models need to capture diverse (and often application-dependent) aspects of the robot’s environment and capabilities. They must also have good computational properties, as robots need to reason while they act in response to perceived context. In this article, we investigate the use of a meta-CSP-based technique to interleave reasoning in diverse knowledge types. We reify the approach through a robotic waiter case study, for which a particular selection of spatial, temporal, resource and action KR formalisms is made. Using this case study, we discuss general principles pertaining to the selection of appropriate KR formalisms and jointly reasoning about them. The resulting integration is evaluated both formally and experimentally on real and simulated robotic platforms. ARTICLE HISTORY Received 28 November 2014 Accepted 3 November 2015	automated reasoning;causal filter;computation;context (computing);experiment;forward error correction;heuristic (computer science);local search (optimization);modeling language;requirement;robot	Masoumeh Mansouri;Federico Pecora	2016	J. Exp. Theor. Artif. Intell.	10.1080/0952813X.2015.1132267	knowledge representation and reasoning;simulation;qualitative reasoning;computer science;artificial intelligence;model-based reasoning;machine learning;reasoning system	AI	-24.783542440156772	-17.816742260089725	27690
21328ec0877945961c6aacd706916d48e3a2dc9e	fast recommendations using gai models	optimal solution;upper bound;collective decision making;utility theory	This paper deals with Decision-Making in the context of multiattribute utility theory and, more precisely, with the problem of efficiently determining the best alternative w.r.t. an agent’s preferences (choice problem). We assume that alternatives are elements of a product set of attributes and that the agent’s preferences are represented by a generalized additive decomposable (GAI) utility on this set. Such a function allows an efficient representation of interactions between attributes while preserving some decomposability of the model. GAI utilities can be compiled into graphical structures called GAI networks that can be exploited to solve choice problems using collect/distribute schemes essentially similar to those used in Bayesian networks. In this paper, rather than directly using this scheme on the GAI network for determining the most preferred alternative, we propose to work with another GAI function, acting as an upper-bound on utility values and enhancing the model’s decomposability. This method still provides the exact optimal solution but speeds up significantly the search. It proves to be particularly useful when dealing with choice and ranking under constraints and within collective Decision-Making, where GAI nets tend to have a large size. We present an efficient algorithm for determining this new GAI function and provide experimental results highlighting the practical efficiency of our procedure.	agent-based model;approximation algorithm;bayesian network;clique (graph theory);compiler;computation;entropy maximization;graphical user interface;interaction;markov chain;markov random field;recommender system;semantic network;utility functions on indivisible goods;value (ethics)	Jean-Philippe Dubus;Christophe Gonzales;Patrice Perny	2009			group decision-making;artificial intelligence;mathematics;upper and lower bounds;utility	AI	-8.568566563110673	1.8442596757416228	27742
802a2d67e76d6b45453b39eb2fb0abde942b9d4c	constitutive norms in the design of normative multiagent systems	design of normative multiagent systems composed of both constitutive and regulative norms;multiagent system;belief;normative system;intelligence artificielle;logical programming;normative multiagent systems;croyance;metafora;programmation logique;equation constitutive;artificial intelligence;ecuacion constitutiva;actitud;inteligencia artificial;creencia;sistema multiagente;metaphor;programacion logica;attitude;constitutive equation;systeme multiagent;metaphore	In this paper, we consider the design of normative multiagent systems composed of both constitutive and regulative norms. We analyze the properties of constitutive norms, in particular their lack of reflexivity, and the trade-off between constitutive and regulative norms in the design of normative systems. As methodology we use the metaphor of describing social entities as agents and of attributing them mental attitudes. In this agent metaphor, regulative norms expressing obligations and permissions are modelled as goals of social entities, and constitutive norms expressing “counts-as” relations are their beliefs.	agent-based model;entity;multi-agent system	Guido Boella;Leon van der Torre	2005		10.1007/11750734_17	psychology;developmental psychology;artificial intelligence;social psychology	AI	-22.477060187176555	-11.027351559467636	27801
f8cce7149bd29848cc543cb3fd4c69f7aa1b0453	don't speak to strangers: the suspicious strategy can help to improve cooperation in spatial donation game	complex networks;convergence;waste materials;coalition mechanism suspicious strategy spatial donation game indirect reciprocity game complex networks indirect reciprocity model;sociology statistics games complex networks convergence computer science waste materials;probability complex networks game theory network theory graphs;games;statistics;computer science;indirect reciprocity spatial donation game reputation;sociology	This paper studies the evolution of cooperation by using an indirect reciprocity game in complex networks. For an indirect reciprocity game, an individual who helps others at the expense of itself can be recognized as a helpful individual. And this meritorious individual can get help from other individuals with a higher probability in the future. Previous studies show that effectively identifying the meritorious individuals is the key to promote the evolution of cooperation. However, discriminating cooperative from various individuals is a big challenge only with a flat indirect reciprocity model. In this paper we introduce a suspicious strategy and combine it with coalition mechanism to improve the cooperation among self-interested individuals of a complex network. In this method, individuals play against each other in a donation game where they can create coalitions to share information about their reputations, and use suspicious strategy to avoid the exploitation from defectors. With extensive experiments, we ascertain that using our method, the cooperation between individuals in a complex network is promoted.	complex network;experiment;the evolution of cooperation	Hong Ding;Junyao Huang;Yuangfang Chen;Yizhi Ren	2015	2015 IEEE International Conference on Computer and Information Technology; Ubiquitous Computing and Communications; Dependable, Autonomic and Secure Computing; Pervasive Intelligence and Computing	10.1109/CIT/IUCC/DASC/PICOM.2015.289	non-cooperative game;games;simulation;convergence;computer science;repeated game;sequential game;computer security;complex network;statistics;strong reciprocity;computer network	Robotics	-15.342964948498427	-14.841660539906902	27899
4cf1fba79a97572ca60fb9dbd0f5e0603a6c01c1	using the affective reasoner to support social simulations	social simulation;personality type	"""This paper is in two parts. In the f i rst par t , the out l ine of an emot ion reasoning architecture, embodied in a s imula t ion program called the Affective Reasoner, is presented, and a rud i mentary personal i ty representation for s imulated agents is in t roduced. In the second par t , an exercise is reviewed in which the Affect ive Reasoner is given the task of representing agents w i t h different personal i ty types in such a way as to al low the user to engage in a s imulated interact ion w i t h them. Representat ional issues per ta in ing to the unique appraisal and behavioral styles of the different personali ty types are addressed. Conclusions are drawn about the usefulness of the Affective Reasoner in such a parad igm. 1 I n t r o d u c t i o n A central assumpt ion of this paper is tha t s imulat ions of social interact ions between agents should incorporate models of i nd iv idua l affect and personali ty. Most human interact ion revolves around people's ind iv idua l needs and goals. These lead to idiosyncrat ic, in ternal ly mot ivated behavior, and to emot ional responses to si tuat ions that arise. If these aspects of menta l life are not captured in s imulat ions of interpersonal interact ions, then s imulated agents w i l l be at best b land, lifeless, and unrealist ic. Th is problem has been largely ignored in A I . 1 This paper describes a general emot ion reasoning architecture, embodied in a program called the Affective Reasoner, which has been used as a basis for s imula t ing such interpersonal interact ions. Also discussed are the results of using th is architecture to solve the prob lem of * Preparation of this article was supported in part by Andersen Consulting through Northwestern University's Institute for the Learning Sciences. *But see [Bates et al.t 1992] and [Frijda and Swagerman, 1987] for interesting approaches to related problems. representing four d is t inct client types in an interact ive s imula t ion designed to teach sell ing. 2 T h e A f fec t i ve Reasoner The Affective Reasoner (hereafter A R ) is a simulat ion p la t fo rm tha t embraces a wide range of emot ionreasoning issues. In the current research, various worlds are s imulated, and populated w i th agents capable of part i c ipa t ing in emot ional episodes based on their concerns. Agents are given unique disposit ions modeled as a h i erarchical set of appraisal frames. These frames represent their ind iv idua l goals, principles, preferences, and moods. Combinat ions of the appraisal frames are used to interpret si tuat ions tha t unfo ld in the s imula t ion. The interpretat ions, in t u r n , are characterized in terms of the way they may or may not meet the el ic i t ing condit ions for emotions. In some cases emotions result, which then may be expressed, through a set of selectively act ivated behavioral channels, in ways tha t are observable by other agents, and as new s imula t ion events which might pertu rb future si tuat ions. Add i t iona l l y , agents use a casebased heuristic classification system to reason about the emotions of other agents, and to bu i ld representations of those other agents' personalities that w i l l help them to predict and explain future emot ion episodes involv ing those observed agents. 2 .1 T h e e m o t i o n e l i c i t i n g c o n d i t i o n t h e o r y Embodied in the AR is a set of rules for mapp ing f rom emot ion el ic i t ing condit ions into emotion types, based on the work of Ortony, Clore, and Col l ins [Ortony et a/., 1988]. The i r theory has been adapted for the simulat ion and extended f r om twentytwo to twenty-four categories of valenced reactions to s i tuat ions, as out l ined in figure 1. Each of the twentyfour emot ion types has a set of e l ic i t ing condit ions. When the el ic i t ing condit ions are met , and various thresholds have been crossed, corresponding emotions result. A key element of the theory is tha t the way an emot ion-e l ic i t ing s i tuat ion maps in to e l ic i t ing condit ions depends on how an ind iv idua l 194 Cognitive Modeling agent interprets that situation. For example, suppose that a captain heroically/foolishly goes down with his ship, while trying to salvage it . On the one hand, his fellow seamen might see this as praiseworthy, since he has upheld the principle of dedication to maritime service. On the other hand his wife might perceive it as blameworthy, since she sees him as having violated the principle of putting the needs of his family foremost. In both cases the act is the same; it is only the construal of the situation which is different. Emotion-eliciting conditions leading to emotions fall into four major categories: those rooted in the effect of events on the goals of an agent, those rooted in the standards and principles invoked by an act of some agent, those rooted in tastes and preferences with respect to objects (including other agents treated as objects), and lastly, selected combinations of these three categories. Another way to view these categories is that they are rooted in an agent's assessment of the desirability of some event, the praiseworthiness or blameworthiness of some act, the attractiveness of some object, or selected combinations of these assessments. This theory was used as an organizing principle for the appraisal mechanisms of agents. Added to the implementation of the theory are components for actually mapping from situations into the eliciting conditions, an expressive component for generating actions, and a component for reasoning about the emotions of other agents. In addition, extensions to permit the representation of mood and emotional intensity are under development [Elliott and Siegle, 1993]. In the sections that follow, overviews of the three main components of the AR are given. Complexities such as those that arise in the implementation of expectations, multiple and conflicting emotions, relationships between agents, and so forth, are not discussed here, but are given a full treatment in [Elliott, 1992].2 2.2 Genera t ing """" e m o t i o n s """" Emotion-eliciting situations may arise in the course of the simulation. These situations may or may not be of concern to one or more agents. If they are, then varied interpretations of the situation may be made, depending upon the makeup of the relevant appraisal frames in each agent's interpretive personality component. These interpretations are reduced to Emotion Eliciting Condition Relations (EECRs), which in turn are used to generate instantiated emotion templates. Figure 2.2 illustrates the different sources for these emotion templates. Below are annotations for the steps illustrated in the figure: 2For example, mood representation alone affects both the appraisal mechanisms and the expressive components of simulated agents; it affects both the intensity and duration of subsequent affective states; and, it may require as many variables to adequately represent.[Elliott and Siegle, 1993; Frijda et al.} 1992; Gilboa et al., ; Clore, 1992]. Group"""	affective computing;cognitive model;computer simulation;data recovery;emoticon;foremost;forward error correction;genera;heuristic;linear algebra;observable;organizing (structure);population;semantic reasoner;word lists by frequency;xojo	Clark Elliott	1993			computer science	AI	-24.497959895444268	-13.089710505375395	27911
4550c0b398f39fb528117c08824e9b6353fa8dbe	envy-free mechanisms with minimum number of cuts		We study the problem of fair division of a heterogeneous resource among strategic players. Given a divisible heterogeneous cake, we wish to divide the cake among n players in a way that meets the following criteria: (I) every player (weakly) prefers his allocated cake to any other player’s share (such notion is known as envy-freeness), (II) the mechanism is strategy-proof (truthful), and (III) the number of cuts made on the cake is minimal. We provide methods, namely expansion process and expansion process with unlocking, for dividing the cake under different assumptions on the valuation functions of the players.	value (ethics)	Reza Alijani;Majid Farhadi;Mohammad Ghodsi;Masoud Seddighin;Ahmad S. Tajik	2017			computer science;mathematical optimization;envy-free	AI	-5.507042591369367	-3.325936397635458	27920
08bdcb8c6fe795f7affb0fb03654c65ff1d9334a	integrated premission planning and execution for unmanned ground vehicles	multi agent system;cooperative robotics;unmanned ground vehicle;unmanned vehicles;agent technology;coordination;cooperating robots	Fielding robots in complex applications can stress the human operators responsible for supervising them, particularly because the operators might understand the applications but not the details of the robots. Our answer to this problem has been to insert agent technology between the operator and the robotic platforms. In this paper, we motivate the challenges in defining, developing, and deploying the agent technology that provides the glue in the application of tasking unmanned ground vehicles in a military setting. We describe how a particular suite of architectural components serves equally well to support the interactions between the operator, planning agents, and robotic agents, and how our approach allows autonomy during planning and execution of a mission to be allocated among the human and artificial agents. Our implementation and demonstrations (in real robots and simulations) of our multi-agent system shows significant promise for the integration of unmanned vehicles in military applications.	human interface device;intelligent agent;interaction;multi-agent system;robot;simulation;unmanned aerial vehicle	Edmund H. Durfee;Patrick G. Kenny;Karl C. Kluge	1998	Auton. Robots	10.1023/A:1008869126852	embedded system;simulation;computer science;artificial intelligence;multi-agent system	Robotics	-26.090140858720357	-21.940093283037807	27942
c154f18095a114222f58c460b8e635c814efdbd6	application studies of rfid technology in the process of coal logistics transport	system integration	For quality control problems in coal transport, RFID technology has been proposed to be applied to coal transportation process. The whole process RFID traceability system from coal production to consumption has been designed and coal supply chain logistics tracking system integration platform has been built, to form the coal supply chain traceability and transport tracking system and providing more and more transparent tracking and monitoring of coal quality information for consumers of coal. Currently direct transport and combined transport are the main forms of coal transportation in China. The means of transport are cars, trains and ships. In the booming networking environment of RFID technology, the RFID technology will be applied to coal logistics and provide opportunity for the coal transportation tracking in the process transportation.© (2012) COPYRIGHT Society of Photo-Optical Instrumentation Engineers (SPIE). Downloading of the abstract is permitted for personal use only.	logistics;radio-frequency identification	Bingqin Qiao;Xiaoming Chang;Meiyan Hao;Dejin Kong	2012		10.1117/12.966824	engineering;operations management;transport engineering;waste management	HCI	-11.887404794627868	-5.264506415473801	27948
244eac7d24cd0ac9d9175dfb91b3cd300bcbbfc5	a sampling-based approach to accelerating queries in log management systems	log management systems;stratified sampling;log messages	Log management systems are common in industry and an essential part of a system administrator’s toolkit. Examples include Splunk, elk, Log Insight, Sexilog, and more. Logs in these systems are characterized by a small number of predefined fields such as timestamp and host, with the bulk of an entry being unstructured text. System administrators query these logs using a combination of range constraints over predefined fields and patterns or regular expressions over the text portion of the message. These queries are both complex and diverse.   We propose a method for maintaining a subset of these logs in a much smaller database known as a sublog. Because queries are issued against a much smaller data set they run to completion quickly and avoid common scaling bottlenecks. However, the improvement in performance comes at a price. Because we only consider a subset of the original data, we are only able to provide approximate responses. Nonetheless, the reduction in accuracy is minimal and we are able to produce high-quality, high-performance results.	approximation algorithm;bottleneck (software);image scaling;log management;regular expression;run to completion scheduling;sampling (signal processing);system administrator	Tal Wagner;Eric Schkufza;Udi Wieder	2016		10.1145/2984043.2989221	computer science;data mining;database;stratified sampling;world wide web;statistics	DB	-31.27444986099424	-2.1299138225671603	28077
479b0bd4661fa881b772b46ef156a0a1a715ab1e	simple strategy-proof approximately walrasian mechanisms	incentive compatibility;exchange economy;incomplete information;journal of economic literature;limit theorem	This paper provides an indirect analysis of the incentive properties of the Walrasian mechanism. It presents mechanisms under which truth-telling is a dominant strategy in ...nite exchange economies (in contrast to the Walrasian mechanism) and whose outcomes (generically) approximate Walrasian ones for large economies. These mechanisms provide new insights on the well-known trade-o¤ between e¢ciency and incentive compatibility in ...nite economies. ¤This paper previously was distributed as a typescript called “On a “folk” strategy-proof approximately Walrasian mechanism.” I gratefully acknowledge the encouragement and very helpful comments from Salvador Barberà; without them this research would not have taken place. In addition, I am indebted to Birgit Grodal, Peter Hammond, Matt Jackson, Alejandro Manelli, Andreu Mas-Colell, Herakles Polemarchakis, and David Wettstein for very helpful remarks. All remaining errors are my own responsibility. This research was undertaken with support from the European Union’s Tacis ACE Programme 1995. At that time, the author was in the IDEA Ph.D Program of the Autonomous University of Barcelona. Support by DGICYT grant PB92-590 is acknowledged. I am also very grateful to the Center in Political Economy (Washington University in St.Louis) for a fellowship and for the exellent conditions to work which I was enjoying there in Winter 1998.	ace;approximation algorithm;jackson;multi-agent system;typescript;whole earth 'lectronic link	Alexander Kovalenkov	2002	J. Economic Theory	10.1006/jeth.2000.2788	economics;incentive compatibility;microeconomics;mathematical economics;welfare economics;complete information	AI	-7.4444094409300945	-4.417286455023706	28085
067e9ce84204404d19272448b2af05929c936653	a comparison of a graph database and a relational database: a data provenance perspective	query language;xslt 1 0;push processing;software systems;xslt 2 0;relational database;pull processing;relational database system	Relational databases have been around for many decades and are the database technology of choice for most traditional data-intensive storage and retrieval applications. Retrievals are usually accomplished using SQL, a declarative query language. Relational database systems are generally efficient unless the data contains many relationships requiring joins of large tables. Recently there has been much interest in data stores that do not use SQL exclusively, the so-called NoSQL movement. Examples are Google's BigTable and Facebook's Cassandra. This paper reports on a comparison of one such NoSQL graph database called Neo4j with a common relational database system, MySQL, for use as the underlying technology in the development of a software system to record and query data provenance information.	apache cassandra;data store;data-intensive computing;google bigtable;graph database;mysql;neo4j;nosql;query language;relational database management system;sql;software system	Chad Vicknair;Michael Macias;Zhendong Zhao;Xiaofei Nan;Yixin Chen;Dawn Wilkins	2010		10.1145/1900008.1900067	data definition language;query optimization;database theory;sql;relational database management system;relational model;entity–relationship model;relational database;computer science;query by example;in-memory processing;database model;data mining;database;conjunctive query;view;database schema;graph database;information retrieval;alias;null;object-relational impedance mismatch;database design	DB	-32.75225661952214	2.3298258422025206	28130
78c23b61763fd5a691055e6066d507a3ce6fc20c	contrastive confirmation: some competing accounts	philosophy of science;probability;contrastive confirmation;munich center for mathematical philosophy mcmp;ddc 100;bayesianism;law of likelihood	I outline four competing probabilistic accounts of contrastive evidential support and consider various considerations that might help arbitrate between these. The upshot of the discussion is that the so-called ‘Law of Likelihood’ is to be preferred to any of the alternatives considered.		Jake Chandler	2010	Synthese	10.1007/s11229-010-9845-9	philosophy of science;philosophy;epistemology;bayesian probability;probability;mathematics;statistics	HCI	-13.826441824251706	3.8711184186868914	28180
db9db47f016a6eaa1accdfe8416c923ef63cc0e9	combining learning and programming for high-performance robot controllers	robot learning;high performance;autonomous robot;robot programming	The implementation of high-performance robot controllers for complex control tasks such as playing autonomous robot soccer i s tedious, errorprone, and a never ending programming task. In this paper we p ropose programmers to write autonomous controllers that optimize and automatically adapt themselves to changing circumstances of task execution usi ng explicit perception, dynamics and action models. To this end we develop R OLL (Robot Learning Language), a control language allowing for model-based robot programming. ROLL provides language constructs for specifying executable code pieces of how to learn and update these models. We are currently using R OLL’s mechanisms for implementing a rational reconstruction of our soccer robot controllers.	autonomous robot;executable;programmer;robot learning	Alexandra Kirsch;Michael Beetz	2005		10.1007/3-540-30292-1_39	control engineering;mobile robot;robot learning;simulation;computer science;artificial intelligence;social robot;robot control;evolutionary robotics;mobile robot navigation;personal robot	Robotics	-27.874338103369364	-21.214589707799234	28220
bbe7fc6891d96819ba093e1367a125f75e77b8d6	what a shame - why good ideas can't make it in architecture: a contemporary approach towards the case-based reasoning paradigm in architecture		The paper deals with the application of the Case-Based Reasoning Paradigm (CBR) in Design Support Systems in Architecture. Based on the finding that promising concepts and systems do exist in architecture the question as to why they do not gain the anticipated success is explored. In search for reasons a comprehensive comparison between the cognitive model and the derived conceptual method, theoretical contemplations of architectural design as well as the actual application of the method in CBR systems in Architecture, manifests the core of the work presented.	accessibility;case-based reasoning;cognitive model;database;knowledge acquisition;programming paradigm	Katharina Richter	2013			natural language processing;artificial intelligence;architecture;case-based reasoning;cognitive model;computer science;shame	AI	-27.042629738500835	-10.950832891392256	28250
fa03eeccc31f775ba9149edcf484b137f3907241	the grey basic element	grey systems decision making;information missing situation;decision makers;biological system modeling;uncertain situation;manganese biological system modeling business conferences biology roads economics;biology;decision maker;manganese;grey basic element;roads;business;grey systems;contradictory problems;economics;uncertain situation grey basic element grey system theory contradictory problems information missing situation decision makers;conferences;grey system theory	The grey system theory is new methodology useful for the study of unascertained situations whose information is missing and extenics is a another one to solve the contradictory problems. Under the information-missing situation, the values of some characteristics are grey. We propose the grey basic-element to treat this situation. The decision-makers can utilize it to solve the contradictory problems under uncertain situation.	systems theory	Qiaoxing Li	2008	2008 IEEE International Conference on Fuzzy Systems (IEEE World Congress on Computational Intelligence)	10.1109/FUZZY.2008.4630618	artificial intelligence;manganese;grey relational analysis;management science;operations research	Robotics	-8.364301276626955	-20.58875549635874	28255
117cc866c4e876685b3c952c038c30fbd7a388a1	xstreamcluster: an efficient algorithm for streaming xml data clustering	cluster algorithm;locality sensitive hashing;bloom filter;query processing;efficient algorithm;exact solution;data clustering;theoretical analysis;approximate solution;xml document;information system;computational efficiency;conference proceeding	XML clustering finds many applications, ranging from storage to query processing. However, existing clustering algorithms focus on static XML collections, whereas modern information systems frequently deal with streaming XML data that needs to be processed online. Streaming XML clustering is a challenging task because of the high computational and space efficiency requirements implicated for online approaches. In this paper we propose XStreamCluster, which addresses the two challenges using a two-layered optimization. The bottom layer employs Bloom filters to encode the XML documents, providing a spaceefficient solution to memory usage. The top layer is based on Locality Sensitive Hashing and contributes to the computational efficiency. The theoretical analysis shows that the approximate solution of XStreamCluster generates similarly good clusters as the exact solution, with high probability. The experimental results demonstrate that XStreamCluster improves both memory efficiency and computational time by at least an order of magnitude without affecting clustering quality, compared to its variants and a baseline approach.	approximation algorithm;baseline (configuration management);bloom filter;cluster analysis;computation;database;encode;information system;locality of reference;locality-sensitive hashing;mathematical optimization;requirement;streaming xml;time complexity;with high probability	Odysseas Papapetrou;Ling Chen	2011		10.1007/978-3-642-20149-3_36	correlation clustering;data stream clustering;xml;computer science;theoretical computer science;bloom filter;machine learning;cure data clustering algorithm;data mining;database;cluster analysis;information system;locality-sensitive hashing	DB	-28.205889067976536	2.3394779364595037	28372
a3d13204993b9d1459cf9dd448d26fc80c6562b3	reciprocity in gift-exchange-games		This paper presents an analysis of data from a gift-exchange-game experiment. The experiment was descri bed in ‘The Impact of Social Comparisons on Reciprocity’ by G̈achter et al. 2012. Since this paper uses state-of-art data science te chniques, the results provide a different point of view on the problem.As already shown in relevant literature from experimental economics, human decisions deviate from rational payoff maximization. The average gift rate was 31%. Gift rate was under no conditions zero. Further, we derive some special findings and calculate their significance.	data science;expectation–maximization algorithm;point of view (computer hardware company);gift	Rustam Tagiew;Dmitry I. Ignatov	2014	CoRR		mathematics;mathematical economics	NLP	-5.231401916356479	-5.409173677238902	28391
166d94f4553bb4e6958f541d9b801b1b4ad1bcc7	taming the complexity of natural and artificial evolutionary dynamics	qa75 electronic computers computer science	The study of complex adaptive systems is among the key modern tasks in science. Such systems show radically different behaviours at different scales and in different environments, and mathematical modelling of such emergent behaviour is very difficult, even at the conceptual level. We require a new methodology to study and understand complex, emergent macroscopic phenomena. Coarse graining, a technique that originated in statistical physics, involves taking a system with many microscopic degrees of freedom and finding an appropriate subset of collective variables that offer a compact, computationally feasible description of the system, in terms of which the dynamics looks “natural”. This paper presents the key ideas of the approach and shows how it can be applied to evolutionary dynamics.		Riccardo Poli;Christopher R. Stephens	2014		10.1007/978-3-642-37577-4_2	simulation;computer science;artificial intelligence	AI	-19.97873859579986	-16.4868439716096	28439
096ced01c2cfcf9ac14ec2edba4c6e9a4c334044	establishing linguistic conventions in task-oriented primeval dialogue	emergent communication system;thorough lexical analysis;performance measurement;simulation result;complex task;task-oriented primeval dialogue;linguistic convention;task-oriented dialogue;coordination task;computer simulation;strong effect	In this paper, we claim that language is likely to have emerged as a mechanism for coordinating the solution of complex tasks. To confirm this thesis, computer simulations are performed based on the coordination task presented by Garrod & Anderson (1987). The role of success in task-oriented dialogue is analytically evaluated with the help of performance measurements and a thorough lexical analysis of the emergent communication system. Simulation results confirm a strong effect of success mattering on both reliability and dispersion of linguistic conventions.	autonomous robot;computer simulation;emergence;interaction;lexical analysis;problem solving	Martin Bachwerk;Carl Vogel	2010		10.1007/978-3-642-25775-9_4	natural language processing;computer science;artificial intelligence;linguistics	NLP	-20.57362672508688	-13.883420075625148	28448
fa6fe014b4f89bc48dc87384502d52d0fe23681b	drs operating primitives based on distributed mutual exclusion	robot sensing systems;sign board;multi agent system;drs;resource sharing distributed mutual exclusion multi agent systems distributed robotic system dme algorithms sign board inter robot communication mechanism drs leader finding dynamic ordering job assignment;clocks;intelligent robots;resource management;distributed robotic system;manufacturing automation;mobile robots;inter robot communication mechanism;orbital robotics;software agents;dme algorithms;multi agent systems;job assignment;resource sharing;resource management robotics and automation robot sensing systems power system reliability mobile robots distributed control clocks orbital robotics manufacturing automation intelligent robots;dynamic ordering;distributed mutual exclusion;power system reliability;distributed control;robotics and automation;leader finding;distributed robotics	Distributed mutual exclusion (DME) is an important concept in any multi-agent systems, including the distributed robotic system (DRS). Several basic DME algorithms employing sign-board as their inter-robot communication mechanism are presented. It is shown that a large number of DRS operating primitives, such as leader finding, dynamic ordering of robots and events, job assignment, and resource sharing, can be effectively implemented with algorithms based on DME.	mutual exclusion	Jing Wang	1993		10.1109/IROS.1993.583316	shared resource;mobile robot;real-time computing;simulation;computer science;engineering;artificial intelligence;software agent;multi-agent system;distributed computing	Robotics	-17.431928350633072	-9.96789327041279	28483
cc6a1dca234544ce9bd4ca59c88b0dd4b90e6457	book review: shavers, brett. placing the suspect behind the keyboard: using digital forensics and investigative techniques to identify cybercrime suspects		Taylor & Francis makes every effort to ensure the accuracy of all the information (the “Content”) contained in the publications on our platform. However, Taylor & Francis, our agents, and our licensors make no representations or warranties whatsoever as to the accuracy, completeness, or suitability for any purpose of the Content. Any opinions and views expressed in this publication are the opinions and views of the authors, and are not the views of or endorsed by Taylor & Francis. The accuracy of the Content should not be relied upon and should be independently verified with primary sources of information. Taylor and Francis shall not be liable for any losses, actions, claims, proceedings, demands, costs, expenses, damages, and other liabilities whatsoever or howsoever caused arising directly or indirectly in connection with, in relation to or arising out of the use of the Content.	cybercrime;francis;primary source	Nicolas Sklavos	2014	Information Security Journal: A Global Perspective	10.1080/19393555.2014.905662	internet privacy;computer security	Mobile	-15.306812785687821	-5.604182671635746	28505
b9d78c4cf984ebba22987eb2e511f5fcf0bf891e	planning human centered robot activities	robots interactive systems planning;human centered robot activities planning;high level robot planning;cognitive robotics;socially acceptable plans;cognitive robotics human robot interaction collaboration teamwork safety collaborative work decision making motion planning contracts costs;satisfiability;robots;human aware task planner;interactive cognitive robot;social acceptance;context dependent;planning;interactive systems;partial order;socially acceptable plans human centered robot activities planning high level robot planning interactive cognitive robot human aware task planner	"""This paper addresses high-level robot planning issues for an interactive cognitive robot that has to act in presence or in collaboration with a human partner. We describe a task planner called HATP (for human aware task planner). HATP is especially designed to handle a set of human-centered constraints in order to provide """"socially acceptable"""" plans that are oriented toward collaborative task achievement. We provide an overall description of HATP and discuss its main structure and algorithmic features."""	cognitive robotics;feasible region;heuristic (computer science);high- and low-level;refinement (computing);robot	Vincent Montreuil;Aurélie Clodic;Maxime Ransan;Rachid Alami	2007	2007 IEEE International Conference on Systems, Man and Cybernetics	10.1109/ICSMC.2007.4413992	partially ordered set;planning;robot;simulation;computer science;knowledge management;artificial intelligence;context-dependent memory;satisfiability;cognitive robotics	Robotics	-19.368006576440962	-9.299171314420937	28539
44175ea3821ca9376d4731ce4eb10d45181a9b84	using process data to populate ontologies	emergency response;ontologies knowledge acquisition humans vocabulary information systems encoding knowledge engineering knowledge management data mining decision support systems;knowledge based systems knowledge acquisition decision support systems knowledge engineering information analysis;data gathering;knowledge management;decision support system;knowledge acquisition;decision support systems;simulated emergency response process data ontologies decision support system knowledge base elicitation encoding validation knowledge engineering expert knowledge process to ontology;expert knowledge;information analysis;knowledge based systems;knowledge base;knowledge engineering	Ontologies are a mechanism for storing knowledge in a form that can be shared and possibly integrated into a decision support system. As in the design of other knowledge bases, the design of ontologies requires the elicitation, encoding and validation of knowledge gleaned from various sources. One approach to elicitation is the observation and analysis of experts as they perform work in the relevant domain. The analysis of such process data can lead to the identification and encoding of the knowledge that experts apply in practice. Yet despite the relevance of process data to knowledge engineering, the current research provides little guidance on how to capture process data in an ontology. This paper proposes a methodology called Process to Ontology for populating an ontology with expert knowledge as it is reflected in process data. An illustrative example of the methodology's implementation is given using data gathered from a simulated emergency response scenario.	ontology (information science);population	Pushkala Venkataraman;David Mendonça	2003		10.1109/ICSMC.2003.1244203	knowledge representation and reasoning;legal expert system;knowledge base;decision support system;knowledge integration;intelligent decision support system;software mining;idef3;computer science;knowledge management;artificial intelligence;data science;body of knowledge;mathematical knowledge management;knowledge-based systems;knowledge engineering;open knowledge base connectivity;data mining;procedural knowledge;knowledge extraction;personal knowledge management;data analysis;commonsense knowledge;domain knowledge;data collection	AI	-32.114450060167364	-6.56966773074882	28553
c257cf3cc32359f05038967f03a907f6bc44b348	a fuzzy temporal object-relational database: model and implementation		In real world, some data have a specific temporal validity that must be appropiately managed. To deal with this kind of data, several proposals of temporal databases have been introduced. Moreover, time can also be affected by imprecision, vagueness, and/or uncertainty, since human beings manage time using temporal indications and temporal notions, which may also be imprecise. For this reason, information systems require appropriate support to accomplish this task. In this work, we present a novel possibilistic valid time model for fuzzy databases including the data structures, the integrity constraints, and the DML. Together with this model, we also present its implementation by means of a fuzzy valid time support module on top of a fuzzy object-relational database system. The integration of these modules allows to perform queries that combines fuzzy valid time constraints together with fuzzy predicates. Besides, the model and implementation proposed support the crisp valid time model as a particular case of the fuzzy valid time support provided. C © 2014 Wiley Periodicals, Inc.	data integrity;data manipulation language;data structure;information system;john d. wiley;object-relational database;relational database management system;temporal database;vagueness;valid time	Juan Miguel Medina;Jose Enrique Pons;Carlos D. Barranco;Olga Pons	2014	Int. J. Intell. Syst.	10.1002/int.21666	defuzzification;type-2 fuzzy sets and systems;fuzzy classification;computer science;artificial intelligence;fuzzy number;neuro-fuzzy;data mining;database;fuzzy set operations	DB	-22.3371457005281	2.7694476628376674	28602
9dee2ade5a6ecab0ccbfd5c05e4e96e90e30e356	on money as a means of coordination between network packets		In this work, we apply a common economic tool, namely money, to coordinate network packets. In particular, we present a network economy, called PacketEconomy, where each flow is modeled as a population of rational network packets, and these packets can selfregulate their access to network resources by mutually trading their positions in router queues. Every packet of the economy has its price, and this price determines if and when the packet will agree to buy or sell a better position. We consider a corresponding Markov model of trade and show that there are Nash equilibria (NE) where queue positions and money are exchanged directly between the network packets. This simple approach, interestingly, delivers improvements even when fiat money is used. We present theoretical arguments and experimental results to support our claims.	academy;algorithmic trading;approximation;arjen lenstra;artificial life;best, worst and average case;computer networks (journal);discrete mathematics;e-book;eli;entity;fair queuing;fisher–yates shuffle;game theory;graham scan;greedy algorithm;integrated services digital network;internet protocol suite;kelly criterion;lawler's algorithm;lenstra–lenstra–lovász lattice basis reduction algorithm;logistics;mason;malware;markov chain;markov model;money;morgan;nash equilibrium;network congestion;network packet;pareto efficiency;peterson's algorithm;probabilistic analysis of algorithms;r language;random permutation;randomized algorithm;requirement;router (computing);routing;stacs;scheduling (computing);simulation;symposium on foundations of computer science;symposium on theory of computing;tcp congestion control;the art of computer programming;theoretical computer science;weighted fair queueing;wikipedia	Pavlos S. Efraimidis;Remous-Aris Koutsiamanis	2012	CoRR		discrete mathematics;network economy;mathematical economics;mathematics;fiat money;router;nash equilibrium;population;markov model;queue;network packet	Theory	-4.727771764276609	2.391919356540207	28743
ac8972fe41c663b77b6dc99ea95d861ee56e06d2	detection of fraudulent sellers in online marketplaces using support vector machine approach		The e-commerce share in the global retail spend is showing a steady increase over the years indicating an evident shift of consumer attention from bricks and mortar to clicks in retail sector. In recent years, online marketplaces have become one of the key contributors to this growth. As the business model matures, the number and types of frauds getting reported in the area is also growing on a daily basis. Fraudulent e-commerce buyers and their transactions are being studied in detail and multiple strategies to control and prevent them are discussed. Another area of fraud happening in marketplaces are on the seller side and is called merchant fraud. Goods/services offered and sold at cheap rates, but never shipped is a simple example of this type of fraud. This paper attempts to suggest a framework to detect such fraudulent sellers with the help of machine learning techniques. The model leverages the historic data from the marketplace and detect any possible fraudulent behaviours from sellers and alert to the marketplace.	cold start;e-commerce;information retrieval;machine learning;mortar methods;naruto shippuden: clash of ninja revolution 3;online marketplace;social media analytics;support vector machine	Shini Renjith	2018	CoRR	10.14445/22315381/IJETT-V57P210	business;support vector machine;marketing;business model	AI	-33.603309821305174	-17.699704581454082	28755
13fd5d5534af35328a626210eb858b9c86253130	study of social consciousness in stochastic agent based simulations: application to supply chains	multiagent system;game theory;agent based simulation;nash equilibrium;simulation;collaboration;articial intelligence;supply chain;analytical model	Empirical game theory allows studying the strategic interactions of agents in simulations. Specifically, traditional game theory describes such interactions by an analytical model, while empirical game theory employs simulations. In this paper, we use empirical game theory to study how the more-or-less selfishness of agents affects their behaviour. To this end, we assume that every agent utility can be split in two parts, a first part representing the direct utility of agents and a second part representing agent social consciousness, i.e., their impact on the rest of the multiagent system. An application to supply chains illustrates this approach. In this application, the collaborative strategy is often used by every company-agent at whatever their same level of social consciousness, which may indicate that every agent is strongly related with one other.	agent-based model;consciousness;game theory;interaction;multi-agent system;simulation;traditional game	Thierry Moyaux;Brahim Chaib-draa;Sophie D'Amours	2006		10.1145/1160633.1160655	implementation theory;game theory;positive political theory;simulation;artificial intelligence;management science;supply chain;normal-form game;simulations and games in economics education;algorithmic game theory;nash equilibrium;agent-based social simulation;collaboration	AI	-15.163821445203686	-12.431584522112702	28772
3b443e041cf0769b887298ef0249261ab3d883e5	group reasoning in social environments	004 informatik	While modeling group decision making scenarios, the existence of a central authority is often assumed which is in charge of amalgamating the preferences of a given set of agents with the aim of computing a socially desirable outcome, for instance, maximizing the utilitarian or the egalitarian social welfare. Departing from this classical perspective and inspired by the growing body of literature on opinion formation and diffusion, a setting for group decision making is studied where agents are selfishly interested and where each of them can adopt her own decision without a central coordination, hence possibly disagreeing with the decision taken by some of the other agents. In particular, it is assumed that agents belong to a social environment and that their preferences on the available alternatives can be influenced by the number of “neighbors” agreeing/disagreeing with them. The setting is formalized and studied by modeling agents’ reasoning capabilities in terms of weighted propositional logics and by focusing on Nash-stable solutions as the prototypical solution concept. In particular, a thoroughly computational complexity analysis is conducted on the problem of deciding the existence of such stable outcomes. Moreover, for the classes of environments where stability is always guaranteed, the convergence of Nash dynamics consisting of sequences of best response updates is studied, too.	analysis of algorithms;computational complexity theory;nash equilibrium	Erman Acar;Gianluigi Greco;Marco Manna	2017			computer science;artificial intelligence	AI	-9.833490484613112	-5.240361746967726	28774
b5b1092d88029fe5a0b28ba51a6b5d1096bef1da	on the fusion of multi-granularity linguistic label sets in group decision making	fuzzy set;information sources;expert opinion;group decision making;linguistic label;expert judgment;fusion operator;human activity	Group decision-making problem is a common and crucial human activity. Many times due to inherent uncertainty, exact numbers can be either costly or unnecessary to be applied to express experts' opinions or preferences. The use of linguistic labels makes expert judgment more reliable and informative for decision-making. This paper presents a new fusion approach for multi-granularity linguistic information for managing information assessed in different linguistic term sets (multi-granularity linguistic term sets). The paper also presents the application of this approach to a decision-making problem with multiple information sources, assuming that the linguistic performance values given to the alternatives by the different experts are represented in linguistic term sets with different granularity and/or semantic.		Zhifeng Chen;David Ben-Arieh	2006	Computers & Industrial Engineering	10.1016/j.cie.2006.08.012	group decision-making;computer science;artificial intelligence;data mining;fuzzy set	AI	-5.03634413854136	-22.53065129844269	28790
39f33d4d4c229d4f5d2c6b9cd15f40e0b17c51ae	3-d visualizations of coastal bathymetry by utilization of airborne topsar polarized data	water depth;continuity equation;unspecified;three dimensional;standard error;confidence interval;first order;surface model;topsar polarized data;fuzzy b spline algorithm;bathymetry;synthetic aperture radar;spatial resolution;volterra algorithm	Taylor & Francis makes every effort to ensure the accuracy of all the information (the “Content”) contained in the publications on our platform. However, Taylor & Francis, our agents, and our licensors make no representations or warranties whatsoever as to the accuracy, completeness, or suitability for any purpose of the Content. Any opinions and views expressed in this publication are the opinions and views of the authors, and are not the views of or endorsed by Taylor & Francis. The accuracy of the Content should not be relied upon and should be independently verified with primary sources of information. Taylor and Francis shall not be liable for any losses, actions, claims, proceedings, demands, costs, expenses, damages, and other liabilities whatsoever or howsoever caused arising directly or indirectly in connection with, in relation to or arising out of the use of the Content.	airborne ranger;algorithm;approximation;bathymetry;book;card security code;digital image processing;esa;electronic band structure;francis;geographic information science;geographic information system;geomatics;geospatial analysis;hayes microcomputer products;l band;malaysian identity card;microwave;nl (complexity);navier–stokes equations;primary source;radar;scott continuity;solid-state drive;velocity (software development)	Maged Marghany;Arthur P. Cracknell;Mazlan Hashim	2010	Int. J. Digital Earth	10.1080/17538940903477406	three-dimensional space;computer vision;mathematical optimization;synthetic aperture radar;confidence interval;image resolution;bathymetry;continuity equation;first-order logic;mathematics;standard error;statistics;remote sensing	Robotics	-14.819090504784587	-6.252444718718907	28975
97b3893e9dcf2d7f21a02e3b448db0f057af7354	managing functional and ontological knowledge in the design of complex mechanical objects	concepcion asistida;complex objects;computer aided design;ontologie;settore inf 01 informatica;sistema experto;ingenierie connaissances;functional properties;knowledge management;intelligence artificielle;satisfiability;conceptual framework;resolucion problema;conception assistee;artificial intelligence;ontologia;inteligencia artificial;systeme expert;ontology;problem solving;resolution probleme;expert system;knowledge engineering	This paper presents a conceptual framework for the development of Knowledge Management (KM) systems to support experts in complex design activities. Designing a complex object is not simple, since it is concerned not only with problem solving issues, but also with the needs for capturing and managing the core knowledge involved in it. A complex object is typically made of a huge number of parts that are put together according to a first set of constraints (i.e. the dynamic knowledge or functional knowledge), dependable on the functional properties it must satisfy, and a second set of rules, dependable on what the expert thinks abut the problem and how he/she would represent it (i.e. the static knowledge or ontological knowledge). The paper introduces how to unify both types of knowledge, exploiting the SA–Nets formalism to capture the dynamic knowledge and an ontological approach to represent static knowledge.		Ettore Colombo;Gianluca Colombo;Fabio Sartori	2005		10.1007/11558590_62	computer science;knowledge management;artificial intelligence;body of knowledge;knowledge-based systems;machine learning;knowledge engineering;ontology;conceptual framework;database;mathematics;procedural knowledge;knowledge extraction;personal knowledge management;expert system;domain knowledge;algorithm;satisfiability	HCI	-24.444004794022007	-3.7072003323744718	28986
29082a518f61618771dcdb861911d2d54e562866	team performance evaluation using fuzzy logic	virtual teams;fuzzy logic;intelligent agents;team performance	In this paper we describe an experiment where team performance is evaluated by intelligent agents with fuzzy logic reasoning. Although not paramount to the study, which seeks to formally define where and how can intelligent agents help assessing team performance, fuzzy logic was implemented using a set of performance evaluation rules. Results show that the intelligent agents are able to perceive and critically evaluate a team's performance.		Mauro Nunes;Henrique O'Neill	2011		10.1007/978-3-642-23713-3_18	fuzzy logic;simulation;computer science;knowledge management;artificial intelligence;intelligent agent	Vision	-21.67450368370364	-11.455751133429416	28999
9843b4b75bb1017e79a37009a3ecbd4af478d4a7	nash equilibria in symmetric graph games with partial observation		We investigate a model for representing large multiplayer games, which satisfy strong symmetry properties. This model is made of multiple copies of an arena; each player plays in his own arena, and can partially observe what the other players do. Therefore, this game has partial information and symmetry constraints, which make the computation of Nash equilibria difficult. We show several undecidability results, and for bounded-memory strategies, we precisely characterize the complexity of computing pure Nash equilibria for qualitative objectives in this game model.	client–server model;computation;emoticon;nash equilibrium;network topology;server (computing);state space;symmetric graph	Patricia Bouyer;Nicolas Markey;Steen Vester	2017	Inf. Comput.	10.1016/j.ic.2016.10.010	combinatorics;mathematics;discrete mathematics;best response;normal-form game;correlated equilibrium;epsilon-equilibrium;nash equilibrium;symmetric game;repeated game;coordination game	AI	-4.867696211337917	1.326946434092443	29041
f65c9ced5616993dcb4c34e042a1a8fad4b57c4a	attribute-based interactions in agent societies for adaptive plan selection	computer science	Collaboration in a society of agents plays a significant role for the overall society to function in an effective manner in reaching its desired goals. Such inter-entity interactions to achieve society goals require prediction of behavior of other entities and an adaptive interaction plan selection and conflict avoidance mechanism to reach local/agent-level- and global/society-level-goals. Earlier works have assumed a priori knowledge and classification of entities and their attributes in a society for selection of a best plan; we consider such assumptions too restrictive and propose an attribute-based adaptive plan selection infrastructure for agents in a society where agents possess minimum knowledge of their surrounding agents. Furthermore we consider attribute rating mechanism for plan conflict resolution.	interaction	Muhammad Kamran Iftikhar;Abdul Haseeb	2009			business;conflict avoidance;a priori and a posteriori;management science;conflict resolution;knowledge management	AI	-12.107059432093543	-11.159397731347791	29092
7402f47a5f5805958dcbc33e48b5646f453bc602	adaptive model-based diagnostic mechanism using a hierarchical model scheme	hierarchical model	This paper describes an adaptive model-based diagnostic mechanism. Although model-based systems are more robust than heuristic-based expert systems, they generally require more computation time. Time consumption can be significantly reduced by using a hierarchical model scheme, which presents views of the device at several different levels of detail. We argue that in order to employ hierarchical models effectively, it is necessary to make economically rational choices concerning the trade-off between the cost of a diagnosis and its precision. The mechanism presented here makes these choices using a model diagnosability criterion which estimates how much information could be gained by using a candidate model. It takes into account several important parameters, including the level of diagnosis precision required by the user, the computational resources available, the cost of observations, and the phase of the diagnosis. Experimental results demonstrate the effectiveness of the proposed mechanism.	hierarchical database model	Yoichiro Nakakuki;Yoshiyuki Koseki;Midori Tanaka	1992			simulation;computer science;artificial intelligence;machine learning;hierarchical database model	AI	-7.308588667007733	-14.233915796540954	29100
4a6f92fc32b19fa35df45b1914fad13ac1688c65	multi-model data management: what's new and what's next?		As more businesses realized that data, in all forms and sizes, is critical to making the best possible decisions, we see the continued growth of systems that support massive volume of non-relational or unstructured forms of data. Nothing shows the picture more starkly than the Gartner Magic quadrant for operational database management systems, which assumes that, by 2017, all leading operational DBMSs will offer multiple data models, relational and NoSQL, in a single DBMS platform. Having a single data platform for managing both well-structured data and NoSQL data is beneficial to users; this approach reduces significantly integration, migration, development, maintenance, and operational issues. Therefore, a challenging research work is how to develop efficient consolidated single data management platform covering both relational data and NoSQL to reduce integration issues, simplify operations, and eliminate migration issues. In this tutorial, we review the previous work on multi-model data management and provide the insights on the research challenges and directions for future work. The slides and more materials of this tutorial can be found at http://udbms.cs.helsinki.fi/?tutorials/edbt2017.	data model;database;magic quadrant;nosql	Jiaheng Lu;Irena Holubová	2017		10.5441/002/edbt.2017.80	data mining;computer science;data management	DB	-33.586577728431074	0.20517568283050194	29109
b92fa705a45dec169c186263f60307d1aeb1fcf9	emergent properties of referral systems	pagerank;emergent properties;referrals	Agents must decide with whom to interact, which is nontrivial when no central directories are available. A classical decentralized approach is referral systems, where agents adaptively give referrals to one another. We study the emergent properties of referral systems, especially those dealing with their quality, efficiency, and structure. Our key findings are (1) pathological graph structures can emerge due to some neighbor selection policies and (2) if these are avoided, quality and efficiency depend on referral policies. Further, authorities emerge automatically and the extent of their relative authoritativeness depends on the policies.	emergence	Pinar Yolum;Munindar P. Singh	2003		10.1145/860575.860670	simulation;computer science;artificial intelligence;management science;emergence	ML	-15.949312861192624	-13.280896035405872	29119
ca0b5c3bd7567383000376ea2301d6723933b642	a critical view of severity classification in risk assessment methods	modelizacion;analyse risque;analisis sistema;sistema critica;securite;safety assessment;risk analysis;trafico aereo;socio technical systems;interaction;gestion trafic;systeme critique;accident;riesgo accidente;traffic management;systeme sociotechnique;classification;dysfunctional interactions;risque accidentel;scenario;modelisation;analisis riesgo;critical system;argumento;sistema socio tecnico;causalite;severity classification;typology;script;safety;defaillance;gestion trafico;system analysis;risk assessment;analyse systeme;interaccion;typologie;accidente;failures;trafic aerien;seguridad;modeling;fallo;air traffic;clasificacion;hazard;tipologia;evaluation risque;causality;causalidad;air traffic management	The knowledge of operational experts plays a fundamental role in performing safety assessments in safety critical organizations. The complexity and socio-technical nature of such systems produce hazardous situations which require a thorough understanding of concrete operational scenarios and cannot be anticipated by simply analysing single failures of specific functions. This paper addresses some limitations regarding state-of-the-art safety assessment techniques, with special reference to the adoption of ‘‘chain of event’’ models in accident causation (widely criticised by many authors), to the use of severity classes and to the adoption of the worst credible effect criterion. Such methods tend to assume a linear link between single hazards considered in isolation and corresponding consequences for safety, thus neglecting the intrinsic complexity of the systems under analysis and reducing the opportunities for an effective involvement of operational experts. An alternative approach is proposed to overcome these limitations, by distinguishing different typologies of hazards and integrating the analysis of single functions with the study of concrete operational scenarios. & 2010 Elsevier Ltd. All rights reserved. 1. The problem: assessing the severity of the final effect The assessment of hazard severity is an essential part of safety assessment methods. Classifying the severity is a prerequisite to establish the safety objectives and the safety requirements that an organization decide to put in place. The safety requirements are then substantiated into mitigation actions – like technical adjustments, innovative features, procedural changes and training programmes – in order to achieve an acceptable level or risk. State-of-the-art methods mainly rely on classifying the severity of the predicted effect of each hazard. For example, if a hazard is expected to generate a real accident, the severity is classified as very high. If the hazard may only result in a significant incident, the severity will be considered low. In case of uncertainty, that is if the hazard may produce a variety of different effects, the methods suggest to adopt the concept of worst credible effect. Based on a conservative approach, the classification will take into account the worst effect among the ones which are reasonably possible to occur. This method works well with simple systems with a controlled number of components, variables and well defined constraints. On the contrary, when applied to complex socio-technical systems, like aviation and air traffic management, it faces a number of ll rights reserved. : +39 06 8558 988.	causality;extreme value theory;hazard (computer architecture);hazard analysis;interaction;limited availability;piaget's theory of cognitive development;reductionism;requirement;risk assessment;sociotechnical system;software reliability testing	Alberto Pasquini;Simone Pozzi;Luca Save	2011	Rel. Eng. & Sys. Safety	10.1016/j.ress.2010.06.029	risk assessment;active traffic management;interaction;systems modeling;typology;risk analysis;causality;biological classification;hazard;engineering;scenario;sociotechnical system;air traffic control;system analysis;operations research;computer security	AI	-11.263077687507353	-15.03786832271782	29185
59a0127a6397c769d0b6ab633dc0e481bb1a581c	a distance measure for decision making in uncertain domains	distance measure	A novel definition of syntactic distance between structural symbolic descriptions is proposed. It is based on a probabilistic interpretation of the canonical matching predicate. By means of this distance measure it is possible to cope with the problem of matching noise affected descriptions or imprecise rules. Furthermore, an extension of the syntactic distance which manages incomplete descriptions is presented. Finally, the application of the syntactic distance to the problem of classifying digitized office documents by using their page layout description is shown.		Floriana Esposito;Donato Malerba;Giovanni Semeraro	1990		10.1007/BFb0028141	computer science	ML	-5.197404260933105	-23.68404382003634	29235
9a0ae66b467225ab0c95ea3f2ab59c5bb38caa27	correlated quantal responses and equilibrium selection	postprint;equilibrium selection;quantal response equilibrium;incomplete information game;global game	This paper considers incomplete information games with payoffs subject to correlated random disturbances. It explains the connection between the uniqueness of quantal response equilibria, where large noise is required, and the uniqueness of equilibria in global games, where small noise is required. JEL classifications: C72, D82.	quantum	Takashi Ui	2006	Games and Economic Behavior	10.1016/j.geb.2005.08.018	mathematical optimization;economics;microeconomics;mathematical economics;global game;welfare economics;equilibrium selection	ECom	-4.774548788009667	-2.186777122401929	29251
bc1a5009221d83da326d610ed49e99cdfa98777b	an adaptive plan-based dialogue agent: integrating learning into a bdi architecture	adaptive dialogue systems;machine learning;bdi agents;dialogue management;symbolic machine learning;dialogue manager	We consider the problem of dialogue adaptation in our Smart Personal Assistant (SPA), which uses a plan-based dialogue model. We present a novel way of integrating learning into a BDI architecture so the agent can learn to select the most suitable plan amongst those applicable, enabling the SPA to tailor its responses according to the conversational context and the user's physical context, device and preferences.		Anh Tuan Le Nguyen;Wayne Wobcke	2006		10.1145/1160633.1160771	simulation;computer science;knowledge management;artificial intelligence	AI	-32.41144898867721	-23.72138238818936	29264
557aef11e55ff08c39184c9fc4866f8304e6e61f	learning expressive performance rules in jazz		If-then rules are one of the most expressive and intuitive knowledge representations and their application to represent musical knowledge raises particularly interesting questions. In this paper we present a machine learning approach for inducing rules of expressive music performance from real performances of Jazz standards. It turns out that some of the induced rules represent extremely simple principles which are surpris-	jazz (computer);machine learning;performance	Rafael Antonio Márquez Ramírez;Amaury Hazan	2004			natural language processing;speech recognition;communication	AI	-27.549711427194683	-17.348202849474717	29286
f2326d2eda114e68ce547fe389ffe0a1702f199f	the role of emotions, mood, personality and contagion in multi-agent system decision making		Emotions have attracted much interest in the Multi Agent Systems community, mainly due to their significance in creating simulations that more accurately predict crowd behaviours. Undoubtedly, infusion of agents with artificial emotions has to be supported by current psychology theories. The present work describes a formal model of artificial emotions based on the dimensionality theory, together with simulation results of an initial experimental evaluation. The model includes interesting aspects of emotions, such as emotion changes due to perception, long term affects due to mood, and emotion contagion due to social interactions.	multi-agent system	Ilias Sakellariou;Petros Kefalas;Suzie Savvidou;Ioanna Stamatopoulou;Marina Ntika	2016		10.1007/978-3-319-44944-9_31	emotional contagion	AI	-21.57693927928562	-16.120163707520177	29292
b0d333139358a83e8edca0d99dde6b61e99e2a8c	hierarchical model and communication by signs, signals and symbols in multi-agent environments	multiagent system;agent modeling;hierarchical model	This paper describes a general framework for designing agents for a multiagent systems. A hierarchical agent model is described, structuring an agent according to different types of situations. It has to deal with: routines, familiar and unfamiliar situations. Then, an idea is developped for the coordination between agents: agents should prefer low levels (i.e. routine and familiar situations) than the high level (i.e. unfamiliar situations). The reason is that low levels are fast, effortless and are propitious for coordinated activities between agents, whereas the high level is slow, laborious and can lead to conflicts between agents. To achieve this, we develop the idea of using communication by signs and signals (and not by symbols) in order to allow agents to rely on their low levels. Finally, implementation and experiments demonstrated, on some scenarios of urban traffic, the applicability of concepts developed in this article.	hierarchical database model	Brahim Chaib-draa;Pascal Levesque	1994		10.1007/3-540-61157-6_28	simulation;engineering;artificial intelligence;hierarchical control system;communication	ML	-22.31297451139788	-9.07824766701234	29334
dc4c9924cd66a5a0cdee3adf252af735b3bfc3af	trial by fire: teleoperated robot targets chernobyl	national aeronautics and space administration;radiation decontamination;department of energy;real time;mobile robots;fires sensor arrays us department of energy robot sensing systems orbital robotics power generation space technology power generation economics proposals energy management;stereo vision;telerobotics;nuclear power plant;core drilling teleoperated robot chernobyl nuclear power plant nuclear accident specialized tethered bulldozer like robot pioneer stereo vision real time 3d mapping;radiation decontamination mobile robots telerobotics	"""The blast that destroyed Unit 4 of the Chernobyl Nuclear Power Plant (CNPP) 12 years ago prompted a firestorm of scientific, technological, political, and economic proposals for managing the worst nuclear accident to date. Following a meeting of the G-7 nations-the United States, Canada, Britain, France, Italy, Germany, and Japan-and Ukrainian representatives, the US Department of Energy (DOE) and National Aeronautics and Space Administration (NASA) organized and funded a """"dream team"""" of experts in robotics as well as computer hardware and software for the """"Pioneer Project"""". Pioneer is a specialized, tethered, bulldozer-like robot equipped with stereo vision for real-time 3D mapping, a core-drilling and sampling apparatus, and an array of radiation and other sensor tools for remotely investigating Unit 4. The team has scheduled Pioneer's deployment at Chernobyl for November 1998."""	robot	Jeffrey Abouaf	1998	IEEE Computer Graphics and Applications	10.1109/38.689654	telerobotics;mobile robot;simulation;computer science;stereopsis;artificial intelligence;mechanical engineering	Visualization	-32.820738477208394	-19.783741082934085	29373
e4848651bdaeb0f5a3a18eb51db485b5639957c9	relationship between human and computational abduction	human abduction;chance discovery;probability density function;inference mechanisms;data mining;humans induction generators artificial intelligence medical expert systems logic testing laboratories knowledge engineering diagnostic expert systems production systems medical diagnosis;hypothetical reasoning;computational abduction;medical services;cognition;face;humans;chance discovery computational abduction human abduction hypothetical reasoning;knowledge based systems	In this paper, I discuss relationships between human and computational abduction. First, I review both abduction to compare them. Then I describe human abduction (Holmes) in hypothetical reasoning's style. By referring to it, I propose coupling of deduction and abduction for better abduction and chance discovery. By the proposal method, active chance discovery can be achieved.	abductive reasoning;natural deduction	Akinori Abe	2008	2008 IEEE International Conference on Systems, Man and Cybernetics	10.1109/ICSMC.2008.4811295	face;probability density function;cognition;computer science;artificial intelligence;knowledge-based systems;data mining;algorithm;statistics	Robotics	-26.324617334267135	-9.974332596691319	29395
01b90f8b58d4fdbc7d99ff14c4f63675ea683e14	applications of self-organising multi-agent systems: an initial framework for comparison	self organisation;software;multi agent system;applications	A lot of work is devoted to formalizing and devising architectures for agents' cooperative behaviour, for coordinating the behaviour of individual agents within groups, as well as to designing agent societies using social laws. However, providing agents with abilities to automatically devise societies so as to form coherent emergent groups that coordinate their behaviour via social laws, is highly challenging. These systems are called self-organised. We are beginning to understand some of the ways in which selforganised agent systems can be devised. In this perspective, this paper provides several examples of multi-agent systems in which self-organisation, based on different mechanisms, is used to solve complex problems. Several criteria for comparison of self-organisation between the different applications are provided. Povzetek: Članek opisuje primere in kriterije samoorgarnizacije v agentnih sistemih.	application domain;apriori algorithm;autonomous robot;avionics;coherence (physics);e-commerce;emergence;holon (philosophy);information retrieval;internet;mobile robot;multi-agent system;relevance;robotics;self-organization;simulation	Carole Bernon;Vincent Chevrier;Vincent Hilaire;Paul Marrow	2006	Informatica (Slovenia)		simulation;computer science;artificial intelligence;multi-agent system;management science;information technology	AI	-20.09075475732203	-13.22588694856644	29411
670aa4758e9f88b7d8ffab43d8a792c9aa24bce4	a peircean theory of decision	abduction;future;comportement;regle;generality;rationnel;connaissance;rational;natural law;principe;loi naturelle;peirce c s;strategy;fin;knowledge;impossibility;definition;permission;end;perfection;impossibilite;theory;processus;decision;determination;process;behavior;scientific;avenir;principle;strategie;rule;prediction;generalite;inference;scientifique;theorie;deduction	It is sometimes argued that the fact that possession of perfect knowledge about the future is impossible, means that it is impossible for decisions to be rational. This reasoning is fallacious. If rationality is given a new interpretation, then decisions can be considered rational. A theory of decision that has as its basis Peirce’s theory of abduction can provide a new way of understanding decisions as rational processes. The Peircean theory of decision (i) considers decisions as part of a complete strategy, and (ii) shows that decision making is governed by the same rules as scientific abduction. These rules are neither permissive rules like rules of deductive inference nor predictive like laws of nature, but rather genuine laws of conduct that determine what step should be made, if a given end is to be reached.	abductive reasoning;deductive language;rationality	Berit Brogaard	1999	Synthese	10.1023/A:1005154800638	end;prediction;definition;fin;philosophy;epistemology;decision field theory;strategy;principle;perfection;mathematics;natural law;knowledge;theory;algorithm;business decision mapping;process;behavior	AI	-13.15187279928192	3.963011406023677	29438
800b0c2f9e1e360ea697d24cf770cf75aeca38cc	a computational normative theory of scientific evidence	experimental evidence;interval probability;statistical inference;evidence combination;probabilistic logic	"""A scientific reasoning system makes decisions using objective evidence in the form of independent experimental trials, propositional axioms, and constraints on the probabilities of events. I propose a collection of algorithms that derive probability intervals and estimate conditional probabilities from objective evidence in those forms. This reasoning system can manage uncertainty about data and rules in a rule-based expert system. I expect that the system will be particularly applicable to diagnosis and analysis in domains with a wealth of experimental evidence such as medicine. The algorithms currently apply to systems with arbitrary amounts of experimental evidence but with less than 20 variables. 1 discuss limitations of this solution and propose future directions for this research. This work can be considered a generalization of Nilsson's """"'probabilistic logic"""" to intervals and experimental observations."""	algorithm;expert system;fuzzy logic;logic programming;reasoning system	David B. Sher	1992	Int. J. Approx. Reasoning	10.1016/0888-613X(92)90002-H	econometrics;statistical inference;artificial intelligence;machine learning;data mining;mathematics;probabilistic logic;statistics	AI	-15.572490043353758	-0.2556080486779691	29445
d9c81be9ec051d09a4492212d7ac46ccdedf8cea	a restructuring service cluster algorithm abc optimised based on virtual resource selection probability	probability density function;service clusters restructuring;cloud manufacturing;abc artificial bee colony optimisation	Taylor & Francis makes every effort to ensure the accuracy of all the information (the “Content”) contained in the publications on our platform. However, Taylor & Francis, our agents, and our licensors make no representations or warranties whatsoever as to the accuracy, completeness, or suitability for any purpose of the Content. Any opinions and views expressed in this publication are the opinions and views of the authors, and are not the views of or endorsed by Taylor & Francis. The accuracy of the Content should not be relied upon and should be independently verified with primary sources of information. Taylor and Francis shall not be liable for any losses, actions, claims, proceedings, demands, costs, expenses, damages, and other liabilities whatsoever or howsoever caused arising directly or indirectly in connection with, in relation to or arising out of the use of the Content.	algorithm;francis;primary source	Jorick Lartigau;Xiaofei Xu;Lanshun Nie;De-chen Zhan	2015	Int. J. Computer Integrated Manufacturing	10.1080/0951192X.2014.941405	probability density function;simulation;engineering;artificial intelligence;operations management;operating system;data mining;database;statistics	Robotics	-14.31875787598062	-5.3788211256767715	29490
e212654b734eb7d6e87474767df6e3588f500aa5	a multi-agent bioinformatics integration system with adjustable autonomy: an overview	integrable system;adjustable autonomy;belief functions;distributed reputation management;trust networks	In this paper we give a brief overview of a Multi-Agent Bioinformatics Integration System that aims at helping users make the most of the available integration facilities while also increasing their trust in the system. To this end, an explanation facility that helps the users to better understand how the system has arrived at a particular answer is provided. This is especially useful when non-expert users want to take control of critical-decisions, i.e. adjust the system's autonomy. This is accomplished by interacting with users and asking for their intervention in decisions, according to their own preferences.	autonomy;bioinformatics;interaction;mathematical optimization;multi-agent system	Konstantinos Karasavvas;Richard A. Baldock;Albert Burger	2002		10.1145/544741.544810	integrable system;simulation;knowledge management;artificial intelligence;management science	AI	-31.696749870711674	-10.16757395747803	29494
6da445c17b546ee71f25beae6ed9732f74089e92	the hitchhiker's guide to affiliation networks: a game-theoretic approach	model specification;theoretical model;game theory;nash equilibrium;nash equilibria;information network;strategic interaction;social network;degree sequence;clustering coefficient;network formation;social structure;complete graph;structural properties;network formation game	We propose a new class of game-theoretic models for network formation in which strategies are not directly related to edge choices, but instead correspond more generally to the exertion of social effort. This differs from existing models in both formulation and results: the observed social network is a byproduct of a more expressive strategic interaction, which can more naturally explain the emergence of complex social structures. Within this framework, we present a natural network formation game in which agent utilities are locally defined and that, despite its simplicity, nevertheless produces a rich class of equilibria that exhibit structural properties commonly observed in social networks – such as triadic closure – that have proved elusive in most existing models. Specifically, we consider a game in which players organize networking events (or gatherings) at a cost that grows with the number of attendees. A gathering’s cost is assumed by the organizer but the benefit accrues equally to all attendees: a link is formed between any two players who see each other at more than a certain number r0 of gatherings per time period, whether at gatherings organized by themselves or by third parties. The graph of connections so obtained is the social network of the model. We analyze the Nash equilibria of this game for the case in which each player derives a benefit a > 0 from all her neighbors in the social network and when the costs are linear, i.e., when the cost of a gathering with ` invitees is b + c`, with b > 0 and c > 0. For γ = a/cr0 > 1 and b sufficiently small, all Nash equilibria have the complete graph as their social network; for γ < 1 the Nash equilibria correspond to a rich class of social networks, all of which have substantial clustering in the sense that the clustering coefficient is bounded below by the inverse of the average degree. Many observed social network structures occur as Nash equilibria of this model. In particular, for any degree sequence with finite mean, and not too many vertices of degree one or two, we can construct a Nash equilibrium producing a social network with the given degree sequence. We also briefly discuss generalizations of this model to more complex utility functions and processes by which the resulting social network is formed.	cluster analysis;clustering coefficient;degree (graph theory);electronic organizer;emergence;game theory;nash equilibrium;network formation;social network;social structure;triadic closure	Christian Borgs;Jennifer T. Chayes;Jian Ding;Brendan Lucier	2011			price of stability;game theory;epsilon-equilibrium;simulation;best response;coordination game;economics;network formation;dynamic network analysis;artificial intelligence;non-credible threat;folk theorem;repeated game;mathematics;correlated equilibrium;microeconomics;risk dominance;normal-form game;mathematical economics;equilibrium selection;algorithm;nash equilibrium	ECom	-13.346540666080418	-16.235375961001946	29513
c74ce74ef44721da57214747ffc361a0cb162891	building decision making models through conceptual constraints: multi-scale process model implementations		The integration of decision-making procedures typically assigned to different hierarchical levels in a production system (strategic, tactical, and operational) requires the use of complex multi-scale mathematical models and high computational efforts, in addition to the need of an extensive management of data and knowledge within the production system. The aim of this study is to propose a comprehensive solution for this integration problem through the use of Conceptual Constraints. The presented methodology is based on a model in a domain ontology and the use of generalized concepts to develop tailor-made decision making models, created according to the introduced data. Different decision making formulations are reviewed and, accordingly, comprehensive Conceptual Constraints for the different concepts (like material balances) can be determined. This work shows how these Conceptual Constraints can be used when the quality of information is changed, enabling multi-scale implementations.		Canan Dombayci;Antonio Espuña	2016		10.1007/978-3-319-55702-1_12	decision-making models;mathematical model;implementation;information quality;ontology;management science;computer science	Vision	-33.20127850804464	-7.302509286666706	29525
ff450e3250e8b43603681ba58b4fb259cc50ce2a	quality of information in the context of ambient assisted living	idea generation and argumentation;ambient assisted living;incomplete information;quality of information;group decision support system;common sense;knowledge representation;idea generation;problem solving	With the use of new computational technologies and novel methodologies for problem solving, recurring to the use of Group Decision Support Systems, normally the problem of incomplete information is marginalized as if we were living in an ideal world. Common sense tells us that in the precise time a decision is make it is impossible to know all the information regarding to it, however decisions must be made. What we propose, in the ambit of the VirtualECare project, is a possible solution to decision making, through the use of Group Decision Support Systems, aware of incomplete information but, even so, able to make decisions based in the quality of the information and its source.	ambit;decision support system;knowledge representation and reasoning;problem solving;sensor;unreachable memory	Luís Lima;Ricardo Costa;Paulo Novais;Cesar Analide;José Bulas-Cruz;José Neves	2008		10.1007/978-3-540-85863-8_74	knowledge representation and reasoning;r-cast;ideation;computer science;knowledge management;artificial intelligence;management information systems;management science;information quality;complete information;business decision mapping	AI	-29.74964045584527	-9.42162449003765	29541
1322c5d0c2f5d986c46bb154c13b49126cf3ea05	turning lemons into peaches using secure computation		In many cases, assessing the quality of goods is hard. For example, when purchasing a car, it is hard to measure how pollutant the car is since there are infinitely many driving conditions to be tested. Typically, these situations are considered under the umbrella of information asymmetry and as Akelrof showed may lead to a market of lemons. However, we argue that in many of these situations, the problem is not the missing information but the computational challenge of obtaining it. In a nutshell, if verifying the value of goods requires a large amount of computation or even infinite amounts of computation, the buyer is forced to use a finite test that samples, in some sense, the quality of the goods. However, if the seller knows the test, then the seller can over-fit the test and create goods that pass the quality test despite not having the desired quality. We show different solutions to this situation including a novel approach that uses secure computation to hide the test from the seller to prevent over-fitting.	computational problem;differential privacy;information theory;overfitting;purchasing;secure multi-party computation;verification and validation	Stav Buchsbaum;Ran Gilad-Bachrach;Yehuda Lindell	2018	CoRR		mathematical optimization;mathematics;computation;purchasing;secure multi-party computation;information asymmetry	ECom	-10.899448399376105	-7.147533519472449	29564
468219aa599c6fca8e61ef02a1370dc3296858eb	towards an advanced modelling of complex economic phenomena - pretopological and topological uncertainty research tools				Jaime Gil-Aluja;Anna Maria Gil Lafuente	2012		10.1007/978-3-642-24812-2	pure mathematics;mathematics;geometry	Robotics	-11.276905138086844	-20.020696582885066	29575
e4ec61ac1a987b6d529801072028f6f8b71e5b9a	analyse des dépendances temporelles des influences et perceptions pour l'exécution distribuée de simulations orientées agent		Agent-Oriented Simulations (AOS) are helpful in the understanding of real complex systems particularly thanks to the ease of modeling and observation they provide. To fully exploit those simulations, AOS platforms should offer shorter simulation times in spite of the in- creasing complexity of simulation models. In this article, we propose a method to mini- mize execution time of AOS. This method is based on the identification of agents’ temporal dependencies. Knowing these dependencies, we use a network of AOS platforms to provide parallel execution of simulation agents. Our proposition is based on the Temporality model we previously presented to ensure events causality during simulation.	simulation	Nicolas Sébastien;Rémy Courdier;Didier Hoareau;Marc-Philippe Huget	2008			proposition;machine learning;simulation modeling;complex system;causality;artificial intelligence;exploit;spite;computer science	Crypto	-19.579919047210744	-17.348748362238396	29590
2a5f03a5d7cbc0340cba18169abfee2901059649	ranking branches of system group company in terms of acceptance preparation of electronic customer relationship management using ahp method	analytic hierarchy process;management system;customer relationship management;customer relations;indexation;electronic customer relationship management;hierarchical model;analytical hierarchy process method	"""The purpose of performing of this research is to determine the importance and effectiveness of major factors on electronic customer relation management (ECRM) capabilities in System Group branches. Also it is specified which changes should be created by this company to implementing such system and which capabilities should be stressed in order to gain success based on the existing circumstances in each of the branches. A hierarchical model based on six major dimensions and sixteen indexes has been applied in this research to evaluate preparation of System Group branches for accepting of electronic customer relation management. In this research AHP method is applied to analyze data and Expert Choice software is used as analysis tool. Research results revealed that strategy has the most importance and priority among major factors of preparation for implementing of electronic customer relation management system. Also among the branches of the group that are called hereinafter as """"Base"""", Tehran North Base has the priority in implementation with regard to main dimensions and indexes. Keywors: Customer Relationship Management; Electronic Customer Relationship Management; Analytical Hierarchy Process Method"""	analytical hierarchy;customer relationship management;hierarchical database model	Mohammad Hossein Moshref Javadi;Zahra Azmoon	2011		10.1016/j.procs.2010.12.199	enterprise relationship management;voice of the customer;customer relationship management;analytic hierarchy process;computer science;management system;customer intelligence;hierarchical database model	DB	-6.417689467293517	-17.59350357115739	29591
b63663a752a2e39988cb2b77e1564230b138576d	mirroring versus simulation: on the representational function of simulation	mirror neurons;mirror systems;mirroring;mindreading;simulation theory;cognitive function;neural reuse;representation;resemblance;functional analysis	Mirror neurons and systems are often appealed to as mechanisms enabling mindreading, i.e., understanding other people’s mental states. Such neural mirroring processes are often treated as instances of mental simulation rather than folk psychological theorizing. I will call into question this assumed connection between mirroring and simulation, arguing that mirroring does not necessarily constitute mental simulation as specified by the simulation theory of mindreading. I begin by more precisely characterizing “mirroring” (Sect. 2) and “simulation” (Sect. 3). Mirroring results in a neural process in an observer that resembles a neural process of the same type in the observed agent. Although simulation is often characterized in terms of resemblance (Goldman, Simulating minds: The philosophy, psychology, and neuroscience of mindreading, 2006), I argue that simulation requires more than mere interpersonal mental resemblance: A simulation must have the purpose or function of resembling its target (Sect. 3.1). Given that mirroring processes are generated automatically, I focus on what is required for a simulation to possess the function of resembling its target. In Sect. 3.2 I argue that this resemblance function, at least in the case of simulation-based mindreading, requires that a simulation serve as a representation or stand-in of what it resembles. With this revised account of simulation in hand, in Sect. 4 I show that the mirroring processes do not necessarily possess the representational function required of simulation. To do so I describe an account of goal attribution involving a motor mirroring process that should not be characterized as interpersonal mental simulation. I end in Sect. 5 by defending the conceptual distinction between mirroring and simulation, and discussing the implications of this argument for the kind of neuroscientific evidence required by simulation theory.		Mitchell Herschbach	2011	Synthese	10.1007/s11229-011-9969-6	epistemology	AI	-25.096016828708095	-14.062303195411106	29600
126d03288bb73d7c94b8d740da87c1b5cbd4e93d	the hazards of fancy backtracking	search space	There has been some recent interest in intelligent backtracking procedures that can return to the source of a dif&ulty without erasing the intermediate work. In this paper, we show that for some problems it can be counterproductive to do this, and in fact that such “inteIIigence” can cause an exponentkd increase in the size of the ultimate search space. We discuss the reason for this phenomenon, and we present one way to	backtracking	Andrew B. Baker	1994			searching the conformational space for docking;computer science;artificial intelligence;algorithm	AI	-14.734533068461348	3.3697461244429934	29615
6f58c4ffc80e92677dd63142ec2d52a90bd4c57b	proposed model of behavior for a community of robotic agents	intelligent agents theory;intelligent agents theory robotic agent community robotic agent behavior multirobot system cooperative methods collaborative work multiagent robot society;collaborative work;multirobot system;multi robot system;maintenance engineering;agent communication;collective robotics;comunnity robts;multi robot systems;comunnity robts multi agentes robotics ontology;intelligent agent;multiagent robot society;cooperative methods;ontologies;multi agentes robotics;communities;robot kinematics communities maintenance engineering proposals collaborative work ontologies;proposals;ontology;robotic agent behavior;robotic agent community;robot kinematics	In a multi-robot system, increasing the complexity of the tasks and work in unstructured spaces shows that a single robot is insufficient to meet the requirements of the goal, thus proliferating the use of robotic communities and cooperative methods and collaborative work, reaching the diverse community concept. This heterogeneity adds a new challenge to collective robotics, which is the ability to coordinate individuals with multiple properties in an intelligent way, considering that when faced with a task, each according to their characteristics and capabilities plays a specific role with the rest should know how to coexist, with satisfactory results through the union of their attributes, and working together In this work, a proposal for a model of behavior for a robotic agent community, called Multi Agent Robot Society (MARS) capable of leading a diverse community of robots so that they cooperate and collaborate with each other to reach a goal that they have been proposed. The model is based on the theory of Intelligent Agents applied to a community of robots for cooperative and collaborative work geared to community work carried out based on agreements between its members, integrating each robot in the ability of making decisions and solving problems integrating the variables and generated proposals for the community, and then reaching a comprehensive settlement, which is considered the best of a group given by members of the community.	coexist (image);intelligent agent;multi-agent system;requirement;robot	Homero Latorre;Karina Harispe;Renato Salinas;Gaston Lefranc	2010	2010 XXIX International Conference of the Chilean Computer Science Society	10.1109/SCCC.2010.8	simulation;engineering;knowledge management;artificial intelligence	Robotics	-18.880130841479414	-10.791341150945374	29638
a552b12763b9d2cba4ec01bc3a897133f1fad4aa	evolutionary tree-structured storage: concepts, interfaces, and applications		Life is subdued to constant evolution. So is our data, be it in research, business or personal information management. From a natural, evolutionary perspective, our data evolves through a sequence of fine-granular modifications resulting in myriads of states, each describing our data at a given point in time. From a technical, antievolutionary perspective, mainly driven by technological and financial limitations, we treat the modifications as transient commands and only store the latest state of our data. It is surprising that the current approach is to ignore the natural evolution and to willfully forget about the sequence of modifications and therefore the past state. Sticking to this approach causes all kinds of confusion, complexity, and performance issues. Confusion, because we still somehow want to retrieve past state but are not sure how. Complexity, because we must repeatedly work around our own obsolete approaches. Performance issues, because confusion times complexity hurts. It is not surprising, however, that intelligence agencies notoriously try to collect, store, and analyze what the broad public willfully forgets. Significantly faster and cheaper random-access storage is the key driver for a paradigm shift towards remembering the sequence of modifications. We claim that (1) faster storage allows to efficiently and cleverly handle finer-granular modifications and (2) that mandatory versioning elegantly exposes past state, radically simplifies the applications, and effectively lays a solid foundation for backing up, distributing and scaling of our data. This work shows, using the example of treestructured XML, that the characteristics and advantages of the evolutionary approach have been recognized and consistently implemented – something, which on its own is an important achievement. We present the concepts of our evolutionary tree-structured storage TreeTank and the general-purpose SlidingSnapshot to prove that (3) formerly modificationaverse tree encodings can be maintained with logarithmic update complexity, (4) linear read scalability beyond memory limitations is still guaranteed while maintaining logarithmic update characteristics, (5) secure copy-on-write semantics can be extended from the file level to the much finer-granular node level, (6) versioned node-level access is predictable and even realtime-capable, and, that (7) node-level snapshots are as or even more space efficient than page-level or file-level snapshots. In the course of our work, we inspired the Java-based iSCSI implementation jSCSI which proved that (8) high-level language block access is fast and also established the Java benchmark framework PERFIDIX as well as the block touch visualization tool VISIDEFIX. We extend REST, the cornerstone interface of the web, with the ability to access the full version and modification history of a resource and call it (9) Temporal REST. This interface will not only encourage application developers to make use of our evolutionary approach, but it will also foster interactive and collaborative applications because they are, according to our claim (10), less complex to write and performing so well that users can now interactively work with large-scale data. Finally, we provide an outlook on how evolutionary (full-text) indices, applications, and schemas can greatly leverage our contributions and how special-purpose hardware can speed-up our tree-structured storage while using far less energy. Especially our suggested approach to schema handling and evolution has the potential to radically simplify ORM-based software development.	benchmark (computing);complexity;computer performance;copy-on-write;emoticon;evolution;general-purpose modeling;high- and low-level;high-level programming language;iscsi;image scaling;interactivity;interface (java);iterative and incremental development;java;microsoft outlook for mac;nosql;object-relational mapping;personal information management;phylogenetic tree;programming paradigm;random access;scalability;secure copy;software development;software versioning;version control;xml	Marc Kramis	2014				DB	-33.15422213496137	0.3070966773833096	29655
22dbceee742c019455dfc1a65397fe1b8dee1f3a	a reinforcement learning model of joy, distress, hope and fear	reinforcement learning;emotion dynamics;emotion;affective computing	In this paper we computationally study the relation between adaptive behavior and emotion. Using the Reinforcement Learning framework, we propose that learned state utility, V(s), models fear (negative) and hope (positive) based on the fact that both signals are about anticipation of loss or gain. Further, we propose that joy/distress is a signal similar to the error signal. We present agent-based simulation experiments that show that this model replicates psychological and behavioral dynamics of emotion. This work distinguishes itself by assessing the dynamics of emotion in an adaptive agent framework coupling it to the literature on habituation, development, extinction, and hope theory. Our results support the idea that the function of emotion is to provide a complex feedback signal for an organism to adapt its behavior. Our work is relevant for understanding the relation between emotion and adaptation in animals, as well as for human-robot interaction, in particular how emotional signals can be used to communicate between adaptive agents and humans.	adaptive behavior;agent-based model;agent-based social simulation;computation;computational model;distress (novel);experiment;feedback;human–robot interaction;rl (complexity);reinforcement learning	Joost Broekens;Elmer Jacobs;Catholijn M. Jonker	2015	Connect. Sci.	10.1080/09540091.2015.1031081	two-factor theory of emotion;emotion;computer science;artificial intelligence;affective computing;reinforcement learning	AI	-21.832537193228305	-15.747467090436643	29681
feac447ba7a81103bf88637335115b683bd07e96	semivalue versatility and applications	conflictivity;semivalue;regularity;versatility;allocation;political economics;general methods;voting;shapley and banzhaf values	Semivalues are shown to exhibit a capability of modification that enables us to introduce additional information in the evaluation of games. After using a general method to design modified versions of the Shapley and Banzhaf values, we apply them to some political, economic and sociological problems.		Francesc Carreras;Josep Freixas	2002	Annals OR	10.1023/A:1016320723186	mathematical optimization;voting;economics;public economics;mathematical economics;welfare economics	PL	-6.94497798633933	-1.4705928829920758	29708
8c348c7b18f1aba5809e6dc7e25b2e6e5cd5b9a8	lyapunov stochastic stability and control of robust dynamic coalitional games with transferable utilities	allocation rule;transferable utility;time varying;game theory;coalitional games;partial information;game design;control problem;science learning;network flow;stochastic stability	This paper considers a dynamic game with transferable utili ties (TU), where the characteristic function is a continuous-time bounded mean ergodic process . A central planner interacts continuously over time with the players by choosing the instantaneous all oc tions subject to budget constraints. Before the game starts, the central planner knows the nature of the process (bounded mean ergodic), the bounded set from which the coalitions’ values are sample d, and the long run average coalitions’ values. On the other hand, he has no knowledge of the underlyi ng probability function generating the coalitions’ values. Our goal is to find allocation rules t hat use a measure of the extra reward that a coalition has received up to the current time by re-dis tributing the budget among the players. The objective is two-fold: i) guaranteeing convergence of t he average allocations to the core (or a specific point in the core) of the average game, ii) driving th e coalitions’ excesses to anpriori given cone. The resulting allocation rules are robust as they guarantee the aforementioned convergence properties despite the uncertain and time-varying nature o f the coaltions’ values. We highlight three main contributions. First, we design an allocation rule bas ed on full observation of the extra reward so that the average allocation approaches a specific point in the core of the average game, while the coalitions’ excesses converge to an a priori given direction. Second, we design a new allocation rule based on partial observation on the extra reward so that the average allocation converges to the Preliminary conference versions of this work were presente d in Allerton 2010 [5] and CDC 2010 [6]. The authors would like to thank Ehud Leher and Eilon Solan for their support in e xploring connections with approachability and attainabil ity. D. Bauso is with Dipartimento di Ingegneria Chimica, Gestio nale, Informatica e Meccanica, Università di Palermo, Ita ly, email: dario.bauso@unipa.it P.V. Reddy is with GERAD and HEC Montreal, email: viswanadha.puduru@gmail.com T. Başar is with Coordinated Science Laboratory, Universi ty of Illinois at Urbana-Champaign, Urbana, IL, USA, e-mail : basar1@illinois.edu April 24, 2012 DRAFT	baudot code;crc-based framing;characteristic function (convex analysis);converge;email;ergodic process;ergodicity;limbo;lyapunov fractal;polyhedron;robustness (computer science)	Dario Bauso;Puduru Viswanadha Reddy	2011	CoRR		game design;game theory;mathematical optimization;flow network;economics;microeconomics;transferable utility;mathematical economics;welfare economics	Theory	-4.8379322128809354	1.3433221906551513	29709
e93136928eb1373882be8cb04a7e0c4aa91d576b	a collective decision model involving vague concepts and linguistic expressions	semantic similarity;decision models;fuzzy set;computing with words;linguistic expression;complex linguistic evaluations;algorithms artificial intelligence decision support techniques fuzzy logic language linguistics natural language processing pattern recognition automated vocabulary controlled;vague concepts;probability distributions;information technology;logic;statistical distributions computational linguistics formal logic inference mechanisms;inference mechanisms;natural languages;data mining;fuzzy sets natural languages humans logic probability distribution data mining information technology computer science mathematical model concrete;fuzzy sets;semantic similarity collective decision computing with words linguistic evaluation linguistic expression linguistic information fusion;statistical distributions;collective decision;linguistic information fusion;probability distribution;formal logic;mathematical model;humans;information fusion;computational linguistics;computer science;linguistic evaluation;linguistic expressions;semantic similarity relation;concrete;probability distributions collective decision model vague concepts linguistic expressions complex linguistic evaluations semantic similarity relation;collective decision model	In linguistic collective decision, the main objective is to select the best alternatives using linguistic evaluations provided by multiple experts. This paper presents a collective decision model, which is able to deal with complex linguistic evaluations. In this decision model, the linguistic evaluations are represented by linguistic expressions which are the logic formulas obtained by applying logic connectives to the set of basic linguistic labels. The vagueness of each linguistic expression is implicitly captured by a semantic similarity relation rather than a fuzzy set, since each linguistic expression determines a semantic similarity distribution on the set of basic linguistic labels. The basic idea of this collective decision model is to convert the semantic similarity distributions determined by linguistic expressions into probability distributions of the corresponding linguistic expressions. The main advantage of this proposed model is its capability to deal with complex linguistic evaluations and partial semantic overlapping among neighboring linguistic labels.	evaluation;fuzzy set;linguistics;logic programming;logical connective;semantic similarity;vagueness	Yongchuan Tang	2008	IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)	10.1109/TSMCB.2007.913125	natural language processing;probability distribution;deep linguistic processing;computer science;artificial intelligence;computational linguistics;machine learning;mathematics;information technology;statistics	NLP	-5.04367012909605	-23.768192485289497	29736
442db5f64f88fbbb6fe78beeaca00cb118128c92	a computationally intelligent framework for uav forced landings	machine vision;fuzzy systems;classification	2006-Present CSIRO Research Scientist, Aerial Robotics Group, Au tonomous Systems Laboratory, ICT Centre, CSIRO The main objective of the project I am involved wit h s to develop a dependable mini helicopter system for civilian inspection and searc h tasks close to obstacles. These operations are to be performed by one operator, bey ond line of sight, in common airspace and in typical Queensland weather conditio s.	aerial photography;dependability;robotics;unmanned aerial vehicle	Daniel Fitzgerald;Rodney Walker;Duncan A. Campbell	2005			machine learning;speech recognition;computer science;artificial intelligence	Robotics	-32.64475495738253	-19.804436713595912	29761
27b6472115899080bdb5384eba42b84305b6ebe0	verisimilitude: a causal approach	causal strength;philosophy;verisimilitude;scientific realism;scientific progress;language dependence;causation;approximate truth	I present a new definition of verisimilitude, framed in terms of causes. Roughly speaking, according to it a scientific model is approximately true if it captures accurately the strengths of the causes present in any given situation. Against much of the literature, I argue that any satisfactory account of verisimilitude must inevitably restrict its judgments to context-specific models rather than general theories. We may still endorse—and only need—a relativized notion of scientific progress, understood now not as global advance but rather as the mastering of particular problems. This also sheds new light on longstanding difficulties surrounding language-dependence and models committed to false ontologies.	bus mastering;causal filter;ontology (information science);oracle machine;theory	Robert Northcott	2011	Synthese	10.1007/s11229-011-9895-7	scientific realism;causation;philosophy;epistemology;mathematics;scientific progress	AI	-12.176771170100276	3.018862000708496	29762
ac8362bd40b9231351a1135b3ca1287c24d4bb75	exploring the dimensions of convention emergence in multiagent systems	topology;multiagent system;learning algorithm;social learning;search space;articulo;population size;network topology;multi dimensional;network structure;convergence time;conventions;multiagent systems	Social conventions are useful self-sustaining protocols for groups to coordinate behavior without a centralized entity enforcing coordination. The emergence of such conventions in different multi agent network topologies has been investigated by several researchers, although exploring only specific cases of the convention emergence process. In this work we will provide multi-dimensional analysis of several factors that we believe determines the process of convention emergence, such as: the size of agents memory, the population size and structure, the learning approach taken by agents, the amount of players in the interactions, or the convention search space dimension. Although we will perform an exhaustive study of different network structures, we are concerned that different topologies will affect the emergence in different ways. Therefore, the main research question in this work is comparing and studying effects of different topologies on the emergence of social conventions. While others have investigated memory for learning algorithms, the effects of memory on the reward have not been investigated thoroughly. We propose a reward metric that is derived directly from the history of the interacting agents. Another research question to be answered is what effect does the history based reward function and the learning approach have on convergence time in different topologies. Experimental results show that all the factors analyzed affect differently the convention emergence process, being such information very useful for policy-makers when designing self-regulated systems.	agent-based model;algorithm;centralized computing;concordance (publishing);converge;emergence;experiment;interaction;interconnection;machine learning;modality (human–computer interaction);multi-agent system;network topology;population;rate of convergence;real life;reinforcement learning	Daniel Villatoro;Sandip Sen;Jordi Sabater-Mir	2011	Advances in Complex Systems	10.1142/S0219525911003013	social learning;population size;simulation;computer science;knowledge management;artificial intelligence;machine learning;multi-agent system;network topology	AI	-16.428711431006597	-13.685009207923022	29797
ca9d825daddc76d1cf84ea2809809cd52c43573e	application of a hybrid case-based reasoning approach in electroplating industry	case base reasoning;performance of systems;decision maker;artificial intelligent;fuzzy logic;artificial intelligence;profitability;case based reasoning;electroplating industry;quick response;article;rule based reasoning	Case-Based Reasoning (CBR), a well known Artificial Intelligence (AI) technique, has already proven its effectiveness in numerous industries. In this research, we try to adopt CBR technique in electroplating industry where the final products are electroplated accessory of watches. In order to ensure sufficient profit margin for electroplating manufacturer, it is important to grasp the coating weight of electroplating component accurately so that salespersons can make sure their quotation prices cover the precious metal cost. Apart from quotation accuracy, responsiveness is also a critical competitive edge in electroplating industry. In this connection, developing a quick response decision-making system with considerably reliable price is what electroplating industry needs. To cope with this problem, a hybrid CBR system combined with Rule-based Reasoning (RBR) and Fuzzy Logic (FL) concepts is established. Such system is capable to convert knowledge from experienced staff; simulate the 'mind-set' of decision maker in solving problem through acquisition of specific knowledge and experience; and build up self-learning characteristics. Moreover, this research interprets cases as some objective selection rules, putting CBR in a position much closer to RBR. This innovative concept differentiates from previous CBR researcher work, and will be explained through a practical example. Further, this research also suggested that it is very difficult and not practical to develop a pure CBR system. Applying some subjective guiding rules in CBR can significantly improve the performance of system in the early learning stage.		Felix T. S. Chan	2005	Expert Syst. Appl.	10.1016/j.eswa.2005.01.010	fuzzy logic;rule-based system;case-based reasoning;computer science;artificial intelligence;machine learning;operations research	AI	-5.800014703505147	-14.461755732193772	29834
25efe1830515da1867b490c231a5bfb14a81f49d	argumentation-based agent interaction in an ambient-intelligence context	sensibilidad contexto;argumentacion;agent interaction;multiagent system;argumentation;context aware;argumentation based dialogue;agent dialogues;ambient intelligence;pervasive computing;distributed decision making process;ambient intelligence system;mobility impaired users;intelligence artificielle;argumentation based agent interaction;distributed decision making multiagent systems intelligent agents argumentation ambient intelligence agent dialogues;informatica difusa;multi agent systems;for intelligent physical agents;handicapped aids;intelligent agents;multi agent systems decision making handicapped aids knowledge based systems mobile computing;distributed decision making;informatique diffuse;intelligent agent;artificial intelligence;interaction protocol;inteligencia artificial;wheelchairs context aware services ambient intelligence distributed decision making transportation heart technology planning monitoring intserv networks research initiatives;sensibilite contexte;sistema multiagente;knowledge based services;mobile computing;intelligent physical agents interaction protocol;knowledge based systems;systeme multiagent;multiagent systems;intelligent physical agents interaction protocol argumentation based agent interaction ambient intelligence system multiagent system knowledge based services mobility impaired users distributed decision making process argumentation based dialogue;knowledge base;integrated services	A multiagent system uses argumentation-based interaction in an ambient-intelligence context to provide services for people with different combinations of impairments. This paper focuses on ambient intelligence system of agents for knowledge-based and integrated services for mobility-impaired users integrated projectpsilas (ASK-ITIP) furthered the challenge by aiming to support users having different types and combinations of impairments. ASK-ITIP use of argumentation to model a distributed decision-making process for a coalition of assistant agents, each an expert on a different impairment. When a user suffers from a combination of impairments, these agents engage in an argumentation-based dialogue to agree on the user's needs. We found that applying argumentation was natural in this context because, generally speaking, we can abstractly define argumentation as the principled interaction of different, potentially conflicting arguments to obtain a consistent conclusion. Moreover, argumentation-based interaction is combined with a standardized interaction type based on the foundation for intelligent physical agents interaction protocol.	agent architecture;agent-based model;ambient intelligence;amplitude-shift keying;high-level programming language;integrated services;interaction protocol;multi-agent system;prototype;theory	Pavlos Moraitis;Nikolaos I. Spanoudakis	2007	IEEE Intelligent Systems	10.1109/MIS.2007.101	ambient intelligence;computer science;knowledge management;artificial intelligence;multi-agent system;integrated services;intelligent agent	AI	-23.911822227897922	-9.186602712356878	29842
1e7de01809361a352a78f14ac7f056e1adc3b363	contribution of fuzzy reasoning method to knowledge integration in a defect recognition system	orm model;vision system;modelizacion;lenguaje natural;regle inference;wood;hierarchical structure;symbolic computation;vision ordenador;sistema experto;fuzzy reasoning;systeme vision;ingenierie connaissances;hierarchized structure;structure arborescente;metodo arborescente;logique floue;langage naturel;logica difusa;structure hierarchisee;computer vision;calculo simbolico;fuzzy logic;inference rule;bois;modelisation;fuzzy rule base;detection defaut;numerical model;estructura arborescente;natural language;tree structure;niam method;pattern recognition;tree structured method;vision ordinateur;peritaje;knowledge integration;expert knowledge;methode arborescente;reconnaissance forme;expertise;systeme expert;reconocimiento patron;modeling;madera;information analysis;calcul symbolique;deteccion imperfeccion;estructura jerarquizada;sistema vision;defect detection;regla inferencia;expert system;knowledge engineering	This article presents the improvement of a defect recognition system for wooden boards by using knowledge integration from two expert fields. These two kinds of knowledge to integrate respectively concern wood expertise and industrial vision expertise. First of all, extraction, modelling and integration of knowledge use the Natural Language Information Analysis method (NIAM) to be formalized from their natural language expression. Then, to improve a classical industrial vision system , we propose to use the resulting symbolic model of knowledge to partially build a numeric model of wood defect recognition. This model is created according to a tree structure where each inference engine is a fuzzy rule based inference system. The expert knowledge model previously obtained is used to configure each node of the resulting hierarchical structure. The practical results we obtained in industrial conditions show the efficiency of such an approach.	knowledge integration;software bug	Vincent Bombardier;Cyril Mazaud;Pascal Lhoste;Raphaël Vogrig	2007	Computers in Industry	10.1016/j.compind.2006.07.006	fuzzy logic;legal expert system;symbolic computation;systems modeling;knowledge integration;computer science;artificial intelligence;knowledge-based systems;machine learning;wood;knowledge engineering;tree structure;natural language;data analysis;expert system;algorithm;rule of inference	AI	-22.495611406186857	-3.285859119240906	29865
c22b18e7e1d9c332867c4c29b1b7bcfb0128fd09	a social network based group decision support system	trustworthy decisions;internet agents;group decisions;dss;group decision support systems;social networks;cbr;delphi method;collective intelligence;casebase reasoning	Decision-making is a cognitive mental process which selects certain actions among several alternatives for a specific problem. This research provides a social network-based group decision model which accounts for collective intelligence. This work considers peers from a user’s social network as experts in the group decision-making process and each peer has its own internet agent. The purpose is to conduct a virtual group decision-making process over the internet at anytime. Each agent can reason by enabling the case-based reasoning approach and discuss by the proposed decision model. The proposed approach attempts to improve efficiency and effectiveness for a quality decision, which is extremely critical and crucial. This work also designed a system which • empowers collective intelligence from a social network • enhances trustworthy group decisions of the social network • ensures heterogeneity of selected experts • diminishes the domination of certain experts.	anytime algorithm;case-based reasoning;collective intelligence;decision support system;dominating set;social network;trust (emotion)	Wei-Lun Chang;Yi-Ping Lo	2012	IJMC	10.1504/IJMC.2012.044522	decision support system;delphi method;computer science;knowledge management;management science;collective intelligence;computer security;social network	Web+IR	-11.875708105105199	-11.765985093189588	29868
5a0415cf63ec00d562ecc9487de1bf2863c32729	a probabilistic analysis of marker-passing techniques for plan recognition	plan recognition;of naval research;probabilistic analysis;national science foundation	Useless paths are a chronic problem for marker-passing techniques. We use a prob­ abilistic analysis to justify a method for quickly identifying and rejecting useless paths. Using the same analysis, we identify key conditions and assumptions necessary for marker-passing to perform well.	probabilistic analysis of algorithms;spreading activation	Glenn Carroll;Eugene Charniak	1991		10.1016/B978-1-55860-203-8.50012-7	probabilistic analysis of algorithms;computer science;artificial intelligence;data mining;operations research	SE	-19.814440467184472	-3.9612496219860014	29892
7d41226d04af1c4fed47b4f1f92f727008d65551	simultaneous processing of multi-skyline queries with mapreduce		With rapid increase of the number of applications as well as the sizes of data, multi-query processing on the MapReduce framework has gained much attention. Meanwhile, there have been much interest in skyline query processing due to its power of multi-criteria decision making and analysis. Recently, there have been attempts to optimize multi-query processing in MapReduce. However, they are not appropriate to process multiple skyline queries efficiently and they also require modifications of the Hadoop internals. In this paper, we propose an efficient method for processing multi-skyline queries with MapReduce without any modification of the Hadoop internals. Through various experiments, we show that our approach outperforms previous studies by orders of magnitude. key words: multi-query processing, skyline query, MapReduce framework	apache hadoop;database;experiment;mapreduce;pareto efficiency	Junsu Kim;Kyong-Ha Lee;Myoung-Ho Kim	2017	IEICE Transactions		web search query;query expansion;computer science;skyline;database;query optimization	DB	-28.212801926194	2.5041954282287335	29911
1c7fbf3abf6c97d2b9d534d22e31452bc5499fa7	soccer server: a tool for research on multiagent systems	multiagent system;multi agent system;artificial intelligent	This paper describes Soccer Server, a simulator of the game of soccer designed as a test-bench for evaluating multi-agent systems and cooperative algorithms. In real life, successful soccer teams require many qualities, such as basic ball control skills, the ability to carry out plans, and teamwork. We believe that simulating such behaviors is a signi cant challenge for Computer Science, Arti cial Intelligence and Robotics technologies. It is to promote the development of such technologies, and to help de ne a new standard problem for research, that we have developed Soccer Server. We demonstrate the potential of Soccer Server by reporting an experiment that uses the system to compare the performance of a neural network architecture and a decision tree algorithm at learning the selection of soccer play-plans. Other researchers using Soccer Server to investigate the nature of cooperative behavior in a multi-agent environment will have the chance to assess their progress at RoboCup-97, an international competition of robotic soccer to be held in conjunction with IJCAI-97. Soccer Server has been chosen as the o cial server for this contest.	agent-based model;algorithm;artificial neural network;computer science;decision tree;experiment;list of algorithms;multi-agent system;network architecture;real life;robot;robotics;server (computing);simulation	Itsuki Noda;Hitoshi Matsubara;Kazuo Hiraki;Ian Frank	1998	Applied Artificial Intelligence	10.1080/088395198117848	simulation;computer science;artificial intelligence;multi-agent system;multimedia	AI	-30.303518521827996	-19.93541496876044	30029
ee46b66280a80e85968a5cdcd193573cb5b57c72	solution uniqueness in a class of currency crisis games	choquet expected utility;expected utility;330 wirtschaft;non additive product measure;nash equilibria;uniqueness theorem;currency crisis;unique equilibria;knightian uncertainty;decision under uncertainty;rational choice;games of incomplete information;global games;current crisis;incomplete information game;capacity;global game;speculative attack;multiple equilibria	A common feature of many speculative attack models on currencies is the existence of multiple equilibrium solutions. When choosing the equilibrium strategy, a trader faces Knightian uncertainty about the rational choice of the other traders. We show that the concept of Choquet expected utility maximization under Knightian uncertainty leads to unique equilibria. In games of incomplete information the optimal strategy maximizes the expected utility with respect to a two-dimensional information: environment and rationality. We define a new concept of equilibria, the Choquet-expected-Nash-equilibria, which allows the analysis of decisions under uncertainty, which result in multiple equilibria in standard analysis.We provide uniqueness theorems for a wide class of incomplete information games including global games and apply them to fairly general currency attack models. The uniqueness of the equilibrium remains valid for arbitrary noise distributions, positively correlated signals, the existence of large traders, individual payoff functions, and for the case that non attacking traders suffer a loss in case of a successful attack, as is the case for investors in the attacked country.		Christian Bauer	2005	IGTR	10.1142/S0219198905000697	financial economics;economics;microeconomics;mathematical economics;global game;welfare economics;rational choice theory	ECom	-4.5730601609065396	-2.2258718495117455	30037
733736e42ec0d1c408fb0bb06c9b8aa4915dc074	the emergence and evolution of openstreetmap: a cellular automata approach	collaborative contributing;openstreetmap;transition rules;spatiotemporal analysis;cellular automata	Taylor & Francis makes every effort to ensure the accuracy of all the information (the “Content”) contained in the publications on our platform. However, Taylor & Francis, our agents, and our licensors make no representations or warranties whatsoever as to the accuracy, completeness, or suitability for any purpose of the Content. Any opinions and views expressed in this publication are the opinions and views of the authors, and are not the views of or endorsed by Taylor & Francis. The accuracy of the Content should not be relied upon and should be independently verified with primary sources of information. Taylor and Francis shall not be liable for any losses, actions, claims, proceedings, demands, costs, expenses, damages, and other liabilities whatsoever or howsoever caused arising directly or indirectly in connection with, in relation to or arising out of the use of the Content.	automata theory;cellular automaton;emergence;francis;openstreetmap;primary source	Jamal Jokar Arsanjani;Marco Helbich;Mohamed Bakillah;Lukas Loos	2015	Int. J. Digital Earth	10.1080/17538947.2013.847125	cellular automaton;geography;computer science;artificial intelligence;operations research	Robotics	-15.008503535776489	-6.093221111730795	30077
b0846ac49e0de7115d61097bdbf5611c2db565f8	geospatial decision support systems: use of criteria based spatial layers for decision support in monitoring of operations		This paper brings out a conceptual approach for geospatial analysis for decision making process while monitoring operations. It capitulates on the ability of GDSS to support GIS layers. The decisions, decision making processes and the time involved are all broken down to a function of criteria over a set of information. This information is recommended to be stored in layers in special criteria based spatial form which reduces the processing requirements to simple manipulation of specific independent layers. This enables incremental decisions based on adequate set of data as and when required, which is akin to anytime algorithm. The human and machine analyses are integrated in a geo-visual analytical model. A case study of evacuation of an injured person from a mine using helicopter is presented. In this example all advantages of the concept are proven.	decision support system	Shanmugavelan Velan	2014		10.1007/978-3-319-13817-6_38	decision support system;intelligent decision support system;knowledge management;data mining;management science	DB	-31.70823492659006	-7.814552623759636	30101
773c37953b635f37c5d659896d4654ae9bd499c8	simple urban simulation atop complicated models: multi-scale equation-free computing of sprawl using geographic automata	high performance computing;geosimulation;agent based model;complexity;coarse projective integration;urban simulation;equation free	Reconciling competing desires to build urban models that can be simple and complicated is something of a grand challenge for urban simulation. It also prompts difficulties in many urban policy situations, such as urban sprawl, where simple, actionable ideas may need to be considered in the context of the messily complex and complicated urban processes and phenomena that work within cities. In this paper, we present a novel architecture for achieving both simple and complicated realizations of urban sprawl in simulation. Fine-scale simulations of sprawl geography are run using geographic automata to represent the geographical drivers of sprawl in intricate detail and over fine resolutions of space and time. We use Equation-Free computing to deploy population as a coarse observable of sprawl, which can be leveraged to run automata-based models as short-burst experiments within a meta-simulation framework.	automata theory;automaton;experiment;geography markup language;grand challenges;observable;simulation;urban computing	Paul M. Torrens;Ioannis G. Kevrekidis;Roger G. Ghanem;Yu Zou	2013	Entropy	10.3390/e15072606	supercomputer;complexity;simulation	HCI	-16.52719850480277	-21.04316571730295	30104
1f74b9cd034c6813881037794e3623e4fdcf8d72	an efficient information sharing approach for large scale multi-agent team	distributed processing;scale free network;information sharing;network topology;large scale;multi agent systems;team network topology information sharing large scale multiagent team;team network topology;multi agent systems distributed processing;large scale multiagent team	Effective communication among agents in large teams is crucial because the members share a common goal but only have a partial views of the environment. Information sharing is difficult in a large team because, a team member may have a piece of valuable information but not know who needs the information, since it is infeasible to know what each other agent is doing. Although much related work has been done on efficient delivery of information, most work is based on assumptions which are not suited to large scale multiagent teams. In this paper, we made two contributions. Firstly, we present a solution to sharing information that is applicable to large teams based on previous research. A key to the solution is imposing a static network topology on the members of the team where each agent requiring communication to be only along very few links in that network. The key observation underlying this solution is that each piece of information is interrelated and the sender of a piece of information can ldquoguessrdquo who might need some information based on previously sent messages. Thus, when an agent has a piece of information, it can determine which of its neighbors in the network is most likely to either need the information or know who does, based on related messages previously received. Secondly, we investigate the influence of different types of team network topology on the efficiency of information sharing. Our results show that our algorithm works with various topologies but gets the best performance on a scale free network.	agent-based model;algorithm;experiment;information exchange;multi-agent system;network topology;social network	Michael Lewis;Katia P. Sycara;Paul Scerri	2008	2008 11th International Conference on Information Fusion		simulation;engineering;knowledge management;distributed computing	AI	-16.49868463773652	-9.960607299184803	30165
65d6ddabb9d53ed614f624f8f660582f2fab6a85	semantic xml views based on geographical context	document handling;measurement;set partitions;query processing;data processing;indexing terms;context xml parallel processing measurement instruction sets partitioning algorithms buildings;scaling up;xml document handling electronic data interchange geographic information systems multiprocessing systems parallel processing query processing;parallelism;geographic information systems;xml;xml document;xml documents semantic xml views geographical context data exchange data storage multiprocessor systems multicore systems xml data processing parallel processing;multiprocessing systems;context;parallel processing;buildings;multi core;electronic data interchange;spatial information;multi core xml context parallelism;partitioning algorithms;instruction sets	XML has become a standard for the storage and exchange of data. The widespread use of XML has made queries executed over related, but distinct, XML data sources increasingly relevant. With the growing popularity of XML a wide variety of schemas may be applied to each document. In particular XML data that describes geographical/spatial information often needs to deal with a large number of complex elements and yet, during access and retrieval only a particular set of relevant information -- such as a local area -- is required. For this reason, we must search for ways to increase the performance of data processing and access. Parallelism is an attractive way in which to achieve this aim. With multi-processor or multi-core systems becoming the standard, the idea of parallelism is emerging as a significantly important concept. Methods for XML data processing have been designed and implemented with varying degrees of success. However, these approaches deliver datasets that can contain irrelevant information for the purposes of the user as they do not take the context into account while parsing. This can result in a decrease in the efficiency of the traversal of the data sets when querying. As such, this paper presents a framework the parallel processing of XML documents with a geographical context to filter and group spatial information. In this paper we propose an algorithm and a possible system implementation and identify a potential scale-up methodology.	algorithm;effective method;multi-core processor;multiprocessing;parallel computing;parsing;relevance;tree traversal;xml database	David J. Rogan;J. Wenny Rahayu	2011	2011 International Conference on Complex, Intelligent, and Software Intensive Systems	10.1109/CISIS.2011.34	well-formed document;xml validation;binary xml;xml schema;computer science;xml framework;data mining;xml database;xml schema;database;xml signature;xml schema editor;information retrieval;efficient xml interchange	DB	-29.851323384100386	1.9665598801613455	30211
a01e08d465678afa88b5786a8a3b020a101d4e4a	use of active disassembly technology to improve remanufacturing productivity: automotive application	active disassembly technology;ad;active disassembly;engineering design;environmental impact;end of life;automotive application;dfrem;interstitial layer;disassembly;adsm;profitability;remanufacturing productivity;il;electronic products;remanufacturing;productivity;electronic control unit;ad il;new products	Taylor & Francis makes every effort to ensure the accuracy of all the information (the “Content”) contained in the publications on our platform. However, Taylor & Francis, our agents, and our licensors make no representations or warranties whatsoever as to the accuracy, completeness, or suitability for any purpose of the Content. Any opinions and views expressed in this publication are the opinions and views of the authors, and are not the views of or endorsed by Taylor & Francis. The accuracy of the Content should not be relied upon and should be independently verified with primary sources of information. Taylor and Francis shall not be liable for any losses, actions, claims, proceedings, demands, costs, expenses, damages, and other liabilities whatsoever or howsoever caused arising directly or indirectly in connection with, in relation to or arising out of the use of the Content.	disassembler;francis;primary source	J. D. Chiodo;W. L. Ijomah	2014	Int. J. Computer Integrated Manufacturing	10.1080/0951192X.2012.667151	disassembler;electronic control unit;productivity;computer science;engineering;operations management;automotive engineering;active disassembly;engineering design process;profitability index;environmental impact assessment;manufacturing engineering;mechanical engineering	Robotics	-15.389603739782638	-4.541233873922676	30267
a3c86d53f71922363aaeb07a75b77f72543f35b1	savvy software agents can encourage the use of second-order theory of mind by negotiators		In social settings, people often reason about unobservable mental content of other people, such as their beliefs, goals, or intentions. This ability helps them to understand and predict the behavior of others. People can even take this ability further, and use higher-order theory of mind to reason about the way others use theory of mind, for example in ’Alice believes that Bob does not know about the surprise’. However, empirical evidence suggests that people do not spontaneously use higher-order theory of mind in strategic games. In this paper, we let participants negotiate with computational theory of mind agents in the setting of Colored Trails. We find that even though participants are unaware of the level of sophistication of their trading partner, within a few rounds of play, participants offers are more indicative of second-order theory of mind reasoning when their trading partner was using second-order theory of mind as well.	computational theory of mind;software agent;theory of computation	Harmen de Weerd;Eveline Broers;Rineke Verbrugge	2015			social psychology;sophistication;psychology;surprise;computational theory of mind;knowledge management;theory of mind;software agent;unobservable;empirical evidence;negotiation	HCI	-14.892573923485411	-11.81646808806807	30294
d8267535d52492e28892ea09c8773c62e42453da	an efficient algorithm for computing range-groupby queries	tratamiento datos;tiempo respuesta;reponse temporelle;base dato multidimensional;data cube;base donnee;range query;grouping;analisis datos;cube;geometrie algorithmique;on line;efficient algorithm;en linea;cubo;interrogation base donnee;computational geometry;database;interrogacion base datos;base dato;data processing;response time;traitement donnee;multidimensional database;temps reponse;busquedas dentro de un rango;data analysis;requete a intervalle;time response;data cubes;analyse donnee;prefix sum arrays;geometria computacional;en ligne;range groupby queries;base donnee multidimensionnelle;agrupamiento;respuesta temporal;database query;groupage;aggregation queries	Aggregation queries for arbitrary regions in an n-dimensional space are powerful tools for data analysis in OLAP. A GROUP BY query in OLAP is very important since it allows us to summarize various trends along with any combination of dimensions. In this paper, we extend the previous aggregation queries by including the GROUP BY clause for arbitrary regions. We call the extension range-groupby queries and present an efficient algorithm for processing them. A typical method of achieving fast response time for aggregation queries is using the prefix-sum array, which stores precomputed partial aggregation values. A naive method for range-groupby queries maintains a prefix-sum array for each combination of the grouping dimensions in an n-dimensional cube, which incurs enormous storage overhead. Our algorithm maintains only one prefix-sum array and still effectively processes range-groupby queries for all possible combinations of multiple grouping dimensions. Compared with the naive method, our algorithm reduces the space overhead by O( 1 2n ), while accessing almost the identical number of cells.	algorithm;data cube;online analytical processing;overhead (computing);precomputation;prefix sum;requirement;response time (technology);xslt/muenchian grouping	Young-Koo Lee;Woong-Kee Loh;Yang-Sae Moon;Kyu-Young Whang;Il-Yeol Song	2006		10.1007/11733836_34	data processing;computational geometry;computer science;data mining;database;algorithm;data cube	DB	-27.17633723635141	3.36506366705339	30414
002f95e40ec7c861cab0712e795b9e921cbc454d	quantitative approaches to representing the value of information within the intelligence cycle	intelligence studies education;value of intelligence;intelligence analysis;value of information	The combination of the burgeoning interest in efficient and reliable Health Systems and the advent of the Information Age represent both a challenge and an opportunity for new paradigms and cutting-edge technologies reaching a certain degree of maturity. Hence, the use of Semantic Technologies for Automated Diagnosis could leverage the potential of current solutions by providing inference-based knowledge and support on decision-making. This paper presents the ADONIS approach, which harnesses the use of ontologies and the underlying logical mechanisms to automate diagnosis and provide significant quality results in its evaluation on real-world data scenarios. medical knowledge (Liu et al., 2009). Since many artificial intelligence approaches have dealt with the diagnosis problem and its application in complex environments such as medical domains (Fuentes-Lorenzo et al., 2009), semantic technologies can provide a strong cutting-edge baseline for knowledge-oriented medical diagnosis systems. The semantic DOI: 10.4018/jdsst.2011010102 22 International Journal of Decision Support System Technology, 3(1), 21-39, January-March 2011 Copyright © 2011, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited. technologies (Berners-Lee et al., 2001), which have been developed and improved alongside the advancement of the Semantic Web, can be exploited to reveal machine-readable latent relationships within specific diagnostic-related information in the medical discipline, where the homogeneity of terminology is particularly problematic (Fuentes-Lorenzo et al., 2009). The specification of the domain knowledge (in our case, the medical domain) by the use of ontologies (Fensel, 2002) provides a knowledge-based system with the opportunity of adding the semantics of the domain, stating an explicit conceptual description of the domain (Fuentes-Lorenzo et al., 2009). However, the efficiency and soundness of Semantic descriptions must be backed up by their underlying logic. The lattice of logic languages and formalisms is not a trivial issue and hence, an ontology must be perfectly defined and explained to serve as a basis for real-world medical applications. For this reason, an accurate and checked ontology should be defined in order to create a base for the medical diagnosis systems. Also, the description of the diseases, symptoms, laboratory tests and other clinical parameters should be done with rigor and checked by medical doctors. This description is the problem presented in the most of actual software for clinical diagnosis where not all the possibilities are taken into account, because in some cases this software are not able to make the correct inference of the disease. This paper presents ADONIS, an architecture that includes a well-structured ontology for automated diagnosis and a three-fold formalization based on Description Logic that will allow to future medical systems that implements these techniques to perform real and more accurate diagnosis that traditional and actual systems. The remainder of the paper is organized as follows. Section 2 outlines related research in the area. In Section 3, the architecture for the ADONIS approach is presented, which demonstrates technological support and potential solutions for problems in current medical diagnosis based in semantics and logical descriptions. An evaluation using calculation of precision and recall rates of the system is also presented in section 4. Conclusions and future work are discussed in Section 5.	artificial intelligence;backup;baseline (configuration management);capability maturity model;decision support system;description logic;experiment;granular computing;human-readable medium;knowledge-based systems;ontology (information science);precision and recall;semantic web	Christopher M. Smith;William T. Scherer;Andrew Todd;Daniel T. Maxwell	2015	IJSDS	10.4018/IJSDS.2015100101	intelligence cycle;intelligence analysis;influence diagram;marketing and artificial intelligence;economics;words of estimative probability;computer science;knowledge management;artificial intelligence;operations management;machine learning;value of information;data mining;military intelligence;management science;expected value of perfect information;management;operations research	AI	-29.42617033645158	-8.32319833092288	30435
2f5c3b2b74ce600daba83631d605f2bc25ddecab	plurality, borda count, or anti-plurality: regress convergence phenomenon in the procedural choice		We focus on voters’ preference profiles where at least two of the three selected voting rules (e.g. plurality, Borda count, and anti-plurality) produce different outcomes—thus, the voting body needs a procedural choice. While this situation evokes an infinite regress argument for the choice of rules to choose rules to choose rules to…and so on, we introduce a new concept named regress convergence, where every voting rule in the menu ultimately gives the same outcome within the finite steps of regress. We study the mechanism of this phenomenon in a large consequential society having a triplet of scoring rules. The results show that, in the menu of plurality, Borda count, and anti-plurality, the probability that the regress convergence happens is 98.2% under the Impartial Culture assumption and 98.8% under the Impartial Anonymous Culture assumption.		Takahiro Suzuki;Masahide Horita	2016		10.1007/978-3-319-52624-9_4	mathematics;mathematical economics;social psychology;welfare economics	ECom	-8.481135932986746	-2.750325082411688	30447
ee9f19d1e30aee86253bdf5c1305e5906de16a39	the scope of dimensional analysis in qualitative reasoning	representation;critical study;connaissance;coaccion;contrainte;dimensional analysis;intelligence artificielle;conocimiento;raisonnement qualitatif;etude critique;raisonnement;analyse;estudio critico;knowledge;constraint;ecuacion;analyse dimensionnelle;razonamiento;analisis dimensional;artificial intelligence;analysis;inteligencia artificial;qualitative reasoning;reasoning;equation;comparative statics;representacion;analisis	Dimensional analysis, traditionally used in physics and engineering to identify quantitative relationships, has recently been applied to qualitative reasoning of physical systems. We illustrate some problems of this approach. In the light of this, we reexamine the fundamentals of dimensional analysis in order to more precisely characterize its scope and limitations as a tool in qualitative reasoning. We also explore its relationship to state equation representations of physical systems. In particular, we describe its value in providing a set of constraints to reduce the ambiguity that bedevils qualitative reasoning schemes. We argue that dimensional analysis should not be seen as a substitute for knowledge about the physics but rather a supplement to other sources of knowledge.		Jayant Kalagnanam;Max Henrion;Eswaran Subrahmanian	1994	Computational Intelligence	10.1111/j.1467-8640.1994.tb00160.x	qualitative reasoning;artificial intelligence;analysis;algorithm	AI	-23.244606169232224	-3.013390265959386	30493
30b4f6b38a30722c59ba0625f725cd0cdf0a1bc4	gaps and bridges: new directions in planning and natural language generation (workshop report)		Imagine yourself in a situation where you need to operate a washing machine, but you happen to be in a country whose language you don't speak and moreover, all the signs and instructions around you are written in characters that do not resemble any of those you have learnt at school. However, somehow you manage to communicate your problem to your neighbour, who also manages to communicate relevant information back to you, and at the end you both can congratulate yourselves for a successful task ful llment (and for a bit of luck too). Although these kind of situations are extreme cases, they actually force us to look at language and its use in a speci c way: linguistic knowledge is by no means enough for successful communication. It isn't even always necessary, although it certainly eases the transfer of information. Instead, we become aware of two other important aspects of communication: strategic planning, which is prior to and independent of language, and creative use of the limited linguistic resources available. Recent research on autonomous cooperative systems has brought similar aspects of communication and conversational agents into the focus of planning studies: rational agency [2], con ict resolution [3] and resource-bounded agency [1] have become central issues within this larger framework. There has also been a focus shift in NLG from the study of wellformedness conditions (grammars) to the exploration of communicative adequacy of linguistic forms: speaking is viewed as an indirect means for achieving communicative goals rather than an exercise to produce grammatically correct output. However, despite a growing awareness of the importance of these factors, there is still relatively little work on connecting these aspects to surface generation and to develop a computational model that integrates these components into a uni ed whole. In order to improve this situation at least four gaps have to be bridged. The rst gap can be termed an interaction gap, referring	autonomous robot;computational model;consensus dynamics;dialog system;naruto shippuden: clash of ninja revolution 3;natural language generation;washing machine	Kristiina Jokinen;Mark T. Maybury;Michael Zock;Ingrid Zukerman	1997	AI Magazine			NLP	-27.789259247166015	-17.91472646136407	30610
47e71deea7b62e9998e34a9038093097df56f327	on the coincidence property	shapley value nucleolus coincidence property sp region st region 2 game ps game simple game;satisfiability;shapley value;convex cone;simple game	The collection of the coalitions b is balanced if the Shapley value of the simple game [chi]b is 0. This observation makes us able to derive a class of simple games with the coincidence property, that is, the Shapley value and the nucleolus coincide. And then we use such a class of simple games as generators to construct coincidence regions, convex cones consisting of games with the coincidence property. We will first propose the SP region. Two sets of games satisfying the coincidence property are introduced. Both are SP regions. In fact, the SP regions do not cover all games satisfying the coincidence property even for 3-person case. To enlarge the class of games with the coincidence property, the ST regions are proposed. All 3-person games with the coincidence property can be classified into 4 ST regions.		Chih Chang;Ying-Chih Tseng	2011	Games and Economic Behavior	10.1016/j.geb.2010.04.010	bondareva–shapley theorem;mathematical optimization;convex cone;mathematics;shapley value;mathematical economics;satisfiability	ECom	-6.132192307134562	-0.35960929014464127	30630
c6f323f59ba81e9c282f1546eecbc2f5aa2130d5	autonomous seller agent for multiple simultaneous english auctions	selling algorithm;online auction;re auction;seller strategy;auction theory;reserve price;english auction;seller agent;heuristic approach;risk type seller	"""The growth of online auction is due to the flexibility and convenience that it offers to consumers. In the context of online auction, deriving the best reserve price can be associated to the seller’s optimization problem. Determining this reserve price is not straightforward due to the dynamic and unpredictable nature of the auction environment. Setting the price too high will lead to the possibility of no sale outcome. Putting the price too low may produce a sale with less profit due to its lower selling price. The authors propose a strategy to derive the best reserve price based on several selling constraints such as the number of competitors (sellers), the number of bidders, the auction duration, and the profit the seller desired when offering an item to be auctioned. However, to obtain the best performance, the strategy must be tuned to the prevailing auction environment where the agent is situated. This paper describes the seller agent’s performance under varying auction environments. The purpose of the experimental evaluation is to assess the ability of the agent to identify its environments accurately to enable it to come up with the best reserve price. DOI: 10.4018/jats.2012040101 2 International Journal of Agent Technologies and Systems, 4(2), 1-21, April-June 2012 Copyright © 2012, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited. to USD14.7 billion excluding vehicles (http:// investor.ebayinc.com). There are four single-object auction types which are widely used and analyzed both theoretically and practically within the context of auction literature (Wurman, 2001). This includes the ascending-price auction (English auction), the descending-price auction (Dutch auction), the first-price sealed-bid auction, and the second-price sealed-bid auction (Vickrey auction). A single-object auction can be also held using different formats based on its different rules of games. The selling format includes the no reserve price auction (no reserve price for the item), the public reserve price auction (the price is publicly announced), the private reserve price auction (the price is not announced) and the buy it now auction (the item can be sold at a known fixed price). In this context, reserve price is defined as the smallest price at which a seller is willing to sell a good or service. Keeping the reserve price secret is a way of restoring the linkage of price paid to the purchased object by inducting a greater participation, thereby increasing the sellers’ profit (Vincent, 1995). Mathematically, this result is consistent with findings from McAfee and MacMillan (1987a) which indicated that maintaining the price uncertainty among the bidders will result in the increase of the seller’s profit. In many auctions, sellers will typically use the secret reserve price in their auctions and this phenomenon has been documented by several authors (Ashenfelter, 1989; Hendricks, Porter, & Wilson, 1994; Elyakime, Laffont, Loisel, & Vuong, 1994). The widespread nature of Internet auctions has invited a rich subject of study with respect to the goods exchange mechanisms (LuckingRiley, 1999). To date, auction has been used as a form of price discovery. In online auctions, the seller’s main problem is to choose the best reserve price, or acceptance rule, during each round of auction (Grant, Kajii, Menezes, & Ryan, 2006). Setting a high price may not result in a sale, whilst setting a low price may result in the item being sold at an unsatisfactorily low price (Law & Anthony, 2007). In cases when the item is auctioned off, the profit the sellers obtained is incredibly low and is way below the market price. For this reason, a great deal of attention has been devoted in deciding and setting the reserve price for use in online auction settings such as in Harris and Raviv (1981), Maskin and Riley (1980), Steven (1979), and Riley and Samuelson (1981). Several critical issues must be considered when sellers offer an item to be auctioned. At any point in time, there are multiple auctions that are selling the same item simultaneously. They may organize their auctions using different selling choices with different start bid price, reserve price, and also the selling duration. Also, bidders tend to appear in a random arrival process with varying bidding behaviors and with the intention of obtaining the item at the lowest price. Each bidder has his own valuation of the item that he is interested in and this value is not known to the seller. In a real auction, the number of competing sellers and the number of bidders who will be participating in the auction are unknown. These issues complicate the strategic setting of the reserve price of an item. In this work, we study the market in which sellers compete by offering auctions with homogeneous goods for buyers. To cope with the uncertainty of the price determination inherent in multi auction context is a complex decision making problem (He, Jennings, & Prugel-Bennet, 2006). Due to the resale options subjected to re-auction (Grant et al., 2006), setting up the reserve price for a given item to be auctioned has become more complicated. There is no clear-cut in deciding the best reserve price (Katkar & Riley, 2006) since observers are always uncertain of the exact amount of the reserve price, as only the upper bound (where price is met) and the lower bound (where price is not met) are disclosed. Particularly, several factors must be considered when deciding for the single optimal price (Law & Anthony, 2008). Firstly, we are uncertain on the number of competitors who will be competing as it is possible to have multiple sellers selling the same item. Secondly, we cannot determine the 19 more pages are available in the full version of this document, which may be purchased using the """"Add to Cart"""" button on the product's webpage: www.igi-global.com/article/autonomous-seller-agent-multiplesimultaneous/69522?camid=4v1 This title is available in InfoSci-Journals, InfoSci-Journal Disciplines Computer Science, Security, and Information Technology, InfoSci-Artificial Intelligence and Smart Computing eJournal Collection, InfoSci-Journal Disciplines Engineering, Natural, and Physical Science, InfoSci-Select. Recommend this product to your librarian: www.igi-global.com/e-resources/libraryrecommendation/?id=2"""	auction algorithm;computer science;discovery (law);fanaroff-riley classification;harris affine region detector;information science;librarian;linkage (software);mathematical optimization;optimization problem;pamela samuelson;price point;situated;software agent;stemming;value (ethics);web page;while	Patricia Anthony;Edwin Law	2012	IJATS	10.4018/jats.2012040101	ask price;auction sniping;walrasian auction;auction algorithm;eauction;vickrey auction;generalized second-price auction;unique bid auction;reverse auction;vickrey–clarke–groves auction;proxy bid;revenue equivalence;multiunit auction;english auction;double auction;auction theory;reservation price;forward auction;dutch auction	ECom	-7.396453656057671	-8.30552374701436	30665
0d3a54d64ec0ed41517b475a3ef49dd5d40c026f	query optimization for massive rdf data based on spark		Sparql (SPARQL Protocol and RDF Query Language) is a query language and data acquisition protocol designed for RDF development. Although it is defined for the RDF data model developed by the W3C, it can be used in any form of RDF to represent data resources. With the explosive growth of web information resources, more and more data is using RDF structure. The research and obtaining of useful information in massive data has become a major challenge. Efficient search and effective query has become the focus attention of research. In this paper, we design an efficient optimization method by finding a semantic connection chain in the system (SparkIlink). Data was stored on the file system of hadoop (HDFS). Based on Spark framework with efficient distributed memory, this system has achieved efficient searching and optimizing performance for massive RDF data. Our work includes the following mechanism: (1) using vertical partition as data storage structure; (2) using twice data statistics; (3) using information connection chain based on semantic. Our system can support massive triples query in distributed environment to achieve efficient query processing. The experiment of this paper is based on the latest SPARQLGX on the spark platform RDF system. In contrast, our system is more efficient in data search than SPARQLGX.	apache hadoop;apache spark;border gateway protocol;computer data storage;data acquisition;data model;database storage structures;distributed memory;mathematical optimization;program optimization;query optimization;rdf query language;resource description framework;sparql;sql;triple des	Shaohui Li;Derong Shen;Yue Kou;Dan Yang	2018	2018 4th International Conference on Big Data Computing and Communications (BIGCOM)	10.1109/BIGCOM.2018.00042	data mining;database;rdf;data model;distributed memory;query language;sparql;rdf query language;query optimization;computer science;computer data storage	DB	-31.19022744434032	1.2490948127335684	30709
c5ec2634c88ab76669c970f0de7505e202e1f557	fuzzy decision making in an agent-based model of non-industrial private forest owners		This paper presents the development and application of a fuzzy inference system (FIS) to an agent-based model of non-industrial private forest owner (NIPFO) timber harvesting activity. The FIS inputs and rules are developed based upon survey and literature data on NIPFOs and agents are embedded into a forested landscape similar to real conditions. Model results indicate harvesting patterns similar to what is actually observed. I argue that these encouraging results indicate the technique merits further development.	agent-based model;embedded system;ibm 7950 harvest;inference engine;logistic regression;refinement (computing);serial ata;social simulation	Robert Zupko	2017	2017 IEEE Symposium Series on Computational Intelligence (SSCI)	10.1109/SSCI.2017.8285222	data mining;agent-based model;logging;fuzzy logic;inference;business	Embedded	-10.047938571719756	-11.743084122717436	30751
1310e03c5e1d15215f7c0c60d9bbd99a036cbfb7	user oriented trajectory similarity search	semantic similarity;1712 software;query processing;kernel density estimation;1710 information systems;computational social science;time cumulative spatial activity density;urban spatial temporal structure;data model;personalized search;theoretical analysis;shape similarity;spatial locality;high efficiency;similarity search;human activity intensity	Trajectory similarity search studies the problem of finding a trajectory from the database such the found trajectory most similar to the query trajectory. Past research mainly focused on two aspects: shape similarity search and semantic similarity search, leaving personalized similarity search untouched. In this paper, we propose a new query which takes user's preference into consideration to provide personalized searching. We define a new data model for this query and identify the efficiency issue as the key challenge: given a user specified trajectory, how to efficiently retrieve the most similar trajectory from the database. By taking advantage of the spatial localities, we develop a two-phase algorithm to tame this challenge. Two optimized strategies are also developed to speed up the query process. Both the theoretical analysis and the experiments demonstrate the high efficiency of the proposed method.	algorithm;data model;experiment;personalization;semantic similarity;similarity search;tame;two-phase commit protocol	Haibo Wang;Kuien Liu	2012		10.1145/2346496.2346513	kernel density estimation;computational sociology;semantic similarity;data model;computer science;data mining;database;web search query;information retrieval;statistics	DB	-27.13181355244541	0.9669402550612098	30839
35ea8d26bb7f912bbca452a3dcf3532a1d8beedf	learning to generate natural language rationales for game playing agents				Upol Ehsan;Pradyumna Tambwekar;Larry Chan;Brent Harrison;Mark O. Riedl	2018			cognitive science;non-player character;natural language;computer science	AI	-27.496365186919867	-15.782198644424897	30844
054cf8674ae97afa58b6fbd06bda8e75847a91de	a dynamic pivoting algorithm based on spatial approximation indexes		Metric indexes aim at reducing the amount of distance evaluations carried out when searching a metric space. Spatial approximation trees (sa-trees for short), in particular, are efficient data structures, which have shown to be competitive in metric spaces of medium to high difficulty, or queries with low selectivity. Sa-trees can be also made dynamic, and can use the available space to improve the query performance adding pivot information. In this paper we show how the pivot information added to dynamic sa-trees can be used to a full extent, in order to improve the search performance. The result is a technique that allows one to traverse a dynamic sa-tree without necessarily comparing all traversed nodes against the query object. As a result, the novel algorithm makes a much better use of the available space, yielding a saving of distance computations of about 10% to 70%, compared with previous sa-tree schemes that use pivot information.	acm computing surveys;acm transactions on algorithms;algorithm;algorithmics;approximation;computation;dspace;data structure;database;information retrieval;lecture notes in computer science;range searching;reyes rendering;search algorithm;selectivity (electronic);similarity search;springer (tank);traverse	Diego Arroyuelo	2014		10.1007/978-3-319-11988-5_7	mathematical optimization;theoretical computer science;algorithm	DB	-26.628448322317848	2.3135887862509907	30880
8512374693b063433bb54bd0a49a01eb7d4ff34e	academic writing support system using bayesian networks	silicon;computer aided instruction belief networks;information system toulmin model bayesian network academic writing argument;bayesian network;bayes methods;toulmin model academic writing support system bayesian networks argument strength argument elaboration support system;sensitivity;indexes;academic writing;toulmin model;writing;information system;probabilistic logic;numerical models;indexes bayes methods writing probabilistic logic silicon sensitivity numerical models;argument	For academic writing, elaborating an argument particularly addressing an argument strength is important to establish causal relations between sentences. However, when an argument becomes large or complex, elaborating an argument considering the argument strength is difficult. To solve this problem, this article presents a proposal for an argument elaboration support system using a Bayesian network representation of the Toulmin model. Using that Bayesian network representation, the proposed system can estimate argument strength, sentence validity, and sentence influence. Moreover, it can generate optimal advice for revising the argument.	bayesian network;causal filter;experiment	Masaki Uto;Maomi Ueno	2015	2015 IEEE 15th International Conference on Advanced Learning Technologies	10.1109/ICALT.2015.16	argument;database index;toulmin method;heuristic argument;argument map;sensitivity;computer science;artificial intelligence;default argument;machine learning;academic writing;bayesian network;database;linguistics;probabilistic logic;silicon;writing;information system;algorithm;statistics	Robotics	-15.24379741150425	-1.1348795985614748	30960
7fb62bf34306bc82e0ab39dc4fc34d84693ef15a	person to purpose manpower architecture applied to a highly autonomous uas cloud	display design;mental workload;hci;autonomy;human factors system integration;command and control;decision making and decision support;requirements analysis;automation	"""Studies indicate that """"cloud"""" based concepts will provide benefits by maximising the availability of capability, reducing redundancy and permitting efficiencies in operation and deployment of effect. To deploy the cloud will require many problems to be solved. This paper examines automation applied to the cloud and builds on substantial work looking at command abstraction of users and consumers interacting with systems. The work retains the absolute authority of the human supervisor. Data is presented of a recent trial which immersed serving military personnel, exercising both manned and unmanned systems within a synthetic environment, whilst divorcing operators from platform ownership and concentrating instead on task ownership (thus linking person to purpose). Baseline systems were compared with systems possessing higher degrees of automation and tool functionality. The results are discussed and the key conclusions show clear benefits to operating in the person to purpose manner."""		Jon Platts;Scott Findlay;Andrew Berry;Helen Keirl	2013		10.1007/978-3-642-39354-9_32	simulation;engineering;operations management;operations research	Robotics	-25.010050473239613	-23.487552402824182	31165
54104609f6852cbf0ce55f2b6c2987e21f95ea95	efficient execution of top-k sparql queries	article in monograph or in proceedings	Top-k queries, i.e. queries returning the top k results ordered by a user-defined scoring function, are an important category of queries. Order is an important property of data that can be exploited to speed up query processing. State-of-the-art SPARQL engines underuse order, and top-k queries are mostly managed with a materialize-then-sort processing scheme that computes all the matching solutions (e.g. thousands) even if only a limited number k (e.g. ten) are requested. The SPARQL-RANK algebra is an extended SPARQL algebra that treats order as a first class citizen, enabling efficient split-and-interleave processing schemes that can be adopted to improve the performance of top-k SPARQL queries. In this paper we propose an incremental execution model for SPARQL-RANK queries, we compare the performance of alternative physical operators, and we propose a rank-aware join algorithm optimized for native RDF stores. Experiments conducted with an open source implementation of a SPARQL-RANK query engine based on ARQ show that the evaluation of top-k queries can be sped up by orders of magnitude.	algorithm;database;first-class citizen;first-class function;free variables and bound variables;join (sql);linear programming relaxation;mathematical optimization;microsoft outlook for mac;open-source software;random access;sparql;scoring functions for docking;speedup;triplestore	Sara Magliacane;Alessandro Bozzon;Emanuele Della Valle	2012		10.1007/978-3-642-35176-1_22	computer science;data mining;database;world wide web;information retrieval	DB	-32.08269492281335	3.7969876513597933	31166
3d0174aee345e1b9d759878229381de2de7737ec	simulation techniques on complex system of mission driving material support	databases;analytical models;compounds;materials maintenance engineering databases analytical models compounds organizations data models;common station model;mission drive;maintenance engineering;failure managing module;materials;failure managing module simulation technique complex system mission driving material support transport system multilevel mission model material status watching;element mission model;transport system;support system;complex system;simulation technique;material support;transportation;common station model material support complex system element mission model mission drive;multilevel mission model;material status watching;mission driving material support;organizations;learning artificial intelligence;transportation large scale systems learning artificial intelligence;large scale systems;data models	To study the material support system, build a simulate system is an efficient way. The complicity of the material support system is analyzed, the similarities and differences of the mission for materials, transport system, and support stations to carry out is proposed; then an element mission model for general use is constructed, based on which the multi-level mission model is set up and expressed; characteristics of support stations belong to different echelons or types are analyzed, and a common station model is set up, based on which the structure of a simulation system is proposed. The models for key modules of the system such as material status watching and failure managing module, the database for the simulate system, are set up. At the end of the paper, a simulate system for three-echelon support system is constructed, a scenario is performed to test the simulate system.	complex system;row echelon form;simulation	De-Jun Mao;Qing-Min Li;Ying-Wu Peng	2010	2010 International Conference on Machine Learning and Cybernetics	10.1109/ICMLC.2010.5581093	maintenance engineering;data modeling;transport;simulation;computer science;organization;electro-mechanical modeling	Robotics	-9.06389402397608	-14.621869541288174	31183
b63ec6fbbee36ab2d254ab63fc28c87b2dae41e0	bayesian network modelling through qualitative patterns	reseau probabiliste;analisis cualitativo;bayesian network;representacion conocimientos;semantics;qualitative analysis;raisonnement qualitatif;semantica;semantique;reseau bayes;article letter to editor;probabilistic net;analyse qualitative;compact representation;red bayes;interaction pattern;representation connaissance;bayes network;razonamiento calitativo;qualitative reasoning;knowledge representation;probabilistic network;bayesian networks	In designing a Bayesian network for an actual problem, developers need to bridge the gap between the mathematical abstractions offered by the Bayesian-network formalism and the features of the problem to be modelled. Qualitative probabilistic networks (QPNs) have been put forward as qualitative analogues to Bayesian networks, and allow modelling interactions in terms of qualitative signs. They thus have the advantage that developers can abstract from the numerical detail, and therefore the gap may not be as wide as for their quantitative counterparts. A notion that has been suggested in the literature to facilitate Bayesian-network development is causal independence. It allows exploiting compact representations of probabilistic interactions among variables in a network. In the paper, we deploy both causal independence and QPNs in developing and analysing a collection of qualitative, causal interaction patterns, called QC patterns. These are endowed with a fixed qualitative semantics, and are intended to offer developers a highlevel starting point when developing Bayesian networks.	analysis of algorithms;anti-pattern;bayesian network;causal filter;causal system;causality;computational complexity theory;grammar-based code;interaction;linear algebra;numerical analysis;semantics (computer science)	Peter J. F. Lucas	2005	Artif. Intell.	10.1016/j.artint.2004.10.011	knowledge representation and reasoning;computer science;artificial intelligence;machine learning;bayesian network;data mining;mathematics;semantics	AI	-19.80095154054338	1.3589624685561623	31257
178a4b39b0a6e9e08acddf5100d09aedda1ab0d4	dynamic recommendations for sequential hiring decisions in online labor markets		Online labor markets facilitate transactions between employers and a diverse set of independent contractors around the globe. When making hiring decisions in these markets, employers have to assess a large and heterogeneous population of contractors. Because many of the contractorsu0027 characteristics are latent, employers often make risky decisions that end up in negative outcomes. In this work, we address this issue by proposing a framework for recommending contractors who are likely to get hired and successfully complete the task at hand. We start our analysis by acknowledging that employersu0027 hiring behavior dynamically evolves with time; Employers learn to choose contractors according to the outcomes of their previously completed tasks. To capture this dynamic evolution, we propose a structured Hidden Markov Model that explicitly models task outcomes through the employersu0027 evolution. We build and evaluate the proposed framework on a dataset of real online hiring decisions. We then compare our approach with a set of previously proposed static algorithms and we show that our proposed framework provides up to 24% improved recommendations. We conclude by discussing the positive impact that such better recommendations of candidates can have on employers, contractors, and the market itself.	algorithm;hidden markov model;markov chain;recommender system	Marios Kokkodis	2018		10.1145/3219819.3219881	knowledge management;artificial intelligence;computer science;machine learning;hidden markov model;globe;population	Web+IR	-5.970553340708292	-9.992309474354617	31259
b7d6452a9fa482f40dd07ef589633217d3bcdfdb	frag-shells cube based on hierarchical dimension encoding tree	olap;hierarchical dimension;hb tree;frag shells cube	Pre-computation of data cube can greatly improve the performance of OLAP (online analytical processing). There are a lot of effective pre-computation methods of data cube. But in practice, appropriate pre-computation method for the characteristics of data set plays a crucial role in improving the efficiency of data cube pre-computation.  In view of the high-dimensional and hierarchical dimension of water census data characteristic, Frag-Shells cube based on hierarchical dimension encoding tree has been proposed in this paper. In order to improve the retrieval efficiency and reduce redundant information in hierarchical dimensions, we have proposed hierarchical dimension encoding tree (HDE-Tree) to index the hierarchical dimension in Frag-Shells cube. In order to increase the efficiency of cube construction, improved Frag-Shells cube calculation method has been used to compute the tuples of non-hierarchical dimension fragments. In order to compress the size of data cube, the TID-List compression method has been used to decrease the storage cost of inverted index in each tuple. Experiments show that the Frag-Shells cube based on hierarchical dimension encoding tree can reduce the construction time and storage cost of data cube which has high-dimensional and dimensions hierarchical figures.	computation;data cube;fragmentation (computing);inverted index;lambda cube;online analytical processing;precomputation	Shanshan Tang;Dingsheng Wan;Yuelong Zhu;Jianguo Yao	2017		10.1145/3022227.3022229	online analytical processing;computer science;theoretical computer science;database;data cube	DB	-28.706900271012227	1.995865155552407	31278
63ae3bea7f9733bce8b4456a56d53fc885de6337	information-based deliberation	multiagent system;agent communication;negotiation;conference proceeding;multiagent systems	Information-based agency is founded on two observations: everything in an agent’s world model is uncertain, and everything that an agent communicates gives away valuable information. The agent’s deliberative mechanism manages interaction using plans and strategies in the context of the relationships the agent has with other agents, and is the means by which those relationships develop.	agent architecture;confidentiality;interaction;preference elicitation;semantic similarity	Carles Sierra;John K. Debenham	2008		10.1145/1402298.1402320	computer science;knowledge management;artificial intelligence;multi-agent system;negotiation;agent-based social simulation	AI	-20.844198624399105	-10.992272901207112	31345
377eb19657e91727bf2dea531abb2503aa04d6a3	a unified theory of acting and agency for a universal interfacing agent	dissertation	With consumer electronics becoming numerous, various and complex, the idea of a single, shared, general and flexible interfacing agent to interface human users with the multitude of task-oriented systems or devices seems appealing. Such a universal interfacing agent has to understand user instructions and issue commands to control the task-oriented system to which it is connected, in a manner that the given user desires. #R##N#Two important issues that such an agent has to deal with are: (i) how to represent and reason about the tasks that a given device can perform and the results that a given device can produce and (ii) how to represent and reason about when different tasks are to be performed and whether the tasks have been successful. The dissertation explores these issues in detail and provides a solution to deal with these issues within a contradiction-tolerant and time-sensitive framework called Active logic. #R##N#The solution involves explicitly representing the beliefs, desires, intentions, expectations, observations and achievements of the interfacing agent and reasoning based on these attitudes; the dissertation provides a theory (ALFA) that agents can use in order to perform this reasoning. The theory specifies the interactions between beliefs, observations, desires, intentions, expectations and achievements for a universal interfacing agent, while taking into consideration issues associated with concurrent execution of actions as well as perturbation tolerance. The main characteristics of the theory are: representing and reasoning about concurrent actions and results, dealing with interactions of preconditions of actions or results, dynamic reconsideration of intentions and reasoning using expectations and achievements. #R##N#The dissertation also provides an architecture (DIRECTOR) for implementing agents based on the theory. In this architecture, a meta-cognitive process controls the cognitive activities of the agent. The rudimentary results of implementing the architecture to create a natural language based interfacing agent (ALFRED) are also discussed in the dissertation. #R##N#This work also discusses how the agent's underlying Active logic knowledge base evolves during reasoning and provides proofs for properties that the knowledge base exhibits, using a meta-theory that specifies how the knowledge base evolves.		Darsana P. Josyula	2005			simulation;computer science;knowledge management;artificial intelligence	Theory	-22.054698969397524	-13.581055775121715	31386
de74adf7e18b4b38372d11c2d9a0b50bd5d24d45	benefits of embedding structural constraints in coherent diagnostic processes	diagnostic medical informatique;computacion informatica;aplicacion medical;contrainte qualitative;probabilidad condicional;coherent inference;probabilite conditionnelle;qualitative constraints;echangeabilite conditionnelle;diagnosis procedures;ciencias basicas y experimentales;inferencia;coherence;medical application;coherencia;grupo a;conditional probability;medical diagnostic computing;conditional exchangeability;medical diagnosis;inference;application medicale	This paper reviews recent results applicable to medical diagnosis, obtained by adding structural constraints to a coherent inference process. Such further considerations turn out to be useful whenever a basic lower-upper conditional probability assessment induces extension bounds too vague to motivate an informed decision. Three general types of qualitative judgements are proposed and fully described. They do not constitute a ''panacea'' to solve every problematic situation, but their application can considerably improve inferences results in specific cases, as two practical applications show.	coherence (physics)	Andrea Capotorti	2005	Int. J. Approx. Reasoning	10.1016/j.ijar.2004.10.010	coherence;conditional probability;artificial intelligence;medical diagnosis;mathematics;algorithm;statistics	AI	-15.549566464966825	-0.21042144739245908	31427
01c1e1a5378846171b9cc5c207eca8b0a8eaa6bf	the incremental analogy machine: a computational model of analogy	computer model		computation;computational model	Mark T. Keane;Mike Brayshaw	1988			computational physics;analogy;computer science	AI	-28.39013715974337	-14.026166638940085	31460
912ed2be33d13b29195363f6bc68468a66660a16	sensory-motor coordination in gaze control	gaze;modelizacion;image recognition;reconocimiento imagen;haute performance;control motor;behavioral analysis;localization;controle moteur;natural images;intelligence artificielle;localizacion;mirada;algoritmo genetico;artificial intelligent;modelisation;regard;gaze control;localisation;motor coordination;analyse comportementale;reconnaissance image;algorithme genetique;alto rendimiento;artificial intelligence;algorithme evolutionniste;genetic algorithm;coordinacion;analisis conductual;algoritmo evolucionista;inteligencia artificial;evolutionary algorithm;modeling;high performance;coordination;motor control	In the field of artificial intelligence, there is a considerable interest in the notion of sensory-motor coordination as an explanation for intelligent behaviour. However, there has been little research on sensory-motor coordination in tasks that go beyond low-level behavioural tasks. In this paper we show that sensory-motor coordination can also enhance performance on a high-level task: artificial gaze control for gender recognition in natural images. To investigate the advantage of sensory-motor coordination, we compare a non-situated model of gaze control (incapable of sensory-motor coordination) with a situated model of gaze control (capable of sensorymotor coordination). The non-situated model of gaze control shifts the gaze according to a fixed set of locations, optimised by an evolutionary algorithm. The situated model of gaze control determines gaze shifts on the basis of local inputs in a visual scene. An evolutionary algorithm optimises the model’s gaze control policy. From the experiments performed, we may conclude that sensory-motor coordination contributes to artificial gaze control for the highlevel task of gender recognition in natural images: the situated model outperforms the non-situated model. The mechanism of sensory-motor coordination establishes dependencies between multiple actions and observations that are exploited to optimise categorisation performance.	artificial intelligence;categorization;evolutionary algorithm;experiment;high- and low-level;situated	Guido C. H. E. de Croon;Eric O. Postma;H. Jaap van den Herik	2005		10.1007/978-3-540-32003-6_34	motor control;simulation;systems modeling;genetic algorithm;internationalization and localization;computer science;artificial intelligence;evolutionary algorithm;motor coordination	AI	-24.174147178438254	-16.601807302907247	31461
3dcb1e9dbb29187eb914b2b862f5834c6784cbff	an analytic hierarchy process and two-sided matching based decision support system for military personnel assignment	military personnel;analytic hierarchy process;satisfiability;support system;decision support system;personnel assignment;two sided matching	Assignment of military personnel to positions is very demanding, primarily a manual process performed by detailers. Detailers try to satisfy needs and preferences of commands and personnel. In this paper, an analytic hierarchy process (AHP) and two sided matching based Decision Support System is proposed to assist detailers. The DSS is programmed to generate positions’ preferences from position requirement profiles and personnel competence profiles by using analytic hierarchy process and matches personnel to positions by using two-sided matching. The use of the proposed DSS is demonstrated with an example. Also, the effects of preference list length on two-sided matching are examined. 2008 Elsevier Inc. All rights reserved.	algorithm;analytical hierarchy;assignment problem;decision support system;organizational behavior;wish list	Ibrahim Korkmaz;Hadi Gökçen;Tahsin Çetinyokus	2008	Inf. Sci.	10.1016/j.ins.2008.03.005	analytic hierarchy process;decision support system;computer science;management science;operations research;satisfiability	AI	-7.005173733197432	-13.673895363642906	31488
6c1391af2b8bbd1525d78c1ab5d44d1d5ba2bae5	learning by weakly-connected adaptive agents	eigenvalues and eigenfunctions;topology;telecommunication network topology graph theory pareto optimisation;cost function;outlier data weakly connected adaptive agents weakly connected graphs leader follower relationship network topology;limiting;network topology topology cost function noise covariance matrices limiting eigenvalues and eigenfunctions;network topology;covariance matrices;leader follower relationship weakly connected graphs distributed strategies pareto optimality;noise	In this paper, we examine the learning mechanism of adaptive agents over weakly-connected graphs and reveal an interesting behavior on how information flows through such topologies. The results clarify how asymmetries in the exchange of data can mask local information at certain agents and make them totally dependent on other agents. A leader-follower relationship develops with the performance of some agents being fully determined by other agents that can even be outside their immediate domain of influence. This scenario can arise, for example, from intruder attacks by malicious agents or from failures by some critical links. The findings in this work help explain why strong-connectivity of the network topology, adaptation of the combination weights, and clustering of agents are important ingredients to equalize the learning abilities of all agents against such disturbances. The results also clarify how weak-connectivity can be helpful in reducing the effect of outlier data on learning performance.	cluster analysis;malware;network topology	Bicheng Ying;Ali H. Sayed	2015	2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	10.1109/ICASSP.2015.7179081	mathematical optimization;product topology;computer science;noise;machine learning;mathematics;distributed computing;extension topology;network topology;limiting;logical topology	Robotics	-13.041250661655894	-14.861619526678428	31497
f52db543bf9d1fad86ea25f63fe873221f9b34e2	"""is genetic programming """"human-competitive""""? the case of experimental double auction markets"""	learning performance;competition;working memories;cognitive psychology;human competitiveness;best strategy;genetic programming;commerce;human subjects;optimal solutions;integer programming;experimental markets;autonomous agents;double auction;two stage	"""In this paper, the performance of human subjects is compared with genetic programming in trading. Within a kind of double auction market, we compare the learning performance between human subjects and autonomous agents whose trading behavior is driven by genetic programming (GP). To this end, a learning index based upon the optimal solution to a double auction market problem, characterized as integer programming, is developed, and criteria tailor-made for humans are proposed to evaluate the performance of both human subjects and software agents. It is found that GP robots generally fail to discover the best strategy, which is a two-stage procrastination strategy, but some human subjects are able to do so. An analysis from the point of view of cognitive psychology further shows that the minority who were able to find this best strategy tend to have higher working memory capacities than the majority who failed to do so. Therefore, even though GP can outperform most human subjects, it is not """"human-competitive"""" from a higher standard."""	genetic programming	Shu-Heng Chen;Kuo-Chuan Shik	2011		10.1007/978-3-642-23878-9_15	auction algorithm;economics;microeconomics;market economy;auction theory;commerce	ECom	-9.126267817197869	-9.01139849392154	31503
11cc93b52a2b6e9426ff1a95d27c3e69c909d1b4	investors' inertia behavior and their repeated decision-making in online reward-based crowdfunding market		Abstract Extending recent work on individual-level decisions in the emerged reward-based crowdfunding market, we formulated a Panel Vector Auto Regression Model with exogenous variables to examine whether investorsu0027 Inertia Behavior (IB) exists in their repeated investment decisions (i.e., which reward tier to select and when to invest). If so, how to quantify the effect of this behavior and how investorsu0027 heterogeneity moderates the effect of this behavior. We collected a novel and individual-level dataset from a leading crowdfunding market. Our analysis suggests the existence of investorsu0027 IB. Furthermore, we also found that (1) Investorsu0027 IB in reward tier selection seems to be stronger than that in investment timing selection. (2) Investorsu0027 platform tenure significantly accentuates their IB reward tier selection, but weakens that in investment timing selection. (3) Project attributes related factors have different impacts on investorsu0027 decision-making and peer investorsu0027 influence have stronger impact on backersu0027 investment timing selection when compared with fundraisersu0027 marketing efforts. Our results provide implications for crowdfunding participants including investors, fundraisers and the crowdfunding intermediaries hosting them.	crowdfunding	Shengsheng Xiao;Qing Yue	2018	Decision Support Systems	10.1016/j.dss.2018.05.005	finance;computer science;knowledge management;investment decisions;intermediary	ECom	-5.285760239102109	-7.9629399351007475	31537
75991a2d1849227b28173a0f591e56380e2e3680	superstore sales reporting: a comparative analysis of relational and non-relational databases - short paper		The purpose of this paper is to realize a comparative analysis of relational and non-relational database management systems. Both conceptual and technical characteristics are introduced, presenting the benefits and disadvantages of each model, using a hybrid application. The application, named SuperstoreSalesReporting, generates comparative reports which describe the technical characteristics of both SQL and NoSQL databases based on the executed operations. The application constitutes the contribution of this study, together with the creation of the SQL Server internal processes for migrating data from a flat file into a star schema.	relational database	Gheorghe Cosofret;Ioana Ciuciu	2017		10.1007/978-3-319-73805-5_10	sql;nosql;flat file database;database;relational database;schema (psychology);computer science	DB	-32.814212311302825	3.1234781312476425	31547
22736787e2554802e3767735318c668a08810be5	semantic query routing in senpeer, a p2p data management system	p2p system;performance evaluation;p2p;distributed data structure;peer to peer;data management system;semantic overlay network;query routing	A challenging problem in a schema-based peer-to-peer (P2P) system is how to locate peers that are relevant with respect to a given query. In this paper, we propose a new semantic routing mechanism in the context of the SenPeer P2P Data Management System (PDMS). SenPeer is an unstructured P2P system based on an organization of peers around super-peers according to their semantic domains. Our proposal is based on the use of a distributed data structure, called expertise table, maintained by the super-peers and describing data at the neighboring peers. This table, combined with matching techniques, is the basis of a semantic overlay network. Semantic links are exploited for efficient query propagation towards peers that may have relevant data. We give a performance evaluation of our semantic query routing with respect to important criteria such as precision, recall and number of messages. The results show that our algorithm significantly outperforms a baseline algorithm without semantics.	management system;routing;semantic query	David Faye;Gilles Nachouki;Patrick Valduriez	2007		10.1007/978-3-540-74573-0_38	query optimization;semantic computing;computer science;peer-to-peer;data mining;database;world wide web	DB	-29.361190600779818	-0.4209435978191614	31553
6e7f7493a34e786647060c1fb5d609f99464e48b	solving sisyphus by design	engineering;industrial and operations engineering;modele dids;configuracion;representacion conocimientos;coaccion;contrainte;satisfaccion;conception;intelligence artificielle;satisfaction;resolucion problema;probleme sisyphus;constraint;acquisition;diseno;independance domaine;artificial intelligence;design;inteligencia artificial;knowledge representation;configuration;representation connaissances;adquisicion;problem solving;resolution probleme	Abstract   This paper demonstrates how the Domain-Independent Design System (DIDS) was used to solve the Sisyphus room-assignment problem by viewing it as a configuration-design task. We have developed a general problem-solving method for configuration design, based on constraint-satisfaction techniques. This method efficiently solves the Sisyphus problem, and provides strong guidance for knowledge acquisition. This paper presents both the problem solver and knowledge-acquisition support created by DIDS to solve the Sisyphus problem.		Alan Balkany;William P. Birmingham;Jay T. Runkel	1994	Int. J. Hum.-Comput. Stud.	10.1006/ijhc.1994.1011	knowledge representation and reasoning;design;computer science;artificial intelligence;constraint;configuration;operations research;algorithm	HCI	-24.452498561718016	-4.420584523335854	31579
4d3524c853fd6589ddd753dbc794a9c236b89a8c	a simple stochastic weather generator for ecological modeling	climate;ecology;weather generator;ecological model;source code;stochastic model	Stochastic weather generators are useful tools for exploring the relationship between organisms and their environment. This paper describes a simple weather generator that can be used in ecological modeling projects. We provide a detailed description of methodology, and links to full Cþþ source code (http://weathergen.sourceforge.net) required to implement or modify the generator. We argue that understanding the principles of weather generation will allow ecologists to tailor a solution for their own requirements. The detailed, repeatable methodology we present demonstrates that weather generation is relatively straightforward for ecologists to implement and modify. 2010 Elsevier Ltd. All rights reserved.	ecology;ecosystem model;requirement;sourceforge	Andrew G. Birt;M. R. Valdez-Vivas;R. M. Feldman;Charles W. Lafon;David M. Cairns;Robert N. Coulson;Maria D. Tchakerian;Weimin Xi;James M. Guldin	2010	Environmental Modelling and Software	10.1016/j.envsoft.2010.03.006	climate;meteorology;biology;simulation;hydrology;computer science;engineering;stochastic modelling;ecology;social ecological model;source code	AI	-15.024759862905116	-21.956499340876825	31650
4524f781c29f6cd6de941d5177b848debb6c0f09	notice of retractionthe complex effect of the financial crisis on u.s. s&p 500 stock market	financial crisis;social network services;complex networks;finance;stock market;maximum spanning tree;financial management;complex network;weight distribution;matrix algebra;trees mathematics;system on a chip;stock markets;degree distribution;correlation stock markets communities finance matlab system on a chip social network services;trees mathematics financial management matrix algebra stock markets;stock market network;community structure;correlation matrix financial crisis price fluctuations power law distribution stock market network maximum spanning tree;price fluctuations;spanning tree;correlation;communities;correlation matrix;power law distribution;matlab;power law distribution complex networks correlation matrix maximum spanning tree community structure	"""We empirically investigated the price fluctuations of S&P 500 stock market using daily close price of S&P 500 stocks under two different periods as corresponding to the time before the financial crisis and under the crisis. Based on our analysis, it is found that under the financial crisis, the weight distribution is showing a special form as majority of links imply strong positive correlation and node numbers with the IS value loses power-law distribution. We establish the stock market network with maximum spanning tree through the correlation matrix and find “community structure"""" has been greatly changed as grouping coefficient rapidly reduced. Degree distribution has remained a power-law distribution, but the end of the deviation increased. Meanwhile, the distribution of intermediate nodes is more crowded."""	coefficient;degree distribution;file spanning;spanning tree	Xu Xiaoping;Han Dingding	2010	2010 International Conference on E-Business and E-Government	10.1109/ICEE.2010.1197	financial economics;financial management;actuarial science;economics;finance;complex network;statistics;commerce	ML	-12.256204617213081	-16.879901088406918	31689
f8cb67e4af6968770a4b6898cbc639299376d492	the problem with p2p	p2p	Taylor & Francis makes every effort to ensure the accuracy of all the information (the “Content”) contained in the publications on our platform. However, Taylor & Francis, our agents, and our licensors make no representations or warranties whatsoever as to the accuracy, completeness, or suitability for any purpose of the Content. Any opinions and views expressed in this publication are the opinions and views of the authors, and are not the views of or endorsed by Taylor & Francis. The accuracy of the Content should not be relied upon and should be independently verified with primary sources of information. Taylor and Francis shall not be liable for any losses, actions, claims, proceedings, demands, costs, expenses, damages, and other liabilities whatsoever or howsoever caused arising directly or indirectly in connection with, in relation to or arising out of the use of the Content.	francis;primary source	Ken Dunham	2006	Information Systems Security	10.1201/1086.1065898X/46051.15.2.20060501/93403.2	computer science;peer-to-peer;computer security	Robotics	-15.115522043396652	-5.63592089680207	31697
19c8eeff3b8007911bd448c077b977dc5d00fc69	learning symbolic formulations in design: syntax, semantics, and knowledge reification	machine learning in design;unsupervised clustering;singular value decomposition;symbolic problem reformulation;pattern extraction	An AI algorithm to automate symbolic design reformulation is an enduring challenge in design automation. Existing research shows that design tools either require high levels of knowledge engineering or large databases of training cases. To address these limitations, we present a singular value decomposition (SVD) and unsupervised clustering based method that performs design reformulation by acquiring semantic knowledge from the syntax of design representations. The development of the method was analogically inspired by applications of SVD in statistical natural language processing and digital image processing. We demonstrate our method on an analytically formulated hydraulic cylinder design problem and an aero-engine design problem formulated using a non-analytic Design Structure Matrix form. Our results show that the method automates various design reformulation tasks on problems of varying sizes from different design domains, stated in analytic and non-analytic representational forms. The behavior of the method presents observations that cannot be explained by pure symbolic AI approaches, including uncovering patterns of implicit knowledge that are not readily encoded as logical rules, and automating tasks that require the associative transformation of sets of inputs to experiences. As an explanation, we relate the structure and performance of our algorithm with findings in cognitive neuroscience and present a set of theoretical postulates addressing an alternate perspective on how symbols may interact with each other in experiences to reify semantic knowledge in design representations.	algorithm;artificial intelligence;cluster analysis;cognitive science;computational neuroscience;cylinder-head-sector;database;design structure matrix;digital image processing;dimensionality reduction;encode;electronic design automation;experience;heuristic;high-level programming language;knowledge acquisition;knowledge engineering;mathematical optimization;natural language processing;numerical analysis;pattern recognition;problem domain;reification (knowledge representation);singular value decomposition;software design;stochastic grammar;symbolic computation;unsupervised learning;windows aero	Somwrita Sarkar;Andy Dong;John S. Gero	2010	AI EDAM	10.1017/S0890060409990175	computer science;engineering;artificial intelligence;theoretical computer science;machine learning;singular value decomposition;algorithm	AI	-31.661462359535584	-13.92386348615016	31737
9b8b7e10a0db85bf983f9e9017d48e75d6e1e60e	shop-floor controller based on rt-middleware technology	robot controller;interchangeable software hardware components rt middleware technology flexible manufacturing cell configuration small and medium sized companies manufacturing changes modular designed controller software components online configuration sensor integration unified programming language machine specific controllers human machine interaction shop floor control architecture adept scara robot;human computer interaction;flexible manufacturing systems;scara robot controller rt middleware cnc;production engineering computing;t2 technology general műszaki tudomanyok altalaban;production engineering computing cellular manufacturing control engineering computing control system synthesis flexible manufacturing systems human computer interaction industrial robots middleware;rt middleware;control system synthesis;industrial robots;scara;tj mechanical engineering and machinery gepeszmernoki tudomanyok;middleware;ferenc tajti geza szayer bence kovacs peter korondi 车间控制器 中间件技术 机器人手臂 制造单元 软件组件 在线配置 中小型企业 模块化设计 shop floor controller based on rt middleware technology;control engineering computing;cnc;computer numerical control joints software service robots hardware robot kinematics;cellular manufacturing	Nowadays the flexible configuration of manufacturing cells becomes to an important requirement especially at small and medium sized companies. This method can make the production fast and effective at small series or frequent manufacturing changes. The shop-floor control method - presented in this paper - offers a solution for the facing problem of fast and easy reconfiguration. The hardware of the controller designed modular with software components for online configuration. This solution allows sensor integration on different levels for every part of the manufacturing cell. With unified programming language and the machine specific controllers (post-processing) the cells can be defined easily by different types of human-machine interaction. The shop-floor control architecture is implemented and validated on an Adept SCARA robot. The robot is driven by standalone, low-level, interchangeable, software and hardware components.	component-based software engineering;high- and low-level;human–computer interaction;programming language;rt middleware;scara;video post-processing	Ferenc Tajti;Géza Szayer;Bence Kovács;Peter Korondi	2013	2013 9th Asian Control Conference (ASCC)	10.1109/ASCC.2013.6606341	control engineering;embedded system;real-time computing;engineering	Robotics	-30.393580731041187	-23.748975515569406	31763
4d87edd03359989b895753714ee856beab6d5e05	the learning agent based interactive performance system		An interactive performance system is described that utilizes the concept of intelligent agents to manage its complexity. Real-Time programming techniques adapted from computer games and audio DSP, as well as a basic machine learning technique are utilized to enable high-level user control.		Michael Spicer;B. T. G. Tan;Chew Lim Tan	2003			error-driven learning	HCI	-27.95421356390834	-22.094568643456935	31768
73c025a5dfa385afb4b1dfcd7b5f0a8ee496eee8	opinion transition model under dynamic environment: experiment in introducing personality to knowledge-based systems	verification;coloured petri nets;knowledge based system;dynamic environment;artificial intelligence;expert system modelling		knowledge-based systems	Masakatsu Ohta;Toshiyuki Iida;Tsukasa Kawaoka	1995			legal expert system;verification;simulation;computer science;knowledge management;artificial intelligence;knowledge-based systems	AI	-26.098476950494526	-8.86648527347374	31797
4914b212996075a5296a16b71cad9d079cc62684	a theory of hung juries and informative voting	voting rule	This paper investigates a jury decision when hung juries and retrials are possible. When jurors in subsequent trials know that previous trials resulted in hung juries, informative voting cannot be an equilibrium regardless of voting rules unless the probability that each juror receives the correct signal when the defendant is guilty is identical to the one when he is innocent. Thus, while Coughlan (2000) claims that mistrials facilitate informative voting, our result shows that such an assertion holds only in limited circumstances.	assertion (software development);information	Fuhito Kojima;Yuki Takagi	2010	Games and Economic Behavior	10.1016/j.geb.2009.12.003	bullet voting;economics;cardinal voting systems;condorcet method;disapproval voting	AI	-7.326472718486247	-3.936523237167085	31805
203be9a047ae752091089953d0c022d0e30ac6b2	exploring auction mechanisms for role assignment in teams of autonomous robots	theoretical framework;dynamic environment;autonomous robot	We are exploring the use of auction mechanisms to assign role s within a team of agents operating in a dynamic environment. Dependi ng on the degree of collaboration between the agents and the specific auction policies employed, we can obtain varying combinations of role assignments that can affect both the speed and the quality of task execution. In order to examine t his extremely large set of combinations, we have developed a theoretical framew ork and an environment in which to experiment and evaluate the various opti ons n policies and levels of collaboration. This paper describes our framewor k and experimental environment. We present results from examining a set of repr esentative policies within our test domain — a high-level simulation of the RoboC up four-legged league soccer environment.	high- and low-level;ibm notes;internet information services;ork;robot;simulation	Vanessa Frías-Martínez;Elizabeth Sklar;Simon Parsons	2004		10.1007/978-3-540-32256-6_49	simulation;knowledge management	AI	-16.026575426737903	-11.272205093600094	31808
2e46a7f66c37662de5ac06b13e80eff1175156e4	stigmergy, self-organization, and sorting in collective robotics	self organization collective robotics stigmergy;collective robotics;self organization;life form;physical environment;social insect;environmental change;stigmergy;spatial orientation	Many structures built by social insects are the outcome of a process of self-organization, in which the repeated actions of the insects interact over time with the changing physical environment to produce a characteristic end state. A major mediating factor is stigmergy, the elicitation of specific environment-changing behaviors by the sensory effects of local environmental changes produced by previous behavior. A typical task involving stigmergic self-organization is brood sorting: Many ant species sort their brood so that items at similar stages of development are grouped together and separated from items at different stages of development. This article examines the operation of stigmergy and self-organization in a homogeneous group of physical robots, in the context of the task of clustering and sorting Frisbees of two different types. Using a behavioral rule set simpler than any yet proposed for ant sorting, and having no capacity for spatial orientation or memory, the robots are able to achieve effective clustering and sorting showing all the signs of self-organization. It is argued that the success of this demonstration is crucially dependent on the exploitation of real-world physics, and that the use of simulation alone to investigate stigmergy may fail to reveal its power as an evolutionary option for collective life forms.	algorithm;behavior;cluster analysis;eusociality;robot (device);robotics;self-organization;simulation;sorting;space perception;stigmergy;statistical cluster	Owen Holland;Chris Melhuish	1999	Artificial Life	10.1162/106454699568737	biology;self-organization;simulation;spatial disorientation;environmental change;artificial intelligence	AI	-16.481462242418257	-14.437190713726826	31809
44afef640ab967df784da3f708d22e32aea03178	off-road robotics—an overview	universitaet;biologisch;rrlab;karsten berns;seminar;roboter;control architectures;robotik;robotics;studium;praktikum;navigation;forschung;robot control;control architecture;informatik;agrosy;lehre;off road;computer science;autonom;perception;kaiserslautern;vorlesung;robot;environment representation	This article gives an overview of the current state of research in the field of off-road robotics. It focuses on techniques used in the areas of perception, environment representation, as well as navigation, and introduces different types of robot control systems. A presentation of different applications is given along with an outlook on future developments.	autonomy;control system;machine perception;microsoft outlook for mac;robot control;robotics	Karsten Berns;Klaus-Dieter Kuhnert;Christopher Armbrust	2011	KI - Künstliche Intelligenz	10.1007/s13218-011-0100-4	robot;computer vision;navigation;simulation;computer science;artificial intelligence;robot control;robotics;perception	Robotics	-30.931907468027365	-20.886723575042435	31902
0773bd0a3248e32bc0d78c5d15516c3d8f1140c5	efficient shortest path finding of k-nearest neighbor objects in road network databases	shortest path;nearest neighbor queries;location based service;road network;building block;index structure;path finding;k nearest neighbor;k nearest neighbor query	This paper addresses an efficient path finding scheme that complements classic k-NN (Nearest Neighbor) queries for the road network. Aiming at finding both k objects and the shortest paths to them at the same time, this paper first selects candidate objects by the k-NN search scheme based on the underlying index structure and then finds the path to each of them by the modified A* algorithm. The path finding step stores the intermediary paths from the query point to all of the scanned nodes and then attempts to match the common segment with a path to a new node, instead of repeatedly running the A* algorithm for all k points. Additionally, the cost to the each object calculated in this step makes it possible to finalize the k objects from the candidate set as well as to order them by the path cost. Judging from the result, the proposed scheme can eliminate redundant node scans and provide one of the most fundamental building blocks for location-based services in the real-life road network.	a* search algorithm;database;finalize (optical discs);k-nearest neighbors algorithm;location-based service;network model;pathfinding;real life;shortest path problem	Sung-Hyun Shin;Sang-Chul Lee;Sang Wook Kim;Junghoon Lee;Eul Gyu Im	2010		10.1145/1774088.1774446	average path length;computer science;pathfinding;machine learning;location-based service;pattern recognition;data mining;nearest neighbor search;shortest path problem;k-nearest neighbors algorithm;k shortest path routing	DB	-25.77859538182965	-0.10313814691322037	31923
58ae1f48bbd24859af0377ebd6af7a23429ba187	a virtual testbed for critical incident investigation with autonomous remote aerial vehicle surveying, artificial intelligence, and decision support.		Autonomous robotics and artificial intelligence techniques can be used to support human personnel in the event of critical incidents. These incidents can pose great danger to human life. Some examples of such assistance include: multi-robot surveying of the scene; collection of sensor data and scene imagery, real-time risk assessment and analysis; object identification and anomaly detection; and retrieval of relevant supporting documentation such as standard operating procedures (SOPs). These incidents, although often rare, can involve chemical, biological, radiological/nuclear or explosive (CBRNE) substances and can be of high consequence. Real-world training and deployment of these systems can be costly and sometimes not feasible. For this reason, we have developed a realistic 3D model of a CBRNE scenario to act as a testbed for an initial set of assisting AI tools that we have developed. 1 Background and Related Research We have developed a bespoke virtual environment (VE) model of a critical incident using a state-of-the-art games engine. We use this model to test a range of assisting AI technologies related to information gathering, real-time analytics and decision support. We developed the VE with the core purpose of using it as a testbed for the development of a range of investigation assisting AI tools. VEs have also been used to train first responder personnel in near photo-realistic yet safe conditions. Chroust and Aumayr [2] note that virtual reality can support training by allowing simulations of potential incidents, as well as the consequences of various courses of action, in a realistic way. There are virtual reality training systems which solely focus on CBRN disaster preparedness. Some of these are outlined by Mossel et al. [9]. Other example uses of virtual worlds include Second Life and Open Simulator [4,3]. CBRNE incident assessment is a critical task which poses significant risks and endangers the lives of human investigators. For this reason, many research projects focus on the use of robots such as Micro Unmanned Aerial Vehicles (MUAV) to carry out remote sensing in such hazardous environments [7,1]. Others can include CBRNE mapping for first responders [6] and multi-robot reconnaissance for detection of threats [12]. 1 This research has received funding from the European Union’s Horizon 2020 Programme under grant agreement No. 700264. ar X iv :1 80 9. 06 24 4v 1 [ cs .A I] 1 4 Se p 20 18 2 A Virtual Testbed for Critical Incidents We have developed and implemented a baseline set of decision support systems for investigating critical incidents. In order to test these in an efficient and cost effective manner, we have developed 3D world models of typical CBRNE incidents using a physics-based game engine. These models include virtual representations of Robotic Aerial Vehicles (RAVs). After identifying the area of interest, multiple RAVs are deployed to survey the scene. The RAVs, which are fitted with sensors and cameras, operate as a multi-agent robot swarm and divide the work up between them. All information is relayed to a central hub in which our Image Analysis module uses a Deep Neural Network (DNN) to detect and identify relevant objects in images taken by RAV cameras. It also uses a DNN to perform pixel-level semantic annotation of the terrain, to support subsequent route-planning for Robotic Ground-based Vehicles (RGVs). Our Probabilistic Reasoning module assesses the likelihood of different threats, as information arrives from the scene commander, survey images and sensor readings. Our Information Retrieval module ranks documentation, using TF-IDF, by relevance to the incident. All interactions are managed by our purpose-built JSON-based communications protocol, which is also supported by real-world RAVs, cameras and sensor systems. This keeps the system loosely coupled, and will support future testing in real-world environments. This work was undertaken as part of a project called ROCSAFE (Remotely Operated CBRNE Scene Assessment and Forensic Examination) and this demonstration overview is based on Smyth et al. [14]. 2.1 Modelling a Critical Incident Scenario To facilitate the development and testing of our AI tools, we have designed, developed and publicly released a VE [15] using the Unreal Engine (UE). This is a suite of tools for creating photo-realistic simulations with accurate real-world physics. UE is open source, scalable and supports plugins that allow the integration of RAVs and RGVs into the environment. For this demonstration, we chose an operational scenario to model that consists of a train carrying radioactive material in a rural setting. We used Microsoft’s AirSim [13] plugin to model the RAVs. AirSim exposes various APIs to allow fine-grain control of RAVs, RGVs and their associated components. We have replicated a number of APIs from real-world RAV and RGV systems to facilitate the application of our AI tools to real-world critical incident use-cases in the future, after firstly testing them in the VE.	aerial photography;anomaly detection;application programming interface;artificial intelligence;autonomous robot;baseline (configuration management);bespoke;communications protocol;decision support system;deep learning;documentation;game engine;image analysis;information retrieval;interaction;json;loose coupling;multi-agent system;open-source software;opensimulator;pixel;plug-in (computing);real-time locating system;real-time transcription;relevance;risk assessment;scalability;second life;sensor;simulation;software deployment;standard operating procedure;swarm robotics;testbed;tf–idf;usb hub;unmanned aerial vehicle;unreal development kit;virtual reality;virtual world	Ihsan Ullah;Sai Abinesh;David L. Smyth;Nazli B. Karimi;Brett Drury;Frank G. Glavin;Michael G. Madden	2018	CoRR		computer science;software deployment;anomaly detection;documentation;decision support system;risk assessment;testbed;european union;robotics;artificial intelligence	AI	-23.13259178333148	-23.01673402986097	31952
51e870cb74025053137ab2b56c8f583f4f7da840	the shape of science	humanidades;filosofia etica	Our scientific efforts to describe and account for the world have not taken the form of a single, tightly integrated investigation. Instead, they have led us to a rich collection of largely independent studies—studies which are often in tension both within and without. In broad, our best scientific descriptions of the world at any given time are conceptually varied, in tension with each other in various respects, and often in conflict at various levels ranging from small scale puzzles to deep and often persistent disagreements over questions which different fields appear to address. Though conflicts are often resolved in the course of time, the persistent presence of conflict in our overall understanding of the world poses a challenge to prevailing assumptions that a best overall description of how things are must be fully consistent or probabilistically coherent. Much of what philosophers of science have had to say about the epistemology of science aims at a picture of the results of scientific investigation as a consistent and unified world view. This was especially true for the logical empiricist tradition, but it remains true for many more recent technical and logically oriented approaches. This is not necessarily a problem for the basic insights that have emerged from that work; much of the resulting philosophical accounts may apply nevertheless, if not to science as a whole, then at least to parts of it treated severally, as well as to our ideas about what an ideal, fully satisfying scientific world view would be like. But I believe our understanding of science has nevertheless been distorted by a failure to recognize and explore the logical tensions that are part of our understanding of the world at any given time.	coherence (physics)	M. Bryson Brown	2014	Synthese	10.1007/s11229-014-0475-5	philosophy;epistemology	PL	-28.859928966080165	-12.67926374560014	31959
65faf9c9f64aae779fcbcf7fd3d9bfeb57767a51	direction election in flocking swarms	mobile robots;swarms;flocking;direction election	Swarm formation and swarm flocking may conflict each other. Without explicit communication, such conflicts may lead to undesired topological changes since there is no global signal that facilitates coordinated and safe switching from one behavior to the other. Moreover, without coordination signals multiple swarm members might simultaneously assume leadership, and their conflicting leading directions are likely to prevent successful flocking. To the best of our knowledge, we present the first set of swarm flocking algorithms that maintain connectivity while electing direction for flocking, under conditions of no communication. The algorithms allow spontaneous direction requests and support direction changes.		Ohad Ben-Shahar;Shlomi Dolev;Andrey Dolgin;Michael Segal	2014	Ad Hoc Networks	10.1016/j.adhoc.2012.05.001	mobile robot;swarm behaviour;simulation;computer science;artificial intelligence;flocking	Mobile	-13.604644806346899	-14.019592102580331	31988
10f9470a81d9f01c70c2dbcf2b45c90a3eb22b6e	developing metrics for the comparison of sorting and segregation algorithms in a group of minimalist robots			algorithm;robot;sorting	Matthew Wilson	2004				Robotics	-17.12418988447686	-14.434440092380537	32002
c37be78b41f932d41cbc844ffe0b89f331d8f9b1	fast document ranking for large scale information retrieval	inverted index;information retrieval;large scale;document database;indexation	For large document databases, evaluation of ranked queries can be expensive in cpu time, memory usage, and disk traffic. It has been shown that memory usage can be dramatically reduced by use of a simple filtering heuristic that eliminates most documents from consideration. In this paper we show that, by designing inverted indexes explicitly to support filtering, cpu time and disk traffic can also be dramatically reduced. The principle of the index design is that inverted lists are sorted by indocument frequency rather than by document number. In the context of compressed indexes such a re-ordering could result in a large increase in index size. We show, however, that it is possible to use the re-ordering to achieve a net reduction in index size, regardless of whether the index is compressed. Together, these techniques simultaneously achieve savings in cpu time, disk traffic, memory usage, and index size.	information retrieval;ranking (information retrieval)	Michael Persin;Justin Zobel;Ron Sacks-Davis	1994		10.1007/3-540-58183-9_53	document retrieval;inverted index;document clustering;data mining;database;vector space model;information retrieval	Web+IR	-28.994402518067883	2.9888249719604607	32013
11e0c22568612ab26a29ba866eca08c88522bb60	emergently developed cognitive architectures: testing by developmental robotics		How useful are bio-developmental approaches for understanding how cognitive capabilities are acquired? One bio-developmental hypothesis is that human cognition unfolds with maturation as a massive collection of adaptive cognitive “capabilities” expressing pre-structured genetic programs. But the seeming plasticity of human cognition argues against simple formulations of innately-specified anatomical & functional processing system composed of specialized computational modules. One alternative is an architecture using domain-specific predispositions and general learning mechanisms to construct modules from interactions. This lets them emerge and unfold in a self- organized fashion as part of developmental experience. The result is a more dynamic, complex cognitive architecture explaining such things as the drive for sensorimotor control in infants, which is combines the generation of exploratory movements constrained by the interaction of ability and environment followed by the selection and maintenance of adaptive movement patterns (Schlesinger et al. 2000). Such findings are consistent with a view that ontogenetic processes are co-important (and co-dependent) with gene- based evolutionary processes for behavior and cognition.	cognitive architecture;developmental robotics	Gary Berg-Cross	2009			cognitive model;artificial intelligence;machine learning	Robotics	-25.244993363750325	-17.497060274353977	32033
3ecd8ac038ba60ee518ac6523ff21f8fc68dfd94	aide à la décision en ingénierie inverse. une approche s'appuyant sur l'argumentation		Evaluating food quality is a complex process since it relies on numerous criteria historically grouped into four main types: nutritional, sensorial, practical and hygienic qualities. They may be completed by other emerging preoccupations such as the environmental impact, economic phenomena, etc. However, all these aspects of quality and their various components are not always compatible and their simultaneous improvement is a problem that sometimes has no obvious solution, which corresponds to a real issue for decision making. This paper proposes a decision support method in reverse engineering, i.e. guided by the objectives defined for the end products of an agrifood chain. It is materialized by a backward chaining approach based on argumentation.	linear algebra	Rallou Thomopoulos;Madalina Croitoru	2013	Revue d'Intelligence Artificielle	10.3166/ria.27.493-513	artificial intelligence;operations management;mathematics;algorithm	AI	-16.97628764096624	-3.025655568765053	32048
0342b15afd9cc9cf5736b279a3e3c0fa1561cce9	personality trait based simulation model of the e-mail system	simulation and modelling;decision tree;personality trait;system modeling;simulation;time series;information and communication services;social network;visualization;information and communication services not elsewhere classified;traffic analysis;social network analysis;personality traits;information and computing sciences;simulation model;artificial intelligence and image processing;e mail;other information and communication services	Within the area of criminal and terrorist social network analysis, there is little research being done on analysing the communication behavior of criminal and terrorist groups. In this paper, we describe the development of a conceptual simulation model of the e-mail system, which is based on the use of personality trait dimensions to model the e-mail traffic behavior of e-mail users. This conceptual simulation model is being used as a first step for further development in simulating criminal and terrorist communication behavior. We also describe the development of an e-mail traffic analyser system, which uses a decision tree to search for interesting e-mail traffic behavioral patterns, and uses social network and time-series visualisation to provide the details of the interesting traffic patterns. We demonstrate that the personality trait based e-mail system model is useful as a tool for generating e-mail traffic behavioral patterns and that decision trees are useful for finding interesting patterns in the email traffic data.	artificial intelligence;artificial neural network;behavior model;behavioral pattern;decision tree;email;simulation;social network analysis;time series;weka	Mark Jyn-Huey Lim;Michael Negnevitsky;Jacky Hartnett	2006	I. J. Network Security	10.6633/IJNS.200609.3(2).10	social network analysis;simulation;systems modeling;visualization;computer science;decision tree;simulation modeling;time series;big five personality traits;computer security;social network	ML	-18.009211004753734	-22.917097409117904	32086
cdf615d93b886c9489302a0e3fc1fed6cb7f08f5	knowledge representation for robotic vision based on conceptual spaces and attentive mechanisms	conceptual space;time delay;cognitive architecture;robot vision;focus of attention;intelligent system;attractor neural network;knowledge representation;artificial vision;high level language	"""A new cognitive architecture for artificial vision is proposed. The architecture is aimed for an autonomous intelligent system, as several cognitive hypotheses have been postulated as guidelines for its design. The design is based on a conceptual representation level between the subsymbolic level processing the sensory data, and the linguistic level describing scenes by means of a high-level language. The architecture is also based on the active role of a focus of attention mechanism in the link between the conceptual and the linguistic level. The link between the conceptual level and the linguistic level is modelled as a time-delay attractor neural network. I Introduction In classical symbolic reasoning systems, the symbols are related to abstract entities according to model theoretic semantics. This turns out to be completely unsatisfactory for an autonomous agent, that needs to find the meaning for its symbols within its internal representation and in its interaction with the external world, overcoming in some way the well known symbol grounding problem [Chella 1994]. This paper presents a cognitive architecture for an artificial vision system, in which an effective internal representation of the environment is built by means of processes defined over a suitable intermediate level that acts as an intermediary between the sensory data and the symbolic level. We hypothesise three representation levels as the basis of our architectural design: the subsymbolic level, in which the information is strictly related to the sensory data; the linguistic level, in which information is expressed by a symbolic language; and an intermediate, """"prelinguistic"""" conceptual level. At this level the information is characterised in terms of a metric space defined by a certain number of """"cognitive"""" dimensions, independent flom any specific language [Gitrdenfors 1992]. The aim of this level is to generate the very internal representation of the agent's external environment and to provide a precise interpretation for the linguistic level. The interpretation of linguistic level categories is implemented by a mapping between the conceptual and the linguistic levels in terms of a connecfiouist device. Neural networks allow to avoid an exhaustive description of conceptual categories at the symbolic level. Moreover, the measure of similarity between a prototype and a given object is implicit in the behaviour of the network and is determined during the learning phases."""		Antonio Chella;Marcello Frixione;Salvatore Gaglio	1995		10.1007/3-540-60437-5_28	computer vision;computer science;artificial intelligence;communication	AI	-26.187369775947076	-16.08940849853044	32129
e45efbbbc9b85322aebda816bcc1d47b4aeedb12	performance modeling of agent-aided operator-interface interaction for the control of multiple uavs	aircraft control;human machine interaction uav control operator interface automation agent performance modeling;human computer interaction;system performance;time pressure;multi agent systems;aerospace computing;performance model;automatic control unmanned aerial vehicles feedback performance gain system performance automation man machine systems workstations aircraft frequency;performance modeling agent aided operator interface interaction multiple uninhabited air vehicles control human machine interaction uav tactical workstation maritime patrol aircraft;interface model;multi agent systems aircraft control human computer interaction aerospace computing;human machine interaction	The control of multiple uninhabited air vehicles (UAVs) is operator intensive and can involve high levels of workload. Feedback from operators indicates that improvements in operator interfaces would reap significant gains in system performance and effectiveness. Incorporating automation agents in UAV control stations has been proposed as a solution to reduce workload and improve overall human-machine performance. This research investigated the efficacy of agent-aided operator interfaces in a scenario that involved multiple UAVs with the interfaces modeled as part of the UAV tactical workstations of a maritime patrol aircraft. A performance model was developed to compare the difference between mission activities with and without agent aids that was reflected in task conflict frequency, number of ongoing tasks, and task completion time. The simulation results revealed that agent-aided interfaces permitted operators to continue working under high time pressure, resulting in critical tasks being achieved in reduced time.	airborne ranger;augmented cognition;design of experiments;information architecture institute;intelligence amplification;interaction;interrupt;numerical analysis;prototype;router (computing);simulation;unmanned aerial vehicle;user interface;workstation	Ming Hou;Robert D. Kobierski	2005	2005 IEEE International Conference on Systems, Man and Cybernetics	10.1109/ICSMC.2005.1571518	embedded system;simulation;computer science;artificial intelligence;multi-agent system;computer performance	Robotics	-24.684934431065354	-23.834314414545624	32138
f55e47a14de14c4cb26855a3fddcd44c6d67ddf1	query expansion and query translation as logical inference	informatica;elargissement question;cross language;inferences;linguistique;probability;translating;information retrieval;logic;logique floue;automatisation;logica difusa;pregunta documental;automatizacion;evaluation methods;question documentaire;fuzzy logic;traduction;linguistica;croisement de langues;recherche information;probability theory;inferencia;query;theorie probabilite;teoria probabilidad;traduccion;informatique;recuperacion informacion;query translation;computer science;multilinguisme;query expansion;models;multilingualism;inference;requete;multilinguismo;automation;linguistics	A number of studies have examined the problems of query expansion in monolingual IR, and query translation for cross-language IR. However, no link has been made between them. This paper first shows that query translation is a special case of query expansion. There is also another set of studies on inferential IR. Again, there is no relationship established with query translation or query expansion. The second claim of this paper is that logical inference is a general form that covers query expansion and query translation. This analysis provides a unified view of different sub-areas of IR. We further develop the inferential IR approach in two particular contexts: using fuzzy logic and probability theory. The evaluation formulas obtained are shown to strongly correspond to the those used in other IR models. This indicates that inference is indeed the core of advanced IR .	cross-language information retrieval;evaluation function;fuzzy logic;inferential programming;inferential theory of learning;level of detail;machine translation;query expansion	Jian-Yun Nie	2003	JASIST	10.1002/asi.10214	fuzzy logic;natural language processing;probability theory;sargable;query optimization;query expansion;web query classification;ranking;boolean conjunctive query;computer science;query by example;automation;probability;rdf query language;view;logic;information retrieval;algorithm;query language;statistics;spatial query	Web+IR	-20.59621348739	-0.44386425128279483	32170
54d7f3046945216e61967003aa848bfb3c694ca0	on the maximum design earthquake in disaster prevention planning	probability;model performance;utility function;investments costs equations earthquake engineering systems engineering and theory cities and towns performance loss insurance history;earthquakes;investment;loss function;probability earthquake disaster prevention planning socio economic view seismic motion level utility functions loss functions insurance investment;socio economic effects earthquakes disasters emergency services probability investment insurance;insurance;socio economic effects;disasters;emergency services	After the Hanshin-Awaji Earthquake, researchers have generally agreed that a disaster prevention plan should take into account a strong seismic motion which exceeds the maximum past level and destroys the city or region. However, many of the issues discussed remain on the methodology of how to determine the reasonable level. This study proposes a methodology to determine the level from a socio-economic viewpoint by focusing the level of remaining functions for reconstruction. Through numerical examinations on the model performance under several kinds of utility functions and loss functions, the usefulness of the proposed model is confirmed. The proposed model gives a framework for further detailed discussion, including an introduction of a policy mix of seismic improvement and inter-regional seismic insurance.		Hideyuki Kita;Keishi Tanimoto;Muneta Yokomatsu	2001		10.1109/ICSMC.2001.973093	actuarial science;insurance;earthquake scenario;investment;probability;loss function	Robotics	-10.487529888935521	-18.968082454255853	32267
ca89894618c2b9aa7f3e21175a8f644b45229f56	constructing the complete linguistic-based and gap-oriented quality function deployment	linguistic variable;quality function deployment;house of quality;aggregation operator;linguistic weighted aggregation operator	This study attempts to construct a novel quality function deployment (QFD) model under a pure linguistic environment by assessing customer needs, evaluating the relationship between customer needs and solution schemes, and prioritizing the solution schemes. Customer needs that are difficult to quantify can be properly characterized using linguistic variables. The tolerance capacity of the results can also further enhance by the linguistic QFD, especially in the gap generated when converting customer needs to solution schemes. Hence, the essence for the proposed approach differs from the common numerical or approximate linguistic QFD model. Operation of the linguistic QFD is described in detail using an algorithm and simple example.	national supercomputer centre in sweden;numerical analysis;quality function deployment;software deployment	Shih-Yuan Wang	2010	Expert Syst. Appl.	10.1016/j.eswa.2009.06.090	quality function deployment;house of quality	ECom	-5.538569230092064	-17.493300746749707	32296
3c2ce6294bb07c9f2f44a5a88d15fc34b5869f42	introduction to the special issue on telework		Taylor & Francis makes every effort to ensure the accuracy of all the information (the “Content”) contained in the publications on our platform. However, Taylor & Francis, our agents, and our licensors make no representations or warranties whatsoever as to the accuracy, completeness, or suitability for any purpose of the Content. Any opinions and views expressed in this publication are the opinions and views of the authors, and are not the views of or endorsed by Taylor & Francis. The accuracy of the Content should not be relied upon and should be independently verified with primary sources of information. Taylor and Francis shall not be liable for any losses, actions, claims, proceedings, demands, costs, expenses, damages, and other liabilities whatsoever or howsoever caused arising directly or indirectly in connection with, in relation to or arising out of the use of the Content.	francis;primary source;telecommuting	Sridhar Narasimhan;Kunihiko Higa	1996	J. Org. Computing and E. Commerce	10.1080/10919399609540282	knowledge management;computer science	Robotics	-15.267871514635354	-5.617683142850808	32306
30bf4f1c5353fe15c763bc8b737905c4e8d6921a	a multi-criteria group decision making model for performance evaluation of commercial banks	pragmatics;performance evaluation;multi criteria group decision making bsc performance evaluation linguistic 2 tuple;indexes;linguistic information multicriteria group decision making model commercial bank performance evaluation index system balanced scorecard;computational modeling;operations research banking decision making;numerical models;pragmatics decision making numerical models performance evaluation computational modeling indexes	It is an important issue to evaluate the performance of commercial banks. Based on the balanced scorecard, this paper introduces a performance evaluation index system. By using the multi-criteria group decision making model that combines the numerical and linguistic information, the paper gives the decision making process to choose the best bank. The computational process is illustrated by an example.	computation;numerical analysis;performance evaluation	Le Jiang;Hongbin Liu	2013	2013 10th International Conference on Fuzzy Systems and Knowledge Discovery (FSKD)	10.1109/FSKD.2013.6816330	database index;influence diagram;decision engineering;computer science;knowledge management;management science;computational model;business decision mapping;pragmatics	Robotics	-5.051984291323243	-17.73915031386933	32414
58970870407bf603acb05ac1c887dc352ea9f41a	structural aspects of semantic-directed clusters	conceptualization;analisis datos;semantics;intelligence artificielle;semantica;semantique;conceptualizacion;data analysis;school of automation;artificial intelligence;analyse donnee;inteligencia artificial;classification automatique;automatic classification;clasificacion automatica;conceptualisation;computer science automation formerly	Knowledge-based clusters are studied from the structural point of view. Generalized descriptions for such clusters are stated and illustrated. Peculiarities of certain knowledge-based cluster configurations are highlighted. The adequacy of the connectives logical and (“and”) logical or (“exclusive-or”) in describing such clusters is justified. The definition of “concept” is elaborated from the clustering point of view and used to establish the equivalence between, descriptions of clusters and concepts. The order-independence of semantic-directed clustering approach is established formally based on axiomatic considerations.	semantic network	B. Shekar;M. Narasimha Murty;G. Krishna	1989	Pattern Recognition	10.1016/0031-3203(89)90039-3	conceptualization;computer science;artificial intelligence;data mining;semantics;data analysis;algorithm	Vision	-22.01656221913025	-0.8683060930589849	32416
61b287bff2fd0a5f0bd816a7390d803d28210654	hybrid and evolutionary agent-based social simulations using the pax framework	global communication;application hybrid intelligent systems agent based social simulations abss evolutionary algorithms cultural algorithms;hybrid intelligent systems;hybrid evolutionary agent model;agent modeling;agent based social simulation;dengue fever spreading scenario;cultural algorithms;hospitals;hybrid intelligent system;genetics;evolutionary agent based social simulations;social sciences computing multi agent systems;multi agent systems;agent based social simulations abss;social sciences computing;cultural component;dengue fever;evolutionary algorithms;cities and towns;humans;evolutionary algorithm;decision component;communities;genetic component;application;cultural component evolutionary agent based social simulations hybrid evolutionary agent model plausible agents matrix framework dengue fever spreading scenario decision component genetic component;plausible agents matrix framework;genetics cultural differences intelligent agent biological system modeling computational modeling global communication evolution biology context modeling hybrid intelligent systems electronic mail;cultural differences	This paper investigates a new hybrid evolutionary agent model for agent-based social simulations (ABSS), which incorporates two decision components: (i) sub-symbolic (genetic) and (ii) symbolic (cultural). These components are coherently combined to produce a more plausible agent model. Experiments were carried out using the Plausible Agents Matrix (PAX) framework, and modeled a real dengue fever spreading scenario. They aim to analyze the qualitative and quantitative predictive power of the model. Previous work has explored the impact of structuring elements on agents’ behaviors and the impacts of communication mechanisms on agents’ behaviors using PAX. In this paper we investigated three types of agent models regarding to the combination of decision components: (1) agents only with genetic component; (2) agents only with cultural component; and (3) agents with both genetic and cultural components. Results show the importance of each component in the model and their synergic effects when combined.	agent-based model;agent-based social simulation;artificial intelligence;component-based software engineering;computer simulation;synergy	Fernando Buarque de Lima Neto;Marcelo Souza Pita;Hugo Serrano Barbosa Filho	2009	2009 Ninth International Conference on Intelligent Systems Design and Applications	10.1109/ISDA.2009.137	simulation;computer science;artificial intelligence;hybrid intelligent system;evolutionary algorithm;dengue fever;cultural diversity	AI	-18.260746561577147	-16.820852640942036	32417
d1f9c8d9a9e034c1329fd3d64009d27010b2ee17	analyzing the social behavior of contract net protocol	contract net protocol;social behavior;negotiation protocol;quantitative analysis;problem solving	Contract Net Protocol (CNP) assigns subtasks to agents which are involved in multiagent problem solving. Although the logical aspects of the negotiation protocol have been analyzed, the social behavior of protocol dynamics remain unclear.  This paper introduces a quantitative analysis of protocol dynamics, an essential for constructing continuous realtime applications. We perform an application independent simulation to analyze the social behavior of CNP. We obtain the following results: contractor utilization rate (contractor utility) increases together with the system load while the manager utilization rate (manager utility) decreases; when the number of agents increases, the contractor utility rises while the manager utility does not change; the uniformity of agents causes the concentration of bids and awards, and thus decreases the manager and the contractor utility.      Our simulation results are used to analyze the social behavior of Enterprise, a famous CNP application, and point out the inherent problem of Enterprise.    	contract net protocol	Cheng Gu;Toru Ishida	1996		10.1007/BFb0031850	knowledge management;business;social psychology;computer security	ECom	-9.971817841020554	-10.379464251920425	32484
8a29745bd87daa9eb2756a16ad06acd9813b750b	simulating computational societies	multi agent system;simulation framework;agent architecture	Multi-agent systems can be considered from a variety of perspectives. One such perspective arises from considering the architecture of an agent itself. Another is that of an instantiated agent architecture and its interaction with its peers in a MAS. A third perspective is that of an external observer. These three perspectives cover a potentially overlapping but essentially distinct set of issues concerning MAS simulation and modelling. In this paper, we consider each of these perspectives in turn and demonstrate how a simulation framework can support a collective treatment of such concepts. We discuss the implications for agent development and agent society design arising from the results and analysis of our simulation approach.	agent architecture;computation;modeling language;multi-agent system;simulation	Lloyd Daniel Kamara;Alexander Artikis;Brendan Neville;Jeremy V. Pitt	2002		10.1007/3-540-39173-8_5	simulation;computer science;knowledge management;management science;agent-based social simulation	AI	-21.22202940899738	-13.398201259974448	32502
909d101feb7a6172558055e50b69c2ff9765fbe5	rational dynamics and epistemic logic in games	fixed point;dynamic logic;public announcement;epistemic logic;model updating;recursive algorithm;backward induction;solution concept;strategic game;rationality	Game-theoretic solution concepts describe sets of strategy profiles that are optimal for all players in some plausible sense. Such sets are often found by recursive algorithms like iterated removal of strictly dominated strategies in strategic games, or backward induction in extensive games. Standard logical analyses of solution sets use assumptions about players in fixed epistemic models for a given game, such as mutual knowledge of rationality. In this paper, we propose a different perspective, analyzing solution algorithms as processes of learning which change game models. Thus, strategic equilibrium gets linked to fixed-points of operations of repeated announcement of suitable epistemic statements. This dynamic stance provides a new look at the current interface of games, logic, and computation.	algorithm;backward induction;computation;dynamic epistemic logic;epistemic modal logic;fits;finite-state machine;fixed point (mathematics);game theory;iteration;lawrence a. hyland;nash equilibrium;rational agent;rationality;recursion;temporal logic;theory;viz: the computer game	Johan van Benthem	2007	IGTR	10.1142/S0219198907001254	dynamic logic;epistemic modal logic;economics;rationality;mathematics;fixed point;microeconomics;mathematical economics;sequential game;backward induction;solution concept;algorithm;recursion	AI	-9.999327593053415	-1.5639756867539314	32508
476adfa355ca1ff5dcfda0577ac138d28292a75f	how albot0 finds its way home: a novel approach to cognitive mapping using robots	spatial cognition;robotics;inexact map;cognitive mapping	Much of what we know about cognitive mapping comes from observing how biological agents behave in their physical environments, and several of these ideas were implemented on robots, imitating such a process. In this paper a novel approach to cognitive mapping is presented whereby robots are treated as a species of their own and their cognitive mapping is being investigated. Such robots are referred to as Albots. The design of the first Albot, Albot0 , is presented. Albot0 computes an imprecise map and employs a novel method to find its way home. Both the map and the return-home algorithm exhibited characteristics commonly found in biological agents. What we have learned from Albot0 's cognitive mapping are discussed. One major lesson is that the spatiality in a cognitive map affords us rich and useful information and this argues against recent suggestions that the notion of a cognitive map is not a useful one.	algorithm;behavior;biological factors;cognitive map;experiment;lasers;mast/stem cell growth factor receptor kit, human;personnameuse - assigned;physical object;robot (device);sonar (symantec);schmidt decomposition;simultaneous localization and mapping;algorithm;cognitive mapping;sensor (device)	Wai-Kiang Yeap	2011	Topics in cognitive science	10.1111/j.1756-8765.2011.01157.x	psychology;cognitive model;fuzzy cognitive map;cognitive map;computer science;artificial intelligence;robotics;communication;social psychology;cognitive robotics	AI	-26.154639899491173	-16.58171805355605	32513
cf26361c45b891f578980960c66dc4c94ea670cf	subsymbolic approaches to musical composition. a behavioral model			artificial intelligence	Peter Beyls	1990			cognitive psychology;developmental psychology;communication	HCI	-26.18386826747565	-16.458913432394283	32517
d753b4701ae266a25ae4276260ebb5a86900c8d4	measures of uncertainty in expert systems	expert system;possibility theory;fuzzy logic;dempster shafer theory;natural language;bayesian theory;conditional probability;independence;imprecise probability	Abstract This paper compares four measures that have been advocated as models for uncertainty in expert systems. The measures are additive probabilities (used in the Bayesian theory), coherent lower (or upper) previsions, belief functions (used in the Dempster-Shafer theory) and possibility measures (fuzzy logic). Special emphasis is given to the theory of coherent lower previsions, in which upper and lower probabilities, expectations and conditional probabilities are constructed from initial assessments through a technique of natural extension. Mathematically, all the measures can be regarded as types of coherent lower or upper previsions, and this perspective gives some insight into the properties of belief functions and possibility measures. The measures are evaluated according to six criteria: clarity of interpretation; ability to model partial information and imprecise assessments, especially judgements expressed in natural language; rules for combining and updating uncertainty, and their justification; consistency of models and inferences; feasibility of assessment; and feasibility of computations. Each of the four measures seems to be useful in special kinds of problems, but only lower and upper previsions appear to be sufficiently general to model the most common types of uncertainty.	expert system	Peter Walley	1996	Artif. Intell.	10.1016/0004-3702(95)00009-7	fuzzy logic;independence;possibility theory;imprecise probability;conditional probability;dempster–shafer theory;bayesian probability;computer science;machine learning;mathematics;natural language;expert system;algorithm;statistics	AI	-15.319021203951033	0.07209954876669582	32555
deb88108c3650a684c9c60fda700f1dfee835ad8	an agent-based application for home intelligence	agent based	Ambient Intelligence is an interesting research application area for Multi-Agent Systems. In this paper, we focus on the methodological support that the agent-oriented methodologies can provide to such kind of systems: in particular we present HomeManager, an application for the control of an intelligent home designed through SODA—an agent-oriented methodology. In this vision, the house is seen as an intelligent environment made of independent and distributed devices, each equipped with an agent to support the user’s goals and tasks.	ambient intelligence;home automation;intelligent environment	Ambra Molesini;Enrico Denti;Andrea Omicini	2009			computer science;intelligent agent	AI	-27.050573644281684	-20.256618007252197	32593
1da98073c44ad1b82cd95d068d0b6490f57eb0ba	externalities, potential, value and consistency	partition function;satisfiability;shapley value potential consistency games in partition function form;shapley value	We provide new characterization results for the value of games in partition function form. In particular, we use the potential of a game to de ne the value. We also provide a characterization of the class of values which satis es one form of reduced game consistency.	ne (complexity);partition function (mathematics)	Bhaskar Dutta;Lars Ehlers;Anirban Kar	2010	J. Economic Theory	10.1016/j.jet.2010.10.007	bondareva–shapley theorem;mathematical optimization;discrete mathematics;example of a game without a value;economics;mathematics;shapley value;partition function;welfare economics;satisfiability	ECom	-6.190111994704063	-1.3750263607879614	32605
2e82910bffeff2db44a5765c84910a4ce6868149	decision maker's knowledge level and the selection of decision strategies in using a decision support system	decision support system		decision support system;game-maker;knowledge level	Hyung-Min Michael Chung	1993			r-cast;decision rule;management science;computer science;human–computer interaction;decision analysis cycle;evidential decision theory;business decision mapping;decision tree;decision analysis;decision support system	AI	-30.87320358044014	-9.130354217174913	32618
7ebb4ee6809486660eb596e5966615eacc60daa7	risk perception in modeling malware propagation in networks	complex networks;fluctuations;propagation model;risk analysis;probability density function;nonlinear effect;linear response;scale free network;random networks;data mining;scale free;computational modeling;malware;propagation model perception malware;sis model risk perception malware propagation;numerical simulation fluctuations switches;mathematical model;risk perception;malware propagation;invasive software;perception;numerical models;mean field approximation;risk analysis invasive software;sis model;numerical simulation	We investigate the effects of risk perception in a SIS model for malware propagating in different types of networks such as regular, random and scale-free. We assume that the perception of the risk of being infected rely on the fraction of neighbors that are infected. The effects are mainly affected by two parameters denoted by J and  , which models the linear response and nonlinear effects respectively. They can reduce the infectivity of the malware as a function of the infected neighbors. We study the models in the mean-field approximation and by numerical simulations for the three kinds of networks. The results show that for homogeneous and random networks, there is always a value of perception that stops the malwares. But in the “worst case” scenario of a scale-free network with diverging connectivity, a linear perception can not stop the malwares. With the nonlinear increase of the perception risk, however, the malware tends to be extinct. This transition is not continuous and is presumably induced by fluctuations in center nodes such as hubs or switches. An understanding of the risk perception in modeling malware propagation in networks is very important for designing effective detection and prevention strategies for such networks.	approximation;best, worst and average case;ethernet hub;flow network;malware;network switch;nonlinear system;numerical analysis;simulation;software propagation	Changguang Wang;Shuai Fu;Xu Bai;Li-jing Bai	2009	2009 WRI World Congress on Computer Science and Information Engineering	10.1109/CSIE.2009.115	computer simulation;simulation;computer science;scale-free network;machine learning;computer security;statistics	ML	-13.586177137130463	-16.943598527023276	32630
25d4fc1aa91830cc303b136e561d041371bc9c29	the niagara cipher - part i		Taylor & Francis makes every effort to ensure the accuracy of all the information (the “Content”) contained in the publications on our platform. However, Taylor & Francis, our agents, and our licensors make no representations or warranties whatsoever as to the accuracy, completeness, or suitability for any purpose of the Content. Any opinions and views expressed in this publication are the opinions and views of the authors, and are not the views of or endorsed by Taylor & Francis. The accuracy of the Content should not be relied upon and should be independently verified with primary sources of information. Taylor and Francis shall not be liable for any losses, actions, claims, proceedings, demands, costs, expenses, damages, and other liabilities whatsoever or howsoever caused arising directly or indirectly in connection with, in relation to or arising out of the use of the Content.	cipher;francis;primary source	Brian Leigh Dunnigan;Frank Lewis;Mike Barlow	1990	Cryptologia	10.1080/0161-119091864832		Robotics	-15.060001432305409	-5.656116445526257	32731
8923885558da15cf07dfc687ef736cc57fca3309	the spirituality of human consciousness: a catholic evaluation of some current neuro-scientific interpretations	free will;animal intelligence;soul;religion;personhood;resilience	Catholic theology's traditional understanding of the spiritual nature of the human person begins with the idea of a rational soul and human mind that is made manifest in free will--the spiritual experience of the act of consciousness and cause of all human arts. The rationale for this religion-based idea of personhood is key to understanding ethical dilemmas posed by modern research that applies a more empirical methodology in its interpretations about the cause of human consciousness. Applications of these beliefs about the body/soul composite to the theory of evolution and to discoveries in neuroscience, paleoanthropology, as well as to recent animal intelligence studies, can be interpreted from this religious and philosophical perspective, which argues for the human soul as the unifying cause of the person's unique abilities. Free will and consciousness are at the nexus of the mutual influence of body and soul upon one another in the traditional Catholic view, that argues for a spiritual dimension to personality that is on a par with the physical metabolic processes at play. Therapies that affect consciousness are ethically problematic, because of their implications for free will and human dignity. Studies of resilience, as an example, argue for the greater, albeit limited, role of the soul's conscious choices in healing as opposed to metabolic or physical changes to the brain alone.		Terence A. McGoldrick	2012	Science and engineering ethics	10.1007/s11948-012-9387-2	psychology;medicine;philosophy;sociology;social psychology	ML	-25.593892372855386	-12.999685261540534	32762
b5315b6c9b867678bf5d8af1275a00924f2c6a21	non-sentential vs. ellipsis approaches: review and extensions		Abstract#R##N##R##N#Non-sententials (also known as fragments, elliptical structures) can be roughly characterized as free-standing utterances, which are, or at least appear to be, smaller than a sentence. The persisting controversy regarding non-sententials is the following: are they pretty much what you see, base-generated words, phrases, or small clauses (non-sentential analysis), or are they full finite sentences that have undergone deletion/ellipsis (sentential/ellipsis analysis). This issue is all the more important today given that various interdisciplinary enterprises hinge on how it is resolved, including studies of language acquisition, language disorders, language evolution, and language representation in the brain. This review focuses on the most recent wave of controversy pertaining to non-sententials and provides a critical assessment of the crucial connectivity/anti-connectivity arguments, which are the backbone of both approaches, including islandhood, case, preposition stranding, and complementizer effects. The conclusion of this review is that a careful reexamination of each of these (anti-)connectivity phenomena demonstrates that the non-sentential approach is at least as successful as the ellipsis approach in accommodating these effects. Moreover, the non-sentential approach opens up new and exciting prospects for enriching syntactic theory with new data and perspectives, as well as provides a better framework for interdisciplinary extensions mentioned above.		Ljiljana Progovac	2013	Language and Linguistics Compass	10.1111/lnc3.12044	psychology;natural language processing;computer science;linguistics;communication	NLP	-27.384205690135726	-13.954498666877376	32770
b23e269281a304f9da31f6a34c957912a39d79f9	a fuzzy query optimization approach for multidatabase systems	approximate fuzzy value;multidatabase system;query optimization;fuzzy cost model;global query optimization;fuzzy optimization	A crucial challenge for global query optimization in a multidatabase system (MDBS) is that some local optimization information, such as local cost parameters, may not be accurately known at the global level because of local autonomy. Traditional query optimization techniques using a crisp cost model may not be suitable for an MDBS because precise information is required. In this paper we present a new approach that performs global query optimization using a fuzzy cost model that allows fuzzy information. We suggest methods for establishing a fuzzy cost model and introduce a fuzzy optimization criterion that can be used with a fuzzy cost model. We discuss the relationship between the fuzzy optimization approach and the traditional (crisp) optimization approach and show that the former has a better chance to find a good execution strategy for a query in an MDBS environment, but its complexity may grow exponentially compared with the complexity of the later. To reduce the complexity, we suggest to use so-called k-approximate fuzzy values to approximate all fuzzy values during fuzzy query optimization. It is proven that the improved fuzzy approach has the same order of complexity as the crisp approach.	query optimization	Qiang Zhu;Per-Åke Larson	1997	International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems	10.1142/S0218488597000518	query optimization;defuzzification;fuzzy transportation;fuzzy classification;computer science;fuzzy number;neuro-fuzzy;machine learning;data mining;database;fuzzy associative matrix;fuzzy set operations	DB	-24.77626457230404	1.883344953716512	32850
0e5adfc2406fdbea124094b1b84712b214be0dca	how similar is very young to 43 years of age? on the representation and comparison of polymorphic properties	case base reasoning;polymorphism;property value	Intelligent computer systems rely on more or less complex computational entities that represent occurrences and events in the real world. Usually, such entities are formed from representational primitives called properties, attributes, features, etc. To reflect varying degrees of uncertainty, originating from human judgement and the intrinsic nature of the world, such property values occur as more or less vague linguistic symbols or exact numeric expressions. Determining similarity between two properties is usually done on either the symbolic or the numeric level. This seems to be too restrictive for case-based reasoning and similar approaches as these often face mixed specifications. In this paper we propose a flexible and systematic scheme for representing crisp properties and two types of fuzzy properties. It also provides a consistent mechanism to establish similarity scores for the various instance combinations.	case-based reasoning;computation;computer;entity;language primitive;vagueness	Werner Dubitzky;Alfons Schuster;John G. Hughes;David A. Bell;Kenneth Adamson	1997			polymorphism;computer science;artificial intelligence;data mining;mathematics;algorithm	AI	-16.613737797593686	0.6838377335116063	32885
4f85220028337b2d25d6de7ce7f0c99216512420	formal engineering frameworks in maritime domain awareness	analytical models;surveillance;observers;trajectory;time series analysis;artificial intelligence;data models	Maritime domain awareness builds on services and systems for interactive situation analysis and decision support to assist marine authorities in their assessment of unfolding situations to determine a response to imminent danger or threats to critical infrastructure or sensitive ecosystems. We propose here a methodical and economically viable approach to systematically develop an advanced situation analysis and decision support framework using formal engineering methods that facilitate continuous design through experimental analysis and validation of situation analysis process models in a realistic operational context. Striving for scalable and extensible solutions, our framework seamlessly integrates qualitative and quantitative modeling methods. An exploratory executable prototype operating on maritime surveillance data has been developed and is being evaluated, gradually extending the feature scope.	algorithm;anomaly detection;coherence (physics);computation;conformance testing;continuous design;decision support system;ecosystem;executable;experiment;formal methods;integration testing;iterative method;mathematical model;prototype;rapid prototyping;real-time clock;requirement;scalability;simulation;software system;time series;unfolding (dsp implementation)	Amir Yaghoubi Shahir;Uwe Glässer;Hamed Yaghoubi Shahir;Mohammad A. Tayebi;Hans Wehn	2016	2016 ACM/IEEE International Conference on Formal Methods and Models for System Design (MEMOCODE)	10.1109/MEMCOD.2016.7797746	data modeling;simulation;computer science;trajectory;time series;data mining	SE	-21.926173396054846	-23.06830224839048	32999
d336eaa4d4a40664c5664836066beca4ef66c8f8	a spatial optimisation model for fuel management to break the connectivity of high-risk regions while maintaining habitat quality		Although some negative effects have been noted, positive effects of bush fires on the habitat for native flora and fauna have been recorded [30]. Reports indicate that areas subject to prescribed burning have more live trees, greater survival, and reduced fire intensity during wildfires compared to untreated areas [29]. Prescribed burning leads to fuel reduction [1] and areas with old vegetation (or areas with excess fuel build-up) are often targeted for treatment [11] and can help mitigate wildfire hazards [28, 3, 5], and the risk to human life and economic assets [22]. Thus it has been argued that fuel management is both necessary and important [4]. For the purposes of fuel mangement, forest and national parks are often divided into treatment units. Deciding on a schedule of treatments is a complex spatio-temporal problem [12, 26] and the resulting spatial patterns are critical [7, 16]. Operations Research methods have been applied to some of these problems [19, 20, 2, 23]. Different spatial patterns have been studied [14] and have led to interesting theoretical results. Patterns include disconnected fuel treatment patches that overlap in the direction of fire spread [8], or taking into account the natural landscape around us [9]. Also preparing explicitly for possible future fires when choosing where to apply treatment [31] taking into account fire ignition risk and probabilities of fire spread [33]. Stochastic programming with sample fires has produced some spatial and temporal relationships for where to burn [21].	habitat;mathematical optimization;offset binary;operations research;stochastic programming	Javier León;Victor M. J. J. Reijnders;John W. Hearne;Melih Özlen;Karin J. Reinke	2018				ML	-11.991300177627174	-23.730891143766947	33028
315e3c74d48ba91fa8fcc6c96b4f44fcc379dedc	sub-lognormal size distribution of hospitals — an agent-based approach and empirical study		This paper studies the size distribution of hospitals and its underlying generative mechanisms. Based on the U.S. hospital data, we find that the size distribution is sub-lognormal (a leptokurtic distribution more skewed than normal but less skewed than lognormal). This distribution is different from those of firms and cities. We develop an agent-based simulation model to simulate the preference behavior of patients and the service processes of hospitals. The model can produce a sub-lognormal size distribution similar to the U.S. hospital size distribution. Sensitivity analysis shows that the patients' preference behavior and search distance are two key factors for the emergence of the sub-lognormal size distribution.	agent-based model;agent-based social simulation;emergence	Baojun Gao;Wai Kin Chan	2013	2013 Winter Simulations Conference (WSC)			Metrics	-15.803357063380073	-18.290490624012104	33031
5d60ee7957bd9a50c9d57b99801808f2959237fd	a remarkable view of ancient america: a book review		Taylor & Francis makes every effort to ensure the accuracy of all the information (the “Content”) contained in the publications on our platform. However, Taylor & Francis, our agents, and our licensors make no representations or warranties whatsoever as to the accuracy, completeness, or suitability for any purpose of the Content. Any opinions and views expressed in this publication are the opinions and views of the authors, and are not the views of or endorsed by Taylor & Francis. The accuracy of the Content should not be relied upon and should be independently verified with primary sources of information. Taylor and Francis shall not be liable for any losses, actions, claims, proceedings, demands, costs, expenses, damages, and other liabilities whatsoever or howsoever caused arising directly or indirectly in connection with, in relation to or arising out of the use of the Content.	francis;primary source	Louis Kruh	1980	Cryptologia	10.1080/0161-118091855211	applied mathematics;theoretical computer science;computer science	Robotics	-15.116218800270918	-5.6797330598155344	33060
13e866066ad1aba52c69ef8e88e251129b326407	coco: runtime reasoning about conflicting commitments		To interact effectively, agents must enter into commitments. What should an agent do when these commitments conflict? We describe Coco, an approach for reasoning about which specific commitments apply to specific parties in light of general types of commitments, specific circumstances, and dominance relations among specific commitments. Coco adapts answer-set programming to identify a maximal set of nondominated commitments. It provides a modeling language and tool geared to support practical applications.	answer set programming;coco/r;maximal set;modeling language	Nirav Ajmeri;Jiaming Jiang;Rada Chirkova;Jon Doyle;Munindar P. Singh	2016			modeling language;artificial intelligence;machine learning;computer science;coco	AI	-18.344053003624087	3.5068806670425334	33113
3bbdd30d339db0c910f818869bf9439606a132a2	improving the efficiency of an online marketplace by incorporating forgiveness mechanism	online marketplaces;reputation;netlogo;forgiveness mechanism	Reputation plays a key role in online marketplace communities improving trust among community members. Reputation works as a decision-making tool for understanding the behavior of the business partners. Success of any online business depends on the trust the business agents share with each other. However, untrustworthy agents have anno place in online marketplaces and are forced to leave the market even if they will potentially cooperate. In this study, we propose an exploration strategy based on a forgiveness mechanism for untrustworthy agents to recover their reputation. Furthermore, a number of experiments based on the NetLogo simulation are performed to validate the applicability of the proposed mechanism. The results show that the online marketplaces incorporating a forgiveness mechanism can be used with the existing reputation systems and improve the efficiency of online marketplaces.	anno 1602;centralized computing;decision support system;distributed computing;electronic business;experiment;game theory;interaction;interpupillary distance;iterated function;multi-agent system;netlogo;online marketplace;prisoner's dilemma;reputation system;risk assessment;simulation;thin-film-transistor liquid-crystal display;ws-trust	Ruchdee Binmad;Mingchu Li	2017	ACM Trans. Internet Techn.	10.1145/2996189	reputation;computer science;netlogo	AI	-9.616130241677707	-8.788268309988295	33116
670650351303c782b22d29bcfcb923bd8475b5c8	selected qualitative spatio-temporal calculi developed for constraint reasoning: a review		In this article a few of the qualitative spatio-temporal knowledge representation techniques developed by the constraint reasoning community within artificial intelligence are reviewed. The objective is to provide a broad exposure to any other interested group who may utilize these representations. The author has a particular interest in applying these calculi (in a broad sense) in topological data analysis, as these schemes are highly qualitative in nature.		Debasis Mitra	2018	CoRR			AI	-27.995975557465215	-12.529208717231386	33143
b2a41e2ed0a6166ca5479271c6dc830c74886b4b	signature extraction method in rectangular database	signature analysis;hachage;base relacional dato;analyse signature;information retrieval;query formulation;gestion fichier;formulacion pregunta;file management;relational database;formulation question;signature file;hashing;general methods;indexing;recherche information;indexation;manejo archivos;indizacion;base donnee relationnelle;relational database system;recuperacion informacion;access method;extraction method;analisis firma	"""The signature file access method has proved to be a convenient indexing technique. The main idea of all signature-based schemes is to reflect the essence of data items into bit pattern """"signatures"""" and store them in a separate file, which acts as a filter to eliminate the unqualified data items for an information request. Previous work on superimposed coding in relational database systems has been characterized by signatures that are generated by records with the same size. The signature generation method is based on hashing. For a documentary database, we can consider any database as a set of objects (values and their associated attribute or class name) that are indexed by specific values (or terms). In a relational database, each tuple of arity n may be considered as a document that is indexed by exactly n different values. In this paper, we propose a signature generation method (for RSCW) for a database that is physically organized into a rectangular structure. More specifically, analytical calculations and experiments have proved that this structure minimizes false drop in the case of monoattribute requests. 1. I N T R O D U C T I O N Signatures have been extensively used for in format ion retrieval in electronic office and documen t filing systems and to some extent in database systems [14, 12, 15]. They are useful for filtering a large quant i ty of data when queries are be ing per formed and they provide an effective way to screen out records (or documents ) that do not match the query. The INFORMA TION SCIENCES 87, 65-78 (1995) © Elsevier Science Inc. 1995 0020-0255/95/$9.50 655 Avenue of the Americas, New York, NY 10010 SSDI 0020-0255(95)00121-5 66 K. AROUR AND A. JAOUA main advantage of a signature file is its simple file structure and its low storage overhead. Signature is bit-vector formed by a hash encoding of relation tuples (or long fields of text). Unlike inverted files, which may have more than 100% storage overhead, a signature file is typically 10-20% the size of the primary database and therefore suitable for large databases [6]. Moreover, signature files can handle insertions more easily than inversion because they need """"append-only"""" operations and no reorganization or rewriting of any portion of the signatures [5]. Insertions are easier, especially compared to inverted index [14]. The efficiency of the signature file access method is determined by the quality of the filtering process, which is performed by the signature extraction methods, and fast query execution supported by adequate storage structures. However, signature files suffer from two weaknesses: first, they are slow compared to inverted files and second, they produce false drop (i.e., the process of filtering may identify a record as that satisfying the query, but in fact it is not). The first problem stems from the fact that the size of the signature file is proportional to the size of the database. The performance becomes a problem for large databases. To minimize signature file size, we represent the database with an economical rectangle decomposition. Rectangular decomposition allows some values of attributes having the same properties to be grouped. In the case of documentary databases, a rectangle is associated to a set of documents that are indexed by a common set of indexing terms. This problem is particularly suitable for large databases, because the number of false drops is proportional to the number of unqualified records. In previous work on superimposed coding, it was generally assumed that signatures were generated from records of the same size. That is, every record contains the same number of attributes. The main objective of this paper is to derive a new way to generate signatures, in which we calculate the signature of rectangles rather than of records. In this method, the size of rectangles is different (number of attributes per rectangle). We have shown by analyses and experimental results that for single query attributes, the false drop probability of this method is indeed smaller than that of the traditional method, although it has slightly lower storage overhead. In Section 2, we review the superimposed coding technique and we state some terminologies. In Section 3, a rectangular decomposition method is introduced. Section 4 is devoted to the description of previous and related work. In Section 5, we describe a new signature generation method using rectangular databases. In Section 6, the performance of the method is evaluated and compared with the superimposed coding method. Both analytical and experimental results are presented in this section. SIGNATURE EXTRACTION METHOD 67 2. SIGNATURE DESCRIPTION AND TERMINOLOGY Signatures compactly encode information about an object. Record and query values are encoded using the same signature algorithm. A signature is a bit string formed from the terms that are used to index a record. Due to the information loss that takes place during signature generation, some signatures seem to qualify the queries although the corresponding records (or block) do not qualify it. In this situation we say that we have false drops. Expressed mathematically [8], FD = {probability signature qualifies and block does not}. There are a number of different methods for constructing a signature file from a database. Our method of generating signatures is based upon the superimposed coding method [14] that we briefly describe below. To accomplish partial-match queries on a file F using the method of superimposed codes, we must first compute a superimposed code word (denoted SCW) [14], which we denote by Si for each record R i in the file. Each S i is formed by ORing together several binary coded words (denoted bcw) of width b (for each value of attributes in the record). Because the number of records Ri in the file F is given by # F = N, there are also N corresponding SCWs S i = (Sil, s~2 ... . , S,b), where sij is either 0 or 1 and b is the signature size. The number k of ones in SCW is called the weight of signature. The lower value of b indicates the best performance. Unfortunately, FD and b are inversely related, so that to decrease the value of b, we must increase the value of FD. We show also the dependence of FD upon the SCW weight. Thus, given a value of the parameter b, the value of the weight parameter k may be chosen so that the minimum number of false drops is obtained. For example, we assume that a record consists of four values. The signature of this record using the superimposed coding is given in Table 1. 3. PREVIOUS AND RELATED WORK A high false drop rate causes unnecessary disk accesses and lower overall system performance. Therefore, a substantial amount of effort has been devoted to the study of optimum algorithms for generating signatures from objects and the estimation of false drop probability [3, 4, 6, 7, 9, 13]. In this section, we review the study of estimating the false drop probability elaborated by Robert [14]. In this paper the author derives mathematical 68 K. AROUR AND A. JAOUA TABLE 1 Signature Extraction using Superimposed Coding"""	algorithm;antivirus software;append;bit array;code word;cryptographic hash function;digital signature;encode;electronic signature;emoticon;experiment;freedos;inverted index;overhead (computing);relational database;rewriting;robert;type signature	Khedija Arour;Ali Jaoua	1995	Inf. Sci.	10.1016/0020-0255(95)00121-2	search engine indexing;relational database management system;hash function;relational database;computer science;data mining;database;access method;world wide web;algorithm;database design	DB	-28.161987116331016	3.8069548436607312	33156
9e168aaebe675b59caed8f8d722dd165aa3b0eb9	multifunctions as approximation operations in generalized approximation spaces	logica algebraica;systeme intelligent;procesamiento informacion;algebraic logic;analisis datos;sistema inteligente;data analysis;logique algebrique;information processing;intelligent system;analyse donnee;information system;traitement information;rough set;ensemble approximatif;systeme information;sistema informacion	An approximation space can be defined as a quintuple A = (T, U, F, Φ, Γ), where F : T → U is a multifunction and Φ and Γ are unary operations on the power set of U.	approximation;spaces	P. Maritz	1998		10.1007/3-540-69115-4_19	algebraic logic;discrete mathematics;rough set;information processing;computer science;machine learning;mathematics;data analysis;information system;algorithm	Theory	-21.03159780136275	-1.6379444572753836	33193
87ed43bb32ed4a230b638a21ae7a5ed2a86979ac	recognition of hand-printed chinese characters using ripple down rules	ripple down rules;scaling up;knowledge acquisition;knowledge base;knowledge engineering	The paper presents a prototype knowledge acquisition system which has been implemented based on Ripple Down Rules. The main aim of our system is to capture the human skills of recognizing and differentiating a character from other similar characters. The user can identify such differences graphically and (if required) modify the Knowledge Base without the guidance of a Knowledge Engineer. The paper outlines the basic framework and presents initial experimental results. Further, it discusses ways of scaling up the approach to handle very large number of Chinese characters.	ripple	Adnan Amin;Michael Bamford;Achim G. Hoffmann;Ashesh Mahidadia;Paul Compton	1996		10.1007/3-540-61577-6_38	computer science;knowledge management;machine learning;data mining	NLP	-30.99807480562893	-7.123179144207504	33199
e702a3dcd8f7b441000c17d00347732b3af1d058	concept learning games: the game of query and response	multiagent system;game theoretic view;game theory;multi agent system;ontologies artificial intelligence;cooperative concept learning;multi agent systems;competitive environment;concept learning game;concept learning;aids remedy project concept learning game game theoretic view cooperative concept learning multiagent system competitive environment game theory ontology knowledge representation tool;concept learning ontology game theory multi agent system mas;ontologies artificial intelligence game theory learning artificial intelligence multi agent systems;multi agent system mas;solution concept;aids remedy project;learning artificial intelligence;knowledge representation;ontology;knowledge representation tool	This article deals with the issue of concept learning and tries to have a game theoretic view over the process of cooperative concept learning among agents in a multi-agent system, in which an extreme sense of competition has arisen. This gives birth to a new realm labeled as ”Learning Games”. We study the cooperative view and give a novel idea to use in competitive environments based on the solution concepts of game theory and an innovative idea of concept scores over an ontology, which is used as our knowledge representation tool for agents. A case study comes at the end and covers the FAQs of this method over a scientific world topic of AIDS remedy project.	concept learning;game theory;knowledge representation and reasoning;multi-agent system	Nima Mirbakhsh;Arman Didandeh;Mohsen Afsharchi	2010	2010 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology	10.1109/WI-IAT.2010.161	computer science;knowledge management;artificial intelligence;game mechanics;machine learning;multi-agent system;solution concept	AI	-19.729620567357916	-12.637486223478001	33203
1d5a475ab7a6cb52d1db3286aef1b50a4b42a5b3	negotiation as a mechanism for language evolution	fipa acl;agent communication languages and protocols;agent based software engineering;language evolution	The aim of our research is to understand and automate the mechanisms by which language can emerge among artificial, knowledge-based and rational agents that interact in open, heterogeneous, and distributed environments. We want to design and implement agents that, upon encountering other agent(s) with which they do not share an agent communication language, are able to initiate creation of, and further able to evolve and enrich, a mutually understandable agent communication language (ACL). Unlike the approaches that seek to centrally design a communication language before hand, like KQML and FIPA, we want to give the agents themselves the ability to enrich and evolve a language that best suites their needs. We define communication as the phenomenon of one agent (speaker) producing a signal that, when responded to by another agent (hearer), confers some advantage (or the statistical probability of it) to the speaker. This definition is supported by numerous approaches to study of communication in cognitive science and linguistics [5, 7]. Simply, the communicative act must be purposeful and beneficial to the speaker, or else a rational speaker would not bother to produce it. Using the the framework of decision theory, a communicative act must lead to an increase of the speaker’s assessment of it’s own expected utility. Our research builds on results of our previous work [8, 10, 9, 11, 16, 17] on coordination and on value of communication, but addresses the issue of language creation and evolution. Given that the ability to communicate can be advantageous, the agents may want to enrich their communicative capabilities, if they are insufficient. For example, if	agent communications language;cognitive science;decision theory;expected utility hypothesis;knowledge query and manipulation language;knowledge-based systems;rational agent	Piotr J. Gmytrasiewicz	2002		10.1145/544862.544874	computer science;programming language	AI	-23.58740186584237	-10.90082897631838	33221
e2a4dbc8aaa4c6433c0fffb2d3bfb3691ff044ec	logic modeling: a tool for management science	management science	Developments in logic and in information technology (especially the advent of logic programming) have converged to the point at which logic is, for a broad variety of problems, a useful tool to employ for modeling in areas of interest to management scientists. This paper presents the concept of logic modeling (model building with symbolic logic) and reviews several lines of research having in common a logic modeling approach to problems of interest in management scientist.	fuzzy logic;logic programming;management science	Steven Orla Kimbrough;Ronald M. Lee	1988	Decision Support Systems	10.1016/0167-9236(88)90094-2	computer science;artificial intelligence;computational logic;data mining;management science	Logic	-29.89426304613979	-10.63284690228848	33249
c02514efdaed8515540465bb29d0d580e8f04d71	reflections on neurocomputational reliabilism		Reliabilism is a philosophical theory of knowledge that has traditionally focused on propositional knowledge. Paul Churchland has advocated for a reconceptualization of reliabilism to “liberate it” from propositional attitudes (such as accepting that p, believing that p, knowing that p, and the like). In the process, he (a) outlines an alternative for the notion of truth (which he calls “representational success”), (b) offers a non-standard account of theory, and (c) invokes the preceding ideas to provide an account of representation and knowledge that emphasizes our skill or capacity for navigating the world. Crucially, he defines reliabilism (and knowledge) in terms of representational success. This paper discusses these ideas and raises some concerns. Since Churchland takes a neurocomputational approach, we discuss our training of neural networks to classify images of faces. We use this work to suggest that the kind of reliability at work in some knowledge claims is not usefully understood in terms of the aforementioned notion of representational success.	amiga reflections;artificial neural network;emoticon	Marcello Guarini;Joshua Chauvin;Julie Gorman	2011			computer science;machine learning;reliabilism;artificial intelligence	AI	-25.97378848426204	-13.23860556214316	33280
1abafa03259cf243739535f3f08836a1ff60fa4d	computational thinking	cognition;problem solving;abstraction;computational thinking;computer science;fundamental skill;human behavior	C omputational thinking builds on the power and limits of computing processes, whether they are executed by a human or by a machine. Computational methods and models give us the courage to solve problems and design systems that no one of us would be capable of tackling alone. Computational thinking confronts the riddle of machine intelligence: What can humans do better than computers? and What can computers do better than humans? Most fundamentally it addresses the question: What is computable? Today, we know only parts of the answers to such questions. Computational thinking is a fundamental skill for everyone, not just for computer scientists. To reading, writing, and arithmetic, we should add computational thinking to every child’s analytical ability. Just as the printing press facilitated the spread of the three Rs, what is appropriately incestuous about this vision is that computing and computers facilitate the spread of computational thinking. Computational thinking involves solving problems, designing systems, and understanding human behavior, by drawing on the concepts fundamental to computer science. Computational thinking includes a range of mental tools that reflect the breadth of the field of computer science. Having to solve a particular problem, we might ask: How difficult is it to solve? and What’s the best way to solve it? Computer science rests on solid theoretical underpinnings to answer such questions precisely. Stating the difficulty of a problem accounts for the underlying power of the machine—the computing device that will run the solution. We must consider the machine’s instruction set, its resource constraints, and its operating environment. In solving a problem efficiently, we might further ask whether an approximate solution is good enough, whether we can use randomization to our advantage, and whether false positives or false negatives are allowed. Computational thinking is reformulating a seemingly difficult problem into one we know how to solve, perhaps by reduction, embedding, transformation, or simulation. Computational thinking is thinking recursively. It is parallel processing. It is interpreting code as data and data as code. It is type checking as the generalization of dimensional analysis. It is recognizing both the virtues and the dangers of aliasing, or giving someone or something more than one name. It is recognizing both the cost and power of indirect addressing and procedure call. It is judging a program not just for correctness and efficiency but for aesthetics, and a system’s design for simplicity and elegance. Computational thinking is using abstraction and decomposition when attacking a large complex task or designing a large complex system. It is separation of concerns. It is choosing an appropriate representation for a problem or modeling the relevant aspects of a problem to make it tractable. It is using invariants to describe a system’s behavior succinctly and declaratively. It is having the confidence we can safely use, modify, and influence a large complex system without understanding its every detail. It is LI A H A N EY Viewpoint Jeannette M. Wing	addressing mode;aliasing;approximation algorithm;artificial intelligence;cobham's thesis;complex system;computable function;computation;computational thinking;computer science;computer scientist;correctness (computer science);humans;invariant (computer science);norm (social);operating environment;parallel computing;principle of good enough;printing;recursion;separation of concerns;simulation;subroutine;type system;viewpoint	Paolo Ferragina;Fabrizio Luccio	2018		10.1007/978-3-319-97940-3	theoretical computer science;computational thinking;computer science	AI	-29.35065734114559	-15.054026229606214	33292
20a2c64440cca5c167c24fa54808c2d79a2be36f	sparql basic graph pattern optimization using selectivity estimation	query optimization;sparql;selectivity estimation	In this paper, we formalize the problem of Basic Graph Pattern (BGP) optimization for SPARQL queries and main memory graph implementations of RDF data. We define and analyze the characteristics of heuristics for selectivity-based static BGP optimization. The heuristics range from simple triple pattern variable counting to more sophisticated selectivity estimation techniques. Customized summary statistics for RDF data enable the selectivity estimation of joined triple patterns and the development of efficient heuristics. Using the Lehigh University Benchmark (LUBM), we evaluate the performance of the heuristics for the queries provided by the LUBM and discuss some of them in more details.	benchmark (computing);border gateway protocol;cartesian closed category;computer data storage;heuristic (computer science);mathematical optimization;memory bound function;result set;sparql;selectivity (electronic);triplestore;variable (computer science)	Markus Stocker;Andy Seaborne;Abraham Bernstein;Christoph Kiefer;Dave Reynolds	2008		10.1145/1367497.1367578	query optimization;computer science;sparql;theoretical computer science;data mining;database	Web+IR	-31.194244207380493	3.121296673852178	33308
6618f929f65cffe31cc3ef66c77a3a32054f82c8	an information filtering system that optimizes the processing method based on mathematical properties	information filtering	In recent years, due to the increasing popularization of various data broadcast services, the amount and the variety of broadcast data have been increasing. As a result, there is a strong demand for filtering techniques that automatically extract only the necessary data. The optimum filtering processing method changes according to such environmental factors as computational capability, number of receivers, and network load. However, to change the processing method according to the environment, filtering results must be consistent among multiple processing methods. In this paper, we describe the implementation of an information filtering system that optimizes the processing method based on mathematical properties. This system automatically changes the processing method to the optimum method according to the environment.		Takuya Kodera;Rie Sawai;Tsutomu Terada;Masahiko Tsukamoto;Shojiro Nishio	2004			computer science;theoretical computer science;collaborative filtering;information filtering system;data mining;information retrieval	Web+IR	-26.74047580123551	-1.284755266514251	33331
78228d02aeb22c70da338f43d67738ecc53403a1	an extended intuitionistic fuzzy topsis method based on a new distance measure with an application to credit risk evaluation		Abstract In the process of multi-criteria decision making (MCDM), decision makers or experts usually exploit quantitative or qualitative methods to evaluate the comprehensive performance of all alternatives on each criterion. How the decision-makers or the experts make the evaluations relies on their professional knowledge and the actual performances on the criteria characters of the alternatives. However, because of both the objective complexity of decision making problem and the uncertainty of human subjective judgments, it is sometimes too hard to get the accurate evaluation information. Intuitionistic fuzzy set (IFS) is a useful tool to deal with uncertainty and fuzziness of complex problems. In this paper, we propose a new distance measure between IFSs and prove some of its useful properties. The experimental results show that the proposed distance measure between IFSs can overcome the drawbacks of some existing distance and similarity measures. Then based on the proposed distance measure, an extended intuitionistic fuzzy TOPSIS approach is developed to handle the MCDM problems. Finally, a practical application which is about credit risk evaluation of potential strategic partners is provided to demonstrate the extended intuitionistic fuzzy TOPSIS approach, and then it is compared with other current methods to further explain its effectiveness.		Feng Shen;Xinsong Ma;Zhiyong Li;Zeshui Xu;Dongliang Cai	2018	Inf. Sci.	10.1016/j.ins.2017.10.045	machine learning;mathematics;fuzzy logic;multiple-criteria decision analysis;artificial intelligence;credit risk;fuzzy set;exploit;topsis;qualitative research	NLP	-4.863790187287453	-18.788880513148644	33376
dc171a15b602748f19550e19b4f9d6931b36c2de	balance sheet approach to agent-based computational economics: the eurace project	agent-based computational economics;balance sheet approach;eurace project.	Handling carefully monetary and real flows, given by agents' be- haviors and interactions, is a key requirement when dealing with complex economic models populated by a high number of agents. The paper shows how the stock-flows consistency issue has been faced in the EURACE model, by considering a dynamic balance sheet approach for modeling and validation purposes.	agent-based computational economics;computation;intelligent agent	Andrea Teglio;Marco Raberto;Silvano Cincotti	2010		10.1007/978-3-642-14746-3_74	simulation;engineering;operations management;management science	NLP	-8.965095261715936	-8.196949119160651	33396
54314296328ba59c49521b111421bbd2a71c3822	optimal path planning for a mobile robot using cuckoo search algorithm	levy flight;path planning;navigation;obstacle avoidance;cuckoo search	Taylor & Francis makes every effort to ensure the accuracy of all the information (the “Content”) contained in the publications on our platform. However, Taylor & Francis, our agents, and our licensors make no representations or warranties whatsoever as to the accuracy, completeness, or suitability for any purpose of the Content. Any opinions and views expressed in this publication are the opinions and views of the authors, and are not the views of or endorsed by Taylor & Francis. The accuracy of the Content should not be relied upon and should be independently verified with primary sources of information. Taylor and Francis shall not be liable for any losses, actions, claims, proceedings, demands, costs, expenses, damages, and other liabilities whatsoever or howsoever caused arising directly or indirectly in connection with, in relation to or arising out of the use of the Content.	automated planning and scheduling;autonomous robot;cuckoo search;emoticon;experiment;francis;mobile robot;motion planning;nl-complete;norsk data;primary source;real-time clock;ruby document format;sl (complexity);search algorithm;simulation	Prases Kumar Mohanty;Dayal R. Parhi	2016	J. Exp. Theor. Artif. Intell.	10.1080/0952813X.2014.971442	mathematical optimization;navigation;simulation;lévy flight;computer science;artificial intelligence;motion planning;obstacle avoidance;cuckoo search	Robotics	-14.854865146848615	-6.764235046063071	33397
7a26a2dab11aa0f87cf0886986c638e382469f3a	environment updating and agent scheduling policies in agent-based simulators		Since Schelling’s segregation model, the ability to represent individual behaviours and to execute them to produce emergent collective behaviour has enabled interesting studies in diverse domains, like artificial financial markets, crowd simulation or biological simulations. Nevertheless, the description of such experiments are focused on the agents behaviours, and seldom clarify the exact process used to execute the simulation. In other words, little details are known on the assumptions, the choices and the design that have been done on the simulator on fundamental notions like time, simultaneity, agent scheduling or sequential/parallel execution. Though, these choices are crucial because they impact simulation results. This paper is focused on parameter sensitivity of agent-based simulators implementations, specifically on environment updating and agent scheduling policies. We highlight concepts that simulator designers have to define and presents several possible implementations and their impact.	agent-based model;centralisation;crowd simulation;emergence;experiment;real-time clock;requirement;scalability;scheduling (computing)	Philippe Mathieu;Yann Secq	2012			real-time computing;simulation;dynamic priority scheduling;distributed computing	AI	-19.519542670906592	-16.333094791648925	33453
965fdb8c0a57fdccc79a3b59012d868d300705a7	the mdta-based method for assessing diagnosis failures and their risk impacts in nuclear power plants	fiabilite humaine;modelizacion;operateur humain;operador humano;methode potentiel;pilot;securite;diagnosis failure;accident;human behaviour;probabilistic approach;emergency;modelisation;human reliability;diagnostic panne;enfoque probabilista;approche probabiliste;analytical method;fault diagnostic;safety;diagnostico pana;urgencia;defaillance;human operator;potential method;misdiagnosis;urgence;nuclear power plant;loss of coolant accident;centrale nucleaire;metodo potencial;accidente;failures;human reliability analysis;pilote;errors of commission;seguridad;modeling;fallo;central nuclear;fiabilidad humana	In the emergency situations of nuclear power plants (NPPs), a diagnosis of the occurring events along an accident progression or as initiating events is crucial for managing or controlling a plant to a safe and stable condition. If the operators fail to diagnose the occurring event(s), their responses to a given event can eventually become inappropriate or inadequate. This paper presents an analytical method for assessing the potential for a diagnosis failure (or misdiagnosis) and its consequences for human behaviour and plant safety. The method largely comprises of three steps as follows: (1) Analysis of the potential for a diagnosis failure, (2) Identification of the human failure events (HFEs) that might be induced due to a diagnosis failure, and (3) Quantification of the HFEs and their modeling into a PSA model. The paper also presents a pilot application of the proposed method to the small loss of coolant accident of a Korean NPP.		Jaewhan Kim;Wondea Jung;Young Seok Son	2008	Rel. Eng. & Sys. Safety	10.1016/j.ress.2006.10.020	potential method;reliability engineering;systems modeling;emergency;engineering;human reliability;forensic engineering;pilot;human behavior;operations research;computer security	EDA	-10.923127541335734	-15.09263222518123	33470
ddab5c2908e79acdef9350299424bf2195f68c81	using norm emergence in addressing the tragedy of the commons		In this paper we propose an approach for the experimental analysis of the classical problem of the Tragedy of the Commons. This approach revolves around norms within multi-agent systems, without regimenting them. The proposed model allows norms to emerge between selfish agents that compete for the same resource. The paper shows how the emerging norms lead to a balanced distribution of resources among the individuals, diminishing the effects of the tragedy.	emergence	Sorin Dascalu;Tudor Scurtu;Andreea Urzica;Mihai Trascau;Adina Magda Florea	2013		10.1007/978-3-642-40495-5_17	computer science;machine learning;artificial intelligence;public economics;tragedy of the commons;tragedy;multi-agent system;norm (social)	AI	-14.826321114769625	-13.846073317758236	33495
a41e1deb2002f645cda7418aa41db47e026e371e	average controllability measures for solitaire games	skill vs luck;solitaire games;markov decision processes	We discuss several ways to measure the extent to which a player can exert control over a one-player game, relating them to the existing literature on the “skill vs chance” dichotomy. We focus on measures that depend only on the rules of the games, and not on how people actually play them. After presenting a set of desirable properties, we show that two statistical measures of effect size satisfy them and we estimate the value of such measures on several wellknown games.	experiment;symmetric multiprocessing;weak value	Marco Faella	2016			markov decision process;simulation;computer science;artificial intelligence	ML	-7.718901683846581	-2.7562259977385386	33502
20b99a93c47a5501bf916d9343d10425ed5b13cc	when experience is wrong: examining cbr for changing tasks and environments	learning process;raisonnement base sur cas;razonamiento fundado sobre caso;systeme intelligent;systeme apprentissage;sistema inteligente;resolucion problema;learning systems;intelligent system;case based reasoning;problem solving;resolution probleme	Case-based problem-solving systems reason and learn from experiences, building up case libraries of problems and solutions to guide future reasoning. The expected bene ts of this learning process depend on two types of regularity: (1) problem-solution regularity, the relationship between problem-to-problem and solution-to-solution similarity measures that assures that solutions to similar prior problems are a useful starting point for solving similar current problems, and (2) problemdistribution regularity, the relationship between old and new problems that assures that the case library will contain cases similar to the new problems it encounters. Unfortunately, these types of regularity are not assured. Even in contexts for which initial regularity is su cient, problems may arise if a system's users, tasks, or external environment change over time. This paper de nes criteria for assessing the two types of regularity, discusses how the de nitions may be used to assess the need for case-base maintenance, and suggests maintenance approaches for responding to those needs. In particular, it discusses the role of analysis of performance over time in responding to environmental changes.	akaike information criterion;case-based reasoning;experience;library (computing);problem solving;sensor	David B. Leake;David C. Wilson	1999		10.1007/3-540-48508-2_16	case-based reasoning;simulation;computer science;artificial intelligence;mathematics;algorithm	AI	-20.941877443912496	-5.565367347777099	33646
a1c207bf509b235c4427bdb9f3e7424fe3001ab7	toward the complexity of the existence of wonderfully stable partitions and strictly core stable coalition structures in enemy-oriented hedonic games	game theory;91a12;wonderful stability;strict core stability;68q17;68q15;hedonic games	We study the computational complexity of the existence and the verification problem for wonderfully stable partitions (WSPE and WSPV) and of the existence problem for strictly core stable coalition structures (SCSCS) in enemy-oriented hedonic games. In this note, we show that WSPV is NP-complete and both WSPE and SCSCS are DP-hard, where DP is the second level of the boolean hierarchy, and we discuss an approach for classifying the latter two problems in terms of their complexity.	boolean hierarchy;computational complexity theory;np-completeness;regular expression	Anja Rey;Jörg Rothe;Hilmar Schadrack;Lena Schend	2015	Annals of Mathematics and Artificial Intelligence	10.1007/s10472-015-9461-y	game theory;discrete mathematics;mathematics;mathematical economics	AI	-5.767040694683592	0.20453830321826855	33679
5f3733f60f148cf00aea61c48327dfdb174921cd	efficient external-memory bisimulation on dags	bisimulation;i o;graphs;external memory	In this paper we introduce the first efficient external-memory algorithm to compute the bisimilarity equivalence classes of a directed acyclic graph (DAG). DAGs are commonly used to model data in a wide variety of practical applications, ranging from XML documents and data provenance models, to web taxonomies and scientific workflows. In the study of efficient reasoning over massive graphs, the notion of node bisimilarity plays a central role. For example, grouping together bisimilar nodes in an XML data set is the first step in many sophisticated approaches to building indexing data structures for efficient XPath query evaluation. To date, however, only internal-memory bisimulation algorithms have been investigated. As the size of real-world DAG data sets often exceeds available main memory, storage in external memory becomes necessary. Hence, there is a practical need for an efficient approach to computing bisimulation in external memory.  Our general algorithm has a worst-case IO-complexity of O(Sort(|N| + |E|)), where |N| and |E| are the numbers of nodes and edges, resp., in the data graph and Sort(n) is the number of accesses to external memory needed to sort an input of size n. We also study specializations of this algorithm to common variations of bisimulation for tree-structured XML data sets. We empirically verify efficient performance of the algorithms on graphs and XML documents having billions of nodes and edges, and find that the algorithms can process such graphs efficiently even when very limited internal memory is available. The proposed algorithms are simple enough for practical implementation and use, and open the door for further study of external-memory bisimulation algorithms. To this end, the full open-source C++ implementation has been made freely available.	best, worst and average case;bisimulation;c++;computer data storage;data structure;directed acyclic graph;open-source software;out-of-core algorithm;turing completeness;xml;xpath	Jelle Hellings;George H. L. Fletcher;Herman J. Haverkort	2012		10.1145/2213836.2213899	input/output;computer science;bisimulation;theoretical computer science;database;graph;programming language;algorithm	DB	-31.234979719215563	2.686692763722795	33704
7cde62302e4c4ba6d9f525b6027d3c0d175bde28	a connectionist approach to knowledge representation and limited inference	tratamiento paralelo;memoire;representacion conocimientos;traitement parallele;connectionism;distributed processing;hombre;cognitive theory;intelligence artificielle;theorie cognitive;connexionnisme;memoria;teoria cognocitiva;human;artificial intelligence;inteligencia artificial;knowledge representation;representation connaissances;traitement reparti;parallel processing;memory;tratamiento repartido;homme	Although the connectionist approach has lead to elegant solutions to a number of problems in cognitive science and artificial intelligence, its suitability for dealing with problems in knowledge representation and inference has often been questioned. This paper partly answers this criticism by demonstrating that effective solutions to certain problems in knowledge representation and limited inference can be found by adopting a connectionist approach. The paper presents a connectionist realization of semantic networks, that is, it describes how knowledge about concepts, their properties, and the hierarchical relationship between them may be encoded as an Interpreter-free massively parallel network of simple processing elements that can solve an interesting class of inherltonce and recognlt/on problems extremely fast-in time proportional to the depth of the conceptual hierarchy. The connectionist realization is based on an evidential formulation that leads to principled solutions to the problems of exceptions and conflicting m&p/e lnherftance situations during inheritance, and the best-match or partlolmatch computation during recognition. The paper also identifies constraints that must be satisfied by the conceptual structure in order to arrive at an efficient parallel realization.	artificial intelligence;cognitive science;computation;connectionism;knowledge representation and reasoning;semantic network	Lokendra Shastri	1988	Cognitive Science	10.1207/s15516709cog1203_2	psychology;parallel processing;connectionism;computer science;artificial intelligence;machine learning;memory;algorithm;cognitive science	AI	-25.05606482725447	-9.403038292130233	33734
606a06663d50d135a4fbf153998aba3150e31aed	c-merge: a tool for policy-based merging of resource classifications	categorisation;ingenierie connaissances;fusion informatique;knowledge management;classification;user support;knowledge visualization;categorizacion;data visualization;merging;controle qualite;visualisation donnee;quality control;user interaction;clasificacion;control calidad;categorization;knowledge engineering	In this paper we present an interactive tool for policy-based merging of resource-classifying networks (RCNs). We motivate our approach by identifying several merge scenarios within organizations and discuss their individual requirements on RCN merge support. The quality-controlled merging of RCNs integrates the contributions from different authors, fostering synergies and the achievement of common goals.#R##N##R##N#The C-Merge tool design is based on a generalized view of the merge process and a simple but flexible model of RCNs. The tool is policy-driven and supports a variable degree of automation. Powerful options for user interaction and expressive change visualization enable substantial user support as well as effective quality control for the merge process.		Florian Matthes;Claudia Niederée;Ulrike Steffens	2001		10.1007/3-540-44796-2_30	quality control;biological classification;computer science;artificial intelligence;knowledge engineering;data mining;database;data visualization;categorization	Logic	-27.34816012640481	-4.816573654140851	33756
c8d3348904728f87c05968642f542324b80aefd3	mechanism design and bounded rationality: the case of type misreporting		In this paper we study the effects of bounded rationality in mechanism design problems. We model bounded rationality by assuming that in the presence of an incentive compatible mechanism, players behave as if their types were in a δ-neighborhood of their true types. In our results, we explore what are the effects of such bounded rationality in the outcomes of the mechanism design problem. To such end, we characterize the social choice functions that are robust to the δ-perturbations in the sense that the designers’ loss is at most of order δ for a certain k. A notable finding is that in quasi-linear utilitarian environments the designer’s loss is of order of δ. We illustrate the applicability of our results by means of examples. JEL Classification: D81, D82.		Javier Rivas	2015	Mathematical Social Sciences	10.1016/j.mathsocsci.2015.08.001	ecological rationality;mathematics;mathematical economics;welfare economics;bounded rationality	ECom	-6.940436714562953	-2.023615515401862	33787
96f562f80b24ba64ca1a2fa932618d2e4ac24656	an industrial application of behavior-oriented robotics	motion control;video streaming;service robots surveillance mobile robots streaming media communication system security circuits tv production cost function human computer interaction;watchguard systems behavior oriented robotics roboguard mobile security device semi autonomous mobile robots video streams wireless intranets;video signal processing;surveillance;path planning;path planning surveillance security mobile robots video signal processing motion control;mobile robots;autonomous mobile robot;industrial application;production cost;security	The so-called RoboGuard is a mobile security device which is tightly integrated into the existing surveillance framework developed and marketed by Quadrox, a Belgian SME. RoboGuards are semi-autonomous mobile robots providing video streams via wireless Intranets to existing watchguard systems, supplemented by various basic and optional behaviors. RoboGuards ll several market-niches. Especially, they are a serious alternative to the standard approach of using Closed Circuit Television (CCTV) for surveillance. Low production cost, user friendliness, and support for easy add-on functionalities were important design targets, which were achieved by following the AI paradigm of behavior-oriented robotics.	add-ons for firefox;autonomous robot;closed-circuit television;intranet;mobile robot;mobile security;obstacle avoidance;programming paradigm;robotics;semiconductor industry;sensor;streaming media;usability	Andreas Birk;Holger Kenn	2001		10.1109/ROBOT.2001.932640	motion control;mobile robot;embedded system;real-time computing;mobile search;simulation;computer science;engineering;artificial intelligence;information security;motion planning;mobile station;mobile computing	Robotics	-23.93228753304499	-0.2582333037613957	33871
567bc1572b7d2b01e006059df0370a9024f34e52	providing objective metrics of team communication skills via interpersonal coordination mechanisms	turn taking organisation;turn taking organisa tion;aviation;prosodic accommodation;communication skills	Being able to communicate efficiently has been acknowledged as a vital skill in many different domains. In particular, team communication skills are of key importance in the operation of complex machinery such as aircrafts, maritime vessels and such other, highly-specialized, civilian or military vehicles, as well as the performance of complex tasks in the medical domain. In this paper, we propose to use prosodic accommodation and turntaking organisation to provide objective metrics of communication skills. To do this, human-factors evaluations, via a coordination Demand Analysis (CDA), were used in conjunction with a dynamic model of prosodic accommodation and turn-taking organisation. Using conversational speech from airline pilots involved in a collaborative task (decision-making exercise), our study reveals that interpersonal coordination mechanisms are indicative of human evaluation of pilots’ communication skills. We discuss our results in terms of relevance for training simulation for personnel in safety or mission critical environments.	.cda file;human factors and ergonomics;mathematical model;mission critical;relevance;simulation	Céline De Looze;Brian Vaughan;Finnian Kelly;Alison Kay	2015			simulation;aviation	AI	-24.6701547942494	-23.945670136449664	33899
36ff2611fb6557277f45d9cea79da48cbaac0d58	measuring the user acceptance of generic manufacturing simulation models by review of modeling assumptions	expert systems;manufacturing data processing;production control;simulation;pc siman;assumption review process;expert system;generic discrete manufacturing models;generic manufacturing simulation models;group technology;intelligent simulation environment;model acceptance;modeling assumptions;user acceptance	A measure of user acceptance for generic discrete manufacturing models is introduced. This measure is based on review of modeling assumptions and computed as the percentage of assumptions that are acceptable to the user. The assumptions, which describe the modeling options that are available in generic models, give the user a detailed account of the capabilities and limitations of the generic models. The assumption review process and the user acceptance measure are implemented within the framework of an intelligent simulation environment. GUIDES, an expert system, guides the user through the review of assumptions and generates the user acceptance scores. It is concluded that, although certain modifications can be made in the generic models to eliminate some of the rejections concerning the assumptions, the model acceptance, in general, is fairly high (91.78%)	simulation	Nur E. Özdemirel	1991			cell;simulation;user modeling;systems modeling;computer science;systems engineering;engineering;knowledge management;artificial intelligence;technical report;object;simulation modeling;manufacturing;computational model;expert system	Robotics	-6.642211719076701	-12.171466391697905	33901
865c0271d7556fed2eb57a173ef14af858810a3a	stats invaders!: learning about statistics by playing a classic video game	preparation for future learning;probability;video game;probability distribution;distributed generators;computer game	"""This poster describes a computer game designed to provide players with exposure to repeated draws from probability distributions. In the game, players shoot aliens dropping from the sky (as in the classic arcade game Space Invaders) while deciding which of two displayed distributions better reflects the pattern of the alien attack. Our hypothesis is that playing this version of the game will better prepare players to learn from a passage about probability distributions (as evidenced by pre-/post-test gains) than will playing a control version that is identical in every respect except instead of deciding which distribution generates the alien attack, players must decide which of two displayed proportions of """"special"""" (differently colored) aliens better reflects the attack."""	arcade game;pc game	Dylan Arena;Daniel L. Schwartz	2010		10.1145/1822348.1822381	non-cooperative game;video game design;probability distribution;game design;cheap talk;simulation;game tree;simultaneous game;computer science;artificial intelligence;information set;metagaming;probability;repeated game;screening game;simulations and games in economics education;sequential game;statistics	AI	-32.63279002987033	-16.65239798149805	33906
4910ebd2a7e59a5ba04fce96e36b65dac8d74a9b	determinants of experienced utility: laws and implications	habit formation;craving;satiation;projection bias;time and budget allocation;experienced utility;variety seeking	Satisfaction in experiencing the future depends on decisions made today. We consider six well-known psychological laws governing satisfaction. The laws capture habit formation, social comparison, and satiation. We show it is possible to formalize these laws by means of a utility model, and to derive implications from the laws: wanting vs. liking, crescendo, recharge periods, variety seeking, and craving. The discussion combines mathematical propositions, experimental findings in psychology, and time-honored wisdom. We discuss how the sixth law, presentism, may lead to incorrect predictions of experienced utility and suboptimal life-balance choices.	rechargeable battery	Manel Baucells;Rakesh K. Sarin	2013	Decision Analysis	10.1287/deca.2013.0270	habit;welfare economics	Web+IR	-10.93403408883089	-3.0211843942329915	33937
36602e7b394055a0b337a4f4cebf88ea33fd40a4	agent-based simulation of freight transport between geographical zones	multi agent systems;conference paper peer reviewed;datavetenskap datalogi;transport simulation;computer science	We present TAPAS-Z, which is an agent-based freight transport analysis model for simulation of decision-making and transport activities. TAPAS-Z is a further development of a simulation model called TAPAS, and it has improved support for simulation of transport in large geographical regions. It is based on the principles that shipments are simulated for chosen supplier-consumer relations in a geographic region, and that the geographic locations of suppliers and consumers are randomly varied for each shipment. In TAPAS-Z, one supplier represents all real-world suppliers in a geographic zone, and one consumer represents all real-world consumers in a zone. In that way, TAPAS-Z is able to capture some of the diversity in freight transport that is caused by the varying geographic locations of senders and receivers, and which is important when assessing the impact of transport policy and infrastructural measures.	agent-based model;randomness;simulation	Johan Holmgren;Mattias Dahl;Paul Davidsson;Jan A. Persson	2013		10.1016/j.procs.2013.06.110	simulation;computer science;artificial intelligence;multi-agent system	Robotics	-15.84491850473182	-18.78751370188759	33941
64c81d9e1275a710425a06bb0d906f10e7908505	a learning strategy for disassembly process planning	belief networks;bayesian network;expert systems;process planning belief networks expert systems learning artificial intelligence petri nets;disassembly process planning;hybrid bayesian network;parameter learning learning strategy disassembly process planning expert systems disassembly petri net hybrid bayesian network disassembled units;parameter learning;human factors;learning strategy;process planning bayesian methods uncertainty parameter estimation expert systems human factors construction industry high level languages equations machine learning;disassembled units;process planning;petri nets;learning artificial intelligence;petri net;disassembly petri net;learning strategies;expert system	To aid in the disassembly process of various obsolete products, expert systems can be used to model the process and provide valuable insight pertaining to the decisions made within the process. This paper discusses such a model that integrates a Disassembly Petri Net (DPN) with a Hybrid Bayesian Network (HBN). The rationale for this framework as well as its construction is presented in detail. With the incorporation of human factors and condition of disassembled units, this model proves to be more applicable to real industry setting. The suggestions for parameter learning are also discussed, allowing for the BN to give better results when many products have been disassembled.	bayesian network;design rationale;disassembler;expert system;human factors and ergonomics;petri net	David E. Grochowski;Ying Tang	2007	2007 IEEE International Conference on Networking, Sensing and Control	10.1109/ICNSC.2007.372827	computer science;knowledge management;artificial intelligence;machine learning;petri net;expert system	Robotics	-30.487170853744672	-7.452622367184642	33960
74604075fcd14528af0bd23392fdb20f5a579d43	statistics and gambling		Statistics can broadly be defined as the science of decision-making in the face of (random) uncertainty. Gambling has the same definition, except in the narrower domain of a gambler making decisions that affect his fortune in games of chance. It is hardly surprising, then, that the two subjects are closely related. Indeed, if the definitions of “game”, “decision”, and “fortune” in the context of gambling are sufficiently broadened, the two subjects become almost indistinguishable. Let’s review a bit of the history of the influence of gambling on the development of probability and statistics. First, of course, gambling is one of the oldest of human activities. The use of a certain type of animal heel bone (called the astragalus) as a crude die dates to about 3500 BCE (and possibly much earlier). The modern six-sided die dates to about 2000 BCE. The early development of probability as a mathematical theory is intimately related to gambling. Indeed, the first probability problems to be analyzed mathematically were gambling problems:	die (integrated circuit)	Kyle Siegrist	2011		10.1007/978-3-642-04898-2_555	probability and statistics;statistics;mathematics;mathematical theory;game of chance	Theory	-32.203750184394735	-16.389018893315725	33965
227a10a36b7e86f2350bef166236eeed26e09517	eliciting comparative linguistic expressions in group decision making	context free grammars comparative linguistic expressions linguistic models linguistic information elicitation information single linguistic terms group decision making model complex linguistic expressions hesitant fuzzy linguistic term sets;pragmatics computational modeling decision making grammar context modeling semantics uncertainty;group theory;fuzzy set theory;grammars;group theory decision making fuzzy set theory grammars	The complexity and relevance of the real world decision making problems have made necessary to use multiple points of view to achieve a common solution by using the knowledge provided for a group of experts. Usually, this knowledge is vague and imprecise. In such cases, the use of linguistic information has provided successful results, although sometimes they are limited because of the linguistic models restrict the elicitation of the linguistic information to single linguistic terms. In qualitative settings there is a high degree of uncertainty, in which experts can hesitate among several linguistic terms to provide their preferences. Therefore, richer expressions than single linguistic terms might support experts in such hesitant situations and improve the preferences elicitation and decision results. In this contribution, it is proposed a new group decision making model able to manage complex linguistic expressions based on hesitant fuzzy linguistic term sets and context-free grammars. The proposed model defines the necessary operations and tools to deal with such linguistic expressions.	context-free grammar;context-free language;relevance;requirements elicitation;vagueness	Rosa M. Rodríguez;Luis Martínez-López;Francisco Herrera	2013	2013 Joint IFSA World Congress and NAFIPS Annual Meeting (IFSA/NAFIPS)	10.1109/IFSA-NAFIPS.2013.6608498	natural language processing;deep linguistic processing;artificial intelligence;mathematics;communication;linguistic description	NLP	-5.077919773195504	-23.196551478012797	33981
5da65a33097b3145fee710b1381782176cb9b232	generalization, consistency, and control	causal analysis;human computer interaction;user interface	Easy learning of a user interface depends in part on users being able to generalize successfully about it. Philosophical doctrine, and some recent work in human-computer interaction, argues that causal analysis of interactions can support generalization. But neither the philosophical literature nor the HCI literature provides a rigorous theory of causal analysis adequate for problems in human-computer interaction. We propose such a rigorous theory here, and show how it accounts for two robust generalizations, using certain general assumptions. We then present evidence that these assumptions are accepted by people. Finally we compare this theory with other treatments of consistency.	causal filter;human–computer interaction;user interface	Clayton H. Lewis;D. Charles Hair;Victor Schoenberg	1989		10.1145/67449.67451	human–computer interaction;computer science;artificial intelligence;theoretical computer science;operating system;user interface	ML	-31.34928072695127	-16.14262478093167	33995
b700c155138ae503cd221588c3c33b7c66951bc1	emergence of pecking order in social cognitive radio societies		In the face of the exponential growth of Internet of Things (IoT) devices, the limited capacity of radio spectrum is likely to reach saturation. Cognitive Radio technology has been proposed to relieve over-saturated channels by allowing for licensed channels to be opportunistically accessed by unlicensed users during periods of time when the license holder is absent from its channel. Un-coordinated competition over a limited number of resources among unlicensed spectrum users leads to complex co-existence challenges. Here we present a new bio-social inspired paradigm for cognitive radio, extending our previous work where we showed a plausible evolutionary trajectory of intra-groups dynamics over time as groups abide by two social behavioral rules, in-group deference and out-group avoidance. In this paper, we relax these social behavior rules in order to allow groups to organize into different social structures. More specifically, we observe how a hierarchical society compares to a classless society. We show that as the system scales, the hierarchical social structure is more likely to emerge in a distributed cognitive radio network. The bio-social paradigm presented here has consequences both in suggesting potential improvements for dynamic spectrum access, and in understanding the natural evolvement of social structures as cognitive radio devices form groups to gain advantage in the competition over resources.	british informatics olympiad;cognitive radio;emergence;internet of things;programming paradigm;social structure;time complexity	Anna Wisniewska;Mohammad Abu Shattal;Bilal Khan;Ala I. Al-Fuqaha;Kirk Dombrowski	2018	IEEE INFOCOM 2018 - IEEE Conference on Computer Communications Workshops (INFOCOM WKSHPS)	10.1109/INFCOMW.2018.8407008	classless society;deference;distributed computing;radio spectrum;social structure;business;social cognitive theory;spectrum management;cognitive radio;pecking order	Mobile	-14.639153730564052	-14.300130985009895	34021
aa016177a764a02d037803c617d81866f6ec8c19	on equilibrium refinements in supermodular games	supermodular game;trembling hand perfect equilibrium;weakly dominated strategy;perfect equilibrium;strategically stable set	We show that supermodular games satisfying sequential better-reply security possess a pure strategy perfect equilibrium and a strategically stable set of pure strategy equilibria. We illustrate that in continuous supermodular games, perfect equilibria may contain weakly dominated actions. Moreover, in discontinuous supermodular games satisfying sequential better-reply security, perfect equilibria may involve play of actions in the interior of the set of weakly dominated actions. We show that supermodular games satisfying sequential better-reply security possess pure strategy perfect equilibria outside the interior of the set of weakly dominated action profiles.	action potential;supermodular function	Oriol Carbonell-Nicolau;Richard P. McLean	2015	Int. J. Game Theory	10.1007/s00182-014-0457-3	mathematical optimization;sequential equilibrium;trembling hand perfect equilibrium;economics;mathematics;mathematical economics;welfare economics	AI	-4.824748040596998	-2.1275091782396673	34030
9bbc6b64cb120ae39834f2a343d85c5c79bc32a2	instant mission rehearsal sensor data, gaming provide valued mission rehearsal for ground troops (abstract)				Mark Conger;Jon Damush	2009			simulation;instant;engineering	Robotics	-33.47729441115275	-23.583429778330505	34130
72587745fe9017f09937793614460bdb076f6e6b	apply fuzzy markup language to knowledge representation for game of computer go		In order to stimulate the development and research in computer Go, sev- eral Taiwanese Go players were invited to play against some famous computer Go programs from 2008 to 2011. Those competitions revealed that the ontology model for Go game might resolve problems happened in the competitions. Therefore, this chapter presents a model of knowledge representation including game of Go record ontology and Go board ontology based on fuzzy markup language (FML). An FML- based fuzzy system is also introduced to provide the regional alarm level for a Go beginner or a computer Go program in order to place the stone at the much more appropriate position. Experimental results indicate that the proposed approach is feasible for computer Go application. Hopefully, advances in the intelligent agent and the FML-based ontology model can provide a significant amount of knowledge to make a progress in computer Go program and achieve as much as computer chess or Chinese chess in the future.	computer go;fuzzy markup language;knowledge representation and reasoning	Chang-Shing Lee;Mei-Hui Wang;Yu-Jen Chen;Shi-Jim Yen	2013		10.1007/978-3-642-35488-5_6	simulation;computer science;artificial intelligence	NLP	-30.227684678152894	-16.36074635735967	34191
ca7a2a8516600482ea1fa7876c6361a6f64b7bfb	optimizing continuous multijoin queries over distributed streams	distributed database;query processing;data stream;query optimization;data streams;distributed databases	Many recently emerging applications, such as network management, financial monitoring, sensor networks, stock tickers etc, fueled the development of continuous query processing techniques over data streams. In these applications, the data sources are typically distributed, e.g. the network hosts or routers in network management. Collecting all the data to a centralized server may not be cost-effective due to the high communication cost. Clearly, a distributed stream processing system is inevitable. Unlike traditional DBMS, where the processing in each node involves expensive I/O operations, stream processing systems often perform main memory operations. These operations are relatively inexpensive in comparison to the communication cost. As both the queries and data streams are continuous, a few existing work focus on minimize the communication cost, especially when the source nodes are connected by wide area network. In this paper, we focus on multi-way window join query. Let us look at an example drawn from the network management application.	centralized computing;computer data storage;database;input/output;optimizing compiler;router (computing);server (computing);stream processing	Yongluan Zhou;Ying Yan;Beng Chin Ooi;Kian-Lee Tan;Aoying Zhou	2005		10.1145/1099554.1099597	sargable;query optimization;query expansion;computer science;data mining;database;web search query;view;distributed database;information retrieval;spatial query	DB	-32.20282600610863	-0.2319298894335657	34215
05347fea3713c5e52ac7de903105545ae66ab44e	multi-agent deep reinforcement learning for task allocation in dynamic environment		The task allocation problem in a distributed environment is one of the most challenging problems in a multiagent system. We propose a new task allocation process using deep reinforcement learning that allows cooperating agents to act automatically and learn how to communicate with other neighboring agents to allocate tasks and share resources. Through learning capabilities, agents will be able to reason conveniently, generate an appropriate policy and make a good decision. Our experiments show that it is possible to allocate tasks using deep Q-learning and more importantly show the performance of our distributed task allocation approach.	action selection;agent-based model;artificial neural network;experiment;multi-agent system;q-learning;reinforcement learning;social collaboration	Dhouha Ben Noureddine;Atef Gharbi;Samir Ben Ahmed	2017		10.5220/0006393400170026	machine learning;systems engineering;error-driven learning;computer science;reinforcement learning;artificial intelligence	AI	-16.76955464573865	-11.009383954858436	34228
1b9412c16ef04a7b45f1bf9ddad3c649744f2731	sources of unresolvable uncertainties in weakly predictive distributed virtual environments		This work expands the notion of unresolvable uncertainties due to modeling issues in weakly predictive simulations to include unique implementation induced sources that originate from fundamental trade-offs associated with distributed virtual environments. We consider these trade-offs in terms of the Consistency, Availability, and Partition tolerance (CAP) theorem to abstract away technical implementation details. Doing so illuminates systemic properties of weakly predictive simulations, including their ability to produce plausible responses. The plausibility property in particular is related to fairness concerns in distributed gaming and other interactive environments.	cap theorem;computer simulation;distributed computing;fairness measure;network partition;plausibility structure;unification (computer science);virtual reality	Jeremy R. Millar;Jason A. Blake;Douglas D. Hodson;John O. Miller;Raymond R. Hill	2016	2016 Winter Simulation Conference (WSC)		atmospheric model;simulation;uncertainty;computer science;theoretical computer science;machine learning;mathematical model;mathematics;predictive modelling;computational model;statistics	HPC	-15.866307084555515	2.9126505128185096	34240
0a86de1cc478416b02496b3c786a8f3288e8b273	optimized data migration within a medical grid	data migration	This paper focuses on creating an intelligent, scalable system that vastly improves the speed and efficiency of looking up medical data. The system automatically and meaningfully organizes the distributed medical data to allow fastest access. Additionally, this research seeks to further improve on the concept of a distributed database service by introducing caching across servers as a means to optimize data retrieval time. Instead of looking to many individual sources, researchers would be able to access data from a single source, which is optimized on a per-region basis to ensure the shortest access times.	data retrieval;distributed database;fastest;scalability	Jared Christopherson;Chun-Hsi Huang	2010			data migration;computer science	HPC	-31.93881086470838	-0.9633758920795672	34347
3f25b6e97e92db170a1619291bebaefffac66542	interval methods in knowledge representation			interval arithmetic;knowledge representation and reasoning	Vladik Kreinovich	2010	International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems	10.1142/S021848851000657X		Robotics	-27.72586898447554	-7.558325364025596	34354
cfd3a03ebc9f7ef14fa9794ec9757ecc3d73ea95	a model theoretic oriented approach to analogy	model theoretic;model theoretic oriented approach	"""F i rs t we have to state that the i n t u i t i v e notion of analogy covers numerous d i f f e ren t aspects and various problem domains. In the past many attempts were made to formalize certain ones of these aspects. Besides some e f fo r ts to develop general approaches to analogy in recent years numerous special methods and algorithms using aspect of analogy were worked out in the f i e l d of a r t i f i c i a l In te l l igence in order to program learning systems or robots, for instance. In the framework of th is short paper we cannot give a complete overview on a l l of these e f f o r t s . We w i l l only mention some approaches to tackle th is f i e l d under general points of view. As fare as we know, already in his """"Fragmente zur Logik"""" G.W.LEIBNIZ t r ied to precise certain aspects of analogy by studing the rel a t i on"""	algorithm;problem domain;robot;theory	Helmut Thiele	1986		10.1007/3-540-18081-8_94	analogy;mathematics;theoretical physics	AI	-27.043385663713682	-10.254684388764753	34356
51bff4e5e371469b52cd938ad56e3d695f83a948	tertiary storage organization for large multidimensional datasets		Large multidimensional datasets are found in diverse application areas, such as data warehousing [6], satellite data processing, and high-energy physics [9]. According to current estimates, these datasets are expected to hold terabytes of data. Since these datasets hold mainly historical and aggregate data, their sizes are increasing. Daily accumulation of raw data and jobs generating aggregate data from the raw data are responsible for this increase. Hence, estimates for the dataset sizes run into several petabytes. Though cost per byte as well as area per byte for secondary storage has been dropping, it is still not cost effective to store petabyte-sized datasets in the secondary storage [4]. Efficient storage organization for multidimensional data has been investigated extensively [8, 1, 5]. Chen et al [1] discuss organization of multidimensional data on a hierarchical storage system. The authors prove that the problem of efficient organization of multidimensional data on a one-dimensional storage system, such as tertiary storage, is NP-complete when arbitrary range queries are allowed. They present a five step strategy based on heuristics for the problem. Jagadish et al ([5]) investigated the problem of efficient organization of a data warehouse on secondary storage. The workload consists of a restricted set of range queries using hierarchies defined on the dimensions. They cast the problem as finding an optimal path through a lattice. They propose a dynamic programming based algorithm that determines how various dimensions are laid out. We are not aware of any work that takes into consideration practical constraints like the order in which the data already exists or will be generated. Given an order in which data currently exists (or will be generated), and a limited amount of temporary storage space, we investigate issues in efficiently organizing multidimensional datasets on tertiary storage. We cast the problem as permutation of the input data stream using limited storage space. The rest of this document is organized as follows: The problem is formulated in Section 2. Section 3 describes our approach. In Section 4, we present performance results. Section 5 presents conclusions.	aggregate data;algorithm;auxiliary memory;byte;computer data storage;constraint (mathematics);dynamic programming;entity–relationship model;heuristic (computer science);hierarchical storage management;job stream;multidimensional scaling;np-completeness;organizing (structure);petabyte;range query (data structures);raw image format;sorting;terabyte;tree accumulation	Sachin More;Alok N. Choudhary	2000			data science;raw data;data mining;aggregate data;byte;range query (data structures);data warehouse;heuristics;dynamic programming;computer data storage	DB	-27.99274216152324	1.2195813982305357	34399
8b046267522bb649536955fbde1afcf4859ba126	an instance vs. the instance	instance;interaction;the problem of universals;class;optimization;deconstruction	This article argues how one problem of computing lies in realizing a significant instance given a class or type. Analysis of a case study on digital narrative suggests two general processes for instantiating significant instances: interaction and optimization. The article then explains how the problem of universals needs to be deconstructed when trying to understand what type of entities significant instances are and what the process for obtaining them is.	entity;mathematical optimization	Kumiko Tanaka-Ishii	2008	Minds and Machines	10.1007/s11023-008-9128-0	interaction;problem of universals;computer science;artificial intelligence;machine learning;class;programming language;deconstruction;algorithm	DB	-27.114175647670702	-11.740908612837519	34411
81da311755b1bacffe36bc78688d21db0c2b7fa1	higher-degree stochastic dominance optimality and efficiency		We characterize a range of Stochastic Dominance (SD) relations by means of finite systems of convex inequalities. For ‘SD optimality’ of degree 1 to 4 and ‘SD efficiency’ of degree 2 to 5, we obtain exact systems that can be implemented using Linear Programming or Convex Quadratic Programming. For SD optimality of degree five and higher, and SD efficiency of degree six and higher, we obtain necessary conditions. We use separate model variables for the values of the derivatives of all relevant orders at all relevant outcome levels, which allows for preference restrictions beyond the standard sign restrictions. Our systems of inequalities can be interpreted in terms of piecewise polynomial utility functions with a number of pieces that increases with the number of outcomes and the degree of SD. An empirical study analyzes the relevance of higher-order risk preferences for comparing a passive stock market index with actively managed stock portfolios in standard data sets from the empirical asset pricing literature. © 2017 Elsevier B.V. All rights reserved.	algorithmic efficiency;linear programming;optimality criterion;polynomial;quadratic programming;relevance;secure digital	Yi Fang;Thierry Post	2017	European Journal of Operational Research	10.1016/j.ejor.2017.03.035	mathematical optimization;combinatorics;discrete mathematics;expected utility hypothesis;linear programming;stochastic dominance;mathematics	AI	-7.289362822700413	-1.584508027007904	34447
aca7319ca8fbd0b7b5b4193445d994d285351604	pure nash equilibria in player-specific and weighted congestion games	metodo polinomial;cardinal number;matroid;congestion trafic;game theory;temps polynomial;congestion trafico;best response dynamics;equilibrio juego;teoria juego;strategie joueur;economic model;theorie jeu;nash equilibria;estrategia jugador;matroide;strategie nash;modelo economico;polynomial time algorithm;nombre cardinal;modele economique;numero cardinal;internet;traffic congestion;polynomial method;retard;polynomial time;estrategia nash;nash strategy;equilibre jeu;jeu ordinateur;game equilibrium;computer games;convergence time;methode polynomiale;retraso;congestion game;lower bound;player strategy;tiempo polinomial	Unlike standard congestion games, weighted congestion games and congestion games with player-specific delay functions do not necessarily possess pure Nash equilibria. It is known, however, that there exist pure equilibria for both of these variants in the case of singleton congestion games, i. e., if the players’ strategy spaces contain only sets of cardinality one. In this paper, we investigate how far such a property on the players’ strategy spaces guaranteeing the existence of pure equilibria can be extended. We show that both weighted and player-specific congestion games admit pure equilibria in the case of matroid congestion games, i. e., if the strategy space of each player consists of the bases of a matroid on the set of resources. We also show that the matroid property is the maximal property that guarantees pure equilibria without taking into account how the strategy spaces of different players are interweaved. Additionally, our analysis of player-specific matroid congestion games yields a polynomial time algorithm for computing pure equilibria. We also address questions related to the convergence time of such games. For player-specific matroid congestion games, in which the best response dynamics may cycle, we show that from every state there exists a short sequences of better responses to an equilibrium. For weighted matroid congestion games, we present a superpolynomial lower bound on the convergence time of the best response dynamics showing that players do not even converge in pseudopolynomial time.	algorithm;converge;existential quantification;maximal set;nash equilibrium;network congestion;p (complexity);polynomial;pseudo-polynomial time;time complexity;weighted matroid	Heiner Ackermann;Heiko Röglin;Berthold Vöcking	2006		10.1007/11944874_6	cardinal number;matroid;time complexity;game theory;combinatorics;the internet;best response;coordination game;economics;economic model;mathematics;microeconomics;mathematical economics;upper and lower bounds;nash equilibrium	ECom	-4.951389279215676	0.5294836342710869	34510
099cd803889553b255fedd13d9234c56766be1da	relevance of qualitative constraints in diagnostic processes	qualitative constraints;diagnosis procedures;conditional exchangeability;coherent inference;medical diagnosis	This paper reviews recent results obtained in the medical diagnosis field by adding to a coherent inference process qualitative constraints. Such further considerations turn out to be significant whenever a basic lower-upper conditional probability assessment induces extension bounds too vague to take any decision. Three general types of qualitative judgements are proposed and fully described. They do not constitute a “panacea” to solve any problematic situation, but their application can considerably improve inferences results in specific fields, as two practical applications show.	coherence (physics);relevance;vagueness	Andrea Capotorti	2003			statistics;medical diagnosis;econometrics;computer science;data mining	AI	-15.49018466899104	-0.05265492575708216	34742
ef62f1d1f182cdde963ebe5c67a46f28177f39e4	cooperative situation assessment in a maritime scenario	multi agent systems;decentralized coordination;situation assessment	In large-scale, complex domains such as space defense and security systems, situation assessment and decision making are evolving from centralized models to high-level, net-centric models. In this context, collaboration among the many actors involved in the situation assessment process is critical in order to achieve a prompt reaction as needed in the operational scenario. In this paper, we propose a multi-agent based approach to situation assessment, where agents cooperate by sharing local information to reach a common and coherent assessment of situations. Specifically, we characterize situation assessment as a classification process based on OWL ontology reasoning, and we provide a protocol for cooperative multi-agent situation assessment, which allows the agents to achieve coherent high level conclusions. We validate our approach in a real maritime surveillance scenario, where our prototype system effectively supports the user in detecting and classifying potential threats; moreover, our distributed solution performs comparably to a centralized method, while preserving independence of decision makers and dramatically reducing the amount of communication required.	agent-based model;belief revision;centralized computing;coherence (physics);high- and low-level;high-level programming language;inferential programming;multi-agent system;net-centric;prototype;robustness (computer science);scalability;sensor;web ontology language	Alessandro Farinelli;Daniele Nardi;Roberta Pigliacampo;Mirco Rossi;Giuseppe Paolo Settembre	2012	Int. J. Intell. Syst.	10.1002/int.21532	simulation;computer science;knowledge management;artificial intelligence;multi-agent system;data mining;situation analysis	AI	-20.123037849841175	-11.271380370610375	34743
e8e683995ca8a27aff1fc5b565bd292f43a0349a	an attitude-adaptation negotiation strategy in electronic market environments	decision models;electronic commerce;learning algorithm;nash equilibrium;lighting face recognition feature extraction;variable lighting;attitude adaptation negotiation strategy;electronic markets;electronic market environments;face recognition feature extraction probes lighting entropy distributed computing pixel software engineering artificial intelligence helium;face recognition;history based learning;market opportunities electronic commerce learning artificial intelligence;feature extraction;market opportunities;half face recognition scheme;consumer electronics educational institutions nash equilibrium supply and demand business proposals genetic algorithms electronic commerce internet game theory;lighting;face images;learning artificial intelligence;illumination compensation half face recognition scheme variable lighting face images;illumination compensation;history based learning attitude adaptation negotiation strategy electronic market environments electronic commerce nash equilibrium;automated negotiation;supply and demand	The automatization of electronic commerce negotiation has become the focus of more and more attention. As one of the core of automated negotiation, strategy is the method employed by agents to maximize their own benefits. The design of negotiation strategy is affected by lots of factors, such as negotiation deadline, the type of resources, the characteristics of opponents, the numbers of competitors, etc. Though lots of work have been done on negotiation strategy, there still lack a uniform strategy framework. In this paper, a general description framework for multi- agent negotiation is proposed. Then solutions to the decision models are given and the existence of the Nash equilibrium in agents' attitude selection at the beginning of negotiations is analyzed. To enable agents to adapt their attitudes according to negotiation duration, the supply and demand ratio, and the characteristics of opponent, we introduce an adaptation function. This function is constructed on the basis of a history-based learning algorithm. Furthermore, the attitude-adaptation strategy and the fixed-attitude strategies are compared by simulation.	algorithm;e-commerce;intelligent agent;nash equilibrium;simulation	Shujuan Ji;Yongquan Liang;Xingpeng Xiao;Jixue Li;Qijia Tian	2007	Eighth ACIS International Conference on Software Engineering, Artificial Intelligence, Networking, and Parallel/Distributed Computing (SNPD 2007)	10.1109/SNPD.2007.26	e-commerce;facial recognition system;decision model;simulation;feature extraction;computer science;knowledge management;artificial intelligence;machine learning;lighting;supply and demand;computer security;nash equilibrium	AI	-9.995487046841353	-9.610298699333432	34886
a5cfd53159417f73f34d807e9b92e17040d50206	starcraft as a testbed for engineering complex distributed systems using cognitive agent technology		It has been argued that the evaluation of cognitive agent systems requires richer benchmark problems. We think that real-time strategy (RTS) games can offer such a testbed, as AI for RTS requires the design of complicated strategies for coordinating hundreds of units that need to solve a range of challenges. Therefore, in this paper, we report on the design and development of the first multi-agent connector that provides full access to StarCraft (Brood War). We provide a new interface that is dedicated to a multi-agent approach by connecting each unit in the game to a cognitive agent. Two main challenges are addressed in this work. First, we decide on the right level of abstraction for unit control by means of agents, designing for instance the percepts that are available to units. Second, a sufficient level of performance needs to be ensured in order to allow a large variety of multi-agent implementations to be successful at tackling challenges of RTS AI. The resulting open-source connector readily supports the hundreds of agents that can come and go during the game. Based on the development of the connector and its initial use by over 200 students, we gained valuable insights. ACM Reference Format: Vincent J. Koeman, Harm J. Griffioen, Danny C. Plenge, Koen V. Hindriks. 2018. StarCraft as a Testbed for Engineering Complex Distributed Systems Using Cognitive Agent Technology. In Proc. of the 17th International Conference on Autonomous Agents and Multiagent Systems (AAMAS 2018), Stockholm, Sweden, July 10–15, 2018, IFAAMAS, 3 pages.	artificial intelligence;autonomous agents and multi-agent systems;benchmark (computing);distributed computing;international conference on autonomous agents and multiagent systems;multi-agent system;open-source software;real-time transcription;starcraft;starcraft: brood war;testbed	Vincent J. Koeman;Harm J. Griffioen;Danny C. Plenge;Koen V. Hindriks	2018			implementation;computer science;distributed computing;cognition;testbed;abstraction	AI	-26.449192497572774	-21.441401283408972	34918
ec9cddf3e7f96d3efc6191d00410ea56338379e6	characterizing the nash equilibria of a three-player bayesian quantum game	quantum games;bayesian games;quantum networks;nash equilibria	Quantum games with incomplete information can be studied within a Bayesian framework. We consider a version of prisoner’s dilemma (PD) in this framework with three players and characterize the Nash equilibria. A variation of the standard PD game is set up with two types of the second prisoner and the first prisoner plays with them with probability p and 1 − p, respectively. The Bayesian nature of the game manifests in the uncertainty that the first prisoner faces about his opponent’s type which is encoded either in a classical probability or in the amplitudes of a wave function. Here, we consider scenarios with asymmetric payoffs between the first and second prisoner for different values of the probability, p, and the entanglement. Our results indicate a class of Nash equilibria (NE) with rich structures, characterized by a phase relationship on the strategies of the players. The rich structure can be exploited by the referee to set up rules of the game to push the players toward a specific class of NE. These results provide a deeper insight into the quantum advantages of Bayesian games over their classical counterpart.	nash equilibrium;prisoner's dilemma;quantum entanglement;quantum game theory;quantum mechanics;quantum network	Neal Solmeyer;Ricky Dixon;Radhakrishnan Balu	2017	Quantum Information Processing	10.1007/s11128-017-1593-z	price of stability;bayesian game;game theory;best response;simultaneous game;folk theorem;repeated game;mathematics;normal-form game;mathematical economics;symmetric game;symmetric equilibrium	Theory	-4.826286589361107	-0.9074740816624223	34931
95e3702caf8979ed263ecb1979f16ea8f63a0e11	dialogue management and automation in interaction with unmanned systems	unmanned systems;dialogue management;automation	As systems get more autonomous and automated, they still should give adequate level of information and adapt their style of communication to the human user. This research aims on designing a dialogue management system that should guide the interaction between the system and the user. The conceptual model underlying this dialogue manager currently includes the following mechanisms: timing, style, team role and priority( of content). The current model was based on observations of dialogue and interaction during current missions of unmanned systems as well as interviews with operators and designers of such systems. This first version of this model will be tested with a scenario that was developed earlier. Future work include prototyping ,and the implementation of the dialogue management system which involve tests with end users.	autonomous robot;dialog system;robotics	Annemiek van Drunen	2012			simulation;systems engineering;engineering;knowledge management	AI	-25.26439273779984	-23.389581975712133	34961
6c52d99309049c2f425d8c06b1141ec9bda3eba0	counterfactual resimulation for causal analysis of rule-based models		Models based on rules that express local and heterogeneous mechanisms of stochastic interactions between structured agents are an important tool for investigating the dynamical behavior of complex systems, especially in molecular biology. Given a simulated trace of events, the challenge is to construct a causal diagram that explains how a phenomenon of interest occurred. Counterfactual analysis can provide distinctive insights, but its standard definition is not applicable in rule-based models because they are not readily expressible in terms of structural equations. We provide a semantics of counterfactual statements that addresses this challenge by sampling counterfactual trajectories that are probabilistically as close to the factual trace as a given intervention permits them to be. We then show how counterfactual dependencies give rise to explanations in terms of relations of enablement and prevention between events.	causal filter;causal model;complex systems;counterfactual conditional;counterfactual definiteness;diagram;dynamical system;interaction;logic programming;sampling (signal processing);standard-definition television	Jonathan Laurent;Jean Yang;Walter Fontana	2018		10.24963/ijcai.2018/260	artificial intelligence;rule-based system;counterfactual thinking;machine learning;computer science	ML	-22.763448723645862	-13.526352828028832	34963
c4a88bda57b9a0ea0746126b09013f1f4ad01846	a dynamic clustering method to improve the coherency of an anp supermatrix		When making decisions with the Analytic Network Process, coherency testing is an important step in the decision making process. Once an incoherent priority vector is identified it can either be costly or in some cases next to impossible to elicit new pairwise comparisons. Remarkably, there is useful information in the linking estimates that one may have already calculated and used in one of the approaches to measure the coherency of the Supermatrix. A dynamic clustering method is used to automatically identify a cluster of coherent linking estimates from which a new coherent priority vector can be calculated and used to replace the most incoherent priority vector. The decision maker can then accept or revise the proposed new and coherent priority vector. This process is repeated until the entire Supermatrix is coherent. This method can save decision makers valuable time and effort by using the information and relationships that already exist in a weighted Supermatrix that is sufficiently coherent. The method is initially motivated and demonstrated through a simple straightforward example. A group of conceptual charts and a figure provide a visual motivation and explanation of themethod. A high level summary of themethod is provided in a table before the method is presented in detail. Simulations demonstrate both the application and the robustness of the proposed method. Code is provided, as supplementary material, in the programming language R so the method can be easily applied by the decision maker.	brushing and linking;chart;cluster analysis;coherence (physics);computer simulation;high-level programming language;interdependence;r language	Idil Yavuz;Orrin Cooper	2017	Annals OR	10.1007/s10479-017-2403-9	mathematical optimization;theoretical computer science;data mining;mathematics;algorithm;statistics	Vision	-5.279381640183985	-20.174095129286748	34991
6033b9cdd0077f820bc7afa29ca732c48917b736	multi-agent based social simulation applied to validation of location services			agent-based social simulation	Jesus J. Martínez;Teresa García-Valverde;Francisco Campuzano;Pablo Campillo-Sanchez;Alberto García-Sola;Juan A. Botía Blaya	2012		10.3233/978-1-61499-050-5-91	computer science;simulation;agent-based social simulation;data mining;location-based service	AI	-19.081692878792524	-11.842806990556584	35038
a0c821be4331d49553737f09ebc284cbdf66e76b	the creation of a reputation in an artificial society organised by a gift system	u10 methodes mathematiques et statistiques;multi agent system;gift;reputation;multi agent systems;autonomous agent	This paper describes simulations in an artificial society in which autonomous agents exchange gifts. In this society agents perform simple acts that are looked at by the others and are analysed so that a common image is created for each agent (a reputation). The model is based on numerous descriptions of non-merchant exchange systems, which are very interesting for ethnologists as well as for economists: they appear to be important for circulation of goods and to insure the reproduction of social links and values. In the system built the agents must make a gift at each time-step. There exist two kinds of gifts and two corresponding kinds of reputation: the agents either give to share or to be prestigious. Since gifts are received according to status, receiving a gift is as important for a reputation as making one. Each agent is characterised by its ''motivation'' to acquire the reputation of being a sharing agent or a prestigious agent. It is also characterised by its ''esteem'', to decide if it will be able to do the gift it wants to do for a time-step. These two characteristics of an agent can be stable during the simulation, but can also evolve according to its history. We study here the different patterns that can appear in the societies, in terms of generation of reputation, and of histories over time. A huge range of these patterns can be observed, depending on the choice made for the parameters. In some cases the agents cannot be individually distinguished, in other cases they can: but, in any case any individual behaviours that emerge have to be sustained by a collective specification that points out more or less the way agents value each reputation.		Juliette Rouchier;Martin O'Connor;François Bousquet	2001	J. Artificial Societies and Social Simulation		public relations;reputation;computer science;artificial intelligence;autonomous agent;multi-agent system;social psychology;commerce	AI	-15.982016446820024	-14.818601369057426	35113
56bd2460b0ca58f3509a4175b7991c690fc6debd	a multiagent system for coordinating ambulances for emergency medical services	multiagent system;confiance;psychologie sociale;healthcare;aplicacion medical;ambulance service;ambulance;healthcare multiagent system emergency medical service ambulance auction mechanism emergency transportation sophisticated medical treatment;servei d ambulancies;healthcare multiagent systems coherence and coordination;intelligence artificielle;medicina informatica;info eu repo semantics article;multiagent systems medical services delay vehicles medical treatment computer architecture humans road transportation appropriate technology hemorrhaging;medical computing;appropriate technology;emergency;hemorrhaging;computer architecture;auction mechanism;multi agent systems;confidence;medical services;confianza;patient treatment emergency services health care medical computing multi agent systems;emergency medical services;urgencia;subasta;urgencies mediques serveis d;sophisticated medical treatment;psicologia social;bidding;emergency medical service;agents intel ligents programari;urgence;patient treatment;sistemes multiagent;artificial intelligence;intelligent agents computer software;social psychology;medical application;humans;vehicles;enchere;inteligencia artificial;medicine data processing;coherence and coordination;medical treatment;road transportation;sistema multiagente;emergency transportation;systeme multiagent;multiagent systems;emergency services;application medicale;health care	To coordinate ambulances for emergency medical services, a multiagent system uses an auction mechanism based on trust. Results of tests using real data show that this system can efficiently assign ambulances to patients, thereby reducing transportation time. Emergency transportation on specialized vehicles is needed when a person's health is in risk of irreparable damage. A patient can't benefit from sophisticated medical treatments and technologies if she or he isn't placed in a proper healthcare center with the appropriate medical team. For example, strokes are neurological emergencies involving a limited amount of time in which treatment measures are effective.	agent-based model;multi-agent system	Beatriz López;Bianca Innocenti;Dídac Busquets	2008	IEEE Intelligent Systems	10.1109/MIS.2008.76	simulation;bidding;emergency;computer science;artificial intelligence;appropriate technology;multi-agent system;confidence;emergency medical services;computer security;health care	AI	-24.04463617696628	-9.102346969183143	35115
39265700c1ccbcb9e1174d8a56e00ac3407fa9cc	a comprehensive performance evaluation framework of complex products based on a fuzzy ahp and ds theory	fuzzy;analytical hierarchy process;dempstere shafer theory;small sample data;evaluation framework	With the development of computer technique, performance evaluation of complex products is playing an increasingly critical role in ensuring product quality and improving development process. An extensible comprehensive performance evaluation framework with the integration of effective group decision-making algorithms could be a supporting tool to achieve an efficient evaluation process and reduce comprehensive evaluation difficulty. This paper aims to provide a evaluation framework with friendly interactive operation and extensive expansibility, which adopts a multi-expert evaluation approach based on fuzzy, analytical hierarchy process (FAHP) and Dempstere–Shafer (DS) theory (FADS) in order to consider experts’ relative importance degree. In addition, an extensible evaluation process and related auxiliary functions are implemented in the framework, including the establishment of an assessment index system, integration and calls of multiple types of testing data preprocessing methods and index assessment methods suitable for small sample data, graphical result display and data analysis, etc. Finally, performance evaluation cases of two models of airborne radar anti-jamming are presented to verify the feasibility and expansibility of our assessment framework. The group decision-making method shows its effectiveness compared with the experimental evaluation results by the FAHP researched method.	performance evaluation	Yuhong Li;Guanghong Gong;Ni Li	2016	IJMSSC	10.1142/S1793962316500203	fuzzy logic;reliability engineering;analytic hierarchy process;simulation;computer science;systems engineering;data mining	Vision	-6.645147836664133	-18.428899046946796	35168
114da97d6b5d1443cb536de1dc893401746b9557	some methodology and representation problems for the semantics of prosaic application domains (extended abstract)	extended abstract;representation problems;prosaic application domains;intelligent agent;use case	As the primary targets for exercises of re-engineering and interoperability, so-called prosaic application domains and their associated systems provide interesting and practically useful case studies for a treatment of semantics from a methodological as well as cognitive point of view. (In this paper we treat cognition as the process of linking knowledge to perception inside an intelligent agent.)		Robert Meersman	1994		10.1007/3-540-58495-1_4	natural language processing;discrete mathematics;theoretical computer science;mathematics	Theory	-29.459891805109965	-12.013816187826475	35179
68754838c7649b6371903777b02e17dc61970546	shaban multi-agent team to herd cows	dynamic environment;agent architecture;agent programming	This paper is submitted as the final team description of SHABaN team, one of the participants in the Second Multi-Agent Programming Contest in association with the ProMAS 2008 workshop. Here we describe the agent architecture and behaviors to solve a cooperative task in a highly dynamic environment. Our approach consists of evaluating strategies in NetLogo and a raw implementation.	agent architecture;computer multitasking;multi-agent programming contest;netlogo	Adel Torkaman Rahmani;Alireza Saberi;Mahdi Mohammadi;Amin Nikanjam;Ehsan Adeli-Mosabbeb;Monireh Abdoos	2008		10.1007/978-3-642-03278-3_20	agent architecture;simulation;computer science;knowledge management;artificial intelligence	AI	-30.692695796785767	-19.84427169143797	35185
0e3836ded3c395926891b1c3a613ba3bff6d98da	the shapley values on fuzzy coalition games with concave integral form		A generalized form of a cooperative game with fuzzy coalition variables is proposed. The character function of the new game is described by the Concave integral, which allows players to assign their preferred expected values only to some coalitions. It is shown that the new game will degenerate into the Tsurumi fuzzy game when it is convex. The Shapley values of the proposed game have been investigated in detail and their simple calculation formula is given by a linear aggregation of the Shapley values on subdecompositions crisp coalitions.		Jinhui Pang;Xiang Chen;Shujin Li	2014	J. Applied Mathematics	10.1155/2014/231508	bondareva–shapley theorem;mathematical optimization;example of a game without a value;repeated game;mathematics;stochastic game;shapley value;normal-form game;mathematical economics	AI	-6.14203474867277	-1.8788796128995469	35211
4bad841e2854f229fcc7fcaf261a1164692d0f31	how to combine expert (and novice) advice when actions impact the environment?	reward dependence;zero sum game;prisoner s dilemma	Theso-called“expertsalgorithms” constitutea methodologyfor choosing actionsrepeatedly , whenthe rewardsdependboth on the choiceof actionandon theunknown currentstateof theenvironment.An experts algorithmhasaccessto asetof strategies(“experts”), eachof whichmay recommendwhich action to choose.Thealgorithmlearnshow to combinetherecommendations of individual expertssothat, in the long run, for any fixedsequenceof statesof theenvironment,it doesaswell asthe bestexpertwouldhavedonerelativeto thesamesequence. Thismethodology maynot besuitablefor situationswheretheevolution of statesof theenvironmentdependson pastchosenactions,asis usuallythecase, for example,in a repeatednon-zero-sumgame. A new expertsalgorithmis presentedandanalyzed in thecontext of repeatedgames.It is shown thatasymptotically, undercertainconditions, it performsaswell asthe bestavailableexpert. This algorithmis quite different from previously proposed expertsalgorithms. It representsa shift from the paradigmsof regret minimizationandmyopic optimization to considerationof the long-termeffect of a player’s actionson the opponent’ s actionsor the environment. The importanceof this shift is demonstratedby the fact that this algorithmis capableof inducingcooperationin the repeatedPrisoner’ s Dilemmagame,whereasprevious expertsalgorithmsconvergeto thesuboptimalnon-cooperati veplay.	ada semantic interface specification;mathematical optimization;regret (decision theory)	Daniela Pucci de Farias;Nimrod Megiddo	2003				Vision	-9.691236374287676	-4.263007277938164	35239
5add35011aadd01c5150b82429ac80b58227492f	complexity at large	security and protection;algorithms;connectionism and neural nets;design;intelligent agents;experimentation;security;human factors;biology and genetics;fault tolerance;complexity measures and classes;measurement;general;network communications;theory;conference proceedings;performance	The following news item is taken in part from the August 2005 issue of Animal Behaviour titled, “Honeybee Swarms: How Do Scouts Guide a Swarm of Uninformed Bees?” by S. Janson, M. Middendorf, and M. Beekman. The organized movement of a swarm of honeybees towards its new home is a perplexing phenomenon because only a small number of scout bees, approximately 5%, know the direction in which the swarm has to move. Nevertheless, in the majority of cases a swarm, comprising about 10,000 mainly uninformed bees, reaches the new home. How do the scouts transfer directional information en route to the uninformed bees? ... We developed a model ... and showed that when scouts fly through the swarm at a speed slightly higher than the speed of the other (uninformed) bees.... A link to this article can be found at http://www.comdig.org/index.php?id_issue 2005.30#22041	complexity;gerard beekmans;swarm intelligence	Martin Middendorf	2005	Complexity	10.1002/cplx.20105	machine learning;artificial intelligence;worst-case complexity;mathematics	ML	-31.831548282908965	-19.3784872384881	35265
09afbefb26cbbc43545bf95f2391c95c0b0ff9cc	smec-3d: a multi-agent 3d game to cognitive stimulation		Multi-agents are being increasingly used in many areas, especially in Health Systems. In a game the agents’ paradigm provides more autonomy, intelligence and pro-activity. In this context, Multi-agents systems can be used to control the user performance, by adapting the interface to the difficulty tasks level. This paper aims at describing the development process of SMEC-3D, a cognitive stimulation game that integrates Virtual Reality and Multi-agent technologies. The SMEC-3D modeling process used i* (i-star) framework to model the goals, agents, domain, plans and tasks. The game objective is to improve attention and memory of patients with neuropsychiatric disorders. The paper describes the development process specially the agents’ methodology. The resulted SMEC-3D game showed that the combination of tools and programming languages applied to this experiment worked efficiently.		Priscilla Fonseca de Abreu Braz;Vera Werneck;Herbet de Souza Cunha;Rosa Maria Esteves Moreira da Costa	2018		10.1007/978-3-319-94779-2_22	human–computer interaction;autonomy;virtual reality;cognitive stimulation;computer science	HCI	-31.608863288988196	-11.04206540339125	35271
3187df37515ab211df8c4d029887f21afc06b357	perspectives on the formal representation of the interpretation of norms		Task independent interpretation and task dependent specification In our society norms are communicated in natural language, and no-one has yet come up with a method that can unambiguously transfer a natural language into a formal specification that can be used by rational agents acting in a complex and dynamic environment, aiming to achieve goals fitting the agents’ intentions. We use agent-based models to test the effectiveness of policies, for example in the SARNET project.	agent-based model;formal specification;interpretation (logic);natural language;rational agent	Robert van Doesburg;Tom M. van Engers	2016		10.3233/978-1-61499-726-9-183	knowledge management;formal system;computer science	AI	-21.742611992458393	-10.776058607973937	35333
55b6433236934c533db3ca64210b443d7c8c0d92	some thoughts on owl-empowered sparql query optimization		The discovery of optimal or close to optimal query plans for SPARQL queries is a difficult and challenging problem for query optimisers of RDF engines. Despite the growing volume of work on optimising SPARQL query answering, using heuristics or data statistics (such as cardinality estimations) there is little effort on the use of OWL constructs for query optimisation. OWL axioms can be the basis for the development of schema-aware optimisation techniques that will allow significant improvements in the performance of RDF query engines when used in tandem with data statistics or other heuristics. The aim of this paper is to show the potential of this idea, by discussing a diverse set of cases that depict how schema information can assist SPARQL query optimisers.	heuristic (computer science);mathematical optimization;program optimization;query optimization;sparql;web ontology language	Vassilis Papakonstantinou;Giorgos Flouris;Irini Fundulaki;Andrey Gubichev	2016		10.1007/978-3-319-47602-5_3	query optimization;named graph;sparql;rdf query language;web search query	Web+IR	-33.19194289090386	3.8536752729647556	35387
c9955655d48c8cc51b7842f040c0e5d5e5d04155	research on the evaluation of development level of principal sports industry based on analytic hierarchy process	eigenvalues and eigenfunctions;principal sports industry;analytic hierarchy process;investments;sport decision making economic indicators leisure industry;industries;frequency measurement;sports industry;ahp;leisure industry;indexes;ahp principal sports industry evaluation;awards activities;industries indexes economics eigenvalues and eigenfunctions awards activities investments frequency measurement;indexation;evaluation index system;evaluation;evaluation index system analytic hierarchy process sports industry economic development mass sports development athletic sports development;economic development;economics;sport;mass sports development;athletic sports development;economic indicators	Sports industry plays an important role in economic development and it is a new growth point of national economic development. This paper, based on the principles of scientificity, integrity, systematicness and maneuverability, selects indices from the perspective of mass sports development and athletic sports development, builds up an evaluation index system for the principal sports industry development, and determines the weight of index evaluation system. Also, this paper, has collected on the basis of some raw data, and makes a complete evaluation and analysis on the development level of athletic sports, mass sports and principal sports industry in Beijing, Guangdong, Shaanxi, Hubei, Hunan and the whole nation.	chinese room	Xu Yong	2010	2010 International Conference on E-Business and E-Government	10.1109/ICEE.2010.745	analytic hierarchy process;economics;computer science;engineering;marketing;operations management;management	Robotics	-8.413709312802428	-19.527033283262845	35440
00e1bc9f2c4abd4ada4baec0ef26d038b6ff2c78	agrios: a hybrid approach to big array analytics	optimisation;scidb;query processing;query optimization;relational database query optimization agrios big array analytics hybrid approach big data analysis analytic tool dedicated data management platform hybrid analytic system array structured data scidb;scidb big array analytics query optimization r;data analysis;arrays shape vectors information management data handling data storage systems data models;data structures;relational databases data analysis data structures optimisation query processing;relational databases;big array analytics;r	Hybrid systems for analyzing big data integrate an analytic tool and a dedicated data-management platform. The necessary movement of data between the components of a hybrid system can lead to performance problems, if that movement is not managed effectively. We present Agrios, a hybrid analytic system for array-structured data, integrating R and SciDB. Agrios minimizes data movement between the two components of the hybrid, using techniques repurposed from relational database query optimization.	big data;data science;disk staging;greedy algorithm;hybrid system;mathematical optimization;memoization;performance tuning;query optimization;relational database;rewriting;scidb;top-down and bottom-up design;tree accumulation	Patrick Leyshock;David Maier;Kristin Tufte	2013	2013 IEEE International Conference on Big Data	10.1109/BigData.2013.6691558	sargable;analytics;query optimization;computer science;data science;data mining;database	Robotics	-32.92454423182738	-0.22477633469872696	35442
9fc8f2f1ed7623735dc1ba818b2d4856d4b8f277	suitability evaluation of urban construction land based on geo-environmental factors of hangzhou, china	analytic hierarchy process;engineering geology;analytic hierarchy process ahp;geographic information system;evaluation method;geographic information system gis;urban development;grid;hangzhou;back propagation bp neural network;期刊论文;self organization;spatial analysis;adaptive capacity;china;back propagation;k means clustering;neural network;environmental factor;geological hazard;suitability evaluation	Suitability evaluation of urban construction land based on geo-environmental factors is the process of determining the fitness of a given tract of land for construction. This process involves a consideration of the geomorphology, geology, engineering geology, geological hazards, and other geological factors and is the basis of urban construction land planning and management. With the support of Geographic Information Systems (GIS), grid analysis, and geo-spatial analysis techniques, four factor groups comprising nine separate subfactors of geo-environmental attributes were selected to be used in the evaluation of the suitability level for construction land in Hangzhou. This was based on K-means clustering and back-propagation (BP) neural network methods due to their advantages in fast computing, unique adaptive capacity, and self-organization. Simultaneously, the evaluation results based on K-means clustering and BP neural network were compared and analyzed, and the accuracy evaluation was set. The results showed that the geo-environmental suitability evaluation results of construction land based on K-means clustering and BP neural network were similar in terms of the distribution and scale of construction land suitability level. At the same time, the results of the two evaluation methods were consistent with the variability in suitability level, engineering geology, and hydrogeology of Hangzhou. The results also showed that the real advantage of the methods proposed in this paper lies in their capacity to streamline the mapping process and to ensure that the results are consistent throughout. The suitability level of the urban construction land based on the geoenvironment in Hangzhou was divided into four construction sites: land for building super high-rise and high-rise buildings, land for building multistorey buildings, land for low-rise buildings, and nonbuilding land. The results of the suitability evaluation for each category will provide a scientific basis for decision-making in urban development in Hangzhou. Crown Copyright & 2011 Published by Elsevier Ltd. All rights reserved.	adobe streamline;artificial neural network;backpropagation;cluster analysis;crown group;geographic information system;heart rate variability;k-means clustering;self-organization;software propagation;spatial analysis;tract (literature)	Kai Xu;Chunfang Kong;Jiangfeng Li;Liqin Zhang;Chonglong Wu	2011	Computers & Geosciences	10.1016/j.cageo.2011.03.006	analytic hierarchy process;computer science;machine learning;spatial analysis;geographic information system;engineering geology;grid;china	AI	-10.485108687179348	-23.169146513182945	35562
537078c7cab9186c7c56f2d8b7122220fc02aaac	isomorphism of reasoning systems with applications to autonomous knowledge acquisition	reasoning system;autonomous knowledge acquisition		autonomous robot;knowledge acquisition;reasoning system	David C. Kuncicky	1991				AI	-27.46179974873162	-7.829462484435304	35615
e38584df2148eb6a22c43e87cc1fa416a7c064be	narrative scenarios, mediating formalisms, and the agent-based simulation of land use change	agent based simulation;programming language;land use change;natural language;narrative scenarios;qualitative ontologies semantics simulation;simulation model;formal ontology	The kinds of system studied using agent-based simulation are intuitively, and to a considerable extent scientifically, understood through natural language narrative scenarios , and that finding systematic and well-founded ways to relate such scenarios to simulation models, and in particular to their outputs, is important in both scientific and policy-related applications of agent-based simulation. The paper outlines a projected approach to the constellation of problems this raises --- which derive from the gulf between the semantics of natural and programming languages. It centers on the use of mediating formalisms: ontologies and specialised formalisms for qualitative representation and reasoning. Examples are derived primarily from ongoing work on the simulation of land use change.	agent-based model;agent-based social simulation;artificial intelligence;cobham's thesis;computational complexity theory;denotational semantics;knowledge representation and reasoning;marcel j. e. golay;maximal set;morgan;nest (neural simulation tool);natural language;ontology (information science);region connection calculus;semantics (computer science);spatial–temporal reasoning;uncore	Nicholas Mark Gotts;J. Gareth Polhill	2006		10.1007/978-3-642-01109-2_8	simulation;computer science;knowledge management;communication	AI	-22.949581368000484	-14.67893467934598	35618
74236a46979154e04f1b617238fc0fd0e12384e6	agent-based computing, adaptive algorithms and bio computing	multi agent system;complex adaptive system;finite difference;asymptotic analysis;finite element;adaptive algorithm;adaptive system;intelligent system;intelligent agent;mathematical model	Agent-oriented system seems to be the attractive tool useful for numerous domains of applications. It gives the ability to integrate results of different domains of computer science and constitutes the powerful tool for solving various problems. The new approach to the simulation particularly in bio-computing and adaptive systems is possible to be developed mainly due to the results of the interactions among intelligent agents in complex adaptive systems. The modern agent-oriented paradigm allows understand the adaptive (e.g. finite element / finite difference) algorithms as a collection of interacting agents making local decision about refinements. This workshop focuses on the various applications of agent-oriented and adaptive systems and the roles of interactions of intelligent agents to build intelligent systems for miscellaneous, interesting applications.	adaptive algorithm;british informatics olympiad;complex adaptive system;computer science;finite difference;finite element method;intelligent agent;interaction;programming paradigm;simulation	Krzysztof Cetnarowicz;Maciej Paszynski;David Pardo;Tibor Bosse;Han La Poutré	2010		10.1016/j.procs.2010.04.218	agent architecture;complex adaptive system;finite difference;simulation;asymptotic analysis;intelligent decision support system;computer science;artificial intelligence;theoretical computer science;adaptive system;finite element method;mathematical model;intelligent agent	AI	-19.30822724607411	-13.682779227350887	35700
b0c57818de6a6be820ba23c1af14299faed65363	an agent based approach to virtual market place simulation	commerce electronique;comercio electronico;marche virtuel;agent based;market share;e commerce;economic model;modelo economico;modele economique;internet;rationalisation;racionalizacion;electronic trade;virtual agent;rationalization	A virtual market place for the qualitative simulation of how product awareness spreads among consumers is described. Potentially this methodology could allow the investigation of hypothetical economic mechanisms underlying tradeoff among product advertisement effort, consumers' memory span and duration, and passing word among friends in determining a product market share. Preliminary experiments showing the potentialities of this approach are reported.		Filippo Neri	2001		10.1007/3-540-45411-X_27	e-commerce;market share;the internet;rationalization;computer science;economic model;rationalisation	AI	-7.036581885469671	-9.256167692591148	35722
2959ca97a6f7d27ca7a7f5638b782b7ac2ffd441	an evolutionary game-theoretic framework for cyber-threat information sharing	experimental design;ess evolutionary game theoretic framework cyber threat information sharing cyber crimes collaborative effort spanning industry federal institutions military agencies academia cybersecurity information exchange combat cyber attacks cybex framework evolutionary game theoretic strategy self enforced evolutionary stability evolutionary stable strategy;incentive model;evolutionary computation;game theory;cybex;computer network security;evolutionary game theory;evolutionary stable strategy;systems engineering;evolutionary game theoretic framework;ess;information sharing cybersecurity cybex evolutionary game theory incentive model;sociology statistics games investment information management computer security;vulnerability;evolution general;cost analysis;investment;cybersecurity information exchange;combat cyber attacks;academia;information sharing;collaborative effort;computer security;cybex framework;heuristic methods;information assurance;cyber crimes;information exchange;information management;games;cyberwarfare;computerized simulation;evolutionary game theoretic strategy;statistics;security of data evolutionary computation game theory;federal institutions;network architecture;cybersecurity;military agencies;revenue sharing;cyber threat information sharing;hacking computer security;self enforced evolutionary stability;security of data;operating systems computers;sociology;intrusion detection computers;spanning industry	The initiative to protect against future cyber crimes requires a collaborative effort from all types of agencies spanning industry, academia, federal institutions, and military agencies. Therefore, a Cybersecurity Information Exchange (CYBEX) framework is required to facilitate breach/patch related information sharing among the participants (firms) to combat cyber attacks. In this paper, we formulate a non-cooperative cybersecurity information sharing game that can guide: (i) the firms (players)1 to independently decide whether to “participate in CYBEX and share” or not; (ii) the CYBEX framework to utilize the participation cost dynamically as incentive (to attract firms toward self-enforced sharing) and as a charge (to increase revenue). We analyze the game from an evolutionary game-theoretic strategy and determine the conditions under which the players' self-enforced evolutionary stability can be achieved. We present a distributed learning heuristic to attain the evolutionary stable strategy (ESS) under various conditions. We also show how CYBEX can wisely vary its pricing for participation to increase sharing as well as its own revenue, eventually evolving toward a win-win situation.		Deepak K. Tosh;Shamik Sengupta;Charles A. Kamhoua;Kevin A. Kwiat;Andrew P. Martin	2015	2015 IEEE International Conference on Communications (ICC)	10.1109/ICC.2015.7249499	games;game theory;evolutionary game theory;simulation;network architecture;information exchange;vulnerability;investment;computer science;knowledge management;information management;cyberwarfare;computer security;evolutionary computation	Robotics	-8.687957377493744	-5.825158320454294	35729
afbd0cf3128752006448c89d7830ba8729708a33	evolution of mindsight and psychological commitment among strategically interacting agents		We study the evolution of strategic psychological capabilities in a population of interacting agents. Specifically, we consider agents which are either blind or with mindsight, and either transparent or opaque. An agent with mindsight can observe the psychological makeup of a transparent agent, i.e., its logic, emotions, commitments and other elements that determine how it chooses actions. A blind agent cannot observe and opaque agents cannot be observed. Our assumption that mindsight and transparency are costly and optional exposes a middle ground between standard game theory without mindsight and evolution of preferences theory with obligatory and costless mindsight. We show that the only evolutionarily stable monomorphic population is one in which all agents are blind, opaque, and act-rational. We find that mindsight, transparency, and rule-rational commitments may evolve, albeit only in a portion of the population that fluctuates in size over generations. We reexamine the Ultimatum and Trust games in light of our findings and demonstrate that an evolved population of agents can differ significantly from a population of simplistic payoff-maximizers in terms of psychological traits and economic outcomes.	evolution;game theory;interaction	Dimitry Rtischev	2016	Games	10.3390/g7030027	ultimatum game;dictator game;economics;microeconomics;welfare economics	AI	-14.667069457648424	-13.685811022585076	35740
1777b54062efbeb17dc1f5de5d64b4ed816ca174	a qualitative approach to markovian equilibrium in infinite horizon economies with capital	lattice programming;monotone function;unique continuation;markov equilibrium;dynamic program;equilibrium comparative statics;fiat money;markovian equilibrium;fixed point;stochastic growth;order theoretic fixed point theory;lipschitz continuity;fixed point theory;decision process;infinite horizon;public policy;numerical approximation;monopolistic competition;iteration method;complete lattice;large classes	Using lattice programming and order theoretic fixpoint theory, we develop a new class of monotone iterative methods that provide a qualitative theory of Markovian equilibrium decision processes for a large class of infinite horizon economies with capital. The class of economies includes models with public policy, valued fiat money, monopolistic competition, production externalities, and various other nonconvexities in the production sets. The results can be adapted to construct symmetric Markov equilibrium in models with many agents and market incompleteness. As the methods are constructive, they provide the foundations for a rigorous analysis of numerical approximation schemes that study extremal Markovian equilibrium. Equilibrium comparative statics results relative to the space of economies are available. Of independent interest, we provide new conditions for preserving complementarity under maximization, and new generalized envelope theorems for nonconcave dynamic programming problems. Our fixed point algorithms are sharp, and are able to distinguish sufficient conditions under which Markovian equilibrium form a complete lattice of Lipschitz continuous, uniformly continuous and semicontinuous monotone functions as well as unique continuously differentiable equilibrium.		Leonard J. Mirman;Olivier F. Morand;Kevin L. Reffett	2008	J. Economic Theory	10.1016/j.jet.2007.05.009	public policy;mathematical optimization;complete lattice;monotonic function;monopolistic competition;mathematics;fixed point;iterative method;microeconomics;lipschitz continuity;fixed-point theorem;mathematical economics;welfare economics	ECom	-5.669821021107846	-0.8673672469274021	35774
24d564c47d14432b303d01361f358040e91c8a8e	can extremism guarantee pluralism?	segregation;extremists;opinion dynamics;social network	Many models have been proposed to explain the opinion formation in a group of individuals; most of these models study the opinion propagation as the interaction between nodes/agents in a social network. Opinion formation is a very complex process and a realistic model should also take into account the important feedbacks that the opinions of the agents have on the structure of the social networks and on the characteristics of the opinion dynamics. In this paper we will show that associating to different agents different kind of interconnections and different interacting behaviour can lead to interesting scenarios, like the co-existence of several opinion clusters, namely pluralism. In our model agents have opinions uniformly and continuously distributed between two extremes. The social network is formed through a social aggregation mechanism including the segregation process of the extremists that results in many real communities. We show how this process affects opinion dynamics in the whole society. In the opinion evolution we consider the different predisposition of single individuals to interact and to to modify each other's opinions; we associate to each individual a different tolerance threshold, depending on its own opinion: extremists are less willing to interact with individuals with strongly different opinions and to change significantly their ideas. A general result is obtained: when there is no interaction restriction, the opinion always converges to uniformity, but the same is happening whenever a strong segregation process of the extremists occurs. Only when extremists are forming clusters but these clusters keep interacting with the rest of the society, the survival of a wide opinion range is guaranteed.	circuit complexity;feedback;interaction;pluralism (philosophy);predispositioning theory;social network;software propagation	Floriana Gargiulo;Alberto Mazzoni	2008	J. Artificial Societies and Social Simulation			Web+IR	-14.74189778381173	-15.646646743103894	35776
d773b9142ef624964d310c4cd4273042435ccc98	fuzzy ensembles for embedding adaptive behaviours in semi-autonomous avatars in 3d virtual worlds	pattern clustering;virtual environments semi autonomous avatar fuzzy inference system fuzzy ensembles;fuzzy neural nets;human computer interaction;fuzzy reasoning;pattern clustering avatars fuzzy neural nets fuzzy reasoning human computer interaction learning by example pattern classification;adaptive behaviour embedding fuzzy system ensemble neuro fuzzy classifier clustering algorithms user action user movement data natural grouping identification user input data clustering fuzzy inference systems learning by imitation human controlled counterparts avatar interaction user controlled input behaviour learning 3d virtual worlds semiautonomous avatar;learning by example;avatars fuzzy logic training testing three dimensional displays fuzzy systems clustering algorithms;pattern classification;avatars	Semi-autonomous avatars should be both realistic and believable. The goal is to learn from and reproduce the behaviours of the user-controlled input to enable semi-autonomous avatars to plausibly interact with their human-controlled counterparts. A powerful tool for embedding autonomous behaviour is learning by imitation. Hence, in this paper an ensemble of fuzzy inference systems cluster the user input data to identify natural groupings within the data to describe the users movement and actions in a more abstract way. Multiple clustering algorithms are investigated along with a neuro-fuzzy classifier; and an ensemble of fuzzy systems are evaluated.	algorithm;autonomous robot;autonomy;avatar (computing);cluster analysis;fuzzy cognitive map;fuzzy control system;fuzzy logic;neuro-fuzzy;semi-supervised learning;semiconductor industry;virtual world	Julie A. Wall;Ebroul Izquierdo;Qianni Zhang	2013	2013 18th International Conference on Digital Signal Processing (DSP)	10.1109/ICDSP.2013.6622818	computer vision;adaptive neuro fuzzy inference system;computer science;artificial intelligence;neuro-fuzzy;machine learning	Robotics	-27.529502802654815	-23.926957128123036	35781
53b22a5418fee4a1f7f73f311bc0d79554becaf4	a symbolic model of human attentional networks	symbolic computation;connectionist models;computer model;rule based;executive control;cognitive architecture;attention network test	An increasing body of evidence has shown that attention is a multi-type and multilevel cognitive faculty. The dominant computational modeling approaches to attention have often focused on one specific type of attention at one specific level. In particular, various connectionist modeling techniques at the subsymbolic level have been widely adopted. In this paper, we report a symbolic computational model of the Attentional Network Test, which simultaneously involves different types of attention (alerting, orienting, and executive control), each subserved by distinctive attentional networks in the brain. The model was developed in ACT-R, a rule-based cognitive architecture. The results show that the model, by sequentially firing rules at a rate of about one every 40 ms, was able to capture the effect of each attentional network. The model implies that while the attentional networks can be distinguished at both neuroanatomical and behavioral levels, different attentional networks may adopt similar computational operations at least at a symbolic rule level. ! 2004 Elsevier B.V. All rights reserved.	act-r;artificial intelligence;cognitive architecture;computation;computational model;connectionism;logic programming	Hongbin Wang;Jin Fan;Todd R. Johnson	2004	Cognitive Systems Research	10.1016/j.cogsys.2004.01.001	psychology;cognitive psychology;symbolic computation;developmental psychology;cognitive architecture;computer science;artificial intelligence;machine learning;social psychology	AI	-24.303048863210332	-15.963854173039099	35790
eae29a28c9dda29961c73cc568bb8991abfaeed6	a new generation of international databases: a multi-agent inspired approach to integrate different theory-driven databases on conflict warning	gestion informacion;multiagent system;systeme intelligent;complexity theory;sistema inteligente;systeme adaptatif;information management;adaptive system;intelligent system;evolutionary strategy;sistema adaptativo;information system;gestion information;sistema multiagente;systeme information;problem solving;systeme multiagent;neural network;sistema informacion	In many quantitative studies, international conflicts have proven difficult to explain and predict. This problem seems to have at least two related sources: 1) the attempts by political scientists to reduce the complexity of international behaviour to parsimonious models of problem-solving; and 2) the consequent lack of complementarity among international conflict databases that have been generated following these different domain definition models. Rarely are two models and their quantitative data sufficiently similar to permit either a direct comparison or an integration of their results. By combining a Neural Network approach with complexity theory, this paper puts forwards a theoretical solution for integrating different theory-driven datasets on international conflicts. An Evolutionary Adaptive Multi-Agent Intelligent System endorsing evolutionary strategies is suggested as a means to solve the prodigious difficulties in making use of theoretically different quantitative data. Furthermore, the multi-agent approach can provide a suitable platform to support more complex and cross-paradigmatic solutions for the study of international conflicts.	database	Monica Lagazio;Evan Govender	2000		10.1007/10720076_53	computer science;artificial intelligence;adaptive system;machine learning;evolution strategy;information management;operations research;information system;artificial neural network;algorithm	DB	-24.600389916019445	-8.909638846476678	35793
ebb46ff6095366ac8abd2568ecc1485d4819cbf5	a new topsis-based multi-criteria approach to personnel selection	fuzzy topsis;veto threshold;multi criteria decision making;top management team;decision maker;decision making process;human resource;analytical method;key success factor;personnel selection	Selection of qualified human resources is a key success factor for an organization. The complexity and importance of the problem call for analytical methods rather than intuitive decisions. The aim of this paper is to support adequately the decision making process. The steps of fuzzy Technique for Order Preference by Similarity to an Ideal Solution (TOPSIS) are considered, incorporating a new concept for the ranking of the alternatives. This is based on the veto threshold, a critical characteristic of the main outranking methods. The ultimate decision criterion is not the similarity to the ideal solution but the distance of the alternatives from the veto set by the decision makers. Additionally, a real life application on the selection of a top management team member shows the practical implications.	personnel selection	Alecos Michail Kelemenis;Dimitris Askounis	2010	Expert Syst. Appl.	10.1016/j.eswa.2009.12.013	decision-making;decision analysis;decision engineering;human resources;data mining;management science;weighted sum model;business decision mapping	NLP	-5.321505400167408	-17.866715096788145	35797
278c859030a29dbafc996afc5fa2e7be4d493280	adaptive query processing: a survey	metodo adaptativo;base donnee repartie;distributed database;query processing;interrogation base donnee;base repartida dato;interrogacion base datos;methode adaptative;traitement question;adaptive query processing;adaptive method;database query	In wide-area database systems, which may be running on unpredictable and volatile environments (such as computational grids), it is difficult to produce efficient database query plans based on information available solely at compile time. A solution to this problem is to exploit information that becomes available at query runtime and adapt the query plan to changing conditions during execution. This paper presents a survey on adaptive query processing techniques, examining the opportunities they offer to modify a plan dynamically and classifying them into categories according to the problem they focus on, their objectives, the nature of feedback they collect from the environment, the frequency at which they can adapt, their implementation environment and which component is responsible for taking the adaptation decisions.	adaptive system;compile time;compiler;database;decision quality;display resolution;feedback;information management;on the fly;query plan;run time (program lifecycle phase);volatile memory	Anastasios Gounaris;Norman W. Paton;Alvaro A. A. Fernandes;Rizos Sakellariou	2002		10.1007/3-540-45495-0_2	online aggregation;sargable;query optimization;query expansion;web query classification;computer science;query by example;data mining;database;distributed computing;rdf query language;web search query;view;world wide web;distributed database;query language	DB	-25.96244842712564	3.559551145411773	35801
3c4cb0fa5b01cd05a489fe0fff6ff3d9c2b1d337	medical diagnosis by possibilistic classification reasoning	decision support systems;decision support system;uncertainty;case based reasoning;medical diagnosis;knowledge base;possibility theory;cognition;pragmatics;knowledge based systems;knowledge representation	In medicine, diagnostic reasoning refers to the approaches used by physicians with the aim of achieving a medical diagnosis concerning a given patient. This paper presents a new approach of medical decision support systems. The proposed approach is based on the use of possibility theory as a global framework, including knowledge representation (as a possibilistic pair of measures: Necessity, Possibility); and, building a possibilistic medical knowledge base (to be exploited in order to make a diagnostic decision (classification of new medical cases)). The efficiency validation of the proposed approach is conducted using an Endoscopic Knowledge and Case Base systems. Obtained results confirm that the proposed approach constitutes an efficient tool in terms of medical knowledge representation and possibilistic diagnostic reasoning.	automated reasoning;case-based reasoning;clinical decision support system;knowledge base;knowledge representation and reasoning;possibility theory;reasoning system	Mohammad Homam Alsun;Laurent Lecornu;Bassel Solaiman;Clara Le Guillou;Jean-Michel Cauvin	2010	2010 13th International Conference on Information Fusion		knowledge management;model-based reasoning;machine learning;data mining;mathematics	AI	-29.439110208818185	-8.131677102108625	35899
6bd42fb9b6a36e25fda3d73410044982bdb44fbd	a new approach to detecting active rule confluence with exclusive rules during an indeterminable rule process		Active rules have been employed for enhance self-reaction functionality, but how to detect their confluence property during an indeterminable rule process is intractable. If two rules without priority have been triggered at the same time, then anyone can be firstly chosen to execute at random and two different executive sequences will be arisen. An active rule set is confluence if and only if the same final database state appears no matter which executive sequence has been chosen to execute. The existing methods based on Rule Commutativity are no more effective to detect the confluence case if a rule set has exclusive rules and has no user-defined priority as they do not designed for rules without priority and they do not consider whether two different executive sequences for rules can be satisfied by the same database state. To address these problems, this work proposes the concepts of Exclusive Rule and Confluence Requirement with exclusive rules based on the conditional formula of an executive sequence. Then, a new algorithm for confluence detection is provided. The examples and theoretical analysis clearly show that the proposed method achieves much better detection performance when exclusive rules appear.	algorithm;confluence;event condition action;exclusive or;os-tan;production (computer science);sensor	Zhongmin Xiong;Jiguang Zhu;Hongchun Yuan;Shijun He;Huiwen Wei	2016	Journal of Intelligent and Fuzzy Systems	10.3233/JIFS-152202	artificial intelligence;data mining;mathematics;algorithm	ML	-11.384837776580358	-4.2038822316183015	35930
a1a8bdec3a988ce715af89835bbe546d67ee3532	lifted probabilistic inference		Many AI problems arising in a wide variety of fields such as machine learning, semantic web, network communication, computer vision, and robotics can elegantly be encoded and solved using probabilistic graphical models. Often, however, we are facing inference problems with symmetries and redundancies only implicitly captured in the graph structure and, hence, not exploitable by efficient inference approaches. A prominent example are probabilistic logical models that tackle a long standing goal of AI, namely unifying first-order logic — capturing regularities and symmetries — and probability — capturing uncertainty. Although they often encode large, complex models using few rules only and, hence, symmetries and redundancies abound, inference in them was originally still at the propositional representation level and did not exploit symmetries. This paper is intended to give a (not necessarily complete) overview and invitation to the emerging field of lifted probabilistic inference, inference techniques that exploit these symmetries in graphical models in order to speed up inference, ultimately orders of magnitude.	computer vision;encode;first-order logic;first-order predicate;graphical model;machine learning;mental representation;robotics;semantic web	Kristian Kersting	2012		10.3233/978-1-61499-098-7-33	computer science;artificial intelligence;theoretical computer science;machine learning;probabilistic logic network;algorithm	AI	-19.921297598873426	3.6039189359792614	36007
366a10cb22c654ab8c51838155e9e65d636dfc2c	simulating tax evasion with utilitarian agents and social feedback	tax evasion;agent based simulation;agent based computational economics;tax modeling	"""This article discusses the TAXSIM model for the simulation of tax evading behavior in a computational model of a single market sector. The rate of tax evasion is an agreement between an employer and an employee that is made to reduce costs. The agents’ expectations and satisfaction are results of the agents’ individual learning, based on their own experiences and on those in their social network. This way the emerging social approach to tax evasion feeds back to individual behavior. The series of experiments reported in this chapter analyze scenarios in which 1) the quality of governmental services increases permanently, 2) a market leader unilaterally adopts the legal position, and 3) multi-national companies with tax allowances enter the market. In addition, we show that in this model, the level and efficiency of tax audits alone cannot control and explain the emerging tax compliance level. DOI: 10.4018/jats.2010120102 International Journal of Agent Technologies and Systems, 2(1), 16-30, January-March 2010 17 Copyright © 2010, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited. the agents. Yet, on the other hand, we do not think that simple regularities would suffice as social norms. Instead, the basic requirement that we pose for a model including social norms is the presence of a circular feedback from the society level pattern to the individual actors. We studied emergence of regularities using the TAXSIM model: a complex agent-based simulation of tax evading behavior with social feedback. Modeling tax paying behavior has a long history, including classical mathematical models, but because of the complexity involved, most of these works fail to approximate or predict tax compliance with an acceptable accuracy. These models (e.g. Allingham & Sandmo, 1972; Becker, 1968) are operating with one or several utility functions: depending on the point of view, the individual taxpayer (or the government) tries to maximize its utility. The weakness of these approaches is the utility function itself: not only that it determines only one unalterable strategy to all, but makes impossible to simulate society otherwise than a bunch of separated individuals. Agent-based modeling (ABM) seems to be a suitable solution to handle a whole society of taxpayers. Early ABM attempts in tax evasion modeling are extending the world of utility functions by deploying inhomogeneous tax payer agents—each using one of the few predefined utility functions to optimize personal and maybe community benefits (Mittone & Patelli, 2000; Davis et al., 2003). In later agent-based models coefficients of the classic utility function come to life by being extended to agents which affect the system by interacting with others (Balsa et al., 2006). Besides, various expansions were made including the social network of taxpayers (Bloomquist, 2006). Although models evolved in the past few years, application of agent-based models as an expert system is still a few steps away. To advance in this direction we made a generative approach of tax evasion trying to identify the main motivations of compliance and evasion. In previous works authors mostly delivered simple answers of the kind: ‘when audit frequency reaches a certain level, total compliance is observed’. The TAXSIM simulator is able to deal with more complex situations. Among others, it is possible to ask questions, like how much extra effort is needed by authorities to compensate taxpayer discontentment; whether increasing the frequency or the thoroughness of audits is the way to go; or how much impact aggregate level market forces have on tax evasion. This article is an extension of the work reported in (Szabó et al., 2008) and has two main goals. The first goal is to introduce the TAXSIM simulator focusing on its novel properties, including its utilitarian approach and the presence of feedback via social influence. The second goal is to give an overview of the rich set of behaviors TAXSIM is able to produce, analyze these using alternative scenarios and to compare the findings to related work. ThE TAx EVASIoN ModEL The TAXSIM model is concerned with the operations of a single market sector, where there are four kinds of agents involved: employee, employer, (tax) authority and government. The economic well-being of employees depend on their net wages, while that of the employers’ is a function of the market demand and the level of gross wages they are forced to pay. The rate of tax evasion is an agreement between an employer and an employee that is made when the employee occupies a new job. As the agreed employment type determines the income of the employee and the (producing) costs of the employer, both participating agents have a motivation to evade. The government and the tax authority have service providing and regulatory roles, respectively. Since the market demand is modeled as an exogenous component and employers and employees are assumed to be homogeneous in technological and productive ability, competitiveness is determined by the agents’ approach to taxes. In this model tax evasion is a technique to reduce costs (and to raise wages). Therefore a more refined measure of level of the evasion fits better our purposes than the classical binary 13 more pages are available in the full version of this document, which may be purchased using the """"Add to Cart"""" button on the product's webpage: www.igi-global.com/article/simulating-tax-evasion-utilitarianagents/39030?camid=4v1 This title is available in InfoSci-Journals, InfoSci-Journal Disciplines Computer Science, Security, and Information Technology. Recommend this product to your librarian: www.igi-global.com/e-resources/libraryrecommendation/?id=2"""	agent-based model;aggregate data;approximation algorithm;coefficient;computational model;computer science;donald becker;emergence;evasion (network security);experience;experiment;expert system;fits;interaction;librarian;mathematical model;norm (social);simulation;social network;software agent;utility;way to go;web page;word lists by frequency	Attila Szabó;László Gulyás;István János Tóth	2010	IJATS	10.4018/jats.2010120102	double taxation;tax credit;tax basis;indirect tax;tax reform;international taxation	AI	-6.75365741464604	-9.665400712944145	36030
1b677856ee8bb9f484f5ebfca1170af53f95db0a	long-run equilibria with dominated strategies	nash equilibrium;best response dynamics;dominated strategies best response process long run equilibrium;nash equilibria;rational number;unique long;evolutionary process;convex combination;normal form game	We show that the predictions of long-run behavior under the evolutionary process are highly sensitive to the addition and elimination of strictly dominated strategies. In particular, for the best response dynamics [cf. Kandori, M., Rob, R., 1995. Evolution of equilibria in the long run: A general theory and applications. J. Econ. Theory 65 (2), 383-414] we prove that for any symmetric normal form game, any strict Nash equilibrium can be selected as the unique long-run equilibrium by appropriately adding only one single strategy which is strictly dominated by all original strategies. Moreover, if we further assume instantaneous adjustment, then any convex combination of strict Nash equilibria with rational number weights can be realized as the long-run distribution by appropriately adding strictly dominated strategies.		Chongmin Kim;Kam-Chau Wong	2010	Games and Economic Behavior	10.1016/j.geb.2009.07.005	price of stability;epsilon-equilibrium;mathematical optimization;best response;trembling hand perfect equilibrium;economics;non-credible threat;mathematics;correlated equilibrium;risk dominance;normal-form game;mathematical economics;welfare economics;equilibrium selection;solution concept;nash equilibrium;symmetric equilibrium	ECom	-4.996610870834794	-2.122519765724516	36103
54efadc48e03b49a3ba2ec159f8b9653c541d223	electre tri-based approach to the failure modes classification on the basis of risk parameters: an alternative to the risk priority number	electre tri;fmeca;failure modes classification	Failure Mode and Effects Analysis (FMEA) is an engineering technique aimed at the detection of potential failures, their causes and consequences on the system/process under investigation. When used for the failure modes prioritization, FMEA is also referred to as Failure Mode, Effects and Criticality Analysis (FMECA). In traditional FMECA, risk priorities of failure modes are determined through the Risk Priority Number (RPN), which is a function of the three risk parameters Occurrence (O), Severity (S), and Detection (D). In the present paper, an alternative approach to the RPN is proposed for the criticality assessment of process/system failure modes. Particularly, the Multi-Criteria Decision Making (MCDM) method ELECTRE TRI is employed to assign failure modes to predefined and ordered risk classes, from the highest to the lowest risky one. Contrarily to the traditional RPN, the method allows the Decision Maker (DM) at taking into account the relative importance of risk parameters as well as his/her uncertainty in assigning each failure mode to a specific risk class. The ELECTRE TRI-based approach is implemented on the applicative case proposed by Kurt and Ozilgen (2013) with reference to Turkish dairy manufacturing industries. A sensitivity analysis is finally performed in order to test the influence of the input parameters on the classification results.	failure mode and effects analysis	Antonella Certa;Mario Enea;Giacomo Galante;Concetta Manuela La Fata	2017	Computers & Industrial Engineering	10.1016/j.cie.2017.04.018	reliability engineering;engineering;operations management;failure mode, effects, and criticality analysis;forensic engineering	ML	-8.065567935748087	-16.69584617662985	36147
d03210bb6e7da4f0c0ef3419a1b7253ee9490fc9	knowledge model of emergency decision-making based on knowledge supply and demand	emergency response;optimal resource allocation;knowledge management;decision maker;emergency management;decision making process;knowledge modeling;supply and demand	In the process of rapid response to emergencies, to supply decision-makers the necessary knowledge is the key to improving the efficiency of decision-making. Starting from emergency decision-making process, this paper proposes emergency decision-making model based on knowledge supply and demand, and knowledge management process is designed to integrate into the emergency decision-making process to achieve an accurate auxiliary emergency decision-making. Modeling in knowledge management is very necessary to be able to clearly express the purpose of the creator. This model is to make an emergency decision-making through effective knowledge management, making full use of emergency management in all types of resources and optimizing resource allocation. And by the typhoon example illustrates the application of the model. Finally further research directions are noted. © 2010 Springer-Verlag.	knowledge representation and reasoning	Bing Wu;Lin-du Zhao	2010		10.1007/978-3-642-16397-5_28	knowledge management;environmental resource management;management science;business	AI	-32.49640438625583	-7.906274056780385	36170
60e139c2bbbc9aff1ca46494b2916592b5c1da34	an integrated fta-dfmea approach for reliability analysis and product configuration considering warranty cost		Product configuration is an important approach in customization environments. In this study, an integrated approach is developed to improve product configuration considering product reliability, warranty and purchasing cost of components as evaluation criteria. In order to meet customer requirements, the market’s feedbacks are considered and used in the fault tree analysis (FTA) to identify product failures and defective components. In addition, reliability and total cost of each generated configuration are computed. Series and parallel systems and redundancy are considered to calculate reliability. Then, an integrated FTA and design failure modes and effects analysis approach is proposed. Risk priority number is used to evaluate each configuration option from risk viewpoint. Finally, a case study of laptop computer is used to show the applicability of the proposed integrated approach. The numerical results show that the proposed approach provides several configuration options for manufacturers by considering various decision criteria.	failure mode and effects analysis;fault tree analysis;knowledge-based configuration;reliability engineering	Ali Azadeh;Mohammad Sheikhalishahi;A. Aghsami	2015	Production Engineering	10.1007/s11740-015-0642-7	reliability engineering;systems engineering;engineering;operations management;physical configuration audit	SE	-8.607219959643482	-15.015244446350046	36204
e075ad477b4e6f28814b31bb1223a11cd6c12c80	"""corrigendum to """"combinatorial auction under fuzzy environment"""" [expert systems with applications 38 (2011) 11482-11488]"""	expert system;combinatorial auction		expert system	Joshua Ignatius;Young-Jou Lai;Seyyed Mahdi Hosseini Motlagh;Mohammad Mehdi Sepehri;Adli Mustafa	2011	Expert Syst. Appl.	10.1016/j.eswa.2011.06.001	combinatorial auction;computer science;artificial intelligence;machine learning;data mining;expert system	ECom	-28.575066645950965	-8.140897967571531	36207
85147f6208c15441124934192fe2dae04f3fe31b	agent bodies: an interface between agent and environment	influence;multi agent systems;environment;interface;laws;capitulo de libro;rules;embodied agent	Interfacing the agents with their environment is a classical problem when designing multiagent systems. However, the models pertaining to this interface generally choose to either embed it in the agents, or in the environment. In this position paper, we propose to highlight the role of agent bodies as primary components of the multiagent system design. We propose a tentative definition of an agent body, and discuss its responsibilities in terms of MAS components. The agent body takes from both agent and environment: low-level agent mechanisms such as perception and influences are treated locally in the agent bodies. These mechanism participate in the cognitive process, but are not driven by symbol manipulation. Furthermore, it allows to define several bodies for one mind, either to simulate different capabilities, or to interact in the different environments physical, socialthe agent is immersed in. We also draw the main challenges to apply this concept effectively.		Julien Saunier;Carlos Carrascosa;Stéphane Galland;Patrick Simo Kanmeugne	2014		10.1007/978-3-319-23850-0_2	simulation;embodied agent;engineering;artificial intelligence;multi-agent system;communication;intelligent agent	AI	-22.194760318736442	-14.65385784590695	36320
0424496448d2c535dec4d31ba3a23a5ef61f890e	congressional samples for approximate answering of group-by queries	decision support;random sampling;database;data mining;archive;scalable;data analysis;internet;biased sampling;astronomy;query rewriting;large data	In large data warehousing environments, it is often advantageous to provide fast, approximate answers to complex decision support queries using precomputed summary statistics, such as samples. Decision support queries routinely segment the data into groups and then aggregate the information in each group (group-by queries). Depending on the data, there can be a wide disparity between the number of data items in each group. As a result, approximate answers based on uniform random samples of the data can result in poor accuracy for groups with very few data items, since such groups will be represented in the sample by very few (often zero) tuples. In this paper, we propose a general class of techniques for obtaining fast, highly-accurate answers for group-by queries. These techniques rely on precomputed non-uniform (biased) samples of the data. In particular, we propose congressional samples, a hybrid union of uniform and biased samples. Given a fixed amount of space, congressional samples seek to maximize the accuracy for all possible group-by queries on a set of columns. We present a one pass algorithm for constructing a congressional sample and use this technique to also incrementally maintain the sample up-to-date without accessing the base relation. We also evaluate query rewriting strategies for providing approximate answers from congressional samples. Finally, we conduct an extensive set of experiments on the TPC-D database, which demonstrates the efficacy of the techniques proposed.	aggregate data;approximation algorithm;aqua;binocular disparity;column (database);decision support system;experiment;ibm tivoli storage productivity center;online analytical processing;precomputation;prototype;question answering;rewriting;sampling (signal processing);usability	Swarup Acharya;Phillip B. Gibbons;Viswanath Poosala	2000		10.1145/342009.335450	sampling;scalability;the internet;decision support system;sampling bias;computer science;data mining;database;data analysis;information retrieval	DB	-27.15040964398448	2.811284181541751	36327
d3816fd68ada0d4e2637befdf6fafd3a1c64e7d8	on-demand index for efficient structural joins	gestion memoire;tiempo busqueda;storage management;xml language;interrogation base donnee;interrogacion base datos;temps recherche;similitude;gestion memoria;internet;indexing;indexation;similarity;indizacion;similitud;systeme gestion base donnee;structural join;union estructura;search time;sistema gestion base datos;database management system;database query;langage xml;lenguaje xml;jointure structurelle	An efficient indexing scheme for moving objects' trajectories on road networks p. 13 Spatial index compression for location-based services based on a MBR semi-approximation scheme p. 26 KCAM : concentrating on structural similarity for XML fragments p. 36 A new structure for accelerating XPath location steps p. 49 Efficient evaluation of multiple queries on streamed XML fragments p. 61 Automated extraction of hit numbers from search result pages p. 73 Keyword extraction using support vector machine p. 85 LSM : language sense model for information retrieval p. 97 Succinct and informative cluster descriptions for document repositories p. 109 LRD : latent relation discovery for vector space expansion and information retrieval p. 122 Web image retrieval refinement by visual contents p. 134 An effective approach for hiding sensitive knowledge in data publishing p. 146 Tracking network-constrained moving objects with group updates p. 158 Dynamic configuring service on semantic grid p. 170 Object placement and caching strategies on AN.P2P p. 182 Role-based peer-to-peer model : capture global pseudonymity for privacy protection p. 193 A reputation management scheme based on global trust model for peer-to-peer virtual communities p. 205 QoS-aware Web services composition using transactional composition operator p. 217 Optimizing the profit of on-demand multimedia service via a server-dependent queuing system p. 229 Service matchmaking based on semantics and interface dependencies p. 240 Crawling Web pages with support for client-side dynamism p. 252 RecipeCrawler : collecting recipe data from WWW incrementally p. 263 CCWrapper : adaptive predefined schema guided Web extraction p. 275 MiniTasking : improving cache performance for multiple query workloads p. 287 Cache consistency in mobile XML databases p. 300 Bulkloading updates for moving objects p. 313 Finding the plateau in an aggregated time series p. 325 Compressing spatial and temporal correlated data in wireless sensor networks based on ring topology p. 337 Discovery of temporal frequent patterns using TFP-tree p. 349 DGCL : an efficient density and grid based clustering algorithm for large spatial database p. 362 Scalable clustering using graphics processors p. 372 TreeCluster : clustering results of keyword search over databases p. 385 A new method for finding approximate repetitions in DNA sequences p. 397 Dynamic incremental data summarization for hierarchical clustering p. 410 Classifying E-mails via support vector machine p. 422	approximation algorithm;central processing unit;client-side;cluster analysis;graphics processing unit;hierarchical clustering;image retrieval;information retrieval;keyword extraction;location-based service;master boot record;optimizing compiler;peer-to-peer;pseudonymity;quality of service;refinement (computing);reputation management;ring network;search algorithm;semantic grid;semiconductor industry;server (computing);spatial database;streaming media;structural similarity;support vector machine;time series;total functional programming;virtual community;www;xml database;xpath	Kun-Lung Wu;Shyh-Kwei Chen;Philip S. Yu	2006		10.1007/11775300_1	search engine indexing;the internet;xml;similarity;computer science;similitude;data mining;database;world wide web;algorithm	DB	-29.063000565897134	0.3055187520041831	36330
adb533763514829d665125a839ebc71eac144cb1	a simulative study of the roles of cultural transmission in language evolution	communication system;multi agent systems digital simulation knowledge acquisition linguistics;conference_paper;linguistic innovations cultural transmission language evolution simulation acquisition framework multiagent computational model language emergence language maintenance;computer model;cultural differences evolutionary computation;multi agent systems;language evolution;knowledge acquisition;simulation study;self organization;cultural transmission;digital simulation;horizontal transmission;linguistics	A multi-agent computational model is proposed to simulate language evolution in an acquisition framework. This framework involves many major forms of cultural transmission, and the simulation results of the model systematically examine the role of cultural transmission in language emergence and maintenance. In addition, this study discusses the effects of conventionalization during horizontal transmission on diffusing linguistic innovations, maintaining high levels of linguistic understandability, and triggering inevitable changes in the communal languages across generations. All these reflect that conventionalization could be a self-organizing property of the human communication system that drives language evolution.	computational model;emergence;multi-agent system;organizing (structure);self-organization;simulation	Tao Gong;James W. Minett;William S.-Y. Wang	2007	2007 IEEE Congress on Evolutionary Computation	10.1109/CEC.2007.4424558	natural language processing;self-organization;cultural transmission in animals;computer science;artificial intelligence;multi-agent system;language technology;communications system	AI	-18.080553005462445	-16.859803575245145	36411
9aeaef952563cfb6e5fddf0d7267bebb90f49a67	building magical realms: responses to pervasive and locative media technology	pervasive;mobile;locative media;game design;ubicomp;magic;scenario planning;locative;participatory design;young people	Taylor & Francis makes every effort to ensure the accuracy of all the information (the “Content”) contained in the publications on our platform. However, Taylor & Francis, our agents, and our licensors make no representations or warranties whatsoever as to the accuracy, completeness, or suitability for any purpose of the Content. Any opinions and views expressed in this publication are the opinions and views of the authors, and are not the views of or endorsed by Taylor & Francis. The accuracy of the Content should not be relied upon and should be independently verified with primary sources of information. Taylor and Francis shall not be liable for any losses, actions, claims, proceedings, demands, costs, expenses, damages, and other liabilities whatsoever or howsoever caused arising directly or indirectly in connection with, in relation to or arising out of the use of the Content.	francis;pervasive informatics;primary source;realms	Stuart Nolan	2006	Digital Creativity	10.1080/14626260600882489	game design;simulation;locative case;human–computer interaction;computer science;scenario planning;mobile technology;multimedia;magic;ubiquitous computing	Robotics	-16.116015160243457	-6.013201031980539	36423
8f50266334dac93542b1e38c10ee9e2bd35ebd2d	towards a guide for engineering the collective behaviour of a mas	multi agent system;cooperation;cooperative agents;feasibility study;tuning;behaviour;collective behaviour	The objective of the work undertaken here is to endow an agent-oriented methodology with a semi-automatic tool for helping designers when drawing up the agents composing an adaptive multi-agent system (AMAS). This tool acts as a guide for enabling designers to influence the emergent global behaviour of an AMAS by acting on the local behaviour of its cooperative agents. The preliminary approach proposed in this article can be seen as a feasibility study aiming at developing a textual guide by considering the principles of the AMAS theory. Simulation of the behaviour of healthy and cancerous cells is used as a base for this study.		Noélie Bonjean;Carole Bernon;Pierre Glize	2010	Simulation Modelling Practice and Theory	10.1016/j.simpat.2010.05.001	feasibility study;simulation;computer science;engineering;artificial intelligence;management science;cooperation	SE	-20.76655527433406	-14.642803754650016	36432
9911aa7853efcbbe561b287ae58075e61e2bd591	using an interpretation system - some observations in hidden operator simulations of 'verbmobil'	experimental design;human interaction;man machine dialogue;computer human interaction;tratamiento lenguaje;intelligence artificielle;language processing;traitement langage;artificial intelligence;dialogo hombre maquina;inteligencia artificial;dialogue homme machine	The international research project VERBMOBIL aims at developing a machine interpretation system capable of interpreting dialogues. This paper focuses on hidden operator simulations, conducted during the first four years of the project. After describing the experimental design, some selected results about factors of acceptance are reported. The most important factors concern the functional elements of an interpretation system, speed on the one hand and completeness, correctness and style on the other. The style of the interpretation seems to be less important. From the perspective of users a machine interpreter should have some additional options but should not have a strong impact on the dialogue itself. Another issue refers to the behaviour of test persons in a simulated Human-Computer-Human Interaction (HCHI). This paper discusses some examples from the study and summarises changes in the human-human interaction as well as interaction between humans and computers. It focuses on obstructions in conversation and provides an indication of possible communication problems. Finally, the results from analysing the typical characteristics of a dialogue enable us to suggest outlines for improving the system.	computer simulation;verbmobil	Detlev Krause	1996		10.1007/3-540-63175-5_36	computer vision;interpersonal relationship;simulation;computer science;artificial intelligence;machine learning;design of experiments;algorithm	Robotics	-25.018348126657937	-7.901983090697972	36456
394cc29ab181d4f66fe7e463fef9c03cc8801e9d	query processing for decision support: the sqlmpp solution	complete relations;data parallel;file servers;decision support;query processing decision support systems relational databases hardware throughput transaction databases spatial databases volcanoes pipeline processing algorithm design and analysis;query processing;sql;data parallelism;large data sets;aggregation;sqlmpp;nesting;parallel databases;query processing decision support systems file servers sql parallel processing indexing;decision support system;transaction databases;parallel database server;indexing;spatial databases;decision support systems;maximal index usage;multi way joins;relational databases;algorithm design and analysis;parallel processing;pipeline processing;volcanoes;throughput;minimal processing query processing decision support systems sqlmpp large data sets multi way joins aggregation nesting parallel database server data parallelism maximal index usage complete relations;hardware;minimal processing	Decision support systems are characterized by large data sets and complex queries with multi-way joins, aggregation and nesting. SQLmpp is a highly parallel database server designed to efficiently support these applications. SQLmpp's query processing strategy is driven by three principal goals: (1) data parallelism in all operations, (2) maximal use of any relevant indexes, and (3) minimal processing of complete relations. This paper describes the general query processing techniques and the specific operations used to achieve these goals. >		Latha S. Colby;Nancy L. Martin;Robert M. Wehrmeister	1994		10.1109/PDIS.1994.331724	online aggregation;query optimization;query expansion;computer science;theoretical computer science;data mining;database;query language	DB	-28.84127560467044	2.5146907243055074	36467
d5340c97d9bfa5b68736fe8d8f1b8a1ec246b8dc	a software system for collaborative robotics applications and its application in particle swarm optimization implementations	layered architecture;swarm intelligence;multiagent system;software system;software systems;particle swarm optimizer;particle swarm optimization;collaborative robotics;security policy	This paper presents a particle swarm optimization (PSO)-inspired multi-robot search application based on an innovative software system for collaborative robotic applications. The system has a multi-layer architecture which provides lowand high-level interfaces to the robots, resource (robots) management, security policies and concurrent robot access. The main result is the successful testing of the PSO-inspired algorithm on real-world experiments, using Khepera III and e-puck robots. Simulated results obtained	algorithm;e-puck mobile robot;experiment;high- and low-level;khepera mobile robot;layer (electronics);mathematical optimization;particle swarm optimization;phase-shift oscillator;software system	Cristian Ioan Vasile;Catalin Buiu	2011	Appl. Soft Comput.	10.1016/j.asoc.2011.05.009	swarm robotics;multi-swarm optimization;simulation;ant robotics;swarm intelligence;computer science;artificial intelligence;theoretical computer science;metaheuristic;software system	Robotics	-18.71725846319244	-10.758352796518167	36472
ab9ce6287056bd6cab8666ae1ed27737bd712f07	towards an ontology-based framework to generate diagnostic decision support systems		The task of a Diagnostic Decision Support System (DDSS) is to deduce the health status of a physical system. We propose a framework to generate DDSS software based on formal descriptions of the application domain and the diagnostic rules. The key idea is to describe systems and related data with a domain ontology, and to describe diagnostic computations with an actor-based model. Implementation-specific code is automatically generated from such descriptions, while the structure of the DDSS is invariant across applications. Considering an artificial scalable domain related to the diagnosis of air conditioning systems, we present a preliminary experimental comparison between a hand-made DDSS, and one generated with a prototype of our framework.	decision support system	Giuseppe Cicala;Marco Oreggia;Armando Tacchella	2013		10.1007/978-3-319-03524-6_3	simulation;computer science;theoretical computer science;data mining	AI	-30.162535202399507	-6.345179863550385	36481
b737a6f09b81309ef4fd69a71f77b2ecd8a34712	control and integration of diverse knowledge in a diagnostic expert system	expert system	Though current expert system technology has become a major success, e x i s t i n g expert systems o f ten f a l l short of human exper t ise In many ways. One Important area is in the use of more bas ic , deep knowledge as an enhancement to the shal low, surface knowledge commonly employed. The In tegra t ed Diagnost ic Model attempts to e x p l o i t the use of both types of knowledge by f i t t i n g the appropr iate knowledge representa t ion and u t i l i z a t i o n techniques to each. The r e s u l t is two separate and Independent expert systems which are then integrated and c o n t r o l l e d by a h i g h e r l e v e l module ca l l ed the execu to r .	compilers: principles, techniques, and tools;expert system;tegra;xilinx ise	Pamela K. Fink	1985			legal expert system;knowledge base;computer science;knowledge management;artificial intelligence;model-based reasoning;knowledge-based systems;data mining;management science;subject-matter expert;expert system	AI	-31.231530174075438	-6.57460219391695	36519
d87b2e68cda4f2a38746d3e3c1c8f2045dda7caf	from reactive to deliberative multi-agent planning		Various researches approached hybrid automata to formally model and coordinate reactive multi-agent systems’ plans situated in a dynamic environment, where the time is critical. However in most of cases, reactivity in dynamic environments is not satisfactory. It is favorable that agents plan their behaviors according to some preference function. Most of current verification tools of hybrid automata are inadequate to model such agents’ plans. Therefore, this paper extends hybrid automata’s decisions making by means of utility functions on transitions. A scenario taken from supply chain management is demonstrated to show the paper’s approach. Analysis of agents’ plans are investigated using a constraint logic program implementation prototype.	automata theory;hybrid automaton;logic programming;multi-agent system;prototype;risk management;situated	Ammar Mohammed;Ulrich Furbach	2009			optoelectronics;argon;plasma;helium;electrode;pinch;vacuum chamber;buffer gas;materials science;lithium	AI	-17.98289126260445	-8.547438494592674	36651
152d30c3ec988c78d3361bd0d6fefdad33cb5703	intelligent agents review	intelligent agent	Software intelligent agents, or simply agents, are one of the most important research areas in computer science and information technology. Plenty of work has been done on different aspects of agents development. This paper presents a survey of research activities in the development of intelligent agents. The survey categorizes the agent related work into three main theoretical based areas: (1) Interaction protocols, (2) Design and architecture, (3) Agent applications. The purpose of this categorization is to understand the main research driven directions in this promising field, and help in choosing a particular direction for more in depth studies.	categorization;computer science;depth perception;intelligent agent;interaction protocol	Khalid Mansour;Ezz Hattab;Emad Abuelrub	2004			intelligent agent;autonomous agent;database;computer science;agent architecture	AI	-32.46496707686004	-17.95271013716283	36656
d4dc64cc6d6f289b0df22f5e15cdedcd85f09cd8	server ranking for distributed text retrieval systems on the internet	text retrieval	Keyword-based search services have become necessary tools for nding information resources on the Internet today. The rapid growth of information on the Internet renders centralized keyword index services incapable of collecting comprehensive resource meta-data in a timely manner. We argue that delegating the task of meta-data collection to local index servers is a more scalable approach. We propose a mechanism for integrating distributed autonomous index servers into a cooperative resource discovery system. Focusing on the retrieval eeec-tiveness of the system, we propose a set of methods , called CVV-based methods, for ranking and selecting index servers with respect to a query, and merging the results returned by the index servers. Through experiments, we evaluate the eeectiveness of the CVV-based methods, and compare our server ranking method with methods proposed by other researchers .	autonomous robot;boolean algebra;card security code;centralized computing;computation;discovery system;document retrieval;experiment;internet;interoperability;rendering (computer graphics);scalability;server (computing);standard boolean model	Budi Yuwono;Dik Lun Lee	1997		10.1142/9789812819536_0005	document retrieval;full text search;computer science;concept search;database;adversarial information retrieval;world wide web;information retrieval;human–computer information retrieval	Web+IR	-29.970768489404385	-0.5449381058868594	36685
559fdbf9d36cc362389e6e381c69dfd96b05baf1	object-oriented database benchmarks	object oriented database	We present in this chapter an overview of the benchmarks aimed at evaluating the performances of Object-Oriented Databases (OODBs). We particularly focus on OCB (the Object Clustering Benchmark), which is both generic and originally designed to specifically evaluate the performances of clustering policies within OODBs. OCB is generic because its sample database may be customized to fit any of the databases introduced by the main previous benchmarks, e.g., OO1 (Object Operation 1) or OO7. The first version of OCB was purposely clustering-oriented due to a clustering-oriented workload, but OCB has been thoroughly extended to be able to suit other purposes. Eventually, OCB’s code is compact and easily portable. OCB has been validated through two implementations: one within the O2 OODB and another one within the Texas persistent object store. The performances of two different clustering policies implemented in Texas, DSTC (Dynamic, Statistical, Tunable Clustering) and DRO (Detection & Reclustering of Objects), have also been compared with OCB.		Jérôme Darmont;Michel Schneider	2002		10.4018/978-1-930708-41-9.ch003	database theory;database server;database tuning;database model;data mining;database;database catalog;view;database schema;database design;component-oriented database	DB	-30.101736140012534	3.2303543651337274	36716
e6f9a359fc716c6914b683c87aab3175d5e52721	from distributed vision networks to human behavior interpretation	smart home;human behavior	Analysing human behavior is a key step in smart home applications. Many reasoning approaches utilize information of location and posture of the occupant in qualitative assessment of the user’s status and events. In this paper, we propose a vision-based framework to provide quantitative information of the user’s posture which can be used to deduct qualitative representations for high-level reasoning. Furthermore, our approach is motivated by potentials introduced by interactions between the vision module and the high-level reasoning module. While quantitative knowledge from the vision network can either complement or provide specific qualitative distinctions for AI-based problems, these qualitative representations can offer clues to direct the vision network to adjust its processing operation according to the interpretation state. The paper outlines potentials for such interactions and describes two visionbased fusion mechanisms. The first employs an opportunistic approach to recover the full-parameterized human model by the vision network, while the second employs directed deductions from vision to address a particular smart home application in fall detection.	active vision;algorithm;artificial intelligence;feedback;high- and low-level;home automation;human-based computation;interaction;poor posture	Hamid K. Aghajan;Chen Wu	2007			home automation;artificial intelligence;computer vision;mechanical engineering;computer science	AI	-27.07619730096968	-19.876210830674918	36732
dfcc0c01a7b0b47483acbf16bba60d623f3e4bab	evaluating the open source data containers for handling big geospatial raster data		Big geospatial raster data pose a grand challenge to data management technologies for effective big data query and processing. To address these challenges, various big data container solutions have been developed or enhanced to facilitate data storage, retrieval, and analysis. Data containers were also developed or enhanced to handle geospatial data. For example, Rasdaman was developed to handle raster data and GeoSpark/SpatialHadoop were enhanced from Spark/Hadoop to handle vector data. However, there are few studies to systematically compare and evaluate the features and performances of these popular data containers. This paper provides a comprehensive evaluation of six popular data containers (i.e., Rasdaman, SciDB, Spark, ClimateSpark, Hive, and MongoDB) for handling multi-dimensional, array-based geospatial raster datasets. Their architectures, technologies, capabilities, and performance are compared and evaluated from two perspectives: (a) system design and architecture (distributed architecture, logical data model, physical data model, and data operations); and (b) practical use experience and performance (data preprocessing, data uploading, query speed, and resource consumption). Four major conclusions are offered: (1) no data containers, except ClimateSpark, have good support for the HDF data format used in this paper, requiring timeand resource-consuming data preprocessing to load data; (2) SciDB, Rasdaman, and MongoDB handle small/mediate volumes of data query well, whereas Spark and ClimateSpark can handle large volumes of data with stable resource consumption; (3) SciDB and Rasdaman provide mature array-based data operation and analytical functions, while the others lack these functions for users; and (4) SciDB, Spark, and Hive have better support of user defined functions (UDFs) to extend the system capability.	apache cassandra;apache hadoop;apache hive;baseline (configuration management);batch processing;big data;bottleneck (software);computer data storage;data cube;data pre-processing;distributed computing;emoticon;experiment;geographic information system;grand challenges;html5 in mobile devices;hierarchical data format;logical data model;mathematical optimization;mongodb;operational system;performance;physical data model;preprocessor;raster data;raster graphics;real-time clock;requirement;spark;scidb;self-balancing binary search tree;source data;systems design;upload;virtual community;rasdaman	Fei Hu;Mengchao Xu;Jingchao Yang;Yanshou Liang;Kejin Cui;Michael M. Little;Christopher Lynnes;Daniel Q. Duffy;Chaowei Phil Yang	2018	ISPRS Int. J. Geo-Information	10.3390/ijgi7040144	physical data model;database;logical data model;geospatial analysis;rasdaman;source data;architecture;big data;data pre-processing;computer science	DB	-33.27123701951849	-0.07341022094501416	36797
e4407e34586eb957828f5dd7cd464ec660e418f9	the emergence engine: a behavior based agent development environment for artists	artificial intelligent;action selection;development environment;autonomous agent;scripting language;virtual worlds	Many artists are intrigued by the creative possibilities presented to them by virtual worlds populated with autonomous agents. Artists wishing to explore these possibilities face many obstacles including the need to learn artificial intelligence programming techniques. The Emergence Engine allows artists with no programming experience to create complex virtual worlds. Using behavior based action selection, the Emergence Engine allows artists to populate their worlds with autonomous situated agents. Artists can then direct the agents’ behaviors using Emergence’s high level scripting language. Artists have used the Emergence Engine successfully since 1998 to create numerous art installations exhibited both in the US and abroad.	action selection;artificial intelligence;autonomous robot;emergence;high-level programming language;population;scripting language;situated;virtual world	Eitan Mendelowitz	2000			simulation;action selection;computer science;artificial intelligence;autonomous agent;scripting language;development environment;multimedia	AI	-25.406720299583895	-21.5325593351242	36811
166e3b3cf1724fc94664a89000d8a5a7f57cb806	agent support for policy-driven mission planning under constraints	policies;support planning;software agents;constraints	Forming ad-hoc coalitions between military forces and humanitarian organizations is crucial in mission-critical scenarios. Very often coalition parties need to operate according to planning constraints and regulations, or policies. Therefore, they find themselves not only in need to consider their own goals, but also to support coalition partners to the extent allowed by such regulations. In time-stressed conditions, this is a challenging and cognition-intensive task. In this paper, we present intelligent agents that support human planners and ease their cognitive burden by detecting and giving advice about the violation of policies and constraints. Through a series of experiments conducted with human subjects, we compare and contrast the agents’ performance on a number of metrics in three conditions: agent support, transparent policy enforcement, and neither support nor enforcement.	cognition;cyber-security regulation;experiment;hoc (programming language);intelligent agent;mission critical;sensor	Murat Sensoy;Daniele Masato;Timothy J. Norman;Martin J. Kollingbaum;Chris Burnett;Katia P. Sycara;Jean Oh	2010			simulation;computer science;artificial intelligence;software agent;management science	AI	-19.919503832585786	-9.431510491247275	36817
47b6ee0812a55e14c71cee2a58070e9a6a95e79a	analysing the low quality of the data in lighting control systems	new technology;energy efficient;ambient intelligence;control system;energy consumption;energy loss;genetic fuzzy system	Energy efficiency represents one of the main challenges in the engineering field, i.e., by means of decreasing the energy consumption due to a better design minimising the energy losses. This is particularly true in real world processes in the industry or in business, where the elements involved generate data full of noise and biases. In other fields as lighting control systems, the emergence of new technologies, as the Ambient Intelligence can be, degrades the quality data introducing linguistic values. The presence of low quality data in Lighting Control Systems is introduced through an experimentation step, in order to realise the improvement in energy efficiency that its of managing could afford. In this contribution we propose, as a future work, the use of the novel genetic fuzzy system approach to obtain classifiers and models able to deal with the above mentioned problems.	ambient intelligence;emergence;fuzzy control system;genetic fuzzy systems;lighting control system	José Ramón Villar;Enrique A. de la Cal;Javier Sedano;Marco Antonio García Tamargo	2010		10.1007/978-3-642-13769-3_51	simulation;ambient intelligence;computer science;control system;efficient energy use	AI	-15.964493381647697	-1.7744574934824993	36953
2ababd89c81d992e431b457a9042412a9c2e067c	massively parallel artificial intelligence	artificial intelligent;intelligent system;parallel machines;large data;affective computing;knowledge base	Massively Parallel Artificial Intelligence is a new and growing area of AI research, enabled by the emergence of massively parallel machines. It is a new paradigm in AI research. A high degree of par­ allelism not only affects computing performance, but also triggers drastic change in the approach to­ ward building intelligent systems; memory-based reasoning and parallel marker-passing are examples of new and redefined approaches. These new ap­ proaches, fostered by massively parallel machines, offer a golden opportunity for AI in challenging the vastness and irregularities of real-world data that are encountered when a system accesses and processes Very Large Data Bases and Knowledge Bases. This article describes the current status of massively par­ allel artificial intelligence research and positions of each panelist.	artificial intelligence;database;definition;emergence;programming paradigm;spreading activation	Hiroaki Kitano;James A. Hendler;Tetsuya Higuchi;Dan I. Moldovan;David L. Waltz	1991			knowledge base;computer science;artificial intelligence;theoretical computer science;machine learning;affective computing;programming language	AI	-32.85974724588388	-13.973911047521383	37017
c3e40b5afdca8cdb49f3a51eae7b8947e3efa006	modeling and analysis of task complexity in single-operator multi-robot teams	supervisory control;complex tasks;metrics;human multi robot interaction;evaluation	"""A model is presented for analyzing the complexity of task assignment in a human/multi-robot team from the perspective of the human team member, or """"operator"""". The focus is on complex domains where tasks have inter-dependencies and/or require tightly coupled coordination among robots. Preliminary validation of model metrics has been carried out through an experiment involving human subjects. Results suggest significant effect of key aspects of the model on human subjects' cognitive workload."""	robot	Arif Tuna Ozgelen;Elizabeth Sklar	2014	2014 9th ACM/IEEE International Conference on Human-Robot Interaction (HRI)	10.1145/2559636.2559843	simulation;computer science;knowledge management;evaluation;supervisory control;metrics	Robotics	-24.99653142505931	-23.464295747629507	37129
527918e80b551072572bdc06346b3ad8e9973827	agent-based modeling for investigating adaptivity of misperception		Misperception is a term which is generally used in a negative sense. However, when information promoting a certain kind of behavior is obtained, it can happen that the diversity of the behavior is enhanced by the misperceptions of the individual in the population, resulting in a situation in which misperception works advantageously for the population. This paper presents this view in terms of four hypotheses, dealing with (1) the basic adaptivity of misperception, (2) basic properties of communication, (3) the adaptivity of misperception in communication, and (4) the behavioral specificity of information in the adaptivity of misperception. A simple agent model for the resourcesearching problem is constructed. Direct misperception, which is misperception in the direct acquisition of information from the surrounding environment, and indirect misperception, which occurs when information is obtained through communication, are considered. Their effects are investigated by simulation experiments. It is shown that misperception enhances the diversity of agent behavior and can contribute to adaptivity. It is also shown that exact communication may decrease the diversity of agent behavior, and that adaptivity is decreased when false information is shared. A tendency for the adaptivity of misperception to decrease when the behavioral specificity in information terms is low is demonstrated. We believe that study of the adaptivity of misperception as a factor generating diversity will lead to new findings in cognitive science, memetics, and fundamental aspects of engineering. © 2006 Wiley Periodicals, Inc. Syst Comp Jpn, 37(12): 96–106, 2006; Published online in Wiley InterScience (www.interscience. wiley.com). DOI 10.1002/scj.20266	cognitive science;digi-comp i;experiment;john d. wiley;meme;memetics;robot;self-information;sensitivity and specificity;simulation	Jin Akaishi;Takaya Arita	2006	Systems and Computers in Japan	10.1002/scj.20266	artificial intelligence	AI	-15.230860328473861	-14.930253788780133	37150
b882dabab658742089677137cc1ab92e2c030281	behavior observation-based rival's private information inferring	production gallium marketing and sales genetics evolution biology gain genetic algorithms;game theory;behavior observation;gain;expected utility;rival private information inferring;rival decision making model;genetics;evolution biology;genetic algorithms behavioural sciences decision making game theory;genetic algorithm behavior observation rival private information inferring rival decision making model influence diagrams;production;behavioural sciences;influence diagrams;genetic algorithm;genetic algorithms;private information;influence diagram;gallium;marketing and sales	It is important for having the initiative in competition to infer the rival's private information accurately. In this paper, the rival's decision-making model is described by influence diagrams. According to the criterion that rival is apt to gain the maximum expected utility in whole multi-steps decision rather than gain the maximum expected utility just in each of the decision steps, we infer rival's private information about cost and bankroll through observing rival's decision behaviors and using the Genetic Algorithm (GA). The experiment results show that our proposed method is both accurate and reasonable.	expected utility hypothesis;genetic algorithm;influence diagram;personally identifiable information	Lihua Zhou;Weiyi Liu;Yufeng Xu;Hongmei Chen	2008	2008 Fourth International Conference on Networked Computing and Advanced Information Management	10.1109/NCM.2008.39	game theory;genetic algorithm;influence diagram;behavioural sciences;computer science;artificial intelligence;machine learning;data mining;management science	Robotics	-8.546060808632422	-10.038377491505447	37173
163f925e8c48ce5dfaf73d968dca4dc14055337e	a study of human performance in computer-aided architectural design	performance measure;experimental design;protocol analysis;human performance;design process;data collection;computer aided architectural design;cognitive process;video recording;markov process;task complexity;student performance;problem solving;graduate student	Taylor & Francis makes every effort to ensure the accuracy of all the information (the “Content”) contained in the publications on our platform. However, Taylor & Francis, our agents, and our licensors make no representations or warranties whatsoever as to the accuracy, completeness, or suitability for any purpose of the Content. Any opinions and views expressed in this publication are the opinions and views of the authors, and are not the views of or endorsed by Taylor & Francis. The accuracy of the Content should not be relied upon and should be independently verified with primary sources of information. Taylor and Francis shall not be liable for any losses, actions, claims, proceedings, demands, costs, expenses, damages, and other liabilities whatsoever or howsoever caused arising directly or indirectly in connection with, in relation to or arising out of the use of the Content.	computer-aided architectural design;francis;human reliability;primary source	Donna L. Cuomo;Joseph Sharif	1989	Int. J. Hum. Comput. Interaction	10.1080/10447318909525958	human performance technology;simulation;cognition;design process;human–computer interaction;computer science;artificial intelligence;operating system;multimedia;markov process;design of experiments;protocol analysis;statistics;data collection	Robotics	-16.145680837790415	-6.0840842980369585	37214
45236b4660cd99973528c3ec6711c19a21586583	towards integrated imitation of strategic planning and motion modeling in interactive computer games	quake;goal orientation;reinforcement learning;strategic planning;artificial intelligent;data analysis;statistical analysis;clustering;pattern recognition;imitation learning;computer game	Modern, commercial computer games rely primarily on AI techniques that were developed several decades ago, and until recently there has been little impetus to change this. Despite the fact that the computer-controlled agents in such games often possess abilities far in advance of the limits imposed on human participants, competent players are capable of easily beating their artificial opponents, suggesting that approaches based on the analysis and imitation of human play may produce superior agents, in terms of both performance and believability.In this article, we describe our work in imitating the observed goal-oriented behaviors of a human player, based on concepts from data analysis and reinforcement learning. Since even the most intelligent artificial agent will be quickly identified as such if it is observed to move in a robotic manner, we also seek to incorporate mechanisms that will result in believably human-like motion. We then present some illustrative examples, demonstrating the effectiveness of our model. Finally, we discuss future work in this field.	artificial intelligence;intelligent agent;pc game;reinforcement learning;robot	Bernard Gorman;Mark Humphrys	2006	Computers in Entertainment	10.1145/1178418.1178432	simulation;strategic planning;computer science;artificial intelligence;machine learning;goal orientation;quake;cluster analysis;data analysis;management;reinforcement learning	AI	-24.037274765159694	-20.206784576632987	37234
2a45d2bc02e73c4375d4be40a45b8df72db6b436	the converse consistency principle in bargaining	bargaining problem;weak consistency;converse consistency;journal of economic literature;restricted converse consistency;egalitarian solution;pareto optimality;nash solution;scale invariance	We investigate the implications of converse consistency in the context of bargaining. A solution is conversely consistent if whenever for some problem, a feasible alternative has the property that for all proper subgroups of the agents it involves, the solution chooses the restriction of the alternative to the subgroup for the associated reduced problem this subgroup faces, then the alternative should be the solution outcome for the problem. We present two alternative characterizations of the egalitarian solution based on converse consistency as well as either weak consistency or population monotonicity, in addition to other standard axioms of weak Pareto optimality, symmetry, and continuity. However, if we strengthen weak Pareto optimality to Pareto opti-mality, then various impossibility results are obtained. On the other hand, by weakening converse consistency to weak converse consistency, which applies the hypotheses of converse consistency only to the problem whose solution outcome is smooth, we can recover both Pareto optimality and scale invari-ance. In fact, we obtain a characterization of the Nash solution based on restricted converse consistency, as well as other axioms of Pareto optimality, symmetry, scale invariance, continuity, and dummy.		Youngsub Chun	2002	Games and Economic Behavior	10.1006/game.2001.0907	bargaining problem;mathematical optimization;weak consistency;economics;scale invariance;mathematics;mathematical economics;welfare economics;local consistency	ECom	-6.761307275916735	-1.328781450695434	37263
23bcafcccaaf1242a43182fd5ccec43ce861c1c8	the tal-family of rules for bankruptcy problems	institutional repositories;fedora;bankruptcy problems;vital;tal family;constrained equal losses rule;vtls;characterization result;ils;constrained equal awards rule;structural properties	This paper analyzes a family of rules for bankruptcy problems that generalizes the Talmud rule (T ) and encompasses both the constrained equal-awards rule (A) and the constrained equal-losses rule (L). The family is defined by means of a parameter θ ∈ [0, 1] that can be interpreted as a measure of the distributive power of the rule. We provide a systematic study of the structural properties of the rules within the family and its connections with the existing literature.	typed assembly language	Juan D. Moreno-Ternero;Antonio Villar	2006	Social Choice and Welfare	10.1007/s00355-006-0121-3	operations management;data mining	ECom	-7.501594325617922	-1.1425850239489896	37397
ab6fa034ad3c0ea49b9262a3c2c7c12c7d80c114	an approach to the development of a knowledge representation and processing system with the use of agent-based technique			agent-based model;knowledge representation and reasoning	Yury A. Zagorulko;Ivan G. Popov;O. Karakozova	1999			knowledge representation and reasoning;natural language processing;artificial intelligence;computer science	AI	-27.65072965251133	-7.998613608488074	37454
76b92fde1039d425de3344fb2b6294fc8b3c1eee	efficient matching in heterogeneous rule engines		Modern institutions seeking more complex software solutions to represent knowledge in the Cloud are using rule-based systems that serve several applications or clients. Rule-based systems hosted in the Cloud are thus required to support its heterogeneous nature. However, current systems only focus on techniques that isolate instances of rule engines. This paper builds upon earlier work on scoped rule engines that provide mechanisms for supporting shared heterogeneous contexts. We present the scope-based hashing algorithm (SBH) that enables efficient matching in scoped rule engines based on the Rete algorithm. SBH introduces scoped hash tables in alpha memories that help in avoiding unnecessary join tests that hamper performance. Our experimental results show that SBH offers significant improvements in efficiency during the matching process of a heterogeneous rule engine. Consequently, SBH significantly decreases the response time of rule engines in heterogeneous environments having entities sharing the same knowledge base.	business rules engine;rule 184	Kennedy Kambona;Thierry Renaux;Wolfgang De Meuter	2017		10.1007/978-3-319-60042-0_44	hash table;hash function;cloud computing;knowledge base;software;response time;distributed computing;rete algorithm;computer science	Robotics	-31.166694362646364	-0.4911034310107534	37458
02c96302b7ae37683cf881e107929ef129e97e7b	agent approach to situation assessment	agent based;signal analysis;industrial application of ai;knowledge representation and reasoning;industrial application;information fusion;synthetic vision;description logic;situation assessment;knowledge base	The Situation Assessment process is evolving from signal-analysis based centralized models to high-level reasoning based net-centric models, according to new paradigms of information fusion proposed by recent	centralized computing;high- and low-level;net-centric	Giuseppe Paolo Settembre;Daniele Nardi;Roberta Pigliacampo	2009			knowledge representation and reasoning;knowledge base;description logic;computer science;knowledge management;artificial intelligence;data mining;synthetic vision system;situation analysis	SE	-27.17911950002465	-8.298756714142089	37476
2f56b3803200ce5d085c4e406e74b8e3d238e49b	monetary policy and banks' loan supply rules to harness asset bubbles and crashes	economie;economia;banking;multiagent system;systeme aide decision;secteur bancaire;credit;sistema ayuda decision;prise decision;commercial banks;decision support system;monetary policy;credito;central bank;economy;sistema multiagente;toma decision;systeme multiagent	By constructing an artificial micro economy including a central bank and a commercial bank, this paper attempts to examine strict decision-making in loan supply and bad loan management by private banks as well as the degree of monetary intervention by the central bank, and how this affects the emergence and collapse of asset bubbles. The virtual experiment demonstrates that the intervention is unnecessary if the commercial bank manage credit creation and nonperforming loans in a self-controlling way. Otherwise, the intervention is both welcoming and effective.	crash (computing);emergence;test harness	Ichiro Takahashi;Isamu Okada	2003		10.1007/978-3-540-24613-8_7	official cash rate;non-conforming loan;monetary policy;non-performing loan;cross-collateralization;soft loan;open market operation;decision support system;monetary base;computer science;chinese financial system;participation loan;bank rate;monetary reform	HCI	-7.471939220733224	-10.901404046250935	37610
37a6b32e96314da1116594c908eb61e89d922dc7	conditioning using conditional expectations: the borel–kolmogorov paradox	borel kolmogorov paradox;qa mathematics;qa mathematics matematika;probability statistics;conditionalization;b philosophy general;interpretation of probability	The Borel–Kolmogorov Paradox is typically taken to highlight a tension between our intuition that certain conditional probabilities with respect to probability zero conditioning events are well defined and the mathematical definition of conditional probability by Bayes’ formula, which loses its meaning when the conditioning event has probability zero. We argue in this paper that the theory of conditional expectations is the proper mathematical device to conditionalize and that this theory allows conditionalization with respect to probability zero events. The conditional probabilities on probability zero events in the Borel–Kolmogorov Paradox also can be calculated using conditional expectations. The alleged clash arising from the fact that one obtains different values for the conditional probabilities on probability zero events depending on what conditional expectation one uses to calculate them is resolved by showing that the different conditional probabilities obtained using different conditional expectations cannot be interpreted as calculating in different parametrizations of the conditional probabilities of the same event with respect to the same conditioning conditions. We conclude that there is no clash between the correct intuition about what the conditional probabilities with respect to probability zero events are and the technically proper concept of conditionalization via conditional expectations—the Borel–Kolmogorov Paradox is just a pseudo-paradox.		Zalán Gyenis;Gábor Hofer-Szabó;Miklós Rédei	2016	Synthese	10.1007/s11229-016-1070-8	marginal distribution;independence;conditional probability distribution;probability and statistics;discrete mathematics;craps principle;conditional independence;conditional probability;conditional expectation;conditional variance;regular conditional probability;conditioning;conditional dependence;tree diagram;chain rule;mathematics;borel–kolmogorov paradox;law of total probability;posterior probability;conditional mutual information;conditional event algebra;statistics;conditional probability table	ML	-11.300379941550435	1.8338070934379227	37766
3f8129845bc6764407fcd57e06c1973943f5860d	feature article - decision analysis: an overview	607 decision analysis;decision analysis;91 overview;855 survey	This article, written for the nondecision analyst, describes what decision analysis is, what it can and cannot do, why one should care to do this, and how one does it. To accomplish these purposes, it is necessary first to describe the decision environment. The article also presents an overview of decision analysis and provides additional sources for its foundations, procedures, history, and applications.	decision analysis	Ralph L. Keeney	1982	Operations Research	10.1287/opre.30.5.803	decision analysis;decision engineering;computer science;data mining;management science;evidential reasoning approach;operations research;business decision mapping	Logic	-31.62035762142582	-9.160233681824634	37768
92db1200846c411623e29f7febe6681a7d6aa505	a methodology for quantitative and cooperative decision making of air mobility operational solutions	game theory;systems engineering;operations research;multiple objectives;dissertation;group decision making;power indices			John LaNay Salmon	2013			r-cast;decision support system;decision analysis;decision engineering;systems engineering;engineering;management science;operations research;business decision mapping	Robotics	-30.86032224455027	-9.41456370712033	37772
738deede87e85355cefc0e5c7ce0ddc916b2ebea	the application of dea/ahp in evaluating comprehensive benefits of heating equipments	dea ahp;statistics data envelopment analysis equipment evaluation hvac matrix algebra;barium;comparison matrix;heating;matrix algebra;dea;ahp;equipment evaluation;input output;comparison matrix dea ahp comprehensive benefits evaluation heating equipments input output system;hvac;data envelopment analysis;chromium;input output system;comprehensive benefits evaluation;electronic government;comperehensive benefits;statistics;cities and towns;heating equipments;comperehensive benefits heating equipments dea ahp;matlab;evaluation model;heating educational institutions cities and towns chromium electronic government matlab barium	To get the sort of the comprehensive benefits of the currently frequently-used heating equipments, this paper constructed a target system of the comprehensive benefits heating equipments. In the paper, with the use of DEA/AHP evaluation model, first of all, calculate the effective coefficient of the heating equipments consisting of input/output system; Then, using comparison matrix consisting of these effective coefficient, calculate the comprehensive benefits evaluation of the heating equipments. Avoiding the subjectivity of artificial to determine the matrix in AHP and DEA can not sort in a full-scale. Making the evaluation findings more objective and reliable.	coefficient;full scale;input/output;the matrix	Shensheng Zhang;Xiaoyun Wang;Xuejiao Zhang	2010	2010 International Conference on E-Business and E-Government	10.1109/ICEE.2010.1188	reliability engineering;hvac;computer science;engineering;operations management;transport engineering	HPC	-7.800173695481319	-19.07338893508297	37794
18bf50373a9f2ea4453d949e10ac84fb0eb37ad6	a performance comparison between two gis multi-criteria decision aid methods: a case study of desertification evaluation				Heithor Alexandre de Araujo Queiroz;Bruno Cardoso Dantas;Cicero Fidelis da Silva Neto;Thiago Emmanuel Pereira;Ricardo da Cunha Correia Lima	2018				NLP	-9.723245583005449	-21.015997153103655	37808
cdfd67b9b3f6cc4f9456a24317c90dbd004a32ed	an efficient automated negotiation strategy for complex environments	empirical game theory;opponent modeling;multi agent systems;electronic business;counter offer prediction;automated multi issue negotiation	A complex and challenging bilateral negotiation environment for rational autonomous agents is where agents negotiate multi-issue contracts in unknown application domains with unknown opponents under real-time constraints. In this paper we present a negotiation strategy called EMAR for this kind of environment that relies on a combination of Empirical Mode Decomposition (EMD) and Autoregressive Moving Average (ARMA). EMAR enables a negotiating agent to acquire an opponent model and to use this model for adjusting its target utility in real-time on the basis of an adaptive concession-making mechanism. Experimental results show that EMAR outperforms best performing agents from the recent Automated Negotiating Agents Competitions (ANAC) in a wide range of application domains. Moreover, an analysis based on empirical game theory is provided that shows the robustness of EMAR in different negotiation contexts. & 2013 Elsevier Ltd. All rights reserved.		Siqi Chen;Gerhard Weiss	2013	Eng. Appl. of AI	10.1016/j.engappai.2013.08.012	simulation;computer science;knowledge management;artificial intelligence;machine learning;electronic business	AI	-10.670160714635804	-8.881728489860082	37814
7d2c4008f74db594664703773e1fafd06e0ba27c	beyond batch processing: towards real-time and streaming big data	real time processing;big data;mapreduce;stream processing	Today, big data are generated from many sources, and there is a huge demand for storing, managing, processing, and querying on big data. The MapReduce model and its counterpart open source implementation Hadoop, has proven itself as the de facto solution to big data processing, and is inherently designed for batch and high throughput processing jobs. Although Hadoop is very suitable for batch jobs, there is an increasing demand for non-batch requirements like: interactive jobs, real-time queries, and big data streams. Since Hadoop is not suitable for these non-batch workloads, new solutions are proposed to these new challenges. In this article, we discussed two categories of these solutions: real-time processing, and stream processing of big data. For each category, we discussed paradigms, strengths and differences to Hadoop. We also introduced some practical systems and frameworks for each category. Finally, some simple experiments were performed to approve effectiveness of new solutions compared to available Hadoop-based solutions.	apache hadoop;batch processing;big data;experiment;mapreduce;open-source software;real-time clock;real-time transcription;requirement;stream processing;throughput	Saeed Shahrivari	2014	Computers	10.3390/computers3040117	parallel computing;stream processing;big data;computer science;operating system;data mining;database;world wide web	DB	-33.20256741522827	-1.4184348237686086	37830
e59efef2f478f4824646bb8537eb418b42cf6ee2	distributed learning in intentional bdi multi-agent systems	distributed data;decision tree;multi agent system;belief desire intention;decision trees multi agent systems learning artificial intelligence distributed processing;distributed processing;practical reasoning;multi agent systems;distributed learning;machine learning;multiagent systems learning systems decision trees data mining logic programming computer architecture computer science software agents psychology;learning artificial intelligence;decision trees;practical reasoning theory distributed learning intentional bdi multi agent system belief desire intention model rational agency bdi learning agent mas learning first order logical decision trees cooperative goal adoption distributed data gathering;first order logic	Despite the relevance of the belief-desire-intention (BDI) model of rational agency, little work has been done to deal with its two main limitations: the lack of learning competences and explicit multi-agent functionality. Our work deals with the problem of designing BDI learning agents situated in a multi-agent system (MAS). From the MAS learning perspective, we have proposed an extended BDI architecture, where agents are able to perform induction of first-order logical decision trees. These agents learn about their practical reasons to adopt a plan as an intention. Particularly, induction is used to update these reasons (the context of plans), if a plan fails when executed, after it had been selected to form an intention. Here, we emphasize the way MAS concepts, as cooperative goal adoption, enable distributed forms of learning, e.g., distributed data gathering. Consistency between learning and the theory of practical reasoning is guaranteed, i.e., learning is just another competence of the agents, performed under BDI rationality.	access control list;agent architecture;automated theorem proving;belief–desire–intention software model;computer science;decision tree;first-order predicate;khepera mobile robot;lisp;mathematical induction;modal logic;multi-agent system;rationality;relevance;simulation;situated;theory;whole earth 'lectronic link	Alejandro Guerra-Hernández;Amal El Fallah-Seghrouchni;Henry Soldano	2004	Proceedings of the Fifth Mexican International Conference in Computer Science, 2004. ENC 2004.	10.1109/ENC.2004.1342610	error-driven learning;computer science;knowledge management;artificial intelligence;machine learning;decision tree;multi-agent system;active learning	AI	-20.612243560786776	-9.744156033844979	37905
c6a514f644fb3bea44a737eb942c9f64abd542c2	managing and instructing information assistants		We describe agents that are customizable information assistants for space control center personnel who monitor mission operations and equipment and who assist space crew. These monitoring agents can provide flexible services that are not provided by autonomous system management agents on a space vehicle. These agents watch for the occurrence of pre-specified patterns in telemetry data and perform selected actions (notes made in the console log, written reports, notification of people performing specified roles) when those events are recognized. We have prototyped tools to help flight controllers and engineers create, review and supervise these agents. We have developed a higher order specification interface for viewing original specifications and making new, similar specifications. We have studied an existing tool that performs similar functions in a control center, and have applied some of the lessons learned to our own work. This study has led to design of a new user interface for constructing and customizing agent instructions.	alf;autonomous robot;autonomous system (internet);intelligent agent;iteration;keystroke logging;mission control;report;simulation;software agent;systems management;user interface	Jane T. Malin;Arthur Molin;Carroll Thronesbery	2005			computer science;machine learning;artificial intelligence;simulation;telemetry;crew;knowledge management;space vehicle;autonomous system (mathematics);user interface	HCI	-28.447672966876333	-22.37866579412044	37907
a89daaeb04fc4304efda0b6c46984d812da89a18	semantic trajectory applied to the navigation of autonomous mobile robots		Current technology produces a big mass of information. The application of this information gives meaning and purpose to this data. Mobile robots can benefit from this information. This paper proposes a framework to apply semantic information to the navigation of autonomous mobile robots, tracking the robot movement into a semantic trajectory and analyzing the context data on the decision-making process through a behavior tree. Experiments show that this framework provides a structure to intelligent navigation and data information to improve the robot behavior.	autonomous robot;behavior tree;database storage structures;energy level;experiment;gene ontology term enrichment;machine learning;mobile robot	Fernando de Lucca Siqueira;Patricia Della Mea Plentz;Edson R. de Pieri	2016	2016 IEEE/ACS 13th International Conference of Computer Systems and Applications (AICCSA)	10.1109/AICCSA.2016.7945766	computer science;robot control;behavior-based robotics;motion planning;semantics;robot;simulation;trajectory;mobile robot;mobile robot navigation	Robotics	-27.911789561103074	-19.909813552915015	37940
d8b035f33f0bb34a8933295320a5b3be630a441f	the within groups and the between groups myerson values	betweenness centrality;myerson value;communication centrality;social networks	In this paper we revisit the additive decomposition that Gomez et al. (2003) introduced for the Myerson value of a symmetric game when viewed as a centrality measure. First, we generalize this decomposition, extending it to general games. This approach permits us to look at the Myerson value of a player as a certain modulus of a two component vector. One of them, the within groups Myerson value, determines which part corresponds to the profit from the coalitions that a given player is in, whereas the other, the between groups Myerson value, evaluates the opportunities that player has as intermediary in the communication among others. These two values are then characterized using additivity and other properties related with previous interpretation: (A) The competitive advantages (or disadvantages) of a null player in a game with restrictions given by a graph (measured in terms of his Myerson value) are due to his ability to intermediate among the others. (B) In the same context, those players essential to coalitions that generate worth cannot obtain profit by intermediating. When restricted to certain symmetric games, the corresponding values can be considered as centrality measures, as they satisfy natural properties that reinforce this interpretation.		Enrique González-Arangüena;Conrado Manuel;Guillermo Owen;Mónica del Pozo	2017	European Journal of Operational Research	10.1016/j.ejor.2016.08.003	mathematics;mathematical economics;betweenness centrality;welfare economics;social network	Theory	-6.795643283809148	-2.439135652697709	38079
118f114578b87d32a0c5900ca25be22059ca2a41	a data base design decision support system	decision support system	The task of physical data base design in an DBTG enviornment is examined. Generation of an internal schema which considers questions of storage versus access costs, efficient implementation of data relationships, efficient placement of data within the data base and allocation of primary and secondary storage is shown to be a formidable task.#R##N##R##N#Current data base design aids are reviewed. One aid, a sophisicated mathematical model of DBTG data bases (Gerritsen 1977) is shown to be a potentially valuable tool. A limitation of this model is that no optimization algorithm other than total enumeration has been found.#R##N##R##N#This paper proposes an implementation of the Gerritsen model. An interactive design tool, based upon the Gerritsen model, is discussed. A Data Base Design Decision Support System (DBD-DSS) for use by the DBA is developed. The objectives and structure of the DBD-DSS are examined. A comprehensive example illustrating both the user interface and the potential benefits of the interactive tool is presented.	decision support system	Thomas J. Gambino;Rob Gerritsen	1977			simulation;decision support system;computer science;data mining;database	EDA	-33.385250760937176	-8.00939030599356	38093
fb7bccb5de8b9761ad20c6515f005dbdd3af3007	introduction to the special issue on cognition, joint action and collective intentionality	joint action		cognition;collective intelligence;intentionality	Luca Tummolini;Cristiano Castelfranchi	2006	Cognitive Systems Research	10.1016/j.cogsys.2006.01.003	psychology;computer science;artificial intelligence;cognitive science	Robotics	-24.862075916239842	-15.296740189812487	38112
ba0f67408f117c269c93b60b01813fe9c5e9bf25	action duality: a constructive principle for quantum foundations	path integral;time symmetry;entanglement;quantum physics;quantum theory;quantum foundations;retrocausality;bell inequality;sum over histories	An analysis of the path integral approach to quantum theory motivates the hypothesis that two experiments with the same classical action should have dual ontological descriptions. If correct, this hypothesis would not only constrain realistic interpretations of quantum theory, but would also act as a constructive principle, allowing any realistic model of one experiment to generate a corresponding model for its action-dual. Two pairs of action-dual experiments are presented, including one experiment that violates the Bell inequality and yet is action-dual to a single particle. The implications generally support retrodictive and retrocausal interpretations.	bell's theorem;experiment;interpretations of quantum mechanics;path integral formulation;social inequality	Ken B. Wharton;David J. Miller;Huw Price	2011	Symmetry	10.3390/sym3030524	quantum operation;path integral formulation;bell state;quantum probability;local hidden variable theory;quantum teleportation;theoretical physics;quantum discord;quantum capacity;open quantum system;quantum pseudo-telepathy;mathematics;geometry;principle of locality;interpretations of quantum mechanics;quantum entanglement;quantum process;hidden variable theory;quantum algorithm;physics;quantum mechanics;bell test experiments	ML	-11.04960614793923	4.120062714029825	38125
655646658aee30d5520ba8e3c809deea6386dd56	some observations on the us e-commerce trade statistics	mape;electronic commerce;mse;trade statistics;e commerce;behavioural trends;mean absolute error;mean absolute percentage error;mae;mean square error;government reports;usa	More and more business transactions are being carried out on the World Wide Web. These data, in the form of monetary amounts are reported by governmental agencies. In the USA, e-commerce data reports are provided and made available to the public by the Department of Commerce. Normally these data sets are provided every quarter and are revised as more accurate information is collected. First, this study deals with the proliferation of e-commerce as a whole and reports on the variety of behavioural trends in the data set. Second, the accuracy of the initial estimates and the revised numbers published each quarter are also examined to determine the magnitude of the changes. Specifically, the MSE, MAE and MAPE of the respective quarters and years are reported and analysed. Global trade experts, decision support model developers, corporate executives, and policy makers will find the outcomes reported to be useful.	e-commerce	Haoyu Wen;Kai S. Koong;Lai Chung Liu	2015	IJSS	10.1504/IJSS.2015.070693	e-commerce;public relations;mean absolute percentage error;economics;computer science;marketing;operations management;data mining;economy;management;law;computer security;statistics	ECom	-8.117412812524277	-22.816687782658974	38130
4e1acb45566717668e99cc5182b790b37a7e8aa5	non-implementability of arrow-debreu equilibria by continuous trading under volatility uncertainty		In diffusion models, few suitably chosen financial securities allow to complete the market. As a consequence, the efficient allocations of static Arrow–Debreu equilibria can be attained in Radner equilibria by dynamic trading. We show that this celebrated result generically fails if there is Knightian uncertainty about volatility. A Radner equilibrium with the same efficient allocation as in an Arrow–Debreu equilibrium exists if and only if the discounted net trades of the equilibrium allocation display no ambiguity in the mean. This property is violated generically in endowments, and thus Arrow–Debreu equilibrium allocations are generically unattainable by dynamically trading few long–lived assets. ∗We gratefully acknowledge financial support through the German Research Foundation (DFG) via CRC 1283 “Taming Uncertainty . . .” and Grant Ri 1128-7-1. We thank Volker Böhm, Rose-Anne Dana, Christoph Kuzmics, Filipe Martins-da-Rocha, and seminar audiences at ETH Zurich, LMU Munich, Rhein-Main-Kolloquium Frankfurt, the Byrne Workshop on Stochastic Analysis in Finance and Insurance at Michigan, D-TEA 2015, York, Paris Dauphine, the BGTS Summer School on Model Uncertainty in Finance and Economics, TU Berlin, de Finetti Seminar Milano, Shandong University, and at our own universities for comments.	arrow–debreu model;cyclic redundancy check;tea;volatility	Patrick Beissner;Frank Riedel	2018	Finance and Stochastics	10.1007/s00780-018-0362-x		ECom	-7.437802792731799	-4.562823646268279	38222
0745d4ff712699415f8d0da2275b1f1300ca8bda	safe and effective autonomous decision making in intelligent robtic systems				Rahee Agate-Walambe	2007				AI	-30.4978449650739	-18.44642202278544	38276
fdd0de2bc13ab5461d8e2b08fcc076bfc3d82c7d	computers from plants we never made. speculations		Plants are highly intelligent organisms. They continuously make distributed processing of sensory information, concurrent decision making and parallel actuation. The plants are efficient green computers per se. Outside in nature, the plants are programmed and hardwired to perform a narrow range of tasks aimed to maximize the plants’ ecological distribution, survival and reproduction. To ‘persuade’ plants to solve tasks outside their usual range of activities, we must either choose problem domains which homomorphic to the plants natural domains or modify biophysical properties of plants to make them organic electronic devices. We discuss possible designs and prototypes of computing systems that could be based on morphological development of roots, interaction of roots, and analog electrical computation with plants, and plant-derived electronic components. In morphological plant processors data are represented by initial configuration of roots and configurations of sources of attractants and repellents; results of computation are represented by topology of the roots’ network. Computation is implemented by the roots following gradients of attractants and repellents, as well as interacting with each Andrew Adamatzky · Simon Harding · Richard Mayne · Nina Gizzie Unconventional Computing Centre, UWE, Bristol, United Kingdom, e-mail: andrew. adamatzky@uwe.ac.uk, e-mail: slh@evolutioninmaterio.com, e-mail: richard. mayne@uwe.ac.uk, e-mail: nina.gizzie@gmail.com Victor Erokhin CNR-IMEM, Parma, Italy, e-mail: victor.erokhin@fis.unipr.it Frantisek Baluska Institute of Cellular and Molecular Botany, University of Bonn, Germany, e-mail: unb15e@	andrew adamatzky;central processing unit;computation;computer;distributed computing;electronic component;email;gradient;homomorphic encryption;interaction;problem domain;unconventional computing	Andrew Adamatzky;Simon Harding;Victor Erokhin;Richard Mayne;Nina Gizzie;František Baluška;Stefano Mancuso;Georgios Ch. Sirakoulis	2017	CoRR			AI	-31.2429724653717	-17.347612286103526	38323
9d464d2d499dcec1f5f6d4dfd0d72ccc33dffab4	distributed decision evaluation model in public transportation systems	multicriteria optimization;multi agent system;agent modeling;public transport;traffic regulation;plurality voting;multi agent systems;public transportation systems;a efficiency;pareto optimality;evaluation model	Due to several external and internal disturbances affecting public transportation systems, some regulation measures have to be undertaken. In the regulation process, the regulator has to evaluate a number of possible decisions in order to determine best compromise of some regulation criteria. The complexity of this task increases when numerous disturbances appear simultaneously and mainly when regulation criteria are contradictory. For these reasons, we propose in this paper a multi-agent model that deals with decision evaluation step as a multicriteria optimization problem. In this model, the best compromise is determined by means of the following concepts: Pareto optimality, a-efficiency and plurality voting. The process of the proposed approach is shown through an illustrative example.		Imen Boudali;Inès Ben Jaâfar;Khaled Ghédira	2008	Eng. Appl. of AI	10.1016/j.engappai.2007.05.007	mathematical optimization;computer science;artificial intelligence;multi-agent system;management science;public transport	AI	-11.940111895792901	-11.26643159431262	38380
4c9b1684d00254d1f45d97f146543bd23873073e	a semantic-based p2p resource organization model r-chord	data management;p2p;semantic link network;journal;knowledge grid;peer data management;resource space model;peer to peer	This paper proposes a semantic-based P2P resource organization model R-Chord by incorporating the Resource Space Model (RSM), the P2P Semantic Link Network Model (P2PSLN) and the DHT Chord protocol. Peers provide services with each other according to the content of their resources and the related configuration information. It incorporates the classification semantics and the relational semantics to provide users and applications with a uniform view on distributed resources. Experiments show that, compared to the Chord approach, the R-Chord approach is more flexible to support semantic-based queries and can significantly decrease the average visiting number of and visiting times on peers for answering queries. 2006 Elsevier Inc. All rights reserved.	distributed hash table;experiment;kripke semantics;link relation;mathematical optimization;network model;peer-to-peer;query optimization;response surface methodology;routing;scalability	Jie Liu;Hai Zhuge	2006	Journal of Systems and Software	10.1016/j.jss.2006.03.001	semantic data model;semantic computing;semantic grid;data management;computer science;peer-to-peer;data mining;database;world wide web	Web+IR	-29.360919607625526	-0.4251348896644368	38438
febf3233063cd6dc68e5d0194d5ba610fe942e99	can you trust online ratings? a mutual reinforcement model for trustworthy online rating systems	unfair ratings false reputation robustness trust;collaboration;multi agent systems computational modeling robustness algorithm design and analysis collaboration;companies;multi agent systems;trusted computing decision making internet iterative methods purchasing retail data processing;computational modeling;iterative adjustment mutual reinforcement model online rating system trustworthiness reputation trustworthiness online purchasing decision true reputation algorithm;robustness;algorithm design and analysis	The average of customer ratings on a product, which we call a reputation, is one of the key factors in online purchasing decisions. There is, however, no guarantee of the trustworthiness of a reputation since it can be manipulated rather easily. In this paper, we define false reputation as the problem of a reputation being manipulated by unfair ratings and design a general framework that provides trustworthy reputations. For this purpose, we propose TRUE-REPUTATION, an algorithm that iteratively adjusts a reputation based on the confidence of customer ratings. We also show the effectiveness of TRUE-REPUTATION through extensive experiments in comparisons to state-of-the-art approaches.	algorithm;cluster analysis;elemental;experiment;machine learning;objectivity/db;purchasing;real life;trust (emotion);trustworthy computing	Hyun-Kyo Oh;Sang Wook Kim;Sunju Park;Ming Zhou	2015	IEEE Transactions on Systems, Man, and Cybernetics: Systems	10.1109/TSMC.2015.2416126	algorithm design;computer science;knowledge management;artificial intelligence;multi-agent system;computational model;robustness;collaboration	Web+IR	-9.525462142564198	-8.678581464776919	38472
672ffcc1f79487d297f4647eadd75b3f7b8df5ab	cucker--smale flocking under hierarchical leadership	rate of convergence;91d30;convergence;leadership;leaders;cucker smale model;social system;sensor network;91c20;fiedler number;dynamic graphs;social behavior;emergent behavior;graph laplacian;perturbation;quantitative method;free will;bio flocking;92d50;92d40	A mathematical theory on flocking serves the foundation for several ubiquitous multi-agent phenomena in biology, ecology, sensor networks, economy, as well as social behavior like language emergence and evolution. Directly inspired by the recent fundamental works of Cucker and Smale on the construction and analysis of a generic flocking model, we study the emergent behavior of Cucker-Smale flocking under hierarchical leadership. The rates of convergence towards asymptotically coherent group patterns in different scenarios are established. The consistent convergence towards coherent patterns may well reveal the advantages and necessities of having leaders and leadership in a complex (biological, technological, economic, or social) system with sufficient intelligence.	coherence (physics);ecology;emergence;flocking (behavior);horseland;multi-agent system	Jianhong Shen	2007	SIAM Journal of Applied Mathematics	10.1137/060673254	leadership;mathematics	ML	-14.772030349721717	-16.417137840492217	38485
c5df55bbe4e8128fc8e5a54a6dff65144def06ba	creation of devs models using imitation learning	real time;transfer learning;devs;imitation learning;case based reasoning	Modelling and simulation of robotic control systems allows for low cost analysis and experimentation. However, creating these models requires a level of technical expertise. To improve the technical quality of such models, we propose a case-based reasoning approach to learn the behaviour of models using the DEVS formalism. By observing a desired behaviour, in the form of outputs produced in response to inputs, a DEVSmodel of the behaviour can be built. This model can then be used during simulation to imitate the behaviour of interest. Our results show that this learning approach can be used to successfully imitate the behaviour of several DEVS models. Additionally, it can be used to transfer behaviour to and from a non-DEVS model.	case-based reasoning;control system;devs;experiment;obstacle avoidance;robot;robotic arm;semantics (computer science);simulation	Michael W. Floyd;Gabriel A. Wainer	2010			case-based reasoning;simulation;transfer of learning;computer science;artificial intelligence;devs;algorithm	AI	-25.28110307026474	-19.909849506455974	38518
9ddc14fb1e11e23cba98cc0931cdf1c517933712	constructing and utilizing large fact databases using artificial intelligence techniques	artificial intelligent			Gian Piero Zarri	1984			artificial architecture;computer science;artificial intelligence;machine learning;computational intelligence;data mining;artificial intelligence system	AI	-27.6755967308577	-8.797793399596236	38587
cb82b01816e2c086237cb21735dc2d8d3371170c	semantic network representations in rule-based inference systems	rule based system;rule based;semantic network	Rule-based inference systems allow judgmental knowledge about a specific problem domain to be represented as a collection of discrete rules. Each rule states that if certain premises are known, then certain conclusions can be inferred. An important design issue concerns the representational form for the premises and conclusions of the rules. We describe a rule-based system that uses a partitioned semantic network representation for the premises and conclusions.	logic programming;problem domain;rule-based system;semantic network	Richard O. Duda;Peter E. Hart;Nils J. Nilsson;Georgia L. Sutherland	1977	SIGART Newsletter	10.1145/1045343.1045351	rule-based system;computer science;artificial intelligence;machine learning;data mining;semantic network;rule of inference	AI	-20.165964064372417	1.2047294620751143	38617
055aaae71f66aa5698b2ef0d221fd9d63bd9cf74	social model shaping for solving generic dec-pomdps	multi agent system;decision making under uncertainty;computer model;equational reasoning;benchmark problem;distributed processing;tightly coupled benchmark problem social model shaping heuristics generic dec pomdp solver decentralized partially observable markov decision problem multiagent decision making computational complexity distributed pomdp coordination locales agent dependency;multi agent systems;computational modeling joints mathematical model robot kinematics collision avoidance equations;computational complexity;reasoning under uncertainty;mathematical model;multi agent systems computational complexity decision making distributed processing markov processes;reasoning under uncertainty multi agent systems dec pomdp;collision avoidance;dec pomdp;markov processes	Decentralized Partially Observable Markov Decision Problem, DEC-POMDP is a popular model to representmulti-agent decision making under uncertainty. However, the significant computational complexity involved in solving DECPOMDPshas limited their application. Recently, social model shaping (TREMOR and D-TREMOR algorithms) was introduced as an alternative to solve a sub-class of DEC-POMDPs. While scalability has been improved to even solve hundred agent problems, social model shaping has been restricted to solving a sub-class of DEC-POMDPs called Distributed POMDPs with Coordination Locales (DPCL). To that end, we make two significant contributions: (a) Firstly, we enhance the model shaping approach to solve general DEC-POMDPs where there is no restriction on the agent dependencies, and (b) Secondly, we provide theoretical justification for the model shaping heuristics. The key intuition is that not all interactions between agents occur at every time step. In addition to solving 100 agent problems in weakly coupled domains (due to extension from TREMOR and D-TREMOR), we are able to show that social model shaping achieves comparable performance to leading DEC-POMDP solvers (such as IMBDP, MBDP-OC, PBIP-IPGetc.) on tightly coupled benchmark problems.	algorithm;benchmark (computing);computational complexity theory;dec alpha;decision problem;decision theory;emoticon;heuristic (computer science);interaction;markov chain;noise shaping;partially observable markov decision process;scalability;social welfare model	Pradeep Varakantham	2011	2011 IEEE/WIC/ACM International Conferences on Web Intelligence and Intelligent Agent Technology	10.1109/WI-IAT.2011.145	simulation;computer science;artificial intelligence;machine learning;multi-agent system;mathematical model;markov process;computational complexity theory	AI	-11.468174129326387	-6.114966571924512	38695
e6cea332a18b5ff4cbe5be780333d09df7670fa8	commandersong: a systematic approach for practical adversarial voice recognition		The popularity of automatic speech recognition (ASR) systems, like Google Assistant, Cortana, brings in security concerns, as demonstrated by recent attacks. The impacts of such threats, however, are less clear, since they are either less stealthy (producing noise-like voice commands) or requiring the physical presence of an attack device (using ultrasound speakers or transducers). In this paper, we demonstrate that not only are more practical and surreptitious attacks feasible but they can even be automatically constructed. Specifically, we find that the voice commands can be stealthily embedded into songs, which, when played, can effectively control the target system through ASR without being noticed. For this purpose, we developed novel techniques that address a key technical challenge: integrating the commands into a song in a way that can be effectively recognized by ASR through the air, in the presence of background noise, while not being detected by a human listener. Our research shows that this can be done automatically against real world ASR applications1. We also demonstrate that such CommanderSongs can be spread through Internet (e.g., YouTube) and radio, potentially affecting millions of ASR users. Finally we present mitigation techniques that defend existing ASR systems against such threat.	automated system recovery;automatic system recovery;cortana (halo);embedded system;google assistant;internet;speech recognition;threat (computer);transducer	Xuejing Yuan;Yuxuan Chen;Yue Zhao;Yunhui Long;Xiaokang Liu;Kai Chen;Shengzhi Zhang;Heqing Huang;Xiaofeng Wang;Carl A. Gunter	2018			voice command device;computer science;over the air;adversarial system;deep learning;speech recognition;artificial intelligence	Security	-15.552204667539495	-2.6001946968913785	38711
c7ecb3d37182cc0b01660dac2bfc2714cb830dc1	aimss: an architecture for data driven simulations in the social sciences	agent based;social sciences;data collection;qualitative data;association rule mining;social science;consistency checking;data driven simulations;architecture	This paper presents a prototype implementation of an intelligent assistance architecture for data-driven simulation specialising in qualitative data in the social sciences. The assistant architecture semi-automates an iterative sequence in which an initial simulation is interpreted and compared with real-world observations. The simulation is then adapted so that it more closely fits the observations, while at the same time the data collection may be adjusted to reduce uncertainty. For our prototype, we have developed a simplified agent-based simulation as part of a social science case study involving decisions about housing. Real-world data on the behaviour of actual households is also available. The automation of the data-driven modelling process requires content interpretation of both the simulation and the corresponding real-world data. The paper discusses the use of Association Rule Mining to produce general logical statements about the simulation and data content and the applicability of logical consistency checking to detect observations that refute the simulation predictions.	agent architecture;agent-based model;agent-based social simulation;association rule learning;computer simulation;e-social science;fits;iteration;machine learning;prototype;semiconductor industry	Catriona Kennedy;Georgios K. Theodoropoulos;Volker Sorge;Edward Ferrari;Peter Lee;Chris Skelcher	2007		10.1007/978-3-540-72584-8_144	simulation;computer science;artificial intelligence;data science;architecture;operating system;machine learning;data mining;algorithm;statistics;data architecture;data collection	AI	-31.6480450470974	-6.810918400692397	38715
6edfde1b39c76ed3b9ff1e54fa1961b8e63fcdb4	an empirical evaluation of a distributed clustering-based index for metric space databases	database indexing;carbon;pattern clustering;search engine;data structures metric space bsp parallel search;metric space;client server system;query processing;search engines;construction industry;parallel programming;client server systems;bsp;data distribution;large databases;indexes;query processing client server systems data structures parallel programming;computational modeling;metric space databases;data structures;large databases distributed clustering based index metric space databases similarity search parallel query processing sequential index data structures client server system;very large databases client server systems data structures database indexing parallel processing pattern clustering query processing;indexation;indexes extraterrestrial measurements distributed databases data structures parallel processing nearest neighbor searches traffic control query processing search engines distributed computing;uranium;sequential index data structures;parallel query processing;not significant;search engines distributed clustering based index metric space databases similarity search parallel query processing index data structures data distribution;parallel search;search problems;model of computation;very large databases;indium;extraterrestrial measurements;index data structures;empirical evaluation;data structure;program processors;distributed clustering based index;similarity search;parallel processing;iodine;arsenic;beryllium	Similarity search has been proved suitable for searching in very large collections of unstructured data objects. We are interested in efficient parallel query processing under situations of continuous streams of queries as in search engines. A number of sequential index data structures for this purpose have been proposed so far. This paper focuses on one representative of a class of these data structures, namely one based on clustering for which we evaluate different ways of distributing the index to support parallelism on a set of processors. Our study reveals that the intuitive method for both data distribution and model of computing are not efficient in practice. The best results are obtained with a strategy that appears to be more costly in construction but we show that in practice this cost is not significant.	central processing unit;cluster analysis;data structure;database;parallel computing;similarity search;web search engine	Veronica Gil Costa;Mauricio Marín;Nora Reyes	2008	2008 IEEE 24th International Conference on Data Engineering Workshop	10.1109/SISAP.2008.14	database index;data structure;computer science;theoretical computer science;data mining;database;programming language;search engine	DB	-28.890784518942844	2.2457464003558645	38747
345d049b0e3151d43db4634457758a3eed4a6d57	predictions with uncertainty to support fair outcomes in online legal disputes	bayesian belief networks online legal disputes australian family law online dispute resolution approach online dispute dialogue argument based model judicial reasoning;online dispute dialogue;bayes methods;alternative dispute resolution;online legal disputes;australian family law;argument based model;law;judicial reasoning;bayesian belief networks;online dispute resolution;bayesian belief network;law bayes methods;uncertainty law legal factors australia computational intelligence protocols bayesian methods intelligent systems knowledge based systems predictive models;online dispute resolution approach	Alternative dispute resolutions systems are not uncommon in Australian family law, however to date these systems are largely negotiation based and are not designed for producing judicially fair outcomes. This paper proposes an online dispute resolution approach that aims to support divorcees to resolve property issues in a manner that is consistent with orders a judge would make if the matter was heard in court. The approach integrates a protocol for online dispute dialogue with an argument based model of judicial reasoning to structure the dispute. The likelihood of alternates outcomes is predicted with a series of Bayesian belief networks.	apriori algorithm;automation;bayesian network;computation;computational intelligence;e-commerce;ftc fair information practice;fairness measure;one definition rule	Nial Muecke	2006	2006 International Conference on Computational Inteligence for Modelling Control and Automation and International Conference on Intelligent Agents Web Technologies and International Commerce (CIMCA'06)	10.1109/CIMCA.2006.164	online dispute resolution;computer science;artificial intelligence;machine learning;dispute mechanism;bayesian network;data mining;management science	Robotics	-15.332681185141205	2.1102678022292967	38776
0e79def9bc561dd650b33db7f3ee29d863cca012	modeling of human society as a locally interacting product-potential networks of automaton		The central problems in social sciences concern the social and psychological mechanisms and conditions required for the emergence and stability of human groups. The present article is dedicated to the problem of stability of human groups. We model human groups using local interacting systems of automaton with relations and reactions and using the structural balance theory. The ‘structural balance theory’ ties the emergence of a human group with the human actor’s thoughts about how another actor treats him and his perception of actors. The Cartwright and Harary formalization the concept of balance theory within a graph theoretical setting unable to get a number of mathematical results pertaining to an algebraic formulation of the theory of balance in signed networks/graphs. The deeper generalization of ’balance theory’ as the smooth product-potential fields on domain gives us the ability to create theory of ’smooth product potential social fields’. We then find that all discrete product-potential system tightly connect with other process process multiplication on the randomly chosen matrices and we find connections between stationary measures and some algebraic objects.	automaton;balance theory;emergence;frank harary;interaction;linear algebra;randomness;stationary process	Vladislav B. Kovchegov	2016	CoRR		combinatorics;computer science;artificial intelligence;machine learning;mathematics	Graphics	-22.673298561195487	-14.330879741976627	38906
a4c12cab0d7da946d5f5a0343bf9e692feb8398f	the context principle and wittgenstein's criticism of russell's theory of types	theorie des types;wittgenstein l;principe du contexte;symbolism;russell b;symbolisme	In this paper, I try to uncover the role played by Wittgenstein's context principle in his criticism of Russell's theory of types. There is evidence in Wittgenstein's writings that a syntactical version of the context principle in connection with the theory of symbolism functions as a good reason for his dispensing with the theory of types.	dispense;symbolism;type theory	Marco Antonio Ruffino	1994	Synthese	10.1007/BF01063927	philosophy;epistemology	NLP	-11.422345920018307	3.536972625035492	38962
afeecc4e96e500b314c7b4519c529d9828471cc6	a possibilistic graphical model for handling decision problems under uncertainty	possibilistic decision theorymin based possibilistic networksjunction trees	Possibilistic networks are important and efficient tools for reasoning under uncertainty. This paper proposes a new graphical model for decision making under uncertainty based on possibilistic networks. In possibilistic decision problems under uncertainty, available knowledge is expressed by means of possibility distribution and preferences are encoded by means another possibility distribution representing the qualitative utility. The first part of the paper proposes a new graphical way to represent such problem, where agent’s knowledge and preferences are encoded separately by two distinct possibilistic networks. The first one encodes agent’s beliefs and the second one represents the qualitative utility. The second part of the paper proposes a new algorithm for computing optimistic optimal decisions based on merging these two possibilistic networks. In fact, the qualitative possibilistic decision is viewed as a data fusion problem of these two particular possibilistic networks. We show that the computation of optimal decisions comes down to compute a normalization degree of the junction tree associated with the graph representing the fusion of agent’s beliefs and preferences.	algorithm;computation;decision problem;decision theory;graphical model;graphical user interface;tree decomposition	Salem Benferhat;Faiza Khellaf;Ismahane Zeddigha	2013		10.2991/eusflat.2013.110	artificial intelligence;machine learning;data mining;mathematics	AI	-8.816371621310873	1.6566988784372993	38978
6a084648bae5d3784c3f9867ac6b7ca852474a18	stability under strategy switching	graphical games;strategy switching;rational agent;strategy specifications	We suggest that a process-like notion of strategy is relevant in the context of interactions in systems of self-interested agents. In this view, strategies are not plans formulated by rational agents considering all possible futures and (mutually recursively) taking into account strategies employed by other players. Instead, they are partial; players start with a set of potential strategies and dynamically switch between them. This necessitates some means in the model for players to access each others’ strategies, and we suggest a syntax by which players’ rationale for such switching may be specified and structurally composed. In such a model one can ask a stability question: given a game arena and a strategy specification, whether players eventually settle down to strategies without further switching. We show that this problem can be algorithmically solved using automata theoretic methods.	algorithm;automata theory;design rationale;futures and promises;interaction;rational agent;recursion;switch	Soumya Paul;Ramaswamy Ramanujam;Sunil Simon	2009		10.1007/978-3-642-03073-4_40	rational agent;simulation;computer science;artificial intelligence;operations management;outcome	Logic	-10.756692432904217	-1.1402772812107338	39079
1b97b4623cf2f183340e548e0aa53abf0f2963d8	representing general relational knowledge in conceptnet 5		ConceptNet is a knowledge representation project, providing a large semantic graph that describes general human knowledge and how it is expressed in natural language. This paper presents the latest iteration, ConceptNet 5, including its fundamental design decisions, ways to use it, and evaluations of its coverage and accuracy.	iteration;knowledge representation and reasoning;natural language;open mind common sense	Robert Speer;Catherine Havasi	2012			artificial intelligence;natural language processing;knowledge representation and reasoning;natural language;computer science;graph	NLP	-27.854257135938784	-6.841911593326121	39134
81abc8df15e971ee2d93c530780cc26c28e94996	implementation of a logic-based support system for concurrent engineering	lenguaje programacion;interfase usuario;concepcion ingenieria;engineering design;systeme intelligent;conceptualization;programmation;tarea concurrente;programming language;user interface;conception ingenierie;implementation;sistema inteligente;logic;coaccion;contrainte;order sorted logic;ingenieria logiciel;productique;constraint satisfaction;software engineering;programacion;design rules;conceptualizacion;ejecucion;support system;constraint;intelligent system;genie logiciel;langage programmation;robotica;interface utilisateur;constraint satisfaction problem;tâche concurrente;printed wiring board;programming;computer integrated manufacturing;concurrent task;deduccion;conceptualisation;logique;logica;concurrent engineering;deduction	Abstract   In this paper we detail the representation and implementation techniques used to build SPARK, a logic-based support system for designers engaged in concurrent engineering. Design rules are represented as constraints in a constraint satisfaction problem. This problem is translated into equivalent order-sorted logic formulae that form a concurrent engineering logic problem. The solution to this problem is determined through interactive constraint satisfaction performed by a deduction system and associated proof strategy. This illustrated with an example from Printed Wiring Board Design.		Arthur R. Greef;Steffen M. Fohn;Robert E. Young;Peter J. O'Grady	1995	Data Knowl. Eng.	10.1016/0169-023X(95)94024-3	constraint logic programming;concurrent constraint logic programming;conceptualization;programming;logic optimization;constraint satisfaction;computer science;artificial intelligence;database;constraint;programming language;user interface;implementation;logic programming;constraint satisfaction problem;logic;algorithm;engineering design process;concurrent engineering	DB	-24.526770470480752	-4.045103355504325	39139
03c441784e604a49e91d472ad15e4f2dc4dfc2a4	tighter upper bounds for join cardinality estimates		1 PROBLEM AND MOTIVATION Despite decades of research, modern database systems still struggle with multijoin queries. Users will often experience long wait times occurring with unpredictable frequency detracting from the usability of the system. In this work we develop a new method to tighten join cardinality upper bounds. The intention for these bounds is to assist the query optimizer (QO) in avoiding expensive physical join plans. Our approach is as follows: leveraging data sketching, and randomized hashing we generate and tighten theoretical join cardinality upper bounds. We outline our base data structures and methodology, and how these bounds may be introduced to a traditional QO framework as a new statistic for physical join plan selection. We evaluate the tightness of our bounds on GooglePlus community graphs and successfully generate degree of magnitude upper bounds even in the presence of multiway cyclic joins.	data structure;database;google+;mathematical optimization;query optimization;randomized algorithm;usability	Walter Cai	2018		10.1145/3183713.3183714	cardinality;data mining;computer science;deep web;name resolution	DB	-24.312985195891066	1.1063486943813672	39175
70c7363c413d29040442701f855e477a0333db04	auction design and performance: an agent-based simulation with endogenous participation		This paper presents results from computational experiments evaluat- ing the impact on performance of different auction design features. The focus of the study is a conservation auction for water quality where auctions are used to allocate contracts for improved land management practices among landhold- ers bidding to provide conservation services. An agent-based model of bidder agents that learn using a combination of direction and reinforcement learning al- gorithms is used to simulate performance. The auction design features studied in- clude: mix of conservation activities in tendered projects (auction scope effects); auction budget levels relative to bidder population size (auction scale effects); auction pricing rules (uniform versus discriminatory pricing); and endogeneity of bidder participation. Both weak and strong bidder responses to tender failure are explored for the case of endogeneity in participation. The results highlight the importance of a careful consideration of scale and scope issues and that policy- makers need to consider alternatives to currently used pay-as-bid or discrimina- tory pricing fromats. Averaging over scope variations, the uniform auction can deliver substantially higher budgetary efficiency compared to the discriminatory auction. This advantage is especially higher when bidder participation decisions are more sensitive to auction outcomes.	simulation	Atakelty Hailu;John Rolfe;Jill Windle;Romy Greiner	2010		10.1007/978-3-642-19890-8_16	eauction;combinatorial auction;generalized second-price auction;unique bid auction;vickrey–clarke–groves auction;common value auction;revenue equivalence;bid shading;auction theory;forward auction	EDA	-6.0699273901317845	-8.240764883382875	39179
f0b2d47f2c1b9b64561f9be30baa2580638283db	chemical structure representation for information exchange	site web;chemicals;intercambio informacion;cas;computer languages;lenguaje computadora;computer graphics;chemical abstracts service;computer graphic;standardisation;langage ordinateur;estructura quimica;chimie;echange information;information exchange;chemistry;computer language;quimica;chemical structure;sitio web;structure chimique;grafico computadora;infographie;information;web site	Information exchange is of primary importance in any scientific discipline but particularly so in such an information‐rich domain as chemistry. Chemists have developed a language of their own for representing information which is essentially graphical in nature: structure diagrams and reaction equations. Methods of converting this graphical language into a computer representation have been developed and efforts have been made to standardise such representations. This paper reports on these achievements and points out where further work has to be done.	information exchange	Thomas Engel;Johann Gasteiger	2002	Online Information Review	10.1108/14684520210432431	chemical industry;information exchange;information;computer science;artificial intelligence;cas registry number;chemical structure;computer graphics;standardization;algorithm	AI	-25.933336301736475	-2.0271259809342648	39205
e9066fd31db51c001b0fddc99c7f9b2a3484f425	resource coordination in single agent and multiagent systems	comas multiagent system resource coordination single agent systems intelligent multiagent system software agents cost benefit analysis prodigy planner;prodigy planner;multiagent system;cost benefit analysis multi agent systems software agents;software agent;resource management;intelligent multiagent system;resource coordination;software agents;multi agent systems;performance analysis;intelligent systems;comas multiagent system;intelligent agent;multiagent systems intelligent agent resource management cities and towns computer science educational institutions intelligent systems software agents performance analysis autonomous agents;cities and towns;computer science;autonomous agents;cost benefit analysis;single agent systems;multiagent systems	An intelligent multiagent system includes a number of software agents interacting to solve a problem. Various agents are responsible for planning different tasks. These tasks must be coordinated to solve complex problems. A number of reasons exist for which coordination among the agents is necessary, and numerous issues have to be tackled to achieve efficient coordination. The focus of this paper is resource coordination. An agent requests a resource from another agent when it does not have enough resources to construct a complete plan. We present a cost-benefit analysis that can be performed to determine if the requesting agent receives the requested resource. We present empirical results that demonstrate the relative goal satisfaction achieved in the PRODIGY planner with and without resource coordination. We have implemented a preliminary multiagent system called COMAS (CoOrdination in MultiAgent Systems) that implements resource coordination.	agent-based model;complex system;interaction;multi-agent system;software agent	Gifty Edwin;Michael T. Cox	2001		10.1109/ICTAI.2001.974444	simulation;computer science;knowledge management;artificial intelligence;software agent;multi-agent system	AI	-17.883002644698248	-9.83406940079872	39268
096e2d66eda4bae0cd2f788b6884b3c44ebd803c	decision making and fundamental matrix approach in process safety	stability;safety;process	The paper describes solving problem of constructing knowledge database of a decision making in process safety. It provides analyses of the requirements as well the analyses of the system incidents caused by specification, design and the implementation of the project. Main focus of this scientific paper is highlighted on practical stability problem and conditions for optimal performance of safe fault-tolerant controllers, I/O, engineering and pressure transmitters. Algorithm of decision making in process safety is developed and the system has been realized taking into account C# approach in Windows environment.		Djordje N. Dihovicni	2013	Int. J. Comput. Intell. Syst.	10.1080/18756891.2013.802871	stability;decision engineering;computer science;management science;process	DB	-9.374821200780326	-18.20629095692312	39269
bd05bc8ae9452d4185c65cccf51c21f98cdcdbd8	development of novel alternative chemistry processes for dielectric etch applications	electrical engineering and computer science;thesis	The removal of dielectric films in semiconductor processing relies almost exclusively on the use of perfluorocompounds (PFCs), which are suspected global warming agents. The two applications in semiconductor manufacture that account for the largest use and emissions of PFCs are the patterning of dielectric films and the cleaning of dielectric film plasma enhanced chemical vapor deposition (PECVD) chambers. The work discussed in the author's Ph.D. thesis was conducted as part of a project whose goal is to identify and develop novel replacement etchants for these applications. The focus of the author's Ph.D. thesis is the patterning application. The research discussed in this document constitutes a follow up to the author's M.S. thesis, which discussed the initial stages of this project. These stages consisted primarily of preliminary screening tests involving a class of chemistries which was expected to be promising from a process standpoint at an early point in the project. The work carried out subsequently covered a far greater scope of activities and included additional preliminary screening tests with chemistries that were not covered by the author's M.S. thesis as well as extensive concept-and-feasibility tests and subsequent process development efforts using several of the more promising chemistries in a dielectric wafer patterning application. Much of this experimental work had been carried out in collaboration with industrial partners belonging to the semiconductor manufacturer, equipment supplier, and gas supplier communities. These tests were carried out on process tools housed both within MTL's Integrated Circuits Laboratory and at an industrial location, namely Motorola Inc.'s Advanced Products Research and Development Laboratory (APRDL). The project to identify and develop alternative chemistries for dielectric film removal applications is continuing after the completion of the author's thesis, with subsequent studies that will build on the results of the work done to date.		Simon Martin Karecki	2000			engineering;engineering physics;chemical engineering;mechanical engineering	EDA	-12.703233986956562	-19.10709640968102	39364
9479d2f76f37cc1c7c41bb6a387e664bed14f142	human reasoning with negative defaults	human reasoning;negative defaults	This paper examines psychological data on human reasoning with sets of negative defaults. A negative default is a statement of the form: Xs are typically not Ys. While there is pragmatic motivation for chaining positive defaults, chaining negative defaults (concluding from, As are typically not Bs and Bs are typically Cs that As are typically not Cs) is far less reasonable. Default inheritance reasoners universally prohibit `negative chaining'. However, examination of the psychological plausibility of various con icting proof theories for default inheritance has demonstrated that some fundamental assumptions of the inheritance literature do not actually hold. This work has also revealed reasoning strategies which do describe human behaviors. In an e ort to de ne inheritance reasoners that are more predictive of human reasoning with defaults, it is important to attend to these ndings. This paper focuses on the fact that many people do in fact chain negative defaults. The paper identi es a group of subjects who consistently do so, and evaluates reasoning strategies which are predictive of the behavior of those subjects with respect to other `benchmark' problems that have been addressed in the literature. Corroboration is found for `most-path' reasoning.	benchmark (computing);default logic;naruto shippuden: clash of ninja revolution 3;open road tolling;plausibility structure;theory	Carl Vogel	1996		10.1007/3-540-61313-7_104	social psychology;of the form;default;mathematics;chaining;human behavior	AI	-13.975949370761851	3.5729363858644665	39382
aded83db7ada03f96bc0f7d103dfb7864acae1b4	the problem of retention	laws;regularity;induction;dispositional properties;prediction;explanation	A popular version of anti-Humeanism is one that views fundamental properties as being irreducibly dispositional in nature, and it is a view to which I am attracted. Proponents of this view typically object to Humean regularity theories of laws on the basis that they do not explain why our world is regular rather than chaotic from moment to moment. It is thought that, for this reason, Humeanism does not provide firm enough foundations for induction. However, in this paper I argue that it is far from clear how these anti-Humeans can themselves explain this regularity. This is because it is far from clear how they can explain why the entities in our world do not change their dispositional properties arbitrarily over time. This is a neglected problem, which I call the retention problem. In an attempt to solve this problem, several naturalistic explanations of retention are explored. Unfortunately, none of these explanations is free of problems, showing that dispositional forms of anti-Humeanism may not have as many advantages as some have assumed where the problem of induction is concerned.	anna karlin;cosmic;entity;irreducibility;our world;theory	Matthew Tugby	2016	Synthese	10.1007/s11229-016-1036-x	epistemology;mathematics	ML	-12.771271770226756	2.000866702100801	39395
1a0f4ac4b211d6d7d723aaf94d3043eea5de7165	on the formulation of performant sparql queries	optimisation;rdf store;optimization;sparql;heuristics;biomedical data;data integration	The combination of the flexibility of RDF and the expressiveness of SPARQL provides a powerful mechanism to model, integrate and query data. However, these properties also mean that it is nontrivial to write performant SPARQL queries. Indeed, it is quite easy to create queries that tax even the most optimised triple stores. Currently, application developers have little concrete guidance on how to write “good” queries. The goal of this paper is to begin to bridge this gap. It describes 5 heuristics that can be applied to create optimised queries. The heuristics are informed by formal results in the literature on the semantics and complexity of evaluating SPARQL queries, which ensures that queries following these rules can be optimised effectively by an underlying RDF store. Moreover, we empirically verify the efficacy of the heuristics using a set of openly available datasets and corresponding SPARQL queries developed by a large pharmacology data integration project. The experimental results show improvements in performance across 6 state–of–the–art RDF stores.	heuristic (computer science);linked data;mathematical optimization;named graph;requirement;resource description framework;sparql;spatial variability;tag cloud;triplestore	Antonis Loizou;Renzo Angles;Paul T. Groth	2015	J. Web Sem.	10.1016/j.websem.2014.11.003	named graph;computer science;sparql;data integration;heuristics;data mining;database;information retrieval;rdf schema	Web+IR	-33.1622583105995	3.858571282116633	39398
41fc78646b46fb985f85e36214392a4e9599adaf	symbolic expressions within a spatial algebra: unification and impact upon spatial reasoning	focusing;symbol manipulation;user interfaces computer graphics inference mechanisms symbol manipulation;database system;spatial reasoning;computer graphics;inference mechanisms;mobile robots;remotely operated vehicles;algebra navigation remotely operated vehicles mobile robots focusing;symbolic images;navigation;visual languages;algebra;spatial algebra;algebraic expressions;spatial relationships;algebraic expressions visual languages spatial algebra spatial reasoning symbolic images;user interfaces	"""Spatial reasoning in symbolic images requires means for identification of spatial relationships. In earlier work an algebra based on symbolic projections for manipulation and transformation of symbolic images has been defined. Although that symbolic algebra was quite powerful for manipulation of symbolic images, it did not include any means for spatial reasoning. With such a goal it was already clear at an early stage that the algebra had to be developed further. This work describes unification of algebraic expressions, which founds a powerful means for spatial reasoning. The paper demonstrates that the algebra constitutes a basis for a tool for spatial reasoning in symbolic images. L TntroductiQn In such systems as, for instance, navigation systems for autonomous or semi-autonomous vehicles, where digitized maps are used there is an obvious need for spatial reasoning. Hence, various means for spatial reasoning have been developed during the last few years and the interest in the area is still growing. Several application areas where techniques for spatialreasoning are necessary exist beside navigation. Among these can path planningbased on digitized map information be mentioned. Examples of knowledge basedmethods for spatial reasoning are e.g. [l], [2J and [3]. Generally, spatial reasoning concerns methods for identification of various types of spatial relationships among different objects in symbolic images, such as, for instance, digitized maps. The algebra, discussed here, is not just limited to these kind of images, however, as it can be applied to any kind of images. The technique that will be described here rests upon a """"symbolic algebra"""",whose basic theories are described by Jungert and Chang [4]. The fundamentals of the theories of that work concern the manipulation and transformation of symbols or objects in the image. The theories described here are a direct continuation of that previous work. As indicated above the main motive for the work has been to develop a means for spatial reasoning. However, the basic ideas of the algebra can be found in [5] and further extensions are described in [SI. So far, no direct work similar to this has been found in the literature. In, e.g. [6] , some relationship is found although here most cases are concemed with various types of grammars. Another work that is somewhat related is that by Allen [7]. In Allen's case, however, the work concerns temporal reasoning and the relations which are identified are of interval type and in one dimension. Nevertheless, there remains a relationship. Finally, [SI discusses problems which are related but only in terms of a structure that is hierarchical. The symbolic algebra, however, is more general since, for instance, quad-tree can be handled as well. The fundamentals of the algebra are described in section 2. An important aspect is unification, which is discussed in section 3. Section 4 and 5 discuss the consequences of overlapping objects and operator precedence, while 6 and 7 concern spatial reasoning and its foundations. Finally in section 8 there is a discussion about justification local to the so-called """"area in focus"""" for spatial reasoning. 2. Fundamentals of the algebra The basic structure in the algebraic expressions are the symbolic projections, originally described by Chang et al. [5] . A symbolic projection is a string of objects, which includes the relative positions of the objects along any of the coordinate axes. In the original version there were just two relational , i.e. """"less than"""" and """"equal to"""". Later it was clear that two operator were not enough and the number was expanded, see e.g. [ 9 ] . The number of operators in the symbolic algebra is three and except for the two in the original work only one extra was necessary; the extra one is called """"edge to edge with"""" and is symbolized with I. Hence, the I-operator denotes that two objects are situated edge-to-edge with each other. Projections of the objects take place along all coordinate axes. Hence, one string for each axis is built up. In the 2-D case the string corresponding to the x-axis is labeled with a U, and the the string corresponding to the y-axis is labeled with V. See, e.g. ( 1 ) and ( 2 ) in the next section. In [4] it was demonstrated that various classes of objects could be generalized. This was especially true for objects corresponding to the empty space, here called e-objects. A generalized e-object is a subobject of the full empty space, which is the space were arbitrary mobile objects are allowed to move freely. An e-object can have arbitrary shape and size. An important aspect of the objects is also their relative positions. Several laws are identified for the e-objects, including : i) they can be merged whenever they are edge-to-edge with each other or, ii) they can be split, where the split is either parallel to and orthogonal to their projected coordinate axes.e-objects are not the only type of generalized objects. Obstacles, in the case of path planning illustrated later in this paper are another type. Rules for manipulation of arbitrary object types are also identified in [4]. These rules are called object manipulation rules. In the object manipulation rules objects are split or merged in many ways which are similar to the laws for manipulation of the e-objects. The merge and split operations concern just 157 TH0277-4/89/0000/0157$1 .OO"""	algol 68;apache axis;autonomous robot;computer algebra system;continuation;linear algebra;map;motion planning;object type (object-oriented programming);optic axis of a crystal;order of operations;quadtree;regular expression;semiconductor industry;situated;spatial–temporal reasoning;string (computer science);theory;unification (computer science)	Erland Jungert	1989		10.1109/WVL.1989.77058	computer vision;discrete mathematics;computer science;theoretical computer science;symbolic data analysis;symbolic trajectory evaluation	AI	-21.647792978406056	3.820716155895711	39414
3aa201f44e4c0208cfbd24aed2d1313a25763a95	a probabilistic model for sensor validation	probabilistic model;knowledge base	The validation of data from sensors has be­ come an important issue in the operation and control of modern industrial plants. One ap­ proach is to use know ledge based techniques to detect inconsistencies in measured data. This article presents a probabilistic model for the detection of such inconsistencies. Based on probability propagation, this method is able to find the existence of a possible fault among the set of sensors. That is, if an er­ ror exists, many sensors present an apparent fault due to the propagation from the sen:. sor(s) with a real fault. So the fault detection mechanism can only tell if a sensor has a po ­ tentwl fault, but it can not tell if the fault is real or apparent. So the central problem is to develop a theory, and then an algorithm, for distinguishing real and apparent faults, given that one or more sensors can fail at the same time. This article then, presents an approach based on two levels: (i) probabilistic reason­ ing, to detect a potential fault, and (ii) con­ straint management, to distinguish the real fault from the apparent. ones. The proposed approach is exemplified by applying it to a power plant model.	algorithm;fault detection and isolation;mir:ror;sensor;software propagation;statistical model	Pablo H. Ibargüengoytia;Luis Enrique Sucar;Sunil Vadera	1996			statistical model;knowledge base;fault coverage;computer science;artificial intelligence;stuck-at fault;machine learning;data mining;fault model;mathematics;statistics	Robotics	-19.74741055719834	-2.574048447243924	39419
1c27c9a13d62e53928cc8e35829e348e12e8f7fa	an introduction to ai course with guide robot programming assignments	course design;artificial intelligent;robots;materials design;artificial intelligence;robot programming	In this paper we describe a collection of course materials designed to be used in an undergraduate introduction to artificial intelligence (AI) course. These materials include three programming assignments, each touching upon core AI topics, which require that the students build the main functionalities of a guide robot. These assignments were carefully designed to allow the same solution to work both with a robot simulator and an inexpensive web-cam as well as with real robots. An overview of the course and the assignments is given along with references to online versions of the resources developed to teach the course.	artificial intelligence;robot;webcam	Nik Swoboda;Juan Bekios-Calfa;Luis Baumela;Javier de Lope	2011		10.1145/1953163.1953231	robot;simulation;computer science;artificial intelligence;software engineering	AI	-33.42387647573004	-21.65241482067265	39475
bbfcf96aa519888960d26120f26c0cbb3d3a51a9	sampling and updating higher order beliefs in decision-theoretic bargaining with finite interactive epistemologies	belief sampling;interactive epistemology;higher order beliefs;bilateral bargaining;decision theory	In this paper we study the sequential strategic interactive setting of bilateral, two-stage, seller-offers bargaining under uncertainty. We model the epistemology of the problem in a finite interactive decision-theoretic framework and solve it for three types of agents of successively increasing (epistemological) sophistication (i.e. capacity to represent and reason with higher orders of beliefs). We relax typical common knowledge assumptions, which, if made, would be sufficient to imply the existence of a, possibly unique, game-theoretic equilibrium solution. We observe and characterize a systematic monotonic relationship between an agent’s beliefs and optimal behavior under a particular moment-based ordering of its beliefs. Based on this characterization, we present the spread-accumulatetechnique of sampling an agent’s higher order belief by generating “evenly dispersed” beliefs for which we (pre)compute offline solutions. Higher order prior belief identification is then approximated to arbitrary precision by identifying a (previously solved) belief “closest” to the true belief. These methods immediately suggest a mechanism for achieving a balance between efficiency and the quality of the approximation – either by generating a large number of offline solutions or by allowing the agent to search online for a “closer” belief in the vicinity of best current solution.	agent-based model;approximation algorithm;arbitrary-precision arithmetic;autonomous robot;bilateral filter;game theory;interaction;multi-agent system;non-monotonic logic;online and offline;problem domain;sampling (signal processing)	Paul Varkey;Piotr J. Gmytrasiewicz	2011			decision theory;knowledge management;management science	AI	-8.474304852717346	-3.895123399185636	39484
6fe6fb42d40953a966be78f63a7f6ea9eb449057	on the communication complexity of multilateral trading: extended report	article accepte pour publication ou publie;multiagent resource allocation;social welfare;communication complexity;complexity;universiteitsbibliotheek;autonomous agent;negotiation	We study the complexity of a multilateral negotiation framework, where autonomous agents agree on a sequence of deals to exchange sets of discrete resources in order to both further their own goals and to achieve a distribution of resources that is socially optimal. When analysing such a framework, we can distinguish different aspects of complexity: How many deals are required to reach an optimal allocation of resources? How many communicative exchanges are required to agree on one such deal? How complex a communication language do we require? And finally, how complex is the reasoning task faced by each agent?	agent-based model;algorithm;autonomous robot;bilateral filter;communication complexity;computation;computational complexity theory;converge;experiment;heuristic (computer science);longest path problem;mathematical optimization;maximal set;money;multi-agent system;shortest path problem;system on a chip;systems theory;technological convergence	Ulrich Endriss;Nicolas Maudet	2005	Autonomous Agents and Multi-Agent Systems	10.1007/s10458-005-1080-2	complexity;computer science;knowledge management;artificial intelligence;autonomous agent;social welfare;communication complexity;management science;negotiation	AI	-10.71945579673267	-5.931165027868971	39485
d1c30d1d94479e6e5ef71d538aca16d6c9fd465e	fuzzy rule-based bayesian reasoning approach for prioritization of failures in fmea	belief networks;benchmarking technique;fuzzy reasoning;risk analysis;maritime risk analysis bayesian reasoning fmea fuzzy rule base;fuzzy control;rule based;fmea;bayesian methods;inference mechanisms;reliability theory belief networks fuzzy set theory inference mechanisms;testing;failure mode;fuzzy set theory;reliability theory;maritime risk analysis;evidential reasoning;fuzzy logic;fuzzy rule based bayesian reasoning approach;failure analysis;bayesian reasoning;benchmarking technique fuzzy rule based bayesian reasoning approach failure mode and effects analysis conventional fuzzy logic collision risk;fuzzy rule base;sensitivity analysis;aggregates;failure mode and effect analysis;collision risk;production systems;fuzzy reasoning bayesian methods fuzzy logic failure analysis fuzzy control fuzzy systems production systems risk analysis aggregates testing;failure mode and effects analysis;fuzzy systems;conventional fuzzy logic;knowledge base	This paper presents a novel, efficient fuzzy rule-based Bayesian reasoning (FuRBaR) approach for prioritizing failures in failure mode and effects analysis (FMEA). The technique is specifically intended to deal with some of the drawbacks concerning the use of conventional fuzzy logic (i.e. rule-based) methods in FMEA. In the proposed approach, subjective belief degrees are assigned to the consequent part of the rules to model the incompleteness encountered in establishing the knowledge base. A Bayesian reasoning mechanism is then used to aggregate all relevant rules for assessing and prioritizing potential failure modes. A series of case studies of collision risk between a floating, production, storage, and off loading (FPSO) system and a shuttle tanker caused by technical failure during tandem off loading operation is used to illustrate the application of the proposed model. The reliability of the new approach is tested by using a benchmarking technique (with a well-established fuzzy rule-based evidential reasoning method), and a sensitivity analysis of failure priority values.	aggregate data;failure cause;failure mode and effects analysis;fuzzy logic;fuzzy rule;knowledge base;logic programming;technical failure	Zaili Yang;Stephen Bonsall;Zhongjing Wang	2008	IEEE Transactions on Reliability	10.1109/TR.2008.928208	reliability engineering;engineering;machine learning;data mining;mathematics;failure mode and effects analysis;fuzzy control system	SE	-7.838697836320714	-16.93975891220197	39498
8111a7abafa95748db5d7420c9149e8b8e43ad45	modelling of medical diagnostic knowledge and reasoning in dedex expert system	expert system		expert system	Ivan H. Chernev;Danail Dochev	1990				AI	-28.579334807449783	-7.743251661329201	39504
c33096871760ca047ee2939300a1b644e3d05599	two-dimensional approximate godunov scheme and what it means for continuum pedestrian flow models		An efficient simulation method for two-dimensional continuum pedestrian flow models is introduced. It is a two-dimensional adaptation of the Godunov scheme for one-dimensional road traffic flow models. It is further extended to include multiple classes, representing groups of pedestrians with different behavior, origin, and destination. The method can be applied to continuum pedestrian flow models in a wide range of applications from the design of train stations and other travel hubs to the study of crowd behavior and safety at sports, religious, and cultural events. The combination of the efficient simulation method with continuum models enables the user to get simulation results much quicker than before. This opens doors to real-time crowd control and to more advanced optimization of planning and control. Test results show the importance of choosing appropriate numerical settings, including grid cell and time step size for realistic simulation results.	godunov's scheme;triune continuum paradigm	Femke van Wageningen-Kessels;Winnie Daamen;Serge P. Hoogendoorn	2018	Transportation Science	10.1287/trsc.2017.0793	grid;mathematics;crowd psychology;mathematical optimization;doors;pedestrian;self-organization;microscopic traffic flow model;crowd simulation;godunov's scheme	Logic	-18.449665866859014	-22.179658711642624	39510
70c516ef6d670e869a1a8045fff09e3bddf66960	farsightedly stable networks	institutional repositories;fedora;vital;vtls;ils	We propose a new concept, the pairwise farsightedly stable set, in order to predict which networks may be formed among farsighted players. A set of networks G is pairwise farsightedly stable (i) if all possible pairwise deviations from any network g ∈ G to a network outside G are deterred by the threat of ending worse off or equally well off, (ii) if there exists a farsightedly improving path from any network outside the set leading to some network in the set, and (iii) if there is no proper subset of G satisfying (i) and (ii). We show that a non-empty pairwise farsightedly stable set always exists and we provide a full characterization of unique pairwise farsightedly stable sets of networks. Contrary to other pairwise concepts, pairwise farsighted stability yields a Pareto dominating network, if it exists, as the unique outcome. Finally, we study the relationship between pairwise farsighted stability and other concepts such as the largest consistent set. JEL classification: A14, C70, D20.	ana (programming language);battery eliminator circuit;bellman equation;existential quantification;linear algebra;louvain modularity;national fund for scientific research;pareto efficiency	P. Jean-Jacques Herings;Ana Mauleon;Vincent Vannetelbosch	2009	Games and Economic Behavior	10.1016/j.geb.2008.12.009	embedded system;architectural engineering;transport engineering	ML	-5.980230826831277	0.7295792915535035	39524
c7349b93330259a3cff58bddf2cf559668469c81	antipattern comprehension: an empirical evaluation	g400 computing;qa76 computer software	Comprehension of justifications is known to be difficult for even experienced ontology engineers, and much more so for other stakeholders. In this paper, we present two methods for displaying justifications using concept diagrams: using multiple concept diagrams to represent the justification (one diagram for each axiom); and using a merged concept diagram to represent all axioms in the justification. We performed an empirical evaluation of both methods along with a textual representation of the justification using Protégé. The results were that participants could both more accurately and more quickly identify an incoherence when using merged diagrams than using multiple diagrams or Protégé statements.	anti-pattern;concept map;diagram;list comprehension;protégé;web ontology language	Tie Hou;Peter Chapman;Andrew Blake	2016		10.3233/978-1-61499-660-6-211	computer science;artificial intelligence;theoretical computer science;algorithm	HCI	-29.53862275423804	-4.074064882996658	39528
1158ae0982e0c960089c5ce250597025cbe92241	rehabilitation supervision using wireless sensor networks	wireless sensor networks protocols base stations medical services real time systems wireless communication acceleration;protocols;rehabilitation;wireless sensor network;biomedical telemetry;communication protocol;communication protocols wireless sensor networks rehabilitation;wireless sensor networks biomedical telemetry protocols;wireless sensor networks;communication protocols;communication protocol wireless sensor networks medical applications sensor nodes interference problems high fidelity rehabilitation supervision low cost rehabilitation monitoring systems	Wireless sensor networks are becoming a topic of great interest in medical applications generating a large amount of work in medical and computer research communities. In this line, several solutions have been proposed to provide unobtrusive, flexible and low cost systems for patient supervision. However, existing solutions can not be used in rehabilitation supervision because of the specific characteristics of this application. Indeed, new major challenges arise from the fact that each sensor node needs to continuously stream large volumes of data at a high rate to enable doctors to extract clinically relevant information. In addition, the placement of several adjacent sensor nodes on the body may cause serious interferences problems. In this work, we describe and demonstrate our wireless sensor network prototype for high-fidelity rehabilitation supervision. Our demonstration allows attendees to experience the potential of wireless sensor networks for enabling flexible and low cost rehabilitation monitoring systems. In order to alleviate transmission problems, we develop a novel communication protocol that meets the clinical requirements of rehabilitation supervision in terms of data quality and data rate.	communications protocol;data quality;data rate units;information system;laptop;personal digital assistant;prototype;requirement;sensor node;sensor web;uncompressed video;unobtrusive javascript	Abdelkrim Hadjidj;Abdelmadjid Bouabdallah;Yacine Challal	2011	2011 IEEE International Symposium on a World of Wireless, Mobile and Multimedia Networks	10.1109/WoWMoM.2011.5986123	sensor web;embedded system;communications protocol;wireless sensor network;telecommunications;computer science;wireless network;key distribution in wireless sensor networks;wi-fi array;fixed wireless;mobile wireless sensor network;computer network	Mobile	-23.02093235756316	0.6394366165379077	39529
e10f88cf31b5fc06ff32996250f0be6949b02b0f	efficient multi-agent coordination using resource-aware junction trees	variable elimination;dcop;gdl;multiagent coordination;junction tree;multi agent coordination;heuristic algorithm	In this paper we address efficient decentralised coordination for cooperative multi-agent systems (framed as DCOPs) by taking into account the communication and computational resources of the system. We focus on techniques that exploit structural independence among agentsu0027 actions to provide optimal solutions to the coordination problem, and, in particular, we use the Generalized Distributed Law (GDL) algorithm. In this settings, we propose a novel resource aware heuristic to build junction trees and to schedule GDL computations across the agents. Our approach aims at minimising directly the total running time of the coordination process, rather than the theoretical complexity of the computation, by considering computational and communication capabilities of agents.	multi-agent system	Nicolas Stefanovitch;Alessandro Farinelli;Alex Rogers;Nicholas R. Jennings	2010		10.1145/1838206.1838408	heuristic;variable elimination;simulation;computer science;theoretical computer science;distributed computing	NLP	-11.247356167179557	-6.075094550396841	39534
c06cc8e29cfa844d07e3029e69a7d601bf419c5e	its planning methodology for chinese cities and its evaluation model	its planning;town and country planning;cities and towns process planning strategic planning research and development urban planning artificial neural networks intelligent transportation systems artificial intelligence investments road transportation;neural nets;evaluation method;automated highways;satisfiability;chinese cities;artificial neural network its planning chinese cities evaluation model;it evaluation;evaluation model;artificial neural network;town and country planning automated highways neural nets	ITS planning methodology (IPM) is significant to guide the ITS research & development (R&D) strategically and systematically. This paper develops a general IPM and the ITS strategic objectives for Chinese cities, which creates a methodological framework to plan the urban ITS. During ITS planning, the ITS evaluation is a key component to make decisions. Based on the IPM and its objectives, for making up the deficiency of conventional evaluation methods, an ITS evaluation model by artificial neural network is built, and its feasibility has been proved by case study. The result shown by the planning and simulation is satisfied. It is practical and convenient to apply this model in the factual ITS planning	angular defect;artificial neural network;chinese room;simulation	Ailing Huang;Jinsheng Shen;Wei Guan	2006	2006 IEEE Intelligent Transportation Systems Conference	10.1109/ITSC.2006.1707373	engineering;operations management;transport engineering;management science;transportation planning	Robotics	-9.6169916263001	-20.33352313421589	39578
c91652efd294cc86faf404d27d9b5983be42854c	multi-agent programming contest 2017	multi-agent systems;programming;competition;68t42	We present the twelfth edition of the Multi-Agent Programming Contest (https://multiagentcontest.org), an annual, community-serving competition that attracts groups from all over the world. Our contest facilitates comparison of multi-agent systems and provides a concrete problem that is interesting in itself and well-suited to be tackled in educational environments. This time, seven teams competed using strictly agent-based as well as traditional programming approaches.	agent-based model;multi-agent programming contest;multi-agent system	Tobias Ahlbrecht;Jürgen Dix;Niklas Fiekas	2018	Annals of Mathematics and Artificial Intelligence	10.1007/s10472-018-9594-x		AI	-30.80982685288453	-19.69719901728124	39595
244a4c16e70cd0cb20475f124ddf3feebc0b767d	automatic problem generation in constraint-based tutors	domain model;sql tutor;conference contributions published;algorithm performance;ordered set;sql;generacion automatica;base connaissance;ensemble ordonne;constraint based tutor;automatic generation;conference contribution paper in published proceedings;domain knowledge;generation automatique;resultado algoritmo;student modelling;performance algorithme;base conocimiento;learning artificial intelligence;student performance;conjunto ordenado;knowledge base;apprentissage intelligence artificielle	Constraint-Based Modelling (CBM) is a student modelling technique that is rapidly maturing. We have implemented several tutors using CBM and demonstrated its suitability to open-ended domains in particular. A problem with open-ended and complex domain models is their large size, necessitating a comprehensive problem set in order to provide sufficient exercises for extended learning sessions. We have addressed this issue by developing an algorithm that automatically generates new problems directly from the domain knowledge base. We present the algorithm and compare students’ performance with generated problems to those using a teacher-authored problem set, and show the performance of the generated problem set to be superior.	algorithm;constraint logic programming;knowledge base;nonlinear gameplay	Brent Martin;Antonija Mitrovic	2002		10.1007/3-540-47987-2_42	knowledge base;sql;simulation;computer science;artificial intelligence;machine learning;domain model;database;mathematics;domain knowledge;algorithm	AI	-25.384444805494667	-3.6483208599230728	39599
21fe13e5ebb17f17740e4543b1c518ee378809ee	revisiting generic bases of association rules	extraction information;association statistique;analisis datos;information extraction;redundancia;systeme aide decision;digitizing;metodo formal;conceptual analysis;methode formelle;statistical association;almacen dato;sistema ayuda decision;prise decision;numerisation;data mining;analisis conceptual;formal method;data analysis;decision support system;asociacion estadistica;regle association;redundancy;regla asociacion;association rule;fouille donnee;decision making process;decouverte connaissance;inferencia;numerizacion;descubrimiento conocimiento;analyse donnee;entrepot donnee;analyse conceptuelle;data warehouse;toma decision;busca dato;extraccion informacion;inference;redondance;formal concept analysis;knowledge discovery	As a side effect of unprecedented amount of digitization of data, classical retrieval tools found themselves unable to go further beyond the tip of the Iceberg. Data Mining in conjunction with the Formal Concept Analysis, is a clear promise to furnish adequate tools to do so and specially to be able to derive concise generic and easy understandable bases of ”hidden” knowledge, that can be reliable in a decision making process. In this paper, we propose to revisit the notion of association rule redundancy and to present sound inference axioms for deriving all association rules from generic bases of association rules.	algorithm;association rule learning;data mining;formal concept analysis;graphical user interface;prototype	Sadok Ben Yahia;Engelbert Mephu Nguifo	2004		10.1007/978-3-540-30076-2_6	association;decision-making;association rule learning;decision support system;computer science;formal concept analysis;artificial intelligence;data warehouse;data mining;redundancy;data analysis;information extraction;algorithm	ML	-23.305665678544283	-0.8350360115488614	39709
4db1a7815a8a10d67e9875f7bf5d34f67a748916	la maximisation du bien-être utilitaire des sociétés d'agents	multiagent system;negociation;resource allocation;emergent phenomenon;intelligence artificielle;asignacion optima;data privacy;negociacion;algorithme reparti;bargaining;allocation optimale;preferencia;artificial intelligence;algoritmo repartido;preference;asignacion recurso;inteligencia artificial;allocation ressource;sistema multiagente;optimal allocation;distributed algorithm;confidentialite donnee;negotiation;systeme multiagent	In this study, we consider the resource allocation problem within an entity set. Centralized approaches that are often used to solve such allocation problems h ave several important drawbacks. For instance, they require that the entities publish their ow n preferences, which compromise the privacy of these data. At the opposite, the provided dece ntralized appraoch is more flexible. This approach, which is based on negotiations among age nts, can be applied with any kind of contact network and any range for the utility values. For this p urpose, we study various agent behaviors in order to identify which one leads to the optimal re source allocation required, thanks to an emergent phenomenon. MOTS-CLÉS :allocation de ressources, algorithme distribué, négociation, émergence .	centralized computing;digital entertainment content ecosystem;emergence;entity;linear algebra	Antoine Nongaillard;Philippe Mathieu;Brigitte Jaumard	2009	Revue d'Intelligence Artificielle	10.3166/ria.23.651-672	simulation;engineering;artificial intelligence;operations research	ECom	-11.642571234669104	-6.731660195493103	39728
39cbd546c40e12645e879bd8f2c008a37f6364fa	fuzzy multiple criteria decision making approach to assess the project quality management in project		Project quality management is all of the processes and activities needed to determine and achieve project quality. It includes the processes required to ensure that the project will satisfy the needs for which it was undertaken. Based on the identified evaluation criteria, a hierarchical structure of three dimensions and fifteen criteria is constructed, and a systematic approach with fuzzy ANP (FANP) was employed to assess the relative importance rates and rankings of these criteria. Discussions for the results are made and a brief conclusion is proposed. Therefore, the purpose of this paper is to evaluation project quality management in project. The results found that there were interactive relations between all the criteria, where the dimension of “Quality planning” was the most influential dimensions; Furthermore, criteria “Project management plan”, “Project Scope”, and “Quality management plan” have the higher influences among each dimension, so we suggest to consider them as the major steps to promote the quality of project management.	fuzzy logic;trusted computer system evaluation criteria	Yao-Feng Chang;Hiroaki Ishii	2013		10.1016/j.procs.2013.09.176	basis of estimate;project management;quality policy;knowledge management;management science;project management triangle;schedule;risk management plan;project portfolio management	SE	-5.719546591792088	-17.671903800680003	39737
aaedebcac33668e8787fe946fbca4f265ab2f1e4	editor's foreword		"""The scope of the topic """"algorithms"""" has been eminently expanded over the past two decades. Today it includes almost everything concerning how we should act to achieve any kind of goal (scientific, industrial, economic or whatever) and is even losing the connection to computers and/or software. The new open access journal, Algorithms (ISSN 1999-4893), has an obvious mission of promoting original research of this new world of algorithms. We are very proud of hereby publishing its inaugural issue. Algorithms shall cover traditional areas like the design and complexity analysis of algorithms, approximation algorithms, computational geometry, cryptography, data structures and data compression, databases, information retrieval, distributed and parallel computation, graph algorithms, on-line computation and scheduling. More contemporary areas like algorithmic game theory, algorithmic mechanical design, Internet algorithms and quantum computation are also included, as are aspects of discrete mathematics like graph theory, number theory and random structures. Applications such as bioinformatics, economics and finance are also important. These are only examples and the world of discrete algorithms is almost limitless. Algorithms has three features: first, it is an Open Access journal. Open access publishing, supported by authors or their institutions, is also much less costly for scientists who are readers and authors of journals. Papers can be rapidly published and freely accessed by readers. Secondly, submission of application-oriented work, such as experimental analysis of algorithms and case studies of real-world applications, is highly recommended. If appropriate, source codes can be included as a part of the paper or as supplementary materials and can be deposited by the publisher. Finally, considering the rapid expansion of our fields, we also welcome survey papers and proposals (guest-editorship) for special issues targeting emerging topics. We are looking for your enthusiastic contributions: it is you who promote this new journal and shall hopefully make it a top-ranking forum for our community."""	algorithmic game theory;analysis of algorithms;approximation algorithm;bioinformatics;code;computation;computational geometry;computer;cryptography;data compression;data structure;database;discrete mathematics;graph theory;information retrieval;international standard serial number;online and offline;parallel computing;quantum computing;scheduling (computing)	Kazuo Iwama	2008	Algorithms	10.3390/a1010001		Theory	-14.156477544832216	-2.708699033762025	39797
7a9e18fb93c69e387c20943dbbd552fb94952c9c	non-conventional computing paradigms	non-conventional computing paradigm	The conventional computing paradigms are usually two: the symbolic representational one and the connectionist (or mechanistic) approach. The first one is dominant since the Christening of Artificial Intelligence in the Summer of 1956. This paradigm assumes that everything that has to be computed needs previously to be represented in terms of data structures and inferential schemes, including algorithms and implementation programs. So, all the information needs to be explicit from the beginning in a declarative manner. The second paradigm, usually known as connectionist, includes the field of Artificial Neural Networks, and other biologically inspired approaches. In essence the first paradigm is related to General Purpose von Neumann Architecture, while the second one is related to Special Purpose Machines in which the control is explicit in the specific electronic circuit that embodies each information processing machine. In addition to these two dominants paradigms, there are other new approaches to the task of computation, not so well established, but in the brainstorming frontier of the science and engineering. These new approaches include Quantum Computation, Membrane Computation, Evolutionary Algorithms and many other Conceptual Proposals still far away from feasible and competitive implementations. This special issue of Natural Computing deals with some of these new paradigms. The articles are extended versions of papers selected from the second International Work Conference on the Interplay between Natural and Artificial Computation (IWINAC) held in La Manga del Mar Menor (Spain) during June 2007.	artificial intelligence;artificial neural network;computation;connectionism;data structure;declarative programming;electronic circuit;evolutionary algorithm;inferential theory of learning;information needs;information processing;linear algebra;natural computing;neural network software;programming paradigm;von neumann architecture	José Manuel Ferrández;José Mira Mira	2009	Natural Computing	10.1007/s11047-009-9139-7	artificial intelligence;mathematics;machine learning;von neumann architecture;computation;information needs;evolutionary algorithm;artificial neural network;information processing;natural computing;data structure	DB	-26.423654115502007	-15.645222900802855	39804
9f6e35ea943cbed22dc64baf83cd5ed34a8eb1b5	a survey on team strategies in robot soccer: team strategies and role description	team strategy;ownership zone;mirosot;robot soccer;role description	This survey paper starts with a basic explanation about robot soccer and its systems, then will focus on the strategies that have been used by previous researchers. There is a time-line of described robot soccer strategies, which will show the trend of strategies and technologies. The basic algorithm for each robot, that is described here, morphs from just simple mechanical maneuvering strategies to biologically inspired strategies. These strategies are adapted from many realms. The realm of educational psychology, produced reinforcement learning and Q-learning, commerce produced concepts of market-driven economy, engineering with its potential field, AI with its petri-nets, neural network and fuzzy logic. Even insect and fish were simulated in PSO and have been adapted into robot soccer. All these strategies are surveyed in this paper. Another aspect surveyed here is the vision system trend that is shifting from global vision, to local omni-directional vision, to front-facing local vision, which shows the evolution is towards biologically inspired robot soccer agent, the human soccer player.	algorithm;artificial neural network;cross-reference;experiment;fuzzy logic;on-board data handling;parabolic antenna;particle swarm optimization;petri net;power supply;q-learning;realms;reinforcement learning;robot;simulation;stereopsis;timeline	Sivadev Nadarajah;Kenneth Sundaraj	2011	Artificial Intelligence Review	10.1007/s10462-011-9284-0	simulation;artificial intelligence;multimedia	AI	-31.196227563155112	-18.693327479627165	39813
dd9d465ba7f09d387987260a501d37f4fd4b481f	when is the boston mechanism strategy-proof?		Kumano (2013) is the first to investigate the Boston school choice mechanism (BOSM) under restricted priority domains. This paper strengthens and extends his result and shows that the BOSM is strategy-proof, if and only if it is fair, if and only if it is equivalent to the student-optimal stable mechanism (SOSM), and if and only if the number of total seats at any two schools exceeds the number of students.		Yajing Chen	2014	Mathematical Social Sciences	10.1016/j.mathsocsci.2014.03.001	mathematics;welfare economics;school choice;if and only if	AI	-6.473210977315163	-3.5428506482413593	39839
d117e71fadf042f09593f4b8094ba3af2fb485bd	on a- and b-theoretic elements of branching spacetimes	laws of nature;indeterminism;branch attrition;a series;b series;determinism indeterminism;physics;open future;branching time;c series;supertime;direction of time;passage of time	This paper assesses branching spacetime theories in light of metaphysical considerations concerning time. I present the A, B, and C series in terms of the temporal structure they impose on sets of events, and raise problems for two elements of extant branching spacetime theories—McCall’s ‘branch attrition’, and the ‘no backward branching’ feature of Belnap’s ‘branching space–time’—in terms of their respective A- and B-theoretic nature. I argue that McCall’s presentation of branch attrition can only be coherently formulated on a model with at least two temporal dimensions, and that this results in severing the link between branch attrition and the flow of time. I argue that ‘no backward branching’ prohibits Belnap’s theory from capturing the modal content of indeterministic physical theories, and results in it ascribing to the world a time-asymmetric modal structure that lacks physical justification.	attrition (website);biochemical systems theory;information-theoretic death;modal logic;theory	Matt Farr	2011	Synthese	10.1007/s11229-011-0046-y	calculus;mathematics;natural law	AI	-29.810663747953708	-13.733676266702364	39880
ece9714da1852ac50a9a2a01f144d47a74c2f947	a knowledge distribution model to support an author in narrative creation	knowledge flow;narrative creation;knowledge distribution;knowledge structure;authoring tool	Adjusting the knowledge of characters and the reader is a critical task for an author in narrative creation. Throughout a narrative, both characters and the reader experience events according to their own timelines and perspectives. They interpret information accumulated through their experience and update knowledge to the narrative-world which the author constructed. In this paper, we present a Knowledge Distribution Model which supports an author in finely controlling the knowledge of characters and the reader. Within the model, the Knowledge Structure is constructed by connecting event, information, and knowledge. The Knowledge State is evaluated as the degree of belief under the knowledge structure. We adopted a probabilistic reasoning model to calculate the knowledge state. The change in knowledge state, defined as Knowledge Flow, is visually presented to the author. We designed a GUI prototype to implement the proposed modeling process, and demonstrated the knowledge flow with an actual cinematic narrative.		Hochang Kwon;Sukhwan Jung;Hyuk Tae Kwon;Wan Chul Yoon	2014		10.1007/978-3-319-07863-2_49	natural language processing;computer science;knowledge management;artificial intelligence;body of knowledge;knowledge-based systems;procedural knowledge;knowledge extraction;personal knowledge management;domain knowledge	NLP	-31.51002119408396	-6.564431187924168	39925
76d6cfc7afb77252b3bec6a3134899ff7499ea95	achieving agent coordination via distributed preferences	stated preference;agent based;market share;software agent;utility function;it value;control system;fuel economy;agent based system;computer aided manufacturing;contract management;artificial intelligence;value function;agent coordination;concurrent engineering;partial order;mathematics computers information science management law miscellaneous	Agent-based systems provide hope for solving a wide variety of distributed problems. One key aspect of agentbased system is coordinating agent actions to achieve coherent behavior. For example, in concurrent engineering (CE), it is necessary to ensure that the individual decision made by constituents in a design organization achieve overall organizational objectives (e.g., increase market share), while still allowing individuals to exploit their expertise. We believe CE is representative of many multiagent problems, in that agent coordination must include facilities to support both solving a hierarchically decomposed problem, e.g., the contract net (Davis & Smith 1983), and interactions among peers (Bahler et al. 1995) as well. One method to support problem decomposition is through task subcontracting (Davis & Smith, 1983). The process of subcontracting creates a hierarchical, decisionmaking organization. Coordination is accomplished by allowing general contractors, who have a global perspective, to provide direction to subcontractors, who have local expertise. We believe that it is both practical and desirable to direct a subcontractor’s actions by explicitly stating a preference structure that the agent must follow. Just as any contract describes a set of constraints that must be met for the contract to be fulfilled, a contract should include a preference structure that must be followed by a subcontractor in order to fulfill its obligations. Specifying a preference structure for a subcontractor does not require the general contractor to reveal all of its preferential knowledge to the subcontractor, only the subset of preferences that rank the implementation domain of the contracted subtask need be specified. We are developing a concurrent-engineering tool, ACME (D’Ambrosio, Darr, & Birmingham 1996), which provides a framework for coordinating design agents based on contracting constraints and preferences among agents. Agent preferences are formally represented using a form of a utility function referred to as an imprecise multi-attribute value function. This function has the desirable property that the amount of work required to construct the function is significantly less than that normally associated with defining a multi-attribute utility function. Consider the following example related to the design of a powertrain control system for an automobile. The project leader establishes contracts with several agents, including an electrical-system agent, and a software-development agent. The project leader’s preferences are represented by a value function based on the component costs of the powertrain controller and the expected fuel economy. In general, these preferences provide only a partial order on a subordinate’s decisions, and the subordinate is free to exploit its own expertise (preferences) in choosing among alternatives for which the supervisor is indifferent to. In this example, the electrical system agent is responsible for selecting the necessary electrical components. This agent is primarily concerned with minimizing component costs, and the agent specifies an appropriate value function to represents its preferences. Since the contract between the project leader and the electrical agent includes the project leader’s preferences, the electrical agent’s decision making is not based on its value function alone, but on a lexicographic value function, where the first and most significant attribute is the value assigned by the supervisor’s value function. Given that the supervisor’s value function is based on fuel economy as well as cost, the electrical agent decisions will be made in a manner consistent with global preferences, as will all of the decisions made by the other agents in the design team. The second attribute in the electrical agent’s lexicographic value function is the value assigned by a group value function, that contains an attribute for the value assigned by each member of the design team, e.g., the electrical agent and the software agent. The group value function creates the necessary relationship among peers to ensure that the value of composite decisions is maximized in terms of the peer’s stated preferences.	agent-based model;bellman equation;coherence (physics);contract net protocol;control system;electronic component;exploit (computer security);interaction;lexicographical order;smith–volterra–cantor set;software agent;uncore;utility	Joseph G. D'Ambrosio;William P. Birmingham	1996			partially ordered set;market share;contract management;simulation;computer science;knowledge management;control system;artificial intelligence;software agent;bellman equation;concurrent engineering	AI	-12.302459012981663	-7.0772625080753	40068
495b9cb524b8312187bac3164fcbe4edbec0c266	reliability model construction for complex system based on common cause failure network		A new construction method of system reliability was proposed in this paper based on network and relevant failure. Taking the component units as the nodes and the interaction relationships between the nodes as the side lines, a new directional network reliability model with certain network topology characteristics was constructed. It can indicate the complex topology relationship, interactionmechanism, and the transmissionmechanism of failure affect betweenmechanical integration and electrical integration of system components. Compared with the traditional research methods, the relevant failure was considered during this process. Through the application of the fault data in the bogie system of high-speed train, it was shown that a new network reliability model which considered the relevant failure can be constructed by the method proposed in this paper and the result can bemore accurate, especially for the complex mechanical and electrical integration systems.		Lijie Li;Limin Jia;Yanhui Wang	2014	Adv. in MM	10.1155/2014/318028	reliability engineering;complex system;artificial intelligence;reliability (computer networking);computer science;network topology;pattern recognition;transmission (mechanics)	DB	-8.551828124633419	-17.04987572188696	40075
a88b57395f5c1db36b853115880a92d6409ba71d	an ontological analysis of diagnostic assertions in electronic healthcare records		We present a comparative analysis of two sets of Referent Tracking Tuples (RTT), which each author of this paper crafted independently from the other and which are about the same portion of reality that one could assume to be described faithfully through registered diagnoses in the problem list of an electronic healthcare record system. The analysis thereby focused on (1) the choice of particulars that each of the authors deemed necessary and sufficient for an accurate description, (2) what these particulars are instances of, (3) how they relate to each other, and (4) the motivations of each author for the choices made. It was found that despite the large variety in RTTs crafted, there was wide, though not total, agreement about the appropriateness of the choices made. Disagreements arose from various issues such as potential lack of orthogonality in the OBO Foundry and in some cases on what types the classes in the ontologies represent. The authors’ main source of disagreement was due to different interpretations of the literature on Information Content Entities (ICEs).	entity;norm (social);obo foundry;ontology (information science);qualitative comparative analysis	Werner Ceusters;William R. Hogan	2015			information retrieval;tuple;referent;ontology;medical diagnosis;ontology (information science);health care;obo foundry;computer science	Web+IR	-17.319586168198857	1.7504480698672003	40089
9202b656c86d160f15e1f18da640a6aba12ae997	using lanchester equations for sequential battle prediction enabling better military decision support	lanchester equations;decision support;military operations;force deployment;military strategy;military decision support;sequential interactions;military decision making;battle prediction;combat modelling;defence support systems;military planning	This paper documents an innovative method for analysing multiple sequential interactions between two forces engaged in battle, to assist military strategists in deploying forces appropriately. It builds on previous combat models for the calculation of probabilistic distributions of battle results and permits analysis of repeated opposing force interactions. The goal is to provide military decision-makers with a more applicable method, enabling better decision-support tools to aid in military planning and operations. The paper makes several recommendations for suggested strategies in sequential battles based on the results of example problems.	decision support system	Patrick T. Hester;Andreas Tolk	2009	IJIDSS	10.1504/IJIDSS.2009.028643	simulation;military strategy;decision support system;computer science;engineering;military tactics;management;operations research	AI	-22.380554974211016	-22.970362815253566	40091
035d232d4292bccb1ec0e94aaea44eb4ac2cdf85	time-series forecasting	time series forecasting	Taylor & Francis makes every effort to ensure the accuracy of all the information (the “Content”) contained in the publications on our platform. However, Taylor & Francis, our agents, and our licensors make no representations or warranties whatsoever as to the accuracy, completeness, or suitability for any purpose of the Content. Any opinions and views expressed in this publication are the opinions and views of the authors, and are not the views of or endorsed by Taylor & Francis. The accuracy of the Content should not be relied upon and should be independently verified with primary sources of information. Taylor and Francis shall not be liable for any losses, actions, claims, proceedings, demands, costs, expenses, damages, and other liabilities whatsoever or howsoever caused arising directly or indirectly in connection with, in relation to or arising out of the use of the Content.	francis;primary source	Craig B. Borkowf	2002	Technometrics	10.1198/tech.2002.s718	probabilistic forecasting;technology forecasting	Robotics	-14.596244340864756	-5.747021223344868	40093
97292b135eac2fb88c0c6733638bf2d5e8a8a99a	the central on-board computer of the philae lander in the context of the rosetta space mission		The Rosetta-Philae space mission is an unprecedented venture. After a ten-year journey across the Solar System and many complicated manoeuvres, the Rosetta spacecraft smoothly approached a small (2-4 km in diameter) celestial body, comet CG/67P. Furthermore, the spacecraft executed additional fine manoeuvres to fly a multitude of low and high altitude orbits around the comet, mapping its shape and surface in detail never seen before, and has continued to observe it for a year since then. The Rosetta spacecraft is equipped with scientific instruments that deliver a wealth of new knowledge about the CG/67P comet, in addition to spectacular pictures. Delivering the Philae lander onto the surface of the comet 500 million km away from Earth was also a remarkable technological success. The direct measurements made by the Philae lander on the surface of the comet provided significant new knowledge. The first half of this paper gives a brief overview of the objectives and highlights of the Rosetta-Philae mission. In the second half the major hardware and software design aspects, including the conceptual design and implementation of the central on-board computer (CDMS) of the Philae lander are outlined. It focuses on the implementation of fault tolerance, autonomous operation and operational flexibility by means of specific linked data structures and code execution mechanisms that can be interpreted as a kind of object oriented model for mission sequencing.	lunar lander (video game series)	A. Balázs;Attila Baksa;H. Bitterlich;I. Hernyes;O. Küchemann;Zoltan Pálos;J. Rustenbach;W. Schmidt;Péter Spányi;J. Sulyán;Sándor Szalai;Laszlo Várhalmi	2015		10.1007/978-3-319-19584-1_2	solar system;real-time computing;remote sensing;comet;object-oriented programming;conceptual design;fault tolerance;scientific instrument;software design;spacecraft;computer science	Theory	-16.095748498795782	-22.42210590356652	40167
77240af72b81c903b075e75e70d26b12c37f7578	compensatory transfers in two-player decision problems	satisfiability;decision problem;social choice;nash bargaining	"""This paper presents an axiomatic characterization of a family of solutions to two-player quasi-linear social choice problems. In these problems the players select a single action from a set available to them. They may also transfer money between themselves. The solutions form a one-parameter family, where the parameter is a nonnegative number, t. The solutions can be interpreted as follows: Any efficient action can be selected. Based on this action, compute for each player a """"best claim for compensation"""". A claim for compensation is the difference between the value of an alternative action and the selected efficient action, minus a penalty proportional to the extent to which the alternative action is inefficient. The coefficient of proportionality of this penalty is t. The best claim for compensation for a player is the maximum of this computed claim over all possible alternative actions. The solution, at the parameter value t, is to implement the chosen efficient action and make a monetary transfer equal to the average of these two best claims. The characterization relies on three main axioms. The paper presents and justifies these axioms and compares them to related conditions used in other bargaining contexts. In Nash Bargaining Theory, the axioms analagous to these three are in conflict with each other. In contrast, in the quasi-linear social choice setting of this paper, all three conditions can be satisfied simultaneously. Acknowledgement: This work was supported by the Division of Research at the Harvard Business School. Thanks are due to the Cowles Foundation for Research in Economics at Yale University for its kind hospitality during the Spring of 2002. I have received helpful advice and comments from Youngsub Chun, Ehud Kalai, Herve Moulin, Al Roth, Ilya Segal, Adam Szeidl, Richard Zeckhauser, and other members of the Theory Seminars at Harvard, MIT, Princeton, Rice and Northwestern."""	coefficient;decision problem;money;nash equilibrium;realms of the haunting	Jerry R. Green	2005	Int. J. Game Theory	10.1007/s00182-005-0200-1	bargaining problem;social choice theory;economics;decision problem;mathematical economics;welfare economics;satisfiability	AI	-6.987336730531913	-3.749271193022625	40190
d94ea69301358944278ba14f4fa8daf0c81aafd3	rules for formal and natural dialogues in agent communication		The paper aims to bring together and unify two traditions in studying dialogue as a game: dialogical logic introduced by Lorenzen; and persuasion dialogue games as specified by Prakken. The first approach allows the representation of formal dialogues in which the validity of argument is the topic discussed. The second tradition has focused on natural dialogues examining, e.g., informal fallacies typical in real-life communication. Our goal is to unite these two approaches in order to allow communicating agents to benefit from the advantages of both, i.e. to equip them with the ability to persuade each other not only about facts, but also about the classical propositional validity of argument used in a dialogue. To this end, Lorenzen’s system needs to be expressed according to the generic specification for natural dialogues proposed by Prakken. As a result, the system proposed in the paper allows the representation and elimination of formal fallacies committed during a dialogue.	embedded system;game semantics;propositional calculus;real life	Olena Yaskorska;Magdalena Kacprzak;Katarzyna Budzynska	2012			persuasion;natural language processing;formal fallacy;knowledge management;artificial intelligence;dialogical self;computer science	AI	-16.80076357950877	3.6971621033488673	40283
813387a35585f2c130c97a907e1744684d67ebac	tell me why: computational explanation of conceptual similarity judgments		In this paper we introduce a system for the computation of explanations that accompany scores in the conceptual similarity task. In this setting the problem is, given a pair of concepts, to provide a score that expresses in how far the two concepts are similar. In order to explain how explanations are automatically built, we illustrate some basic features of COVER, the lexical resource that underlies our approach, and the main traits of the MeRaLi system, that computes conceptual similarity and explanations, all in one. To assess the computed explanations, we have designed a human experimentation, that provided interesting and encouraging results, which we report and discuss in depth.	computation;tell-tale	Davide Colla;Enrico Mensa;Daniele P. Radicioni;Antonio Lieto	2018		10.1007/978-3-319-91473-2_7	computation;machine learning;lexical semantics;mathematics;artificial intelligence	NLP	-27.619677492332002	-12.36761101765544	40415
7eb6203e3c7dd870ec6220d557c2c1251d3ba9c5	information retrieval by logical imaging	medida informacion;representation graphique;analyse cooccurrence;cluster;methode mesure;amas;probabilidad condicional;etude experimentale;information retrieval;representacion grafica;mesure information;logic;probabilite conditionnelle;pertinencia;semantics;possible words semantics;metodo medida;systeme recherche;representation par terme indexation;cranfield 2;semantica;semantique;cooccurrence analysis;graphs;evaluation methods;similitude;documentation data processing;search system;interpretacion;modal logic;modelo logico;retrieval by imaging rbi;recherche documentaire;retroaccion;mathematical formulas;information measure;retroaction;sistema investigacion;logique modale;pertinence;recuperacion documental;similarity;feedback regulation;logica modal;interpretation;document retrieval;monton;relevance;similitud;logic model;measurement method;search pattern;semantique mondes possibles;information theoretic;conditional probability;estudio experimental;expected mutual information measure emim;possible worlds;graphics;test collection;futures of society;representacion por termino indexacion;modele logique;informacion documental;collection test;informatique documentaire	"""The evaluation of an implication by Imaging is a logical technique developed in the framework of modal logic. Its interpretation in the context of a \possible worlds"""" semantics is very appealing for IR. In 1989, Van Rijsbergen suggested its use for solving one of the fundamental problems of logical models in IR: the evaluation of the implication d! q (where d and q are respectively a document and a query representation). Since then, others have tried to follow that suggestion proposing models and applications, though without much success. Most of these approaches had as their basic assumption the consideration that \a document is a possible world"""". We propose instead an approach based on a completely di erent assumption: \a term is a possible world"""". This approach enables the exploitation of term{ term relationships which are estimated using an information theoretic measure. 1 The use of non-classical logic in Information Retrieval In Information Retrieval (IR) there is no lack of models: the Boolean, the vector space, the probabilistic, and the fuzzy model are all well known. HowOn leave from Dipartimento di Elettronica ed Informatica, Universit a degli Studi di Padova, Italy."""	accessibility;computation;experiment;heuristic (computer science);information retrieval;information theory;many-worlds interpretation;modal logic;p (complexity);possible world;relevance;statistical model	Fabio Crestani;C. J. van Rijsbergen	1995	Journal of Documentation	10.1108/eb026939	modal logic;document retrieval;relevance;similarity;conditional probability;epistemology;interpretation;computer science;graphics;artificial intelligence;similitude;data mining;mathematics;semantics;logic;algorithm;cluster	Web+IR	-20.59063488029436	-0.5635732428722587	40491
1da61f2a033c43066713358a60878c160cbdccea	mapping factors influencing the selection of subsea petroleum production systems: a case study		The development, design and selection of subsea petroleum production equipment and facilities are critical activities, as the decisions made will impact the success and profitability of the project. Technical, economic and government regulations are some of the factors that need to be evaluated in order to contract subsea services and procurement activities. Pre-studies need to be conducted to design the best subsea concept and to assess the development costs in order to succeed in the project execution and to keep the production rate and profits as expected. There are many factors that should be addressed before selecting the concept. By identifying and studying these aspects, the project management will be able to develop an optimum production system and select the best equipment to cover the functions needed, as well as identify health, safety, environmental and quality requirements and spare parts’ availability for maintenance interventions. This will help to achieve the integrity of the installation and to reduce risks. In this paper we identify various aspects, factors and design criteria that need to be addressed in the design phase.	exploit (computer security);fits;interference (communication);pipeline (computing);procurement;production system (computer science);requirement;reservoir computing;scheduling (computing)	Jorge Moreno-Trejo;Rajesh Kumar;Tore Markeset	2012	Int. J. Systems Assurance Engineering and Management	10.1007/s13198-012-0090-0	reliability engineering;systems engineering;engineering;operations management	HCI	-8.492273009243906	-13.776466339848989	40509
fc778fbdfb894e15150aa68135d139c71fd6a5e3	a knowledge acquisition tool for bayesian-network troubleshooters	bayesian network;knowledge acquisition	This paper describes a domain-specific knowledge acquisition tool for intelligent automated troubleshooters based on Bayesian networks. No Bayesian network knowledge is required to use the tool. and troubleshooting information can be specified as natural and intuitive as possible. Probabilities can be specified in the direction that is most natural to the domain expert. Thus, the knowledge acquisition efficiently removes the traditional knowledge acquisition bottleneck of Bayesian networks.	bayesian network;knowledge acquisition;subject-matter expert	Claus Skaanning	2000			computer science;data science;machine learning;bayesian network;data mining	AI	-31.470270829540276	-6.178209412812597	40528
6f7177c3ceacd25743f133000469b9c49528c983	question answering with textual cbr	raisonnement base sur cas;razonamiento fundado sobre caso;systeme intelligent;case base reasoning;query processing;information retrieval;sistema inteligente;recherche documentaire;recherche information;traitement question;recuperacion documental;intelligent system;document retrieval;recuperacion informacion;information system;case based reasoning;systeme information;question answering;sistema informacion	1 I n t r o d u c t i o n Case-based reasoning (CBR) is concerned with the reuse of knowledge obtained during earlier problem solving episodes. In a problem situation, the key idea is to look for similar problem descriptions from the past and to utilize the solution that worked for this past problem. In this sense, CBR models the cognitive idea of experience. Obviously, this paradigm implies that a case base is available containing these experiences. Traditionally, CBR has been concerned with more structured domains where cases can be encoded in terms of attribute-value vectors, sets of features, graphs and so on. In practice, however, an enormous amount of the above mentioned experiences is available as natural language texts only. Typical examples are manuals of technical equipment, documentations, reports by physicians, and, of course, the widely-used collections of Frequently Asked Questions (FAQ). Consequently, CBR researchers started to address the issue of knowledge contained in textual documents recently. In this paper, we describe how CBR techniques can be used to build question answering systems. For this, we first describe the characteristics of a typical application area and then present our approach of TextuM CBR. To illustrate the application of this technique, we describe in some detail a project performed in an industrial setting. Finally, we discuss related work and briefly evaluate the behavior of the system. 2 A T y p i c a l A p p l i c a t i o n A r e a : T h e H o t l i n e Today it is becoming more and more difficult to sell products without a reliable and efficient customer support. This is true both, for industrial equipment as	case-based reasoning;customer support;documentation;natural language;problem solving;programming paradigm;question answering;structured programming	Mario Lenz;André Hübner;Mirjam Kunze	1998		10.1007/BFb0056005	document retrieval;case-based reasoning;question answering;computer science;artificial intelligence;data mining;information retrieval;information system	AI	-31.264865340512006	-4.100376844054118	40595
6eb4b31dad4f40394e5d156dc854d797e7637968	jumps and logic in the law	nonmonotonic logic;defeasibility;coherence;principles;weighing	The main stream of legal theory tends to incorporate unwritten principles into the law. Weighing of principles plays a great role in legal argumentation, inter alia in statutory interpretation. A weighing and balancing of principles and other prima facie reasons is a jump. The inference is not conclusive. To deal with defeasibility and weighing, a jurist needs both the belief-revision logic and the nonmonotonic logic. The systems of nonmonotonic logic included in the present volume provide logical tools enabling one to speak precisely about various kinds of “rules about rules”, dealing with such things as applicability of rules, what is assumed by rules, priority between rules and the burden of proof. Nonmonotonic logic is an example of an extension of the domain of logic. But the more far-reaching the extension is, the greater problems it meets. It seems impossible to make logical reconstruction of the totality of legal argumentation. The lawyers' search for reasons has no obvious end point. Ideally, the search for reasons may end when one arrives at a coherent totality of knowledge. In other words, coherence is the termination condition of reasoning. Both scientific knowledge and knowledge of legal and moral norms progresses by trial and error, and that one must resort to a certain convention to define what “error” means. The main difference is, however, that conventions of science are much more precise than those of legal scholarship. Consequently, determination of “error” in legal science is often holistic and circular. The reasons determining that a legal theory is “erroneous” are not more certain than the contested theory itself. A strict and formal logical analysis cannot give us the full grasp of legal rationality. A weaker logical theory, allowing for nonmonotonic steps, comes closer, at the expense of an inevitable loss of computational efficiency. Coherentist epistemology grasps even more of this rationality, at the expense of a loss of preciseness.	belief revision;coherence (physics);computational epistemology;holism;non-monotonic logic;rationality	Aleksander Peczenik	1996	Artificial Intelligence and Law	10.1007/BF00118495	coherence;computer science;artificial intelligence;non-monotonic logic;principle;defeasible reasoning;algorithm	AI	-13.011047523842896	4.137943061754682	40660
1bbe60b0aac430caac6e11a4479d37707f57c886	préservation de la vie privée. recherche de motifs séquentiels dans des bases de données distribuées	extraction information;expresion regular;base donnee repartie;distributed database;analisis datos;information extraction;ingenierie connaissances;privacy preserving;base repartida dato;sequential patterns;data mining;vida privada;data analysis;private life;data privacy;fouille donnee;expression reguliere;vie privee;analyse donnee;information system;busca dato;confidentialite donnee;extraccion informacion;regular expression;systeme information;sistema informacion;knowledge engineering	Extracting knowledge without disclosing any individual or sensitive information is a new challenging problem for the data mining community. In this paper, we present a new algorithm PRIPSEP (privacy preserving sequential patterns) for the mining of sequential patterns from distributed databases while preserving privacy. We prove that our architecture and protocols employed by our algorithm are secure. MOTS-CLÉS : fouille de données, motifs séquentiels, préservation de la vie privée.	algorithm;bibliothèque de l'école des chartes;data mining;distributed database;information sensitivity;linear algebra	Vishal Kapoor;Pascal Poncelet;François Trousset;Maguelonne Teisseire	2007	Ingénierie des Systèmes d'Information	10.3166/isi.12.1.85-107	computer science;artificial intelligence;knowledge engineering;data mining;data analysis;distributed database;information extraction;information system;regular expression	ML	-27.951353636523827	-3.129269988919985	40675
d37c13fd802abb13433d83621c3defdc8efb581b	arcades: a deep model for adaptive decision making in voice controlled smart-home		In a voice controlled smart-home, a controller must respond not only to user’s requests but also according to the interaction context. This paper describes Arcades, a system which uses deep reinforcement learning to extract context from a graphical representation of home automation system and to update continuously its behavior to the user’s one. This system is robust to changes in the environment (sensor breakdown or addition) through its graphical representation (scale well) and the reinforcement mechanism (adapt well). The experiments on realistic data demonstrate that this method promises to reach long life context-aware control of smart-home.	arcade game;experiment;graphical user interface;home automation;reinforcement learning	Alexis Brenon;François Portet;Michel Vacher	2018	Pervasive and Mobile Computing	10.1016/j.pmcj.2018.06.011	real-time computing;control theory;reinforcement learning;deep learning;home automation;distributed computing;computer science;artificial intelligence;reinforcement	HCI	-29.253026439481538	-23.618800995828387	40772
1ee4ecce108110598c7c9c2ad5c82b8192a58fdd	parallel text query processing using composite inverted lists	data structure;indexation	The inverted lists strategy is frequently used as an index data structure for very large textual databases. Its implementation and comparative performance has been studied in sequential and parallel applications. In the latter, with relatively few studies, there has been a sort of “which-is-better” discussion about two alternative parallel realizations of the basic data structure and algorithms. We suggest that a mix between the two is actually a better alternative. Depending on the workload generated by the users, the composite inverted lists algorithm we propose in this paper can operate either as a local or global inverted list, or both at the same time.	parallel text	M. Marin	2002			query expansion;sargable;query language;inverted index;information retrieval;sort;query by example;query optimization;data structure;computer science	Web+IR	-29.203727877832822	3.010176963025542	40793
9cf94139556cfdd714aacc164b8d899df7572160	relevance: an improved framework for explicating the notion	aboutness;relevance	Synthesizing and building on many ideas from the literature, this article presents an improved conceptual framework that clarifies the notion of relevance with its many elements, variables, criteria, and situational factors. Relevance is defined as a Relationship (R) between an Information Object (I) and an Information Need (N) (which consists of Topic, User, Problem/Task, and Situation/ Context) with focus on R. This defines Relevance-as-is (conceptual relevance, strong relevance). To determine relevance, an Agent A (a person or system) operates on a representation I of the information object and a representation N of the information need, resulting in relevance-as-determined (operational measure of relevance, weak relevance, an approximation). Retrieval tests compare relevance-as-determined by different agents. This article discusses and compares two major approaches to conceptualizing relevance: the entityfocused approach (focus on elaborating the entities involved in relevance) and the relationship-focused approach (focus on explicating the relational nature of relevance). The article argues that because relevance is fundamentally a relational construct the relationshipfocused approach deserves a higher priority and more attention than it has received. The article further elaborates on the elements of the framework with a focus on clarifying several critical issues on the discourse on relevance.	approximation;biological anthropology;black box;closing (morphology);computer;entity;fits;faceted classification;hardware description language;information needs;information retrieval;information seeking;interaction;matching (graph theory);operational definition;primacy of mind;relevance;systems design;usability testing	Xiaoli Huang;Dagobert Soergel	2013	JASIST	10.1002/asi.22811	relevance;computer science;artificial intelligence;data mining	ML	-29.672339551792952	-3.326263642003872	40800
3ca510062ae2994685708f2ca2d419eda37ef86c	actual causation: a stone soup essay	philosophy of science;bayesian network;combinatorics;philosophy of language;bepress selected works;actual causation;logic;combinatoire;iron;current account;causalite reelle;cognitive sciences;onion;potato;intuitions;philosophy;epistemology;reseau bayesien;metaphysics;intuition;actual causation bayesian networks combinatorics intervention intuitions;causation;intervention;bayesian networks;sciences cognitives	We argue that current discussions of criteria for actual causation are ill-posed in several respects. (1) The methodology of current discussions is by induction from intuitions about an infinitesimal fraction of the possible examples and counterexamples; (2) cases with larger numbers of causes generate novel puzzles; (3) “neuron” and causal Bayes net diagrams are, as deployed in discussions of actual causation, almost always ambiguous; (4) actual causation is (intuitively) relative to an initial system state since state changes are relevant, but most current accounts ignore state changes through time; (5) more generally, there is no reason to think that philosophical judgements about these sorts of cases are normative; but (6) there is a dearth of relevant psychological research that bears on whether various philosophical accounts are descriptive. Our skepticism is not directed towards the possibility of a correct account of actual causation; rather, we argue that standard methods will not lead to such an account. A different approach is required. Once upon a time a hungry wanderer came into a village. He filled an iron cauldron with water, built a fire under it, and dropped a stone into the water. “I do like a tasty stone soup” he announced. Soon a villager added a cabbage to the pot, another added some salt and others added potatoes, onions, carrots, mushrooms, and so on, until there was a meal for all. Once upon a time a hungry wanderer came into a village. He filled an iron cauldron with water, built a fire under it, and dropped a stone into the water. “I do like a tasty stone soup” he announced. Soon a villager added a cabbage to the pot, another added some salt and others added potatoes, onions, carrots, mushrooms, and so on, until there was a meal for all.	bayesian network;causal filter;causality;crazy stone (software);diagram;mathematical induction;neuron;salt (cryptography);semantics (computer science);well-posed problem;world wide web wanderer	Clark Glymour;David Danks;Bruce Glymour;Frederick Eberhardt;Joseph Ramsey;Richard Scheines;Peter Spirtes;Choh Man Teng;Jiji Zhang	2009	Synthese	10.1007/s11229-009-9497-9	probabilistic causation;philosophy;epistemology;bayesian network;intuition;mathematics		-12.697839202073338	3.376008026455607	40826
6f36297eca7c468e596ed5e06b9d91a6428402be	causal compositional models in valuation-based systems	valuation based system;compositional model;conditionals;intervention;causality	This paper shows that Pearl’s causal networks can be described using compositional models in the valuation-based systems (VBS) framework. There are several advantages of using the VBS framework. First, VBS is a generalization of several uncertainty theories (e.g., probability theory, a version of possibility theory where combination is the product t-norm, Spohn’s epistemic belief theory, and Dempster-Shafer belief function theory). This implies that causal compositional models, initially described in probability theory, are now described in all uncertainty calculi that fit in the VBS framework. Second, using the operators of VBS, we describe how causal inference can be made in causal compositional models in an elegant and unifying algebraic way. This includes the computation of conditioning, and the computation of the effect of interventions.	causal filter;causal inference;computation;linear algebra;possibility theory;t-norm;vbscript;value (ethics)	Radim Jirousek;Prakash P. Shenoy	2014		10.1007/978-3-319-11191-9_28	combinatorics;discrete mathematics;mathematics	AI	-9.56761815452034	0.037192150126253314	40853
a6bf8afa3e94686e6eb461b8603cfef49def9ab6	the ‘gray’s elegy’ argument, and the prospects for the theory of denoting concepts		Russell’s new theory of denoting phrases introduced in “On Denoting” in Mind 1905 is now a paradigm of analytic philosophy. The main argument for Russell’s new theory is the so-called ‘Gray’s Elegy’ argument, which purports to show that the theory of denoting concepts (analogous to Frege’s theory of senses) promoted by Russell in the 1903 Principles of Mathematics is incoherent. The ‘Gray’s Elegy’ argument rests on the premise that if a denoting concept occurs in a proposition, then the proposition is not about the concept. I argue that the premise is false. The ‘Gray’s Elegy’ argument does not exhaust Russell’s ammunition against the theory of denoting concepts. Another reason Russell rejects the theory is, as he says, that it cannot provide an adequate account of non-uniquely denoting concepts. In the last section of the paper, I argue that even though Russell was right in thinking that the theory of denoting concepts cannot provide an adequate account of non-uniquely denoting concepts, Russell’s new theory does not succeed in eliminating the occurrence of all denoting concepts, as it requires a commitment to the existence of variables that indirectly denote their values. However, the view that variables are denoting concepts is unproblematic once the ‘Gray’s Elegy’ argument is blocked.	frege;programming paradigm	Berit Brogaard	2005	Synthese	10.1007/s11229-005-0547-7	philosophy;epistemology;mathematics;algorithm	AI	-12.670259316058765	3.9424953489479164	41030
2ac44f1f7cc6831ef8b84fe6ddbb591a188c3926	partial retrieval of compressed semi-structured documents	busqueda informacion;modelizacion;structural model;text;essai statique;data compression;information retrieval;word based tagged code;useful information;text compression;informacion util;texte;modele statique;modele structure;ensayo estatico;modelisation;semistructured data;compression models;dato semi estructurado;recherche information;acceso aleatorio;static test;modelo estatico;static model;modelo estructura;compresion dato;information system;intencion;semi structured documents;structured documents;texto;modeling;random access;systeme information;intention;information utile;compression donnee;sistema informacion;donnee semistructuree;acces aleatoire	We describe a compression model called tri-structural contexts model (TSCM), for semi-structured documents. The intention is that separation of the start tag, the attribute name/attribute value and textual words may reduce the entropy. We also combine the attributes with their values and use a separate container for them. We mainly focus on semi-static models, and test our idea using a word-based tagged code. This code allows random access and partial decompression of the compressed collection. The compression time is found to be better than scmhuff and decompression time is also observed much less than scmhuff and xmlppm. The shorter time for partial decompression emphasises the use of TSC model to keep the semistructured document compressed all the time. The algorithm and proposed model are useful in information retrieval systems.	algorithm;archive;central processing unit;data compression;information retrieval;random access;remote desktop services;research data archiving;semiconductor industry;triangular function;xml	Ashutosh Gupta;Suneeta Agarwal	2010	IJCAT	10.1504/IJCAT.2010.034524	data compression;speech recognition;systems modeling;computer science;artificial intelligence;data mining;static testing;information system;random access	Web+IR	-27.152840915556293	-2.5938272079390416	41067
f065add964e3e422d02bb767d053b1076f26887a	design of an agent-based model to predict crime (wip)	crime prediction;agent based model;crime simulation	In modern societies where fighting crime has a long history, establishing effective methods for crime prevention is of high significance. For this purpose, police departments worldwide undertake efforts to analyze past crime data. They aim to detect the most prolific crime areas and predict their development, in order to direct their prevention efforts. In parallel, scholars investigate possibilities to build crime prediction models, by applying various techniques, from simple regression to data mining. Acknowledging the latest advances in this field, which suggest that Agent-Based Modeling (ABM) is a promising method, in this paper we present the design of an ABM capable of predicting where and when future crimes will most probably happen. We extend the previous work by accounting for offender behavior and integrating a realistic representation of the environment. In contrast to existing models, past crime data will be included to achieve automatic calibration. Furthermore, we will assess how crime data can be used to model agent’s behavior and we will include environmental data stepwise, in order to achieve the optimal balance between prediction accuracy and complexity. The resulting ABM will be developed as a crime prediction tool, and as an experimental environment to test prevention strategies.	agent architecture;agent-based model;data mining;protein structure prediction;prototype;repast (modeling toolkit);simulation;stepwise regression	Raquel Rosés Brüngger;Cristina Kadar;Irena Pletikosa Cvijikj	2016			simulation;engineering;artificial intelligence;forensic engineering;computer security	ML	-18.185501542765927	-23.358482253752452	41107
2cf3d0dc1e7522ea68a7ac1fa3fe6e553c0b4da7	a fuzzy multi-criteria outranking approach in support of business angels' decision-analysis process for the assessment of companies as investment opportunities	multi criteria optimization;investment decision;decision analysis;fuzzy logic;investment decisions;decision support system;decision support systems;web based system;decision process;business angels	In this paper, a multi-criteria method is presented for the evaluation and ranking of a selected set of companies as investment opportunities in aid of the relevant decision-analysis process of business angels. The multi-criteria methodology is based on the PROMETHEE method, which is further extended to deal with fuzzy input data in order to address the data imprecision and uncertainty of the decision process. The paper concludes by suggesting a web-based system implementation of the proposed methodology, which will significantly enhance modern business angels networks.	decision analysis	Spiros Mouzakitis;George Karamolegkos;Emmanouil Ntanos;John E. Psarras	2013	J. Optimization Theory and Applications	10.1007/s10957-011-9816-4	fuzzy logic;optimal decision;decision support system;decision analysis;decision engineering;management science;evidential reasoning approach;business decision mapping	ML	-5.760876746022346	-16.161672295740164	41131
9f4c55d71a15bf65ce656f885723b7892fa8bf55	simulation within simulation for agent decision-making: theoretical foundations from cognitive science to operational computer model	internal simulation;autonomous behavior;virtual reality;behavioral simulation	This article deals with artificial intelligence models inspired from cognitive science. The scope of this paper is the simulation of the decision-making process for virtual entities. The theoretical framework consists of concepts from the use of internal behavioral simulation for human decision-making. Inspired from such cognitive concepts, the contribution consists in a computational framework that enables a virtual entity to possess an autonomous world of simulation within the simulation. It can simulate itself (using its own model of behavior) and simulate its environment (using its representation of other entities). The entity has the ability to anticipate using internal simulations, in complex environments where it would be extremely difficult to use formal proof methods. Comparing the prediction and the original simulation, its predictive models are improved through a learning process. Illustrations of this model are provided through two implementations. First illustration is an example showing a shepherd, his herd and dogs. The dog simulates the sheep’s behavior in order to make predictions testing different strategies. Second, an artificial 3D juggler plays in interaction with virtual jugglers, humans and robots. For this application, the juggler predicts the behavior of balls in the air and uses prediction to coordinate its behavior in order to juggle.	artificial intelligence;autonomous robot;cognitive science;computer simulation;entity;formal proof;humans;numerical weather prediction;predictive modelling;sculpt 3d	Cédric Buche;Nathalie Le Bigot;Mihai Polceanu	2016	Cognitive Systems Research	10.1016/j.cogsys.2016.03.001	simulation;computer science;artificial intelligence;machine learning;virtual reality;communication	AI	-21.764263045137717	-15.424491831358443	41168
4a3911f780872e4d3e4e126523055c765fd8d541	an open simulation architecture for force xxi	expert system players open simulation architecture force xxi american army combat command levels platoon on platoon operation unilateral actions enemy headquarters friendly headquarters high fidelity simulation simultaneous actions command echelons multi level simulation task force commander real time live video virtual view constructive simulation virtual simulation live simulation expert systems human players;new technology;expert systems;expert systems digital simulation open systems distributed processing software engineering command and control systems interactive video;interactive video;real time;distributed processing;software engineering;level of detail;computational modeling computer simulation humans discrete event simulation yarn computer science expert systems operations research art computer architecture;cold war;technical report;open systems;command and control systems;digital simulation;expert system	Force XXI will be America's Army in the 21st century. New technology, a post-Cold War world and a declining force structure have made simulation a critical means for defining and implementing Force XXI. Military organizations are hierarchical. In combat, these command levels operate simultaneously with varying levels of coupling. A platoon on platoon operation can be significantly affected by unilateral actions of higher level friendly or enemy headquarters. A high-fidelity simulation must be able to represent the simultaneous actions of several command echelons. A multi-level simulation approach is presented in which different echelons of command can view objects at varying levels of detail consistently. A task force commander should be able to view the position and movement of a tank platoon on a map or a virtual view of the battlefield as seen from the platoon leader's hatch or real-time live video from an actual tank on the ground. Each view must be logically consistent with each other, so that the mountain on the map sheet affects movement in the same manner as the virtual mountain and the actual mountain seen via live video. Various combinations of live, virtual and constructive simulations will run concurrently in the same simulation infrastructure. Expert systems will control constructive simulation nodes lacking human players. At any level in the simulation human players and expert system players may be interchanged. The opposing force will be similarly configured. Force on force virtual simulations will be supported in the simulation infrastructure. The resulting open simulation architecture (OSA) is discussed in detail.	coupling (computer programming);expert system;real-time transcription;simulation	John A. Hamilton;Udo W. Pooch	1995		10.1145/224401.224811	simulation;computer science;engineering;artificial intelligence;technical report;level of detail;open system;expert system	Graphics	-23.96864720544379	-22.623222788111594	41183
3469e826c6048b7f5c52cd88760551943d2045cf	simulation validation with historic outcomes	biscay agent-based simulation;mission-level model;agent-based mission-level model;probability distribution model;extended campaign;total simulation time;time period;simulation output;historic outcome;extended time frame;common distribution;simulation validation;probability distribution;multi agent systems;statistical analysis	Combat, unlike many real-world processes, tends to be singular in nature. That is, there are not multiple occurrences from which to hypothesize a probability distribution model of the real-world system. Mission-level models may offer more flexibility on some measures due to their extended time frame. Additionally, the parameters involved in the mission-level model may be unchanged for significant stretches of the total simulation time. In these cases, time periods may be devised so that the periods hold sufficiently similar traits such that the incremental results may be assumed to come from a common distribution. This paper details a new statistical methodology for use in validating an agent-based mission-level model. The test is developed within the context of the Bay of Biscay agent-based simulation and uses the monthly data from the extended campaign as a basis of comparison to the simulation output.	agent-based model;simulation;world-system	Lance E. Champagne;Raymond R. Hill	2005	Proceedings of the Winter Simulation Conference, 2005.		probability distribution;simulation;computer science;engineering;multi-agent system;mathematics;operations research;statistics	AI	-15.05322145973512	-19.783027459209723	41207
6dcab868c9fbc8d34ffceab1912aa359906930c7	efficient query processing infrastructures: a half-day tutorial at sigir 2018		Typically, techniques that benefit effectiveness of information retrieval (IR) systems have a negative impact on efficiency. Yet, with the large scale of Web search engines, there is a need to deploy efficient query processing techniques to reduce the cost of the infrastructure required. This tutorial aims to provide a detailed overview of the infrastructure of an IR system devoted to the efficient yet effective processing of user queries. This tutorial guides the attendees through the main ideas, approaches and algorithms developed in the last 30 years in query processing. In particular, we illustrate, with detailed examples and simplified pseudo-code, the most important query processing strategies adopted in major search engines, with a particular focus on dynamic pruning techniques. Moreover, we present and discuss the state-of-the-art innovations in query processing, such as impact-sorted and blockmax indexes. We also describe how modern search engines exploit such algorithms with learning-to-rank (LtR) models to produce effective results, exploiting new approaches in LtR query processing. Finally, this tutorial introduces query efficiency predictors for dynamic pruning, and discusses their main applications to scheduling, routing, selective processing and parallelisation of query processing, as deployed by a major search engine.	algorithm;database;information retrieval;learning to rank;parallel computing;pseudocode;query optimization;routing;scheduling (computing);web search engine	Nicola Tonellotto;Craig MacDonald	2018		10.1145/3209978.3210191	computer science;data mining;information retrieval;learning to rank;search engine;scheduling (computing);exploit	DB	-33.51177071493369	2.3784987943724385	41411
89b8c2bb73bb59d3b0449e60746b6482ae269a19	what are fuzzy rules and how to use them	fuzzy set;fuzzy rules;fuzzy control;logique floue;conjunto difuso;logica difusa;ensemble flou;fuzzy logic;approximate reasoning;possibility theory;knowledge representation;teoria posibilidad;theorie possibilite	"""Fuzzy rules have been advocated as a key tool for expressing pieces of knowledge in """"fuzzy logic"""". However, there does not exist a unique kind of fuzzy rules, nor is there only one type of """"fuzzy logic"""". This diversity has caused many a misunderstanding in the literature of fuzzy control. The paper is a survey of different possible semantics for a fuzzy rule and shows how they can be captured in the framework of fuzzy set and possibility theory. It is pointed out that the interpretation of fuzzy rules dictates the way the fuzzy rules should be combined. The various kinds of fuzzy rules considered in the paper (gradual rules, certainty rules, possibility rules, and others) have different inference behaviors and correspond to various intended uses and applications. The representation of fuzzy unless-rules is briefly investigated on the basis of their intended meaning. The problem of defining and checking the coherence of a block of parallel fuzzy rules is also briefly addressed. This issue has been neglected in the fuzzy control literature although it looks important for validation purposes."""	fuzzy concept;fuzzy control system;fuzzy logic;fuzzy rule;fuzzy set;possibility theory	Didier Dubois;Henri Prade	1996	Fuzzy Sets and Systems	10.1016/0165-0114(96)00066-8	fuzzy logic;t-norm fuzzy logics;knowledge representation and reasoning;possibility theory;fuzzy cognitive map;membership function;defuzzification;adaptive neuro fuzzy inference system;type-2 fuzzy sets and systems;fuzzy mathematics;fuzzy classification;computer science;artificial intelligence;fuzzy number;neuro-fuzzy;machine learning;fuzzy measure theory;data mining;mathematics;fuzzy set;fuzzy associative matrix;fuzzy set operations;fuzzy control language;algorithm;fuzzy control system	AI	-19.486023225463015	-0.7398115473541074	41434
95bcb92aac034afc258dc8c5558402aae71baca3	special issue on robotics: science and systems	special issue	This issue of Autonomous Robots presents journal articles that are based on papers originally presented at the 2013 Robotics Science and Systems conference, held in Berlin, Germany. Although these were selected by a committee to exemplify the best papers presented that year, the decision over which papers to include was a difficult one due to the substantial number of very strong papers in the cohort.While the strength of these papers can be partially attributed to the fact that the conference itself generally attracts strong papers, it is also a sign of the maturation of our field. The papers in this issue reflect a few broad themes that are currently attracting the attention of the robotics research community: the development of multi-agent systems (where the agents can be either multiple robots, or a mixture of humans and robots), the link between sensing andmanipulation in robotic systems, and the continuing use of sophisticated probabilistic representations in robot control. In the paper “Multivariate Evaluation of Interactive Robot Systems” amethod for evaluating interactive robotic systems is described. This work emphasizes the ability to evaluate a complex system with a large number of design variables using tools from multiple regression, and does so in the context of human–robot interaction where exhaustive methods would be impractical. The context is that of understanding	robotics	Gregory Dudek;Dieter Fox	2014	Auton. Robots	10.1007/s10514-014-9416-x	geography of robotics;future of robotics	Robotics	-31.579253355356794	-19.526089942501333	41476
ff3e395b43a76e3ca6d920fde58b487ccffb5a8c	where and when can open source thrive? towards a theory of robust performance	qualitative data;economic impact	While the economic impact of, and the interest in, open source innovation and production has increased dramatically in recent years, there is still no widely accepted theory explaining its performance. We combine original fieldwork with agent-based simulation to propose that the performance of open source is surprisingly robust, even as it happens in seemingly harsh environments with free rider, rival goods, and high demand. Open source can perform well even when cooperators constitute a minority, although their presence reduces variance. Under empirically realistic assumptions about the level of cooperative behavior, open source can survive even increased rivalry and performance can thrive if demand is managed. The plausibility of the propositions is demonstrated through qualitative data and simulation results.	agent-based model;agent-based social simulation;field research;open-source hardware;open-source software;plausibility structure	Sheen S. Levine;Michael J. Prietula	2010			economic impact analysis;innovation;qualitative property;simulation;performance;engineering;knowledge management;artificial intelligence;operations management;management	AI	-13.150433850274073	-12.379496098599564	41510
04bfdebf1a90987f347f59a12f9ca6c6bb5230e5	finality revived: powers and intentionality	endnotes;pubications	Proponents of physical intentionality argue that the classic hallmarks of intentionality highlighted by Brentano are also found in purely physical powers. Critics worry that this idea is metaphysically obscure at best, and at worst leads to panpsychism or animism. I examine the debate in detail, finding both confusion and illumination in the physical intentionalist thesis. Analysing a number of the canonical features of intentionality, I show that they all point to one overarching phenomenon of which both the mental and the physical are kinds, namely finality. This is the finality of ‘final causes’, the long-discarded idea of universal action for an end to which recent proponents of physical intentionality are in fact pointing whether or not they realise it. I explain finality in terms of the concept of specific indifference, arguing that in the case of the mental, specific indifference is realised by the process of abstraction, which has no correlate in the case of physical powers. This analysis, I conclude, reveals both the strength and weakness of rational creatures such as us, as well as demystifying (albeit only partly) the way in which powers work.	causality;intentionality;irreducibility;mental representation;mind;non-deterministic turing machine;sed	David S. Oderberg	2016	Synthese	10.1007/s11229-016-1057-5	philosophy;epistemology;mathematics	HCI	-12.850759709504404	2.5381135552293004	41533
bc559895988169839969f95a6d791d877cf1383c	talking to unix in english: an overview of an on-line unix consultant	operating system;good operating system command;on-line unix consultant;new user;natural language front;unix operating system;operating system component;intelligent natural language interface;natural language help facility;natural language;natural language dialogue	The goal of UC is to provide a natural language help facility that allows new users to learn operating systems conventions in a relatively painless way UC is not meant to be a substitute for a good operating system command int,erpreter, but rather, an additional tool at the disposal of the new user, to be used in conjunction with other operating system components UrjIXI CONSULTANT [UC] is an intelligent natural language interface that allows naive users to communicate with the UNIX operating system in ordinary English UC allows the user to engage in natural language dialogues with the operating system While there are a number of other natural language interfaces available today, these are mostly used as natural language front ends to particular data bases (Hayes & Carbonell 1981, Hendrix 1977, Robinson 1982, Waltz et al. 1976, Woods 1970). In contrast: the user uses UC in order to learn how better to use the UNIX environment in which UC is embedded UC can handle requests stated in a wide variety of forms, and has a number This research was sponsored in part by the Office of Naval Research under contract NOOO14.80-C-0732 and the National Science Foundation under grant hZCS79-06543 IUNIX is trademark of Bell Laboratories of features to enhance its function as a user interface. These include the following: 1. A robust language analyzer, which almost never has a “hard” failure and which has the ability to handle most elliptical constructions in context 2 A context and memory mechanism that determines the focus of attention and helps with lexical and syntactic disambiguation, and with some aspects of pronominal reference. 3 Highly extensible knowledge bases both of facts about UN IX and about the English language 4. A mechanism for trying to make sense out of illformed inputs 5 An experimental planning component that provides commonsense reasoning in creating plans for the user 6 A goal analysis mechanism, which performs functions related to interpreting the user’s statements as speech acts. 7. A UC Teacher, which enables UC to learn new vocabulary and new facts about UNIX by being instructed in natural language. While some of the components of the system are experimental in nature: the basic features of UC provide a usable device to obtain information about UNIX. In addition, THE AI ,MAGAZINE Spring 1984 29 it is straightforward to extend UC’s knowledge base to cover areas of UNIX with which UC is not currently familiar. UC: Typing “Is -I filename” will tell what the protection on the file named filename is (For more information on the Is command type “man Is “) UC Examples User: How can I change the write permission on my terminal? (or permission of or protection) The following examples are illustrative of the breadth of dialogues in which UC can participate. UC is capable of generating the answers shown below in response to most forms of the request users might supply. UC can participate in some dialogues that are considerably more involved than this one, and which will be discussed in more detail later on:	command (computing);commonsense reasoning;database;embedded system;hayes microcomputer products;knowledge base;natural language user interface;operating system;uc browser;unix;vocabulary;word-sense disambiguation	Robert Wilensky	1984	AI Magazine		unix architecture;human–computer interaction;computer science;operating system;world wide web;tmpdir	ML	-33.02489113401209	-14.654771390809868	41554
ef1cf9ae9aed46682ef7e42b9385e169b772f258	a new approach to noncooperative games under uncertainty		The novelty of the approach presented in this paper is that each player of a conflict seeks not only to increase his payoff, but also to reduce his risk, taking into account a possible realization of any uncertainty from a given admissible set. A new concept, the so-called strongly guaranteed Nash equilibrium in payoffs and risks, is introduced and its existence in mixed strategies is proved under standard constraints for noncooperative games, i.e., compact sets of players’ strategies and continuous payoff functions.		Vladislav Iosifovich Zhukovskiy;Tatiana Vladimirovna Makarkina;Maria Ivanovna Vysokos	2018	IGTR	10.1142/S0219198917500244	novelty;mathematical economics;admissible set;microeconomics;welfare economics;economics;traveler's dilemma;best response;epsilon-equilibrium;risk dominance;nash equilibrium;stochastic game	HCI	-6.747799595232082	-1.828949953930494	41661
2ed593fae2f74f0b063eb5a95fde7e94333aa960	evidential reasoning for webtrust assurance services	insurance data processing case based reasoning;american institute of certified public accountants;belief function;electronic commerce uncertainty information technology html impedance security protection transactions committee world wide web synthetic aperture sonar;insurance data processing;assurance services;risk management;evidential reasoning;webtrust;decision theoretic model evidential reasoning webtrust assurance services evidential network model dempster shafer theory belief functions;network model;decision theory;decision theoretic;case based reasoning;assured service;article	In this paper we develop an evidential network mod for “WebTrust Assurance,” a service recentl proposed by the American Institute of Certified Pub Accountants and the Canadian Institute of Charter Accountants. Our model augments the AICPA/CIC approach and presents five categories of assertio related to providing WebTrust Assurance. We th derive goals, sub-goals and evidence that are rela to the overall assurance to be provided. Th aggregation of evidence and the resolution uncertainties in the model follow the approach Dempster-Shafer theory of belief functions. Next consider the assurance planning problem and deve a decision theoretic model for this problem.	theory	Rajendra P. Srivastava;Theodore J. Mock	1999	J. of Management Information Systems	10.1109/HICSS.1999.772921	case-based reasoning;decision theory;risk management;computer science;knowledge management;artificial intelligence;network model;data mining;evidential reasoning approach;computer security;statistics	ML	-16.909043660105134	-5.413935028249244	41699
d1455a166a388079001a09c3094c0fbe2d4e4407	modeling meta-cognition in a cognitive architecture	human cognition;neural networks;cognitive architecture;cognitive process;metacognition;cognitive modeling;cognitive model;neural network	This paper describes how meta-cognitive processes may be captured within a cognitive architecture Clarion. Existing cognitive architectures often lack built-in metacognitive mechanisms. However, meta-cognitive processes are important, in that they are an essential part of cognition and without them, cognition may not function properly. We contend that meta-cognitive mechanisms should be an integral part of cognitive architectures, and thus they have been developed as a part of Clarion. It is demonstrated how human data of metacognitive experiments may be simulated using Clarion. The simulations show that meta-cognitive processes can be adequately captured within the Clarion framework.	clarion;cognition;cognitive architecture;experiment;floor and ceiling functions;simulation	Ron Sun;Xi Zhang;Robert C. Mathews	2006	Cognitive Systems Research	10.1016/j.cogsys.2005.09.001	psychology;cognitive psychology;cognitive model;cognition;developmental psychology;cognitive architecture;computer science;artificial intelligence;machine learning;clarion;rational analysis;artificial neural network;cognitive science;cognitive robotics;lida	AI	-24.664100624052832	-16.014401877555088	41729
8c6d202ecd958ae2809e10e837029fda8c7c0983	a survey of knowledge representation and retrieval for learning in service robotics		Within the realm of service robotics, researchers have placed a great amount of effort into learning motions and manipulations for task execution by robots. The task of robot learning is very broad, as it involves many tasks such as object detection, action recognition, motion planning, localization, knowledge representation and retrieval, and the intertwining of computer vision and machine learning techniques. In this paper, we focus on how knowledge can be gathered, represented, and reproduced to solve problems as done by researchers in the past decades. We discuss the problems which have existed in robot learning and the solutions, technologies or developments (if any) which have contributed to solving them. Specifically, we look at three broad categories involved in task representation and retrieval for robotics: 1) activity recognition from demonstrations, 2) scene understanding and interpretation, and 3) task representation in robotics datasets and networks. Within each section, we discuss major breakthroughs and how their methods address present issues in robot learning and manipulation.	activity recognition;computer vision;internationalization and localization;knowledge representation and reasoning;machine learning;motion planning;object detection;robot learning;robotics	David Paulius;Yu Sun	2018	CoRR		simulation;activity recognition;engineering;object detection;knowledge representation and reasoning;machine learning;motion planning;robot;robot learning;artificial intelligence;robotics	Robotics	-30.228081536576326	-21.287750026477617	41736
2b43a277cda075803bccca55fc792331e1ff2d8e	a model for investigating the effects of machine autonomy on human behavior	unmanned aerial vehicle;collision avoidance machine autonomy human behavior autonomous machine social situation unmanned aerial vehicles air collision piloted aircraft;aircraft man machine systems remotely operated vehicles collision avoidance;remotely operated vehicles;decision maker;human behavior;human subjects;humans unmanned aerial vehicles aircraft testing collision avoidance error correction man machine systems;collision avoidance;individual difference;man machine systems;aircraft	As autonomous machines become more pervasive, situations arise when human decision-makers receive advice from both machines and other humans. When these instructions conflict, a new social situation is defined for which we have little precedent. The authors propose a model for investigating these situations. The model synthesizes research from several different fields, including machine autonomy, affect, initial trust, individual differences, and training. The model is explained, and a set of propositions is described. The model is used to analyze the case of an air collision in which machines and humans provided conflicting advice. The model is also applied to situations in which unmanned aerial vehicles and piloted aircraft seek to avoid collisions with each other. Ways of testing the model through human subject experiments are discussed.	aerial photography;autonomous robot;autonomy;experiment;humans;lisp machine;pervasive informatics;unmanned aerial vehicle	Jeffrey V. Nickerson;Richard R. Reilly	2004	37th Annual Hawaii International Conference on System Sciences, 2004. Proceedings of the	10.1109/HICSS.2004.1265325	remotely operated underwater vehicle;decision-making;simulation;human behavior;computer security	Robotics	-19.838659695249536	-9.36848431768599	41749
87bf2d88a9741644d8bb6ea0606fd582daf428f4	symmetric von neumann-morgenstern stable sets in pure exchange economies	exchange economy;stable set;pareto optimality	We show that in a (finite) neoclassical pure exchange economy (with a weaker monot condition than the usual one): if the number of traders of each type is the same and eve has a corner on one of the commodities, then the set of all symmetric Pareto-optimal alloca the economy (i.e., Pareto-optimal allocations which assign indifferent commodity bundles to t of the same type) is a von Neumann–Morgenstern stable set. Moreover, this is the unique st of symmetric allocations. A similar result holds in atomless economies with a finite number of without the convexity assumption on the preference relations. It is also not necessary to ass the atomless case) that the members of the types’ partition have the same measure.  2003 Elsevier Science (USA). All rights reserved. JEL classification: C71; D51	eve;pareto efficiency;traders	Ezra Einy;Benyamin Shitovitz	2003	Games and Economic Behavior	10.1016/S0899-8256(02)00550-X	financial economics;independent set;economics;microeconomics;mathematical economics;welfare economics	AI	-5.743664222410805	-1.8713406927553733	41751
583dca828c0fcdc18ac6ce489a7a95c59a3ff45f	bringing information retrieval back to database management systems	lucene;performance evaluation;full text search engines;scalability.;dbms;information retrieval;database management system;functional requirement;search engine	Information retrieval emerged as independent research area from traditional database management system more than a decade ago. This was driven by the increasing functional requirements that modern full text search engines have to meet. Current database management systems (DBMS) are not capable of supporting such flexibility. However, with the increase of data to be indexed and retrieved and the increasing heavy workloads, modern search engines suffer from scalability, reliability, distribution and performance problems. The DBMS have a long tradition in coping with these challenges. Instead of reinventing the wheel, we propose using current DBMS as backend to existing full text search engines. This way, we bring back both worlds together. We present a new and simple way for integration and compare the performance of our system to the current implementations based on storing the full text index directly on the file system.	distributed database;experiment;functional requirement;information retrieval;lock (computer science);logical data model;management system;mysql;performance evaluation;reinventing the wheel;robustness (computer science);scalability;search engine indexing;system integration;web search engine	Khaled Nagi	2007			human–computer information retrieval;inverted index;concept search;information retrieval;search engine;adversarial information retrieval;full text search;document retrieval;database;data retrieval;computer science	DB	-31.75726403806578	2.1823119202749486	41771
677f97068becaf4ef744cadf8eb4520db02a6a62	context aware architecture for distributed robotics	path planning;servers;monitoring;bandwidth;context;robot kinematics	Multi-robot applications in industrial scenarios have to cover a large spectrum of tasks reaching from low level control functions on the machine level up to high level coordination tasks. The configuration of these tasks related to single or multi-robot algorithms depends on the individual requirements of the scenario (i.e. number of entities, communication bandwidth, failure assumptions). Therefore, the developer may decide to run a path planning algorithm individually for each robot to avoid an additional exchange of information. For a scenario with a large communication bandwidth, a planner in the global context would be more suitable in order to receive an optimal result. In this paper we present an architecture that implements this decision online. Our context-aware task controller evaluates the communication situation and triggers a context switch (global, local, individual) of the task execution. By shifting the decision from design-time to run-time, we close the gap between supervision and swarm approaches and provide an optimized behavior.	algorithm;automated planning and scheduling;bandwidth (signal processing);context switch;control function (econometrics);entity;high-level programming language;motion planning;requirement;response time (technology);robot;robotics;simulation;swarm	Martin Seidel;Sebastian Zug	2016	2016 IEEE 21st International Conference on Emerging Technologies and Factory Automation (ETFA)	10.1109/ETFA.2016.7733646	embedded system;real-time computing;simulation;computer science;artificial intelligence;operating system;machine learning;distributed computing;motion planning;bandwidth;robot kinematics;server	Robotics	-19.01621592157512	-8.295623474020527	41781
93cf13d5630806222279db996320d4e8cb54c0b2	modeling interaction between individuals, social networks and public policy to support public health epidemiology	response strategy;social network;fast disease propagation;human behavior;high performance computing;public policy;disease dynamic;stable social interaction;dense social interaction;public health epidemiology;realistic social network;government policies;dynamic system;markov decision process;public health;graph theory;mathematical model;behavioural sciences;social interaction;computer simulation;social networks;markov processes;computational modeling	Human behavior, social networks, and civil infrastructure are closely intertwined. Understanding their co-evolution is critical for designing public policies. Human behaviors and day-to-day activities of individuals create dense social interactions that provide a perfect fabric for fast disease propagation. Conversely, people's behavior in response to public policies and their perception of the crisis can dramatically alter normally stable social interactions. Effective planning and response strategies must take these complicated interactions into account. The basic problem can be modeled as a coupled co-evolving graph dynamical system and can also be viewed as partially observable Markov decision process. As a way to overcome the computational hurdles, we describe an High Performance Computing oriented computer simulation to study this class of problems. Our method provides a novel way to study the co-evolution of human behavior and disease dynamics in very large, realistic social networks with over 100 Million nodes and 6 Billion edges.	computer simulation;graph dynamical system;interaction;markov chain;partially observable markov decision process;partially observable system;social network;software propagation	Keith R. Bisset;Xizhou Feng;Madhav V. Marathe;Shrirang M. Yardi	2009	Proceedings of the 2009 Winter Simulation Conference (WSC)		public policy;social dynamics;simulation;computer science;knowledge management;management science;social network	ML	-16.73874943449133	-18.061624357413066	41869
d5409662be1d9a277cc57edc6c1b27d86b2f3a3d	modèle d'aide à la décision pour la prévention parasismique urbaine. une approche multi-agent de la vulnérabilité du bâti		This paper offers a decision-making tool for poli tics in charge of the prevention of the seismic risk of a city. The multi-agents method ol gy is applied to an urban area as a spatial environment. The focus is on the question o f the public buildings, their maintenance and the investments which allow reducing their vulner ability. The public buildings are viewed as agents whose attributes are the quality of the construction, with a demography which makes them born, become older and eventually d isappear. Their behaviour is mainly governed by public regulations. Our goal is to offe r a method, which is at first experimented for schools and the city of Grenoble, but could be applied to other kinds of buildings and used in other spatial contexts. MOTS-CLÉS : modèle multi-agents, simulation, prévention, risqu e sismique, politique publique, bâtiments, écoles, vulnérabilité.	decision support system;linear algebra;multi-agent system;simulation	Mahfoud Boudis;Yves Saillard;Philippe Guéguen;Paule-Annick Davoine	2010	Revue Internationale de Géomatique	10.3166/rig.20.279-302		AI	-18.14006512877753	-23.41050330262122	41889
854f9f3fe42449142529d3d6249a7c070b8e0f77	a rough set based approach to distributor selection in supply chain management	empirical study;rough set theory;qualitative data;data mining;distributor selections;rough set theory rst;supply chain management scm;statistical techniques;rough set;supply chain management;decision rule	Distributor’s selection is an important issue in Supply chain management, particularly in the current competitive environment. The current research works provide only conceptual, descriptive, and simulation results, focusing mainly on firm resources and general marketing factors. The selection and evaluation of distributors generally incorporate qualitative information; however, analyzing qualitative information is difficult by standard statistical techniques. Consequently, a more suitable approach is desired. In this paper, a method based on Rough set theory, which has been recognized as a powerful tool in dealing with qualitative data in the literature, is introduced and modified for preferred distributor selection. We derived certain decision rules which are able to facilitate distributor selection and identified several significant features based on an empirical study conducted in China. 2010 Elsevier Ltd. All rights reserved.	rough set;set theory;simulation	Zhonghai Zou;Tzu-Liang Tseng;Hansuk Sohn;Guofang Song;Rafael Gutierrez	2011	Expert Syst. Appl.	10.1016/j.eswa.2010.06.021	supply chain management;rough set;computer science;machine learning;data mining;operations research;dominance-based rough set approach	AI	-5.187655156176952	-15.370107743429836	41908
3956270637c6bb9f607f2675efa60360632b9705	qualitative reasoning and cim	mental simulation;common sense reasoning;artificial intelligent;qualitative reasoning;knowledge representation	Qualitative reasoning has been suggested and studied in artificial intelligence as a tool for knowledge representation, mental simulation and simulation of behavior of physical systems. This paper is an attempt to formalize various aspects of human thought covering common sense reasoning about physical reality. We try to point to those CIM tasks, which are of qualitative nature. This review helps us to identify those existing qualitative techniques, which are ready to be used in CIM. This paper introduces readers to some techniques of qualitative simulation on examples.	artificial intelligence;commonsense reasoning;computer-integrated manufacturing;knowledge representation and reasoning;simulation	Ivo Marvan;Olga Stepánková	1995		10.1007/3-540-60286-0_122	knowledge representation and reasoning;opportunistic reasoning;case-based reasoning;qualitative reasoning;verbal reasoning;computer science;knowledge management;artificial intelligence;adaptive reasoning;model-based reasoning;machine learning;procedural reasoning system;psychology of reasoning;reasoning system;automated reasoning;deductive reasoning	AI	-26.899097965333613	-9.901570362791446	41935
261a3e124b31ccb084a116951025c238d01ecdd8	evaluating sql-on-hadoop for big data warehousing on not-so-good hardware		Big Data is currently conceptualized as data whose volume, variety or velocity impose significant difficulties in traditional techniques and technologies. Big Data Warehousing is emerging as a new concept for Big Data analytics. In this context, SQL-on-Hadoop systems increased notoriety, providing Structured Query Language (SQL) interfaces and interactive queries on Hadoop. A benchmark based on a denormalized version of the TPC-H is used to compare the performance of Hive on Tez, Spark, Presto and Drill. Some key contributions of this work include: the direct comparison of a vast set of technologies; unlike previous scientific works, SQL-on-Hadoop systems were connected to Hive tables instead of raw files; allow to understand the behaviour of these systems in scenarios with ever-increasing requirements, but not-so-good hardware. Besides these benchmark results, this paper also makes available interesting findings regarding an architecture and infrastructure in SQL-on-Hadoop for Big Data Warehousing, helping practitioners and fostering future research.	apache hadoop;apache hive;benchmark (computing);big data;data model;denormalization;emergence;ibm tivoli storage productivity center;multi-user;presto;query language;random-access memory;relevance;requirement;sql;scalability;schema evolution;scientific literature;star schema;velocity (software development)	Maribel Yasmina Santos;Carlos Costa;João Galvão;Carina Andrade;Bruno Augusto Martinho;Francisca Vale Lima;Eduarda Costa	2017		10.1145/3105831.3105842	data mining;database;sql;computer hardware;architecture;computer science;big data;warehouse;data warehouse	DB	-33.32382406011377	0.03243352331963345	41941
749761dbd58a2cfaab4a51b310579be8a74e2dc2	perspectives on industrial reactor control 2: an update from cpc 3	industrial;model predictive control;monitoring;advanced regulatory control;modeling;reactor	This paper will discuss the evolution of reactor control over the last 25 years within the DuPont Company and its subsidiaries. It will focus on high level trends in control philosophy, systems and approaches. These changes have been necessary in order to achieve higher rates, better yields, improved uptime and a more sustainable footprint. This paper is an update to an article that was presented twenty five years ago at CPC 3. The main focus will be on the use of Model Predictive Control (MPC) for reactor processes.	cartesian perceptual compression;high-level programming language;reactor (software);uptime	Phillip D. Schnelle;John R. Richards	2013	Computers & Chemical Engineering	10.1016/j.compchemeng.2013.03.017	control engineering;systems modeling;engineering;control theory;chemical engineering;model predictive control;mechanical engineering	DB	-23.19429743312725	0.46835230241734366	41959
6d1f8692b42061ba50545de8f07e62e1eac8f01a	complex knowledge in the environmental domain: building intelligent architectures for water management	modelizacion;teoria cognitiva;water management;water resource;cybernetique;cybernetics;multiagent system;architecture systeme;chaos;caos;desarrolo cognitivo;cognitive theory;intelligence artificielle;probabilistic approach;cognitive development;approche deterministe;theorie cognitive;cognitive architecture;social cognition;deterministic approach;modelisation;planificacion;gestion recurso agua;developpement cognitif;enfoque probabilista;approche probabiliste;agent intelligent;enfoque determinista;gestion ressource eau;intelligent agent;cognicion social;artificial intelligence;arquitectura sistema;decision process;planning;actitud;cognition sociale;agente inteligente;inteligencia artificial;water resource management;planification;system architecture;sistema multiagente;modeling;attitude;systeme multiagent;cibernetica;environmental planning	The upcoming argumentative approach to environmental planning is increasingly spreading out, challenging the traditional strong and absolute rationality of planning. Aiming at structuring the complex issues of the environmental domain, rather than simplify problems, several agents need to interact, locate and share behaviours and knowledge, meanwhile learning from each others' attitudes and knowledge patterns. In this context, cybernetic rationality is being increasingly reconsidered as a quite strong theoretical limitation to environmental planning, a background being founded on merely linear paths of elements and states which is hard to be removed. This rationality is indeed able to cope with deterministic processes, but unable to face the probabilistic and chaotic environmental phenomena, so making it extremely hard to point out elements, to schedule times, to respect consistencies. Given this starting conceptual condition, this paper discusses some theoretical and experimental issues for the development of cognitive architectures of intelligent agent communities in water resources management. This is done through the recognition of the common good nature of water resources, which in turn affects the features of social and individual cognitions involved, as well as the decisions processes. Throughout the paper, a special attention is paid to dilemmas of cognitive change and knowledge-inactions development in multi-agent participatory environments, through references to both cognitive and organizational analysis.	intelligent agent	Dino Borri;Domenico Camarda;Laura Grassini	2005		10.1007/11504894_106	attitude;planning;social cognition;simulation;cognitive architecture;cybernetics;computer science;artificial intelligence;cognitive development;intelligent agent	AI	-23.61986997964468	-9.207005619120373	42050
426af52891a37662937ab18527feed2df097da7f	disclosure of information in matching markets with non-transferable utility	costly disclosure of information;increasing differences;non transferable utility;partial unraveling;positive assortative matching;matching markets	We present a model of two-sided matching where utility is non-transferable and information about individuals’ skills is private. Men can freely disclose their skill, while women have to pay to make their skill observable. Agents whose skill is unobserved are matched randomly, while others are matched in a standard way. We show that an equilibrium always exists if all agents’ utility satisfies strict monotonicity in partner’s type and women’s utility satisfies increasing differences in their own and men’s skill. We provide a characterization of equilibria, showing that at least a stable equilibrium exists. Comparative statics and welfare analysis show the existence of non-trivial externalities. More precisely, while a reduction in the cost of disclosure and a generalized increase in women’s skills both increase the degree of disclosure, welfare need not increase. Moreover, a generalized increase in men’s skills has ambiguous effects on both welfare and the degree of disclosure.	observable;randomness;supermodular function	Ennio Bilancini;Leonardo Boncinelli	2013	Games and Economic Behavior	10.1016/j.geb.2013.07.003	economics;public economics;microeconomics;mathematical economics;welfare economics	AI	-4.829454660367889	-4.289655195037801	42094
775f026ac095da04e23a504d3a7ed8f58d15bff8	an ann pruning algorithm based approach to vendor selection	cybernetics;neural nets;business environment;neural net;systems analysis;vendor relations;system analysis;selection criteria;artificial neural network;neural network;design methodology	Purpose – The purpose of this paper is to help enterprises to define and refresh their specific vendor selection criteria according to changing situations.Design/methodology/approach – This paper firstly analyzes the variety of vendor selection criteria according to the diverse business environment. Furthermore, an approach of vendor selection based on MW‐OBS (an artificial neural network pruning algorithm) is put forward. MW‐OBS contributes a lot in distinguishing the crucial items of selection criteria based on certain enterprise's operational data, instead of assuming the criteria set subjectively. Meanwhile MW‐OBS evaluates the importance weights of these crucial items in criteria by data training.Findings – The vendor selection criteria is believed to change for diverse enterprises and even for an enterprise's mutative business conditions because of the attribute of materials, cooperation relationships, and supplier's performance. The approach establishes the vendor selection criteria for different e...	algorithm	Qian Li	2009	Kybernetes	10.1108/03684920910943994	systems analysis;design methods;computer science;artificial intelligence;data mining;system analysis;artificial neural network	NLP	-5.174588635699757	-14.963156265602064	42100
e17eedfca8e6d6ee3b937766384e515c4e6c41b4	towards reasoning and coordinating action in the mental space	mental simulation;animal reasoning;passive motion paradigm;forward inverse models;inverse modeling;2 stick paradigm;recurrent neural networks;recurrent neural network	"""Unlike a purely reactive system where the motor output is exclusively controlled by the actual sensory input, a cognitive system must be capable of running mental processes which virtually simulate action sequences aimed at achieving a goal. The mental process either attempts to find a feasible course of action compatible with a number of constraints (Internal, Environmental, Task Specific etc) or selects it from a repertoire of previously learned actions, according to the parameters of the task. If neither reasoning process succeeds, a typical backup strategy is to look for a tool that might allow the operator to match all the task constraints. This further necessitates having the capability to alter ones own goal structures to generate sub-goals which must be successfully accomplished in order to achieve the primary goal. In this paper, we introduce a forward/inverse motor control architecture (FMC/IMC) that relaxes an internal model of the overall kinematic chain to a virtual force field applied to the end effector, in the intended direction of movement. This is analogous to the mechanism of coordinating the motion of a wooden marionette by means of attached strings. The relaxation of the FMC/IMC pair provides a general solution for mentally simulating an action of reaching a target position taking into consideration a range of geometric constraints (range of motion in the joint space, internal and external constraints in the workspace) as well as effort-related constraints (range of torque of the actuators, etc.). In case, the forward simulation is successful, the movement is executed; otherwise the residual """"error"""" or measure of inconsistency is taken as a starting point for breaking the action plan into a sequence of sub actions. This process is achieved using a recurrent neural network (RNN) which coordinates the overall reasoning process of framing and issuing goals to the forward inverse models, searching for alternatives tools in solution space and formation of sub-goals based on past context knowledge and present inputs. The RNN + FMC/IMC system is able to successfully reason and coordinate a diverse range of reaching and grasping sequences with/without tools. Using a simple robotic platform (5 DOF Scorbot arm + Stereo vision) we present results of reasoning and coordination of arm/tool movements (real and mental simulation) specifically directed towards solving the classical 2-stick paradigm from animal reasoning at a non linguistic level."""		Vishwanathan Mohan;Pietro G. Morasso	2007	International journal of neural systems	10.1142/S0129065707001172	simulation;computer science;artificial intelligence;recurrent neural network;machine learning	Robotics	-24.886966412759087	-17.84181386589184	42148
397eb1071f156d7a2fa01e2d0e7d42dfab7d99ec	comparing gis-multicriteria decision analysis for landslide susceptibility mapping for the lake basin, iran	terrain mapping decision making geographic information systems geomorphology lakes;lakes;landslide susceptibility;urmia lake basin landslide mapping landslide susceptibility gis mcda;wlc method gis multicriteria decision analysis methods landslide susceptibility mapping urmia lake basin iran landslide causal factors spatial database factor weight class weight associated factors analytic hierarchy process weighted linear combination ordered weighted average owa method;geomorphology;urmia lake basin;geographic information systems;terrain factors hazards open wireless architecture decision making educational institutions lakes remote sensing;landslide mapping;gis mcda;terrain mapping	In this study, three different GIS-Multicriteria Decision Analysis (MCDA) methods were applied to landslide susceptibility mapping (LSM) for the Urmia lake basin, Iran. Nine landslide causal factors were used, whereby parameters were extracted from an associated spatial database. These factors were evaluated, and then the respective factor weight and class weight were assigned to each of the associated factors. The landslide susceptibility maps were produced based on GIS based MCDA methods including Analytic Hierarchy Process (AHP), Weighted Linear Combination (WLC) and Ordered Weighted Average (OWA). An existing inventory of known landslides within the case study area was compared with the resulting susceptibility maps. Results indicated the AHP performed best in the landslide susceptibility mapping closely followed by the OWA method while the WLC method delivered significantly poorer results.	causal filter;decision analysis;geographic information system;map;minimum-weight triangulation;ordered weighted averaging aggregation operator;outlook.com;spatial database	Bakhtiar Feizizadeh;Thomas Blaschke	2012	2012 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2012.6352388	geomorphology;geology;hydrology;geographic information system;geotechnical engineering	Embedded	-10.207708551580355	-23.225048659485847	42239
de09d48d6774e7c0930e64e87bac2eca43cb23b4	rough sets and approximation schemes	artificial intelligent;approximate reasoning;approximation scheme;rough set	Approximate reasoning is used in a variety of reasoning tasks in Logicbased Artificial Intelligence. In this abstract we compare a number of such reasoning schemes and show how they relate and differ from the approach of Pawlak’s Rough Sets.	approximation;artificial intelligence;rough set	Victor W. Marek;Miroslaw Truszczynski	2007		10.1007/978-3-540-73451-2_4	combinatorics;discrete mathematics;rough set;machine learning;mathematics;reasoning system;dominance-based rough set approach	AI	-21.209469706986866	-1.6640532497788159	42274
fe4b1e01a7fd64b1c0fa7152606b66506b010e41	an anfis approach for evaluation of team-level service climate in gsd projects using taguchi-genetic learning algorithm	service climate;global software development;adaptive neuro fuzzy inference system;taguchi genetic learning algorithm	The GSD team-level service climate is one of the key determinants to achieve the outcome of global software development (GSD) projects from the software service outsourcing perspective. The main aim of this study is to evaluate the GSD team-level service climate and GSD project outcome relationship based on adaptive neuro-fuzzy inference system (ANFIS) with the genetic learning algorithm. For measuring the team-level service climate, the Hybrid Taguchi-Genetic Learning Algorithm (HTGLA) is adopted in the ANFIS, which is more appropriate to determine the optimal premise and consequent constructs by reducing the root-mean-square-error (RMSE) of service climate criteria. For measuring the GSD teamlevel service climate, synthesizing the literature reviews and consistent with the earlier studies on IT service climate which is classified into three main criterion: managerial practices (deliver quality of aguchi-genetic learning algorithm service), global service climate (measure overall perceptions), service leadership (goal setting, work planning, and coordination) which comprises 25 GSD team-level service climate attributes. The experimental results show that the optimal prediction error is obtained by the HTGLA-based ANFIS approach is 3.26%, which outperforms the earlier result that is the optimal prediction errors 4.41% and 5.75% determined, respectively, by ANFIS and statistical methods. © 2015 Elsevier B.V. All rights reserved.	adaptive neuro fuzzy inference system;genetic algorithm;inference engine;neuro-fuzzy;outsourcing;software as a service;software development;taguchi methods	Arun Kumar Sangaiah;Arunkumar Thangavelu;Xiao Zhi Gao;N. Anbazhagan;M. Saleem Durai	2015	Appl. Soft Comput.	10.1016/j.asoc.2015.02.019	simulation;adaptive neuro fuzzy inference system;computer science;artificial intelligence	AI	-6.32062888583957	-17.82883192682634	42294
70d1b2bd4ffd0ce2f098bec976a9ab1ba8e66215	uncertainty and sensitivity analysis for the nominal scenario class in the 2008 performance assessment for the proposed high-level radioactive waste repository at yucca mountain, nevada	radioactive waste disposal;epistemic uncertainty;yucca mountain;uncertainty analysis;sensitivity analysis;nominal scenario class;performance assessment;expected dose	Extensive work has been carried out by the U.S. Department of Energy (DOE) in the development of a proposed geologic repository at Yucca Mountain (YM), Nevada, for the disposal of high-level radioactive waste. In support of this development and an associated license application to the U.S. Nuclear Regulatory Commission (NRC), the DOE completed an extensive performance assessment (PA) for the proposed YM repository in 2008. This presentation describes uncertainty and sensitivity analysis results for the nominal scenario class (i.e., for undisturbed conditions) obtained in the 2008 YM PA. The following topics are addressed: (i) uncertainty and sensitivity analysis procedures, (ii) drip shield and waste package failure, (iii) engineered barrier system conditions, (iv) radionuclide release results for the engineered barrier system, unsaturated zone, and saturated zone, and (v) dose to the reasonably maximally exposed individual specified in the NRC regulations for the YM repository. The present article is part of a special issue of Reliability Engineering and System Safety devoted to the 2008 YM PA; additional articles in the issue describe other aspects of the 2008 YM PA.	high- and low-level	Clifford W. Hansen;G. A. Behie;A. Bier;K. M. Brooks;Yunxia Chen;Jon C. Helton;S. P. Hommel;K. P. Lee;B. Lester;P. D. Mattie;S. Mehta;S. P. Miller;Cédric J. Sallaberry;S. David Sevougian;P. Vo	2014	Rel. Eng. & Sys. Safety	10.1016/j.ress.2013.06.008	uncertainty quantification;uncertainty analysis;engineering;civil engineering;mathematics;forensic engineering;radioactive waste;sensitivity analysis;statistics	SE	-12.584462806177653	-19.54628663358419	42323
9087e8c3e8f2ecd08582ce0ed4ff81baa06e29eb	awareness design and analysis upon two infectious states based on susceptible-exposed-infected-vigilant (seiv) model		In this paper, the interaction between human awareness design and epidemic dynamics over arbitrary directed networks has been studied. People gain awareness and fear of the disease from three information sources and a novel awareness design upon two infectious states is proposed to reduce the susceptibility of individuals, which in turn could affect the threshold and outbreak of the epidemic spreading system. The novel awareness response design is applied to a continuous mean-field SEIV model to illustrate the effectiveness of the system. The system global exponential stability analysis and epidemic threshold embedded with human awareness are proposed in this paper. Simulation studies are carried out to verify the effectiveness of two human awareness which can increase the epidemic threshold, reduce the epidemic breakout scale and inhibit disease transmission.	awareness;breakout box;control theory;embedded system;ising model;network topology;numerical linear algebra;simulation;time complexity	Zhixun Li;Jie Hong;Changbin Yu;Zhiyong Sun	2017	2017 11th Asian Control Conference (ASCC)	10.1109/ASCC.2017.8287539	breakout;risk analysis (engineering);disease;outbreak;business	Mobile	-14.057240877095753	-17.838659077823774	42328
aa7f096b61623cef985e4eaa0b448de33e47ff9b	an agent-based model of the anopheles gambiae mosquito life cycle	oviposition;habitat;malaria;c;daily mortality rate	Anopheles gambiae is the primary mosquito species that serves as a vector for the transmission of the Plasmodium falciparum malaria parasite among humans in malaria endemic areas. This paper introduces an agent-based model representing the Anopheles gambiae mosquito life cycle and its C++ implementation called AGiLESim. This model explicitly simulates the eight distinct stages in the Anopheles gambiae mosquito life cycle and handles female and male mosquitoes in the aquatic and adult phases individually. In this paper, we discuss the daily mortality rate and the mosquito development time at each stage, and the oviposition rule that guides egglaying behavior of gravid adult female mosquito agents. In the implementation section, we illustrate the framework of our C++ software architecture. Finally, sensitivity analysis of the three key parameters, the initial mosquito abundance, the adult daily mortality rate, and the daily temperature, used in our model is given.	agent-based model	Ying Zhou;S. M. Niaz Arifin;James E. Gentile;Steve Kurtz;Gregory J. Davis;Barbara A. Wendelberger	2010			habitat;oviparity	NLP	-16.864949680026417	-21.74562367498958	42355
c9ce320a9898d96c65fce9a79f729d1cf3ecfede	implementable representations of level-2 fuzzy regions for use in databases and gis	level 2 fuzzy regions;technology and engineering;spatial data models	Many spatial data are prone to uncertainty and imprecision, which calls for a way of representing such information. In this contribu- tion, implementable models for the representation of level-2 fuzzy regions are presented. These models are designed to still adhere to the theoreti- cal model of level-2 fuzzy regions - which employs fuzzy set theory and uses level-2 fuzzy sets to combine imprecision with uncertainty - but im- pose some limitations and modifications so that they can be represented and used in a computer system. These limitations are mainly aimed at restricting the amount of data that needs to be stored; apart from the representation structures, the operations also need to be defined in an algorithmic and computable way.	geographic information system	Jörg Verstraete	2012		10.1007/978-3-642-31709-5_37	computer science;theoretical computer science;machine learning;data mining	DB	-22.191716927218334	2.7677592002740727	42370
c85bbdb76e2233d6279e8262c38091995d38d9d6	relevant applications of monte carlo simulation in solvency ii		The definition of solvency for insurance companies, within the European Union, is currently being revised as part of Solvency II Directive. The new definition induces revolutionary changes in the logic of control and expands the responsibilities in business management. The rationale of the fundamental measures of the Directive cannot be understood without reference to probability distribution functions. Many insurers are struggling with the realisation of a so-called “internal model” to assess risks and determine the overall solvency needs, as requested by the Directive. The quantitative assessment of the solvency position of an insurer relies on Monte Carlo simulation, in particular on nested Monte Carlo simulation that produces very hard computational and technological problems to deal with. In this paper, we address methodological and computational issues of an “internal model” designing a tractable formulation of the very complex expectations resulting from the “market-consistent” valuation of fundamental measures, such as Technical Provisions, Solvency Capital Requirement and Probability Distribution Forecast, in the solvency assessment of life insurance companies. We illustrate the software and technological solutions adopted to integrate the Disar system—an asset–liability computational system for monitoring life insurance policies—in advanced computing environments, thus meeting the demand for high computing performance that makes feasible the calculation process of the solvency measures covered by the Directive.	monte carlo method;simulation	Giuseppe Casarano;Gilberto Castellani;Luca Passalacqua;Francesca Perla;Paolo Zanetti	2017	Soft Comput.	10.1007/s00500-015-1847-6	actuarial science	EDA	-9.80436526895723	-18.076389450934006	42399
6bc604168bd90b112a550dc14bb6e36dc039db83	modeling and animating myriapoda: a real-time kinematic/dynamic approach	based modeling;keywords;physics based modeling;cr categories;millipedes;centipedes;behavioral animation;physics;i 3 7 computer graphics;types of simulation;animation;i 6 8 simulation and modeling;three dimensional graphics and realism;artificial life;myriapoda	Unlike two, four, six, and eight legged animals, Myriapoda---i.e., centipedes, millipedes, etc.---have been largely overlooked in the computer graphics literature. We present an artificial life framework for modeling these arthropods and animating their locomotive behavior over regular or irregular surfaces in real time with compelling physical and biological realism. Our hybrid approach combines kinematic and dynamic simulation, as well as a decentralized, distributed leg control system whose emergent behavior is suitable for animating simulated myriapoda of different morphologies with the characteristically vivid leg wave patterns of their biological counterparts. The simulated creature's antennae sense its virtual environment and the sensory information guides its adaptive behaviors, including obstacle avoidance and foraging.	artificial life framework;computer graphics;control system;emergence;obstacle avoidance;real time kinematic;real-time locating system;simulation;virtual reality	Jingyi Fang;Chenfanfu Jiang;Demetri Terzopoulos	2013		10.1145/2485895.2485899	anime;computer vision;simulation;computer science;artificial intelligence;artificial life;computer graphics (images)	Graphics	-20.91015721716147	-20.48607162792864	42409
3c529c869bb5d12afed999ab7f56971689cbe314	connectivity modeling system: a probabilistic modeling tool for the multi-scale tracking of biotic and abiotic variability in the ocean	probabilistic;multi scale;inertial motion;biotic variability;lagrangian;open source	Pelagic organisms’ movement and motion of buoyant particles are driven by processes operating across multiple, spatial and temporal scales. We developed a probabilistic, multi-scale model, the Connectivity Modeling System (CMS), to gain a mechanistic understanding of dispersion and migration processes in the ocean. The model couples offline a new nested-grid technique to a stochastic Lagrangian framework where individual variability is introduced by drawing particles’ attributes at random from specified probability distributions of traits. This allows 1) to track seamlessly a large number of both actively swimming and inertial particles over multiple, independent ocean model domains and 2) to generate ensemble forecasts or hindcasts of the particles’ three dimensional trajectories, dispersal kernels, and transition probability matrices used for connectivity estimates. In addition, CMS provides Lagrangian descriptions of oceanic phenomena (advection, dispersion, retention) and can be used in a broad range of oceanographic applications, from the fate of pollutants to the pathways of water masses in the global ocean. Here we describe the CMS modular system where particle behavior can be augmented with specific features, and a parallel module implementation simplifies data management and CPU intensive computations associated with solving for the tracking of millions of active particles. Some novel features include on-the-fly data access of operational hydrodynamic models, individual particle variability and inertial motion, and multi-nesting capabilities to optimize resolution. We demonstrate the performance of the interpolation algorithm by testing accuracy in tracing the flow stream lines in both time and space and the efficacy of probabilistic modeling in evaluating the bio-physical coupling against empirical data. Finally, following recommended practices for the development of community models, we provide an open source code with a series of coupled standalone, optional modules detailed in a user’s guide. 2012 Elsevier Ltd. All rights reserved. Software availability Name of software: Connectivity Modeling System Developers: Claire B. Paris, Judith Helgers, Erik van Sebille, and Ashwanth Srinivasan Contact details: cparis@rsmas.miami.edu Year first available: 2012 Hardware required: Linux system Software required: Fortran 90 compiler, C-compiler, and NetCDF libraries Program language: Fortran 90 Program size: 1.6 MB Availability and cost: Free Open Source Software (OSS) declared under GNU Lesser General Public License	algorithm;british informatics olympiad;central processing unit;claire;compiler;computation;data access;download;ecology;ensemble forecasting;experiment;fortran;gnu;interpolation;lagrangian system;library (computing);linux;marine ecosystem;markov chain;mike lesser;modular design;netcdf;numerical analysis;online and offline;open-source software;programming tool;self-propelled particles;spatial variability;statistical model;velocity (software development)	Claire B. Paris;Judith Helgers;Erik van Sebille;Ashwanth Srinivasan	2013	Environmental Modelling and Software	10.1016/j.envsoft.2012.12.006	simulation;theoretical computer science;lagrangian;probabilistic logic;ecology	SE	-15.247818904922813	-21.852016126381958	42516
03c49708d495b431087619533239d517c08e20cb	natural deduction in connectionist systems	externalism;cognitive science;representationalism;syntax;cognitive systems;connectionism;learning;systematicity;pensee;langage naturel;syntaxe;cognitive process;connexionnisme;apprentissage;recognition;natural language;natural deduction;pattern recognition;representationnalisme;reconnaissance;systematicite;thought;externalisme;deduction	The relation between logic and thought has long been controversial, but has recently influenced theorizing about the nature of mental processes in cognitive science. One prominent tradition argues that to explain the systematicity of thought we must posit syntactically structured representations inside the cognitive system which can be operated upon by structure sensitive rules similar to those employed in systems of natural deduction. I have argued elsewhere that the systematicity of human thought might better be explained as resulting from the fact that we have learned natural languages which are themselves syntactically structured. According to this view, symbols of natural language are external to the cognitive processing system and what the cognitive system must learn to do is produce and comprehend such symbols. In this paper I pursue that idea by arguing that ability in natural deduction itself may rely on pattern recognition abilities that enable us to operate on external symbols rather than encodings of rules that might be applied to internal representations. To support this suggestion, I present a series of experiments with connectionist networks that have been trained to construct simple natural deductions in sentential logic. These networks not only succeed in reconstructing the derivations on which they have been trained, but in constructing new derivations that are only similar to the ones on which they have been trained.	artificial intelligence;cognition;cognitive science;connectionism;experiment;natural deduction;natural language;pattern recognition;propositional calculus	William Bechtel	1994	Synthese	10.1007/BF01063897	connectionism;cognition;syntax;philosophy;epistemology;thought;mathematics;externalism;natural language;direct and indirect realism;natural deduction	AI	-27.07903953139339	-15.653761621588046	42527
5d1017b11c46098a9be8a910bbc1cb1ad9c58d63	outline for a theory of intelligence	maps;level 2;hierarchical system;memoire;cybernetics;value judgment intelligence theory cybernetics sensory feedback model hierarchical system architecture perceptual resolution planning horizons memories task decomposition world modeling sensory processing;representacion conocimientos;control theory;base donnee;systeme intelligent;architecture systeme;sensory processing;mapa;learning;neural nets;deteccion;sistema inteligente;planning artificial intelligence cybernetics hierarchical systems knowledge engineering;hierarchical systems;systeme hierarchise;database;planning artificial intelligence;base dato;intelligence artificielle;sensory feedback;detection;carte;aprendizaje;sistema jerarquizado;apprentissage;memoria;natural selection;analyse sensorielle;selection naturelle;temporal pattern;intelligent system;pattern recognition;analisis sensorial;automata theory;artificial intelligence;arquitectura sistema;systeme naturel;inteligencia artificial;perception;behavior;knowledge representation;system architecture;architecture computers;learning theory;representation connaissances;seleccion natural;machine intelligence intelligent robots artificial intelligence intelligent sensors psychology biological system modeling humans military computing robotics and automation optical noise;systeme artificiel;sensory analysis;memory;biological models mathematics;knowledge engineering	Intelligence is defined as that which produces successful behavior. Intelligence is assumed to result from natural selection. A model is proposed that integrates knowledge from research in both natural and artificial systems. The model consists of a hierarchical system architecture wherein: 1) control bandwidth decreases about an order of magnitude at each higher level, 2) perceptual resolution of spatial and temporal patterns contracts about an order-of-magnitude at each higher level, 3) goals expand in scope and planning horizons expand in space and time about an order-of-magnitude at each higher level, and 4) models of the world and memories of events expand their range in space and time by about an order-of-magnitude at each higher level. At each level, functional modules perform behavior generation (task decomposition planning and execution), world modeling, sensory processing, and value judgment. Sensory feedback control loops are closed at every level.	control theory;feedback;systems architecture	James S. Albus	1991	IEEE Trans. Systems, Man, and Cybernetics	10.1109/21.97471	sensory analysis;natural selection;simulation;cybernetics;computer science;artificial intelligence;machine learning;learning theory;knowledge engineering;automata theory;memory;perception;artificial neural network;behavior	AI	-24.083366760221853	-17.670139987694252	42581
9187efaad42b328b52b630bd74b66e76a6f86c94	liberal approaches to ranking infinite utility streams: when can we avoid interference?	continuity;intergenerational justice;d71 social choice;social welfare;clubs;d90 general;non interference;associations;committees;d63 equity justice inequality and other normative criteria and measurement;social welfare function;social welfare relation;pareto optimality;pareto axiom	In this work we analyse social welfare relations on sets of finite and infinite utility streams that satisfy various types of liberal non-interference principles. Earlier contributions have established that (finitely) anonymous and strongly Paretian quasiorderings exist that verify non-interference axioms together with weak preference continuity and further consistency. Nevertheless Mariotti and Veneziani [16] prove that a fully liberal non-interfering view of a finite society leads to dictatorship if the weak Pareto principle is imposed. We first prove that this impossibility result vanishes when we extend the horizon to infinity. Then we investigate a related problem: namely, the possibility of combining “standard” semicontinuity with efficiency in the presence of noninterference. We provide several impossibility results that prove that there is a generalised incompatibility between relaxed forms of continuity and noninterference principles, both under ordinal and cardinal views of the problem. José Carlos R. Alcantud Campus Unamuno. Edificio FES. E37007 Salamanca, Spain. Personal webpage: http://web.usal.es/jcr E-mail: jcr@usal.es Tel: +34-923-294640. Fax: +34-923-294686.	fax;global serializability;interference (communication);non-interference (security);numerical analysis;ordinal data;pareto efficiency;responsive web design;scott continuity;semi-continuity;shin megami tensei: persona 3;software incompatibility;uniform resource identifier;web page	José Carlos Rodriguez Alcantud	2013	Social Choice and Welfare	10.1007/s00355-012-0687-x	economics;public economics;social welfare;mathematics;sociology;microeconomics;mathematical economics;law;welfare economics;statistics	AI	-7.098153093317426	-1.0670533377186642	42595
5bebc78825819b643c5b6ca54e4c2bcaf995c3f3	additional media type structured syntax suffixes		"""A content media type name sometimes includes partitioned meta-#N#information distinguished by a structured syntax to permit noting an#N#attribute of the media as a suffix to the name. This document defines#N#several structured syntax suffixes for use with media type#N#registrations. In particular, it defines and registers the """"+json"""",#N#""""+ber"""", """"+der"""", """"+fastinfoset"""", """"+wbxml"""" and """"+zip"""" structured syntax#N#suffixes, and provides a media type structured syntax suffix#N#registration form for the """"+xml"""" structured syntax suffix. This#N#document is not an Internet Standards Track specification; it is#N#published for informational purposes."""		Tony Hansen;Alexey Melnikov	2013	RFC	10.17487/RFC6839	natural language processing;abstract syntax;computer science;linguistics;programming language;abstract syntax tree	NLP	-28.797149469445365	-2.883650962004349	42716
dbe93bcfd52cb2e9c648d453773398547445b5d7	an evidential approach for managing temporal relations uncertainty		Temporal information can be often perceived in a vague way as infected with imprecision and uncertainty. Therefore, we need to find some way of handling the invaluable temporal information. This paper presents a belief functions-based approach to represent temporal relations uncertainty in the point algebra context. We would like to show the concept of mass function is suitable for modeling the uncertain knowledge about possible relations between dates. The temporal uncertainty can also be expressed thanks to a vector of belief measures. A set of rules that allows some reasoning about evidential temporal relations, is then established.		Nessrine El Hadj Salem;Allel HadjAli;Aymen Gammoudi;Boutheina Ben Yaghlane	2016		10.1007/978-3-319-45243-2_9	knowledge management;pattern recognition;data mining;evidential reasoning approach	NLP	-18.509881235178515	2.065374711212114	42735
c46d9f2fb2caf998e4027d8b194fc3bb01c4d2d6	microprocessor-oriented expert systems for statistical analysis	statistical analysis;technical report;expert system	This paper presents a road map of the decision making process of the simulator relative to the statistical significance of the parameters employed in the mathematical model. It defines strengths and weaknesses of a stat ist ical expert system relative to the cost components involved in its use. It introduces a systemsanalytic approach to the definition of parameters before submitting them to statistical scrutiny. A typology of statistical tests is provided. Some available expert systems for statistical applications are reviewed. Examples are given from the Statistical Navigator, a stat ist ical expert system available on the market.	biological anthropology;expert system;mathematical model;microprocessor;simulation;stat (system call);ical	Turkan K. Gardenier	1992		10.1145/167293.167338	computer science;technical report;world wide web;expert system;statistics	EDA	-8.436030446779336	-23.48679073719539	42833
3387c3b3318a06186c4f49ddb4809fbb5f966fa7	improved risk analysis for large projects : bayesian networks approach	computer science			Milijana Fineman	2010				SE	-30.90820344507669	-9.409447816302599	42876
4cf98c98a29dd6dcec83bee6b7abc67767d0ea42	extended event-condition-action rules and fuzzy petri nets based exception handling for workflow management	workflow management;fuzzy reasoning;generalized fuzzy event condition action rule;domain knowledge;typed fuzzy petri net extended by process knowledge;event condition action;exception handling;integral representation;petri net;knowledge modeling;business process;knowledge base	Exception handling plays a key role in dynamic workflow management that enables streamlined business processes. Handling application-specific exceptions is a knowledge-intensive process involving different decision-making strategies and a variety of knowledge, especially much fuzzy knowledge. Current efforts in workflow exception management are not adequate to support the knowledge-based exception handling. This paper proposes a hybrid exception handling approach based on two extended knowledge models, i.e., generalized fuzzy event-condition-action (GFECA) rule and typed fuzzy Petri net extended by process knowledge (TFPN-PK). The approach realizes integrated representation and reasoning of fuzzy and non-fuzzy knowledge as well as specific application domain knowledge and workflow process knowledge. In addition, it supports two handling strategies, i.e., direct decision and analysis-based decision, during exception management. The approach fills in the gaps in existing related researches, i.e., only providing the capability of direct exception handling and neglecting fuzzy knowledge. Based on TFPN-PK, a weighted fuzzy reasoning algorithm is designed to address the reasoning problem of uncertain goal propositions and known goal concepts by combining forward reasoning with backward reasoning and therefore to facilitate cause analysis and handling of workflow exceptions. A prototype system is developed to implement the proposed approach.		Yan Ye;Zhibin Jiang;Xiaodi Diao;Gang Du	2011	Expert Syst. Appl.	10.1016/j.eswa.2011.02.097	exception handling;workflow;knowledge base;computer science;knowledge management;artificial intelligence;data mining;business process;petri net;workflow management system;domain knowledge	DB	-30.950517979313457	-4.679704499241756	42933
9e0663b9d85f00022f5e402cea33bf5c66790edb	managing complexity and unforeseeable uncertainty in startup companies: an empirical study	empirical study;selectionism;learning;new ventures;complexity;unforeseeable uncertainty	Novel startup companies often face not only risk, but also unforeseeable uncertainty (the inability to recognize and articulate all relevant variables affecting performance). The literature recognizes that established risk planning methods are very powerful when the nature of risks is well understood, but that they are insufficient for managing unforeseeable uncertainty. For this case, two fundamental approaches have been identified: trial-and-error learning, or actively searching for information and repeatedly changing the goals and course of action as new information emerges, and selectionism, or pursuing several approaches in parallel to see ex post what works best. Based on a sample of 58 startups in Shanghai, we test predictions from prior literature on the circumstances under which selectionism or trial-and-error learning leads to higher performance. We find that the best approach depends on a combination of uncertainty and complexity of the startup: risk planning is sufficient when both are low; trial-and-error learning promises the highest potential when unforeseeable uncertainty is high, and selectionism is preferred when both unforeseeable uncertainty and complexity are high, provided that the choice of the best trial can be delayed until its true market performance can be assessed.	computer performance;risk management	Svenja C. Sommer;Christoph H. Loch;Jing Dong	2009	Organization Science	10.1287/orsc.1080.0369	complexity;simulation;economics;operations management;management science;sociology;empirical research;management	AI	-13.659231212895946	-11.85254978894315	42936
a84bc67eb75024a111e9a443829982a3c58d1750	approximate reasoning models by ramon lopez de mántaras, ellis horwood, chichester, 1990, pp 109.search, inference and dependencies in artificial intelligence by murray shanahan and richard southwick, ellis horwood, chichester, 1989, pp 140	artificial intelligent;approximate reasoning		artificial intelligence;bruce ellis	Paul J. Krause	1991	Knowledge Eng. Review	10.1017/S0269888900005841	computer science;artificial intelligence;cognitive science	AI	-27.638261081390993	-8.583299621813445	43007
115bcff07ec24c2a6bfa941e12eedb2094427913	a software system for assessing the spatially distributed ecological risk posed by oil shipping	bayesian network;ecology;oil spill;maritime accident;risk assessment;geospatial	A maritime accident involving an oil tanker may lead to large scale mortality or reductions in populations of coastal species due to oil. The ecological value at stake is the biota on the coast, which are neither uniformly nor randomly distributed. We used an existing oil spill simulation model, an observation database of threatened species, and a valuation method and developed a software system for assessing the spatially distributed ecological risk posed by oil shipping. The approach links a tanker accident model to a set of oil spill simulations and further to a spatial ecological value data set. The tanker accident model is a Bayesian network and thus we present a case of using a Bayesian network in geographic analysis. A case in the Gulf of Finland is used for illustration of the methodology. The method requires and builds on an extensive data collection and generation effort and modeling. The main difference of our work to earlier works on using a Bayesian network in geospatial setting is that in our case the Bayesian network was used to compute the probabilities of spatial scenarios directly in a global sense while in earlier works Bayesian networks have been used for each location separately to obtain global results. The result was a software system that was used by a distributed research team. © 2014 Elsevier Ltd. All rights reserved. Software availability Name (description): license (URL) GDAL þ various libraries (geospatial data access, manipulation and output): free (open source and no cost) (http://www.gdal. org) Hugin Expert (Bayesian network library): proprietary (closed source and fee e limited version is available at no cost) (http://www.hugin.com) Geoinformatica (geospatial application development framework): free (open source and no cost) (http://geoinformatics. aalto.fi/doc/Geoinformatica/html/) Hugin.pm (Perl module for Hugin Expert): free (open source and no cost) (https://geoinformatics.aalto.fi/trac/browser/ bntools/trunk/Hugin) SAFGOF (scripts and add-ons to implement spatial risk assessment): open source, no license (https:// geoinformatics.aalto.fi/trac/browser/safgof/trunk) nukka.lehikoinen@helsinki.fi riikka.venesjarvi@helsinki.fi	application framework;bayesian network;data access;gdal;geoinformatics;https;hugin;library (computing);open-source software;perl module;population;randomness;risk assessment;simulation;software system;value (ethics)	Ari Jolma;A. Lehikoinen;I. Helle;Riikka Venesjärvi	2014	Environmental Modelling and Software	10.1016/j.envsoft.2014.06.023	risk assessment;environmental engineering;computer science;environmental resource management;geospatial analysis;machine learning;bayesian network;data mining;ecology	AI	-15.020967105629802	-22.47954958505602	43046
a87e39cfbe8ec3c8582ef1b2ca5cdeeceea23ba5	a fuzzy cognitive maps tool for developing a rbi&m model	maintenance;criticality analysis;fuzzy cognitive maps;risk based inspection	A proper maintenance plan is directly related to the definition of critical indexes for ensuring a high level of safety and high level in service quality for all equipments in the plants. The traditional approach, according to risk-based inspection and maintenance (RBI&M), requires that each parameter considered in the definition of critical indexes shall be divided into intervals in order to assign it a score. By the elaboration of these scores, the critical indexes are calculated. However, what are the rules that allow the company the definition of the range and the assignment of the relative score? Are these rules subjective or objectives? Literature in the field highlights that these decisions are often carried out by maintenance managers. In order to overcome this approach, in this paper, a method based on Fuzzy Cognitive Maps (FCMs) is presented. FCMs have been used for structuring and supporting decisional processes. The criticality of equipments is described in terms of concepts affecting its functioning. No ranges or scores are defined, but only structural and functional features are considered in order to define a criticality index. The resulting fuzzy model can be used to analyse, simulate, test the influence of concepts and predict the behaviour of the system. The RBI&M model, proposed in this work, has been analysed through a case study of an Italian refinery Copyright © 2014 John Wiley & Sons, Ltd.	automation;business process;computation;critical section;criticality matrix;enterprise information management;fuzzy cognitive map;high-level programming language;ising model;john d. wiley;logistics;maurizio lenzerini;megabyte;new product development;radio frequency;relevance;reliability engineering;risk assessment;self-organized criticality;simulation;soft computing;system safety	Maurizio Bevilacqua;Filippo Emanuele Ciarapica;Giovanni Mazzuto	2016	Quality and Reliability Eng. Int.	10.1002/qre.1756	fuzzy cognitive map;engineering;artificial intelligence;operations management;failure mode, effects, and criticality analysis;operations research	AI	-8.13287168505616	-16.711198307478814	43060
06a17487745a53f02c1bc159655b14c5ff125d5a	implementation of heuristic search in an expert database system	database system;overland search problem;heuristic search;expert database systems;spatial data bases	Abstract   This paper shows how a relational database management system (DBMS) may be extended in order to solve a complex heuristic search problem  DBMS-internally , i.e., without using a host language. To achieve this goal, the query language has been modified to include abstract data types and sophisticated control structures for efficient rule processing. Compared with conventional expert systems shells, this expert database approach seems particularly promising for problems that involve large amounts of data. The example application considered in this paper is the  overland search problem , where one tries to find the best path between two points on a geographic map. In our system the map is represented by a set of disjoint adjacent polygons and stored in an INGRES relational database. The path search was implemented in a rule-based manner using an extension of the INGRES query language QUEL. In order to improve the performance of our system we also describe how to utilize geographic knowledge and geometric algorithms to perform a hierarchical decomposition of the given search problem.	database;heuristic	Oliver Günther	1991	Decision Support Systems	10.1016/0167-9236(91)90040-I	search-oriented architecture;beam search;heuristic;computer science;artificial intelligence;theoretical computer science;database model;machine learning;data mining;database;incremental heuristic search;view;world wide web;database schema;database design	DB	-27.31793211338488	2.487570849221941	43110
cddd2830b3596c077e630b1bb4a4d0c10cfce626	zplan: an automatic reasoning system for situations	automatic reasoning system	Without Abstract	automated reasoning;reasoning system	Frank M. Brown;Seung S. Park;Jim Phelps	1988		10.1007/BFb0012884	opportunistic reasoning;model-based reasoning;reasoning system	NLP	-27.6218293385638	-7.742915923141637	43152
a433dfff894c8cb0f626c6187e9b1561c4107d64	dynamic modeling of trust in human-machine interactions		In an increasingly automated world, trust between humans and autonomous systems is critical for successful integration of these systems into our daily lives. In particular, for autonomous systems to work cooperatively with humans, they must be able to sense and respond to the trust of the human. This inherently requires a control-oriented model of dynamic human trust behavior. In this paper, we describe a gray-box modeling approach for a linear third-order model that captures the dynamic variations of human trust in an obstacle detection sensor. The model is parameterized based on data collected from 581 human subjects, and the goodness of fit is approximately 80% for a general population. We also discuss the effect of demographics, such as national culture and gender, on trust behavior by re-parameterizing our model for subpopulations of data. These demographic-based models can be used to help autonomous systems further predict variations in human trust dynamics.	autonomous robot;autonomous system (internet);box modeling;complex dynamics;human–computer interaction;interaction;synergy	Kumar Akash;Wan-Lin Hu;Tahira Reid;Neera Jain	2017	2017 American Control Conference (ACC)	10.23919/ACC.2017.7963172	control engineering;computer science;simulation;automation;data science;data modeling;system dynamics;human–machine system;autonomous system (internet);population;sense and respond;context model	Robotics	-19.52334155610007	-20.424805906953157	43158
31ed25b4709fb99f9e28f8d78941f6cd04c84acc	a systematic formulation for hazop analysis based on structural model	structural model;hazop;hazards identification	The combination of an automatic HAZOP analysis with a structural model was introduced to obtain a systematic procedure for hazard and mal-operations identification. There are three stages of the proposed procedure. The first stage was used to analyze the conventional hazard and mal-operations for each process unit, whereas the second stage extended the analysis to adjacent units. The interaction style was used to identify the cause–consequence relationships between upstream and downstream unit with the concepts of the non-local path and the dummy parameters. Therefore, a generic HAZOP library will be additional modified. The third stage created the templates for hazard and mal-operations identification for operating arbitrary units. This proposed HAZOP analysis was verified with conventional HAZOP of the defatted soy flour pilot plant with three scenarios. The analysis scheme fulfilled the library of the case study and discovered 18 new consequences for the first scenario, 10 new consequences for the second scenario. For the third scenario, the analysis specified on an arbitrary flash drum by applying three guide-words (more, less and no) and found 46 causes and 83 consequences. The proposed methodology, therefore, can simplify and reveal the guidance for hazards and mal-operations identification. & 2013 Elsevier Ltd. All rights reserved.	de-identification;downstream (software development);dummy variable (statistics);hazard (computer architecture)	Narapan Boonthum;Unchalee Mulalee;Thongchai Srinophakun	2014	Rel. Eng. & Sys. Safety	10.1016/j.ress.2013.08.008	reliability engineering;systems engineering;engineering;forensic engineering;hazard and operability study	Security	-9.309087513217897	-13.27741679266519	43180
640c7a0e10764e5d31c4dfc65c6de819e9e31c5a	a sharable ontology for the formal representation of engineering-design knowledge	engineering design;system modeling;design knowledge	This paper discusses the use of a domain-indendent, sharable ontology for the formal representation of engineering design knowledge, called YMIR. The central concept in YMIR is that of a primitive generic system model which represents the basic dependencies between the behaviour and the form of a technical system. We believe that it is important to integrate existing formal approaches in the diierent engineering disciplines as much as possible in modelling design knowledge. To this end, we explain how these primitive generic components can be deened in terms of System Theory. Engineering design, in this context, consists of synthesising complex speciic system models by combining and instantiating more elementary generic system models, which in turn are built from primitive models. Furthermore, we present the structures in YMIR for representing knowledge about this synthesis process in terms of system models. Based on these knowledge structure concepts, a basic inferencing strategy for the synthesis of technical systems is proposed.	archi;autocad;engineering design process;graphical user interface;heuristic (computer science);knowledge representation and reasoning;prim's algorithm;prolog;shallow parsing;systems theory;web ontology language;wolfram mathematica;workstation	L. K. Alberts	1994			computer science;systems engineering;knowledge management;ontology;body of knowledge;knowledge-based systems;knowledge engineering;open knowledge base connectivity;data mining;knowledge extraction	AI	-30.05480566050118	-5.980743372378379	43304
bed565ca415602dcf80a6b0ed857d7407ad07f30	the relation between protocols and games		Both, games in a game theoretic sense and protocols in an informational sense describe rule based interactions between systems. Some similarities and differences of both approaches are explored and illustrated with the example of the well known game tic tac toe. The main thesis of this article can be roughly states as “protocols, enriched by decisions are games without payoff evaluation”. Introducing decisions as an additional input alphabet to determine the usually nondeterministic transition relation of a protocol leads to a classification of decisions as being either spontaneous (or inducing) or selection decisions. Relating protocols and games, the complementarity of the focus of current game theory and informatics becomes better visible: the focus of current game theory to find distinguished strategies within single interactions requires the introduction of some often quite arbitrary payoff function for optimization purposes. The focus of current informatics to solve the coordination problem for finite systems, that is to determine the nondeterminacies of single interactions by other interactions may contribute to an inappropriate disregard of the decision and thereby the strategy concept of game theory.	complementarity theory;game theory;inductive reasoning;informatics;interaction;mathematical optimization;spontaneous order;whole earth 'lectronic link	Johannes Reich	2009			non-cooperative game;combinatorial game theory;implementation theory;positive political theory;simulation;simultaneous game;computer science;artificial intelligence;metagaming;repeated game;simulations and games in economics education;sequential game;communication;symmetric game	ECom	-11.232657103394164	-0.6174991212158413	43312
e3b5a2803874d6dc400843182767c22e7bae9802	a cyber-physical system simulator for risk-free transport studies	intelligent transportation systems;simulation;highway operations;vehicle to infrastructure communications;vehicle to vehicle communications;cyber physical system simulator;travel behavior	Traffic operations result from human decision making and complex multidriver interaction at different behavioral levels. Cyber-Physical System Simulator (CPSS) is a novel platform for conducting controlled and risk-free driving and traveling behavior studies. The key features of CPSS are: (1) simulation of multiuser immersive driving in a three-dimensional (3D) virtual environment; (2) integration of traffic and communication simulators with human driving based on dedicated middleware; and (3) accessibility of multiuser driving simulator on popular software and hardware platforms. This combination of features allows for the easy collection of large-scale data on interesting phenomena regarding the interaction between multiple user drivers, which is not possible with current single-user driving simulators. The paper's contribution are threefold: (1) to introduce a multiuser driving simulator based on DiVE, the authors original massively multiuser networked 3D virtual environment; (2) to introduce OpenV2X, a middleware for simulating vehicle-to-vehicle (V2V) and vehicle-to-infrastructure (V2I) communication; and (3) to present two experiments based on the CPSS platform. The first experiment investigates the “rubbernecking” phenomenon, where a platoon of four user drivers experiences an accident in the oncoming direction of traffic. Second, the authors report on a pilot study about the effectiveness of a Cooperative Intelligent Transport Systems advisory system with a focus on V2V communications to identify vehicles that drive at high speed.	cyber-physical system	Helmut Prendinger;Marc Miska;Kugamoorthy Gajananan;Alfredo Nantes	2014	Comp.-Aided Civil and Infrastruct. Engineering	10.1111/mice.12068	embedded system;intelligent transportation system;simulation;computer science;engineering;civil engineering;operating system;transport engineering;travel behavior	SE	-21.437905677893323	-23.417372988649724	43348
71921d0ad09d5e55a0ea1fe0348280ea4749f84e	education, neighborhood effects and growth: an agent-based model approach	neighborhood effect;social interaction;agent modeling;agent based model;workingpaper;time preference;poverty trap;self organizing system;neighbourhood effect;growth rate;human capital;neighbourhood effects;neighborhood effects;agent based modelling;long run growth;agent modelling;economic growth;overlapping generations	Endogenous, ideas-led, growth theory and agent based modelling with neighbourhood effects literature are crossed. In an economic overlapping generations framework, it is shown how social interactions and neighbourhood effects are of vital importance in the endogenous determination of the long run number of skilled workers and therefore of the growth prospects of an economy. Neighbourhood effects interact with the initial distribution of educated agents across space and play a key role in the long run stabilisation of the number of educated individuals. Our model implies a tendency towards segregation, with a possibly positive influence on growth, if team effects operate. The long run growth rate is also shown to depend on the rate of time preference. Initial circumstances are of vital importance for long run outcomes. A poor initial education endowment will imply a long run reduced number of skilled workers and a mediocre growth rate, so there no economic convergence tendency. On the contrary, poor societies will grow less, or will even fall into a poverty trap, and will diverge continuously from richer ones.	agent-based model;interaction	Tanya Araújo;Miguel St. Aubyn	2008	Advances in Complex Systems	10.1142/S0219525908001441	social relation;economics;time preference;socioeconomics;economic growth;overlapping generations model;labour economics	Web+IR	-15.532566968763248	-16.240036261788124	43366
1fc61d530b25b155c3f0dd9231e47ff3ca41b897	reduced cover-trees and their application in the sabre access path model	index selection;multi attribute clustering;data base machine;primary index;access paths;cover tree;tree structure;secondary index;reduced cover tree	In this paper we define a tree-structure, the reduced cover-tree (RCT), for implementing both classical indexes and multiattribute search structures and we outline its application in the data access model of the relational multi-processor data base machine SABRE. The kernel of this data access model is an RCT describing the placement of a relation that could be either a multi-attribute clustering scheme also used to - in some extent - substitute secondary indexes, or a non-dense unique key index. If the placement is achieved by multi-attribute clustering a unique key index can be nicely constructed with the same tree-structure. The RCT is represented by a bit-table in a most economic way and thus the number of accesses to memory when retrieval can be considerably cut down. On the average the memory occupation rate should turn about 75 per cent.	sabre (computer system)	Kjell Karlsson	1981			computer science;machine learning;data mining;database;cover tree;tree structure	NLP	-28.180015827629017	2.6848084872968756	43380
b1f51af6d432902ed43fb89f1de2257d5a50cd2f	user-directed, cluster-based retrieval for large document collections in highly parallel environments			computer cluster	Petros Belsis;Charalampos Konstantopoulos;Basilis Mamalis;Grammati E. Pantziou;Christos Skourlas	2012	I. J. Comput. Appl.		information retrieval;computer science	Web+IR	-30.329776975411388	-1.8924915565285019	43395
9ee7ab2f3db823c764167efb60bde1f637cf0ed4	an ontology-based intelligent speed adaptation system for autonomous cars		Intelligent Speed Adaptation (ISA) is one of the key technologies for Advanced Driver Assistance Systems (ADAS), which aims to reduce car accidents by supporting drivers to comply with the speed limit. Context awareness is indispensable for autonomous cars to perceive driving environment, where the information should be represented in a machine-understandable format. Ontologies can represent knowledge in a format that machines can understand and perform human-like reasoning. In this paper, we present an ontology-based ISA system that can detect overspeed situations by accessing to the ontology-based Knowledge Base (KB). We conducted experiments on a car simulator as well as on real-world data collected with an intelligent car. Sensor data are converted into RDF stream data and we construct SPARQL queries and a C-SPARQL query to access to the Knowledge Base. Experimental results show that the ISA system can promptly detect overspeed situations by accessing to the ontology-based Knowledge Base.	architecture design and assessment system;autonomous car;autonomous robot;commonsense reasoning;context awareness;cost efficiency;experiment;knowledge base;obedience (human behavior);ontology (information science);sparql;semantic web rule language;sensor;simulation	Lihua Zhao;Ryutaro Ichise;Seiichi Mita;Yutaka Sasaki	2014		10.1007/978-3-319-15615-6_30	real-time computing;rdf;advanced driver assistance systems;ontology;sparql;knowledge base;intelligent speed adaptation;ontology (information science);context awareness;computer science	AI	-33.50533646747709	-12.763175278596796	43404
929496f56e751bfb175958ba3a21c97952f38e16	learning to collaborate in distributed environments by means of an awareness-based artificial neural network	learning model;collaboration;distributed environment;learning strategy;awareness;multi agent architecture;distributed collaboration;learning strategies;artificial neural network	This paper is an extension of a previous work presented in International Work Conference on Artificial Neural Network 2009 (IWANN 2009). The paper contains more details and results of the strategy known as Collaborative Distributed Environment by means of an Awareness & Artificial Neural Network strategy (CAwANN). CAwANN is part of the structure of Awareness-based learning Model for distriButed collAborative enviRonment (AMBAR) which is an awareness-based learning model, developed for distributed environments, that allows nodes to accomplish an effective collaboration by means of a multi-agent architecture in which agents are aware of its surroundings by means of a parametrical and flexible use of this information. CAwANN is an ANN-based strategy used to include learning abilities into AMBAR aiming to improve the effectiveness and efficiency of collaboration process by learning three different processes: (1) to collaborate based on levels of awareness; (2) to select a potential candidate to negotiate on saturated conditions; and (3) to decide whether or not a node must change the information that describes its current conditions related with collaboration. Based on the definitions of efficiency and effectiveness presented in this paper and the results obtained from simulated conditions CAwANN has an average efficiency of 100% and an average effectiveness of 86%.	artificial neural network;awareness	Maurício Paletta;Pilar Herrero	2011	Neurocomputing	10.1016/j.neucom.2011.04.002	error-driven learning;awareness;computer science;knowledge management;artificial intelligence;machine learning;artificial neural network;distributed computing environment;collaboration	ML	-16.776248134970302	-9.785419073280952	43423
ed5a47b8311f7f21dd9403d4be1b2c9117dd38f3	teams of agents	cognitive systems;psychology;psychology multi agent systems cognitive systems;multi agent systems;necessary and sufficient condition;humans permission computer science sufficient conditions particle measurements books software agents insects;team like measures teams of agents sufficient conditions common mental state intention	This paper attempts to focus the discussion about necessary and sufficient conditions for the existence of a “team”, the nature of the common mental state required of the agents forming the team, in particular, what an intention is, and various measures of how “team-like” a group of agents is.	mental state;theory	Gordon Beavers;Henry Hexmoor	2001		10.1109/ICSMC.2001.969875	simulation;computer science;knowledge management;artificial intelligence;multi-agent system	AI	-22.46168499482574	-12.332171510880709	43572
a1cb2d34e180e5ff2b3308ed6c578c0d2e807d48	is cognitive dissonance compatible with human evolution?	cd theory cognitive dissonance human evolution contradictory knowledge;cognition;cognition psychology animals presses cultural differences educational institutions multiple signal classification	Cognitive dissonance, CD, leads to discarding of contradictory knowledge. The presentation discusses that all knowledge is contradictory and according to CD theory should have been discarded in evolution before its usefulness would have been established. Therefore a powerful ability should have emerged along with language and diverse knowledge to overcome this aspect of CD. We present experimental evidence that music has this ability. Then we discuss why music might have this ability.	cognitive science;cognitive tutor	Leonid I. Perlovsky;Nobuo Masataka;Michel Cabanac	2013	The 2013 International Joint Conference on Neural Networks (IJCNN)	10.1109/IJCNN.2013.6706903	self-justification;cognition;self-perception theory	AI	-26.1814123575361	-14.528341189993226	43613
0571021a138ec44287837e97e66b775048b50335	assessment of uncertainty in the projective tree test using an anfis learning approach	uncertainty;software engineering;fuzzy logic;psychometrics	In psychology projective tests are interpretative and subjective obtaining results based on the eye of the beholder, they are widely used because they yield rich and unique data and are very useful. Because measurement of drawing attributes have a degree of uncertainty it is possible to explore a fuzzy model approach to better assess interpretative results. This paper presents a study of the tree projective test applied in software development teams as part of RAMSET’s (Role Assignment Methodology for Software Engineering Teams) methodology to assign specific roles to work in the team; using a Takagi-Sugeno-Kang (TSK) Fuzzy Inference System (FIS) and also training data applying an ANFIS model to our case studies we have obtained an application that can help in role assignment decision process recommending best suited roles for performance in software engineering teams.	adaptive neuro fuzzy inference system;eye of the beholder;personnel selection;programmer;programming tool;serial ata;software development;software engineering;sugeno integral;tree testing	Luis G. Martínez;Juan R. Castro;Guillermo Licea Sandoval;Antonio Rodríguez Díaz	2011		10.1007/978-3-642-25330-0_5	fuzzy logic;mathematical optimization;simulation;uncertainty;computer science;artificial intelligence;machine learning;psychometrics;statistics	SE	-7.212630041091365	-17.915490024727013	43655
bed8c8998a5f4fafe31c18086e121bfb56ea8ae7	naoisis: a 3-d behavioural simulator for the nao humanoid robot	robot simulators;robotic soccer;strategic behaviours	We present NaOISIS, a three-dimensional behavioural simulator for the NAO humanoid robot, aimed at designing and testing physically plausible strategic behaviours for multi-agent soccer teams. NaOISIS brings together features from both physical three-dimensional simulators that model robot dynamics and interactions, and two-dimensional environments that are used to design sophisticated team coordination strategies, which are however difficult to implement in practice. To this end, the focus of our design has been on the accurate modeling of the simulated agents’ perceptual limitations and their compatibility with the corresponding capabilities of the real NAO robot. The simulator features presented in this paper suggest that NaOISIS can be used as a rapid prototyping tool for implementing behavioural algorithms for the NAO, and testing them in the context of matches between simulated agents.	algorithm;fundamental interaction;high- and low-level;humanoid robot;matlab;machine learning;model robot;motion planning;multi-agent system;nao (robot);rapid prototyping;reinforcement learning;simulation	Aris Valtazanos;Subramanian Ramamoorthy	2011		10.1007/978-3-642-32060-6_29	computer vision;simulation;artificial intelligence	Robotics	-26.00598532808107	-20.03892222590882	43660
8f3398bbad82c40deb0df31b715dd831b4db4902	using hybrid mcdm to evaluate the service quality expectation in linguistic preference	topsis;service quality expectation;fuzzy set theory;hybrid method;dematel;triangular fuzzy number;service quality	This study proposes a combined fuzzy Technique for Order Performance by Similarity to Ideal Solution (TOPSIS) and the Decision Making Trial and Evaluation Laboratory (DEMATEL) method using linguistic preference to deal with this study objective. This study is aimed to evaluate service quality expectation in hot spring hotel’s ranking problem. This criteria ranking might be a key strategic direction of the hot spring		Ming-Lang Tseng	2011	Appl. Soft Comput.	10.1016/j.asoc.2011.08.011	topsis;computer science;data mining;fuzzy set;service quality	Web+IR	-5.337462793831802	-17.897555749838148	43711
6d3103601dde0266bcefa3db4a17ff2bfee8b51e	adaptive and intelligent agents applied in the taking of decisions inside of a web-based education system	web service;web based educational system;intelligent agent	A new Agents and Components Oriented Architecture for the development of adaptive and intelligent Web-Based Education systems  is presented. This architecture is divided into client and server parts to facilitate adaptability in various configurations  such as online, offline and mobile scenarios. This architecture shows an implementation of adaptability and intelligent technology  in the development of authoring and evaluation tools, which are oriented to offer application level interoperability under  the philosophy of Web Services.  		Alejandro Canales Cruz;Rubén Peredo Valderrama	2009		10.1007/978-3-540-88071-4_5	web service;agent architecture;simulation;computer science;artificial intelligence;autonomous agent;intelligent agent	AI	-32.544538032672484	-23.473987396160616	43723
95b02b824a7d9e07c9a1d0c99ec6d6d054ba76ee	douglas walton, appeal to expert opinion– arguments from authority.	expert opinion	A new pragmatic approach, based on the latest developments in argumentation theory, analyzing appeal to expert opinion as a form of argument....		Ronald E. Leenes	2000	Artificial Intelligence and Law	10.1023/A:1008394704101	dissenting opinion;computer science;opinion	AI	-15.159006524418183	1.6746090360037762	43740
48be46bd2339299b2763d7cb6df6364ce9766a19	multi-agent systems: which research for which applications	distributed system;multiagent system;architecture systeme;systeme reparti;multi agent system;learning;agent based;productique;artificial intelligent;aprendizaje;mechanical engineering;apprentissage;sistema repartido;workflow system;focal point;robotica;coordinacion;arquitectura sistema;physical environment;agent architecture;system architecture;distributed ai;sistema multiagente;computer integrated manufacturing;autonomous robot;systeme multiagent;coordination	For some time now agent-based and multi-agent systems (MAS) have attracted the interest of researchers far beyond traditional computer science and artificial intelligence (AI). In this article we try to identify focal points of interest for researchers working in the area of distributed AI (DAI) and MAS as well as application oriented researchers coming from related disciplines, e.g. electrical and mechanical engineering. We do this by presenting key research topics in DAI and MAS research and by identifying application domains in which the DAI and MAS technologies are most suitable. The research topics we discuss are separated into agent architectures and organisations, negotiation among agents, and selfadaptation of MAS using learning techniques. Regarding the application domains for these techniques we distinguish the application domains according to whether the agents control a physical or virtual body (Gestalt) or not. This separation of the application domains is not strict; it represents two ends of a continuum. On the one end of this continuum we have autonomous robot systems which act in a physical environment (sometimes referred to as hardware agents) and, on the other end, we have abstract environments, such as in workflow systems, which rarely display the geometrical and physical aspects of the environment we are used to living in.	agent-based model;application domain;autonomous robot;computer science;distributed artificial intelligence;environment variable;focal (programming language);gestalt psychology;hoc (programming language);intelligent agent;interaction;interactivity;mental state;multi-agent system;point of interest;problem solving;rationality;requirement;software agent;triune continuum paradigm;utility;virtual body	Eugénio C. Oliveira;Klaus Fischer;Olga Stepánková	1999	Robotics and Autonomous Systems	10.1016/S0921-8890(98)00085-2	agent architecture;simulation;computer science;artificial intelligence;multi-agent system;computer-integrated manufacturing;systems architecture	AI	-23.913935258021407	-8.621790706867971	43799
55c408aa8c24b5a9cc85566235b86488ff62867f	leveraging sources of collective wisdom on the web for discovering technology synergies	semantic similarity;control group;text mining;best practice;product line;collective wisdom;portfolio management;web 2 0;empirical evaluation	One of the central tasks of R&D strategy and portfolio management at large technology companies and research institutions refers to the identification of technological synergies throughout the organization. These efforts are geared towards saving resources by consolidating scattered expertise, sharing best practices, and reusing available technologies across multiple product lines. In the past, this task has been done in a manual evaluation process by technical domain experts. While feasible, the major drawback of this approach is the enormous effort in terms of availability and time: For a structured and complete analysis every combination of any two technologies has to be rated explicitly. We present a novel approach that recommends technological synergies in an automated fashion, making use of abundant collective wisdom from the Web, both in pure textual form as well as classification ontologies. Our method has been deployed for practical support of the synergy evaluation process within our company. We have also conducted empirical evaluations based on randomly selected technology pairs so as to benchmark the accuracy of our approach, as compared to a group of general computer science technologists as well as a control group of domain experts.	benchmark (computing);best practice;computer science;general computer corporation;ontology (information science);randomness;synergy;world wide web	Cai-Nicolas Ziegler;Stefan Jung	2009		10.1145/1571941.1572035	semantic similarity;text mining;computer science;knowledge management;machine learning;data mining;management science;web 2.0;world wide web;information retrieval;scientific control;best practice	Web+IR	-32.992546900402566	-5.686240214839824	43823
c63544434953b17c96c1574c688c77caff91a042	multi-robot cooperative pursuit based on task bundle auctions	case base reasoning;multi robot system;autonomous mobile robot;coalition formation;auction mechanism;case based reasoning;fault injection;pursuit evasion game	This paper mainly discusses the pursuit-evasion games, in which a team of autonomous mobile robots act as pursuers to pursue multiple moving targets cooperatively. In order to reduce the communication load during the task negotiation process, the auction mechanism in Economics was introduced, and an improved task negotiation process based on Task Bundle Auction was proposed. It allocated task dynamically through Dynamic coalition formation of multiple robots. In this paper, we propose the three possible coalition objectives and three different matrics of a multi-robot exploration and pursuit-evader. Based on these extensions, a kind of multi-robot cooperative pursuit algorithm that allows fault injection dynamic alliance is proposed. Simulation results show the feasibility and validity of the given algorithm.	robot	Ze-Su Cai;Lining Sun;Hai-Bo Gao;Pu-Cheng Zhou;Songhao Piao;Qing-Cheng Huang	2008		10.1007/978-3-540-88513-9_26	case-based reasoning;simulation;computer science;engineering;artificial intelligence;computer security	NLP	-17.777123210095255	-10.643821056935703	43839
6c2791ce545119fb4d05850a8533739ca5a33c52	simulated tom thumb, the rule of thumb for autonomous robots		Robots M. A. El-Dosuky 1, M. Z. Rashad 1, T. T. Hamza 1, and A.H. EL-Bassiouny 2 1 Department of Computer Sciences, Faculty of Computers and Information sciences, Mansoura University, Egypt 2 Department of Mathematics, Faculty of Sciences, Mansoura University, Egypt Abstract For a mobile robot to be truly autonomous, it must solve the simultaneous localization and mapping (SLAM) problem. We develop a new metaheuristic algorithm called Simulated Tom Thumb (STT), based on the detailed adventure of the clever Tom Thumb and advances in researches relating to path planning based on potential functions. Investigations show that it is very promising and could be seen as an optimization of the powerful solution of SLAM with data association and learning capabilities. STT outperform JCBB. The performance is 100 % match.	algorithm;autonomous robot;computer science;correspondence problem;joint compatibility branch and bound;mathematical optimization;metaheuristic;mobile robot;motion planning;simultaneous localization and mapping;tom	M. A. El-Dosuky;M. Z. Rashad;T. T. Hamza;Ahmed H. El-Bassiouny	2012	CoRR		simulation;engineering;artificial intelligence;machine learning	Robotics	-31.63548783126941	-20.479873420432988	43851
3807b7856a0be0ca2a6bb40b0ac41eddb0fa08a2	multiplicity of interpretation in an asynchronous updating rule: emergence of collective cognition		Many kinds of interactions among individuals construct collective animal behavior, but how to apply this multiplicity of interactions is often unclear when constructing models. We propose multiplicity of interaction in a simple model constructed from three factors: asynchronous updating, learning site patterns, and agent anticipation. We found that the first two contribute to an efficient searching strategy, and that adding agent anticipation enables sign making (avoidance) in heterogeneous environments. Our model surprisingly suggests that searching strategies and territorial behavior such as boundary marking — seemingly contradicting behaviors — emerge from two aspects of our simple interaction rule. We discuss the possibility of collective cognition in animals when heterogeneous environments change. Our study suggests that multiplicity of interaction in asynchronous updating is very important for understanding many aspects of emergent collective behavior in animals.	cognition;collective intelligence;emergence;interaction;item unique identification;smart environment	Takayuki Niizato	2013		10.7551/978-0-262-31709-2-ch104	artificial intelligence	HCI	-18.315412274479726	-14.663569494813638	43854
560f8a25227ea0f0234b5334782fe7877e0214e5	touring machines: autonomous agents with attitudes	automatic control;layered architecture;computerised control;intelligent robots;processor scheduling;autonomous agents processor scheduling intelligent agent intelligent robots robustness production facilities power generation space stations centralized control automatic control;mobile robots;unpredictable domains;computer architecture;testbed;testbed multilayered integrated architecture autonomous mobile agents touring machines deliberative behaviors unpredictable domains behavior based agent architectures simplified control features layered architecture robustness flexibility dynamic settings control architecture;autonomous agent;control architecture;production facilities;space stations;simplified control features;intelligent agent;autonomous mobile agents;power generation;robustness;multilayered integrated architecture;centralized control;dynamic settings;mobile robots computer architecture computerised control knowledge based systems;mobile agent;touring machines;autonomous agents;deliberative behaviors;knowledge based systems;control method;flexibility;behavior based agent architectures	A multilayered integrated architecture for controlling autonomous mobile agents, or Touring Machines, is introduced. This architecture combines capabilities for producing a range of reactive and deliberative behaviors in dynamic, unpredictable domains. The approach is influenced by recent work on reactive and behavior-based agent architectures. Touring Machines blend sophisticated and simplified control features. Experience shows that this layered architecture can be configured to behave with robustness and flexibility simultaneously in dynamic settings. The implementation of the control architecture on a testbed is reported.<<ETX>>	autonomous agent;autonomous robot;experience;mobile agent;robustness (computer science);testbed	Innes A. Ferguson	1992	Computer	10.1109/2.144395	embedded system;simulation;computer science;artificial intelligence;autonomous agent;automatic control;intelligent agent	AI	-18.731256144949047	-10.301783983267914	43868
a2fc5709fc64690c822468fa2d64215d211be687	keyword oriented bitmap join index for in-memory analytical processing	bitmap join index;keyword;hot data;star join	Nowadays computers are equipped with multicore processors and large RAM to support high performance processing. In-memory analytical processing and just-in-time data warehousing have become realistic for various enterprises. An analytical query normally requires a small proportion of 'hot' data, usually defined by a set of keywords, instead of the entire data set, which involves large volume table scan and costly star joins. Therefore, identifying frequent keywords to retrieve hot data can dramatically reduce the cost of full table scan or star-join. In this paper, we propose a keyword oriented bitmap join index to improve the space efficiency and performance of in-memory data warehouse. Keyword oriented bitmap join index is a global bitmap join index for the entire data warehouse, as opposed to conventional bitmap join indexes which are indicated for specified attributes. With our index, star-join is first converted into keyword search and bitmap combination. The resulting bitmap filters are then employed to filter records. Through the filtering by bitmaps, a star-join is converted into positional scan on the fact table and additional dimension filtering. Both memory bandwidth and analytical performance can then be improved.	bitmap	Yansong Zhang;Mingchuan Su;Xuan Zhou;Shan Wang;Xue Wang	2013		10.1007/978-3-642-38562-9_41	hash join;computer science;bitmap index;star schema;data mining;database;information retrieval	DB	-28.856899788881336	2.049757389674392	43922
a2ac6f43792e3558df3898fe7a6e6c698c401125	an axiomatic foundation of dempster-shafer theory	bayesian theory;belief function;bayes rule;cognitive modeling with heuristics;machine learning;learning strategy;dempster shafer theory;dempster shafer;heuristics;foundations of probability	This abstract introduces an axiomatic study on Dempster-Shafer theory of handling uncertainty in AI systems. A Dempster-Shafer belief function, based on probabilities, is intended to measure the degree of support a piece of evidence provides for various propositions in its domain. Dempster's rule provides a method of combining evidence that may justify partial beliefs. Shafer argued that the Bayesian theory is a special case of this theory and that Bayes rule of conditioning is a special case of Dempster's rule of combination. However, the development of evidence models, including Dempster's rule, is based on intuition and lacks the axiomatic foundation of probability theory.	rule 90	Chun-Hung Tzeng	1989		10.1145/75427.1030291	dempster–shafer theory;artificial intelligence;machine learning;pattern recognition;statistics	AI	-15.142368655553462	0.6977341328383904	43965
210ac39a2035ef33e345c8366c73a96b97f06107	models of human problem solving: detection, diagnosis, and compensation for system failures	man machine interaction;human problem solving;detection;system failures;compensation;diagnosis;problem solving	MAN--MACHINE interaction has been a topic of formal study for well over 50 years. The earliest investigations focused on the environment as it affected the human operator's safety and ability to perform his job. Later investigations began to consider also the design of equipment in terms of identifying possible limitations and devising potential enhancements of operator performance. Much progress has been made in these areas, although a great deal remains to be accomplished. More recently, the impact of automation has come to be of increasing importance. In aircraft, ships, process plants, transportation networks, and other large-scale systems, more and more control loops that were once closed manually are now automatically controlled. As a result the human operator is becoming more of a monitor and supervisor of automation (Sheridan and Johannsen, 1976). The possibility of failures is the primary reason for having human monitoring of automatically controlled processes. If hardware and software failures could not occur and if the automation were capable of handling all contingencies, then human operators would be unnecessary. However, failures	control flow;gunnar johannsen;problem solving	Willian Bill Rouse	1983	Automatica	10.1016/0005-1098(83)90025-0	mathematical optimization;simulation;engineering;artificial intelligence;medical diagnosis	AI	-19.695149248569972	-3.6755820970327697	43986
7a5d7d7bb44bf076f190adc61661c45017e7045c	a method to discover trend reversal patterns using behavioral data		Cognitive biases often influence decision processes related to investment on stock markets. Mainly, this concerns complex problems with perception and understanding of surrounding financial and economic reality. This research was aimed at detecting cognitive biases in the data-driven manner. A few basic cogni- tive biases were examined: the Gambler's Fallacy, and the Hot Hand and Cold Hand effects. Detecting and modeling sequences leading to particular cognitive bi- as can significantly improve the trader's strategy. This paper presents a concept of a platform which can detect specific user beha- viors. These are derived from the observation of technical analysis indicators, as well as the trader's own built-in indicators. Along with the standard functionalities of a stock market simulator, a few methods of data mining were applied: inductive decision trees, sequential association rules, clustering and visual exploration.		Jerzy Korczak;Aleksander Fafula	2011		10.1007/978-3-642-25676-9_7	engineering;artificial intelligence;data mining;social psychology	ML	-18.08727559886252	-19.810673312824353	44026
4c7899fa25cd81507ba8566850067de86d7018d7	online discrete optimization in social networks	networked control systems;learning;optimization learning networked control systems;fictitious centralized entity online discrete optimization social networks collective decision making learning capabilities discrete time model uncertain environment cost functions decision time local interaction costs agent costs default mixed strategy decentralized agent strategies;social networking online decision making learning artificial intelligence multi agent systems;optimization;social network services cost function probability distribution decision making modeling bayes methods physics	We discuss collective decision-making and learning capabilities of social networks in the presence of uncertainty. We present a discrete-time decision-making model for a network of agents in an uncertain environment wherein no agent has a model of the environment evolution. The environment impact on the agent network is captured through a sequence of cost functions, where the costs are revealed to the agents after the agents' decision time. The costs include individual agent costs and local-interaction costs incurred by each agent and its neighbors in the social network. In this model, each agent has a default mixed strategy that stays fixed regardless of the state of the environment, and the agent must expend effort when deviating from this strategy in order to alleviate the impact of the uncertain costs coming from the environment. We construct decentralized agent strategies whereby each agent selects its strategy based only on its related costs and the decisions of its neighbors in the network. In this setting, we quantify social learning in terms of regret, which is given by the difference between the realized network performance over a given time horizon and the best performance that could have been achieved in hindsight by a fictitious centralized entity with full knowledge of the environment's evolution.	best, worst and average case;centralized computing;discrete optimization;glauber;image scaling;markov chain;mathematical optimization;network performance;real-time clock;real-time web;regret (decision theory);social network	Maxim Raginsky;Angelia Nedic	2014	2014 American Control Conference	10.1109/ACC.2014.6858819	mathematical optimization;computer science;knowledge management;machine learning;mathematics;management science	AI	-16.671545736732927	-12.439168671984726	44049
4d1e7eda85768477ce4d5e13d5334c009d7089c3	noncooperatively optimized tolerance: decentralized strategic optimization in complex systems	adverse event;game theory;self organizing system;complex system;forest fire;decision theory;highly optimized tolerance;self organized critical	We introduce noncooperatively optimized tolerance (NOT), a game theoretic generalization of highly optimized tolerance (HOT), which we illustrate in the forest fire framework. As the number of players increases, NOT retains features of HOT, such as robustness and self-dissimilar landscapes, but also develops features of self-organized criticality. The system retains considerable robustness even as it becomes fractured, due in part to emergent cooperation between players, and at the same time exhibits increasing resilience against changes in the environment, giving rise to intermediate regimes where the system is robust to a particular distribution of adverse events, yet not very fragile to changes.	adverse event;complex systems;emergence;exhibits as topic;fracture;generalization (psychology);highly optimized tolerance;program optimization;self-organized criticality;the forest;theory	Yevgeniy Vorobeychik;Jackson Mayo;Robert C. Armstrong;Joseph R. Ruthruff	2011	Physical review letters	10.1103/PhysRevLett.107.108702	game theory;decision theory;adverse effect	ML	-13.477577601311758	-13.334518388484243	44050
1b033c3fbcfd1ca3049ce8901ad844efe2c7b213	distributive concept exploration - a knowledge acquisition tool in formal concept analysis	systeme intelligent;procesamiento informacion;adquisicion del conocimiento;modele mathematique;systeme apprentissage;sistema inteligente;apprentissage conceptuel;modelo matematico;acquisition connaissances;learning systems;aprendizaje conceptual;knowledge acquisition;information processing;intelligent system;mathematical model;aufsatz;concept learning;traitement information;formal concept analysis	Formal Concept Analysis provides a mathematical model of the concept which is used in data analysis for examining conceptual hierarchies in data tables. If these tables are too large to be completely given, then the conceptual structure has to be determined in an interactive knowledge acquisition process from an expert of the domain. The expert is asked either to confirm them or to provide typical counter-examples. The result of the exploration is a lattice that is generated by addind all largest common subconcepts and/or least common superconcepts.	formal concept analysis;knowledge acquisition	Gerd Stumme	1998		10.1007/BFb0095433	concept learning;information processing;computer science;formal concept analysis;artificial intelligence;machine learning;mathematical model;algorithm	Logic	-23.615552696268146	-3.0452668259859683	44137
c7cd5a3d584505ec828730cce04a93b28a344a8f	cockpit systems design in future military aircraft	system design	This paper describes an approach of how to support the design of the crew interface of future air transport/weapon systems. Due to increasing demands put on crews of military aircraft, effective cockpit systems will be required in order to reduce workload and to improve crew performance. This paper presents an approach to crew assistance in tactical flight missions. The underlying tasks are tactical decision making, low-level flight planning and flight guidance. The integration of the Tactical Situation System as part of a knowledge based crew assistant and a flight guidance display system incorporating sensor and synthetic vision components offer a promising solution to improve the situational awareness of the crew. Respective prototypes have been successfully tested and evaluated in a simulated environment.	systems design	Axel Schulte	1997			simulation;flight simulator;synthetic vision system;cockpit;systems design;crew;flight management system;situation awareness;flight planning;engineering	EDA	-24.272829193436056	-23.428563705147692	44143
b15ccb6066afa816995aac385c8f43ffe329d05c	getting symbols out of a neural architecture	neural computation;connectionism;mental representation;dynamic binding;computer architecture;relational processing;human perception;symbolic representation	Traditional connectionist networks are sharply limited as general accounts of human perception and cognition because they are unable to represent relational ideas such as loves (John, Mary) or bigger-than (Volkswagen, breadbox) in a way that allows them to be manipulated as explicitly relational structures. This paper reviews and critiques the four major responses to this problem in the modeling community: (1) reject connectionism (in any form) in favor of traditional symbolic approaches to modeling the mind; (2) reject the idea that mental representations are symbolic (i.e., reject the idea that we can represent relations); and (3) attempt to represent symbolic structures in a connectionist/neural architecture by finding a way to represent role-filler bindings. Approach (3) is further subdivided into (3a) approaches based on varieties of conjunctive coding and (3b) approaches based on dynamic role-filler binding. I will argue that (3b) is necessary to get symbolic processing out of a neural computing architecture. Specifically, I will argue that vector addition is both the best way to accomplish dynamic binding and an essential part of the proper treatment of symbols in a neural architecture.	artificial neural network;cognition;computer architecture;connectionism;late binding;spherical basis;star filler;symbolic computation	John E. Hummel	2011	Connect. Sci.	10.1080/09540091.2011.569880	connectionism;computer science;artificial intelligence;mental representation;machine learning;perception;algorithm;cognitive science;models of neural computation	ML	-26.809170835542574	-15.213432589868868	44177
20966c0c145ad151c4c388d8045e0f4849259f81	information retrieval from digital libraries in sql	database system;dirichlet prior;vector space model;sql;information retrieval;digital library;information retrieval model;query optimization;probabilistic model;ranking;term extraction;documents;relational database system;language model	Information retrieval techniques have been traditionally exploited outside of relational database systems, due to storage overhead, the complexity of programming them inside the database system, and their slow performance in SQL implementations. This project supports the idea that searching and querying digital libraries with information retrieval models in relational database systems can be performed with optimized SQL queries and User-Defined Functions. In our research, we propose several techniques divided into two phases: storing and retrieving. The storing phase includes executing document pre-processing, stop-word removal and term extraction, and the retrieval phase is implemented with three fundamental IR models: the popular Vector Space Model, the Okapi Probabilistic Model, and the Dirichlet Prior Language Model. We conduct experiments using article abstracts from the DBLP bibliography and the ACM Digital Library. We evaluate several query optimizations, compare the on-demand and the static weighting approaches, and we study the performance with conjunctive and disjunctive queries with the three ranking models. Our prototype proved to have linear scalability and a satisfactory performance with medium-sized document collections. Our implementation of the Vector Space Model is competitive with the two other models.	digital library;disjunctive normal form;experiment;information retrieval;language model;library (computing);overhead (computing);preprocessor;prototype;relational database management system;sql;scalability;statistical model;terminology extraction	Carlos Garcia-Alvarado;Carlos Ordonez	2008		10.1145/1458502.1458512	dirichlet distribution;statistical model;data definition language;query optimization;sql;relational database management system;digital library;stored procedure;ranking;relational database;computer science;query by example;database model;machine learning;data mining;database;okapi bm25;conjunctive query;world wide web;vector space model;information retrieval;null;database design;language model;divergence-from-randomness model	DB	-29.55831443719327	3.677427611434278	44252
3aefcb28139b8093e0f629ecb5d0ae91b12d9428	the scope of turing's analysis of effective procedures	philosophy of mathematics;turing machine;decision problem;philosophy of computation;decision procedure;effective procedure;epistemic procedure	Turing's (1936) analysis of effective symbolic procedures is a model of conceptual clarity that plays an essential role in the philosophy of mathematics. Yet appeal is often made to the effectiveness of human procedures in other areas of philosophy. This paper addresses the question of whether Turing's analysis can be applied to a broader class of effective human procedures. We use Sieg's (1994) presentation of Turing's Thesis to argue against Cleland's (1995) objections to Turing machines and we evaluate her proposal to understand the effectiveness of procedures in terms of their reliability and precision. A number of conditions for effectiveness are identified and these are used to provide a general argument against the possibility of a Leibnizian decision procedure.	church–turing thesis;decision problem;turing machine	Jeremy Seligman	2002	Minds and Machines	10.1023/A:1015638814511	turing degree;philosophy of mathematics;epistemology;computer science;turing machine;artificial intelligence;decision problem;algorithm characterizations;algorithm;super-recursive algorithm	SE	-15.180091442250955	3.30532846440758	44335
4523a15a22bcabad38c81e1eba13a1bddd6704c5	the ubiquitous b-tree	database system;indexation;access method	B-trees have become, de facto, a standard for file organization. File indexes of users, dedicated database systems, and general-purpose access methods have all been proposed and nnplemented using B-trees This paper reviews B-trees and shows why they have been so successful It discusses the major variations of the B-tree, especially the B+-tree, contrasting the relatwe merits and costs of each implementatmn. It illustrates a general purpose access method whmh uses a B-tree.	b-tree;database;general-purpose markup language	Douglas Comer	1979	ACM Comput. Surv.	10.1145/356770.356776	computer science;operating system;data mining;database;programming language;access method;world wide web	DB	-29.81532675382774	2.9956637017122985	44368
03708d55f94c5f2485146401e2d9b77f0dd68fe5	evaluation of computer algebra systems using fuzzy ahp at the universities of cyprus		The paper proposes an evaluation model based on fuzzy AHP to help users select CAS that best matches their requirements. The subjectiveness and imprecision of the evaluation process are modeled using linguistic terms. The evaluation criteria framework based on the usability and problem solving capability of CAS is developed. Fuzzy (AHP) is employed to determine the relative importance weights of criteria and the preference order of alternatives. The applicability and effectiveness of the proposed methodology is illustrated.	problem solving;requirement;usability	Ilham Huseyinov;Feride S. Tabak	2013		10.1007/978-3-642-39262-7_45	fuzzy logic;management science;human–computer interaction;analytic hierarchy process;usability;symbolic computation;computer science	AI	-5.689966191060195	-18.454182762980487	44434
de616aa65c8e3861467eaeda654eba27c3566f07	victortango architecture for autonomous navigation in the darpa urban challenge	traffic management city driving autonomous vehicles;selected works;bepress selected works;traffic management;city driving;bepress;autonomous navigation;autonomous vehicles	DOI: 10.2514/1.40547 To solve the autonomous urban driving problem presented by the 2007 DefenseAdvanced Research Project Agency Urban Challenge, team VictorTango developed a tri-level architecture with a deliberative-reactive-deliberative structure. The VictorTango architecture emphasizes a robust, reusable, and modular design, using hardware independent virtual actuators and virtual sensors. Details of the Urban Challenge implementation are provided, highlighting the functionalities and interactions of different modules within the architecture. Situational examples from the Urban Challenge problem illustrate the performance of the architecture in real-world situations, and communications latencies with their effect on decision making are analyzed. Finally, recommendations for future refinement of the architecturearepresented.TheVictorTangoarchitectureultimatelyprovedcapableofcompleting the Urban Challenge problem. Furthermore, the modularity, hardware independence, and robustness of the architecture have enabled it to be applied to other platforms and other problems in the Unmanned Systems field.	darpa grand challenge (2007)	Jesse W. Hurdus;Andrew Bacha;Cheryl Bauman;Stephen Cacciola;Ruel Faruque;Peter King;Chris Terwelp;Patrick Currier;Dennis W. Hong;Al Wicks;Charles F. Reinholtz	2008	JACIC	10.2514/1.40547	computer vision;active traffic management;simulation;engineering;transport engineering	Robotics	-31.136647099961866	-20.523876027344	44526
4cfccb0c385e1663f4243d8ce0ea74d0dacaae75	mechanisms and constitutive relevance	constitutive relevance;capacities;mechanisms;craver	This paper will examine the nature of mechanisms and the distinction between the relevant and irrelevant parts involved in a mechanism’s operation. I first consider Craver’s account of this distinction in his book on the nature of mechanisms, and explain some problems. I then offer a novel account of the distinction that appeals to some resources from Mackie’s theory of causation. I end by explaining how this account enables us to better understand what mechanisms are and their various features.	causality;relevance	Mark B. Couch	2011	Synthese	10.1007/s11229-011-9882-z	epistemology	NLP	-25.652186692834736	-12.689313432721127	44530
2eb696a2476464ee53f3abec38c6639b36b7826a	technological architecture evolutions of information systems: trade-off and optimization	multicriteria optimization;strategic management;mathematical programming;multiobjective optimization;information system;point of view;system architecture;off the shelf;life span	In the normal lifespan of large enterprises, the strategic management of IT often evolves. Existing services must be replaced with new services without impairing operations. The problem of scheduling such replacement is of critical importance for the success of the operation. We analyze this problem from a quantitative point of view, underlining the trade-off nature of its solutions. We formalize this multi-objective optimization problem as a mathematical programming formulation. We discuss its theoretical properties and show that real-world instances can be solved by standard off-the-shelf tools.	information system;mathematical optimization;multi-objective optimization;optimization problem;scheduling (computing);strategic management	Vassilis Giakoumakis;Daniel Krob;Leo Liberti;Fabio Roda	2012	Concurrent Engineering: R&A	10.1177/1063293X12447715	engineering optimization;economics;systems engineering;engineering;operations management;multi-objective optimization;management science;information system;strategic management	DB	-7.715439399009045	-12.603889939733428	44547
ba57355fe25c5890c7757233b993ac10e81280c5	forensic disk image indexing and search in an hpc environment	database management forensic disk image indexing hpc environment searching heterogeneous data sets hadoop high performance computing;parallel processing big data database management systems digital forensics image retrieval indexing;forensics indexing data mining pipelines libraries electronic mail;hpc big data digital forensics	We describe a solution for fast indexing and searching within large heterogeneous data sets whose main purpose is to support investigators that need to analyze forensic disk images originated by seizures or created from bodies of evidence. Our approach is based on a combination of techniques aimed at improving efficiency and reliability of the indexing process.We do not rely on existing frameworks like Hadoop but borrow concepts from different contexts including High Performance Computing and Database management.	apache hadoop;database;disk image;expect;speedup;text corpus	Massimo Bernaschi;Marco Cianfriglia;Antonio Di Marco;Alessandro Sabellico;Gianluigi Me;Giancarlo Carbone;Giuseppe Totaro	2014	2014 International Conference on High Performance Computing & Simulation (HPCS)	10.1109/HPCSim.2014.6903735	computer science;database;internet privacy;world wide web	HPC	-31.390707595539013	-0.6088305168540933	44553
a48843485a637227924bfb553f9d3f47fe7faa83	big data analysis using apache hadoop	shuffling big data analysis apache hadoop data heterogeneity data volume computing infrastructure data management data warehousing data analysis systems hdfs fault tolerant dbms techniques joins graph search data clustering data classification map reduce framework hadoop distributed file system minimization technique file indexing mapping sorting;big data program processors computer architecture file systems fault tolerance fault tolerant systems distributed databases;software fault tolerance big data distributed databases network operating systems pattern clustering	"""We live in on-demand, on-command Digital universe with data prolifering by Institutions, Individuals and Machines at a very high rate. This data is categories as """"Big Data"""" due to its sheer Volume, Variety and Velocity. Most of this data is unstructured, quasi structured or semi structured and it is heterogeneous in nature. The volume and the heterogeneity of data with the speed it is generated, makes it difficult for the present computing infrastructure to manage Big Data. Traditional data management, warehousing and analysis systems fall short of tools to analyze this data. Due to its specific nature of Big Data, it is stored in distributed file system architectures. Hadoop and HDFS by Apache is widely used for storing and managing Big Data. Analyzing Big Data is a challenging task as it involves large distributed file systems which should be fault tolerant, flexible and scalable. Map Reduce is widely been used for the efficient analysis of Big Data. Traditional DBMS techniques like Joins and Indexing and other techniques like graph search is used for classification and clustering of Big Data. These techniques are being adopted to be used in Map Reduce. In this paper we suggest various methods for catering to the problems in hand through Map Reduce framework over Hadoop Distributed File System (HDFS). Map Reduce is a Minimization technique which makes use of file indexing with mapping, sorting, shuffling and finally reducing. Map Reduce techniques have been studied in this paper which is implemented for Big Data analysis using HDFS."""	apache hadoop;big data;cluster analysis;clustered file system;dce distributed file system;facebook graph search;fault tolerance;heterogeneous computing;mapreduce;scalability;semiconductor industry;sorting;statistical classification;velocity	Shankar Ganesh Manikandan;Siddarth Ravi	2014	2014 International Conference on IT Convergence and Security (ICITCS)	10.1109/ICITCS.2014.7021746	programming with big data in r;computer science;operating system;data mining;database	DB	-31.658158772124896	-0.18956000235144455	44583
e978752563760e3c8d76ff3b8a57010deef2727a	the framework of an adaptive user interface for e-learning environment using artificial neural network	artificial neural network		adaptive user interface;artificial neural network	Sucheta Kolekar;Sriram Sanjeevi;Dattatraya S. Bormane	2010			time delay neural network;artificial neural network;learning environment;machine learning;artificial intelligence;computer science;adaptive user interface	Robotics	-29.352592700314037	-19.942695657045817	44598
0f84dcc9d81969f359700574a45cb53fc82a3ee9	emergence of cooperation in competitive environments	network theory graphs behavioural sciences game theory;emergence;prisoner s dilemma;face numerical models games sociology statistics numerical simulation computational modeling;computational modeling;ieee computer society;discrete space competitive environments prisoner s dilemma cooperative behavior agent population directed network continuous space euclidean distance competitive agents;social dynamics prisoner s dilemma emergence;games;statistics;face;numerical models;sociology;numerical simulation;social dynamics	We study the Prisoner's Dilemma in competitive environments with the aim to investigate if, and under which conditions, a cooperative behavior emerges in an agent population. In particular, agents are embedded in two different regions of space, i.e., A continuous space and a discrete space. The former is represented by a simple square, whereas the latter by a directed network. In both spaces, agents face by playing the Prisoner's Dilemma with their neighbors. In the continuous space, neighbors are identified by a rule based on the Euclidean distance among agents. Instead, in the network, agents have as neighbors those connected with them. In the proposed model, the competitiveness corresponds to the number of opponents each agent decides to face, i.e., Competitive agents faces many agents at each time step. Therefore, in the continuous space, the competitiveness is represented by the radius of each agent within it finds its opponents. Instead, in the discrete space, the competitiveness corresponds to the agent's out-degree, i.e., The number of neighbors connected with an arrow starting from the considered agent an directed to its neighbors. We study the evolution of the system over time in both spaces, analyzing also the degree distribution (both the in-degree and the out-degree) of the resulting directed network. It is worth to highlight that, as main result, we found the competitiveness strongly improves cooperation among agents in both domains. Furthermore, as cooperation emerges when the Prisoner's Dilemma is played over a network, several agents become hubs (i.e., Agents with a high out-degree).	competitive analysis (online algorithm);degree distribution;directed graph;embedded system;emergence;euclidean distance;prisoner's dilemma;software agent	Marco Alberto Javarone;Antonio Emanuele Atzeni	2014	2014 Tenth International Conference on Signal-Image Technology and Internet-Based Systems	10.1109/SITIS.2014.97	face;superrationality;games;social dynamics;simulation;computer science;artificial intelligence;mathematics;computational model;prisoner's dilemma;statistics;emergence	AI	-15.852185666334758	-15.802655317450082	44611
23264dd7c1db7ead4d3a7c2ab3705f539d2bc76a	distributing and porting general linguistic tools	general linguistic tool;linguistic tool;computational lexicon;present particular portability problem;command language;code portability;french lexicon;better exploitation;linguistic resource;data portability;adaptable linguistic tool;natural computing	"""Our main motivation is to build general and adaptable linguistic tools and we have faced the problem of their portability. We first make a quick description of the linguistic tools we have at hand and we explain why linguistic tools, unlike other software tools, present pmticular portability problems. We then discuss code portability and also data portability and we describe the method we have used for a French lexicon, showing that portability leads to a more """"natural"""" computational lexicon. We then propose the use of a command language to interface the tools with more complex applications and we show that this technique facilitates integration of tools from various sources, entails a better exploitation of linguistic resources and makes easier the distribution of tools on several machines."""	command language;compiler;data portability;lexicon;library (computing);parsing;personal computer;software portability;unix	Damien Genthial;Jacques Courtin;Jacques Menezo	1996			natural language processing;software portability;natural computing;computer science;theoretical computer science;programming language;portability testing	NLP	-33.195971518559524	-15.126363378969321	44684
7494122a896b812fd64a03ff2a68ef1138b86020	cregis-q: a gis tool to support decision making in case of aquifer contamination emergency		INTRODUCTION The GIS capability to store, query and analyze data is a known important resource in environmental framework and can be very useful in risk analysis. The present work focuses on hazardous liquid transport, which is an issue well suited to being analyzed in a GIS environment (Lovett et al, 1997). When an emergency occurs, as an accidental spill, due for example to the overturning of a tank lorry, a bottleneck is often due not only to the scarce information available, but also to the ability to retrieve it and manage optimally to obtain quick responses, hence support decision making. A customized GIS tool (CREGIS-Q) has been developed to automate data processing and analysis operations (De Smith et al, 2007) in order to obtain firstly an immediate answer to alert the authorities for the resources that could be affected by the accidental event and, secondly, to support further analysis. The latter task is performed by loading the informative layers available for the site (hydrogeology, ground water vulnerability, hydrodynamic parameters, etc.), selecting them from larger databases previously implemented, and providing the relevant information to be used in further analysis such as transport modeling. The tool has been conceived as a part of a “Best Practices” protocol on the management of groundwater contamination in case of accidental events, as required by the National Civil Protection Department. The tool is aimed at both national and local authorities in order to improve response capabilities in emergency situations.	best practice;database;error-tolerant design;geographic information system;it risk management	Anna Bruna Petrangeli;Elisabetta Preziosi;Francesco Campopiano;Angelo Corazza;Andrea Duro	2016	PeerJ PrePrints	10.7287/peerj.preprints.2235v1	emergency management;ecology;systems engineering;software;contamination;civil defense;decision support system;data mining;biology;risk analysis (business);python (programming language)	AI	-12.329758947437023	-21.870233412902017	44687
a9108e91a09df8af1a3a39aae2e222bc22777bb6	tripcube: a trip-oriented vehicle trajectory data indexing structure			spatial database	Tao Xu;Xihui Zhang;Christophe Claramunt;Xiang Li	2018	Computers, Environment and Urban Systems	10.1016/j.compenvurbsys.2017.08.005		Robotics	-27.75263058233536	0.31935748515455364	44739
c21976ceb8a2bdc118b23de34bf908ce2650da28	indeterminancy in recent theories of content	representation;fodor;semantics;disjunction problem;indeterminacy;analytic synthetic distinction;content;meaning;fodor j;epistemology;dretske f;indication;asymmetric dependence;dretske;intentionality	Jerry Fodor has charged that Fred Dretske's account of content suffers from indeterminacy to the extent that we should reject it in favor of Fodor‘s own account. In this paper, we ask what the problem of indeterminacy really is; we distinguish a relatively minor problem we call ‘looseness of fit’ from a major problem of failing to show how to point to what is not there. We sketch Dretske's account of content and how it is supposed to solve the major problem. After presenting Fodor's challenge as the claim that Dretske has failed to solve the major problem, we articulate a response available to Dretske. Although we do not think the response is ultimately successful, we argue that it is every bit as good as the response Fodor has offered to a similar challenge, in his so-called ‘mixed theory.’ The upshot is this: despite advertisements to the contrary, Fodor's theory, in its mixed version, offers no real advantages over Dretske's regarding the serious problem of indeterminacy.	failure;fred (chatterbot);mixed reality;nondeterministic algorithm	Donna Summerfield;Pat Manfredi	1998	Minds and Machines	10.1023/A:1008243329833	psychology;philosophy;epistemology;artificial intelligence;semantics;linguistics;meaning;social psychology;representation;algorithm;cognitive science	ECom	-13.142828406491946	3.434777884247663	44769
ae4b78af285312a6ebf0f68223898989c087a3e1	rough set based approximations of classes in the owl ontology of places in poland (extended abstract)		The main goal of our research is to build the ontology of places in Poland covering a variety of aspects of places, mainly administrative and socio-economic. The ontology is being implemented using the OWL 2 Web Ontology Language. In the created OWL ontology, we can distinguish two kinds of classes, primary classes exactly de ned in the ontology as well as secondary classes de ned over the ontology on the basis of primary classes and properties of individuals considered in the ontology. We show how to use rough sets to approximate secondary classes by means of primary classes in the created ontology. Rough set approximations enable us to extract some useful knowledge about places.	approximation algorithm;ontology (information science);rough set;web ontology language	Piotr Grochowalski;Krzysztof Pancerz;Tomasz Szul	2016			web ontology language;approximations of π;data mining;rough set;mathematics	Web+IR	-22.00467128152692	3.643271317279534	44802
ea8506136644c3cae37c8fe1834c8fd7772a40b2	conditionals right and left: probabilities for the whole family	causal independence;standard probabilistic calculus;probabilistic theory of conditionals;embedded conditionals	The fact that the standard probabilistic calculus does not define probabilities for sentences with embedded conditionals is a fundamental problem for the probabilistic theory of conditionals. Several authors have explored ways to assign probabilities to such sentences, but those proposals have come under criticism for making counterintuitive predictions. This paper examines the source of the problematic predictions and proposes an amendment which corrects them in a principled way. The account brings intuitions about counterfactual conditionals to bear on the interpretation of indicatives and relies on the notion of causal (in)dependence.	causal filter;causality;counterfactual conditional;embedded system;fits;modal logic;refinement (computing);s-expression	Stefan Kaufmann	2009	J. Philosophical Logic	10.1007/s10992-008-9088-0	pure mathematics;mathematics;algorithm	AI	-13.58456076284489	4.083694592580748	44807
3b5e18aaff6a3d1d9c0ab8f4966545bd87ff1a34	adaptive self type changing strategy of incarnation for maintaining optimal intelligent information system	intelligent systems information systems computational intelligence humans system testing knowledge management computer science virtual environment adaptive systems management information systems;biology computing;knowledge network;surviving energy gauge;virtual memory;internal entropy adaptive self type changing incarnation system intelligent information system living thing virtual environment surviving energy gauge knowledge cell virtual memory knowledge network management;knowledge cell;intelligent information system;virtual reality;knowledge network management strategy;management strategy;living thing;virtual reality biology computing knowledge based systems;knowledge network management;intelligent system;adaptive self type changing incarnation system;internal entropy knowledge network management strategy;internal entropy;virtual environment;knowledge based systems	Everything in the world has own properties and interacts with other things dynamically. By their associative relationship they are linked , sometimes combined and separated. These features make a living thing possible to survive in the complex environment. In the case of a sudden change and a barren environment, the living things change their characteristics and adapt their way of life to a new environment. As more computational virtual environment is developed rapidly, the requirement of intelligent system adopting the properties of living things is getting high. Accordingly in this paper for making more efficient intelligent system, adaptive self type changing strategy of incarnation for maintaining optimal intelligent information system was proposed by defining their own types and SEG(surviving energy gauge) of knowledge cell. We apply this system to the virtual memory and show testing results.	artificial intelligence;information system;memory management;type system;virtual reality	Jeong Yon Shim	2007	Third International Conference on Natural Computation (ICNC 2007)	10.1109/ICNC.2007.163	simulation;engineering;knowledge management;artificial intelligence	Robotics	-29.133727412375965	-15.858224812446013	44823
2452fc1c7ee45180ffdd145bae24eee94f0da186	data association in multi-target tracking using belief theory: handling target emergence and disappearance issue	belief networks;target tracking disaster management state estimation uncertainty information resources;belief function;belief theory;virtual hypothesis data association multitarget tracking belief theory handling target emergence disappearance issue;data handling target tracking belief networks;data association;multiple target tracking;multi target tracking;data handling;target tracking	When associating data in the context of multiple target tracking, one is faced with the problem of handling the target emergence and disappearance. In this paper we show that we are able to handle this issue using belief theory based data association method without the introduction of an additional hypothesis to the frame of discernment. Using a specific modelling of belief functions, this is done by detecting and managing a portion of a conflict, which originates from the non-exhaustivity of the frame of discernment. The proposed method is associative and does not rely on the order under which the beliefs are combined. We demonstrate the effectiveness of the proposed method with experiments on simulated data. Additionally, we compare it with the extended world based data association method where a virtual hypothesis is added to the frame of discernment.	correspondence problem;emergence;experiment;expert system;modal logic;open-source software;sensor;state space	Najla Megherbi Bouallagu;Sebastien Ambellouis;Olivier Colot;François Cabestaing	2005	IEEE Conference on Advanced Video and Signal Based Surveillance, 2005.	10.1109/AVSS.2005.1577322	computer science;artificial intelligence;machine learning;group method of data handling;data mining	Robotics	-18.64233961751186	-3.1161919109642144	44838
c4e8a096f0ab347c744dd57570277a2852e47842	babytigers: osaka legged robot team	osaka legged robot team;teaching methods;science and technology;robot learning;graphic user interface;3d reconstruction;action selection	Our interests are learning issues such as action selection, observation strategy without 3D-reconstruction, and emergence of walking. This year we focused our development on embodied trot walking and behavior of goal keeper. We consider that our embodied walking showed the fastest movement in the all twelve teams since we got 2nd place in the RoboCup Challenge 1 and 2, also achieved shortest time in the RoboCup Challenge 3 in spite of our stop-observeact approach.	action selection;emergence;fastest;keeper (password manager)	Noriaki Mitsunaga;Yukie Nagai;Minoru Asada	2000		10.1007/3-540-45324-5_104		Robotics	-31.730633010510516	-20.949484160098727	44877
47e12a3850bed4bc09f78a50807040439340e974	pawlak's conflict model: directions of development	analytical models;electronic mail;information systems;multi agent systems;computational modeling;mathematical model;computer science	The article provides an overview of different approaches to the methods of conflict analysis that are inspired by the model of Zdzislaw Pawlak. In the first part of the paper, Pawlak's original model is described. In the second part, the model proposed by Skowron and Deja is discussed. In the third part, the model proposed by the authors is presented.		Alicja Wakulicz-Deja;Malgorzata Przybyla-Kasperek	2016	2016 Federated Conference on Computer Science and Information Systems (FedCSIS)	10.15439/2016F003	computer science;artificial intelligence;multi-agent system;mathematical model;management science;computational model;information system;statistics	Vision	-22.38897234859089	-10.387233428154726	44901
1d5c444593da0d6e08ac223089eda604bf442e36	blending and choosing within one mind: should judgments be based on exemplars, rules or both?		Accurate judgments and decisions are crucial for success in many areas of human life. The accuracy of a judgment or decision depends largely on the cognitive process applied. In research on judgment, decision making, and categorization, two kinds of cognitive processes have often been contrasted: exemplar-based processes, which use similarity to previously encountered items to make judgments, decisions, and categorizations, and rule-based processes, which use abstracted cue knowledge. Although most cognitive models of judgment and decision processes assume that people rely on both processes, they differ in whether they assume that one process is selected or that both processes are blended into a single response. The present research takes a functional perspective and investigates what kind of interaction between the two processes leads to accurate responses. Based on crossvalidated simulations in real-world domains, it shows that blending ruleand exemplar-based processes generally leads to better judgments than does choosing between them, suggesting that the default strategy should be a blend of both processes, which is abandoned only when feedback justifies it.	alpha compositing;categorization;cognition;cognitive model;logic programming;mind;simulation	Stefan Herzog;Bettina von Helversen	2013				AI	-24.059646004054276	-14.303666618345275	44913
853b1b5b79b0270ab91c8aa478fdb633f92748eb	a dual modelling of evolving political opinion networks		Abstract We present the result of a dual modeling of opinion network. The model complements the agentbased opinion models by attaching to the social agent (voters) network a political opinion (party) network having its own intrinsic mechanisms of evolution. These two sub-networks form a global network which can be either isolated from or dependent on the external influence. Basically, the evolution of the agent network includes link adding and deleting, the opinion changes influenced by social validation, the political climate, the attractivity of the parties and the interaction between them. The opinion network is initially composed of numerous nodes representing opinions or parties which are located on a one dimensional axis according to their political positions. The mechanism of evolution includes union, splitting, change of position and of attractivity, taken into account the pairwise node interaction decaying with node distance in power law. The global evolution ends in a stable distribution of the social agents over a quasi-stable and fluctuating stationary number of remaining parties. Empirical study on the lifetime distribution of numerous parties and vote results is carried out to verify numerical results. keywords: Complex network, opinion network, dual model, network of political parties	apache axis;complex network;global network;normative social influence;numerical analysis;social proof;stationary process	Ru Wang;Qiuping Alexandre Wang	2012	CoRR		power law;complex systems;stable distribution;social system;empirical research;statistics	ML	-14.470981807670022	-16.573888870116086	44989
73061c427537299fca65857efcb7e6f7cb64f532	exploring coordination properties within populations of distributed agents		This paper presents a discussion of coordination properties within populations of geospatially distributed embodied agents. We define two axes: interaction mechanisms andpopulation diversity; and we present a new framework designed for exploring the relationship between values along these axes and the efficiency of solutions for a set of related tasks, e.g., foraging, resource allocation and area coverage.	embodied agent;population	Elizabeth Sklar;Martijn Shut;Konrad Diwold;Simon Parsons	2006			machine learning;computer science;artificial intelligence;population;embodied cognition;foraging;distributed computing;resource allocation	HCI	-17.396080874524912	-14.223371824593682	45085
03db552aeed13298563fb1a62e210dde7c4f0292	a new product development concept selection approach based on cumulative prospect theory and hybrid-information madm		Abstract New product development (NPD) concept selection is one of the foremost phases in the early stage of NPD to identify the best alternative concept for an enterprise. In practice, not all attributes of NPD concept can be estimated precisely considering inevitable uncertainty associated with the NPD processes. Thus, the NPD concept selection is a hybrid-information multiple attribute decision making (HI-MADM) problem, in which attribute values are represented in various formats (e.g., crisp numbers, interval numbers, and linguistic terms). In the concept selection, psychological behaviors of the NPD team (NPDT) have a non-negligible influence on the accuracy of the final decision. Nevertheless, the decision behaviors are rarely considered in existing studies on the concept selection. In this paper, a risk HI-MADM method based on cumulative prospect theory (CPT) is proposed to select the NPD alternative concepts. Initially, decision information in various formats is normalized and the expectations of the NPDT are set as the corresponding reference points with considering the psychology of the NPDT. Subsequently, the gain and loss matrix relative to the reference points is constructed. Furthermore, the prospect values of concept attributes are calculated based on the value function of CPT. Then, by aggregating prospect values and attribute weights by the simple additive weighting (SAW) method, the comprehensive prospect values of alternative concepts are obtained, and then the ranking order of all concepts can be determined. Finally, a NPD case study of a new automatic dishwasher is used to illustrate the feasibility and validity of the proposed approach and meanwhile a sensitivity analysis and a comparison analysis are conducted.	new product development	Cheng-shuo Ying;Yan-Lai Li;Kwai-Sang Chin;Hong-Tai Yang;Jie Xu	2018	Computers & Industrial Engineering	10.1016/j.cie.2018.05.023	new product development;management science;cumulative prospect theory;computer science	SE	-4.73491810369274	-18.219440895800084	45093
de9cd4869c9bf3ca49baffebe640806352112372	smooth dynamics, good performance in cognitive-agent congestion problems		In a congestion game, individuals exhaust a common resource out of selfish behavior. In this scenario, drivers create traffic jams by choosing the shortest route according to their individual knowledge. They can avoid them by communicating their belief states about the traffic situation in real-time through a peer-to-peer network, assuming unlimited bandwidth. We study two potential, cognitively inspired models of human behavior: 1) categorization (quantized memorization and communication), which dampens communication and belief adoption, but leads to undesired oscillations and lower performance. 2) Instance-based blending with memory decay, which achieves good dynamics and near-optimal performance without the same bandwidth needs. We argue that this supports our hypothesis of co-adaptation of cognitive function and communicating communities.	alpha compositing;categorization;cognition;network congestion;peer-to-peer;real-time transcription	David Reitter;Paul Scerri	2013			categorization;machine learning;cog;congestion game;complex system;social psychology;small number;forgetting;cognitive architecture;memorization;artificial intelligence;computer science	Networks	-15.110727932503845	-12.584971157503968	45168
20bcd5ae2ceed305743d2870a5c216f370ddc5ef	an algebraic graphical model for decision with uncertainties, feasibilities, and utilities	conditional independence;decision tree;sequential decision making;generic algorithm;variable elimination;quantified boolean formula;expected utility;operational semantics;artificial intelligent;decision problem;graphical model;influence diagram	Numerous formalisms and dedicated algorithms have been designed in the last decades to model and solve decision making problems. Some formalisms, such as constraint networks, can express “simple” decision problems, while others are designed to take into account uncertainties, unfeasible decisions, and utilities. Even in a single formalism, several variants are often proposed to model different types of uncertainty (probability, possibility...) or utility (additive or not). In this article, we introduce an algebraic graphical model that encompasses a large number of such formalisms: (1) we first adapt previous structures from Friedman, Chu and Halpern for representing uncertainty, utility, and expected utility in order to deal with generic forms of sequential decision making; (2) on these structures, we then introduce composite graphical models that express information via variables linked by “local” functions, thanks to conditional independence; (3) on these graphical models, we finally define a simple class of queries which can represent various scenarios in terms of observabilities and controllabilities. A natural decision-tree semantics for such queries is completed by an equivalent operational semantics, which induces generic algorithms. The proposed framework, called the Plausibility-Feasibility-Utility (PFU) framework, not only provides a better understanding of the links between existing formalisms, but it also covers yet unpublished frameworks (such as possibilistic influence diagrams) and unifies formalisms such as quantified boolean formulas and influence diagrams. Our backtrack and variable elimination generic algorithms are a first step towards unified algorithms.	algorithm;backtracking;decision problem;decision theory;decision tree;emoticon;environment variable;expected utility hypothesis;graphical model;graphical user interface;influence diagram;linear algebra;nat friedman;operational semantics;plausibility structure;semantics (computer science);utility functions on indivisible goods;variable elimination	Cédric Pralet;Thomas Schiex;Gérard Verfaillie	2007	J. Artif. Intell. Res.	10.1613/jair.2151	variable elimination;discrete mathematics;genetic algorithm;optimal decision;influence diagram;conditional independence;expected utility hypothesis;computer science;artificial intelligence;machine learning;decision tree;decision problem;mathematics;graphical model;operational semantics;algorithm	AI	-8.614097764538995	2.7056055926075895	45219
1f7e7bf12e98e99cfd502ef7c0754b99088fbfa9	collective decision with 100 kilobots: speed versus accuracy in binary discrimination problems	majority rule;voter model;chemical reaction network;gillespie algorithm;ordinary differential equations;self organization;swarm robotics;kilobot;collective decision making	Achieving fast and accurate collective decisions with a large number of simple agents without relying on a central planning unit or on global communication is essential for developing complex collective behaviors. In this paper, we investigate the speed versus accuracy trade-off in collective decision-making in the context of a binary discrimination problem—i.e., how a swarm can collectively determine the best of two options. We describe a novel, fully distributed collective decision-making strategy that only requires agents with minimal capabilities and is faster than previous approaches. We evaluate our strategy experimentally, using a swarm of 100 Kilobots, and we study it theoretically, using both continuum and finite-size models. We find that the main factor affecting the speed versus accuracy trade-off of our strategy is the agents’ neighborhood size—i.e., the number of agents with whom the current opinion of each agent is shared. The proposed strategy and the associated theoretical framework can be used to design swarms that take collective decisions at a given level of speed and/or accuracy.	approximation algorithm;chemical reaction network theory;data acquisition;experiment;gillespie algorithm;gmax;kilobot;level of detail;marco dorigo;mathematical model;maxima and minima;modulation;positive feedback;requirement;robot;selection algorithm;swarm;swarm intelligence;swarm robotics;time complexity;triune continuum paradigm;voter model	Gabriele Valentini;Eliseo Ferrante;Heiko Hamann;Marco Dorigo	2015	Autonomous Agents and Multi-Agent Systems	10.1007/s10458-015-9323-3	swarm robotics;ordinary differential equation;majority rule;self-organization;simulation;group decision-making;computer science;artificial intelligence;gillespie algorithm	AI	-17.062395988532934	-11.69379884367843	45231
d24bcee5332cad7e8f3f79ca5d90de8c11cc4042	the use of hugin® to develop bayesian networks as an aid to integrated water resource planning	water management;water resource;bayesian network;uncertainty;integrated water resource management;integrated management;decision making process;uncertainty relation;expert opinion;stakeholder participation;sustainable development	Integrated management is the key to the sustainable development of Europe’s water resources. This means that decisions need to be taken in the light of not only environmental considerations, but also their economic, social, and political impacts; it also requires the active participation of stakeholders in the decision making process. The problem is to find a practical way to achieve these aims. One approach is to use Bayesian networks (Bns): networks allow a range of different factors to be linked together, based on probabilistic dependencies, and at the same time provide a framework within which the contributions of stakeholders can be taken into account. A further strength is that Bns explicitly include the element of uncertainty related to any strategy or decision. The links are based on whatever data are available. This may be an extensive data set, output from a model or, in the absence of data, can be based on expert opinion. Networks are being developed for four catchments in Europe as part of the MERIT project; these are in the UK, Denmark, Italy and Spain. In each case stakeholder groups are contributing to the design of the networks that are used as a focus for the consultation process. As an example, the application to water management of a UK basin is discussed. Crown Copyright 2004 Published by Elsevier Ltd. All rights reserved.	bayesian network;crown group;enterprise resource planning;graphical user interface;holism;hugin;linear algebra;operational system;panos	John Bromley;Nick A. Jackson;O. J. Clymer;Anna Maria Giacomello;Finn Verner Jensen	2005	Environmental Modelling and Software	10.1016/j.envsoft.2003.12.021	decision-making;uncertainty;computer science;environmental resource management;machine learning;bayesian network;mathematics;management science;ecology;sustainable development;statistics	AI	-14.29758394451026	-20.681904635143578	45262
efe10fde2454b9a7e946104ee7e8934cfe18fccf	a computational basis for the presence of sub-cultures in cultural algoithms	topology;cultual algorithms;complexity theory;social fabric;sub cultures problem complexity evolutionary approaches dual inheritance system decision making agent problem solving social fabric population space passive knowledge sources active knowledge sources belief space cultural evolution social evolution computational models cultural algorithms;fixed class;homogeneous topologies;periodic class;chaotic class;heterogeneous topologies;statistics;fabrics;sub cultured heterogeneous topologies;problem solving decision making evolutionary computation multi agent systems;topology sociology statistics cultural differences wheels fabrics complexity theory;sociology;chaotic class cultual algorithms social fabric homogeneous topologies heterogeneous topologies sub cultured heterogeneous topologies fixed class periodic class;wheels;cultural differences	Cultural Algorithms are computational models of social evolution based upon principle of Cultural Evolution. A Cultural Algorithm consists of a Belief Space consisting of a network of active and passive knowledge sources and a Population Space of agents. The agents are connected via a social fabric over which information used in agent problem solving as passed. The knowledge sources in the Belief Space compete with each other in order to influence the decision making of agents in the Population Space. Likewise, the problem solving experiences of agents in the Population Space are sent back to the Belief Space and used to update the knowledge sources there. It is a dual inheritance system in which both the Population and Belief spaces evolve in parallel. In this paper we investigate why sub-cultures can emerge in the Population Space in response to the complexity of the problems presented to a Cultural System. This system is compared with other evolutionary approaches relative to a variety of benchmark problem of varying complexity. We show that the presence of sub-cultures can provide computational advantages in problem landscape that are generated by multiple independent processes. These advantages can increase problem solving efficiency along with the ability to dampen the impact of increase in problem complexity.	benchmark (computing);computation;computational model;cultural algorithm;cultural system;heart rate variability;network topology;population;problem solving;sorting	Yousof A. Gawasmeh;Robert G. Reynolds	2014	2014 IEEE Symposium on Swarm Intelligence	10.1109/SIS.2014.7011813	mathematical optimization;cultural algorithm;artificial intelligence;machine learning;mathematics	AI	-17.694118450508476	-14.578071157971484	45290
3bdea03c14fe3a584f9d1a288761f0a22e369c73	long-term reliability analysis of a microgrid on isolated mode using cpn formalism		It is well-known that the high penetration of Distributed Energy Resources (DERs) can be troublesome because of their unpredictable behaviors. In this context, renewable energy source (RES) appears as one of the most random component, since, in general, they are weather-dependent. The present paper develops a methodology to evaluate the reliability impacts of RES penetration in microgrid’s distribution system. For this evaluation, was used the Colored Petri Nets (CPN) formalism and event-driven analysis, in order to formulate the stochastic behaviors and simulate the system. To avoid the complexity on modeling a microgrid, the agent approach was used, which permits to manage each component as a unique entity, and assemble the whole system using the communication between the agents. Concerning the validation of the proposed methodology, a comparison between the results of CPN modeling and Monte Carlo simulation is done by means of statistical analysis.	coloured petri net;microgrid;reliability engineering;semantics (computer science)	Pedro Henrique Ferreira Machado;Luiz Edival de Souza;Jean-Claude Maun	2017		10.1007/978-3-319-61578-3_5	coloured petri net;monte carlo method;distributed generation;control engineering;petri net;formalism (philosophy);computer science;microgrid	NLP	-10.102745463013093	-14.0565300663877	45368
005efdaf512af4a60a0b29100c0133aee2b2e9ef	automated generation of various and consistent populations in multi-agent simulations		The variety and consistency of the agents behaviors greatly influences the realism in multi-agent simulations, and designing scenarios that simultaneously take into account both aspects is a complex task. To address this issue, we propose an approach to automatically create populations using sample data. It facilitates the designers tasks, and variety as well as consistency issues are handled by the generation model. The proposed approach is based on a behavioral differentiation model that describes the behaviors of agents using norms. To automatically configure this model, we propose an inference mechanism based on Kohonen networks and estimation distribution functions. We then introduce agents generators that can create a specified population, and are automatically configured by the inferred norms. The approach has been evaluated in traffic simulation, in association with a commercial software. Experimental results show that it allows to accurately reproduce the populations represented in sample data.	commercial software;computer simulation;crowd simulation;driving simulator;multi-agent system;norm (social);population;self-organizing map;statistically close;teuvo kohonen	Benoit Lacroix;Philippe Mathieu	2012		10.1007/978-3-642-28786-2_14	data mining;commercial software;self-organizing map;inference;traffic simulation;population;computer science;preemption	AI	-21.836944251103596	-21.25067433309932	45373
0be652d208be5c37738f27b6d9c2f6fe157ae40d	fraque: a framework for rapid query processing evaluation		In this paper we present FRaQuE (Framework for Rapid Query Processing Evaluation). The main purpose of FRaQuE is to offer to a non-expert user a “push-button” solution aimed to help her to evaluate query processors for Ontology Based Data Access, focusing only on input and output data, without take into account both theoretical and technical issues.	central processing unit;data access;input/output;push-button	Jean-Rémi Bourguet;Luca Pulina	2013			web search query;query expansion;database;information retrieval;sargable;rdf query language;computer science;data access;input/output;query optimization	DB	-33.29522069594775	1.6831568964595074	45387
e7ea5e4dc6c67f985b9d2abb8157be2bf08b4773	design and implementation of a fuzzy expert decision support system for vendor selection - case study in oiec iran (oil industerial engineering and construction)	vendor selection;fuzzy logic theory;decision support system.;fuzzy logic;decision support system	Supplier selection and evaluation is a complicated multi objective process with many uncertain factors. Sealed bid evaluation is the most common approach for supplier selection purpose in Iran. In this paper, a fuzzy expert decision support system is developed for solving the vendor selection problem with multiple objectives, in which some of the parameters are fuzzy in nature. Basic important factors considered for supplier selection are price, quality and delivery time. The designed system has been designed and implemented and evaluated in a lead famous company and the results are discussed.	decision support system;performance evaluation;prototype;selection algorithm	Maryam Ramezani;Gholam Ali Montazer	2006				HCI	-4.8625160864667345	-16.91230328239905	45405
c5aa4dce69e4c8aa7a71a6c513da81cfd6be05a8	an agent-based support system for railway station dispatching	agent based;railway station operation;local dispatching;dynamic optimization	A D-Agent support system is modular designed for railway station dispatching.The D-Agent can behave as a dispatcher by embedding expert dispatching knowledge.MIPL formulations are integrated to optimize the railway traffic control.The D-Agent can keep improving by extending skills and learning.Its ability of communication prepares it to work in a dynamic environment. For those railway stations without being automated, railway traffic dispatching still depends on dispatchers, especially under disturbed circumstances. In this study, an agent-based support system, named D-Agent, is developed to assist human dispatchers to make decisions in station operation. To this end, the common knowledge and possible difficulties concerning a station dispatcher in his/her routine work are firstly studied, and the D-Agent is proposed with the purpose of working out practicable solutions to these challenging tasks as a dispatcher does. Then the general model of the D-Agent is established, containing five basic modules: local database, knowledge base, skill base, reasoning mechanism and communication interfaces. The internal skills of the D-Agent are designed to execute various tasks in different scenarios. Besides, a skill extension of the D-Agent with mathematical formulations is particularly discussed in this paper, to find feasible and optimal traffic control solutions in disturbance situations such as train delays and route conflicts. The D-Agent is designed to learn from its own experimental history in applying different skills, and evaluate the skills by preference weights of alternative solutions in a particular task. This procedure allows the agent to have potential for continuous improvement. To verify the applicability of the proposed support system, a D-Agent for a terminal station of subway is simulated. The numerical example of train delays and route conflicts shows that the D-Agent can generally perform as a station dispatcher in fulfilling the specific tasks, estimate the traffic state in different operation strategies and support the decision-making of favored solutions. Significantly, it indicates that the mathematical methods can also been employed by an intelligent agent.	agent-based model	Taomei Zhu;Jose Manuel Mera;Berta Suarez;Joaquín Maroto	2016	Expert Syst. Appl.	10.1016/j.eswa.2016.05.011	simulation;artificial intelligence	HCI	-13.059470688717207	-9.040940822408833	45416
864685560cefa0950388198df85800cf974d19ee	machine learning simulates agent-based model		Running agent-based models (ABMs) is a burdensome computational task, specially so when considering the flexibility ABMs intrinsically provide. This paper uses a bundle of model configuration parameters along with obtained results from a validated ABM to train some Machine Learning methods for socioeconomic optimal cases. A larger space of possible parameters and combinations of parameters are then used as input to predict optimal cases and confirm parameters calibration. Analysis of the parameters of the optimal cases are then compared to the baseline model. This exploratory initial exercise confirms the adequacy of most of the parameters and rules and suggests changing of directions to two parameters. Additionally, it helps highlight metropolitan regions of higher quality of life. Better understanding of ABM mechanisms and parameters’ influence may nudge policy-making slightly closer to optimal level.	agent-based model;baseline (configuration management);computation;machine learning;nudge (instant messaging)	Bernardo Alves Furtado	2017	CoRR		computer science;simulation;agent-based model;machine learning;artificial intelligence	ML	-17.109583713493247	-18.700104955803656	45506
0d8b8ee1f48ceb6287d81d3c493f3c5466f08aae	sunk-cost effects on purely behavioral investments	psichologia cognitiva;comportement;cognitive psychology;inversion;hombre;prise de decision;sunk cost;investment;behavioral decision making;mental accounting;conducta;psychologie cognitive;human;investissement;coste;esfuerzo;sunk costs;effort;behavior;toma decision;effort and decision;homme;cout	Although the sunk-cost effect is a well-documented psychological phenomenon in monetary investments, existing literature investigating behavioral investments (e.g., time, effort) has not replicated this effect except when such investments relate to monetary values. The current explanation for this discrepancy proposes that purely behavioral sunk-cost effects are unlikely to be observed because they are difficult to book, track, and balance in a mental account. Conversely, we argue that, through an effort-justification mechanism, people account for the amount of behavioral resources invested when selecting an alternative, in which case they may fall prey to purely behavioral sunk-cost effects. The results of two experiments support this prediction. Because many decisions involve behavioral investments, behavioral sunk-cost effects should be pervasive psychological phenomena.	discrepancy function;experiment;investments;money;pervasive informatics;prey;replication (computing)	Marcus Cunha;Fabio Caldieraro	2009	Cognitive science	10.1111/j.1551-6709.2008.01005.x	psychology;sunk costs;developmental psychology;sociology;social psychology	HCI	-25.441362054450575	-10.810110508365371	45528
459e08fc70994287a7b8e461436503a063a55941	efficient and validated simulation of crowds for an evacuation assistant	high performance computing;actual result;mass event;large crowd;central aspect;emergency egress;evacuation assistant;john wiley;complex building;parallelization concept;cellular automata	To improve safety at mass events, an evacuation assistant that supports security services in case of emergencies is developed. One central aspect is forecasting the emergency egress of large crowds in complex buildings. This requires realistic models of pedestrian dynamics that can be simulated faster than real-time by using methods applied in high performance computing. We give an overview of the project and present the actual results. We also describe the modeling approaches used thereby focusing on the runtime optimization and parallelization concepts. Copyright © 2012 John Wiley u0026 Sons, Ltd.	simulation	Armel Ulrich Kemloh Wagoum;Mohcine Chraibi;Jonas Mehlich;Armin Seyfried;Andreas Schadschneider	2012	Journal of Visualization and Computer Animation	10.1002/cav.1420	simulation;multimedia;computer security	Visualization	-18.63879700646868	-23.2812508948815	45557
29575790fccb76be6da0ffffe35c477cb5ca5795	comparative evaluation of mal algorithms in a diverse set of ad hoc team problems	multiagent learning;agent coordination;ad hoc teams	This paper is concerned with evaluating different multiagent learning (MAL) algorithms in problems where individual agents may be heterogenous, in the sense of utilizing different learning strategies, without the opportunity for prior agreements or information regarding coordination. Such a situation arises in ad hoc team problems, a model of many practical multiagent systems applications. Prior work in multiagent learning has often been focussed on homogeneous groups of agents, meaning that all agents were identical and a priori aware of this fact. Also, those algorithms that are specifically designed for ad hoc team problems are typically evaluated in teams of agents with fixed behaviours, as opposed to agents which are adapting their behaviours. In this work, we empirically evaluate five MAL algorithms, representing major approaches to multiagent learning but originally developed with the homogeneous setting in mind, to understand their behaviour in a set of ad hoc team problems. All teams consist of agents which are continuously adapting their behaviours. The algorithms are evaluated with respect to a comprehensive characterisation of repeated matrix games, using performance criteria that include considerations such as attainment of equilibrium, social welfare and fairness. Our main conclusion is that there is no clear winner. However, the comparative evaluation also highlights the relative strengths of different algorithms with respect to the type of performance criteria, e.g., social welfare vs. attainment of equilibrium.	agent-based model;algorithm;fairness measure;hoc (programming language);intelligent agent;multi-agent system	Stefano V. Albrecht;Subramanian Ramamoorthy	2012			simulation;computer science;knowledge management;artificial intelligence	AI	-15.361534371989132	-12.1893796209522	45560
9472e9438add20a0493e3d2ce260f4b311ca02b4	abstraction and decomposition in interoperable gis	geographic information system;distributed computing	ion and decomposition in interoperable GIS Agnes Voisard & Heinz Schweppe Published online: 29 Jun 2010. To cite this article: Agnes Voisard & Heinz Schweppe (1998) Abstraction and decomposition in interoperable GIS, International Journal of Geographical Information Science, 12:4, 315-333, DOI: 10.1080/136588198241815 To link to this article: http://dx.doi.org/10.1080/136588198241815 PLEASE SCROLL DOWN FOR ARTICLE Taylor & Francis makes every effort to ensure the accuracy of all the information (the “Content”) contained in the publications on our platform. However, Taylor & Francis, our agents, and our licensors make no representations or warranties whatsoever as to the accuracy, completeness, or suitability for any purpose of the Content. Any opinions and views expressed in this publication are the opinions and views of the authors, and are not the views of or endorsed by Taylor & Francis. The accuracy of the Content should not be relied upon and should be independently verified with primary sources of information. Taylor and Francis shall not be liable for any losses, actions, claims, proceedings, demands, costs, expenses, damages, and other liabilities whatsoever or howsoever caused arising directly or indirectly in connection with, in relation to or arising out of the use of the Content. This article may be used for research, teaching, and private study purposes. Any substantial or systematic reproduction, redistribution, reselling, loan, sub-licensing, systematic supply, or distribution in any form to anyone is expressly forbidden. Terms & Conditions of access and use can be found at http://www.tandfonline.com/page/terms-andconditions D ow nl oa de d by [ U ni ve rs ity o f T as m an ia ] at 0 4: 25 1 4 N ov em be r 20 14 int. j. geographical information science, 1998, vol. 12, no. 4, 315 ± 333	algorithm;browsing;database transaction;defense in depth (computing);distributed computing;encapsulation (networking);extensibility;francis;geographic information system;global variable;heuristic (computer science);high- and low-level;information science;internet;interoperability;materialized view;mathematical optimization;nl (complexity);ontology (information science);openness;operational data store;primary source;principle of abstraction;prototype;query optimization;software engineering;software repository;software system;web service;world wide web	Agnès Voisard;Heinz Schweppe	1998	International Journal of Geographical Information Science	10.1080/136588198241815	distributed gis;enterprise gis;gis file format;computer science;data mining;database;geographic information system;am/fm/gis;world wide web;remote sensing	Robotics	-15.812178202808287	-6.120143590665616	45605
8f0d2fc0501dfbe16984a7dfc1a1677312d1b89d	explanation-based learning for intelligent process planning	fabrication;production control explanation learning artificial intelligence manufacturing data processing process control;explanation;learning process;process planning learning systems manufacturing processes machine learning job shop scheduling couplings product design computer aided manufacturing machining shape;fabricacion;explication;learning;automatisation;intelligence artificielle;automatizacion;aprendizaje;apprentissage;planificacion;production control;machine learning;manufacturing data processing;explanation based learning;manufacturing;process control;learning process planner explanation based learning intelligent process planning variant approach generative approach weak method planner skeletal planner strong method concepts exblipp;artificial intelligence;planning;inteligencia artificial;process planning;planification;learning artificial intelligence;preparation gamme fabrication;automation	The possibility of applying explanation-based learning (EBL), a technique from machine learning, to intelligent process planning is explored. There are currently two major approaches to process planning: the variant approach and the generative approach. Each has advantages and deficiencies. The authors' hypothesis is that EBL could successfully unite these apparently disparate approaches. EBL can be used to transform a traditional weak method planner into a strong method skeletal planner by acquiring strong method concepts which are generalized weak-method explanations of observed episodes. It would seem to be a natural vehicle to unite variant and generative process planning. A learning process planner, called EXBLIPP is implemented to test the authors' hypothesis. It is found that the system possesses many of the intended advantages. It is demonstrated that the EBL capability enables the process planning system to learn new schemata which yield many of the advantages of variant process planning. >	explanation-based learning	Sang-Chan Park;Melinda T. Gervasio;Michael J. Shaw;Gerald DeJong	1993	IEEE Trans. Systems, Man, and Cybernetics	10.1109/21.257757	planning;computer science;artificial intelligence;automation;machine learning;process control;manufacturing;fabrication	Robotics	-23.651189570681858	-4.8413880367414945	45613
c00302561be6703bf52eb5a5402e40da39eb9a2e	causal interpretation in systems of equations	philosophy of science;explanation;naturel;explication;experience;epistemologie;interpretation of;regress;autonomy;natural;invariance;regression;causalite;system;epistemology;econometry;model;modele;manipulation;systeme;system of equations;equation;interpretation de;econometrie;intervention;autonomie;causality	For example, withn = 2, Y in (1) might be interpreted as measuring the height of individual plants in some population, and X1 andX2 as the amount of water and fertilizer that these plants receive. Discussions of regression tell us that an equation like (1) can be used for several different purposes. It can be used simply to describe or represent the pattern of correlations amongY , X1, . . . , Xn but it can also be used to make or represent a causal claim. In the latter case (1) is understood as claiming thatX1, . . . , Xn are causes of Y and thatU represents the combined influence of all the other causes of Y besidesX1, . . . , Xn that are not explicitly represented in (1). I will call this the natural causal interpretation of (1). My interest in this essay is in what causal claims of this sort mean – both in the case of individual equations and systems of equations. What is it that we should understand (1) as claiming when we give it its natural causal interpretation? What conditions must be satisfied if (1) can regarded as making a true causal claim? I distinguish this interpretive issue, as I shall call it, from issues about the conditions under which one can reliably estimate the coefficients in (1). The latter issues are epistemological in character – they have to do not with what (1) means, but rather with when and how one can determine the values of the coefficients in (1). Textbooks in econometrics have a great deal to say about such estimation problems. For example, a familiar result is that if the distribution of the error term satisfies various conditions, one of which is that the error term is uncorrelated with each of the independent variablesXi, then Ordinary Least Squares (OLS) estimators for the coefficients will have various desirable properties like unbiasedness. One of my themes in what follows will be that a substantial amount of recent discussion, both among philosophers and econometricians, has run together	causal filter;coefficient;ordinary least squares	Jim Woodward	1999	Synthese	10.1023/A:1005242000548	philosophy of science;natural;system of linear equations;regression;causality;philosophy;epistemology;equation;invariant;intervention;system;autonomy	ML	-12.258152119784558	2.1734485855128907	45674
7f60968082f832303d798b0c0dc2e011a9aa33ec	handling of uncertainty and temporal indeterminacy for what-if analysis		Enabling experts to not only analyze current and historic data but also to evaluate the impact of decisions on the future state of the business greatly increased the value of decision support. However, the highly relevant aspect of representing and processing uncertain and temporally indeterminate data is often ignored in this context. Although the management of uncertainty has been researched intensely in the last decade, its role in decision support has not attracted much attention. We hold that not considering such information restricts the analyses users can run and the insights they can get into their data. In this pa- per, we complement large-scale data analyses with support for what-if analyses over uncertain and temporally indeterminate data. We use a histogram-based model to represent arbitrary uncertainty and temporal indeterminacy and allow its processing in a flexible manner using opera- tors for analyzing, deriving, and modifying uncertainty in decision sup- port tasks. We describe a prototypical implementation and approaches for parallelization on a commercial column store and present an initial evaluation of our solution.	indeterminacy in concurrent computation	Katrin Eisenreich;Gregor Hackenbroich;Volker Markl;Philipp Rösch;Robert Schulze	2010		10.1007/978-3-642-22970-1_8	real-time computing;simulation;computer science;data mining;database	NLP	-28.76934217772012	-2.4977231920023066	45721
ea9507fb696bb16d089e69954d6105a2d4e1a384	lazy induction of descriptions for relational case-based learning	analyse risque;entity relationship model;raisonnement base sur cas;razonamiento fundado sobre caso;apprentissage base cas;lazy induction of description lid method;risk analysis;modelo entidad relacion;modele entite relation;similitude;analisis riesgo;induccion;induction;similarity;risk assessment;case based learning;similitud;case based reasoning;learning artificial intelligence;apprentissage intelligence artificielle	Reasoning and learning from cases are based on the concept of similarity often estimated by a distance. This paper presents LID, a learning technique adequate for domains where cases are best represented by relations among entities. LID is able to 1) define a similitude term, a symbolic description of what is shared between a problem and precedent cases; and 2) assess the importance of the relations involved in a similitude term with respect to the purpose of correctly classifying the problem. The paper describes two application domains of relational case-based learning with LID: marine sponges identification and diabetes risk assessment.	lazy evaluation	Eva Armengol;Enric Plaza	2001		10.1007/3-540-44795-4_2	risk assessment;case-based reasoning;similarity;risk analysis;entity–relationship model;computer science;artificial intelligence;similitude;machine learning;mathematics;algorithm	AI	-20.540125747134827	-1.2142209592108768	45740
1db882fdc143c6643e22b33ff5336aab1c67592f	virtual doctor system (vds): reasoning challenges for simple case diagnosis based on ontologies alignment	bayesian network;human computer interaction;causal reasoning;ontology alignment	Human computer Interaction based on emotional modelling and physical views, collectively; is investigated and reported in this paper. Two types of ontologies have been presented to formalize a patient state: Mental Ontology reflecting the patient mental behavior due to certain disorder and Physical Ontology reflecting the observed physical behavior exhibited through disorder. These two types of ontology have been mapped and aligned using a simple Bayesian Network for causal reasoning to define what we call as simple case diagnosis. We have constructed an integrated computerized model which reflects a human diagnostician as computer model and through it; an integrated interaction between that model and the real human user (patinet) us utlilized for 1st stage dignosis purposes.	ontology (information science)	Hamido Fujita;Jun Hakura;Masaki Kurematsu	2011		10.1007/978-3-642-20039-7_1	ontology alignment;causal reasoning;computer science;knowledge management;ontology;artificial intelligence;machine learning;bayesian network;data mining;process ontology	AI	-25.414731654376098	-15.783997579807771	45798
b1874f7fd91aff1afbc98f644cf6eeac9acfa576	mean consumption representation of consumption externalities	strong law of large numbers;utility function;exchange economy;consumption externalities;social choice;interdependent preferences	Abstract   The author previously investigated exchange economies with a price-dependent reference coalition externality which can be represented as a mean consumption bundle of a reference coalition  C  [Noguchi, M., 2005. Interdependent preferences with a continuum of agents. Journal of Mathematical Economics 41, 665–686]. In the present paper, we justify, under a suitable generalization of the notion of negatively interdependent preferences [Ok, E.A., Kockesen, L., 2000. Negatively interdependent preferences. Social Choice and Welfare 17, 533–558], that consumers act as if they compute the mean consumption bundle ∫  C    xdμ   C   of  C  and maximize an appropriate utility function  V  whose consumption externality depends only on ∫  C    xdμ   C  . The strong law of large numbers plays a crucial role in our arguments.		Mitsunori Noguchi	2006	Mathematical Social Sciences	10.1016/j.mathsocsci.2006.02.001	social choice theory;law of large numbers;economics;public economics;mathematics;microeconomics;mathematical economics;welfare economics;statistics	AI	-5.660562426003665	-2.7520969403273527	45937
1b628c73c82a0e184527c92469afb418effa5492	occam: ontology-based computational contextual analysis and modeling	potential model;agent modeling;cognitive agents;agent models;contextual information;bayesian modeling;cognitive models;contextual analysis;cognitive model;probabilistic relational model;computational sociology;bayesian model	The ability to model cognitive agents depends crucially on being able to encode and infer with contextual information at many levels (such as situational, psychological, social, organizational, political levels). We present initial results from a novel computational framework, Coordinated Probabilistic Relational Models (CPRM), that can potentially model the combined impact of multiple contextual information sources for analysis and prediction.	compiler;computation;encode;emoticon;estimation theory;graphical model;graphical user interface;interdependence;iteration;list of toolkits;owl-s;protégé;robustness (computer science);run time (program lifecycle phase);simulation;systemics;web ontology language;occam	Srini Narayanan;Katie Sievers;Steven J. Maiorano	2007		10.1007/978-3-540-74255-5_27	computational sociology;artificial intelligence;machine learning;data mining;bayesian inference	AI	-22.793309061592673	-9.662589704822487	45995
1c19e83a32ed74080a9f70b63b6ea070e13e4651	effects of introducing survival behaviours into automated negotiators specified in an environmental and behavioural framework	negotiation framework;e commerce;pseudocode;message passing;automated negotiation	With the rise of distributed e-commerce in recent years, demand for automated negotiation has increased. In turn, this has facilitated a demand for ever more complex algorithms to conduct these negotiations. As the complexity of these algorithms increases, our ability to reason about and predict their behaviour in an ever larger and more diverse negotiation environment decreases. In addition, with the proliferation of internet-based negotiation, any algorithm also has to contend with potential reliability issues in the underlying messagepassing infrastructure. These factors can create problems for building these algorithms, which need to incorporate methods for survival as well as negotiation. This paper proposes a simple yet effective framework for integrating survivability into negotiators, so they are better able to withstand imperfections in their environment. Results of an experiment are provided which show how the stability of a negotiation community is affected by incorporating an example survival behaviour into negotiators operating in an environment developed to support this framework.	algorithm;e-commerce;experiment;internet	Peter Henderson;Stephen Crouch;Robert John Walters;Qinglai Ni	2005	Journal of Systems and Software	10.1016/j.jss.2004.06.024	e-commerce;pseudocode;message passing;simulation;computer science;engineering;knowledge management;management science;programming language	AI	-13.039283820390029	-12.018222079849618	46065
aae16012e32d2199afd1749eb0c10a3aa7765d51	data interpretation technology for continuous measurement production profile logging	java netbeans;production profile;ciflog;continuous measurement;multiphase flow;production logging	Up till now, there is no production logging data interpretation module in CIFLog, which is the 3rd generation well-logging software platform in China. So the situation has a strong impact on its promotion and utilization. In this paper, firstly, the authors introduce the characteristics of the existing and mature logging interpretation software, and design the data interpretation module functions for continuous measurement production profile logging based on JAVA-NetBeans. Secondly, the calculation methods of apparent fluid velocity, holdup, superficial velocity and flow rate of each phase are presented. Thirdly, eight module functions including wellbore message, curve value, physical parameters, and parameter settings are described. Finally, the authors has analyzed three-phase flow production profile logging data of X well using this module, which includes seven parameters of continuous measurement, and provided the result chart and table. In a word, the practice has proved that the module application effect is good.	compiler;executable compression;java;netbeans ide;test data;the superficial;velocity (software development)	Junfeng Liu;Heng Li;Yingming Liu	2014	Journal of Multimedia	10.4304/jmm.9.5.729-735	real-time computing;simulation	PL	-11.431779347266096	-20.799046023636052	46118
a62d29a266d9741b98a47f7103a968a7f5708962	singular propositions and singular thoughts		The core of the debate between Fregeans and Russellians in the philosophy of language concerns the content of object-dependent propositions, or how we ought to individuate and semantically represent the content of propositions that are about specific individuals. This essay is an investigation of the contemporary status of this debate. My aim is to show how the causal theorists’ picture of reference determination entails the need for both Fregean and Russellian conceptions of propositional content in the study of mind and language, and to investigate some of the consequences of this position.	causal filter	Arthur Sullivan	1998	Notre Dame Journal of Formal Logic	10.1305/ndjfl/1039293023	discrete mathematics;mathematics	NLP	-12.580550212571794	4.056529894754572	46124
a7797b1ae3f2ca064c4e58736499588e18e833ad	effective graph clustering for path queries in digital map databases	random graph;memory management;algorithm analysis;query processing;graph clustering;query optimization;association rules;data mining;background;optimization;scalability;experimental evaluation;digital mapping;spatial partitioning	Clustering for Path Queries in Digital Map Databases * Ning Jingt Elke A. Rundensteiner Changsha Institute of Technology University of Michigan jning@eecs.umiclt.edu rtmdenst@eecs.umich.edu In this paper, we present an experimental evaluation of graph clustering strategies in terms of their effectiveness in optimizing I/O for path query processing in digital map databases. Clustering optimization is attractive because it does not incurs any run-time cost, and is complimentary to many of the existing techniques in path query optimization. We first propose a novel graph clustering technique, called Spatial Partition Clustering (SPC), that creates balanced partitions of links based on the spatial proximity of their origin nodes. We then select three alternative clustering techniques from the literature, namely two-way partitioning, approximately topological clustering, and random clustering, to compare their performance in path query processing with SPC. Experimental evahration indicates that our SPC performs the best for the high-locality graphs (such as GIS maps), whereas the two-way partitioning approach performs the best for no-locality random graphs.	cluster analysis;database;geographic information system;input/output;locality of reference;map;mathematical optimization;random graph	Yun-Wu Huang;Ning Jing;Elke A. Rundensteiner	1996		10.1145/238355.238497	random graph;correlation clustering;query optimization;power graph analysis;scalability;digital mapping;association rule learning;computer science;space partitioning;theoretical computer science;data mining;clustering coefficient;database;graph database;tree decomposition;memory management	DB	-31.034688967497456	2.9841245852208007	46228
9740207adaa90e3a57709d72d7517b461afe65e5	"""erratum to """"an interactive procedure dedicated to a bicriteria plant location model"""": [computers & operations research 30 (2003) 1977-2002]"""	operations research;location model	Erratum to “An interactive procedure dedicated to a bicriteria plant location model” [Computers & Operations Research 30 (2003) 1977–2002] Joana Diasa ;∗, M. Eug/ eniab, Joao Climacoa Faculdade de Economia and INESC, Universidade de Coimbra, Av. Dias da Silva, 3000 Coimbra, Portugal DEIO and CIO, Faculdade de Ciencias da Universidade de Lisboa, Campo Grande, Bloco C2, Piso2, 1749-016 Lisboa, Portugal	chief information officer;operations research	Joana Dias;M. Eugénia V. Captivo;João C. N. Clímaco	2004	Computers & OR	10.1016/S0305-0548(03)00193-X	simulation;computer science;mathematics;operations research	Theory	-12.524786739372075	-4.158412452134485	46232
7bfbf74cddb118468e4abd1a2d84e4dfa790984f	semantic query routing experiences in a pdms	indexation	Querying a PDMS means either flooding the network with messages to all peers or taking advantage of a routing mechanism to reformulate a query only on thebestpeers selected according to some given criteria. As reformulations may lead to semantic approximations, we deem that such approximations can be exploited for locating thesemantically best directionsto forward a query to. In this paper, we present our experiences in devising and testing a mechanism for effective query routing in a PDMS. In particular, we describe a distributed index mechanism where each peer is provided with a Semantic Routing Index (SRI) for routing queries effectively. We illustrate SRIs’ structure, their use and the framework we devised for their incremental update, then we provide an extensive evaluation of their effectiveness through a set of query routing experiments on a variety of scenarios. This work is partially supported by the PRIN WISDOM and FIRB NeP4B national projects.	approximation;experiment;incremental backup;pdms;routing;semantic query	Federica Mandreoli;Riccardo Martoglia;Wilma Penzo;Simona Sassatelli	2006			web search query;information retrieval;query expansion;computer science;rdf query language;semantic query;indexation;sargable;query optimization	DB	-29.29756684879398	-0.4676290406106829	46240
80eff3d6baa77b0a59943d5bfe5ad781611f7275	case analysis of criminal behaviour	dynamic model	In this paper, it is shown how behavioural properties can be specified for three types of violent criminals. Moreover, it is shown how empirical material in the form of informal descriptions of traces of crime-related events can be formalised. Furthermore, it is shown how these formalised traces and behavioural properties can be used in automated analysis, for example in order to determine which type of criminal can have committed such a crime. Moreover, an underlying dynamical model is presented that shows causal mechanisms behind each of the behaviours, and their dependencies on the characteristics of the type of criminal and inputs in terms of stimuli from the environment.	causal filter;tracing (software)	Tibor Bosse;Charlotte Gerritsen;Jan Treur	2007		10.1007/978-3-540-73325-6_62	computer science	SE	-22.822624680678214	-13.475395675719817	46275
a7734aa9590dffe9602050a8ca63a9b7b4f00001	state policy couple dynamics in evolutionary games	game theory;standards;nash equilibrium;manifolds;sociology statistics games mathematical model standards manifolds nash equilibrium;games;statistics;mathematical model;occupation measure state policy couple dynamics standard evolutionary game framework two strategies evolutionary game;sociology	Standard Evolutionary Game framework is a useful tool to study large interacting systems and to understand the strategic behavior of individuals in such complex systems. Adding an individual state to model local feature of each player in this context, allows one to study a wider range of problems in various application areas as networking, biology, etc. In this paper, we introduce such an extension of evolutionary game framework and particularly, we focus on the dynamical aspects of this system. Precisely, we study the coupled dynamics of the strategies and the individual states inside a population of interacting individuals. We consider here a two strategies evolutionary game. We first obtain a system of combined dynamics and we show that the rest-points of this system are equilibria of our evolutionary game with individual state. Second, by assuming two different time scales between states and strategy dynamics, we can compute explicitly the equilibria. Then, by transforming our evolutionary game with individual states into a standard evolutionary game, we obtain an equilibrium which is equivalent, in terms of occupation measure, to the previous one. All our results are illustrated with numerical results.	complex systems;dynamical system;interaction;numerical analysis;social network;strategy dynamics	Ilaria Brunetti;Yezekael Hayel;Eitan Altman	2015	2015 American Control Conference (ACC)	10.1109/ACC.2015.7170987	combinatorial game theory;implementation theory;games;game theory;simulation;best response;manifold;extensive-form game;artificial intelligence;repeated game;mathematical model;mathematical game;mathematics;screening game;chicken;normal-form game;simulations and games in economics education;mathematical economics;sequential game;equilibrium selection;symmetric game;solution concept;nash equilibrium;statistics	ECom	-13.454054931339304	-15.08904001474075	46279
dfe3a37cba83c17688e719f66ae4318381e5d3f6	market-based task assignment strategies for multi-agent systems deployed for bushfire fighting	service robots emergency services fires multi robot systems;mathematical model robot kinematics predictive models heating robot sensing systems couplings;bushfire spread market based task assignment strategies multi agent systems simulated bushfire fighting scenario extinguishing agents market based auction algorithm bushfire prediction model wildfire boundary	This paper studies the task assignment strategies for multi-agent systems to cooperatively accomplish a set of tasks while achieving a team objective that give near-optimal final assignments, in the context of simulated bushfire fighting scenario. The purpose of this research is to develop efficient strategies to employ multiple robots to cooperate to extinguish a bushfire with multiple fire fronts by delivering sufficient extinguishing agents to each fire fronts and for each agent to replenish its resources between every assigned fire front. We address the problem by extending the existing market-based auction algorithm to incorporate the use of a bushfire prediction model. We approach this problem with saving the properties and populations as the main objective. However, this objective does not make the property location a target for the robots nor the entire wildfire boundary being selected as targets. Instead, we propose a target selection model that determines the rendezvous point of the agents and the critical fire fronts which poses the most threats to property or human life. The complexity of the problem is mainly due to the dynamic nature of the bushfire spreading. However, this can be taken into account with a highly reliable bushfire prediction model that considers the majority of the significant factors that affects the spreading of the fires. The auction algorithm auctions the destinations for the agents which in fact are the critical points at which the agents rendezvous the fire fronts. The modifications to the standard auction algorithm are also presented.	auction algorithm;autonomous robot;multi-agent system;population;robot;simulation;spreading activation	KuangYee Teng;Jayantha Katupitiya	2014	11th IEEE International Conference on Control & Automation (ICCA)	10.1109/ICCA.2014.6870890	simulation;engineering;computer security	Robotics	-13.82266313099889	-10.87290835012233	46304
1d75061e40e0d201f282466d5baf5d0247ca34bb	foundations of inference	probability;divergence;satisfiability;artificial intelligent;bayesian;data analysis;measure;entropy;information;inference;lattice	We present a simple and clear foundation for finite inference that unites and significantly extends the approaches of Kolmogorov and Cox. Our approach is based on quantifying lattices of logical statements in a way that satisfies general lattice symmetries. With other applications such as measure theory in mind, our derivations assume minimal symmetries, relying on neither negation nor continuity nor differentiability. Each relevant symmetry corresponds to an axiom of quantification, and these axioms are used to derive a unique set of quantifying rules that form the familiar probability calculus. We also derive a unique quantification of divergence, entropy and information.	complementarity theory;scott continuity;vergence	Kevin H. Knuth;John Skilling	2012	Axioms	10.3390/axioms1010038	entropy;combinatorics;discrete mathematics;information;measure;bayesian probability;lattice;probability;mathematics;data analysis;divergence;statistics;satisfiability	ML	-11.084721512862112	1.5501862402876636	46359
a443946ebf2e0651ce35afecb759ae653c33a697	homophily, influence and the decay of segregation in self-organizing networks	graph theory;network segregation;influence;community structure;differential equation method;network dynamics;agent based models;homophily	We study the persistence of network segregation in networks characterized by the co-evolution of nodal attributes and link structures, in particular where individual nodes form linkages on the basis of similarity with other network nodes (homophily), and where nodal attributes diffuse across linkages, making connected nodes more similar over time (influence). A general mathematical model of these processes is used to examine the relative influence of homophily and influence in the maintenance and decay of network segregation in self-organizing networks. While prior work has shown that homophily is capable of producing strong network segregation when attributes are fixed, we show that adding even minute levels of influence is sufficient to overcome the tendency towards segregation even in the presence of relatively strong homophily processes. This result is proven mathematically for all large networks, and illustrated through a series of computational simulations that account for additional network evolution processes. This research contributes to a better theoretical understanding of the conditions under which network segregation and related phenomenon—such as community structure—may emerge, which has implications for the design of interventions that may promote more efficient network structures.	organizing (structure);self-organization	Adam Douglas Henry;Dieter Mitsche;Pawel Pralat	2016	Network Science	10.1017/nws.2016.1	econometrics;combinatorics;graph theory;network dynamics;mathematics;social psychology;community structure	ML	-13.939853197946901	-15.803149595931336	46394
26b539a33fa3f66e30e308c86eb10bd9f2d7f30e	house allocation with existing tenants: an equivalence	exchange economy;indivisible good;mechanism design	We analyze two mechanisms designed to eliminate inefficiencies in house allocation pro where there are both existing tenants and newcomers. The first mechanism chooses the un allocation of a “sister” exchange economy constructed by endowing each existing tenant w current house and each newcomer with a random vacant house. The second mechanism ch ordering from a given distribution and determines the final outcome as follows: Assign the the best available house one-at-a-time following their ordering in the queue and whenever a demands the house of an existing tenant who is still in the line, modify the queue by inserti existing tenant at the top. Whenever a loop of existing tenants forms, assign each of them th she demands and proceed. We show that the first mechanism is equivalent to an extreme ca second which favors the newcomers.  2004 Elsevier Inc. All rights reserved. JEL classification:C71; C78; D71; D78	algorithm;randomness;top trading cycle;turing completeness	Tayfun Sönmez;M. Utku Ünver	2005	Games and Economic Behavior	10.1016/j.geb.2004.04.008	mechanism design;economics;operations management;microeconomics;mathematical economics;operations research	AI	-5.729741812406413	-3.767172626222619	46425
26950f4229aad70361e975c8ffda066923f86717	causal temporal constraint networks for representing temporal knowledge	application development;temporal knowledge representation;computer model;temporal information;artificial intelligent;temporal constraints;artificial intelligence;commonkads;development methodology;knowledge representation;temporal reasoning;causality;knowledge engineering	In this work we describe causal temporal constraint networks (CTCN) as a new computable model for representing temporal information and efficiently handling causality. The proposed model enables qualitative and quantitative temporal constraints to be established, introduces the representation of causal constraints, and suggests mechanisms for representing inexact temporal knowledge. The temporal handling of information is achieved by structuring the information in different interpretation contexts, linked to each other through an inference mechanism which obtains interpretations that are consistent with the original temporal information. In carrying out inferences, we take into account the temporal relationships between events, the possible inexactitude associated with the events, and the atemporal or static information which affects the interpretation pattern being considered. The proposed schema is illustrated with an application developed using the CommonKADS methodology.	causal filter;temporal logic	Ángel Fernández-Leal;Vicente Moret-Bonillo;Eduardo Mosqueira-Rey	2009	Expert Syst. Appl.	10.1016/j.eswa.2007.09.044	causality;computer science;artificial intelligence;machine learning;knowledge engineering;data mining;rapid application development	AI	-21.260240755063514	1.8616734596271378	46475
3dfd5d624c00a7d2ec978a24395a45904d754e7b	associative reinforcement learning - a proposal to build truly adaptive agents and multi-agent systems		In this position paper we propose to enhance learning algorithms, reinforcement learning in particular, for agents and for multi-agent systems, with the introduction of concepts and mechanisms borrowed from associative learning theory. It is argued that existing algorithms are limited in that they adopt a very restricted view of what “learning” is, partly due to the constraints imposed by the Markov assumption upon which they are built. Interestingly, psychological theories of associative learning account for a wide range of social behaviours, making it an ideal framework to model learning in single agent scenarios as well as in multi-agent domains.	algorithm;biological system;business process;e-commerce;information filtering system;machine learning;markov chain;multi-agent system;reinforcement learning;robotics;theory	Eduardo Alonso;Esther Mondragón	2013			artificial intelligence;machine learning;distributed computing	AI	-21.38508461637151	-14.076089136603104	46496
d52b4923d1dd621e8335594f75c60db6ae98378a	a decision-making support system on a products recovery management framework. a fuzzy approach	recovery options;fuzzy decision support system;reverse logistics;reverse logistic;support system;decision support system;fuzzy system	The considerable amount of uncertainty involved in defining the factors that affect reverse logistics (RL) decision-making and the complex interrelationships between those factors make it rather difficult to decide what recovery policy a business should pursue. This article proposes a fuzzy system that helps in such decision-making and thereby mitigates these difficulties. The knowledge related to the decision is incorporated into the system by means of conditional rules, which serve to provide the ideal recovery policy for each particular case. The model proposed is applied to the analysis of a number of examples and proves to be a versatile tool that provides coherent results. These characteristics could be of critical importance especially in the point of entry into the RL pipeline and in the Centralized Return Centres.	fuzzy logic	Isabel Fernández;Javier Puente;Nazario García;Alberto Gomez	2008	Concurrent Engineering: R&A	10.1177/1063293X08092486	decision support system;computer science;systems engineering;engineering;artificial intelligence;operations management;management science	DB	-6.567343772976313	-15.792047869303094	46533
b57740779b4c5d353946ae18100212fea75bb26f	interval methods in knowledge representation			interval arithmetic;knowledge representation and reasoning	Vladik Kreinovich	2016	International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems	10.1142/S0218488516970060		Robotics	-27.73183426500037	-7.587647244361182	46537
a23c6ffe909bc9e0f1cd6833f3fc5292259bc117	choice set formation with multiple flexible activities under space-time constraints	transportation networks;trip chaining;theoretical framework;geographic information system;multiple flexible activities;choice set;space time constraints;space time;multipurpose trips	In classical time geography, an individual travel path is composed of a chain of visits, with each visit being a flexible activity between two fixed activities at two known stations. In reality, individuals tend to carry out trips with much variation and complexity, with multipurpose trips being a prominent and pervasive phenomenon. There is limited research to date on multipurpose trips in time-geographic analysis by geographic information system GIS scientists, or more specifically, multiple flexible activities between two fixed stations. To fill this gap, this article proposes four models for identifying the choice set with multiple flexible activities under space–time constraints. The models are derived through set-theoretic formalism based on the concept of trip chaining. The structure of the four models establishes a theoretical framework for conceptualizing trip-chaining behaviour with respect to the fixity of activities and the number of fixed stations as destinations or origins. They provide fundamental and rigorous apparatus for studying complex individual activity–travel patterns in many applied contexts when multipurpose trips are involved. This article also describes implementation of the models with a real transportation network as a way of validation.		Xiang Chen;Mei-Po Kwan	2012	International Journal of Geographical Information Science	10.1080/13658816.2011.624520	simulation;space time;mathematics;geographic information system;choice set;statistics	Vision	-17.446668303721516	-21.622599323011514	46582
20014090ed50dbfd71ec03ebf031bffc64d3f6f5	yabench: a comprehensive framework for rdf stream processor correctness and performance assessment		RDF stream processing (RSP) has become a vibrant area of research in the semantic web community. Recent advances have resulted in the development of several RSP engines that leverage semantics to facilitate reasoning over flows of incoming data. These engines vary greatly in terms of implemented query syntax, their evaluation and operational semantics, and in various performance dimensions. Existing benchmarks tackle particular aspects such as functional coverage, result correctness, or performance. None of them, however, assess RSP engine behavior comprehensively with respect to all these dimensions. In this paper, we introduce YABench, a novel benchmarking framework for RSP engines. YABench extends the concept of correctness checking and provides a flexible and comprehensive tool set to analyze and evaluate RSP engine behavior. It is highly configurable and provides quantifiable and reproducible results on correctness and performance characteristics. To validate our approach, we replicate results of the existing CSRBench benchmark with YABench. We then assess two well-established RSP engines, CQELS and C-SPARQL, through more comprehensive experiments. In particular, we measure precision, recall, performance, and scalability characteristics while varying throughput and query complexity. Finally, we discuss implications on the development of future stream processing engines and benchmarks.	benchmark (computing);computer performance;correctness (computer science);decision tree model;experiment;granular configuration automation;list of sparql implementations;microsoft windows;operational semantics;precision and recall;sparql syntax expressions;scalability;self-replicating machine;semantic web;stream processing;test case;test data;throughput;usb on-the-go	Maxim Kolchin;Peter Wetz;Elmar Kiesling;A Min Tjoa	2016		10.1007/978-3-319-38791-8_16	computer science;data mining;database;programming language	DB	-32.42914683820017	2.803141141686593	46587
a5b3d4b4a36d43093bb31fa640c22f948679616b	a conceptual graph description of medical data for brain tumour classification	agent based;magnetic resonance spectroscopy;magnetic resonance image;support system;conceptual graph;knowledge representation;brain tumour	HealthAgents proposes an agent-based distributed decision support system for brain tumour diagnosis and prognosis which employs Magnetic Resonance Imaging and Magnetic Resonance Spectroscopy techniques and genomic profiles. From a knowledge representation view point the distributed nature and the heterogeneity of the data to be integrated pose a number of challenging problems. This paper shows how Conceptual Graphs can be employed to describe the data sources in the HealthAgents system. Such knowledge representation based description of data allows for reasoning power when querying and for data modularisation capabilities.	agent-based model;blackwell (series);conceptual graph;daily active users;de morgan's laws;decision support system;diagram;first-order logic;information processing;john f. sowa;julia;knowledge representation and reasoning;kolibrios;lecture notes in computer science;minimal recursion semantics;problem solving;reasoning system;resonance;springer (tank);thomas j. watson research center;video-in video-out;voxel	Madalina Croitoru;Bo Hu;Srinandan Dashmapatra;Paul H. Lewis;David Dupplaw;Liang Xiao	2007		10.1007/978-3-540-73681-3_11	nuclear magnetic resonance spectroscopy;conceptual graph;knowledge representation and reasoning;computer vision;computer science;artificial intelligence;magnetic resonance imaging;data mining	AI	-27.814412615015502	-7.595043588703552	46599
23abe6cb4f5f7061e751f33abae5c135067f1b33	knowledge-based multiagent credit assignment: a study on task type and critic information	knowledge based multiagent credit assignment;learning;reinforcement learning;or type tasks;credit assignment;multi agent systems learning artificial intelligence;information content;and type task;critic information;or type tasks knowledge based multiagent credit assignment critic information multiagent reinforcement learning cooperative team and type task;multi agent systems;reinforcement learning credit assignment multiagent learning;learning intelligent agent multiagent systems artificial intelligence history uncertainty working environment noise large scale systems design engineering intelligent systems;multiagent learning;learning artificial intelligence;multiagent reinforcement learning;cooperative team;knowledge base	Multiagent credit assignment (MCA) is one of the major problems in the realization of multiagent reinforcement learning. Since the environment usually is not intelligent enough to qualify individual agents in a cooperative team, it is very important to develop some methods for assigning individual agents' credits when just a single team reinforcement is available. MCA cannot be solved in general cases, using a single technique. Therefore, our goal in this research is first to present a new view of the problem and second, to introduce a new idea of using agents' knowledge to partially solve MCA. In this research, an approach that is based on agents' learning histories and knowledge is proposed to solve the MCA problem. Knowledge evaluation-based credit assignment (KEBCA) along with certainty, a measure of agents' knowledge, is developed to judge agents' actions and to assign them proper credits. The proposed KEBCA method is general, however; we study it in some simulated extreme cases in order to gain a better insight into MCA problem and to evaluate our approach in such cases. More specifically, we study the effects of task type (and-type and or-type tasks) on solving MCA problem in two cases. In the first case, in addition to the team reinforcement, it is assumed that some extra information at the team level is available. In the second case, such extra information does not exist. In addition, performance of the system is examined in presence of some uncertainties in the environment, modeled as noise on agents' actions. The information content of team reinforcements and assumed extra information are theoretically calculated and discussed. The mathematical calculations confirm the related simulation results.	agent-based model;approximation algorithm;correctness (computer science);knowledge-based systems;nondeterministic algorithm;reinforcement learning;robot;self-information;simulation	Ahad Harati;Majid Nili Ahmadabadi;Babak Nadjar Araabi	2007	IEEE Systems Journal	10.1109/JSYST.2007.901641	knowledge base;self-information;computer science;knowledge management;artificial intelligence;machine learning;reinforcement learning	AI	-18.007103705782235	-9.797057325030165	46668
26672c3d440f8486450f55090466cce84c5c1a28	quantum theory and probability theory: their relationship and origin in symmetry	foundations of quantum theory;foundations of probability theory;quantum theory;probability theory	Quantum theory is a probabilistic calculus that enables the calculation of the probabilities of the possible outcomes of a measurement performed on a physical system. But what is the relationship between this probabilistic calculus and probability theory itself? Is quantum theory compatible with probability theory? If so, does it extend or generalize probability theory? In this paper, we answer these questions, and precisely determine the relationship between quantum theory and probability theory, by explicitly deriving both theories from first principles. In both cases, the derivation depends upon identifying and harnessing the appropriate symmetries that are operative in each domain. We prove, for example, that quantum theory is compatible with probability theory by explicitly deriving quantum theory on the assumption that probability theory is generally valid.	quantum mechanics;theory	Philip Goyal;Kevin H. Knuth	2011	Symmetry	10.3390/sym3020171	probability amplitude;probability theory;combinatorics;discrete mathematics;quantum probability;dempster–shafer theory;c-minimal theory;valuation;quantum t-design;probability interpretations;mean field theory;mathematics;thermal quantum field theory;algebra of random variables;probabilistic number theory;conditional mutual information;physics;quantum mechanics;relationship between string theory and quantum field theory	Theory	-13.527307492991014	0.359236323472513	46717
a3b323cb04e1c689215a00bf2342f0ed497d1e28	d-cite - a serious game to analyze complex decision-making in air traffic management	atm simulation	"""Air Traffic is a complex system, where different stakeholders e.g. Airlines, Airport, Air Traffic Controller, Ground-Handler interact with each other. To optimize especially airport processes, cooperation between the above mentioned stakeholders is mandatory, but divergent goals and interests are supposed to have an influence on their decision-making process. Because of this, the way of collaborative decision-making seems to be a challenge. The aspects of human interactions during negotiations and human performance in planning activities are difficult to measure with conventional methods of real- and fast-time simulations. Serious Gaming is a new method in this research field to validate interaction processes in Air Traffic Management. The serious multiplayer game """"D-CITE"""" Decisions based on Collaborative Interactions in TEams was developed to specifically analyze underlying factors that drive decision-making processes in an airport management environment. The aim of this paper is to illustrate the main ideas of D-CITE as well as to discuss the aspect of collaborative learning."""		Maria Freese;Sebastian Drees	2015		10.1007/978-3-319-40216-1_3	simulation;engineering;operations management;management science	HCI	-24.01483424448586	-20.81706562990282	46813
e8743f25be287451200d27d8c5b1a20276800e32	spatial indexing and analytics on hadoop	spatial indexing;distributed processing;analytics;k nn;mapreduce;quadtree;hadoop;hdfs	Effective processing of extremely large volumes of spatial data has led to many organizations employing distributed processing frameworks. Hadoop is one such open-source framework that is enjoying widespread adoption. In this paper, we detail an approach to indexing and performing key analytics on spatial data that is persisted in HDFS. Our technique differs from other approaches in that it combines spatial indexing, data load balancing, and data clustering in order to optimize performance across the cluster. In addition, our index supports efficient, random-access queries without requiring a MapReduce job; neither a full table scan, nor any MapReduce overhead is incurred when searching. This facilitates large numbers of concurrent query executions. We will also demonstrate how indexing and clustering positively impacts the performance of range and k-NN queries on large real-world datasets. The performance analysis will enable a number of interesting observations to be made on the behavior of spatial indexes and spatial queries in this distributed processing environment.	apache hadoop;cluster analysis;distributed computing;full table scan;k-nearest neighbors algorithm;load balancing (computing);mapreduce;open-source software;overhead (computing);random access	Randall T. Whitman;Michael B. Park;Sarah M. Ambrose;Erik G. Hoel	2014		10.1145/2666310.2666387	analytics;computer science;data science;quadtree;data mining;database	DB	-28.436763297755775	-0.6245821547446875	46840
c20dfa3dda4d306e96a233ef215e104015805d66	minimizing data transfers in distributed query processing: a comparative study and evaluation	estudio comparativo;distributed database systems;pregunta documental;systeme base donnee distribuee;question documentaire;distributed query processing;algorithme;etude comparative;transfert donnee;heuristic methods;comparative study;query;algorithms;methode heuristique;data transfer	A new heuristic, called Algorithm W, is presented as a method for efficiently generating cost-effective semijoin schedules for distributed query processing. It uses the concepts of profit, marginal profit and gain to determine a sequence of semijoins to minimize the total volume of data transferred over the network. Reducers, which are small in size and highly selective are constructed and applied in a cost-effective way. We show that in most cases the heuristic has complexity O(nm). However, static strategies, such as Algorithm W rely on accurate estimates to function properly. If the estimates are incorrect then the strategy may be less than optimal. Dynamic strategies, where the schedule of operations is monitored and modified during execution, are proposed as a solution to this problem. We propose two new dynamic heuristics: Algorithm D1 has minimal overheads and does not require schedule modification; Algorithm D2 is a more sophisticated dynamic strategy that has a 'look ahead' phase to determine the 'best' starting point for the optimization and it permits schedule modifications. We evaluate the performance of the heuristics and test the hypothesis that a dynamic strategy allows for better estimates and improved schedules.		Joan M. Morrissey;W. T. Bealor	1996	Comput. J.	10.1093/comjnl/39.8.675	computer science;theoretical computer science;comparative research;data mining;database;distributed database;algorithm	DB	-25.98839415040589	3.7965084864215113	46882
f379562c47aea70ce873774336aae1e1665c08d4	reasoning about interaction: from game theory to logic and back (dagstuhl seminar 11101)	game theory logic mechanism design security cooperation model checking rationality knowledge;004	This report documents the program and the outcomes of Dagstuhl Seminar 11101 “Reasoning about Interaction: From Game Theory to Logic and Back”. The notion of interaction is crucial in several disciplines, including social science, operational research, and economics. Two frameworks are most prominent in the formal treatment of interaction: game theory and mathematical logic. Quantitative analysis is usually conducted using models and tools of game theory. At the same time, logic provides vocabulary and methods to study interaction in a qualitative way. The aim of the seminar was to bring together researchers who approach interaction-related phenomena from different perspectives (and with different conceptual tools). We hoped that, by synergy and exchange of expertise, a more integrative view of interaction could be obtained. In particular, we focussed on how interaction between individual entities (be it humans, robots and/or virtual creatures) can lead to emergence of social structures, collective behavior, and teamwork and, ultimately, help all involved parties benefit from cooperation. Seminar 06.–11. March, 2011 – www.dagstuhl.de/11101 1998 ACM Subject Classification I.2 Artificial Intelligence, F.4.1 Mathematical Logic, I.2.4 Knowledge Representation Formalisms and Methods	artificial intelligence;emergence;entity;game theory;humans;knowledge representation and reasoning;operations research;robot;social structure;synergy;vocabulary	Jürgen Dix;Wojciech Jamroga;Dov Samet	2011	Dagstuhl Reports	10.4230/DagRep.1.3.1	positive political theory;computer science;knowledge management;artificial intelligence;algorithmic game theory;social psychology	AI	-23.666688604226746	-12.834842429005768	46915
8fb4d2011fb792a9a610280c8fa28921a0b6a194	creativity, cognitive mechanisms, and logic	creativity;cognitive mechanisms;logic;analogy;concept blending	Creativity is usually not considered to be a major issue in current AI and AGI research. In this paper, we consider creativity as an important means to distinguish human-level intelligence from other forms of intelligence (be it natural or artificial). We claim that creativity can be reduced in many interesting cases to cognitive mechanisms like analogymaking and concept blending. These mechanisms can best be modeled using (non-classical) logical approaches. The paper argues for the usage of logical approaches for the modeling of manifestations of creativity in order to step further towards the goal of building an artificial general intelligence.	alpha compositing;artificial general intelligence;artificial intelligence	Ahmed M. H. Abdel-Fattah;Tarek R. Besold;Kai-Uwe Kühnberger	2012		10.1007/978-3-642-35506-6_1	psychology;analogy;creativity technique;artificial intelligence;creativity;social psychology;logic;cognitive science	AI	-25.596216103708645	-13.652180249659782	46934
cf543414b627952a0940e598d471444f924bcb55	genetic-aided multi-issue bilateral bargaining for complex utility functions	negotiation experimentation;utility function;genetics;negotiation algorithms;bilateral bargaining;agreement technologies;negotiation	In this paper, a non-mediated multi-issue bilateral bargaining model for complex utility functions is presented. Before the negotiation process, a genetic algorithm (GA) is used to sample one’s own utility function. During the negotiation process, genetic operators are applied over the opponent’s and one’s own proposals in order to sample new proposals that are interesting for both parties.	bilateral filter;genetic algorithm;genetic operator;software release life cycle;utility	Víctor Sánchez-Anguix;Soledad Valero;Vicente Julián;Vicent J. Botti;Ana García-Fornes	2010		10.1145/1838206.1838501	knowledge management;negotiation	AI	-9.35308176963192	-7.818451471629256	46937
6548ffd5bf2ae51b74b4f9927c21b142db025c4d	performance evaluation of scientific research program in zhejiang colleges based on uncertainty analysis	ahpcolleges s&t programentropythe membership degree � uncertainty analysis	  This paper concentrates on the performance evaluation of scientific research program in Zhejiang colleges based on uncertainty  analysis. Firstly, it sets up the index system. It considers the characteristics of scientific research program in Zhejiang  colleges and determines some indexes. It introduces the membership function to determine the membership degree of indexes.  Secondly, the paper confirms the index weights. It uses the principle of Analytic Hierarchy Process (AHP) and the entropy  weight method to confirm the index weights. This paper establishes an assessment model and gives a theoretical supportive  to case study on performance evaluation of scientific research program in Zhejiang colleges.    	performance evaluation	Lian-fen Yang;Yun Tang	2011		10.1007/978-3-642-18387-4_17	mathematics education;engineering management;alternative medicine;engineering	HPC	-7.646929293287641	-19.255435223497646	46943
305e18bc962b3593eaa83a1a88b44be7d9e1f8d7	designing efficient online trading systems	p2p system;multiagent system;trading system;mobile ad hoc network;mechanism design;free riding;multiagent systems	In many online domains, agents share goods or services that are both cheap to provide and valuable to receive. Examples include ratings in a recommender system, forwarding a message to node closer to its destination in a mobile ad-hoc network, and uploading a file in a P2P system. Existing systems in these domains often rely on agents to voluntarily provide goods. Despite the low cost of doing so, many agents instead choose to free-ride, leading to a loss in social efficiency. We present an initial step towards addressing this problem in the context of an abstract, extremely simplified model, where we identify more efficient mechanisms, including one that is provably optimal. Of course, we are not the first to consider this problem, or to offer a solution (see, e.g., [1] for recommender systems, [3] for ad-hoc networks, and [2] and [4] for P2P systems).	algorithmic trading;hoc (programming language);peer-to-peer;recommender system;upload	Ryan Porter;Yoav Shoham	2004		10.1145/988772.988822	mechanism design;mobile ad hoc network;economics;computer science;artificial intelligence;multi-agent system;microeconomics;mathematical economics;free riding	ECom	-8.197326558097144	-7.795725916703463	46946
ef1b2d72816cc7bc0adf2693728784dbda2a0491	polynomial time algorithms for finding unordered tree patterns with internal variables	arbre graphe;tratamiento datos;extraction information;extensible markup language;web documents;red www;temps polynomial;analisis datos;tree graph;information extraction;structure arborescente;data processing;traitement donnee;data mining;polynomial time algorithm;data analysis;internet;fouille donnee;estructura arborescente;tree structure;polynomial time;xml;arbre minimal;world wide web;analyse donnee;inductive inference;arbol minimo;reseau www;arbol grafo;busca dato;minimal tree;tiempo polinomial;extraction informacion	Many documents such as Web documents or XML files have tree structures. A term tree is an unordered tree pattern consisting of internal variables and tree structures. In order to extract meaningful and hidden knowledge from such tree structured documents, we consider a minimal language (MINL) problem for term trees. The MINL problem for term trees is to find a term tree t such that the language generated by t is minimal among languages, generated by term trees, which contain all given tree structured data. Firstly, we show that the MINL problem for regular term trees is computable in polynomial time if the number of edge labels is infinite. Next, we show that the MINL problems with optimizing the size of an output term tree are NP-complete. Finally, in order to show that our polynomial time algorithm for the MINL problem can be applied to data mining from real-world Web documents, we show that regular term tree languages are polynomial time inductively inferable from positive data if the number of edge labels is infinite.	algorithm;computable function;computational complexity theory;data mining;inductive reasoning;karp's 21 np-complete problems;p (complexity);polynomial;time complexity;tree (data structure);tree automaton;web page;xml	Takayoshi Shoudai;Tomoyuki Uchida;Tetsuhiro Miyahara	2001		10.1007/3-540-44669-9_32	left-child right-sibling binary tree;segment tree;combinatorics;tree rotation;xml;vantage-point tree;data processing;computer science;theoretical computer science;order statistic tree;range tree;2–3 tree;machine learning;incremental decision tree;k-ary tree;interval tree;database;k-minimum spanning tree;mathematics;fractal tree index;tree structure;search tree;tree traversal;information extraction;algorithm;avl tree	Theory	-22.765265774547256	4.044667879502744	46981
ac34d6c12fe5e8ffb333a48f9b8883b85885df2e	spatial agent-based models for socio-ecological systems: challenges and prospects	multi agent system;human environment system;agent based model;socio ecological system;review	Departing from the comprehensive reviews carried out in the field, we identify the key challenges that agent-based methodology faces when modeling coupled socio-ecological systems. Focusing primarily on the papers presented in this thematic issue, we review progress in spatial agent-based models along the lines of four methodological challenges: (1) design and parameterizing of agent decision models, (2) verification, validation and sensitivity analysis, (3) integration of socio-demographic, ecological, and biophysical models, and (4) spatial representation. Based on this we critically reflect on the future work that is required to make agent-based modeling widely accepted as a tool to support the real world policy. 2013 Elsevier Ltd. All rights reserved.	agent-based model;ecosystem	Tatiana Filatova;Peter H. Verburg;Dawn Cassandra Parker;Carol Ann Stannard	2013	Environmental Modelling and Software	10.1016/j.envsoft.2013.03.017	simulation;computer science;artificial intelligence;socio-ecological system;multi-agent system;management science;operations research	AI	-15.387962360914054	-21.601280672145506	47004
6f32e15067bd3336b6218e407ad61b97790bff5e	expect: intelligent support for knowledge base refinement	high level languages;expert finding;computer architecture;knowledge acquisition;natural language;problem solving method;guidance;procedural knowledge;tools;scenarios;data acquisition;models;knowledge based systems;limitations;problem solving;systems approach;knowledge base	Effective knowledge acquisition amounts to having good sources of expectations that can provide guidance about what knowledge needs to be acquired from users. Current approaches to knowledge acquisition often rely on strong models of the problem-solving method used in the task domain to form expectations. These methods are often implicit in the tool, which is a strong limitation for their use in different domains. Additionally, these tools require an understanding of the method to be used that most experts find difficult to overcome. In this paper we present EXPECT, a novel approach to knowledge acquisition based on the EES architecture that forms expectations based on the current knowledge contained in the system about the task, and are not hard-coded in the tool. We show how the explicit representation of domain principles and its relation to compiled procedural knowledge enables a system to form expectations as to what knowledge is missing or incorrect. This capability coupled with a dialogue-based explanation facility makes communication with the knowledge acquisition tool more natural to domain experts.	compiler;embedded entertainment system;expect;hard coding;knowledge acquisition;knowledge base;problem solving	Cécile Paris;Yolanda Gil	1993		10.1007/3-540-57253-8_56	knowledge base;computer science;knowledge management;artificial intelligence;explicit knowledge;body of knowledge;knowledge-based systems;data mining;procedural knowledge;knowledge extraction;natural language;data acquisition;personal knowledge management;high-level programming language;domain knowledge;systems thinking	AI	-30.080022348522796	-5.653270228920589	47024
0cc3d69e545e420d59c4741983010091e3166756	comparative analysis of agent-based social simulations: geosim and fearlus models	comparative analysis;multi agent based social simulation;resource allocation;agent based social simulation;territorial resource allocation;2 dimensional;model comparison;comparative modeling;relational model;structural similarity;multi agent based simulation	In this paper we compare models of two different kinds of processes in multi-agentbased social simulations (MABSS): military conflict within a states-system (GeoSim), and land use and ownership change (FEARLUS). This is a kind of model-to-model comparison which is novel within MABSS research, although well-known within mathematics, physics and biology: comparing objects (in this case MABSS) drawn from distinct research domains, in order to draw out their structural similarities and differences. This can facilitate research in both domains, by allowing the use of findings from each to illuminate the other. Based on the similarities between FEARLUS and GeoSim, we conclude by identifying a new class of MABS (multi-agent-based simulation) models based on territorial resource allocation processes occurring on a 2-dimensional space (which we define as the “TRAP” class). The existence of the cross-domain TRAP class of models in turn suggests that MABS researchers should look for other members of the class, sharing some of the properties or dynamics common to the GeoSim and FEARLUS models compared in this study: a systematic comparison of a set of related models from a range of apparently distinct domains should generate insights into both MABS modeling, and the domains concerned. 1 Authors are listed alphabetically. The present work was completed with partial support from the Complex Systems Network of Excellence (Exystence), FET-IST European Communities grant IST-2001-32802. Cioffi was supported by the Center for Social Complexity at George Mason University. Gotts was supported by the Scottish Executive Environment and Rural Affairs Department. The authors are grateful to the authors of the simulation models compared in this study, but they are solely responsible for any errors of interpretation.	agent-based model;complex systems;computer simulation;interpretation (logic);mason;model selection;multi-agent system;social complexity	Claudio Cioffi-Revilla;Nicholas Mark Gotts	2003	J. Artificial Societies and Social Simulation		qualitative comparative analysis;homology modeling;two-dimensional space;relational model;social science;simulation;resource allocation;computer science;structural similarity;management science;sociology;social psychology;agent-based social simulation	AI	-18.441278022781038	-17.103186107222573	47031
e3d42b39acf0b49fb5e0e5767bc3be9391ec50fe	in for a surprise when migrating nosql data		Schema-flexible NoSQL data stores lend themselves nicely for storing versioned data, a product of schema evolution. In this lightning talk, we apply pending schema changes to records that have been persisted several schema versions back. We present first experiments with MongoDB and Cassandra, where we explore the trade-off between applying chains of pending changes stepwise (one after the other), and as composite operations. Contrary to intuition, composite migration is not necessarily faster. The culprit is the computational overhead for deriving the compositions. However, caching composition formulae achieves a speed up: For Cassandra, we can cut the runtime by nearly 80%. Surprisingly, the relative speedup seems to be system-dependent. Our take away message is that in applying pending schema changes in NoSQL data stores, we need to base our design decisions on experimental evidence rather than on intuition alone.	apache cassandra;data store;experiment;mongodb;nosql;overhead (computing);schema evolution;software versioning;speedup;status message (instant messaging);stepwise regression	Uta Störl;Theo Riviere;Meike Klettke;Stefanie Scherzinger	2018	2018 IEEE 34th International Conference on Data Engineering (ICDE)	10.1109/ICDE.2018.00202	data mining;surprise;database;nosql;overhead (computing);speedup;computer science;data migration;schema evolution;schema (psychology);intuition	DB	-30.85254791525108	1.9913156416520972	47114
61187605127b447feaeb649e405a7ccd8b02a670	calhidra 3.0 - new software application for river water quality prediction based on rwqm1	programming paradigm;environmental conditions;water quality;rwqm1;river water quality;monte carlo method;component object model;hydrodynamic model;saint venant equations;software package;dynamic simulation;water quality model;monte carlo;ultimate	This paper presents CalHidra 3.0, a new software package developed for dynamic simulation of water quality in rivers. CalHidra 3.0 combines a 1-D hydrodynamic model based on Saint Venant equations, a transport sub-model that incorporates the advectionedispersion terms, and a simplified version of the River Water Quality Model 1 (RWQM1) for the biochemical transformations. This advanced biochemical sub-model allows the dynamic simulation of the bacterial populations in rivers, making possible the simulation of the river acclimatisation to changes of pollutant load or environmental conditions. The software also includes new tools for a Monte Carlo based Bayesian calibration of the unknown model parameters. CalHidra 3.0 is implemented based on the Component Object Model (COM) programming paradigm and uses the Windows graphical environment. Three case studies illustrate the possibilities of the CalHidra 3.0 software. 2011 Elsevier Ltd. All rights reserved. Software availability Name of software: CalHidra 3.0 Developer: CEIT Environmental Engineering Department (http://www.ceit.es/) First available year: 2008 Software requirements: Windows 2000 or XP Programming language: C/Cþþ, Fortran and C# Program availability and cost: The software application CalHidra 3.0 is property of the engineering company EPTISA S.A., Madrid, Spain. Contact person: Diego San Martín. E-mail: dsanmartin@eptisa.es	extreme programming;fortran;graphical user interface;mail (macos);microsoft windows;monte carlo method;population;programming language;programming paradigm;requirement;simulation;software requirements	Claudia M. Cardona;Cristina Martín;Antonio Salterain;Alain Castro;D. San-Martín;Eduardo Ayesa	2011	Environmental Modelling and Software	10.1016/j.envsoft.2011.02.006	dynamic simulation;simulation;hydrology;computer science;operations management;mathematics;statistics;monte carlo method	SE	-13.965961278442075	-19.93233641012926	47123
0c504d0c8319802c9f63eeea0d7b437cded2f4ef	high-performance complex event processing over streams	streams;sequences;complex event language;optimization technique;query optimization;events;rfid;performance analysis;complex event processing;high performance;facility management;supply chain management;sliding window	In this paper, we present the design, implementation, and evaluation of a system that executes complex event queries over real-time streams of RFID readings encoded as events. These complex event queries filter and correlate events to match specific patterns, and transform the relevant events into new composite events for the use of external monitoring applications. Stream-based execution of these queries enables time-critical actions to be taken in environments such as supply chain management, surveillance and facility management, healthcare, etc. We first propose a complex event language that significantly extends existing event languages to meet the needs of a range of RFID-enabled monitoring applications. We then describe a query plan-based approach to efficiently implementing this language. Our approach uses native operators to efficiently handle query-defined sequences, which are a key component of complex event processing, and pipeline such sequences to subsequent operators that are built by leveraging relational techniques. We also develop a large suite of optimization techniques to address challenges such as large sliding windows and intermediate result sizes. We demonstrate the effectiveness of our approach through a detailed performance analysis of our prototype implementation under a range of data and query workloads as well as through a comparison to a state-of-the-art stream processor.	complex event processing;franklin electronic publishers;java;mathematical optimization;microsoft windows;pipeline (computing);prototype;publish–subscribe pattern;query plan;real-time clock;scalability;software deployment;stream processing;window of opportunity	Eugene Wu;Yanlei Diao;Shariq Rizvi	2006		10.1145/1142473.1142520	radio-frequency identification;sliding window protocol;query optimization;real-time computing;supply chain management;computer science;complex event processing;data mining;sequence;database;streams;facility management	DB	-32.43352305270868	2.7093170923488104	47191
fbe2880bd9e5fcb2d67cbf162699769e2a4f0317	specsolv: artificially intelligent or artificially innovative?	artificial intelligent		artificial intelligence;intelligent agent	Michel Carabedian	1997	Journal of Chemical Information and Computer Sciences	10.1021/ci960033r	chemistry;computer science	AI	-29.990210864761274	-16.810769333795818	47194
eeab397780456d5d0ce276e96a29105236d19636	task-structure analysis for knowledge modeling	modelizacion;representacion conocimientos;organizacion funcional;structure arborescente;sistema informatico;base connaissance;abstraction;computer system;intelligence artificielle;abstraccion;artificial intelligent;domain knowledge;modelisation;estructura arborescente;tree structure;information processing;artificial intelligence;base conocimiento;systeme informatique;analysis;inteligencia artificial;information system;knowledge representation;representation connaissances;modeling;task organization;organisation fonctionnelle;systeme information;knowledge modeling;structure analysis;sistema informacion;knowledge base;analyse tâche structure	n recent years there has been increasing interest in describing complicated information processing systems in terms of the knowledge they have, rather than by the details of their implementation. This requires a means of modeling the knowledge in a system. Several different approaches to knowledge modeling have been developed by researchers working in Artificial Intelligence (AI). Most of these approaches share the view that knowledge must be modeled with respect to a goal or task. In this article , we outline our modeling approach in terms of the notion of a task-structure, which recursively links a task to alternative methods and to their subtasks. Our emphasis is on the notion of modeling domain knowledge using tasks and methods as mediating concepts. We begin by tracing the development of a number of different knowledge-modeling approaches. These approaches share many features, but their differences make it difficult to compare systems that have been modeled using different approaches. We present these approaches and describe their similarities and differences. We then give a detailed description , based on the task structure, of our knowledge-modeling approach and illustrate it with task structures for diagnosis and design. Finally, we show how the task structure can be used to compare and unify the other approaches. A knowledge-based system (KBS) has explicit representations of knowledge as well as inference processes that operate on these representations to achieve a goal. An inference process consists of a number of inference steps, each step creating additional knowledge. The process of applying inference steps is repeated until the information needed to fulfill the requirements of the problem-solving goal or task is generated. Typically, both domain knowledge and possible inference steps have to be modeled and represented in some form. In one sense, knowledge is of general utility-the same piece can be utilized in different contexts and problems; so, unlike traditional procedural approaches, knowledge should not be tied to one task or goal. On the other hand, it is difficult to know what knowledge to put in a system without having an idea of the tasks the KBS will confront. In spite of claims of generality, all KBSs are designed with some task or class of tasks in mind. Similarly, they are designed to be operational across some range of domains. Thus, a clear understanding of the relationship between tasks, knowledge and inferences required to perform the task is needed before knowledge in …	artificial intelligence;information processing;knowledge modeling;knowledge-based systems;mind;problem solving;recursion;requirement	B. Chandrasekaran;Todd R. Johnson;Jack W. Smith	1992	Commun. ACM	10.1145/130994.131002	knowledge base;systems modeling;information processing;computer science;artificial intelligence;analysis;abstraction;structural analysis;tree structure;operations research;information system;domain knowledge;algorithm	AI	-24.13857056207691	-3.4956526014601037	47259
ef0707a81222b769bded151870f978c8026fbce8	questions about functionalism in kant's philosophy of mind: lessons for cognitive science	cognitive science;transcendental psychology;discursive mind;kant;transcendental method;philosophy of mind;theory of mind;artificial intelligent;functionalism;cognitive process;history of cognitive science;subjective deduction	It has been argued by Kitcher, Brook, Sellars and others that: (1) Kant's philosophy of mind has valuable contributions to make to contemporary cognitive science and artificial intelligence projects contra earlier positivist commentators like P. F. Strawson; and (2) Kant's theory of mind is an early version of functionalism. The author agrees with the first thesis and disagrees with the second. Kant's theory of mental processing has a superficial resemblance to functional theories, but it diverges on several important points: Kant employs a transcendental method that is distinct and more powerful than the functionalist method, Kant believes that there is a specific transcendental architecture in the mind that functionalism is not well equipped to identify, Kant's theory has much stronger ontological commitments than those of functionalism, on Kant's view causal relationships are the product of cognitive processing, functionalism presupposes them, and Kant describes a reflexive problem created by the attem...	cognitive science;philosophy of mind	Matt McCormick	2003	J. Exp. Theor. Artif. Intell.	10.1080/0952813021000055180	functionalism;transcendental philosophy;cognition;philosophy of mind;computer science;artificial intelligence;cognitive science	AI	-26.110747739117688	-13.102609562932711	47264
1e825df28d601e1edcabe88c427161e9a5f08d94	using simulation to make order acceptance/rejection decisions	simulation ordinateur;manufacturing systems;control optimo;control optimo matematicas;systeme aide decision;simulation based order acceptance;production system;systeme production;acceptance;sistema ayuda decision;online simulation;aceptacion;sistema produccion;optimal control;controle optimal;decision support system;rejection;acceptation;commande optimale;order review and release;optimal control mathematics;simulation en ligne;simulacion computadora;rechazo;rejet;computer simulation	Simulation is a powerful decision-making tool that can be used to decide whether a candidate order should be accepted or rejected by a manufacturing system. Such a simulation-based order acceptance rule is presented, and important features of the rule are highlighted. How the manufacturing system can be optimally controlled using this rule and its effects on the main performance measures of the system are also demonstrated. In addition, modeling such a simulation-based order acceptance rule is challenging and requires resolving many issues. This article discusses these issues. The lessons learned from this modeling experience are generic and can be used in similar contexts.	decision support system;rejection sampling;simulation	Amitava Nandi;Paul Rogers	2004	Simulation	10.1177/0037549704045046	computer simulation;simulation;optimal control;decision support system;computer science;engineering;artificial intelligence;production system;operations research	Robotics	-6.409477425832029	-12.101323119585608	47312
9b58090cb12e6826e99a2dcc86e2610b7b7b7056	simulation of the dynamics of nonplayer characters' emotions and social relations in games	games artificial intelligence intelligent agent avatars computational intelligence computational modeling computer industry industrial relations toy industry computer science;toy industry;emotions;personality;nonplayer characters personality;nonplayer characters emotion;computational intelligence;dynamic model;computer industry;video game;nonplayer character npc;social relation;social relations;computational modeling;social science;human factors;non player character;socioemotional state;games;nonplayer characters behavior believability;intelligent agent;video game industry;avatars;industrial relations;artificial intelligence;nonplayer characters personality nonplayer characters emotion social relation video game industry social relation dynamics socioemotional state nonplayer characters behavior believability;social relation dynamics;computer science;human factors artificial intelligence computer games;computer games;social relations emotions nonplayer character npc personality	One of the main challenges faced by the video game industry is to give life to believable nonplayer characters (NPCs). Research shows that emotions play a key role in determining the behavior of individuals. In order to improve the believability of NPCs' behavior, we propose in this paper a model of the dynamics of emotions taking into account the personality and the social relations of the character. First, we present work from the literature on emotions, personality, and social relations in computer science and in human and social sciences. We focus on the influence of personality on the triggering of emotions, and the influence of emotions on the dynamics of social relations. Based on this work, we propose a dynamic model of the socioemotional state and its implementation as part of a tool for game programmers. This tool aims at the simulation of the evolution of emotions and social relations of NPCs based on their personality and roles.	action selection;affective computing;autonomous robot;cognition;computer science;dialog manager;heuristic;high-level programming language;immersion (virtual reality);intelligent agent;interaction;mathematical model;natural language generation;programmer;simulation;synthetic intelligence;usability;virtual reality	Magalie Ochs;Nicolas Sabouret;Vincent Corruble	2009	IEEE Transactions on Computational Intelligence and AI in Games	10.1109/TCIAIG.2009.2036247	games;social relation;simulation;emotion;computer science;artificial intelligence;personality;computational model	AI	-22.343990070618233	-19.286462519438533	47363
32d1c165bb799531c35120f3768b02c71f2b8bae	information, evolution and “error-friendliness”	genetics	Information can be conceived as being composed of two complementary components: novelty and confirmation. Whenever either of the two is zero, information is zero. Genetic information too requires both novelty and confirmation. Evolution can be seen as the history of diversification. Selection alone reduces diversity. Recessivity appears to serve as a mechanism to protect diversity against selection. So does the geographical and behavioural “separation” of species. Both recessivity and separation can be seen as “error-friendly”, a broader concept that is supportive of diversity, learning and further evolution. The principle should also be obeyed in technological systems.	diversification (finance);evolution	Ernst Ulrich von Weizsäcker;Christine von Weizsäcker	1998	Biological Cybernetics	10.1007/s004220050499		ML	-18.337605280561903	-19.21642463815276	47379
3695066bb112f77c023d15f524c7b5f0d46897ed	bigyap: exo-compilation meets udi		The widespread availability of large data-sets poses both an opportunity and a challenge to logic programming. A first approach is to couple a relational database with logic programming, say, a Prolog system with MySQL. While this approach does pay off in cases where the data cannot reside in main memory, it is known to introduce substantial overheads. Ideally, we would like the Prolog system to deal with large data-sets in an efficient way both in terms of memory and of processing time. Just In Time Indexing (JITI) was mainly motivated by this challenge, and can work quite well in many application. Exo-compilation, designed to deal with large tables, is a next step that achieves very interesting results, reducing the memory footprint over two thirds. We show that combining exocompilation with Just In Time Indexing can have significant advantages both in terms of memory usage and in terms of execution time. An alternative path that is relevant for many applications is User-Defined Indexing (UDI). This allows the use of specialized indexing for specific applications, say the spatial indexing crucial to any spatial system. The UDI sees indexing as pluggable modules, and can naturally be combined with Exo-compilation. We do so by using UDI with exo-data, and incorporating ideas from the UDI into high-performance indexers for specific tasks.	compiler;computer data storage;just-in-time compilation;logic programming;memory footprint;mysql;prolog;relational database;run time (program lifecycle phase);spatial reference system;uniform driver interface	Vítor Santos Costa;David Vaz	2013	TPLP	10.1017/S1471068413000501	computer science;theoretical computer science;computational science	DB	-31.375069569960388	2.3211645149209716	47437
61ba9cb6b55346e253dcaffbb97acdb682a476f7	a characterization of dictatorial social choice correspondences with continuous preferences	social choice correspondence	In this paper, under the assumption that all preferences are continuous and have unique top-ranked alternatives, we establish the equivalence between strict monotonicity and dictatorship for social choice correspondences.		Haixiang Yao;Jianxin Yi	2008	Mathematical Social Sciences	10.1016/j.mathsocsci.2007.09.003	economics;mathematical economics;welfare economics	AI	-6.6908749963283665	-1.2338780915733976	47455
bc8f9c24b9fb1153f6bbf6395c5b402db05e2adb	k-core covers and the core	k k compromise stability;core;k k core cover;k k compromise admissibility;core cover;assignment games	This paper extends the notion of individual minimal rights for a transferable utility game (TU-game) to coalitional minimal rights using minimal balanced families of a specific type, thus defining a corresponding minimal rights game. It is shown that the core of a TU-game coincides with the core of the corresponding minimal rights game. Moreover, the paper introduces the notion of the k-core cover as an extension of the core cover. The k-core cover of a TU-game consists of all efficient payoff vectors for which the total joint payoff for any coalition of size at most k is bounded from above by the value of this coalition in the corresponding dual game, and from below by the value of this coalition in the corresponding minimal rights game. It is shown that the core of a TU-game with player set N coincides with the b |N| 2 c-core cover. Furthermore, full characterizations of games for which a k-core cover is nonempty and for which a k-core cover coincides with the core are provided.		Estela Sánchez-Rodríguez;Peter Borm;Arantza Estévez-Fernández;M. Gloria Fiestras-Janeiro;Manuel A. Mosquera	2015	Math. Meth. of OR	10.1007/s00186-014-0490-9	core;mathematics;mathematical economics	AI	-6.166075067514103	-2.258169350267109	47512
477b257da29328994fa24b319ddc4afc3a740cdb	applying design-dependent knowledge in structural engineering design	acquired experience;concepcion ingenieria;engineering design;sistema experto;metodologia;construction structure;conception ingenierie;experience acquise;base connaissance;methodologie;structure construction;estudio caso;experiencia adquirida;estructura construccion;structural engineering;etude cas;base conocimiento;systeme expert;methodology;knowledge base;expert system	This paper discusses the character of the design-dependent knowledge in a structural engineering context, describes two initial applications of case-based reasoning to component design, and presents a general paradigm for a knowledge-based design system integrating rule-based and case-based reasoning	engineering design process	H. Craig Howard;Jenmu Wang;Francois Daube;Taufiq Rafiq	1989	AI EDAM	10.1017/S0890060400001141	knowledge representation and reasoning;legal expert system;knowledge base;computer science;engineering;artificial intelligence;knowledge engineering;methodology;reasoning system;structural pattern;expert system;engineering design process	AI	-24.340364549075787	-4.594047354304398	47548
b9c4e0a1252a3baa2498264630fa352c6ab7116a	participatory, embodied, multi-agent simulation	sensors;agent modeling;real time control;embedded agents;robotics;maturity model;multi agent simulation;participatory simulation	We will demonstrate the integration of a software-based multi-agent modeling platform with a participatory simulation environment and real-time control over a physical agent (robot). Both real and virtual participants will be able to act as agents in a simulation that will control a physical agent. The backbone of this demonstration is a widely used, freely available, mature modeling platform known as NetLogo.	agent-based model;algorithm;internet backbone;multi-agent system;netlogo;real-time locating system;simulation	Paulo Blikstein;William Rand;Uri Wilensky	2006		10.1145/1160633.1160913	real-time computing;simulation;real-time control system;computer science;sensor;artificial intelligence;robotics;capability maturity model;agent-based social simulation	AI	-24.82723356094393	-20.48218693520985	47553
9814096174ebdb628f93e71bae59c3efba510a63	the evaluation and analysis of competitiveness in regional equipment manufacturing based on factor analysis	economic strength regional equipment manufacturing factor analysis evaluation system investment competitiveness output competitiveness market competitiveness;industrial economics;machinery production industries;investment;machine learning;factor analysis;machinery production industries industrial economics investment;indexation;manufacturing economics indexes investments industries machine learning cybernetics;system analysis;empirical analyses region equipment manufacturing competitiveness index system factor analysis	Based on influence factors of competitiveness of equipment manufacturing, this paper proposes an evaluation system from three key elements which refer to investment competitiveness, output competitiveness and market competitiveness, and twelve indexes. Then determined measurement and evaluation of competitiveness of factor analysis to regional equipment manufacturing and have system analysis of equipment manufacturing in thirty regions from 2005 to 2008 based on the results of evaluation. The conclusion is: There has strong correlativity between competitiveness of regional equipment manufacturing and economic strength. Various regions should adjust measures to local conditions and take effective measures to improve competitiveness of equipment manufacturing.	factor analysis;system analysis	Rong-Ping Li;Hui-Dong Cui;Zheng Cui	2011	2011 International Conference on Machine Learning and Cybernetics	10.1109/ICMLC.2011.6016907	investment;machine learning;system analysis;factor analysis	Robotics	-7.212068067916294	-17.067124067553202	47602
561b95f93ff868423fe664cbb0bef87d8ccb1b3f	cordula: software requirements extraction utilizing chatbot as communication interface		Natural language requirement descriptions are often unstructured, contradictory and incomplete and are therefore challenging for automatic processing. Although many of these deficits can be compensated by means of natural language processing, there still remain cases where interaction with end-users is necessary for clarification. In this vision paper, we present CORDULA, a system using chatbot technology to establish end-user communication in order to support the requirement elicitation and partial compensation of deficits in user requirements.	natural language processing;requirement;software requirements;user requirements document	Edwin Friesen;Frederik Simon Bäumer;Michaela Geierhos	2018			software engineering;systems engineering;chatbot;natural language;computer science;software requirements	SE	-32.486656875458394	-5.182299808952273	47622
6fb663f2a2db9de3b9d9fc20e147d04bf49fc0e5	utilizing active software to capture tacit knowledge for strategic use	ingenierie connaissances;tacit knowledge;best practice;knowledge management;pertinencia;intelligence artificielle;software engineering;intelligent agents;pertinence;intelligent agent;genie logiciel;software framework;artificial intelligence;knowledge elicitation;knowledge elicitation methodology;inteligencia artificial;relevance;active software;ingenieria informatica;knowledge engineering	Knowledge on the organization's own work-strategies for carrying out regular tasks are now being recognized as an increasingly more valuable resource. However, due to the complexity of eliciting the distributed, fragmented and partly tacit knowledge inherent in best practice and “know-how”, tools to handle this need seem systematically unaccounted for. This paper outlines an approach on extracting this knowledge by utilizing an augmented active software framework. Our focus in this paper is how this approach provides a beneficiary way of employing the knowledge generated by active software during a session. We illustrate the relevance of this approach by a sample scenario extending a real-world example taken from the software engineering domain.#R##N##R##N#Topic: Knowledge Representation and Management, Intelligent Agents		Jenny Eriksson Lundström	2005		10.1007/11554028_35	relevance;software mining;computer science;knowledge management;artificial intelligence;software framework;body of knowledge;knowledge extraction;knowledge value chain;intelligent agent;domain knowledge;best practice	Robotics	-32.08834122696149	-6.131203438951352	47700
1db20dd282fd0aa6f38f24aa60046ca2ad01ca6e	strategic behavior and information transmission in a stylized (so-called chinos) guessing game	information transmission;strategic behavior;herding;chinos game;guessing game	"""A guessing game very popular in some European countries involves several players hiding in their hands a number of coins (or pebbles) between zero and three, then attempting to guess in turn the total number of coins in the hands of everyone, with the restriction that no player can repeat the guess issued by any predecessor. After a full round, the player, if any, who guesses correctly wins. Of course, rounds without a winner are also possible, in which case a new round is started afresh. The purpose of the present article is to present an analysis of this game (called Chinos in Spain, as a perturbation of """"chinas"""", i.e. pebbles), and some of its possible variants. Our primary aim is to show its potential to shed light on some issues of strategic behavior and information transmission that seem very germane to some social and economic problems."""		Luis Pastor-Abia;José M. Pérez-Jordá;Emilio San-Fabián;Enrique Louis;Fernando Vega-Redondo	2001	Advances in Complex Systems	10.1142/S0219525901000152	non-cooperative game;herding;simulation;economics;computer science;artificial intelligence;social psychology	HCI	-6.7831468572878135	-4.326480896404815	47814
9b1507e229b7ade0420cacdecdffd86f23684b18	logical agents for language and action	automated reasoning;game development;non player character;formal logic;datavetenskap datalogi;computer science;agent architecture;computer game	Game developers are faced with the difficult task of creating non-player characters with convincing behavior. This commonly involves an exhaustive specification of their actions in every conceivable situation that might arise. The process is laborious and the results do not apply in new and unforeseen circumstances. We present an agent architecture where game characters have a basic understanding of their environment that enables them to figure out what to do by themselves. Knowledge about facts and actions is encoded in a formal logic where automated reasoning technology can apply the knowledge to answer novel questions in dialog and to plan actions in new situations. A number of examples serve to demonstrate how the technology meets the challenges of application in a simple computer game prototype. We envision this technology being used to create more flexible game characters with a deeper understanding of the world they inhabit.	agent architecture;automated reasoning;automated theorem proving;autonomous agent;autonomous robot;commonsense knowledge (artificial intelligence);decision tree;finite-state machine;pc game;pac-land;population;problem solving;prototype;reasoning system;video game developer;dialog	Martin Magnusson;Patrick Doherty	2008			game design;agent architecture;game development tool;computer science;artificial intelligence;theoretical computer science;automated reasoning;game design document;video game development;logic	AI	-24.433453760630613	-21.041287016650955	47848
9d8f8be0b33693aaf9afbd72a43f2a57c7aa05fc	using a novel conjunctive mcdm approach based on dematel, fuzzy anp, and topsis as an innovation support system for taiwanese higher education	multiple criteria decision making;fuzzy analytic network process fanp;higher education;higher education institution;support system;decision making trial and evaluation laboratory dematel;analytic network process;innovation support system iss;technique for order preference by similarity to an ideal solution topsis;article	Increasing numbers of Taiwanese higher education institutes are pursuing innovation operation. However, these institutes generally rely greatly on academic research to evaluate innovation performance. Nevertheless, the performance of innovation may be affected by numerous factors that are often beyond the scope of a single academic study. Thus, to address this concern, this paper constructs an innovation support system (ISS) for Taiwanese higher education institutes to comprehensively evaluate their innovation performance. Previous research often evaluates performance by independently considering a number of criteria. However, this assumption of independence does not model the so-called ‘‘real world”; thus, we present a novel conjunctive multiple criteria decision-making (MCDM) approach that addresses dependent relationships among each measurement criteria. As such, we utilize a decisionmaking trial and evaluation laboratory (DEMATEL), a fuzzy analytical network process (FANP), and a technique for order preference by similarity to an ideal solution (TOPSIS) forming order to develop an innovation support system (ISS) that considers the interdependence and the relative weights of each measurement criterion. 2009 Elsevier Ltd. All rights reserved.	interdependence	Jui-Kuei Chen;Jui-Kuei Chen	2010	Expert Syst. Appl.	10.1016/j.eswa.2009.06.079	computer science;knowledge management;artificial intelligence;management science;higher education;analytic network process	HCI	-5.565141919211909	-18.14403362992656	47941
0fb6f896540ac046ac4a59b41b5a3c393c5e9977	belief-free equilibria in games with incomplete information: characterization and existence	information structure;incentive compatibility;games with incomplete information;repeated game;incomplete information;necessary and sufficient condition;repeated game with incomplete information harsanyi doctrine belief free equilibria;individual rationality	We characterize belief-free equilibria in infinitely repeated games with incomplete information with N ≥ 2 players and arbitrary information structures. This characterization involves a new type of individual rational constraint linking the lowest equilibrium payoffs across players. The characterization is tight: we define a set of payoffs that contains all the belief-free equilibrium payoffs; conversely, any point in the interior of this set is a belief-free equilibrium payoff vector when players are sufficiently patient. Further, we provide necessary and sufficient conditions on the information structure for this set to be non-empty, both for the case of known-own payoffs, and for arbitrary payoffs.	action potential;continuation;data structure;game theory;personally identifiable information;rate of convergence	Johannes Hörner;Stefano Lovo;Tristan Tomala	2011	J. Economic Theory	10.1016/j.jet.2011.06.001	bayesian game;economics;incentive compatibility;repeated game;microeconomics;mathematical economics;welfare economics;complete information	ECom	-4.829029887287879	-1.8231937335316126	47961
8439587d5c1ab0ba181f115ebf29da0fd3f2cb57	an approach to optimal design of storage parameters in databases	resident;storage parameter optimization;optimal design;overflow storage;database organization;parameter optimization	"""loop until all descendants are marked or value is true: lm := leftmost unmarked descendant; if value(lm) = T then value is true else mark descendant; repeat; then all descendants are mar/ted ~ value : = F; value is true ~ value := T; fi; 6. Conclusion The discussion in this paper centers around the handling of a single query, and results in an optimal technique for a response to it. In practice, however, queries arrive in streams from many remote terminals into the central computer system. In order to have our response system function more efficiently in that environment , we accumulate and batch incoming queries. Specifically, we prepare the record negotiating algorithm described above for each query, and then apply this set of individual algorithms to every record of the file. The method described in this paper is applicable in other contexts as well. For example, in the evaluation of a regular Boolean expression, when all the components 1~ are assumed to have equal values of t(h) and p(I~), or in the analysis of problem solving techniques as described in [11], chapter 4. There a use is made of AND/OR graphs which resemble our tree structure, and the property of a node being """"solved"""" by that methodology is similar to identifying a node as having a value T in the approach presented in this discussion. A relational model of data for large shared data banks."""	algorithm;boolean expression;computer;database;optimal design;problem solving;relational model;tree structure	Y. Milman	1977	Commun. ACM	10.1145/359581.359601	computer science;optimal design;data mining;database;statistics	DB	-27.834007149314385	3.890586155020796	47968
faeb145dd94036a641d145189e92d48bfa73c2ca	identifying prohibition norms in agent societies	simulation;prohibition norms;agents;norm identification;societies;norms;architecture;normative multi agent systems normas	In normative multi-agent systems, the question of “how an agent identifies norms in an open agent society” has not received much attention. This paper aims at addressing this question. To this end, this paper proposes an architecture for norm identification for an agent. The architecture is based on observation of interactions between agents. This architecture enables an autonomous agent to identify prohibition norms in a society using the prohibition norm identification (PNI) algorithm. The PNI algorithm uses association rule mining, a data mining approach to identify sequences of events as candidate norms. When a norm changes, an agent using our architecture will be able to modify the norm and also remove a norm if it does not hold in the society. Using simulations of a park scenario we demonstrate how an agent makes use of the norm identification framework to identify prohibition norms.	agent architecture;algorithm;association rule learning;autonomous agent;autonomous robot;data mining;interaction;multi-agent system;peering;simulation;t-norm	Bastin Tony Roy Savarimuthu;Stephen Cranefield;Maryam Purvis;Martin K. Purvis	2012	Artificial Intelligence and Law	10.1007/s10506-012-9126-7	computer science;artificial intelligence;architecture	AI	-19.992728766857986	-11.209540339253351	47992
51a764453817464a770514eb89334760bdae051a	accumulative information enhancement in the self-organizing maps and its application to the analysis of mission statements	systemy neuronowe;informacja;komunikat;statement;mission;zbior danych;computational method;artificial data set;neural systems;metoda obliczeniowa;misja;information			Ryozo Kitajima;Ryotaro Kamimura	2015	J. Artif. Intell. Soft Comput. Res.	10.1515/jaiscr-2015-0026	information;computer science;artificial intelligence;data mining;operations research;statistics	AI	-29.075393861735677	-7.82097931605795	48008
68f61d95bc68844c7e60ffb913af9a9fe5190fd7	expressing collaborative and competitive coordination among abductive			abductive reasoning	Anna Ciampolini;Evelina Lamma;Paola Mello;Paolo Torroni	2000			theoretical computer science;natural language processing;computer science;artificial intelligence	ECom	-26.59397048369072	-9.35927247954992	48121
a9967bc0ef5ebd348d2cfabb3b18fe0e9c971275	prefix based numbering schemes for xml: techniques, applications and performances	labeling scheme;network routing;storage capacity;knowledge representation	Commonly used in network routing, programming, classification and knowledge representation systems, labeling schemes have also interested the XML community. We thus motivate and describe numbering schemes, their applications, and the trade off between storage capacities and runtime performance. We present a taxonomy of numbering schemes for XML based on the types of supported queries (ancestor, adjacent, etc), the encoding technique, and whether the scheme offers robustness properties according to updates. We describe some of the numbering techniques proposed for XML. We focus on prefixbased schemes. We give a qualitative comparison of the existing numbering schemes, discussing their advantages and drawbacks. Then, we compare their storage requirement and performances. Finally, we consider the new research directions that are likely to benefit from numbering scheme techniques.	experiment;knowledge representation and reasoning;mathematical optimization;mobile phone;performance;personal digital assistant;routing;run time (program lifecycle phase);statistical classification;taxonomy (general);xlink;xml	Virginie Sans;Dominique Laurent	2008	PVLDB	10.14778/1454159.1454228	knowledge representation and reasoning;routing;computer science;theoretical computer science;data mining;database	DB	-28.631572087508527	0.9416624742251236	48186
780ca972986eef92bff6fc7ae9ad75bd6042aaaf	a better project performance prediction model using fuzzy time series and data envelopment analysis	forecasting;fuzzy time series;performance management;cost and schedule performance index;journal of the operational research society;data envelopment analysis;earned value management	Earned value management (EVM) is a critical project management methodology that evaluates and predicts project performance from cost and schedule perspectives. The novel theoretical framework presented in this paper estimates future performance of a project based on the past performance data. The model benefits from a fuzzy time series forecasting model in the estimation process. Furthermore, fuzzy-based estimation is developed using linguistic terms to interpret different possible conditions of projects. Eventually, data envelopment analysis is applied to determine the superior model for forecasting of project performance. Multiple illustrative cases and simulated data have been used for comparative analysis and to illustrate the applicability of theoretical model to real situations. Contrary to EVM-based approach, which assumes the future performance is the same as the past, the proposed model can greatly assist project managers in more realistically assessing prospective performance of projects and thereby taking necessary and on-time appropriate actions. Journal of the Operational Research Society advance online publication, 6 April 2016; doi:10.1057/jors.2016.20	data envelopment analysis;fuzzy concept;performance prediction;prospective search;qualitative comparative analysis;simulation;theory;time series	Mostafa Salari;Homayoun Khamooshi	2016	JORS	10.1057/jors.2016.20	performance management;economics;earned value management;forecasting;operations management;data envelopment analysis;management science;management;operations research	Metrics	-6.787113648486878	-15.155481918220456	48197
f1e6a2e328c487394540c12b21680c51b5780a96	collaborative explanation and response in assisted living environments enhanced with humanoid robots	distributed reasoning;service robots;conference paper;social robotics	An ageing population with increased social care needs has provided recent impetus for research into assisted living technologies, as the need for different approaches to providing supportive environments for senior citizens becomes paramount. Ambient intelligence (AmI) systems are already contributing to this endeavour. A key feature of future AmI systems will be the ability to identify causes and explanations for changes to the environment, in order to react appropriately. We identify some of the challenges that arise in this respect, and argue that an iterative and distributed approach to explanation generation is required, interleaved with directed data gathering. We further argue that this can be realised by developing and combining state-of-the art techniques in automated distributed reasoning, activity recognition, robotics, and knowledge-based control.	abductive reasoning;activity recognition;ambient intelligence;artificial intelligence;centrality;computation;defeasible reasoning;endeavour (supercomputer);extensibility;icaart;iteration;iterative method;knowledge representation and reasoning;knowledge-based systems;mobile robot;next-generation network;norm (social);robotics	Antonis Bikakis;Patrice Caire;Keith Clark;Gary Cornelius;Jiefei Ma;Rob Miller;Alessandra Russo;Holger Voos	2016		10.5220/0005823405060511	simulation;computer science;artificial intelligence;social robot;future of robotics	AI	-31.911204013355718	-15.054080982210545	48308
46542a115bb25fc06024101a71917860a2a14ba5	dynamic view selection for olap	online analytical processing;olap;view selection;data warehousing;combinatorial optimization	In a data warehousing environment, aggregate views are often materialized in order to speed up aggregate queries of online analytical processing (OLAP). Due to the increasing size of data warehouses, it is often infeasible to materialize all views. View selection, the task of selecting a subset of views to materialize based on updates and expectations of the query load, is an important and challenging problem. In this article, we explore dynamic view selection in which the distribution of queries changes over time and the set of materialized views must be tuned by replacing some of the previously materialized views with new ones.	aggregate data;materialized view;online analytical processing	Michael Lawrence;Andrew Rau-Chaplin	2008	IJDWM	10.4018/jdwm.2008010103	materialized view;combinatorial optimization;online analytical processing;computer science;data warehouse;data mining;database;information retrieval	DB	-26.22455411229045	4.022913543880534	48331
9ac2bae870b0107f7d40ec7199ed356b84e78ab6	using real-life troubleshooting interactions to inform self-assistance design	interfase usuario;multiagent system;base donnee;sistema experto;keyword;guidage;centre appel;maintenance;building block;user interface;relacion hombre maquina;database;call centre;base dato;base connaissance;man machine relation;palabra clave;guiado;mot cle;printer;service utilisateur;keyword search;imprimante;mantenimiento;impresora;guidance;base conocimiento;interface utilisateur;call centres;relation homme machine;servicio usuario;systeme expert;user service;sistema multiagente;systeme multiagent;knowledge base;expert system	Technical troubleshooting is a domain that has changed enormously in recent years. Instead of relying on visits from service personnel end users facing technical problems with machinery, for example computers and printers, can now seek assistance from systems that guide them toward an autonomous solution of the problem. Systems that can be offered to them are wide in their range, but typically fall either in the category of Expert Systems or searchable databases that can be queried with keyword searches. Both approaches present advantages and disadvantages in terms of flexibility to address different levels of user expertise and ease of maintenance. However, few studies explicitly address the issue of how best to design for a balance between guidance and user freedom in such systems. In the work reported here an office equipment manufacturer’s call centre was studied in order to understand the mechanisms used when human agents guide users toward a resolution. The overall aim here is not to reproduce the agent behaviour in a system, but rather to identify which interactional building blocks such a system should have. These are assessed in relation to the existing online knowledge base resources offered by the same company in order to exemplify the kinds of issues designers need to attend to in this domain.	interaction	Jacki O'Neill;Antonietta Grasso;Stefania Castellani;Peter Tolmie	2005		10.1007/11555261_32	knowledge base;simulation;computer science;artificial intelligence;operating system;database;distributed computing;user interface;world wide web;computer security;expert system;algorithm	AI	-25.596692578122568	-3.9749107656424933	48332
436488752ac00e20d0770934d97652eb88843608	developing an ontology-based rollover monitoring and decision support system for engineering vehicles		The increasing number of rollover accidents of engineering vehicles has attracted close attention; however, most researchers focus on the analysis and monitoring of rollover stability indexes and seldom the assessment and decision support for the rollover risk of engineering vehicles. In this context, an ontology-based rollover monitoring and decision support system for engineering vehicles is proposed. The ontology model is built for representing monitored rollover stability data with semantic properties and for constructing semantic relevance among the various concepts involved in the rollover domain. On the basis of this, ontology querying and reasoning methods based on the Simple Protocol and RDF Query Language (SPARQL) and Semantic Web Rule Language (SWRL) rules are utilized to realize the rollover risk assessment and to obtain suggested measures. PC and mobile applications (APPs) have also been developed to implement the above methods. In addition, five sets of rollover stability data for an articulated off-road engineering vehicle under different working conditions were analyzed to verify the accuracy and effectiveness of the proposed system.	decision support system;mobile app;rdf query language;relevance;risk assessment;sparql;semantic web rule language	Feixiang Xu;Xinhui Liu;Chen Zhou	2018	Information	10.3390/info9050112	semantic property;data mining;computer science;semantic web rule language;ontology;rollover;sparql;rdf query language;decision support system;risk assessment	Web+IR	-33.62166375508989	-12.666364718279866	48345
eb7b3cad31d560eea6dc90e893ece15d5e0d51d7	an improved voting analytic hierarchy process-data envelopment analysis methodology for suppliers selection	analytic hierarchy process;analytic hierarchy process ahp;multi criteria decision making;multi criteria decision making mcdm;data envelopment analysis dea;voting analytic hierarchy process vahp;data envelope analysis;supplier selection	Taylor & Francis makes every effort to ensure the accuracy of all the information (the “Content”) contained in the publications on our platform. However, Taylor & Francis, our agents, and our licensors make no representations or warranties whatsoever as to the accuracy, completeness, or suitability for any purpose of the Content. Any opinions and views expressed in this publication are the opinions and views of the authors, and are not the views of or endorsed by Taylor & Francis. The accuracy of the Content should not be relied upon and should be independently verified with primary sources of information. Taylor and Francis shall not be liable for any losses, actions, claims, proceedings, demands, costs, expenses, damages, and other liabilities whatsoever or howsoever caused arising directly or indirectly in connection with, in relation to or arising out of the use of the Content.	analytical hierarchy;data envelopment analysis;francis;primary source	Abdollah Hadi-Vencheh;M. Niazi-Motlagh	2011	Int. J. Computer Integrated Manufacturing	10.1080/0951192X.2011.552528	analytic hierarchy process;economics;computer science;operations management;data envelopment analysis;operations research;welfare economics;analytic network process	Robotics	-14.436728273141716	-5.331769396849493	48359
098d40c7c8eb1fa41b32e199dc73567eea10eac5	the grid file: an adaptable, symmetric multikey file structure	range query;data compression;search space;multidimensional data;upper bound;file system;sparse matrix;dynamic storage allocation	Traditional file structures that provide multikey access to records, for example, inverted files, are extensions of file structures originally designed for single-key access. They manifest various deficiencies in particular for multikey access to highly dynamic files. We study the dynamic aspects of file structures that treat all keys symmetrically, that is, file structures which avoid the distinction between primary and secondary keys. We start from a bitmap approach and treat the problem of file design as one of data compression of a large sparse matrix. This leads to the notions of a grid partition of the search space and of a grid directory, which are the keys to a dynamic file structure called the grid file. This file system adapts gracefully to its contents under insertions and deletions, and thus achieves an upper bound of two disk accesses for single record retrieval; it also handles range queries and partially specified queries efficiently. We discuss in detail the design decisions that led to the grid file, present simulation results of its behavior, and compare it to other multikey access file structures.	acm transactions on database systems;bitmap;computer data storage;data compression;directory (computing);graceful exit;grid file;inverted index;leaky bucket;range query (data structures);simulation;space partitioning;sparse matrix	Jürg Nievergelt;Hans Hinterberger;Kenneth C. Sevcik	1984	ACM Trans. Database Syst.	10.1145/348.318586	data compression;fork;self-certifying file system;range query;grid file;torrent file;indexed file;memory-mapped file;device file;sparse matrix;computer file;computer science;class implementation file;stub file;versioning file system;theoretical computer science;operating system;unix file types;journaling file system;database;open;data file;upper and lower bounds;file system fragmentation;file control block	DB	-28.029609444429713	2.8945269939290608	48362
0c945a02a060fb31f92fccbc706a5ad0ca510846	a neuro-cognitive theory of deductive relational reasoning with mental models and visual images	parietal cortex;cognitive theory;mental imagery;visual mental imagery;visual working memory;spatial representation;visual impedance effect;mental model;relational reasoning;deduction	Many neuro-imaging studies have provided evidence that the parietal cortex plays a key role in reasoning based on mental models, which are supposed to be of abstract spatial nature. However, these studies have also shown concurrent activation in vision-related cortical areas which have often been interpreted as evidence for thespatial nature. However, these studies have also shown concurrent activation in vision-related cortical areas which have often been interpreted as evidence for the role of visual mental imagery in reasoning. The aim of the paper is to resolve the inconsistencies in the previous literature on reasoning and imagery and to develop a neurally and cognitively plausible theory of human relational reasoning. The main assumption is that visual brain areas are only involved if the problem information is easy to visualize and when this information must be processed and maintained in visual working memory. A regular reasoning process, however, does not involve visual images but more abstract spatial representations—spatial mental models—held in parietal cortices. Only these spatial representations are crucial for the genuine reasoning processes.	causality;epiphenomenon;experience;gottfried ungerboeck;holism;image;list comprehension;medical imaging;mental model;mental operations;mind;multimodal interaction;neuro-fuzzy;simulation;theory	Markus Knauff	2009	Spatial Cognition & Computation	10.1080/13875860902887605	psychology;mental image;cognitive psychology;computer vision;neuroscience;visual memory;verbal reasoning;posterior parietal cortex;social psychology	AI	-25.093903382136094	-15.358717919759052	48387
918fc06946b6759dcc2eb745a736c2c5eff7d10e	estimating global stress environment by observing local behavior in distributed multiagent systems	reliability;multiagent system;cognitive systems;survivability global stress environment estimation observing local behavior distributed multiagent system supply chain planning system cognitive agent architecture local time series deterministic dynamical system k nearest neighbor algorithm;multiagent systems supply chains manufacturing industries scalability stress control electrical equipment industry data mining acoustical engineering degradation nonlinear dynamical systems;cognitive agents;dynamic system;time series;reliability multi agent systems supply chain management planning cognitive systems time series;multi agent systems;supply chain planning;k nearest neighbor;planning;supply chain management;local time	A multiagent system can be considered survivable if it adapts itself to varying stresses without considerable performance degradation. Such an adaptivity comprises of identifying the behavior of the agents in a society, relating them to stress situations, and then invoking control rules. This problem is a hard one, especially in distributed multiagent systems wherein the agent behaviors tend to be nonlinear and dynamic. In this paper, we study a supply chain planning system implemented in COUGAAR (cognitive agent architecture) and develop a methodology for identifying the behavior of agents through their behavioral parameters, and relating those parameters to stress situations. One important aspect of our approach is that we identify the stress situations of agents in the society by observing local behavior of one representative agent. This approach is motivated by the fact that a local time series can have the information of the dynamics of the entire system in deterministic dynamical systems. We validate our approach empirically through identifying the stress situations using k-nearest neighbor algorithm based on the behavioral parameters.	agent architecture;agent-based model;cougaar;dynamical system;elegant degradation;k-nearest neighbors algorithm;multi-agent system;nonlinear system;time series	Seokcheon Lee;Soundar R. T. Kumara	2005	IEEE International Conference on Automation Science and Engineering, 2005.	10.1109/COASE.2005.1506771	simulation;engineering;artificial intelligence;operations management	Robotics	-13.524017881339322	-12.675142457948942	48431
55a723201355a49f6f705446d66b3c4fc625b236	fuzzy methodology application for failure analysis of transmission system		The aim of this research work is to propose a fuzzy methodology-based integrated framework for the failure analysis of the transmission system of the TATA Company-made heavy commercial vehicle. Under the failure analysis failure mode effect analysis (FMEA) approaches has been applied and the critical components of the considered system were identified on the basis of their risk priority number (RPN). The identification of critical components on the basis of RPN score results in confusion to system analyst as it becomes difficult to allocate appropriate risk priorities under same RPN scores. Also, importance among the probability of occurrence of failure (Of), severity (S), probability of non-detection (Od) are assumed to be of same importance, however, in real practical application there exists relative importance among these three factors. Therefore, to overcome such types of limitations of FMEA approach a fuzzy decision making system (FDMS) and grey relation analysis (GRA) approaches were applied. The r...	failure analysis	Dilbagh Panchal;Umesh Jamwal;Priyank Srivastava;Kushal Kamboj;Rohit Sharma	2018	IJMOR	10.1504/IJMOR.2018.10010217	confusion;fuzzy logic;mathematical optimization;reliability engineering;transmission system;failure mode and effects analysis;mathematics	Robotics	-7.928275943210141	-17.21403781741482	48449
f46e141d919b6b2fcc2c39e71fe33e3658e58b53	driving into the future with its	engineering;systems;intelligent transport system;traffic engineering computing artificial intelligence automated highways;technology;computer science artificial intelligence;intelligent transportation system;automated highways;transportation artificial intelligence intelligent systems communication system traffic control internet traffic control system testing intelligent networks control systems computer simulation;transport infrastructure;artificial intelligent;ai based technology;its;science technology;transportation;transportation artificial intelligence intelligent systems;intelligent systems;intelligent system;artificial intelligence;traffic engineering computing;computer science;engineering electrical electronic;research trends;ai based technology its intelligent transportation system	Intelligent transportation systems have integrated a broad range of AI-based technologies into both the transportation infrastructure and vehicles themselves. Although the future of ITS is promising, the field is anything but futuristic. Various ITS products and services are already at work throughout the world, significantly improving transportation safety, mobility, and productivity		Fei-Yue Wang	2006	IEEE Intelligent Systems	10.1109/MIS.2006.45	intelligent transportation system;simulation;intelligent decision support system;computer science;artificial intelligence;technology	Robotics	-20.404946192546323	-23.78760625598652	48500
1626157998ff2d3b286ea19aa21c166c3495ce98	midi music generator based on stm32		This paper describes a use of ARM processors STM32F407ZET6's and MIDI music generator hardware and software design and implementation, STM32F407ZET6 communicate with the host computer through serial ports, and the cpu can access and quickly identify the vocal baseband data, and finally convert it to a MIDI sound chip that can recognize MIDI message, so that the MIDI sound source and vocal fundamental frequency corresponding to the different sounds of electronic tones.	midi;stm32	Xinyuan Guo	2013		10.1007/978-3-642-53703-5_13	midi;i-cubex;speech recognition;acoustics;computer hardware;engineering;midi beat clock	NLP	-14.573203393664537	-8.487186625101293	48534
4729a85d3c5774a44299c6ce9534f079386cbe2b	achieving human-level intelligence through integrated systems and research: introduction to this special issue	human-level intelligence;integrated system;special issue	12 AI MAGAZINE ■ This special issue is based on the premise that in order to achieve human-level artificial intelligence researchers will have to find ways to integrate insights from multiple computational frameworks and to exploit insights from other fields that study intelligence. Articles in this issue describe recent approaches for integrating algorithms and data structures from diverse subfields of AI. Much of this work incorporates insights from neuroscience, social and cognitive psychology or linguistics. The new applications and significant improvements to existing applications this work has enabled demonstrates the ability of integrated systems and research to continue progress towards human-level artificial intelligence.	algorithm;artificial intelligence;data structure	Nicholas L. Cassimatis;Erik T. Mueller;Patrick Henry Winston	2006	AI Magazine		computer science;engineering;artificial intelligence;operations research	AI	-25.267064859012418	-16.352075956199815	48535
0427ff5a393f388ebda91640d261bd9376f468dc	artificial intelligence: deep neural reasoning	neuroscience;computer science	The human brain can solve highly abstract reasoning problems using a neural network that is entirely physical. The underlying mechanisms are only partially understood, but an artificial network provides valuable insight. See Article p.471	artificial intelligence	Herbert Jaeger	2016	Nature	10.1038/nature19477	nervous system network models;biology;artificial intelligence system	AI	-26.548100704351658	-14.972424564059901	48646
5b3e70252470e0aae61686bfd5afb3132d17a5cc	justified inference	justification;inference;rationality;normativity;internalism;belief;coherence;coherentism;foundationalism;warrant transmission	This paper proposes a general account of the epistemological significance of inference. This account rests on the assumption that the concept of a “justified” belief or inference is a normative concept. It also rests on a conception of belief that distinguishes both (a) between conditional and unconditional beliefs and (b) between enduring belief states and mental events of forming or reaffirming a belief, and interprets all of these different kinds of belief as coming in degrees. Conceptions of “rational coherence” and “competent inference” are then formulated, in terms of the undefeated instances of certain rules of inference. It is proposed that (non-accidental) rational coherence is a necessary and sufficient condition of justified enduring belief states, while competent inference always results in a justified mental event of some kind. This proposal turns out to tell against the view that there are any non-trivial cases of “warrant transmission failure”. Finally, it is explained how these proposals can answer the objections that philosophers have raised against the idea that justified belief is “closed” under competent inference.	emoticon;error-tolerant design;mental event	Ralph Wedgwood	2011	Synthese	10.1007/s11229-011-0012-8		AI	-13.388133480972655	3.244643552423408	48647
5f98820430f56eebb759861f077c293084066776	risk analysis in a linguistic environment: a fuzzy evidential reasoning-based approach	risk analysis;dempster shafer theory of evidence;fuzzy set theory;evidential reasoning;complex system;failure mechanism;complex systems;expert knowledge;systemic risk;uncertain data;similarity measure	Performing risk analysis can be a challenging task for complex systems due to lack of data and insufficient understanding of the failure mechanisms. A semi quantitative approach that can utilize imprecise information, uncertain data and domain experts' knowledge can be an effective way to perform risk analysis for complex systems. Though the definition of risk varies considerably across disciplines, it is a well accepted notion to use a composition of likelihood of system failure and the associated consequences (severity of loss). A complex system consists of various components, where these two elements of risk for each component can be linguistically described by the domain experts. The proposed linguistic approach is based on fuzzy set theory and Dempster-Shafer theory of evidence, where the later has been used to combine the risk of components to determine the system risk. The proposed risk analysis approach is demonstrated through a numerical example.	complex systems;it risk management;numerical analysis;uncertain data	Yong Deng;Rehan Sadiq;Wen Jiang;Solomon Tesfamariam	2011	Expert Syst. Appl.	10.1016/j.eswa.2011.06.018	complex systems;risk analysis;computer science;artificial intelligence;machine learning;data mining;mathematics;fuzzy set;evidential reasoning approach;systemic risk	NLP	-5.857622464108618	-21.329883523730626	48710
1d48bf16fdcc92b841b1260bc7db6afcd811d872	from 0.5 million to 2.5 million: efficiently scaling up real-time bidding	digital signal processing;servers real time systems load modeling data mining media resource management digital signal processing;tendering advertising data processing electronic commerce resource allocation;resource management;hierarchical resource allocation problem media inventory auction system programmatic buying platforms contemporary real time bidding system advertiser advertisements bid request model;scalability online advertising real time bidding modeling;data mining;media;servers;online advertising;scalability;load modeling;modeling;real time bidding;real time systems	Real-Time Bidding allows an advertiser to purchase media inventory through an auction system that unfolds in the order of milliseconds. Media providers are increasingly being integrated into such programmatic buying platforms. It is typical for a contemporary Real-Time Bidding system to receive millions of bid requests per second at peak time, and have a large portion of these to be irrelevant to any advertiser. Meanwhile, given a valuable bid request, tens of thousands of advertisements might be qualified for scoring. We present our efforts in building selection models for both bid requests and advertisements to handle this scalability challenge. Our bid request model treats the system load as a hierarchical resource allocation problem and directs traffic based on the estimated quality of bid requests. Next, our exploration/exploitation advertisement model selects a limited number of qualified advertisements for thorough scoring based on the expected value of a bid request to the advertiser given its features. Our combined bid request and advertisement model is able to win more auctions and bring more value to clients by stabilizing the bidding pipeline. We empirically show that our deployed system is capable of handling 5x more bid requests.	load (computing);online advertising;online and offline;real-time bidding;real-time transcription;reinforcement learning;relevance;scalability;web server	Jianqiang Shen;Burkay Orten;Sahin Cem Geyik;Daniel Liu;Shahriar Shariat;Fang Bian;Ali Dasdan	2015	2015 IEEE International Conference on Data Mining	10.1109/ICDM.2015.72	auction sniping;online advertising;scalability;systems modeling;media;real-time bidding;computer science;resource management;digital signal processing;data mining;server	DB	-7.343028218332821	-9.741687513445198	48744
92d7d866d2b9c582da866e8a23dfe04ce1bc08a6	query evaluation on a database given by a random graph	busqueda informacion;modelizacion;graph theory;random graph;approximation asymptotique;base donnee;teoria grafo;probabilidad condicional;information retrieval;grafo aleatorio;probabilite conditionnelle;interrogation base donnee;database;interrogacion base datos;base dato;graphe aleatoire;probabilistic approach;theorie graphe;modelisation;data privacy;recherche information;query evaluation;enfoque probabilista;approche probabiliste;asymptotic approximation;modeling;conditional probability;confidentialite donnee;database query;aproximacion asintotica	We consider random graphs, and their extensions to random structures, with edge probabilities of the form βn−−α, where n is the number of vertices, α, β are fixed and α> 1 (α arity – 1 for structures of higher arity). We consider conjunctive properties over these random graphs, and investigate the problem of computing their asymptotic conditional probabilities. This provides us a novel approach to dealing with uncertainty in databases, with applications to data privacy and other database problems.	random graph	Nilesh N. Dalvi	2007		10.1007/11965893_11	random regular graph;random graph;combinatorics;systems modeling;boolean conjunctive query;conditional probability;computer science;graph theory;theoretical computer science;data mining;mathematics	DB	-22.801763440516588	3.9557901020794604	48749
a6c45384ca22a31f6911fd47d9ca42296664f4d7	primacy of immediate reward underlying violation - basic study on safety management	violation;time discount;irrationality;pursuit of immediate profit;primacy of immediate reward;loss aversion	We generally tend to discount the satisfaction induced by the consumption in the future relative to the satisfaction at present. We feel more attractive to the immediate reward even if it is not a great amount of money. This is called primacy of immediate reward. Therefore, it is possible that this property forces us to put immediate profits or rewards before those in the future especially when the incentive to immediate awards or profits is stronger. It is speculated that such a property leads to cognitive biases to commit violation, and at the worst case causes a crucial accident such as the critical mass accident at the uranium processing plant of JCO Tokai Works Test Facility. As the basis for the prevention of violation-based human error, the primacy of immediate reward was explored in detail and an attempt was made to identify the condition under which the primacy of immediate reward is dominant. The primacy of immediate reward did not always arise, and it readily occurred under the following situation: 1 very uncertain situation under which a promise is not necessarily observed, and 2 situation under which one feels much starved and need money to eat something with. It was found that the urged to gain an immediate reward readily led to time discount.	primacy of mind	Atsuo Murata;Yukio Ohta;Makoto Moriwaka	2015		10.1007/978-3-319-20373-7_23		ECom	-6.518317347906128	-7.432725473593984	48751
352211377cedcb2ff055f25db06f9b6fb84e9f0b	evolutionary games for multiple accessl control: from egoism to altruism		This paper studies multiple access games with a large population of mobiles decomposed into several groups. Mobiles interfere with each others through many local interactions. We assume that each mobile (or player) cooperates with his group by taking into account the performance of his group. The degree of cooperation not only covers the fully non-cooperative behavior and the fully cooperative behavior, but also the fully altruistic behavior. To do so, we make use of the evolutionary game theory which we extend to cover this kind of behavior. We define and characterize the equilibrium (called Evolutionary Stable Strategy) for these games and establish the optimal level of cooperation that maximizes the probability of successful transmission. We also study the game dynamics both in its classical form and in the presence of delay. Interestingly, we show that, in order to maximize the system performance, the mobiles should be less cooperative.	access control;game theory;interaction;sql;transmission (bittorrent client)	Houssem Gaiech;Rachid El Azouzi;Majed Haddad;Eitan Altman;Issam Mabrouki	2014	2014 7th International Conference on NETwork Games, COntrol and OPtimization (NetGCoop)		altruism;ethical egoism;mathematical economics;evolutionary game theory;social psychology;evolutionarily stable strategy;replicator equation;population;economics	Robotics	-6.237264072621532	-3.208570077887346	48771
b39771470b0e38bd6c636458aed03ebf2706d2dd	verifying knowledge bases by anomaly detection: an experience report	anomaly detection;experience report;knowledge base		anomaly detection	Alun D. Preece;Rajjan Shinghal	1992			knowledge base;anomaly detection;computer science;artificial intelligence;data mining	AI	-31.981661603500903	-6.075298929536723	48773
1da8077b9cc5b673b6f099a7a83847189ec1a235	interpretive reasoning with hypothetical cases	decision maker	Reasoning with hypothetical cases helps decision-makers evaluate alternate hypotheses for deciding a case. The hypotheticals demonstrate the sensitivity of a hypothesis to apparently small factual differences that may require different results because they shift the tradeoffs among conflicting underlying principles. By anticipating variations, the decision-maker seeks to formulate as general and robust a hypothesis as possible. This paper presents a model of the role of hypothetical cases in assessing legal hypotheses and illustrates it with examples drawn from a Supreme Court oral argument. It describes the LARGO program, an intelligent tutoring system to help law students learn the model by graphically representing complex argument examples. LARGO analyzes students’ graphs and provides feedback to encourage them to reflect on the examples in light of the model. 1	argument (complex analysis);case-based reasoning;graph (discrete mathematics)	Kevin D. Ashley	2007			artificial intelligence;machine learning;natural language processing;supreme court;hypotheticals;computer science;intelligent tutoring system;graph	AI	-13.798757475647363	0.7442141016689052	48780
863bf64514e766bb7f1677e97edfdbd3985f8c7b	error and attack tolerance of collective problem solving: the darpa shredder challenge	complexity;computer appl in social and behavioral sciences;collective intelligence;error and attack tolerance;crowdsourcing;socio and econophysics population and evolutionary models	The Internet has unleashed the capacity for planetary-scale collective problem solving (also known as crowdsourcing), with ever increasing successful examples. A key hypothesis behind crowdsourcing is that, at a critical mass of participation, it has the capacity not only to agglomerate and coordinate individual contributions from thousands of individuals, but also to filter out erroneous contributions, and even malicious behavior. Mixed evidence on this front has arisen from limited observational data and controlled laboratory experiments with problems of moderate difficulty. We analyze behavioral data from our participation in the DARPA Shredder Challenge, an NP-hard combinatorial puzzle beyond computational reach, which involved 3,500 participants from five continents over three consecutive weeks. We study thousands of erroneous contributions and a number of large-scale attacks, and quantify the extent to which the crowd was able to detect, react, and recover from them. Whereas the crowd is able to self-organize to recover from errors, we observe that participants are (i) unable to contain malicious behavior (attacks) and (ii) the attacks displayed persistence over the subsequent participants, manifested in decreased participation and reduced problem solving efficiency. Our results raise caution in the application of crowdsourced problem solving for sensitive tasks involving Financial Markets and National Security.	attack tolerance;computation;crowdsourcing;darpa shredder challenge 2011;experiment;persistence (computer science);planetary scanner;problem solving;self-organization;the sims	Nicolas Stefanovitch;Aamena Alshamsi;Manuel Cebrián;Iyad Rahwan	2014	EPJ Data Science	10.1140/epjds/s13688-014-0013-1	complexity;simulation;computer science;artificial intelligence;collective intelligence;crowdsourcing;algorithm	ML	-14.651899785060436	-13.191632734872968	48847
3fcaae51508341ffc918ed4d41cd93d5b704521f	the impact of network structure on the perturbation dynamics of a multi-agent economic model	complex adaptive system;system response;key system metrics;system dynamic;agent-based cas model;perturbation dynamic;multi-agent economic model;simple component structure;simple structure;local network structure;complex network	Complex adaptive systems (CAS) modeling has become a common tool to study the behavioral dynamics of agents in a broad range of disciplines from ecology to economics. Many modelers have studied structure’s importance for a system in equilibrium, while others study the effects of perturbations on system dynamics. There is a notable absence of work on the effects of agent interaction pathways on perturbation dynamics. We present an agent-based CAS model of a competitive economic environment. We use this model to study the perturbation dynamics of simple structures by introducing a series of disruptive events and observing key system metrics. Then, we generate more complex networks by combining the simple component structures and analyze the resulting dynamics. We find the local network structure of a perturbed node to be a valuable indicator of the system response.	agent-based model;complex adaptive system;complex network;ecology;key;peripheral;perturbation theory;system dynamics;usb hub	Marshall A. Kuypers;Walter E. Beyeler;Robert J. Glass;Matthew Antognoli;Michael D. Mitchell	2012		10.1007/978-3-642-29047-3_40	social dynamics;simulation;computer science;artificial intelligence;operations research	ECom	-19.176978846447387	-16.622868048160857	48876
7b34cc1f8c8a9fafdffab018e01cfe58033217d0	extending the bdi architecture with commitments	normative multi agent systems;bdi agents;logics for agents;profitability;agent architecture	In this paper, we describe a novel agent architecture for normative multiagent systems which is based on multi-context systems. It models the three modalities of Rao and Georgeff’s BDI agents as individual contexts and adds a fourth one for commitments. This new component is connected to all other mental attitudes via two sets of bridge rules, injecting formulae into it and modifying the BDI components after reasoning about commitments. As with other normative approaches the need for methods to deal with consistency is a key concern. We suggest three forms of dealing with the truth maintenance problem, all of which profit from the use of multi-context systems.	agent architecture;agent-based model;multi-agent system;reason maintenance	Dorian Gaertner;Pablo Noriega;Carles Sierra	2006			engineering;knowledge management;artificial intelligence;social psychology	AI	-21.519304173247587	-10.714478961579895	48894
45c068fed35e6c7c1836cdf5af51c8db478bf274	truncation strategies in two-sided matching markets: theory and experiment	truncation strategies;experiments;two sided matching	We investigate strategic behavior in a centralized matching clearinghouse based on the GaleShapley deferred acceptance algorithm. To do so, we conduct a laboratory experiment to test whether agents strategically misrepresent their preferences by submitting a “truncation” of their true preferences. Our experimental design uses a restricted environment in which subjects always have a best-response in truncation strategies. We find that subjects do not truncate their preferences more often when truncation is profitable. They do, however, truncate less often when truncation is dangerous that is, when there is a risk of “over-truncating” and remaining unmatched. Our findings suggest that eliminating profitable opportunities for strategic behavior may not be sufficient to induce participants to report their true preferences. JEL codes: C78, C92, D47	algorithm;centralized computing;code;design of experiments;truncation	Marco E. Castillo;Ahrash Dianat	2016	Games and Economic Behavior	10.1016/j.geb.2016.06.006	econometrics;mathematics;welfare economics;statistics	AI	-5.075901129325368	-5.352664052780852	48905
ff110bd910029841be5d8c4015c46aa5597dd314	cartographic circuits inside gis environment for the construction of the landscape sensitivity map in the case of cremona	spatial statistical models;geostatistics and spatial simulation;spatial data analysis;data mining;spatial data mining;urban modeling	The centrality of the landscape, inside territorial planning, has been influencing, for years, the testing of innovative analytical techniques aimed to gather the peculiarities of urban and suburban context. The experience upon construction of landscape sensitivity maps, written for the Cremona's Urban Variant, brings out the wide variety of cartographic outputs resulting from the large amount of investigations conducted on the various aspects of the local landscape. The fundamental operations of preliminary information recognition are mainly aimed to obtain the specific territorial units of inquiry, the next step concerns the development of detailed evaluation using multidimensional analysis applications, which allow to lead to the different portions of the Cremona area, specific landscape sensitivity classes, by combining synthetic indicators: i) insularisation of non-built spaces ii) morphological / structural values iii) perceptual aspects of the landscape; iv) permanence of the urban system; v) the degree of imperativeness of the environmental constraints; vi) the integrity of land use.	geographic information system	Pier Luigi Paolillo;Umberto Baresi;Roberto Bisceglie	2012		10.1007/978-3-642-31075-1_25	computer science;spatial analysis	EDA	-12.91628945967662	-23.90905455929043	48908
0825568fe350fae101213f5428387db910eb0ea1	efficient point-based pattern search in 3d motion capture databases		3D motion capture data is a specific type of data arising in the Internet of Things. It is widely used in science and industry for recording the movements of humans, animals, or objects over time. In order to facilitate efficient spatio-temporal access into large 3D motion capture databases collected via internet-of-things technology, we propose an efficient 2-Phase Point-based Trajectory Search Algorithm (2PPTSA) which is built on top of a compact in-memory spatial access method. The 2PPTSA is fundamental to any type of pattern-based investigation and enables fast and scalable point-based pattern search in 3D motion capture databases. Our empirical evaluation shows that the 2PPTSA is able to retrieve the most similar trajectories for a given point-based query pattern in a few milliseconds with a comparatively low number of I/O accesses.	humans;in-memory database;input/output;internet of things;motion capture;nosql;pattern search (optimization);sql;scalability;search algorithm;spatial database	Christian Beecks;Alexander Grass	2018	2018 IEEE 6th International Conference on Future Internet of Things and Cloud (FiCloud)	10.1109/FiCloud.2018.00041	access method;pattern search;database;scalability;search algorithm;motion capture;trajectory;internet of things;computer science	DB	-27.84159747369733	-0.015236413289499012	48993
da0b66b39d43bfb78fe07f7cce7e915ddbc037e0	utilizing a cellular automaton model to explore the influence of coastal flood adaptation strategies on helsinki's urbanization patterns		A cellular automaton model (SLEUTH-3r) is utilized to explore the impacts of coastal flood risk management strategies on the urbanization parameters of Helsinki's metropolitan area, at a 50-m spatial resolution by 2040. The current urbanization trend is characterized by the consolidation of existing built-up land and loss of interspersed green spaces, whereas the most intense growth is forecast inside the coastal flood risk areas. This baseline is compared to strategies that test various responses of the planning system to real estate market forces and the spatial distribution of flood risks. A set of scenarios translates property price effects of flood risk information into various attraction-repulsion areas in and adjacent to the floodplain, while a second set explores varying degrees of restricting new growth in the flood risk zones without reference to the housing market.#R##N##R##N#The simulations indicate that growth under all scenarios is distributed in a more fragmented manner relative to the baseline, which can be interpreted favorably regarding house prices and increased access to ecosystem services, although the indirect effects should also be considered. Demand for coastal flood-safe properties does not appear to automatically translate to refocusing of development toward those areas, unless planning interventions encourage this redistribution. The character of the planning system with respect to market drivers and the spatial distribution of risks and amenities is thus important. A mixture of market-based measures and moderate zoning interventions may be preferable for flood risk management and provide the necessary precision for adaptation strategies.	cellular automaton	Athanasios Votsis	2017	Computers, Environment and Urban Systems	10.1016/j.compenvurbsys.2017.04.005	environmental engineering;geography;civil engineering;ecology;cartography	HCI	-13.578598515435237	-21.517544450519615	49072
a6568fbf0ad2f99e5f17e2d2ccfc06f7a05b1764	simulating human behavior in not-yet built environments by means of event-based narratives	event based model;human behavior simulation;virtual users;building design evaluation	Current Computer-Aided Architectural Design (CAAD) systems fail to represent buildings in-use before their realization. This failure prevents testing the extent to which a proposed setting supports the activities of its intended users. We present a novel approach to human behavior simulation based on a thorough representation of end-user activities by means of  events  -- computational constructs that simulate users' individual and group activities to achieve a specific goal. Human behavior narratives result from a combination of  top-down  (planned) and  bottom-up  (unplanned) sequences of events, as a reaction to time-based schedules and to social and environmental stimuli, respectively. A narrative management system orchestrates the narrative developments and resolves conflicts that may arise among competing events.		Davide Schaumann;Yehuda E. Kalay;Seung Wan Hong;Davide Simeone	2015			simulation;engineering;communication;social psychology	Robotics	-23.094385190179384	-16.08971751229071	49079
bd84bc22fb06ce730adeac973d8ab36be70da5c2	efficient formalization of railway interlocking data in railml	railml database;railway interlocking;knowledge based railway systems;uml class diagram;simplification of railway engineering processes	Railways wish to reduce the costs of engineering interlocking systems by simplifying the exchange of technical information between stakeholders. Exchanging interlocking data in a machine-readable and standardized format removes inefficiency due to misinterpretation and conversion of data from non-standard, often paper-based formats. This paper proposes an UML class representation of the interlocking data that maps the characteristics of the interlocking system. These data model represents both tabular and geographical interlocking. The model reflects the topology of the railway network that the interlocking controls, routes, relations between signal aspects, speed indication signals, automatic train protection (ATP) and the state of movable and non-movable track elements. The data are machine-readable RailML, an incarnation of XML that is gaining the status of standard in railway modelling. We applied our approach to model the Dutch Santpoort Noord station, starting from paper-based track and signal plans. The resulting database captures all the features of the interlocking, whilst removing data redundancy. The model has general validity and it is easily extendible to other interlocking and ATP systems. Our approach contributes to create standard, electronic interlocking databases, directly from technical documents currently used in the practical world. & 2014 Elsevier Ltd. All rights reserved.	automated theorem proving;data model;data redundancy;database;extensibility;human-readable medium;iteration;map;money;table (information);unified modeling language;waste;while;xml	Mark Bosschaart;Egidio Quaglietta;Bob Janssen;Rob M. P. Goverde	2015	Inf. Syst.	10.1016/j.is.2014.11.007	simulation;computer science;artificial intelligence;class diagram;data mining;database;computer security;algorithm	DB	-32.98438154176541	-3.3478104862337057	49090
a9a2c7d7a5bee99121f72ba2459b814654b95d8d	cognitive architectures for social human-robot interaction		Social HRI requires robots able to use appropriate, adaptive and contingent behaviours to form and maintain engaging social interactions with people. Cognitive Architectures emphasise a generality of mechanism and application, making them an ideal basis for such technical developments. Following the successful first workshop on Cognitive Architectures for HRI at the 2014 HRI conference, this second edition of the workshop focusses specifically on applications to social interaction. The full-day workshop is centred on participant contributions, and structured around a set of questions to provide a common basis of comparison between different assumptions, approaches, mechanisms, and architectures. These contributions will be used to support extensive and structured discussions, with the aim of facilitating the development and application of cognitive architectures to social HRI systems. By attending, we envisage that participants will gain insight into how the consideration of cognitive architectures complements the development of autonomous social robots.	autonomous robot;cognitive architecture;contingency (philosophy);human–robot interaction;social robot	Paul Baxter;Séverin Lemaignan;J. Gregory Trafton	2016	2016 11th ACM/IEEE International Conference on Human-Robot Interaction (HRI)		human–robot interaction;simulation;cognition;computer science;artificial intelligence;robot kinematics;cognitive robotics	HCI	-23.509097494967428	-15.649370484004548	49144
532eec1cb353f6f1bee15d06271503965b92d5a4	perceived motives and reciprocity		In reciprocal interactions, both genuine kindness and self-interested material gain may motivate socially beneficial actions. The paper presents results from two experiments that distinguish the role of perceived motives in reciprocal decision making from the role of outcomes or perceived intentions. The results indicate that positive reciprocity triggered by the same beneficial action is lower when the first-mover is more likely to be motivated by strategic incentives. Therefore, stronger incentives for beneficial behavior may not increase total welfare.		A. Yesim Orhun	2018	Games and Economic Behavior	10.1016/j.geb.2018.01.002	reciprocity (social psychology);economics;kindness;incentive;social psychology;social preferences;reciprocal;economic surplus	ECom	-5.863840220431875	-6.745326736233259	49157
2e3c6e8e8a60c7263b2f9b4a000d6fce21d2c950	reinforcement learning for adaptive dialogue systems - a data-driven methodology for dialogue management and natural language generation	system development;multimodal dialogue system;reinforcement learning;dialogue system;dialogue management;data-driven method;new methodology;data-driven approach;adaptive dialogue systems;wizard-of-oz data collection;data-driven methodology;computer science;machine learning;natural language generation	The past decade has seen a revolution in the field of spoken dialogue systems. As in other areas of Computer Science and Artificial Intelligence, data-driven methods are now being used to drive new methodologies for system development and evaluation. Features 7 A new methodology for developing spoken dialogue systems is described in detail 7 A research guide for students and researchers 7 This work provides insights, lessons, and inspiration for future research	artificial intelligence;computer science;dialog system;natural language generation;reinforcement learning	Verena Rieser;Oliver Lemon	2011		10.1007/978-3-642-24942-6	natural language processing;computer science;artificial intelligence;communication	NLP	-30.634323538874234	-21.856980070487992	49208
60adf00f8bb77e41c7f20809550581869fb40e29	an agent-based approach to modeling yard cranes at seaport container terminals	agent based;articulo;agent based model;an agent based approach to modeling yard cranes at seaport container terminals;utility function;agent based modeling;utility maximization;environmental concern;yard cranes;container terminal;waiting time;decision making process;seaport container terminals;truck turn time	Due to environmental concerns, terminal operators at seaport container terminals are increasingly looking to reduce the time a truck spends at the terminal to complete a transaction. For terminals that stack their containers, the solution may seem obvious: add more yard cranes to reduce trucks' wait time in the yard. However, the high cost of these cranes often prohibits terminal operators from freely buying more. Another reason is because there is no clear understanding of how the yard cranes' availability and service strategy affect truck turn time. This study introduces an agent-based approach to model yard cranes for the analysis of truck turn time with respect to service strategy. It is accomplished by modeling the cranes as utility-maximizing agents. This study has identified a set of utility functions that properly capture the essential decision making process of crane operators in choosing the next truck to provide service to. The agent-based model is implemented using NetLogo, a cross-platform multi-agent programmable modeling environment. Simulation results show that the distance-based service strategy produces the best results in terms of average waiting time and the maximum waiting time of any truck.	agent-based model;multi-agent system;netlogo;simulation	Nathan Huynh;José M. Vidal	2010		10.1145/1878537.1878663	decision-making;engineering;automotive engineering;transport engineering	AI	-9.233334869580496	-10.429999587137265	49246
b4092dd52ebdb1fc7ece0dcb0bc4a02ed740f49e	a multiagent simulation for traffic flow management with evolutionary optimization	multiagent system;traffic flow;self organizing system;traffic flow management;evolutionary optimization;multiagent simulation;industrial agglomeration	A traffic flow is one of the main transportation issues in nowadays industrialized agglomerations. Configuration of traffic lights is among the key aspects in traffic flow management. This paper proposes an evolutionary optimization tool that utilizes multiagent simulator in order to obtain accurate model. Even though more detailed studies are still necessary, a preliminary research gives an expectation for promising results. 1 Traffic flow management Early models of traffic flow (called macroscope models) treated vehicles in the collective manner basing on the analogy to particles in a fluid [7]. Later on, more precise (mezoscope) models were being created consecutively (mostly based on gas kinetics) [5]. Currently, a multiagent simulation mechanism provides much more efficient microscope model where each vehicle can be regarded separately allowing for highly detailed analysis including collision avoidance [4], traffic virtualization [2], interactions with pedestrians [3], etc. Traffic flow management varies from tracing main roads average capacity across certain area (where macroscope models give satisfactory results) to very low-level manipulations including re-arrangement of lanes, modifying traffic lights configuration, planning bridge locations, etc. where microscope models are most suitable [9]. 2 Multiagent traffic flow simulator The agent-based traffic flow simulator described in [9] is the universal microscope model. The environment for agents in this model comprises of a system of city streets defined in XML files using the following entities illustrated in Figure 1:	agent-based model;entity;evolutionary algorithm;high- and low-level;interaction;kinetics internet protocol;macroscope;mathematical optimization;simulation;x86 virtualization;xml	Patryk Filipiak	2011	CoRR		simulation;traffic flow;advanced traffic management system	Metrics	-17.49166406294172	-20.666727320293113	49515
6e264929dd032d16a3da724f345b6b0b92d716ee	towards dialogue based shared control of navigating robots	agent based;control system;user cooperation;natural language understanding;space use;natural language;cognitive control;service robot;spatial model;spatial information	Establishing a clean relationship between a robot’s spatial model and natural language components is a non-trivial task, but is key to designing verbally controlled, navigating service robots. In this paper we examine the issues involved in the development of dialogue controlled navigating robots. In particular, we treat our robots as so-called Shared Control Systems, where robot and user cooperate to achieve a shared goal. We begin by characterising four categories of Shared Control Problems that affect verbally controlled navigating robots. Producing solutions to these problems requires a clear methodology in the linking of ’common-sense’ representations of space used by the robots, and the language interface. To this end, we present the SharC Cognitive Control Architecture as a general purpose, agent-based dialogue control system that provides a suitable framework for relating spatial information to natural language communication. To illustrate the approach, we focus in particular on our approach to natural language understanding, and show how natural language utterances may be mapped to formally modelled spatial concepts, thus helping to overcome problems in shared control.	agent-based model;application domain;autonomous robot;control system;enterprise architecture framework;formal ontology;language technology;natural language understanding;online and offline;reasoning system;semiconductor industry;super harvard architecture single-chip computer	Robert J. Ross;Hui Shi;Tillman Vierhuff;Bernd Krieg-Brückner;John A. Bateman	2004		10.1007/978-3-540-32255-9_26	simulation;computer science;artificial intelligence;communication	Robotics	-26.308911052115434	-18.538334729062623	49551
4759c72ac60bcfa0f5bbef385d1b98930e028628	safety and security issues in electric power industry	electric power industry;analyse risque;seguridad funcionamiento;surete fonctionnement;securite;risk analysis;sistema informatico;automatisation;computer system;automatizacion;analisis riesgo;industria electrica;dependability;safety;systeme informatique;electric power;seguridad;industrie electrique;automation	The paper presents, the main types of hazards for personnel, equipment and electric power systems which should be taken into consideration in the design of computer-based systems applied in electric power industry, as well as threats to the systems from security point of view. Additionally, examples of problems are described which appeared in carrying out, for the first time in Polish electric power sector, the safety analysis of a extra-high voltage substation software interlockings. The problems were mainly connected with the lack of standards or guidelines on the design of computer-based systems applied in power substations and the lack of exact data on failures of substation components, breakdowns and accidents at substations and large failures of the national electric power system. The data which are used for the traditional relay-based control systems design are insufficient. In conclusion some suggestions are given to improve the situation.		Zdzislaw Zurakowski	2000		10.1007/3-540-40891-6_14	reliability engineering;electric power;risk analysis;engineering;electric power industry;automation;dependability;computer security	Crypto	-11.015281936070096	-14.974022046120552	49557
2c4385550aa286a92e8dda62048f10a20a65e30a	subgame-perfect ϵ-equilibria in perfect information games with common preferences at the limit	subgame perfect equilibrium;perfect information games	We prove the existence of a pure subgame–perfect epsilon–equilibrium, for every epsilon > 0, in multiplayer perfect information games, provided that the payoff functions are bounded and exhibit common preferences at the limit. If, in addition, the payoff functions have finite range, then there exists a pure subgame–perfect 0–equilibrium. These results extend and unify recent existence theorems for bounded and semicontinuous payoffs.		János Flesch;Arkadi Predtetchinski	2016	Math. Oper. Res.	10.1287/moor.2015.0774	markov perfect equilibrium;mathematical optimization;perfect information;mathematics;mathematical economics;subgame perfect equilibrium	ECom	-6.105676142120773	-1.056924595622549	49566
5bf9ba8594f67340452066a9f5841714855ee87e	continuity issues of the implicational interpretation of fuzzy rules	continuity;implicational interpretation;fuzzy rules;rule based;real world application;linguistic description;conjunctive normal form	The implicational interpretation of fuzzy rules has received little attention in real-world applications so far. This is largely due to the fact that ensuring continuity of the resulting function is not a straightforward task. This paper targets this subject. Departing from consistent linguistic descriptions/rule bases, we introduce sufficient conditions for the continuity of the implicational interpretation with mean of maximum defuzzification. We demonstrate that continuity can be achieved under practically feasible conditions, regardless of the dimensionality of the input.	fuzzy rule;scott continuity	Martin Stepnicka;Ulrich Bodenhofer;Martina Danková;Vilém Novák	2010	Fuzzy Sets and Systems	10.1016/j.fss.2010.03.009	rule-based system;conjunctive normal form;discrete mathematics;computer science;artificial intelligence;mathematics;linguistic description;algorithm	Logic	-18.106400254449802	1.2821127050061625	49646
24f01c5b8939c9c6885e88cf9b085a0b311cad4f	methodology for evaluation of linked multidimensional measurement system with balanced scorecard	structural model;measurement system;balanced scorecard;choquet integral;fuzzy inference;business performance	  Balanced Scorecard was articulated as a comprehensive framework for evaluating a company’s business performance. Some of authors  have proposed a multidimensional measurement system with BSC in which a structural modeling of four perspectives is constructed  in the 1st stage, and the evaluation process in each perspective is performed in the 2nd stage, then the integrated value  is calculated in the following stage. In that system, FSM based structural modeling method is applied for calculating the  weight of measures in each perspective, then fuzzy inference mechanism and Choquet integrals are applied to have integrated  values. In this paper, we propose a new methodology for evaluating the strategy oriented business performance of a company  by means of linked structure of measurements in BSC framework. Fuzzy inference mechanism and FSM based structural modeling  method also play an important role. We give a scheme of our system and show how it works by an illustrative example.    	system of measurement	Yutaka Kigawa;Kiyoshi Nagata;Fuyume Sai;Michio Amagasa	2010		10.1007/978-3-642-14058-7_76	system of measurement;balanced scorecard;choquet integral	Metrics	-6.409417351813728	-17.42245510243439	49687
31949b5a7d37576e3757e4920082a455fa77ac0b	autonomous units as a rule based concept for the modeling of autonomous and cooperating process			autonomous robot	Karsten Hölscher	2008				AI	-30.287419247520702	-18.476066564783004	49723
211942e4a967697c9b3959880d3d73b2641dcb7a	belief modelling for situation awareness in human-robot interaction	belief networks;pragmatics;cognitive systems;speech based user interfaces belief networks cognitive systems formal logic human robot interaction markov processes mobile robots multi agent systems;spatio temporal framing;mobile robot;top down;markov logic;markov random fields;contextual information;mobile robots;human robot interaction;probabilistic graphical model;speech based user interfaces;cognitive architecture;spoken dialogue belief modelling situation awareness human robot interaction belief model markov logic first order logic probabilistic graphical model low level sensory data spatio temporal framing multi agent epistemic status cognitive architecture mobile robots;expressive power;multi agent systems;smoothing methods;belief modelling;spoken dialogue;probability distribution;robots;markov random fields robots probability distribution probabilistic logic pragmatics smoothing methods;formal logic;situation awareness;belief model;markov processes;probabilistic logic;multi agent epistemic status;low level sensory data;first order logic	To interact naturally with humans, robots need to be aware of their own surroundings. This awareness is usually encoded in some implicit or explicit representation of the situated context. In this paper, we present a new framework for constructing rich belief models of the robot's environment. Key to our approach is the use of Markov Logic as a unified framework for inference over these beliefs. Markov Logic is a combination of first-order logic and probabilistic graphical models. Its expressive power allows us to capture both the rich relational structure of the environment and the uncertainty arising from the noise and incompleteness of low-level sensory data. The constructed belief models evolve dynamically over time and incorporate various contextual information such as spatio-temporal framing, multi-agent epistemic status, and saliency measures. Beliefs can also be referenced and extended “top-down” via linguistic communication. The approach is being integrated into a cognitive architecture for mobile robots interacting with humans using spoken dialogue.	cognitive architecture;experiment;expressive power (computer science);file binder;first-order logic;first-order predicate;framing (world wide web);graphical model;high- and low-level;human–robot interaction;machine learning;markov chain;markov logic network;mobile robot;multi-agent system;scalability;semantics (computer science);situated;statistical relational learning;top-down and bottom-up design;unified framework	Pierre Lison;Carsten Ehrler;Geert-Jan M. Kruijff	2010	19th International Symposium in Robot and Human Interactive Communication	10.1109/ROMAN.2010.5598723	human–robot interaction;mobile robot;computer science;artificial intelligence;machine learning;pragmatics	AI	-18.846740594258346	-2.9940459799017285	49735
69c4756f848d07d807a4812d7a59a32a85f72d14	the well-designed young mathematician	virtual machine;philosophy of mathematics;human vision;mathematics;development;spatial reasoning;young children;kant;geometry;natural extension;empirical vs necessary;altricial vs precocial species and competences;biological evolution;functional analysis;self monitoring;forms of representation;architectures;hume;nature nurture tradeoffs;evolution	This paper complements McCarthy’s “The well designed child”, in part by putting it in a broader context, the space of possible well designed progeny, and in part by relating design features to development of mathematical competence. I first moved into AI in an attempt to understand myself, especially hoping to understand how I could do mathematics. Over the ensuing four decades, my interactions with AI and other disciplines led to: design-based, cross-disciplinary investigations of requirements, especially those arising from interactions with a complex environment; a draft partial ontology for describing spaces of possible architectures, especially virtual machine architectures, for behaving systems (including our precursors); investigations of varied forms of representation and how they are suited to different functions; analysis of biological nature/nurture tradeoffs and their relevance to future machines; studies of control issues in a complex architecture; and showing how the states and processes possible in such an architecture relate to our (simplified) intuitive concepts of motivation, feeling, preferences, emotions, attitudes, values, moods, consciousness, etc. In 1971 I thought working models of human vision could lead to models of visual/spatial reasoning that would help to support Kant’s view of mathematics, against Hume’s. This has not yet happened, but I am still exploring requirements for such models, partly motivated by the hypothesis that human mathematical abilities are a natural extension of abilities produced by biological evolution that are not yet properly understood, and have barely been noticed by psychologists and neuroscientists. Some aspects of our ability to interact with complex 3-D structures and processes extend Gibson’s ideas concerning action affordances, to include proto-affordances, epistemic affordances and deliberative affordances. Some of what a child learns about structures and processes starts as empirical then as a result of reflective processes can be transformed to the status of necessary (e.g. mathematical) truths. These processes normally develop unnoticed in young children, but provide the basis for much creativity in behaviour, as well as leading, in some, to development of an interest in mathematics. We still need to understand what sort of (possibly self-extending) architecture, and what forms of representation, are required to make this possible. This paper does not presuppose that all mathematical learners can do logic, though some fairly general form of reasoning seems to be required.	action potential;evolution;hume (programming language);interaction;progeny linux systems;relevance;requirement;spatial–temporal reasoning;virtual machine;whole earth 'lectronic link	Aaron Sloman	2008	Artif. Intell.	10.1016/j.artint.2008.09.004	functional analysis;philosophy of mathematics;computer science;virtual machine;artificial intelligence;evolution;mathematics	AI	-25.903816550914062	-13.606179454671405	49747
64c474b79c3d4ebc58d1fa29773ef14f68dd93bc	a similarity indexing method for the data warehousing - bit-wise indexing method	decision support;on line processing;raisonnement base sur cas;razonamiento fundado sobre caso;base donnee;case base reasoning;efficient algorithm;database;base dato;stockage donnee;similitude;indexing method;tratamiento en linea;data storage;indexing;indexation;similarity;indizacion;data warehousing;almacenamiento datos;similitud;traitement en ligne;case based reasoning;data warehouse;similarity index;on line analytical processing	Data warehouse is an information provider that collects necessary data from individual source databases to support the analytical processing of decision-support functions. Recently, research about the indexing technologies of data warehousing has been proposed to help efficient on-line analytical processing (OLAP). In the past decades, some novel indexing technologies of data warehousing were proposed to retrieve the information precisely. However, the concept of similarity indexing technology in the increasingly larger data warehousing was seldom been discussed. In this paper, the performance issue of approximation indexing technology in the data warehousing is discussed and a new similarity indexing method, called bit-wise indexing method, and the corresponding efficient algorithms are proposed for retrieving the similar cases of a case-based reasoning system using a data warehouse to be the storage space. Some experiments are made for comparing the performance with two other methods and the results show the efficiency of the proposed method.		Wei-Chou Chen;Shian-Shyong Tseng;Lu-Ping Chang;Mon-Fong Jiang	2001		10.1007/3-540-45357-1_56	case-based reasoning;similarity;computer science;artificial intelligence;similitude;data warehouse;data mining;database;information retrieval	DB	-26.20094167890828	1.902303693235903	49808
6cfeca659d8e7c06f0f03302081a409cb6212576	rsaw: a situation awareness system for autonomous robots	robot sensing systems;semantics;resource description framework;robot sensing systems semantics resource description framework ontologies predictive models;robustness rsaw autonomous robots robotic system dynamic real world environment operator intervention robot situation awareness system knowledge representation ontology model driven engineering methodology mde methodology smart autonomous majordomo robot sam robot;predictive models;ontologies;software engineering control engineering computing mobile robots ontologies artificial intelligence robot dynamics robust control	Services and technologies are in evolution in order to develop a new generation of robotic systems that might operate in dynamic real-world environments. In this paper, we focus on the ability of robot to understand and to surpass the blocked situations autonomously without operator intervention. Such situations may occur when the robot cannot succeed the current action and cannot move to the next one. We remark that in the literature, the operator has a crucial role consisting in providing all information about the environment and in making interpretations. In this paper, we propose an RSAW (Robot Situation AWareness) system, developed in order to help a robot to surpass a blocked situation and accomplish its goal whilst minimizing the operator intervention. RSAW is a new general system aiming to increase the autonomy of the robot; It is inspired by the notion of Situation Awareness (SA). In fact, RSAW defines a knowledge representation using ontologies and a process in order to surpass a blocked situation. RSAW is designed according to the Model Driven Engineering (MDE) methodology. This choice is done to preserve the generality of our system. This paper focalizes on the process of the RSAW system and the interaction between the process and the knowledge representation. The experimentations conducted in real environment with the Smart Autonomous Majordomo (SAM) robot, have shown the robustness and the efficiency of the proposed system.	autonomous robot;knowledge representation and reasoning;majordomo;model-driven engineering;ontology (information science);while	Mohamed Walid Ben Ghezala;Amel Bouzeghoub;Christophe Leroux	2014	2014 13th International Conference on Control Automation Robotics & Vision (ICARCV)	10.1109/ICARCV.2014.7064347	computer vision;simulation;computer science;engineering;knowledge management;ontology;artificial intelligence;social robot;rdf;semantics;predictive modelling	Robotics	-33.21320166008815	-13.059715780794527	49880
ad86692a765813dff4d48ae910ddb657b30e267e	efficient sentinel mining using bitmaps on modern processors	databases;art;time measurement;sentinel mining sentbit algorithm scales multicore architectures cpu specific instructions indication streams bitmapped encoding bitmap operations website traffic customer problems multidimensional data cube schema level relationships sentinel discovery bitmap based approach;data mining;pattern mining;cube based data mining;bidirectional control;web sites;data mining time measurement bidirectional control art encoding organizations databases;predictive data mining;multiprocessing systems;cube based data mining data mining time measurement bidirectional control art encoding organizations databases sentinels pattern mining predictive data mining;organizations;encoding;web sites data mining encoding multiprocessing systems;sentinels	This paper proposes a highly efficient bitmap-based approach for discovery of so-called sentinels. Sentinels represent schema level relationships between changes over time in certain measures in a multidimensional data cube. Sentinels are actionable and notify users based on previous observations, for example, that revenue might drop within two months if an increase in customer problems combined with a decrease in website traffic is observed. We significantly extend prior art by representing the sentinel mining problem by bitmap operations, using bitmapped encoding of so-called indication streams. We present a very efficient algorithm, SentBit, that is 2-3 orders of magnitude faster than the state of the art, and utilizes CPU specific instructions and the multicore architectures available on modern processors. The SentBit algorithm scales efficiently to very large data sets, which is verified by extensive experiments on both real and synthetic data.	algorithm;approximation;association rule learning;bitmap;central processing unit;data cube;data mining;experiment;graphics processing unit;image scaling;multi-core processor;sequential pattern mining;synthetic data;the sentinel;web traffic	Morten Middelfart;Torben Bach Pedersen;Jan Krogsgaard	2013	IEEE Transactions on Knowledge and Data Engineering	10.1109/TKDE.2012.198	computer science;organization;data science;data mining;database;world wide web;encoding;time	DB	-28.35259847581673	-1.8878885569813213	49919
8dc4f2ae7a79cdbfa9eb68bffbc697442c9a40f4	the complex product design modeling based on spatial sequence colored petri-nets	behavior flow;petri nets;semantic networks;spatial sequence	Functional modeling is the mainly option in current conceptual design, which relies on the designers’ subjective experience and lacks of intelligence. We choose behavior flow modeling which is more intelligent for conceptual design and express the behavior flow by establish the semantic network and Petri nets in this paper. At the end, we illustrate the expression of spatial sequence in behavior flow by the instance of auto engine design.	cognitive science;computer simulation;petri net;semantic network;systems science	Yongtao Hao;Peng Dai;Diming Liu	2013	JSW		simulation;computer science;artificial intelligence;machine learning;database;semantic network;petri net	AI	-25.584342883485036	-9.757082218153283	49958
42b9481c0157e2e78d4dc901a0c69467b86e442c	cleaning uncertain streams by parallelized probabilistic graphical models	video surveillance;data processing;probabilistic graphical model;real world application;parallel systems;data cleaning;object identification	Real-world applications generate uncertain streams due to unreliable equipments and/or data processing such as object identification. However, application context implies specific rules, which are critical in cleaning data and make them closer to the reality. In this paper, we propose a framework for cleaning uncertain streams by Parallelized Probabilistic Graphical Models (P2GM). Making full use of multi-core processing architecture, the system processes parallelized high-volume streams efficiently. With P2GM, users can define their own cleaning algorithms and generate specific parallelized systems. We implement a prototype of video surveillance based on P2GM, and demonstrate the quality and performance of our approaches experimentally.	graphical model;parallel computing;plasma cleaning	Qian Zhang;Shan Wang;Biao Qin	2010		10.1007/978-3-642-14246-8_28	data processing;computer science;probabilistic database;theoretical computer science;data mining;database;data cleansing	ML	-23.854050430178827	3.040250014295515	50004
0598d2977a185f76eb9ac5a8edc66c27fe459288	social consensus and tipping points with opinion inertia	tipping points;influencing;social networks;opinion dynamics;opinion inertia	When opinions, behaviors or ideas diffuse within a population, some are invariably stickier than others. The stickier the opinion, behavior or idea, the greater is an individual’s inertia to replace it with an alternative. Here we study the effect of stickiness of opinions in a two-opinion model, where individuals change their opinion only after a certain number of consecutive encounters with the alternative opinion. Assuming that one opinion has a fixed stickiness, we investigate how the critical size of the competing opinion required to tip over the entire population varies as a function of the competing opinion’s stickiness. We analyze this scenario for the case of a completegraph topology through simulations, and through a semi-analytical approach which yields an upper bound for the critical minority size. We present analogous simulation results for the case of the Erdős-Rényi random network. Finally, we investigate the coarsening properties of sticky opinion spreading on two-dimensional lattices, and show that the presence of stickiness gives rise to an effective surface tension that causes the coarsening behavior to become curvature-driven. ar X iv :1 41 1. 17 23 v1 [ ph ys ic s. so cph ] 6 N ov 2 01 4 Social consensus and tipping points with opinion inertia 2	erdős number;erdős–rényi model;random graph;semiconductor industry;simulation;sticky bit	Casey Doyle;Sameet Sreenivasan;Boleslaw K. Szymanski;Gyorgy Korniss	2014	CoRR	10.1016/j.physa.2015.09.081	social network	Theory	-13.732066462557052	-16.528773975920746	50013
e1c9aa302d1a746220f031ced450bddce61e6e50	using emotions for the development of human-agent societies	multi agent systems virtual environments emotional agents;j a rincon j bajo a fernandez v julian c carrascosa using emotions for the development of human agent societies	Human-agent societies refer to applications where virtual agents and humans coexist and interact transparently into a fully integrated environment. One of the most important aspects in this kind of applications is including emotional states of the agents (humans or not) in the decision-making process. In this sense, this paper presents the applicability of the JaCalIVE (Jason Cartago implemented intelligent virtual environment) framework for developing this kind of society. Specifically, the paper presents an ambient intelligence application where humans are immersed into a system that extracts and analyzes the emotional state of a human group. A social emotional model is employed to try to maximize the welfare of those humans by playing the most appropriate music in every moment.	aggregate data;ambient intelligence;coexist (image);comparison of command shells;humans;intelligent agent;interaction;jason;multi-agent system;software agent;virtual reality	J. A. Rincon;Javier Bajo;Antonio Fernández-Caballero;Vicente Julián;Carlos Carrascosa	2016	Frontiers of Information Technology & Electronic Engineering	10.1631/FITEE.1500343	computer science;artificial intelligence	AI	-21.520997418269825	-13.697705193013876	50045
159b103b0fd79177c11f402b5f7445b2531bf829	a predictive theory of games	game theory;statistical mechanics;nash equilibrium;noncooperative game theory;bounded rationality;first principle;nash equilibria;satisfiability;self organizing system;statistical physics;quantal response equilibrium;loss function;probability distribution;decision theory;probability theory;optimal prediction;information theoretic;information theory;mixed strategy	Conventional noncooperative game theory hypothesizes that the joint (mixed) strategy of a set of reasoning players in a game will necessarily satisfy an “equilibrium concept”. The number of joint strategies satisfying that equilibrium concept has measure zero, and all other joint strategies are considered impossible. Under this hypothesis the only issue is what equilibrium concept is “correct”. This hypothesis violates the first-principles arguments underlying probability theory. Indeed, probability theory renders moot the controversy over what equilibrium concept is correct — while in general there are joint (mixed) strategies with zero probability, in general the set {strategies with non-zero probability} has measure greater than zero. Rather than a firstprinciples derivation of an equilibrium concept, game theory requires a first-principles derivation of a distribution over joint strategies. However say one wishes to predict a single joint strategy from that distribution. Then decision theory tell us to first specify a loss function, a function which concerns how we, the analyst/scientist external to the game, will use that prediction. We then predict that the game will result in the joint strategy that is Bayes-optimal for that loss function and distribution over joint strategies. Different loss functions — different uses of the prediction — give different such optimal predictions. There is no more role for an “equilibrium concept” that is independent of the distribution and choice of loss function. This application of probability theory to games, not just within games, is called Predictive Game Theory (PGT). This paper shows how information theory provides a first-principles argument for how to set a distribution over joint strategies. The connection of this distribution to the bounded rational Quantal Response Equilibrium (QRE) is elaborated. In particular, taking the QRE to be an approximation to the mode of the distribution, correction terms to the QRE are derived. In addition, some Nash equilibria are not approached by any limiting sequence of increasingly rational QRE joint strategies. However it is shown here that every Nash equilibrium is approached with a limiting sequence of joint strategies all of which have non-zero probability. (In general though not all strategies in those sequences are modes of the associated distributions over joint strategies.) ∗D. Wolpert is with NASA Ames Research Center, Moffett Field, CA, 94035 dhw@ptolemy.arc.nasa.gov	approximation;decision theory;game theory;information theory;loss function;nash equilibrium;quantum;quick response engine;rendering (computer graphics)	David H. Wolpert	2005	CoRR		non-cooperative game;implementation theory;bayesian game;game theory;minimax;positive political theory;mathematical optimization;example of a game without a value;best response;information theory;extensive-form game;statistical mechanics;artificial intelligence;information set;repeated game;mathematics;correlated equilibrium;normal-form game;mathematical economics;algorithmic game theory;outcome;sequential game;equilibrium selection;symmetric game;solution concept;nash equilibrium;statistics	AI	-9.49476647316162	-2.801980878400063	50051
890f48c7b69f45d36156bd27010bb6adfc9f3b57	characterizing and modeling linguistic style in dialogue for intelligent social agents	dialogue;intelligent agents;sarcasm;argument	With increasing interest in the development of intelligent agents capable of learning, proficiently automating tasks, and gaining world knowledge, the importance of integrating the ability to converse naturally with users is more crucial now than ever before. This thesis aims to understand and characterize different aspects of social language to facilitate the development of intelligent agents that are socially aware and able to engage users to a level that was not previously possible with language generation systems. Using various machine learning algorithms and data-driven approaches to model the nuances of social language in dialogue, such as factual and emotional expression, sarcasm and humor and the related subclasses of rhetorical questions and hyperbole, we can come closer to modeling the characteristics of the social language that allows us to express emotion and knowledge, and thereby exhibit these styles in the agents we develop.	algorithm;commonsense knowledge (artificial intelligence);intelligent agent;machine learning;natural language generation	Shereen Oraby	2017		10.1145/3030024.3038284	argument;computer science;artificial intelligence;machine learning;linguistics;intelligent agent	AI	-27.41487286416332	-17.293316176482858	50067
b2fb7626cc8bc6ca2ea1cdfdaa081df098e9de36	goal model analysis of autonomy requirements for unmanned aircraft systems		Designing Unmanned Aircraft Systems (UASs) for optimal autonomy while meeting user requirements is quite challenging. Researchers have focused on improving autonomy algorithms and verification methods to ensure safe and reliable autonomous behavior in UASs, but little research has been conducted on requirements engineering for UASs to answer design questions and explore the trade space for using autonomy to satisfy user requirements. This paper introduces a method to determine an optimal set of autonomous capabilities that satisfies UAS user requirements in the early stages of conceptual design. The method uses a modified Autonomy Requirements Engineering (ARE) process that applies quantitative measures and statistical analysis to Goal-Oriented Requirements Engineering (GORE). We demonstrate this method in a case study of a “disaster robot,” i.e., a hazard response UAS for which the autonomy requirements were optimized using a goal model developed in the Goal-oriented Requirement Language (GRL), as implemented in the modeling tool jUCMNav. The high-level goals of the hazard response UAS—system performance, cost, and safety—were evaluated using the formula-based GRL strategy evaluation algorithm resident in jUCMNav version 6.0. An autonomy trade space study was conducted through a Design and Analysis of Simulation Experiments (DASE). Our designed simulation experiment inserted the number of trials (evaluation strategies) and inputs into the goal model, and evaluation data were analyzed to optimize design factors based on user weightings of the response variables. This paper presents a structured method of ARE for UASs, which could be adopted more broadly across other domains, demonstrating how to optimize autonomous capabilities for different design conditions.	algorithm;autonomous robot;autonomy;experiment;goal-oriented requirements language;high- and low-level;requirement;requirements engineering;simulation;strategic management;unmanned aerial vehicle;user requirements document	Kerry Neace;Robert Roncace;Pavel Fomin	2017	Requirements Engineering	10.1007/s00766-017-0278-6	requirements engineering;systems engineering;management science;conceptual design;evaluation strategy;goal modeling;computer science;user requirements document;autonomy	SE	-24.87636524344074	-23.480983857989663	50094
4270650fced0b5629cda3c2a5f548647d98e5db6	"""review of """"introduction to the design and analysis of algorithms by ananay levitin"""", addison-wesley"""	analysis of algorithm;design technique	This is a beginning algorithms book, suitable for the late undergraduate or early graduate computer science student. Subjects covered include an introduction of the concept of algorithms, a taxonomy of various algorithms and design techniques, up through a preliminary discussion of the topics of complexity and computability. The subject of algorithms is, of course, well known and fundamental to the computer sciences. This book provides an introduction to the subject through the use of some well-known and not so well-known puzzles and computing problems.	algorithm;analysis of algorithms;computability;computer science;taxonomy (general)	William Fahle	2004	SIGACT News	10.1145/1054916.1054925	applied mathematics;computer science;theoretical computer science;mathematics;algorithm	Theory	-22.459713323862715	1.2153920172028667	50107
a89b0ea03da49d8b340231385c6abf437399f410	data transformation and migration in polystores	data mining;arrays;engines;transforms;distributed databases;relational databases	Ever increasing data size and new requirements in data processing has fostered the development of many new database systems. The result is that many data-intensive applications are underpinned by different engines. To enable data mobility there is a need to transfer data between systems easily and efficiently. We analyze the state-of-the-art of data migration and outline research opportunities for a rapid data transfer. Our experiments explore data migration between a diverse set of databases, including PostgreSQL, SciDB, S-Store and Accumulo. Each of the systems excels at specific application requirements, such as transactional processing, numerical computation, streaming data, and large scale text processing. Providing an efficient data migration tool is essential to take advantage of superior processing from that specialized databases. Our goal is to build such a data migration framework that will take advantage of recent advancement in hardware and software.	apache accumulo;computation;data-intensive computing;database;experiment;numerical analysis;parallel computing;postgresql;requirement;scidb;stream (computing);transaction processing	Adam Dziedzic;Aaron J. Elmore;Michael Stonebraker	2016	2016 IEEE High Performance Extreme Computing Conference (HPEC)	10.1109/HPEC.2016.7761594	data modeling;data migration;computer science;theoretical computer science;data mining;database	DB	-32.98681226791432	0.499878887193225	50160
1da593345fc4fb00b50914a5eec9bbd2816c67fd	continuous reverse k nearest neighbors queries in euclidean space and in spatial networks	continuous queries;reverse nearest neighbors;journal article;spatial queries;continuous monitoring;spatial networks	In this paper, we study the problem of continuous monitoring of reverse k nearest neighbors queries in Euclidean space as well as in spatial networks. Existing techniques are sensitive toward objects and queries movement. For example, the results of a query are to be recomputed whenever the query changes its location. We present a framework for continuous reverse k nearest neighbor (RkNN) queries by assigning each object and query with a safe region such that the expensive recomputation is not required as long as the query and objects remain in their respective safe regions. This significantly improves the computation cost. As a byproduct, our framework also reduces the communication cost in client–server architectures because an object does not report its location to the server unless it leaves its safe region or the server sends a location update request. We also conduct a rigid cost analysis for our Euclidean space RkNN algorithm. We show that our techniques can also be applied to answer bichromatic RkNN queries in Euclidean space as well as in spatial networks. Furthermore, we show that our techniques can be extended for the spatial networks that are represented by directed graphs. The extensive experiments demonstrate that our techniques outperform the existing techniques by an order of magnitude in terms of computation cost and communication cost.	client–server model;computation;directed graph;experiment;k-nearest neighbors algorithm;server (computing);spatial network	Muhammad Aamir Cheema;Wenjie Zhang;Xuemin Lin;Xuefei Li	2011	The VLDB Journal	10.1007/s00778-011-0235-9	computer science;machine learning;data mining;database;spatial query	DB	-25.89597451129935	0.09785597147081955	50256
3002d1ba6ab2cafc1be203974e4d251f902f092a	impatience, risk propensity and rationality in timing games		Games of timing reflect dynamic decision-making under uncertainty, as it takes place in many real-world situations, including health care, safety and security. Rather than making discrete decisions, participants choose one or more points in time that determine the outcome. We study individual’s biases and characteristics in such games of timing. We examine risk propensity as a personal preference affecting timing decisions and document a bias, impatience. Experiment 1 analyzes people’s strategy in timing games in relation to a rational model. Contrasting two cognitive models suggests that individuals apply risk propensity to the probability distributions underlying short games and when unfamiliar with the situation, but that, over time, impatience takes over as a linear adjustment. In Experiment 2, impatient participants risk their incentive payment in order to play early, even if they receive no advantage from doing so.	cognitive model;experiment;lock (computer science);rationality	Moojan Ghafurian;David Reitter	2014			social psychology;psychology;expected utility hypothesis;operationalization;rationality;repeated game;rational planning model;stochastic game;incentive;covert	HCI	-6.440735834552945	-7.250292733110355	50281
40f68131a9c675da444460bd3e3a4d0a6d273798	mandevillian intelligence		Mandevillian intelligence is a specific form of collective intelligence in which individual cognitive vices (i.e., shortcomings, limitations, constraints and biases) are seen to play a positive functional role in yielding collective forms of cognitive success. The present paper introduces the concept of mandevillian intelligence and reviews a number of strands of empirical research that help to shed light on the phenomenon. The paper also attempts to highlight the value of the concept of mandevillian intelligence from a philosophical, scientific and engineering perspective. Inasmuch as we accept the notion of mandevillian intelligence, then it seems that the cognitive and epistemic value of a specific social or technological intervention will vary according to whether our attention is focused at the individual or collective level of analysis. This has a number of important implications for how we think about the design and evaluation of collective cognitive systems. For example, the notion of mandevillian intelligence forces us to take seriously the idea that the exploitation (or even the accentuation) of individual cognitive shortcomings could, in some situations, provide a productive route to collective forms of cognitive and epistemic success.	artificial intelligence;cognition;collective intelligence;expectation propagation;experiment;heart rate variability;personalization;personalized search;scientific literature;search algorithm	Paul R. Smart	2017	Synthese	10.1007/s11229-017-1414-z		AI	-25.31572013008812	-12.570105762897745	50301
06cb7a6508863979e613f0685382b13ca79cd898	flexible information discovery in decentralized distributed systems	distributed system;information resources;computational grid;range query;partial knowledge;technological innovation;multidimensional information space;peer to peer systems;resource allocation;peer to peer computing grid computing distributed computing resource management fault tolerant systems central processing unit costs technological innovation indexing multidimensional systems;resource management;query formulation;distributed computing;p2p;client server systems;information discovery;design evaluation;p2p information discovery system;p2p storage systems;design evaluation decentralized distributed systems partial knowledge resource sharing distributed environments computational grids peer to peer systems p2p storage systems p2p retrieval systems p2p information discovery system range queries dimension reducing indexing scheme multidimensional information space;dimension reducing indexing scheme;indexing;distributed environment;fault tolerant systems;indexation;p2p retrieval systems;grid computing query formulation resource allocation information resources distributed databases content based retrieval client server systems;distributed databases;resource sharing distributed environments;computational grids;experimental evaluation;decentralized distributed systems;peer to peer computing;peer to peer;grid computing;content based retrieval;multidimensional systems;central processing unit;range queries	The ability to efficiently discover information using partial knowledge (for example keywords, attributes or ranges) is important in large, decentralized, resource sharing distributed environments such as computational Grids and Peer-to-Peer (P2P) storage and retrieval systems. This paper presents a P2P information discovery system that supports flexible queries using partial keywords and wildcards, and range queries. It guarantees that all existing data elements that match a query are found with bounded costs in terms of number of messages and number of peers involved. The key innovation is a dimension reducing indexing scheme that effectively maps the multidimensional information space to physical peers. The design, implementation and experimental evaluation of the system are presented.	algorithm;archive;computer data storage;data element;database;discovery system;distributed computing;distributed hash table;experiment;fault tolerance;information discovery;load balancing (computing);locality of reference;map;network topology;overlay network;peer-to-peer;range query (data structures);recursion;run time (program lifecycle phase);scalability;self-similarity	Cristina Schmidt;Manish Parashar	2003		10.1109/HPDC.2003.1210032	range query;computer science;resource management;theoretical computer science;database;distributed computing	HPC	-29.542066883565493	1.0750088226386942	50395
95ccf96944710738caa9b2c2475cf4838ff54a51	evaluating expert-authored rules for military reasoning	rule based;course of action;kraken;large scale;knowledge acquisition;nusketch battlespace;evaluation;subject matter expert;rkf;knowledge representation;shaken	Eliciting complex logical rules directly from logic-naive subject matter experts (SMEs) is a challenging knowledge capture task. We describe a large-scale experiment to evaluate tools designed to produce SME-authored rule bases. We assess the quality of the rule bases with respect to the: 1) performance on the addressed functional task (military course of action (COA) critiquing); and 2) intrinsic knowledge representation quality. In the course of this assessment, we note both strengths and weaknesses in the state of the art, and accordingly suggest some foci for future development in this important technology area.	knowledge management;knowledge representation and reasoning;rule 110;subject matter expert turing test;subject-matter expert	Mike Pool;Kenneth S. Murray;Julie Fitzgerald;Mala Mehrotra;Robert Schrag;Jim Blythe;Jihie Kim;Hans Chalupsky;Pierluigi Miraglia;Thomas A. Russ;David Schneider	2003		10.1145/945645.945661	rule-based system;knowledge representation and reasoning;computer science;knowledge management;artificial intelligence;evaluation;data mining;kraken;subject-matter expert	AI	-31.085947639275023	-7.633359255666876	50398
fc9e3253663bbc02dd4c78c3c06620095cc5f679	effect of background knowledge in a task model self-organization method	multi modal interface;task model;background knowledge;self organization	The method is proposed to self-organize a task model for realizing a multi-modal interface system. The method selforganizes the task model from word sequences and their responses using 6 basic rules and two kinds of background knowledge. This paper considers how strong the background knowledge have an influence on word sequences including noises. This paper also evaluates the influence by using a house designing task.	automaton;emoticon;modal logic;motorola 68060;power supply unit (computer);self-organization	Shigeaki Sakurai;Hironobu Takahashi;Ryuichi Oka	2000		10.1145/335603.335619	self-organization;simulation;computer science;knowledge management;artificial intelligence;task analysis	AI	-26.795061359479096	-17.221487967013204	50400
20f5df6adcc320c07480e9c04d5d4c1a1a01ec7d	cooperative driving based on negotiation with persuasion and concession		Recently, along with emergence of autonomous driving vehicles, it is predicted that in the near future, human drivers need to share road and interact with self-driving cars in all the possible traffic scenarios. In this paper, an algorithm based on negotiation with both persuasion and concession is proposed to tackle the challenging task of cooperative driving involving both human and robot drivers. The decision making process is formulated as an optimization based negotiation problem. The persuasion of autonomous vehicle is achieved by making commitment to tipping towards cooperation in the form of convex constraint. The concession is accomplished by gradually tuning weights in the objective function. We propose an approach suitable for most common driving scenarios including ramp merging, lane keeping/changing and intersection crossing. The effectiveness of the proposed algorithm is demonstrated by simulation for several different driving scenarios.	algorithm;autonomous car;autonomous robot;emergence;interaction;loss function;machine learning;mathematical optimization;optimization problem;ramp simulation software for modelling reliability, availability and maintainability	Cheng Peng;Masayoshi Tomizuka	2018	2018 IEEE Intelligent Vehicles Symposium (IV)	10.1109/IVS.2018.8500702	persuasion;management science;merge (version control);decision-making;negotiation;computer science	Robotics	-13.781083999460998	-10.73364801504542	50403
5569baca605b8b987a4cb7e4616ace91c9c3deb1	function-based, biologically inspired concept generation	engineering design;biologically inspired;function based design;concept generation	The natural world provides numerous cases for inspiration in engineering design. Biological organisms, phenomena, and strategies, which we refer to as biological systems, provide a rich set of analogies. These systems provide insight into sustainable and adaptable design and offer engineers billions of years of valuable experience, which can be used to inspire engineering innovation. This research presents a general method for functionally representing biological systems through systematic design techniques, leading to the conceptualization of biologically inspired engineering designs. Functional representation and abstraction techniques are used to translate biological systems into an engineering context. The goal is to make the biological information accessible to engineering designers who possess varying levels of biological knowledge but have a common understanding of engineering design. Creative or novel engineering designs may then be discovered through connections made between biology and engineering. To assist with making connections between the two domains concept generation techniques that use biological information, engineering knowledge, and automatic concept generation software are employed. Two concept generation approaches are presented that use a biological model to discover corresponding engineering components that mimic the biological system and use a repository of engineering and biological information to discover which biological components inspire functional solutions to fulfill engineering requirements. Discussion includes general guidelines for modeling biological systems at varying levels of fidelity, advantages, limitations, and applications of this research. The modeling methodology and the first approach for concept generation are illustrated by a continuous example of lichen.	archive;biological system;conceptualization (information science);engineering design process;function model;information engineering;mit engineering systems division;modelling biological systems;norm (social);parallels desktop for mac;requirement;software repository	Jacquelyn K. S. Nagel;Robert L. Nagel;Robert B. Stone;Daniel A. McAdams	2010	AI EDAM	10.1017/S0890060410000375	information engineering;system of systems engineering;systems engineering;engineering;artificial intelligence;engineering design process;mechanical engineering	SE	-20.47496920447755	-17.223214788084547	50461
15a4e3ae3a7e16a3d66a472cf57be146952c83e0	reply to cheeseman's an inquiry into computer understanding	context dependent	The repeated claim that, “McDermott has shown that a direct translation of commonsense reasoning into logical form leads to unsurmountable difficulties” (Abstract, and following). A series of suggestions (Sect. 2) that probabilities are a good idea, because -it is important to be able to label statements as other than simply unquestionably true or unquestionably false, -these labels should indicate something about the contexts in which they are valid, and -these labels should include numeric information. That the assignment of context-dependent labels can help solve the problem of referential opacity (Sect. 2). That the priors problem can be solved using the existence of “objective priors available for most of the commonly encountered situations” (Sect. 2) such as Jeffrey’s priors (Sect. 3 ) . That the use of probabilities solves the learning problem (Sect. 4). That “logic is just a special case within probability theory, but the converse is not true” (Sect. 5). That probabilities can be used to solve the ravens paradox and related difficulties (Sect. 5) . That a randomly selected passage from (Nilsson 1980) deals with probabilistic information (Sect. 6); Cheeseman attempts to infer the ubiquity of probabilistic reasoning from this.	artificial intelligence;certificate authority;commonsense reasoning;context-sensitive language;de bruijn graph;drew mcdermott;moravec's paradox;palo;randomness;reason maintenance	Matthew L. Ginsberg	1988	Computational Intelligence	10.1111/j.1467-8640.1988.tb00097.x	computer science;artificial intelligence;context-dependent memory	AI	-16.36686581948577	1.0410808783491696	50510
42ef5eba2f8e646ecc90d6af9d01e0cce4cce760	appeals immune bargaining solution with variable alternative sets	non expected utility;necessary and sufficient condition;nash bargaining	A bargaining solution based on the Rubinstein–Safra–Thomson ‘ordinal Nash’ outcome is investigated in the Peters–Wakker ‘revealed group preferences’ framework. Assuming non-expected utility preferences, necessary and sufficient conditions are stated on preference pairs in order for the solution to be well-defined and axiomatized uniquely. © 2006 Elsevier Inc. All rights reserved. JEL classification: C78	expected utility hypothesis;ordinal data	Eran Hanany	2007	Games and Economic Behavior	10.1016/j.geb.2006.04.006	bargaining problem;economics;microeconomics;mathematical economics;welfare economics	AI	-6.662382389192864	-1.7054703871283534	50533
6caeda3856b51ce566196db20489d48087b800ee	evaluation of land ecological safety based on fuzzy matter-element theory	fuzzy theory;land resource;ecosystem;ecological safety	Study on land ecological safety has become a forefront topic of regional sustainable development. The paper constructed an evaluation index system of land ecological safety. Then it discussed the ranges of indexes corresponding to each evaluation grade. Considering the illegibility and uncertainty in land ecological safety evaluation, the paper combined fuzzy matter-element and entropy method to establish an evaluation model of land ecological safety. Then it developed a case study on Hebei Province. The results show that there is a tendency of gradual improvement. Conditions of land ecological safety of 2000 and 2001 belong to relatively unsafe grade and the other six years belong to critically safe grade. Land ecological safety conditions of Hebei Province from 2000 to 2007 are unsatisfactory and need to be improved. The results can reflect the real conditions of land ecosystem of Hebei Province.	ecology;ecosystem;microsoft forefront	Jiulong Zhu;Xiaoyan Tao	2011	JCP	10.4304/jcp.6.12.2639-2646	ecosystem	Mobile	-10.375211535443988	-22.581560240123462	50558
8c7f266d7a5b24616aec95a07dbf5d67e50d14d9	an experimental performance comparison for indexing mobile objects on the plane	velocity;plane;performance comparison;mobile object;algorithm;future positions;indexation;value distribution;range queries	In this paper, the authors present a time-efficient approach to index objects moving on the plane in order to answer range queries about their future positions. Each object is moving with non small velocity u, meaning that the velocity value distribution is skewed (Zipf) towards u min in some range [ , ] u u min max , where u min is a positive lower threshold. This algorithm enhances a previously described solution (Sioutas, Tsakalidis, Tsichlas, Makris, & Manolopoulos, 2007) by accommodating the ISB-tree access method as presented in Kaporis et al. (2005). Experimental evaluation shows the improved performance, scalability, and efficiency of the new algorithm. DOI: 10.4018/978-1-4666-1577-9.ch019	algorithm;maxima and minima;range query (data structures);scalability;velocity (software development);zipf's law	Spyros Sioutas;George Papaloukopoulos;Kostas Tsichlas;Yannis Manolopoulos	2010	IJOCI	10.4018/joci.2010100105	range query;simulation;theoretical computer science;plane;data mining;velocity	DB	-26.521406277087518	0.9236289447097464	50563
beb4b5ff3825ec0cad685f323a29ca2d89574bbb	on aggregating information in actor networks	delay intolerant;routing;challenged networks;adaptive;multipath;fan out	This paper provides a way to think formally about the aggregation processes that take place in networks where individual actors (whether sensors, robots, or people) possess data whose value may decay over time. The various actors use data to make decisions: the larger the value, the better (i.e. more informed) the decision. At every moment, individual actors have the choice of making a decision or else to defer the decision to a later time. However, the longer they wait, the lower the value of the data they hold. To counter-balance the effect of time discounting, we define an algebraic operation that we call aggregation, whereby two or more actors integrate their data in the hope of increasing its value. Our main contribution is a formal look at the value of time-discounted information and at the algebra of its aggregation. We allow aggregation of time-discounted information to proceed in an arbitrary, not necessarily pairwise, manner. Our model relates aggregation decisions to the ensuing value of information and suggests natural thresholding strategies for the aggregation of the information collected by sets of network actors. Extensive simulations have confirmed the accuracy of our theoretical predictions.	robot;sensor;simulation;thresholding (image processing)	Stephan Olariu;Shahram Mohrehkesh;Xianping Wang;Michele C. Weigle	2014	Mobile Computing and Communications Review	10.1145/2581555.2581569	multipath propagation;routing;computer science;adaptive behavior;fan-out;data mining;computer network	AI	-10.710558831788637	-4.4540614508950345	50588
62414fb44f7b7b411175850cbaa8bab510974b1c	an introduction to intention revision: issues and problems		The change of beliefs on the basis of new information has been widely studied; however, the change of other mental states has received less attention, and particularly, intentions. Despite there are philosophical and formal theories about intentions, few of them consider the revision of intentions.We suggest introductory guidelines to define a research program for the revision of intentions regarding that: (i) intentions are intimately related to the beliefs and desires of agents immersed in a dynamic world; (ii) intentions are directly related to planning; and (iii) a reconsideration function is needed.	automated planning and scheduling;belief revision;mental state;theory	José Martín Castro-Manzano	2009			research program;social psychology;political science	AI	-24.198948967945782	-13.022001895336839	50619
439e2d6dfac009167fff38e256bac8a3a641063a	the origin of epistemic structures and proto-representations	representation;simulation theory;extended mind;situated cognition;cognitive load;distributed cognition;epistemic structure;cognitive complexity	Organisms across species use the strategy of generating structures in their environment to lower cognitive complexity. Examples include pheromones, markers, colour codes, etc. Distributed Cognition theory has argued that studying such ‘epistemic structures’ can provide insights into the development and nature of internal representations, and cognition itself. We develop this claim by providing a model of the origin of such structures, and present a simulation where organisms with only reactive behaviour learn, within their lifetime, to add such structures systematically to their world to lower cognitive load. This implementation is then extended to show that the same underlying process could generate traces of the world in an ‘internal environment’ to lower cognitive load. We then examine two implications of this internal trace model. First, it provides a novel account of the origin of internal representations. Further, as both external and internal traces lower cognitive load and are generated using the same mechanism, the location of the structure becomes opportunistic, and a matter of utility. This supports the ‘extended mind’ hypothesis. Second, the stored internal traces develop entirely out of actions. They thus encapsulate action components and could activate actions. This feature explains the origin of enactable and action-oriented mental content.	code;cognitive complexity;distributed cognition;marker (telecommunications);mind;simulation;trace (psycholinguistics);tracing (software)	Sanjay Chandrasekharan;Terrence C. Stewart	2007	Adaptive Behaviour	10.1177/1059712307076256	psychology;computer science;artificial intelligence;machine learning;cognitive complexity;simulated reality;situated cognition;cognitive load;communication;social psychology;representation	HCI	-25.015493114198886	-13.38738823947752	50642
ab6e3788afd4868f7c29fa91568454c78209a829	objective versus subjective coordination in the engineering of agent systems	multiagent system;design and development;agent modeling;conceptual framework;agent systems;coordinacion;agent coordination;sistema multiagente;systeme multiagent;coordination	The governance of interaction is a critical issue in the engineering of agent systems. Research on coordination addresses this issue by providing a wide range of models, abstractions and technologies. It is often the case, however, that such a wide range of proposals could not easily find an unitary and coherent conceptual framework where all the different views and solutions can be understood and compared – and this is particularly true in the context of agent models and systems. In this paper, we first discuss how all the many diverse approaches to agent coordination can be categorised in two main classes – the subjective and objective approaches – , depending on whether they adopt the agent’s or the engineer’s viewpoint, respectively. We then claim that the two approaches have a deep and different impact on the way in which agent systems are modelled and built, and show two examples rooted in different models and technologies. Finally, we advocate that both approaches play a fundamental role in the engineering of agent systems, and that any methodology for the design and development of agent systems has to exploit both objective and subjective coordination models and technologies.	coherence (physics);multi-agent system	Andrea Omicini;Sascha Ossowski	2003		10.1007/3-540-36561-3_9	simulation;artificial intelligence;conceptual framework;agent-based social simulation	AI	-21.147623432703437	-14.316432819923953	50660
032f623a447c1bd7b22884af9ed7333ef927465e	the agent network architecture (ana)	activation energy;autonomous agent;spreading activation;network architecture	"""The goal of my work is to develop and implement an architecture for an autonomous agent, which I refer to as """"ANA"""". An ANA agent consists of a distributed set of """"competence modules"""". Competence modules are linked in a network. A spreading activation process operates on the network to decide what the """"relevance"""" or relative strength of a competence module is in the current context. This process implements a competition among modules for activation energy. The higher the activation energy level of a module, the more likely it is that this module determines what the autonomous agent does or communicates to believe. Learning is a central, completely integrated feature of the architecture. The competence module network is continuously being developed and changed on the basis of experience: links are added and deleted depending on real world observations and new """"macro modules"""" are created whenever a goal is achieved. This paper presents an overview of the architecture. It describes the functionalities that have been implemented, the results that have been obtained with robotic and simulated ANA agents, and finally it discusses (current) limitations and future work."""	autonomous agent;autonomous robot;energy level;experience;network architecture;relevance;spreading activation	Pattie Maes	1991	SIGART Bulletin	10.1145/122344.122367	real-time computing;activation energy;simulation;network architecture;computer science;artificial intelligence;autonomous agent;spreading activation	AI	-25.82199582140363	-18.123209426600397	50703
03c2a6846117c0b0cd8d2d79c2081ba79d10c5d3	a solomonic solution to the problem of assigning a private indivisible good	indivisible private good;strategy proofness;quasi linear preferences;vickrey clarke groves mechanism	A benevolent Planner wishes to assign an indivisible private good to n claimants, each valuing the object differently. Individuals have quasi-linear preferences. Therefore, the possibility of transfers is allowed. A second-best efficient mechanism is a strategy-proof and anonymous mechanism that is not Pareto dominated by another strategy-proof and anonymous mechanism. In this context, we identify three conditions that are necessary and, together with Voluntary Participation, sufficient for a mechanism to be second-best efficient. This set includes mechanisms that destroy the good at certain profiles. For domains comprising two individuals we provide an explicit characterization of the family of second-best efficient mechanisms.	indivisible	Efthymios Athanasiou	2013	Games and Economic Behavior	10.1016/j.geb.2013.07.007	economics;microeconomics;mathematical economics;welfare economics	Theory	-5.509384016548335	-3.4704532259847114	50714
8b6af86a51874072cded4fd32cea97aa64335c63	auditory expectation: the information dynamics of music perception and cognition	musical melody;creativity;segmentation;aesthetics;expectation;pitch;probabilistic modeling;prediction	Following in a psychological and musicological tradition beginning with Leonard Meyer, and continuing through David Huron, we present a functional, cognitive account of the phenomenon of expectation in music, grounded in computational, probabilistic modeling. We summarize a range of evidence for this approach, from psychology, neuroscience, musicology, linguistics, and creativity studies, and argue that simulating expectation is an important part of understanding a broad range of human faculties, in music and beyond.	cognition;computation;linguistics;neuroscience discipline;simulation	Marcus Pearce;Geraint A. Wiggins	2012	Topics in cognitive science	10.1111/j.1756-8765.2012.01214.x	psychology;cognitive psychology;prediction;music psychology;artificial intelligence;machine learning;pitch;linguistics;music and emotion;communication;creativity;social psychology;segmentation;cognitive science;expected value;statistics	NLP	-27.214118875399777	-14.733065981933866	50728
268fed1aabc490a4cb6e87a6cb54a5270259e72c	the supercore for normal-form games	nash equilibrium;prisoner s dilemma;nash equilibria;stable set;normal form game	We study the supercore of a system derived from a normal form game. For the case of a finite game with pure strategies, we define a sequence of games and show that the supercore of that system coincides with the set of Nash equilibrium strategy profiles of the last game in the sequence. This result is illustrated with the characterization of the supercore for the n-person prisoners’ dilemma. With regard to the mixed extension of a normal form game, we show that the set of Nash equilibrium profiles coincides with the supercore for games with a finite number of Nash equilibria. For games with an infinite number of Nash equilibria this need not be no longer the case. Yet, it is not difficult to find a binary relation which guarantees the coincidence of these two sets.	a-normal form;nash equilibrium	María Elena Iñarra García;María Concepción Larrea Jaurrieta;Ana Isabel Saracho de la Torre	2007	J. Economic Theory	10.1016/j.jet.2005.06.004	price of stability;game theory;epsilon-equilibrium;mathematical optimization;best response;trembling hand perfect equilibrium;coordination game;economics;subgame;non-credible threat;folk theorem;repeated game;mathematics;correlated equilibrium;chicken;microeconomics;risk dominance;normal-form game;mathematical economics;subgame perfect equilibrium;welfare economics;equilibrium selection;symmetric game;solution concept;nash equilibrium;symmetric equilibrium	ECom	-5.300250515570061	-1.4513925528859446	50768
051ed9ef5b9dadff9f19921f088875d6a86247b2	representing, archiving, and searching the space of mathematical knowledge		There is an interesting duality between the forms and extents of mathematical knowledge that is verbally expressed (published in articles, scribbled on blackboards, or presented in talks/discussions) and the forms that are needed to successfully extend and apply mathematics. To “do mathematics”, we need to judge the veracity, extract the relevant structures, and reconcile them with the context of our existing knowledge - recognizing parts as already known and identifying those that are new to us. In this process we may abstract from syntactic differences, and even employ interpretations via non-trivial mappings as long as they are meaning-preserving.		Mihnea Iancu;Michael Kohlhase;Corneliu-Claudiu Prodescu	2014		10.1007/978-3-662-44199-2_5	computer vision;computer science;theoretical computer science	AI	-31.3253684026819	-12.759622117984271	50823
b0cb3be87b7f4f50d62d8dbba5a2e8d78c7d90a9	symbols among the neurons: details of a connectionist inference architecture	distributed representation;variable binding;production system;computer architecture;emergent properties;pattern matching;neural network	Pattern matching and variable binding are easily implemented in conventional computer architectures, but not necessarily in all architectures. In a distributed neural network architecture each symbol is represented by activity in many units and each unit contributes to the representation of many symbols. Manipulating symbols using this type of distributed representation is not as easy as with a local representation whore each unit denotes one symbol, but there is evidence that the distributed approach is the one chosen by nature. We describe a working implementation of a production system interpreter in a neural network using distributed representations for both symbols and rules. The research provides a detailed account of two important symbolic reasoning operations, pattern matching and variable binding, as emergent properties of collections of neuron-like elements. The success of our production system implementation goes some way towards answering a common criticism of connectionist theories: that they aren't powerful enough to do symbolic reasoning.	artificial neural network;as-easy-as;computer architecture;connectionism;emergence;network architecture;neuron;pattern matching;production system (computer science);symbolic computation;theory	David S. Touretzky;Geoffrey E. Hinton	1985			computer science;artificial intelligence;theoretical computer science;machine learning;pattern matching;production system;programming language;artificial neural network;emergence	ML	-26.81867387526501	-15.623540208392889	50865
5da1914358a3387d3ec66111e57c5437a976b3f6	managing multiple case bases: dimensions and issues	case base reasoning	Case-based reasoning (CBR) models the process of reasoning from specific experiences acquired by an agent, and contained in the agent’s case-base. When multiple agents acquire cases, opportunities arise for sharing their case-bases, with accompanying issues for how to apply others’ experiences effectively. This paper examines issues for multi-casebase reasoning (MCBR), the reasoning process needed for a CBR system to exploit external case-bases reflecting similar but different tasks and task environments. The paper summarizes the component processes required, the dimensions along which these processes may differ, and some of the key research issues that must be addressed for successful MCBR systems. It closes with a perspective on the relationships of case-based reasoning and multi-case-base reasoning, examining the analogy between reasoning about cases in CBR and case-bases in MCBR.	case-based reasoning;experience	David B. Leake;Raja Sooriamurthi	2002			opportunistic reasoning;case-based reasoning;qualitative reasoning;computer science;knowledge management;artificial intelligence;adaptive reasoning;management science;reasoning system	AI	-23.25098021321283	-9.589346353835207	50908
455c1847d8695652b5c6bfa813207135a7c5b51d	network voronoi diagram based range search	mobile query processing;generators;geographic information system;query processing;application software;probability density function;information technology;geometry;computational geometry;mobile databases;query processing spatial query processing voronoi diagram mobile query processing spatial databases mobile databases;euclidean distance spatial databases geographic information systems query processing application software information technology computer networks computer science wireless communication communications technology;euclidean distance;tree data structures;data mining;mobile database;spatial database;computer networks;spatial query processing;wireless communication;distance measurement;query processing geographic information system network voronoi diagram mobile database euclidean distance geometrical analysis;geographic information systems;spatial databases;network voronoi diagram;communications technology;search problems;computer science;visual databases computational geometry geographic information systems geometry query processing search problems tree data structures;geometrical analysis;voronoi diagram;visual databases	One of the most frequent queries in spatial and mobile databases is range search, which is originated from the construction of R-tree that limits the spatial database application to Euclidean distance. Nowadays, Geographic Information System (GIS) demands the applications to be practicable for factual distance, normally identified as network distance. Even though some algorithms are engaged in this area, network distance range search is still a time consuming and storage space occupation task. In this paper, we propose a novel approach which is based on Network Voronoi Diagram that is diffusely used in geometrical analysis. We are looking into how to improve the performance of range search query processing using Network Voronoi Diagram.	algorithm;computation;euclidean distance;experiment;geographic information system;mobile app;mobile computing;national vulnerability database;parallel computing;performance;r-tree;range searching;spatial database;time complexity;voronoi diagram	Kefeng Xuan;Geng Zhao;David Taniar;Bala Srinivasan;Maytham Safar;Marina L. Gavrilova	2009	2009 International Conference on Advanced Information Networking and Applications	10.1109/AINA.2009.82	mobile database;computer science;theoretical computer science;data mining;database;geographic information system	DB	-26.23548653455676	0.36941651071002973	50915
e4b4f937b4bc8d1aff872e271159065700cc0e5d	artificial universes - towards a systematic approach to evaluation algorithms which learn form examples		The theory behind artificial universes - full probabilistic models of domains - is developed. Universes can be used to provide a ready supply of randomly selected examples for use by classification algorithms. Simple universes are quite sufficient to provide challenging tasks for such algorithms. The means of defining a universe is described in detail with a running example. The issue of alternate representation is discussed and the idea of a standard representation such as the ID3 form is introduced. Properties of attributes, especially those of pure noise and redundancy, are defined. The use of information theory concepts (including the primitive notion of majorisation) to model noise in the domain and to provide measures for the universe is described. In particular the notions of accuracy and efficiency of an induced rule are defined.	algorithm	Ray J. Hickey	1992			redundancy (engineering);mathematics;information theory;machine learning;probabilistic logic;artificial intelligence;primitive notion;algorithm;statistical classification;universe	AI	-15.112802340322638	0.7287891258776343	50944
461866864fcd65dd8d11612d2db197402f31fb06	mudra: user-friendly fine-grained gesture recognition using wifi signals	wifi signals;signal cancellation;gesture recognition	"""There has been a great interest in recognizing gestures using wireless communication signals. We are motivated in detecting extremely fine, subtle finger gestures with WiFi signals. We envision this technology to find applications in finger-gesture control, disabled-friendly devices, physical therapy etc. The requirements of mm-level sensitivity and user-friendly feature using existing WiFi signals pose great challenges. Here, we present Mudra, a fine-grained finger gesture recognition system which leverages WiFi signals to enable a near-human-to-machine interaction with finger motion.  Mudra uses a two-antenna receiver to detect and recognize finger gesture. It uses the signals received from one antenna to cancel the signal from the other. This """"cancellation"""" is extremely sensitive to and enables us detect small variation in channel due to finger movements. Since Mudra decodes gestures with existing WiFi transmissions, Mudra enables gesture recognition without sacrificing WiFi transmission opportunities. Besides, Mudra is user-friendly with no need of user training. To demonstrate Mudra, we implement prototype on the NI-based SDR platform and use COTS WiFi adapter. We evaluate Mudra in a typical office environment. The results show that our system can achieve 96% accuracy."""	etsi satellite digital radio;gesture recognition;prototype;requirement;sensor;usability	Ouyang Zhang;Kannan Srinivasan	2016		10.1145/2999572.2999582	embedded system;speech recognition;computer science;gesture recognition	Mobile	-15.494884878520267	-2.5557392540387323	51016
3141afc2fcc34253188eaa97ca044b04f496617d	landscape: a knowledge-based system for visual landscape assessment	acondicionamiento medio ambiente;paysagisme;representacion conocimientos;sistema experto;knowledge based system;adquisicion del conocimiento;rule based system;acquisition connaissance;paisajismo;systeme base connaissances;amenagement milieu;knowledge acquisition;expert knowledge;environmental design;systeme expert;knowledge representation;representation connaissances;knowledge based systems;landscape design;expert system;environmental planning	The landscape study is an interpretation task, usually performed in environmental planning, for which a wide range of expert knowledge sources is required. In order to help the experts in this field, a rule-based system that operates on fuzzy domains, has been used. However, some consistency problems together with an insufficient capability of adaptation to users' requirements have been detected. To improve this system, a new knowledge-based system has been designed and implemented. This approach exploits the fact that gradual knowledge rules are available, as these were obtained in the knowledge acquisition phase. In this work, we describe the main characteristics of such a system as well as its contribution to improve the capacity of adaptation to a great variety of user' inputs.	knowledge-based systems	Rodrigo Martínez-Béjar;Fernando Martín-Rubio	1998		10.1007/3-540-64574-8_471	computer science;knowledge management;artificial intelligence;knowledge-based systems;landscape design	AI	-23.68710053765093	-4.460736748055599	51030
13e0e342125c092b9fa33bcd54071eec61cc9137	study on pedestrian flow evacuation with individual-guidance mechanism	learning;simulation;intelligent agents;social networks;behaviour;artificial intelligence	Purpose – The purpose of this paper is to provide the possible and better selection for pedestrian flow evacuation. Design/methodology/approach – Simulation. Findings – First, according to the model with self-decision agents, the paper figures out that the effect of evacuation guided by the random-walk mechanism exceeds that guided by the inertial mechanism, and specifically, the effect of evacuation could significantly improve if random-walk agents restraint the probability of random walk under 0.4. Besides, on neighborhood reference mechanism, individuals who take neighbors’ average direction as reference tend to achieve better effect of evacuation than that of following majority rule. Furthermore, this paper proposes that an optimal ratio of the proportion of clever individuals and system density exists for evacuation effect improvement. Finally, the evacuating effect with barrier locating in different space is also studied in our research. Originality/value – The effect of evacuation could significantly improve if random-walk agents restraint the probability of random walk under 0.4. On neighborhood reference mechanism, individuals who take neighbors’ average direction as reference tend to achieve better effect of evacuation than that of following majority rule.	agent-based model;agent-based social simulation;autonomy;intelligent agent;missile guidance;nl (complexity);network congestion;self-similarity;simulation	Canzhong Yao;Xiaofeng Liu;Ji-Nan Lin	2016	Kybernetes	10.1108/K-04-2015-0096	simulation;computer science;artificial intelligence;operations research;intelligent agent;social network	AI	-13.425450891434627	-14.18853690265907	51065
dfd79f37224863d26702a9e03a8b74f31368f1ba	a characterization of the uniform rule with several commodities and agents	single peaked preference;several infinitely divisible commodities;iser discussion paper;infinite divisibility;satisfiability;separable preferences;strategy proofness;uniform rule;article	We consider the problem of allocating infinitely divisible commodities among a group of agents. Especially, we focus on the case where there are several commodities to be allocated, and agents have continuous, strictly convex, and separable preferences. In this paper, we establish that the uniform rule is the only rule satisfying strategy-proofness, unanimity, symmetry, and nonbossiness.	convex function;infinite divisibility	Shuhei Morimoto;Shigehiro Serizawa;Stephen Ching	2013	Social Choice and Welfare	10.1007/s00355-011-0648-9	mathematical optimization;economics;mathematics;linguistics;mathematical economics;welfare economics;infinite divisibility;satisfiability	AI	-5.706554263832703	-1.7520038233152102	51109
7eae1a1e93b49cb6e1338eab3a6100e345a05980	dynamic contract design for heterogenous workers in crowdsourcing for quality control		Crowdsourcing sites heavily rely on paid workers to ensure completion of tasks. Yet, designing a pricing strategies able to incentivize users' quality and retention is non trivial. Existing payment strategies either simply set a fixed payment per task without considering changes in workers' behaviors, or rule out poor quality responses and workers based on coarse criteria. Hence, task requesters may be investing significantly in work that is inaccurate or even misleading. In this paper, we design a dynamic contract to incentivize high-quality work. Our proposed approach offers a theoretically proven algorithm to calculate the contract for each worker in a cost-efficient manner. In contrast to existing work, our contract design is not only adaptive to changes in workers' behavior, but also adjusts pricing policy in the presence of malicious behavior. Both theoretical and experimental analysis over real Amazon review traces show that our contract design can achieve a near optimal solution. Furthermore, experimental results demonstrate that our contract design 1) can promote high-quality work and prevent malicious behavior, and 2) outperforms the intuitive strategy of excluding all malicious workers in terms of the requester's utility.	algorithm;cost efficiency;crowdsourcing;experiment;malware;statistical classification;theory;tracing (software)	Chenxi Qiu;Anna Cinzia Squicciarini;Sarah Michele Rajtmajer;James Caverlee	2017	2017 IEEE 37th International Conference on Distributed Computing Systems (ICDCS)	10.1109/ICDCS.2017.187	distributed computing;algorithm design;computer science;pricing strategies;payment;crowdsourcing;contract management	HCI	-10.315074899543538	-8.348532336812987	51114
fc6d057d90b649c497e6f13465df8be3f8cc49ae	on the interplay between incentive compatibility and envy freeness	game theory;incentive compatibility;satisfiability;pareto optimality	We study mechanisms for an allocation of goods among agents, where agents have no incentive to lie about their true values (incentive compatible) and for w hich no agent will seek to exchange outcomes with another (envy-free). Mechanisms satisfying each requ i ment separately have been studied extensively, but there are few results on mechanisms achieving bo th. We are interested in those allocations for which there exist payments such that the resulting mechanis m is simultaneously incentive compatible and envy-free. Cyclic monotonicity is a characterization of incentive com patible allocations, local efficiency is a characterization for envy-free allocations. We combine th e above to give a characterization for allocations which are both incentive compatible and envy free. W e show that even for allocations that allow payments leading to incentive compatible mechanisms , and other payments leading to envy free mechanisms, there may not exist any payments for which the me chanism is simultaneously incentive compatible and envy-free. The characterization that we giv lets us compute the set of Pareto-optimal mechanisms that trade off envy freeness for incentive compa tibility. AT&T Labs-Research, 180 Park Avenue, Florham Park, NJ. School of Business Administration and Center for the Study o f Rationality, The Hebrew University of Jerusalem. The Blavatnik School of Computer Science, Tel Aviv Universi ty. The Blavatnik School of Computer Science, Tel Aviv Universi ty. The Blavatnik School of Computer Science, Tel Aviv Universi ty.	call of duty: black ops;co-ment;computer science;existential quantification;pareto efficiency;rationality	Edith Cohen;Michal Feldman;Amos Fiat;Haim Kaplan;Svetlana Olonetsky	2010	CoRR		industrial organization;game theory;economics;incentive compatibility;microeconomics;welfare economics;satisfiability	ECom	-5.577719587249828	-2.8213194096118706	51138
b0234cb1c012153248948af209a0f8c7102a3e3f	optimal task allocation in multi-human multi-robot interaction		Multi-human multi-robot interaction is a complex system in which robots, e.g., unmanned aerial vehicles,may share informationwith a group of human operators to perform geographically-dispersed priority-based tasks within a specified time. In this complex system, the key is to optimally allocate tasks comprising of high-risk and low-risk information at multiple-levels in order to maximize effectiveness of the entire system given the limited resources. A multi-level programming model is developed in which an agent allocates information received from multiple robots to multiple team leaders who in turn distribute information to operators within their teams. The objective of the agent is to optimally allocate tasks tomultiple team leaders tomaximize the overall system performance and to minimize the processing cost and time while considering human factors. The developed model is solved using backward induction and details are presented in reverse time sequence. If human factors are included along with the productivity metrics then the performance of the multi-human multi-robot interaction systems can be improved.	aerial photography;backward induction;complex system;human factors and ergonomics;programming model;robot;time series;unmanned aerial vehicle	Monali S. Malvankar-Mehta;Siddhartha S. Mehta	2015	Optimization Letters	10.1007/s11590-015-0890-7	real-time computing;simulation	AI	-24.96028893949285	-23.608574760743373	51203
69239fa1ba989be64a8af2fb0e8e34308ba4df70	a rule-based system embedded with fuzzy logic for risk estimation	emergency response;logistics project management fuzzy logic rule based reasoning risk analysis;fuzzy set;service provider;risk analysis;project manager;rule based system;preventive measures;decision makers;risk management;decision maker;companies;fuzzy sets;fuzzy logic;rule based system fuzzy logic risk estimation decision makers express delivery service provider company risk level;risk factors;logistics;estimation;risk estimation;company risk level;fuzzy logic companies risk management fuzzy sets estimation logistics educational institutions;risk management fuzzy logic knowledge based systems;knowledge based systems;logistics project management;rule based reasoning;express delivery service provider	Different kinds of risks caused by various risk factors that a company needs to face are difficult to assess and manage since the decision makers cannot evaluate the risks systematically. A direct or indirect loss will occur as a result. Taking an express delivery service provider as an illustrative example, this study proposes a systematic approach embedded with fuzzy logic to assess the corporation's risk level. The company's risk problems are then classified into three major groups evaluated with fuzzy values in terms of the likelihood of occurrence and the severity of the consequences. By having an indication of the company's risk level, decision makers can be better aware of any changes in the environment which affect the company's risk level and hence are able to draw up preventive measures in a more rational manner.	embedded system;fuzzy logic;logistics;reliable messaging;risk assessment;risk factor (computing);risk management;rule-based system	Cassandra X. H. Tang;Henry C. W. Lau	2011	2011 Eighth International Conference on Fuzzy Systems and Knowledge Discovery (FSKD)	10.1109/FSKD.2011.6019501	rule-based system;computer science;knowledge management;artificial intelligence;data mining;fuzzy set	SE	-7.71745533167855	-15.998060670978365	51225
c7045906ef09ca1b52415b45bf8049269bd3ec83	a methodology for multiple-fault diagnosis based on the independent choice logic	bayesian network;bayes net;incertidumbre;uncertainty;sistema complejo;scaling up;reseau bayes;development environment;systeme complexe;diagnostic panne;complex system;dynamic bayesian network;fault diagnostic;diagnostico pana;incertitude;electric power;probabilistic logic;logique probabiliste;fault diagnosis;probabilistic logics	We propose a methodology to diagnose multiple faults in complex systems. The approach is based on the Independent Choice Logic (ICL) and comprises two phases. In phase 1 we generate the explanations of the observed symptoms and handle the combinatorial explosion with a heuristic. In phase 2 we observe process signals to detect abnormal behavior that can lead us to identify the real faulted components. A proposal is made to automate this task with Dynamic Bayesian Networks (DBNs) embedded in the ICL formalism. The overall scheme is intended to give a definite diagnosis. ICL is a framework, which comprises a theory and a development environment. We show that ICL can be scaled-up to real-world, industrial-strength problems by using it in diagnosing faults in an electrical power transmission network.		Luis E. Garza-Castañón;Francisco J. Cantú Ortiz;Salvador Acevedo	2000		10.1007/3-540-44399-1_43	complex systems;computer science;artificial intelligence;machine learning;bayesian network;mathematics;algorithm	NLP	-21.044058066799842	-3.8091187420459116	51271
3274404ce49dce96f4ee52693bbcbc3eff17d09d	reasoning with contextual graphs	decision tree;design and development;artificial intelligent;support system;contextual graphs;decision support system;transportation;artificial intelligence;context based reasoning	Decision trees allow the modeling of event-dependent reasoning, but do not consider the dynamics of contextual changes in reasoning. In the framework of the SART project, which aims at the design and development of an intelligent support system for subway regulators, we have to model highly contextual reasoning. We introduce the notion of contextual graph to take into account temporal and context-based reasoning. This model relies on observed reasoning modes in which the context and its dynamics are essential. Ó 2002 Elsevier Science B.V. All rights reserved .	decision tree;graph (abstract data type);reasoning system	Patrick Brézillon;Laurent Pasquier;Jean-Charles Pomerol	2002	European Journal of Operational Research	10.1016/S0377-2217(01)00116-3	opportunistic reasoning;transport;qualitative reasoning;decision support system;computer science;knowledge management;artificial intelligence;adaptive reasoning;model-based reasoning;machine learning;decision tree;procedural reasoning system;psychology of reasoning;reasoning system;automated reasoning;evidential reasoning approach	AI	-21.103389657838093	0.9292852150264023	51283
c348c87310445699c447c93b8faabb24b15e7750	study on evolutionarily stable strategies (ess) in sme clusters	electronic switching systems random variables probability distribution game theory costs environmental economics data mining knowledge management delay animals;information structure;pattern clustering;theoretical model;evolutionary computation;game theory;evolutionarily stable strategy;evolutionarily stable strategies ess;small to medium enterprises;partial information;evolution game small medium enterprise sme evolutionarily stable strategies ess;information structures evolutionarily stable strategies sme clusters small medium enterprise partial information game theoretical model;small medium enterprise sme;evolution game;small to medium enterprises evolutionary computation game theory pattern clustering	Evolutionarily stable strategies (ESS) is used between species co-exist in small medium enterprise (SME) clusters. We assume that each of the potential helpers knows the others’ strategies in cluster in this paper. We show that the ability to observe their realizations influences the Evolutionarily Stable Strategies (ESS) of the game. According to our results, under the partial information structure ESS do not always exist. No assistance and immediate assistance are possible ESS, while delayed assistance cannot be an ESS. This paper considers a symmetric conflict, all the potential helpers have the same strategy sets and they all play the same role. A general game theoretical model is developed under one information structures: partial information. At the same time we apply our model to study of the assistance in SME clusters.	theory	Enping Shen;Zuobing Fan	2009	2009 Second International Workshop on Knowledge Discovery and Data Mining	10.1109/WKDD.2009.72	game theory;simulation;computer science;evolutionarily stable strategy;evolutionary computation	ML	-7.879044303716655	-6.595261073243844	51299
9da3c66060eeace1330610dc0bb867d6196f2d08	dynamic scheduling of maintenance tasks in the petroleum industry: a reinforcement approach	multi agent system;reinforcement learning;production system;maintenance tasks;continuous improvement;adaptive learning;petroleum industry;on line scheduling;task scheduling;computer simulation;production efficiency;dynamic scheduling	Petroleum industry production systems are highly automatized. Maintenance of such systems is vital, not only to maintain production efficiency but also to insure minimal safety levels. Maintenance task scheduling is difficult since some tasks are already identified because they must be done repeatedly, and other tasks need to be identified dynamically. In this paper, we present a multi-agent approach for the dynamic maintenance task scheduling for a petroleum industry production system. Agents simultaneously insure effective maintenance scheduling and the continuous improvement of the solution quality by means of reinforcement learning, using the SARSA algorithm. Reinforcement learning allows the agents to adapt, learning the best behaviors for their various roles without reducing the performance or reactivity. To demonstrate the innovation of our approach, we include a computer simulation of our model and the results of experimentation applying our model to an Algerian petroleum refinery.	scheduling (computing)	Nassima Aissani;Bouziane Beldjilali;Damien Trentesaux	2009	Eng. Appl. of AI	10.1016/j.engappai.2009.01.014	computer simulation;fair-share scheduling;real-time computing;simulation;dynamic priority scheduling;computer science;petroleum industry;artificial intelligence;productive efficiency;two-level scheduling;scheduling;production system;adaptive learning;reinforcement learning	AI	-19.681442823746334	-6.715617625123477	51397
c5c79607c91d1b1fb5b1db2c60cca5edfddb1d61	research and design of extension case base based on cbr	automotive engineering;case base reasoning;design engineering;financial management;vehicles case based reasoning knowledge representation learning artificial intelligence traffic engineering computing;information retrieval;conference management;maintenance engineering;data mining;extension case base;binary trees;vents;machine learning;fuels;extension case base cbr extenics knowledge representation;intelligent vehicles;cognition;fault diagnosis system;intelligent systems;intelligent system;fault diagnosis intelligent vehicles intelligent systems knowledge representation artificial intelligence automotive engineering information retrieval design engineering conference management financial management;cbr;artificial intelligence;traffic engineering computing;machine learning vehicle maintenance process intelligent fault diagnosis system case based reasoning knowledge representation;vehicles;vehicle maintenance process;case based reasoning;learning artificial intelligence;knowledge representation;intelligent fault diagnosis system;fault diagnosis;extenics;binary tree	In order to solve the problems that there is less valid information on the vehicle maintenance and the intelligent fault diagnosis system is inefficient with increasing the case base, based on Case Based Reasoning (CBR). Extenics is used in designing case base. Firstly, extension model and binary tree are used for the formal description, as the mode of knowledge representation. Secondly, extension reasoning is applied to extending the case base. Last, customers’ feedbacks with the new case are made use of maintaining the case base, to complete the machine learning. The extension case base is built to conveniently classify, retrieve and maintain the case. Thus, the efficiency and flexibility of the intelligent system is improved together.	binary tree;case-based reasoning;knowledge representation and reasoning;machine learning;redundancy (engineering)	Dan Han;Zhiwei Ni;Gongrang Zhang;Hongyu Wang;Jun Yan	2009	2009 International Conference on Business Intelligence and Financial Engineering	10.1109/BIFE.2009.57	use-case analysis;systems engineering;engineering;artificial intelligence;machine learning	AI	-28.963764149238806	-5.787482137253613	51408
2e277366897335550fbb7fac6f754c2f0b942d6e	the three musketeers: four classical solutions to bankruptcy problems	comparative analysis;equal awards solution;proportional rule;bankruptcy problems;talmud solution;equal losses solution;classical solution;constrained equal losses rule;proportional solution equal awards solution;proportional solution;constrained equal awards rule	This paper provides a comparative analysis of some classical solutions to bankruptcy problems from an axiomatic viewpoint. These rules are the constrained equal-awards rule, the constrained equal-losses rule, the proportional rule and the Talmud rule. The purpose of this study is to facilitate the understanding of their di¤erences and to clarify the type of situations in which each of these rules is better. Key-words: Bankruptcy problems, proportional solution, equal-awards solution, equal-losses solution, Talmud solution. JEL classi...cation number: D63	qualitative comparative analysis	Carmen Herrero;Antonio Villar	2001	Mathematical Social Sciences	10.1016/S0165-4896(01)00075-0	qualitative comparative analysis;mathematical optimization;social science;operations management;mathematical economics	AI	-6.9578373063690995	-2.3958545087392618	51465
9521f9055e542921b001a4fe9b14c4f5fc283b55	collaborative spatial decision making with qualitative constraints	query language;computer model;spatial planning;heterogeneous databases;geographic information sys tem;decision maker;satisfiability;requirement analysis;group decision making;point of view;cooperative work	Usually spatial planning problems involve a large number of decision makers with different backgrounds and interests. The process of Collaborative Spatial Decision Making (CSDM) has to reconcile the individual approaches and lead to solutions that satisfy all participants. In this paper we deal with a particular instance of CSDM that involves qualitative constraints. Qualitative CSDM is very important for practical applications where decision makers communicate spatial knowledge using relations in space rather than absolute coordinates. It is also an interesting topic from the scientific point of view, because it combines several research areas related to Geographic Information Systems such as Spatial Query Languages, Constraint Satisfaction Mechanisms, Heterogeneous Databases, Spatial Access Methods and Group Decision Making. We describe the problems that need to be dealt with, we outline solutions, and we propose a computational model that can automate a large party of Qualitative CSDM. Topics: GIS and cooperative work, Requirements analysis for GIS applications, Interoperability among heterogeneous GIS, GIS meta data	automated planning and scheduling;computational model;constraint satisfaction;gis applications;geographic information system;interoperability;requirements analysis;spatial query	Nikos I. Karacapilidis;Dimitris Papadias;Max J. Egenhofer	1995			computer simulation;decision-making;requirements analysis;r-cast;group decision-making;influence diagram;decision support system;decision analysis;decision engineering;computer science;knowledge management;data mining;database;management science;query language;business decision mapping;satisfiability	AI	-29.52166486236331	-10.939663178286482	51540
cd26d8b70340aa47def0888d4e74ae4e5516ecb2	the impact of reputation on supply chains. an analysis of permanent and discounted reputation	bullwhip effect;agent based computational economic;material flow;supply chain;supply chain management	In long-term recurring contractual relationships, which are common in the B2B-arena, reputation and trust play a crucial role. This analysis investigates the joint impact of reputation and price-based ranking of suppliers on the material flow in the supply chain. Positive reputation proves to be a key factor in reaching dominating market positions, which illustrates the importance of building brand awareness in all stages of a supply chain. Through our simulation, it will be observed that the ranking of suppliers by reputation-based choice has a stabilizing effect on the material flow in the supply chain. A strong reputation component in the individual choice stimulates the formation of monopolies, while the discount of reputation imposes a countertendency on this effect. The Bullwhip Effect, another phenomenon that carries a countertendency to the reputation-based monopoly effect, is observed to be even stronger for members of tiers with a high fluctuation of order rates.		Jochen Franke;Tim Stockheim;Wolfgang König	2005	Inf. Syst. E-Business Management	10.1007/s10257-005-0007-4	supply chain management;economics;marketing;bullwhip effect;operations management;microeconomics;supply chain;material flow;commerce	ECom	-4.711283110567209	-7.42192230589996	51654
d7f8b42435350f81d9050ee5af4755511e845eb3	commentary: issues in knowledge-based decision support	decision support;representacion conocimientos;sistema experto;base connaissance;raisonnement;razonamiento;base conocimiento;systeme expert;reasoning;knowledge representation;representation connaissances;knowledge base;expert system	Etude sur la conception et le developpement de supports d'aide a la decision a base de connaissances		Erik Hollnagel	1987	International Journal of Man-Machine Studies	10.1016/S0020-7373(87)80028-7	knowledge base;computer science;knowledge management;artificial intelligence;expert system;reason;algorithm	Arch	-24.723473633701982	-4.882831037813646	51656
b6b918a48f28d8233c0e952ca1b61bea6839d11d	fair algorithms for learning in allocation problems		Settings such as lending and policing can be modeled by a centralized agent allocating a scarce resource (e.g. loans or police officers) amongst several groups, in order to maximize some objective (e.g. loans given that are repaid, or criminals that are apprehended). Often in such problems fairness is also a concern. One natural notion of fairness, based on general principles of equality of opportunity, asks that conditional on an individual being a candidate for the resource in question, the probability of actually receiving it is approximately independent of the individual's group. For example, in lending this would mean that equally creditworthy individuals in different racial groups have roughly equal chances of receiving a loan. In policing it would mean that two individuals committing the same crime in different districts would have roughly equal chances of being arrested.  In this paper, we formalize this general notion of fairness for allocation problems and investigate its algorithmic consequences. Our main technical results include an efficient learning algorithm that converges to an optimal fair allocation even when the allocator does not know the frequency of candidates (i.e. creditworthy individuals or criminals) in each group. This algorithm operates in a censored feedback model in which only the number of candidates who received the resource in a given allocation can be observed, rather than the true number of candidates in each group. This models the fact that we do not learn the creditworthiness of individuals we do not give loans to and do not learn about crimes committed if the police presence in a district is low.  As an application of our framework and algorithm, we consider the predictive policing problem, in which the resource being allocated to each group is the number of police officers assigned to each district. The learning algorithm is trained on arrest data gathered from its own deployments on previous days, resulting in a potential feedback loop that our algorithm provably overcomes. In this case, the fairness constraint asks that the probability that an individual who has committed a crime is arrested should be independent of the district in which they live. We investigate the performance of our learning algorithm on the Philadelphia Crime Incidents dataset.	algorithm;centralized computing;fairness measure;feedback	Hadi Elzayn;Shahin Jabbari;Christopher Jung;Michael Kearns;Seth Neel;Aaron Roth;Zachary Schutzman	2019	CoRR	10.1145/3287560.3287571	mathematics;allocator;algorithm;loan;predictive policing;feedback loop;resource allocation	Theory	-6.711968399941714	-4.726689070043124	51686
24eef0f7fabaea310b69924037e4c1cd321de788	online vs. offline behavior: how to design strategic agents for distributed coordinator-free environments	behavioral experiments;game theory;development;offline behavior;humans peer to peer computing economic forecasting intelligent agent game theory environmental economics design methodology social network services control systems;distributed processing;resource management;games;behavioral experiments online behavior offline behavior distributed systems development;humans;economics;peer to peer computing;offline players strategic agents distributed coordinator free environments highly distributed coordinator free systems peer to peer systems free riding incentive mechanisms complex settings formal analyses structured p2p systems online players;distributed systems;peer to peer computing distributed processing;online behavior	Highly distributed coordinator-free systems with many agents, such as peer-to-peer systems, are receiving much interest in research and practice. In such systems, free riding continues to be a severe and difficult problem. To reach a high degree of cooperation, researchers have proposed numerous incentive mechanisms against free riding. Our concern in turn is a more profound question: Under which circumstances do human individuals indeed resort to effective strategies in those settings? This question is important as humans control the agents. In economics, mimicking the behavior of humans is an accepted method for strategy design. In particular, this holds for complex settings where formal analyses must rely on simplifying assumptions that do not hold in reality. By means of extensive human experiments in one specific setup, namely structured P2P systems, this paper provides evidence that strategies in the settings under investigation often are the result of a non-strategic perspective. This perspective lets participants overlook obvious strategies that are effective. Further, our experiments reveal the following: Online players, i.e., individuals taking part in the system directly, intuitively tend to find better strategies than offline players, i.e., individuals who just implement agents. Offline players have difficulties predicting the strategies of others and overestimate the quality of their strategies. We conclude that a combination of 'online' and 'offline' strategy design is a cost-efficient and effective solution.	cost efficiency;experiment;online and offline;peer-to-peer	Stephan Schosser;Klemens Böhm;Bodo Vogt	2008	2008 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology	10.1109/WIIAT.2008.10	games;game theory;simulation;computer science;knowledge management;artificial intelligence;resource management;distributed computing;world wide web	ECom	-13.621140800706424	-11.141329263658378	51702
1ad369a882286505ba3874b0106230503a086a6d	new and surprising ways to be mean. adversarial npcs with coupled empowerment minimisation		Creating Non-Player Characters (NPCs) that can react robustly to unforeseen player behaviour or novel game content is difficult and time-consuming. This hinders the design of believable characters, and the inclusion of NPCs in games that rely heavily on procedural content generation. We have previously addressed this challenge by means of empowerment, a model of intrinsic motivation, and demonstrated how a coupled empowerment maximisation (CEM) policy can yield generic, companion-like behaviour. In this paper, we extend the CEM framework with a minimisation policy to give rise to adversarial behaviour. We conduct a qualitative, exploratory study in a dungeon-crawler game, demonstrating that CEM can exploit the affordances of different content facets in adaptive adversarial behaviour without modifications to the policy. Changes to the level design, underlying mechanics and our character’s actions do not threaten our NPC’s robustness, but yield new and surprising ways to be mean.	adversary (cryptography);interaction;level design;np-completeness;nonlinear gameplay;procedural generation;web crawler	Christian Guckelsberger;Christoph Salge;Julian Togelius	2018	CoRR			HCI	-14.493568614248609	-10.914748240670262	51723
